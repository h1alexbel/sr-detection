${RULTOR:+sudo} npm install -g ghminer@0.0.7

changed 7 packages in 1s

1 package is looking for funding
  run `npm fund` for details
npm notice
npm notice New major version of npm available! 10.8.2 -> 11.1.0
npm notice Changelog: https://github.com/npm/cli/releases/tag/v11.1.0
npm notice To update run: npm install -g npm@11.1.0
npm notice
poetry self add 'poethepoet[poetry_plugin]'
Using version ^0.32.2 for poethepoet

Updating dependencies
Resolving dependencies...

Package operations: 0 installs, 1 update, 0 removals

  - Updating poethepoet (0.32.0 -> 0.32.2)

Writing lock file
cd sr-data && poetry install
Skipping virtualenv creation, as specified in config file.
Installing dependencies from lock file

No dependencies to install or update

Installing the current project: sr-data (0.0.0)
cd sr-train && poetry install
Skipping virtualenv creation, as specified in config file.
Installing dependencies from lock file

No dependencies to install or update

Installing the current project: sr-train (0.0.0)
Skipping virtualenv creation, as specified in config file.
Installing dependencies from lock file

No dependencies to install or update

Installing the current project: sr-detection (0.0.0)
mkdir -p collection/2024-2025
ghminer --query "stars:>10 language:java size:>=20 mirror:false template:false NOT android" --start "2024-01-01" --end "2025-01-01" --tokens "$PATS" --filename "repos"
Running ghminer@0.0.7
Compiled search query: stars:>10 language:java size:>=20 mirror:false template:false NOT android created:2024-01-01..2025-01-01
Total results: 4639
Checking if date range should be split: stars:>10 language:java size:>=20 mirror:false template:false NOT android created:2024-01-01..2024-07-02
{ search: { repositoryCount: 1378 } }
Results: 1378

Splitting 2024-01-01..2024-07-02 into 183 days...
Checking if date range should be split: stars:>10 language:java size:>=20 mirror:false template:false NOT android created:2024-01-01..2024-04-01
{ search: { repositoryCount: 738 } }
Results: 738

Extracted 10 results for 2024-01-01..2024-04-01...


Rate Limit: {
  limit: 5000,
  cost: 1,
  remaining: 4996,
  used: 4,
  resetAt: '2025-02-03T08:24:37Z',
  nodeCount: 0
}
hasNextPage: true
endCursor: Y3Vyc29yOjEw

Extracted 20 results for 2024-01-01..2024-04-01...


Rate Limit: {
  limit: 5000,
  cost: 1,
  remaining: 4995,
  used: 5,
  resetAt: '2025-02-03T08:24:37Z',
  nodeCount: 0
}
hasNextPage: true
endCursor: Y3Vyc29yOjIw
ClientError: GraphQL Error (Code: 502): {"response":{"status":502,"headers":{}},"request":{"query":"query ($searchQuery: String!, $first: Int, $after: String) {\n  search(query: $searchQuery, type: REPOSITORY, first: $first, after: $after) {\n    repositoryCount\n    nodes {\n      ... on Repository {\n        nameWithOwner\n        defaultBranchRef {\n          name\n        }\n        createdAt\n        refs(refPrefix: \"refs/heads/\") {\n          totalCount\n        }\n        defaultBranchRef {\n          name\n          target {\n            repository {\n              object(expression: \"HEAD:README.md\") {\n                ... on Blob {\n                  text\n                }\n              }\n            }\n          }\n        }\n        releases(first:1) {\n          edges {\n            node {\n              id\n            }\n          }\n          totalCount\n        }\n        issues(states: [OPEN]) {\n          totalCount\n        }\n        object(expression: \"HEAD:.github/workflows/\") {\n          ... on Tree {\n            entries {\n              name\n              object {\n                ... on Blob {\n                  byteSize\n                }\n              }\n            }\n          }\n        }\n        licenseInfo {\n          spdxId\n        }\n      }\n    }\n    pageInfo {\n      endCursor\n      hasNextPage\n    }\n  }\n}\n","variables":{"searchQuery":"stars:>10 language:java size:>=20 mirror:false template:false NOT android created:2024-01-01..2024-04-01","first":10,"after":"Y3Vyc29yOjIw"}}}
    at runRequest (file:///usr/lib/node_modules/ghminer/node_modules/graphql-request/build/legacy/helpers/runRequest.js:26:16)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async GraphQLClient.request (file:///usr/lib/node_modules/ghminer/node_modules/graphql-request/build/legacy/classes/GraphQLClient.js:66:26)
    at async fetchResultsBatch (/usr/lib/node_modules/ghminer/src/index.js:103:18)
    at async fetchResultsBatch (/usr/lib/node_modules/ghminer/src/index.js:122:14)
    at async fetchResultsBatch (/usr/lib/node_modules/ghminer/src/index.js:122:14)
    at async fetchAllResults (/usr/lib/node_modules/ghminer/src/index.js:202:28) {
  response: {
    status: 502,
    headers: HeadersList {
      cookies: null,
      [Symbol(headers map)]: [Map],
      [Symbol(headers map sorted)]: null
    }
  },
  request: {
    query: 'query ($searchQuery: String!, $first: Int, $after: String) {\n' +
      '  search(query: $searchQuery, type: REPOSITORY, first: $first, after: $after) {\n' +
      '    repositoryCount\n' +
      '    nodes {\n' +
      '      ... on Repository {\n' +
      '        nameWithOwner\n' +
      '        defaultBranchRef {\n' +
      '          name\n' +
      '        }\n' +
      '        createdAt\n' +
      '        refs(refPrefix: "refs/heads/") {\n' +
      '          totalCount\n' +
      '        }\n' +
      '        defaultBranchRef {\n' +
      '          name\n' +
      '          target {\n' +
      '            repository {\n' +
      '              object(expression: "HEAD:README.md") {\n' +
      '                ... on Blob {\n' +
      '                  text\n' +
      '                }\n' +
      '              }\n' +
      '            }\n' +
      '          }\n' +
      '        }\n' +
      '        releases(first:1) {\n' +
      '          edges {\n' +
      '            node {\n' +
      '              id\n' +
      '            }\n' +
      '          }\n' +
      '          totalCount\n' +
      '        }\n' +
      '        issues(states: [OPEN]) {\n' +
      '          totalCount\n' +
      '        }\n' +
      '        object(expression: "HEAD:.github/workflows/") {\n' +
      '          ... on Tree {\n' +
      '            entries {\n' +
      '              name\n' +
      '              object {\n' +
      '                ... on Blob {\n' +
      '                  byteSize\n' +
      '                }\n' +
      '              }\n' +
      '            }\n' +
      '          }\n' +
      '        }\n' +
      '        licenseInfo {\n' +
      '          spdxId\n' +
      '        }\n' +
      '      }\n' +
      '    }\n' +
      '    pageInfo {\n' +
      '      endCursor\n' +
      '      hasNextPage\n' +
      '    }\n' +
      '  }\n' +
      '}\n',
    variables: {
      searchQuery: 'stars:>10 language:java size:>=20 mirror:false template:false NOT android created:2024-01-01..2024-04-01',
      first: 10,
      after: 'Y3Vyc29yOjIw'
    }
  }
}
TypeError: result is not iterable (cannot read property undefined)
    at fetchAllResults (/usr/lib/node_modules/ghminer/src/index.js:203:21)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
TypeError: Cannot read properties of undefined (reading 'map')
    at writeFiles (/usr/lib/node_modules/ghminer/src/index.js:235:33)
    at /usr/lib/node_modules/ghminer/src/index.js:263:5
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
cd sr-data && poetry poe pipeline --representation resources/pipeline.json --steps pulls,filter,workflows,junit --pipes "../steps.txt" --out "../files.txt"
Poe => pipeline --representation resources/pipeline.json --steps pulls,filter,workflows,junit --pipes ../steps.txt --out ../files.txt
2025-02-03 07:24:53.284 | DEBUG    | sr_data.pipeline:main:70 - Built step: just pulls "../repos.csv" $GH_TOKEN "../repos-with-pulls.csv"
2025-02-03 07:24:53.284 | DEBUG    | sr_data.pipeline:main:70 - Built step: just filter "../repos-with-pulls.csv" "../filtered.txt" "../after-filter.csv"
2025-02-03 07:24:53.284 | DEBUG    | sr_data.pipeline:main:70 - Built step: just workflows "../after-filter.csv" "../after-workflows.csv"
2025-02-03 07:24:53.284 | DEBUG    | sr_data.pipeline:main:70 - Built step: just junit "../after-workflows.csv" $GH_TOKEN "../after-junit.csv"
2025-02-03 07:24:53.285 | INFO     | sr_data.pipeline:main:75 - The following commands will be executed:
 ['just pulls "../repos.csv" $GH_TOKEN "../repos-with-pulls.csv"', 'just filter "../repos-with-pulls.csv" "../filtered.txt" "../after-filter.csv"', 'just workflows "../after-filter.csv" "../after-workflows.csv"', 'just junit "../after-workflows.csv" $GH_TOKEN "../after-junit.csv"']
2025-02-03 07:24:53.285 | INFO     | sr_data.pipeline:main:76 - We expect the following files to be generated: ['repos.csv', 'repos-with-pulls.csv', 'after-filter.csv', 'after-workflows.csv', 'after-junit.csv']
cd sr-data && poetry poe pulls --repos "../repos.csv" --token "REDACTED" --out "../repos-with-pulls.csv"
Poe => pulls --repos ../repos.csv --token REDACTED --out ../repos-with-pulls.csv
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/sr-data/src/sr_data/steps/pulls.py", line 32, in main
    frame = pd.read_csv(repos)
            ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '../repos.csv'
error: Recipe `pulls` failed on line 78 with exit code 1
cd sr-data && poetry poe filter --repos "../repos-with-pulls.csv" --out "../after-filter.csv" --filtered "../filtered.txt"
Poe => filter --repos ../repos-with-pulls.csv --out ../after-filter.csv --filtered ../filtered.txt
2025-02-03 07:24:56.520 | INFO     | sr_data.steps.filter:main:40 - Start filtering...
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/sr-data/src/sr_data/steps/filter.py", line 42, in main
    frame = pd.read_csv(repos)
            ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '../repos-with-pulls.csv'
error: Recipe `filter` failed on line 103 with exit code 1
cd sr-data && poetry poe workflows --repos ../after-filter.csv --out ../after-workflows.csv
Poe => workflows --repos ../after-filter.csv --out ../after-workflows.csv
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/sr-data/src/sr_data/steps/workflows.py", line 33, in main
    frame = pd.read_csv(repos)
            ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '../after-filter.csv'
error: Recipe `workflows` failed on line 140 with exit code 1
cd sr-data && poetry poe junit --repos "../after-workflows.csv" --out "../after-junit.csv" --token "REDACTED"
Poe => junit --repos ../after-workflows.csv --out ../after-junit.csv --token REDACTED
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/sr-data/src/sr_data/steps/junit_tests.py", line 40, in main
    frame = pd.read_csv(repos)
            ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '../after-workflows.csv'
error: Recipe `junit` failed on line 88 with exit code 1
"/root/.cargo/bin"/just numerical "..//after-junit.csv" "..//numerical.csv"
cd sr-data && poetry poe numerical --repos "..//after-junit.csv" --out "..//numerical.csv"
Poe => numerical --repos ..//after-junit.csv --out ..//numerical.csv
2025-02-03 07:24:59.574 | INFO     | sr_data.steps.numerical:main:30 - Creating dataset with all numerical data...
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/sr-data/src/sr_data/steps/numerical.py", line 31, in main
    frame = pd.read_csv(repos)
            ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '..//after-junit.csv'
error: Recipe `numerical` failed on line 183 with exit code 1
error: Recipe `datasets` failed on line 161 with exit code 1
